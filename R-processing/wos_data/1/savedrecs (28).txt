FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Karsten-Berier, N
   Karsten, M
   Schmitt, J
   Steinmetz, R
AF Karsten-Berier, N
   Karsten, M
   Schmitt, J
   Steinmetz, R
TI A modular approach to mobile QoS - Signaling motivation, design &
   implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mobility; quality of service; signaling protocols; internet architecture
AB In order to support mobile multimedia applications in next generation wireless IP-based networks, it is necessary to deliver seamless voice, video and data at high quality. Therefore, session mobility and Quality of Service (QoS) for mobile end systems are required. Within this article, the authors point out a new way to approach the problem. Instead of tightly coupling a modified QoS signaling mechanism with a certain mobility mechanism, a more generic and long-term solution is proposed and exemplified on the basis of existing IETF protocols. The connection-less IP network layer is enhanced by a lightweight and truly optional connection-oriented mobile network service, which offers the possibility to establish soft state unicast connections at the network layer. Hence, a connection-oriented network service is available within a radio access network ( RAN) architecture to all end systems-mobile or fixed-independent of the application. Thereby, it is possible to integrate QoS and connectivity signaling for mobile end systems, as well as other connection-oriented services like explicit routing or load balancing.
C1 Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   TH Darmstadt, Multimedia Commun Lab, KOM, Darmstadt, Germany.
C3 University of Waterloo; Technical University of Darmstadt
RP Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM Nicole.Berier@kom.tu-darmstadt.de; mkarsten@uwaterloo.ca;
   jschmitt@informatik.uni-kl.de; Ralf.Steinmetz@kom.tu-darmstadt.de
RI Steinmetz, Patrick R. H./AAD-4093-2022
OI Steinmetz, Ralf/0000-0002-6839-9359
CR [Anonymous], 2001, 3031 RFC
   AWDUCHE D, 2001, 3209RSVPTE RFC
   AWDUCHE DO, 2002, OIVERVIEW PRINCIPLES
   BERIER N, 2000, P MOB MULT COMM MOMU
   BLACK D, 2000, 2983 RFC
   Braden R., 1994, INTEGRATED SERVICES
   BRADEN R, 1997, 2205 RFC RSVP
   CAMPBELL AT, 1999, IEEE WIR COMM NETW C
   CHO K, 2001, THESIS KEIO U JAPAN
   FRASER K, 2000, MPLS LINUX
   GUSTAFSSON E, 2002, IN PRESS INTERNET DR
   JAMOUSSI B, 2002, 3212 RFC
   KARSTEN M, 2001, P 9 IEEE IFIP INT WO
   KARSTEN M, 1999, P INT C COMP COMM IC
   KARSTEN M, 2001, P 20 ANN JOINT C IEE
   LEU JR, 2001, MPLS LINUX
   LI T, 1998, 2430 RFC PASTE
   MAHADEVAN I, 1998, 1 ACM INT WORKSH WIR
   MAHMOODIAN A, 1999, IFIP TC 6 5 INT C BR
   Perkins C.E., 1998, Mobile IP - Design Principles and Practices
   PERKINS CE, 1996, RFC 2002 IP MOBILITY
   RAMJEE R, 1999, P 7 ANN INT C NETW P
   ROSE MT, 1989, OPEN BOOK PRACTICAL
   SCHELEN O, 1997, P 22 IEEE C COMP NET
   SINGH S, 1996, JSAC COMPUTER COMMUN, V19
   SOLOMON J, 1996, RFC2005 APPL STATEME
   TALUKDAR A, 1998, P ACTS MOB SUMM 98 J
   TERZIS A, 2000, RFC2746 RSVP
   TERZIS A, 1999, P IEEE INFOCOM 99 MA
   ZENG JWM, 2000, P NETW 2000 C MAY
NR 30
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2004
VL 22
IS 2
BP 117
EP 135
DI 10.1023/B:MTAP.0000011931.70169.7e
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 762YR
UT WOS:000188035600002
DA 2024-07-18
ER

PT J
AU Aliradi, R
   Ouamane, A
AF Aliradi, Rachid
   Ouamane, Abdelmalik
TI A novel descriptor (LGBQ) based on Gabor filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binarisation Gabor filter; Face verification; LGBQ; Tensor subspace;
   MWPCA; TEDA; LBP; LPQ
AB Recently, many existing automatic facial verification methods have focused on learning the optimal distance measurements between facials. Especially in the case of learning facial features by similarity which can make the proposed descriptors too weak. To justify filling this gap, we have proposed a new descriptor called Local Binary Gabor Quantization (LGBQ) for 3/2D face verification based on Gabor filters and uses tensor subspace transformation. Our main idea is to binarize the responses of eight Gabor filters based on eight orientations theta as a binary code which is converted into a decimal number and combines the advantage of three methods: Gabor, LBP, and LPQ. These descriptors provide more robustness to shape variations in face parts such as expression, pose, lighting, and scale. To do this, we have chosen to merge two techniques which are multilinear whitened principal component analysis (MWPCA) and tensor exponential discriminant analysis (TEDA). The experimentation is using two publicly available databases, namely, Bhosphorus, and CASIA 3D face database. The results show the supremacy of our method in terms of accuracy and execution time compared to state-of-the-art methods.
C1 [Aliradi, Rachid] Res Ctr Sci & Tech Informat CERIST, Algiers, Algeria.
   [Ouamane, Abdelmalik] Univ Biskra, Dept Elect Engn, Lab LI3C, Biskra, Algeria.
C3 Centre de Recherche sur l'Information Scientifique et Technique
   (CERIST); Universite Mohamed Khider Biskra
RP Aliradi, R (corresponding author), Res Ctr Sci & Tech Informat CERIST, Algiers, Algeria.
EM roliradi@gmail.com
CR Al-Shiha AAM, 2014, PATTERN RECOGN, V47, P544, DOI 10.1016/j.patcog.2013.08.005
   Aliradi R., 2023, BSIF Features Learning using TXQEDA Tensor Subspace for kinship verification
   Aliradi R, 2019, Doctoral dissertation
   Aliradi R, 2018, Multimed Tools Appl, V28, P1
   Aliradi R, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Aliradi R, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY - WORKSHOPS (WI-IAT), VOL 3, P30, DOI 10.1109/WI-IAT.2013.212
   Almuashi M, 2022, MULTIMED TOOLS APPL, V81, P39311, DOI 10.1007/s11042-022-12735-0
   Amrane A., 2014, Int J Adv Media Commun, V5, P182, DOI [10.1504/IJAMC.2014.060496, DOI 10.1504/IJAMC.2014.060496]
   [Anonymous], 2010, Communication-avoiding Krylov subspace methods
   Belahcene M., 2011, 2011 3rd European Workshop on Visual Information Processing, P252, DOI 10.1109/EuVIP.2011.6045519
   Bessaoudi M, 2021, APPL INTELL, V51, P3534, DOI 10.1007/s10489-020-02044-0
   Bessaoudi M, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Chouchane A, 2023, 2023 IEEE INT C IMAG
   Chouchane A, 2023, PATTERN ANAL APPL, V26, P1191, DOI 10.1007/s10044-023-01144-0
   Chowdhury PR, 2023, COGN SYST RES, V78, P1, DOI 10.1016/j.cogsys.2022.11.006
   Dakin SC, 2009, J VISION, V9, DOI 10.1167/9.4.2
   Daugman J, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P715, DOI 10.1016/B978-0-12-374457-9.00025-1
   Duan B, 2020, P IEEE CVF C COMP VI
   Dutta K, 2021, APPL INTELL, V51, P2500, DOI 10.1007/s10489-020-02012-8
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Elaiwat S., 2022, An automated system for cephalometric soft-tissue landmark detection
   Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981
   Feng JY, 2019, ADV INTELL SYST COMP, V670, P123, DOI 10.1007/978-981-10-8971-8_12
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Guo HJ, 2020, APPL INTELL, V50, P1222, DOI 10.1007/s10489-019-01574-6
   Guo YC, 2018, INFORMATION, V9, DOI 10.3390/info9030048
   Hamouchene I, 2016, SIGNAL IMAGE VIDEO P, V10, P1361, DOI 10.1007/s11760-016-0900-y
   Laiadi O, 2020, NEUROCOMPUTING, V377, P286, DOI 10.1016/j.neucom.2019.10.055
   Laiadi O, 2019, APPL INTELL, V49, P3894, DOI 10.1007/s10489-019-01489-2
   Li HH, 2019, APPL INTELL, V49, P2956, DOI 10.1007/s10489-019-01427-2
   Liu H, 2021, NEUROCOMPUTING, V433, P310, DOI 10.1016/j.neucom.2020.09.068
   Liu TT, 2020, IEEE T IND INFORM, V16, P544, DOI 10.1109/TII.2019.2934728
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Ming Y, 2014, NEUROCOMPUTING, V129, P445, DOI 10.1016/j.neucom.2013.09.014
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ouamane A., 2015, Pattern Recognition and Image Analysis, V25, P603
   Ouamane A, 2015, Reconnaissance Biometrique par Fusion Multimodale du Visage 2D et 3D
   Ouamane A, 2017, COMPUT ELECTR ENG, V62, P68, DOI 10.1016/j.compeleceng.2017.01.001
   PR SD, 2023, Multimed Tools Appl, P1
   Saoud A, 2020, MULTIMED TOOLS APPL, V79, P23071, DOI 10.1007/s11042-020-09095-y
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Siddiqi MH, 2018, APPL INTELL, V48, P2912, DOI 10.1007/s10489-017-1121-y
   Singhal M, 2024, MULTIMED TOOLS APPL, V83, P30981, DOI 10.1007/s11042-023-16683-1
   Wang B, 2020, VISUAL COMPUT, V36, P1897, DOI 10.1007/s00371-019-01779-3
   Wang Q, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23187715
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu Y, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107405
   Xu C, 2004, CHINESE C BIOMETRIC
   Yusoff N., 2019, Int. J. Adv. Comput. Res, V9, P197, DOI [10.19101/ijacr.pid37, DOI 10.19101/IJACR.PID37]
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DL, 2022, CIRC SYST SIGNAL PR, V41, P425, DOI 10.1007/s00034-021-01788-5
   Zhang GP, 2011, PATTERN RECOGN LETT, V32, P1009, DOI 10.1016/j.patrec.2011.02.004
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11669
EP 11686
DI 10.1007/s11042-023-17853-x
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001133108800002
DA 2024-07-18
ER

PT J
AU Khmag, A
AF Khmag, Asem
TI Image dehazing and defogging based on second-generation wavelets and
   estimation of transmission map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Edge detection; Atmospheric light; Transmission map; Image dehazing
ID VISIBILITY; REMOVAL; WEATHER; VISION
AB Image dehazing is one of the pivotal topics in computer vision arena due to its significant effects on improving the foggy images that taken under poor weather conditions. Problems such as halo outliers and over-saturation are presented in the ridges i.e. high-frequency components of the hazy images which lead to false guesstimate of atmospheric light and transmission depth that negatively results on the task of visibility restoration image. In this paper, the proposed method has the ability to deal with hazy images with several haze density while most of state-of-the-art dehazing techniques suffer from lack of contrast of the observed object in the dehazed images due to unequal distribution of transmission depth. In order to achieve high visual quality from the contaminated hazy images, the proposed method is designed according to semi soft thresholding and Gamma transformation where the second-generation wavelet transformation is used to improve the transmission map. Qualitative and quantitative results showed that, the proposed method outperforms sophisticated state-of-the-art image haze removal techniques both in visual image quality and time efficiency.
C1 [Khmag, Asem] Univ Zawia, Fac Engn, Comp Syst Engn, Az Zawia, Libya.
RP Khmag, A (corresponding author), Univ Zawia, Fac Engn, Comp Syst Engn, Az Zawia, Libya.
EM Khmaj2002@gmail.com
OI Khmag, Asem/0000-0002-1360-5346
CR Afridi IU, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217246
   Anan S, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030285
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Choudhury, 2005, ACM SIGGRAPH 2005 Courses, P5, DOI 10.1145/1198555.1198565
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Khmag A, 2023, SOFT COMPUT, V27, P17505, DOI 10.1007/s00500-023-09204-7
   Khmag A, 2018, VISUAL COMPUT, V34, P675, DOI 10.1007/s00371-017-1406-5
   Khmag A, 2017, VISUAL COMPUT, V33, P1141, DOI 10.1007/s00371-016-1273-5
   Khmag A, 2016, IEEJ T ELECTR ELECTR, V11, P339, DOI 10.1002/tee.22223
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lin Z., 2012, Open J. Appl. Sci, V2, P123
   Linan Y., 2012, TELKOMNIKA INDONESIA, V10, P1644, DOI DOI 10.11591/TELK0MNIKA.V10I7.1556
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sandeep M., 2014, INT J RES STUD COMPU, V1, P44
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Tripathi AK, 2012, 2012 IEEE INT C SIGN, P1
   Wang MW, 2021, OPTOELECTRON LETT, V17, P40, DOI 10.1007/s11801-021-0081-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xingyong Lv, 2010, 2010 Pacific Graphics (PG). Proceedings 18th Pacific Conference on Computer Graphics and Applications, P62, DOI 10.1109/PacificGraphics.2010.16
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Zou YY, 2021, IEEE ACCESS, V9, P11416, DOI 10.1109/ACCESS.2021.3050260
NR 37
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17819-z
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800003
DA 2024-07-18
ER

PT J
AU Chen, SG
   Wang, Q
   Zhu, X
AF Chen, Siguang
   Wang, Qian
   Zhu, Xi
TI Energy and delay co-aware intelligent computation offloading and
   resource allocation for fog computing networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fog computing; Computation offloading; Deep learning; Deep reinforcement
   learning; Resource allocation; Joint optimization
ID INDUSTRIAL INTERNET; MOBILE; FRAMEWORK; COMMUNICATION; ALGORITHM
AB In the data-rich everything-connected world, rapid and green data processing is essential, especially for some delay-sensitive and computation-intensive tasks. Motivated by these requirements, an energy and delay co-aware intelligent fog computation offloading and resource allocation scheme is conceived in this paper. Specifically, we formulate a weighted sum minimization problem of the task completion time and energy consumption at the local fog to achieve efficient task computation. A deep learning-based joint offloading decision and resource allocation (DL-JODRA) algorithm is developed to address this problem by jointly optimizing the offloading action, local CPU, bandwidth and external CPU occupation ratios. The optimal offloading decision based comprehensive optimization consideration of network resources further improves the network efficiency. Subsequently, to improve the efficiency and solution in a large-scale network scenario, a deep reinforcement learning-based joint offloading decision and resource allocation (DRL-JODRA) algorithm is constructed to obtain the optimal offloading and resource allocation policy. This approach is more suitable and stable for the solution of continuous-discrete action space by integrating the design of probabilistic discrete operation and inverting the gradient update. Finally, the extensive simulation results demonstrate that the proposed DL-JODRA and DRL-JODRA algorithms can rapidly achieve optimal offloading decision and resource allocation and gain a significant reduction in network costs (i.e., delay and energy) compared with other benchmark methods.
C1 [Chen, Siguang; Wang, Qian; Zhu, Xi] Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Chen, SG (corresponding author), Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing, Peoples R China.
EM sgchen@njupt.edu.cn; qian_wang96@163.com; zhuxi1994@foxmail.com
RI Zhu, Xi/JWP-6566-2024; Chen, Siguang/AAG-2934-2020
OI Zhu, Xi/0000-0001-9467-2753; Chen, Siguang/0000-0002-7375-0393
FU National Natural Science Foundation of China
FX No Statement Available
CR Alelaiwi A, 2019, J PARALLEL DISTR COM, V127, P58, DOI 10.1016/j.jpdc.2019.01.003
   Amma NGB, 2020, FUTURE GENER COMP SY, V113, P255, DOI 10.1016/j.future.2020.07.020
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Bozorgchenani A, 2018, IEEE WCNC
   Chen SG, 2020, IEEE T GREEN COMMUN, V4, P566, DOI 10.1109/TGCN.2019.2960767
   Chen SG, 2020, IEEE T SUST COMPUT, V5, P95, DOI 10.1109/TSUSC.2019.2906729
   Chen SG, 2017, IEEE INTERNET THINGS, V4, P1716, DOI 10.1109/JIOT.2017.2709810
   Chen YL, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148698
   Cisco, 2016, Cisco global cloud index: Forecast and methodology, 2015-2000
   Du JB, 2020, IEEE INTERNET THINGS, V7, P9517, DOI 10.1109/JIOT.2020.3003449
   Eshratifar AE, 2018, PR GR LAK SYMP VLSI, P111, DOI 10.1145/3194554.3194565
   Feng J, 2020, IEEE INTERNET THINGS, V7, P6214, DOI 10.1109/JIOT.2019.2961707
   Han GJ, 2021, IEEE INTERNET THINGS, V8, P17747, DOI 10.1109/JIOT.2021.3082633
   Huang L, 2020, IEEE T MOBILE COMPUT, V19, P2581, DOI 10.1109/TMC.2019.2928811
   Huang L, 2022, MOBILE NETW APPL, V27, P1123, DOI 10.1007/s11036-018-1177-x
   Jiang FB, 2020, IEEE INTERNET THINGS, V7, P9278, DOI 10.1109/JIOT.2020.2988457
   Jiang FB, 2020, IEEE INTERNET THINGS, V7, P6252, DOI 10.1109/JIOT.2019.2954503
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lillicrap, 2015, ARXIV150902971, P1
   Lu HF, 2020, FUTURE GENER COMP SY, V102, P847, DOI 10.1016/j.future.2019.07.019
   Lu HD, 2020, IEEE INTERNET THINGS, V7, P9255, DOI 10.1109/JIOT.2020.2981557
   Ning ZL, 2019, IEEE INTERNET THINGS, V6, P4804, DOI 10.1109/JIOT.2018.2868616
   Pengfei Yao, 2019, 2019 IEEE International Conference on Smart Internet of Things (SmartIoT). Proceedings, P417, DOI 10.1109/SmartIoT.2019.00074
   Ran XK, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P42, DOI 10.1145/3097895.3097903
   Ren YJ, 2021, IEEE T IND INFORM, V17, P4978, DOI 10.1109/TII.2020.3021024
   Salmani M, 2020, IEEE T SIGNAL PROCES, V68, P1646, DOI 10.1109/TSP.2020.2970309
   Satyanarayanan M, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.82
   Shah SDA, 2019, P IEEE REGION 10 ANN, P1193
   Sheng M, 2020, IEEE T COMMUN, V68, P1524, DOI 10.1109/TCOMM.2019.2959338
   Wang XF, 2020, IEEE COMMUN SURV TUT, V22, P869, DOI 10.1109/COMST.2020.2970550
   Wang XF, 2019, IEEE NETWORK, V33, P156, DOI 10.1109/MNET.2019.1800286
   Wozniak M, 2021, IEEE T IND INFORM, V17, P5583, DOI 10.1109/TII.2020.3021689
   Xu ZW, 2021, IEEE T IND INFORM, V17, P5118, DOI 10.1109/TII.2020.3007644
   Yang TT, 2020, IEEE INTERNET THINGS, V7, P5954, DOI 10.1109/JIOT.2019.2958662
   Ye JH, 2020, IEEE T MOBILE COMPUT, V19, P2076, DOI 10.1109/TMC.2019.2922602
   Yu S, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292514
   Zhang C, 2019, FUTURE GENER COMP SY, V96, P111, DOI 10.1016/j.future.2019.01.059
   Zhang K, 2019, IEEE INTERNET THINGS, V6, P7635, DOI 10.1109/JIOT.2019.2903191
   Zhao XL, 2019, FUTURE GENER COMP SY, V99, P346, DOI 10.1016/j.future.2019.04.039
   Zhu X, 2019, IEEE IPCCC, DOI 10.1109/ipccc47392.2019.8958729
   Zou JF, 2021, IEEE T COMPUT, V70, P228, DOI 10.1109/TC.2020.2987567
NR 41
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17775-8
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100001
DA 2024-07-18
ER

PT J
AU Mannem, K
   Rao, PN
   Reddy, SCM
AF Mannem, Kiran
   Rao, Pasumarthy Nageswara
   Reddy, S. Chandra Mohan
TI Power optimized intelligent Handoff mechanism for 5G-Heterogeneous
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Handoff; 5G wireless network; Heterogeneous system; Throughput; Optimal
   power consumption
AB The 5G-heterogeneous system has become worldwide in the current life scenario, advancing in many wireless applications. However, managing Handoff is a major issue because the improper Handoff procedure leads to high power consumption and less throughput ratio. Hence, the lower throughput ratio tends to report a poor data transmission rate. So, the current research work has planned to end these issues by executing a novel Wolf-based Power-Optimized Handoff (WbPOH) strategy for managing signal drop and power usage. WiMax and cellular network macrocells are created with several Small Cells (SC) to make the heterogeneous system. Hereafter, the fitness process of the grey wolf has afforded continuous monitoring for forecasting the nearest incoming signal of Handoff and work-free node prediction. Moreover, the power usage in this designed system has been optimized by making the workless node the sleep position. Apart from that, during the Handoff process, the designed WbPOH first enabled the single strongest near signal, and then the previous signal was lost. After that, parameters like throughput, network efficiency, and Handoff behaviour have been measured and validated with other conventional models. Furthermore, in the proposed novel WbPOH, 5Mbps throughput is obtained for the cellular network, and 5.2Mbps throughput is gained for the Worldwide Inter-operability for Microwave Access (WiMax) network. In addition, the recorded cellular network efficiency is 95%, and the WiMax network efficiency is 96%.
C1 [Mannem, Kiran; Reddy, S. Chandra Mohan] JNT Univ Anantapur, Dept Elect & Commun Engn, Ananthapuramu 515002, Andhra Pradesh, India.
   [Mannem, Kiran] Gokaraju Rangaraju Inst Engn & Technol, Dept Elect & Commun Engn, Hyderabad 500090, Telangana, India.
   [Rao, Pasumarthy Nageswara] Vardhaman Coll Engn, Dept Elect & Commun Engn, Hyderabad 501218, Telangana, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Gokaraju
   Rangaraju Institute of Engineering & Technology; Vardhaman College of
   Engineering
RP Mannem, K (corresponding author), JNT Univ Anantapur, Dept Elect & Commun Engn, Ananthapuramu 515002, Andhra Pradesh, India.; Mannem, K (corresponding author), Gokaraju Rangaraju Inst Engn & Technol, Dept Elect & Commun Engn, Hyderabad 500090, Telangana, India.
EM kiranmannem14@gmail.com; nrraop@yahoo.com; email2cmr@gmail.com
RI Mannem, Kiran/HMV-8920-2023; Nageswara Rao, Pasumarthy/AHD-3894-2022
OI Mannem, Kiran/0000-0002-2808-0941; Nageswara Rao,
   Pasumarthy/0000-0002-1234-0964
CR Abiri M, 2022, MULTIMED TOOLS APPL, V81, P12325, DOI 10.1007/s11042-021-11312-1
   Alablani IA, 2021, IEEE ACCESS, V9, P64224, DOI 10.1109/ACCESS.2021.3075324
   Alcaraz S., 2023, Network, V3, P142, DOI 10.3390/network3010007
   Alhabo M, 2022, WIRELESS PERS COMMUN, V122, P2113, DOI 10.1007/s11277-021-08983-2
   Ampririt Phudit, 2021, Advances in Internet, Data and Web Technologies. 9th International Conference on Emerging Internet, Data & Web Technologies (EIDWT-2021). Lecture Notes on Data Engineering and Communications Technologies (LNDECT 65), P24, DOI 10.1007/978-3-030-70639-5_3
   Cheng X, 2021, INT C BIG DAT AN CYB, DOI [10.1007/978-981-16-7466-2_105, DOI 10.1007/978-981-16-7466-2_105]
   Dhipa M, 2021, J AMB INTEL HUM COMP, V12, P7461, DOI 10.1007/s12652-020-02422-z
   Eappen G, 2021, ARAB J SCI ENG, V46, P3115, DOI 10.1007/s13369-020-05084-3
   El Menbawy N, 2023, J SUPERCOMPUT, V79, P20076, DOI 10.1007/s11227-023-05387-w
   Evangeline CS, 2022, PEER PEER NETW APPL, V15, P107, DOI 10.1007/s12083-021-01228-w
   Goh MI, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12112384
   Guo SW, 2021, CHIN CONTR CONF, P3011, DOI 10.23919/CCC52363.2021.9550412
   Jahangeer N, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4743
   Kaur J, 2021, IEEE ACCESS, V9, P23472, DOI 10.1109/ACCESS.2021.3051557
   Kulkarni SS, 2023, J INTERCONNECT NETW, V23, DOI 10.1142/S0219265922500098
   Lai SW, 2021, PHYS COMMUN-AMST, V45, DOI 10.1016/j.phycom.2021.101283
   Li XW, 2020, MULTIMED TOOLS APPL, V79, P33381, DOI 10.1007/s11042-018-6833-4
   Liu QY, 2021, MOBILE NETW APPL, V26, P27, DOI 10.1007/s11036-020-01718-w
   Mei LF, 2022, COMPUT NETW, V204, DOI 10.1016/j.comnet.2021.108736
   Mondal S, 2021, IEEE ACCESS, V9, P44463, DOI 10.1109/ACCESS.2021.3066554
   Ouamri MA, 2020, PHYS COMMUN-AMST, V39, DOI 10.1016/j.phycom.2020.101037
   Palas MR, 2021, COMPUT COMMUN, V174, P81, DOI 10.1016/j.comcom.2021.04.020
   Park D, 2020, J AMB INTEL HUM COMP, V11, P5913, DOI 10.1007/s12652-020-02101-z
   Peddi Soumya, 2022, Information and Communication Technology for Competitive Strategies (ICTCS 2020): ICT: Applications and Social Interfaces. Lecture Notes in Networks and Systems (191), P1057, DOI 10.1007/978-981-16-0739-4_97
   Pengcheng Zhou, 2021, 2021 8th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2021 7th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom), P167, DOI 10.1109/CSCloud-EdgeCom52276.2021.00039
   Pulligilla MK, 2023, INTERNET THINGS-NETH, V22, DOI 10.1016/j.iot.2023.100723
   Rani SN, 2023, WIRELESS PERS COMMUN, DOI 10.1007/s11277-023-10225-6
   Reddy PV, 2021, 2021 2 INT C SMART E, DOI [10.1109/ICOSEC51865.2021.9591629, DOI 10.1109/ICOSEC51865.2021.9591629]
   Sanchez JDV, 2021, ANN TELECOMMUN, V76, P155, DOI 10.1007/s12243-020-00799-8
   Singh R, 2021, IEEE INT CONF COMM, DOI [10.1109/ICSC53193.2021.9673197, 10.1109/ICCWorkshops50388.2021.9473593]
   Singla S, 2023, INT J SYST ASSUR ENG, V14, P474, DOI 10.1007/s13198-022-01820-0
   Stanic I., 2023, 2023 22 INT S INFOTE, DOI [10.1109/infoteh57020.2023.10094090, DOI 10.1109/INFOTEH57020.2023.10094090]
   Sun JN, 2020, IEEE WIREL COMMUN LE, V9, P1327, DOI 10.1109/LWC.2020.2990713
   Taha M, 2021, MULTIMED TOOLS APPL, V80, P26833, DOI 10.1007/s11042-021-10934-9
   Valiveti HB, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1079, DOI 10.1109/ICICT50816.2021.9358562
   Verma J, 2023, 2023 INT C COMM CIRC, DOI [10.1109/IC3S57698.2023.10169349, DOI 10.1109/IC3S57698.2023.10169349]
   Xue XS, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15020438
   Zaheeruddin, 2023, IETE TECH REV, V40, P822, DOI 10.1080/02564602.2023.2176934
   Zhao H, 2021, Smart Innov Syst Technol, P59, DOI [10.1007/978-981-15-5697-5_7, DOI 10.1007/978-981-15-5697-5_7]
NR 39
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17709-4
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100003
DA 2024-07-18
ER

PT J
AU Hamroun, M
   Lajmi, S
   Jallouli, M
   Souid, A
AF Hamroun, Mohamed
   Lajmi, Sonia
   Jallouli, Maryam
   Souid, Abdelbaki
TI Efficient text-based query based on multi-level and deep-semantic
   multimedia indexing and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Textual query; Classification; Semantic indexing; Relevance feedback;
   Query expansion; Concept; Context
ID SENTIMENT ANALYSIS; FUSION; ATTENTION
AB Recent technological advancements have led to a significant increase in the quantity and accessibility of videos. The decrease in video acquisition costs and the increase in memory capacity have made it possible to store large video collections in computer systems. To effectively exploit these collections, it is crucial to have tools that facilitate access and management. In this paper, we present a multimedia retrieval approach that prioritizes the user's needs by starting with a text-based query. The approach consists of two main parts: (i) a new multi-level and deep-semantic video classification indexing method, and (ii) a query expansion mechanism and relevance feedback system to improve the results based on the user's feedback. Our contribution is demonstrated through the implementation of the Deep-VISEN prototype and experiments on a collection of 2700 videos and 62838 images. The results show that our algorithm is effective and precise.
C1 [Hamroun, Mohamed] Univ Limoges, UMR CNRS 7252, XLIM, 123 Ave Albert Thomas, F-87060 Limoges, France.
   [Hamroun, Mohamed] 3iL Grp, 43 Rue St Anne, F-87015 Limoges, France.
   [Lajmi, Sonia; Jallouli, Maryam] Univ Sfax, MIRACL Lab, Technopole Sfax,POB 242, Sfax, Tunisia.
   [Lajmi, Sonia] Albaha Univ, Albaha, Saudi Arabia.
   [Souid, Abdelbaki] Gabes Univ, Natl Engn Sch Gabes, MACS Res Lab RL16ES22, Gabes 6029, Tunisia.
C3 Universite de Limoges; Centre National de la Recherche Scientifique
   (CNRS); Centre de Recherche en Numerique de Sfax (CRNS); Universite de
   Sfax; Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Al Baha University; Universite de Gabes
RP Hamroun, M (corresponding author), Univ Limoges, UMR CNRS 7252, XLIM, 123 Ave Albert Thomas, F-87060 Limoges, France.; Hamroun, M (corresponding author), 3iL Grp, 43 Rue St Anne, F-87015 Limoges, France.
EM mohamed.hamroun@unulim.fr; slajmi@bu.edu.sa; jallouli.maryam@gmail.com;
   souidabdelbaki@gmail.com
OI lajmi, sonia/0009-0009-1744-9078; HAMROUN, Mohamed/0000-0002-4618-8673
CR Amato F, 2015, DATA CENTRIC SYST AP, P291, DOI 10.1007/978-3-319-20062-0_14
   Azad HK, 2022, PATTERN RECOGN LETT, V158, P148, DOI 10.1016/j.patrec.2022.04.013
   Behmo R, 2008, 2008 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2008.4587840, DOI 10.1109/CVPR.2008.4587840]
   Belz A., 2015, P 4 WORKSH VIS LANG, V15, P104, DOI DOI 10.18653/V1/W15-2816
   Ben Halima M, 2013, Arxiv, DOI [arXiv:1308.3225, 10.48550/arXiv.1308.3225, DOI 10.48550/ARXIV.1308.3225]
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Chen FH, 2018, IEEE T MULTIMEDIA, V20, P997, DOI 10.1109/TMM.2017.2757769
   Chen J, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P743, DOI 10.1145/3442381.3450127
   Chin J, 1988, ACM CHIi
   Christel MG, 2005, LECT NOTES COMPUT SC, V3568, P134
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elleuch N, 2010, Regimvid at trecvid2010: semantic indexing, DOI [10.13140/2.1.4395.3607, DOI 10.13140/2.1.4395.3607]
   Elleuch N, 2015, MULTIMED TOOLS APPL, V74, P1397, DOI 10.1007/s11042-014-1955-9
   Ellouze N, CITOM: approche de construction incrementale d'une Topic Map multilingue
   Etter D, 2009, KB Video Retrieval at TRECVID 2011
   Faudemay P, 1997, EIGHTH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P172, DOI 10.1109/DEXA.1997.617264
   Feki I, 2012, Int J Comput Electr Eng, P515, DOI [10.7763/IJCEE.2012.V4.546, DOI 10.7763/IJCEE.2012.V4.546]
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Galanopoulos D., 2017, P 2017 ACM INT C MUL, P397, DOI DOI 10.1145/3078971.3079043
   Hamid A, 2017, Relevance feedback in information retrieval systems
   Hamroun M, 2018, P 20 INT C ENT INF S, P253, DOI [10.5220/0006806702530261, DOI 10.5220/0006806702530261]
   Hamroun M, 2019, INT DATABASE ENG APP, P199, DOI 10.1145/3331076.3331094
   HARMAN D, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hu XW, 2022, PROC CVPR IEEE, P17959, DOI 10.1109/CVPR52688.2022.01745
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   ieee, Development and application of a metric on semantic nets | IEEE Journals & Magazine | IEEE Xplore
   Janwe N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1870-9
   Jiang JJ, 1997, arXiv, DOI [10.48550/arXiv.cmp-lg/9709008, DOI 10.48550/ARXIV.CMP-LG/9709008]
   Jones K., 1971, Automatic keyword classification for information retrieval
   Kennedy L, 2007, A reranking approach for context-based concept fusion in video indexing and retrieval, P333, DOI [10.1145/1282280.1282331, DOI 10.1145/1282280.1282331]
   Kermany Daniel, 2018, Mendeley Data, V3
   keyworddiscovery, 2020, Keyword: query size by country
   Kingma D. P., 2014, arXiv
   Azad HK, 2019, Arxiv, DOI arXiv:1708.00247
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035
   Meng L, 2014, IEEE T KNOWL DATA EN, V26, P2293, DOI 10.1109/TKDE.2013.47
   Nguyen H, 2022, Arxiv, DOI arXiv:2012.15029
   Ntirogiannis K, 2011, PROC INT CONF DOC, P673, DOI 10.1109/ICDAR.2011.141
   Poria S, 2016, Convolutional mkl based multimodal emotion recognition and sentiment analysis, P439, DOI DOI 10.1109/ICDM.2016.0055
   PORTER M, 1982, Implementing a probabilistic information retrieval system
   Rashid U, 2016, INFORM SCIENCES, V370, P303, DOI 10.1016/j.ins.2016.07.072
   Resnik P, 1995, arXiv, DOI [10.48550/arXiv.cmp-lg/9511007, DOI 10.48550/ARXIV.CMP-LG/9511007]
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rossetto L, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P457, DOI 10.1145/3078971.3079012
   Shao Z, 2023, IEEE T MULTIMEDIA, V25, P8753, DOI 10.1109/TMM.2023.3241517
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Sjoberg M, 2009, PicSOM Experiments in TRECVID
   Slimi Jamel, 2013, 2013 11th International Workshop on Content-Based Multimedia Indexing (CBMI), P161, DOI 10.1109/CBMI.2013.6576575
   Slimi J, P 10 C OP RES AR INF, P213
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275
   statista, 2020, Statista: average number of search terms for online search queries in the united states as of january 2020
   SUS, A quick and dirty usability scale
   Toriah S.T.M., 2018, J Comput Commun, V6, P28, DOI [10.4236/jcc.2018.68003, DOI 10.4236/JCC.2018.68003]
   VANRIJSBERGEN CJ, 1986, COMPUT J, V29, P481, DOI 10.1093/comjnl/29.6.481
   VANRIJSBERGEN CJ, 1977, J DOC, V33, P106, DOI 10.1108/eb026637
   Vrochidis S, 2010, 2010 INT WORKSH CONT, P1, DOI [10.1109/CBMI.2010.5529884, DOI 10.1109/CBMI.2010.5529884]
   Worring M, 2006, LECT NOTES COMPUT SC, V4071, P533
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xu J, 2019, KNOWL-BASED SYST, V178, P61, DOI 10.1016/j.knosys.2019.04.018
   Xu J, 2019, APPL SOFT COMPUT, V80, P387, DOI 10.1016/j.asoc.2019.04.010
   Xu N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P152, DOI 10.1109/ISI.2017.8004895
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yu C.T., 1983, GEN TERM DEPENDENCE
   Yu JF, 2020, IEEE-ACM T AUDIO SPE, V28, P429, DOI 10.1109/TASLP.2019.2957872
   Zhang Z, 2016, Lecture Notes in Computer Science, P412, DOI [10.1007/978-3-319-27674-8_42, DOI 10.1007/978-3-319-27674-8_42]
   Zhao ZY, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102097
NR 71
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17256-y
EA NOV 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700005
DA 2024-07-18
ER

PT J
AU Kaur, H
   Rani, V
   Kumar, M
   Sachdeva, M
   Mittal, A
   Kumar, K
AF Kaur, Harmandeep
   Rani, Veenu
   Kumar, Munish
   Sachdeva, Monika
   Mittal, Ajay
   Kumar, Krishan
TI Federated learning: a comprehensive review of recent advances and
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Federated learning; IoT; Artificial intelligence; Machine learning
ID NETWORKS
AB Federated Learning is a promising technique for preserving data privacy that enables communication between distributed nodes without the need for a central server. Previously, data privacy concerns have made it challenging for firms to share large datasets in critical locations, as network data tampering is a potential risk. Federated Learning offers a solution by allowing the benefits of data privacy without the need for data to be shared with a central server. This field has attracted researchers from a range of disciplines and is still in its early stages. This systematic review article provides an overview of Federated Learning, covering its framework, categories, and benefits, as well as various application areas. The article also highlights recent cutting-edge research and addresses fundamental concerns that have emerged from this research, such as the need for more advanced privacy preservation techniques. Finally, the article suggests future research directions to facilitate the practical application of Federated Learning in real-world scenarios. As Federated Learning is a relatively new research field, there is still much to be explored. However, its potential advantages in terms of data privacy and collaboration make it a compelling area of study for researchers and businesses alike. The article serves as a valuable resource for those interested in understanding the current state of Federated Learning and its potential applications.
C1 [Kaur, Harmandeep; Rani, Veenu; Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Sachdeva, Monika] IKG Punjab Tech Univ, Dept Comp Sci & Engn, Kapurthala, Punjab, India.
   [Mittal, Ajay] Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
   [Kumar, Krishan] Panjab Univ, Dept Informat Technol, Univ Inst Engn & Technol, Chandigarh 160014, India.
C3 I. K. Gujral Punjab Technical University; Panjab University; Panjab
   University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM harmandeepk08@gmail.com; veenugoyal7@gmail.com; munishcse@gmail.com;
   monasach1975@gmail.com; ajay_mittal825@yahoo.com; k.salujauiet@gmail.com
RI Berwal, Krishan/AAC-3473-2020; Kumar, Munish/P-7756-2018
OI Berwal, Krishan/0000-0002-7068-6541; Kumar, Munish/0000-0003-0115-1620
CR AbdulRahman S, 2021, IEEE INTERNET THINGS, V8, P5476, DOI 10.1109/JIOT.2020.3030072
   Ahmed L, 2020, IEEE ACCESS, V8, P208518, DOI 10.1109/ACCESS.2020.3038676
   Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]
   [Anonymous], An Industrial Grade Federated Learning Framework
   [Anonymous], Baidu PaddlePaddle Releases 21 New Capabilities to Accelerate Industry-Grade Model Development
   [Anonymous], Let's Solve Privacy
   [Anonymous], We Research and Build Artificial Intelligence Technology and Services
   Cao MR, 2023, IEEE T NEUR NET LEAR, V34, P2028, DOI 10.1109/TNNLS.2021.3105810
   Chandiramani K, 2019, PROCEDIA COMPUT SCI, V165, P349, DOI 10.1016/j.procs.2020.01.039
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P2457, DOI 10.1109/TWC.2020.3042530
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P269, DOI 10.1109/TWC.2020.3024629
   Chen Y, 2020, IEEE T NEUR NET LEAR, V31, P4229, DOI 10.1109/TNNLS.2019.2953131
   Chen Z, 2020, IEEE ACCESS, V8, P217463, DOI 10.1109/ACCESS.2020.3041793
   Dasaradharami Reddy K, 2023, Comput Intell Neurosci, V2023, P8393990, DOI 10.1155/2023/8393990
   Doku R, 2019, 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2019), P184, DOI 10.1109/IRI.2019.00039
   Duan MM, 2021, IEEE T PARALL DISTR, V32, P59, DOI 10.1109/TPDS.2020.3009406
   Hao M, 2020, IEEE T IND INFORM, V16, P6532, DOI 10.1109/TII.2019.2945367
   Khan LU, 2021, IEEE COMMUN SURV TUT, V23, P1759, DOI 10.1109/COMST.2021.3090430
   Li H, 2023, FUTURE GENER COMP SY, V144, P271, DOI 10.1016/j.future.2023.02.021
   Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Lillicrap Timothy P, 2015, ARXIV150902971
   Lim WYB, 2020, IEEE COMMUN SURV TUT, V22, P2031, DOI 10.1109/COMST.2020.2986024
   Liu W, 2020, IEEE T PARALL DISTR, V31, P1754, DOI 10.1109/TPDS.2020.2975189
   Liu Y, 2020, IEEE INTERNET THINGS, V7, P7751, DOI 10.1109/JIOT.2020.2991401
   Liu YY, 2021, 2021 IEEE 13TH INTERNATIONAL CONFERENCE ON COMPUTER RESEARCH AND DEVELOPMENT (ICCRD 2021), P121, DOI 10.1109/ICCRD51685.2021.9386709
   Lu XF, 2020, IEEE ACCESS, V8, P48970, DOI 10.1109/ACCESS.2020.2978082
   Lu YL, 2020, IEEE T IND INFORM, V16, P4177, DOI 10.1109/TII.2019.2942190
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   O'Shea TJ, 2016, COMM COM INF SC, V629, P213, DOI 10.1007/978-3-319-44188-7_16
   Pang JJ, 2021, TSINGHUA SCI TECHNOL, V26, P759, DOI 10.26599/TST.2021.9010026
   Pang JJ, 2021, IEEE INTERNET THINGS, V8, P3088, DOI 10.1109/JIOT.2020.3007662
   Pfitzner B, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3412357
   Posner J, 2021, IEEE NETWORK, V35, P152, DOI 10.1109/MNET.011.2000430
   Reina G. A., 2021, arXiv
   Saha R, 2021, IEEE INTERNET THINGS, V8, P8456, DOI 10.1109/JIOT.2020.3046509
   Sattler F, 2020, IEEE T NEUR NET LEAR, V31, P3400, DOI 10.1109/TNNLS.2019.2944481
   Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1
   Shi JB, 2020, IEEE CONF COMPUT, P1105, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162958
   Sun HF, 2020, IEEE INTERNET THINGS, V7, P11053, DOI 10.1109/JIOT.2020.2994596
   TensorFlow Federated, Machine Learning on Decentralized Data
   Xia Q, 2021, HIGH-CONFID COMPUT, V1, DOI 10.1016/j.hcc.2021.100008
   Xu GW, 2020, IEEE T INF FOREN SEC, V15, P911, DOI 10.1109/TIFS.2019.2929409
   Xu J, 2021, IEEE T WIREL COMMUN, V20, P1188, DOI 10.1109/TWC.2020.3031503
   Xu J, 2021, J HEALTHC INFORM RES, V5, P1, DOI 10.1007/s41666-020-00082-4
   Yu R, 2021, IEEE NETWORK, V35, P148, DOI 10.1109/MNET.011.2000295
   Zhan YF, 2020, IEEE INTERNET THINGS, V7, P6360, DOI 10.1109/JIOT.2020.2967772
   Zhang C, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106775
   Zhou CY, 2020, IEEE INTERNET THINGS, V7, P10782, DOI 10.1109/JIOT.2020.2987958
   Zhu HF, 2020, IEEE ACCESS, V8, P198275, DOI 10.1109/ACCESS.2020.3034602
NR 50
TC 0
Z9 0
U1 13
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17737-0
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700010
DA 2024-07-18
ER

PT J
AU Pazhanikumar, K
   KuzhalVoiMozhi, SN
AF Pazhanikumar, K.
   KuzhalVoiMozhi, S. Nithya
TI Remote sensing image classification using modified random forest with
   empirical loss function through crowd-sourced data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE SAT-4; SAT-6; RSI-CB; VGG19; ResNet 50; Modified random forest with
   empirical loss function
AB Environmental changes are captured as satellite images and stored in datasets for monitoring a particular location. These remote sensing images can be employed in predicting valuable data for both urban planning and in land-use management. Moreover, infrastructure planning, management of natural resources are also assessed using these images. Many traditional classification approaches have been utilized in classifying images. However, it resulted with processing of limited images and acquired minimum accuracy rate. In order to overcome the challenges in existing systems, the present research takes effort in utilizing three datasets such as SAT-4, SAT-6 and RSI-CB for proposed classification. Using such crowd sourced data, images are annotated clearly through vector information. Such images are taken for three stage implementation in proposed work for effective classification of satellite images. Large scale distribution data contains six categories and 35 sub-classes with 40,000 images of size 128 x 128 pixels. Initially, pre-processing performs checking of missing values and feature scaling to avoid incorrect predictions. The second stage is the feature extraction process performed by VGG19 and ResNet 50 architecture which provides best features. Individually extracted features from both models are concatenated and sent as input to the third stage of classification. Modified RF (Random Forest) with empirical loss function is used for classification which classifies images with majority voting process on tree based structure. Loss values are computed to determine the efficacy of the model. In addition to that, classification process is also executed by DT (Decision Tree) and K-NN (K-Nearest Neighbour) to exhibit the classification efficiency of proposed model. Performance evaluation on three datasets along with comparative analysis with other classification methods in terms of precision, accuracy, f1-score and recall are performed for determining the effectiveness of present research.
C1 [Pazhanikumar, K.] ST Hindu Coll, Dept Comp Sci, Nagercoil 2, Tamilnadu, India.
   [KuzhalVoiMozhi, S. Nithya] Manonmaniam Sundaranar Univ, Tirunelveli, India.
C3 Manonmaniam Sundaranar University
RP Pazhanikumar, K (corresponding author), ST Hindu Coll, Dept Comp Sci, Nagercoil 2, Tamilnadu, India.
EM skpk73@gmail.com
RI K, Dr.K.Pazhanikumar/JSK-8848-2023
OI K, Dr.K.Pazhanikumar/0000-0002-2047-5818
CR Alam MM, 2021, APPL ARTIF INTELL, V35, P1196, DOI 10.1080/08839514.2021.1975381
   Arndt J, 2021, IEEE J-STARS, V14, P2634, DOI 10.1109/JSTARS.2021.3052961
   Ayhan B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12081333
   Boulila W, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106014
   Chen XL, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14225838
   Chen ZL, 2020, IEEE GEOSCI REMOTE S, V17, P844, DOI 10.1109/LGRS.2019.2934341
   Deur M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233926
   Devi NB, 2022, J INDIAN SOC REMOTE, V50, P961, DOI 10.1007/s12524-022-01506-x
   Firat H, 2023, NEURAL PROCESS LETT, V55, P1087, DOI 10.1007/s11063-022-10929-z
   Gajendran N., 2020, Indian J Sci Technol, V13, P1786, DOI [10.17485/IJST/v13i17.538, DOI 10.17485/IJST/v13i17.538]
   Gamshadzaei MH, 2021, GEOCARTO INT, V36, P2264, DOI 10.1080/10106049.2019.1700554
   Gargees RS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091661
   Gargees RS, 2020, IEEE GEOSCI REMOTE S, V17, P1386, DOI 10.1109/LGRS.2019.2948799
   Holloway J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151796
   Kareem Razia Sulthana Abdul, 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-021-07791-z
   Kato S, 2021, INT J APPL EARTH OBS, V103, DOI 10.1016/j.jag.2021.102491
   Koteswaramma N, 2019, Int J Dev Technol Sci, V1, P40
   Kuldeep PK, 2021, Advances in Remote Sensing for Natural Resource Monitoring, P405
   Lee SH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12203372
   Liyanage K, 2020, SATELLITE IMAGE CLAS, P1
   Lv CZ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178845
   Ma CH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071270
   Maheswari KU, 2020, SOFT COMPUT, V24, P15561, DOI 10.1007/s00500-020-04884-x
   Meher SK, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105655
   Peng C, 2021, IEEE T GEOSCI REMOTE, V59, P6092, DOI 10.1109/TGRS.2020.3020424
   Razaque A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134431
   Roy SK, 2023, IEEE Transactions on Geoscience and Remote Sensing, V61
   Saboori M, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092097
   Scott GJ, 2018, INT GEOSCI REMOTE SE, P665, DOI 10.1109/IGARSS.2018.8519300
   Scott GJ, 2018, IEEE GEOSCI REMOTE S, V15, P1451, DOI 10.1109/LGRS.2018.2839092
   Singh S, 2021, ICICNIS 2020, DOI [10.2139/ssrn.3769768, DOI 10.2139/SSRN.3769768]
   Subraja N., 2021, Turkish Online Journal of Qualitative Inquiry, V12, P111
   Thiagarajan K, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214351
   Tuyen D, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9222846
   Unnikrishnan A, 2019, MULTIMED TOOLS APPL, V78, P18379, DOI 10.1007/s11042-019-7179-2
   Wang JJ, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3286422
   Wang XY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14205095
   Wu X, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132457
   Xia M, 2020, INT J REMOTE SENS, V41, P7779, DOI 10.1080/01431161.2020.1763511
   Zhang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102028
   Zhang Z, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14010141
   Zhong YF, 2017, REMOTE SENS LETT, V8, P136, DOI 10.1080/2150704X.2016.1235299
NR 42
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17556-3
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200004
DA 2024-07-18
ER

PT J
AU Wu, JS
   Sun, Y
   Kong, YY
   Shu, HZ
   Senhadji, L
AF Wu, Jiasong
   Sun, Yu
   Kong, Youyong
   Shu, Huazhong
   Senhadji, Lotfi
TI AHMN: A multi-modal network for long MOOC videos chapter segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video understanding; Low-quality video; Multimodal embedding; Attention
   mechanism
AB This paper proposes a task named MOOC Videos Chapter Segmentation (MVCS) which is a significant problem in the field of video understanding. To solve this problem, we first introduce a dataset called MOOC Videos Understanding (MVU) which consists of approximately 10k annotated chapters organized by 120k snippets from 400 MOOC videos where chapters and snippets are two levels of video unit proposed in this paper for hierarchical level expression of videos. Then, we design the Attention-based Hierarchical bi-LSTM Multi-modal Network (AHMN) based on three core ideas: (1) we take advantage of the features of multi-modal semantic elements, including video, audio, and text, along with an attention-based multi-modal fusion module to extract video information in a comprehensive way. (2) we focus on chapters boundaries rather than the content recognition of chapters themselves, so we develop Boundary Predict Network (BPN) to label boundaries between chapters. (3) we exploit the semantic consistency between snippets and develop Consistency Modeling as an auxiliary task to improve the performance of BPN. Our experiments demonstrate that the proposed AHMN can solve the MVCS precisely, outperforming previous methods on all evaluation metrics.
C1 [Wu, Jiasong; Sun, Yu; Kong, Youyong; Shu, Huazhong] Southeast Univ, Key Lab New Generat Artificial Intelligence Techno, Minist Educ, Nanjing, Peoples R China.
   [Senhadji, Lotfi] Univ Rennes, Rennes, France.
C3 Southeast University - China; Universite de Rennes
RP Sun, Y (corresponding author), Southeast Univ, Key Lab New Generat Artificial Intelligence Techno, Minist Educ, Nanjing, Peoples R China.
EM jswu@seu.edu.cn; yusun@seu.edu.cn; kongyouyong@seu.edu.cn;
   shu.list@seu.edu.cn; lotfi.senhadji@univ-rennes1.fr
RI Senhadji, Lotfi/E-5903-2013
OI Senhadji, Lotfi/0000-0001-9434-6341
FU This work was supported in part by the National Key Research and
   Development Program of China (Nos. 2021ZD0113202, 2022YFE0116700), in
   part by the National Natural Science Foundation of China under Grants
   62171125, 61876037, and in part by the Industry-Uni [2021ZD0113202,
   2022YFE0116700]; National Key Research and Development Program of China
   [62171125, 61876037]; National Natural Science Foundation of China
   [BY2022564]; Industry-University-Research cooperation project of Jiangsu
   Province
FX This work was supported in part by the National Key Research and
   Development Program of China (Nos. 2021ZD0113202, 2022YFE0116700), in
   part by the National Natural Science Foundation of China under Grants
   62171125, 61876037, and in part by the Industry-University-Research
   cooperation project of Jiangsu Province under grant BY2022564.
CR Aldausari N, 2022, IEEE COMPUT SOC CONF, P4690, DOI 10.1109/CVPRW56347.2022.00515
   [Anonymous], 2017, TREC VIDEO RETRIEVAL
   Anyi Rao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10143, DOI 10.1109/CVPR42600.2020.01016
   Basu Subhasree, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P238, DOI 10.1007/978-3-319-27671-7_20
   Bendraou Y, 2017, Video shot boundary detection and key-frame extraction using mathematical models
   Berlage O, 2020, INT CONF ACOUST SPEE, P751, DOI [10.1109/icassp40776.2020.9054315, 10.1109/ICASSP40776.2020.9054315]
   Che X., 2013, P 21 ACM INT C MULT
   Chen Y., 2015, THESIS
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Croitoru Ioana, 2023, 2023 IEEE/CVF International Conference on Computer Vision (ICCV), P2594, DOI 10.1109/ICCV51070.2023.00245
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Ge YY, 2022, PROC CVPR IEEE, P16146, DOI 10.1109/CVPR52688.2022.01569
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Ghauri JA, 2020, arXiv
   Gupta R, 2023, PROC CVPR IEEE, P19923, DOI 10.1109/CVPR52729.2023.01908
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Iashin V, 2021, Arxiv, DOI arXiv:2110.08791
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Katharopoulos A, 2020, PR MACH LEARN RES, V119
   Koshorek O, 2018, Arxiv, DOI arXiv:1803.09337
   Lee D.W., 2022, arXiv
   Lei J, 2021, PROC CVPR IEEE, P7327, DOI 10.1109/CVPR46437.2021.00725
   Lin M, 2005, INT J TECHNOL HUM IN, V1, P27, DOI 10.4018/jthi.2005040102
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu XB, 2022, EUR SIGNAL PR CONF, P1145
   Liu Z, 2022, SPIE, V12342, P601
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Ma D, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P221, DOI 10.1109/ICMLA.2017.0-155
   Mei XH, 2022, Arxiv, DOI arXiv:2203.15537
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mukherjee A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1329, DOI 10.1145/3331184.3331400
   Munro J, 2020, PROC CVPR IEEE, P119, DOI 10.1109/CVPR42600.2020.00020
   Shah RR, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P209, DOI 10.1145/2647868.2656407
   Shao H, 2015, AER ADV ENG RES, V38, P951
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Singer U, 2022, Arxiv, DOI arXiv:2209.14792
   Soares ER, 2019, WEBMEDIA 2019: PROCEEDINGS OF THE 25TH BRAZILLIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB, P513, DOI 10.1145/3323503.3349548
   Tapaswi M, 2014, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2014.111
   Thao Minh Le, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9969, DOI 10.1109/CVPR42600.2020.00999
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Xiao Y, 2024, IEEE T CIRC SYST VID, V34, P2789, DOI 10.1109/TCSVT.2023.3312321
   Xiao Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3107352
   Yang A, 2022, PROC CVPR IEEE, P16421, DOI 10.1109/CVPR52688.2022.01595
   Zhang SY, 2022, IEEE T PATTERN ANAL, V44, P9073, DOI 10.1109/TPAMI.2021.3120745
   Zhao BQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1680, DOI 10.1145/3123266.3123406
   Zhong YY, 2022, Arxiv, DOI arXiv:2203.01225
NR 52
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 20
PY 2023
DI 10.1007/s11042-023-17654-2
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y2LV7
UT WOS:001103642400003
DA 2024-07-18
ER

PT J
AU Amarnadh, V
   Moparthi, NR
AF Amarnadh, Vadipina
   Moparthi, Nageswara Rao
TI Prediction and assessment of credit risk using an adaptive Binarized
   spiking marine predators' neural network in financial sector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Credit risk; Approve loan; Reject loan; Neural network; Banking sector;
   Loan status
AB The rapid advancement of technologies has pushed for additional enhancements to banking and other credit platforms. While assisting small and medium sized business in lowering financing costs, banks and credit platforms must take into account practical matters like, their own capital expenses and risk evaluation. Even though, there are several methods for credit risk assessment, no comprehensive literature reviews have provided sufficient accuracy and better results while implementing in banking sectors. To overcome these issues, this manuscript proposes credit risk assessment in the banking sector using an Adaptive Binarized Spiking Marine Predators Neural Network (ABSMPNN) for accurate identification of customer credit quality within a short period of time. The evaluation using the credit risk dataset from Kaggle leads to the decision to grant or reject the customer's loan application. The concentration phase of the Variable Color Harmony Algorithm (VCHA) effectively achieves the selection of the most relevant features from the noisy and irrelevant ones. The optimization of neural network parameters with Adaptive Marine Predators Algorithm (AMPA) has further improved the overall accuracy (98.9%) with minimization of loss function. The outcomes depict that the introduced model attains higher accuracy and lower computational period of credit risk evaluation when compared with state-of-the-art.
C1 [Amarnadh, Vadipina; Moparthi, Nageswara Rao] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Prades, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Amarnadh, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Prades, India.
EM vadipina@gmail.com; rao1974@gmail.com
RI Moparthi, Nageswara Rao/V-8130-2017; Amarnadh, Vadipina/KRO-8279-2024
OI Moparthi, Nageswara Rao/0000-0001-6406-4554; Amarnadh,
   Vadipina/0009-0005-3584-4881
CR Bai YP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4796075
   Baser F, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119882
   Belhadi A, 2021, ANN OPER RES, DOI 10.1007/s10479-021-04366-9
   Chen DX, 2023, RES INT BUS FINANC, V65, DOI 10.1016/j.ribaf.2023.101940
   Clements JM, 2020, arXiv, DOI [10.48550/arXiv.2012.15330, DOI 10.48550/ARXIV.2012.15330]
   Dahooie JH, 2021, COMPUT OPER RES, V129, DOI 10.1016/j.cor.2021.105223
   Das Rik, 2021, International Journal of Information Technology, P1365, DOI 10.1007/s41870-021-00722-x
   Dhaigude R, 2022, 2022 INTERDISCIPLINA, P1, DOI [10.1109/IRTM54583.2022.9791511, DOI 10.1109/IRTM54583.2022.9791511]
   Fan BZ, 2023, APPL ARTIF INTELL, V37, DOI 10.1080/08839514.2023.2181517
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   Garain A, 2021, NEURAL COMPUT APPL, V33, P12591, DOI 10.1007/s00521-021-05910-1
   Gopi Arepalli Peda, 2023, International Journal of Information Technology, P965, DOI 10.1007/s41870-019-00409-4
   Hao M., 2022, Comput Aided Design, V19, P36
   Hayashi K, 2023, COMPUT AIDED GEOM D, V101, DOI 10.1016/j.cagd.2023.102169
   Itoo Fayaz, 2021, International Journal of Information Technology, V13, P1503, DOI 10.1007/s41870-020-00430-y
   Kheradpisheh SR, 2022, NEURAL PROCESS LETT, V54, P1255, DOI 10.1007/s11063-021-10680-x
   Kumar MPP, 2021, J SUPERCOMPUT, V77, P8445, DOI 10.1007/s11227-020-03547-w
   Lappas PZ, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107391
   Li JY, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12071643
   Li YX, 2022, FORECASTING-BASEL, V4, P184, DOI 10.3390/forecast4010011
   Liu LL, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/9650934
   Machado L, 2022, Credit risk modelling and prediction: Logistic regression versus machine learning boosting algorithms
   Zhang N, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102763
   Nerkar Bhavana, 2021, International Journal of Information Technology, P2305, DOI 10.1007/s41870-021-00772-1
   Oreski G, 2023, KNOWL-BASED SYST, V274, DOI 10.1016/j.knosys.2023.110646
   Pei SW, 2020, INFORM SCIENCES, V513, P17, DOI 10.1016/j.ins.2019.11.040
   Rao CJ, 2023, COMPLEX INTELL SYST, V9, P1391, DOI 10.1007/s40747-022-00854-y
   Roeder J, 2022, DECIS SUPPORT SYST, V158, DOI 10.1016/j.dss.2022.113770
   Roy PK, 2023, INT J FINANC ECON, V28, P372, DOI 10.1002/ijfe.2425
   Runchi Z, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118732
   Sadgali I., 2021, Indonesian J Electrical Eng Comput Sci (IJEECS), V21, P1704, DOI [10.11591/ijeecs.v21.i3.pp1704-1712, DOI 10.11591/IJEECS.V21.I3.PP1704-1712]
   Sahu Aanchal, 2021, International Journal of Information Technology, V13, P2011, DOI 10.1007/s41870-021-00650-w
   Sun MT, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/9007140
   Wang DN, 2022, INFORM SCIENCES, V602, P259, DOI 10.1016/j.ins.2022.04.058
   Wang K, 2022, PROCEDIA COMPUT SCI, V199, P1128, DOI 10.1016/j.procs.2022.01.143
   Wang LN, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3088915
   Wang YS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5177015
   Wei YQ, 2022, INT T ELECTR ENERGY, V2022, DOI 10.1155/2022/4766597
   Wu X, 2023, ECON ANAL POLICY, V78, P419, DOI 10.1016/j.eap.2023.03.012
   Xie XF, 2024, INT T OPER RES, V31, P2765, DOI 10.1111/itor.13257
   Yang F, 2022, ANN OPER RES, DOI 10.1007/s10479-022-04531-8
   Yin W, 2023, APPL SOFT COMPUT, V142, DOI 10.1016/j.asoc.2023.110302
   Zaeimi M, 2020, SOFT COMPUT, V24, P12027, DOI 10.1007/s00500-019-04646-4
   Zeng H, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/8532918
   Zhang L, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6826573
   Zhang LH, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/7826838
   Zhong KY, 2021, COMPUT METHOD APPL M, V385, DOI 10.1016/j.cma.2021.114029
NR 47
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17467-3
EA NOV 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500032
DA 2024-07-18
ER

PT J
AU Bhuyan, P
   Singh, PK
   Das, SK
AF Bhuyan, Parag
   Singh, Pranav Kumar
   Das, Sujit Kumar
TI Res4net-CBAM: a deep cnn with convolution block attention module for tea
   leaf disease diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tea leaf disease; Deep learning; Smart agriculture; Attention module
AB Early detection of tea leaf diseases is crucial for maintaining crop yield and agricultural production. However, manual inspection is a time-consuming and error-prone process, emphasizing the need for automated procedures. Deep learning methods have shown great potential in diagnosing plant leaf diseases. Convolutional Neural Networks (CNNs) outperform traditional deep learning models. However, the performance of these approaches is limited due to computational complexity, feature quality issues, and increasing feature dimensionality. In this study, we propose Res4net-CBAM, a deep convolutional neural network (CNN) specifically designed for tea leaf disease diagnosis, aiming to reduce the model's complexity and improve disease identification accuracy. The Res4net-CBAM model utilizes a residual block-based Res4net architecture with a network interactive convolutional block attention module (CBAM) to accurately extract complex features associated with different diseases. We conducted extensive experiments to compare the performance of our model with standard CNN models such as AlexNet, VGG16, ResNet50, DenseNet121, and InceptionV3, based on metrics such as accuracy, precision, recall, and F1-score. Our results demonstrate that the Res4net-CBAM model outperforms all other models, achieving an average recognition accuracy of 98.27% on self-acquired tea leaf disease data samples. Specifically, the Res4net-CBAM model achieved an average sensitivity of 98.39%, specificity of 98.26%, precision of 98.35%, and F1-score of 98.37%, while utilizing the Adagrad optimizer with a learning rate of 0.001. Moreover, our model surpasses some recent and existing works in this field, highlighting its effectiveness in diagnosing tea leaf diseases.
C1 [Bhuyan, Parag; Singh, Pranav Kumar] Cent Inst Technol, Btr 783370, Assam, India.
   [Das, Sujit Kumar] Siksha O Anusandhan Univ, Bhubaneswar, Odisha, India.
C3 Siksha 'O' Anusandhan University
RP Singh, PK (corresponding author), Cent Inst Technol, Btr 783370, Assam, India.
EM paragbhuyan12@gmail.com; snghpranav@gmail.com; dassujit88@gmail.com
RI Singh, Pranav Kumar/ISU-9525-2023
OI Singh, Pranav Kumar/0000-0001-8987-0229
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2022, ABOUT US
   Bao WX, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06181-z
   Bhowmik S, 2020, 2020 ADVANCED COMMUNICATION TECHNOLOGIES AND SIGNAL PROCESSING (IEEE ACTS), DOI 10.1109/ACTS49415.2020.9350413
   Bhuyan P, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13304
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Chao XF, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071065
   Chen J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030343
   Chen YT, 2020, IEEE ACCESS, V8, P102907, DOI 10.1109/ACCESS.2020.2997466
   Das K, 2006, J WORLD INTELLECT PR, V9, P459, DOI 10.1111/j.1422-2213.2006.00300.x
   Datta Saikat, 2023, Procedia Computer Science, P2273, DOI 10.1016/j.procs.2023.01.203
   GibsonKimutai AF, 2022, Tea sickness dataset
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hossain MS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P150, DOI 10.1109/CSPA.2018.8368703
   Hu GS, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107023
   Hu GS, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.100353
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ishengoma FS, 2022, ECOL INFORM, V67, DOI 10.1016/j.ecoinf.2021.101502
   Jackulin C., 2022, Measurement: Sensors
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kamrul MH, 2020, P INT C COMPUTING AD, P1, DOI [10.1145/3377049.3377122, DOI 10.1145/3377049.3377122]
   Kaur A., 2015, Global Journal of Bio-Science and Biotechnology, V4, P116
   Keith L, 2006, Identification guide for diseases of tea (Camellia sinensis)
   Lee H, 2020, IEEE T ULTRASON FERR, V67, P1344, DOI 10.1109/TUFFC.2020.2972573
   Lehmann-Danzinger H, 2000, TROPENLANDWIRT, V101, P13
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Ma JunCheng Ma JunCheng, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P186
   Mi ZW, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.558126
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Pooja V, 2017, 2017 IEEE TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT (TIAR), P130, DOI 10.1109/TIAR.2017.8273700
   Shah SK, 2016, J. Tea Sci. Res, V6, DOI [10.5376/jtsr.2016.06.0005, DOI 10.5376/JTSR.2016.06.0005]
   Sun YY, 2019, COMPUT ELECTRON AGR, V157, P102, DOI 10.1016/j.compag.2018.12.042
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   ThouheedAhmed SS, 2016, 2016 INT C COMP TECH, P1, DOI [10.1109/ICCTIDE.2016.7725324, DOI 10.1109/ICCTIDE.2016.7725324]
   Vishnoi VK, 2021, J PLANT DIS PROTECT, V128, P19, DOI 10.1007/s41348-020-00368-0
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xiao YT, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.781551
   Yanan L, 2021, Tablets defect detection based on improved resnet-cbam
   Ye W, 2019, CONFERENCE PROCEEDINGS OF 2019 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (IEEE ICSPCC 2019)
   Zeng WH, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105341
NR 46
TC 0
Z9 0
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17472-6
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500027
DA 2024-07-18
ER

PT J
AU Su, XP
   Zhao, XK
   Ren, J
   Li, YH
   Raetsch, M
AF Su, Xueping
   Zhao, Xingkai
   Ren, Jie
   Li, Yunhong
   Raetsch, Matthias
TI Pre-training neural machine translation with alignment information via
   optimal transport
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Optimal Transport; Alignment Information; Pre-training; Neural Machine
   Translation
AB With the rapid development of globalization, the demand for translation between different languages is also increasing. Although pre-training has achieved excellent results in neural machine translation, the existing neural machine translation has almost no high-quality suitable for specific fields. Alignment information, so this paper proposes a pre-training neural machine translation with alignment information via optimal transport. First, this paper narrows the representation gap between different languages by using OTAP to generate domain-specific data for information alignment, and learns richer semantic information. Secondly, this paper proposes a lightweight model DR-Reformer, which uses Reformer as the backbone network, adds Dropout layers and Reduction layers, reduces model parameters without losing accuracy, and improves computational efficiency. Experiments on the Chinese and English datasets of AI Challenger 2018 and WMT-17 show that the proposed algorithm has better performance than existing algorithms.
C1 [Su, Xueping; Zhao, Xingkai; Ren, Jie; Li, Yunhong] Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
   [Raetsch, Matthias] Reutlingen Univ, Dept Engn, Interact & Mobile Robot & Artificial Intelligence, Reutlingen, Germany.
C3 Xi'an Polytechnic University
RP Su, XP (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM yifeichongtian1201@163.com
FU This work was supported by the National Natural Science Foundation of
   China under Grant 61902301, Shaanxi Natural Science Basic Research
   Project under Grant 2022JM-394, and Xi'an Science and Technology Bureau
   Science and Technology Innovation Leading Proje [61902301]; National
   Natural Science Foundation of China [2022JM-394]; Shaanxi Natural
   Science Basic Research Project [21XJZZ0020;]; Xi'an Science and
   Technology Bureau Science and Technology Innovation Leading Project;
   Youth Innovation Team of Shaanxi Universities
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61902301, Shaanxi Natural Science Basic Research
   Project under Grant 2022JM-394, and Xi'an Science and Technology Bureau
   Science and Technology Innovation Leading Project under Grant
   21XJZZ0020;The Youth Innovation Team of Shaanxi Universities.
CR [Anonymous], 2013, EMNLP
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P33701, DOI 10.1007/s11042-021-11345-6
   Chen KH, 2022, IEEE-ACM T AUDIO SPE, V30, P330, DOI 10.1109/TASLP.2021.3138714
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chen YD, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3881
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chrisman L., 1991, Connection Science, V3, P345, DOI 10.1080/09540099108946592
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Fan Y, 2020, IEEE-ACM T AUDIO SPE, V28, P1574, DOI 10.1109/TASLP.2020.2995270
   Gehring J, 2017, PR MACH LEARN RES, V70
   Ghorbani Behrooz, 2021, INT C LEARN REPR
   Imamura K, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P55
   Kinga D, 2015, INT C LEARNING REPRE, V5, P6
   Kitaev N., 2013, IComputer Science, V2020, P164
   Kobayashi Sosuke, 2018, P 2018 C N AM CHAPT, V2, P452, DOI [10.18653/v1/N18-2072, DOI 10.18653/V1/N18-2072]
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Leong C, 2021, IEEE-ACM T AUDIO SPE, V29, P2829, DOI 10.1109/TASLP.2021.3105798
   Li HY, 2020, IEEE-ACM T AUDIO SPE, V28, P1864, DOI 10.1109/TASLP.2020.2999724
   Li YY, 2020, AAAI CONF ARTIF INTE, V34, P8285
   Lin ZH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2649
   Liu XQ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2286
   Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343
   Pan X, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P244
   Peyre G., 2017, Computational optimal transport, Center for Research in Economics and Statistics Working Papers, P2017
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Song KT, 2019, PR MACH LEARN RES, V97
   Sutskever I, 2014, ADV NEUR IN, V27
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei XP, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7930
   Wu Felix, 2018, INT C LEARN REPR
   Yang JC, 2020, AAAI CONF ARTIF INTE, V34, P9378
NR 34
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17479-z
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900014
DA 2024-07-18
ER

PT J
AU Dalai, R
   Dalai, N
   Sekhar, S
   Dalai, N
AF Dalai, Radhamadhab
   Dalai, Nirupama
   Sekhar, Sashank
   Dalai, Nibedita
TI Gazelle-based 3DUnet segmentation model and control in robotic motion
   for brain tumor surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3DUnet model; Gazelle optimizer; Brain tumor segmentation; Path
   planning; Collision avoidance; Deep reinforcement learning; Point cloud
   generation; Q-learning; Robotic surgery
AB In recent years, various technical advances in engineering, computer science, and medical imaging developments have significantly enhanced complex neurosurgery prospects. The complexity and increased sensitivity of anatomical areas require skill and precision. In the proposed study, the robotic automation of surgical sub-process is considered for brain tumor removal, which means the removal of tumor region under the surgeon's supervision. The proposed framework utilizes point clouds rather than analytical geometry. Initially, the proposed framework obtains the medical images and performs pre-processing using an adaptive bilateral filtering process. Then, the pre-processed images are segmented by employing a gazelle-based 3DUnet model and establishing a 3D reconstruction process. Further, the generated point clouds from the segmented images are provided for path planning. A deep Q-learning-based reinforcement learning network (DQN) is applied to offer robust path planning. Along with path plans, the resultant metrics have been provided to the surgeons to choose an optimal candidate for robotic surgery. The proposed framework is implemented in the Matlab platform using the TCIA and BraTS2018 datasets and assessed the performance in terms of different evaluation metrics. Moreover, the performance of a proposed framework is compared with existing models. The maximum segmentation accuracy obtained by the proposed framework is 96% for the TCIA dataset and 95% for the BraTS2018 dataset, which is superior to the existing methods for brain tumor removal.
C1 [Dalai, Radhamadhab] Sikshya O Anusandhan Univ, Comp Sci & Engn, Bhubaneswar, India.
   [Dalai, Nirupama] OUAT, Vet Sci, Bhubaneswar, Odisha, India.
   [Sekhar, Sashank] Belghachhia Univ, Vet Sci, Kolkata, West Bengal, India.
   [Dalai, Nibedita] PMEC Berhampur Coll, Berhampur, Odisha, India.
C3 Siksha 'O' Anusandhan University; Orissa University of Agriculture &
   Technology
RP Dalai, R (corresponding author), Sikshya O Anusandhan Univ, Comp Sci & Engn, Bhubaneswar, India.
EM radhamadhabdalai@soa.ac.in
CR Abdi A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051697
   Alqaoud Motaz, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P3495, DOI 10.1109/EMBC48229.2022.9871109
   Baalamurugan KM, 2022, INT J INTELL UNMANNE, V10, P98, DOI 10.1108/IJIUS-08-2020-0038
   Barnoy Y, 2021, Arxiv, DOI arXiv:2105.01006
   Comin FJ, 2018, IEEE T ROBOT, V34, P1659, DOI 10.1109/TRO.2018.2861898
   Dalai Radhamadhab, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0617, DOI 10.1109/ICCSP48568.2020.9182438
   de'Angelis N, 2022, WORLD J EMERG SURG, V17, DOI 10.1186/s13017-022-00410-6
   Farooq MU, 2023, MECHATRONICS, V94, DOI 10.1016/j.mechatronics.2023.103029
   Ferrentino E, 2020, J INTELL ROBOT SYST, V99, P245, DOI 10.1007/s10846-019-01116-9
   Ghaffari M, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P420, DOI 10.1109/dicta47822.2019.8946023
   Han JP, 2022, INT J MED ROBOT COMP, V18, DOI 10.1002/rcs.2358
   Haoran E., 2023, Ann Cardiothorac Surg, V12, P340
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Ibrahim MK., 2023, AIP Publish LLC, V2591, P030008
   Jiang HJ, 2022, ACTA NEUROCHIR, V164, P2299, DOI 10.1007/s00701-022-05235-5
   Jiang ZL, 2020, IEEE T AUTOM SCI ENG, V17, P2, DOI 10.1109/TASE.2019.2920133
   Lee Y, 2019, IEEE SYS MAN CYBERN, P342, DOI 10.1109/SMC.2019.8914191
   Manjila S, 2023, WORLD NEUROSURG, V176, P127, DOI 10.1016/j.wneu.2023.01.025
   Mei JW, 2018, IEEE ACCESS, V6, P32367, DOI 10.1109/ACCESS.2018.2841000
   Mitra M., 2021, OCE J ENG STUD RES, V1, P1, DOI [10.1234/1234, DOI 10.1234/1234]
   Nichols AC, 2022, J CLIN ONCOL, V40, P866, DOI 10.1200/JCO.21.01961
   Pathiyil RK, 2023, Neuro-oncology explained through multiple choice questions, P63, DOI [10.1007/978-3-031-13253-7_6, DOI 10.1007/978-3-031-13253-7_6]
   Pinzi M, 2019, INT J COMPUT ASS RAD, V14, P659, DOI 10.1007/s11548-019-01923-3
   Ramezanlou MT, 2019, RSI INT CONF ROBOT M, P259, DOI [10.1109/icrom48714.2019.9071893, 10.1109/ICRoM48714.2019.9071893]
   Sharma R, 2019, APPL MATH MODEL, V73, P228, DOI 10.1016/j.apm.2019.03.041
   Si WX, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0015-8
   Wang CQ, 2023, NEUROL THER, V12, P977, DOI 10.1007/s40120-023-00451-2
   Wang J, 2018, IEEE ACCESS, V6, P35132, DOI 10.1109/ACCESS.2018.2848938
   Xu HF, 2022, INT J MED ROBOT COMP, V18, DOI 10.1002/rcs.2361
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhou CH, 2019, LECT NOTES COMPUT SC, V11384, P497, DOI 10.1007/978-3-030-11726-9_44
   Zirino S, Vision-based deep reinforcement learning for autonomous target reaching in minimally invasive robotic surgery
NR 32
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17421-3
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300003
DA 2024-07-18
ER

PT J
AU Chan, DY
   Wang, JF
   Chin, HT
AF Chan, Din Yuen
   Wang, Jhing-Fa
   Chin, Hsu-Ting
TI A new speaker-diarization technology with denoising spectral-LSTM for
   online automatic multi-dialogue recording
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic recordings; Speaker-diarization; Denoising model; LSTM
AB In AI pandemic applications, the online automatic AI recording apparatus for official councils such as court trials, business conferences and commercial meetings will become imperative because it could let the opinion identification and consensus of participants be synchronically available to implicitly diminish social costs such as follow-up disputes and controversies. Hence, in this study, an automatic on-line multi-dialogue recording system is completely constructed, where the unbounded interleaved-state recurrent neural networks (UIS-RNN) with proposed crux improvements is exploited to achieve confident speaker-diarization. For keeping the systematic robustness, a denoising spectral-LSTM, which is precisely modified from the dual-signal transformation LSTM (DTLN), can strengthen its subsequent crux-improved UIS-RNN and automatic speech recognition (ASR). Finally, the MacBERT model is set to rectify the possible wrong words in conversed sentences according to the learned rational context. For making our system being a practical software apparatus in the use of unmarked multi-person councils, we have also completed the convenient interfaces for the operations of ASR and speaker-diarization, which can exhibit on-line denoising efficacy and speaker-diarization results as well as offer real-time hand-crafted rectifications to common users. In extensive experiments, the proposed recording system can promise high accuracy rates of online speaker diarization and speech-separated ASR. Our proposed system had been examined by the cooperated law court staffs, who offered the noise-embedded speeches of practical court field to test our system. Since the tight recording burden had been indeed noticeably alleviated in their legal-action councils, the court staffs had endorsed that the proposed entire system could be a friendly labor-saving AI apparatus for on-line automatic multi-dialogue recording.
C1 [Chan, Din Yuen] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
   [Wang, Jhing-Fa; Chin, Hsu-Ting] Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
C3 National Chiayi University; National Cheng Kung University
RP Chan, DY (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM dychan@mail.ncyu.edu.tw; wangjf@mail.ncku.edu.tw;
   N26091403@gs.ncku.edu.tw
FU This work was supported by the funding of Ministry of Science and
   Technology of Taiwan under Grant MOST 111-2221-E006-177-MY2. Also, we
   would like to thank the AIGO competition for inspiring us to develop
   this system and then giving the high approval. Part [MOST
   111-2221-E006-177-MY2]; Ministry of Science and Technology of Taiwan
FX This work was supported by the funding of Ministry of Science and
   Technology of Taiwan under Grant MOST 111-2221-E006-177-MY2. Also, we
   would like to thank the AIGO competition for inspiring us to develop
   this system and then giving the high approval. Particularly, we are
   grateful to the Tainan District Court as the mainly cooperated
   institution for examining our proposed system and consecutively feeding
   key advices back via their practical applications.
CR Ayasi A, 2022, P 2 INT C NEXT GEN I, DOI [10.1109/ICNGIS54955.2022.10079831, DOI 10.1109/ICNGIS54955.2022.10079831]
   Cheng SW, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P431, DOI 10.1109/AICAS54282.2022.9870007
   Cui YM, 2020, Arxiv, DOI [arXiv:2004.13922, DOI 10.18653/V1/2020.FINDINGS-EMNLP.58]
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Gan Z, 2022, GLOB C ROB ART INT I
   Garcia-Romero D, 2017, INT CONF ACOUST SPEE, P4930, DOI 10.1109/ICASSP.2017.7953094
   Hao X, 2021, P IEEE INT C AC SPEE
   Higuchi Y, 2020, INT CONF ACOUST SPEE, P7129, DOI [10.1109/icassp40776.2020.9054273, 10.1109/ICASSP40776.2020.9054273]
   Hou J, 2021, P IEEE 6 INT C COMP, DOI [10.1109/ICCCS52626.2021.9449307, DOI 10.1109/ICCCS52626.2021.9449307]
   Hu Y, 2020, arXiv
   Hung J-W, 2021, P 7 INT C APPL SYST, DOI [10.1109/ICASI52993.2021.9568478, DOI 10.1109/ICASI52993.2021.9568478]
   Jannu C, 2023, P 3 INT C ART INT SI, DOI [10.1109/AISP57993.2023.10134933, DOI 10.1109/AISP57993.2023.10134933]
   Kanda N, 2022, INT CONF ACOUST SPEE, P8082, DOI 10.1109/ICASSP43922.2022.9746225
   Kong ZF, 2022, INT CONF ACOUST SPEE, P7867, DOI 10.1109/ICASSP43922.2022.9746169
   Li JY, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P114, DOI [10.1109/ASRU46091.2019.9003906, 10.1109/asru46091.2019.9003906]
   Li Z, 2021, P IEEE INT C AC SPEE
   Pang BW, 2022, 2022 13TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P502, DOI 10.1109/ISCSLP57327.2022.10037846
   Ravanelli M, 2018, IEEE T EM TOP COMP I, V2, P92, DOI 10.1109/TETCI.2017.2762739
   Rethage D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5069, DOI 10.1109/ICASSP.2018.8462417
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   robots, Audio-visual dataset VoxCeleb
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   Variani Ehsan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4052, DOI 10.1109/ICASSP.2014.6854363
   Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5239, DOI 10.1109/ICASSP.2018.8462628
   Westhausen N-L, 2020, P INT
   Yang G, 2022, P 4 INT C NAT LANG P, DOI [10.1109/ICNLP55136.2022.00055, DOI 10.1109/ICNLP55136.2022.00055]
   Zajíc Z, 2017, INTERSPEECH, P3562, DOI 10.21437/Interspeech.2017-51
   Zhang AN, 2019, INT CONF ACOUST SPEE, P6301, DOI 10.1109/ICASSP.2019.8683892
   Zhang C, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7063, DOI 10.1109/ICASSP39728.2021.9413934
   Zhao SK, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6648, DOI 10.1109/ICASSP39728.2021.9414569
   Zhu WZ, 2016, INT CONF ACOUST SPEE, P5045, DOI 10.1109/ICASSP.2016.7472638
NR 32
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17283-9
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100005
DA 2024-07-18
ER

PT J
AU Dhevanandhini, G
   Yamuna, G
AF Dhevanandhini, G.
   Yamuna, G.
TI An optimal intelligent video surveillance system in object detection
   using hybrid deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent video surveillance; Object detection; Segmentation; Feature
   optimization
ID RECOGNITION
AB Detecting objects within real-time video frames is a formidable challenge due to visual degradation and object movement complexities. This research presents a three-step strategy to construct an advanced intelligent video surveillance system using hybrid deep learning techniques. A modified Barnacles Mating Optimization (MBMO) algorithm is introduced to segment objects from video frames, addressing redundancy and temporal intricacies. Further, a Chaotic Hummingbird Optimization (CHO) algorithm is employed for feature optimization, mitigating data dimensionality issues. The core innovation involves a Hybrid Convolutional Neural Network with Supreme Gradient Boosting (hybrid CNN-SGboost) classifier for precise object prediction and detection. Validation is conducted on benchmark datasets, including Penn-Fudan pedestrians, Daimler pedestrian segmentation, and Inria person, comparing the hybrid CNN-SGboost classifier against state-of-the-art alternatives using common evaluation parameters. Simulation outcomes affirm the superiority of the hybrid model, marking a significant advancement in accurate object detection for video surveillance applications.
C1 [Dhevanandhini, G.; Yamuna, G.] Annamalai Univ, Dept Elect & Commun Engn, Annamalainagar, Tamil Nadu, India.
C3 Annamalai University
RP Dhevanandhini, G (corresponding author), Annamalai Univ, Dept Elect & Commun Engn, Annamalainagar, Tamil Nadu, India.
EM dheva_venki@yahoo.com; yamuna.sky@gmail.com
CR Ahmadi M, 2020, ARAB J SCI ENG, V45, P1421, DOI 10.1007/s13369-019-03969-6
   Ahmed I, 2021, J REAL-TIME IMAGE PR, V18, P1803, DOI 10.1007/s11554-021-01144-5
   Ahmed I, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107489
   Alotaibi MF, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050733
   Antonik P, 2019, NAT MACH INTELL, V1, P530, DOI 10.1038/s42256-019-0110-8
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Chen CJ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11206-8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding DD, 2020, J INTELL TRANSPORT S, V24, P304, DOI 10.1080/15472450.2019.1670659
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Doshi K, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107865
   Gautam K., 2021, Turk J Comput Math Educ (TURCOMAT), V12, P2709
   Golestani N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15086-2
   Hu Y, 2020, J GRID COMPUT, V18, P227, DOI 10.1007/s10723-020-09506-2
   Huang C, 2021, IEEE Trans Ind Inf
   Huang Y, 2020, IEEE T INTELL TRANSP, V21, P79, DOI 10.1109/TITS.2018.2888698
   Huang Z, 2022, IEEE Trans Image Process
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khandelwal G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P32, DOI 10.1109/ICRCICN.2015.7434205
   Kolluri J, 2023, IMAGE VISION COMPUT, V131, DOI 10.1016/j.imavis.2023.104628
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Lei YJ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11842-0
   Liao WH, 2011, CONF TECHNOL APPL, P179, DOI 10.1109/TAAI.2011.38
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Nguyen Trung Quy, 2013, International Journal of Contents, V9, P1, DOI 10.5392/IJoC.2013.9.3.001
   Patil PW, 2019, IEEE T INTELL TRANSP, V20, P4066, DOI 10.1109/TITS.2018.2880096
   Peng JQ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3162596
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Phyo CN, 2019, IEEE T CONSUM ELECTR, V65, P243, DOI 10.1109/TCE.2019.2908986
   Qian C, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30377-6
   Qin ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1884, DOI 10.1145/3474085.3475342
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Shahid M, 2021, IEEE Access
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tsai CY, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102798
   Werthen-Brabants L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08240-x
   Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu Z, 2021, IEEE ACCESS, V9, P155457, DOI 10.1109/ACCESS.2021.3129465
   Zou JH, 2017, ENERG BUILDINGS, V152, P385, DOI 10.1016/j.enbuild.2017.07.064
NR 48
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17102-1
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600006
DA 2024-07-18
ER

PT J
AU Jonnala, NS
   Gupta, N
AF Jonnala, Naga Surekha
   Gupta, Neha
TI SAR U-Net: Spatial attention residual U-Net structure for water body
   segmentation from remote sensing satellite images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Water Body Segmentation; Residual Block; U-Net; Spatial Attention
   Module; Satellite Images
ID EXTRACTION
AB The analysis of remote-sensing images always requires the extraction of data about the aquatic environment. However, it might be challenging to identify any water surface since the backgrounds of water zones in remote sensing images are usually complicated structures and dense vegetation. Furthermore, less significant tributaries and edge data could not be accurately detected using traditional water detection methods. As a result, a spatial attention residual U-Net architecture is proposed to enhance the effectiveness of water body segmentation. The suggested approach reweights the feature representation spatially to obtain data on water features, using U-Net as the network architecture. The feature of the water zone is obtained using the residual block. It obtains more precise local position data for the water zone, which enhance edge segmentation accuracy. The spatial attention module retrieves, segregates, and combines the low-level information and high-level information as two discrete inputs in various dimensions. To effectively segregate the water region from the context, the spatial attention module combines spatial features with deep contextual information. The experiments are performed using satellite images of kaggle dataset aquatic bodies and a real-time dataset. The results of the experiments reveal 96% of accuracy that the suggested strategy out performs the existing models.
C1 [Jonnala, Naga Surekha; Gupta, Neha] VIT AP Univ, Sch Elect Engn, Amaravati 522237, AP, India.
C3 VIT-AP University
RP Gupta, N (corresponding author), VIT AP Univ, Sch Elect Engn, Amaravati 522237, AP, India.
EM nagasurekha.20phd7090@vitap.ac.in; neha27brs@gmail.com
RI GUPTA, NEHA/KFQ-7449-2024
OI GUPTA, NEHA/0000-0002-1725-7908; Gupta, Neha/0000-0002-2287-1259
CR Akiyama Thales Shoiti, 2021, 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, P4716, DOI 10.1109/IGARSS47720.2021.9553345
   Aroma RJ, 2021, J INDIAN SOC REMOTE, V49, P341, DOI 10.1007/s12524-020-01194-5
   Babu AA, 2020, COMPUT INTELL-US, V36, P1242, DOI 10.1111/coin.12339
   Chen ST, 2021, INT J REMOTE SENS, V42, P5029, DOI 10.1080/01431161.2021.1906981
   Chen Y, 2020, J HYDROL, V588, DOI 10.1016/j.jhydrol.2020.125092
   Duan L, 2019, IEEE Geoscience and Remote Sensing Letters, P1
   Duan LH, 2020, IEEE GEOSCI REMOTE S, V17, P686, DOI 10.1109/LGRS.2019.2926412
   Erfani SMH, 2022, ENVIRON MODELL SOFTW, V149, DOI 10.1016/j.envsoft.2022.105333
   Feng WQ, 2019, IEEE GEOSCI REMOTE S, V16, P618, DOI 10.1109/LGRS.2018.2879492
   Kaplan G, 2017, EUR J REMOTE SENS, V50, P137, DOI 10.1080/22797254.2017.1297540
   Lalchhanhima R, 2021, MICROPROCESS MICROSY, V87, DOI 10.1016/j.micpro.2021.104360
   Li LW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101162
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Moradkhani K, 2022, APPL SOFT COMPUT, V124, DOI 10.1016/j.asoc.2022.109038
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Rajyalakshmi C, 2022, TRAIT SIGNAL, V39, P669, DOI 10.18280/ts.390230
   Roy S., 2014, ICT and Critical Infrastructure: Proceedings of the 48th Annual Convention of Computer Society of India-Vol II, P349, DOI DOI 10.1007/978-3-319-03095-1_38
   Roy S, 2017, FRONT COMPUT SCI-CHI, V11, P717, DOI 10.1007/s11704-016-5129-y
   Shi WY, 2022, INT J APPL EARTH OBS, V109, DOI 10.1016/j.jag.2022.102777
   Singh S, 2022, Data Intelligence and Cognitive Informatics, P831
   Srivastava V, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108259
   Tambe RG, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103141
   Wang JM, 2022, INT J DIGIT EARTH, V15, P345, DOI 10.1080/17538947.2021.1995513
   Wang LJ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14010200
   Xia M, 2021, INT J REMOTE SENS, V42, P2594, DOI 10.1080/01431161.2020.1856964
   Yang XC, 2018, REMOTE SENS ENVIRON, V219, P259, DOI 10.1016/j.rse.2018.09.016
   Yuan KH, 2021, IEEE J-STARS, V14, P7422, DOI 10.1109/JSTARS.2021.3098678
   Zhang X, 2022, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
   Zhou YA, 2014, IEEE J-STARS, V7, P4301, DOI 10.1109/JSTARS.2014.2360436
NR 29
TC 0
Z9 0
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-16965-8
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600016
DA 2024-07-18
ER

PT J
AU Konduri, PS
   Rao, GSN
AF Konduri, Praveen S. R.
   Rao, G. Siva Nageswara
TI A transfer learning coupled framework for distortion classification in
   laparoscopic videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Laparoscopic videos; Distortions; Zero-shot transfer learning; Knowledge
   transfer; DenseNet-65; Flow direction algorithm; Softmax classifier
AB Capturing laparoscopic videos helps physicians to conduct minor surgeries and treatments effectively. But the problem is that these videos are easily affected by environmental conditions and various distortions that diminish the overall clarity. This reduces the possibility for physicians to complete the treatments successfully. To deal with this, video enhancement techniques are introduced, which require the help of effective distortion-type classification strategies. This work presents a compelling and accurate distortion classification technique based on transfer learning. The proposed work includes three main stages: feature extraction, fine-tuning and classification. The DenseNet-65 convolutional neural network (DDCNN) model has been chosen as the baseline, where the DenseNet-65 is pre-trained on the Imagenet dataset. The pre-trained model is used for feature extraction using the zero-shot transfer learning (ZSTL) technique, where only the first few layers of a model are engaged to extract the crucial spatial features. Then, the fine-tuning process was carried out using the flow direction algorithm (FDA) that tunes the parameters of the top layers. Finally, classification has been done using the softmax classifier, where the model classifies five different distortions in videos such as smoke, AWGN noise, motion blur, defocus blur and uneven illumination. The work has been implemented in Python, and the ICIP2020 challenge dataset is used for evaluations. The achieved accuracy outcomes of different distortion classes are smoke (97.8%), AWGN noise (100%), Motion blur (95.83%), Defocus blur (98.65%) and uneven illumination (99.01%). Moreover, the performance of a proposed scheme is examined in terms of different performance measures accuracy (98.8%), F1-score (96.9%), processing time (0.037 s), Spearman rank order correlation coefficient SROCC (0.995), Pearson linear correlation coefficient (PLCC) (0.995), and Kendall rank order correlation coefficient (KROCC) (0.857). The performance evaluations proved the efficacy of the proposed method compared to other techniques.
C1 [Konduri, Praveen S. R.; Rao, G. Siva Nageswara] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Konduri, PS (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
EM praveenkonduricse@gmail.com
RI G, Siva Nageswara Rao/GMW-7483-2022
OI G, Siva Nageswara Rao/0000-0001-6422-4968
CR Acharya D, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891989
   AlDahoul N, 2021, F1000Research, V10, P1010
   AlDahoul N, 2023, LECT NOTES ARTIF INT, V13739, P195, DOI 10.1007/978-3-031-20650-4_16
   Aldahoul N, 2021, IEEE ACCESS, V9, P115006, DOI 10.1109/ACCESS.2021.3105454
   Ameur Z, 2022, NEURAL COMPUT APPL, V34, P21607, DOI 10.1007/s00521-021-06576-5
   Badgery H., 2022, ARTIF INTELL MED, P175, DOI [10.1007/978-981-19-1223-8_8, DOI 10.1007/978-981-19-1223-8_8]
   Beghdadi A, 2022, IEEE IMAGE PROC, P1521, DOI 10.1109/ICIP46576.2022.9897415
   Borate P. A., 2021, Opt. Photon. Inf. Process., V11841, P55
   Chen E, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.101710
   Fox M, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P6, DOI 10.1145/3512527.3531424
   Ghamsarian N, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3577, DOI 10.1145/3394171.3413658
   Haemmerle-Uhl J, 2012, LECT NOTES COMPUT SC, V7512, P574, DOI 10.1007/978-3-642-33454-2_71
   Khan ZA, 2022, End-to-end blind quality assessment for laparoscopic videos using neural networks
   Khan ZA, 2022, COMPUT MED IMAG GRAP, V101, DOI 10.1016/j.compmedimag.2022.102121
   Khan ZA, 2020, IEEE IMAGE PROC, P176, DOI 10.1109/ICIP40778.2020.9191111
   Khan ZA, 2020, PROC SPIE, V11316, DOI 10.1117/12.2549266
   Kletz S, 2019, INT WORK CONTENT MUL
   Kumcu AE, 2014, SPIE, V9037, P65
   Li X., 2023, Int. J. Netw. Dyn. Intell, V2, P93, DOI [DOI 10.53941/IJNDI0201006, 10.53941/ijndi0201006]
   Lin JZ, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6320
   Liu XW, 2020, IEEE T MULTIMEDIA, V22, P949, DOI 10.1109/TMM.2019.2934425
   Lu C, 2020, OPT EXPRESS, V28, P15300, DOI 10.1364/OE.392493
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   NAMAZI B., 2019, towards automated understanding of laparoscopic videos
   Nguyen TS, 2020, IEEE INT WORKSH MULT
   Szankin M., 2022, Int J Netw Dyn Intell, V1, P48
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Venkatesh V, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103873
   Wang CC, 2019, PROC SPIE, V10949, DOI 10.1117/12.2507822
   Wang Mihang, 2022, Interdisciplinary Research for Printing and Packaging. Lecture Notes in Electrical Engineering (896), P99, DOI 10.1007/978-981-19-1673-1_17
   Yue J, 2022, IEEE T BROADCAST, V68, P370, DOI 10.1109/TBC.2022.3152064
   Zhang S, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.01.78
NR 32
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17257-x
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600007
DA 2024-07-18
ER

PT J
AU Mareen, H
   Courteaux, M
   Speelmans, PJ
   Lambert, P
   Van Wallendael, G
AF Mareen, Hannes
   Courteaux, Martijn
   Speelmans, Pieter-Jan
   Lambert, Peter
   Van Wallendael, Glenn
TI A study on keyframe injection in three generations of video coding
   standards for fast channel switching and packet-loss repair
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fast channel switching; Random access; Packet loss; Error recovery;
   H.264/AVC; H.265/HEVC; H.266/VVC
ID IPTV; DELAY; TIME
AB It is challenging to enable fast channel switching and packet-loss repair in low-delay live video distribution without negatively influencing the steady-state viewing performance. For example, regularly breaking the inter-frame dependency by introducing intra-predicted keyframes enables random access, but is costly in terms of rate-distortion performance. For this reason, the keyframe-injection method minimizes the impact by sending a compression-efficient normal video stream to all end-users. As accompaniment, a companion stream that solely consists of keyframes is sporadically used for only those users that switch channels or experience packet loss. This paper describes the requirements to implement keyframe injection in three video coding standard generations (H.264/AVC, H.265/HEVC, and H.266/VVC). We evaluated the impact that keyframe injection has on the quality of the video in terms of a decrease in VMAF, PSNR and SSIM. We demonstrate that the quality reduction caused by keyframe insertion is generally low, meaning that keyframe injection typically is imperceptible. However, drift-error artifacts become perceptible over time for rare outliers. Moreover, we pinpointed the cause of this worst-case artifact type to be halfpel interpolation. As a solution, codecs can disable subpel motion estimation, and future standards could design their filters more carefully. Lastly, it should be noted that keyframe injection will only be applied sporadically when users require a random access or experience packet loss, and only to those users. Most interestingly, all other users receive a compression-efficient stream wherein the inter-frame dependency is not artificially broken at regular short intervals. As such, our proposed solution makes low-latency video distribution efficient and viable in multiple coding standards.
C1 [Mareen, Hannes; Courteaux, Martijn; Lambert, Peter; Van Wallendael, Glenn] Univ Ghent, Dept Elect & Informat Syst, IDLab, Imec, B-9000 Ghent, Belgium.
   [Speelmans, Pieter-Jan] THEO Technol, B-3001 Leuven, Belgium.
C3 IMEC; Ghent University
RP Mareen, H (corresponding author), Univ Ghent, Dept Elect & Informat Syst, IDLab, Imec, B-9000 Ghent, Belgium.
EM hannes.mareen@ugent.be; Martijn.Courteaux@ugent.be;
   pieter-jan.speelmans@theoplayer.com; Peter.Lamberte@ugent.be;
   Glenn.VanWallendael@ugent.be
RI Courteaux, Martijn/IUO-8125-2023; Van Wallendael, Glenn/H-8315-2015
OI Courteaux, Martijn/0000-0002-9971-3128; Van Wallendael,
   Glenn/0000-0001-9530-3466
FU The computational resources (STEVIN Supercomputer Infrastructure) and
   services used in this work were kindly provided by Ghent University, the
   Flemish Supercomputer Center (VSC), the Hercules Foundation and the
   Flemish Government department EWI.; Hercules Foundation; Flemish
   Government department EWI
FX The computational resources (STEVIN Supercomputer Infrastructure) and
   services used in this work were kindly provided by Ghent University, the
   Flemish Supercomputer Center (VSC), the Hercules Foundation and the
   Flemish Government department EWI.
CR Akgul T, 2020, IEEE T CONSUM ELECTR, V66, P61, DOI 10.1109/TCE.2019.2956625
   [Anonymous], 2018, IPTV delivery networks: next generation architectures for live and video-on-demand services
   Begen AC, 2009, 2009 6 IEEE CONS COM, P1
   Bejerano Y, 2009, IEEE INFOCOM SER, P1971, DOI 10.1109/INFCOM.2009.5062119
   Benjak M, 2021, IEEE IMAGE PROC, P2114, DOI 10.1109/ICIP42928.2021.9506399
   Bossen F., 2013, JCTVCL1100
   Boyce JM, 2005, IEEE ICCE, P1
   Bross B., 2014, High Efficiency Video Coding HEVC, P113
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   De Praeter J, 2017, IEEE T MULTIMEDIA, V19, P2252, DOI 10.1109/TMM.2017.2734330
   Erfanian A, 2020, PROCEEDINGS OF THE 2020 6TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2020): BRIDGING THE GAP BETWEEN AI AND NETWORK SOFTWARIZATION, P301, DOI 10.1109/NetSoft48620.2020.9165450
   Farber N, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P73, DOI 10.1109/ICIP.1997.638676
   Farber N, 1996, FIRST INTERNATIONAL WORKSHOP ON WIRELESS IMAGE/VIDEO COMMUNICATIONS, P8, DOI 10.1109/WIVC.1996.624635
   Fraunhofer, 2023, High Efficiency Video Coding (H.265/HEVC)-JVT-VC
   Fraunhofer, 2023, Advanced Video Coding (H.264/AVC)-JVT
   Fraunhofer, 2023, Versatile Video Coding (VVC)-JVET
   Ghahfarokhi BS, 2017, MULTIMED TOOLS APPL, V76, P23239, DOI 10.1007/s11042-016-4037-3
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jennehag U, 2008, CONSUM COMM NETWORK, P638, DOI 10.1109/ccnc08.2007.147
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   Kazemi M, 2021, Multimed Tools App
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Lee E, 2014, IEEE T CONSUM ELECTR, V60, P124, DOI 10.1109/TCE.2014.6780934
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Van LP, 2016, IEEE T MULTIMEDIA, V18, P364, DOI 10.1109/TMM.2015.2512231
   Mareen H, 2022, 2022 DAT COMPR C DCC
   Muratori C, 2019, Stable Filtering-Part 1
   Netflix Technology Blog, 2016, Toward A Practical Perceptual Video Quality Metric
   Ozer Jan, 2017, Finding the Just Noticeable Difference with Netflix VMAF
   Praeter JD, 2021, arXiv
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Ramos FMV, 2011, SIGNAL PROCESS-IMAGE, V26, P400, DOI 10.1016/j.image.2011.03.005
   Skupin R, 2021, PICT COD SYMP, P91, DOI 10.1109/PCS50896.2021.9477501
   Speelmans PJ, 2021, Internet-Draft draft-theo-hesp-01
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Van Wallendael G, 2022, PICT COD SYMP, P319, DOI 10.1109/PCS56426.2022.10018074
   Van Wallendael G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060748
   Van Wallendael G, 2014, IEEE IMAGE PROC, P5991, DOI 10.1109/ICIP.2014.7026209
   Van Wallendael G, 2012, IEEE T BROADCAST, V58, P57, DOI 10.1109/TBC.2011.2170610
   VideoLAN, 2023, x264, the best H.264/AVC encoder
   VideoLAN, 2023, x265, the free H.265/HEVC encoder
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang C, 2015, IEEE T MULTIMEDIA, V17, P1096, DOI 10.1109/TMM.2015.2429552
NR 46
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17163-2
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600008
DA 2024-07-18
ER

PT J
AU Tian, XY
   Jin, Y
   Zhang, Z
   Liu, P
   Tang, XL
AF Tian, Xiaoyan
   Jin, Ye
   Zhang, Zhao
   Liu, Peng
   Tang, Xianglong
TI Spatial-temporal graph transformer network for skeleton-based temporal
   action segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skeleton-based temporal action segmentation; Spatial-temporal graph;
   Transformer; Spatial-temporal correlation; Over-segmentation errors;
   Ambiguous boundaries
AB Temporal action segmentation (TAS) of minute-long untrimmed videos involves locating and classifying human action segments using multiple action class labels. Previously, research on this task typically involved generating an initial estimate using designed temporal convolutional layers and gradually refining this estimate solely based on RGB features. This approach, however, exhibits several limitations, including the inability to capture inherent long-range dependencies and insufficient consideration of intricate spatial-temporal correlations in the changing relationships between human joints. To address these constraints, we introduce a novel spatial-temporal graph transformer network (STGT) for the skeleton-based TAS task. Our STGT employs a series of skeleton graph transformer blocks (SGT blocks) within an encoder-decoder architecture. Particularly, the spatial-temporal graph layer with an adaptive graph strategy enhances the graph structure, rendering it more flexible and robust. Additionally, the spatial-temporal transformer layer in the SGT block constructs parallel attention mechanisms to model the dynamic spatial and non-linear temporal correlations. Integrating these advancements into the TAS task represents a notable achievement. Experimental results on three challenging datasets (PKU-MMD, HuGaDB, and LARa) indicate the improved performance of the proposed framework compared with that of existing TAS models (MS-TCN, ASRF, BCN, ETSN, and ASFormer). Furthermore, our approach effectively addresses concerns regarding over-segmentation errors and ambiguous boundaries.
C1 [Tian, Xiaoyan; Jin, Ye; Liu, Peng; Tang, Xianglong] Harbin Inst Technol, Fac Comp, 92 West Da Zhi St, Harbin 150001, Peoples R China.
   [Zhang, Zhao] Harbin Inst Technol, Sch Instrument Sci & Engn, 92 West Da Zhi St, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Jin, Y (corresponding author), Harbin Inst Technol, Fac Comp, 92 West Da Zhi St, Harbin 150001, Peoples R China.
EM tianxy@stu.hit.edu.cn; jinye@hit.edu.cn; zhangzhao@stu.hit.edu.cn;
   pengliu@hit.edu.cn; tangxl@hit.edu.cn
RI Tian, Xiaoyan/HGD-8506-2022
OI Tian, Xiaoyan/0000-0001-9278-1032
FU This work was supported by the National Natural Science Foundation of
   China (Grant Number: 51935005), Basic Scientific Research Project (Grant
   Number: JCKY20200603C010), Natural Science Foundation of Heilongjiang
   Province of China (Grant Number: LH2021F023 [51935005]; National Natural
   Science Foundation of China [JCKY20200603C010]; Basic Scientific
   Research Project [LH2021F023]; Natural Science Foundation of
   Heilongjiang Province of China
FX This work was supported by the National Natural Science Foundation of
   China (Grant Number: 51935005), Basic Scientific Research Project (Grant
   Number: JCKY20200603C010), Natural Science Foundation of Heilongjiang
   Province of China (Grant Number: LH2021F023).
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Aziere N, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104567
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Casini L, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-36015-5
   Chen J, 2022, IEEE T CYBERNETICS, V52, P5935, DOI 10.1109/TCYB.2021.3064092
   Chereshnev R, 2018, LECT NOTES COMPUT SC, V10716, P131, DOI 10.1007/978-3-319-73013-4_12
   Ding GD, 2023, Arxiv, DOI arXiv:2210.10352
   Du DZ, 2022, Arxiv, DOI arXiv:2205.13425
   Filtjens B, 2024, IEEE T EMERG TOP COM, V12, P202, DOI 10.1109/TETC.2022.3230912
   Ishikawa Y, 2021, IEEE WINT CONF APPL, P2321, DOI 10.1109/WACV48630.2021.00237
   Kong F, 2019, MULTIMED TOOLS APPL, V78, P4623, DOI 10.1007/s11042-018-6423-5
   Kuehne H, 2016, IEEE WINT CONF APPL
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Li C, 2018, Arxiv, DOI arXiv:1804.06055
   Li H, 2022, LECT NOTES COMPUT SC, V13670, P532, DOI 10.1007/978-3-031-20080-9_31
   Li SJ, 2023, IEEE T PATTERN ANAL, V45, P6647, DOI 10.1109/TPAMI.2020.3021756
   Li WS, 2023, PATTERN RECOGN LETT, V168, P86, DOI 10.1016/j.patrec.2023.03.003
   Li YH, 2021, NEUROCOMPUTING, V454, P373, DOI 10.1016/j.neucom.2021.04.121
   Liu C., 2017, P WORKSH VIS AN SMAR, P1
   Liu KY, 2022, IEEE SIGNAL PROC LET, V29, P1883, DOI 10.1109/LSP.2022.3199670
   Liu YA, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108146
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Niemann F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154083
   Park J, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108764
   Plizzari Chiara, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12663), P694, DOI 10.1007/978-3-030-68796-0_50
   Rashmi M, 2021, MULTIMED TOOLS APPL, V80, P2907, DOI 10.1007/s11042-020-09741-5
   Ribeiro LFR, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P385, DOI 10.1145/3097983.3098061
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shi Lei, 2020, P AS C COMP VIS
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Singhania D., 2021, PREPRINT
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Tian X, 2023, Pattern Anal Appl, V26, P1375
   Tian XY, 2023, MULTIMEDIA SYST, V29, P615, DOI 10.1007/s00530-022-00998-4
   Tsai MF, 2022, MULTIMED TOOLS APPL, V81, P7439, DOI 10.1007/s11042-022-12000-4
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu LY, 2023, COMPUT VIS IMAGE UND, V232, DOI 10.1016/j.cviu.2023.103707
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang DW, 2023, APPL INTELL, V53, P2738, DOI 10.1007/s10489-022-03569-2
   Yi FQ, 2021, Arxiv, DOI arXiv:2110.08568
   Zhang Z, 2023, IEEE Trans. Instrum. Meas., V72, P1
   Zhenzhi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P34, DOI 10.1007/978-3-030-58595-2_3
NR 44
TC 2
Z9 2
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17276-8
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000001
DA 2024-07-18
ER

PT J
AU Venkatesh, C
   Chinnababu, J
   Kiran, A
   Nagaraju, CH
   Kumar, M
AF Venkatesh, C.
   Chinnababu, J.
   Kiran, Ajmeera
   Nagaraju, C. H.
   Kumar, Manoj
TI A hybrid model for lung cancer prediction using patch processing and
   deeplearning on CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer; Computer-aided systems; Deep learning; CT Images; Patch
   processing
ID CLASSIFICATION
AB Cancer is a common disease with an increasing mortality rate in recent years. Lung cancer is the most common cancer in men and women alike. It is caused by uncontrolled cell development in the lungs. These cells are divided into two types: benign and malignant. Benign tumours are usually harmless, do not spread to other cells, and have a smooth and regular shape, whereas malignant tumours can be dangerous and spread to other body cells to form a new cancerous nodule with an uneven shape. If lung cancer is detected early, it can be treated. Lung cancer symptoms typically appear in the human body when it is in its final stage, but advanced technology and computer-aided systems can detect it at an early stage. Currently, numerous conventional and machine learning techniques are used for such automated detection systems to detect lung cancer in its early stages, but such automated detection systems do not provide accurate detection and the processing of lung cancer detection takes a long time. As a result, a novel method for detecting lung cancer that employs deep learning techniques for accurate detection while requiring less computation time is proposed. CT images are used in this study because they have less noise disturbance than MRI and X-ray images. Median filtering and patch processing are used to improve image quality on such CT scans. These pre-processed images are then subjected to a clustering segmentation process, which segments the image and feeds it to a CNN classifier. For feature extraction and classification, CNN architecture is used. In the future extraction section, various low-level and high-level features are extracted. The classification layer is in charge of determining whether the provided image contains a malignant, benign, or normal tumour. Finally, statistical parameters like MSE, PSNR, Accuracy, Sensitivity, Specificity, and others were computed and combined with the existing system in this work.
C1 [Venkatesh, C.; Chinnababu, J.; Nagaraju, C. H.] Annamacharya Inst Technol & Sci, Dept Elect & Commun Engn, Rajampet 516126, India.
   [Kiran, Ajmeera] MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad 500043, Telangana, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 MLR Institute of Technology; University of Wollongong; Middle East
   University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM venky.cc@gmail.com; jchinnababu@gmail.com; kiranphd.jntuh@gmail.com;
   chrajuaits@gmail.com; wss.manojkumar@gmail.com
RI Ch, Nagaraju/ADG-8763-2022; Dr., Chinna Babu J/U-1972-2019; Dasu,
   Venkata/GQQ-1698-2022; Kumar, Manoj/AFS-0700-2022; VENKATESH, Dr.
   C/ABA-4725-2020
OI Ch, Nagaraju/0000-0001-9178-6448; Dr., Chinna Babu
   J/0000-0001-9005-0615; Dasu, Venkata/0000-0002-8870-4410; Kumar,
   Manoj/0000-0001-9598-0280; VENKATESH, Dr. C/0000-0001-9323-177X
FU CAUL and its Member Institutions
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions No funding received to carry out this work
CR Abdillah B, 2017, J PHYS CONF SER, V893, DOI 10.1088/1742-6596/893/1/012063
   Aggarwal T, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1189, DOI 10.1109/ICACCI.2015.7275773
   Ahmed T, 2020, Journal of Computer and Communications, V8, P35, DOI [10.4236/jcc.2020.83004, DOI 10.4236/JCC.2020.83004]
   Al-Afandy KA., 2016, Adv Sci Technol Eng Syst J, V1, P42, DOI [10.25046/aj010508, DOI 10.25046/AJ010508]
   Al-Yasriy HF, 2021, 2 INT SCI C AL AYEN, P1
   Al-Yasriy HF, 2020, 2 INT SCI C AL AYEN, P1
   AlAfandy KA, 2022, Approaches and applications of deep learning in virtual medical care, P127
   AlAfandy KA, 2022, CMC-COMPUT MATER CON, V72, P739, DOI 10.32604/cmc.2022.022457
   Alba E, 2007, IEEE C EVOL COMPUTAT, P284, DOI 10.1109/CEC.2007.4424483
   Alkinani MH, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0203-4
   Ankita R, 2019, Int J Innov Technol Explor Eng (IJITEE)., V8, P2211
   Ansari AS, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/8544337
   Asuntha A, 2016, J Chem Pharm Res, V8, P351
   Cashmi A J., 2019, Merit research Journal of Engineering, Pure and Applied Sciences, V5, P014
   Dontha MR, 2022, Int J Spec Educ., V37, P12722
   Fatma T., 2012, American Journal of Biomedical Engineering, P136, DOI [DOI 10.5923/J.AJBE.20120203.08, 10.5923/j.ajbe.20120203.08]
   Garud S, 2021, INT C ADV COMP COMM, P1
   Guo YR, 2022, INSIGHTS IMAGING, V13, DOI 10.1186/s13244-022-01162-2
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hasan MR, 2019, J Emerg Trends Eng Appl Sci., V11
   Hatuwal B.K., 2020, Int. J. Comput. Trends Technol., V68, P21
   Ismail MBS., 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P7048
   Jassim MM, 2022, J INTELL SYST, V31, P944, DOI 10.1515/jisys-2022-0062
   Johora FT, 2018, Int Res J Eng Technol (IRJET)., V5, P27
   Kapoor A, 2021, Research Article EAI. EU, P1
   Kareem H.F., 2021, Indonesian J. Electr. Eng. Comput. Sci., V21, P1731, DOI DOI 10.11591/IJEECS.V21.I3.PP1731-1738
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kumar KS, 2019, Hindawi Comput Math Methods Med., P1
   Makaju S, 2018, PROCEDIA COMPUT SCI, V125, P107, DOI 10.1016/j.procs.2017.12.016
   Masood A, 2020, IEEE T IND INFORM, V16, P7791, DOI 10.1109/TII.2020.2972918
   Nagala GD, 2022, Int J Res Appl Sci Eng Technol (IJRASET)., V8, P1770
   Patra R., 2020, Commun Comput Inf Sci, V1235 CCIS, P132, DOI 10.1007/978-981-15-6648-6_11
   Prasad DVR, 2013, Int J Latest Trends Eng Technol (IJLTET)., V3, P370
   Raj D, 2019, J Emerg Technol Innov Res., V6
   Ramakrishnan M, 2022, Automated Lung Cancer Nodule Detection., P1
   Rana P, 2021, BRAZ ARCH BIOL TECHN, V64, DOI 10.1590/1678-4324-2021200221
   Roy TS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1204, DOI 10.1109/CCAA.2015.7148560
   Sajja TK, 2019, TRAIT SIGNAL, V36, P339, DOI 10.18280/ts.360406
   Sharma A, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/7433186
   Song QZ, 2017, Hindawi J Healthc Eng., V2017, P1
   Sowmiya BR., 2018, Int J Innov Technol Explor Eng (IJITEE), V8
   Vaishnavi D, 2019, Int J Eng Res Technol., V7, P1
   Venkatesh C, 2022, WIRELESS PERS COMMUN, V125, P2621, DOI 10.1007/s11277-022-09676-0
   Venkatesh C, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.769692
NR 44
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17349-8
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000021
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, H
   Chi, JN
   Li, XQ
   Wu, CD
   Wu, H
AF Wang, Huan
   Chi, Jianning
   Li, Xiaoqiang
   Wu, Chengdong
   Wu, Hao
TI Generative facial prior embedded degradation adaption network for
   heterogeneous face hallucination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heterogeneous face hallucination; Facial priors transformation;
   Generative adversarial network; Contrastive learning
AB In real-world long-range surveillance systems, thermal face images captured from a distance suffer from low resolution and noise, posing challenges for thermal-to-visible face image translation. Current methods assume similar resolutions and noise-free conditions between thermal and visible images, limiting their applicability. To address these issues, we propose the Generative Facial Prior Embedded Degradation Adaption Network (GDANet), which synthesizes high-quality visible images from low-quality thermal images. GDANet combines pretrained Generative Adversarial Network (GAN) blocks with a U-shaped deep neural network (DNN) to incorporate faithful facial priors, including geometry, facial textures, and colors. Additionally, an unsupervised degradation representation learning scheme is developed to capture abstract degradation representations of degraded thermal images in a representation space. This approach allows GDANet to adapt spatial features based on the degradation representation, striking a balance between fidelity and texture faithfulness using degradation-aware feature fusion (DAFF) blocks. Experimental results demonstrate that GDANet outperforms state-of-the-art methods, showing its effectiveness in handling real-world low-quality thermal images across diverse practical applications.
C1 [Wang, Huan; Chi, Jianning; Li, Xiaoqiang; Wu, Chengdong] Northeastern Univ, Shenyang 110167, Peoples R China.
   [Wu, Hao] Univ Sydney, Sydney, NSW 2006, Australia.
C3 Northeastern University - China; University of Sydney
RP Wu, CD (corresponding author), Northeastern Univ, Shenyang 110167, Peoples R China.
EM wanghuan@stu.neu.edu.cn; chijianning@mail.neu.edu.cn;
   lixiaoqiang@stu.neu.edu.cn; wuchengdong@mail.neu.edu.cn;
   hawu1598@uni.sydney.edu.au
RI Li, Xiaoqiang/P-4087-2019
OI Li, Xiaoqiang/0000-0002-9692-1458
FU The authors would like to thank Zi Teng and Chuanjiang Leng for helpful
   discussions and fruitful feedback along the way.
FX The authors would like to thank Zi Teng and Chuanjiang Leng for helpful
   discussions and fruitful feedback along the way.
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Anghelone D, 2021, 2021 16 IEEE INT C A, P1
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2017, IEEE C COMP VIS PATT
   Bell-Kligler S, 2019, ADV NEUR IN, V32
   Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Cheema U., 2021, arXiv
   Chen C., 2019, 2019 14 IEEE INT C A, P1
   Dai Q., 2021, arXiv, DOI [10.1145/3474085.3475356, DOI 10.1145/3474085.3475356]
   Di X, 2018, INT CONF BIOMETR THE
   Du H, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3507902
   Duan B., 2020, P IEEE CVF C COMP VI
   Fu CY, 2019, ADV NEUR IN, V32
   Gao GW, 2023, IEEE T IMAGE PROCESS, V32, P1978, DOI 10.1109/TIP.2023.3261747
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hensel M, 2017, ADV NEUR IN, V30
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou XX, 2022, NEURAL NETWORKS, V145, P209, DOI 10.1016/j.neunet.2021.10.017
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Immidisetti Rakhil, 2021, 2021 IEEE International Joint Conference on Biometrics (IJCB), DOI 10.1109/IJCB52358.2021.9484353
   Jaderberg M, 2015, ADV NEUR IN, V28
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kingma D. P., 2014, arXiv
   Konečny J, 2017, Arxiv, DOI arXiv:1610.05492
   Kumar S, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104376
   Liu L., 2020, IEEE Trans Cybern, P1
   Liu L, 2021, IEEE Trans Neural Netw Learn Syst, P1
   Luo M, 2022, IEEE T INF FOREN SEC
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Mei Y., 2022, P IEEE CVF C COMP VI, P18676
   Michaeli T, 2013, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2013.121
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Panetta K, 2020, IEEE T PATTERN ANAL, V42, P509, DOI 10.1109/TPAMI.2018.2884458
   Rai D, 2022, IEEE Trans Instrum Meas
   Sarfraz MS, 2017, INT J COMPUT VISION, V122, P426, DOI 10.1007/s11263-016-0933-2
   Song LX, 2018, AAAI CONF ARTIF INTE, P7355
   Teng Z, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.797231
   Tennessee U, 2012, Iris thermal/visible face database
   Tomar AS, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244837
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Zhixin, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P1704, DOI 10.1109/CVPR52729.2023.00170
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao WX, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3149101
   Xie C., 2023, P IEEE CVF C COMP VI, P2534
   Xing Di, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P266, DOI 10.1109/TBIOM.2021.3060641
   Xu C, 2022, LECT NOTES COMPUT SC, V13675, P54, DOI 10.1007/978-3-031-19784-0_4
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yu JC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1018
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang H, 2019, 36 INT C MACHINE LEA, V97
   Zhang H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P100
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang T, 2018, INT CONF BIOMETR, P174, DOI 10.1109/ICB2018.2018.00035
   Zheng Qingping, 2022, P IEEE CVF C COMP VI, P4156
NR 63
TC 0
Z9 0
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-16932-3
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000015
DA 2024-07-18
ER

PT J
AU Aftab, H
   Hussain, M
   Riaz, Q
   Zeeshan, M
   Jung, KH
AF Aftab, Hira
   Hussain, Mehdi
   Riaz, Qaiser
   Zeeshan, Muhammad
   Jung, Ki-Hyun
TI Hiding EPR and watermark in medical images using repeated pixel
   differencing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data embedding; ERP embedding; Steganography; Pixel value
   differencing; Tamper detection
ID HIGH-CAPACITY; COMPUTATIONALLY EFFICIENT; CLINICAL INFORMATION; SCHEME;
   STEGANOGRAPHY; CONTRAST
AB This research proposes a novel high-capacity-based reversible data embedding strategy for e-healthcare applications. The proposed reversible embedding scheme for electronic patient records (EPR) replaced the conventional embedding and interpolation techniques with a simple pixel-to-block-level transformation, repeated pixel differencing (RPD) and conditional pixel permutation (CPP) strategies. A fragile watermark image combined with EPR is employed to identify tamper detection in medical stego-images. In the proposed pixel-to-block conversion, a pixel is replicated to a 2 x 2 pixel block to facilitate the reversibility of EPR data. For embedding, RPD determines and adjusts the 2 x 2 pixel differences based on EPR and watermark data. Further, to ensure high imperceptibility for the human visual system proposed scheme computes the average value of pixels that must similar to the seed pixel. To maintain a histogram invariant stego-images, a permutation of 2 x 2 pixels is employed to embed additional secret data bits while exploiting the CPP strategy. The proposed scheme is extensively evaluated on + 2000 images regarding embedding capacity, perceptual imperceptibility, and tamper detection while employing different image processing attacks. Experimental results show that the proposed scheme achieved an average of 2.24 bpp with 41.27 dB PNSR on medical images and 2.49 bpp with 40.68 PSNR with general images. The proposed strategy outperformed existing approaches in terms of high embedding capacity, acceptable visual imperceptibility, and tamper detection while ensuring the 100% reversibility of EPR data in medical images.
C1 [Aftab, Hira; Hussain, Mehdi; Riaz, Qaiser; Zeeshan, Muhammad] Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci, Islamabad, Pakistan.
   [Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Andong, South Korea.
C3 National University of Sciences & Technology - Pakistan; Andong National
   University
RP Hussain, M (corresponding author), Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci, Islamabad, Pakistan.; Jung, KH (corresponding author), Andong Natl Univ, Dept Software Convergence, Andong, South Korea.
EM haftab.msis17seecs@seecs.edu.pk; mehdi.hussain@seecs.edu.pk;
   qaiser.riaz@seecs.edu.pk; muhammad.zeeshan@seecs.edu.pk;
   khanny.jung@gmail.com
OI Jung, Ki-Hyun/0000-0002-0662-8355
FU This research was supported by the National University of Sciences and
   Technology (NUST) under the Department of Computing, School of
   Electrical Engineering and Computer Science, Islamabad, Pakistan. This
   research was supported by Brain Pool program funded; National University
   of Sciences and Technology (NUST) under the Department of Computing,
   School of Electrical Engineering and Computer Science, Islamabad,
   Pakistan [2019H1D3A1A01101687]; Brain Pool program - Ministry of Science
   and ICT through the National Research Foundation of Korea
   [2021R1I1A3049788]; Basic Science Research Program through the National
   Research Foundation of Korea (NRF) - Ministry of Education
FX This research was supported by the National University of Sciences and
   Technology (NUST) under the Department of Computing, School of
   Electrical Engineering and Computer Science, Islamabad, Pakistan. This
   research was supported by Brain Pool program funded by the Ministry of
   Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A3049788).
CR Abadi M. A. M., 2010, 2010 5th International Symposium on Telecommunications (IST), P840, DOI 10.1109/ISTEL.2010.5734139
   Akintunde Tosin Yinka, 2021, Glob Health J, V5, P128, DOI 10.1016/j.glohj.2021.07.006
   [Anonymous], Structured Analysis of the Retina
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   Chang Q, 2021, IEEE T CIRC SYST VID, V31, P4850, DOI 10.1109/TCSVT.2021.3055612
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Dissent, 2020, Almost 11 million patients impacted by Blackbaud incident-and still counting
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Hick JL, 2020, NEW ENGL J MED, V382, DOI 10.1056/NEJMp2005118
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kat J, 2021, Banner Health agrees to pay $200k to settle potential HIPAA violations
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Kumar V, 2022, MULTIMED TOOLS APPL, V81, P37441, DOI 10.1007/s11042-022-13546-z
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Loan NA, 2017, J BIOMED INFORM, V73, P125, DOI 10.1016/j.jbi.2017.08.002
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mansour RF, 2021, ARAB J SCI ENG, V46, P9129, DOI 10.1007/s13369-021-05716-2
   Meenpal A, 2022, MULTIMED TOOLS APPL, V81, P40535, DOI 10.1007/s11042-022-13031-7
   Naheed T., 2011, Proceedings of the 2011 Frontiers of Information Technology (FIT 2011), P281, DOI 10.1109/FIT.2011.59
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Open i, Open Access Biomedical Image Search Engine
   Ossebaard HC, 2016, INT J QUAL HEALTH C, V28, P415, DOI 10.1093/intqhc/mzw032
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Singh AK, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3414474
   Southwick R, 2022, The 10 biggest health data breaches in the first half of 2022
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Nguyen TS, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14081726
   U.S. Department of Health & Human Services, 2020, Health Insurer Pays $6.85 Million to Settle Data Breach Affecting
   Weber A.G., 1997, USC-SIPI Report, P315
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Zhang C, 2023, COMPUT J, V66, P888, DOI 10.1093/comjnl/bxab203
NR 43
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-15434-6
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1QN5
UT WOS:001082618800001
DA 2024-07-18
ER

PT J
AU Singh, LK
   Khanna, M
   Singh, R
AF Singh, Law Kumar
   Khanna, Munish
   Singh, Rekha
TI Efficient feature selection for breast cancer classification using soft
   computing approach: A novel clinical decision support system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emperor Penguin Optimization; Gravitational Search Optimization; Hybrid
   Algorithm; Breast Cancer prediction; Feature Selection
ID PARTICLE SWARM OPTIMIZATION; VECTOR MACHINES; DIAGNOSIS; ALGORITHM;
   MODELS
AB One of the essential data pre-processing methods for enhancing the performance of machine learning (ML) models is feature selection. Because they choose the most optimal features for ML problems, metaheuristic feature selection algorithms have gained popularity recently. The Gravitational Search Optimization Algorithm (GSOA), Emperor Penguin Optimization (EPO), and an integrated (hGSEPO) algorithm that combines GSOA and EPO are three metaheuristic feature selection algorithms that are presented in this paper. GSOA performs the global search in hGSEPO, and Emperor Penguin Optimizer (EPO) performs a more thorough local search. In order to find influential features while eliminating irrelevant features and reducing complexity, this article introduces a pioneering hybrid approach that combines the two distinct algorithms GSOA and EPO. While the baseline algorithms have been employed for feature selection in a few ML tasks, the hybrid of these two has been used for the first time for breast cancer (BC) classification. The reason for selecting BC as a case of investigation is due to its recognition as the second leading cause of death in women. According to earlier research, the feature selection (FS) stage is crucial when processing large datasets with the goal of forecasting medical conditions like BC. Based on the selection of the most important features necessary to achieve enhanced accuracy, this intelligent classification system divides the data from the benchmark BC Wisconsin Diagnostic Breast Cancer (WDBC) feature set into two classes. Additionally, the intention of the research is to ascertain the minimum quantity of features necessary to attain a higher level of accuracy. The experimental results show that the proposed approach works auspiciously and categorizes with astounding results, with the highest accuracy of 97.66%, 0.9687 sensitivity, 1.000 specificity, 1.000 precision, 0.9516 F1-score, and 0.9980 area under the curve (AUC).
C1 [Singh, Law Kumar] GLA Univ, Dept Comp Sci & Engn, Mathura, India.
   [Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Singh, Rekha] Uttar Pradesh Rajarshi Tandon Open Univ, Dept Phys, Prayagraj, Uttar Pradesh, India.
C3 GLA University
RP Singh, LK (corresponding author), GLA Univ, Dept Comp Sci & Engn, Mathura, India.
EM lawkumarcs@gmail.com; munishkhanna.official@rocketmail.com;
   singh.rekha70@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852
CR Abdar M, 2020, PATTERN RECOGN LETT, V132, P123, DOI 10.1016/j.patrec.2018.11.004
   Agustian F, 2020, 2020 8 INT C CYB IT, P1
   Ak MF, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020111
   Akay MF, 2009, EXPERT SYST APPL, V36, P3240, DOI 10.1016/j.eswa.2008.01.009
   Alickovic E, 2017, NEURAL COMPUT APPL, V28, P753, DOI 10.1007/s00521-015-2103-9
   Alweshah M, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107629
   Alzu'bi A, 2021, MULTIMED TOOLS APPL, V80, P13787, DOI 10.1007/s11042-020-10448-w
   Barakat NH, 2010, IEEE T INF TECHNOL B, V14, P1114, DOI 10.1109/TITB.2009.2039485
   Bhardwaj A, 2015, EXPERT SYST APPL, V42, P4611, DOI 10.1016/j.eswa.2015.01.065
   Boudouh SS, 2023, MULTIMED TOOLS APPL, V82, P34913, DOI 10.1007/s11042-023-14410-4
   Chaurasia V., 2020, SN Comput. Sci, V1, P1, DOI [10.1007/s42979-020-00296-8, DOI 10.1007/S42979-020-00296-8]
   Chen HL, 2011, EXPERT SYST APPL, V38, P9014, DOI 10.1016/j.eswa.2011.01.120
   Christo VRE, 2022, IETE J RES, V68, P2508, DOI 10.1080/03772063.2020.1713917
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   El-Kenawy ES, 2020, INT J INNOV COMPUT I, V16, P831, DOI 10.24507/ijicic.16.03.831
   Farr Alex, 2013, Rev Obstet Gynecol, V6, P165
   Fayyad U, 1996, AI MAG, V17, P37
   Fei SW, 2010, EXPERT SYST APPL, V37, P6748, DOI 10.1016/j.eswa.2010.02.126
   Gu DX, 2017, ARTIF INTELL MED, V77, P31, DOI 10.1016/j.artmed.2017.02.003
   Hamed Ghada, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P322, DOI 10.1007/978-3-030-44289-7_30
   Ibrahim RA, 2019, J AMB INTEL HUM COMP, V10, P3155, DOI 10.1007/s12652-018-1031-9
   Idris NF, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.427
   Jen CH, 2012, EXPERT SYST APPL, V39, P8852, DOI 10.1016/j.eswa.2012.02.004
   Kadam VJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1397-z
   Karabatak M, 2015, MEASUREMENT, V72, P32, DOI 10.1016/j.measurement.2015.04.028
   Karabatak M, 2009, EXPERT SYST APPL, V36, P3465, DOI 10.1016/j.eswa.2008.02.064
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Krawczyk B, 2015, ARTIF INTELL MED, V65, P219, DOI 10.1016/j.artmed.2015.07.005
   Liu N, 2019, INFORM PROCESS MANAG, V56, P609, DOI 10.1016/j.ipm.2018.10.014
   Lu HY, 2019, EXPERT SYST APPL, V116, P340, DOI 10.1016/j.eswa.2018.08.040
   Mambou SJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092799
   MunishKhanna, 2024, MULTIMED TOOLS APPL, V83, P17773, DOI 10.1007/s11042-023-16236-6
   Murugesan S, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6662420
   Mushtaq Z, 2020, J CHIN INST ENG, V43, P80, DOI 10.1080/02533839.2019.1676658
   Nilashi M, 2017, TELEMAT INFORM, V34, P133, DOI 10.1016/j.tele.2017.01.007
   Peng LX, 2016, COMPUT METH PROG BIO, V134, P259, DOI 10.1016/j.cmpb.2016.07.020
   Qiu H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16665-y
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rahman M. A., 2021, PEERJ COMPUT SCI, V7, P344
   Raiesdana S, 2021, MIDDLE EAST J CANCER, V12, P48, DOI 10.30476/mejc.2020.85601.1294
   Rajaguru Harikumar, 2019, Asian Pac J Cancer Prev, V20, P3777, DOI 10.31557/APJCP.2019.20.12.3777
   Ramadevi GN., 2015, International Journal of Scientific and Innovative Mathematical Research, V3, P763
   Rani S, 2022, MULTIMED TOOLS APPL, V81, P9939, DOI 10.1007/s11042-022-12144-3
   Rao H, 2019, APPL SOFT COMPUT, V74, P634, DOI 10.1016/j.asoc.2018.10.036
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ronoud S, 2019, SOFT COMPUT, V23, P13139, DOI 10.1007/s00500-019-03856-0
   Sahebi G, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103974
   Sahu B, 2019, EAI ENDORSED TRANS S, V6, DOI 10.4108/eai.19-12-2018.156086
   Sakri SB, 2018, IEEE ACCESS, V6, P29637, DOI 10.1109/ACCESS.2018.2843443
   Seera M, 2014, EXPERT SYST APPL, V41, P2239, DOI 10.1016/j.eswa.2013.09.022
   Sharma N, 2013, NETW MODEL ANAL HLTH, V2, P285, DOI 10.1007/s13721-013-0045-7
   Sheikhpour R., 2014, INDIAN J SCI TECHNOL, V7, P472, DOI 10.17485/ijst/2014/v7i4.20
   Siegel R, 2014, CA-CANCER J CLIN, V64, P9, DOI 10.3322/caac.21208
   Singh LK, 2024, SOFT COMPUT, V28, P2431, DOI 10.1007/s00500-023-08449-6
   Singh LK, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103338
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Thawkar S, 2023, INT J IMAG SYST TECH, V33, P1696, DOI 10.1002/ima.22889
   Thawkar S, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104968
   Thongkam J, 2009, EXPERT SYST APPL, V36, P12200, DOI 10.1016/j.eswa.2009.04.067
   Ul Haq A, 2020, J INTELL FUZZY SYST, V38, P2383, DOI 10.3233/JIFS-191461
   Vaka AR, 2020, ICT EXPRESS, V6, P320, DOI 10.1016/j.icte.2020.04.009
   Wang SJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03430-5
NR 63
TC 5
Z9 5
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17044-8
EA OCT 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400024
DA 2024-07-18
ER

PT J
AU Yadav, N
   Dass, R
   Virmani, J
AF Yadav, Niranjan
   Dass, Rajeshwar
   Virmani, Jitendra
TI Deep learning-based CAD system design for thyroid tumor characterization
   using ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-aided diagnosis system; Thyroid tissue characterization;
   Pre-trained models; Semantic segmentation; PCA-SVM classifier
ID CANCER TISSUE CHARACTERIZATION; COMPUTER-AIDED DIAGNOSIS;
   HASHIMOTOS-THYROIDITIS; CLASSIFICATION; NODULES; ULTRASONOGRAPHY;
   RECOGNITION; NETWORK; MODEL
AB Computer-Aided Diagnosis (CAD) system is preferred for automatic thyroid tumor ultrasound image characterization instead of manual assessment by the experts. Segmentation and control despeckling are the important pre-processing stages required to develop an effective CAD system. This work primarily aims to design an efficient CAD system for thyroid tumor characterization using ultrasound (US) images. Here, Edge Preserving Smoothing despeckling filter and encoder decoder-based ResNet50 segmentation model are used as pre-processing stages of the proposed CAD system to enhance its performance for thyroid tumor characterization. Extracting the image features using pre-trained models effectively captures the underlying textural and morphological characteristics exhibited by thyroid tumors in ultrasound images. The pre-trained- models learn by automatic feature extraction representing the underlying characteristics using multiple stages by convolution with various filters. The pre-train-based neural network classifies tumors more accurately due to learning the extract multiple sets of features. Accordingly, fifteen (15) deep learning-based pre-trained models have been utilized in the present work to extract information from the thyroid tumor US images and train the PCA-SVM classifier. These pre-train models have been taken from different categories of deep learning algorithms, including Series / DAG / Lightweight architectures, namely AlexNet, VGG16, VGG19, Darknet19, Darknet53, GoogleNet, DenseNet201, ResNet18, ResNet50, ResNet101, EfficientNetb0, NasNetMobile, MobileNet, SqueezeNet, and ShuffleNet for characterization of thyroid tissues. An exhaustive set of experiments have been conducted, and the best-performing pre-trained models have been selected as optimal feature extractors based on classification accuracy. Thus, the features extracted from the best-performing pre-trained network, i.e., ResNet50, are fed to the PCA-SVM classifier to yield an efficient CAD system for classifying TTUS images. The optimal CAD design proposed in the present work yields 99.5% classification accuracy to distinguish between benign and malignant thyroid tumors.
C1 [Yadav, Niranjan; Dass, Rajeshwar] Deenbandhu Chhotu Ram Univ Sci & Technol Murthal, Dept Elect & Commun Engn, Sonepat 131039, India.
   [Virmani, Jitendra] CSIR, Cent Sci Instruments Org, Chandigarh 160030, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Scientific Instruments Organisation (CSIO)
RP Yadav, N (corresponding author), Deenbandhu Chhotu Ram Univ Sci & Technol Murthal, Dept Elect & Commun Engn, Sonepat 131039, India.
EM niranjanyadav97@gmail.com; rajeshwardas10@gmail.com;
   jitendra.virmani@csio.res.in
RI yadav, niranjan/AFJ-1422-2022
OI yadav, niranjan/0000-0002-1023-0438
FU The first author acknowledges "National Project Implementation Unit
   (NPIU), a unit of the Ministry of Human Resource Development, Government
   of India" for the financial assistantship through the TEQIP-III project
   at Deenbandhu Chhotu Ram University of Scie; National Project
   Implementation Unit (NPIU), a unit of the Ministry of Human Resource
   Development, Government of India
FX The first author acknowledges "National Project Implementation Unit
   (NPIU), a unit of the Ministry of Human Resource Development, Government
   of India" for the financial assistantship through the TEQIP-III project
   at Deenbandhu Chhotu Ram University of Science and Technology, Murthal,
   Haryana, India.
CR Aboudi N, 2023, ARAB J SCI ENG, V48, P10563, DOI 10.1007/s13369-023-07674-3
   Acharya UR, 2014, ULTRASCHALL MED, V35, P237, DOI 10.1055/s-0032-1330336
   Acharya UR, 2013, P I MECH ENG H, V227, P788, DOI 10.1177/0954411913483637
   Acharya UR, 2016, KNOWL-BASED SYST, V107, P235, DOI 10.1016/j.knosys.2016.06.010
   Acharya UR, 2014, TECHNOL CANCER RES T, V13, P289, DOI 10.7785/tcrt.2012.500381
   Acharya UR, 2013, P I MECH ENG H, V227, P284, DOI 10.1177/0954411912472422
   Acharya UR, 2012, IEEE ENG MED BIO, P452, DOI 10.1109/EMBC.2012.6345965
   Acharya UR, 2012, ULTRASONICS, V52, P508, DOI 10.1016/j.ultras.2011.11.003
   Ahmed J., 2016, Int Conf Intell Syst Eng, V2016, P1, DOI [10.1109/INTELSE.2016.7475160, DOI 10.1109/INTELSE.2016.7475160]
   Akkus Z, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512574
   [Anonymous], 2017, Gen Relativ Quantum Cosmol Univ, DOI DOI 10.1103/PHYSREVD.97.101501
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Augustin S, 2013, INT J COMPUT SCI MOB, P134
   Avola D, 2022, IEEE T CIRC SYST VID, V32, P2527, DOI 10.1109/TCSVT.2021.3074414
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Beyyala A, 2023, Lecture Notes in Networks and Systems, V649, DOI [10.1007/978-3-031-27499-2_85, DOI 10.1007/978-3-031-27499-2_85]
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bibicu D, 2013, J DIGIT IMAGING, V26, P119, DOI 10.1007/s10278-012-9475-5
   Biomedical F, 2016, Traditional Feature Engineering and Deep Learning Approaches at Medical Classification Task of ImageCLEF 2016
   Buda M, 2019, RADIOLOGY, V292, P695, DOI 10.1148/radiol.2019181343
   Carina Pereira, 2018, SPIE Med Imaging, V2018
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Chai YJ, 2018, 7 INT C EXH SURG 3 I, V08, P46, DOI [10.4172/2161-1076-C2-038, DOI 10.4172/2161-1076-C2-038]
   Chaudhary Vikas, 2013, Indian J Endocrinol Metab, V17, P219, DOI 10.4103/2230-8210.109667
   Cheng XC, 2022, J SUPERCOMPUT, V78, P17114, DOI 10.1007/s11227-022-04561-w
   [迟剑宁 Chi Jianning], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1582
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Chuang Xi RD, 2023, Early View, P1, DOI [10.1002/VIW.20220057, DOI 10.1002/VIW.20220057]
   Corina Maria Vasile A. L., 2021, Disorders in Ultrasound Images Curr Health Sci J., V47, P221, DOI [10.12865/CHSJ.47.02.12, DOI 10.12865/CHSJ.47.02.12]
   Dass Rajeshwar, 2018, Procedia Computer Science, V132, P1543, DOI 10.1016/j.procs.2018.05.118
   Dass R, 2020, PROCEDIA COMPUT SCI, V167, P2382, DOI 10.1016/j.procs.2020.03.291
   Davis UC, 2017, CoRR abs/170905011
   Elangovan A, 2016, FIRST INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING, TECHNOLOGY AND SCIENCE - ICETETS 2016
   Elder EM, 2018, J Med Phys., DOI [10.17310/ntj.2013.4.08, DOI 10.17310/NTJ.2013.4.08]
   Fernández Sánchez J, 2014, Rev. argent. radiol., V78, P138, DOI 10.1016/j.rard.2014.07.015
   Frank E, 2016, The WEKA workbench. Online appendix for data mining: practical machine learning tools and techniques
   Fu YH, 2018, MINER ENG, V115, P68, DOI 10.1016/j.mineng.2017.10.005
   Geng M, 2016, Comput Vis Pattern Recognition, DOI [10.14393/BJ-v32n2a2016-30491, DOI 10.14393/BJ-V32N2A2016-30491]
   Gesing A., 2015, Thyroid Res, V8, pA8, DOI [DOI 10.1186/1756-6614-8-S1-A8, 10.1186/1756-6614-8-S1-A8]
   Ghoniem RM, 2020, INFORMATION, V11, DOI 10.3390/info11020080
   Gireesha HM., 2014, INT J ENG RES TECHNO, V3, P2252
   Gore DV, 2023, Advances in Intelligent Systems and Computing, V1348, DOI [10.1007/978-981-19-4676-9_54, DOI 10.1007/978-981-19-4676-9_54]
   Göreke V, 2023, INTERDISCIP SCI, V15, P360, DOI 10.1007/s12539-023-00560-4
   Guan Q, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.04.34
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080848
   Hassan TM, 2017, ARAB J SCI ENG, V42, P3127, DOI 10.1007/s13369-016-2387-9
   ImageNet, ABOUT US
   Jaglan P, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115580
   Jiahao Xie, 2020, Journal of Physics: Conference Series, V1693, DOI 10.1088/1742-6596/1693/1/012160
   Katsigiannis SEGK, 2010, Eng Intell Syst, V18
   Keramidas EG, 2012, J MED SYST, V36, P1271, DOI 10.1007/s10916-010-9588-7
   Kesarkar Xhitij A., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P11, DOI 10.1109/ICAIS50930.2021.9396035
   Koprowski R, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-91
   Korfiati A, 2021, Intl J Adv Res (IJAR), DOI [10.21474/IJAR01/13681, DOI 10.21474/IJAR01/13681]
   Koundal D, 2018, BIOMED SIGNAL PROCES, V40, P117, DOI 10.1016/j.bspc.2017.08.025
   Kriti, 2020, MULTIMED TOOLS APPL, V79, P27257, DOI 10.1007/s11042-020-09337-z
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P536, DOI 10.1016/j.bbe.2019.02.004
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P100, DOI 10.1016/j.bbe.2018.10.002
   La Vecchia C, 2015, INT J CANCER, V136, P2187, DOI 10.1002/ijc.29251
   Lee E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56395-x
   Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9
   Liang XW, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/1763803
   Liu TJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101555
   Liu TJ, 2017, INT CONF ACOUST SPEE, P919, DOI 10.1109/ICASSP.2017.7952290
   Ma XS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5582029
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mcloughlin I, 2017, Deep Bottleneck Feature for Image Classification, P491
   Moussa O, 2020, INT J IMAG SYST TECH, V30, P185, DOI 10.1002/ima.22363
   Nagataki S, 2002, THYROID, V12, P889, DOI 10.1089/105072502761016511
   Nugroho A., 2016, COMMUN SCI TECHNOL, V1, P61, DOI [10.21924/cst.1.2.2016.25, DOI 10.21924/CST.1.2.2016.25]
   Oluwadare Adepeju Adebisi A., 2020, IOSR J Comput Eng (IOSR-JCE), V22, P60, DOI DOI 10.9790/0661-2203016066
   Park VY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54434-1
   Pavithra S, 2022, Lecture Notes in Networks and Systems, V300, DOI 10.1007/
   Pavya K, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INNOVATIONS IN GREEN ENERGY AND HEALTHCARE TECHNOLOGIES (IGEHT)
   Peddakama R, 2023, medRxiv, P1, DOI [10.1101/2022.12.31.22284087, DOI 10.1101/2022.12.31.22284087]
   Pedraza L, 2015, PROC SPIE, V9287, DOI 10.1117/12.2073532
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Rani J, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13309
   Russ G, 2016, ULTRASONOGRAPHY, V35, P25, DOI 10.14366/usg.15027
   Scheipers U, 2003, ULTRASOUND MED BIOL, V29, P1137, DOI 10.1016/S0301-5629(03)00062-0
   Shankarlal B, 2023, IETE J RES, V69, P995, DOI 10.1080/03772063.2020.1844083
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
   Song GS, 2015, J ULTRAS MED, V34, P1753, DOI 10.7863/ultra.15.14.10045
   Song WF, 2019, IEEE J BIOMED HEALTH, V23, P1215, DOI 10.1109/JBHI.2018.2852718
   Sornam M, 2017, INT CONF ADV COMPU, P121, DOI 10.1109/ICoAC.2017.8441512
   Srivastava R, 2022, INT J GRID UTIL COMP, V13, P624, DOI 10.1504/IJGUC.2022.128316
   Sundar KVS, 2018, 1 C MED IM DEEP LEAR, P1
   Tasnimi M, 2023, MULTIMED TOOLS APPL, V82, P3859, DOI 10.1007/s11042-022-13433-7
   Tianjiao Liu, 2017, 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI), P1096, DOI 10.1109/ISBI.2017.7950707
   Tsantis S, 2006, COMPUT METH PROG BIO, V84, P86, DOI 10.1016/j.cmpb.2006.09.006
   Tsantis S, 2009, COMPUT MED IMAG GRAP, V33, P91, DOI 10.1016/j.compmedimag.2008.10.010
   ultrasoundcases, 2018, September
   Veda Reddy T., 2023, Intl Res J Modern Eng Technol Sci, V5, P2949
   Verma A, 2022, Lecture Notes in Electrical Engineering, V924, DOI [10.1007/978-981-19-4136-8, DOI 10.1007/978-981-19-4136-8]
   Verma A, 2022, MULTIMED TOOLS APPL, V81, P37541, DOI 10.1007/s11042-022-13545-0
   Virmani J., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P212, DOI 10.1109/MSPCT.2011.6150477
   Virmani J, 2013, DEFENCE SCI J, V63, P478, DOI 10.14429/dsj.63.3951
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Wang JX, 2018, IEEE IMAGE PROC, P3114, DOI 10.1109/ICIP.2018.8451085
   Wang SH, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6633755
   Xie GS, 2015, IEEE I CONF COMP VIS, P1179, DOI 10.1109/ICCV.2015.140
   Xie Xia, 2023, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2023.3251323
   Yadav Niranjan, 2022, Emergent Converging Technologies and Biomedical Systems: Select Proceedings of ETBS 2021. Lecture Notes in Electrical Engineering (841), P575, DOI 10.1007/978-981-16-8774-7_48
   Yadav N., 2022, Int J Med Eng Inform, V1, P1, DOI [10.1504/IJMEI.2022.10049164, DOI 10.1504/IJMEI.2022.10049164]
   Yadav N, 2023, J ULTRASOUND, V26, P673, DOI 10.1007/s40477-022-00726-8
   Yadav N, 2022, MULTIMED TOOLS APPL, V81, P8905, DOI 10.1007/s11042-022-11965-6
   Yoo YJ, 2018, KOREAN J RADIOL, V19, P665, DOI 10.3348/kjr.2018.19.4.665
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zahir Shokouh Taghipour, 2016, J Ayub Med Coll Abbottabad, V28, P644
   Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808
   Zhang XY, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262128
   Zhao WJ, 2022, J CLIN ENDOCR METAB, V107, P953, DOI 10.1210/clinem/dgab870
   Zheng H, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.939418
   Zhu Y, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1819, DOI 10.1109/CompComm.2017.8322853
NR 116
TC 8
Z9 8
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17137-4
EA OCT 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400023
DA 2024-07-18
ER

PT J
AU Rani, J
   Anand, A
   Shivani, S
AF Rani, Jyoti
   Anand, Ashima
   Shivani, Shivendra
TI SecECG: secure data hiding approach for ECG signals in smart healthcare
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ECG; Watermarking; Pan tompkins; Contourlet transform; MSVD
   (multi-resolution singular value decomposition); Encryption
AB Rapid development of communication technologies and Point of Care (POC) services has encouraged the sharing of digital biomedical records through the open network to achieve remote health assistance. These medical records contain sensitive and confidential information about patients. Preserving this data from illegal distribution and alteration during transmission is a major challenge. To secure biomedical signals, the encryption-based non-blind watermarking method is introduced in this article. A robust and secure technique is established for embedding a watermark into an ECG signal using the Contourlet Transform and Multi-resolution SVD. In the initial phase, the mark image is ciphered using chaotic shift transform and modified henon map-based encryption technique to improve the security of the proposed work. The encrypted watermark is then inserted into the higher frequency coefficients of the ECG signal to prevent ownership issues and ensure copyright protection. The standard ECG MIT-BIH and PTB Diagnostic ECG datasets are utilized to evaluate the suggested algorithm. The suggested approach is compared to the current literature, and the results reveal a maximum improvement in robustness of 28.98 %. This method yields promising outcomes in terms of stability, invisibility, and safety. The experimental results on visual quality and resilience suggest that the proposed approaches keep the high resolution of watermarked images and are remarkably resilient to a wide range of conventional attacks.
C1 [Rani, Jyoti; Anand, Ashima; Shivani, Shivendra] Thapar Inst Engn & Technol, Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Anand, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn, Patiala, Punjab, India.
EM ashima.anand@thapar.edu
NR 0
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17049-3
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200008
DA 2024-07-18
ER

PT J
AU Jiang, XH
   Fang, X
AF Jiang, Xiuhan
   Fang, Xi
TI A novel high-utility association rule mining method and its application
   to movie recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Association Rules; Collaborative Filtering; Interest Transfer; Rating
   Prediction; Movie System
AB The rapid development of the Internet and information technology has caused a surge in the amount of information in the network, and the problem of "information overload" has affected the user experience. The research object of this paper is the movie recommendation system, mainly from the algorithm of recommendation technology, and the recommendation effect is verified by simulation experiments on the Movielens dataset. High-utility association rule mining is applied to the recommendation algorithm, and the sparse scoring matrix is filled with high-utility itemsets. The experimental results show that the proposed high-efficiency mining method can effectively fill the user rating matrix, and its precision is increased by 9.59% compared with the traditional algorithm, the recall rate is increased by 8.97%, and the coverage rate is increased by 9.30%.It is proposed that the temporal distance is used to process the user rating time series, and then the temporal similarity is used to calculate the user interest. The experimental results show that the precision of the proposed method is improved by 1.32% and the recall rate is improved by 1.57% compared with the above algorithms. This method can also be applied to other recommender systems.
C1 [Jiang, Xiuhan; Fang, Xi] Wuhan Univ Technol, Sch Sci, Wuhan, Peoples R China.
C3 Wuhan University of Technology
RP Fang, X (corresponding author), Wuhan Univ Technol, Sch Sci, Wuhan, Peoples R China.
EM fangxi@whut.edu.cn
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Ahmadian M, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116697
   Azeez NA, 2019, COMPUTERS, V8, DOI 10.3390/computers8040086
   Cheng Wei Wu, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P824, DOI 10.1109/ICDM.2011.60
   Choi HJ, 2019, EXPERT SYST APPL, V115, P27, DOI 10.1016/j.eswa.2018.07.051
   De Maio C., 2018, Concurr Comput Pract Exp, V30, P1532
   Deldjoo Y, 2018, INT J MULTIMED INF R, V7, P207, DOI 10.1007/s13735-018-0155-1
   Djenouri Y, 2017, INFORM SCIENCES, V420, P1, DOI 10.1016/j.ins.2017.08.043
   Gan MX, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114695
   Gan WS, 2020, IEEE T CYBERNETICS, V50, P1195, DOI 10.1109/TCYB.2019.2896267
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Hong TP, 2009, 2009 10TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS, AND NETWORKS (ISPAN 2009), P421, DOI 10.1109/I-SPAN.2009.24
   Honglei J, 2014, Research on recommendation method based on high-efficiency pattern mining
   Iqbal M, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102347
   Kim D, 2017, APPL INTELL, V47, P114, DOI 10.1007/s10489-016-0890-z
   Li H, 2016, NEUROCOMPUTING, V210, P164, DOI 10.1016/j.neucom.2015.09.134
   Liu Y, 2005, LECT NOTES ARTIF INT, V3518, P689
   Manotumruksa J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1383, DOI 10.1145/3077136.3084159
   Mocanu DC, 2015, PATTERN RECOGN LETT, V66, P100, DOI 10.1016/j.patrec.2015.01.013
   Mu YH, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11040895
   Peipei W., 2019, Comput Simul, V36, P434
   Qin ZT, 2021, PROCEEDINGS OF 2021 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS '21), DOI 10.1145/3469213.3470423
   Rabiu I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072204
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Rui S., 2021, Comput Appl Res, V38, P975
   Shaofeng W., 2020, Comput Appl Res, V37, P2571
   Xiaochuan Z., 2019, J Chongqing Univ Technol, V24, P161
   Xiaofang M., 2019, Comput Appl Softw, V36, P243
   Yajin Z, 2021, Comput Appl Softw, V38, P182
   Yan L, 2017, Comput Sci, V44, P295
   Yang D, 2021, J ORGAN END USER COM, V33, P19, DOI 10.4018/JOEUC.20210501.oa2
   Yin M., 2020, J Phys: Conf Ser, V1746, P22
   Yutong X., 2019, Appl Res Comput, V36, P3605
   Zhang YL, 2022, PROCEDIA COMPUT SCI, V199, P871, DOI 10.1016/j.procs.2022.01.109
   Zheng WK, 2020, MATERIALS, V13, DOI 10.3390/ma13041009
   Zhiqiang B., 2019, Mod Electron Technol, V42, P78
   Zhixuan X., 2017, Small Microcomput Syst, V38, P2080
NR 38
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17063-5
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800006
DA 2024-07-18
ER

PT J
AU Tasci, B
   Tasci, G
   Ayyildiz, H
   Kamath, AP
   Barua, PD
   Tuncer, T
   Dogan, S
   Ciaccio, EJ
   Chakraborty, S
   Acharya, UR
AF Tasci, Burak
   Tasci, Gulay
   Ayyildiz, Hakan
   Kamath, Aditya P.
   Barua, Prabal Datta
   Tuncer, Turker
   Dogan, Sengul
   Ciaccio, Edward J.
   Chakraborty, Subrata
   Acharya, U. Rajendra
TI Automated schizophrenia detection model using blood sample scattergram
   images and local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Schizophrenia detection; Scattergram images; Local Binary Pattern;
   Iterative Neighborhood Component Analysis; Iterative Hard Majority
   Voting
ID COMPLEXITY
AB The main goal of this paper is to advance the field of automated Schizophrenia (SZ) detection methods by presenting a pioneering feature engineering technique that achieves high classification accuracy while maintaining low time complexity. Furthermore, we introduce a novel data type known as scattergram images, which can be obtained through a simple blood test. These scattergram images provide a cost-effective approach for SZ detection. The scattergram image datasets used in this research consist of images collected from 202 participants, with 106 individuals diagnosed with SZ and the remaining 96 individuals serving as control subjects. Our objective is to assess the ability of scattergram images to detect SZ. To achieve accurate classification with minimal computational burden, we propose a feature engineering model based on the local binary pattern (LBP) technique. Initially, a preprocessing method is applied to separate blood cells from the scattergram images, followed by image rotation to ensure robust results. Both 1D-LBP and 2D-LBP are utilized to extract informative features. Our feature engineering model incorporates iterative neighborhood component analysis (INCA) to select the most relevant features. In the classification phase, shallow classifiers are employed to demonstrate the capability of the extracted features for classification. Information fusion is accomplished using iterative hard majority voting (IHMV) to select the most accurate result. We have tested our proposal on the collected two scattergram image datasets and our proposal attained 89.29% and 90.58% classification accuracies on the used datasets, respectively. The findings of this study demonstrate the potential of scattergram images as an effective tool for SZ detection, thus serving as a promising new biomarker in the field. Our auto-detection model of SZ disease is clinically ready for use in hospital settings and outpatient clinics as an additional means to assist clinicians in their diagnostics procedure.
C1 [Tasci, Burak] Firat Univ, Vocat Sch Tech Sci, TR-23119 Elazig, Turkiye.
   [Tasci, Gulay] Elazig Fethi Sekin City Hosp, Dept Psychiat, Elazig, Turkiye.
   [Ayyildiz, Hakan] Elazig Fethi Sekin City Hosp, Dept Biochem, Elazig, Turkiye.
   [Kamath, Aditya P.] Brown Univ, Biomed Engn, Providence, RI USA.
   [Barua, Prabal Datta] Univ Southern Queensland, Sch Business Informat Syst, Toowoomba, Qld 4350, Australia.
   [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
   [Ciaccio, Edward J.] Columbia Univ, Irving Med Ctr, Dept Med, New York, NY USA.
   [Chakraborty, Subrata] Univ New England, Fac Sci Agr Business & Law, Sch Sci & Technol, Armidale, NSW 2351, Australia.
   [Chakraborty, Subrata] Univ Technol Sydney, Fac Engn & IT, Ctr Adv Modelling & Geospatial Informat Syst, Sydney, NSW 2007, Australia.
   [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia.
C3 Firat University; Brown University; University of Southern Queensland;
   Firat University; NewYork-Presbyterian Hospital; Columbia University;
   University of New England; University of Technology Sydney; University
   of Southern Queensland
RP Dogan, S (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM btasci@firat.edu.tr; akcagulay01@gmail.com;
   hakan.ayyildiz1@saglik.gov.tr; aditya_kamath@brown.edu;
   prabal.barua@usq.edu.au; turkertuncer@firat.edu.tr; sdogan@firat.edu.tr;
   ciaccio@columbia.edu; subrata.chakraborty@une.edu.au;
   Rajendra.Acharya@usq.edu.au
RI DOGAN, Sengul/W-4854-2018; Chakraborty, Subrata/IXX-0792-2023; Taşcı,
   Burak/L-7100-2018
OI DOGAN, Sengul/0000-0001-9677-5684; Chakraborty,
   Subrata/0000-0002-0102-5424; Taşcı, Burak/0000-0002-4490-0946
FU We gratefully acknowledge the Ethics Committee, Firat University data
   transcription.
FX We gratefully acknowledge the Ethics Committee, Firat University data
   transcription.
CR Ahmedt-Aristizabal D, 2021, IEEE J BIOMED HEALTH, V25, P69, DOI 10.1109/JBHI.2020.2984238
   Alves CL, 2022, J PHYS-COMPLEXITY, V3, DOI 10.1088/2632-072X/ac5f8d
   Aslan Z, 2022, PHYS ENG SCI MED, V45, P83, DOI 10.1007/s13246-021-01083-2
   Aydemir E, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10040643
   Ayyildiz H, 2022, TRAIT SIGNAL, V39, P449, DOI 10.18280/ts.390206
   Bagherzadeh S, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105570
   Barua PD, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104841
   Baygin M, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102936
   Bighelli I, 2021, LANCET PSYCHIAT, V8, P969, DOI 10.1016/S2215-0366(21)00243-1
   Bigorra L, 2020, CLIN CHIM ACTA, V511, P181, DOI 10.1016/j.cca.2020.10.015
   Bondugula Rohit Kumar, 2022, Intelligent Systems: Proceedings of ICMIB 2021. Lecture Notes in Networks and Systems (431), P653, DOI 10.1007/978-981-19-0901-6_57
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Demir F., 2022, ARTIF INTELL, P317
   Devia C, 2019, IEEE T NEUR SYS REH, V27, P1193, DOI 10.1109/TNSRE.2019.2913799
   Dogan A, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104867
   Göker H, 2023, SIGNAL IMAGE VIDEO P, V17, P2627, DOI 10.1007/s11760-022-02479-7
   Grover N, 2023, IEEE T NEUR SYS REH, V31, P464, DOI 10.1109/TNSRE.2023.3237375
   Hassan F, 2023, INFORM FUSION, V92, P466, DOI 10.1016/j.inffus.2022.12.019
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ilakiyaselvan N, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103278
   Kaplan E, 2022, COMPUT METH PROG BIO, V224, DOI 10.1016/j.cmpb.2022.107030
   Kaplan E, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/6034971
   Khare SK, 2023, PHYSIOL MEAS, V44, DOI 10.1088/1361-6579/acbc06
   Khare SK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3070608
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2020, J STAT MECH-THEORY E, V2020, DOI 10.1088/1742-5468/abc62b
   Li Ran, 2022, 2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information (ICETCI), P1014, DOI 10.1109/ICETCI55101.2022.9832216
   Meyer U, 2010, PROG NEUROBIOL, V90, P285, DOI 10.1016/j.pneurobio.2009.10.018
   Müller N, 2018, SCHIZOPHRENIA BULL, V44, P973, DOI 10.1093/schbul/sby024
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   North HF, 2021, EUR ARCH PSY CLIN N, V271, P595, DOI 10.1007/s00406-021-01237-z
   Oh SL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142870
   Piryatinska A, 2017, COMPUT METH PROG BIO, V152, P131, DOI 10.1016/j.cmpb.2017.09.001
   Qureshi MNI, 2019, ARTIF INTELL MED, V98, P10, DOI 10.1016/j.artmed.2019.06.003
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seeman MV, 2021, EXPERT REV NEUROTHER, V21, P443, DOI 10.1080/14737175.2021.1898947
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh K, 2022, MULTIMED TOOLS APPL, V81, P28875, DOI 10.1007/s11042-022-12611-x
   Siuly S, 2020, IEEE T NEUR SYS REH, V28, P2390, DOI 10.1109/TNSRE.2020.3022715
   Stilo SA, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1091-3
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tasci B, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103948
   Tasci B, 2022, APPL ACOUST, V196, DOI 10.1016/j.apacoust.2022.108897
   Tavakoli N, 2022, Prognostic Models in Healthcare: AI and Statistical Approaches, P161
   Teoh L, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0268962
   Thilakvathi B, 2017, BIOMED RES-INDIA, V28, P1
   Tomasik J, 2016, SCHIZOPHR RES, V176, P3, DOI 10.1016/j.schres.2014.07.025
   Tuncer SA, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104579
   Tuncer T, 2020, IEEE ACCESS, V8, P84532, DOI 10.1109/ACCESS.2020.2992641
   Vahia VN, 2013, INDIAN J PSYCHIAT, V55, P220, DOI 10.4103/0019-5545.117131
   Vickers NJ, 2017, CURR BIOL, V27, pR713, DOI 10.1016/j.cub.2017.05.064
   Yang X., 2022, Mach Learn Appl, V8
   Zeng LL, 2018, EBIOMEDICINE, V30, P74, DOI 10.1016/j.ebiom.2018.03.017
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 63
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16676-0
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800025
DA 2024-07-18
ER

PT J
AU Kumar, A
   Misra, R
   Singh, TN
   Dhiman, G
AF Kumar, Abhijit
   Misra, Rajiv
   Singh, T. N.
   Dhiman, Gaurav
TI APO-AN feature selection based Glorot Init Optimal TransCNN landslide
   detection from multi source satellite imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Landslide detection; Independent Component Analysis (ICA) based DBSCAN;
   Archimedes principle optimization based attention network (APO-AN);
   Glorot Initialization Optimal TransCNN; And feature descriptor
ID NETWORKS
AB The work presents a comprehensive approach for landslide detection in satellite imagery by combining multiple techniques. The proposed methodology involves denoising the landslide image using the maximum information coefficient-based Wavelet Filter (MIC-WF) to enhance image quality. The denoising process with MIC-WF effectively reduces noise in the landslide image, resulting in improved image clarity and quality. To address the issue of overlapping pixels, an innovative approach based on Independent Component Analysis (ICA) based "Density-Based Spatial Clustering of Applications with Noise (DBSCAN)" is exploited for pixel separation. The separation of overlapping pixels using ICA-DBSCAN overcomes the challenge of pixel ambiguity, allowing for precise identification of individual landslide areas. Furthermore, the feature point discriptor as a feature selection method based on the Archimedes principle optimization-based attention network (APO-AN) is utilized to identify the most informative features for landslide detection. The feature selection based on APO-AN ensures that only the most relevant features are used for landslide detection, reducing computational complexity and enhancing model efficiency. Finally, a landslide detection model is developed using the Glorot Initialization Optimal TransCNN approach for accurate classification of landslide areas, leveraging the benefits of optimized weight initialization. FMRCNN, R-CNN, M-CNN, and CNN techniques achieve specificities of 93.47%, 92.11%, 91.78%, and 90.25%, respectively. The denoising, pixel separation, feature selection, and classification stages collectively contribute to the accurate detection of landslide areas in satellite imagery. The integration of these techniques offers a comprehensive solution for landslide detection, aiding in early warning systems and disaster management.
C1 [Kumar, Abhijit; Misra, Rajiv; Singh, T. N.] Indian Inst Technol Patna, Dept Comp Sci & Engn, Dayalpur Daulatpur 801106, India.
   [Kumar, Abhijit] Univ Petr & Energy Studies Dehradun, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
   [Singh, T. N.] Indian Inst Technol Bombay Powai, Dept Earth Sci, Mumbai 400076, Maharashtra, India.
   [Dhiman, Gaurav] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
   [Dhiman, Gaurav] Chandigarh Univ, Univ Ctr Res & Dev, Dept Comp Sci & Engn, Gharuan 140413, India.
   [Dhiman, Gaurav] Graphic Era, Dept Comp Sci & Engn, Dehra Dun 248002, India.
   [Dhiman, Gaurav] Lovely Profess Univ, Div Res & Dev, Phagwara, India.
   [Dhiman, Gaurav] Jagat Guru Nanak Dev Punjab State Open Univ, Sch Sci & Emerging Technol, Patiala 147001, Punjab, India.
C3 Indian Institute of Technology (IIT) - Patna; University of Petroleum &
   Energy Studies (UPES); Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bombay; Lebanese
   American University; Chandigarh University; Graphic Era University;
   Lovely Professional University
RP Dhiman, G (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.; Dhiman, G (corresponding author), Chandigarh Univ, Univ Ctr Res & Dev, Dept Comp Sci & Engn, Gharuan 140413, India.; Dhiman, G (corresponding author), Graphic Era, Dept Comp Sci & Engn, Dehra Dun 248002, India.; Dhiman, G (corresponding author), Lovely Profess Univ, Div Res & Dev, Phagwara, India.; Dhiman, G (corresponding author), Jagat Guru Nanak Dev Punjab State Open Univ, Sch Sci & Emerging Technol, Patiala 147001, Punjab, India.
EM abhijitkaran@hotmail.com; rajivm@iitp.ac.in; tnsingh@iitb.ac.in;
   gdhiman0001@gmail.com
RI Dhiman, Gaurav/AAP-6925-2020; Kumar, Abhijit/AAT-5363-2020
OI Dhiman, Gaurav/0000-0002-6343-5197; Kumar, Abhijit/0000-0002-6378-4936
FU Visvesvaraya PhD Scheme, MeitY, Govt. of India [MEITY-PHD-2527]
FX This work is supported by Visvesvaraya PhD Scheme, MeitY, Govt. of India
   MEITY-PHD-2527.
CR Abbas N, 2021, 2021 3RD IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (MENACOMM), P142, DOI 10.1109/MENACOMM50742.2021.9678279
   Bao S, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010088
   Bao S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239104
   Chen X, 2023, FRONT EARTH SC-SWITZ, V11, DOI 10.3389/feart.2023.1182145
   [杜宇峰 Du Yufeng], 2023, [测绘通报, Bulletin of Surveying and Mapping], P16
   Fu R, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14163928
   Gerges Firas, 2021, AIPR 2021: 2021 4th International Conference on Artificial Intelligence and Pattern Recognition, P607, DOI 10.1145/3488933.3488993
   Ghorbanzadeh O, 2022, IEEE J-STARS, V15, P9927, DOI 10.1109/JSTARS.2022.3220845
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Hammoud A, 2022, IEEE T NETW SERV MAN, V19, P3062, DOI 10.1109/TNSM.2022.3172370
   Helwan A., 2021, International Conference on Emerging Technologies and Intelligent Systems, P215
   Kuang P, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14081919
   Kumar A, 2023, SPRINGER P MATH STAT, V403, DOI [10.1007/978-3-031-16178-0_21, DOI 10.1007/978-3-031-16178-0_21]
   Li Y, 2023, LANDSLIDES, V20, P547, DOI 10.1007/s10346-022-01997-2
   Lv PY, 2023, IEEE J-STARS, V16, P2681, DOI 10.1109/JSTARS.2023.3253769
   Niu C, 2023, LAND-BASEL, V12, DOI 10.3390/land12020313
   Saab SS, 2021, INT J CONTROL, V94, P1273, DOI 10.1080/00207179.2019.1642518
   Saab SS, 2022, IEEE T IND ELECTRON, V69, P1858, DOI 10.1109/TIE.2021.3063866
   Sayour MH, 2022, J ROBOT, V2022, DOI 10.1155/2022/2585656
   Shen D, 2022, IEEE T AUTOMAT CONTR, V67, P4123, DOI 10.1109/TAC.2021.3106860
   Shen D, 2022, IEEE T NEUR NET LEAR, V33, P7559, DOI 10.1109/TNNLS.2021.3085559
   Tang XC, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122884
   Tao Wang, 2021, 2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P367, DOI 10.1109/PRAI53619.2021.9551067
   Tarhini A, 2022, PAC ASIA J ASSOC INF, V14, P1, DOI 10.17705/1pais.14201
   Wang GH, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092228
   Wang ZQ, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142316311
   Yang ZQ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122885
   Zhao D, 2022, CEUR WORKSHOP PROC
NR 28
TC 2
Z9 2
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17090-2
EA OCT 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400006
DA 2024-07-18
ER

PT J
AU Younsi, M
   Yesli, S
   Diaf, M
AF Younsi, Merzouk
   Yesli, Samir
   Diaf, Moussa
TI Depth-based human action recognition using histogram of templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human action recognition; Depth sequence; Action representation;
   Histogram of templates; Fuzzy k-nearest neighbor
ID FEATURES; JOINT; REPRESENTATION; SYSTEM
AB In this paper, we propose an efficient, fast, and easy-to-implement method for recognizing human actions in depth image sequences. In this method, the human body silhouettes are initially extracted from the depth image sequences using the Gaussian mixture background subtraction model. After removing noise from the foreground image by performing a cascade of morphological operations and area filtering, the contour of the human silhouette is extracted by applying Moore's neighbor contour tracing algorithm. From this contour, features describing the human posture are calculated using the Histogram of Templates (HoT) descriptor. These features are then used to train a Dendogram-based support vector machine for generating the frame-by-frame posture variation signal of the action sequence. The histogram of this signal is created, and finally introduced as an input vector into a Fuzzy k Nearest Neighbor (FkNN) classifier for recognizing human actions. The proposed method is evaluated on two publicly available datasets containing various daily actions (Bending, Sitting, Lying, etc.) performed by different human subjects. Extensive experiments are conducted using several values of the nearest neighbor (k) in the FkNN and different similarity measures, namely Euclidean distance, Bhattacharyya distance, Kullback-Leibler distance, and histogram intersection-based distance. The results show that the proposed method performs better or comparable to other state-of-the-art approaches. Moreover, this method can process 18 frames per second from the image sequence, which makes it well suited for applications needing real-time human action recognition.
C1 [Younsi, Merzouk; Yesli, Samir; Diaf, Moussa] Mouloud Mammeri Univ UMMTO, Lab Vis Artificielle & Automat Syst LVAAS, Tizi Ouzou, Algeria.
C3 Universite Mouloud Mammeri de Tizi Ouzou
RP Younsi, M (corresponding author), Mouloud Mammeri Univ UMMTO, Lab Vis Artificielle & Automat Syst LVAAS, Tizi Ouzou, Algeria.
EM merzouk.younsi@ummto.dz
OI Younsi, Merzouk/0000-0002-5542-2900
CR Adhikari K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P81, DOI 10.23919/MVA.2017.7986795
   Ahmed H., 2019, Condition Monitoring with Vibration Signals: Compressive Sampling and Learning Algorithms for Rotating Machines, P307, DOI [10.1002/9781119544678.ch15, DOI 10.1002/9781119544678.CH15]
   Akula A, 2018, COGN SYST RES, V50, P146, DOI 10.1016/j.cogsys.2018.04.002
   Asadzadeh S, 2019, BIOMED SIGNAL PROCES, V48, P171, DOI 10.1016/j.bspc.2018.08.028
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   Aslan M, 2015, APPL SOFT COMPUT, V37, P1023, DOI 10.1016/j.asoc.2014.12.035
   Batchuluun G, 2021, IEEE ACCESS, V9, P11716, DOI 10.1109/ACCESS.2021.3051375
   Batchuluun G, 2019, IEEE ACCESS, V7, P103893, DOI 10.1109/ACCESS.2019.2931804
   Ben Fredj Ines, 2017, 2017 International Conference on Advanced Systems and Electric Technologies (IC_ASET). Proceedings, P118, DOI 10.1109/ASET.2017.7983676
   Benabdeslem K, 2006, ITI 2006: PROCEEDINGS OF THE 28TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P173, DOI 10.1109/ITI.2006.1708473
   Bulbul MF, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04528-1
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Cai LQ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051218
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen E., 2017, Int J Multimed Ubiquit Eng, V12, P203, DOI [10.14257/ijmue.2017.12.1.17, DOI 10.14257/IJMUE.2017.12.1.17]
   Chen T., 2023, 2023 IEEE 17 INT C A, P1, DOI [10.1109/FG57933.2023.10042671, DOI 10.1109/FG57933.2023.10042671]
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404
   Duan H., 2022, CVPR, P2969, DOI DOI 10.1109/CVPR52688.2022.00298
   El-Ghaish HA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P343, DOI 10.5220/0006625703430350
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   falldataset, Fall detection Dataset
   Fan JM, 2022, ROBOT CIM-INT MANUF, V75, DOI 10.1016/j.rcim.2021.102304
   Fan KB, 2019, MULTIMED TOOLS APPL, V78, P9101, DOI 10.1007/s11042-018-5638-9
   Fan YB, 2020, IEEE ACCESS, V8, P15280, DOI 10.1109/ACCESS.2020.2968054
   Feng LQ, 2022, ARTIF INTELL REV, V55, P4275, DOI 10.1007/s10462-021-10107-y
   Gao YB, 2018, IEEE ACCESS, V6, P52277, DOI 10.1109/ACCESS.2018.2869790
   Gattal A, 2015, INT J COMPUT INTELL, V14, DOI 10.1142/S1469026815500054
   Ghorbel E, 2015, INT CONF IMAG PROC, P61, DOI 10.1109/IPTA.2015.7367097
   Gou JP, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3319532
   Goyal K, 2018, ARTIF INTELL REV, V50, P241, DOI 10.1007/s10462-017-9542-x
   Guo Y, 2018, PATTERN RECOGN, V76, P137, DOI 10.1016/j.patcog.2017.10.034
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   Ha S, 2016, IEEE IJCNN, P381, DOI 10.1109/IJCNN.2016.7727224
   He LF, 2017, PATTERN RECOGN, V70, P25, DOI 10.1016/j.patcog.2017.04.018
   Host K, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09633
   Jalal A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080817
   Jalloul N, 2018, IEEE J BIOMED HEALTH, V22, P989, DOI 10.1109/JBHI.2017.2762404
   Javeed M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041699
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Kumar P, 2021, MULTIMED TOOLS APPL, V80, P16515, DOI 10.1007/s11042-019-07978-3
   Kumar S. S., 2016, P 2016 IEEE INT CARN, P1, DOI DOI 10.1109/CCST.2016.7815694
   Kushwaha AKS, 2017, MULTIMEDIA SYST, V23, P451, DOI 10.1007/s00530-016-0505-x
   Li X, 2020, MULTIMED TOOLS APPL, V79, P35761, DOI 10.1007/s11042-020-09593-z
   Liu GL, 2018, IEEE SENS J, V18, P7570, DOI 10.1109/JSEN.2018.2859268
   Liu JJ, 2020, NEUROCOMPUTING, V385, P22, DOI 10.1016/j.neucom.2019.11.048
   Liu MY, 2016, NEUROCOMPUTING, V175, P747, DOI 10.1016/j.neucom.2015.11.005
   Lu MQ, 2020, APPL INTELL, V50, P1100, DOI 10.1007/s10489-019-01603-4
   Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Malawski F, 2019, J VIS COMMUN IMAGE R, V61, P198, DOI 10.1016/j.jvcir.2019.03.026
   Mansour A, 2019, MULTIMED TOOLS APPL, V78, P6441, DOI 10.1007/s11042-018-6256-2
   Merrouche F, 2020, MULTIMED TOOLS APPL, V79, P30489, DOI 10.1007/s11042-019-08428-w
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Murtaza F, 2016, IET COMPUT VIS, V10, P758, DOI 10.1049/iet-cvi.2015.0416
   Olatunji IE, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012148
   Patrona F, 2018, PATTERN RECOGN, V76, P612, DOI 10.1016/j.patcog.2017.12.007
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Qin Y, 2020, VISUAL COMPUT, V36, P621, DOI 10.1007/s00371-019-01644-3
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Rajamoney J, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7468
   Roh MC, 2010, PATTERN RECOGN LETT, V31, P639, DOI 10.1016/j.patrec.2009.11.017
   Sanchez-Riera J, 2012, LECT NOTES COMPUT SC, V7583, P332, DOI 10.1007/978-3-642-33863-2_33
   Shao ZP, 2018, IEEE INT CONF ROBOT, P1978
   Sharan RV, 2015, NEUROCOMPUTING, V158, P90, DOI 10.1016/j.neucom.2015.02.001
   Shi L, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108170
   Shrivastava A, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.07.010
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Sidaoui B, 2017, INT J COMPUT APPL T, V55, P183
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Sotiropoulos Dionisios N., 2017, International Journal of Computational Intelligence Studies, V6, P52
   Sowmyayani S, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-14056-8
   sucro, SDUFall Dataset
   Sun B, 2019, MULTIMED TOOLS APPL, V78, P6329, DOI 10.1007/s11042-018-6370-1
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Tahir SBUD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050579
   Tan YT, 2015, NEUROCOMPUTING, V148, P409, DOI 10.1016/j.neucom.2014.06.001
   Tang SP, 2010, INT CONF ACOUST SPEE, P2186, DOI 10.1109/ICASSP.2010.5495685
   Tomasev N, 2014, INT J MACH LEARN CYB, V5, P445, DOI 10.1007/s13042-012-0137-1
   Trelinski J, 2019, LECT NOTES ARTIF INT, V11509, P91, DOI 10.1007/978-3-030-20915-5_9
   Tyagi V., 2017, Content-Based Image Retrieval: Ideas, Influences, and Current Trends, P63, DOI DOI 10.1007/978-981-10-6759-4_4
   Varshney N, 2022, MULTIMED TOOLS APPL, V81, P34633, DOI 10.1007/s11042-021-11313-0
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Wang HS, 2018, PATTERN RECOGN, V81, P23, DOI 10.1016/j.patcog.2018.03.030
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xu WY, 2019, IEEE ACCESS, V7, P41811, DOI 10.1109/ACCESS.2019.2907720
   Xu Y, 2013, PATTERN RECOGN LETT, V34, P980, DOI 10.1016/j.patrec.2013.01.028
   Yao L, 2018, COMPUTING, V100, P369, DOI 10.1007/s00607-018-0603-z
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang JG, 2015, NEUROCOMPUTING, V149, P752, DOI 10.1016/j.neucom.2014.08.002
   Zhou ES, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115802
NR 98
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-16989-0
EA OCT 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400009
DA 2024-07-18
ER

PT J
AU Fang, QP
   Ying, N
   Chen, HH
   Hu, M
   Shu, Q
   Zhao, J
   Zhang, XW
AF Fang, Qianping
   Ying, Na
   Chen, Huahua
   Hu, Miao
   Shu, Qin
   Zhao, Jian
   Zhang, Xuewei
TI Gait recognition based on Orthogonal view feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gait recognition; Feature Decomposition; Orthogonal views; Multi-view
   gait recognition
AB Gait is used for personal identification but is sensitive to covariates such as views and walking conditions. To reduce the influence of views on the accuracy of gait recognition, this paper proposes an Orthogonal-view Feature Decomposition Network based on GaitSet (OFD-GaitSet). The algorithm regards gait recognition as two orthogonal view components of gait recognition. Firstly, the algorithm improves the setting of the gait gallery so that each sample in the gallery contains gait information with two views: 0 degrees and 90 degrees; Secondly, the algorithm designs two Feature Extraction Networks, which extract the gait sub-features of the gait silhouettes sequence from two views. At the same time, the View Identification Network and Distance Block are used to weight the Euclidean Distance between the gait sub-features and the gallery's, and the recognition results are obtained through comparison. This algorithm uses Cross Entropy Loss and improved Triplet Loss for training. Experiments on the CASIA-B dataset show that the average Raank-1 accuracy reaches 99.8% under normal walking (NM) conditions, 99.1% under walking with bag (BG) conditions, and 88.2% under wearing coat or jacket (CL) conditions. Compared with GaitSet, it improves by 4.8%, 11.9%, and 17.8%, respectively; Experiments on the OU-MVLP dataset have achieved a Rank-1 accuracy of 89.8%, which is 2.7% higher than the GaitSet.
C1 [Fang, Qianping; Ying, Na; Chen, Huahua; Hu, Miao; Shu, Qin; Zhao, Jian; Zhang, Xuewei] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Ying, N (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou, Zhejiang, Peoples R China.
EM 806621728@qq.com; yingna@hdu.edu.cn; iseealv@hdu.edu.cn;
   miao_hu@foxmail.com; 15669601897@163.com; 2535860560@qq.com;
   1466587180@qq.com
OI Ying, Na/0000-0003-1631-551X
CR Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen CH, 2011, PATTERN RECOGN, V44, P988, DOI 10.1016/j.patcog.2010.10.021
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Lin BB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14628, DOI 10.1109/ICCV48922.2021.01438
   Qi Yang, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P1457
   Saihui Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P382, DOI 10.1007/978-3-030-58545-7_22
   Song CF, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106988
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Teepe T., 2021, arXiv
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
NR 22
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17031-z
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600024
DA 2024-07-18
ER

PT J
AU Nivethithai, S
   Hariharan, B
AF Nivethithai, S.
   Hariharan, B.
TI Efficient budget aware workflow scheduling in cloud using adaptive
   Tasmanian Devil Optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Budget constraints; Workflow scheduling algorithm; Energy function; Cost
   coefficient factor; Tasmanian devil optimization; Levy flight
AB In order to decrease energy usage in cloud computing, we design the Efficient Budget aware Workflow Scheduling Algorithm (EBWSM) in this study. To achieve this concept, an adaptive Tasmanian Devil Optimization algorithm (ATDO) is developed. The projected ATDO is a combination of Tasmanian Devil Optimization (TDO) and Levy Flight (LF) functions. In the TDO, the position updating process is updated with the assistance of the LF function. The objective function of the cost coefficient factor and energy function is considered for enabling the efficient workflow scheduling model in cloud computing. The efficient pre-suggestion of the available budget is a main key process of this projected method. This workflow scheduling method was created as an effective way to reduce energy consumption while taking the cost coefficient factor and energy into account. This enables equitable allocation of the supplied budget for the cloud workflow application's unscheduled jobs.The proposed method is implemented and compared with the conventional methods of workflow scheduling model. In terms of energy usage, cost function, and makespan, the projected method outperformed the current approaches.
C1 [Nivethithai, S.] SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Computat Intelligence, SRM Nagar, Kattankulathur, Tamil Nadu, India.
   [Hariharan, B.] SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Computat Intelligence, SRM Nagar, Kattankulathur, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Hariharan, B (corresponding author), SRM Inst Sci & Technol, Coll Engn & Technol, Sch Comp, Dept Computat Intelligence, SRM Nagar, Kattankulathur, Tamil Nadu, India.
EM Nivethitaiphd2022@gmail.com; hariharanresearch2021@gmail.com
CR Aarthi B, 2023, NEURAL COMPUT APPL, V35, P18395, DOI 10.1007/s00521-023-08657-z
   Ahmad W, 2021, J SUPERCOMPUT, V77, P11946, DOI 10.1007/s11227-021-03733-4
   Ajmal MS, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107419
   Calzarossa MC, 2021, IEEE ACCESS, V9, P89891, DOI 10.1109/ACCESS.2021.3091310
   Chakravarthi KK, 2022, CLUSTER COMPUT, V25, P1189, DOI 10.1007/s10586-021-03464-4
   Chakravarthi KK, 2021, J SYST ARCHITECT, V114, DOI 10.1016/j.sysarc.2020.101916
   Dehghani M, 2022, IEEE ACCESS, V10, P19599, DOI 10.1109/ACCESS.2022.3151641
   Dubey Vineet Kumar, 2023, Soft Computing: Theories and Applications: Proceedings of SoCTA 2022. Lecture Notes in Networks and Systems (627), P317, DOI 10.1007/978-981-19-9858-4_27
   Gao TL, 2022, IEEE ACCESS, V10, P76636, DOI 10.1109/ACCESS.2022.3192846
   Gupta S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6454
   Juve G, 2013, FUTURE GENER COMP SY, V29, P682, DOI 10.1016/j.future.2012.08.015
   Konjaang JK, 2022, J NETW COMPUT APPL, V203, DOI 10.1016/j.jnca.2022.103400
   Lei J, 2022, FUTURE GENER COMP SY, V131, P269, DOI 10.1016/j.future.2022.01.018
   Li H, 2023, Cluster Comput, P1
   Li HF, 2022, SOFT COMPUT, V26, P3809, DOI 10.1007/s00500-022-06782-w
   Li ZJ, 2018, IEEE T SERV COMPUT, V11, P713, DOI 10.1109/TSC.2015.2466545
   Mollajafari M, 2021, CLUSTER COMPUT, V24, P2639, DOI 10.1007/s10586-021-03285-5
   Mboula JEN, 2021, CLUSTER COMPUT, V24, P2697, DOI 10.1007/s10586-021-03289-1
   Pillareddy VR, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13021101
   Reside A, 2022, J MAMMAL, V103, P891, DOI 10.1093/jmammal/gyac042
   Rizvi N, 2021, SIMUL MODEL PRACT TH, V110, DOI 10.1016/j.simpat.2021.102328
   Saeedizade E, 2021, J SUPERCOMPUT, V77, P14525, DOI 10.1007/s11227-021-03858-6
   Singh Poonam, 2021, Communication and Intelligent Systems. Proceedings of ICCIS 2020. Lecture Notes in Networks and Systems (LNNS 204), P759, DOI 10.1007/978-981-16-1089-9_59
   Taghinezhad-Niar A, 2022, COMPUTING, V104, P601, DOI 10.1007/s00607-021-01030-9
   Taghinezhad-Niar A, 2021, CLUSTER COMPUT, V24, P3449, DOI 10.1007/s10586-021-03314-3
   Tao S., 2023, IEEE Transactions on Automation Science and Engineering
   Yao FG, 2021, IEEE ACCESS, V9, P37262, DOI 10.1109/ACCESS.2021.3063456
   Zhang LX, 2022, PEER PEER NETW APPL, V15, P973, DOI 10.1007/s12083-021-01267-3
   Zhu ZM, 2016, IEEE T PARALL DISTR, V27, P1344, DOI 10.1109/TPDS.2015.2446459
NR 29
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17088-w
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600009
DA 2024-07-18
ER

PT J
AU Tran, DT
   Ha, NTT
   Hai, LQ
   Tran, DN
   Shankar, A
AF Tran, Duc-Tan
   Ha, Nguyen Thi Thu
   Hai, Luong Quang
   Tran, Duc-Nghia
   Shankar, Achyut
TI Shear complex modulus imaging utilizing frequency combination in the
   least mean square/algebraic Helmholtz inversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Complex Shear Modulus Imaging; Viscosity; Complex shear modulus;
   Adaptive filter; Algebraic Helmholtz Inversion; Double-frequency
   excitation; Single-frequency excitation
ID WAVE ELASTOGRAPHY; VISCOELASTIC PROPERTIES; FINITE-DIFFERENCE;
   SIMULATION; STEP
AB Complex shear modulus imaging (CSMI) is a technique used to determine the elasticity and viscosity of soft tissues; it aids in investigating tissue structure and detecting tumors. CSMI methods can be categorized into quasi-static and dynamic approaches. The dynamic method utilizes force excitation and particle velocity measurements to estimate the Complex Shear Modulus (CSM). However, noise poses a challenge to shear wave estimation, affecting accuracy. Researchers are actively exploring adaptive filtering techniques and signal processing algorithms to address the noise issue and obtain reliable shear wave estimations. By integrating the Algebraic Helmholtz Inversion (AHI) method and the Least Mean Square (LMS) filter, imaging accuracy can be enhanced by mitigating the impact of noise. This study introduces a pioneering advancement in Complex Shear Modulus Imaging (CSMI). A new approach is proposed, using a dual-frequency excitation technique, strategically employing 100 Hz and 150 Hz frequencies. The proposed method is meticulously designed to enhance the overall efficiency of CSMI. Furthermore, a highly effective signal sampling and spectrum estimation procedure is introduced, aimed at elevating the accuracy of Algebraic Helmholtz Inversion (AHI) and significantly mitigating computational complexity in contrast to prior investigations.
C1 [Tran, Duc-Tan] Phenikaa Univ, Fac Elect & Elect Engn, Hanoi 12116, Vietnam.
   [Ha, Nguyen Thi Thu] Elect Power Univ, Hanoi, Vietnam.
   [Hai, Luong Quang] Le Quy Don Tech Univ, Fac Control Engn, 236 Hoang Quoc Viet Str, Hanoi 11313, Vietnam.
   [Tran, Duc-Nghia] Vietnam Acad Sci & Technol, Inst Informat Technol, Hanoi, Vietnam.
   [Shankar, Achyut] Univ Warwick, WMG, Coventry CV74AL, England.
   [Shankar, Achyut] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara 144411, Punjab, India.
C3 Electric Power University; Le Quy Don Technical University; Vietnam
   Academy of Science & Technology (VAST); University of Warwick; Lovely
   Professional University
RP Tran, DT (corresponding author), Phenikaa Univ, Fac Elect & Elect Engn, Hanoi 12116, Vietnam.
EM tan.tranduc@phenikaa-uni.edu.vn; ashankar2711@gmail.com
RI Tran, Duc-Tan/S-3941-2019; Tran Ha, Nguyen/ABF-8048-2021
OI Tran, Duc-Tan/0000-0002-7673-388X; Tran Ha, Nguyen/0000-0001-5193-1794
FU National Foundation for Science and Technology Development (NAFOSTED)
   [103.05-2020.13]
FX This work was supported by National Foundation for Science and
   Technology Development (NAFOSTED) under Grant 103.05-2020.13.
CR Aggarwal A, 2003, P SOC PHOTO-OPT INS, V5047, P314, DOI 10.1117/12.484108
   [Anonymous], 1989, Creep and relaxation of nonlinear viscoelastic materials, DOI DOI 10.1115/1.3424077
   Bercoff J, 2008, ULTRASON, P321, DOI 10.1109/ULTSYM.2008.0079
   Berg WA, 2004, RADIOLOGY, V233, P830, DOI 10.1148/radiol.2333031484
   Beuve S, 2021, ULTRASONICS, V110, DOI 10.1016/j.ultras.2020.106239
   Bhatt M, 2019, IEEE T ULTRASON FERR, V66, P1065, DOI 10.1109/TUFFC.2019.2908550
   Bismor D, 2012, ARCH ACOUST, V37, P31, DOI 10.2478/v10168-012-0005-8
   Brar DS, 2023, INT J FOOD PROP, V26, P1390, DOI 10.1080/10942912.2023.2218066
   Budelli E, 2017, PHYS MED BIOL, V62, P91, DOI 10.1088/1361-6560/62/1/91
   Deng XF, 2021, MATH BIOSCI ENG, V18, P3313, DOI 10.3934/mbe.2021165
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Fung YC, 1993, BIOMECHANICS MECH PR
   Gennisson J-L, 2013, Diagn Interv Imaging, V94, P487, DOI 10.1016/j.diii.2013.01.022
   Goel A, 2023, SPAT INF RES, V31, P275, DOI 10.1007/s41324-022-00494-x
   Goswami S, 2022, IEEE T ULTRASON FERR, V69, P975, DOI 10.1109/TUFFC.2021.3140203
   Greenleaf JF, 2003, ANNU REV BIOMED ENG, V5, P57, DOI 10.1146/annurev.bioeng.5.040202.121623
   Hao NT, 2013, INT C GREEN HUM INF, P88
   Harper Paul R, 2005, Health Policy, V71, P315, DOI 10.1016/j.healthpol.2004.05.002
   Hayes M. H., 2009, STAT DIGITAL SIGNAL
   Haykin S, 2003, Least-mean-square adaptive filters, P31
   Kijanka P, 2021, IEEE T ULTRASON FERR, V68, P389, DOI 10.1109/TUFFC.2020.2968147
   Kijanka P, 2020, IEEE T ULTRASON FERR, V67, P526, DOI 10.1109/TUFFC.2019.2948512
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Machado E, 2020, IEEE INT ULTRA SYM
   Marcon J, 2016, CLIN HEMORHEOL MICRO, V64, P447, DOI 10.3233/CH-168115
   McAleavey S, 2009, ULTRASONIC IMAGING, V31, P217, DOI 10.1177/016173460903100403
   Moore CJ, 2017, INT ULTRASONICS S, P1
   Orescanin Marko, 2010, 2010 International Ultrasonics Symposium, P61, DOI 10.1109/ULTSYM.2010.0016
   Orescanin M, 2011, IEEE T ULTRASON FERR, V58, P389, DOI 10.1109/TUFFC.2011.1816
   Orescanin M, 2010, IEEE T ULTRASON FERR, V57, P1358, DOI 10.1109/TUFFC.2010.1555
   Ormachea J, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2778
   Papadacci C, 2017, IEEE T MED IMAGING, V36, P357, DOI 10.1109/TMI.2016.2596706
   Papazoglou S, 2008, PHYS MED BIOL, V53, P3147, DOI 10.1088/0031-9155/53/12/005
   Park DW, 2016, J ELECTR ENG TECHNOL, V11, P1486, DOI 10.5370/JEET.2016.11.5.1486
   Qiang B, 2015, PHYS MED BIOL, V60, P1289, DOI 10.1088/0031-9155/60/3/1289
   Rawat A. S., 2018, IAES Int. J. Artif Intell., V7, P138, DOI [DOI 10.11591/IJAI.V7.I3.PP138-142, 10.1109/RICE.2018.8509069, DOI 10.1109/RICE.2018.8509069]
   Rouze NC, 2015, J ACOUST SOC AM, V138, P1012, DOI 10.1121/1.4927492
   Sandrin L, 2003, ULTRASOUND MED BIOL, V29, P1705, DOI 10.1016/j.ultrasmedbio.2003.07.001
   Sarvazyan AP, 1998, ULTRASOUND MED BIOL, V24, P1419, DOI 10.1016/S0301-5629(98)00110-0
   Schröder CT, 2000, IEEE T GEOSCI REMOTE, V38, P1505, DOI 10.1109/36.851950
   Skerl K, 2017, INT J COMPUT ASS RAD, V12, P1533, DOI 10.1007/s11548-017-1596-3
   Teixeira FL, 2008, IEEE T ANTENN PROPAG, V56, P2150, DOI 10.1109/TAP.2008.926767
   Tran QH, 2021, MATH BIOSCI ENG, V18, P7631, DOI 10.3934/mbe.2021378
   Urban MW, 2009, IEEE T ULTRASON FERR, V56, P748, DOI 10.1109/TUFFC.2009.1097
   Van Sloun RJ, 2017, 2017 IEEE INT ULTR S, P1
   Wang Q, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5021675
   Wang Y., 2018, Ultrasound Elastography for Biomedical Applications and Medicine, P118
   Wang Y, 2013, ULTRASONIC IMAGING, V35, P126, DOI 10.1177/0161734613477321
   Wang YQ, 2017, ULTRASONIC IMAGING, V39, P369, DOI 10.1177/0161734617712238
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yamakoshi Y, 2018, IEEE INT ULTRA SYM
   Yamamoto A, 2018, J MED ULTRASON, V45, P129, DOI 10.1007/s10396-017-0803-8
   Youk JH, 2017, ULTRASONOGRAPHY, V36, P300, DOI 10.14366/usg.17024
   Zhang CY, 2017, J MED IMAG HEALTH IN, V7, P211, DOI 10.1166/jmihi.2017.2008
   Zheng Y, 2007, IEEE T ULTRASON FERR, V54, P290, DOI 10.1109/TUFFC.2007.243
   Zhou P, 2020, MATH BIOSCI ENG, V17, P654, DOI 10.3934/mbe.2020034
   Zhu Y, 2014, MED ENG PHYS, V36, P1401, DOI 10.1016/j.medengphy.2014.04.002
NR 60
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17061-7
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600012
DA 2024-07-18
ER

PT J
AU Helaly, HA
   Badawy, M
   Haikal, AY
AF Helaly, Hadeer A.
   Badawy, Mahmoud
   Haikal, Amira Y.
TI A review of deep learning approaches in clinical and healthcare systems
   based on medical image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Deep learning; Healthcare systems; Medical image analysis; Diagnostics
   tools; Health data analytics
ID CONVOLUTIONAL NEURAL-NETWORKS; RECTIFIED LINEAR UNIT; CLASSIFICATION;
   MRI; SEGMENTATION
AB Healthcare is a high-priority sector where people expect the highest levels of care and service, regardless of cost. That makes it distinct from other sectors. Due to the promising results of deep learning in other practical applications, many deep learning algorithms have been proposed for use in healthcare and to solve traditional artificial intelligence issues. The main objective of this study is to review and analyze current deep learning algorithms in healthcare systems. In addition, it highlights the contributions and limitations of recent research papers. It combines deep learning methods with the interpretability of human healthcare by providing insights into deep learning applications in healthcare solutions. It first provides an overview of several deep learning models and their most recent developments. It then briefly examines how these models are applied in several medical practices. Finally, it summarizes current trends and issues in the design and training of deep neural networks besides the future direction in this field.
C1 [Helaly, Hadeer A.] Damietta Univ, Fac Engn, Elect Engn Dept, Dumyat, Egypt.
   [Helaly, Hadeer A.; Badawy, Mahmoud; Haikal, Amira Y.] Mansoura Univ, Fac Engn, Comp & Control Syst Engn Dept, Mansoura, Egypt.
   [Badawy, Mahmoud] Taibah Univ, Appl Coll, Dept Comp Sci & Informat, Al Madinah Al Munawwarah 41461, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Damietta University; Egyptian Knowledge
   Bank (EKB); Mansoura University; Taibah University
RP Helaly, HA (corresponding author), Damietta Univ, Fac Engn, Elect Engn Dept, Dumyat, Egypt.; Helaly, HA (corresponding author), Mansoura Univ, Fac Engn, Comp & Control Syst Engn Dept, Mansoura, Egypt.
EM hadeerhelaly@du.edu.eg; engbadawy@mans.edu.eg; amirayh@gmail.com
OI helaly, hadeer/0000-0003-1529-9298
CR Agarap AFM, 2015, 2ND INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2018), P5, DOI 10.1145/3184066.3184080
   Aggarwal P, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105350
   Al Duhayyim M, 2023, COMPUT SYST SCI ENG, V45, P753, DOI 10.32604/csse.2023.030556
   Aljuaid H, 2022, COMPUT METH PROG BIO, V223, DOI 10.1016/j.cmpb.2022.106951
   Allioui H, 2019, INT J ADV COMPUT SC, V10, P365
   Almajalid R, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1103, DOI 10.1109/ICMLA.2018.00179
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   [Anonymous], 2015, Predicting Alzheimer's disease: a neuroimaging study with 3D convolutional neural networks, DOI DOI 10.1613/JAIR.301
   Asiri AA, 2023, INTELL AUTOM SOFT CO, V36, P299, DOI 10.32604/iasc.2023.032426
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baker RE, 2022, NAT REV MICROBIOL, V20, P193, DOI 10.1038/s41579-021-00639-z
   Balcha AA, 2023, Literature Review, DOI [10.4236/aid.2023.131005, DOI 10.4236/AID.2023.131005]
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Carmo D, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06226
   Chakraborty S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042013
   Chen JY, 2021, AUTOMAT CONSTR, V123, DOI 10.1016/j.autcon.2020.103526
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chitradevi D, 2021, NEURAL COMPUT APPL, V33, P223, DOI 10.1007/s00521-020-04984-7
   Choi KS, 2005, BIOCHEM BIOPH RES CO, V330, P1299, DOI 10.1016/j.bbrc.2005.03.111
   Chung YW, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28082-5
   Coan LJ, 2023, SURV OPHTHALMOL, V68, P17, DOI 10.1016/j.survophthal.2022.08.005
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   Dev A, 2021, Artificial intelligence and speech Technology, DOI [10.1201/9781003150664, DOI 10.1201/9781003150664]
   Din NMU, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106073
   Dodia S, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105490
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Eltrass AS, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102326
   Ge CJ, 2019, IEEE IMAGE PROC, P789, DOI 10.1109/ICIP.2019.8803731
   Ghayvat H, 2023, NEURAL COMPUT APPL, V35, P14591, DOI 10.1007/s00521-022-07055-1
   Goebel R, 2022, Series Editors, DOI [10.5771/9783748924418-207, DOI 10.5771/9783748924418-207]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gouda W, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10020343
   Gumma L. N., 2022, SN Computer Science, V3, P1, DOI DOI 10.1007/S42979-021-00887-Z
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guo ZQ, 2021, INT J IMAG SYST TECH, V31, P1954, DOI 10.1002/ima.22608
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   Hatcher WG, 2018, IEEE ACCESS, V6, P24411, DOI 10.1109/ACCESS.2018.2830661
   Helaly HA, 2022, COGN COMPUT, V14, P1711, DOI 10.1007/s12559-021-09946-2
   Helaly HA, 2022, NEURAL COMPUT APPL, V34, P1047, DOI 10.1007/s00521-021-06430-8
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Impedovo D, 2019, COGN COMPUT, V11, P576, DOI 10.1007/s12559-019-09642-2
   Innat M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-32611-7
   Ismail Nur Syahmi, 2019, 2019 International UNIMAS STEM 12th Engineering Conference (EnCon). Proceedings, P89, DOI 10.1109/EnCon.2019.8861256
   Jain R., 2021, Computational intelligence in healthcare, P327, DOI [10.1007/978-3-030-68723-6_18, DOI 10.1007/978-3-030-68723-6_18]
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Jalali Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010268
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Junaid Umer M., 2023, Comput. Syst. Sci. Eng, V45, P1001, DOI [10.32604/csse.2023.030463, DOI 10.32604/CSSE.2023.030463]
   Kabir S, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118942
   Kahramanli H, 2012, Int J Futur Comput Commun, V1, P199, DOI DOI 10.7763/IJFCC.2012.V1.52
   Khagi B, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P121, DOI 10.23919/elinfocom.2019.8706339
   Khan HA, 2020, MATH BIOSCI ENG, V17, P6203, DOI 10.3934/mbe.2020328
   Khvostikov A., 2018, 3D INCEPTION BASED C, V3, P102, DOI [10.13140/RG.2.2.30737.28006, DOI 10.13140/RG.2.2.30737.28006]
   Klingenberg M, 2023, ALZHEIMERS RES THER, V15, DOI 10.1186/s13195-023-01225-6
   Koh J, 2022, CLIN BREAST CANCER, V22, P26, DOI 10.1016/j.clbc.2021.04.015
   Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lai ZF, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/2061516
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei L, 2019, IEEE INT WORK SIGN P, DOI 10.1109/spawc.2019.8815447
   Lei M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11030534
   Lin CL, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05293-1
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu L, 2020, SIMUL MODEL PRACT TH, V99, DOI 10.1016/j.simpat.2019.102023
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Mahmud M, 2021, COGN COMPUT, V13, P1, DOI 10.1007/s12559-020-09773-x
   Mohammed Kamel K., 2021, Journal of Medical Engineering & Technology, V45, DOI 10.1080/03091902.2021.1905895
   Nobakht S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072427
   Ogrean V, 2021, INT J ADV COMPUT SC, V12, P28
   Ourselin S, 2016, MED IMAGE COMPUTING, DOI [10.1007/10704282, DOI 10.1007/10704282]
   Pan D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00259
   Parmar H, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.5.056001
   Pawar U, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBER SITUATIONAL AWARENESS, DATA ANALYTICS AND ASSESSMENT (CYBER SA 2020), DOI 10.1109/cybersa49311.2020.9139655
   Raaj RS, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104558
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahumbaiev I, 2018, 2018 IEEE NUCLEAR SCIENCE SYMPOSIUM AND MEDICAL IMAGING CONFERENCE PROCEEDINGS (NSS/MIC), DOI 10.1109/NSSMIC.2018.8824317
   Sarraf S., 2016, Classification of Alzheimer's Disease Structural MRI Data by Deep Learning Convolutional Neural Networks, P8, DOI DOI 10.1097/IAE.0000000000001460
   Segato A, 2020, APL BIOENG, V4, DOI 10.1063/5.0011697
   Shamshirband S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103627
   Shao Jun, 2022, Front Biosci (Landmark Ed), V27, P212, DOI 10.31083/j.fbl2707212
   She YL, 2022, EBIOMEDICINE, V86, DOI 10.1016/j.ebiom.2022.104364
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shirokikh B, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020035
   Siegel RL, 2022, CA-CANCER J CLIN, V72, P7, DOI 10.3322/caac.21708
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AV, 2015, Content-Based Image Retrieval using Deep Learning, DOI [10.13140/RG.2.2.29510.16967, DOI 10.13140/RG.2.2.29510.16967]
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Spasov SE, 2018, IEEE ENG MED BIO, P1271, DOI 10.1109/EMBC.2018.8512468
   Squires M, 2023, BRAIN INFORM, V10, DOI 10.1186/s40708-023-00188-6
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Subramanian N, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105233
   Sun JW, 2020, INT J COMPUT ASS RAD, V15, P445, DOI 10.1007/s11548-019-02106-w
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   Tariq M, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114095
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Vassanelli S, 2020, Series, DOI [10.1007/978-3-030-59277-6, DOI 10.1007/978-3-030-59277-6]
   Walvekar S, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P203, DOI 10.1109/ESCI50559.2021.9397043
   Wang J, 2021, MOBILE NETW APPL, V26, P351, DOI 10.1007/s11036-020-01672-7
   Wang SH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0932-7
   Wang Y, 2018, IEEE ENG MED BIO, P754, DOI 10.1109/EMBC.2018.8512372
   Xiao XL, 2020, Arxiv, DOI [arXiv:2006.12703, DOI 10.48550/ARXIV.2006.12703, 10.48550/arXiv.2006.12703]
   Yamanakkanavar N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113243
   Alom MZ, 2018, Arxiv, DOI arXiv:1803.01164
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
   Zheng SY, 2023, RADIOTHER ONCOL, V180, DOI 10.1016/j.radonc.2023.109483
   Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004
   Zhuang JT, 2019, IEEE INT CONF COMP V, P847, DOI 10.1109/ICCVW.2019.00113
NR 115
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16605-1
EA SEP 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600009
DA 2024-07-18
ER

PT J
AU Jiang, H
   Asad, M
   Liu, JJ
   Zhang, HX
   Cheng, DQ
AF Jiang, He
   Asad, Mujtaba
   Liu, Jingjing
   Zhang, Haoxiang
   Cheng, Deqiang
TI Single image detail enhancement via metropolis theorem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Detail enhancement; Metropolis theorem; Thermodynamics-based; Residual
   Learning; Global optimization
ID FILTER
AB Traditional image detail enhancement is local filter-based or global filter-based. In both approaches, the original image is first divided into the base layer and the detail layer, and then the enhanced image is obtained by amplifying the detail layer. Our method is different, and its innovation lies in the special way to get the image detail layer. The detail layer in our method is obtained by updating the residual features, and the updating mechanism is usually based on searching and matching similar patches. However, due to the diversity of image texture features, perfect matching is often not possible. In this paper, the process of searching and matching is treated as a thermodynamic process, where the Metropolis theorem can minimize the internal energy and get the global optimal solution of this task, that is, to find a more suitable feature for a better detail enhancement performance. Extensive experiments have proven that our algorithm can achieve better results in quantitative metrics testing and visual effects evaluation. The source code can be obtained from the website https://github.com/hehesjtu/Metropolis-Theorem.
C1 [Jiang, He; Liu, Jingjing; Zhang, Haoxiang; Cheng, Deqiang] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou, Peoples R China.
   [Asad, Mujtaba] Univ Cent Punjab, Dept Comp Sci, Lahore, Pakistan.
C3 China University of Mining & Technology; University of Central Punjab
RP Jiang, H; Cheng, DQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou, Peoples R China.
EM jianghe@cumt.edu.cn; chengdq@cumt.edu.cn
OI Jiang, He/0000-0002-3345-9665
FU National Natural Science Foundation of China [52204177, 52304182];
   Fundamental Research Funds for the Central Universities [2020QN49]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant (No.52204177, No.52304182) and supported
   in part by the Fundamental Research Funds for the Central Universities
   (2020QN49).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Cheng J, 2018, IEEE T MED IMAGING, V37, P2536, DOI 10.1109/TMI.2018.2838550
   Deng YB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P870, DOI 10.1145/3240508.3240531
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Fan QN, 2021, IEEE T PATTERN ANAL, V43, P33, DOI 10.1109/TPAMI.2019.2925793
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Ghosh S, 2019, NATL CONF COMMUN, DOI 10.1109/ncc.2019.8732250
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Jian L, 2018, J Ambient Intell Humaniz Comput, V1, P1
   Jiang H, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.4.043016
   Jiang H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1428, DOI 10.1109/ICASSP.2018.8462182
   Kim D, 2014, IEEE T CONSUM ELECTR, V60, P18, DOI 10.1109/TCE.2014.6780920
   Kim Y, 2017, IEEE T IMAGE PROCESS, V26, P4079, DOI 10.1109/TIP.2017.2710621
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Kou F, 2015, IEEE SIGNAL PROC LET, V22, P211, DOI 10.1109/LSP.2014.2353774
   Li YJ, 2019, IEEE T PATTERN ANAL, V41, P1909, DOI 10.1109/TPAMI.2018.2890623
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu W, 2022, IEEE T PATTERN ANAL, V44, P6631, DOI 10.1109/TPAMI.2021.3097891
   Liu W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3388887
   Liu W, 2020, IEEE T CIRC SYST VID, V30, P23, DOI 10.1109/TCSVT.2018.2890202
   Lu ZW, 2018, IEEE SIGNAL PROC LET, V25, P1585, DOI 10.1109/LSP.2018.2867896
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Tao X, 2017, IEEE I CONF COMP VIS, P222, DOI 10.1109/ICCV.2017.33
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Wang J, 2022, COMPUT GRAPH FORUM, V41, P335, DOI 10.1111/cgf.14681
   Wang Y, 2017, J Electron Imaging, V26
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HK, 2018, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2018.00197
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang QX, 2015, IEEE T IMAGE PROCESS, V24, P1919, DOI 10.1109/TIP.2015.2403238
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang Y, 2022, 2022 INT C LEARN REP, P1
   Zhang Y., 2021, 2021 NEURAL INFORM P, P1
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu FD, 2019, IEEE T IMAGE PROCESS, V28, P3556, DOI 10.1109/TIP.2019.2908778
NR 45
TC 3
Z9 3
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16914-5
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600020
DA 2024-07-18
ER

PT J
AU Zhang, T
   Yang, YH
   Zou, YB
   Zhao, J
   Wu, SH
AF Zhang, Tie
   Yang, Yuanhang
   Zou, Yanbiao
   Zhao, Jun
   Wu, Shenghong
TI Deep residual attention network for human defecation prediction using
   bowel sounds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Wavelet Packet Transform; Bowel Sounds; Defecation
   Prediction
ID INCONTINENCE-ASSOCIATED DERMATITIS; ABSORBENT PRODUCTS; PREVENTION;
   CARE; DECOMPOSITION; MANAGEMENT; ADULTS; TERM
AB Background and objectiveFecal incontinence may lead to incontinence-associated dermatitis (IAD), affecting the physical health of the patient. Since human defecation is related to intestinal activity, and bowel sounds can reflect bowel motility, a prediction method for human defecation based on deep residual attention network (DRAN) using bowel sounds was proposed to prevent IAD.MethodsWe collected 1140 bowel sounds of 20 seconds from 15 volunteers. These bowel sounds were transformed into time-frequency maps by wavelet packet transform (WPT). Then the time-frequency maps are taken as input to the DRAN. DRAN classified bowel sounds to predict whether the patient would defecate.ResultsAfter training, the defecation prediction accuracy, precision and recall of DRAN could reach 91.18%, 91.67% and 90.59% respectively,ConclusionThe result indicates that the proposed method could provide a high-precision defecation prediction result for patients with fecal incontinence, so as to prepare for defecation in advance and prevent the occurrence of IAD.
C1 [Zhang, Tie; Yang, Yuanhang; Zou, Yanbiao; Wu, Shenghong] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510641, Peoples R China.
   [Zhao, Jun] China Rehabil Res Ctr, Beijing, Peoples R China.
C3 South China University of Technology
RP Zhang, T (corresponding author), South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510641, Peoples R China.
EM merobot@scut.edu.cn; 928031769@qq.com; ybzou@scut.edu.cn;
   zaojun@aliyun.com; 202021003154@mail.scut.edu.cn
RI zhao, jun/KIJ-0611-2024
OI Zou, Yanbiao/0000-0001-7581-6774
FU National Major Science and Technology Project of China [2020YFC2007600]
FX This work was supported by the National Major Science and Technology
   Project of China [grant numbers 2020YFC2007600].
CR Alickovic E, 2018, BIOMED SIGNAL PROCES, V39, P94, DOI 10.1016/j.bspc.2017.07.022
   Bampton PA, 2000, AM J GASTROENTEROL, V95, P1027, DOI 10.1111/j.1572-0241.2000.01839.x
   Banharak S, 2021, J MULTIDISCIP HEALTH, V14, P2983, DOI 10.2147/JMDH.S329672
   Brown HW, 2020, OBSTET GYNECOL, V136, P811, DOI 10.1097/AOG.0000000000004054
   Ching SS, 2012, WORLD J GASTROENTERO, V18, P4585, DOI 10.3748/wjg.v18.i33.4585
   Coyer F, 2018, NURS CRIT CARE, V23, P198, DOI 10.1111/nicc.12331
   CROWELL MD, 1991, AM J PHYSIOL, V261, pG263, DOI 10.1152/ajpgi.1991.261.2.G263
   Denat Y, 2011, J WOUND OSTOMY CONT, V38, P171, DOI 10.1097/WON.0b013e31820af24e
   Dimoulas C, 2008, EXPERT SYST APPL, V34, P26, DOI 10.1016/j.eswa.2006.08.014
   Du XH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124240
   Eren L, 2004, IEEE T INSTRUM MEAS, V53, P431, DOI 10.1109/TIM.2004.823323
   Gray M, 2018, J WOUND OSTOMY CONT, V45, P243, DOI 10.1097/WON.0000000000000431
   Hassan SA, 2020, MULTIMED TOOLS APPL, V79, P30735, DOI 10.1007/s11042-020-09518-w
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Juzheng L, 2018, IEEE BIOM CIRC SYST, P1
   Kim KS, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-69
   Lim YSL, 2019, J WOUND OSTOMY CONT, V46, P30, DOI 10.1097/WON.0000000000000490
   Lin BS, 2013, IEEE J BIOMED HEALTH, V17, P675, DOI 10.1109/JBHI.2013.2244097
   Mugita Y, 2021, J TISSUE VIABILITY, V30, P599, DOI 10.1016/j.jtv.2021.07.002
   Nowak JK, 2021, Sensors, V21
   Palit S, 2012, DIGEST DIS SCI, V57, P1445, DOI 10.1007/s10620-012-2071-1
   Ngoc PP, 2015, IFMBE PROC, V46, P179, DOI 10.1007/978-3-319-11776-8_44
   Sung VW, 2014, OBSTET GYNECOL, V123, P1023, DOI 10.1097/AOG.0000000000000236
   Tan JH, 2018, COMPUT BIOL MED, V94, P19, DOI 10.1016/j.compbiomed.2017.12.023
   Tikkanen PE, 1997, P ANN INT IEEE EMBS, V19, P313, DOI 10.1109/IEMBS.1997.754537
   Tu W, 2009, INT C INTEL HUM MACH, P188, DOI 10.1109/IHMSC.2009.55
   Ulusar UD, 2014, COMPUT BIOL MED, V51, P223, DOI 10.1016/j.compbiomed.2014.05.013
   Yang BH, 2016, COMPUT METH PROG BIO, V129, P21, DOI 10.1016/j.cmpb.2016.02.020
   Yildirim O, 2020, NEURAL COMPUT APPL, V32, P15857, DOI 10.1007/s00521-018-3889-z
   Zhang Y, 2021, AUST CRIT CARE, V34, P103, DOI 10.1016/j.aucc.2020.04.152
NR 31
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17091-1
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600019
DA 2024-07-18
ER

PT J
AU Hassan, AMA
   Mohsen, S
   Abo-Zahhad, MM
AF Hassan, Ashraf Mohamed Ali
   Mohsen, Saeed
   Abo-Zahhad, Mohammed M.
TI ECG signals compression using dynamic compressive sensing technique
   toward IoT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of things (IoT); Compressive sensing; Sparse; Curvelet
   transform; Compression ratio (CR)
ID ELECTROCARDIOGRAM; RECOVERY
AB This paper provides a novel compressive sensing (CS) technique to compress electrocardiogram (ECG) signals. The proposed technique extends a dynamic compressed sensing method, originally based on a single lead signal, to multiple lead signals. The sensing matrix used by the dynamic sensing technique receives its components dynamically from the compressed signal. In this way, a single sensing matrix is recommended to be used for an application of many leads, for which its components are obtained from the fusion of many leads. The CS technique is tested using a variety of signals that are collected from both healthy people and those with various diseases, including bundle branch block, cardiomyopathy, and myocardial infarction. The experiment's results show that the suggested CS technique can be applied to achieve a compression ratio (CR) of 16 without affecting the metrics of the signal.
C1 [Hassan, Ashraf Mohamed Ali] October High Inst Engn & Technol, Elect & Commun Engn Dept, 6th October City 12596, Egypt.
   [Mohsen, Saeed] Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.
   [Mohsen, Saeed] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, S Sinai, Egypt.
   [Abo-Zahhad, Mohammed M.] Sohag Univ, Fac Engn, Dept Elect Engn, Sohag, Sohag, Egypt.
C3 King Salman International University; Egyptian Knowledge Bank (EKB);
   Sohag University
RP Mohsen, S (corresponding author), Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.; Mohsen, S (corresponding author), King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, S Sinai, Egypt.
EM g17082131@eng.asu.edu.eg
RI Mohsen, Saeed/GQH-2016-2022
OI Mohsen, Saeed/0000-0003-2863-0074
CR Abdulbaqi AS, 2018, 2018 1ST ANNUAL INTERNATIONAL CONFERENCE ON INFORMATION AND SCIENCES (AICIS 2018), P229, DOI 10.1109/AiCIS.2018.00049
   Adochiei NI, 2011, ENVIRON ENG MANAG J, V10, P553, DOI 10.30638/eemj.2011.077
   Balestrieri E, 2019, P 2019 IEEE INT S ME, P26
   Bera P, 2016, MEASUREMENT, V91, P651, DOI 10.1016/j.measurement.2016.05.085
   Burke M. J., 2001, P 5 WSES INT C CIRC, P8
   Chandra' S, 2021, IRBM, V42, P227, DOI 10.1016/j.irbm.2020.05.004
   Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172
   Craven D, 2015, IEEE J BIOMED HEALTH, V19, P529, DOI 10.1109/JBHI.2014.2327194
   Daponte P, 2021, IEEE INT SYM MED MEA, DOI 10.1109/MeMeA52024.2021.9478766
   Djelouat H, 2018, IEEE SENS J, V18, P9629, DOI 10.1109/JSEN.2018.2871411
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Hammad M, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033072
   Iadarola G, 2021, IEEE IMTC P, DOI 10.1109/I2MTC50364.2021.9459905
   Iadarola G, 2020, IEEE INT SYM MED MEA
   Laudato G., 2021, Frontiers in Human Dynamics, V3, P1
   Laudato G, 2021, HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF, P386, DOI 10.5220/0010236003860393
   Lux RL, 2000, J ELECTROCARDIOL, V33, P203, DOI 10.1054/jelc.2000.20347
   Maalej A, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108031
   Mamaghanian H, 2014, P 2014 IEEE INT C AC, P4
   Mamaghanian H, 2011, IEEE T BIO-MED ENG, V58, P2456, DOI 10.1109/TBME.2011.2156795
   Meek S, 2002, BRIT MED J, V324, P415, DOI 10.1136/bmj.324.7334.415
   Mitra D, 2020, IEEE T INSTRUM MEAS, V69, P3642, DOI 10.1109/TIM.2019.2936776
   Nemcova A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72656-6
   Pandey A, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107252
   Picariello F, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108259
   PTB Diagnostic ECG Database, PhysioBank Clinical Database
   Ravelomanantsoa A, 2014, IEEE T INSTRUM MEAS, V63, P2973, DOI 10.1109/TIM.2014.2320393
   Saliga J, 2021, MEASUREMENT, V183, DOI 10.1016/j.measurement.2021.109803
   Singh A, 2016, BIOMED SIGNAL PROCES, V29, P53, DOI 10.1016/j.bspc.2016.05.008
   Starobin OE, 2002, J Intensive Care Med, V17
   Surekha KS, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P468, DOI 10.1109/SAI.2014.6918229
   Tigges T., 2015, Current Direction in Biomedical Engineering, V1, P65, DOI [10.1515/cdbme-2015-0017, DOI 10.1515/CDBME-2015-0017]
   Wang J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3432, DOI 10.1109/BigData.2016.7841004
   Wang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030864
   Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265
   Zhang J, 2018, IEEE T INSTRUM MEAS, V67, P2024, DOI 10.1109/TIM.2018.2811438
   Zhang QX, 2019, 2019 IEEE HEALTHCARE INNOVATIONS AND POINT OF CARE TECHNOLOGIES (HI-POCT), P103, DOI [10.1109/HI-POCT45284.2019.8962742, 10.1109/hi-poct45284.2019.8962742]
   Zhang ZL, 2011, INT CONF ACOUST SPEE, P3932
NR 38
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-17099-7
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700010
DA 2024-07-18
ER

PT J
AU Wang, KJ
   Hsu, CN
   Sanjaya, L
AF Wang, Kung-Jeng
   Hsu, Ching-Ning
   Sanjaya, Lucy
TI Empowering facial emotion recognition in service industry - a two-stage
   convolutional neural network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Deep learning; Emotional intelligence;
   Facial emotion recognition; Service industry
ID EXPRESSION RECOGNITION; FACE
AB Deep-learning based facial emotion recognition (FER) has potential in the service industry. To solve conventional emotion recognition problems, this study proposes a deep learning-based model to achieve a highly-efficient FER system. The proposed FER model consists of two stages. The first stage uses the multitask convolution neural network to distinguish precise face-bounding box positions, whereas the second adopts a deep-learning network to achieve real-time recognition of emotions and features. By training our model using three global FER datasets, its accuracy indicates that the proposed model outperforms existing FER models. The study illustrated the model from three aspects. First, a massive facial database is investigated for model feasibility with a variety of service scenarios. Secondly, we demonstrated practical examples in the restaurant and retailing service industries. Third, the model performs advice by monitoring the emotion when the player is assembling Lego. The model can analyze human emotions in the service industry to identify customer satisfaction with products and/or services, fatigue in working domains, and/or safety in jobs. The model will help improve customer relationships, provide pleasant transaction solutions, and even help to broaden product offerings and promotions. Such facial recognition technology can further motivate new digital business models and change customer-server dynamics.
C1 [Wang, Kung-Jeng; Hsu, Ching-Ning; Sanjaya, Lucy] Natl Taiwan Univ Sci & Technol, Dept Ind Management, Taipei 108, Taiwan.
   [Wang, Kung-Jeng] Natl Taiwan Univ Sci & Technol, Artificial Intelligence Operat Management Res Ctr, Taipei 108, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Wang, KJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Ind Management, Taipei 108, Taiwan.; Wang, KJ (corresponding author), Natl Taiwan Univ Sci & Technol, Artificial Intelligence Operat Management Res Ctr, Taipei 108, Taiwan.
EM kjwang@mail.ntust.edu.tw; fq84774@gmail.com; lucysanjaya.ls@gmail.com
CR American Heart Association, 2017, US
   Bagozzi Richard P., 2020, [Korean Journal of Marketing, 마케팅연구], V35, P1
   Bi Y, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107152
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Casalboni A, 2017, GOOGLE VISION VS AMA
   Chang YC, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107861
   Chao Su, 2020, Journal of Physics: Conference Series, V1651, DOI 10.1088/1742-6596/1651/1/012158
   Chuah SHW, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2021.102551
   Dallimore KS, 2007, J SERV RES-US, V10, P78, DOI 10.1177/1094670507304694
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Dosovitskiy A, 2022, ARXIV
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 2003, UNMASKING FACE GUIDE
   Evergreen, 2021, FAC REC SERV REV
   Ghofrani A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P817, DOI [10.1109/kbei.2019.8734924, 10.1109/KBEI.2019.8734924]
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Henkel AP, 2020, J SERV MANAG, V31
   Hollebeek LD, 2021, J SERV RES-US, V24, P3, DOI 10.1177/1094670520975110
   Huang MH, 2021, J SERV RES-US, V24, P30, DOI 10.1177/1094670520902266
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Indira DNVSLS, 2021, IOP C SERIES MAT SCI, V1074
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kossaifi J, 2017, AFEW VA DATABASE VAL
   Kotler P, 2021, J MACROMARKETING, V41, P194, DOI 10.1177/0276146721996433
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Lei JM, 2017, IEEE ACCESS, V5, P5723, DOI 10.1109/ACCESS.2017.2686424
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li XC, 2020, IEEE ACCESS, V8, P174922, DOI 10.1109/ACCESS.2020.3023782
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mehrabian A., 2017, Nonverbal Communication
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   NVIDIA, 2021, NVIDIA TRANSF LEARN
   Pang L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061678
   Perusquia-Hernandez M., 2021, EMOT STUD, V6, P57
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Prentic C, 2020, J RETAIL CONSUM SERV, V56, DOI 10.1016/j.jretconser.2020.102186
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Robinson S, 2020, J BUS RES, V116, P366, DOI 10.1016/j.jbusres.2019.08.038
   González-Rodríguez MR, 2020, TELEMAT INFORM, V51, DOI 10.1016/j.tele.2020.101404
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Singh G, 2021, TQM J
   Small DA, 2009, J MARKETING RES, V46, P777, DOI 10.1509/jmkr.46.6.777
   Söderlund M, 2008, INT J SERV IND MANAG, V19, P552, DOI 10.1108/09564230810903460
   Vielzeuf V, 2017, ARXIV
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang KJ, 2022, ADV ENG INFORM, V52, DOI 10.1016/j.aei.2022.101643
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Yang K, 2021, SERV IND J, V41, P84, DOI 10.1080/02642069.2020.1863373
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 52
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33161
EP 33184
DI 10.1007/s11042-023-16717-8
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001071641500003
DA 2024-07-18
ER

PT J
AU Charoghchi, S
   Mashhadi, S
AF Charoghchi, Sara
   Mashhadi, Samaneh
TI A secure secret image sharing with steganography and authentication by
   Hamming code (15,11) for compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Homogeneous linear recursion; Secret image sharing; Block truncation
   coding; Steganography; Authentication
ID BINOCULAR-RIVALRY; NOTICEABLE-DIFFERENCE; VISUAL-CORTEX; ORIENTATION;
   SUPPRESSION; MODEL; DISCRIMINATION; MASKING; PROFILE; DEPTH
AB The impressive increase in the rate of image transmission via internet has, more than ever, highlighted the importance of image securing techniques. One of the efficient solutions to secure images is Secret Image Sharing (SIS) with stegranography and authentication where an image is distributed among the shareholders without raising adversaries' suspicion. Additionally, the cheats of the dealer and share holders in the reconstruction of the image are discoverable. This means that the integration of the shares is verifiable. Although almost all the images on internet are compressed, the majority of proposed SIS schemes with steganography are not applicable to compressed images which is the area that our work attemps to improve. In this paper a novel SIS scheme based on homogeneous linear recursion (HLR) with steganography and authentication for Absolute Moment Block Truncation Coding (AMBTC) compressed images is proposed. For steganography Hamming code (15,11) is applied which enables embedding with little changes so that the stego and cover images are visually and statistically very similar. An additional merit is that the reconstructed image is of an acceptable quality. What is more, authentication algorithm makes it possible for the scheme to detect any form of cheating and secures it against passive steganographic attacks.
C1 [Charoghchi, Sara; Mashhadi, Samaneh] Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran, Narmak, Iran.
C3 Iran University Science & Technology
RP Mashhadi, S (corresponding author), Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran, Narmak, Iran.
EM s_charoghchi@mathdep.iust.ac.ir; smashhadi@iust.ac.ir
RI mashhadi, samaneh/ISV-0962-2023
OI mashhadi, samaneh/0000-0001-9191-1376
FU Iran National Science Foundation
FX No Statement Available
CR Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133802
   Charoghchi S, 2021, INFORM SCIENCES, V552, P220, DOI 10.1016/j.ins.2020.11.034
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Dehkordi MH, 2008, INFORM SCIENCES, V178, P2262, DOI 10.1016/j.ins.2007.11.031
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Guo YZ, 2019, IEEE ACCESS, V7, P73782, DOI 10.1109/ACCESS.2019.2919294
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Kaur S, 2022, INT J INTERACT MULTI, V7, P48, DOI 10.9781/ijimai.2022.01.004
   Kumar A, 2023, INT J INTERACT MULTI, V8, P150, DOI 10.9781/ijimai.2021.11.004
   Kumari RR, 2021, INT J INTERACT MULTI, V7, P150, DOI 10.9781/ijimai.2021.10.006
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1, DOI 10.1007/s11042-015-3011-9
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101236
   Liu Y-X., 2018, Commun Image R, DOI [10.1016/j.jvcir.2018.08.003, DOI 10.1016/J.JVCIR.2018.08.003]
   Maan VK, 2013, Int. J. Eng. Res. Technol. (IJERT), V02
   Mashhadi S, 2023, MULTIMED TOOLS APPL, V82, P39077, DOI 10.1007/s11042-023-15016-6
   Mashhadi S, 2016, WIRELESS PERS COMMUN, V90, P93, DOI 10.1007/s11277-016-3332-7
   Sardar M.K., 2020, J. Vis. Commun. Image Represent, V68, DOI [10.1016/j.jvcir.2020.102768, DOI 10.1016/J.JVCIR.2020.102768]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Teng Guo, 2013, Information and Communications Security. 15th International Conference, ICICS 2013. Proceedings: LNCS 8233, P404, DOI 10.1007/978-3-319-02726-5_29
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Xiong LZ, 2021, IEEE T INF FOREN SEC, V16, P2912, DOI 10.1109/TIFS.2021.3065794
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yan XH, 2017, COMM COM INF SC, V727, P305, DOI 10.1007/978-981-10-6385-5_26
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
   Zhou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070249
NR 30
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31933
EP 31955
DI 10.1007/s11042-023-16688-w
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900011
DA 2024-07-18
ER

PT J
AU Chen, X
   Wang, L
   Ding, F
AF Chen, Xiang
   Wang, Ling
   Ding, Feng
TI Computed tomography simulation projection acquisition method of artistic
   relics based on voxel model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voxel model; Artistic relics; CT image; Projection; Geometric primitive
AB By acquiring the CT (Computed Tomography) simulation projection images of artistic relics, the visual expression ability of artistic relics is improved, and a method of acquiring CT simulation projection of artistic relics based on voxel model is proposed. The geometric primitive is established by using the geometric information of artistic objects, and the three-dimensional surface of the objects is reconstructed by the voxel model reconstruction method with intersecting surfaces. The surface rendering of artistic relics is divided into voxel level and slice level. The surface of the object composed of small patches is redrawn by using graphics. The slice level reconstruction method is used to reduce redundant patches in the CT simulation projection process of artistic relics, and the number of points and patches is reduced. By adjusting the transparency of the object, the result can not only show the outer surface of the object, but also the contour edge correspondence and contour stitching algorithm are used to improve the reconstruction accuracy and speed. According to the three-dimensional feature expression of voxel model, the fusion and reorganization of intermediate geometric primitives are realized. The simulation results show that the effect of CT simulation projection reconstruction and three-dimensional visual expression of artistic relics using this method is good, and the accuracy and speed of CT reconstruction of artistic relics are high.
C1 [Chen, Xiang; Wang, Ling; Ding, Feng] Jiangsu Shipping Coll, Nantong 226010, Jiangsu, Peoples R China.
C3 Jiangsu Shipping College
RP Chen, X (corresponding author), Jiangsu Shipping Coll, Nantong 226010, Jiangsu, Peoples R China.
EM xingqi7961976573@163.com
FU Nantong Science and Technology Bureau 2022 Nantong Basic Science
   Research and Social Livelihood Science and Technology Plan Project
   [JCZ2022045]
FX The study was supported by "Nantong Science and Technology Bureau 2022
   Nantong Basic Science Research and Social Livelihood Science and
   Technology Plan Project (Grant No. JCZ2022045)".
CR Casa R., 2020, J. Geodesy Geoinform. Sci., V3, P79
   Chaudhuri J, 2022, CHEM ENG SCI, V248, DOI 10.1016/j.ces.2021.117096
   [郭澳庆 Guo Aoqing], 2022, [测绘学报, Acta Geodetica et Cartographica Sinica], V51, P2171
   Hou HY, 2022, NEUROCOMPUTING, V492, P343, DOI 10.1016/j.neucom.2022.04.040
   Hu P, 2021, ELECTRON LETT, V57, P357, DOI 10.1049/ell2.12133
   Karamov R, 2021, COMP MATER SCI, V197, DOI 10.1016/j.commatsci.2021.110551
   Li F, 2022, BRIT J OPHTHALMOL, V57, P2669
   [梁月吉 Liang Yueji], 2020, [测绘学报, Acta Geodetica et Cartographica Sinica], V49, P833
   Liu Guang, 2021, [Journal of Geodesy and Geoinformation Science, 测绘学报], V4, P77
   Peichen Z., 2022, CULT RELICS PROT ARC, V34, P60
   Song Heqian, 2021, SCRIPTA MATER, V191, P4
   [魏立飞 Wei Lifei], 2020, [测绘学报, Acta Geodetica et Cartographica Sinica], V49, P343
   Wei S., 2022, CULT RELICS PROT ARC, V34, P51
   [张红 Zhang Hong], 2021, [测绘学报, Acta Geodetica et Cartographica Sinica], V50, P405
   Zhenhong LI., 2022, J GEODESY GEOINF SCI, V5, P1
NR 15
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32001
EP 32017
DI 10.1007/s11042-023-16832-6
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067933300002
DA 2024-07-18
ER

PT J
AU Murugesh, V
   Janarthanan, P
   Kavitha, A
   Sivakumar, N
   Jaganathan, SCB
   Suriyan, K
AF Murugesh, V.
   Janarthanan, P.
   Kavitha, A.
   Sivakumar, N.
   Jaganathan, Subash Chandra Bose
   Suriyan, Kannadasan
TI Provisioning a risk predictor model for Alzheimers disease using an
   improved deep network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Earlier diagnosis; Alzheimer's disease; Feature representation; Neural
   network; Conversion prediction
AB Alzheimer's disease is a cognitive disorder that threatens human lives. Computer-based diagnosis are recommended for Ad progression prediction. Capsule Networks receive investigators' attention which owes to the capability for the efficient features of the fuse multi-dimensionality and the model's coefficients among the samples. Various deep network models are adopted for node classification and utilization of a complete dataset for constructing the dense network, which is not used for independent testing. In addition, network maintenance and construction benefit matrix decomposition to overcome the demerits. An improved CapsNetwork (i-CN\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$i-CN$$\end{document}) model was proposed for AD diagnosis. The sample data provided among the routing neurons works from the lower level to higher level, i.e. it enhances the prediction accuracy. The model intends to recognize the complete entity by analysing the features of input samples. Capsules are vectors that represent the sample features. The improved network model tries to reduce the computational complexity identified in various existing learning approaches. The under-fitting issues due to smaller dataset are also rectified with the proposed model. Primarily, the learning model is realized by introducing the metric-based feature representation to test independently via the different classification tasks. Appropriate samples are needed to generalize the model without sensitivity and to enhance the performance. Further, designing the i-CN\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$i-CN$$\end{document} layer poses the probability of realizing the efficient fuse of multi-dimensional data. The model needs to be verified using TADPOLE where mild cognitive impairment (MCI) prediction and the earlier AD diagnosis are achieved. The proposed system gives better performance having an accuracy of 95% and AUC of 98.7%. The outcomes proved that the proposed system enhances flexibility to ensure better performance in the classification. It helps to promote the enhancement of disease diagnosis for deep learning algorithms.
C1 [Murugesh, V.] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
   [Janarthanan, P.] Sri Venkateswara Coll Engn, Dept Comp Sci & Engn, Sriperumbudur, TN, India.
   [Kavitha, A.] Dwaraka Doss Goverdhan Doss Vaishnav Coll, Dept Comp Sci UG & PG, Chennai, Tamil Nadu, India.
   [Sivakumar, N.] Jain Univ, Sch Comp Sci & Informat Technol, Bangalore, Karnataka, India.
   [Jaganathan, Subash Chandra Bose] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Sehore 466114, Madya Pradesh, India.
   [Suriyan, Kannadasan] Study World Coll Engn, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Jain University; VIT Bhopal University
RP Janarthanan, P (corresponding author), Sri Venkateswara Coll Engn, Dept Comp Sci & Engn, Sriperumbudur, TN, India.
EM murugesh72@gmail.com; jana.mca.me@gmail.com;
   kavithaa@dgvaishnavcollege.edu.in; drsivakumar.nadarajan@gmail.com;
   jsubashme@gmail.com; kannadhasan.ece@gmail.com
RI Kavitha, Dr A/AAG-1094-2021; Suriyan, Dr. Kannadhasan/AAI-7925-2020
OI Kavitha, Dr A/0000-0002-8921-4923; Suriyan, Dr.
   Kannadhasan/0000-0001-6443-9993; Nadarajan,
   Sivakumar/0000-0001-5039-072X
CR Afzal S, 2019, IEEE ACCESS, V7, P115528, DOI 10.1109/ACCESS.2019.2932786
   Altaf T, 2018, BIOMED SIGNAL PROCES, V43, P64, DOI 10.1016/j.bspc.2018.02.019
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Brier MR, 2012, J NEUROSCI, V32, P8890, DOI 10.1523/JNEUROSCI.5698-11.2012
   Bucholc M, 2019, EXPERT SYST APPL, V130, P157, DOI 10.1016/j.eswa.2019.04.022
   Cheng D, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Choi H, 2018, BEHAV BRAIN RES, V344, P103, DOI 10.1016/j.bbr.2018.02.017
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1
   El-Sappagh S, 2020, NEUROCOMPUTING, V412, P197, DOI 10.1016/j.neucom.2020.05.087
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Gulhare K.K., 2017, INT J ADV RES COMPUT, V7, P1, DOI DOI 10.23956/IJARCSSE/V7I6/0259
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Ibrahim A, 2020, IEEE ACCESS, V8, P122121, DOI 10.1109/ACCESS.2020.3007336
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Khademi A, 2020, MAGN RESON IMAGING, V66, P116, DOI 10.1016/j.mri.2019.08.022
   Kong R, 2019, bioRxiv, DOI [10.1101/548644, DOI 10.1101/548644]
   Lee G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37769-z
   Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045
   Lu DH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22871-z
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   MCKHANN G, 1984, NEUROLOGY, V34, P939, DOI 10.1212/WNL.34.7.939
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Ng YS, 2019, MADIMA'19: PROCEEDINGS OF THE 5TH INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P33, DOI 10.1145/3347448.3357168
   Noh Y, 2014, NEUROLOGY, V83, P1936, DOI 10.1212/WNL.0000000000001003
   Ramirez J, 2018, J NEUROSCI METH, V302, P47, DOI 10.1016/j.jneumeth.2017.12.005
   Sherubha P, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01451-w
   Suk HI, 2015, BRAIN STRUCT FUNCT, V220, P841, DOI 10.1007/s00429-013-0687-3
   Sukkar R, 2012, IEEE ENG MED BIO, P2845, DOI 10.1109/EMBC.2012.6346556
   Veitch DP, 2019, ALZHEIMERS DEMENT, V15, P106, DOI 10.1016/j.jalz.2018.08.005
   Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 38
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33465
EP 33488
DI 10.1007/s11042-023-16858-w
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900020
DA 2024-07-18
ER

PT J
AU Chen, DP
   Kong, DH
   Li, JH
   Wang, SF
   Yin, BC
AF Chen, Dongpan
   Kong, Dehui
   Li, Jinghua
   Wang, Shaofan
   Yin, Baocai
TI ADOSMNet: a novel visual affordance detection network with object shape
   mask guided feature encoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual affordance detection; Object shape mask; Feature representation;
   Feature enhancement; Image segmentation
ID CLASSIFICATION
AB Visual affordance detection aims to understand the functional attributes of objects, which is crucial for robots to achieve interactive tasks. Most existing affordance detection methods mainly utilize the global image features for affordance detection while do not fully exploit the features of local relevant objects in the image, which often leads to suboptimal detection accuracy under the interference of cluttered backgrounds and neighbour objects. Numerous researches have proved that the accuracy of affordance detection largely depends on the quality of extracted image features. In this paper, we propose a novel affordance detection network with object shape mask guided feature encoders. The masks play as an attention mechanism that enforce the network to focus on the shape regions of target objects in the image, which facilitate to obtain high-quality features. Specifically, we first propose a shape mask guided encoder, which uses masks to effectively locate all target objects so as to extract more expressive features. Based on the encoder, we then propose a dual enhance feature aggregation module, which consists of two branches. The first branch encodes the global features of the original image, while the second branch locates each local relevant object and encodes its precise features. Aggregating these features enhances the feature representation of each object, further improving feature quality and suppressing interference. Quantitative and qualitative evaluations compared with state-of-the-art methods demonstrate that the proposed method achieves superior performance on the two commonly used affordance detection datasets.
C1 [Chen, Dongpan; Kong, Dehui; Li, Jinghua; Wang, Shaofan; Yin, Baocai] Beijing Univ Technol, Beijing Artificial Intelligence Inst, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, 100 Pingleyuan, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Kong, DH (corresponding author), Beijing Univ Technol, Beijing Artificial Intelligence Inst, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, 100 Pingleyuan, Beijing 100124, Peoples R China.
EM cdp@emails.bjut.edu.cn; kdh@bjut.edu.cn; lijinghua@bjut.edu.cn;
   wangshaofan@bjut.edu.cn; ybc@dlut.edu.cn
RI Chen, Dongpan/JAX-2113-2023
OI Chen, Dongpan/0000-0003-2011-100X
FU National Natural Science Foundation of China [62172022, U21B2038];
   Beijing Outstanding Young Scientists Project [BJJWZYJH01201910005018]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62172022, and U21B2038, in part by the
   Beijing Outstanding Young Scientists Project under Grant
   BJJWZYJH01201910005018.
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Nguyen A, 2017, IEEE INT C INT ROBOT, P5908, DOI 10.1109/IROS.2017.8206484
   Nguyen A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2765, DOI 10.1109/IROS.2016.7759429
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen L, 2022, LECT NOTES COMPUT SC, V13696, P95, DOI 10.1007/978-3-031-20059-5_6
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P1466, DOI 10.1109/TVCG.2018.2871190
   Chu FJ, 2019, IEEE ROBOT AUTOM LET, V4, P1140, DOI 10.1109/LRA.2019.2894439
   Deng SH, 2021, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR46437.2021.00182
   Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909
   Fooladgar F, 2020, MULTIMED TOOLS APPL, V79, P4499, DOI 10.1007/s11042-019-7684-3
   GIBSON JAMES J., 1966
   Gu QP, 2021, NEUROCOMPUTING, V440, P36, DOI 10.1016/j.neucom.2021.01.018
   Gupta N, 2022, ARTIF INTELL REV, V55, P4755, DOI [10.1080/19475683.2022.2040587, 10.1007/s10462-021-10116-x]
   Haq NU, 2021, MULTIMED TOOLS APPL, V80, P21771, DOI 10.1007/s11042-021-10510-1
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hermans T, 2011, IEEE INT C ROB AUT I, P181
   Hou Z, 2021, PROC CVPR IEEE, P495, DOI 10.1109/CVPR46437.2021.00056
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Jiang SQ, 2020, IEEE T CIRC SYST VID, V30, P3119, DOI 10.1109/TCSVT.2019.2934989
   Kjellström H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kuo WC, 2019, IEEE I CONF COMP VIS, P9206, DOI 10.1109/ICCV.2019.00930
   Liu ZH, 2022, ROBOT CIM-INT MANUF, V77, DOI 10.1016/j.rcim.2022.102360
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu L, 2022, IEEE Transactions on Artificial Intelligence, P1
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Mao AH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3467889
   Minh CND, 2020, 2020 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), DOI 10.1109/DICTA51227.2020.9363390
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Munguia-Galeano F, 2023, IEEE ACCESS, V11, P31282, DOI 10.1109/ACCESS.2023.3262450
   Myers A, 2015, IEEE INT CONF ROBOT, P1374, DOI 10.1109/ICRA.2015.7139369
   Nie J, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3443708
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy A, 2016, LECT NOTES COMPUT SC, V9908, P186, DOI 10.1007/978-3-319-46493-0_12
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sawatzky J, 2017, IEEE INT CONF COMP V, P1383, DOI 10.1109/ICCVW.2017.164
   Shao D, 2020, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR42600.2020.00269
   Srivastava Y., 2021, COMPUTER VISION IMAG, P75
   Tang Y, 2022, Multimedia Tools and Applications, P1
   Do TT, 2018, IEEE INT CONF ROBOT, P5882, DOI 10.1109/ICRA.2018.8460902
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XY, 2020, IEEE T CIRC SYST VID, V30, P2663, DOI 10.1109/TCSVT.2019.2924912
   Wang X, 2020, ACM T MULTIM COMPUT, V16, DOI [10.1145/3397513, 10.1145/3397340]
   Wimbauer F, 2021, PROC CVPR IEEE, P6108, DOI 10.1109/CVPR46437.2021.00605
   Wu YH, 2023, IEEE T PATTERN ANAL, V45, P12760, DOI 10.1109/TPAMI.2022.3202765
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xu C, 2022, arXiv
   Yin CC, 2022, NEURAL COMPUT APPL, V34, P17963, DOI 10.1007/s00521-022-07446-4
   Yuan X, 2022, P AS C COMP VIS, P1909
   Zhang Y, 2022, 2022 INT JOINT C NEU, P1
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao X, 2020, NEURAL COMPUT APPL, V32, P14321, DOI 10.1007/s00521-019-04336-0
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
   Zhong Y, 2021, IEEE T CIRC SYST VID, V31, P3518, DOI 10.1109/TCSVT.2020.3040900
NR 60
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31629
EP 31653
DI 10.1007/s11042-023-16898-2
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200013
DA 2024-07-18
ER

PT J
AU Xu, XL
   Wang, KD
   Wang, CZ
   Chen, RH
   Zhu, FD
   Long, HX
   Guan, Q
AF Xu, Xinli
   Wang, Kaidong
   Wang, Chengze
   Chen, Ruihao
   Zhu, Fudong
   Long, Haixia
   Guan, Qiu
TI Iterative learning for maxillary sinus segmentation based on bounding
   box annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maxillary sinus segmentation; Bounding boxes; Weakly supervised;
   Superpixel classification; Graph convolution network; Iterative learning
ID NASAL CAVITY
AB An accurate segmentation of the maxillary sinus (MS) is helpful for preoperative planning of dental implantation, diagnosis and evaluation of sinusitis, and validation of radiotherapy for sinus cancer. Many medical image segmentation models based on convolutional neural networks have achieved excellent performance, however, relied heavily on manual accurate labeling of training data. We propose an iterative learning method for MS segmentation with only bounding box supervision. First, a cone-beam computed tomography (CBCT) image is over-segmented into a set of superpixels and a feature extraction network is optimized to better extract multi-scale features of each small-size superpixel. Second, an improved graph convolutional network (IGCN) is developed to merge superpixel regions and improve the feature transformation ability of each node on a superpixel-wise graph. Finally, the iterative learning combined with the superpixel-conditional random field and IGCN makes pseudo labels gradually refine and close to fully supervised information. On a practical MS dataset, the proposed method achieves 90.5% in Dice similarity coefficient. Extending to the public dataset Promise12 for prostate MR image segmentation, it also performs well. The results show that our proposed method has good comprehensive weakly supervised segmentation performance and can narrow a gap between the bounding box and full supervision.
C1 [Xu, Xinli; Wang, Kaidong; Chen, Ruihao; Long, Haixia; Guan, Qiu] Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou 310023, Peoples R China.
   [Wang, Chengze; Zhu, Fudong] Zhejiang Univ, Key Lab Oral Biomed Res Zhejiang Prov, Clin Res Ctr Oral Dis Zhejiang Prov,Sch Stomatol, Canc Ctr,Sch Med,Stomatol Hosp, Hangzhou 310006, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University
RP Long, HX (corresponding author), Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou 310023, Peoples R China.; Zhu, FD (corresponding author), Zhejiang Univ, Key Lab Oral Biomed Res Zhejiang Prov, Clin Res Ctr Oral Dis Zhejiang Prov,Sch Stomatol, Canc Ctr,Sch Med,Stomatol Hosp, Hangzhou 310006, Peoples R China.
EM zfd@zju.edu.cn; longhaixia@zjut.edu.cn
RI chen, ruihao/ABG-9547-2021; guan, qiu/G-7683-2012; Wang,
   Kaidong/JGM-5273-2023
OI chen, ruihao/0000-0001-8425-1234; Wang, Kaidong/0000-0001-9900-1537
FU National Natural Science Foundation of China
FX This work was supported partly by National Natural Science Foundation of
   China (No. 62106225 and No. U20A20171), partly by Natural Science
   Foundation of Zhejiang Province (No. LY21F020027), partly by Zhejiang
   Province Public Welfare Technology Application Research Project (No.
   LGG20F020017), and partly by Key Programs for Science and Technology
   Development of Zhejiang Province (No. 2022C03113).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aksoy EA, 2014, J CRANIOFAC SURG, V25, P1801, DOI 10.1097/SCS.0000000000000966
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Andersen TN, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170663
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Berberi A, 2015, J MAXILLOFAC ORAL SU, V14, P624, DOI 10.1007/s12663-014-0736-3
   Bui NL, 2015, INT J COMPUT ASS RAD, V10, P1269, DOI 10.1007/s11548-014-1134-5
   Cha JY, 2021, J CLIN MED, V10, DOI 10.3390/jcm10122577
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Choi H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18436-w
   Cui F, 2021, IEEE INT GEOSC REM S, P2178, DOI [10.1109/IGARSS47720.2021.9554635, DOI 10.1109/IGARSS47720.2021.9554635]
   Demir UL, 2015, SURG RADIOL ANAT, V37, P1093, DOI 10.1007/s00276-015-1459-y
   Di SH, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117347
   dos Santos ES, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102363
   Dosovitskiy A., 2021, ICLR
   Giacomini G, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190770
   Gomes AF, 2019, INT J LEGAL MED, V133, P1241, DOI 10.1007/s00414-018-1869-6
   Gugulothu VK, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15802-2
   Han K., 2022, P ADV NEUR INF PROC, V35, P8291
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong YF, 2023, MULTIMED TOOLS APPL, V82, P6829, DOI 10.1007/s11042-022-13606-4
   Hu Hanzhe., 2020, European Conference on Computer Vision, P1
   Huang QH, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101657
   Hung KF, 2022, CLIN ORAL INVEST, V26, P3987, DOI 10.1007/s00784-021-04365-x
   Imtiaz T, 2020, IEEE ACCESS, V8, P25335, DOI 10.1109/ACCESS.2019.2961630
   Iqbal MJ, 2022, MULTIMED TOOLS APPL, V81, P38409, DOI 10.1007/s11042-022-13166-7
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Jinda-Apiraksa A, 2009, TENCON 2009 2009 IEE, P1, DOI DOI 10.1109/TENCON.2009.5396044
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Jung SK, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11040688
   Kervadec H, 2020, PR MACH LEARN RES, V121, P365
   Keusterman W, 2019, COMPUT BIOL MED, V105, P27, DOI 10.1016/j.compbiomed.2018.12.008
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Kipf TN, 2017, INT C LEARN REPR
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li S, 2018, PROC SPIE, V10577, DOI 10.1117/12.2293240
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Ling H, 2019, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR.2019.00540
   Ma F, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212586
   Mahani GK, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761558
   Martins AFT, 2015, J MACH LEARN RES, V16, P495
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Morgan N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11483-3
   Qu H, 2020, IEEE T MED IMAGING, V39, P3655, DOI 10.1109/TMI.2020.3002244
   Rajchl Martin, 2017, IEEE Trans Med Imaging, V36, P674, DOI 10.1109/TMI.2016.2621185
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi HJ, 2006, INT J COMPUT ASS RAD, V1, P177, DOI 10.1007/s11548-006-0050-8
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang WM, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104265
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Valvano G, 2021, IEEE T MED IMAGING, V40, P1990, DOI 10.1109/TMI.2021.3069634
   Velickovic Petar, 2018, INT C LEARN REPR
   Wei J, 2022, LECT NOTES COMPUT SC, V13433, P67, DOI 10.1007/978-3-031-16437-8_7
   Xu JC, 2020, INT J COMPUT ASS RAD, V15, P1457, DOI 10.1007/s11548-020-02228-6
NR 55
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33263
EP 33293
DI 10.1007/s11042-023-16544-x
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500011
DA 2024-07-18
ER

PT J
AU Ez-ziymy, S
   Hatim, A
   Hammia, S
AF Ez-ziymy, Siham
   Hatim, Anas
   Hammia, Slama
TI Real-time hardware architecture of an ECG compression algorithm for IoT
   health care systems and its VLSI implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG Compression; Hardware Architecture; FPGA; Smart Systems; IT
ID RECOGNITION
AB The Internet of Things (IoT) in the medical and biomedical field proposes new and efficient hardware for healthcare services. Thanks to machine-machine interaction and real-time solutions, the problems of accessibility and reliability are resolved. In addition, increased patient engagement in decision-making will drive health service compliance. Vital signals like the electrocardiogram (ECG) are some of the most critical biomedical information to process; it is the subject of several studies. The data flow of those signals is enormous, making real-time transmission a tough job, hence the need to compress these vital signals. Designing efficient hardware compression engines is a promising challenge for efficient real-time transmission. This article introduces a new VLSI (Very-Large-Scale Integration) architecture for an ECG compression engine based on the algorithm presented in the same work. The efficiency of our processor was verified using the MIT BIH databases. We have also implemented it using An FPGA, which reaches a frequency of 170 MHz and 65 n TCMS CMOS. The proposed processor uses 1.85 Kgates and consumes 25 nW with a compression ratio of 3.42.
C1 [Ez-ziymy, Siham] Ibn Zohr Univ, Natl Sch Appl Sci Agadir, Lab Energy Engn Mat & Syst, Agadir, Morocco.
   [Hatim, Anas; Hammia, Slama] Cadi Ayyad Univ, Natl Sch Appl Sci Marrakech, Technol Informat & Multimedia Team, Marrakech, Morocco.
C3 Ibn Zohr University of Agadir; Cadi Ayyad University of Marrakech
RP Ez-ziymy, S (corresponding author), Ibn Zohr Univ, Natl Sch Appl Sci Agadir, Lab Energy Engn Mat & Syst, Agadir, Morocco.
EM sihamezziymy@gmail.com; a.hatim@uca.ma; hammia.slama@gmail.com
CR Ahmed S. M., 2009, Journal of Medical Engineering & Technology, V33, P1, DOI 10.1080/03091900701797453
   Ali AM., 2019, Int J Comput Appl, V181, P0975
   Ballesteros Dora M, 2012, Ingeniare. Rev. chil. ing., V20, P8, DOI 10.4067/S0718-33052012000100002
   Binu PK, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P487, DOI 10.1109/ICACCI.2017.8125887
   Buxi D, 2012, BIOMED CIRC SYST C, P308, DOI 10.1109/BioCAS.2012.6418435
   Chan HL, 2011, J MED BIOL ENG, V31, P331, DOI 10.5405/jmbe.715
   Chen QH, 2022, IEEE T CIRCUITS-II, V69, P5194, DOI 10.1109/TCSII.2022.3204550
   Chen SL, 2013, ELECTRON LETT, V49, P91, DOI 10.1049/el.2012.3505
   Chen SL, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.2202
   Chen WJ, 2017, INT SYMP NEXTGEN
   Chen YH, 2020, CIRC SYST SIGNAL PR, V39, P1665, DOI 10.1007/s00034-019-01198-8
   Chen Z, 2018, IEICE Trans Inf Syst, VE101-D, DOI [10.1587/transient.2017EDL8206, DOI 10.1587/TRANSIENT.2017EDL8206]
   Cherupally SK, 2020, IEEE T BIOMED CIRC S, V14, P198, DOI 10.1109/TBCAS.2020.2974387
   Chowdhury MH, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53460-3
   Deepu CJ, 2017, IEEE T BIOMED CIRC S, V11, P245, DOI 10.1109/TBCAS.2016.2591923
   Ding YS, 2016, IEEE 13 INT C WEAR I, DOI [10.1109/BSN.2016.7516240, DOI 10.1109/BSN.2016.7516240]
   Ibrahim MK., 2019, J Univ Babylon Eng Sci, V27, P242
   Ieong CI, 2017, IEEE T VLSI SYST, V25, P1307, DOI 10.1109/TVLSI.2016.2638826
   Jagadeeswari V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0049-x
   Jla M, A Lossless Electrocardiogram Compression System Based on Dual-Mode Prediction and Error Modeling, DOI [10.1109/ACCESS.2020.2998608, DOI 10.1109/ACCESS.2020.2998608]
   Kalaivani S, 2020, WIRELESS PERS COMMUN, V113, P599, DOI 10.1007/s11277-020-07241-1
   Kerdjidj O, 2019, MICROPROCESS MICROSY, V67, P131, DOI 10.1016/j.micpro.2019.03.007
   Kumar A, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0953-2
   Kuppusamy P. G., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1964/6/062073
   Lee S, 2011, IEEE T BIO-MED ENG, V58, P2448, DOI 10.1109/TBME.2011.2156794
   Lin KJ, 2018, IEEE 7 GLOB C CONS E, DOI [10.1109/GCCE.2018.8574652, DOI 10.1109/GCCE.2018.8574652]
   Lin KJ, 2018, IEEE GLOB CONF CONSU, P132, DOI 10.1109/GCCE.2018.8574652
   Luo JH, 2017, IEICE ELECTRON EXPR, V14, DOI 10.1587/elex.14.20170865
   Luo JH, 2017, IEICE ELECTRON EXPR, V14, DOI 10.1587/elex.14.20170524
   Martínez JP, 2004, IEEE T BIO-MED ENG, V51, P570, DOI 10.1109/TBME.2003.821031
   Padhy S, 2016, BIOMED SIGNAL PROCES, V23, P10, DOI 10.1016/j.bspc.2015.06.012
   Preethi KGM, 2020, UGC Care Journal, V40
   Sandanalakshmi R, 2016, PROCEDIA COMPUT SCI, V85, P496, DOI 10.1016/j.procs.2016.05.201
   Sarma J, 2022, IEEE SENSOR LETT, V6, DOI 10.1109/LSENS.2022.3157030
   Tekeste T, 2019, IEEE T CIRCUITS-I, V66, P669, DOI 10.1109/TCSI.2018.2867746
   Tiwari A, 2019, BIOMED SIGNAL PROCES, V51, P338, DOI 10.1016/j.bspc.2019.03.004
   Tsai TH, 2018, IEEE INT C CONS EL T, DOI [10.1109/ICCE-China.2018.8448939, DOI 10.1109/ICCE-CHINA.2018.8448939]
   Tsai TH, 2020, IEEE T CIRCUITS-II, V67, P3317, DOI 10.1109/TCSII.2020.2978554
   Tsai TH, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101879
   Tseng YH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102288
   Wang LH, 2022, IEEE SENS J, V22, P18045, DOI 10.1109/JSEN.2022.3195501
   Wang LH, 2012, BIOMED CIRC SYST C, P156, DOI 10.1109/BioCAS.2012.6418396
   Zigel Y, 1997, COMPUT CARDIOL, V24, P279, DOI 10.1109/CIC.1997.647885
NR 43
TC 3
Z9 3
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30937
EP 30961
DI 10.1007/s11042-023-16631-z
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000013
DA 2024-07-18
ER

PT J
AU El-Ateif, S
   Idri, A
AF El-Ateif, Sara
   Idri, Ali
TI Eye diseases diagnosis using deep learning and multimodal medical eye
   imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye diseases; Diabetic eye diseases; Binary classification; Late fusion;
   Multimodality; Deep convolutional neural networks
ID CONVOLUTIONAL NEURAL-NETWORKS; DIABETIC-RETINOPATHY; AUTOMATIC
   DETECTION; RETINAL IMAGES; FUNDUS IMAGES
AB The present study carries out an empirical evaluation and comparison of the seven most recent deep Convolutional Neural Network (CNN) techniques (VGG19, DenseNet121, InceptionV3, InceptionResNetV2, Xception, ResNet50V2, MobileNetV2) for eye disease classification into normal and diseased using mono-modality and late fusion multimodality over three datasets. All empirical evaluations were carried out using: (1) six classification metrics, (2) the Scott-Knott Effect Size Difference (SK-ESD) statistical test, (3) Borda count method, and (4) publicly available datasets: DHS (combining three datasets: DRIVE, STARE, and HRF), FFA, and Macula. The results showed that DenseNet121 and ResNet50V2 were the top performing and less sensitive techniques on the three datasets using mono-modality with accuracy values of 99.57% and 99.51% respectively. As for late fusion techniques, they outperformed mono-modality across the three datasets, regardless of the mono-modality used. Moreover, ResNet50V2 late fusion was the best late fusion technique and scored 100% in accuracy across all three datasets. Additionally, our proposed ResNet50V2 late fusion model trained on the Macula dataset outperforms current state-of-the-art models trained on more than one eye disease (accuracy of: proposed ResNet50V2 late fusion = 100%, New CNN = 81.33%), and is similar to best ranking feature-level fusion one eye disease model with accuracy equal to 100%.
C1 [El-Ateif, Sara; Idri, Ali] Mohammed V Univ, Software Project Management Res Team, ENSIAS, Rabat, Morocco.
   [Idri, Ali] Mohammed VI Polytech Univ, Benguerir, Morocco.
C3 Mohammed V University in Rabat; Mohammed VI Polytechnic University
RP Idri, A (corresponding author), Mohammed V Univ, Software Project Management Res Team, ENSIAS, Rabat, Morocco.; Idri, A (corresponding author), Mohammed VI Polytech Univ, Benguerir, Morocco.
EM sara_elateif@um5.ac.ma; ali.idri@um5.ac.ma
OI Idri, Ali/0000-0002-4586-4158
FU The authors would like to thank the Google Ph.D. Fellowship program for
   supporting Sara El-Ateif.
FX The authors would like to thank the Google Ph.D. Fellowship program for
   supporting Sara El-Ateif.
CR Abràmoff MD, 2013, JAMA OPHTHALMOL, V131, P351, DOI 10.1001/jamaophthalmol.2013.1743
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Alipour SHM, 2014, SIGNAL IMAGE VIDEO P, V8, P205, DOI 10.1007/s11760-013-0530-6
   An GZ, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4061313
   An GZ, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/6874765
   APTOS, 2019, Blindness Detection
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Canayaz M, 2022, APPL SOFT COMPUT, V128, DOI 10.1016/j.asoc.2022.109462
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Lima ACD, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439477
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   El-Ateif S, 2022, SCI AFR, V17, DOI 10.1016/j.sciaf.2022.e01280
   Elmidaoui S, 2020, CEUR WORKSHOP PROC, V2725, P1, DOI [10.5277/E-INF190105, DOI 10.5277/E-INF190105]
   Emerson P, 2013, SOC CHOICE WELFARE, V40, P353, DOI 10.1007/s00355-011-0603-9
   Fenner BJ, 2018, OPHTHALMOL THER, V7, P333, DOI 10.1007/s40123-018-0153-7
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fumero F, 2011, COMP MED SY
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gençay R, 2001, IEEE T NEURAL NETWOR, V12, P726, DOI 10.1109/72.935086
   Gómez-Valverde JJ, 2019, BIOMED OPT EXPRESS, V10, P892, DOI 10.1364/BOE.10.000892
   Gu Zongyun, 2023, Comput Intell Neurosci, V2023, P1305583, DOI 10.1155/2023/1305583
   Harangi B, 2019, IEEE ENG MED BIO, P2699, DOI [10.1109/embc.2019.8857073, 10.1109/EMBC.2019.8857073]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hervella AS, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105302
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jin K, 2022, ACTA OPHTHALMOL, V100, pE512, DOI 10.1111/aos.14928
   Lee Y.C., 2022, Classification for referable glaucoma with fundus photographs using multimodal deep learning, P2
   Li JQ, 2020, EUR J EPIDEMIOL, V35, P11, DOI 10.1007/s10654-019-00560-z
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Liu C, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1810.13395
   Liu TYA, 2023, BRIT J OPHTHALMOL, V107, P1484, DOI 10.1136/bjo-2021-320897
   Phan S, 2019, JPN J OPHTHALMOL, V63, P276, DOI 10.1007/s10384-019-00659-6
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Qiu Shangran, 2018, Alzheimers Dement (Amst), V10, P737, DOI 10.1016/j.dadm.2018.08.013
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarki R, 2022, EAI ENDORSED TRANS S, V9, DOI 10.4108/eai.16-12-2021.172436
   Sarki R, 2020, IEEE ACCESS, V8, P151133, DOI 10.1109/ACCESS.2020.3015258
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sun DD, 2019, IEEE ACM T COMPUT BI, V16, P841, DOI 10.1109/TCBB.2018.2806438
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tantithamthavorn C, 2019, IEEE T SOFTWARE ENG, V45, P683, DOI 10.1109/TSE.2018.2794977
   Tseng VS, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.41
   Umapathy A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON BIOSCIENCE, BIOCHEMISTRY AND BIOINFORMATICS (ICBBB 2019), P17, DOI 10.1145/3314367.3314376
   Vaghefi E, 2020, J OPHTHALMOL, V2020, DOI 10.1155/2020/7493419
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Yao ZM, 2022, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.961386
   Yoo TK, 2019, MED BIOL ENG COMPUT, V57, P677, DOI 10.1007/s11517-018-1915-z
   Zanzottera EC, 2015, INVEST OPHTH VIS SCI, V56, P3253, DOI 10.1167/iovs.15-16431
NR 59
TC 2
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30773
EP 30818
DI 10.1007/s11042-023-16835-3
EA SEP 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900008
DA 2024-07-18
ER

PT J
AU Dubey, P
   Kanumuri, T
   Vyas, R
   Jain, PK
AF Dubey, Pawan
   Kanumuri, Tirupathiraju
   Vyas, Ritesh
   Jain, Prashant Kumar
TI Anisotropic differential concavity codes for palmprint representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint recognition; Curved Palmlines; Palmline concavity; Anisotropic
   filters; Curvilinar anisotrpic filtering; Differential concavity codes
ID VERIFICATION; RECOGNITION; IDENTIFICATION; FUSION
AB The straight excitatory filters such as Gabor filters and Modified finite Radon transform can not include the vital and inherent curvature information residing in palmlines of the palm-print. Moreover, Gabor filter bank, employed in majority research work of the literature, is frequency dependent which require tuning to avoid false line representation for principle line/wrinkles. Therefore in this work to evade the false palmline assessment within the neighbourhood region and include inherent curvature attribute of the palmlines, a curvilinear anisotropic filter, (C-AGF) is proposed and employed for palmprint representation. The proposed filter bank exploits both positive and negative concavities constituted within the palmlines. A novel representation called as the Anisotropic Differential Concavity (AD(C)) codes is obtained from difference plane obtained by subtracting curvilinear anisotropic filter responses of the palmprint sample at various orientations and for both positive and negative concavities, followed by the zero-crossings of these difference planes. Finally, it is observed that the experimental performance of the proposed representation, on standard PolyU 2D and IITD touch-less databases, outperforms several state-of-the-art approaches.
C1 [Dubey, Pawan] Madhav Inst Sci & Technol, Dept Ctr ArtifitiaI Intellegence AI, Gwalior 474005, MP, India.
   [Kanumuri, Tirupathiraju] Natl Inst Technol Delhi, Dept Elect & Elect Engn, Plot FA7,Zone, P1,GT Karnal Rd, Delhi 110036, India.
   [Vyas, Ritesh] Pandit Deendayal Energy Univ, Sch Technol, Dept Informat & Commun Technol, Gandhinagar 382426, Gujarat, India.
   [Jain, Prashant Kumar] Raj Gandhi Prodhyogiki Vishwavidyalaya, Bhopal 462036, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science; National Institute of
   Technology (NIT System); National Institute of Technology Delhi; Pandit
   Deendayal Energy University
RP Dubey, P (corresponding author), Madhav Inst Sci & Technol, Dept Ctr ArtifitiaI Intellegence AI, Gwalior 474005, MP, India.
EM pawand@mitsgwalior.in; ktraju@nitdelhi.ac.in;
   ritesh.vyas@sot.pdpu.ac.in; pjain@rgpv.ac.in
RI Kanumuri, Tirupathiraju/V-5584-2019
OI Kanumuri, Tirupathiraju/0000-0002-0441-7642
CR Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Badrinath GS, 2012, FUTURE GENER COMP SY, V28, P287, DOI 10.1016/j.future.2010.11.029
   comp.polyu.edu.hk, 2016, HONG KONG POLYU 2D 3
   Dubey P, 2022, MULTIMED TOOLS APPL, V81, P20291, DOI 10.1007/s11042-022-12580-1
   Dubey P, 2018, SIGNAL IMAGE VIDEO P, V12, P677, DOI 10.1007/s11760-017-1207-3
   Dubey P, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1979
   Fei L, 2022, IEEE T NEUR NET LEAR
   Fei LK, 2016, IEEE T HUM-MACH SYST, V46, P787, DOI 10.1109/THMS.2016.2586474
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Huikai Shao, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P714, DOI 10.1109/CVPRW.2019.00098
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Liu JL, 2014, IMAGE VISION COMPUT, V32, P37, DOI 10.1016/j.imavis.2013.12.001
   Liu L., 2005, IEEE International Conference on Image Processing, V3, pIII269, DOI 10.1109/ICIP.2005.1530380
   Minaee S., 2017, P IEEE INT S CIRC SY, P1, DOI DOI 10.1109/ISCAS.2017.8050421
   Peters G, 1997, P 1 STIPR, P113
   Prasad SM, 2011, SECUR COMMUN NETW, V4, P577, DOI 10.1002/sec.234
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Samai D, 2018, 2018 3 INT C PATT AN, P1, DOI DOI 10.1109/PAIS.2018.8598522
   Shu W, 1998, INT C PATT RECOG, P219, DOI 10.1109/ICPR.1998.711120
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tabejamaat M, 2017, MULTIMED TOOLS APPL, V76, P9387, DOI 10.1007/s11042-016-3544-6
   Tamrakar D, 2015, SIGNAL IMAGE VIDEO P, V9, P535, DOI 10.1007/s11760-013-0475-9
   Xiangyu Xu, 2019, Machine Learning and Intelligent Communications. 4th International Conference, MLICOM 2019. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 294), P748, DOI 10.1007/978-3-030-32388-2_61
   Xu Yunhong, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538568
   Yao P, 2006, INT C PATT RECOG, P461
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zhong DX, 2018, LECT NOTES COMPUT SC, V10996, P48, DOI 10.1007/978-3-319-97909-0_6
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31001
EP 31015
AR s11042-023-16690-2
DI 10.1007/s11042-023-16690-2
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400003
DA 2024-07-18
ER

PT J
AU Kumar, M
   Yadav, DK
   Ray, S
   Tanwar, R
AF Kumar, Manoj
   Yadav, Dileep Kumar
   Ray, Susmita
   Tanwar, Rohit
TI Handling illumination variation for motion detection in video through
   intelligent method: An application for smart surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance system; Moving object detection; Illumination
   variation; Niblack's threshold; Classification
ID MOVING OBJECT DETECTION; BACKGROUND SUBTRACTION; TRACKING
AB The motion-based human detection from video data in the real-time automated surveillance system is a tedious and challenging task that requires extracting meaningful information and filtering out redundant information. The surveillance system developed for the recommended task should be able to handle challenges like cluttered background, non-constant light intensity, and other sources of illumination, along with many more. Practically, handling the variation of illumination in the background is dreary. This paper proposes an adaptive method for the maintenance of the background model and adaptive threshold generation using the Niblack's threshold method, which is used to classify the moving and non-moving pixels by avoiding the external involvement for threshold selection at the run-time. To evaluate the efficacy, the performance of the proposed work is analyzed through numerous parameters to achieve higher accuracy with minimum false alarm rate with overall outcome of better results. The performance of the proposed method is analyzed vis-a-vis the existing methods in terms of precision, recall, F1-score, and ROC-curve. The qualitative and quantitative experimental results demonstrate better real-time performance and usability against the state of the art methods. This research work is also incorporated the proposed intelligent algorithm generates automatic threshold locally for individual pixels and demonstrates better classification of moving pixels and analysed its performance against considered peer methods.
C1 [Kumar, Manoj; Ray, Susmita] Manav Rachna Univ, Faridabad, Haryana, India.
   [Yadav, Dileep Kumar] Bennett Univ, Greater Noida, UP, India.
   [Tanwar, Rohit] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Tanwar, R (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, India.
EM rohit.tanwar.cse@gmail.com
RI Tanwar, Rohit/AAD-8805-2020; Yadav, Dr. Dileep Kumar/AAI-6235-2020;
   Kumar, Manoj/AFS-0700-2022
OI Tanwar, Rohit/0000-0002-9087-6019; Yadav, Dr. Dileep
   Kumar/0000-0003-1469-9433; Kumar, Manoj/0000-0001-9598-0280
CR Ahmad J, 2019, INFRARED PHYS TECHN, V98, P45, DOI 10.1016/j.infrared.2019.02.006
   Bouwmans T., 2014, Background Modeling and Foreground Detection for Video Surveillance, DOI [10.1201/b17223, DOI 10.1201/B17223]
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chen P, 2018, IEEE T INTELL TRANSP, V19, P131, DOI 10.1109/TITS.2017.2750091
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dou JF, 2019, MULTIMED TOOLS APPL, V78, P14549, DOI 10.1007/s11042-018-6854-z
   Giveki D, 2020, OPTIK, V209, DOI 10.1016/j.ijleo.2020.164563
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Haque Mahfuzul, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P41, DOI 10.1109/AVSS.2008.12
   Jung CR, 2009, IEEE T MULTIMEDIA, V11, P571, DOI 10.1109/TMM.2009.2012924
   Ng KK, 2011, PROC SPIE, V7882, DOI 10.1117/12.872610
   Lee S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-30
   Li YT, 2023, ACM T SENSOR NETWORK, V19, DOI 10.1145/3599727
   Mahalingam T, 2021, APPL COMPUT INFORM, V17, P2, DOI 10.1016/j.aci.2018.01.001
   Mishra Sneha, 2022, 2022 2nd Asian Conference on Innovation in Technology (ASIANCON), P1, DOI 10.1109/ASIANCON55314.2022.9909108
   Mishra S., 2021, Turkish Online Journal of Qualitative Inquiry, V12, P9892
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Raja R, 2023, MULTIMED TOOLS APPL, V82, P12635, DOI 10.1007/s11042-022-13954-1
   Sadkhan Abbas S. B., 2021, 2021 1st Babylon International Conference on Information Technology and Science (BICITS), P69, DOI 10.1109/BICITS51482.2021.9509887
   Saikrishnan V, 2023, INT C SUST COMP DAT, P1
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Sengar SS, 2020, MULTIMED TOOLS APPL, V79, P5919, DOI 10.1007/s11042-019-08506-z
   Senthilkumaran N., 2014, International Journal of Computer Science and Information Technologies, V5, P2174
   Sharma L., 2017, International Journal of Telemedicine and Clinical Practices, V2, P74
   Sharma L, 2016, INFRARED PHYS TECHN, V78, P118, DOI 10.1016/j.infrared.2016.07.012
   Songa J., 2020, INFRARED PHYS TECHN, V105, P1
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sultana M, 2021, IEEE T MULTIMEDIA, V23, P2005, DOI 10.1109/TMM.2020.3006419
   Thepade SD, 2020, INT J INTELL ENG INF, V8, P77
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Xiang JH, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/827461
   Xu XG, 2019, INFRARED PHYS TECHN, V100, P87, DOI 10.1016/j.infrared.2019.02.014
   Yadav D.K., 2019, Intern. J. Spatio-Temp. Data Sci, V1, P4, DOI [10.1504/IJSTDS.2019.097600, DOI 10.1504/IJSTDS.2019.097600]
   Yadav DK, 2016, INFRARED PHYS TECHN, V76, P21, DOI 10.1016/j.infrared.2015.12.027
   Yadav DK, 2019, BOOKVISUAL SURVEIL I, P1
   Yazdi M, 2018, COMPUT SCI REV, P1
   Zeng Q, 2020, J REAL-TIME IMAGE PR, V17, P1103, DOI 10.1007/s11554-019-00858-x
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zi X, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051259
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29139
EP 29157
DI 10.1007/s11042-023-16595-0
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063370800001
DA 2024-07-18
ER

PT J
AU Luo, XQ
   Li, K
   Wang, AQ
   Zhang, ZC
   Wu, XJ
AF Luo, Xiaoqing
   Li, Kai
   Wang, Anqi
   Zhang, Zhancheng
   Wu, Xiaojun
TI Infrared and visible image fusion based on quaternion wavelets transform
   and feature-level Copula model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared and visible image fusion; Quaternion wavelet transform; Copula;
   Redundancy; Complementarity
ID ALGORITHM
AB To solve the problems that the correlation of multi-scale coefficients is ignored, as well as inaccurate identification of complementarity and redundancy of source images in traditional infrared and visible image fusion methods, an infrared and visible image fusion method based on quaternion wavelet transform (QWT) and feature-level copula model is proposed in this paper. The proposed method extracts the luminance, contrast and structure features of QWT magnitude and phase subbands. Then, the feature-level copula model capturing the inter-scale and phase-magnitude correlation is constructed to describe the intrinsic structure of images. The redundant and complementary feature type of QWT coefficient is further determined through the similarity of proposed models. According to the feature types, different fusion rules for high-frequency subbands are designed to accurately transfer the salient features of source images into fused image. For the low frequency subbands, a fusion rule is proposed using multiple features to avoid the degradation of image visual quality caused by false information. Finally, the fused low frequency subbands and high frequency subbands are transformed by inverse QWT to get the fused image. Experimental results show that the proposed method can effectively retain the rich details and structure information in infrared and visible images.
C1 [Luo, Xiaoqing; Li, Kai; Wang, Anqi; Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
   [Luo, Xiaoqing; Li, Kai; Wang, Anqi; Wu, Xiaojun] Jiangnan Univ, Inst Adv Technol, Wuxi 214122, Peoples R China.
   [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou 215009, Peoples R China.
C3 Jiangnan University; Jiangnan University; Suzhou University of Science &
   Technology
RP Zhang, ZC (corresponding author), Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou 215009, Peoples R China.
EM cimszhang@163.com
FU National Natural Science Foundation of China [61772237]; Six Talent
   Climax Foundation of Jiangsu [XYDXX-030]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772237, in part by the Six Talent
   Climax Foundation of Jiangsu under Grant XYDXX-030.
CR Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Bayro-Corrochano E, 2006, J MATH IMAGING VIS, V24, P19, DOI 10.1007/s10851-005-3605-3
   Chai PF, 2017, IEEE ACCESS, V5, P6724, DOI 10.1109/ACCESS.2017.2685178
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   [邓立暖 Deng Linuan], 2017, [电子学报, Acta Electronica Sinica], V45, P2965
   Geng P, 2017, J MED BIOL ENG, V37, P230, DOI 10.1007/s40846-016-0200-6
   Guo LQ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107513
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li CR, 2013, IEEE SIGNAL PROC LET, V20, P799, DOI 10.1109/LSP.2013.2247596
   Li H, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103039
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   [李凯 Li Kai], 2019, [计算机科学, Computer Science], V46, P293
   Liu Gui-Xi, 2002, Acta Automatica Sinica, V28, P927
   Liu Jian, 2016, Control and Decision, V31, P453, DOI 10.13195/j.kzyjc.2014.1932
   Liu SL, 2022, IEEE T WIREL COMMUN, V21, P7852, DOI [10.1109/TWC.2022.3162595, 10.1109/IECON49645.2022.9968484]
   Liu S, 2023, IEEE T RELIAB, V72, P15, DOI 10.1109/TR.2022.3162346
   Liu XB, 2022, J KING SAUD UNIV-COM, V34, P6179, DOI 10.1016/j.jksuci.2021.07.014
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2023, IEEE T MULTIMEDIA, V25, P608, DOI 10.1109/TMM.2021.3129354
   Luo XQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3105250
   Luo XQ, 2017, IEEE SENS J, V17, P1760, DOI 10.1109/JSEN.2016.2646741
   Luo XQ, 2016, AEU-INT J ELECTRON C, V70, P186, DOI 10.1016/j.aeue.2015.11.004
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Marchi, 2012, J DATA SCI, V10, P711, DOI [10.6339/JDS.201210_10(4).0008, DOI 10.6339/JDS.201210_10(4).0008]
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Simoncelli EP, 1999, P SOC PHOTO-OPT INS, V3813, P188, DOI 10.1117/12.366779
   Sklar A., 1973, Kybernetika, V9, P449
   Ulow TB, 1999, HYPERCOMPLEX SPECTRA
   Wang XH, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105387
   [王相海 Wang Xianghai], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1778
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   [闫利 Yan Li], 2016, [电子学报, Acta Electronica Sinica], V44, P761
   Yang Bo, 2010, Acta Automatica Sinica, V36, P12, DOI 10.3724/SP.J.1004.2010.00012
   [殷明 Yin Ming], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1289
   Zhang QH, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.5.057006
   [张小利 Zhang Xiaoli], 2014, [自动化学报, Acta Automatica Sinica], V40, P306
NR 44
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28549
EP 28577
DI 10.1007/s11042-023-15536-1
EA SEP 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000010
DA 2024-07-18
ER

PT J
AU Gupta, K
   Tayal, DK
   Jain, A
AF Gupta, Kavya
   Tayal, Devendra Kumar
   Jain, Aarti
TI An energy-efficient hierarchical data fusion approach in IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational complexity; Data fusion; Energy efficiency; Internet of
   Things; Spatiotemporal data fusion; Wireless sensor networks
ID FUZZY; ALGORITHM; NETWORKS; INTERNET; LANDSAT
AB Data Fusion (DF) involves merging data from various heterogeneous sources to generate fused data that is reduced in volume while preserving its integrity, consistency, and veracity. However, DF methodologies often pose challenges for low computational-powered sensor nodes (SNs) in energy-constrained Wireless Sensor Networks (WSNs) enabled Internet of Things (IoT). This study introduces a hierarchical data fusion (HDF) technique specifically designed to distribute the computational load among SNs with a focus on addressing the challenges of spatiotemporal data (STD). The hierarchy consists of three levels: A spatiotemporal data fusion (STDF) method, employed at the SNs level that efficiently handles the complex relationships between STD attributes; A fuzzy data fusion method, implemented at the cluster head (CH) level that effectively addresses the imprecise and fuzzy nature of real-world; The final fusion, applied at the sink (SKN) level that is based on the count of encoded icon values (EIVs). The proposed method achieves high accuracy (ACC), low error rates (ERR), and improved precision (PRE), recall (REC), and f1-score (F1S) values compared to avant-garde methods. Moreover, the analysis of the proposed technique reveals reduced computational complexity by distributing the computational load across different levels of hierarchy. Additionally, the proposed HDF technique exhibits lowered energy consumption and reduced communication overhead, making it well-suited for implementation in WSNs-enabled IoT.
C1 [Gupta, Kavya; Tayal, Devendra Kumar] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Jain, Aarti] Netaji Subhas Univ Technol, Dwarka Sect 3, Delhi 110078, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Netaji
   Subhas University of Technology
RP Gupta, K (corresponding author), Indira Gandhi Delhi Tech Univ Women, Delhi, India.
EM gupta.kavya12@gmail.com; dev_tayal2001@yahoo.com; rtjain2001@gmail.com
RI Gupta, Kavya/JVZ-4639-2024
OI GUPTA, KAVYA/0000-0002-2207-9616
CR Alam CN, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT, P189
   Ali MS, 2008, PROCEEDINGS OF ICECE 2008, VOLS 1 AND 2, P909, DOI 10.1109/ICECE.2008.4769341
   Arefin SE, 2021, ARXIV
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Bilal J, 2017, ELECTRON ENG, P135, DOI [10.1007/978-981-10-1627-1_11, DOI 10.1007/978-981-10-1627-1_11]
   Borjian N, 2018, MULTIMED TOOLS APPL, V77, P6165, DOI 10.1007/s11042-017-4524-1
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chopde NR., 2013, INT J INNOVATIVE RES, V1, P298, DOI DOI 10.15680/IJIRCCE
   Dong TF, 2016, INT J APPL EARTH OBS, V49, P63, DOI 10.1016/j.jag.2016.02.001
   Eckhardt D, 2019, PLASMA SOURCES SCI T, V28, DOI 10.1088/1361-6595/ab0b1f
   Elrahman S. M. A., 2013, J NET INNOV COMPUT, V1, P332, DOI DOI 10.20943/01201706.4351
   Fakhet Walid, 2017, 2017 International Conference on Internet of Things, Embedded Systems and Communications (IINTEC). Proceedings, P67, DOI 10.1109/IINTEC.2017.8325915
   Fawzy D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217035
   Gao F, 2006, IEEE T GEOSCI REMOTE, V44, P2207, DOI 10.1109/TGRS.2006.872081
   Ghazal T. M., 2022, P 2022 INT C BUS AN, DOI [10.1109/ICBATS54253.2022.9758929, DOI 10.1109/ICBATS54253.2022.9758929]
   Hamdi A, 2022, ARTIF INTELL REV, V55, P1441, DOI 10.1007/s10462-021-09994-y
   Hu YC, 2023, CLUSTER COMPUT, V26, P2913, DOI 10.1007/s10586-022-03751-8
   Husain S., 2017, IOSR Journal of Computer Engineering (IOSR-JCE), P19, DOI DOI 10.9790/0661-1906031925
   Ivashkin V., 2018, ARXIV
   Ju XT, 2021, J HIGH SPEED NETW, V27, P225, DOI 10.3233/JHS-210663
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Kim YH, 2000, FUZZY SET SYST, V111, P215, DOI 10.1016/S0165-0114(97)00409-0
   Kong FY, 2020, MULTIMED TOOLS APPL, V79, P35195, DOI 10.1007/s11042-019-7614-4
   Li JW, 2021, COMPUT IND ENG, V161, DOI 10.1016/j.cie.2021.107671
   Lin TY, 2019, IEEE ACCESS, V7, P158296, DOI 10.1109/ACCESS.2019.2950328
   Long D, 2020, REMOTE SENS ENVIRON, V246, DOI 10.1016/j.rse.2020.111863
   Lu YT, 2019, ENVIRON MONIT ASSESS, V191, DOI 10.1007/s10661-019-7200-2
   Maimaitijiang M, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111599
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Micci-Barreca D., 2001, ACM SIGKDD Explorations Newsletter, V3, P27, DOI DOI 10.1145/507533.507538
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Pérez-Rodríguez M, 2021, FOOD CHEM, V339, DOI 10.1016/j.foodchem.2020.128125
   Quilodrán CS, 2021, SCI TOTAL ENVIRON, V792, DOI 10.1016/j.scitotenv.2021.148312
   Saranya SS, 2022, CMC-COMPUT MATER CON, V70, P1857, DOI 10.32604/cmc.2022.019621
   Saxena R, 2021, WOODSTOCK 18 ACM S N
   Sengül G, 2021, MULTIMED TOOLS APPL, V80, P33527, DOI 10.1007/s11042-021-11105-6
   Shao XF, 2022, J HIGH SPEED NETW, V28, P299, DOI 10.3233/JHS-222003
   Sinde R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051540
   Tandon R., 2012, INT J COMPUTER NETWO, V4, P235, DOI DOI 10.5121/IJCNC.2012.4415
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Wu MQ, 2016, INFORM FUSION, V31, P14, DOI 10.1016/j.inffus.2015.12.005
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yu N, 2023, SOFT COMPUT, V27, P1189, DOI 10.1007/s00500-021-06145-x
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang TH, 2020, BUILD ENVIRON, V175, DOI 10.1016/j.buildenv.2020.106810
   Zhao BX, 2020, IEEE ACCESS, V8, P76632, DOI 10.1109/ACCESS.2020.2989443
   Zhao GZ, 2020, TSINGHUA SCI TECHNOL, V25, P12, DOI 10.26599/TST.2018.9010138
NR 51
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25843
EP 25865
DI 10.1007/s11042-023-16541-0
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001064537600001
DA 2024-07-18
ER

PT J
AU Fu, XF
   Wu, WB
   Omata, M
AF Fu, Xiaofeng
   Wu, Wenbin
   Omata, Masaki
TI Phase driven transformer for micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression recognition; Transformer; Data augmentation; Frequency
   domain
AB Because of the brevity, unconsciousness and subtlety of micro-expression (ME), the scale of ME dataset is not large and the ME recognition (MER) rate is not high. In addition, most methods focus on the extraction of spatial features, but ignore the information of other domains. To solve the above problems, this paper proposes phase driven Transformer (PDT). The PDT generated amplitude and phase information from two networks and fused them for network training. By incorporating image features in the frequency domain, the richness and diversity of features are better increased, enabling the model to extract more effective information and solve the problem of unclear micro-expression features. To address the problem of small sample size, dense relative localization loss is adopted in this paper. The experiments are conducted on three public datasets: SMIC, SAMM, and CASME II. The results demonstrate that the PDT outperforms other methods.
C1 [Fu, Xiaofeng; Wu, Wenbin] Hangzhou Dianzi Univ, Coll Comp Sci & Technol, 1158 2nd St, Hangzhou 310018, Zhejiang, Peoples R China.
   [Omata, Masaki] Univ Yamanashi, Coll Comp Sci & Engn, Takeda St, Kofu, Yamanashi 4000013, Japan.
C3 Hangzhou Dianzi University; University of Yamanashi
RP Fu, XF (corresponding author), Hangzhou Dianzi Univ, Coll Comp Sci & Technol, 1158 2nd St, Hangzhou 310018, Zhejiang, Peoples R China.
EM fuxiaofeng@hdu.edu.cn; wuwenbin@hdu.edu.cn;
   omata@hci.media.yamanashi.ac.jp
FU National Natural Science Foundation of China [61672199]
FX AcknowledgementsThis work was supported by some grants: National Natural
   Science Foundation of China (No.61672199).
CR [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Chen B, 2023, IEEE T MULTIMEDIA, V25, P1345, DOI 10.1109/TMM.2022.3141616
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Franke M., 2009, ELECT TECHNOLOGY ISS, P1
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2237, DOI 10.1145/3394171.3413714
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li XY, 2021, COMPUT VIS MEDIA, V7, P407, DOI 10.1007/s41095-021-0217-9
   Li YT, 2021, NEUROCOMPUTING, V436, P221, DOI 10.1016/j.neucom.2021.01.032
   Li YT, 2021, IEEE T IMAGE PROCESS, V30, P249, DOI 10.1109/TIP.2020.3035042
   Liong ST, 2020, J SIGNAL PROCESS SYS, V92, P705, DOI 10.1007/s11265-020-01523-4
   Liong ST, 2019, IEEE INT CONF AUTOMA, P658, DOI 10.1109/fg.2019.8756567
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2017, LECT NOTES COMPUT SC, V10117, P345, DOI 10.1007/978-3-319-54427-4_26
   Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586
   Liu KH, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116153
   Liu YJ, 2021, IEEE T AFFECT COMPUT, V12, P254, DOI 10.1109/TAFFC.2018.2854166
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Liu YC, 2019, IEEE INT CONF AUTOMA, P631, DOI 10.1109/fg.2019.8756583
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mayya V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P699, DOI 10.1109/ICACCI.2016.7732128
   Nie X, 2021, NEUROCOMPUTING, V427, P13, DOI 10.1016/j.neucom.2020.10.082
   Oh YH, 2016, INT CONF ACOUST SPEE, P1851, DOI 10.1109/ICASSP.2016.7471997
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Reddy SPT, 2019, IEEE IJCNN
   See J, 2019, IEEE INT CONF AUTOMA, P647
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang YH, 2022, PROC CVPR IEEE, P10925, DOI 10.1109/CVPR52688.2022.01066
   Van Quang N., 2019, IEEE INT CONF AUTOMA, DOI [10.1109/FG.2019.8756544, DOI 10.1109/fg.2019.8756544]
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang YD, 2020, IEEE WORLD CONGR SER, P266, DOI [10.1109/SERVICES48979.2020.00059, 10.1007/978-3-030-37731-1_22]
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Xu K, 2020, PROC CVPR IEEE, P1737, DOI 10.1109/CVPR42600.2020.00181
   Yahui L., 2021, Proc. Adv. Neural Inf. Process. Syst., P23818, DOI [10.48550/arXiv.2106.03746, DOI 10.48550/ARXIV.2106.03746]
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 51
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27527
EP 27541
DI 10.1007/s11042-023-16512-5
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600012
DA 2024-07-18
ER

PT J
AU Choudhury, SD
   Bhattacharyya, A
AF Choudhury, Shouvik Datta
   Bhattacharyya, Arindam
TI Generalised curvature estimation using geometric measure theory with a
   feature detection application in computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric analysis; Geometric measure theory; Differential forms
ID GAUSSIAN CURVATURE; SHAPE OPERATORS; CONVERGENCE; MESHES; APPROXIMATION
AB Due to the inherent ambiguity of a polygonal approximation of the surface, it is difficult to compute the major curvatures of a smooth surface with sufficient differentiability when just a polygonal approximation of the surface is given. A variety of techniques-based approaches have been presented in the past for addressing this issue. We examine the challenge of estimating curvature from a smooth surface samples. The definition of the curvature tensor for polyhedral surfaces is derived using the notion of normal cycles. This definition is very direct and novel formula in the spirit of 2003. Our concept goes beyond that of 2003, offering a more solid mathematical underpinning. When applied to a polyhedral approximation of a smooth surface, it produces a reliable and efficient approach for estimating curvature. In addition, we limit the discrepancy between the calculated curvature and the smooth surface curvature for restricted Delaunay triangulations. As a demonstration, we will run feature detection procedures on a 3D model later.
C1 [Choudhury, Shouvik Datta; Bhattacharyya, Arindam] Jadavpur Univ, Dept Math, Kolkata 700032, India.
C3 Jadavpur University
RP Choudhury, SD (corresponding author), Jadavpur Univ, Dept Math, Kolkata 700032, India.
EM shouvikdc8645@gmail.com; aribh22@hotmail.com
CR Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   Amenta N, 2000, P 16 ANN S COMPUTATI, P213
   [Anonymous], 1949, THESIS CALTECH
   Banchoff T. F., 1967, Journal of Differential Geometry, V1, P245, DOI DOI 10.4310/JDG/1214428092
   Berger M, GEOMETRIE DIFFERENTI
   Borrelli V, 2003, COMPUT AIDED GEOM D, V20, P319, DOI 10.1016/S0167-8396(03)00077-3
   Boschiroli M, 2012, GRAPH MODELS, V74, P29, DOI 10.1016/j.gmod.2011.11.002
   Cartan H., COURS CALCUL DIFFERE
   Cazals F., 2003, Symposium on Geometry Processing, P177
   Cohen-Steiner D., 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Desbrun M, DISCRETE DIFFERENTIA
   Edelsbrunner H, 1997, INT J COMPUT GEOM AP, V7, P365, DOI 10.1142/S0218195997000223
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Farin GeraldE., 1991, NURBS for Curve and Surface Design, DOI [10.5555/531858, DOI 10.5555/531858]
   Federer H., 1983, GEOMETRIC MEASURE TH
   Federer H., 1959, Transactions of the American Mathematical Society, V93, P418, DOI [DOI 10.1090/S0002-9947-1959-0110078-1, 10.1090/S0002-9947-1959-0110078-1]
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   FU JHG, 1993, J DIFFER GEOM, V37, P177
   Funfzig C, 2008, P GRAPHICS INTERFACE, P219
   Funke S, 2002, SIAM PROC S, P781
   Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134
   Goldman R, 2005, COMPUT AIDED GEOM D, V22, P632, DOI 10.1016/j.cagd.2005.06.005
   graphics .stanford .edu, About Us
   Grinspun E, 2006, COMPUT GRAPH FORUM, V25, P547, DOI 10.1111/j.1467-8659.2006.00974.x
   Harrison, GAUSS GREEN THEOREM
   Hildebrandt K, 2006, GEOMETRIAE DEDICATA, V123, P89, DOI 10.1007/s10711-006-9109-5
   Hildebrandt K, 2011, COMPUT AIDED GEOM D, V28, P321, DOI 10.1016/j.cagd.2011.05.001
   Ju T, 2002, ACM T GRAPHIC, V21, P339
   Kalogerakis E., 2007, P EUROGRAPHICSSIGGRA, P13
   Kerautret B, 2008, LECT NOTES COMPUT SC, V5358, P710, DOI 10.1007/978-3-540-89639-5_68
   Kolingerová I, 2002, COMPUT GRAPH-UK, V26, P477, DOI 10.1016/S0097-8493(02)00090-0
   Krantz SG., 2008, Geometric Integration Theory, DOI [10.1007/978-0-8176-4679-0, DOI 10.1007/978-0-8176-4679-0]
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Magid E, 2007, COMPUT VIS IMAGE UND, V107, P139, DOI 10.1016/j.cviu.2006.09.007
   Mao ZH, 2011, COMPUT AIDED DESIGN, V43, P1561, DOI 10.1016/j.cad.2011.06.006
   Max N., 1999, Journal of Graphics Tools, V4, P1, DOI 10.1080/10867651.1999.10487501
   Meek DS, 2000, COMPUT AIDED GEOM D, V17, P521, DOI 10.1016/S0167-8396(00)00006-6
   Mesmoudi MM., 2010, INT WORKSH APPL DISC, P28
   Meyer M, 2002, INT WORKSH VIS MATH
   Morgan F., 1987, Geometric measure theory. A beginner's guide
   Morvan, 2008, GEN CURVATURES GEOME, DOI [10.1007/978-3-540-73792-6, DOI 10.1007/978-3-540-73792-6]
   Morvan JM, 2004, DISCRETE COMPUT GEOM, V32, P383, DOI 10.1007/s00454-004-1096-4
   Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354
   Peyré G, 2011, COMPUT SCI ENG, V13, P94, DOI 10.1109/MCSE.2011.71
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Pottmann H, 2007, COMPUT AIDED GEOM D, V24, P428, DOI 10.1016/j.cagd.2007.07.004
   Pottmann H, 2009, COMPUT AIDED GEOM D, V26, P37, DOI 10.1016/j.cagd.2008.01.002
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Simon Leon., Introduction to geometric measure theory
   Steiner J, 1840, GESAMMELTE WERKE, V2, P114
   Su F, 2017, ACTA MATH SCI, V37, P1230, DOI 10.1016/S0252-9602(17)30070-X
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Vasa L, 2016, COMPUT AIDED DESIGN
   Vlachos A., 2001, P 2001 S INTERACTIVE, P159, DOI [DOI 10.1145/364338.364387, 10.1145/364338.364387]
   Whitney H., 2015, Geometric integration theory
   Wintgen P., 1982, J DIFFER GEOM, V21
   Xu GL, 2006, COMPUT AIDED GEOM D, V23, P193, DOI 10.1016/j.cagd.2005.07.002
   ZAHLE M, 1986, ARCH MATH, V46, P557, DOI 10.1007/BF01195026
NR 60
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25415
EP 25434
DI 10.1007/s11042-023-16408-4
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800001
DA 2024-07-18
ER

PT J
AU Guo, Y
   Zhou, YT
   Yang, F
AF Guo, Ya
   Zhou, Yatong
   Yang, Fan
TI UAV scale enhanced cross-modality graph matching net-USCMGM-net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image matching; Cross modality; Unmanned aerial vehicle sensors; Graph
   matching; Convolutional neural network
ID UNMANNED AERIAL VEHICLE; VISUAL NAVIGATION
AB Image matching for cross-modality is always a hotspot and difficulty in the unmanned aerial vehicle (UAV) scene-matching visual navigation. Aiming at the problem of cross-modality image matching of UAV different sensors in different imaging modes, we propose a UAV scale enhanced cross-modality graph matching net-USCMGM-Net, which combines a convolutional neural network (CNN) feature extraction based on a pyramid structure with a graph neural network (GNN) feature matching to achieve better performance of UAV cross-modality matching. First, a convolutional neural network (CNN) based on a scale-enhanced discrete image pyramid model is used to extract the cross-modality image pairs' keypoints, descriptors, and scores. In addition, a scale enhancement module is added to each scale of the pyramid structure to further increase the number of extracted feature points. In the matching stage, the GNN is adapted to match the feature descriptors of the image pair. Finally, the random sample consensus (RANSAC) method based on the affine transform model is used for screening and evaluation of matching feature points. The experimental results on seven groups of UAV cross-modality image pairs are shown. Then, we compare our proposed USCMGM-Net with SIFT+FLANN, CMM-Net, and SuperPoint+SuperGlue image matching methods. Besides, ablation experiments such as SIFT+SuperGlue, and UCMGM-Net methods are used to further analyze the performance of each module of the proposed method. It shows the proposed USCMGM-Net method has better accuracy, robustness, and real-time performance for UAV cross-modality image matching.
C1 [Guo, Ya; Zhou, Yatong; Yang, Fan] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Hebei University of Technology
RP Zhou, YT (corresponding author), Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM 18734166761@163.com; zyt@hebut.edu.cn; yangfan@hebut.edu.cn
RI Yang, Fan/GRJ-6470-2022
FU Special Foundation for Beijing Tianjin Hebei Basic Research Cooperation
   [J210008, H2021202008]; Inner Mongolia Discipline Inspection and
   Supervision Big Data Laboratory [IMDBD202105]
FX This work was supported by the Special Foundation for Beijing Tianjin
   Hebei Basic Research Cooperation (J210008, H2021202008), and the Inner
   Mongolia Discipline Inspection and Supervision Big Data Laboratory
   (IMDBD202105).
CR Alexander C, 2018, INT J APPL EARTH OBS, V72, P86, DOI 10.1016/j.jag.2018.05.024
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Chen H., 2021, P IEEECVF INT C COMP, P6301
   [戴激光 Dai Jiguang], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P746
   Dehkordi RH, 2020, INT J APPL EARTH OBS, V91, DOI 10.1016/j.jag.2020.102147
   Deng L, 2018, ISPRS J PHOTOGRAMM, V146, P124, DOI 10.1016/j.isprsjprs.2018.09.008
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Ferrer-González E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152447
   Gallo E, 2023, AEROSPACE-BASEL, V10, DOI 10.3390/aerospace10030220
   Hai J, 2021, APPL ARTIF INTELL, V35, P1529, DOI 10.1080/08839514.2021.1985799
   Hamylton SM, 2020, INT J APPL EARTH OBS, V89, DOI 10.1016/j.jag.2020.102085
   Jiang XY, 2021, INFORM FUSION, V73, P22, DOI 10.1016/j.inffus.2021.02.012
   [蓝朝桢 Lan Chaozhen], 2021, [测绘学报, Acta Geodetica et Cartographica Sinica], V50, P189
   Lee JJL, 2020, CANCER CYTOPATHOL, V128, P348, DOI 10.1002/cncy.22245
   Li JY, 2020, IEEE T IMAGE PROCESS, V29, P3296, DOI 10.1109/TIP.2019.2959244
   Li R., 2019, GEOM SPATIAL INF TEC, V42, P23
   Li S., 2020, P IEEE CVF C COMP VI, P10196
   Lin WP, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5547689
   Lin YC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242893
   Ling Zhi-gang, 2010, Acta Electronica Sinica, V38, P2892
   Liu HQ, 2019, IEEE ACCESS, V7, P165356, DOI 10.1109/ACCESS.2019.2953539
   Liu W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242912
   Liu YB, 2020, PROC CVPR IEEE, P4462, DOI 10.1109/CVPR42600.2020.00452
   Lu JZ, 2019, IEEE ACCESS, V7, P177474, DOI 10.1109/ACCESS.2019.2958658
   Luo ZX, 2019, PROC CVPR IEEE, P2522, DOI 10.1109/CVPR.2019.00263
   Medley DO, 2020, IEEE T IMAGE PROCESS, V29, P2380, DOI 10.1109/TIP.2019.2948728
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Rocco I, 2022, IEEE T PATTERN ANAL, V44, P1020, DOI 10.1109/TPAMI.2020.3016711
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   [王峰 Wang Feng], 2016, [电子学报, Acta Electronica Sinica], V44, P548
   Wang YX, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3126398
   Wu ZC, 2019, INT J APPL EARTH OBS, V77, P129, DOI 10.1016/j.jag.2018.12.001
   [闫利 Yan Li], 2018, [测绘学报, Acta Geodetica et Cartographica Sinica], V47, P71
   Yan YA, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232753
   [叶沅鑫 Ye Yuanxin], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P268
   Yu DD, 2016, IEEE T BIO-MED ENG, V63, P1653, DOI 10.1109/TBME.2015.2465855
   Zhang HT, 2021, IEEE T NEUR NET LEAR, V32, P5345, DOI 10.1109/TNNLS.2021.3080980
   Zhao D., 2021, P IEEE CVF INT C COM, P3354, DOI DOI 10.48550/ARXIV.2108.00211
   [周微硕 Zhou Weishuo], 2019, [红外技术, Infrared Technology], V41, P561
NR 39
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16103-4
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900004
DA 2024-07-18
ER

PT J
AU Ramakrishnan, B
   Nkandeu, YPK
   Tamba, VK
   Tchamda, AR
   Rajagopal, K
AF Ramakrishnan, Balamurali
   Nkandeu, Yannick Pascal Kamdeu
   Tamba, Victor Kamdoum
   Tchamda, Andre Rodrigue
   Rajagopal, Karthikeyan
TI Image encryption based on S-box generation constructed by using a
   chaotic autonomous snap system with only one equilibrium point
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic snap system; Self-excited and hidden attractors; Coexistence of
   attractors; Hopf bifurcation; Electronic circuit implementation; Image
   encryption based on substitution-box
ID HYPERJERK SYSTEM; HIDDEN ATTRACTOR; CIRCUIT; DESIGN
AB An autonomous chaotic snap system with only one equilibrium point is proposed and analyzed in this paper. Periodic oscillations, self-excited chaotic attractors, hidden chaotic attractors and coexistence of a stable equilibrium point with a hidden chaotic attractor are found during the numerical simulations of the autonomous snap system with hidden and self-excited attractors. The Hopf bifurcation and its first Lyapunov coefficient are derived. The autonomous snap system with hidden and self-excited attractors is implemented in OrCAD-PSpice software to confirm the numerical simulations results. Finally, the chaotic behavior found in autonomous snap system with hidden and self-excited attractors is used as a pseudorandom number sequence (PRNS) in the design of an image encryption and decryption algorithm based on substitution-box (S-box) generation. The proposed image encryption and decryption algorithm provides outstanding results such as a high sensitivity to any bit change, a very large key space of 2(600), S-box time generation of 0.0009 s and the number of pixels change rate (NPCR) and unified average changing intensity (UACI) give a minimum value of 99.64%and 33.58%, respectively just to name a few. The security tests perform witness that proposed image encryption and decryption algorithmis efficient and fast moreover in accordance with the standard needed in multimedia communications.
C1 [Ramakrishnan, Balamurali; Rajagopal, Karthikeyan] Chennai Inst Technol, Ctr Nonlinear Syst, Chennai 600069, Tamilnadu, India.
   [Nkandeu, Yannick Pascal Kamdeu] Univ Yaounde I, HTTTC Higher Tech Teachers Training Coll, Dept Med & Biomed Engn, Signal Image & Syst Lab, POB 886, Ebolowa, Cameroon.
   [Tamba, Victor Kamdoum] Univ Dschang, Dept Telecommun & Network Engn, IUT Fotso Victor Bandjoun, POB 134, Bandjoun, Cameroon.
   [Tchamda, Andre Rodrigue] Univ Dschang, Fac Agron & Agr Sci, Dept Rural Engn, POB 222, Dschang, Cameroon.
   [Rajagopal, Karthikeyan] Chandigarh Univ, Univ Ctr Res & Dev, Dept Elect & Commun Engn, Mohali 140413, Punjab, India.
C3 Chennai Institute of Technology; University of Yaounde I; Universite de
   Dschang; Universite de Dschang; Chandigarh University
RP Tamba, VK (corresponding author), Univ Dschang, Dept Telecommun & Network Engn, IUT Fotso Victor Bandjoun, POB 134, Bandjoun, Cameroon.
EM vkamdoum@gmail.com
RI Rajagopal, Karthikeyan/L-6724-2015
OI Rajagopal, Karthikeyan/0000-0003-2993-7182
FU Center for Nonlinear Systems, Chennai Institute of Technology, India
   [CIT/CNS/2023/Rp-007]
FX AcknowledgementsThis work is partially funded by the Center for
   Nonlinear Systems, Chennai Institute of Technology, India via funding
   number CIT/CNS/2023/Rp-007.
CR Ahmad I, 2018, IEEE ACCESS, V6, P35449, DOI 10.1109/ACCESS.2018.2850371
   Ali TS, 2022, MULTIMED TOOLS APPL, V81, P20585, DOI 10.1007/s11042-022-12268-6
   Alkhayyat A, 2022, J SIGNAL PROCESS SYS, V94, P315, DOI 10.1007/s11265-022-01744-9
   Alshammari BM, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010129
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Bragin VO, 2011, J COMPUT SYS SC INT+, V50, P511, DOI 10.1134/S106423071104006X
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Dudkowski D, 2016, PHYS REP, V637, P1, DOI 10.1016/j.physrep.2016.05.002
   Gong LH, 2022, PHYSICA A, V591, DOI 10.1016/j.physa.2021.126793
   Hayat U, 2021, ARAB J SCI ENG, V46, P8887, DOI 10.1007/s13369-021-05666-9
   Ibrahim S, 2021, INFORM SCIENCES, V558, P246, DOI 10.1016/j.ins.2021.01.014
   Kengne LK, 2021, INT J CIRC THEOR APP, V49, P1470, DOI 10.1002/cta.2968
   Kuznetsov N. V., 2010, IFAC Proc, V43, P29, DOI DOI 10.3182/20100826-3-TR-4016.00009
   Leonov GA, 2015, EUR PHYS J-SPEC TOP, V224, P1421, DOI 10.1140/epjst/e2015-02470-3
   Leonov GA, 2012, PHYSICA D, V241, P1482, DOI 10.1016/j.physd.2012.05.016
   Leonov GA, 2011, PHYS LETT A, V375, P2230, DOI 10.1016/j.physleta.2011.04.037
   MATSUMOTO T, 1984, IEEE T CIRCUITS SYST, V31, P1055, DOI 10.1109/TCS.1984.1085459
   Natiq H, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12360-y
   Nkandeu YK, 2022, MULTIMED TOOLS APPL, V81, P17131, DOI 10.1007/s11042-022-12649-x
   Nkandeu YPK, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00318-y
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Rajagopal K, 2017, CHAOS SOLITON FRACT, V103, P476, DOI 10.1016/j.chaos.2017.07.007
   Ramakrishnan B, 2022, MULTIMED TOOLS APPL, V81, P23819, DOI 10.1007/s11042-022-12400-6
   Schneier B, 1996, APPL CRYPTOGRAPHY PR, V2nd, P572
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Sotomayor J, 2007, COMPUT APPL MATH, V26, P19
   Sotomayor J, 2007, Arxiv, DOI arXiv:0709.3949
   SPROTT JC, 1994, PHYS REV E, V50, pR647, DOI 10.1103/PhysRevE.50.R647
   Vaidyanathan S, 2018, ARCH CONTROL SCI, V28, P239, DOI 10.24425/123458
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Yan WH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111313
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
NR 32
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16367-w
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100004
DA 2024-07-18
ER

PT J
AU Aydin, ZE
   Ozturk, ZK
AF Aydin, Zeliha Ergul
   Ozturk, Zehra Kamisli
TI Filter-based feature selection methods in the presence of missing data
   for medical prediction models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Feature selection; Medical prediction model; Missing
   data imputation
ID MUTUAL INFORMATION; CHAINED EQUATIONS; IMPUTATION
AB Medical prediction models have gained increasing prevalence in recent years due to their potential to enhance patient outcomes, improve healthcare efficiency, and advance public health. Feature selection and missing data imputation play a key role in medical prediction models. This study aims to analyze the effect of the missing data imputation and filter-based feature selection methods combination on medical prediction models to make a general judgment. We use the four well-known missing data imputation methods (K-Nearest Neighbor, Soft-Impute, Multivariate Imputation by Chained Equations (MICE), and Mean), six commonly used filter-based feature selection methods (Fisher Score, Gini Index, Relieff, Chi-square, Random Forest, and Mutual Information) and three different classifiers (K-Nearest Neighbor: KNN, Logistic Regression: LR, and Support Vector Machine: SVM). We perform all combinations of these models on 6 medical datasets in our experiments. According to Friedman statistical test, which combination of missing data imputation and filter-based feature selection methods used did not affect the performance of medical prediction models where LR and SVM classifiers were used. However, Mean & Chi-square, Mean & GiniIndex combinations statistically perform better than SoftImpute & Fisher score combination for the KNN classifier according to Nemenyi post-hoc statistical test. In addition to these findings, our experiments show that Chi-square has the lowest feature selection run time, while the Relieff method has the longest run time. Besides, we show that all classifiers' prediction success with feature selection is better than or equal to without feature selection.
C1 [Aydin, Zeliha Ergul; Ozturk, Zehra Kamisli] Eskisehir Tech Univ, Dept Ind Engn, Eskisehir, Turkiye.
C3 Eskisehir Technical University
RP Aydin, ZE (corresponding author), Eskisehir Tech Univ, Dept Ind Engn, Eskisehir, Turkiye.
EM zergul@eskisehir.edu.tr
OI ERGUL AYDIN, Zeliha/0000-0002-7108-8930
FU Eskisehir Technical University Scientific Research Projects Committee
   [ESTUBAP-20DRP025]
FX AcknowledgementsThis study is supported by Eskisehir Technical
   University Scientific Research Projects Committee (ESTUBAP-20DRP025).
CR Abdulla M, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115902
   Alhassan AM, 2021, IEEE ACCESS, V9, P87310, DOI 10.1109/ACCESS.2021.3088613
   [Anonymous], 2002, STAT ANAL MISSING DA, DOI [DOI 10.1002/9781119013563, 10.1002/9781119013563]
   Azur MJ, 2011, INT J METH PSYCH RES, V20, P40, DOI 10.1002/mpr.329
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bommert A, 2020, COMPUT STAT DATA AN, V143, DOI 10.1016/j.csda.2019.106839
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Colombelli F, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109655
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Darshan SLS, 2018, PROCEDIA COMPUT SCI, V125, P346, DOI 10.1016/j.procs.2017.12.046
   DEMSAR J, 2006, STAT COMP CLASSIFIER, DOI DOI 10.5555/1248547.1248548
   Doquire G, 2012, NEUROCOMPUTING, V90, P3, DOI 10.1016/j.neucom.2012.02.031
   Dua D., 2017, UCI MACHINE LEARNING
   Elter M, 2007, MED PHYS, V34, P4164, DOI 10.1118/1.2786864
   Fernandes K, 2017, LECT NOTES COMPUT SC, V10255, P243, DOI 10.1007/978-3-319-58838-4_27
   Graham JW, 2009, ANNU REV PSYCHOL, V60, P549, DOI 10.1146/annurev.psych.58.110405.085530
   Hapfelmeier A, 2014, COMPUT STAT DATA AN, V80, P129, DOI 10.1016/j.csda.2014.06.017
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Hu Z, 2017, J BIOMED INFORM, V68, P112, DOI 10.1016/j.jbi.2017.03.009
   KIRA K, 1992, MACHINE LEARNING /, P249
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Lee CH, 2017, KIDNEY RES CLIN PRAC, V36, P3, DOI 10.23876/j.krcp.2017.36.1.3
   Lee In-Hee, 2011, J Clin Bioinforma, V1, P11, DOI 10.1186/2043-9113-1-11
   Liu CH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072344
   Maniruzzaman M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0940-7
   Mazumder R, 2010, J MACH LEARN RES, V11, P2287
   Mebane WR, 2011, J STAT SOFTW, V42, P1
   Naheed N, 2020, CMES-COMP MODEL ENG, V125, P1, DOI 10.32604/cmes.2020.011380
   Nematzadeh H, 2022, APPL SOFT COMPUT, V130, DOI 10.1016/j.asoc.2022.109699
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Remeseiro B, 2019, COMPUT BIOL MED, V112, DOI 10.1016/j.compbiomed.2019.103375
   Ren K, 2020, J HYDROL, V586, DOI 10.1016/j.jhydrol.2020.124897
   Rubinsteyn Alex, 2016, fancyimpute: An imputation library for python
   Sánchez-Maroño N, 2007, LECT NOTES COMPUT SC, V4881, P178
   Solorio-Fernández S, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113745
   Stiglic G, 2019, HEALTH INFORM J, V25, P951, DOI 10.1177/1460458217733288
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Van Buuren S., 2018, Flexible imputation of missing data
   Witten IH, 2011, MOR KAUF D, P1
NR 40
TC 2
Z9 2
U1 11
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-15917-6
EA AUG 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000003
DA 2024-07-18
ER

PT J
AU Sharma, S
   Guleria, K
AF Sharma, Shagun
   Guleria, Kalpna
TI A systematic literature review on deep learning approaches for pneumonia
   detection using chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Pneumonia; Machine learning; Deep learning; Convolutional neural
   network; Pre-trained models; Ensemble models
ID PREDICTION
AB As per World Health Organization, in 2019, 2.5 million deaths were reported due to pneumonia, of which 14% were observed among children between 0-5 years of age. Due to the increased mortality rate, it is essential to diagnose pneumonia to avoid the failure of the human body's functioning. Machine and deep learning techniques can be implemented for pneumonia prediction, but deep learning is preferred over machine learning due to its applicability of better performance outcomes along with an automatic feature extraction from the dataset. This systematic literature review meticulously discusses a wide range of techniques for detecting pneumonia using deep learning, including convolutional neural networks, pre-trained models, and ensemble models. The review provides an in-depth illustration of architecture and working process and evaluates the effectiveness of these models in solving various medical domain challenges. It presents a summarization and analytical discussion on convolutional neural networks-based, pre-trained, and ensemble models offering a deep insight into several factors, including performance measures, hyperparameters, and fine-tuning of the models. This meta-analysis also discusses the highly robust and outperforming ensemble pneumonia detection models. Furthermore, the review highlights various research gaps in the existing models, and probable solutions, enabling a deeper understanding of their performance and suitability for pneumonia detection tasks.
C1 [Sharma, Shagun; Guleria, Kalpna] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Guleria, K (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM guleria.kalpna@gmail.com
RI Sharma, Shagun/JCD-4569-2023; Guleria, Kalpna/ABK-6340-2022
OI Guleria, Kalpna/0000-0003-2359-8351; Sharma, Shagun/0000-0002-3616-7940
CR Ahmad J, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19010480
   Alhasan M, 2021, COMPUT MED IMAG GRAP, V91, DOI 10.1016/j.compmedimag.2021.101933
   Allegra A, 2022, CANCERS, V14, DOI 10.3390/cancers14030606
   Alqudah AM, 2021, J MED BIOL ENG, V41, P599, DOI 10.1007/s40846-021-00631-1
   Alyasseri ZAA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12759
   [Anonymous], 2018, NIH CHEST XRAY MULT
   Asnaoui Khalid El., 2021, ARTIF INTELL, P257, DOI [DOI 10.1007/978-3-030-74575-214, DOI 10.1007/978-3-030-74575-2_14]
   Basheera S, 2020, COMPUT MED IMAG GRAP, V81, DOI [10.1016/j.compmedimg.2020.101713, 10.1016/j.compmedimag.2020.101713]
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Chen ZH, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102014
   DIEHR P, 1984, J CHRON DIS, V37, P215, DOI 10.1016/0021-9681(84)90149-8
   Ding K., 2022, arXiv
   España PP, 2006, AM J RESP CRIT CARE, V174, P1249, DOI 10.1164/rccm.200602-177OC
   Frondelius T, 2022, J CRIT CARE, V67, P44, DOI 10.1016/j.jcrc.2021.10.001
   Gayathri JL, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105134
   Gour M, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105047
   Guleria K., 2022, Meas Sensors, V24, DOI DOI 10.1016/J.MEASEN.2022.100482
   Gunasekeran DV, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00412-9
   Haghanifar A, 2022, MULTIMED TOOLS APPL, V81, P30615, DOI 10.1007/s11042-022-12156-z
   Hammoudi K, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01745-4
   Hasan MDK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9929274
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   Hasoon JN, 2021, RESULTS PHYS, V31, DOI 10.1016/j.rinp.2021.105045
   Huang ZX, 2021, APPL INTELL, V51, P2838, DOI 10.1007/s10489-020-01965-0
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Ieracitano C, 2022, NEUROCOMPUTING, V481, P202, DOI 10.1016/j.neucom.2022.01.055
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Jakhar K., 2018, 2018 4 INT C COMP CO, P1, DOI [10.1109/ccaa.2018.8777571, DOI 10.1109/CCAA.2018.8777571]
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kareem Amer, 2022, Human-Centric Intelligent Systems, V2, P31, DOI 10.1007/s44230-022-00002-2
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kundu R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256630
   Li YY, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103898
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Majeed A, 2022, MULTIMED TOOLS APPL, V81, P43163, DOI 10.1007/s11042-022-13147-w
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Mijwil M.M., 2022, ARTIF INTELL, V10, P1, DOI DOI 10.24203/AJPNMS.V10I1.6961
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Mohammed MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1307944
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Mrad H, 2021, CHESTX RAY8 DATASET
   Nagi AT, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136364
   Padash S, 2022, PEDIATR RADIOL, V52, P1568, DOI 10.1007/s00247-022-05368-w
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Rehman MU, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020461
   Saraiva AA, 2019, BIOIMAGING: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2, P112, DOI 10.5220/0007404301120119
   Shah Aakash, 2022, Chronic Dis Transl Med, V8, P154, DOI 10.1002/cdt3.17
   Sharma R, 2021, INT CO SIG PROC COMM, P377, DOI 10.1109/ICSPC51351.2021.9451800
   Sharma Shagun, 2023, Procedia Computer Science, P357, DOI 10.1016/j.procs.2023.01.018
   Sharma Shagun, 2022, 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P1733, DOI 10.1109/ICACITE53722.2022.9823516
   Sharma S., 2022, Measurement: Sensors, V24, P100506, DOI [10.1016/j.measen.2022.100506, DOI 10.1016/J.MEASEN.2022.100506]
   Sharma S., 2021, Journal of Physics: Conference Series, V2089, DOI [10.1088/1742-6596/2089/1/012003, DOI 10.1088/1742-6596/2089/1/012003]
   Sim JZT, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010175
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P1743, DOI 10.1007/s11042-021-11409-7
   Sirazitdinov I, 2019, COMPUT ELECTR ENG, V78, P388, DOI 10.1016/j.compeleceng.2019.08.004
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Stokes K, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103325
   Togaçar M, 2020, IRBM, V41, P212, DOI 10.1016/j.irbm.2019.10.006
   Varshni Dimpy, 2019, 2019 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT), DOI 10.1109/ICECCT.2019.8869364
   Wu N, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3494523
   Yasar H, 2021, MULTIMED TOOLS APPL, V80, P5423, DOI 10.1007/s11042-020-09894-3
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
   Zhang CM, 2021, J IND INF INTEGR, V23, DOI 10.1016/j.jii.2021.100224
   Zhang FJ, 2021, MEDICINE, V100, DOI 10.1097/MD.0000000000026855
NR 66
TC 5
Z9 5
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16419-1
EA AUG 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400003
DA 2024-07-18
ER

PT J
AU Bodini, A
   Manohar, A
   Colecchia, F
   Harrison, D
   Garaj, V
AF Bodini, Aimone
   Manohar, Arthi
   Colecchia, Federico
   Harrison, David
   Garaj, Vanja
TI Envisioning the future of virtual production in filmmaking: A remote
   co-design study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-design; Remote workshop; Audiovisual production; Virtual reality;
   Augmented reality
AB Virtual Production is a new process in the audiovisual industry, taking advantage of emerging technologies and attracting a significant degree of interest in academic and industrial research. This article documents a research process focusing on co-design of innovative solutions for Virtual Production relying on immersive technologies. Two remote collaborative workshops were organized involving audiovisual professionals covering different roles in different phases of the making process of audiovisual production. A range of innovative design concepts was generated as part of the research following group-based iterative discussion and evaluation. The study has contributed a set of innovative design solutions in relation to applications of immersive technologies in the audiovisual industry. The authors argue that the methods adopted have the potential to serve as a blueprint for design and implementation of future remote collaborative co-design processes in relation to audiovisual studies and, more generally, across disciplinary boundaries.
C1 [Bodini, Aimone; Manohar, Arthi; Colecchia, Federico; Harrison, David; Garaj, Vanja] Brunel Univ London, Brunel Design Sch, London, England.
C3 Brunel University
RP Bodini, A (corresponding author), Brunel Univ London, Brunel Design Sch, London, England.
EM aimone.bodini@brunel.ac.uk
FU StoryFutures: Gateway Cluster Partnership for Audiovisual Digital
   Creativity [AH/S002758/1]; Arts and Humanities Research Council (AHRC),
   UK; UUI [AH/S002758/1] Funding Source: UKRI
FX The authors wish to thank all the participants who took part in the
   co-design workshops and the Brunel Design School staff for their support
   throughout the study. This work was supported by StoryFutures: Gateway
   Cluster Partnership for Audiovisual Digital Creativity (AH/S002758/1), a
   research and development grant by the Arts and Humanities Research
   Council (AHRC), UK.All the diagrams were created by the authors
CR Ali A.X., 2021, Interactions, V28, P82, DOI [10.1145/3447790, DOI 10.1145/3447790]
   Avital M., 2011, Open Design Now: Why Design Cannot Remain Exclusive, P48
   Bakirlioglu Y., 2020, Interactions, V27, P20, DOI DOI 10.1145/3414462
   Bandura A., 1986, Social foundations of thought and action: A social cognitive theory, V1986, P23
   Bennett J, 2021, VIRTUAL PRODUCTION G
   Bertran FA, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3506698
   Blomkamp E., 2018, Routledge Handbook of Policy Design, P59
   Bodini A, 2023, MULTIMED TOOLS APPL, V82, P12379, DOI 10.1007/s11042-022-13680-8
   Boland J, 2022, PUBLIC HEALTH RES PR, V32, DOI 10.17061/phrp31232112
   Brüggen E, 2009, INT J MARKET RES, V51, P363, DOI 10.2501/S1470785309200608
   Bryant L, 2024, DISABIL REHABIL-ASSI, V19, P90, DOI 10.1080/17483107.2022.2063423
   Daniels N, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919885786
   De Goussencourt T, 2015, INT BROADC CONV AMST
   Di Stefano G., 2015, Academy of Management Proceedings, V2015, P12709, DOI [10.5465/ambpp.2015.12709abstract, DOI 10.5465/AMBPP.2015.12709ABSTRACT]
   Ehn P., 2017, PDC 17 PART DES C, P41
   Flynn R, 2018, INT J QUAL METH, V17, DOI 10.1177/1609406917750781
   Forrestal S.G., 2015, SURVEY PRACTICE, V8, P1, DOI DOI 10.29115/SP-2015-0015
   Giardina C, 2019, LION KING VFX TEAM O
   Helzle V, 2015, DIGITAL REPRESENTATI, P347
   Hurley E, 2021, AUSTRALAS MARK J, V29, P66, DOI 10.1177/1839334921998541
   Kite James, 2017, F1000Res, V6, P122, DOI 10.12688/f1000research.10427.1
   Lin IS, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284424
   Lupton D., 2021, Doing Fieldwork in a Pandemic" (July 5
   Mares J, 2014, TRACTION STARTUP GUI
   Meroni A., 2018, Massive Codesign. A Proposal for a Collaborative Design Framework, V1st edn
   Muender T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188612
   Muller M., 1993, PARTICIPATORY DESIGN, P211
   Muller MJ, 2012, HUM FACTORS ERGON, P1125
   Netflix Studios, 2022, WHAT IS VIRT PROD
   Newton C, 2022, VERGE
   QSR International, 2023, NVIVO12
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Ramesh Aditya, 2022, Hierarchical text-conditional image generation with clip latents
   Rayo Michael F, 2018, Proc Int Symp Hum Factors Ergon Healthc, V7, P1, DOI 10.1177/2327857918071001
   Rijn H., 2008, Proceedings of the Tenth Anniversary Conference on Participatory Design, P178
   Saharia C., 2022, Advances in Neural Information Processing Systems, V35, P36479
   Sanders E., 2008, CoDesign, V4, P5, DOI DOI 10.1080/15710880701875068
   Sanders E.B.-N., 2010, P 11 BIENNIAL PARTIC, V10, P195, DOI [10.1145/1900441.1900476, DOI 10.1145/1900441.1900476]
   Seymour M, 2020, ART LED WALL VIRTUAL
   Sleeswijk-Visser F, 2009, THESIS DELFT U
   Slingerland G, 2022, COMPUT SUPP COOP W J, V31, P669, DOI 10.1007/s10606-022-09438-3
   Spielmann S, 2018, ACM SIGGRAPH 2018 EM
   Ssozi-Mugarura F, 2017, CODESIGN, V13, P110, DOI 10.1080/15710882.2017.1310904
   Steen M, 2011, INT J DES, V5, P53
   Tactivos Inc, 2023, MURAL
   Thacker J, 2012, SEARCH VIRTUAL PRODU
   Trint, 2023, ABOUT US
   Unreal Engine, 2022, EP GAM
   Zhang ZH, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14116716
   Zimmer C, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3132805
   Zoom Video Communications Inc, 2023, ZOOM M CHAT VERS 5 7
NR 51
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19015
EP 19039
DI 10.1007/s11042-023-16308-7
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900009
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, R
   Zhou, MQ
   Zhang, D
   Yan, YH
   Huo, QS
AF Li, Rui
   Zhou, Mingquan
   Zhang, Dan
   Yan, Yuhuan
   Huo, Qingsong
TI A survey of multi-source image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-source image fusion; Transform domain; Spatial domain; Deep
   Learning; Evaluation methodology
ID MULTI-FOCUS IMAGE; QUALITY ASSESSMENT; VISIBLE IMAGES; DENSE SIFT;
   PERFORMANCE; DECOMPOSITION; SEGMENTATION; TRANSFORM; NETWORK; ALGORITHM
AB Multi-source image fusion has become an important and useful new technology in the image understanding and computer vision fields. The purpose of multi-source image fusion is to intelligently synthesize image data from multiple information sources, to generate more accurate and reliable descriptions and judgments than single-sensor data and to make fused images more consistent with human and machine visual features. Although there are many studies on multi-source image fusion, few papers summarize both theoretical and experimental aspects. This paper reviews, classifies and discusses the more advanced multi-source image fusion methods. We comprehensively introduce existing image fusion evaluation methods and compare them based on different standards. The representative algorithms are evaluated by using 12 famous target fusion metrics, and the advantages and disadvantages of each type are discussed in detail. Through research, the challenges encountered in this field and possible future research directions and development prospects are discussed.
C1 [Li, Rui; Zhou, Mingquan; Zhang, Dan; Yan, Yuhuan; Huo, Qingsong] Qinghai Normal Univ, Sch Comp Coll, West Wu Si Rd, Xining 810000, Qinghai, Peoples R China.
   [Li, Rui] Nanyang Inst Technol, Sch Comp & Software, Nanyang 473000, Henan, Peoples R China.
   [Zhou, Mingquan; Zhang, Dan; Yan, Yuhuan; Huo, Qingsong] Qinghai Normal Univ, Acad Plateau Sci & Sustainabil Dev, West Wu Si Rd, Xining 810000, Qinghai, Peoples R China.
C3 Qinghai Normal University; Nanyang Institute of Technology; Qinghai
   Normal University
RP Zhou, MQ (corresponding author), Qinghai Normal Univ, Sch Comp Coll, West Wu Si Rd, Xining 810000, Qinghai, Peoples R China.; Zhou, MQ (corresponding author), Qinghai Normal Univ, Acad Plateau Sci & Sustainabil Dev, West Wu Si Rd, Xining 810000, Qinghai, Peoples R China.
EM 3162067@nyist.edu.cn; 531599690@qq.com; 358774518@qq.com;
   2314305749@qq.com; 2399662@qq.com
RI ZHOU, MING/JVP-2920-2024
CR Adebisi OA., 2022, INT J ADV COMPUTER R, V03, P19, DOI [10.1007/978-981-16-8150-9_2, DOI 10.1007/978-981-16-8150-9_2]
   Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Ahmed ST, 2020, PROCEDIA COMPUT SCI, V167, P2617, DOI 10.1016/j.procs.2020.03.323
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Ali H, 2015, ARAB J SCI ENG, V40, P3173, DOI 10.1007/s13369-015-1791-x
   Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Aymaz S, 2019, INFORM FUSION, V45, P113, DOI 10.1016/j.inffus.2018.01.015
   Bavirisetti DP, 2018, AIN SHAMS ENG J, V9, P1103, DOI 10.1016/j.asej.2016.06.011
   Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Bhalla K, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103485
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chai Y, 2011, OPT COMMUN, V284, P4376, DOI 10.1016/j.optcom.2011.05.046
   Chaudhary V, 2018, SIGNAL IMAGE VIDEO P, V12, P271, DOI 10.1007/s11760-017-1155-y
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Chenzhong gao, 2021, Journal of Beijing Institute of Technology, P113, DOI 10.15918/j.jbit1004-0579.2021.016
   Deng X, 2021, IEEE T IMAGE PROCESS, V30, P3098, DOI 10.1109/TIP.2021.3058764
   Dong ZK, 2018, NEUROCOMPUTING, V308, P172, DOI 10.1016/j.neucom.2018.04.066
   Duan JW, 2018, NEUROCOMPUTING, V318, P43, DOI 10.1016/j.neucom.2018.08.024
   Duan JW, 2016, APPL OPTICS, V55, P10352, DOI 10.1364/AO.55.010352
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   Guo Z, 2018, I S BIOMED IMAGING, P903, DOI 10.1109/ISBI.2018.8363717
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hayat N, 2019, J VIS COMMUN IMAGE R, V62, P295, DOI 10.1016/j.jvcir.2019.06.002
   Hill P., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P487
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Jin SP, 2022, AAAI CONF ARTIF INTE, P1104
   Karakaya D, 2021, PAS MEF MULTIEXPOSUR, P1515, DOI [10.48550/arXiv.2105.11809, DOI 10.48550/ARXIV.2105.11809]
   Lai R, 2019, IEEE ACCESS, V7, P114385, DOI 10.1109/ACCESS.2019.2935006
   Lee SH, 2018, IEEE IMAGE PROC, P1737, DOI 10.1109/ICIP.2018.8451153
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li H., 2018, ARXIV, V5, P6, DOI [10.48550/arXiv.1804.08992, DOI 10.48550/ARXIV.1804.08992]
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P5805, DOI 10.1109/TIP.2020.2987133
   Li H, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103039
   Li H, 2018, IEEE IMAGE PROC, P1723, DOI 10.1109/ICIP.2018.8451689
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li JJ, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4179397
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li MJ, 2014, APPL MECH MATER, V525, P715, DOI 10.4028/www.scientific.net/AMM.525.715
   Li QL, 2021, IEEE SENS J, V21, P7458, DOI 10.1109/JSEN.2019.2921803
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu W, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107252
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2014, COMM COM INF SC, V484, P372
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   [刘羽 Liu Yu], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1435
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2018, MULTIMED TOOLS APPL, V77, P22407, DOI 10.1007/s11042-018-5985-6
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, CHIN CONTR CONF, P5464, DOI 10.23919/ChiCC.2017.8028223
   Ma KD, 2020, IEEE T IMAGE PROCESS, V29, P2808, DOI 10.1109/TIP.2019.2952716
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Manu CS, 2015, 2015 8 INT C ADV PAT, DOI [10.1109/icapr.2015.7050690, DOI 10.1109/ICAPR.2015.7050690]
   med.harvard.edu, WHOL BRAIN ATL HARV
   Muthiah MA, 2020, P 2019 2 INT C POWER, P175, DOI [10.1109/ICPEDC47771.2019.9036665, DOI 10.1109/ICPEDC47771.2019.9036665]
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Piella G, 2009, INT J COMPUT VISION, V83, P1, DOI 10.1007/s11263-009-0206-4
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Qiu CH, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/9308745
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Qu LH, 2022, AAAI CONF ARTIF INTE, P2126
   Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Shao ZF, 2018, IEEE J-STARS, V11, P1656, DOI 10.1109/JSTARS.2018.2805923
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Song X, 2019, LECT NOTES ARTIF INT, V11377, P1, DOI 10.1007/978-3-030-20984-1_1
   Stathaki T, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1
   Stimpel B, 2020, IEEE T MED IMAGING, V39, P1703, DOI 10.1109/TMI.2019.2955184
   Thouheed Ahmed Syed, 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P723, DOI 10.1007/978-981-13-0617-4_68
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Toet A, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.72
   Wang L, 2020, IEEE INT C BIOINFORM, P2538, DOI 10.1109/BIBM49941.2020.9313288
   Wang Q, 2005, PHYSICA D, V200, P287, DOI 10.1016/j.physd.2004.11.001
   Wang QT, 2020, IEEE T CIRC SYST VID, V30, P2418, DOI 10.1109/TCSVT.2019.2919310
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZB, 2019, MULTIMEDIA SYST, V25, P323, DOI 10.1007/s00530-019-00608-w
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu H, 2020, IEEE T IMAGE PROCESS, V29, P7203, DOI 10.1109/TIP.2020.2999855
   Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan X, 2018, RES ALGORITHM MULTIS
   Yang B, 2015, OPTIK, V126, P4460, DOI 10.1016/j.ijleo.2015.08.023
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang Y, 2018, IEEE SIGNAL PROC LET, V25, P1885, DOI 10.1109/LSP.2018.2877893
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang CY, 2015, J ALGORITHMS COMPUT, V9, P303
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang LX, 2020, RES PIXEL LEVEL FAST, P06
   Zhang XC, 2021, INFORM FUSION, V74, P111, DOI 10.1016/j.inffus.2021.02.005
   Zhang XC, 2022, IEEE T PATTERN ANAL, V44, P4819, DOI 10.1109/TPAMI.2021.3078906
   Zhang YX, 2019, SIGNAL IMAGE VIDEO P, V13, P727, DOI 10.1007/s11760-018-1402-x
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFRARED PHYS TECHN, V83, P227, DOI 10.1016/j.infrared.2017.05.007
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao C, 2021, NEURAL COMPUT APPL, V33, P6595, DOI 10.1007/s00521-020-05421-5
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhou ZQ, 2016, APPL OPTICS, V55, P6480, DOI 10.1364/AO.55.006480
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
   [左一帆 Zuo Yifan], 2023, [中国图象图形学报, Journal of Image and Graphics], V28, P102
NR 124
TC 2
Z9 2
U1 23
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18573
EP 18605
DI 10.1007/s11042-023-16071-9
EA JUL 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700013
DA 2024-07-18
ER

PT J
AU Karmakar, A
   Ghosh, P
   Banerjee, PS
   De, DBS
   Pande, A
AF Karmakar, Amiya
   Ghosh, Pritam
   Banerjee, Partha Sarathi
   De, Debashis
   Pande, Arindam
TI MediChain: Medical data fusion using blockchain integrated elastic
   storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Consumer Medical Things; Cryptography; Elastic Storage
AB The Internet of Medical Things (IoMT) consists of interconnected bio-sensor-based health devices. Large numbers of medical devices are supposed to generate a high amount of real-time health data. Therefore, secure and adaptive storage of critical health information is crucial for successfully operating the IoMT architecture. To this end, we propose MediChain, a blockchain-based storage efficient framework that uses blockchain to maintain the integrity, privacy, and confidentiality of critical medical data shared by the bio-sensor devices attached to the consumers. The proposed model also explores Elastic Data Storage (EDS) with the DoD 5220.22-M-ECE technique to achieve storage efficiency and sustainability. The EDS method efficiently removes historical data to observe sustainable traffic adaptive expansion and contraction of storage space. MediChain follows a cloud-native approach that ensures the high availability of close to 99% and durability of critical information to both the consumer and the user. The proposed model is implemented in a lab environment, and its effectiveness is compared empirically with other state-of-art models. MediChain outperforms other models in terms of identity preservation, increasing storage efficiency by almost 25-30%, and sustainability.
C1 [Karmakar, Amiya; De, Debashis] Maulana Abul Kalam Azad Univ Technol, Ctr Mobile Cloud Comp, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
   [Ghosh, Pritam] Iswar Chandra Vidyasagar Polytech, Dept Comp Sci & Technol, Jhargram, West Bengal, India.
   [Banerjee, Partha Sarathi] Kalyani Govt Engn Coll, Dept Informat Technol, Kalyani, West Bengal, India.
   [Pande, Arindam] Med Superspecialty Hosp, Mukundapur Kolkata, India.
C3 Maulana Abul Kalam Azad University of Technology; Kalyani Government
   Engineering College
RP Karmakar, A (corresponding author), Maulana Abul Kalam Azad Univ Technol, Ctr Mobile Cloud Comp, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
EM amiyakarmakar.ak@gmail.com; ghoshpritam25@gmail.com;
   psbanerjee.kgec@gmail.com; debashis.de@makautwb.ac.in;
   drapande@gmail.com
RI Banerjee, Partha (Pat)/KAL-7347-2024
CR Al-Zubaidie M, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15010152
   Al-Zubaidie M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062007
   Berdik D, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102397
   Chen Z, 2021, FUTURE GENER COMP SY
   Fang HS, 2021, J MED INTERNET RES, V23, DOI 10.2196/25094
   Ferrag M. A., 2021, IEEE Internet of Things J., P1
   Han Y, 2022, INT J ENV RES PUBLIC, V19
   Irannezhad E, 2023, MARIT POLICY MANAG, V50, P428, DOI 10.1080/03088839.2021.1930223
   Jayaprakash Varsha, 2022, Proceedings of International Conference on Network Security and Blockchain Technology: ICNSBT 2021. Lecture Notes in Networks and Systems (481), P225, DOI 10.1007/978-981-19-3182-6_18
   Khan S, 2021, IEEE CONSUM ELECTR M, V1-1
   Khatoon A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010094
   Liu XG, 2019, IEEE ACCESS, V7, P118943, DOI 10.1109/ACCESS.2019.2937685
   Nazarenko L, 2021, ZAMM-Z ANGEW MATH ME, V101, DOI 10.1002/zamm.202100005
   Ray PP, 2021, IEEE SYST J, V15, P134, DOI 10.1109/JSYST.2020.2968614
   Shi SY, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101966
   Singh SK, 2023, INFORM FUSION, V90, P233, DOI 10.1016/j.inffus.2022.09.027
   Swathi P., 2019, 2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)
   Tan L, 2022, IEEE T NETW SCI ENG, V9, P271, DOI 10.1109/TNSE.2021.3101842
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Tsai CW, 2024, IEEE CONSUM ELECTR M, V13, P52, DOI [10.1080/17538157.2021.2007930, 10.1109/MCE.2021.3076611]
   Yang J, 2022, IEEE T SMART GRID, V1-1
   Zhang L, 2021, SECURE EFFICIENT DAT
NR 22
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17873
EP 17895
DI 10.1007/s11042-023-16064-8
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000006
DA 2024-07-18
ER

PT J
AU Sheela, SJ
   Suresh, KV
AF Sheela, S. J.
   Suresh, K. V.
TI Real time region of interest based chaotic image cryptosystem for IoT
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; ROI; YOLOv3; MHM; Object detection; Real time image encryption
ID ENCRYPTION
AB Recently, internet of things (IoT) is extensively used in wide applications like industry, e-healthcare, agriculture to send images through internet for the cloud storage. However, these images should be secured before the transmission. In this context, a novel cryptosystem for region of interest protection of images is proposed in this article. The proposed cryptosystem employs You Only Look Once v3 (YOLOv3) to detect regions of interest (ROI) in the original image and a new row column shift (RCS) image encryption algorithm based on two dimensional modified Henon map (2D-MHM) in order to obtain encrypted object image. A series of analyses are carried out to validate the proposed cryptosystem which includes histogram analysis, correlation coefficient analysis, information entropy analysis etc. The experimental results reveal that the ROI based image encryption algorithm shows strong performance with respect to security. Moreover, it reduces the time and computational complexity when compared to full encryption scheme.
C1 [Sheela, S. J.; Suresh, K. V.] Siddaganga Inst Technol, Dept ECE, Tumakuru 572103, Karnataka, India.
C3 Siddaganga Institute of Technology
RP Sheela, SJ (corresponding author), Siddaganga Inst Technol, Dept ECE, Tumakuru 572103, Karnataka, India.
EM sheeladinu@sit.ac.in; sureshkvsit@sit.ac.in
OI Sheela, S. J./0000-0001-6793-1182
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Asgari-Chenaghlu M, 2021, INFORM SCIENCES, V542, P212, DOI 10.1016/j.ins.2020.07.007
   Ghanim ZN, 2022, COGENT ENG, V9, DOI 10.1080/23311916.2022.2026555
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Hosny KM., 2020, MULTIMEDIA SECURITY
   imageprocessingplace.c, US
   Jawad LM., 2015, RES J APPL SCI ENG T, V9, P969, DOI [10.19026/rjaset.9.2590, DOI 10.19026/RJASET.9.2590]
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Murali P, 2023, VISUAL COMPUT, V39, P1057, DOI 10.1007/s00371-021-02384-z
   Nykvist C, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4327
   Raj MG, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.300824
   Ramacharya BP, 2023, EVOL INTELL, V16, P667, DOI 10.1007/s12065-021-00693-9
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   sipi.usc.edu, US
   Song W, 2022, NEURAL COMPUT APPL, V34, P5743, DOI 10.1007/s00521-021-06725-w
   Xiao D, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501935
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 28
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16161
EP 16177
DI 10.1007/s11042-023-16093-3
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600007
DA 2024-07-18
ER

PT J
AU Biswas, C
   Dutta, R
   Sarkar, S
AF Biswas, Chinmoy
   Dutta, Ratna
   Sarkar, Sumanta
TI An efficient post-quantum secure dynamic EPID signature scheme using
   lattices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Post-quantum cryptography; Lattice-based signature; Group signature;
   Short integer solution problem; Anonymous attestation
ID ZERO-KNOWLEDGE
AB Enhanced Privacy ID (EPID) signatures can be viewed as a direct anonymous attestation mechanism with expanded revocation capabilities. When the device's private key is unknown, the revocation manager can revoke a device based on its signatures. Making these systems post-quantum secure is of great importance due to its widespread application in real-world systems. Boneh et al. first propose two post-quantum EPID signature schemes based on symmetric primitives only. In this work, we propose an EPID signature scheme based on la ttices. To the best of our knowledge, our EPID signature scheme based on lattices is the first strong post-quantum variant of EPID signature scheme which achieves security based on the hardness of standard short integer solution (SIS) problem. Our construction employs an updatable Merkle tree accumulator which provides us the flexibility that our EPID signature scheme supports dynamically joining or revoking of any group members at any time. We provide an estimated efficiency comparison of our EPID signature with the existing similar schemes and we observe that our scheme is comparable with the existing schemes despite the usage of strong post-quantum variant and enjoying post-quantum security.
C1 [Biswas, Chinmoy] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttaranchal, India.
   [Dutta, Ratna] Indian Inst Technol Kharagpur, Dept Math, Kharagpur 721302, W Bengal, India.
   [Sarkar, Sumanta] Univ Warwick, Dept Comp Sci, Coventry, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur; University of
   Warwick
RP Biswas, C (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttaranchal, India.
EM chinmoy88biswas@gmail.com
OI Biswas, Chinmoy/0000-0002-4497-4144
CR Albrecht MR, 2015, LECT NOTES COMPUT SC, V9056, P430, DOI 10.1007/978-3-662-46800-5_17
   Ateniese G, 2003, LECT NOTES COMPUT SC, V2357, P183
   Ateniese G, 2000, LECT NOTES COMPUT SC, V1880, P255
   Backes M, 2008, P IEEE S SECUR PRIV, P202, DOI 10.1109/SP.2008.23
   Bellare M, 2003, LECT NOTES COMPUT SC, V2656, P614
   Boneh Dan, 2019, Topics in Cryptology - CT-RSA 2019. The Cryptographers Track at the RSA Conference 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11405), P251, DOI 10.1007/978-3-030-12612-4_13
   Boneh D, 2004, LECT NOTES COMPUT SC, V3152, P41, DOI 10.1007/978-3-540-28628-8_3
   Boneh D., 2004, CCS 04, P168
   Brickell E., 2009, IACR CRYPTOLOGY EPRI, V2009, P95
   Brickell E, 2008, LECT NOTES COMPUT SC, V4968, P166
   Brickell E, 2007, WPES'07: PROCEEDINGS OF THE 2007 ACM WORKSHOP ON PRIVACY IN ELECTRONIC SOCIETY, P21
   Camenisch J, 2002, LECT NOTES COMPUT SC, V2442, P61
   Camenisch J, 1997, LECT NOTES COMPUT SC, V1294, P410
   Costan V., 2016, IACR Cryptol. ePrint Arch, DOI DOI 10.1159/000088809
   Fiat Amos., 1986, CRYPTO, V263, P186
   Fouque P.-A., 2018, P NISTS POSTQUANTUM, V36, P5
   Giacomelli I, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P1069
   Goldreich O., 2009, FDN CRYPTOGRAPHY, V2
   Goldreich O., 1996, IACR Cryptol. ePrint Arch, V1996, P9
   Gordon SD, 2010, LECT NOTES COMPUT SC, V6477, P395, DOI 10.1007/978-3-642-17373-8_23
   Ishai Y, 2009, SIAM J COMPUT, V39, P1121, DOI 10.1137/080725398
   Kawachi A, 2008, LECT NOTES COMPUT SC, V5350, P372, DOI 10.1007/978-3-540-89255-7_23
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ling S, 2015, LECT NOTES COMPUT SC, V9020, P427, DOI 10.1007/978-3-662-46447-2_19
   Ling S, 2013, LECT NOTES COMPUT SC, V7778, P107, DOI 10.1007/978-3-642-36362-7_8
   Micciancio Daniele, 2011, Post-quantum Cryptography, P713, DOI 10.1007/978-1-4419-5906-5417
   Peikert C, 2014, FOUND TRENDS THEOR C, V10, P283, DOI 10.1561/0400000074
   San Ling, 2017, Applied Cryptography and Network Security. 15th International Conference, ACNS 2017. Proceedings: LNCS 10355, P293, DOI 10.1007/978-3-319-61204-1_15
   Stern J, 1996, IEEE T INFORM THEORY, V42, P1757, DOI 10.1109/18.556672
NR 31
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13791
EP 13820
DI 10.1007/s11042-023-15737-8
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700001
DA 2024-07-18
ER

PT J
AU Chandana, MS
   Rao, KR
   Reddy, BNK
AF Chandana, M. Sree
   Rao, K. Raghava
   Reddy, B. Naresh Kumar
TI Developing an adaptive active sleep energy efficient method in
   heterogeneous wireless sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive Active Sleep Energy Efficient Method (AASEEM); Data
   aggregation; Energy efficiency; Heterogeneity; Reliability; Network
   optimization
ID PROTOCOL
AB The development of an energy-efficient wireless sensor network is a difficult problem since batteries are used to energize the sensor nodes. In certain circumstances, charging a battery is extremely difficult or even impossible. If the heterogeneity of sensor nodes is not correctly used, it can result in unequal energy consumption and lowering network performance. By combining power control and data aggregation, clustering has the ability to reduce energy consumption and extend network life. Many routing methods have been suggested for network optimization, with a major focus on energy efficiency, network longevity, and clustering processes. We proposed the Adaptive Active Sleep Energy Efficient Method (AASEEM) for Wireless Sensor Networks (WSNs), which takes into account network heterogeneity. We examine and improve some difficulties including network stability and cluster head selection procedure. The principle of providing a detailed pairing among sensor nodes is used to maximize energy usage. The results of the simulations show that the suggested method improves network performance significantly and it might be a beneficial technique for WSNs.
C1 [Chandana, M. Sree; Rao, K. Raghava] Koneru Lakshmaiah Educ Fdn, Vijayawada, Andhra Prades, India.
   [Reddy, B. Naresh Kumar] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamilnadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Reddy, BNK (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamilnadu, India.
EM naresh.nitg@gmail.com
CR [Anonymous], 2010, 2010 5 INT S 4 COMM, DOI DOI 10.1109/ISVC.2010.5656252
   Ennaciri A, 2019, PROCEDIA COMPUT SCI, V151, P1140, DOI 10.1016/j.procs.2019.04.162
   Faisal S, 2013, J BASIC APPL SCI RES, V3
   Hsu CC, 2014, IEEE T COMPUT, V63, P1840, DOI 10.1109/TC.2012.282
   Javaid S, 2018, MULTIMED TOOLS APPL, V77, P4433, DOI 10.1007/s11042-016-4224-2
   Kalburgi SS, 2022, MULTIMED TOOLS APPL, V81, P15815, DOI 10.1007/s11042-022-12302-7
   Li DL, 2017, AIP CONF PROC, V1839, DOI 10.1063/1.4982583
   Liwa H, 2021, PREPRINT
   Mahapatra RP, 2015, PROCEDIA COMPUT SCI, V57, P1005, DOI 10.1016/j.procs.2015.07.505
   Mukherjee A, 2021, MULTIMED TOOLS APPL, V80, P16619, DOI 10.1007/s11042-020-08909-3
   Nurlan Z, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041021
   Oliveira L., 2011, J COMMUN, V6, P143, DOI DOI 10.4304/JCM.6.2.143-151
   Ramesh RDC, 2014, 2 INT C EMERGING TRE, DOI [10.15242/iie.e0514532, DOI 10.15242/IIE.E0514532]
   Rao KGV, 2023, SOFT COMPUT, V27, P15269, DOI 10.1007/s00500-023-07940-4
   Rao PCS, 2021, MULTIMED TOOLS APPL, V80, P26093, DOI 10.1007/s11042-021-10901-4
   Sekine M, 2006, 2006 AS PAC COMM, P1, DOI [10.1109/APCC.2006.255873, DOI 10.1109/APCC.2006.255873]
   Shagari NM, 2020, IEEE ACCESS, V8, P12232, DOI 10.1109/ACCESS.2020.2965206
   Singh A, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P4654, DOI 10.1109/ICEEOT.2016.7755602
   Smaragdakis G., 2004, Technical report
   Zhang X, 2015, P IEEE 82 VEHICULAR, P1, DOI [10.1109/VTCFall.2015.7390918, DOI 10.1109/VTCFALL.2015.7390918]
NR 20
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13689
EP 13706
DI 10.1007/s11042-023-16054-w
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025717900002
DA 2024-07-18
ER

PT J
AU Souza, M
   Horikoshi, WC
   Saito, PTM
   Bugatti, PH
AF Souza, Marcelo
   Horikoshi, William C.
   Saito, Priscila T. M.
   Bugatti, Pedro H.
TI Soybean seed vigor classification through an effective image
   learning-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image analysis; Machine learning; Convolutional neural networks;
   Handcrafted features; Deep features; Seed vigor
ID COLOR; VISION
AB To obtain better productivity in soybean crops, it is essential to use high-quality seeds. The quality impacts the growing process of the plant. Currently, human specialists perform this quality control process through seed vigor analysis.It is not only a labor-intensive approach highly susceptible to failure, but also the analysts must understand seed anatomy. This paper proposes a learning-based expert approach and pipeline capable of automatically defining the seeds' vigor. Our proposed approach simplifies, in an intuitive manner, the entire process of the seed vigor analysis. To corroborate our learning-based approach, we applied it in a real environment to capture, process, and use two real-world datasets composed of hundreds of soybean images with different damages from a seed classification laboratory. From the experiments, we can testify to a strong efficacy and efficiency in these real-world cases, reaching up to 80.17%& PLUSMN;2.37 of accuracy. Our approach provides technological enhancements and opens new ways to solve the seed vigor definition regarding in-place image analysis, aggregating an entire on-the-fly seed analysis pipeline.
C1 [Souza, Marcelo; Horikoshi, William C.; Saito, Priscila T. M.; Bugatti, Pedro H.] Fed Univ Technol, Dept Comp, UTFPR, 1640 Alberto Carazzai Ave, BR-86300000 Cornelio Procopio, PR, Brazil.
   [Saito, Priscila T. M.; Bugatti, Pedro H.] Fed Univ Sao Carlos UFSCar, Dept Comp, Km 235, Rod Washington Luis, BR-13565905 Sao Carlos, SP, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade Federal de Sao
   Carlos
RP Bugatti, PH (corresponding author), Fed Univ Technol, Dept Comp, UTFPR, 1640 Alberto Carazzai Ave, BR-86300000 Cornelio Procopio, PR, Brazil.; Bugatti, PH (corresponding author), Fed Univ Sao Carlos UFSCar, Dept Comp, Km 235, Rod Washington Luis, BR-13565905 Sao Carlos, SP, Brazil.
EM marcelojunior.2015@alunos.utfpr.edu.br; wcardosoh@gmail.com;
   priscilasaito@ufscar.br; pedrobugatti@ufscar.br
RI Saito, Priscila/E-8159-2013; Bugatti, Pedro/T-5178-2017
OI Saito, Priscila/0000-0002-4870-4766; Bugatti, Pedro/0000-0001-9421-9254
FU National Council for Scientific and Technological Development- CNPq
   [422811/2016-5, 431668/2016-7]; Coordination for the Improvement of
   HigherEducation Personnel - CAPES; Fundacao Araucaria; UTFPR
FX This work has been supported by National Council for Scientific and
   Technological Development- CNPq [grant numbers #431668/2016-7,
   #422811/2016-5]; Coordination for the Improvement of HigherEducation
   Personnel - CAPES; Fundacao Araucaria and UTFPR
CR Al-Sharadqah AA, 2016, SIGNAL PROCESS, V120, P468, DOI 10.1016/j.sigpro.2015.09.025
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Del Egido LL, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.00747
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Franca-Neto JB, 1998, TETRAZOLIUM TEST SOY, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Kleber A, 2013, DEVEL SEDIM, V66, P1, DOI 10.1016/B978-0-444-53118-6.00001-5
   Leist N, 2011, ISTA WORKING SHEETS, VI and II
   Liu WD, 2017, IEEE IMAGE PROC, P2891, DOI 10.1109/ICIP.2017.8296811
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009
   Nanni L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149399
   Narwade J, 2016, P INT C INF COMM TEC, P293
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Pereira DF, 2019, DATA BRIEF, V23, DOI 10.1016/j.dib.2018.12.090
   Pereira DF, 2021, IEEE T IND ELECTRON, V68, P1675, DOI 10.1109/TIE.2020.2969106
   Peters J., 2010, TETRAZOLIUM TESTING
   Rehman TU, 2019, COMPUT ELECTRON AGR, V156, P585, DOI 10.1016/j.compag.2018.12.006
   Rocha D. M., 2019, Journal of Agricultural Science (Toronto), V11, P115, DOI 10.5539/jas.v11n15p115
   Russell S., 2016, Artificial intelligence a modern approach
   Sandid F, 2016, PATTERN RECOGN LETT, V80, P15, DOI 10.1016/j.patrec.2016.05.010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stanitsas P, 2016, INT C PATT RECOG, P1490, DOI 10.1109/ICPR.2016.7899848
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Strutz T., 2016, Data fitting and uncertainty: a practical introduction to weighted least squares and beyond, V2nd
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Valenzuela G, 2018, IEEE SYS MAN CYBERN, P2096, DOI 10.1109/SMC.2018.00361
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
NR 33
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13113
EP 13136
DI 10.1007/s11042-023-15804-0
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800001
DA 2024-07-18
ER

PT J
AU Gueham, T
   Merazka, F
AF Gueham, Tarek
   Merazka, Fatiha
TI Packet loss concealment method based on hidden Markov model and decision
   tree for AMR-WB codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Packet loss concealment; HMM; Decision tree; HMDT model; Machine
   learning; WB-PESQ; EMBSD; MUSHRA
ID VOICE QUALITY; SPEECH; RECONSTRUCTION; RECOVERY
AB Packet loss concealment (PLC) techniques are utilized to improve the quality of Voice over IP (VoIP) communications by reconstructing missing speech packets. Hidden Markov Model (HMM)-based PLC methods have shown a significant improvement over traditional methods by tracking the statistical evolution of speech signals. However, these methods may result in perceptually disturbing artifacts that arise from the structure of the HMM model. In this study, we introduce HMM-based PLC methods and investigate the impact of Markovian assumptions on their performance, specifically pitch fluctuation and gain mismatching. We then propose a new PLC method implemented on the G.722.2 codec, which incorporates the HMM and Decision Tree (DT) architecture. Our proposed architecture avoids the HMM's emissions dependencies assumption by using a DT layer, resulting in more accurate speech packet regeneration and natural transitions between the synthesized and concealed speech signals. The proposed method uses HMM and DT to track the statistical evolution of speech signals and accurately predict/estimate lost speech packets by exploiting the surrounding received speech packets. The proposed method is evaluated using mathematical proofs, objective, and subjective metrics, with results showing a considerable enhancement in speech quality compared to conventional PLC methods, achieving a Perceptual Evaluation of Speech Quality (PESQ) score higher than 3 at a 20% packet loss ratio.
C1 [Gueham, Tarek; Merazka, Fatiha] USTHB Univ, Telecommun Dept, LIS Lab, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Merazka, F (corresponding author), USTHB Univ, Telecommun Dept, LIS Lab, Algiers, Algeria.
EM gueham.tarek@gmail.com; fmerazka@usthb.dz
RI Merazka, Fatiha/Q-6874-2019
OI Merazka, Fatiha/0000-0002-5568-4927
CR Akamine M, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-10
   [Anonymous], 2003, G7222 ITU T
   Borgström BJ, 2010, IEEE T AUDIO SPEECH, V18, P1612, DOI 10.1109/TASL.2009.2038811
   Chibani M, 2007, IEEE T AUDIO SPEECH, V15, P2485, DOI 10.1109/TASL.2007.907332
   Circus Drake, 2012, COMPUT COMMUN, V28, P582
   Dube P., 2002, NETWORKING 2002. Networking Technologies, Services, and Protocols; Performance of Computer and Communication Networks; Mobile and Wireless Communications. Second International IFIP-TC6 Networking Conference. Proceedings (Lecture Notes in Computer Science Vol.2345), P226
   Franzese M., 2019, Encyclopedia of Bioinformatics and Computational Biology, V1, P706
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Goodarzi MM, 2016, INT J SPEECH TECHNOL, V19, P769, DOI 10.1007/s10772-016-9369-x
   Gournay P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P108
   Gueham T, 2018, IEEE 26 EUR SIGN PRO, V26, P77
   Gueham T, 2023, COMPUT STAND INTER, V85, DOI 10.1016/j.csi.2022.103709
   Gueham T, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P377, DOI 10.1109/TSP.2017.8076009
   Hofmann P, 2020, LECT NOTES COMPUT SC, V12139, P464, DOI 10.1007/978-3-030-50420-5_35
   Ilk HG, 2005, IEEE T WIREL COMMUN, V4, P93, DOI 10.1109/TWC.2004.840208
   Khreich W, 2010, PATTERN RECOGN LETT, V31, P91, DOI 10.1016/j.patrec.2009.09.023
   Lai K., 2019, Encycl. Bioinform. Comput. Biol. ABC Bioinform, P272, DOI 10.1016/B978-0-12-809633-8.20325-7
   Martin R, 2001, INT CONF ACOUST SPEE, P729, DOI 10.1109/ICASSP.2001.941018
   Martinian E, 2004, IEEE T INFORM THEORY, V50, P2494, DOI 10.1109/TIT.2004.834844
   Mittag G, 2018, INTERSPEECH, P1883, DOI 10.21437/Interspeech.2018-1098
   Nadkarni P, 2016, CLIN RES COMPUTING, P85
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Rodbro CA, 2006, IEEE T AUDIO SPEECH, V14, P1609, DOI 10.1109/TSA.2005.858561
   Rodriguez DZ, 2013, INT J ADV INTERNET T, V6, P261
   Salamon J., 2017, International Society of Music Information Retrieval (ISMIR)
   Sanneck HA, 1999, MULTIMEDIA COMPUTING, ppp1
   Sanneck HA., 1999, MULTIMEDIA COMPUTING, V12, P245
   Santiago Pascual JP., 2021, COMPUT SCI, V10, P78
   Srivastava DK, 2017, INT CONF COMM SYST, P74, DOI [10.1109/CSNT.2017.8418514, 10.1109/CSNT.2017.15]
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Teunen R, 2007, P INTERSPEECH2007 SE, P2097
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P521, DOI 10.1016/B978-1-59749-272-0.50011-6
   Tu YH, 2020, IEEE-ACM T AUDIO SPE, V28, P1608, DOI 10.1109/TASLP.2020.2996503
   Turunen J, 2005, COMPUT COMMUN, V28, P582, DOI 10.1016/j.comcom.2004.02.027
   Wellekens C. J., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P384
   Yang WZ, 2017, EARLY WARNING FOR INFECTIOUS DISEASE OUTBREAK: THEORY AND PRACTICE, P3, DOI 10.1016/B978-0-12-812343-0.00001-1
   Yeh JF, 2013, J APPL RES TECHNOL, V11, P559, DOI 10.1016/S1665-6423(13)71563-3
   Zhou WL, 2019, NEUROCOMPUTING, V349, P261, DOI 10.1016/j.neucom.2019.03.051
NR 39
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11261
EP 11297
DI 10.1007/s11042-023-15914-9
EA JUN 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dokuz, Y
AF Dokuz, Yesim
TI Discovering popular and persistent tags from YouTube trending video big
   dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trending video analysis; Video tag analysis; Popular and persistent tag
   discovery; YouTube big data analytics
ID EARLY PREDICTION
AB YouTube is the most popular video content platform which provides easy and fast accessibility, huge number of videos, qualified and large number of content producers, and wide range of users. Based on these advantages, YouTube datasets have a big data nature in terms of data analytics. Analyzing YouTube big datasets is essential for discovering user-video relations, video recommendation, semantic analysis of video comments and trending videos analysis. However, YouTube big data analysis has several challenges, such as video content issues, textual and semantic challenges, different metadata information about videos, and big data nature of YouTube datasets. In the literature, several studies are performed for sentiment analysis of YouTube video comments, video recommendation methods, and trending video analyses approaches. In this study, a new method is proposed for popular and persistent tags discovery which uses YouTube trending video dataset of United States for the year of 2021. A new algorithm is proposed, named as Popular and Persistent Tag Discovery algorithm (PPTagD algorithm), which uses proposed method. The proposed algorithm is experimentally evaluated on the dataset. The experimental results show the effectiveness of the proposed algorithm on discovering popular and persistent tags. The results reveal the tendency of United States YouTube users in terms of video tag popularity.
C1 [Dokuz, Yesim] Nigde Omer Halisdemir Univ, Engn Fac, Comp Engn Dept, Nigde, Turkiye.
C3 Nigde Omer Halisdemir University
RP Dokuz, Y (corresponding author), Nigde Omer Halisdemir Univ, Engn Fac, Comp Engn Dept, Nigde, Turkiye.
EM ytorun@ohu.edu.tr
OI Dokuz, Yesim/0000-0001-7202-2899
CR Abebe MA, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.025
   Agarwal Swati., 2014, P 25 ACM C HYPERTEXT, P294
   Alassad M, 2019, LECT NOTES COMPUT SC, V11549, P224, DOI 10.1007/978-3-030-21741-9_23
   Alkaff M, 2020, 2020 5 INT C INF COM, P1, DOI [10.1109/ICIC50835.2020.9288579, DOI 10.1109/ICIC50835.2020.9288579]
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   Bendimerad A, 2021, IEEE T KNOWL DATA EN, V33, P796, DOI 10.1109/TKDE.2019.2931340
   Brodersen Anders, 2012, P 21 INT C WORLD WID, P241, DOI DOI 10.1145/2187836.2187870
   Chang WL, 2019, CYBERNET SYST, V50, P563, DOI 10.1080/01969722.2019.1646012
   Chelaru S.V., 2012, INT C WEB INF SYST E, P552, DOI DOI 10.1007/978-3-642-35063-4_40
   Chen YL, 2019, EXPERT SYST APPL, V133, P59, DOI 10.1016/j.eswa.2019.05.015
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Fernández-Martínez F, 2015, EXPERT SYST APPL, V42, P293, DOI 10.1016/j.eswa.2014.07.033
   Figueiredo F, 2016, INFORM SCIENCES, V349, P172, DOI 10.1016/j.ins.2016.02.025
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Gajanayake GMHC, 2020, INT CONF ADV ICT, P149, DOI 10.1109/ICTer51097.2020.9325476
   Hoiles W, 2017, IEEE T KNOWL DATA EN, V29, P1426, DOI 10.1109/TKDE.2017.2682858
   Jansen BJ, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115611
   Kaushal Rishabh, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P157, DOI 10.1109/PST.2016.7906950
   Krishna A., 2013, Proceedings of the 19th International Conference on Management of Data, COMAD'13 (Ahmedabad, India, 2013), P125
   Liu Q, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2613, DOI 10.1145/3340531.3416021
   Liu S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3020, DOI 10.1145/3308558.3313513
   Maître E, 2022, LECT NOTES BUS INF P, V446, P670, DOI 10.1007/978-3-031-05760-1_42
   Mariconti Enrico, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359309
   Matamoros-Fernández A, 2017, INFORM COMMUN SOC, V20, P930, DOI 10.1080/1369118X.2017.1293130
   Novendri R., 2020, B COMPUTER SCI ELECT, V1, P26, DOI [10.25008/bcsee.v1i1.5, DOI 10.25008/BCSEE.V1I1.5]
   Oberlo, 2022, OB YOUTUBE STAT
   Ottoni R, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P323, DOI 10.1145/3201064.3201081
   Rastogi N, 2018, P IEEE INT S DYN SPE, P1, DOI [10.1109/IoT-SIU.2018.8519858, DOI 10.1109/IOT-SIU.2018.8519858]
   Severyn A, 2016, INFORM PROCESS MANAG, V52, P46, DOI 10.1016/j.ipm.2015.03.002
   Sharma R, 2022, YOUTUBE TRENDING VID
   Singh Shivdeep, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P250, DOI 10.1109/ICSCCC51823.2021.9478128
   Srivastava A., 2017, ARXIV170301488, P1, DOI [DOI 10.1109/ICACCAF.2017.8344732, 10.1109/ICISC.2017.8068607, DOI 10.1109/ICISC.2017.8068607]
   Statista, 2022, STAT MOST POP SOC NE
   Tran GTC, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221094587
   Wang J, 2020, COMPUT SYST SCI ENG, V35, P523
   Wang J, 2020, J INTERNET TECHNOL, V21, P393, DOI 10.3966/160792642020032102008
   Wilhelm M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2165, DOI 10.1145/3269206.3272018
   Yan M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/2671188.2749344
   Zhang YH, 2021, LECT NOTES COMPUT SC, V12843, P43, DOI 10.1007/978-3-030-82472-3_5
   Zhou RJ, 2020, IEEE ACCESS, V8, P6954, DOI 10.1109/ACCESS.2019.2961392
NR 41
TC 1
Z9 1
U1 9
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10779
EP 10797
DI 10.1007/s11042-023-16019-z
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000010
DA 2024-07-18
ER

PT J
AU Wen, ZF
   Chen, AB
   Zhou, GX
   Yi, JZ
   Peng, WX
AF Wen, Zhifang
   Chen, Aibin
   Zhou, Guoxiong
   Yi, Jizheng
   Peng, Weixiong
TI Parallel attention of representation global time-frequency correlation
   for music genre classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genre classification; Attention mechanism; Convolutional neural
   network; Global time-frequency correlation; Mel-spectrogram
ID NETWORKS; MACHINE
AB Music genre classification (MGC) is an indispensable branch of music information retrieval. With the prevalence of end-to-end learning, the research on MGC has made some breakthroughs. However, the limited receptive field of convolutional neural network (CNN) cannot capture a correlation between temporal frames of sounding at any moment and sound frequencies of all vibrations in the song. Meanwhile, time-frequency information of channels is not equally important. In order to deal with the above problems, we apply dual parallel attention (DPA) in CNN-5 to focus on global dependencies. First, we propose parallel channel attention (PCA) to build global time-frequency dependencies in the song and study the influence of different weighting methods for PCA. Next, we design dual parallel attention, which focuses on global time-frequency dependencies in the song and adaptively calibrates contribution of different channels to feature map. Then, we analyzed the effect of applying different numbers and positions of DPA in CNN-5 for performance and compared DPA with multiple attention mechanisms. The results on GTZAN dataset demonstrated that the proposed method achieves a classification accuracy of 91.4%, and DPA has the highest performance.
C1 [Wen, Zhifang; Chen, Aibin; Zhou, Guoxiong; Yi, Jizheng] Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.
   [Peng, Weixiong] Hunan Zixing Artificial Intelligence Technol Grp C, Beijing, Peoples R China.
C3 Central South University of Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.
EM hotaibin@163.com
RI Pong, Eric/JDD-9269-2023
FU Postgraduate Scientific Research Innovation Project of Hunan Province
   [CX20210879]; Postgraduate Scientific Research Innovation Project of
   Central South University of Forestry and Technology [CX202102059]; Hunan
   Key Laboratory of Intelligent Logistics Technology [2019TP1015]
FX This work was supported by Postgraduate Scientific Research Innovation
   Project of Hunan Province (CX20210879), Postgraduate Scientific Research
   Innovation Project of Central South University of Forestry and
   Technology (CX202102059) and Hunan Key Laboratory of Intelligent
   Logistics Technology (2019TP1015).
CR [Anonymous], 2014, FOUND TRENDS INF RET, V8, P128, DOI 10.1561/1500000042
   Arabi Arash Foroughmand, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P101, DOI 10.1109/ICSIPA.2009.5478635
   Ashraf M, 2020, IEEE ACCESS, V8, P220980, DOI 10.1109/ACCESS.2020.3043142
   Baniya BK, 2014, INT CONF ADV COMMUN, P96, DOI 10.1109/ICACT.2014.6778929
   Cai X, 2022, MULTIMEDIA SYST, V28, P779, DOI 10.1007/s00530-021-00886-3
   Chang PC, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P29, DOI 10.1145/3460426.3463619
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Choi K., 2017, ARXIV
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gao Y., 2020, RES MUSIC AUDIO CLAS
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gong Y., 2021, ARXIV
   Gupta Rahul, 2021, Proceedings of International Conference on Intelligent Computing, Information and Control Systems. (ICICCS 2020). Advances in Intelligent Systems and Computing (AISC 1272), P207, DOI 10.1007/978-981-15-8443-5_17
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Himawan I., 2018, WORKSH DET CLASS AC, P1
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang Z., 2022, arXiv
   Ioffe, 2015, INT CONFE MACHINE LE
   Kahl S., 2017, CLEF WORKING NOTES
   Karunakaran N, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS), P128, DOI 10.1109/ICoIAS.2018.8494161
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ndou N, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P581, DOI 10.1109/IEMTRONICS52119.2021.9422487
   Palmason H, 2017, INT S COMP MUS MULT, V7
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Promane Barry., 2009, Freddie Mercury and Queen: Technologies of Genre and the Poetics of Innovation
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Sarkar R, 2015, 2015 8 INT C ADV PAT
   Saunders Craig., 1998, SUPPORT VECTOR MACHI
   Scalvenzi RR, 2019, INT J SEMANT COMPUT, V13, P415, DOI 10.1142/S1793351X19500028
   Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3169927
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1371
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Yang B, 2008, INT CONF ACOUST SPEE, P3541
   Yang HS, 2019, INTERSPEECH, P3382, DOI 10.21437/Interspeech.2019-1298
   Yang L, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9937383
   Yu Y, 2020, NEUROCOMPUTING, V372, P84, DOI 10.1016/j.neucom.2019.09.054
   Zhang PJ, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P379, DOI 10.1145/2671188.2749367
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
   Zhang X, 2019, ECOL INFORM, V54, DOI 10.1016/j.ecoinf.2019.101009
   Zhang ZC, 2021, NEUROCOMPUTING, V453, P896, DOI 10.1016/j.neucom.2020.08.069
NR 51
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10211
EP 10231
DI 10.1007/s11042-023-16024-2
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400001
DA 2024-07-18
ER

PT J
AU Almalki, FA
   Angelides, MC
AF Almalki, Faris A. A.
   Angelides, Marios C. C.
TI A serious gaming approach for optimization of energy allocation in
   CubeSats
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious gaming; Optimization; Energy allocation; Energy consumption;
   Cubesat; Aerial model; Wireless connectivity
ID GAME-THEORY; NETWORKS; EFFICIENCY
AB Energy consumption remains an open challenge in aerial systems such as CubeSats and therefore optimization of its allocation is a top priority for maximizing operational capacity. Our research review reveals a plethora of approaches for optimization of energy allocation and all achieving varying degrees of success and not without any compromises. In this paper, we exploit the use of serious gaming in a novel energy allocation algorithm that aims at minimizing energy consumption to maximize the utilities of both CubeSats and terrestrial sensors. To demonstrate this, we use Stackelberg for serious gaming and standalone topology for CubeSat configuration. The experimental results show that the use of a Stackelberg game approach for optimization has led to reduction in the required transmission energy in sensors, an improved link performance between the CubeSat and ground sensors, and an increase in network lifetime and performance without resorting into sensor power enhancements or other external power sources. The overall average operational capacity improvement predictions range between 22 to 27% across all performance indicators of energy efficiency across RF chains of link budgets.
C1 [Almalki, Faris A. A.] Taif Univ, Coll Comp & Informat Technol, Dept Comp Engn, POB 11099, Taif 21994, Saudi Arabia.
   [Angelides, Marios C. C.] Brunel Univ London, Coll Engn Design & Phys Sci, Brunel Design Sch, Uxbridge, England.
C3 Taif University; Brunel University
RP Angelides, MC (corresponding author), Brunel Univ London, Coll Engn Design & Phys Sci, Brunel Design Sch, Uxbridge, England.
EM m.faris@tu.edu.sa; marios.angelides@brunel.ac.uk
OI Angelides, Marios/0000-0003-3931-4616
CR Alharbi AG, 2022, INT J ANTENN PROPAG, V2022, DOI 10.1155/2022/1736377
   Almalki FA., 2019, INT J COMPUT NETW CO, V11, P111, DOI DOI 10.5121/IJCNC.2019.11607
   Almalki FA, 2022, COMPUT COMMUN, V190, P154, DOI 10.1016/j.comcom.2022.03.022
   Almalki FA, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/1827155
   Almalki FA, 2019, COMPUT COMMUN, V142, P9, DOI 10.1016/j.comcom.2019.04.001
   AlSkaif T, 2015, J NETW COMPUT APPL, V54, P33, DOI 10.1016/j.jnca.2015.03.011
   Angelides MC, 2013, MULTIMED TOOLS APPL, V62, P287, DOI 10.1007/s11042-011-0981-0
   Bennaceur J, 2021, TELECOM, V2, P232, DOI 10.3390/telecom2030016
   Charilas DE, 2010, COMPUT NETW, V54, P3421, DOI 10.1016/j.comnet.2010.06.020
   DAI N, 2021, 2019 IEEE COGNITIVE, P1
   Del Re E, 2009, 2009 INTERNATIONAL CONFERENCE ON GAME THEORY FOR NETWORKS (GAMENETS 2009), P117, DOI 10.1109/GAMENETS.2009.5137392
   Erol Ö, 2022, APPL ENERG, V316, DOI 10.1016/j.apenergy.2022.118944
   Essid C, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1040333
   Fernandez-Cerero D, 2018, P 32 EUR C MOD SIM W, DOI [10.7148/2018-0460, DOI 10.7148/2018-0460]
   Jiang X, 2022, CHINESE J AERONAUT, V35, P19, DOI 10.1016/j.cja.2021.04.025
   Li F, 2018, IEEE T VEH TECHNOL, V67, P2398, DOI 10.1109/TVT.2017.2771770
   Li X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3051383
   Liu BJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18114074
   Luis JJG, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172682
   Papaioannou TG, 2014, INT CONF SMART GRID, P800, DOI 10.1109/SmartGridComm.2014.7007746
   Petraki DK, 2009, IEEE T COMP INTEL AI, V1, P134, DOI 10.1109/TCIAIG.2009.2027693
   Qian Zhang, 2020, 2020 IEEE 20th International Conference on Communication Technology (ICCT), P622, DOI 10.1109/ICCT50939.2020.9295825
   Radi MA, 2022, ADV SCI ENG TECHN IN, P1, DOI [10.1109/ASET53988.2022.9735123, DOI 10.1109/ASET53988.2022.9735123]
   Rigo CA, 2021, ACTA ASTRONAUT, V179, P550, DOI 10.1016/j.actaastro.2020.11.016
   Ruan L, 2018, CHINA COMMUN, V15, P194, DOI 10.1109/CC.2018.8485481
   Saeed N, 2020, IEEE COMMUN SURV TUT, V22, P1839, DOI 10.1109/COMST.2020.2990499
   Salh A, 2022, IEEE ACCESS, V10, P4714, DOI 10.1109/ACCESS.2021.3139338
   Sun ZM, 2021, IEEE COMMUN SURV TUT, V23, P2660, DOI 10.1109/COMST.2021.3108466
   Tong JF, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030299
   Wang KW, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNETSAT), P188, DOI 10.1109/Comnetsat50391.2020.9328949
   Zhang EQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010058
   Zhang H., 2021, 2021 IEEE CIC INT C, P398
   Zhu XM, 2020, IEEE T COGN COMMUN, V6, P509, DOI 10.1109/TCCN.2020.2981016
NR 33
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8707
EP 8727
DI 10.1007/s11042-023-15795-y
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000009
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Bi, HB
   Tong, JH
   Zhang, C
   Mo, DS
   Wang, XF
AF Bi, Hongbo
   Tong, Jinghui
   Zhang, Cong
   Mo, Disen
   Wang, Xiufang
TI Camouflaged objects detection network via contradiction detection and
   feature aggregation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camouflaged object detection; Contradiction detection; Feature
   aggregation; Attention mechanism
ID NET
AB Camouflaged Object Detection(COD) aims to segment objects with a similar appearance to the background. There are some problems in existing algorithms, such as blurred edges and incomplete detection. To address the above issues, we propose a novel COD framework termed CFNet. Our network consists of the Contradiction Area Detection Module(CADM) and Feature Aggregation Module(FAM). In the CADM, we propose an improved receptive field mechanism, which utilizes max pooling operation and convolution block to highlight the contradictory areas and refine the edge of the hidden object. Besides, the FAM is designed to connect two adjacent layers via attention and anti-attention strategy, leading to cross-layer feature enhancement and information fusion. More specifically, the self-attention mechanism helps supplement semantic information, and the anti-attention mechanism contributes to removing redundant information. Extensive experiments conducted on the four public COD datasets show the comparable performance of the proposed CFNet with SOTAs, and the ablation experiments demonstrate the effectiveness of the proposed modules.
C1 [Bi, Hongbo; Tong, Jinghui; Zhang, Cong; Mo, Disen; Wang, Xiufang] Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163000, Hei Longjiang, Peoples R China.
C3 Northeast Petroleum University
RP Bi, HB (corresponding author), Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163000, Hei Longjiang, Peoples R China.
EM bhbdq@126.com; tongjinghui0601@163.com; congzhang98@126.com;
   modisen2022@163.com; wxfdqpi@163.com
RI Yuan, Fang/JQV-7426-2023; Wei, Wei/JVM-8876-2024; Wang,
   Chen/JZE-6385-2024; Yang, Fan/JMA-9594-2023; Yang, Fan/JVO-8611-2024;
   Chen, Nuo/JZD-0344-2024
OI Wei, Wei/0000-0002-4109-3878; Bi, Hongbo/0000-0003-2442-330X
FU Key Lab of Digital Signal and Image Processing of Guangdong Province
   Open Fund [022GDDSIPL-05]; Infrared and Low Temperature Plasma Key
   Laboratory of Anhui Province [IRKL2022KF07]; Foundation of State Key
   Laboratory of Public Big Data [PBD2022-15]
FX The paper is supported by Key Lab of Digital Signal and Image Processing
   of Guangdong Province Open Fund under No. 022GDDSIPL-05, Infrared and
   Low Temperature Plasma Key Laboratory of Anhui Province under No.
   IRKL2022KF07, Foundation of State Key Laboratory of Public Big Data (No.
   PBD2022-15).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Beiderman Y, 2010, OPT COMMUN, V283, P4274, DOI 10.1016/j.optcom.2010.06.059
   Bhajantri NU, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P145
   Bi H., 2021, IEEE T CIRC SYST VID
   Bi H-B, 2021, ARXIV
   Boot WR, 2009, ATTEN PERCEPT PSYCHO, V71, P950, DOI 10.3758/APP.71.4.950
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chu HK, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778788
   Cuthill IC, 2005, NATURE, V434, P72, DOI 10.1038/nature03312
   Fan D, 2021, INT J COMPUT VISION, P2622
   Fan D, 2021, ARXIV
   Fan D-P, 2020, MED IMAGE COMPUT COM
   Fan DQ, 2021, IRONMAK STEELMAK, V48, P769, DOI 10.1080/03019233.2020.1861857
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ge YL, 2021, COMPUT VIS MEDIA, V7, P115, DOI 10.1007/s41095-020-0200-x
   Hall JR, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0064
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li A., 2021, ARXIV
   Lv Y, 2021, COMPUTER VISION PATT
   Malathi T, 2013, ANNU IEEE IND CONF
   Mei H, 2021, COMPUTER VISION PATT
   Owens A, 2014, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2014.350
   Pang Y., 2022, PROC CVPR IEEE, P2160, DOI DOI 10.1109/CVPR52688.2022.00220
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Rao CP, 2020, INT J SPEECH TECHNOL, V23, P327, DOI 10.1007/s10772-020-09699-7
   Ren J., 2021, ARXIV
   Sengottuvelan P., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P6, DOI 10.1109/ICETET.2008.232
   Siricharoen P., 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P463, DOI 10.1109/ICGCS.2010.5543017
   Skurowski P., 2018, Animal camouflage analysis: Chameleon database
   Song L., 2010, P INT C MULT TECHN, P1
   Stevens M, 2009, PHILOS T R SOC B, V364, P423, DOI 10.1098/rstb.2008.0217
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tankus A, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P42
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang AZ, 2017, NEURAL PROCESS LETT, V46, P1083, DOI 10.1007/s11063-017-9610-x
   Wang Kang, 2021, IEEE T IND ELECT TIE, P1
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xue F, 2015, MULTIMEDIA SYST, V21, P169, DOI 10.1007/s00530-014-0368-y
   Yan JN, 2021, IEEE ACCESS, V9, P43290, DOI 10.1109/ACCESS.2021.3064443
   Yin JQ, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.412
   Zhai Q, 2021, COMPUTER VISION PATT
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang JL, 2020, LECT NOTES COMPUT SC, V11962, P361, DOI 10.1007/978-3-030-37734-2_30
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
   Zhang X, 2017, IEEE T CIRC SYST VID, V27, P2001, DOI 10.1109/TCSVT.2016.2555719
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 55
TC 0
Z9 0
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9161
EP 9179
DI 10.1007/s11042-023-15304-1
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400013
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Zhang, C
   Li, WD
   Gao, LY
   Liu, LM
   Fang, L
   Zhang, CS
AF Chen, Zhenyu
   Zhang, Chen
   Li, Wendi
   Gao, Lanyu
   Liu, Liming
   Fang, Lei
   Zhang, Changsheng
TI Fire danger forecasting using machine learning-based models and
   meteorological observation: a case study in Northeastern China
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fire danger forecasting; Machine learning; Canadian fire weather index;
   LSTM; Random forest
ID NEURAL-NETWORK; PREDICTION; SYSTEM; LSTM
AB Wildfire is one of the primary natural disturbance agents in the forests of China. The forecast of fire danger is critically important to assist stakeholders to avoid and mitigate wildfire-induced hazards and losses to both human society and natural ecosystems. Currently, fire danger rating methods often focus on fire weather classification based on fixed thresholds, which has shortcomings in generalizability and robustness. Based on historical fire occurrence data and meteorological data of Northeastern China from 2004 to 2015, we proposed a forest fire danger rating classification and forecasting model by combining the advantages of the Canadian Fire Weather Index (FWI) system and two machine learning models such as the Long Short-Term Memory (LSTM) network and Random Forest (RF) model. The method is divided into two stages. The first stage is the LSTM-based FWI system indexes prediction. In the first stage, the future FWI system indexes are obtained through the LSTM-based prediction model, and the RMSE and MAE of the prediction results are calculated to verify the prediction performance of the model. The second stage is random forest-based fire danger rating prediction method. In the second stage, we use the random forest method to get the fire danger occurrence probability and present the fire danger rating classification scheme. Then we verify the reliability of the fire danger rating classification scheme by using the forest fire danger data in Qipan Mountain. Our method predicts two randomly selected future intervals, and the prediction accuracy is 87.5%. The experimental results show that our machine learning-based forest fire danger rating classification method can provide a new idea for forest fire danger warnings.
C1 [Chen, Zhenyu; Zhang, Chen; Li, Wendi; Gao, Lanyu; Liu, Liming; Zhang, Changsheng] Northeastern Univ, Shenyang 110819, Peoples R China.
   [Fang, Lei] Shandong Univ, Environm Res Inst, Qingdao 266237, Peoples R China.
   [Fang, Lei] Chinese Acad Sci, Inst Appl Ecol, CAS Key Lab Forest Ecol & Management, Shenyang 110016, Peoples R China.
   [Fang, Lei] Shandong Univ, Big Data Res Ctr Ecol & Environm, Qingdao 266237, Peoples R China.
C3 Northeastern University - China; Shandong University; Chinese Academy of
   Sciences; Shenyang Institute of Applied Ecology, CAS; Shandong
   University
RP Zhang, CS (corresponding author), Northeastern Univ, Shenyang 110819, Peoples R China.; Fang, L (corresponding author), Shandong Univ, Environm Res Inst, Qingdao 266237, Peoples R China.; Fang, L (corresponding author), Chinese Acad Sci, Inst Appl Ecol, CAS Key Lab Forest Ecol & Management, Shenyang 110016, Peoples R China.; Fang, L (corresponding author), Shandong Univ, Big Data Res Ctr Ecol & Environm, Qingdao 266237, Peoples R China.
EM leifang@sdu.edu.cn; zhangchangsheng@mail.neu.edu.cn
RI zhang, changsheng/HSG-7911-2023; chen, xu/JNT-3068-2023; Chen,
   Zhenyu/AAA-6776-2022; Li, Wen-Di/B-3517-2012
OI Li, Wen-Di/0000-0002-7005-2784
FU Key Project of National Natural Science Foundation of China [U1908212];
   National Key R&D Program of China [2017YFA0604403]; National Natural
   Science Foundation of China [32071583]; Young and Middle-Aged Scientific
   and Technological Innovation Talent Support Program of Shenyang
   [RC210081]; Local Science and Technology Development Fund Project Under
   the Guidance of the Central Government of China [1653137155953]; Taking
   Lead Science and Technology Research Project of Liaoning
   [2021jh1/10400006]
FX Funding This research was financially supported by the Key Project of
   National Natural Science Foundation of China (U1908212), the National
   Key R & D Program of China (2017YFA0604403), the National Natural
   Science Foundation of China (32071583), the Young and Middle-Aged
   Scientific and Technological Innovation Talent Support Program of
   Shenyang (RC210081), the Local Science and Technology Development Fund
   Project Under the Guidance of the Central Government of China
   (1653137155953), and the Taking Lead Science and Technology Research
   Project of Liaoning (2021jh1/10400006).
CR Abid F, 2021, FIRE TECHNOL, V57, P559, DOI 10.1007/s10694-020-01056-z
   Alonso-Betanzos A, 2003, EXPERT SYST APPL, V25, P545, DOI 10.1016/S0957-4174(03)00095-2
   [Anonymous], 2006, FOREST ECOL MANAG, DOI DOI 10.1016/J.FORECO.2006.08.237
   Bianchini G, 2015, J COMPUT SCI-NETH, V6, P58, DOI 10.1016/j.jocs.2014.12.001
   Bianchini G, 2010, J COMPUT SCI-NETH, V1, P229, DOI 10.1016/j.jocs.2010.07.005
   Pham BT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12061022
   Buchholz RR, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29623-8
   Cansler A, 2022, FOREST ECOL MANAG, V504, DOI 10.1016/j.foreco.2021.119764
   Chang XM, 2020, INT CONF ACOUST SPEE, P8981, DOI [10.1109/icassp40776.2020.9054088, 10.1109/ICASSP40776.2020.9054088]
   Bui DT, 2019, J ENVIRON MANAGE, V237, P476, DOI 10.1016/j.jenvman.2019.01.108
   epa.gov, CLIMATE CHANGE INDIC
   Feikema PM, 2013, J HYDROL, V488, P1, DOI 10.1016/j.jhydrol.2013.02.001
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769
   Gibson R, 2020, REMOTE SENS ENVIRON, V240, DOI 10.1016/j.rse.2020.111702
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hodges JL, 2019, FIRE SAFETY J, V108, DOI 10.1016/j.firesaf.2019.102854
   Le HV, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101300
   Janiec P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244157
   Kalantar B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223682
   Li X, 2017, ENVIRON POLLUT, V231, P997, DOI 10.1016/j.envpol.2017.08.114
   Li YL, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/8138942
   Li ZZ, 2021, FIRE TECHNOL, V57, P1, DOI 10.1007/s10694-020-01028-3
   Liu ZC, 2020, OPTIK, V223, DOI 10.1016/j.ijleo.2020.165491
   Malik A, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12010109
   Nepstad M, 1998, CONSERV BIOL
   Sayad YO, 2019, FIRE SAFETY J, V104, P130, DOI 10.1016/j.firesaf.2019.01.006
   de Dios VR, 2021, FORESTS, V12, DOI 10.3390/f12040469
   Sakr GE, 2011, ENG APPL ARTIF INTEL
   Sharma R, 2020, MULTIMED TOOLS APPL
   Si L., 2022, Nat. Hazards Res, V2, P25, DOI [10.1016/j.nhres.2022.01.002, DOI 10.1016/J.NHRES.2022.01.002]
   Singh K.R., 2021, Soft Comput. Lett, V3, DOI [DOI 10.1016/J.SOCL.2021.100014, 10.1016/j.socl.2021.100014]
   Stefanidou A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232786
   Tariq A, 2022, J FORESTRY RES, V33, P183, DOI 10.1007/s11676-021-01354-4
   Vidal A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113481
   Vs A, 2019, FOREST ECOL MANAG, V457
   Wang PP, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110214
   Wang Y., 2017, 2017 12 INT C INTELL, P1
   Wu X, 2020, FIRE TECHNOL, V57
   Yang BL, 2019, NEUROCOMPUTING, V332, P320, DOI 10.1016/j.neucom.2018.12.016
   Yu C, 2020, NEUROCOMPUTING, V394
   Zhang GL, 2019, INT J DISAST RISK SC, V10, P386, DOI 10.1007/s13753-019-00233-1
   Zhang XH, 2022, IEEE ACCESS, V10, P20212, DOI 10.1109/ACCESS.2022.3149523
   Zhang XY, 2022, FORESTS, V13, DOI 10.3390/f13020346
   Zhao ZY, 2022, SCI TOTAL ENVIRON, V838, DOI 10.1016/j.scitotenv.2022.156550
NR 44
TC 3
Z9 3
U1 13
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15881-1
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000002
DA 2024-07-18
ER

PT J
AU Guo, Z
   Liu, Y
   Liu, XW
   Pan, ZJ
   Liu, SY
   Fan, YY
AF Guo, Zhe
   Liu, Yang
   Liu, Xuewen
   Pan, Zhaojun
   Liu, Shiya
   Fan, Yangyu
TI LTVAL: Label Transfer Virtual Adversarial Learning framework for
   source-free facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial expression recognition; Source-free facial expression
   recognition; Virtual adversarial training; Information maximization
AB Previous research on cross-domain Facial Expression Recognition (FER) mainly focused on metric learning or adversarial learning, which presupposes access to source domain data to find domain invariant information. However, in practical applications, due to the high privacy and sensitivity of face data, it is often impossible to directly obtain source domain data. In this case, these methods cannot be effectively applied. In order to better apply the cross-domain FER method to the real scenarios, this paper proposes a source-free FER method called Label Transfer Virtual Adversarial Learning (LTVAL), which does not need to directly access source domain data. First, we train the target domain model based on the information maximization constraint, and obtain the pseudo-labels of the target domain data through deep clustering to achieve label transfer. Secondly, the perturbation is added to the target domain samples, and the perturbed samples and the original samples are together used for virtual adversarial training with local distributed smoothing constraints. Finally, a joint loss function is constructed to optimize the target domain model. Using the source domain model trained on RAF-DB, experiments on four public datasets FER2013, JAFFE, CK+, and EXPW as target domain datasets show that our approach achieves much higher performance than the state-of-the-art cross-domain FER methods that require access to source domain data.
C1 [Guo, Zhe; Liu, Yang; Liu, Xuewen; Pan, Zhaojun; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Liu, Shiya] Content Prod Ctr Virtual Real, Beijing 101318, Peoples R China.
C3 Northwestern Polytechnical University
RP Guo, Z (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
EM guozhe@nwpu.edu.cn; yang191@mail.nwpu.edu.cn;
   202020262198@mail.nwpu.edu.cn; 20294734372@qq.com;
   shiya.liu@cpcvr.org.cn; fan_yangyu@nwpu.edu.cn
FU National Natural Science Foundation of China [62071384]; Key Research
   and Development Project of Shaanxi Province of China [2023-YBGY-239];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2023-JC-YB-531]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (62071384), the Key Research and Development
   Project of Shaanxi Province of China(2023-YBGY-239), Natural Science
   Basic Research Plan in Shaanxi Province of China (2023-JC-YB-531).
CR Akamatsu S, 1998, P 3 INT C AUT FAC GE, P14, DOI DOI 10.5281/ZENODO.3451524
   Chen TS, 2022, IEEE T PATTERN ANAL, V44, P9887, DOI 10.1109/TPAMI.2021.3131222
   Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400
   Deng J, 2019, 2019 IEEE CVF C COMP
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P881, DOI 10.1109/TAFFC.2020.2973158
   Li S, 2018, INT C PATT RECOG, P3092, DOI 10.1109/ICPR.2018.8545284
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li TD, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P54
   Liang J., 2020, INT C MACH LEARN, P6028, DOI DOI 10.48550/ARXIV.2002.08546
   Liang J, 2022, IEEE T PATTERN ANAL, V44, P8602, DOI 10.1109/TPAMI.2021.3103390
   Liu H., 2021, INT C NEURAL INF PRO, V34, P22968
   Liu S., 2022, IEEE INT THINGS J
   Liu S, 2022, Int J Mach Learn Cybern, P1
   Liu S, 2022, INT J INTELL SYST, V37, P10968, DOI 10.1002/int.23029
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Long MS, 2018, ADV NEUR IN, V31
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Newell Alejandro., 2017, Advances in neural information processing systems, V9, P30
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   She JH, 2021, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR46437.2021.00618
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Xie Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1255, DOI 10.1145/3394171.3413822
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang X, 2022, IEEE T CIRC SYST VID, V32, P1681, DOI 10.1109/TCSVT.2021.3056098
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhou LY, 2022, NEURAL COMPUT APPL, V34, P925, DOI 10.1007/s00521-021-06045-z
   Zhou Q, 2021, NEURAL COMPUT APPL, V33, P7709, DOI 10.1007/s00521-020-05513-2
   Zhu RH, 2016, INT CONF BIOMETR
   Zhu YC, 2021, IEEE T NEUR NET LEAR, V32, P1713, DOI 10.1109/TNNLS.2020.2988928
   Zou W, 2022, APPL INTELL, V52, P2918, DOI 10.1007/s10489-021-02575-0
NR 46
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15297-x
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400003
DA 2024-07-18
ER

PT J
AU Singh, A
   Kumar, M
AF Singh, Anshy
   Kumar, Manoj
TI Bayesian fuzzy clustering and deep CNN-based automatic video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep convolution neural network; Video summarization; Bayesian Fuzzy
   clustering; Segmentation; Videos
AB The expansion of growth in the generation of video data in various organizations causes an urgent requirement for effectual video summarization methods. This paper devises a novel optimization-driven deep learning technique for video summarization. The aim is to give an automated video summarization. Initially, the video data is extracted from the database. Then, the representative frame selection is done using Bayesian fuzzy clustering (BFC). After that, the frames are then temporally segmented, wherein each segment is modelled as a representative frame, which is generated by clustering the temporal segment into clusters. These segments are selected from each cluster closest to the cluster center. The next step is fine refining that is performed using Deep convolution neural network (Deep CNN), which helps to refine the final frame set. The Deep CNN is trained using the proposed Lion deer hunting (LDH) algorithm. The LDH algorithm is the integration of the Deer hunting optimization algorithm (DHOA) and Lion optimization algorithm (LOA). Thus, the final frames obtained by the proposed LDH-based Deep CNN are employed for video summarization. Here, the final frames are adapted to play as a continuous output video. The developed LDH-based Deep CNN offered enhanced performance than other techniques with the highest precision of 0.841, highest recall of 0.810, and highest F1-Score of 0.888.
C1 [Singh, Anshy; Kumar, Manoj] GLA Univ, Mathura, India.
C3 GLA University
RP Singh, A (corresponding author), GLA Univ, Mathura, India.
EM anshy.singh@gla.ac.in
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280
CR Abonyi J, 2003, LECT NOTES COMPUT SC, V2810, P275, DOI 10.1007/978-3-540-45231-7_26
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   Aote SS, 2018, MULTIMED TOOLS APPL, P1
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Brammya G., 2019, Comput J, DOI [10.1093/comjnl/bxy133, DOI 10.1093/COMJNL/BXY133]
   Chen KT, 2021, Arxiv, DOI arXiv:2107.04191
   Choi TM, 2017, IEEE T CYBERNETICS, V47, P81, DOI 10.1109/TCYB.2015.2507599
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Fei MJ, 2018, MULTIMED TOOLS APPL, V77, P11957, DOI 10.1007/s11042-017-4843-2
   Glenn TC, 2015, IEEE T FUZZY SYST, V23, P1545, DOI 10.1109/TFUZZ.2014.2370676
   Hannane R, 2018, J VIS COMMUN IMAGE R, V55, P179, DOI 10.1016/j.jvcir.2018.06.002
   He Y, 2017, NEUROCOMPUTING, V225, P64, DOI 10.1016/j.neucom.2016.11.011
   Huang CF, 2020, IEEE T CONTR SYST T, V28, P1042, DOI 10.1109/TCST.2019.2891522
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   Jadhav JN., 2018, Int J Eng Technol, V7, P290, DOI 10.14419/ijet.v7i3.27.17894
   Jog V. V., 2014, INT J SCI ENG COMPUT, V4, P392
   Li L., 2011, Proc. 20th Int. Conf. World Wide Web, P287
   Muhammad K, 2020, IEEE INTERNET THINGS, V7, P4455, DOI 10.1109/JIOT.2019.2950469
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Murugan TS, 2019, INT J KNOWL-BASED IN, V23, P61, DOI 10.3233/KES-190400
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   openu, VIOLENT FLOWS DATABA
   Pande D, 2014, ENHANCING SECURITY O
   paperswithcode, SUMME DAT TAK
   paperswithcode, TVSUM DAT TAK
   Puttaswamy MR, 2020, MULTIMED RES, V3
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Taha M, 2021, MULTIMED TOOLS APPL, V80, P26833, DOI 10.1007/s11042-021-10934-9
   Taha M, 2021, TELECOMMUN SYST, V77, P63, DOI 10.1007/s11235-020-00741-2
   Thomas SS, 2017, IEEE T CIRC SYST VID, V27, P1790, DOI 10.1109/TCSVT.2016.2556558
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Ullah A., 2018, IEEE Transactions on Industrial Electronics
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang X, 2021, MAR GEORESOUR GEOTEC, V39, P1, DOI 10.1080/1064119X.2020.1748775
   Wu J, 2019, MULTIMED TOOLS APPL
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
NR 39
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15431-9
EA MAY 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700004
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Kumar, A
   Ganguly, R
AF Agarwal, Swati
   Kumar, Ashrut
   Ganguly, Rijul
TI Investigating transformer-based models for automated e-governance in
   Indian Railway using Twitter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Indian railway; Public grievances; Code-mixed text classifier;
   Transformers learning; Twitter
ID SOCIAL MEDIA; COMPLAINTS
AB Recently, Twitter has been used as a citizen-engaging platform by Indian Railway Ministry (IRM) for collecting civic issues. However, due to the manual inspection model, a large percentage of complaints are left unaddressed affecting the credibility of the citizen-sourcing mediums. The existing solutions are for English reports and unable to capture the diverse range of code-mixed languages used in the complaints. In this paper, we developed a multilingual cased version of BERT (mBERT) for automated identification of monolingual and code-mixed Hindi-English complaints. In addition to the grievances classification, we also employ BERT multi-label classifier for labelling the tweets with the issues reported in the complaints. The proposed solution approach obtains a weighted f1-score of 82% and overall accuracy of 96% for binary and multilabel tasks, respectively. We compare our results against conventional machine learning algorithms proposed in existing literature. Further, the benchmarking is performed against BERTweet and IndicBERT and observe that the proposed framework outperforms these models. Additionally, a critical analysis is presented on the classified reports and a location-based analysis to visualise the velocity and veracity of complaints across India.
C1 [Agarwal, Swati; Kumar, Ashrut; Ganguly, Rijul] BITS Pilani, Dept Comp Sci & Informat Syst, Computat Linguist & Social Networks Lab, Goa Campus, Pilani 403726, Goa, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Agarwal, S (corresponding author), BITS Pilani, Dept Comp Sci & Informat Syst, Computat Linguist & Social Networks Lab, Goa Campus, Pilani 403726, Goa, India.
EM agrswati@ieee.org; f20170137@goa.bits-pilani.ac.in;
   f20170971@goa.bits-pilani.ac.in
CR Agarwal S, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P67, DOI 10.1145/3152494.3152517
   Akhtar Nadeem, 2021, Data Management, Analytics and Innovation. Proceedings of ICDMAI 2020. Advances in Intelligent Systems and Computing (AISC 1174), P195, DOI 10.1007/978-981-15-5616-6_14
   Akhtar N, 2020, DATA MANAGEMENT ANAL, P195
   Anderson M, 2015, PORTL INT CONF MANAG, P2453, DOI 10.1109/PICMET.2015.7273207
   Anggareska Dekha., 2014, 2014 International Conference on Data and Software Engineering (ICODSE), P1
   Atreja S, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P617, DOI 10.1145/3172944.3172955
   Ayranci P, 2022, J COMB OPTIM, V44, P770, DOI 10.1007/s10878-022-00856-z
   Baziotis C., 2017, P 11 INT WORKSHOP SE, P747, DOI [DOI 10.18653/V1/S17-2126, 10.18653/v1/S17-2126]
   Cetinoglu Ozlem, 2016, P 2 WORKSH COMP APPR, P1
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen ZH, 2022, I S BIOMED IMAGING, DOI [10.1109/isbi52829.2022.9761497, 10.1109/ISBI52829.2022.9761497]
   Chiang TA, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.306748
   Congosto M, 2015, IEEE INTERNET COMPUT, V19, P18, DOI 10.1109/MIC.2015.117
   Depraetere I, 2021, J PRAGMATICS, V171, P215, DOI 10.1016/j.pragma.2020.09.026
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dumrewal A, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P180, DOI 10.1145/3152494.3152511
   Frias-Martinez V, 2014, 6 ASE INT C SOC COMP, P1
   Goyal Mukta, 2020, Micro-Electronics and Telecommunication Engineering. Proceedings of 3rd ICMETE 2019. Lecture Notes in Networks and Systems (LNNS 106), P721, DOI 10.1007/978-981-15-2329-8_73
   Gupta M, 2021, J RAIL TRANSPORT PLA, V20, DOI 10.1016/j.jrtpm.2021.100265
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Hua T, 2013, COMPUTER, V46, P80, DOI 10.1109/MC.2013.442
   Jha V., 2016, MICROELECTRONICS COM, P1
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kakwani D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4948
   Kumar A, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1223, DOI 10.1145/2600428.2609550
   Kurup S, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P541, DOI 10.1145/2968219.2968318
   Kwon HY, 2016, SPAT INF RES, V24, P127, DOI 10.1007/s41324-016-0014-1
   Meijer AJ, 2016, AM REV PUBLIC ADM, V46, P143, DOI 10.1177/0275074014551381
   Merson F, 2017, ADV RES COMPUT COMMU, V6
   Mittal Nitish, 2016, Advanced Data Mining and Applications. 12th International Conference, ADMA 2016. Proceedings: LNAI 10086, P619, DOI 10.1007/978-3-319-49586-6_44
   Norvig Peter, 2009, Beautiful data, P219
   Oliveira TA, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072926
   Panagiotopoulos P, 2016, TECHNOL FORECAST SOC, V111, P86, DOI 10.1016/j.techfore.2016.06.010
   Pender B, 2013, AUSTRALASIAN TRANSPO, P1
   Rahman SS, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1240, DOI 10.1145/2808797.2809369
   Rosenberg H, 2020, CAN J EMERG MED, V22, P418, DOI 10.1017/cem.2020.361
   Sobaci MZ, 2013, GOV INFORM Q, V30, P417, DOI 10.1016/j.giq.2013.05.014
   Tao C-C., 2022, WSEAS T COMPUT, V20, P110, DOI [10.37394/23205.2022.21.16, DOI 10.37394/23205.2022.21.16]
   Tao DP, 2019, IEEE T NEUR NET LEAR, V30, P163, DOI 10.1109/TNNLS.2018.2836969
   Zirtiloglu H, 2008, INT WORKSH ONT SUPP
NR 40
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15331-y
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400002
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Liu, ZW
AF Zhang, Xiaoqiang
   Liu, Zhiwei
TI Fast color image encryption algorithm based on FCSM and pre-storage
   Arnold transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Arnold transform; Combination chaotic system; Image encryption;
   Pre-storage
ID SCHEME; CHAOS
AB Image encryption is an important multimedia security technology to protect the image content during network transmission. Chaotic systems are widely used in the field of image encryption due to their pseudo-randomness. To solve the problem of poor chaotic effect of traditional chaotic systems, this paper proposes a novel Fibonacci combined Cubic-Sine Map (FCSM) with large key space and chaotic characteristics, which passes each of NIST SP 800-22 tests. Besides, a fast color image encryption algorithm is designed using FCSM and pre-storage Arnold transform. Firstly, the SHA-256 is used to generate initial values; secondly, pseudo-random sequences are generated using FCSM, which scramble the image in combination with the row & column shift and circular rotation; finally, the pre-storage Arnold transform is designed to diffuse the pixel values. The experimental results and security analyses show that the proposed algorithm has ideal encryption effect with NPCR and UACI reaching to 99.6096% and 33.4657%, which are very close to the ideal values. The proposed algorithm is very efficient, which takes only about 0.6 second to encrypt a color image with the size of 512 x 512. Therefore, the proposed algorithm is secure and efficient, which can be a candidate for the real-time encryption system.
C1 [Zhang, Xiaoqiang; Liu, Zhiwei] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM grayqiang@163.com
RI Liu, Zhiwei/AAN-8965-2021
CR Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chen LP, 2020, FRONT INFORM TECH EL, V21, P866, DOI 10.1631/FITEE.1900709
   Chen Y, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac6d85
   Duan CF, 2022, OPT LASER ENG, V150, DOI 10.1016/j.optlaseng.2021.106881
   Fang J, 2022, MULTIMED TOOLS APPL, V81, P17245, DOI 10.1007/s11042-022-12604-w
   Farwa S, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0135-x
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Guleria V, 2020, MULTIMED TOOLS APPL, V79, P33119, DOI 10.1007/s11042-020-09615-w
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P505, DOI 10.1007/s11042-021-11384-z
   Hu CH, 2022, J MOD OPTIC, V69, P511, DOI 10.1080/09500340.2022.2055188
   Huang HQ, 2020, MULTIMED TOOLS APPL, V79, P28065, DOI 10.1007/s11042-020-09378-4
   Huang ZW, 2022, OPT LASER TECHNOL, V149, DOI 10.1016/j.optlastec.2022.107879
   Jain K, 2021, PATTERN RECOGN LETT, V152, P356, DOI 10.1016/j.patrec.2021.10.033
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1223, DOI 10.1007/s11128-013-0721-7
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Kaur M, 2019, NEURAL COMPUT APPL, V31, P7975, DOI 10.1007/s00521-018-3642-7
   Li H, 2020, MULTIMED TOOLS APPL, V79, P19387, DOI 10.1007/s11042-020-08826-5
   Li SS, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6624809
   Liu Q, 2020, IEEE ACCESS, V8, P83596, DOI 10.1109/ACCESS.2020.2991420
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Mansouri A, 2021, VISUAL COMPUT, V37, P189, DOI 10.1007/s00371-020-01791-y
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Mondal B, 2022, MULTIMED TOOLS APPL, V81, P34547, DOI 10.1007/s11042-021-11657-7
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Patel S, 2021, NEURAL COMPUT APPL, V33, P14533, DOI 10.1007/s00521-021-06096-2
   Kari AP, 2021, MULTIMEDIA SYST, V27, P907, DOI 10.1007/s00530-021-00772-y
   Prasad B, 2021, CHAOS SOLITON FRACT, V145, DOI 10.1016/j.chaos.2020.109922
   Sheela SJ, 2022, MULTIDIM SYST SIGN P, V33, P579, DOI 10.1007/s11045-021-00814-8
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Skokos C, 2016, LECT NOTES PHYS, V915, P221, DOI 10.1007/978-3-662-48410-4_7
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tora H, 2022, MULTIMED TOOLS APPL, V81, P31349, DOI 10.1007/s11042-022-11985-2
   Valle-minon Marcos, 2022, 2022 28th International Semiconductor Laser Conference (ISLC), P1, DOI 10.23919/ISLC52947.2022.9943461
   Vidhya R, 2022, MULTIMED TOOLS APPL, V81, P3735, DOI 10.1007/s11042-021-11720-3
   Wan YJ, 2023, MULTIMED TOOLS APPL, V82, P22103, DOI 10.1007/s11042-022-13345-6
   Wang XY, 2022, MULTIMED TOOLS APPL, V81, P13845, DOI 10.1007/s11042-022-12220-8
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2023, VISUAL COMPUT, V39, P43, DOI 10.1007/s00371-021-02311-2
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Yang FF, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac4fd0
   Yang S, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac59fa
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang XQ, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac8840
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
NR 56
TC 0
Z9 0
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15577-6
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY7
UT WOS:000990968000001
DA 2024-07-18
ER

PT J
AU Peng, Y
   Fu, GB
   Yu, Q
   Luo, YG
   Hu, J
   Duan, CF
AF Peng, Ye
   Fu, GuoBin
   Yu, Qi
   Luo, YingGuang
   Hu, Jia
   Duan, ChaoFan
TI Enhancing the anti-steganalysis ability of steganography via adversarial
   examples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Deep learning; Adversarial example; Generative
   adversarial network
ID IMAGE STEGANOGRAPHY; FRAMEWORK
AB Steganography technology can effectively conceal secret information in the carrier medium, enable covert communication without drawing the attention of a third party, and ensure the safe and reliable transmission of confidential information. However, with the development of steganalysis technology, steganalysers based on deep learning can accurately identify the modification traces in the steganographic cover, which poses a huge threat to steganography. Therefore, the focus of the research is how to reduce the detection accuracy of deep learning-based steganalyzer. In this work, we design an Adversarial Example STeganography (AEST) method, which hides the secret grayscale image into the color cover image to obtain the stego image that is difficult to distinguish by the naked eye. Then, the attack module composed of the FGM and PGD adversarial attacks added small perturbations to generate adversarial steganographic images, reducing the detection accuracy of the steganalyzer. In addition, to reduce the impact of adversarial examples on secret information recovery, we designed a decoder based on adversarial training and the generative adversarial network. Finally, the experimental results show that AEST has a good performance of anti-steganalysis ability. For example, the adversarial steganographic image based on PGD attack can make the detection error rate of the XuNet steganalyzer reach 63.511%.
C1 [Peng, Ye; Fu, GuoBin; Yu, Qi; Luo, YingGuang; Hu, Jia; Duan, ChaoFan] Natl Univ Def Technol, Coll Informat & Commun, 45 Liberat Pk Rd, Wuhan 430000, Hubei, Peoples R China.
C3 National University of Defense Technology - China
RP Luo, YG (corresponding author), Natl Univ Def Technol, Coll Informat & Commun, 45 Liberat Pk Rd, Wuhan 430000, Hubei, Peoples R China.
EM pengye17@nudt.edu.cn; lygsuiping@126.com
CR Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Baluja S, 2017, ADV NEUR IN, V30
   Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chaumont M., 2020, Digital Media Steganography, P321, DOI [DOI 10.1016/B978-0-12-819438-6.00022-0, 10.1016/B978-0-12-819438-6.00022-0]
   Donahue J., 2016, arXiv
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Ghamizi S, 2021, IEEE INT CONF COMP V, P31, DOI 10.1109/ICCVW54120.2021.00010
   Ghosal SK, 2021, MULTIMEDIA SYST, V27, P73, DOI 10.1007/s00530-020-00703-3
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Kharrazi M, 2006, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2006.312386
   Kurakin A, 2017, Arxiv, DOI arXiv:1607.02533
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liu J, 2020, IEEE ACCESS, V8, P60575, DOI 10.1109/ACCESS.2020.2983175
   Liu X, 2022, IEEECVF C COMPUTER V, P2303
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Madry A, 2019, Arxiv, DOI arXiv:1706.06083
   Pan WW, 2022, IEEE T PATTERN ANAL, V44, P7871, DOI 10.1109/TPAMI.2021.3114555
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian Y, 2015, ELECT IMAGING
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Reinel TS, 2019, IEEE ACCESS, V7, P68970, DOI 10.1109/ACCESS.2019.2918086
   Ruan F, 2020, J REAL-TIME IMAGE PR, V17, P149, DOI 10.1007/s11554-019-00915-5
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang WX, 2021, IEEE T INF FOREN SEC, V16, P952, DOI 10.1109/TIFS.2020.3025438
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu CY, 2022, PHYSICA A, V605, DOI 10.1016/j.physa.2022.128017
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang CN, 2021, AAAI CONF ARTIF INTE, V35, P3296
   Zhou NR, 2023, SIGNAL PROCESS-IMAGE, V110, DOI 10.1016/j.image.2022.116891
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 47
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15306-z
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100013
DA 2024-07-18
ER

PT J
AU Mohammadpoory, Z
   Nasrolahzadeh, M
   Amiri, SA
AF Mohammadpoory, Zeynab
   Nasrolahzadeh, Mahda
   Amiri, Sekineh Asadi
TI Classification of healthy and epileptic seizure EEG signals based on
   different visibility graph algorithms and EEG time series
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic seizure detection; EEG signals; Visibility graph algorithm;
   Sequential forward feature selection method; Random Forest classifier
ID COMPLEX NETWORKS; SYSTEM; IDENTIFICATION; RECOGNITION; DIAGNOSIS;
   FEATURES
AB Recently, the idea of processing time series by transforming them onto graphs has been used in many studies. One of the simple methods proposed to convert a time series onto a graph is the visibility graph (VG). The current study investigates the ability of different VG algorithms for epileptic seizure detection. In the algorithm, single-channel Electroencephalogram (EEG) signals are transformed onto five different VG graphs, and then 13 features are generated from obtained graphs. After that, efficient features are extracted using the Sequential forward feature selection (SFFS) algorithm and classified by Random Forest (RF) into two or three classes. The experimental results show that VG algorithms are fast and easy on the performance of classification. In addition, it has shown that the proposed method not only is able to discriminate two classes with 100% accuracy, but also recognizes three classes with high accuracy, sensitivity, and specificity of 97.98%, 96.19%, and 99.12%, respectively. The comparison of this study with other methods shows the effectiveness of the proposed method for seizure detection.
C1 [Mohammadpoory, Zeynab] Shahrood Univ Technol, Dept Elect Engn, Shahrood, Iran.
   [Nasrolahzadeh, Mahda] Hakim Sabzevari Univ, Dept Biomed Engn, Sabzevar, Iran.
   [Amiri, Sekineh Asadi] Univ Mazandaran, Dept Engn & Technol, Babolsar, Iran.
C3 Shahrood University of Technology; University of Mazandaran
RP Mohammadpoory, Z (corresponding author), Shahrood Univ Technol, Dept Elect Engn, Shahrood, Iran.
EM z.mohammadpoory@gmail.com; ms.nasrolahzadeh@yahoo.com; s.asadi@umz.ac.ir
CR Acharya UR, 2011, INT J NEURAL SYST, V21, P403, DOI 10.1142/S0129065711002912
   Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808
   Adeli H, 2007, IEEE T BIO-MED ENG, V54, P205, DOI 10.1109/TBME.2006.886855
   Ahadpour S, 2014, INFORM SCIENCES, V274, P286, DOI 10.1016/j.ins.2014.03.007
   Ahmadlou M, 2010, J NEURAL TRANSM, V117, P1099, DOI 10.1007/s00702-010-0450-3
   Amitai G, 2004, J MOL BIOL, V344, P1135, DOI 10.1016/j.jmb.2004.10.055
   Barrat A, 2008, DYNAMICS PROCESSES C, P50
   Bezsudnov IV, 2014, PHYSICA A, V414, P53, DOI 10.1016/j.physa.2014.07.002
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chua KC, 2011, J MED SYST, V35, P1563, DOI 10.1007/s10916-010-9433-z
   del Sol A, 2006, MOL SYST BIOL, V2, DOI 10.1038/msb4100063
   Donner RV, 2011, INT J BIFURCAT CHAOS, V21, P1019, DOI 10.1142/S0218127411029021
   Du X, 2012, J MED SYST, V36, P1731, DOI 10.1007/s10916-010-9633-6
   Firpi H, 2007, IEEE T BIO-MED ENG, V54, P212, DOI 10.1109/TBME.2006.886936
   Gao ZK, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.066303
   GOTMAN J, 1979, ELECTROEN CLIN NEURO, V46, P510, DOI 10.1016/0013-4694(79)90004-X
   Gutin G, 2011, PHYSICA A, V390, P2421, DOI 10.1016/j.physa.2011.02.031
   Institute of Medical Biometry Informatics and Epidemiology of the, MEDIZINISCHEEINRICHT
   Islam MS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030728
   Kim J, 2008, PHYSICA A, V387, P2637, DOI 10.1016/j.physa.2008.01.015
   Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2
   Lacasa L, 2012, EUR PHYS J B, V85, DOI 10.1140/epjb/e2012-20809-8
   Lacasa L, 2009, EPL-EUROPHYS LETT, V86, DOI 10.1209/0295-5075/86/30001
   Lacasa L, 2008, P NATL ACAD SCI USA, V105, P4972, DOI 10.1073/pnas.0709247105
   Lacasa L, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.036120
   Last M, 2001, PATTERN RECOGN LETT, V22, P799, DOI 10.1016/S0167-8655(01)00019-8
   Luque B, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046103
   Mohammadpoory Z., 2018, Iranian Journal of Medical Physics, V15, P286
   Mohammadpoory Z, 2019, COGN NEURODYNAMICS, V13, P325, DOI 10.1007/s11571-019-09527-y
   Mohammadpoory Z, 2019, MEASUREMENT, V140, P133, DOI 10.1016/j.measurement.2019.02.089
   Mohammadpoory Z, 2017, SEIZURE-EUR J EPILEP, V50, P202, DOI 10.1016/j.seizure.2017.07.001
   Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499
   Nakariyakul S, 2009, PATTERN RECOGN, V42, P1932, DOI 10.1016/j.patcog.2008.11.018
   Nasrolahzadeh M., 2014, Asian Journal of the Mathematics and Computational Research, V2, P33
   Nasrolahzadeh M, 2022, MACH LEARN APPL, V7, DOI 10.1016/j.mlwa.2021.100225
   Nasrolahzadeh M, 2020, IEEE ACCESS, V8, P112393, DOI 10.1109/ACCESS.2020.3001426
   Nasrolahzadeh M, 2019, COGN NEURODYNAMICS, V13, P45, DOI 10.1007/s11571-018-9501-5
   Nasrolahzadeh M, 2018, COGN NEURODYNAMICS, V12, P583, DOI 10.1007/s11571-018-9499-8
   Neeraj, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104940
   Newman M. E. J., 2018, Networks: An Introduction, DOI [DOI 10.1093/ACPROF:OSO/9780199206650.001.0001, 10.1093/acprof:oso/9780199206650.001.0001]
   Newman MEJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026126
   Ouyang GX, 2008, CLIN NEUROPHYSIOL, V119, P1747, DOI 10.1016/j.clinph.2008.04.005
   Pei X, 2014, COGN NEURODYNAMICS, V8, P417, DOI 10.1007/s11571-014-9297-x
   Polat K, 2007, APPL MATH COMPUT, V187, P1017, DOI 10.1016/j.amc.2006.09.022
   Rashed-Al-Mahfuz M, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3050925
   Schenk Joachim, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1251, DOI 10.1109/ICDAR.2009.130
   Sharma M, 2017, PATTERN RECOGN LETT, V94, P172, DOI 10.1016/j.patrec.2017.03.023
   Sharmila A, 2016, IEEE ACCESS, V4, P7716, DOI 10.1109/ACCESS.2016.2585661
   Srinivasan V, 2007, IEEE T INF TECHNOL B, V11, P288, DOI 10.1109/TITB.2006.884369
   Swami P, 2016, EXPERT SYST APPL, V56, P116, DOI 10.1016/j.eswa.2016.02.040
   Tang XY, 2013, CLIN EEG NEUROSCI, V44, P150, DOI 10.1177/1550059412464449
   Theodoridis S, 2003, PATTERN RECOGN, P40
   Tzimourta KD, 2019, HEALTH TECHNOL-GER, V9, P135, DOI 10.1007/s12553-018-0265-z
   Tzimourta KD., 2018, BIOMED J SCI TECHN R, V7, P1
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Wang JH, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00016
   Witten I. H., 2005, DATA MINING PRACTICA
   Xiang J, 2015, J NEUROSCI METH, V243, P18, DOI 10.1016/j.jneumeth.2015.01.015
   Zhang J, 2008, PHYSICA D, V237, P2856, DOI 10.1016/j.physd.2008.05.008
   Zhong J, 2012, IEEE ASME INT C ADV, P432, DOI 10.1109/AIM.2012.6265947
   Zhou TT, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.030506
   Zhu GH, 2014, COMPUT METH PROG BIO, V115, P64, DOI 10.1016/j.cmpb.2014.04.001
   Zhu GH, 2013, AIP CONF PROC, V1559, P31, DOI 10.1063/1.4824993
NR 67
TC 2
Z9 2
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15681-7
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800005
DA 2024-07-18
ER

PT J
AU Singh, H
   Sharma, RK
   Singh, VP
AF Singh, Harjeet
   Sharma, R. K.
   Singh, V. P.
TI Language model based suggestions of next possible Gurmukhi character or
   word in online handwriting recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online handwriting recognition; Gurmukhi script; SVM classifier; Bigram
   and trigram language models; Forecasting probabilities
AB In general, the prediction models are increasingly being used for reasoning and decision making in various applications. With the advancements in IT based devices such as Tablet-PC, touch-screen based smart phones, digital-pen/stylus based devices, and digitizers, the demand of real-time based applications is also increasing. The present study describes the Language Model (LM) based forecasting the occurrence of next possible Gurmukhi character/word in a word/sentence, which depends on the immediately preceding character(s)/word(s), written in the real-time environment. The online handwritten captured character/word information is first segmented into its individual strokes, which are recognized using Support Vector Machine (SVM) classifier. Once a character/word is recognized, this will be useful to assist the writers in order to provide the suggestions for next possible character/word. The n-gram language models (bigram and trigram) have been implemented at character- and word-level for this purpose. In this study, the corpus, "PunjabiMonolingual Text Corpus-AnglaMT" (available at https://tdil-dc.in), containing approximately 83,000 sentences has been used for training the model. Experimental results show that the proposed online handwritten character/word forecasting framework significantly outperforms and produce consistent forecasts for the most likely character/word on the basis of given handwritten character/word information and saving computational costs. This model can also be used for many other non-Indic and Indic scripting languages.
C1 [Singh, Harjeet] Chitkara Univ, Inst Engn & Technol, Rajpura 140401, Punjab, India.
   [Sharma, R. K.; Singh, V. P.] Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Chitkara University, Punjab; Thapar Institute of Engineering &
   Technology
RP Singh, H (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura 140401, Punjab, India.
EM harjeet.singh@chitkara.edu.in; rksharma@thapar.edu; vpsingh@thapar.edu
RI Singh, Harjeet/AAE-4215-2020
OI Singh, Harjeet/0000-0002-9760-5166; Singh, V. P./0000-0001-7648-9170
FU Technology Development for Indian Languages (TDIL), DeitY; MoCIT;
   Government of India
FX We take this opportunity to extend our special thank to Technology
   Development for Indian Languages (TDIL), DeitY, MoCIT, and Government of
   India for sponsoring this research work.
CR Abou-zeid HMR, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P969
   Aparna KH, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P438, DOI 10.1109/IWFHR.2004.80
   Bahri H, 1982, TEACH YOURSELF PANJA
   Belhe S, 2012, P WORKSH DOC AN REC, P9, DOI DOI 10.1145/2432553.2432556
   Bharath A, 2009, ADV PATTERN RECOGNIT, P209, DOI 10.1007/978-1-84800-330-9_11
   Bhattacharya U., 2008, P 11 INT C FRON HAND, P320
   Dahake D, 2017, 2017 2 INT C MAN MAC, P1
   Dehghani A, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P506, DOI 10.1109/ITCC.2001.918847
   Graves A., 2008, ADV NEURAL INFORM PR, V20, P1
   Haque Md, 2016, ARXIV
   Jelinek F., 1990, Readings in Speech Recognition, P450, DOI [10.1016/b978-0-08-051584-7.50045-0, 10.1016/B978-0-08-051584-7.50045-0]
   Jurafsky D, 2009, COMPUT LINGUIST
   Kannan RJ, 2008, SECTECH: 2008 INTERNATIONAL CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P159, DOI 10.1109/SecTech.2008.33
   Kumar R, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413530029
   Li YX, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P257
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886
   Perraud F, 2003, PROC INT CONF DOC, P1053
   Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96
   Quiniou S, 2005, PROC INT CONF DOC, P516, DOI 10.1109/ICDAR.2005.220
   Quiniou S, 2006, 10 INT WORKSH FRONT
   Rahiman M. Abdul, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P147, DOI 10.1109/ICMLC.2010.8
   Sharma D., 2010, Int J Comput Appl, V4, P9, DOI DOI 10.5120/850-1188
   SharmaA, 2009, 10 INT C DOC AN REC, P1241, DOI DOI 10.1109/ICDAR.2009.36
   Singh H, 2021, SOFT COMPUT, V25, P6329, DOI 10.1007/s00500-021-05620-9
   Singh H, 2019, NEURAL COMPUT APPL, V31, P3957, DOI 10.1007/s00521-017-3340-x
   Singh H, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0961-4
   Sundaram S, 2015, ACM T ASIAN LOW-RESO, V14, DOI 10.1145/2671014
   Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14
   Zimmermann M, 2004, INT C PATT RECOG, P541, DOI 10.1109/ICPR.2004.1334297
NR 31
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47271
EP 47289
DI 10.1007/s11042-023-14654-0
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984658600003
DA 2024-07-18
ER

PT J
AU Zhao, YM
   Tuo, M
   Zhang, HM
   Zhang, H
   Wu, JN
   Gao, FY
AF Zhao, Yongmei
   Tuo, Mingfu
   Zhang, Hongmei
   Zhang, Han
   Wu, Jiangnan
   Gao, Fengyin
TI Nonnegative low-rank tensor completion method for spatiotemporal traffic
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-Rank Tensor Completion; Non-Negative Tensor Completion; Traffic
   Data; Truncated Nuclear norm
ID SVD-BASED INITIALIZATION; TUCKER DECOMPOSITION
AB Although tensor completion theory performs well with high data missing rates, a lack of attention is encountered at the level of data completion non-negative constraints, and a remaining lack of effective non-negative tensor completion methods is still found. In this article, a new non-negative tensor completion model, based on the low-rank tensor completion theory, called the Nonnegative Weighted Low-Rank Tensor Completion (NWLRTC) method, is proposed. Due to the advantages of Truncated Nuclear Norm (TNN) in low-rank approximation, NWLRTC considers the TNN as the objective optimization function and adds a directional weight factor to the model to avoid its dependency on the data input direction. In addition to considering the completion accuracy, NWLRTC also imposes non-negativity constraints to meet the requirements of practical engineering applications. Finally, NWLRTC is realized by the alternating direction multiplier method. As for the experiments, they are carried out using different methods for generating missing data and for different iteration times. The experimental results show that the NWLRTC algorithm has high completion accuracy at low missing data rates, and it maintains a stable completion accuracy even when the missing rate hits 80%.
C1 [Zhao, Yongmei] Northwestern Polytech Univ, Sch Comp Sci Engn, Xian, Peoples R China.
   [Zhao, Yongmei; Tuo, Mingfu; Zhang, Hongmei; Zhang, Han; Wu, Jiangnan] Air Force Engn Univ, Sch Mat Management & Unmanned Aerial Vehicle Engn, Xian 710051, Peoples R China.
   [Gao, Fengyin] Air Force Engn Univ, Foundmental Dept, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Air Force Engineering University;
   Air Force Engineering University
RP Zhao, YM (corresponding author), Northwestern Polytech Univ, Sch Comp Sci Engn, Xian, Peoples R China.; Zhao, YM (corresponding author), Air Force Engn Univ, Sch Mat Management & Unmanned Aerial Vehicle Engn, Xian 710051, Peoples R China.
EM yong_zhao_2@163.com
RI Zhang, Hongmei/S-8894-2019
FU National Natural Science Foundation of China [6200238]
FX AcknowledgmentsThis work is supported by the National Natural Science
   Foundation of China (No. 6200238).
CR Phan AH, 2011, NEUROCOMPUTING, V74, P1956, DOI 10.1016/j.neucom.2010.06.031
   Atif SM, 2019, PATTERN RECOGN LETT, V122, P53, DOI 10.1016/j.patrec.2019.02.018
   Bengua JA, 2017, IEEE T IMAGE PROCESS, V26, P2466, DOI 10.1109/TIP.2017.2672439
   Bin R, 2016, PLOS ONE, V11, P7
   Chen BL, 2019, IEEE ACCESS, V7, P95903, DOI 10.1109/ACCESS.2019.2929189
   Chen X, 2021, IEEE T INTELL TRANSP, V129
   Chen XY, 2022, IEEE T PATTERN ANAL, V44, P4659, DOI 10.1109/TPAMI.2021.3066551
   Chen XY, 2020, TRANSPORT RES C-EMER, V117, DOI 10.1016/j.trc.2020.102673
   Chen XY, 2019, TRANSPORT RES C-EMER, V98, P73, DOI 10.1016/j.trc.2018.11.003
   Gillis N., 2020, Nonnegative Matrix Factorization
   Guo XW, 2017, AAAI CONF ARTIF INTE, P1948
   Jingnan, 2017, STAT IM ROAD SECT
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li Q, 2020, IEEE ACCESS, V8, P63188, DOI 10.1109/ACCESS.2020.2984588
   Liu CS, 2020, NEUROCOMPUTING, V387, P255, DOI 10.1016/j.neucom.2020.01.009
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Morison G, 2021, EUR SIGNAL PR CONF, P2001, DOI 10.23919/Eusipco47968.2020.9287726
   Nie T, 2022, TRANSPORT RES C-EMER, V141, DOI 10.1016/j.trc.2022.103737
   Pan JJ, 2021, IEEE T PATTERN ANAL, V43, P1546, DOI 10.1109/TPAMI.2019.2956046
   Qiao HL, 2015, PATTERN RECOGN LETT, V63, P71, DOI 10.1016/j.patrec.2015.05.019
   Ran B, 2016, PHYSICA A, V446, P54, DOI 10.1016/j.physa.2015.09.105
   Sinha T.K., 2022, P IEEE CVF WINT C AP, P3732
   Sjolund J., 2022, arXiv
   Song Y, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102791
   Tan HC, 2013, PROCD SOC BEHV, V96, P2431, DOI 10.1016/j.sbspro.2013.08.272
   Tan HC, 2013, TRANSPORT RES C-EMER, V28, P15, DOI 10.1016/j.trc.2012.12.007
   Tsitsikas Y, 2020, BIG DATA-US, V8, P412, DOI 10.1089/big.2020.0074
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wahlberg B, 2012, ADMM ALGORITHM CLASS, P83
   Wang XD, 2019, IEEE INT C INTELL TR, P1658, DOI 10.1109/ITSC.2019.8917169
   Wu Q, 2014, NEUROCOMPUTING, V129, P17, DOI 10.1016/j.neucom.2013.04.049
   Xinyu C., 2018, URBAN TRAFFIC SPEED
   Xu M, 2019, IEEE T INTELL TRANSP, V20, P4704, DOI 10.1109/TITS.2019.2941649
   Xu YY, 2015, MATH PROGRAM COMPUT, V7, P39, DOI 10.1007/s12532-014-0074-y
   Yin WG, 2019, NEUROCOMPUTING, V364, P77, DOI 10.1016/j.neucom.2019.06.054
   Zheng YB, 2019, APPL MATH MODEL, V70, P677, DOI 10.1016/j.apm.2019.02.001
   Zhou GX, 2015, IEEE T IMAGE PROCESS, V24, P4990, DOI 10.1109/TIP.2015.2478396
   Zhou W, 2019, 2019 11 INT C WIRELE
NR 38
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15511-w
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800008
DA 2024-07-18
ER

PT J
AU Abir, NAM
   Warif, NBA
   Zainal, N
AF Abir, Noor Atikah Mat
   Warif, Nor Bakiah Abd
   Zainal, Nurezayana
TI An automatic enhanced filters with frequency-based copy-move forgery
   detection for social media images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital images; Copy-move forgery (CMF); Copy-move forgery detection
   (CMFD); Social media
ID ROBUST-DETECTION; ALGORITHM; ALGEBRA
AB Using images in various file types has become common in the modern digital world, such as social media posts, research reports, and legal documents. The availability of low-cost image manipulation tools has made it easier to change images, potentially leading to undetected image fraud. One such form of image manipulation is copy-move forgery (CMF), which is difficult to detect due to the similarities in image features. There have been efforts to detect CMF using copy-move forgery detection (CMFD) methods. However, most research has focused on CMF images with attacks rather than social media. Social media has contributed significantly to the image manipulation phenomenon, and additional post-processing techniques on social media platforms have affected the efficiency of the CMFD methods. Therefore, this research proposes a two-stage pre-processing phase combined with frequency-based CMFD to detect CMF images in different social media platforms. The first stage includes automatic image selection, followed by image enhancement with filters to improve image quality. The experimental results show that the proposed method achieves the highest detection score compared to existing CMFD methods, with an average score of 90% for CMF-Facebook, 91% for CMF-WhatsApp, and 85% for CMF-Twitter. This research highlights the importance of developing solutions to detect image forgery in social media and the potential of combining pre-processing with frequency-based methods to improve results.
C1 [Abir, Noor Atikah Mat] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Batu Pahat, Johor, Malaysia.
   [Warif, Nor Bakiah Abd] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Ctr Informat Secur Res, Batu Pahat, Johor, Malaysia.
   [Zainal, Nurezayana] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Appl Informat Syst Focus Grp, Batu Pahat, Johor, Malaysia.
C3 University of Tun Hussein Onn Malaysia; University of Tun Hussein Onn
   Malaysia; University of Tun Hussein Onn Malaysia
RP Warif, NBA (corresponding author), Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Ctr Informat Secur Res, Batu Pahat, Johor, Malaysia.
EM nooratikahmatabir@gmail.com; norbakiah@uthm.edu.my;
   nurezayana@uthm.edu.my
OI ABD WARIF, NOR BAKIAH/0000-0002-6226-2271; Zainal,
   Nurezayana/0000-0002-5424-8410
FU Ministry of Higher Education (MOHE) through Fundamental Research Grant
   Scheme [FRGS/1/2020/ICT04/UTHM/02/1]
FX AcknowledgementsThis research was supported by Ministry of Higher
   Education (MOHE) through Fundamental Research Grant Scheme
   (FRGS/1/2020/ICT04/UTHM/02/1).
CR Abd Warif NB, 2019, FORENSIC SCI INT, V295, P83, DOI 10.1016/j.forsciint.2018.12.004
   Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Abir M, 2021, IEEE C PUBLICATION
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ammour N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040312
   [Anonymous], IEEE Journals & Magazine | IEEE Xplore
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bansal, 2019, AUST J FORENSIC SCI, V28, P15
   Barnes C, 2011, COMMUN ACM, V54, P103, DOI 10.1145/2018396.2018421
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Chen JX, 2023, IEEE T CIRC SYST VID, V33, P935, DOI 10.1109/TCSVT.2022.3204753
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   FotoForensics, 2022, US
   Fridrich J, DETECTION COPY MOVE, P10
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Hochman N, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714546645
   Isaac MM, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P394, DOI 10.1145/2791405.2791453
   Ismail A, 2019, INT J INTEGR ENG, V11
   Jaiswal Ankit Kumar, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P471, DOI 10.1109/SPIN48934.2020.9071015
   Langille A., 2006, CRV '06: Proceedings of the The 3rd Canadian Conference on Computer and Robot Vision, Washington, DC, USA, IEEE Computer Society, P64, DOI DOI 10.1109/CRV.2006.9
   Li SX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082702
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Zanardelli M, 2023, MULTIMED TOOLS APPL, V82, P17521, DOI 10.1007/s11042-022-13797-w
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 42
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 8
PY 2023
DI 10.1007/s11042-023-15506-7
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7FF6
UT WOS:000983956900002
DA 2024-07-18
ER

PT J
AU Sharma, VK
   Khandelwal, J
   Singhal, S
AF Sharma, Vijay Kumar
   Khandelwal, Jyoti
   Singhal, Sunita
TI Identification of Best Image Scrambling and Descrambling Method for
   Image Steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image scrambling; Arnold transform; Random image shuffling;
   Steganography; Stego image
ID TRANSFORM; SVD
AB Steganography has a great role in secrete sharing. The secret image is embedded inside the cover image, and it is called stego image. The stego image looks like a cover image with naked eyes. Still, there is a need to enhance the security of a secret image to prevent attacks. Stego image security can be enhanced using scrambling techniques. This paper finds out the best image scrambling technique by studying the different image scrambling methods and their comparative study on different image quality measurements. It compares four image scrambling methods namely Arnold transform, Quantum scrambling, Circular shifting and swapping, Hyperchaotic System and Fibonacci Q-Matrix. It is observed from the results section that Hyperchaotic System and Fibonacci Q-Matrix is excellent method among all four methods.
C1 [Sharma, Vijay Kumar; Khandelwal, Jyoti] Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
   [Singhal, Sunita] Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, India.
C3 Manipal University Jaipur; Manipal University Jaipur
RP Khandelwal, J (corresponding author), Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
EM jyoti.khandelwal19@gmail.com
CR Abed FS., 2011, INT J COMPUT SCI ISS, V8, P514
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bonny T, 2023, MULTIMED TOOLS APPL, V82, P1067, DOI 10.1007/s11042-022-13317-w
   Chaudhary S, 2021, TRAIT SIGNAL, V38, P1113, DOI 10.18280/ts.380422
   Debnath B, 2017, IET CIRC DEVICE SYST, V11, P58, DOI 10.1049/iet-cds.2015.0245
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Hasscne S, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P63, DOI 10.1109/ATSIP.2016.7523060
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Khalili M, 2013, IET SIGNAL PROCESS, V7, P177, DOI 10.1049/iet-spr.2012.0380
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0029-0
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Mengyue Hu, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P147, DOI 10.1109/CISP.2010.5646384
   Mostafa R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P300, DOI 10.1109/IntelCIS.2015.7397238
   Prabakaran G., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P1096, DOI 10.1109/ICCEET.2012.6203811
   Prajwalasimha SN, 2017, 2017 2 INT C ELECT C, P1
   Radwan AG, 2016, P ASME 2016 10 INT C, P1, DOI DOI 10.1115/ES2016-59411
   Rima V. G., 2019, 2019 International Conference on Communication and Electronics Systems (ICCES), P673, DOI 10.1109/ICCES45898.2019.9002412
   Sathiyamurthi P, 2022, MULTIMED TOOLS APPL, V81, P6331, DOI 10.1007/s11042-021-11757-4
   Sharma VK, 2020, 2020 4 INT C EL COMM, P831
   Sirisha BL, 2020, J DISCRET MATH SCI C, V23, P779, DOI 10.1080/09720529.2019.1698801
   Subhedar MS, 2019, MULTIMED TOOLS APPL, V78, P22155, DOI 10.1007/s11042-019-7512-9
   Wang J, 2019, INT J CIRC THEOR APP, V47, P702, DOI 10.1002/cta.2617
   Wu WQ, 2023, MULTIMED TOOLS APPL, V82, P10367, DOI 10.1007/s11042-022-13675-5
   Yuanmei Wang, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P449, DOI 10.1109/ISDEA.2010.198
   Zhang C-Y., 2015, J INF HIDING MULTIME, V6, P666
   Zhou TQ, 2020, FUTURE GENER COMP SY, V108, P1307, DOI 10.1016/j.future.2018.04.008
NR 29
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45659
EP 45678
DI 10.1007/s11042-023-15602-8
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983013200011
DA 2024-07-18
ER

PT J
AU Bhele, S
   Shriramwar, S
   Agarkar, P
AF Bhele, Sujata
   Shriramwar, Shashank
   Agarkar, Poonam
TI An efficient texture-structure conserving patch matching algorithm for
   inpainting mural images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture-structure; Inpainting; Criminisi algorithm; Priority; Confidence
   and data; Similarity distance
AB Preserving heritage paintings across the globe has nowadays gained momentum to let know artistic values of our ancestors in terms of their art techniques and natural material used in creating variety of magnificent paintings so that remains as witness and evidences of ancient historical and cultural heritage. Also, reconstruction of degraded medical images for proper diagnosis is crucial concern for the medical industry. An efficient texture-structure conserving patch matching algorithm (TSCPMA) has been proposed to inpaint the degraded region of an image. The novel feature of Criminisi algorithm to generate large missing areas and reconstruct small gaps is enhanced by improving quality of inpainting and removing existing drawbacks. The priority dependency on confidence and data had been removed by selecting patch to reconstruct with least number of unknown elements. The criteria for minimum similarity distance to select the best patch match had been refined for better patch match thus improving inpainting quality. The target pixel is assigned final value after all unknown pixels from the degraded region have been estimated. The look up table is updated at each iteration so that neighbourhood information can better relate adjacent pixels rather than approximating them with values from other distant known regions of the image. The proposed TSCPMA is able to preserve the color, textural and structural quality of the reconstructed patches as indicated by inpainted results and performance parameters when compared with state of art methods.
C1 [Bhele, Sujata; Shriramwar, Shashank] Priyadarshini Coll Engn, Dept Elect Engn, Digdoh Hills, Nagpur, Maharashtra, India.
   [Agarkar, Poonam] Yeshwantrao Chavan Coll Engn, Dept Elect & Telecommun Engn, Hingna Rd, Nagpur, Maharashtra, India.
C3 Yeshwantrao Chavan College of Engineering
RP Agarkar, P (corresponding author), Yeshwantrao Chavan Coll Engn, Dept Elect & Telecommun Engn, Hingna Rd, Nagpur, Maharashtra, India.
EM sujata_bhele@yahoo.co.in; sshriramwar2@gmail.com;
   poonamagarkar71@gmail.com
RI Bhele, Sujata/IWE-0312-2023
OI Bhele, Sujata/0000-0002-6085-2550; Agarkar, Poonam/0000-0002-6045-0375
CR Abdulla AA, 2021, MULTIMED TOOLS APPL, V80, P13143, DOI 10.1007/s11042-020-10414-6
   Ahmed MW., 2020, UHD J SCI TECHNOL, V4, P1, DOI DOI 10.21928/UHDJST.V4N1Y2020.PP1-8
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Borole RP, 2013, J INTELL SYST, V22, P335, DOI 10.1515/jisys-2013-0031
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Cheng W.-H., 2005, P INT C COMP GRAPH I, P64
   Cheng Y, 2019, 31 INT C SOFTWARE EN, P630
   Cho D, 2008, INT C PATT RECOG, P664
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   DARABI S, 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185578
   Deng LJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141199
   Desai M., 2012, INT J COMPUT APPL, V56, P20, DOI [10.5120/8919-2977, DOI 10.5120/8919-2977]
   Ding D, 2018, PATTERN RECOGN, V83, P174, DOI 10.1016/j.patcog.2018.05.025
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Gouasnouane O., 2022, MATH MODEL COMPUT, V9, P536, DOI [10.23939/mmc2022.03.536, DOI 10.23939/MMC2022.03.536]
   Hou Z, 2016, REV TEC FAC ING UNIV, V39, P203, DOI 10.21311/001.39.9.27
   Ishi MS, 2014, INT C INF COMM EMB S, P1
   Junhong Zhao, 2022, MATEC Web of Conferences, V355, DOI 10.1051/matecconf/202235503004
   Kim BS, 2015, OPTIK, V126, P3978, DOI 10.1016/j.ijleo.2015.07.168
   Kuo TY, 2017, IEEE INT CON MULTI, P1315, DOI 10.1109/ICME.2017.8019405
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Li C., 2022, Journal of Physics: Conference Series, V2253, DOI 10.1088/1742-6596/2253/1/012023
   Liu YF, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P209, DOI 10.1109/CIS.2013.51
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Nan AJ, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P885, DOI 10.1109/BMEI.2014.7002897
   Prajapati A., 2018, INT J COMPUT APPL, V182, P27, DOI [10.5120/ijca2018918042, DOI 10.5120/IJCA2018918042]
   Rao B. Janardhana, 2018, IETE Journal of Education, V59, P26, DOI 10.1080/09747338.2018.1474808
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wang WL, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0186-1
   Wang XT, 2022, MULTIMED TOOLS APPL, V81, P31831, DOI 10.1007/s11042-022-12489-9
   Yamauchi H, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P120, DOI 10.1109/CGI.2003.1214456
   Yao F, 2019, CLUSTER COMPUT, V22, P13683, DOI 10.1007/s10586-018-2068-4
   Yin LX, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P739, DOI 10.1109/ICCT.2012.6511302
   Ying H, 2017, PROCEDIA COMPUT SCI, V107, P796, DOI 10.1016/j.procs.2017.03.175
   Yuan P, 2010, MODIFIED EXEMPLAR BA
   Yuheng S, 2018, ARXIV
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang N, 2020, RES IMPROVED EXEMPL
NR 40
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46741
EP 46762
DI 10.1007/s11042-023-15370-5
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000003
DA 2024-07-18
ER

PT J
AU Liu, YF
   Li, M
   Fan, HJ
AF Liu, Yanfang
   Li, Ming
   Fan, Haiju
TI Cryptanalysis of a color image encryption using minimax differential
   evolution-based 7D hyper-chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen-plaintext attack; 7D hyper-chaotic map; Minimax
   differential evolution
ID ALGORITHM; LORENZ; SYSTEM; TRANSFORM
AB This paper proposes two attack methods to break the encryption algorithm using minimax differential evolution-based 7D hyper-chaotic map. In attack method 1, the secret keys generated by the 7D hyper-chaotic map can be directly revealed through two pairs of plain/cipher images. Once the secret keys are known, any cipher image can be decrypted easily. In attack method 2, we build three dictionary matrices of R, G and B channels firstly, and the corresponding plain image pixel value can be queried in the dictionary matrix one by one without using the secret keys or any system parameter. Experimental results demonstrate that the cryptosystem can be broken successfully by either of the proposed methods, thus avoiding the potential unexpected loss caused by the use of insecure encryption schemes.
C1 [Liu, Yanfang; Li, Ming; Fan, Haiju] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Peoples R China.
   [Liu, Yanfang; Li, Ming; Fan, Haiju] Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan, Peoples R China.
C3 Henan Normal University
RP Li, M (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Peoples R China.; Li, M (corresponding author), Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan, Peoples R China.
EM liming@htu.edu.cn
RI Wang, yl/JNR-4963-2023; Yang, Lili/JTT-5215-2023; Liu,
   Yiwei/JUF-2477-2023; Huang, Jingyi/KCY-2239-2024; Li, Ming/Q-6532-2016;
   zheng, Li/JVN-7465-2024
OI Yang, Lili/0009-0008-2926-484X; Liu, Yanfang/0000-0001-6144-9352
FU National Natural Science Foundation of China [61602158]; Science and
   Technology Research Project of Henan Province [212102210413]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (61602158) and the Science and Technology Research
   Project of Henan Province (212102210413).
CR [Anonymous], 2020, KERCKH PRINC
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chen TH, 2010, INFORM SCIENCES, V180, P1690, DOI 10.1016/j.ins.2009.12.021
   Fan HJ, 2018, SIGNAL PROCESS, V143, P28, DOI 10.1016/j.sigpro.2017.08.018
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Kaur M, 2020, APPL PHYS B-LASERS O, V126, DOI 10.1007/s00340-020-07480-x
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Kaur M, 2018, IET IMAGE PROCESS, V12, P1273, DOI 10.1049/iet-ipr.2017.1016
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li M, 2019, NONLINEAR DYNAM, V96, P31, DOI 10.1007/s11071-019-04771-7
   Qiu X, 2018, IEEE T CYBERNETICS, V48, P1355, DOI 10.1109/TCYB.2017.2692963
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang QG, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500578
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhang E, 2017, INFORM SCIENCES, V387, P180, DOI 10.1016/j.ins.2016.09.056
   Zhang Y, 2020, INFORM SCIENCES, V526, P180, DOI 10.1016/j.ins.2020.03.054
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 26
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44209
EP 44225
DI 10.1007/s11042-023-15445-3
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979973000001
DA 2024-07-18
ER

PT J
AU Dogra, A
   Taqdir
AF Dogra, Amit
   Taqdir
TI DDOS attack prevention and validation with metric based ensemble
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DDOS attack; Network Layer; normalization; KMLP; Voting classifier
ID CHALLENGES; PRIVACY
AB DDOS attack is malicious attack that causes disturbance in service corresponding to target server. Malicious user in this case try to flood the server with large volume of packets. Resources thus will not be available to consumers and network is said to be jammed. The research towards distributed denial of service is carried out. Research indicates that network layer is most prone to this type of attack. The proposed work prevents the DDOS attack by reducing the surface area of the attack. This is accomplished by reducing the exposure of resources to ports and applications. The entire work of prevention is categorized into pre-processing that is accomplished through normalization. This operation is used to bring the features from the dataset into specific range. Feature extraction and selection is with optimal procedure of KMLP. K value indicates the exposure value that will act as threshold for exposing server to different ports and applications. Multi-layer perceptron will be used to select optimal features from extracted features. Classification is the last phase that is accomplished with voting classifier including adaptive boost, random forest and KNN. The result of the classification indicates reduced packet drop and increased lifetime of the network. Packet drop ratio is improved by 10% and lifetime by 7%.
C1 [Dogra, Amit] BGSB Univ, Dept Comp Sci & Engn, SoET, Rajouri, India.
   [Taqdir] Guru Nanak Dev Univ, Dept Comp Sci & Technol, Reg Campus, Gurdaspur, India.
C3 Guru Nanak Dev University
RP Dogra, A (corresponding author), BGSB Univ, Dept Comp Sci & Engn, SoET, Rajouri, India.
EM amitdogra306@gmail.com
CR Behal S, 2018, J NETW COMPUT APPL, V111, P49, DOI 10.1016/j.jnca.2018.03.024
   Behal S, 2016, PROCEDIA COMPUT SCI, V85, P7, DOI 10.1016/j.procs.2016.05.170
   Bhuyan MH, 2014, IEEE COMMUN SURV TUT, V16, P303, DOI 10.1109/SURV.2013.052213.00046
   Cao Y, 2018, IEEE ACCESS, V6, P66641, DOI 10.1109/ACCESS.2018.2877710
   Chang RKC, 2002, IEEE COMMUN MAG, V40, P42, DOI 10.1109/MCOM.2002.1039856
   Cheng JR, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6459326
   Ganapathy S, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-271
   Gu YH, 2019, IEEE ACCESS, V7, P64351, DOI 10.1109/ACCESS.2019.2917532
   Jazi HH, 2017, COMPUT NETW, V121, P25, DOI 10.1016/j.comnet.2017.03.018
   Liu ZT, 2019, IEEE T INF FOREN SEC, V14, P1098, DOI 10.1109/TIFS.2018.2870828
   Meng WZ, 2018, IEEE ACCESS, V6, P7234, DOI 10.1109/ACCESS.2017.2772294
   Misbahuddin M, 2021, J KING SAUD UNIV-COM, V33, P436, DOI 10.1016/j.jksuci.2019.02.003
   Newman S., 2019, NETWORK SECURITY, V2019, P18, DOI [10.1016/S1353-4858(19)30025-X, DOI 10.1016/S1353-4858(19)30025-X]
   Phan TV, 2019, IEEE ACCESS, V7, P18701, DOI 10.1109/ACCESS.2019.2896783
   Praseed A, 2019, IEEE COMMUN SURV TUT, V21, P661, DOI 10.1109/COMST.2018.2870658
   Roman R, 2013, COMPUT NETW, V57, P2266, DOI 10.1016/j.comnet.2012.12.018
   Shiravi A, 2012, COMPUT SECUR, V31, P357, DOI 10.1016/j.cose.2011.12.012
   Simpson S, 2018, IEEE T NETW SERV MAN, V15, P879, DOI 10.1109/TNSM.2018.2828938
   Singh K, 2017, COMPUT SECUR, V65, P344, DOI 10.1016/j.cose.2016.10.005
   Zargar ST, 2013, IEEE COMMUN SURV TUT, V15, P2046, DOI 10.1109/SURV.2013.031413.00127
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44147
EP 44154
DI 10.1007/s11042-023-15523-6
EA APR 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000978477000004
DA 2024-07-18
ER

PT J
AU Nadeem, N
   Hayat, MF
   Qureshi, MA
   Majid, M
   Nadeem, M
   Janjua, J
AF Nadeem, Nida
   Hayat, Muhammad Faisal
   Qureshi, Muhammad Ali
   Majid, Mamoona
   Nadeem, Mehwish
   Janjua, Jamshaid
TI Hybrid Blockchain-based Academic Credential Verification System (B-ACVS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Ethereum; Smart contract; Transaction fee; Etherscan; Legacy
   systems; Replacement; Blockchain adoption; Gas price; Solidity;
   Verification; Fake certificate
ID SMART CONTRACTS
AB Blockchain, the pillar of the Fourth Industrial Revolution (4IR), is being used to provide security to the data of traditional record-keeping systems. However, the implementation of blockchain technology is not easily possible in such systems. For instance, the execution cost of shifting the existing system to the blockchain is extremely high making it unfeasible for many organizations. Moreover, this technology is still immature and is not being fully adopted yet in all parts of the world and may have severe challenges and complexities to achieve its widespread adoption. Considering these two major concerns, the replacement of existing traditional systems with purely Blockchain-based systems will be risky especially in developing countries as it requires major social, legal, and political changes. In this paper, a hybrid Blockchain-based Academic Credential Verification System (B-ACVS) is proposed. The framework combines Blockchain technology with the off-chain centralized data storage that offers facilitation of high security at an affordable cost to any existing system. For a proof of concept, a prototype implementation of a fully transparent, time-saving cost-effective B-ACVS using the proposed hybrid framework is presented. Rich features like Legacy System Support, Hard Commit, and Auto Synchronization of on-chain and off-chain data provide significance to hybrid B-ACVS upon other Blockchain-based solutions. A cost analysis of the proposed hybrid framework along with purely Blockchain-based systems is also provided. The proposed hybrid B-ACVS framework not only provides integrity of data to detect any tempering in off-chain data as well as security of data by utilizing blockchain technology. Thie proposed system is fully recoverable if an attempt is made to destroy it or a part of it.
C1 [Nadeem, Nida; Hayat, Muhammad Faisal] Univ Engn & Technol, Lahore, Pakistan.
   [Qureshi, Muhammad Ali] Islamia Univ Bahawalpur, Bahawalpur, Pakistan.
   [Majid, Mamoona] Natl Univ Comp & Emerging Sci FAST NUCES Lahore, Dept Software Engn, Lahore, Pakistan.
   [Nadeem, Mehwish; Janjua, Jamshaid] Al Khawarizmi Inst Comp Sci, UET Lahore, Lahore, Pakistan.
C3 University of Engineering & Technology Lahore; Islamia University of
   Bahawalpur
RP Qureshi, MA (corresponding author), Islamia Univ Bahawalpur, Bahawalpur, Pakistan.
EM 2017mscs09@student.uet.edu.pk; muhammad.faisal.hayat@uet.edu.pk;
   ali.qureshi@iub.edu.pk; Mamoona.majid01@gmail.com;
   mehwish.nadeem@kics.edu.pk; jamshaid.janjua@kics.edu.pk
RI Qureshi, Muhammad Ali/C-3857-2012
OI Qureshi, Muhammad Ali/0000-0003-4390-2461
CR Alharby M, 2017, ARXIV
   Arenas R, 2018, INT ICE CONF ENG
   Azzi R, 2019, COMPUT IND ENG, V135, P582, DOI 10.1016/j.cie.2019.06.042
   Bakos Y, 2021, COMMUN ACM, V64, P20, DOI 10.1145/3442371
   Bell L., 2018, Blockchain in Healthcare Today, DOI DOI 10.30953/BHTY.V1.8
   Bragagnolo S, 2018, 2018 IEEE 1ST INTERNATIONAL WORKSHOP ON BLOCKCHAIN ORIENTED SOFTWARE ENGINEERING (IWBOSE), P9, DOI 10.1109/IWBOSE.2018.8327566
   Buterin V., 2013, GitHub repository, P22
   Carson B., 2018, Blockchain beyond the hype: What is the strategic business value, V1:, P1
   Chatterjee R, 2017, INT CONF COMPUT INT, P126, DOI 10.1109/CINE.2017.33
   Chen HS, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3391195
   Chen J, 2018, IEEE INFOCOM SER, P2069
   Cheng JC, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P1046, DOI 10.1109/ICASI.2018.8394455
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Efanov D, 2018, PROCEDIA COMPUT SCI, V123, P116, DOI 10.1016/j.procs.2018.01.019
   Ex Batallion, 2018, TRUSTED AC CRED VER
   Froelings L, 2017, BLOCKCHAIN PROJECTS
   GovTech Singapore, 2020, OP
   Gresch J, 2019, LECT NOTES BUS INF P, V339, P185, DOI 10.1007/978-3-030-04849-5_16
   Grolleau G, 2008, J ECON ISSUES, V42, P673, DOI 10.1080/00213624.2008.11507173
   Guang Chen, 2018, Smart Learning Environments, V5, DOI 10.1186/s40561-017-0050-x
   Han DZ, 2022, IEEE T IND INFORM, V18, P3530, DOI 10.1109/TII.2021.3114621
   Hasan M, 2021, PROCEDIA MANUF, V53, P594, DOI 10.1016/j.promfg.2021.06.060
   Hjálmarsson FT, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P983, DOI 10.1109/CLOUD.2018.00151
   Iuon-Chang Lin, 2017, International Journal of Network Security, V19, P653, DOI 10.6633/IJNS.201709.19(5).01
   Jing Li, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P2637, DOI 10.1109/IMCEC.2018.8469456
   Kanan T, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P629, DOI 10.1109/JEEIT.2019.8717505
   Khandelwal H, 2020, ADV CYBERNETICS COGN, P251
   Kumar KD., 2020, INT J SYST ASSUR ENG, V9, P0
   Laurie B, 2004, WORKSH EC INF SEC, V2004
   Le T-V, 2021, IEEE T IND INFORM
   Li SL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART INTERNET OF THINGS (SMARTIOT 2018), P276, DOI [10.1109/SmartloT.2018.00056, 10.1109/SmartIoT.2018.00056]
   Liu L, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P380, DOI 10.1109/ICCCBDA.2018.8386546
   Niranjanamurthy M., 2019, Cluster Computing, V22, P14743, DOI 10.1007/s10586-018-2387-5
   Panescu Adrian-Tudor, 2018, Science & Technology Libraries, V37, P235, DOI 10.1080/0194262X.2018.1474838
   Park JY, 2020, ENTREP SUSTAIN ISS, V7, P3048, DOI 10.9770/jesi.2020.7.4(32)
   Prasad RV, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P90, DOI 10.1109/CIC.2018.00023
   Saleh OS, 2020, BLOCKCHAIN BASED FRA
   Savelyev A, 2017, INF COMMUN TECHNOL L, V26, P116, DOI 10.1080/13600834.2017.1301036
   SEONGKYU KIM, 2019, Journal of Multimedia Information System, V6, P125, DOI 10.33851/JMIS.2019.6.3.125
   Sergey I, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360611
   SHARMA K, 2019, 10 INT C COMP COMM N, P1
   Sharples M, 2016, LECT NOTES COMPUT SC, V9891, P490, DOI 10.1007/978-3-319-45153-4_48
   Sisi Z, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4217
   Skiba DJ, 2017, NURS EDUC PERSPECT, V38, P220, DOI 10.1097/01.NEP.0000000000000190
   Sony Global Education, 2016, SON GLOB ED DEV TECH
   Tariq A, 2019, ARXIV
   Tomov Y.K., 2019, 2019 IEEE 28 INT SCI, DOI [10.1109/ET.2019.8878322, 10.1109/et.2019.8878322, DOI 10.1109/ET.2019.8878322]
   Tran T.-T., 2021, FUTURE DATA SECURITY, V8, P293
   Tsai WT, 2017, 2017 11TH IEEE SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE), P174, DOI 10.1109/SOSE.2017.35
   Yaga D, 2019, ARXIV
   Yan W, 2018, 2 IEEE C EN INT EN S, P1
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhu SD, 2020, IEEE T IND INFORM, V16, P4196, DOI 10.1109/TII.2019.2941735
NR 53
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43991
EP 44019
DI 10.1007/s11042-023-14944-7
EA APR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976820400006
DA 2024-07-18
ER

PT J
AU Kanaparthi, SD
   Patle, A
   Naik, KJ
AF Kanaparthi, Sai Dheeraj
   Patle, Anjali
   Naik, K. Jairam
TI Prediction and detection of emotional tone in online social media mental
   disorder groups using regression and recurrent neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gated recurrent units; Recurrent neural networks; Sentiment analysis;
   Prediction; DistilBERT; VADER; TextBlob
AB Online social media networks have become a significant platform for persons with mental illnesses to discuss their struggles and obtain emotional and informational assistance in recent years. One such platform is Reddit, where sub-groups called 'subreddits' exist, based on a variety of topics including mental illnesses such as anxiety or depression. We analyse the user's interactions to calculate the mental health status by formulating and using a parameter called 'emotional tone' representing the user's emotional state. VADER sentiment analysis and TextBlob are used to categorise emotional tone and find distribution of emotional polarity and subjectivity of comments. For final tone prediction, RNN and State-Of-The-Art word embedding techniques are used to develop a predictive model. The resultant model provides end-to-end categorization and prediction of emotional tone. We obtain results with respect to Weighted L1 Loss that deals with extreme responses. The MODEL transcends all the baselines by at least 12.1% and the final emotional status of the authors is positive.
C1 [Kanaparthi, Sai Dheeraj; Patle, Anjali; Naik, K. Jairam] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Kanaparthi, SD (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur, Madhya Pradesh, India.
EM kanaparthi.saidheeraj@gmail.com; anjalipatle1417@gmail.com;
   Jnaik.cse@nitrr.ac.in
OI Naik, Dr K Jairam/0000-0002-6332-418X
CR Althoff T., 2016, Trans Assoc Comput Linguist
   Althoff T, 2016, ARXIV
   [Anonymous], 2017, Saudi. Med. J., V38, P444
   Baba T, 2020, ADV INFORM NETWORKIN
   Caplan S, 2010, PRIM CARE COMPANION, V12
   Chancellor S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174240
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fraga BS, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P568, DOI 10.1109/WI.2018.00-36
   Gkotsis G, 2017, SCI REP-UK, V7, DOI 10.1038/srep45141
   Gruda D, 2019, COMPUT HUM BEHAV, V98, P245, DOI 10.1016/j.chb.2019.04.020
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Ive Julia, 2018, P 5 WORKSH COMP LING, P69, DOI DOI 10.18653/V1/W18-0607
   Merchant RM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215476
   Park A, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8219
   Saha K, 2020, MEDRXIV
   Sanh V., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.01108
   Shing H.-C., 2018, NAACL HLT, P25, DOI 10.18653/v1/W18-0603
   Silveira B, 2021, FUTURE GENER COMP SY, V125, P641, DOI 10.1016/j.future.2021.07.014
   textblob.readthedocs.io, TEXTBLOB SIMPLIFIED
   Thorstad R, 2019, BEHAV RES METHODS, V51, P1586, DOI 10.3758/s13428-019-01235-z
   World Health Organization, 2013, Mental health action plan
NR 22
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43819
EP 43839
DI 10.1007/s11042-023-15316-x
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001066758900007
PM 37362737
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Malhotra, R
   Singh, P
AF Malhotra, Ruchika
   Singh, Priya
TI Recent advances in deep learning models: a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep Learning; Autoencoder; Convolutional Neural Network; Recurrent
   Neural Network; Generative Adversarial Network; Long Short-Term Memory;
   Transformer Neural Network
ID SHORT-TERM-MEMORY; NEURAL-NETWORK; TIME-SERIES; LSTM; ALGORITHM;
   TRANSFORMER; TEXT
AB In recent years, deep learning has evolved as a rapidly growing and stimulating field of machine learning and has redefined state-of-the-art performances in a variety of applications. There are multiple deep learning models that have distinct architectures and capabilities. Up to the present, a large number of novel variants of these baseline deep learning models is proposed to address the shortcomings of the existing baseline models. This paper provides a comprehensive review of one hundred seven novel variants of six baseline deep learning models viz. Convolutional Neural Network, Recurrent Neural Network, Long Short Term Memory, Generative Adversarial Network, Autoencoder and Transformer Neural Network. The current review thoroughly examines the novel variants of each of the six baseline models to identify the advancements adopted by them to address one or more limitations of the respective baseline model. It is achieved by critically reviewing the novel variants based on their improved approach. It further provides the merits and demerits of incorporating the advancements in novel variants compared to the baseline deep learning model. Additionally, it reports the domain, datasets and performance measures exploited by the novel variants to make an overall judgment in terms of the improvements. This is because the performance of the deep learning models are subject to the application domain, type of datasets and may also vary on different performance measures. The critical findings of the review would facilitate the researchers and practitioners with the most recent progressions and advancements in the baseline deep learning models and guide them in selecting an appropriate novel variant of the baseline to solve deep learning based tasks in a similar setting.
C1 [Malhotra, Ruchika; Singh, Priya] Delhi Technol Univ, Dept Software Engn, Delhi, India.
C3 Delhi Technological University
RP Singh, P (corresponding author), Delhi Technol Univ, Dept Software Engn, Delhi, India.
EM priya.singh.academia@gmail.com
RI SINGH, PRIYA/KLC-6487-2024
OI SINGH, PRIYA/0000-0001-7656-7108
CR Ab Aziz MF, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115441
   Aberbour M., 1998, Proceedings of the IEEE International Symposium on Circuits Systems, V3, P199, DOI [10.1109/ISCAS.1998.703974, DOI 10.1109/ISCAS.1998.703974]
   Ainslie J, 2020, ARXIV
   Akhtar MM, 2023, MULTIMED TOOLS APPL, V82, P17353, DOI 10.1007/s11042-022-13934-5
   Al-Sarem M, 2019, IEEE ACCESS, V7, P152788, DOI 10.1109/ACCESS.2019.2947855
   Alexia JM, 2018, INT C LEARNING REPRE
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Amjady N, 2001, IEEE T POWER SYST, V16, P798, DOI 10.1109/59.962429
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Atassi A, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, CONTROL, OPTIMIZATION AND COMPUTER SCIENCE (ICECOCS)
   Aygun RC, 2017, 2017 IEEE 4 INT C CY, DOI [10.1109/CSCloud.2017.39, DOI 10.1109/CSCLOUD.2017.39]
   Bhaskar S, 2023, MULTIMED TOOLS APPL, V82, P5455, DOI 10.1007/s11042-022-12796-1
   Biolchini L, 2005, SYSTEMATIC REV SOFTW
   Brock Andrew, 2018, Large scale gan training for high fidelity natural image synthesis, P5
   Buettner Ricardo, 2020, 2020 IEEE Symposium on Industrial Electronics & Applications (ISIEA), DOI 10.1109/ISIEA49364.2020.9188131
   Cai CF, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119206
   Chen GX, 2020, IEEE IMAGE PROC, P608, DOI 10.1109/ICIP40778.2020.9191332
   Chen HF, 2010, IEEE T AUTOMAT CONTR, V55, P868, DOI 10.1109/TAC.2010.2041997
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Chen YQ, 2021, I S BIOMED IMAGING, P779, DOI 10.1109/ISBI48211.2021.9434057
   Cheng Z, 2021, INT J INTELL SYST, V36, P7103, DOI 10.1002/int.22582
   Child R., 2019, ARXIV
   Choromanski KM, 2020, RETHINKING ATTENTION
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Clauwaert J, 2022, IEEE ACM T COMPUT BI, V19, P97, DOI 10.1109/TCBB.2020.3035021
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Cui J, 2019, CHIN AUTOM CONGR, P4428, DOI [10.1109/cac48633.2019.8996379, 10.1109/CAC48633.2019.8996379]
   Dai Z., 2020, ADV NEUR IN, V33, P4271
   DAS M, 2019, INT JOINT C NEUR NET, P1, DOI DOI 10.1109/IJCNN.2019.8851757
   Dehuri S, 2012, J SYST SOFTWARE, V85, P1333, DOI 10.1016/j.jss.2012.01.025
   Denton E, 2015, ADV NEUR IN, V28
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding Z, 2019, INT C LEARNING REPRE
   Dos Reis AF, 2022, IEEE ACCESS, V10, P121985, DOI 10.1109/ACCESS.2022.3223113
   Fang X, 2022, IEEE T IND INFORM, V18, P5698, DOI 10.1109/TII.2021.3136562
   Fetanat M, 2022, IEEE T BIO-MED ENG, V69, P1733, DOI 10.1109/TBME.2021.3129459
   Gao F, 2018, COMPUT MED IMAG GRAP, V70, P53, DOI 10.1016/j.compmedimag.2018.09.004
   Gavrilescu R, 2018, INT CONF EXPO ELECTR, P165, DOI 10.1109/ICEPE.2018.8559776
   Geng ZQ, 2022, IEEE T IND INFORM, V18, P1521, DOI 10.1109/TII.2021.3086798
   Gnanha AT, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108222
   Gong WF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071693
   Gu Quan, 2022, ICCSIE '22: Proceedings of the 7th International Conference on Cyber Security and Information Engineering, P725, DOI 10.1145/3558819.3565179
   Gu SH, 2019, LECT NOTES ARTIF INT, V11838, P314, DOI 10.1007/978-3-030-32233-5_25
   Guan J, 2019, INT C LEARNING REPRE
   Guo MS, 2019, AAAI CONF ARTIF INTE, P6489
   Guo QP, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1315
   Guo QP, 2019, IEEE-ACM T AUDIO SPE, V27, P2213, DOI 10.1109/TASLP.2019.2944078
   Hah J, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6465949
   Han LG, 2022, IEEE WINT CONF APPL, P955, DOI 10.1109/WACV51458.2022.00103
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He W, 2017, PROCEDIA COMPUT SCI, V122, P308, DOI 10.1016/j.procs.2017.11.374
   He YL, 2022, ISA T, V127, P350, DOI 10.1016/j.isatra.2021.08.030
   He ZY, 2019, IEEE ACCESS, V7, P115368, DOI 10.1109/ACCESS.2019.2936243
   Heo YJ, 2023, APPL INTELL, V53, P7512, DOI 10.1007/s10489-022-03867-9
   Hsu WN, 2016, IEEE W SP LANG TECH, P467, DOI 10.1109/SLT.2016.7846305
   Hu L., 2014, J INT COUNC ELECT EN, V4, P114, DOI [10.5370/JICEE.2014.4.2.114, DOI 10.5370/JICEE.2014.4.2.114]
   Huang Hao, 2022, 2022 7th International Conference on Image, Vision and Computing (ICIVC), P232, DOI 10.1109/ICIVC55077.2022.9886321
   Huang K, 2022, APPL INTELL, V52, P2838, DOI 10.1007/s10489-021-02566-1
   Huang WW, 2023, INT J PRECIS ENG MAN, V24, P33, DOI 10.1007/s12541-022-00729-9
   Ingle KK, 2021, AEU-INT J ELECTRON C, V138, DOI 10.1016/j.aeue.2020.153371
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jabeen G, 2022, APPL INTELL, V52, P17614, DOI 10.1007/s10489-022-03350-5
   Joshy AA, 2022, IEEE T NEUR SYS REH, V30, P1147, DOI 10.1109/TNSRE.2022.3169814
   Jung W., 2019, PROC MACH LEARN SYST, V1, P14
   Karabayir I, 2021, IEEE T NEUR NET LEAR, V32, P685, DOI 10.1109/TNNLS.2020.2979121
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Khamparia A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12400
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Ayush, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P806, DOI 10.1109/ICACITE51222.2021.9404697
   Kumar M, 2022, IEEE T NETW SCI ENG, V9, P3272, DOI 10.1109/TNSE.2021.3098011
   Kumar N, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105198
   Kuo PH, 2018, ENERGIES, V11, DOI 10.3390/en11010213
   Lata Kusam, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P186, DOI 10.1109/ICECA.2019.8822195
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Changlin, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1586), P398, DOI 10.1007/978-3-031-06767-9_33
   Li JY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163260
   Li JQ, 2022, IEEE ICC, P4462, DOI 10.1109/ICC45855.2022.9839224
   Li L, 2023, IEEE-ACM T AUDIO SPE, V31, P96, DOI 10.1109/TASLP.2022.3214763
   Li QL, 2020, IEEE ACCESS, V8, P182026, DOI 10.1109/ACCESS.2020.3028995
   Li W, 2023, IEEE T NEUR NET LEAR, V34, P10502, DOI 10.1109/TNNLS.2022.3167482
   Li X, 2020, P 34 INT C NEURAL IN, V426, P16997, DOI [10.5555/3495724.3497150, DOI 10.5555/3495724.3497150]
   Li XF, 2022, IEEE T INTELL TRANSP, V23, P2296, DOI 10.1109/TITS.2021.3072872
   Li YC, 2018, IEEE ACCESS, V6, P11342, DOI 10.1109/ACCESS.2018.2804278
   Li Yasong, 2024, IEEE Trans Neural Netw Learn Syst, V35, P6180, DOI 10.1109/TNNLS.2022.3202234
   Li YJ, 2022, IEEE T INTELL TRANSP, V23, P9311, DOI 10.1109/TITS.2021.3071790
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin T., 2022, AI Open, V3, P111, DOI [DOI 10.1016/J.AIOPEN.2022.10.001, 10.1016/j.aiopen.2022.10.001]
   Lirong Yao, 2018, 2018 IEEE International Conference of Safety Produce Informatization (IICSPI). Proceedings, P565, DOI 10.1109/IICSPI.2018.8690387
   Liu BY, 2020, INT J EMBED SYST, V12, P22, DOI 10.1504/IJES.2020.105287
   Liu W, 2021, IEEE J-STARS, V14, P3330, DOI 10.1109/JSTARS.2021.3063911
   Lodha I, 2022, PROCEEDINGS OF THE 5TH JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA, CODS COMAD 2022, P213, DOI 10.1145/3493700.3493731
   Lu SQ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P555, DOI 10.1145/3331184.3331218
   Lu YZ, 2017, MIDWEST SYMP CIRCUIT, P1601, DOI 10.1109/MWSCAS.2017.8053244
   Luo X, 2021, IEEE J BIOMED HEALTH, V25, P3332, DOI 10.1109/JBHI.2021.3083605
   Lv WY, 2021, J INTELL MANUF, V32, P441, DOI 10.1007/s10845-020-01584-z
   Ma J, 2013, J CRYST GROWTH, V370, P265, DOI 10.1016/j.jcrysgro.2012.10.028
   Ma L, 2017, ADV NEURAL INFORM PR
   Martín A, 2022, NEURAL COMPUT APPL, V34, P10205, DOI 10.1007/s00521-022-07344-9
   Mary NAB, 2020, MULTIMED TOOLS APPL, V79, P30601, DOI 10.1007/s11042-020-09521-1
   Mashudi NA, 2022, IEEE ACCESS, V10, P93155, DOI 10.1109/ACCESS.2022.3203065
   McDowall TM, 1997, P SOC PHOTO-OPT INS, V3077, P344, DOI 10.1117/12.271496
   Mirza M, 2014, COMPUTER VISION PATT
   Mittal V, 2021, WIRELESS PERS COMMUN, V119, P2287, DOI 10.1007/s11277-021-08331-4
   Moon T, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P65, DOI 10.1109/ASRU.2015.7404775
   Mou LT, 2019, IEEE ACCESS, V7, P98053, DOI 10.1109/ACCESS.2019.2929692
   Nagabushanam P, 2020, SOFT COMPUT, V24, P9981, DOI 10.1007/s00500-019-04515-0
   Neifar N, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P645, DOI 10.1145/3477314.3507300
   Nguyen TT, 2020, IEEE T CYBERNETICS, V50, P3826, DOI 10.1109/TCYB.2020.2977374
   Ni QJ, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105232
   Odena A, 2017, PR MACH LEARN RES, V70
   Ogundokun RO, 2022, LECT NOTES COMPUT SC, V13381, P593, DOI 10.1007/978-3-031-10548-7_43
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pandey A, 2022, IEEE-ACM T AUDIO SPE, V30, P1374, DOI [10.1109/TASLP.2022.3161143, 10.1109/taslp.2022.3161143]
   Playout C, 2018, LECT NOTES COMPUT SC, V11071, P101, DOI 10.1007/978-3-030-00934-2_12
   Price S.R., 2019, IEEE INT C FUZZY SYS, P1, DOI [DOI 10.1109/FUZZ-IEEE.2019.8858790, 10.1109/FUZZIEEE.2019.8858790, DOI 10.1109/FUZZIEEE.2019.8858790]
   Qing YH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13112216
   Qiu DF, 2022, COMPUT METH PROG BIO, V225, DOI 10.1016/j.cmpb.2022.106995
   Rakotonirina NC, 2020, INT CONF ACOUST SPEE, P3637, DOI 10.1109/ICASSP40776.2020.9054071
   Roy A, 2021, T ASSOC COMPUT LING, V9, P53, DOI 10.1162/tacl_a_00353
   Sermanet P., 2013, INT C LEARNING REPRE
   Serradilla O, 2022, APPL INTELL, V52, P10934, DOI 10.1007/s10489-021-03004-y
   She JK, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892346
   Shi NB, 2022, IEEE ACCESS, V10, P129564, DOI 10.1109/ACCESS.2022.3228600
   Shi YX, 2020, IEEE ACCESS, V8, P155429, DOI 10.1109/ACCESS.2020.3019048
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Shubhendu Kumar, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P34, DOI 10.1109/ICMLA.2019.00015
   Song C., 2021, 3 INT C APPL MACH LE, P76, DOI DOI 10.1109/ICAML54311.2021.00024
   Song JM, 2018, ADV NEUR IN, V31
   Song W, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114936
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang XY, 2019, IEEE ACCESS, V7, P40525, DOI 10.1109/ACCESS.2019.2905634
   Tay Y., 2020, INT C MACHINE LEARNI, P9438, DOI DOI 10.5555/3524938.3525813
   Tian CJ, 2018, ENERGIES, V11, DOI 10.3390/en11123493
   Tripathi BK, 2017, APPL INTELL, V47, P382, DOI 10.1007/s10489-017-0902-7
   Uyar K, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103563
   Valliani AA, 2019, NEUROL THER, V8, P351, DOI 10.1007/s40120-019-00153-8
   Venkatachalam K, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119270
   Vyas A., 2020, Advances in neural information processing systems, V33, P21665
   Wang H, 2019, IEEE INT CONF ELECTR, P312, DOI [10.1109/iceiec.2019.8784610, 10.1109/ICEIEC.2019.8784610]
   Wang JL, 2022, ISPRS J PHOTOGRAMM, V186, P246, DOI 10.1016/j.isprsjprs.2022.02.003
   Wang JL, 2018, IEEE T IND INFORM, V14, P748, DOI 10.1109/TII.2017.2754641
   Wang Q, 2020, IEEE ACCESS, V8, P65395, DOI 10.1109/ACCESS.2020.2985418
   Wang R, 2023, MULTIMED TOOLS APPL, V82, P18691, DOI 10.1007/s11042-022-14228-6
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2019, IEEE INTERNET THINGS, V6, P2933, DOI 10.1109/JIOT.2018.2877510
   Wang ZY, 2021, LECT NOTES ARTIF INT, V12816, P64, DOI 10.1007/978-3-030-82147-0_6
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Wei Liangkun, 2022, 2022 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA), P1370, DOI 10.1109/AEECA55500.2022.9918996
   Wu JH, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105959
   Xia LX, 2019, IEEE INT CONF ASAP, P107, DOI 10.1109/ASAP.2019.00-21
   Xiong YY, 2021, AAAI CONF ARTIF INTE, V35, P14138
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   Xu T, 2017, P IEEE INT C COMP VI, DOI [10.1109/ICCV.2017.629, DOI 10.1109/ICCV.2017.629]
   Xu XL, 2021, PEER PEER NETW APPL, V14, P1829, DOI 10.1007/s12083-020-01043-9
   Xu XL, 2020, OCEAN ENG, V217, DOI 10.1016/j.oceaneng.2020.107704
   Yang M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/2836064
   Yang MM, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107236
   Yang R, 2017, IEEE INT CON MULTI, P817, DOI 10.1109/ICME.2017.8019299
   Yang S, 2022, INT C COMM COMP CYB, P1, DOI [10.1109/CCCI55352.2022.9926584, DOI 10.1109/CCCI55352.2022.9926584]
   Yang YQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112528
   Yin AJ, 2021, IEEE SENS J, V21, P11791, DOI 10.1109/JSEN.2020.3013668
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang L, 2017, IEEE T CYBERNETICS, V47, P3243, DOI 10.1109/TCYB.2016.2588526
   Zhang Y, 2022, IEEE T INTELL TRANSP, V23, P12711, DOI 10.1109/TITS.2021.3116966
   Zhang ZY, 2022, 2022 ASIA CONFERENCE ON ADVANCED ROBOTICS, AUTOMATION, AND CONTROL ENGINEERING (ARACE 2022), P57, DOI 10.1109/ARACE56528.2022.00019
   Zhao HQ, 2011, INFORM SCIENCES, V181, P3677, DOI 10.1016/j.ins.2011.04.033
   Zhao Junbo, 2017, ICLR
   Zhao RY, 2022, IEEE T INTELL TRANSP, V23, P5480, DOI 10.1109/TITS.2021.3054376
   Zheng C, 2019, IEEE T NEUR NET LEAR, V30, P2611, DOI 10.1109/TNNLS.2018.2885219
   Zhong Han, 2022, ICCSIE '22: Proceedings of the 7th International Conference on Cyber Security and Information Engineering, P429, DOI 10.1145/3558819.3565120
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
NR 178
TC 4
Z9 4
U1 20
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44977
EP 45060
DI 10.1007/s11042-023-15295-z
EA APR 2023
PG 84
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000974976800001
DA 2024-07-18
ER

PT J
AU Ramtekkar, PK
   Pandey, A
   Pawar, MK
AF Ramtekkar, Praveen Kumar
   Pandey, Anjana
   Pawar, Mahesh Kumar
TI Accurate detection of brain tumor using optimized feature selection
   based on deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; CNN; GLCM; Histogram segmentation; Particle swarm
   optimization (PSO); Whale optimization algorithm (WOA); Gray wolf
   optimization (GWO)
AB An unusual increase of nerves inside the brain, which disturbs the actual working of the brain, is called a brain tumor. It has led to the death of lots of lives. To save people from this disease timely detection and the right cure is the need of time. Finding of tumor-affected cells in the human brain is a cumbersome and time- consuming task. However, the accuracy and time required to detect brain tumors is a big challenge in the arena of image processing. This research paper proposes a novel, accurate and optimized system to detect brain tumors. The system follows the activities like, preprocessing, segmentation, feature extraction, optimization and detection. For preprocessing system uses a compound filter, which is a composition of Gaussian, mean and median filters. Threshold and histogram techniques are applied for image segmentation. Grey level co-occurrence matrix (GLCM) is used for feature extraction. The optimized convolution neural network (CNN) technique is applied here that uses whale optimization and grey wolf optimization for best feature selection. Detection of brain tumors is achieved through CNN classifier. This system compares its performance with another modern technique of optimization by using accuracy, precision and recall parameters and claims the supremacy of this work. This system is implemented in the Python programming language. The brain tumor detection accuracy of this optimized system has been measured at 98.9%.
C1 [Ramtekkar, Praveen Kumar; Pandey, Anjana; Pawar, Mahesh Kumar] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Bhopal, Madhya Pradesh, India.
C3 Rajiv Gandhi Technological University
RP Ramtekkar, PK (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Bhopal, Madhya Pradesh, India.
EM pramtekkar@rediffmail.com; apeeshukla77@gmail.com; mkpawar24@gmail.com
RI Pawar, Mahesh/AAE-4565-2019
OI Pawar, Mahesh/0000-0002-6520-0025
CR Abdel-Gawad AH, 2020, IEEE ACCESS, V8, P136243, DOI 10.1109/ACCESS.2020.3009898
   [Anonymous], 2012, MED IM CANC CAR CHAR
   Avsar E, 2019, TEH GLAS, V13, P337, DOI 10.31803/tg-20190712095507
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bhima K, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P2109, DOI 10.1109/ICCSP.2016.7754551
   Borole V.Y., 2015, Int J Emerging Trends Technol Comput Sci, V4, P28, DOI [10.2749/IJETTCS.361.944, DOI 10.2749/IJETTCS.361.944]
   Fouad A., 2020, Int J Intell Eng Syst, V13, P40, DOI [10.22266/ijies2020.0430.05, DOI 10.22266/IJIES2020.0430.05]
   Geetha A, 2020, BIOMED ENG-BIOMED TE, V65, P191, DOI 10.1515/bmt-2018-0244
   GONG S, 2019, COMPUT INTELL-US, P1
   Gunasekara SR., 2021, HINDAWI J HEALTHCARE, V2021, P13
   Hebli AP, 2016, P 65 IRF INT C
   Hossain T, 2019, 1 INT C ADV SCI ENG
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Kapoor L, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P582, DOI 10.1109/CONFLUENCE.2017.7943218
   Khan AH, 2022, APPL COMPUT INTELL S, V2022, DOI 10.1155/2022/8104054
   Kumar P., 2016, WORLD J MED SCI, V13, P8592
   Louis DN., 2007, WHO CLASSIFICATION T
   Mishra PK, 2021, OPEN COMPUT SCI, V11, P380, DOI 10.1515/comp-2020-0166
   Parihar AS, 2017, INT CONF COMPUT
   Rammurthy D, 2020, J KING SAUD UNIV-COM, P1
   Ramtekkar PK, 2020, 2020 2 INT C DAT ENG
   Ramtekkar PK, 2023, INT J SYST ASSUR ENG, DOI 10.1007/s13198-022-01819-7
   Shankar K, 2019, COMPUT ELECTR ENG, V77, P230, DOI 10.1016/j.compeleceng.2019.06.001
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sharma AK, 2022, IEEE ACCESS, V10, P17920, DOI 10.1109/ACCESS.2022.3149824
   Sindhu A, 2020, BIOSCI BIOTECH RES C, V13, P1886, DOI 10.21786/bbrc/13.4/38
   Verma SS, 2021, BIOMED SIGNAL PROCES
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
NR 28
TC 7
Z9 7
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44623
EP 44653
DI 10.1007/s11042-023-15239-7
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001066758900004
PM 37362641
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Rao, BM
   Kumar, A
AF Rao, B. Mohan
   Kumar, Aman
TI Explainable detection of atrial fibrillation using deep convolutional
   neural network with UCMFB
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network; Electrocardiogram; Atrial
   fibrillation; Uniform cosine modulated filter bank; Accuracy;
   Specificity; Precision; Sensitivity; F1-score; ROC
ID ARTIFICIAL-INTELLIGENCE; AUTOMATED DETECTION; ECG SIGNALS; FILTER-BANK;
   OUTLIER DETECTION; PREDICTION MODEL; DIAGNOSIS; CLASSIFICATION
AB Atrial fibrillation (AF) is considered to be the most dangerous cardiovascular disease and its prevalence is growing year by year. In this work, an automated detection system for the early identification of atrial fibrillation is presented. A deep convolutional neural network (DCNN) model along with the uniform cosine modulated filter banks (UCMFB) is utilized for the classification purpose. The ECG signal is first decomposed into 8 sub-signals using 8-channel UCMFB and out of which first 6 sub-signals are utilised for the further processing. These sub-signals converted into images using wavelet transform packet (WTP) by considering short segments of 5 seconds. These images are then fed to DCNN model for the classification, and tested over MIT-BIH AF and normal sinus rhythm (NSR) databases. The proposed method has achieved an overall Accuracy of 99.82%, Sensitivity of 99.86%, Precision of 99.86%, Specificity of 99.87%, F1-score of 99.82%, and ROC of 100%. It is observed that the proposed method is able to achieve the best label classification when the ECG signal is converted into images. Also, the DCNN based method decreases the false diagnosis rates in identification of AF.
C1 [Rao, B. Mohan; Kumar, Aman] Natl Inst Technol, Dept Elect & Commun Engn, Hamirpur, Himachal Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Rao, BM (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Hamirpur, Himachal Prades, India.
EM brao@nith.ac.in; akumar@nith.ac.in
OI MOHANRAO, BADAVATH/0000-0002-4159-3119
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Baloglu UB, 2019, PATTERN RECOGN LETT, V122, P23, DOI 10.1016/j.patrec.2019.02.016
   Camm AJ, 2012, EUR HEART J, V33, P2719, DOI 10.1093/eurheartj/ehs253
   Camm AJ, 2010, EUR HEART J, V31, P2369, DOI [10.1093/eurheartj/ehq278, 10.1093/europace/euq350]
   Cervigón R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135908
   Chandra S, 2020, IRBM, V41, P2, DOI 10.1016/j.irbm.2019.06.002
   Chen XJ, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.106009
   [陈煜 Chen Yu], 2013, [航天医学与医学工程, Space Medicine & Medical Engineering], V26, P352
   Chetan A, 2018, J MED BIOL ENG, V38, P304, DOI 10.1007/s40846-017-0294-5
   Cruz-Roldan Fernando, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P2187
   Cui XR, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120677
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Degirmenci M, 2022, IRBM, V43, P422, DOI 10.1016/j.irbm.2021.04.002
   Dhakal S, 2020, PARASITOLOGY, V147, P120, DOI 10.1017/S0031182019001331
   Doblinger G, 2012, IEEE T SIGNAL PROCES, V60, P6693, DOI 10.1109/TSP.2012.2217139
   Dörr M, 2019, JACC-CLIN ELECTROPHY, V5, P199, DOI 10.1016/j.jacep.2018.10.006
   Eswari JS, 2020, BIOMECH MODEL MECHAN, V19, P1697, DOI 10.1007/s10237-020-01300-z
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Ghosh SK, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01565-y
   Ghosh SK, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103632
   Gliner V, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73060-w
   Go AS, 2001, JAMA-J AM MED ASSOC, V285, P2370, DOI 10.1001/jama.285.18.2370
   Goldberger A. L., 1981, Crit. Care Med., P891
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hagiwara Y, 2018, INFORM SCIENCES, V467, P99, DOI 10.1016/j.ins.2018.07.063
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heo TS, 2021, SENSOR MATER, V33, P393, DOI 10.18494/SAM.2021.3023
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jamshidi MB, 2020, IEEE ACCESS, V8, P109581, DOI 10.1109/ACCESS.2020.3001973
   Jo YY, 2021, INT J CARDIOL, V328, P104, DOI 10.1016/j.ijcard.2020.11.053
   Jun TJ, 2018, ARXIV
   Kamaleswaran R, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aaaa9d
   Kharshid A, 2019, 2019 IEEE 2 INT C NE, P1, DOI [10.1109/ICTCS.2019.8923079, DOI 10.1109/ICTCS.2019.8923079]
   Kido K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071731
   Kumar A, 2022, AEU-INT J ELECTRON C, V150, DOI 10.1016/j.aeue.2022.154198
   Kumar M, 2018, BIOCYBERN BIOMED ENG, V38, P564, DOI 10.1016/j.bbe.2018.04.004
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Ladavich S, 2015, BIOMED SIGNAL PROCES, V18, P274, DOI 10.1016/j.bspc.2015.01.007
   Lee J, 2013, IEEE T BIO-MED ENG, V60, P203, DOI 10.1109/TBME.2012.2208112
   Lu L, 2019, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-030-13969-8
   Maji U, 2013, PROC TECH, V10, P45, DOI 10.1016/j.protcy.2013.12.335
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Martis RJ, 2013, KNOWL-BASED SYST, V54, P269, DOI 10.1016/j.knosys.2013.09.016
   Martis RJ, 2012, J MECH MED BIOL, V12, DOI 10.1142/S0219519412400234
   Mousavi S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104057
   Panda R, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103939
   Pourbabaee B, 2018, IEEE T SYST MAN CY-S, V48, P2095, DOI 10.1109/TSMC.2017.2705582
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   She Wan-Jou, 2022, IUI '22 Companion: 27th International Conference on Intelligent User Interfaces, P22, DOI 10.1145/3490100.3516455
   Shi JJ, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6691177
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Stridh M, 2001, IEEE T BIO-MED ENG, V48, P19, DOI 10.1109/10.900245
   Taniguchi H, 2021, INT HEART J, V62, P534, DOI 10.1536/ihj.21-094
   Thakur S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102920
   Tripathy RK, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400449
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang JB, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101662
   Wang TJ, 2003, CIRCULATION, V107, P2920, DOI 10.1161/01.CIR.0000072767.89944.6E
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu RZ, 2018, IEEE ENG MED BIO, P4636, DOI 10.1109/EMBC.2018.8513132
   Zubair M., 2016, Proceedings of the 2016 6th international conference on IT convergence and security (ICITCS), P1, DOI DOI 10.1109/ICITCS.2016.7740310
NR 66
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40683
EP 40700
DI 10.1007/s11042-023-15123-4
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961632300001
DA 2024-07-18
ER

PT J
AU Hadjadj, Z
AF Hadjadj, Zineb
TI A cooperative framework for automated segmentation of tumors in brain
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Brain tumor; SVM classifier; Active contour model (ACM);
   Magnetic resonance imaging (IRM); Region-edge cooperation
ID ACTIVE CONTOURS; SYSTEM
AB Brain tumor segmentation from 2D Magnetic Resonance Images (MRI) is an important task for several applications in the field of medical analysis. Commonly, this task is performed manually by medical professionals, but it is not always obvious due to similarities between tumors and normal tissue and variations in tumor appearance. Therefore, the automation of medical image segmentation remains a real challenge that has attracted the attention of several researchers in recent years. Instead of choosing between region and contour approaches, in this article, we propose a region-edge cooperative method for brain tumor segmentation from MRI images. The region approach used is support vector machines (SVMs), one of the popular and highly motivated classification methods, the method distinguishes between normal and abnormal pixels based on some features: intensity and texture. To control and guide the segmentation region, we take advantage of the Ron Kimmel geodesic Active Contour Model (ACM) which produces a good delimitation of the boundaries of the object. The two methods have been cooperated sequentially in order to obtain a flexible and effective system for brain tumor segmentation. Experimental studies are performed on synthetic and real 2D MRI images of various modalities from the radiology unit of the university hospital center in Bab El Oued Algeria. The used MRI images represent various tumor shapes, locations, sizes, and intensities. The proposed cooperative framework outperformed SVM-based segmentation and ACM-based segmentation when executed independently.
C1 [Hadjadj, Zineb] Res Ctr Sci & Tech Informat CERIST, Algiers, Algeria.
C3 Centre de Recherche sur l'Information Scientifique et Technique (CERIST)
RP Hadjadj, Z (corresponding author), Res Ctr Sci & Tech Informat CERIST, Algiers, Algeria.
EM hadjadj_zineb@yahoo.fr
CR Allioui H, 2020, J COMMUN SOFTW SYS, V16, P143, DOI 10.24138/jcomss.v16i2.830
   Allioui Hanane, 2019, Advanced Intelligent Systems for Sustainable Development (AI2SD'2018). Advanced Intelligent Systems Applied to Health. Advances in Intelligent Systems and Computing (AISC 914), P314, DOI 10.1007/978-3-030-11884-6_28
   Allioui H, 2019, INTELIGENCIA ARTIFIC, V22, P102, DOI 10.4114/intartif.vol22iss63pp102-122
   Amiri S, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P292, DOI 10.1109/ATSIP.2016.7523095
   Babu KR, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCCI50826.2021.9402433
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Benhamza K, 2020, 4 INT C EL ENG CONTR, P1221, DOI [10.1007/978-981-15-6403-1_86, DOI 10.1007/978-981-15-6403-1_86]
   Bensalem S, 2014, THESES
   Boudraa O, 2015, IFIP ADV INF COMM TE, V456, P515, DOI 10.1007/978-3-319-19578-0_42
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Drevelegas A, 2011, IMAGING OF BRAIN TUMORS WITH HISTOLOGICAL CORRELATIONS, SECOND EDITION, P13, DOI 10.1007/978-3-540-87650-2_2
   Gokmen Z., 2012, International Journal of Computer Science Issues, V9, P355
   Gupta B., 2014, INT J COMPUTER SCI M, V3, P1259
   Hamad Yousif Ahmed, 2019, International Journal of Advanced Pervasive and Ubiquitous Computing, V11, P45, DOI 10.4018/IJAPUC.2019010104
   Haroun R, 2005, LECT NOTES ARTIF INT, V3446, P174
   Islam MM, 2021, IRAN J COMPUTER SCI, V4, P125, DOI [10.1007/s42044-020-00078-8, DOI 10.1007/S42044-020-00078-8]
   Jayadevappa D., 2009, INT J SIGNAL PROCESS, V2, p29
   Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4
   Lakshmi Narayanan K., 2021, RECENT TRENDS INTENS, V39, P777, DOI [10.3233/APC210279, DOI 10.3233/APC210279]
   Luo YZ, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/9157341
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nachour Abdelhafid, 2016, International Journal of Computer Information Systems and Industrial Management Applications, V8, P115
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Parveen, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P98, DOI 10.1109/SPIN.2015.7095308
   Shariatpanahi HF, 2006, IEEE IJCNN, P4535
   Sulaiman SN, 2010, IEEE T CONSUM ELECTR, V56, P2661, DOI 10.1109/TCE.2010.5681154
   Vapnik V., 1999, NATURE STAT LEARNING
NR 30
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41381
EP 41404
DI 10.1007/s11042-023-14736-z
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000960423600015
DA 2024-07-18
ER

PT J
AU Jaiswal, AK
   Srivastava, R
AF Jaiswal, Ankit Kumar
   Srivastava, Rajeev
TI Fake region identification in an image using deep learning segmentation
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Digital image forgery; Image segmentation; Deep
   learning; Convolutional neural network
ID MOVE FORGERY DETECTION; SPLICING DETECTION; DIGITAL FORGERIES;
   LOCALIZATION
AB A forged image is a major source of counterfeit news and is mostly used in a spiteful manner such as exciting targeted mob, identity theft, defaming individual, or misleading law bodies. Therefore, a technique is required to detect the tampered regions in a forged image. Deep learning is surpassing technology for prediction or classification tasks in images. Challenges in this technology are a variety of datasets to train the model and specific architecture for a specific application. In this paper, a deep learning model is extended for the localization of tampered regions in a forged image. This is an extension of the well-known U-Net segmentation model. In the proposed model, batch normalization layers and identity-blocks are placed at suitable places of the U-Net model to overcome the challenges such as overfitting and loss of information during max-pooling. To overcome the challenge of the dataset five different publicly available datasets are taken to train, validate and test the model. The trained model is also tested on four created forged images (not belong to the dataset) whose acquisition sources may different i.e. medical image, identity document, natural image, and scanned report. The result of the proposed model is compared with state-of-the-art techniques which show that the method works better than others.
C1 [Jaiswal, Ankit Kumar] Jawaharlal Nehru Univ, Sch Engn, Dept Comp Sci & Engn, New Delhi 110067, India.
   [Srivastava, Rajeev] IIT BHU, Dept CSE, Comp & Vis Lab, Varanasi 221005, India.
C3 Jawaharlal Nehru University, New Delhi; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology BHU Varanasi (IIT
   BHU Varanasi)
RP Jaiswal, AK (corresponding author), Jawaharlal Nehru Univ, Sch Engn, Dept Comp Sci & Engn, New Delhi 110067, India.
EM ankitkrjaiswal.rs.cse17@iitbhu.ac.in; rajeev.cse@iitbhu.ac.in
CR Agarwal Saurabh, 2015, International Journal of Image, Graphics and Signal Processing, V7, P78, DOI 10.5815/ijigsp.2015.10.08
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Chen B, 2020, IEEE T MULTIMEDIA
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   deeplearning.stanford, TUT CONV NEUR NETW
   Dong J, 2018, V1 0 CASIA V2 0 IMAG
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hosny KM, 2022, IEEE ACCESS, V10, P48622, DOI 10.1109/ACCESS.2022.3172273
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   IFS T, 2019, IEEE IFS TC IM FOR C
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iuliani M., 2015, IEEE International Workshop on Information Forensics and Security (WIFS), P1
   Jaiswal AK, 2022, NEURAL PROCESS LETT, V54, P75, DOI 10.1007/s11063-021-10620-9
   Jaiswal AK, 2021, PATTERN ANAL APPL, V24, P655, DOI 10.1007/s10044-020-00930-4
   Jaiswal AK, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01107-z
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kadam KD, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6845326
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Li D, 2019, IEEE IMAGE PROC, P1425, DOI [10.1109/ICIP.2019.8803101, 10.1109/icip.2019.8803101]
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li QW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19325-y
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Mezzofiore G, 2017, THERESA MAY HER CABI
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   NG A, 2020, SLIDES DEEPLEARNING
   Pan X, 2012, INT CONF E BUS ENG, P17, DOI 10.1109/ICEBE.2012.13
   Rao Y, 2016, IEEE INT WORKS INFOR
   Reichman Benjamin, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P266, DOI 10.1007/978-3-030-68763-2_20
   Riess C, 2017, MULTIMED TOOLS APPL, V76, P4747, DOI 10.1007/s11042-016-3655-0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh A, 2018, MULTIMED TOOLS APPL, V77, P28949, DOI 10.1007/s11042-018-6075-5
   Swaminathan A, 2007, IEEE T INF FOREN SEC, V2, P91, DOI 10.1109/TIFS.2006.890307
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Yao H, 2012, IEEE SIGNAL PROC LET, V19, P123, DOI 10.1109/LSP.2011.2182191
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
NR 49
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38901
EP 38921
DI 10.1007/s11042-023-15032-6
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500007
DA 2024-07-18
ER

PT J
AU Rashtehroudi, AR
   Akoushideh, A
   Shahbahrami, A
AF Rashtehroudi, Atefeh Ranjkesh
   Akoushideh, Alireza
   Shahbahrami, Asadollah
TI PESTD: a large-scale Persian-English scene text dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cursive script; Deep learning; Farsi; Arabic; Urdu; Farsi-English;
   Multilingual; Persian-English; Scene text dataset
ID OBJECT DETECTION
AB Extracting text from natural scene images has become a vital issue. The uncertainty of size, color, background, and alignment of the characters make text recognition in natural scene images a demanding challenge. Also, another recent challenge has been the development and expansion of intelligent systems in the field of transportation, especially the recognition of traffic signs, which help ensure safer and easier driving. Therefore, existing a scene-text dataset as a benchmark to generalize researchers' algorithms is critical. This study, as one of the first studies in the field of text-based traffic signs, intends to prepare a Persian-English multilingual dataset (PESTD) that includes 5832 instances including letters, digits, and symbols in three categories: Persian, English, and Persian-English. Due to the similarity of the calligraphy of numbers and letters in Persian (Farsi), Arabic and Urdu languages, The PESTD can be used in all countries with these languages. To prepare PESTD instances, the text detection process was performed on the traffic signs in Iran. The CRAFT feature extraction algorithm with YOLO and the Tesseract engine have been combined to take an effective step to recognize cursive and multilingual languages despite their specific challenges. Experimental results depict that the values of the evaluation criteria in YOLOv5 are better than its older versions. The accuracy and F1-score values on the PESTD have been attained at 95.3% and 92.3%, respectively.
C1 [Rashtehroudi, Atefeh Ranjkesh; Shahbahrami, Asadollah] Guilan Univ, Comp Engn Dept, Rasht, Iran.
   [Akoushideh, Alireza] Tech & Vocat Univ TVU, Elect & Comp Dept, Guilan Branch, Rasht, Iran.
C3 University of Guilan
RP Akoushideh, A (corresponding author), Tech & Vocat Univ TVU, Elect & Comp Dept, Guilan Branch, Rasht, Iran.
EM akushide@tvu.ac.ir
RI Shahbahrami, Asadollah/ABD-2432-2020; Akoushideh, Alireza/K-8143-2019
OI Shahbahrami, Asadollah/0000-0002-5195-1688; Akoushideh,
   Alireza/0000-0001-9958-4613
CR Ahmed SB, 2019, IEEE ACCESS
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Brunessaux S, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P349, DOI 10.1109/DAS.2014.58
   Chernyshova Y, 2021, LECT NOTES COMPUT SC, V12822, P258, DOI 10.1007/978-3-030-86331-9_17
   Chowdhury MA, 2013, INT J COMPUT APPL, V74, P18
   Chtourou I, 2015, PROC INT CONF DOC, P836, DOI 10.1109/ICDAR.2015.7333879
   Dvorin Y, 2009, GOOGLE PATENTS
   Greenwood PM, 2022, TRANSPORT RES F-TRAF, V86, P131, DOI 10.1016/j.trf.2021.08.006
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   International Phonetic Association and International Phonetic Association Staff and others, 1999, HDB INT PHONETIC ASS
   Jaderberg M., 2014, ARXIV
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kheirinejad Saba, 2020, Proceedings of the 10th International Conference on Computer and Knowledge Engineering (ICCKE 2020), P060, DOI 10.1109/ICCKE50421.2020.9303646
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Maier D, 2022, COMMUN METHODS MEAS, V16, P19, DOI 10.1080/19312458.2021.1955845
   Mishra A., 2012, CVPR
   Naiemi F, 2022, MULTIMED TOOLS APPL, V81, P20255, DOI 10.1007/s11042-022-12693-7
   Powers D.M., 2020, arXiv
   Rashtehroudi AR, 2020, INT C MACH VIS IM PR
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Schulz R, 2015, IEEE INT CONF ROBOT, P1100, DOI 10.1109/ICRA.2015.7139313
   SHETTY AK, 2021, P 2021 6 INT C CONVE, P1, DOI DOI 10.1109/I2CT51068.2021.9417895
   Souidene Mseddi W, 2021, EUR SIGNAL PR CONF, P746, DOI 10.23919/EUSIPCO54536.2021.9616354
   Tounsi M, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P140, DOI 10.1109/ASAR.2017.8067776
   Tounsi M, 2015, PROC INT CONF DOC, P1036, DOI 10.1109/ICDAR.2015.7333919
   Tourani A., 2021, 5 INT C PATT REC IM, P1, DOI DOI 10.1109/IPRIA53572.2021.9483461
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Tsai SS, 2011, 18 IEEE INT C IMAGE
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2022, INT J REMOTE SENS, V43, P1323, DOI 10.1080/01431161.2022.2038396
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Wu WT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259283
   Yousfi S, 2015, PROC INT CONF DOC, P1221, DOI 10.1109/ICDAR.2015.7333958
   Zayene O, 2015, 13 INT C DOCUMENT AN
   Zhan FN, 2018, LECT NOTES COMPUT SC, V11212, P257, DOI 10.1007/978-3-030-01237-3_16
   Zhang CS, 2021, IEEE T INTELL TRANSP, V22, P4727, DOI 10.1109/TITS.2020.3017632
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 41
TC 3
Z9 3
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34793
EP 34808
DI 10.1007/s11042-023-15062-0
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000956327700003
DA 2024-07-18
ER

PT J
AU Renzi, G
   Rinaldi, AM
   Russo, C
   Tommasino, C
AF Renzi, Gianluigi
   Rinaldi, Antonio M.
   Russo, Cristiano
   Tommasino, Cristian
TI A storytelling framework based on multimedia knowledge graph using
   linked open data and deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge graph; Linked open data; Deep learning
ID WEB
AB Automatic storytelling is a broad challenge in research contexts such as Natural Language Processing and Contend Based Image Analysis. Despite the considerable achievements of machine learning techniques in these research fields, combining different approaches to fill the gap between an automatic generated story and human handwriting is hard. This work proposes a novel storytelling framework in the Cultural Heritage domain. We developed our framework based on a Multimedia Knowledge Graph (MKG), a crucial point of our work. Furthermore, we populated our Multimedia Knowledge Graph with a focused crawler that employs deep learning techniques to recognise a multimedia object from web resources. Furthermore, we used a combined approach of deep learning techniques and Linked Open Data (LOD) to retrieve information about images and depicted figures using Instance Segmentation. The system has a dynamic, user-friendly interface that guides the user during the storytelling process. Finally, we evaluated the system from a qualitative and quantitative point of view.
C1 [Renzi, Gianluigi; Rinaldi, Antonio M.; Russo, Cristiano; Tommasino, Cristian] Univ Napoli Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
C3 University of Naples Federico II
RP Rinaldi, AM (corresponding author), Univ Napoli Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
EM renzigianluigi2@gmail.com; antoniomaria.rinaldi@unina.it;
   cristiano.russo@unina.it; cristian.tommasino@unina.it
RI Tommasino, Cristian/IST-2432-2023; Rinaldi, Antonio M./O-7452-2019
OI Tommasino, Cristian/0000-0001-9763-8745; Rinaldi, Antonio
   M./0000-0001-7003-4781; Russo, Cristiano/0000-0002-8732-1733
FU Universita degli Studi di Napoli Federico II within the CRUI-CARE
   Agreement
FX Open access funding provided by Universita degli Studi di Napoli
   Federico II within the CRUI-CARE Agreement.
CR Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2016, P 20 SIGNLL C COMP N, DOI 10.18653/v1/K16-1006
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bauer F, 2011, LINKED OPEN DATA ESS, P710
   Capuano A, 2020, MULTIMED TOOLS APPL, V79, P7577, DOI 10.1007/s11042-019-08252-2
   Chen HJ, 2019, SOFT COMPUT, V23, P11409, DOI [10.1007/978-3-030-34139-8_1, 10.1007/s00500-019-04088-y]
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DB A, 2022, AR DB
   Dictionaries OL, 2021, DEF STOR
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Fensel D., 2020, KNOWLEDGE GRAPHS, P1, DOI [10.1007/978-3-030-37439-6_1, DOI 10.1007/978-3-030-37439-6, 10.1007/978-3-030-37439-6]
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang T, 2016, LECT NOTES ARTIF INT, V9652, P233, DOI 10.1007/978-3-319-31750-2_19
   Iacobacci I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P897
   Kim B, 2009, J AM SOC INF SCI TEC, V60, P1012, DOI 10.1002/asi.21041
   Lin CS, 2005, INFORM MANAGE-AMSTER, V42, P683, DOI 10.1016/j.im.2004.04.003
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Littlefield DF, 1992, STUD AM INDIAN LIT, P136
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Loganathan K., 2020, MATER TODAY-PROC, DOI 10.1016/j.matpr.2020.10.624
   Lukin SM, 2018, ARXIV
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moro A., 2014, Trans. Assoc. Computat. Ling., V2, P231, DOI [10.1162/tacl_a_00179, DOI 10.1162/TACL_A_00179]
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   Radford A., 2019, LANGUAGE MODELS ARE
   Ricardo Baeza Y., 2011, MODERN INFORM RETRIE
   Rinaldi AM, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114320
   Rinaldi AM, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES'18), P31, DOI 10.1145/3281375.3281386
   Rinaldi AM, 2019, INT J INTELL INF TEC, V15, P1, DOI 10.4018/IJIIT.2019070101
   Rinaldi AM, 2009, ACM T INTERNET TECHN, V9, DOI 10.1145/1552291.1552293
   Rinaldi AM, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12110183
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shiri A, 2004, LIB REV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wang X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P899
   Yang PC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5356
   Yang X, 2020, CEUR WORKSHOP PROC, V2699
   Yang ZL, 2017, LECT NOTES COMPUT SC, V10667, P109, DOI 10.1007/978-3-319-71589-6_10
   Zhang Y, 2021, PATTERN RECOGN LETT, V143, P43, DOI 10.1016/j.patrec.2020.12.020
   Zhong Z., 2010, Proceedings of the ACL 2010 system demonstrations, P78
NR 45
TC 0
Z9 0
U1 7
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31625
EP 31639
DI 10.1007/s11042-023-14398-x
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000954481800004
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, B
   Liu, JD
   Liu, YJ
   Xu, HQ
   Wang, J
AF Li, Bo
   Liu, Jiandong
   Liu, Yujie
   Xu, Haoqiang
   Wang, Jin
TI Image encryption algorithm with 2D coupled discrete chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Two-dimensional coupled; Tent map; Image encryption
ID SCHEME; MAP
AB A two-dimensional coupled discrete chaotic system is constructed by combining a two-dimensional coupled map lattice with a dynamic discrete tent map. The system has good initial value sensitivity and can quickly generate multi-dimensional integer pseudo-random sequences with uniform distribution properties. Based on this system, a color image encryption algorithm is designed, using the integer pseudo-random sequence generated by the two-dimensional coupled discrete chaos to construct the diffusion function, complete the diffusion operation of pixels, and achieve the position permutation of pixels by using the uniform distribution property of the chaotic sequence to realize the image encryption operation. The simulation results prove that the algorithm has a large key space, high key sensitivity and high security, and can effectively resist common cryptanalysis,and meet the demand for the secure transmission of image data.
C1 [Li, Bo; Liu, Jiandong; Liu, Yujie; Xu, Haoqiang; Wang, Jin] Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
C3 Beijing Institute of Petrochemical Technology
RP Li, B (corresponding author), Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
EM noble-bobo@outlook.com
RI chen, yuying/JNS-9778-2023; wang, wei/JBS-7400-2023; WANG,
   HUI/JFA-9683-2023; Jiang, Yu/JEZ-9814-2023; xu, wei/JZD-2112-2024; li,
   wenjing/JMP-7498-2023; Yang, Tian/JFB-1008-2023; Liu,
   Yujie/IWU-6535-2023; zhou, xian/JYQ-9844-2024; zhang, hui/GXH-6098-2022
OI Liu, Yujie/0000-0002-1153-6156; Li, Bo/0000-0002-6921-9196
FU Beijing Municipal Institution Classification Development Project
   [11000023T000002199202]
FX Beijing Municipal Institution Classification Development Project
   (11000023T000002199202)
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Cover Thomas M., 1991, ELEMENTS INFORM THEO, DOI DOI 10.1002/0471200611
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Gopalakrishnan T, 2019, WIRELESS PERS COMMUN, V109, P437, DOI 10.1007/s11277-019-06573-x
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hua ZY, 2020, IEEE T IND INFORM, V16, P887, DOI 10.1109/TII.2019.2923553
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Irfan M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010104
   ISMAIL O, 2021, NONLINEAR DYNAM, V103, P2805, DOI DOI 10.1007/S11071-021-06235-3
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Noshadian S, 2018, MULTIMED TOOLS APPL, V77, P25569, DOI 10.1007/s11042-018-5807-x
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Wang CF, 2019, NONLINEAR DYNAM, V98, P257, DOI 10.1007/s11071-019-05187-z
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang Y., 2018, ACTA ELECT SIN, V47, P657
   Weisstein Eric W., MathWorld-A Wolfram Web Resource
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Yildirim M, 2020, MICROELECTRON J, V104, DOI 10.1016/j.mejo.2020.104878
   Zhang J, 2021, MULTIMED TOOLS APPL, V80, P27155, DOI 10.1007/s11042-021-10960-7
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
NR 34
TC 0
Z9 0
U1 7
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35379
EP 35400
DI 10.1007/s11042-023-15002-y
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200003
DA 2024-07-18
ER

PT J
AU Kumar, MD
   Sivanarayana, G
   Indira, DNVSLS
   Raj, MP
AF Kumar, Mikkili Dileep
   Sivanarayana, G., V
   Indira, D. N. V. S. L. S.
   Raj, M. Pruthvi
TI Skin cancer segmentation with the aid of multi-class dilated D-net
   (MD<SUP>2</SUP>N) framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-class dilated D-net; Dilated convolution;
   Segmentation; Anisotropic diffusion filter; Cross-entropy; Fusion unit;
   Encoder; Decoder
ID CLASSIFICATION; DIAGNOSIS
AB Skin cancer is one of the world's most hazardous diseases, and identification of skin cancer is more challenging. Recently Deep learning algorithms have evolved to produce outstanding outcomes in a wide range of clinical practices. But classifying different classes of skin cancer is complex due to the fine-grained variability of skin lesion regions. Based on this insight, the current work considers an early and accurate multi-class skin cancer classification issue by introducing a novel deep learning model. As typical deep learning models have fewer receptive fields, they are unable to gather global context information from wider regions, making it difficult to identify diseased areas. Furthermore, in previous studies, the segmented skin lesion region caused higher noise and worse classification accuracy. To overcome the existing problem, a novel Multi-class Dilated D-Net ((MDN)-N-2) framework is introduced to segment and classify multiple classes of skin cancer screening. The encoder phase of the proposed (MDN)-N-2 reduces feature information losses by adopting a downsampling ratio while also distinguishing small skin lesion patches. Dilated manifold Parallel convolution effectively expands the network's receptive field and eliminates the "grid issue" that plagues ordinary dilated convolution. As a result, the model can get more rich feature information of skin lesions areas of dissimilar sizes. Further, the proposed deep learning model initiates the system to accurately segment and classify lesion regions from the input skin image obtained from International Skin Imaging Collaboration.
C1 [Kumar, Mikkili Dileep; Indira, D. N. V. S. L. S.] MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Sivanarayana, G., V] GITAM Univ, Dept Comp Sci, GIT, Visakhapatnam, Andhra Pradesh, India.
   [Raj, M. Pruthvi] NRI Inst Technol, Dept Comp Sci, Guntur, Andhra Pradesh, India.
C3 MLR Institute of Technology; Gandhi Institute of Technology & Management
   (GITAM)
RP Kumar, MD (corresponding author), MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM mikkilidileepkumar@gmail.com
RI DNVSLS, Indira/ABB-1074-2020
OI DNVSLS, Indira/0000-0003-1631-1156
CR López-Leyva JA, 2021, IEEE ACCESS, V9, P35207, DOI 10.1109/ACCESS.2021.3061873
   Abd ElGhany S, 2021, CMC-COMPUT MATER CON, V68, P117, DOI 10.32604/cmc.2021.016102
   Adla D, 2022, DISTRIB PARALLEL DAT, V40, P717, DOI 10.1007/s10619-021-07360-z
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Anjum MA, 2020, IEEE ACCESS, V8, P129668, DOI 10.1109/ACCESS.2020.3009276
   Arora G, 2022, NEURAL COMPUT APPL, V34, P8385, DOI 10.1007/s00521-020-05212-y
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Demir A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P533, DOI [10.1109/tiptekno47231.2019.8972045, 10.1109/CLEOE-EQEC.2019.8871518]
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Gaikwad PS, 2021, INT J ADV SCI RES EN, V6, DOI [10.51319/2456-0774.2021.0015, DOI 10.51319/2456-0774.2021.0015]
   Hekler A, 2019, EUR J CANCER, V120, P114, DOI 10.1016/j.ejca.2019.07.019
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Huang HW, 2021, J DERMATOL, V48, P310, DOI 10.1111/1346-8138.15683
   Jiang SC, 2021, IEEE J BIOMED HEALTH, V25, P1483, DOI 10.1109/JBHI.2021.3052044
   Jinnai S, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10081123
   Kadampur Mohammad Ali, 2020, Informatics in Medicine Unlocked, V18, P119, DOI 10.1016/j.imu.2019.100282
   Khamparia A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3963
   Khan MA, 2021, IEEE J BIOMED HEALTH, V25, P4267, DOI 10.1109/JBHI.2021.3067789
   Majji R, 2020, IET IMAGE PROCESS, V14, P4122, DOI 10.1049/iet-ipr.2020.0318
   Murugan A, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103727
   Murugan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1400-8
   Pham TC, 2020, IEEE ACCESS, V8, P150725, DOI 10.1109/ACCESS.2020.3016653
   Privalle A, 2020, J AM ACAD DERMATOL, V82, P110, DOI 10.1016/j.jaad.2019.08.012
   Rajput G, 2022, INT J IMAG SYST TECH, V32, P354, DOI 10.1002/ima.22616
   Rezvantalab A., 2018, arXiv
   Song L, 2020, IEEE J BIOMED HEALTH, V24, P2912, DOI 10.1109/JBHI.2020.2973614
   Tan TY, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105725
   Thanh DNH, 2020, J DIGIT IMAGING, V33, P574, DOI 10.1007/s10278-019-00316-x
   Thurnhofer-Hemsi K, 2021, NEURAL PROCESS LETT, V53, P3073, DOI 10.1007/s11063-020-10364-y
   Togaçar M, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110714
   Ul Ain Q, 2021, IEEE TETCI, V5, P554, DOI 10.1109/TETCI.2020.2983426
   Yap J, 2018, EXP DERMATOL, V27, P1261, DOI 10.1111/exd.13777
NR 32
TC 6
Z9 6
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35995
EP 36018
DI 10.1007/s11042-023-14605-9
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000949737500001
DA 2024-07-18
ER

PT J
AU Peng, YY
   Luan, PP
   Tu, HB
   Li, X
   Zhou, P
AF Peng, Yuanyuan
   Luan, Pengpeng
   Tu, Hongbin
   Li, Xiong
   Zhou, Ping
TI Pulmonary fissure segmentation in CT images based on ODoS filter and
   shape features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT images; Shape features; 3D skeletonization model; Pulmonary fissure
   segmentation
ID LOBE SEGMENTATION; FRAMEWORK
AB Pulmonary fissure segmentation in computed tomography (CT) images can be treated as important ancillary information in the diagnosis and treatment of pulmonary diseases, yet it poses a nontrivial uncertainty for the segmentation task due to complex structures such as indistinguishable pulmonary vessels, blurring pulmonary fissures and unpredictable pathological deformation. To address these challenges, a useful approach based on an oriented derivative of stick (ODoS) filter and shape features is presented for pulmonary fissure segmentation. Here, we adopt an ODoS filter by fusing its orientation and magnitude information to highlight structural features for fissure enhancement, which can effectively distinguish between pulmonary fissures and undesirable clutter. Motivated by the fact that pulmonary fissures appear as linear structures in 2D space and planar structures in 3D space in the orientation field, an orientation curvature criterion and an orientation partition scheme are fused to separate fissure patches and other structures in different orientation partitions, which is expected to achieve more complete fissure detection and suppress other structures. Considering the shape difference between pulmonary fissures and tubular structures in the magnitude field, a shape measurement approach and a 3D skeletonization model are combined to remove clutter for pulmonary fissure segmentation. When applying our scheme to 55 chest CT scans acquired from publicly available LOLA11 datasets, the median F1-score, false discovery rate (FDR), and false negative rate (FNR) were 0.90, 0.11, and 0.10, respectively, which indicates that our scheme has satisfactory pulmonary fissure segmentation performance.
C1 [Peng, Yuanyuan; Luan, Pengpeng; Tu, Hongbin] East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330000, Peoples R China.
   [Peng, Yuanyuan] Northwestern Polytech Univ, Sch Comp Sci, Xian 710000, Peoples R China.
   [Li, Xiong] East China Jiaotong Univ, Sch Software, Nanchang 330000, Peoples R China.
   [Zhou, Ping] Hunan Univ, Coll Biol, Changsha 410000, Peoples R China.
C3 East China Jiaotong University; Northwestern Polytechnical University;
   East China Jiaotong University; Hunan University
RP Peng, YY (corresponding author), East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang 330000, Peoples R China.; Peng, YY (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710000, Peoples R China.
EM 3066@ecjtu.edu.cn
OI Luan, Pengpeng/0009-0002-9190-7099; Peng, Yuanyuan/0000-0003-2154-9759
FU Jiangxi Provincial Natural Science Foundation [20212BAB202007,
   20202BAB212004, 20212BAB211009, 20204BCJL23035, 20192ACB21004,
   20181BAB202017]; Hunan Provincial Natural Science Foundation
   [2021JJ30165]; Hunan Special Funds for the Construction of Innovative
   Province(Huxiang High-level Talent Gathering Project-Innovative talents)
   [2019RS1072]; Educational Science Research Project of China Institute of
   communications Education [JTYB20-33]; Scientific and Technological
   Research Project of Education Department in Jiangxi Province [GJJ190356,
   GJJ210645]; Science and Technology project of Changsha City [kq2001014]
FX This research was supported by the Jiangxi Provincial Natural Science
   Foundation (nos. 20212BAB202007, 20202BAB212004, 20212BAB211009,
   20204BCJL23035, 20192ACB21004, 20181BAB202017), the Hunan Provincial
   Natural Science Foundation (no. 2021JJ30165), the Hunan Special Funds
   for the Construction of Innovative Province(Huxiang High-level Talent
   Gathering Project-Innovative talents) (no. 2019RS1072), the Educational
   Science Research Project of China Institute of communications Education
   (no. JTYB20-33), the Scientific and Technological Research Project of
   Education Department in <EM><STRONG> </STRONG></EM>Jiangxi Province
   (nos. GJJ190356, GJJ210645) and the Science and Technology project of
   Changsha City (no. kq2001014).
CR Ananthanarasimhan J., 2020, Plasma Research Express, V2, DOI 10.1088/2516-1067/abae49
   Anitha S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1396-0
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Bragman FJS, 2017, IEEE T MED IMAGING, V36, P1650, DOI 10.1109/TMI.2017.2688377
   Buck SD., 2022, INT J COMPUT ASS RAD, V2022, P1
   Chen M, 2022, CLIN ORAL INVEST, V26, P901, DOI 10.1007/s00784-021-04071-8
   Das A, 2022, MULTIMED TOOLS APPL, V81, P5407, DOI 10.1007/s11042-021-11787-y
   Ding SF, 2020, IET IMAGE PROCESS, V14, P4461, DOI 10.1049/iet-ipr.2020.0475
   Diniz JOB, 2021, MULTIMED TOOLS APPL, V80, P29367, DOI 10.1007/s11042-021-11153-y
   Doel T, 2015, COMPUT MED IMAG GRAP, V40, P13, DOI 10.1016/j.compmedimag.2014.10.008
   Doel T, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1491, DOI 10.1109/ISBI.2012.6235854
   Gerard SE, 2019, I S BIOMED IMAGING, P1207, DOI [10.1109/ISBI.2019.8759212, 10.1109/isbi.2019.8759212]
   Gerard SE, 2019, IEEE T MED IMAGING, V38, P156, DOI 10.1109/TMI.2018.2858202
   Giuliani N, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P387, DOI 10.5220/0006624103870394
   Goyal A, 2019, MED BIOL ENG COMPUT, V57, P1213, DOI 10.1007/s11517-019-01952-9
   Gu XM, 2019, MED PHYS, V46, P3603, DOI 10.1002/mp.13648
   He WL, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107778
   Jia JN, 2021, I S BIOMED IMAGING, P1329, DOI 10.1109/ISBI48211.2021.9433985
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Klinder T, 2013, PROC SPIE, P919
   Kuchana M, 2021, MULTIMED TOOLS APPL, V80, P9161, DOI 10.1007/s11042-020-10010-8
   Lee S, 2019, J THORAC DIS, V11, pS420, DOI 10.21037/jtd.2018.11.78
   Liu JX, 2021, INT J COMPUT ASS RAD, V16, P895, DOI 10.1007/s11548-021-02360-x
   Liu JZ, 2023, INT J PAVEMENT ENG, V24, DOI 10.1080/10298436.2022.2134570
   Manjunath M, 2021, INDIAN J RADIOL IMAG, V31, P797, DOI 10.1055/s-0041-1741045
   Pang HW, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105792
   Panigrahi L, 2019, EXPERT SYST APPL, V115, P486, DOI 10.1016/j.eswa.2018.08.013
   Passah A, 2021, IET IMAGE PROCESS, V15, P1285, DOI 10.1049/ipr2.12104
   Peng YY, 2022, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.755309
   Peng YY, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5588629
   [彭圆圆 Peng Yuanyuan], 2020, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V32, P1154
   Peng YY, 2018, BIOMED SIGNAL PROCES, V43, P278, DOI 10.1016/j.bspc.2018.03.013
   Qiang LI, 2020, 2020 International Conference on Machine Learning and Cybernetics (ICMLC), P224, DOI 10.1109/ICMLC51923.2020.9469543
   Ross JC, 2020, COMPUT MED IMAG GRAP, V83, DOI 10.1016/j.compmedimag.2020.101712
   Roy R, 2020, IEEE ENG MED BIO, P1282, DOI [10.1109/EMBC44109.2020.9175310, 10.1109/embc44109.2020.9175310]
   Shukla AK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101883
   Sinaga NS., 2022, J INFORM MANAG INF T, V2, P60
   Srinidhi CL, 2018, BIOMED SIGNAL PROCES, V44, P110, DOI 10.1016/j.bspc.2018.04.016
   Tan W, 2022, ARXIV
   van Rikxoort E.M., 2011, Proc. of the Fourth International Workshop on Pulmonary Image Analysis, P261
   van Rikxoort EM, 2010, IEEE T MED IMAGING, V29, P1286, DOI 10.1109/TMI.2010.2044799
   Wang H, 2020, ENERGY REP, V6, P1033, DOI 10.1016/j.egyr.2020.11.080
   Wang X., 2022, OXID MED CELL LONGEV, V2022, P2022
   Wiemker R, 2005, INT CONGR SER, V1281, P1121, DOI 10.1016/j.ics.2005.03.130
   Xiao CY, 2016, IEEE T MED IMAGING, V35, P1488, DOI 10.1109/TMI.2016.2517680
   Xiao RN, 2019, ALGORITHMS, V12, DOI 10.3390/a12040075
   Xie ZH, 2022, MULTIMED TOOLS APPL, V81, P19151, DOI 10.1007/s11042-021-10537-4
   Yue KJ, 2018, IET IMAGE PROCESS, V12, P1450, DOI 10.1049/iet-ipr.2017.1071
   Zhang F, 2020, MULTIMED TOOLS APPL, V79, P33215, DOI 10.1007/s11042-020-09660-5
   Zhang JP, 2022, MULTIMED TOOLS APPL, V81, P16133, DOI 10.1007/s11042-022-12055-3
   Zhao H, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107602
   Zheng SH, 2021, IET IMAGE PROCESS, V15, P1644, DOI 10.1049/ipr2.12133
NR 52
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34959
EP 34980
DI 10.1007/s11042-023-14931-y
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000949737500009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tiwari, A
AF Tiwari, Anurag
TI Wilson's disease classification using higher-order Gabor tensors and
   various classifiers on a small and imbalanced brain MRI dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wilson's disease; Gabor tensors; Tucker decomposition; Low-rank
   approximation; J48; Support vector machine; RF; XGBoost classifier
ID PREDICTION; FEATURES; MACHINE
AB Wilson's Disease (WD) is a rare, autosomal recessive disorder caused by excessive accumulation of Copper (Cu) in various human organs such as the liver, brain, and eyes. Accurate WD diagnosis is challenging because of: (1) subtle intensity variations in infected tissues, and (2) Biased training results in case of a small and imbalanced dataset. This study provides a novel WD classification model for a small MRI dataset (3072 scans). The proposed study explores multi-dimensional Gabor kernels in five scales and eight orientations to produce pixel-specific features and process them in the 4th-order tensor format. The tucker decomposition technique is applied to obtain approximate factors from the Gabor tensors set. Five-fold cross-validation results show that the proposed classification model achieves 99.91% classification accuracy which is better than four well-known feature extraction techniques: (1) 2D-Discrete Wavelet Transform, (2) Intensity histograms, (3) Histogram of oriented gradients, and (4) Grey level co-occurrence matrix. Also, our method improves the classification accuracy by an average of 33% and Area Under the Curve (AUC) by 25% over the above-mentioned feature extraction techniques. In the latter category, the performance of the proposed method is compared with three deep learning models: (1) Customized Convolution Neural Network (CCNN), (2) AlexNet, and (3) VGGNet. In addition, it enhances classification accuracy by 10%, 3.5%, and 3%, compared to CCNN, AlexNet, and VGGNet, respectively. Also, our proposed approach is computationally fast compared to discussed feature extraction techniques.
C1 [Tiwari, Anurag] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiyala 147002, India.
C3 Thapar Institute of Engineering & Technology
RP Tiwari, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiyala 147002, India.
EM anuragtiwari575@gmail.com
RI TIWARI, ANURAG/GWR-3545-2022
OI TIWARI, ANURAG/0000-0003-3237-1888
CR Agarwal M, 2021, MED BIOL ENG COMPUT, V59, P511, DOI 10.1007/s11517-021-02322-0
   Alom MZ, 2018, arXiv
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Awan MJ., 2021, ANN ROM SOC CELL BIO, V25, P5296
   Beheshti Z, 2018, CYBERNET SYST, V49, P452, DOI 10.1080/01969722.2018.1541597
   Brewer GJ, 2003, NORD GUIDE RARE DISO, P506
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chou CP, 2015, J CHIN MED ASSOC, V78, P719, DOI 10.1016/j.jcma.2015.06.018
   Collins CJ, 2021, GASTROENTEROLOGY, V160, P2367, DOI 10.1053/j.gastro.2021.02.052
   Dinapoli N, 2018, INT J RADIAT ONCOL, V102, P765, DOI 10.1016/j.ijrobp.2018.04.065
   Dusek P, 2020, MOVEMENT DISORD, V35, P994, DOI 10.1002/mds.28018
   Dusek P, 2018, J MAGN RESON IMAGING, V47, P282, DOI 10.1002/jmri.25702
   Garg M, 2021, NEURAL COMPUT APPL, V33, P1311, DOI 10.1007/s00521-020-05017-z
   Ghaffar TYA, 2011, BMC PEDIATR, V11, DOI 10.1186/1471-2431-11-56
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Hao ZF, 2013, IEEE T IMAGE PROCESS, V22, P2911, DOI 10.1109/TIP.2013.2253485
   He J, 2018, CHIN AUTOM CONGR, P4146, DOI 10.1109/CAC.2018.8623238
   Heckemann RA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129211
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Jun Ou, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P215, DOI 10.1109/ICCMS.2010.45
   Karaboga D., 2010, Scholarpedia, V5, P6915, DOI [DOI 10.4249/SCHOLARPEDIA.6915, 10.4249/scholarpedia.6915]
   Khan S, 2019, J GRID COMPUT, V17, P239, DOI 10.1007/s10723-018-9459-x
   Kim YH, 2007, ROUTL CRIT INTRO URB, P1
   Kisil I, 2021, ARXIV
   Liu YY, 2014, ADV NEUR IN, V27
   Livne M, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00097
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Mameniskiene R, 2017, SEIZURE-EUR J EPILEP, V44, P74, DOI 10.1016/j.seizure.2016.10.010
   Medici V, 2021, BIOMOLECULES, V11, DOI 10.3390/biom11081243
   MORI E, 1989, J NEUROL NEUROSUR PS, V52, P1260, DOI 10.1136/jnnp.52.11.1260
   Morsing A, 2019, EUR J NUCL MED MOL I, V46, P2138, DOI 10.1007/s00259-019-04402-8
   Movellan J. R., 2002, Open Source Document, V40, P1
   Nainggolan Rena, 2019, Journal of Physics: Conference Series, V1361, DOI 10.1088/1742-6596/1361/1/012015
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Raghavaiah P, 2021, MULTIMED TOOLS APPL, V80, P26411, DOI 10.1007/s11042-021-10928-7
   Ranjan A, 2015, CLIN NEUROL NEUROSUR, V138, P31, DOI 10.1016/j.clineuro.2015.07.013
   Saba L, 2020, ELECTRON LETT, V56, P1395, DOI 10.1049/el.2020.2102
   Saba Luca, 2019, Front Biosci (Elite Ed), V11, P166
   Sharma H., 2016, Int J Sci Res (IJSR), V5, P2094, DOI [DOI 10.21275/V5I4.NOV162954, 10.21275/v5i4.NOV162954]
   Shim HJ, 2021, ARXIV
   Shribman S, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.04.27
   Smith S.M., 2000, BET: Brain extraction tool
   Speiser JL, 2019, EXPERT SYST APPL, V134, P93, DOI 10.1016/j.eswa.2019.05.028
   Taeger D, 2014, STATISTICAL HYPOTHESIS TESTING WITH SAS AND R, P1, DOI 10.1002/9781118762585
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Thurnhofer-Hemsi K, 2020, ARXIV
   Tiwari A, 2022, EXPERT SYST APPL, V196, DOI 10.1016/j.eswa.2022.116621
   Trivedi VK, 2022, MULTIMED TOOLS APPL, V1-28, P81
   Unser M, 2010, IEEE T IMAGE PROCESS, V19, P636, DOI 10.1109/TIP.2009.2038832
   Wang P, 2021, PATTERN RECOGN LETT, V141, P61, DOI 10.1016/j.patrec.2020.07.042
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wiens TS, 2008, ECOL MODEL, V212, P244, DOI 10.1016/j.ecolmodel.2007.10.005
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yang Y, 2007, CELL MOL LIFE SCI, V64, P601, DOI 10.1007/s00018-007-6396-4
   Yu GY, 2020, INT J HYDROGEN ENERG, V45, P30244, DOI 10.1016/j.ijhydene.2020.08.042
   Zheng YB, 2021, AAAI CONF ARTIF INTE, V35, P11071
NR 58
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35121
EP 35147
DI 10.1007/s11042-023-14979-w
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946494700005
DA 2024-07-18
ER

PT J
AU Li, HJ
   Chen, JY
   Sun, XH
   Li, CB
   Chen, JJ
AF Li, Hongjun
   Chen, Jinyi
   Sun, Xiaohu
   Li, Chaobo
   Chen, Junjie
TI Multi-memory video anomaly detection based on scene object distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Scene object distribution; Multi-memory;
   Anomaly positioning
ID INTRUSION DETECTION SYSTEM; NETWORK; ATTACK
AB With the popularity of surveillance equipment and the rise of intelligent surveillance, video anomaly detection has gradually become a research hotspot. Among them, for video processing, the three-channel video frame data can be directly used as the input of model, or some motion information can be extracted from the video frame, such as calculating optical flow, and then motion information and video frame can be input into the model together for anomaly detection. However, since the amount of background information in the overall situation is far greater than that of object information, abnormal objects are not concerned. In addition, there ia a phenomenon that objects close to the camera are more likely to be judged as anomalous due to the difference in viewpoint resulting in different sizes of objects captured in the scene. This paper proposes a multi-memory video anomaly detection algorithm based on scene object distribution. Firstly, add local anomaly branch to the model, and use memory modules to explicitly model the multiple normal modes of the global frame and the local object; secondly, scale the object to the same measurement standard according to the scene object distribution, which alleviates the impact of the view difference; finally, considering the difficulty of anomaly positioning, a new anomaly location method that combines global anomalies and local anomalies is proposed. The experimental results on the UCSD Ped2, CUHK Avenue and ShanghaiTech datasets have obtained AUC values of 96.75%, 84.34% and 77.08% respectively, which shows that the proposed method attains competitive detection accuracy.
C1 [Li, Hongjun; Chen, Jinyi; Sun, Xiaohu; Li, Chaobo; Chen, Junjie] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] TONGKE Sch Microelect, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), TONGKE Sch Microelect, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 2010320025@stmail.ntu.edu.cn;
   2010310052@stmail.ntu.edu.cn; 1811310007@yjs.ntu.edu.cn;
   cjjcy@ntu.edu.cn
OI sun, xiao hu/0000-0002-5501-5424; li, hongjun/0000-0001-7500-4979; Chen,
   Junjie/0000-0003-4219-6171; Li, Chaobo/0000-0003-3772-3344
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Nanjing University State Key Lab [KFKT2019B15]; Nantong
   Science and Technology Program [JC2021131]; Postgraduate Research and
   Practice Innovation Program of Jiangsu Province [KYCX21_3084,
   KYCX22_3340]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61871241, Grant 61971245 and Grant 61976120, in part
   by Nanjing University State Key Lab. for Novel Software Technology under
   Grant KFKT2019B15, in part by Nantong Science and Technology Program
   JC2021131 and in part by Postgraduate Research and Practice Innovation
   Program of Jiangsu Province KYCX21_3084 and KYCX22_3340.
CR Bahrami M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103232
   Bedja-Johnson Z, 2022, APPL OCEAN RES, V120, DOI 10.1016/j.apor.2021.103030
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Cai YH, 2021, NEUROCOMPUTING, V423, P264, DOI 10.1016/j.neucom.2020.10.044
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chaudhary A, 2014, INT C REC ADV INN EN, P1
   Chaudhary A, 2015, SMART INNOV SYST TEC, V32, P345, DOI 10.1007/978-81-322-2208-8_32
   Chaudhary A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P178, DOI 10.1109/ICROIT.2014.6798326
   Chaudhary A, 2014, IEEE INT ADV COMPUT, P256, DOI 10.1109/IAdCC.2014.6779330
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Doshi K, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107865
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Fernando T, 2020, NEURAL NETWORKS, V127, P67, DOI 10.1016/j.neunet.2020.04.011
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kingma D. P., 2014, arXiv
   Kumar Krishan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P385, DOI 10.1007/978-981-10-7895-8_30
   Kumar K, 2019, ADV INTELL SYST, V748, P453, DOI 10.1007/978-981-13-0923-6_39
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Lee S, 2021, PROC CVPR IEEE, P3053, DOI 10.1109/CVPR46437.2021.00307
   Li B, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103249
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, NEUROCOMPUTING, V444, P332, DOI 10.1016/j.neucom.2019.12.148
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shin W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500343
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang WQ, 2021, NEUROCOMPUTING, V433, P37, DOI 10.1016/j.neucom.2020.12.025
   Wang ZG, 2021, IEEE SIGNAL PROC LET, V28, P1794, DOI 10.1109/LSP.2021.3107750
   Wei BB, 2022, NEUROCOMPUTING, V471, P161, DOI 10.1016/j.neucom.2021.10.112
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu CK, 2022, CLUSTER COMPUT, V25, P2715, DOI 10.1007/s10586-021-03439-5
   Wu RZ, 2021, NEUROCOMPUTING, V462, P523, DOI 10.1016/j.neucom.2021.05.112
   Xu Z, 2022, INTELL AUTOM SOFT CO, V31, P1703, DOI 10.32604/iasc.2022.016919
   Yu L, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104374
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhong YH, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108336
NR 52
TC 1
Z9 1
U1 6
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35557
EP 35583
DI 10.1007/s11042-023-14956-3
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000945311800004
DA 2024-07-18
ER

PT J
AU Zhou, L
   Yuan, XH
   Liu, YY
   Chen, ZL
   Xie, P
AF Zhou, Lin
   Yuan, Xiaohui
   Liu, Yuanyuan
   Chen, Zhanlong
   Xie, Peng
TI Secure map legends based on just noticeable distortion and watermark bit
   recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Legends; Watermarking; Copyright protection
AB An important component of cartography, the map legends can be a type of hybrid data with small data quantity and high precision. Therefore, its watermark method should be versatile to all map legend data types. In addition, its watermark should be robust, imperceivable, and small. In this regard, our study proposes a novel watermarking method of map legends for copyright protection. The data types of map legends are evaluated. According to the data types and just noticeable distortion tolerance, the watermark bit embedding positions of each data type are defined. A text watermark is adopted to reduce the number of watermark bits. By the watermark bit count, map legends are divided into groups to contain multiple watermarks. Meanwhile, a watermark bit recovery method is designed to fix the damaged watermark bits based on the extracted ones, which ensures greater robustness. The experimental results demonstrate the proposed method achieves the expected goal in terms of various types of attacks and image operations.
C1 [Zhou, Lin; Liu, Yuanyuan; Chen, Zhanlong; Xie, Peng] China Univ Geosci, Wuhan, Peoples R China.
   [Yuan, Xiaohui] Univ North Texas, Denton, TX 76203 USA.
C3 China University of Geosciences; University of North Texas System;
   University of North Texas Denton
RP Yuan, XH (corresponding author), Univ North Texas, Denton, TX 76203 USA.
EM xiaohui.yuan@unt.edu
RI xie, peng/IQU-6481-2023; liu, yuanyuan/IQS-2755-2023
OI Yuan, Xiaohui/0000-0001-6897-4563
FU National Natural Science Foundation of China [41871305]; National Key R
   & D Program of China [2017YFC0602204]
FX This work was supported by the National Natural Science Foundation of
   China, grant number 41871305, and the National Key R & D Program of
   China, grant number 2017YFC0602204.
CR Abubahia A, 2017, MULTIMED TOOLS APPL, V76, P12205, DOI 10.1007/s11042-016-3441-z
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Gomathisankaran M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING (GRC), P120, DOI 10.1109/GrC.2013.6740392
   Hamouda E, 2014, P INT C COMP COMM NE, P1
   He WT, 2013, IEEE INT CONF CON AU, P1098
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Jungyeop Kim, 2011, Proceedings of the 2011 7th International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA 2011), P154
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Li SS, 2012, PROCEDIA ENGINEER, V29, P1331, DOI 10.1016/j.proeng.2012.01.136
   Lv Yan-li, 2010, 2010 Second IITA International Conference on Geoscience and Remote Sensing (IITA-GRS 2010), P560, DOI 10.1109/IITA-GRS.2010.5602689
   Rosiyadi D, 2015, INT CARN CONF SECU, P304
   Wang L, 2017, INT GEOSCI REMOTE SE, P815, DOI 10.1109/IGARSS.2017.8127077
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wu MG, 2017, CARTOGR GEOGR INF SC, V44, P62, DOI 10.1080/15230406.2015.1102083
   Yang CS, 2020, MULTIMED TOOLS APPL, V79, P30709, DOI 10.1007/s11042-020-08916-4
   Yuan X, 2016, SECURE MEDICAL IMAGE, P155
   Zeng P, 2017, SECUR COMMUN NETW, V2017
   Zhao HT, 2013, INT ARCH PHOTOGRAMM, V40-2, P65
   Zheng Zhang, 2012, 2012 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER), P1, DOI 10.1109/CYBER.2012.6319873
   [周林 Zhou Lin], 2017, [测绘科学, Science of Surveying and Mapping], V42, P137
NR 21
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29037
EP 29056
DI 10.1007/s11042-023-14452-8
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000945792800001
DA 2024-07-18
ER

PT J
AU Prasath, GA
   Annapurani, K
AF Prasath, G. Arun
   Annapurani, K.
TI Prediction of sign language recognition based on multi layered CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Deep learning; Multi-layer convolutional
   neural network; Linear and non-linear features; Higher level and
   lower-level features; Precision; Accuracy
ID GESTURE RECOGNITION; SPEECH
AB Sign Language Recognition (SLR) helps to bridge the gap between ordinary and hearing-impaired people. But various difficulties and challenges are faced by SLR system during real-time implementation. The major complexity associated with SLR is the inability to provide a consistent recognition process and it shows lesser recognition accuracy. To handle this issue, this research concentrates on adopting the finest classification approach to provide a feasible end-to-end system using deep learning approaches. This process transforms sign language into the voice for assisting the people to hear the sign language. The input is taken from the ROBITA Indian Sign Language Gesture Database and some essential pre-processing steps are done to avoid unnecessary artefacts. The proposed model is incorporated with the encoder Multi-Layer Convolutional Neural Networks (ML-CNN) for evaluating the scalability, accuracy of the end-to-end SLR. The encoder analyses the linear and non-linear features (higher level and lower level) to improve the quality of recognition. The simulation is carried out in a MATLAB environment where the performance of the ML-CNN model outperforms the existing approaches and establishes the trade-off. Some performance metrics like accuracy, precision, F-measure, recall, Matthews Correlation Coefficient (MCC), Mean Absolute Error (MAE) are evaluated to show the significance of the model. The prediction accuracy of the proposed ML-CNN with encoder is 87.5% in the ROBITA sign gesture dataset and it's increased by 1% and 3.5% over the BLSTM and HMM respectively.
C1 [Prasath, G. Arun] SRM Inst Sci & Technol, Sch Comp, Dept Networking & Commun, Chengalpattu 603203, Tamilnadu, India.
   [Annapurani, K.] SRM Inst Sci & Technol Kattankulathur, Sch Comp, Dept Networking & Commun, Chengalpattu 603203, Tamilnadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Prasath, GA (corresponding author), SRM Inst Sci & Technol, Sch Comp, Dept Networking & Commun, Chengalpattu 603203, Tamilnadu, India.
EM ag7678@srmist.edu.in
RI G, Arun Prasath/IQS-7973-2023
OI G, Arun Prasath/0000-0002-8962-2249; Annapurani, K/0000-0003-0551-3705
CR Abid MR, 2015, IEEE T INSTRUM MEAS, V64, P596, DOI 10.1109/TIM.2014.2351331
   Al-Hammadi M, 2020, IEEE CONSUM ELECTR M, V9, P95, DOI 10.1109/MCE.2019.2941464
   Ali Z, 2017, IEEE ACCESS, V5, P3900, DOI 10.1109/ACCESS.2017.2680467
   Assaleh K., 2010, Journal of Intelligent Learning Systems and Applications, V2, P19, DOI 10.4236/jilsa.2010.21003
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan YJ, 2019, PATTERN RECOGN, V88, P643, DOI 10.1016/j.patcog.2018.12.015
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P744
   Guo D, 2018, AAAI CONF ARTIF INTE, P6845
   Hosoe H, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P85, DOI 10.23919/MVA.2017.7986796
   Huang J, 2018, AAAI CONF ARTIF INTE, P2257
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Kim T, 2017, COMPUT SPEECH LANG, V46, P209, DOI 10.1016/j.csl.2017.05.009
   Kim Y, 2014, IEEE T SYST MAN CY-S, V44, P981, DOI 10.1109/TSMC.2014.2298214
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Lim KM, 2016, J VIS COMMUN IMAGE R, V40, P538, DOI 10.1016/j.jvcir.2016.07.020
   Mousa AED, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1023
   Muhammad G, 2018, IEEE COMMUN MAG, V56, P60, DOI 10.1109/MCOM.2018.1700790
   Nandy Anup, 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P712, DOI 10.1109/ICCCT.2010.5640434
   Nandy A, 2010, COMM COM INF SC, V70, P102
   Nimisha Kp, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P186, DOI 10.1109/ICCSP48568.2020.9182351
   Poon G, 2019, MULTIMED TOOLS APPL, V78, P23469, DOI 10.1007/s11042-019-7660-y
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P885
   Quesada L, 2017, J AMB INTEL HUM COMP, V8, P625, DOI 10.1007/s12652-017-0475-7
   Saha S, 2018, ADV INTELL SYST, V518, P271, DOI 10.1007/978-981-10-3373-5_27
   Sincan OM, 2020, IEEE ACCESS, V8, P181340, DOI 10.1109/ACCESS.2020.3028072
   Stefanidis Kiriakos, 2020, IGI Global, P50, DOI DOI 10.4018/978-1-5225-5294-9.CH009
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1483, DOI 10.1145/3240508.3240671
   Wu J, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN)
   Zhang JG, 2017, IEEE T CYBERNETICS, V47, P960, DOI 10.1109/TCYB.2016.2535122
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao TM, 2018, IEEE INFOCOM SER, P1457, DOI 10.1109/INFOCOM.2018.8486006
   Zhou H, 2019, IEEE INT CON MULTI, P1282, DOI 10.1109/ICME.2019.00223
NR 35
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29649
EP 29669
DI 10.1007/s11042-023-14548-1
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943009100009
DA 2024-07-18
ER

PT J
AU Mungekar, RP
   Jayagowri, R
AF Mungekar, Rohit Pravin
   Jayagowri, R.
TI Color tone determination prior algorithm for depth variant underwater
   images from AUV's to improve processing time and image quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color tone determination; Gamma correction; Image fusion; Red channel
   restoration; Underwater image quality metrics
AB There are different movements of AUV based on the design and if the AUV glides up and down underwater, so the images captured by the AUV cameras are depth variant images. In this scenario processing and getting high quality images and its information with the less battery power consumption has become a challenge. Recent AUV technology to capture the underwater images demands dedicated hardware unit to obtain clear underwater images without any haze. Since, underwater images are available in different color tones depending on the depth at which images are taken by the AUV cameras requires different processing methods. In this paper, a single hardware unit with Color tone determination prior (CTDP) algorithm is proposed to integrate with AUV's to process with different color tone images and produce good results. In our proposed image processing method, during the first phase of our work, we determined the color tone using CTDP and restored the red channel. In the second phase, white balancing and image fusion is performed to improve the underwater images for artifact free blending. Our method is experimented on various images of underwater image enhancement benchmark dataset (UIEBD). The results are compared with state-of-art underwater image enhancement methods for different metrics and it is observed that our method maintains the image quality in many benchmark images, it also shows improvement in non-reference metrics UIQM by 6% to 15%, by maintaining proper entropy and UCIQE and full reference metrics PSNR by 5% and SSIM by 11% as compared with previous works. Also, in our paper we proposed the power optimization techniques to be implemented on the proposed hardware unit.
C1 [Mungekar, Rohit Pravin; Jayagowri, R.] BMS Coll Engn, Bangalore 560019, India.
C3 BMS College of Engineering
RP Mungekar, RP (corresponding author), BMS Coll Engn, Bangalore 560019, India.
EM mungekar.lvs19@bmsce.ac.in; rjayagowri.ece@bmsce.ac.in
RI R, JAYAGOWRI/ABW-7876-2022
OI R, JAYAGOWRI/0000-0003-2492-5748; Pravin Mungekar,
   Rohit/0000-0001-7927-4415
FU BMS College of Engineering, Bangalore, India
FX This work was supported in part by BMS College of Engineering,
   Bangalore, India.
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D., 2017, P BRIT MACH VIS C, V1
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-757
   Gong YH, 2016, IEEE J-STSP, V10, P99, DOI 10.1109/JSTSP.2015.2506122
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Lee Ho Sang, 2020, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V57, P47
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Liu RS, 2019, IEEE T NEUR NET LEAR, V30, P2973, DOI 10.1109/TNNLS.2018.2862631
   Muthukumar P, 2021, P NATL A SCI INDIA A, V91, P661, DOI 10.1007/s40010-021-00763-8
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Sharma S, 2022, ENG SCI TECHNOL, V32, DOI 10.1016/j.jestch.2021.09.005
   Trembanis A., 2021, Encyclopedia of Geology, P251, DOI DOI 10.1016/B978-0-12-409548-9.12466-2
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Younggun Cho, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P710, DOI 10.1109/ICRA.2017.7989087
   Yu CE, 2020, TOURISM MANAGE, V80, DOI 10.1016/j.tourman.2020.104110
   Zhang WD, 2019, IEEE ACCESS, V7, P182259, DOI 10.1109/ACCESS.2019.2959560
   Zhang WD, 2019, IEEE ACCESS, V7, P72492, DOI 10.1109/ACCESS.2019.2920403
   Zuras D., 2008, 7542008 IEEE, V754-2008, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2008.5976968]
NR 30
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31211
EP 31231
DI 10.1007/s11042-023-14773-8
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500009
DA 2024-07-18
ER

PT J
AU Petrovic, N
   Milovancevic, M
AF Petrovic, Nikola
   Milovancevic, Milos
TI Historical survey of communication satellites for television
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Satellite; TV; Transponder; Ku band; C band
AB This paper presents a survey of data related to development of the communication satellites for TV broadcasting, located in the geostationary orbit, for the period starting with the emergence of the first commercial satellite television broadcasting in 1965 up to 2018. It presents development of the satellite network technology through the number of satellites and active satellite transponders in the Ku and C bands at the end of each year for the mentioned period. These numbers are presented graphically for different geographical zones. Moreover, a list of satellite TV operators with their basic characteristics and availability, as well as their numbers of satellites and active Ku and C transponders are given as a tabular presentation.
C1 [Petrovic, Nikola; Milovancevic, Milos] Univ Nis, Fac Mech Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
C3 University of Nis
RP Milovancevic, M (corresponding author), Univ Nis, Fac Mech Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
EM milovancevic@uni.org.rs
OI Petrovic, Nikola/0000-0002-9166-1263
CR [Anonymous], SATELLITES TV
   [Anonymous], CHRONOLOGY SPACE LAU
   [Anonymous], TV SATELLITES
   astrochymist, US
   Car V, 2010, MEDIJSKE STUD, V1, P91
   CHAPLIN J, 1992, ELECTRON COMMUN ENG, V4, P33, DOI 10.1049/ecej:19920010
   Choi CQ, 1998, 1 COMMUNICATION SATE
   daviddarling, SATELLITE MOLNIYA
   Haykin S, TELECOMMUNICATION SY, V1
   ISHIDA J, 1982, IEEE T BROADCAST, V28, P165, DOI 10.1109/TBC.1982.266464
   Maral G., 2009, SATELLITE COMMUNICAT, DOI [10.1002/9780470834985, DOI 10.1002/9780470834985]
   Marcotte, 2012, ROAD UHDTV
   Martin, 1991, COMMUNICATION SATELL
   Martin D.H., 2006, Communication satellites, V5th
   Mignone V, 2011, P IEEE, V99, P1905, DOI 10.1109/JPROC.2011.2161848
   Mirabito M., 2004, The new communication technologies, V5th
   Pattan Bruno., 1993, Satellite Systems: Principles and Technologies
   Pechard S, 2006, IEEE IMAGE PROC, P409, DOI 10.1109/ICIP.2006.312480
   Solyman AAA, 2020, IEEE ACCESS, V8, P67591, DOI 10.1109/ACCESS.2020.2982001
   tbs-satellite, GEOSTATIONARY TELECO
   Thompson P, 2015, IEEE INT CONF COMM, P1669, DOI 10.1109/ICCW.2015.7247420
   Tirro S., 1993, SATELLITE COMMUNICAT, DOI [10.1007/978-1-4615-3006-0, DOI 10.1007/978-1-4615-3006-0]
   Valenti MC, 2011, MODERN DIGITAL SATEL
NR 23
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25289
EP 25306
DI 10.1007/s11042-023-14952-7
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000940775500001
DA 2024-07-18
ER

PT J
AU Gowada, R
   Pawar, D
   Barman, B
AF Gowada, Raghavendra
   Pawar, Digambar
   Barman, Biplab
TI Unethical human action recognition using deep learning based hybrid
   model for video forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unethical human action recognition (UHAR); Multimedia forensics; 3D CNN;
   Two-stream Inflated 3D ConvNet (I3D); Spatio temporal attention (STA);
   Hybrid STA+I3D
AB With the rapid growth in multimedia collections around the world, video forensics faces new obstacles in recognizing human actions under video surveillance systems, human-computer interaction, etc. that requires multiple activity recognition systems. Due to issues such as background clutter, partial occlusion, scaling, viewpoint, lighting, and appearance, recognizing human activities from video sequences or still images is a difficult process. In the literature, there are a variety of Deep Learning methods that can be employed to solve the problems of unethical human action recognition which are effective in learning low-level temporal and spatial features but struggle from learning high-level features that affect the feature learning capability of the model. Due to this problem, deep learning methods suffer from poor performance and learning ability. From digital forensic perspective, deep analysis of video has become a prerequisite in human action recognition methods concerning to cyber-crime investigation and prevention. In this paper, we propose a Deep Learning based hybrid model for unethical human action recognition using two-stream inflated 3D ConvNet (I3D) and spatio-temporal attention (STA) modules. The I3D model improves the performance of 3D CNN architecture by inflating 2D convolution kernels into 3D kernels and STA increases the learning capability by giving attention to each frame's spatial and temporal information. To test the capability of our model, we have built a multi-action dataset using the subset of diverse datasets like Weizmann, HMDB51, UCF-101, NPDI, and UCF-Crime then compared our proposed model with existing models using unique and multi-action datasets to show better performance capability.
C1 [Gowada, Raghavendra; Pawar, Digambar; Barman, Biplab] Cent Univ, Univ Hyderabad, Sch CIS, Prof CR Rao Rd, Hyderabad 500046, Telangana, India.
C3 University of Hyderabad
RP Gowada, R (corresponding author), Cent Univ, Univ Hyderabad, Sch CIS, Prof CR Rao Rd, Hyderabad 500046, Telangana, India.
EM rscholar2018@gmail.com
RI Gowada, Raghavendra/IZE-0533-2023
OI Pawar, Digambar/0000-0002-1540-5647
CR [Anonymous], 2021, INDIATODAY
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Battiato S, 2016, COMPUTER SYSTEMS AND TECHNOLOGIES, COMPSYSTECH'16, P5, DOI 10.1145/2983468.2983470
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   da Silva MV, 2018, IB C PATT REC, P547
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Huang YK, 2020, IEEE ACCESS, V8, P45753, DOI 10.1109/ACCESS.2020.2978223
   Jahandad, 2019, PROCEDIA COMPUT SCI, V161, P475, DOI 10.1016/j.procs.2019.11.147
   Jalal A, 2019, J ELECTR ENG TECHNOL, V14, P455
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Liu GC, 2020, ALGORITHMS, V13, DOI 10.3390/a13110301
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Maqsood R, 2021, MULTIMED TOOLS APPL, V80, P18693, DOI 10.1007/s11042-021-10570-3
   Moustafa M, 2015, ARXIV
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sharma S, 2017, Towards Data Sci, V6, P310, DOI [DOI 10.33564/IJEAST.2020.V04I12.054, 10.33564/IJEAST.2020.v04i12.054]
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Xianyuan Wang, 2019, IOP Conference Series: Materials Science and Engineering, V569, DOI 10.1088/1757-899X/569/3/032035
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhu Y., 2019, ARXIV
NR 34
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28713
EP 28738
DI 10.1007/s11042-023-14508-9
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936195100005
DA 2024-07-18
ER

PT J
AU Dang, TL
   Pham, TH
   Dang, QM
   Monet, N
AF Dang, Tuan Linh
   Pham, Trung Hieu
   Dang, Quang Minh
   Monet, Nicolas
TI A lightweight architecture for hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Lightweight architecture; Segmentation;
   Classification
AB This paper proposes a lightweight architecture to recognize hand gestures that can be implemented in the resource-constrained device. There are two main components in our proposed architecture. The first component uses segmentation algorithms as preprocessing to remove noise and irrelevant parts from the input data, while the second component employs a classification algorithm to recognize hand gestures. Different lightweight segmentation and classification algorithms were also investigated and customized. Experimental results showed that the proposed lightweight architecture obtained high accuracy with various datasets even with noisy and complicated-background samples, especially with the combinations of DeepLabV3+ as the segmentation method and MobileNetV2 or EfficientNetB0 as the classification method. In addition, the inference speed of our lightweight system can achieve approximately 20 milliseconds with the fastest backbone even without using a high-end GPU.
C1 [Dang, Tuan Linh; Pham, Trung Hieu; Dang, Quang Minh] Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, 01 Dai Co Viet Rd, Hanoi 100000, Vietnam.
   [Monet, Nicolas] NAVER CLOVA, Avatar, 6 Buljeong Ro, Seongnam Si, Gyeonggi Do, South Korea.
C3 Hanoi University of Science & Technology (HUST); Naver
RP Dang, TL (corresponding author), Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, 01 Dai Co Viet Rd, Hanoi 100000, Vietnam.
EM linhdt@soict.hust.edu.vn; hieu.pt194763@sis.hust.edu.vn;
   minh.dq194796@sis.hust.edu.vn; monet.nicolas@navercorp.com
OI Dang, Tuan Linh/0000-0002-9966-5576
FU Hanoi University of Science and Technology and Naver Corporation.
FX This work was supported by the cooperation between Hanoi University of
   Science and Technology and Naver Corporation.
CR [Anonymous], 2019, MOBILENETV3 IMPLEMEN
   [Anonymous], 2020, DATABASE HAND GESTUR
   Baheti B, 2020, PATTERN RECOGN LETT, V138, P223, DOI 10.1016/j.patrec.2020.07.029
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   CHONG Y, 2016, J SOFTW ENG APPL, V9, P103, DOI DOI 10.4236/JSEA.2016.94009
   Choudhury AR, 2019, LECT NOTES COMPUT SC, V11384, P154, DOI 10.1007/978-3-030-11726-9_14
   Dadashzadeh A, 2019, IET COMPUT VIS, V13, P700, DOI 10.1049/iet-cvi.2018.5796
   Dang T., 2022, 2022 IEEE C EVOLUTIO, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elleuch H, 2015, INT CONF INTELL SYST, P195, DOI 10.1109/ISDA.2015.7489224
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Guo L, 2021, IEEE T HUM-MACH SYST, V51, P300, DOI 10.1109/THMS.2021.3086003
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jing JF, 2022, TEXT RES J, V92, P30, DOI 10.1177/0040517520928604
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Khan S, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068809
   Kingma D. P., 2014, arXiv
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Matilainen M, 2016, INT CONF IMAG PROC
   Miao H, 2019, IEEE IJCNN
   Moin A, 2021, NAT ELECTRON, V4, P54, DOI 10.1038/s41928-020-00510-8
   Nalepa J, 2014, COMM COM INF SC, V424, P364
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Qi W, 2021, IEEE ROBOT AUTOM LET, V6, P6039, DOI 10.1109/LRA.2021.3089999
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Reifinger S, 2007, LECT NOTES COMPUT SC, V4552, P728
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Sulyman AA, 2017, J THEOR APPL INF TEC, V95
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan YS, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114797
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
NR 40
TC 1
Z9 1
U1 9
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28569
EP 28587
DI 10.1007/s11042-023-14550-7
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939670800004
DA 2024-07-18
ER

PT J
AU Albadr, MAA
   Tiun, S
   Ayob, M
   Nazri, MZA
   AL-Dhief, FT
AF Albadr, Musatafa Abbas Abbood
   Tiun, Sabrina
   Ayob, Masri
   Nazri, Mohd Zakree Ahmad
   AL-Dhief, Fahad Taha
TI Grey wolf optimization-extreme learning machine for automatic spoken
   language identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Grey wolf optimisation; Language
   identification
ID DEEP NEURAL-NETWORK; CLASSIFICATION; ALGORITHM
AB Natural language classification and determination based on a particular content and dataset is carried out using Spoken Language Identification (LID) which typically involves the extraction of valuable elements in a mature data processing procedure whereby the regular LID features had been developed using the Mel Frequency Cepstral Coefficient (MFCC), Shifted Delta Coefficient (SDC), Gaussian Mixture Model (GMM) and an i-vector framework. However, there remains a need for optimization in terms of the learning process so as to allow for all the knowledge embedded in the extracted features to be captured completely. A powerful machine learning algorithm known as Extreme Learning Machine (ELM) is used for conducting regression and classification and can train single hidden layer neural networks effectively. Yet, ELM's learning process remains under-optimized owing to the entrenched random weights selection in the input hidden layer. Based on the standard feature extraction, this current study chooses ELM as the learning model for LID. An optimized method known as the Enhanced Self-Adjusting-ELM (ESA-ELM) has been chosen as a benchmark with enhancements via the adoption of an alternate optimization approach i.e., Grey Wolf Optimisation (GWO) rather than Enhanced Ameliorated Teaching Learning-Based Optimization (EATLBO) to ensure higher performance. Ultimately, this enhanced version of the ESA-ELM is referred to as a Grey Wolf Optimisation-Extreme Learning Machine (GWO-ELM). The results generation is carried out based on LID using the exact benchmark dataset that was derived from eight separate languages. The results indicated that the GWO-ELM LID has a much superior performance than the ESA-ELM LID with respective accuracies of 100.00% for the former and merely 96.25% for the latter.
C1 [Albadr, Musatafa Abbas Abbood; Tiun, Sabrina; Ayob, Masri; Nazri, Mohd Zakree Ahmad] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, CAIT, Bangi, Selangor, Malaysia.
   [AL-Dhief, Fahad Taha] Univ Teknol Malaysia, Sch Elect Engn, Dept Commun Engn, UTM Johor Bahru, Johor Baharu, Johor, Malaysia.
C3 Universiti Kebangsaan Malaysia; Universiti Teknologi Malaysia
RP Albadr, MAA (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, CAIT, Bangi, Selangor, Malaysia.
EM mustafa_abbas1988@yahoo.com
RI tiun, sabrina/M-4315-2019; Albadr, Musatafa Abbas Abbood/AAJ-6453-2020
OI Albadr, Musatafa/0000-0003-2062-688X; Ahmad, Zuraini/0009-0008-3363-7127
FU Universiti Kebangsaan Malaysia under Dana Impak Perdana [GUP-2020-063]
FX This project was funded by the Universiti Kebangsaan Malaysia under Dana
   Impak Perdana grant (Research code: GUP-2020-063).
CR AL-Dhief FT, 2021, ASIA-PAC CONF COMMUN, P1, DOI 10.1109/APCC49754.2021.9609830
   Al-Dhief FT, 2021, IEEE ACCESS, V9, P77293, DOI 10.1109/ACCESS.2021.3082565
   Al-Dhief FT, 2020, IEEE ACCESS, V8, P64514, DOI 10.1109/ACCESS.2020.2984925
   AL-Dhief FT, 2020, 2020 IEEE 5 INT S TE
   Albadr MA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111758
   Albadr MAA, 2022, MULTIMED TOOLS APPL, V81, P23963, DOI 10.1007/s11042-022-12747-w
   Albadr MAA, 2021, COGN COMPUT, V13, P1136, DOI 10.1007/s12559-021-09914-w
   Albadr MAA, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242899
   Albadr MAA, 2020, CIRC SYST SIGNAL PR, V39, P4596, DOI 10.1007/s00034-020-01388-9
   Albadr MAA, 2019, INT J SPEECH TECHNOL, V22, P711, DOI 10.1007/s10772-019-09621-w
   Albadr MAA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194770
   Albadra MAA, 2017, INT J APPL ENG RES, V12, P4610, DOI DOI 10.37622/000000
   Alexander V, 2016, ADV INTELL SYST, V412, P301, DOI 10.1007/978-981-10-0251-9_29
   Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081
   Ben-Reuven E, 2016, ARXIV
   Deng CW, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5269-3
   Faris H, 2019, INT J MACH LEARN CYB, V10, P2901, DOI 10.1007/s13042-018-00913-2
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Ganapathy S, 2014, 15 ANN C INT SPEECH
   Gao RF, 2019, INT CONF WIREL OPT, P370, DOI 10.1109/wocc.2019.8770552
   Garg Archana, 2014, Journal of Emerging Technologies in Web Intelligence, V6, P388, DOI 10.4304/jetwi.6.4.388-400
   Gazeau Valentin, 2018, International Journal of Information Technology and Computer Science, V10, P11, DOI 10.5815/ijitcs.2018.08.02
   Hafen RP, 2012, MULTIMEDIA SYST, V18, P499, DOI 10.1007/s00530-012-0266-0
   Han K, 2014, INTERSPEECH, P223
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jiang  B., 2014, PLOS ONE, V9
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Lan Y, 2013, NEURAL COMPUT APPL, V22, P417, DOI 10.1007/s00521-012-0946-x
   Lee KA, 2016, INTERSPEECH, P3211, DOI 10.21437/Interspeech.2016-624
   Li JY, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P187, DOI 10.1109/ASRU.2015.7404793
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Lopez-Moreno I, 2016, COMPUT SPEECH LANG, V40, P46, DOI 10.1016/j.csl.2016.03.001
   MAA Albadr, 2021, 2021 INT C ELECT COM
   Malik H, 2019, ADV INTELL SYST, V697, P607, DOI 10.1007/978-981-13-1822-1_57
   Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   Muthusamy H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/394083
   Nayak PK, 2016, NEURAL COMPUT APPL, V27, P2107, DOI 10.1007/s00521-015-2010-0
   Naz A, 2018, 2018 IEEE 21ST INTERNATIONAL MULTI-TOPIC CONFERENCE (INMIC)
   Niu PF, 2016, NEURAL PROCESS LETT, V44, P813, DOI 10.1007/s11063-016-9496-z
   Pal M, 2013, REMOTE SENS LETT, V4, P619, DOI 10.1080/2150704X.2013.777485
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Singh G, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5123671
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   van Heeswijk M, 2015, ADV EXTREME LEARNING
   Wang MJ, 2017, ENG APPL ARTIF INTEL, V63, P54, DOI 10.1016/j.engappai.2017.05.003
   Wang W, 2019, PROCEDIA COMPUT SCI, V147, P36, DOI 10.1016/j.procs.2019.01.181
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795
   Xu JM, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0066-5
   Yang ZY, 2016, COGN NEURODYNAMICS, V10, P73, DOI 10.1007/s11571-015-9358-9
   Zazo R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146917
   Zhou ZY, 2019, OPTIK, V185, P364, DOI 10.1016/j.ijleo.2019.01.105
NR 56
TC 6
Z9 6
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27165
EP 27191
DI 10.1007/s11042-023-14473-3
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000929402000002
DA 2024-07-18
ER

PT J
AU Yin, J
   Xu, SH
   Du, YB
   Jia, RS
AF Yin, Jian
   Xu, Shao-Hua
   Du, Yan-Bin
   Jia, Rui-Sheng
TI Super resolution reconstruction of CT images based on multi-scale
   attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT images; Super resolution reconstruction; Attention mechanism;
   Multiscale
ID CONVOLUTIONAL NETWORK; SUPERRESOLUTION
AB CT diagnosis has been widely used in clinic because of its special diagnostic value. The image resolution of CT imaging system is constrained by X-ray focus size, detector element spacing, reconstruction algorithm and other factors, which makes the generated CT image have some problems, such as low contrast, insufficient high-frequency information, poor perceptual quality and so on. To solve the above problems, a super-resolution reconstruction method of CT image based on multi-scale attention mechanism is proposed. First, use a 3 x 3 and a 1 x 1 convolution layer extracting shallow features. In order to better extract the high-frequency features of CT images and improve the image contrast, a multi-scale attention module is designed to adaptively detect the information of different scales, improve the expression ability of features, integrate the channel attention mechanism and spatial attention mechanism, and pay more attention to important information, retain more valuable information. Finally, sub-pixel convolution is used to improve the resolution of CT image and reconstruct high-resolution CT image. The experimental results show that this method can effectively improve the CT image contrast and suppress the noise. The peak signal-to-noise ratio and structural similarity of the reconstructed CT image are better than the comparison method, and has a good subjective visual effect.
C1 [Yin, Jian; Xu, Shao-Hua; Du, Yan-Bin; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Xu, Shao-Hua; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Xu, SH; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Xu, SH; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
EM xush62@163.com; jrs716@163.com
RI Xu, Shaohua/AAV-1152-2021; Jia, Rui-Sheng/D-4460-2015
OI Jia, Rui-Sheng/0000-0003-1612-4764
FU State Key Research & Development Program of China [2018YFC1406203]
FX The authors are grateful for collaborative funding support from the
   State Key Research & Development Program of China (2018YFC1406203)
CR Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Cai WW, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102106
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Feng C.M., 2021, arXiv
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kang E, 2018, IEEE T MED IMAGING, V37, P1358, DOI 10.1109/TMI.2018.2823756
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Park J., 2018, ARXIV
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang YZ, 2018, PHYSICA A, V493, P177, DOI 10.1016/j.physa.2017.10.022
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XY, 2021, MULTIMED TOOLS APPL, V80, P33747, DOI 10.1007/s11042-021-11230-2
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Xu LM, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101600
   Yan YY, 2021, IEEE T IMAGE PROCESS, V30, P4905, DOI 10.1109/TIP.2021.3077135
   Yan ZY, 2015, INT J IMAG SYST TECH, V25, P92, DOI 10.1002/ima.22125
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao C, 2019, MAGN RESON IMAGING, V64, P132, DOI 10.1016/j.mri.2019.05.038
   Zhao TL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21206870
NR 42
TC 2
Z9 2
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22651
EP 22667
DI 10.1007/s11042-023-14436-8
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000926356100001
PM 36778717
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Jadhav, SB
   Deshmukh, NK
   Humbe, VT
AF Jadhav, Sharad B.
   Deshmukh, N. K.
   Humbe, V. T.
TI HDL-PI: hybrid DeepLearning technique for person identification using
   multimodal finger print, iris and face biometric features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Person identification; Multimodal; Hybrid deep learning;
   Feature selection
ID SCORE LEVEL FUSION; SYSTEM
AB Due of its uniqueness, biometric technologies are employed for security and access control in today's digital world. Global demand for biometric technology has led to the development of biometric systems integrating many features. The robustness depends on the capacity to derive meaningful information from single biometric features. Multimodal biometric security systems are thought to be more accurate and secure than unimodal ones. An attacker may still enter the system using a stolen or hacked biometric data, even the greatest multi-biometric architecture. A hybrid deep learning approach for person identification (HDL-PI) employing palm print, iris, and face biometric features is proposed. It eliminates undesirable artefacts from the raw input image. After feature extraction, we develop a modified group search optimization (MGSO) technique to optimize features and minimize data dimensionality. In order to improve prediction accuracy and minimize error metrics, teacher learning based deep neural networks (TL-DNN) is presented. Performance measurements include accuracy, precision, recall, and F-measure; error metrics include equal error rate (EER), false alarm rate (FAR), false rejection rate (FRR), and genuine acceptance rate (GAR).
C1 [Jadhav, Sharad B.; Deshmukh, N. K.] SRTM Univ, Sch Computat Sci, Nanded 431606, India.
   [Humbe, V. T.] STRMUN, Sub Ctr Latur, Sch Technol, Latur, Maharashtra, India.
C3 Swami Ramanand Teerth Marathwada University
RP Jadhav, SB (corresponding author), SRTM Univ, Sch Computat Sci, Nanded 431606, India.
EM jadhavsb96@gmail.com; nileshkd.srt@gmail.com
OI , Sharad B. Jadhav/0000-0002-8985-914X; Deshmukh,
   Nilesh/0009-0007-3490-279X
FU  [CSMNRF-2021/2021-22/896]
FX AcknowledgementsThe authors thank to the SARATHI of Maharashtra for the
   funding provided through CSMNRF-2021/2021-22/896.The authors are also
   grateful to School of Computational Sciences, Swami Ramanand Thirth
   Marathwada University, Nanded.
CR Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Alam MR, 2015, PATTERN RECOGN LETT, V52, P65, DOI 10.1016/j.patrec.2014.10.006
   Aleem S, 2020, WORLD WIDE WEB, V23, P1299, DOI 10.1007/s11280-019-00698-6
   Ali Z, 2018, FUTURE GENER COMP SY, V85, P76, DOI 10.1016/j.future.2018.02.040
   Ammour B, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010085
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bhilare S, 2018, MACH VISION APPL, V29, P1269, DOI 10.1007/s00138-018-0959-2
   Brutti A, 2017, IEEE T HUM-MACH SYST, V47, P40, DOI 10.1109/THMS.2016.2620110
   Chanukya PSVVN, 2020, MULTIMED TOOLS APPL, V79, P659, DOI 10.1007/s11042-019-08123-w
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   El Rahman SA, 2020, SOFT COMPUT, V24, P12599, DOI 10.1007/s00500-020-04700-6
   El-Bendary MAM, 2020, MULTIMED TOOLS APPL, V79, P24507, DOI 10.1007/s11042-020-08926-2
   Fox NA, 2007, IEEE T MULTIMEDIA, V9, P701, DOI 10.1109/TMM.2007.893339
   Harifi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P115, DOI 10.1109/ICCTIM.2015.7224603
   Kamlaskar C., 2021, AIMS Electronics and Electrical Engineering, V5, P229
   Karmakar D, 2014, MACH VISION APPL, V25, P477, DOI 10.1007/s00138-013-0532-y
   Lohith MS, 2021, IETE J RES, V67, P90, DOI 10.1080/03772063.2018.1531069
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   McLaughlin N, 2013, IEEE T HUM-MACH SYST, V43, P214, DOI 10.1109/TSMCC.2012.2227959
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Mustafa A. J., 2020, Int. J. Adv. Sci. Technol., V29, P7423
   Nigam A, 2015, NEUROCOMPUTING, V151, P1120, DOI 10.1016/j.neucom.2014.03.083
   Peng JL, 2014, OPTIK, V125, P6891, DOI 10.1016/j.ijleo.2014.07.027
   Pinto JR, 2018, IEEE ACCESS, V6, P34746, DOI 10.1109/ACCESS.2018.2849870
   Raghavendra R, 2013, SIGNAL IMAGE VIDEO P, V7, P1015, DOI 10.1007/s11760-012-0294-4
   Raja J, 2019, CLUSTER COMPUT, V22, P215, DOI 10.1007/s10586-018-2649-2
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Sujatha E., 2021, Data Analytics and Management. Proceedings of ICDAM. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 54), P267, DOI 10.1007/978-981-15-8335-3_22
   Sujatha E, 2018, WIRELESS PERS COMMUN, V99, P23, DOI 10.1007/s11277-017-5034-1
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Vijay M, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0967-y
   Walia GS, 2019, EXPERT SYST APPL, V116, P364, DOI 10.1016/j.eswa.2018.08.036
   Wrobel K, 2018, PATTERN RECOGN, V81, P585, DOI 10.1016/j.patcog.2018.04.030
NR 34
TC 2
Z9 2
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30039
EP 30064
DI 10.1007/s11042-022-14241-9
EA DEC 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000905894000001
DA 2024-07-18
ER

PT J
AU Panda, SK
   Diwan, T
   Kakde, OG
   Tembhurne, JV
AF Panda, Saroj Kumar
   Diwan, Tausif
   Kakde, Omprakash G. G.
   Tembhurne, Jitendra V. V.
TI Improvised detection of deepfakes from visual inputs using light weight
   deep ensemble model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deepfakes; Deep learning; Convolution neural network; Long short-term
   memory; Ensemble
AB Due to rapid growing image and video technology, synthesis or fabrication of the visual contents by replacing the original person of the visual contents with some other public figure has emerged as Deepfake. Mostly, the intention of such alterations is to spread propagandas, to create controversies, to defame a celebrity or public figure, or sometime just for fun. These deepfakes are then spread over the internet via social networking platforms such as Twitter, Facebook, etc. and the consequences of such spreads are very impactful in terms of embarrassment, legal actions, propagandas, and violence. The alterations are too realistic to detect the originality of the same. Lots of machine learning and deep learning models have been proposed for the detection of deepfakes but they report limited accuracy. Moreover, the model complexity is also high when we talk in terms of deep models. Herein, we propose light weight deep ensemble binary classification model utilizing pretrained convolutional neural networks for visual features' extraction and long short-term memory to extract the temporal features from the input frames after being preprocessed by OpenCV Haar cascade. The proposed model utilizes comparatively lesser frames and outperforms other state of the arts models on the well-known Celeb-DF-v2 dataset. We report 97% accuracy for an ensemble of VGG19 and BiLSTM and highly recommend the use of aforementioned ensemble for the deepfake detection and classification in case of balanced dataset.
C1 [Panda, Saroj Kumar; Diwan, Tausif; Kakde, Omprakash G. G.; Tembhurne, Jitendra V. V.] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
   [Panda, Saroj Kumar] Tata Consultancy Serv, Nagpur, India.
RP Diwan, T (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
EM dtei20cse005@iiitn.ac.in; tdiwan@iiitn.ac.in; director@iiitn.ac.in;
   jtembhurne@iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; PANDA, SAROJ KUMAR/GYA-1770-2022
OI PANDA, SAROJ KUMAR/0000-0002-5353-0393
CR Agarwal S, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358349
   Akhtar Z., 2019, SSRN ELECT J, DOI DOI 10.2139/SSRN.3419272
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Bai X, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108102
   Bottou L., 1998, ONLINE LEARNING NEUR, V17, P142
   Chollet, 2021, DEEP LEARNING PYTHON, P1
   Deshmukh A., 2021, INTELLIGENT COMPUTIN, V146, P293, DOI [10.1007/978-981-15-7421-4_27, DOI 10.1007/978-981-15-7421-4_27]
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Kaur S, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.3.033013
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li YZ, 2017, ADV NEUR IN, V30
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Maksutov Artem A., 2020, 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus). Proceedings, P408, DOI 10.1109/EIConRus49466.2020.9039057
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Saha B, 2017, J FORENSIC INVESTIG, V5, P2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A., 2020, SN Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wu, 2020, LAMDA GROUP
   Yu C.M., 2019, ARXIV
NR 25
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20101
EP 20118
DI 10.1007/s11042-022-14307-8
EA DEC 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000903319100004
DA 2024-07-18
ER

PT J
AU Fathi, IS
   Ahmed, MA
   Makhlouf, MA
AF Fathi, Islam S.
   Ahmed, Mohamed Ali
   Makhlouf, M. A.
TI An efficient compression technique for Foetal phonocardiogram signals in
   remote healthcare monitoring systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote healthcare monitoring systems; fPCG signal compression; Fetal
   phonocardiography (fPCG); Charlier moments; Householder method; Energy
   efficiency
ID STABLE COMPUTATION; CHARLIER MOMENTS; CLASSIFICATION; EXTRACTION;
   FILTERS; PAIRS
AB Remote Healthcare Monitoring Systems (RHMs) that employ fetal phonocardiography (fPCG) signals are highly efficient technologies for monitoring continuous and long-term fetal heart rate. Wearable devices used in RHMs still face a challenge that decreases their efficacy in terms of energy consumption because these devices have limited storage and are powered by batteries. This paper proposes an effective fPCG compression algorithm to reduce RHM energy consumption. In the proposed algorithm, the Discrete Orthogonal Charlier Moment (DOCMs) is used to extract features of the signal. The householder orthonormalization method (HOM) is used with the Charlier Moment to overcome the propagation of numerical errors that occur when computing high-order Charlier polynomials. The proposed algorithm's performance is evaluated in terms of CR, PRD, SNR, PSNR, and QS and provides the average values 18.33, 0.21, 48.85, 68.86, and 90.88, respectively. The results of the comparison demonstrate the proposed compression algorithm's superiority over other algorithms. It also tested in terms of compression speed and computational efficiency. The results indicate that the proposed algorithm has a high Compression speed (218.672 bps) and high computational efficiency (21.33). Additionally, the results reveal that the proposed algorithm decreases the energy consumption of a wearable device due to the transmission time decreasing for data by 3.68 s.
C1 [Fathi, Islam S.; Ahmed, Mohamed Ali] Suez Canal Univ, Fac Sci, Dept Math, Ismailia, Egypt.
   [Makhlouf, M. A.] Suez Canal Univ, Fac Comp & Informat, Dept Informat Syst, Ismailia, Egypt.
   [Makhlouf, M. A.] Nahda Univ, Fac Comp Sci, Bani Suwayf, Egypt.
C3 Egyptian Knowledge Bank (EKB); Suez Canal University; Egyptian Knowledge
   Bank (EKB); Suez Canal University
RP Fathi, IS (corresponding author), Suez Canal Univ, Fac Sci, Dept Math, Ismailia, Egypt.
EM i_said76@yahoo.com; Mohamed_ibrahim1@science.suez.edu.eg;
   m.abdallah@ci.suez.edu.eg
RI Ibrahim, Mohamed Ali Ahmed/HGA-8222-2022; Makhlouf,
   Mohamed/IVH-8552-2023
OI Ibrahim, Mohamed Ali Ahmed/0000-0001-7656-9728; 
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Aazam M, 2020, IEEE CONSUM ELECTR M, V9, P96, DOI 10.1109/MCE.2019.2953749
   Abd Elaziz M, 2019, SOFT COMPUT, V23, P9573, DOI 10.1007/s00500-018-3521-2
   Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   Adithya PC, 2017, BIOMED SIGNAL PROCES, V33, P289, DOI 10.1016/j.bspc.2016.11.007
   Aggarwal V., 2018, INT J COMP SYS ENG, V4, P165, DOI [10.1504/IJCSYSE.2018.091396, DOI 10.1504/IJCSYSE.2018.10012646]
   Aggarwal V, 2022, IETE J RES, V68, P2736, DOI 10.1080/03772063.2020.1725662
   Altaheri H, 2023, NEURAL COMPUT APPL, V35, P14681, DOI 10.1007/s00521-021-06352-5
   Arican M, 2019, COMPUT METH PROG BIO, V176, P149, DOI 10.1016/j.cmpb.2019.05.011
   Atteeq M, 2019, ICBBT 2019: 2019 11TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL TECHNOLOGY, P100, DOI 10.1145/3340074.3340087
   Bendifallah A, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING (ICEE), P258
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Cesarelli M, 2012, COMPUT METH PROG BIO, V107, P513, DOI 10.1016/j.cmpb.2011.11.008
   Chien YR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175842
   Chourasia VS, 2013, SCI WORLD J, DOI 10.1155/2013/505840
   Daoui A, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108596
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P32947, DOI 10.1007/s11042-021-11206-2
   Daoui A, 2022, CIRC SYST SIGNAL PR, V41, P166, DOI 10.1007/s00034-021-01764-z
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P1641, DOI 10.1007/s11042-020-09739-z
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   Elgendi M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00540-x
   Ernawan F, 2017, OPTIK, V148, P106, DOI 10.1016/j.ijleo.2017.08.007
   Fathi IS., 2021, INT J HYBRID INF TEC, V1, P33, DOI [10.21742/IJHIT.2021.1.1.03, DOI 10.21742/IJHIT.2021.1.1.03]
   Fathi IS, 2022, EURASIP J ADV SIG PR, V2022, DOI 10.1186/s13634-022-00938-4
   Fathi IS, 2022, IEEE ACCESS, V10, P39129, DOI 10.1109/ACCESS.2022.3166476
   Ford W, 2014, NUMERICAL LINEAR ALG, P1, DOI [10.1016/B978-0-12-394435-1.0000-X, DOI 10.1016/B978-0-12-394435-1.0000-X]
   Ghosh SK, 2021, IEEE SENSOR LETT, V5, DOI 10.1109/LSENS.2021.3074985
   Habibzadeh H, 2020, IEEE INTERNET THINGS, V7, P53, DOI [10.1109/JIOT.2019.2946359, 10.1109/jiot.2019.2946359]
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   Hosny KM, 2020, SOFT COMPUT, V24, P409, DOI 10.1007/s00500-019-03922-7
   Hosny KM, 2018, BIOCYBERN BIOMED ENG, V38, P385, DOI 10.1016/j.bbe.2018.02.006
   Jezewski M, 2019, EXPERT SYST APPL, V118, P109, DOI 10.1016/j.eswa.2018.09.030
   Jezewski M, 2016, APPL ARTIF INTELL, V30, P572, DOI 10.1080/08839514.2016.1193718
   Jha CK, 2021, IRBM, V42, DOI 10.1016/j.irbm.2020.05.008
   Karmouni H, 2018, CIRC SYST SIGNAL PR, V37, P4015, DOI 10.1007/s00034-018-0755-2
   Ladrova M, 2019, IFAC PAPERSONLINE, V52, P440, DOI 10.1016/j.ifacol.2019.12.703
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y., 2022, ROBUST MULTIWATERMAR, DOI [10.1007/978-3-031-06791-4_31, DOI 10.1007/978-3-031-06791-4_31]
   Martinek R., 2020, IEEE ACCESS, V8, DOI 10.22489/CinC.2017.331-075
   Martinek R, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00648
   Mozaffarian D, 2015, CIRCULATION, V131, pE29, DOI 10.1161/CIR.0000000000000152
   Mubarak QUA, 2018, COMPUT METH PROG BIO, V164, P143, DOI 10.1016/j.cmpb.2018.07.006
   physionet, CGI BIN ATM ATM
   Rahman SMM, 2016, PATTERN RECOGN, V54, P83, DOI 10.1016/j.patcog.2016.01.003
   Rajasekar P, 2020, SOFT COMPUT, V24, P14545, DOI 10.1007/s00500-020-04804-z
   Sbrollini A, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.331-075
   Stojkoska B.R., 2017, 2017 25th Telecommunication Forum (TELFOR), P1, DOI 10.1109/TELFOR.2017.8249368
   Strand S, 2019, J AM HEART ASSOC, V8, DOI 10.1161/JAHA.119.013436
   Tang H, 2016, COMPUT BIOL MED, V71, P24, DOI 10.1016/j.compbiomed.2016.01.017
   Tsai TH, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101879
   Vadali VABK, 2018, COMP STUDY SIGNAL PR
   Welba C., 2020, J SIGNAL INFORM PROC, V11, P35, DOI [10.4236/jsip.2020.113003, DOI 10.4236/JSIP.2020.113003]
   Xiao B, 2020, INFORM SCIENCES, V516, P545, DOI 10.1016/j.ins.2019.12.044
   Xiao B, 2016, NEUROCOMPUTING, V214, P587, DOI 10.1016/j.neucom.2016.06.050
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang Q, 2019, P NATL ACAD SCI USA, V116, P24463, DOI 10.1073/pnas.1907956116
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
NR 59
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19993
EP 20014
DI 10.1007/s11042-022-14259-z
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000889032600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, ZP
   Jiang, YN
   Chen, SF
AF Wang, Zhongpeng
   Jiang, Yannan
   Chen, Shoufa
TI Image parallel block compressive sensing scheme using DFT measurement
   matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel compressive sensing; Image; Peak signal to noise ratio (PSNR);
   Measurement matrix; Sparse basis matrix
ID SIGNAL RECOVERY; ENCRYPTION; PROJECTIONS; DESIGN
AB Compressive sensing (CS)-based image coding has been widely studied in the field of image processing. However, the CS-based image encoder has a significant gap in image reconstruction performance compared with the conventional image compression methods. In order to improve the reconstruction quality of CS-based image encoder, we proposed an image parallel block compressive sensing (BCS) coding scheme, which is based on discrete Cosine transform (DCT) sparse basis matrix and partial discrete Fourier transform (DFT) measurement matrix. In the proposed parallel BCS scheme, each column of an image block is sampled by the same DFT measurement matrix. Due to the complex property of DFT measurement matrix, the compressed image data is complex. Then, the real part and imaginary part of the resulting BCS data are quantized and transformed into two bit streams, respectively. At the reconstruction stage, the resulting two bit streams are transformed back into two real signals using inverse quantization operation. The resulting two real signals are combined into one complex signal, which is served as the input data of the CS reconstructed algorithm. The theoretical analysis based on minimum Frobenius norm method demonstrates that the proposed DFT measurement matrix outperforms the other conventional measurement matrices. The simulation results show that the reconstructed performance of the proposed DFT measurement matrix is better than that of the other conventional measurement matrices for the proposed parallel BCS. Specifically, we analyzed the impact of quantization on the reconstruction performance of CS. The experiment results show that the effect of the quantization on reconstruction performance in BCS framework can nearly be ignored.
C1 [Wang, Zhongpeng; Jiang, Yannan; Chen, Shoufa] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Science & Technology
RP Wang, ZP (corresponding author), Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Peoples R China.
EM wzp1966@163.com
OI Wang, Zhongpeng/0000-0002-8236-7054
FU Key Laboratory of Universal Wireless Communications (BUPT), Ministry of
   Education, China [KFKT-2020103]; Zhejiang Provincial key Natural Science
   Foundation of China [LZ21F010001]
FX This work was supported by Key Laboratory of Universal Wireless
   Communications (BUPT), Ministry of Education, China, under KFKT-2020103,
   and by the Zhejiang Provincial key Natural Science Foundation of China
   under LZ21F010001. The authors would like to thank Dr. Linlin Xue for
   her finishing the added experiment data collecting and participating in
   writing or technical editing of the manuscript.
CR Asmann A, 2022, IEEE T COMPUT IMAG, V8, P385, DOI 10.1109/TCI.2022.3174803
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chakraborty P, 2022, WIRELESS PERS COMMUN, V123, P2959, DOI 10.1007/s11277-021-09270-w
   Chen Z, 2020, IEEE T CIRC SYST VID, V30, P1109, DOI 10.1109/TCSVT.2019.2898908
   Chen Z, 2018, IEEE T MULTIMEDIA, V20, P1610, DOI 10.1109/TMM.2017.2774004
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dou YQ, 2021, MULTIMED TOOLS APPL, V80, P24437, DOI 10.1007/s11042-021-10850-y
   Duarte-Carvajalino JM, 2009, IEEE T IMAGE PROCESS, V18, P1395, DOI 10.1109/TIP.2009.2022459
   Ebrahimkhani M, 2018, INT CONF INFRA MILLI
   Elad M, 2007, IEEE T SIGNAL PROCES, V55, P5695, DOI 10.1109/TSP.2007.900760
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Foroozan F, 2017, EUR SIGNAL PR CONF, P2111, DOI 10.23919/EUSIPCO.2017.8081582
   Gan HP, 2020, CIRC SYST SIGNAL PR, V39, P1581, DOI 10.1007/s00034-019-01223-w
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Gui YQ, 2020, IEEE T CIRC SYST VID, V30, P3181, DOI 10.1109/TCSVT.2019.2935127
   Hong T, 2019, SIGNAL PROCESS, V159, P119, DOI 10.1016/j.sigpro.2019.02.004
   Hsieh SH, 2018, IEEE SIGNAL PROC LET, V25, P591, DOI 10.1109/LSP.2018.2809693
   Hu GQ, 2017, OPT LASER ENG, V98, P123, DOI 10.1016/j.optlaseng.2017.06.013
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Jasra B, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P221, DOI [10.1109/confluence47617.2020.9058071, 10.1109/Confluence47617.2020.9058071]
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Kalogerias DS, 2014, P 48 ANN C INF SCI S, P1, DOI [10.1109/CISS.2014.6814115, DOI 10.1109/CISS.2014.6814115]
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Li G, 2015, IEEE T IMAGE PROCESS, V24, P5389, DOI 10.1109/TIP.2015.2479474
   Li G, 2013, IEEE T SIGNAL PROCES, V61, P2887, DOI 10.1109/TSP.2013.2253776
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mitra D, 2020, IEEE T INSTRUM MEAS, V69, P3642, DOI 10.1109/TIM.2019.2936776
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Obermeier R, 2017, IEEE T COMPUT IMAG, V3, P217, DOI 10.1109/TCI.2017.2671398
   Pham CDK, 2022, IEEE T IND INFORM, V18, P1271, DOI 10.1109/TII.2021.3082498
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   Ravelomanantsoa A, 2015, IEEE T INSTRUM MEAS, V64, P3405, DOI 10.1109/TIM.2015.2459471
   Stankovic I, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P357
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang H, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5598009
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang JM, 2022, IEEE T IMAGE PROCESS, V31, P734, DOI 10.1109/TIP.2021.3135476
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang ZP, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106246
   Wang ZP, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00284-5
   Wei ZR, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7979606
   Wei ZR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093288
   Xu GW, 2015, IEEE T INFORM THEORY, V61, P469, DOI 10.1109/TIT.2014.2375259
   Zelnik-Manor L, 2011, IEEE T SIGNAL PROCES, V59, P4300, DOI 10.1109/TSP.2011.2159211
   Zhang LY, 2015, IEEE INT SYMP CIRC S, P2744, DOI 10.1109/ISCAS.2015.7169254
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
NR 53
TC 5
Z9 5
U1 7
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21561
EP 21583
DI 10.1007/s11042-022-14176-1
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000889417700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Yum, M
AF Yum, Misun
TI Digital image color analysis method to extract fashion color semantics
   from artworks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic differential technique; Emotion of painting; Psychological
   codes; Color image scale; Color semiotics
AB Color in artworks is an inspirational source for fashion designers. Product color is a fundamental design element to stimulate customers' emotional response as designers intend or express conceptual trends they want to infuse into products. Thus, artwork color analysis and the color selection process are crucial for product designs. This study aims to establish digital color analysis whereby fashion designers can extract colors from digital images of artworks and find relevant fashion codes with automation. The analysis method provides the image color attributes in Munsell, Practical Color Coordinate System, and Shigenobu Kobayashi Color Scale. It reveals underlying color semiotics representative of digital images. That is essential to provide color guidance to fashion experts when planning product colors. The semiotics analysis is based on Kobayashi's 3-color combination scale and quantitatively estimates the similarity of an artwork image to the 3-color bar. Symbolic adjective of the image is found whereby image coordinates in semantic space can be estimated. This method was used to investigate the colors of 190 Monet's paintings. The results found that Monet frequently expressed subject matters in nature with colors of low saturation tone. We explore the manifestation of the painting colors in dress collections as fashion codes. This approach found that an inspiring painting and a designed dress impress the same or similar fashion codes.
C1 [Yum, Misun] Sungshin Womens Univ, Dept Fash Ind, 55 Dobong Ro 76ga Gil, Seoul 01133, South Korea.
C3 Sungshin Women's University
RP Yum, M (corresponding author), Sungshin Womens Univ, Dept Fash Ind, 55 Dobong Ro 76ga Gil, Seoul 01133, South Korea.
EM msy0027@gmail.com
CR Aicardi I, 2018, J CULT HERIT, V32, P257, DOI 10.1016/j.culher.2017.11.006
   [Anonymous], 2018, PYTHON 37 NUMPY 1164
   [Anonymous], 1998, COLOR COMBINATION IM
   [Anonymous], TOP ENG PEARS LIN CO
   [Anonymous], 2017, COS COL RC MUNS REN
   [Anonymous], 2021, MUNSELL CONVERSION S
   [Anonymous], 2015, TIMELESS INSPIRATION
   Aslan S, 2020, PATTERN RECOGN LETT, V131, P158, DOI 10.1016/j.patrec.2019.12.007
   Becattini F., 2016, Euro-Mediterranean Conference, P781
   Bernier, 2010, MONUMENT MOMENT MEMO
   Bigi Wolmer, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2472, DOI 10.1145/3394171.3413530
   Bongini P, 2020, IOP CONF SER-MAT SCI, V949, DOI 10.1088/1757-899X/949/1/012074
   Cheng W., 2020, ARXIV
   Choudhury AKR, 2014, WOODHEAD PUBL SER TE, P1, DOI 10.1533/9780857099242.1
   Cinar, 2017, NEW TRENDS ISSUES P, P53
   Cooper J., 2020, RECENT ADV BIG DATA, P330, DOI DOI 10.1007/978-3-030-16841-4_34
   CUTLER E.P., 2015, Art + Fashion: Collaborations and Connections Between Icons
   De Divitiis Lavinia, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P282, DOI 10.1007/978-3-030-68790-8_23
   De Divitiis L, 2021, INT WORK CONTENT MUL, P1, DOI 10.1109/CBMI50038.2021.9461912
   Goguen, 2012, INFLUENCE COLOR PURC
   Gonthier N, 2019, LECT NOTES COMPUT SC, V11130, P692, DOI 10.1007/978-3-030-11012-3_53
   Horiguchi S, 2018, COLOR RES APPL, V43, P827, DOI 10.1002/col.22286
   Kang D, 2018, MULTIMED TOOLS APPL, V77, P4985, DOI 10.1007/s11042-017-4667-0
   Kang Dongwoo., 2015, Mass Storage Systems and Technologies, P1
   Kim YI, 2006, COLOR RES APPL, V31, P341, DOI 10.1002/col.20232
   KOBAYASHI S, 1981, COLOR RES APPL, V6, P93, DOI 10.1002/col.5080060210
   Kobayashi S., 1990, Color image scale
   Lee JH, 2007, COLOR RES APPL, V32, P71, DOI 10.1002/col.20290
   Lindbloom B, 2017, US
   Ranjgar B, 2019, IEEE ACCESS, V7, P120857, DOI 10.1109/ACCESS.2019.2936896
   Schlag I, 2017, IEEE INT CONF COMP V, P2898, DOI 10.1109/ICCVW.2017.342
   Song XM, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P320, DOI 10.1145/3343031.3350956
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Winner E., 2019, ART WORKS PSYCHOL EX
   Yu LW, 2018, COLOR RES APPL, V43, P258, DOI 10.1002/col.22180
   Yum M., 2012, J KOREA SOC COLOR ST, V26, P71, DOI [10.17289/jkscs.26.4.201211.71, DOI 10.17289/JKSCS.26.4.201211.71]
   Yun SA, 2019, COLOR RES APPL, V44, P115, DOI 10.1002/col.22288
   Yun Sun Ae, 2017, [Journal of the Korean Society of Costume, 복식], V67, P1, DOI 10.7233/jksc.2017.67.6.001
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
NR 41
TC 1
Z9 1
U1 20
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17115
EP 17133
DI 10.1007/s11042-022-14189-w
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880356300001
DA 2024-07-18
ER

PT J
AU Silva, PA
   Santos, R
AF Silva, Paula Alexandra
   Santos, Renato
TI An opinion mining methodology to analyse games for health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Opinion mining; Usability; User experience;
   Health; Quality of life
ID EXPERIENCE; QUALITY
AB Despite the positive impact of games for health on players' health, users tend to stop playing them after a short period of time, leading benefits to fade. It is therefore important to understand how to sustain interest and, in this way, preserve the health benefits of games for health. This could be achieved by continuously reviewing user feedback after product launch and using this information to inform (re)design and better address user needs. With the growth of social media, user opinions became widely available in public forums. This abundance of information affords us the possibility of, through the application of natural language processing and sentiment analysis techniques, tapping into user opinions and automatically analysing and extracting knowledge from them. This paper introduces a methodology that analyses user comments posted on YouTube about the Just Dance game, to automatically extract information about Usability, User Experience (UX), and Perceived Health Impacts related to Quality of Life (H-QoL). In doing so, the methodology uses a pre-established vocabulary, based on the English lexicon and its semantic relations, to annotate the presence of 38 concepts (five of Usability, 18 of UX, and 15 of H-QoL) and to analyse sentiment. The results of the information extraction and processing are displayed on a dashboard that allows for the exploration and browsing of the results, which can be useful to better understand the opinions and impacts perceived by users and to inform the (re)design of games for health. The methodology proposed builds upon over 500,000 user comments collected from over 32,000 videos.
C1 [Silva, Paula Alexandra; Santos, Renato] Univ Coimbra, Ctr Informat & Syst, Dept Informat Engn, Coimbra, Portugal.
C3 Universidade de Coimbra
RP Silva, PA (corresponding author), Univ Coimbra, Ctr Informat & Syst, Dept Informat Engn, Coimbra, Portugal.
EM paulasilva@dei.uc.pt; renatojms@student.dei.uc.pt
RI Silva, Paula Alexandra/N-5939-2014
OI Silva, Paula Alexandra/0000-0003-1573-7446
FU FCT -Foundation for Science and Technology [UID/CEC/00326/2020];
   Portugal2020 program [CENTRO-01-0247-FEDER047148]; European Union's
   structural funds [CENTRO-01-0247-FEDER047148]
FX This work was supported by project the FCT -Foundation for Science and
   Technology in the context of the project CISUC -UID/CEC/00326/2020 and
   by project CENTRO-01-0247-FEDER047148 INPACT -"Intelligent Platform for
   Autonomous Collaborative Telerehabilitation" financed by the
   Portugal2020 program and European Union's structural funds.
CR Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54
   Alqahtani F, 2020, HEALTH INFORM J, V26, P2042, DOI 10.1177/1460458219896492
   [Anonymous], 2019, 15 BEST DANC RHYTHM
   Bakiu E, 2017, 2017 IEEE 25TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P182, DOI 10.1109/REW.2017.76
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Bravo-Marquez F, 2021, FELIPEBRAVOM STATICT
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Buzzi MC, 2017, MULTIMED TOOLS APPL, V76, P10677, DOI 10.1007/s11042-015-3190-4
   Ceci L., 2022, YOUTUBE STAT FACTS
   Clark EricM., 2018, A sentiment analysis of breast cancer treatment experiences and healthcare perceptions across twitter
   da Silva, 2017, TRADITIONAL EVALUATI, P1
   Diniz, 2022, CAN USER REV INDICAT
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Haslwanter JDH, 2018, J ENABLING TECHNOL, V12, P186, DOI 10.1108/JET-12-2017-0053
   Hedegaard S.Simonsen., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P2089, DOI DOI 10.1145/2470654.2481286NULL
   Hori Y, 2010, P INT C MULT, P1039, DOI [10.1145/1873951.1874144, DOI 10.1145/1873951.1874144]
   Hoysniemi Johanna., 2006, Comput. Entertain, V4, P8, DOI [10.1145/1129006.1129019, DOI 10.1145/1129006.1129019]
   Hutto CJ, 2021, CJHUTTO VADERSENTIME
   Hyde M, 2003, AGING MENT HEALTH, V7, P186, DOI 10.1080/1360786031000101157
   Jin J, 2016, ENG APPL ARTIF INTEL, V47, P38, DOI 10.1016/j.engappai.2015.05.006
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Lin JH, 2015, GAMES HEALTH J, V4, P183, DOI 10.1089/g4h.2014.0092
   Loria S., 2018, Textblob documentation, DOI DOI 10.1109/ICDM.2008.94
   MacDonald K, 2014, JUST DANCE CONQUERED
   Magge A, 2021, P 6 SOCIAL MEDIA MIN, P21, DOI DOI 10.18653/V1/2021.SMM4H-1.4
   Mansfield L, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-020959
   Maynard D, 2017, J WEB SEMANT, V44, P75, DOI 10.1016/j.websem.2017.05.002
   McConnell J, 2021, ECLIPSE JETTY ECLIPS
   Messaoudi C, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-021-00855-8
   meta, 2021, about us
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   O'Neil P, 2009, LECT NOTES COMPUT SC, V5895, P237, DOI 10.1007/978-3-642-10424-4_17
   Oyebode O, 2020, IEEE ACCESS, V8, P111141, DOI 10.1109/ACCESS.2020.3002176
   Peng W, 2011, CYBERPSYCH BEH SOC N, V14, P681, DOI 10.1089/cyber.2010.0578
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Porter MF, 2001, Snowball: a language for stemming algorithms
   Prieto VM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086191
   Sardi L, 2017, J BIOMED INFORM, V71, P31, DOI 10.1016/j.jbi.2017.05.011
   Sawyer B, 2008, IEEE COMPUT GRAPH, V28, P83, DOI 10.1109/MCG.2008.114
   Severyn A, 2016, INFORM PROCESS MANAG, V52, P46, DOI 10.1016/j.ipm.2015.03.002
   Shuyo N., 2010, Language detection library for java
   Sifei, 2021, SIF DICT SENT AN
   Silva, 2021, SETTING HLTH RELATED, P169
   Sirbu D, 2016, INT SYMP SYMB NUMERI, P227, DOI [10.1109/SYNASC.2016.044, 10.1109/SYNASC.2016.38]
   STRAAT B, 2017, GHITALY CHITALY
   Tromp E, 2014, ARXIV
   Tuch A.N., 2013, P SIGCHI C HUMAN FAC, P2079, DOI DOI 10.1145/2470654.2481285
   unicode, 2022, FULL EMOJI LIST V131
   Ushaw G., 2015, ACM International Conference Proceeding Series, May 2015, P1, DOI [DOI 10.1145/2750511, 10.1145/2750511.2750513]
   Wang Y, 2018, ENVIRONMETRICS, V29, DOI 10.1002/env.2500
   WASD, 2020, JUST DANC 2020
   Wattanasoontorn V, 2013, ENTERTAIN COMPUT, V4, P231, DOI 10.1016/j.entcom.2013.09.002
   Weber L, 2020, ARXIV
   wikipedia, 2021, JUST DANC VID GAM SE
   Wikipedia, 2021, LIST ENGL CONTR
   Woldemariam Y, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P27
   Yadav A, 2020, PROC INT CONF SOFTW, P308, DOI 10.1145/3377812.3390790
   Yang B, 2019, INT J INFORM MANAGE, V46, P173, DOI 10.1016/j.ijinfomgt.2018.12.006
   YouTube, 2021, YOUTUBE DAT API
   Zhu MQ, 2015, INT J HUM-COMPUT INT, V31, P413, DOI 10.1080/10447318.2015.1036228
   Zucco C, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1333
NR 62
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12957
EP 12976
DI 10.1007/s11042-022-14070-w
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000879138200001
PM 36373074
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI Effective electrocardiogram steganography for secured patient
   information transmission based on most significant bit planes prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-healthcare; ECG signal; MSB prediction; Symmetric encryption;
   Reversible data hiding
AB These days a large number of people are suffering from heart diseases on the planet. Therefore in E-healthcare framework a large number of ECG signals as well as patient confidential information will be communicated via the Internet. Any modifications in the ECG signal may conduct a wrong diagnosis by the specialist, which can be deadly for patients. To ensure secure and safe communication in E-healthcare framework, proposed method presents an enhanced reversible data hiding algorithm based on prediction of most significant bit planes (MSB). Proposed method reserved room for embedding patient information before encryption, after data embedding stego signal is encrypted through combination of stream ciphers respectively. The experimental study has performed on MIT-BIH arrythmia database and proposed method achieved average embedding rate of 15.04 bits per sample, at receiver end precisely recover patient information (Bit Error Rate value is zero) with an average percentage residual difference of 0.0415 between the cover and reconstructed ECG signal successfully.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2022, J AMB INTEL HUM COMP, P1
   Bhardwaj R, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103265
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Yang CY, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0426-9
   Yang CY, 2018, P FUT TECHN C FTC 20, V1, P640
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng KM, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P295, DOI 10.1109/CIS.2008.71
NR 20
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15779
EP 15796
DI 10.1007/s11042-022-13955-0
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000874060500001
DA 2024-07-18
ER

PT J
AU Huang, ZH
   Shivakumara, P
   Kaljahi, MA
   Kumar, A
   Pal, U
   Lu, T
   Blumenstein, M
AF Huang, Zhiheng
   Shivakumara, Palaiahnakote
   Kaljahi, Maryam Asadzadeh
   Kumar, Ahlad
   Pal, Umapada
   Lu, Tong
   Blumenstein, Michael
TI Writer age estimation through handwriting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fourier phase spectrum; Harmonic wavelet phase spectrum; Phase
   statistics; Handwriting analysis; Age estimation
ID GENDER CLASSIFICATION; DOCUMENT IMAGE; SEGMENTATION
AB Handwritten image-based writer age estimation is a challenging task due to the various writing styles of different individuals, use of different scripts, varying alignment, etc. Unlike age estimation using face recognition in biometrics, handwriting-based age classification is reliable and inexpensive because of the plain backgrounds of documents. This paper presents a novel model for deriving the phase spectrum based on the Harmonic Wavelet Transform (HWT) for age classification on handwritten images from 11 to 65 years. This includes 11 classes with an interval of 5 years. In contrast to the Fourier transform, which provides a noisy phase spectrum due to loss of time variations, the proposed HWT-based phase spectrum retains time variations of phase and magnitude. As a result, the proposed HWT-based phase spectrum preserves vital information of changes in handwritten images. In order to extract such information, we propose new phase statistics-based features for age classification based on the understanding that as age changes, writing style also changes. The features and the input images are fed to a VGG-16 model for age classification. The proposed method is tested on our own dataset and three standard datasets, namely, IAM-2, KHATT and that of Basavaraja et al. to demonstrate the effectiveness of the proposed model compared to the existing methods in terms of classification rate. The results of the proposed and existing methods on different datasets show that the proposed method outperforms the existing methods in terms of classification rate.
C1 [Huang, Zhiheng; Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Shivakumara, Palaiahnakote; Kaljahi, Maryam Asadzadeh] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
   [Kumar, Ahlad] Dhirubhai Ambani Inst Informat & Commun Technol, Ahmadabad, Gujarat, India.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Blumenstein, Michael] Univ Technol Sydney, Australian Artificial Intelligence Inst, Sydney, NSW, Australia.
C3 Nanjing University; Universiti Malaya; Dhirubhai Ambani Institute of
   Information & Communication Technology; Indian Statistical Institute;
   Indian Statistical Institute Kolkata; University of Technology Sydney
RP Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM hzh408@qq.com; shiva@um.edu.my; asadradeh@um.edu.my;
   kumarahlad@gmail.com; umapada@isical.ac.in; lutong@nju.edu.cn;
   rnichael.blumenstein@uts.edu.au
RI Pal, Umapada/AAC-4930-2022; Palaiahnakote, Shivakumara/ITU-6488-2023;
   Palaiahnakote, Shivakumara/B-6261-2013
FU Natural Science Foundation of China [61,672,273, 61,832,008]; Ministry
   of Higher Education of Malaysia [FRGS/1/2020/ICT02/UM/02/4]
FX This work is supported by the Natural Science Foundation of China under
   Grant 61,672,273 and Grant 61,832,008, and Ministry of Higher Education
   of Malaysia for the generous grant Fundamental Research Grant Scheme
   (FRGS) with code number FRGS/1/2020/ICT02/UM/02/4.
CR Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   Basavaraja V., 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1131, DOI 10.1109/ICDAR.2019.00183
   Bi N, 2018, PATTERN RECOGN LETT
   Bian CL, 2019, IET COMPUT VIS, V13, P329, DOI 10.1049/iet-cvi.2018.5281
   Bouadjenek N, 2016, APPL SOFT COMPUT, V46, P980, DOI 10.1016/j.asoc.2015.10.021
   Bouadjenek N, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P311, DOI 10.1109/DAS.2016.27
   Bouadjenek N, 2015, PROC INT CONF DOC, P1116, DOI 10.1109/ICDAR.2015.7333934
   Chen YL, 2019, NEUROCOMPUTING, V367, P346, DOI 10.1016/j.neucom.2019.08.034
   Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583
   Erbilek M, 2012, IET BIOMETRICS, V1, P136, DOI 10.1049/iet-bmt.2012.0011
   Feng S, 2019, NEUROCOMPUTING, V325, P288, DOI 10.1016/j.neucom.2018.09.087
   Gattal A, 2018, EXPERT SYST APPL, V99, P155, DOI 10.1016/j.eswa.2018.01.038
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Gupta D, 2019, MULTIMED TOOLS APPL, V78, P19361, DOI 10.1007/s11042-019-7286-0
   He S, 2016, COMPUT VIS IMAGE UND, V152, P167, DOI 10.1016/j.cviu.2016.08.008
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Lee MC, 2017, INFORM PROCESS LETT, V128, P14, DOI 10.1016/j.ipl.2017.07.010
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Li ZJ, 2019, J VIS COMMUN IMAGE R, V61, P23, DOI 10.1016/j.jvcir.2019.01.021
   Liu LQ, 2016, IEEE T MULTIMEDIA, V18, P64, DOI 10.1109/TMM.2015.2500730
   McAllister P, 2016, LECT NOTES COMPUT SC, V10069, P178, DOI 10.1007/978-3-319-48746-5_18
   Mohammad K, 2021, MULTIMED TOOLS APPL, V80, P2177, DOI 10.1007/s11042-020-09737-1
   Ng CC, 2018, IMAGE VISION COMPUT, V69, P92, DOI 10.1016/j.imavis.2017.08.005
   Obaidullah SM, 2017, MULTIMED TOOLS APPL
   Papaodysseus C, 2014, COMPUT VIS IMAGE UND, V121, P57, DOI 10.1016/j.cviu.2014.01.003
   Park HC, 2009, NDT&E INT, V42, P534, DOI 10.1016/j.ndteint.2009.03.004
   Retisinas G, 2018, IEEE T PAMI
   Salwa L, 2017, PATTERN RECOGN LETT, V100, P1, DOI 10.1016/j.patrec.2017.09.027
   Sanasam I, 2020, MULTIMED TOOLS APPL, V79, P30135, DOI 10.1007/s11042-020-09416-1
   Taheri S, 2019, IET BIOMETRICS, V8, P124, DOI 10.1049/iet-bmt.2018.5141
   Xie ZC, 2019, NEUROCOMPUTING, V350, P271, DOI 10.1016/j.neucom.2019.04.001
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
   Zouaoui F, 2017, PROC ICEE B
NR 35
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16033
EP 16055
DI 10.1007/s11042-022-13840-w
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000865911600002
DA 2024-07-18
ER

PT J
AU Khan, A
   Wong, K
AF Khan, Ahmed
   Wong, KokSheik
TI High payload watermarking based on enhanced image saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High payload; Image saliency; Robust watermarking; Multiple watermarks
ID FRAGILE WATERMARKING; DIGITAL WATERMARKING; SCHEME; AUTHENTICATION;
   ROBUST; LOCALIZATION; SECURE
AB Nowadays, images are circulated rapidly over the internet and they are subject to some risk of misuses. To address this issue, various watermarking methods are proposed in the literature. However, most conventional methods achieve a certain trade-off among imperceptibility and high capacity payload, and they are not able to improve these criteria simultaneously. Therefore, in this paper, a robust saliency-based image watermarking method is proposed to achieve high payload and high quality watermarked image. First, an enhanced salient object model is proposed to produce a saliency map, followed by a binary mask to segments the foreground/background region of a host image. The same mask is then consulted to decompose the watermark image. Next, the RGB channels of the watermark are encrypted by using Arnold, 3-DES and multi-flipping permutation encoding (MFPE). Furthermore, the principal key used for encryption is embedded in the singular matrix of the blue channel. Moreover, the blue channel is encrypted by using the Okamoto-Uchiyama homomorphic encryption (OUHE) method. Finally, these encrypted watermark channels are diffused and embedded into the host channels. When the need arises, more watermarks can be embedded into the host at the expense of the quality of the embedded watermarks. Our method can embed watermark of the same dimension as the host image, which is the first of its kind. Experimental results suggest that the proposed method maintains robustness while achieving high image quality and high payload. It also outperforms the state-of-the-art (SOTA) methods.
C1 [Khan, Ahmed] Monash Univ Malaysia, Sch Informat Technol, Sunway, Malaysia.
   [Wong, KokSheik] Monash Univ Malaysia, Adv Engn Platform, Sunway, Malaysia.
C3 Monash University; Monash University Malaysia; Monash University; Monash
   University Malaysia
RP Wong, K (corresponding author), Monash Univ Malaysia, Adv Engn Platform, Sunway, Malaysia.
EM ahmed.khan1@monash.edu; wong.koksheik@monash.edu
RI Wong, KokSheik/B-9796-2011
OI Wong, KokSheik/0000-0002-4893-2291
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abdallah HA, 2016, OPTIK, V127, P2374, DOI 10.1016/j.ijleo.2015.10.050
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Chang CC, 2020, MULTIMED TOOLS APPL, V79, P24795, DOI 10.1007/s11042-020-09132-w
   Chen D., 2006, J ELECT CHINA, V23, P549, DOI [10.1007/s11767-004-0238-4, DOI 10.1007/S11767-004-0238-4]
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Chotikawanid Piyanart, 2015, Applied Mechanics and Materials, V781, P543, DOI 10.4028/www.scientific.net/AMM.781.543
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Huang H-C, 2007, INTELLIGENT MULTIMED, V58
   Huang Y, 2019, IEEE T MULTIMEDIA, V21, P2447, DOI 10.1109/TMM.2019.2907475
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kavitha KJ, 2021, J AMB INTEL HUM COMP, V12, P7715, DOI 10.1007/s12652-020-02496-9
   Khan A, 2019, SOFT COMPUT, V23, P8045, DOI 10.1007/s00500-018-3441-1
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Li L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030347
   Lin CC, 2021, MULTIMED TOOLS APPL, V80, P29497, DOI 10.1007/s11042-021-10598-5
   Liu F., 2018, J. Inf. Hiding Multimed. Signal Process. C, V9, P629
   Liu HM, 2018, INFORMATION, V9, DOI 10.3390/info9090239
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Mitchell CJ, 2016, IEEE T INFORM THEORY, V62, P6260, DOI 10.1109/TIT.2016.2611003
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Nejati F, 2021, WIRELESS PERS COMMUN, DOI 10.1007/s11277-021-08895-1
   Pan PJ-S, 2004, WORLD SCI, V7
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P20897, DOI 10.1007/s11042-020-08715-x
   Puteaux P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103085
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Ramasamy R, 2021, J AMB INTEL HUM COMP, V12, P7121, DOI 10.1007/s12652-020-02379-z
   Reddy I. Raja Sekhar, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P2443, DOI 10.1109/ICECDS.2017.8389889
   Ridho Abdurrahman, 2020, 2020 3rd International Conference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT), P123, DOI 10.1109/MECnIT48290.2020.9166598
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Sidiropoulos P, 2009, CHAOS SOLITON FRACT, V42, P2667, DOI 10.1016/j.chaos.2009.03.173
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh SP, 2020, J AMB INTEL HUM COMP, V11, P1869, DOI 10.1007/s12652-019-01296-0
   Singh SK, 2020, MULTIMED TOOLS APPL, V79, P17885, DOI 10.1007/s11042-020-08644-9
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Su GD, 2020, IEEE ACCESS, V8, P160840, DOI 10.1109/ACCESS.2020.3019832
   Suwandi R, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTING (ICIC), P329, DOI 10.1109/IAC.2016.7905739
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Tohidi F, 2021, IEEE ACCESS, V9, P57510, DOI 10.1109/ACCESS.2021.3072314
   Verma D, 2017, AIP CONF PROC, V1897, DOI 10.1063/1.5008715
   Wang FH, 2009, STUD COMPUT INTELL, V232, P11
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhang YF, 2019, OPTIK, V186, P379, DOI 10.1016/j.ijleo.2019.04.091
NR 55
TC 1
Z9 1
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15553
EP 15571
DI 10.1007/s11042-022-13907-8
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865154500002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Atlam, HF
   Wills, GB
AF Atlam, Hany F.
   Wills, Gary B.
TI ANFIS for risk estimation in risk-based access control model for smart
   homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Risk estimation; ANFIS model; Internet of things; Smart homes; Security
   risk; Risk-based access control
ID FUZZY INFERENCE SYSTEM; NETWORK; DESIGN
AB The risk-based access control model is one of the dynamic models that use the security risk as a criterion to decide the access decision for each access request. This model permits or denies access requests dynamically based on the estimated risk value. The essential stage of implementing this model is the risk estimation process. This process is based on estimating the possibility of information leakage and the value of that information. Several researchers utilized different methods for risk estimation but most of these methods were based on qualitative measures, which cannot suit the access control context that needs numeric and precise risk values to decide either granting or denying access. Therefore, this paper presents a novel Adaptive Neuro-Fuzzy Inference System (ANFIS) model for risk estimation in the risk-based access control model for the Internet of Things (IoT). The proposed ANFIS model was implemented and evaluated against access control scenarios of smart homes. The results demonstrated that the proposed ANFIS model provides an efficient and accurate risk estimation technique that can adapt to the changing conditions of the IoT environment. To validate the applicability and effectiveness of the proposed ANFIS model in smart homes, ten IoT security experts were interviewed. The results of the interviews illustrated that all experts confirmed that the proposed ANFIS model provides accurate and realistic results with a 0.713 in Cronbach's alpha coefficient which indicates that the results are consistent and reliable. Compared to existing work, the proposed ANFIS model provides an efficient processing time as it reduces the processing time from 57.385 to 10.875 Sec per 1000 access requests, which demonstrates that the proposed model provides effective and accurate risk evaluation in a timely manner.
C1 [Atlam, Hany F.; Wills, Gary B.] Univ Southampton, Elect & Comp Sci Dept, Southampton SO17 1BJ, Hants, England.
   [Atlam, Hany F.] Univ Derby, Coll Sci & Engn, Derby DE22 1GB, England.
C3 University of Southampton; University of Derby
RP Atlam, HF (corresponding author), Univ Southampton, Elect & Comp Sci Dept, Southampton SO17 1BJ, Hants, England.; Atlam, HF (corresponding author), Univ Derby, Coll Sci & Engn, Derby DE22 1GB, England.
EM h.atlam@derby.ac.uk; gbw@soton.ac.uk
RI Atlam, Hany/S-8160-2018
OI Atlam, Hany/0000-0003-4142-6377
CR Abd Ghani Mohd Khanapi, 2017, Journal of Theoretical and Applied Information Technology, V95, P3127
   Al-Hmouz A, 2012, IEEE T LEARN TECHNOL, V5, P226, DOI 10.1109/TLT.2011.36
   Alawad H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155156
   Alayda S., 2020, INT J ENG RES TECHNO, V13, P3404, DOI 10.37624/IJERT/13.11.2020.3404-3414
   [Anonymous], 2011, INT J ARTIF INTELL E
   Atlam HF, 2019, INTERNET THINGS-NETH, V6, DOI 10.1016/j.iot.2019.100052
   Atlam HF, 2021, MOBILE NETW APPL, V26, P2545, DOI 10.1007/s11036-019-01214-w
   Atlam HF, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P655, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.103
   Atlam HF, 2017, IOTBDS: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, BIG DATA AND SECURITY, P254, DOI 10.5220/0006292602540260
   Bolderston Amanda, 2012, J Med Imaging Radiat Sci, V43, P66, DOI 10.1016/j.jmir.2011.12.002
   Chen AG, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P579, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.90
   Chen P, 2007, 2007 IEEE S SECURITY, P22
   Cheng TR, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P407, DOI [10.1109/CIS.2016.0099, 10.1109/CIS.2016.98]
   Choi D, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/265132
   Connolly P, 2011, QUANTITATIVE DATA AN
   Cook D. A., 2005, CROSSTALK J DEFENSE, P20
   DiCicco-Bloom B, 2006, MED EDUC, V40, P314, DOI 10.1111/j.1365-2929.2006.02418.x
   Diep Nguyen Ngoc, 2007, Proceedings of the 2007 International Conference on Security & Management. SAM 2007, P406
   Döringer S, 2021, INT J SOC RES METHOD, V24, P265, DOI 10.1080/13645579.2020.1766777
   dos Santos DR, 2014, IEEE IFIP NETW OPER
   DUBOIS D, 1992, INFORM SCIENCES, V66, P245, DOI 10.1016/0020-0255(92)90096-Q
   Gao P, 2015, ENERGIES, V8, P13021, DOI 10.3390/en81112356
   Ghorbanzadeh O, 2018, NAT HAZARDS, V94, P497, DOI 10.1007/s11069-018-3449-y
   Guest G, 2006, FIELD METHOD, V18, P59, DOI 10.1177/1525822X05279903
   Guney K, 2008, PROG ELECTROMAGN RES, V84, P253, DOI 10.2528/PIER08070603
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Kaur J, 2020, RISK MANAG HEALTHC P, V13, P355, DOI 10.2147/RMHP.S233706
   Khambhammettu H, 2013, COMPUT SECUR, V39, P86, DOI 10.1016/j.cose.2013.03.010
   Kristjanpoller RW, 2018, APPL SOFT COMPUT, V67, P106, DOI 10.1016/j.asoc.2018.02.055
   Li J, 2013, IEEE INT CONF TRUST, P17, DOI 10.1109/TrustCom.2013.66
   Li Y, 2008, SECTECH: 2008 INTERNATIONAL CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P13, DOI 10.1109/SecTech.2008.50
   McGraw R., 2009, Risk-adaptable access control (radac). privilege (access) management workshop.
   Metoui N, 2018, LECT NOTES COMPUT SC, V10720, P1, DOI 10.1007/978-3-662-56266-6_1
   Morse JM., 2002, INT J QUAL METH, V1, P13, DOI [DOI 10.1177/160940690200100202, 10.1177/160940690200100202]
   Mostafa SA, 2018, INT J MED INFORM, V112, P173, DOI 10.1016/j.ijmedinf.2018.02.001
   Ni Q., 2010, P 5 ACM S INFORM COM, P250, DOI 10.1145/1755688.1755719
   Pramanik N, 2009, HYDROLOG SCI J, V54, P247, DOI 10.1623/hysj.54.2.247
   Rajabi M, 2019, Arxiv, DOI arXiv:1910.12952
   Rezaei K, 2014, P 4 INT C SOFT COMPU, P263
   Saduf MAW, 2013, INT J ADV RES COMP S, V3, P1151
   Shahzadi S, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/5352108
   Shaikh RA, 2012, COMPUT SECUR, V31, P447, DOI 10.1016/j.cose.2012.02.006
   Sharma M, 2012, IEEE I C EMBED SOFTW, P1047, DOI 10.1109/HPCC.2012.153
   Suparta W., 2016, MODELING TROPOSPHERI, DOI [DOI 10.1007/978-3-319-28437-8, 10.1007/978-3-319-28437-8_2, DOI 10.1007/978-3-319-28437-8_2]
   Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2
   Tiwari S, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/8971079
   Vieira J., 2004, P CONV AUD ENG SOC B, P1
   Wang Qingsong, 2011, Proceedings of the 2011 IEEE CIE International Conference on Radar (Radar), P406, DOI 10.1109/CIE-Radar.2011.6159563
   Wang YM, 2008, EXPERT SYST APPL, V34, P3099, DOI 10.1016/j.eswa.2007.06.026
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/353910
   Xu QZ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/659809
   Yao F., 2017, 2017 INT C CYB SEC P, P1, DOI [10.1109/CyberSecPODS.2017.8074846, DOI 10.1109/CYBERSECPODS.2017.8074846]
   Zanchettin C, 2010, INT J COMPUT INTELL, V9, P137, DOI 10.1142/S1469026810002823
NR 57
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18269
EP 18298
DI 10.1007/s11042-022-14010-8
EA OCT 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863553400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Bhattacharya, A
   Biswas, SK
   Mandal, A
AF Bhattacharya, Arijit
   Biswas, Saroj Kr
   Mandal, Ardhendu
TI Credit risk evaluation: a comprehensive study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Credit risk assessment; Statistical methods; Machine learning models;
   Optimization techniques
ID GENETIC ALGORITHM; RULE EXTRACTION; NEURAL-NETWORK; PROBABILISTIC
   FUNCTIONS; BANKRUPTCY PREDICTION; FEATURE-SELECTION; MODEL;
   OPTIMIZATION; CLASSIFIERS; MANAGEMENT
AB To date, there has been relatively little research in the field of credit risk analysis that compares all of the well known statistical, optimization technique (heuristic methods) and machine learning based approaches in a single article. Review on credit risk assessment using sixteen well-known approaches has been conducted in this work. The accuracy of the machine learning approaches in dealing with financial difficulties is superior to that of traditional statistical methods, especially when dealing with nonlinear patterns, according to the findings. Hybrid or Ensemble algorithms, on the other hand have been found to outperform their traditional counterparts - standalone classifiers in the vast majority of situations. Finally, the paper compares the models with nine machine learning classifiers utilizing two benchmark datasets. In this study, we have encountered with 46 datasets, among them 35 datasets have been utilized for once; whereas among the other 11 datasets, Australian, German and Japanese are the three most frequently utilized datasets by the researchers. The study showed that the performance of ensemble classifiers were very much significant. As per the experimental result, for both datasets ensemble classifiers outperformed other standalone classifiers which validate with the prior research also. Although some of these approaches have a high level of accuracy, additional study is required to discover the right parameters and procedures for better outcomes in a transparent manner. Additionally this study is a valuable reference source for analyzing credit risk for both academic and practical domains, since it contains relevant information on the most major machine learning approaches employed so far.
C1 [Bhattacharya, Arijit] Gour Mahavidyalaya, Dept Comp Sci, Malda, W Bengal, India.
   [Biswas, Saroj Kr] Natl Inst Technol, Dept Comp Sci & Engn, Silchar, Assam, India.
   [Mandal, Ardhendu] Univ North Bengal, Dept Comp Sci & Technol, Darjeeling, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; University of North Bengal
RP Bhattacharya, A (corresponding author), Gour Mahavidyalaya, Dept Comp Sci, Malda, W Bengal, India.
EM barijit@hotmail.com; bissarojkum@yahoo.com; am.csa.nbu@gmail.com
RI ; Mandal, Ardhendu/F-5184-2017
OI Bhattacharya, Arijit/0000-0001-9455-1644; Mandal,
   Ardhendu/0000-0002-4685-7283
CR Abdelmoula A.K., 2015, Accounting and Management Information Systems, V14, P79
   ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933
   Altman EI, 1997, J BANK FINANC, V21, P1721, DOI 10.1016/S0378-4266(97)00036-8
   Anagnostou I, 2019, RISKS, V7, DOI 10.3390/risks7020066
   Anderson B, 2019, EXPERT SYST APPL, V137, P349, DOI 10.1016/j.eswa.2019.07.011
   [Anonymous], 2020, GLOBAL PANDEMIC PROS
   Atiya AF, 2001, IEEE T NEURAL NETWOR, V12, P929, DOI 10.1109/72.935101
   Augasta MG, 2012, NEURAL PROCESS LETT, V35, P131, DOI 10.1007/s11063-011-9207-8
   Ayodele OE, 2021, THESIS FEDERAL U TEC
   Back B., 1996, Turku Centre for Computer Science Technical Report, V40, P1
   Bahrammirzaee A, 2010, NEURAL COMPUT APPL, V19, P1165, DOI 10.1007/s00521-010-0362-z
   Balin B.J., 2008, Basel I, Basel II, and Emerging Markets: A Non-Technical Analysis
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8
   BERTSIMAS D, 1993, STAT SCI, V8, P10, DOI 10.1214/ss/1177011077
   Bhattacharya A, 2014, SIMULATED ANNEALING
   Biswas SK, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017500063
   Chakraborty M, 2019, NEW GENERAT COMPUT, V37, P67, DOI 10.1007/s00354-018-0048-0
   Chakraborty M, 2018, NEW GENERAT COMPUT, V36, P119, DOI 10.1007/s00354-018-0031-9
   Chang YC, 2016, COMMUN STAT-THEOR M, V45, P6803, DOI 10.1080/03610926.2014.968730
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen HL, 2011, KNOWL-BASED SYST, V24, P1348, DOI 10.1016/j.knosys.2011.06.008
   Chen N, 2016, ARTIF INTELL REV, V45, P1, DOI 10.1007/s10462-015-9434-x
   Chi GT, 2019, INT J ARTIF INTELL T, V28, DOI 10.1142/S0218213019500179
   Chi L., 2006, AUSTR J MANAGEMENT, V31, P17, DOI [10.1177/031289620603100102, DOI 10.1177/031289620603100102]
   Chidambaram S, 2019, CLUSTER COMPUT, V22, P189, DOI 10.1007/s10586-018-2036-z
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahiya S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12217
   Danenas P, 2015, EXPERT SYST APPL, V42, P3194, DOI 10.1016/j.eswa.2014.12.001
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Estrella Arturo., 2000, Credit Ratings and Complementary sources of Credit Quality Information' BCBS
   Fatemi A, 2006, MANAG FINANC, V32, P227, DOI 10.1108/03074350610646735
   Gavira-Durón N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9080879
   Gyamfi NK, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P37, DOI 10.1109/IEMCON.2018.8614994
   Harris T, 2015, EXPERT SYST APPL, V42, P741, DOI 10.1016/j.eswa.2014.08.029
   He J, 2004, INT J INF TECH DECIS, V3, P633, DOI 10.1142/S021962200400129X
   Henley W. E., 1997, IMA Journal of Mathematics Applied in Business and Industry, V8, P305, DOI 10.1093/imaman/8.4.305
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Hu J, 2017, ADV INTEL SYS RES, V141, P373
   Huang CL, 2007, EXPERT SYST APPL, V33, P847, DOI 10.1016/j.eswa.2006.07.007
   Huang JJ, 2006, APPL MATH COMPUT, V174, P1039, DOI 10.1016/j.amc.2005.05.027
   Huang XB, 2018, COGN SYST RES, V52, P317, DOI 10.1016/j.cogsys.2018.07.023
   Imandoust S. B., 2013, INT J ENG RES APPL, V3, P605
   Khashman A, 2011, APPL SOFT COMPUT, V11, P5477, DOI 10.1016/j.asoc.2011.05.011
   Khashman A, 2010, EXPERT SYST APPL, V37, P6233, DOI 10.1016/j.eswa.2010.02.101
   Khemakhem S, 2018, J MODEL MANAG, V13, P932, DOI 10.1108/JM2-01-2017-0002
   Konglai ZHU., 2011, MANAG SCI ENG, V4, P24
   Larghi O.P., 1988, P407
   Le R, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113940
   Leo M, 2019, RISKS, V7, DOI 10.3390/risks7010029
   Lileikiene A, 2008, INZ EKON, P32
   Marinakis Y, 2008, J GLOBAL OPTIM, V42, P279, DOI 10.1007/s10898-007-9242-1
   Marinakis Y, 2008, NEW MATH NAT COMPUT, V4, P107, DOI 10.1142/S1793005708000957
   Marinakis Y, 2009, EXPERT SYST APPL, V36, P10604, DOI 10.1016/j.eswa.2009.02.055
   Martens D, 2010, J OPER RES SOC, V61, P561, DOI 10.1057/jors.2008.164
   Masmoudi K, 2019, EXPERT SYST APPL, V127, P157, DOI 10.1016/j.eswa.2019.03.014
   Metawa N, 2017, EXPERT SYST APPL, V80, P75, DOI 10.1016/j.eswa.2017.03.021
   Miller LH, 1988, CREDIT ASSESSMENT MO
   Mohammadi Nasser, 2016, International Journal of Information Technology and Computer Science, V8, P58, DOI 10.5815/ijitcs.2016.03.07
   Moulal FE, 2017, RISK MANAG-UK, V19, P158, DOI 10.1057/s41283-017-0016-x
   Nazari M., 2013, J Manage Res, V5, P17
   Oguz HT, 2008, 2008 23 INT S COMPUT, P1
   Oreski S, 2014, EXPERT SYST APPL, V41, P2052, DOI 10.1016/j.eswa.2013.09.004
   Pacelli V., 2011, J INTELLIGENT LEARNI, V3, P103, DOI [10.4236/jilsa.2011.32012, DOI 10.4236/JILSA.2011.32012]
   Pavlenko T, 2010, INT J INTELL SYST, V25, P326, DOI 10.1002/int.20410
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Regulation R-BB, 2009, FDN BANK RISK
   Rodan A, 2016, LECT NOTES ARTIF INT, V9621, P595, DOI 10.1007/978-3-662-49381-6_57
   Roy A. G., 2019, CREATIVE BUSINESS SO, P79, DOI [10.1007/978-3-030-01662-3_10, DOI 10.1007/978-3-030-01662-3_10]
   Satchidananda S., 2006, Comparing decision trees with logistic regression for credit risk analysis
   Setiono R, 2008, IEEE T NEURAL NETWOR, V19, P299, DOI 10.1109/TNN.2007.908641
   Souza C. R., 2010, Creative Commons Attribution-Noncommercial-Share Alike, V3, P29
   Tao Wang, 2019, IOP Conference Series: Materials Science and Engineering, V490, DOI 10.1088/1757-899X/490/6/062041
   Triki MW, 2017, BANK CREDIT RISK EVI
   Uddin MS, 2021, 4 IND REVOLUTION IMP, P417, DOI DOI 10.1007/978-3-030-62796-6_25
   Wang D, 2018, J COMPUT APPL MATH, V329, P307, DOI 10.1016/j.cam.2017.04.036
   Wang SJ, 2009, EXPERT SYST APPL, V36, P6466, DOI 10.1016/j.eswa.2008.07.041
   Ye X, 2018, ELECTRON COMMER R A, V32, P23, DOI 10.1016/j.elerap.2018.10.004
   Yi Jiang, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P18, DOI 10.1109/CSIE.2009.481
   Yongkai Wang, 2021, Journal of Physics: Conference Series, V1774, DOI 10.1088/1742-6596/1774/1/012056
   Yurynets R, 2019, CEUR WORKSHOP PROCEE, V2362, P153
   Zhang R, 2011, EXPERT SYST APPL, V38, P14225, DOI 10.1016/j.eswa.2011.04.235
   Zhang WY, 2019, EXPERT SYST APPL, V121, P221, DOI 10.1016/j.eswa.2018.12.020
   Zhenya Tian, 2020, Procedia Computer Science, V174, P150, DOI 10.1016/j.procs.2020.06.070
NR 84
TC 3
Z9 3
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18217
EP 18267
DI 10.1007/s11042-022-13952-3
EA OCT 2022
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863811400007
DA 2024-07-18
ER

PT J
AU Pradhan, AK
   Mishra, D
   Das, K
   Obaidat, MS
   Kumar, M
AF Pradhan, Ashwini Kumar
   Mishra, Debahuti
   Das, Kaberi
   Obaidat, Mohammad S.
   Kumar, Manoj
TI A COVID-19 X-ray image classification model based on an enhanced
   convolutional neural network and hill climbing algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE X-Ray images; COVID 19; Image classification; Tailored convolutional
   neural network; Hill climbing algorithms
AB The classification of medical images is significant among researchers and physicians for the early identification and clinical treatment of many disorders. Though, traditional classifiers require more time and effort for feature extraction and reduction from images. To overcome this problem, there is a need for a new deep learning method known as Convolution Neural Network (CNN), which shows the high performance and self-learning capabilities. In this paper,to classify whether a chest X-ray (CXR) image shows pneumonia (Normal) or COVID-19 illness, a test-bed analysis has been carried out between pre-trained CNN models like Visual Geometry Group (VGG-16), VGG-19, Inception version 3 (INV3), Caps Net, DenseNet121, Residual Neural Network with 50 deep layers (ResNet50), Mobile-Net and proposed CNN classifier. It has been observed that, in terms of accuracy, the proposed CNN model appears to be potentially superior to others. Additionally, in order to increase the performance of the CNN classifier, a nature-inspired optimization method known as Hill-Climbing Algorithm based CNN (CNN-HCA) model has been proposed to enhance the CNN model's parameters. The proposed CNN-HCA model performance is tested using a simulation study and contrasted to existing hybridized classifiers like as Particle Swarm Optimization (CNN-PSO) and CNN-Jaya. The proposed CNN-HCA model is compared with peer reviewed works in the same domain. The CXR dataset, which is freely available on the Kaggle repository, was used for all experimental validations. In terms of Receiver Operating Characteristic Curve (ROC), Area Under the ROC Curve (AUC), sensitivity, specificity, F-score, and accuracy, the simulation findings show that the CNN-HCA is possibly superior than existing hybrid approaches. Each method employs a k-fold stratified cross-validation strategy to reduce over-fitting.
C1 [Pradhan, Ashwini Kumar; Mishra, Debahuti; Das, Kaberi] Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar 751030, Odisha, India.
   [Obaidat, Mohammad S.] Indian Inst Technol, Dhanbad, Bihar, India.
   [Obaidat, Mohammad S.] Univ Jordan, KASIT, Amman, Jordan.
   [Obaidat, Mohammad S.] Univ Sci & Technol Beijing, Beijing, Peoples R China.
   [Kumar, Manoj] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
C3 Siksha 'O' Anusandhan University; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (Indian School of Mines)
   Dhanbad; University of Jordan; University of Science & Technology
   Beijing; University of Wollongong
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
EM ashwini.10.pradhan@gmail.com; debahutimishra@soa.ac.in;
   kaberidas@soa.ac.in; msobaidat@gmail.com; wss.manojkumar@gmail.com
RI Pradhan, Ashwini/GZM-0401-2022; Obaidat, Mohammad S./KBC-2747-2024;
   Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280; Mishra, Debahuti/0000-0002-6827-6121;
   Kumar, Dr. Manoj/0000-0001-5113-0639; kumar pradhan,
   Ashwini/0000-0002-1822-4235
CR Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Ayyar MP, 2021, IEEE INT CONF COMP V, P519, DOI 10.1109/ICCVW54120.2021.00064
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chen Joy Iong-Zong, 2021, J. ISMAC, V3, P02, DOI DOI 10.36548/JISMAC.2021.2.006
   Chithaluru PK, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4881
   Chithaluru P, 2022, IEEE INTERNET THINGS, V9, P7251, DOI 10.1109/JIOT.2021.3098430
   Chithaluru P, 2021, ENERGY REP, V7, P8277, DOI 10.1016/j.egyr.2021.07.136
   Chithaluru P, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102254
   Chithaluru P, 2021, WIRELESS PERS COMMUN, V116, P153, DOI 10.1007/s11277-020-07709-0
   Chithaluru P, 2019, COMPUT NETW, V162, DOI 10.1016/j.comnet.2019.106863
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng XM, 2018, IEEE T IMAGE PROCESS, V27, P1888, DOI 10.1109/TIP.2017.2779600
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goel T, 2021, APPL INTELL, V51, P1351, DOI 10.1007/s10489-020-01904-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Hu TQ, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102764
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Ko H, 2020, J MED INTERNET RES, V22, DOI 10.2196/19569
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D, 2020, EURASIAN J MED ONCOL, V4, P8, DOI 10.14744/ejmo.2020.51418
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pathan S, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107238
   Pradhan Ashwini Kumar, 2021, Intelligent and Cloud Computing. Proceedings of ICICC 2019. Smart Innovation, Systems and Technologies (SIST 153), P449, DOI 10.1007/978-981-15-6202-0_46
   Pradhan A, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9172095
   Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sheng T, 2018, 2018 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2), P14, DOI 10.1109/EMC2.2018.00011
   Shukla A, 2021, INT FORUM ALLERGY RH, V11, P1264, DOI 10.1002/alr.22783
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Skalak D., 1994, Proceedings of the Eleventh International Conference on Machine Learning, P293, DOI [https://doi.org/10.1016/B978-1-55860-335-6.50043-X, DOI 10.1016/B978-1-55860-335-6.50043-X, 10.1016/B978-1-55860-335-6.50043-X]
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Wu XJ, 2020, EUR J RADIOL, V128, DOI 10.1016/j.ejrad.2020.109041
   Wu X, 2019, IEEE ACCESS, V7, P59376, DOI 10.1109/ACCESS.2019.2914731
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Young S. R., 2015, P WORKSH MACH LEARN, P1, DOI DOI 10.1145/2834892.2834896
   Zhang HT, 2020, EUR J NUCL MED MOL I, V47, P2525, DOI 10.1007/s00259-020-04953-1
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 45
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14219
EP 14237
DI 10.1007/s11042-022-13826-8
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900010
PM 36185320
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ren, LF
   Hu, RM
   Li, DS
   Wang, Z
   Wu, JH
   Li, XX
   Hu, WY
AF Ren, Lingfei
   Hu, Ruimin
   Li, Dengshi
   Wang, Zheng
   Wu, Junhang
   Li, Xixi
   Hu, Wenyi
TI Who is your friend: inferring cross-regional friendship from mobility
   profiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Friendship inference; Bipartite graph embedding; Heterogeneous graph;
   Graph attention network; Location based social networks
ID PREDICTION
AB Location Based Social Networks (LBSNs) have been widely used as a primary data source to study friendship inference. Traditional approaches mainly focused on exploring pairwise co-location frequency, that it, the more frequency two users co-location, the more likely that they are friends. Such methods fail to solve the geographically restricted friends recommendation. In this paper, we tackle a novel friendship inference problem: cross-regional friendship inference, i.e., inferring whether users from different regions are friends. By revisiting mobility and social friendship of cross-regional friends based on a large-scale LBSNs dataset, we spot that cross-regional users are likely to form friendship when their mobility profiles are of high similarity. To this end, we propose Category-Aware Heterogeneous Graph Embedding Framework (CHGE) for inferring cross-regional friendship. We first utilize multi-bipartite graph embedding to capture users' mobility neighbor proximity and activity category preference simultaneously, then the contributions of Point of Interest (POI) and category are learned by a category-aware heterogeneous graph attention network in an unsupervised method. Extensive evaluations on the real-world LBSNs dataset show that our CHGE significantly outperforms the state-of-the-art approaches by up to 9.7% on Area Under the ROC Curve (AUC) and 7.3% on Average Precision (AP).
C1 [Ren, Lingfei; Hu, Ruimin; Wang, Zheng; Wu, Junhang; Li, Xixi; Hu, Wenyi] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan, Peoples R China.
   [Li, Dengshi] Jianghan Univ, Sch Artificial Intelligence, Wuhan, Peoples R China.
C3 Wuhan University; Jianghan University
RP Hu, RM (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan, Peoples R China.
EM hrm@whu.edu.cn
OI Hu, Ruimin/0000-0002-5872-3872
FU National Nature Science Foundation of China; National Social Science
   Foundation of China [19ZDA113]; Application Foundation Frontier Project
   of Wuhan Science and Technology Bureau [2020010601012288]
FX The work is supported by the National Nature Science Foundation of China
   (No.U1803262), National Social Science Foundation of China
   (No.19ZDA113), Application Foundation Frontier Project of Wuhan Science
   and Technology Bureau (No.2020010601012288) and National Nature Science
   Foundation of China (No.U1736206).
CR Backes M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1943, DOI 10.1145/3133956.3133972
   Cao JX, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P635, DOI 10.1145/3437963.3441783
   Cen YK, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1358, DOI 10.1145/3292500.3330964
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chauhan S, 2021, INT J PERVASIVE COMP, V17, P404, DOI 10.1108/IJPCC-01-2021-0013
   Cheng R, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1284, DOI 10.1145/2808797.2808884
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Cranshaw J, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P119
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Eagle N, 2009, P NATL ACAD SCI USA, V106, P15274, DOI 10.1073/pnas.0900282106
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He XL, 2021, IEEE T DEPEND SECURE, V18, P2193, DOI 10.1109/TDSC.2021.3068307
   Hsieh HP, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293319
   Hsieh Hsun-Ping, 2015, INT C INF KNOWL MAN, P1839
   Hu H., 2022, DIGIT COMMUN NETW, V32, P19
   Huang, 2021, 2021 16 IBERIAN C IN, P1, DOI DOI 10.23919/CISTI52073.2021.9476543
   Huang CJ, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3494558
   Kingma D. P., 2014, arXiv
   Kishor A, 2021, INT J INTERACT MULTI, V6, P7, DOI 10.9781/ijimai.2020.12.004
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Li JS, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3068299
   Li J, 2020, IEEE INTERNET THINGS, V7, P5116, DOI 10.1109/JIOT.2020.2974669
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Mei GX, 2022, NEUROCOMPUTING, V468, P276, DOI 10.1016/j.neucom.2021.10.001
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Min SJ, 2021, INT CONF COMPUT AUTO, P48, DOI 10.1109/ICCAE51876.2021.9426115
   Piao YHR, 2021, IEEE ACCESS, V9, P40417, DOI 10.1109/ACCESS.2021.3064208
   Shaabani E, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2079, DOI 10.1145/2783258.2788618
   Shi, 2022, GRAPH NEURAL NETWORK, P51
   Shuai SY, 2022, SMART INNOV SYST TEC, V268, P377, DOI 10.1007/978-981-16-8048-9_36
   Sookoo A, 2021, INT J SYST ASSUR ENG, V12, P461, DOI 10.1007/s13198-021-01092-0
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tripathi SP, 2022, FUTURE GENER COMP SY, V127, P409, DOI 10.1016/j.future.2021.09.024
   Trung H, 2022, MSC LBSN MULTISOCIA, DOI [10.13140/RG.2.2.26964.07048, DOI 10.13140/RG.2.2.26964.07048]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2021, 2021 17TH INTERNATIONAL CONFERENCE ON MOBILITY, SENSING AND NETWORKING (MSN 2021), P247, DOI 10.1109/MSN53354.2021.00048
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562
   Wei XY, 2021, GERONTOLOGY, V67, P323, DOI 10.1159/000511911
   Wu YJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3898
   Yang DQ, 2022, IEEE T KNOWL DATA EN, V34, P1843, DOI 10.1109/TKDE.2020.2997869
   Yang DQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2147, DOI 10.1145/3308558.3313635
   Yi HC, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab340
   Yi YZ, 2022, SECUR PRIVACY, V5, DOI 10.1002/spy2.194
   Zhang CX, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P690, DOI 10.1145/3289600.3291001
   Zhang DK, 2018, LECT NOTES ARTIF INT, V10938, P196, DOI 10.1007/978-3-319-93037-4_16
   ZHANG W, 2020, IEEE RANS NEURAL NET, P1
   Zhang W., 2020, IEEE T KNOWL DATA EN
   Zhang Y, 2015, LECT NOTES COMPUT SC, V9313, P55, DOI 10.1007/978-3-319-25255-1_5
   Zheng Chen, 2020, 2020 International Conference on Big Data and Informatization Education (ICBDIE). Proceedings, P413, DOI 10.1109/ICBDIE50010.2020.00103
   Zhou F, 2021, INFORMS J COMPUT, V33, P1400, DOI 10.1287/ijoc.2020.0989
NR 50
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12719
EP 12737
DI 10.1007/s11042-022-13672-8
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858369900001
DA 2024-07-18
ER

PT J
AU Leelavathi, R
   Prasad, MNG
AF Leelavathi, R.
   Prasad, M. N. Giri
TI A high capacity reversible data hiding scheme in efficient LZW
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Lossless compression; LZW; Compression ratio;
   Bits per pixel
AB Reversible data hiding (RDH) is a steganography technique where the cover data is recovered completely after extracting the secret message from the stego media. RDH would allow the users to transmit confidential information in cover media without raising any suspicion. Primarily, compressed images are transmitted over the internet as they consume less bandwidth. RDH can only be applied on images compressed with lossless compression techniques. As the RDH algorithms do not affect the cover media, the compressed data remains intact, which can later be decompressed to get the original cover image. This paper presents an RDH technique implemented in the compressed domain. In present work, a modified LZW Lossless compression is used to compress the cover image, since the conventional compression works effectively only when the redundancy of the cover image is high. But for natural images, the resultant LZW data stream has more bits than the original image. In order to increase the redundancy in the cover image, a modified LZW compression technique is employed. This modifies the pixel values before compression, which is considered as preprocessing. In this preprocessing Consecutive pixels in the image are subtracted, and the resultant difference is converted into signed binary notation. As the similarity in nearby pixels is high, this process increases the redundancy in the data. This processed data is now compressed using modified LZW compression. The resultant data is a 16-bit integer sequence. But the maximum number in the data is 4096. Thus, every compressed data pixel has four vacant bits in which the secret message can be embedded. The proposed algorithm is compared with the existing techniques in terms of compression ratio and hiding capacity in terms of bits/pixel. The proposed method obtained a high capacity of four bits per pixel with high compression efficiency.
C1 [Leelavathi, R.; Prasad, M. N. Giri] JNTUA, Dept ECE, Ananthapuram, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Leelavathi, R (corresponding author), JNTUA, Dept ECE, Ananthapuram, India.
EM leelavathirudraksha@gmail.com
RI Sairam, Sairam Sairam/IAO-6330-2023
CR Chang C-C., 2018, INT J NETWORK SECUR, V20, P478
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Choudhary S. M, 2015, INT J ENG SCI INNOV, V4, P45
   Du Y, 2022, IEEE T DEPEND SECURE, V19, P1420, DOI 10.1109/TDSC.2020.3013326
   Fridrich J, 2004, PROC SPIE, V5306, P354, DOI 10.1117/12.525418
   Ghernaouti-Helie S., 2011, Proceedings of the 2011 14th International Conference on Network-Based Information Systems (NBiS 2011), P208, DOI 10.1109/NBiS.2011.38
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Huang LC, 2021, INFORMATICA-LITHUAN, V32, P69, DOI 10.15388/20-INFOR422
   Kalaichelvi V, 2021, J AMB INTEL HUM COMP, V12, P7235, DOI 10.1007/s12652-020-02398-w
   Kumar A., 2010, Int. J Comput. Appl., V9, P19
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Liu XL, 2016, IMAGING SCI J, V64, P364, DOI 10.1080/13682199.2016.1213983
   Malik A, 2016, AICTC 16, P1
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Rashmi N, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P81, DOI 10.1109/ICISC.2018.8398946
   Sarmah DK, 2020, OPTIMIZATION MODELS, P33, DOI DOI 10.1007/978-3-030-42044-4_2
   Shipunov IS, 2019, IEEE NW RUSS YOUNG, P339, DOI [10.1109/EIConRus.2019.8657219, 10.1109/eiconrus.2019.8657219]
   Tyagi A., 2020, J ADV DATABASE MANAG, V7, P12
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang ZH, 2013, J SYST SOFTWARE, V86, P2771, DOI 10.1016/j.jss.2013.06.024
   Wedaj FT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0206-1
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Welch TA, 1985, U.S. Patent, Patent No. [4,558,302, 4558302]
   Zhang C, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102821
   Zhang C, 2020, MULTIMED TOOLS APPL, V79, P19045, DOI 10.1007/s11042-020-08809-6
NR 28
TC 1
Z9 1
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9459
EP 9476
DI 10.1007/s11042-022-13765-4
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854682700002
DA 2024-07-18
ER

PT J
AU Cimolin, V
   Paraskevopoulos, IT
   Sala, M
   Tarabini, M
   Galli, M
AF Cimolin, Veronica
   Paraskevopoulos, Ioannis Th
   Sala, Maurizio
   Tarabini, Marco
   Galli, Manuela
TI The smart body concept as a demonstration of the overarching utility and
   benefits of 3D avatars in retail, health and wellbeing: an accuracy
   study of body measures from 3D reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Avatar; Body scanner; Anthropometry; 3D models; Accuracy; Fashion;
   Fitness; Wellness; Healthcare
ID LASER SCANNER; CIRCUMFERENTIAL METHOD; ARM VOLUME; HAND-HELD; SHAPE;
   CLASSIFICATION; RELIABILITY; VALIDATION; WOMEN
AB Recent developments in 3D graphic technologies enable the affordable and precise reconstruction of body scanned models that can be applied in a variety of verticals, such as fashion, fitness and wellness, and healthcare. The accuracy of body measurements is a crucial element for the successful application of avatars in the following use cases: Avatars that go beyond visual representation and offer intrinsic and precise anthropometric data defined as a smart body are discussed in this paper. In particular, this paper presents the Gate technology, an innovative, autonomous, sustainable body scanner, coupled with an automatic production pipeline and the concept of avatars as smart bodies. We present an accuracy study of scanning technology for scanning inanimate objects, as well as body parts versus the ground, by using an established accuracy scanning system. The results appear to be promising and confirm the hypothesis of applying the technology to the use cases discussed as well as broadening the research to other studies and future applications.
C1 [Cimolin, Veronica; Galli, Manuela] Politecn Milan, Dept Elect Informat & Bioengn, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.
   [Cimolin, Veronica] San Giuseppe Hosp, Orthoped Rehabil Unit & Res Lab Biomech, Ist Auxol Italiano, IRCCS, I-28824 Oggebbio, Italy.
   [Paraskevopoulos, Ioannis Th; Sala, Maurizio] IGOODI SrL, Via Gaetano Negri 4, I-20123 Milan, Italy.
   [Tarabini, Marco] Politecn Milan, Dept Mech Engn, Via La Masa 1, I-20156 Milan, Italy.
C3 Polytechnic University of Milan; IRCCS Istituto Auxologico Italiano;
   Polytechnic University of Milan
RP Cimolin, V (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.; Cimolin, V (corresponding author), San Giuseppe Hosp, Orthoped Rehabil Unit & Res Lab Biomech, Ist Auxol Italiano, IRCCS, I-28824 Oggebbio, Italy.
EM VERONICA.CIMOLIN@POLIMI.IT
RI Cimolin, Veronica/AFY-3578-2022; Galli, Manuela/AAH-8783-2019; Tarabini,
   Marco/D-3624-2011
OI Tarabini, Marco/0000-0002-2640-1764; Cimolin,
   Veronica/0000-0001-6299-7254
FU Politecnico di Milano within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Milano within the
   CRUI-CARE Agreement.
CR ALTMAN DG, 1983, J ROY STAT SOC D-STA, V32, P307, DOI 10.2307/2987937
   [Anonymous], IEEE Journals & Magazine
   [Anonymous], 2022, 725012017 ISO
   [Anonymous], 2022, 2068512018 ISO
   Atkinson G, 1998, SPORTS MED, V26, P217, DOI 10.2165/00007256-199826040-00002
   Aysan AF, 2020, REFLECTIONS ON THE PANDEMIC IN THE FUTURE OF THE WORLD, P515, DOI 10.32983/2222-4459-2020-5-94-99
   Berlusconi D., 2021, U.S. patent, Patent No. [10,924,662, 10924662]
   Boyle A, 2022, BMJ-BRIT MED J, V378, DOI 10.1136/bmj.o1702
   Bragança S, 2017, WORK, V57, P9, DOI 10.3233/WOR-172532
   Cau N, 2016, J NOV PHYSIOTHER, V6, DOI 10.4172/2165-7025.1000303
   Cau N, 2018, J VASC SURG-VENOUS L, V6, P96, DOI 10.1016/j.jvsv.2017.08.014
   Cau N, 2016, J VASC SURG-VENOUS L, V4, P64, DOI 10.1016/j.jvsv.2015.05.005
   Connell L., 2003, Body scan analysis for fit models based on body shape and posture analysis
   de Best R, 2019, RET PACK
   Ding D, 2020, BRIT J SPORT MED, V54, P1183, DOI 10.1136/bjsports-2020-102575
   Elflein, 2021, PERCENTAGE US WOMEN
   GAZZUOLO E, 1992, APPL ERGON, V23, P161, DOI 10.1016/0003-6870(92)90219-L
   Glock F, 2017, PEDIATR RES, V81, P736, DOI 10.1038/pr.2016.274
   Hackl C., 2022, Forbes
   Harrison JA, 2004, BRIT J ORAL MAX SURG, V42, P8, DOI 10.1016/S0266-4356(03)00192-X
   Iivari N, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102183
   Kim RJ, 2021, INT J FOOD SCI NUTR, V72, P537, DOI [10.1080/09637486.2020.1840533, 10.1109/EMR.2020.2990115]
   Koepke N, 2017, PEERJ, V5, DOI 10.7717/peerj.2980
   Kouchi M, 2011, APPL ERGON, V42, P518, DOI 10.1016/j.apergo.2010.09.011
   Lee JY, 2007, INT J CLOTH SCI TECH, V19, P374, DOI 10.1108/09556220710819555
   Lele S.R., 2001, INTER DISC
   Lim Ho-sun, 2010, [Journal of the Korean Society of Clothing and Textiles, 한국의류학회지], V34, P1968
   Lin YC, 2004, APPL ERGON, V35, P173, DOI 10.1016/j.apergo.2004.01.004
   LIU Z, 2021, IEEE T DEPEND SECURE, P1
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma Q, 2021, ARXIV
   Marques ICP, 2020, HEALTH TECHNOL-GER, V10, P575, DOI 10.1007/s12553-019-00402-8
   Masuda T, 2007, SEN-I GAKKAISHI, V63, P23
   McKinnon JG, 2007, J SURG ONCOL, V96, P381, DOI 10.1002/jso.20790
   Medina-Inojosa Jose, 2016, Obes Open Access, V2, DOI 10.16966/2380-5528.122
   Mestre S, 2014, J VASC SURG-VENOUS L, V2, P39, DOI 10.1016/j.jvsv.2013.08.002
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Muller L, 2021, ARXIV
   Newcomb EA., 2006, BODY SHAPE ANAL HISP
   Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175
   Robinette Kathleen M, 2006, Appl Ergon, V37, P259, DOI 10.1016/j.apergo.2005.07.009
   Seetharaman P, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102173
   Shahbandeh M, 2021, REVENUE APPAREL MARK
   Simmons K.P., 2004, J TEXTILE APPAREL TE, V4, P1
   Singh S, 2021, INT J PROD RES, V59, P1993, DOI 10.1080/00207543.2020.1792000
   Song HK, 2011, TEXT RES J, V81, P914, DOI 10.1177/0040517510392448
   Vuruskan A, 2011, INT J CLOTH SCI TECH, V23, P46, DOI 10.1108/09556221111096732
   Wells JCK, 2008, INT J OBESITY, V32, P152, DOI 10.1038/sj.ijo.0803685
   Xia SB, 2019, J TEXT I, V110, P1103, DOI 10.1080/00405000.2018.1541437
   Yi K-H, 2008, J KOREAN SOC CLOTH T, V32, DOI 10.5850/JKSCT.2008.32.6.959
   Yu M, 2020, FASH TEXT, V7, DOI 10.1186/s40691-020-00223-8
NR 51
TC 4
Z9 4
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11079
EP 11098
DI 10.1007/s11042-022-13661-x
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852929500005
PM 36118187
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Garg, G
   Prasad, G
   Garg, L
   Miyakoshi, M
   Nakai, T
   Coyle, D
AF Garg, Gaurav
   Prasad, Girijesh
   Garg, Lalit
   Miyakoshi, Makoto
   Nakai, Toshiharu
   Coyle, Damien
TI Regional optimum frequency analysis of resting-state fMRI data for early
   detection of Alzheimer's disease biomarkers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Functional-MRI (fMRI); Resting-state fMRI; Frequency-domain analysis;
   regional optimum frequency analysis; Clustering; Gaussian mixture model;
   Alzheimer's disease biomarkers
ID MILD COGNITIVE IMPAIRMENT; FUNCTIONAL CONNECTIVITY; DEFAULT MODE;
   AMPLITUDE; NETWORKS
AB The blood-oxygen label dependent (BOLD) signal obtained from functional magnetic resonance images (fMRI) varies significantly among populations. Yet, there is some agreement among researchers over the pace of the blood flow within several brain regions relative to the subject's age and cognitive ability. Our analysis further suggested that regional coherence among the BOLD fMRI voxels belonging to the individual region of the brain has some correlation with underlying pathology as well as cognitive performance, which can suggest potential biomarkers to the early onset of the disease. To capitalise on this we propose a method, called Regional Optimum Frequency Analysis (ROFA), which is based on finding the optimum synchrony frequency observed at each brain region for each of the resting-state BOLD frequency bands (Slow 5 (0.01-0.027 Hz), Slow 4 (0.027-0.073 Hz) and slow 3 (0.073 to 0.198 Hz)), and the whole frequency band (0.01-0.167 Hz) respectively. The ROFA is carried out on fMRI data of total 310 scans, i.e., 26, 175 and 109 scans from 21 young-healthy (YH), 69 elderly-healthy (EH) and 33 Alzheimer's disease (AD) patients respectively, where these scans include repeated scans from some subjects acquired at 3 to 6 months intervals. A 10-fold cross-validation procedure evaluated the performance of ROFA for classification between the YH vs EH, YH vs AD and EH vs AD subjects. Based on the confusion-matrix parameters; accuracy, precision, sensitivity and Matthew's correlation coefficient (MCC), the proposed ROFA classification outperformed the state-of-the-art Group-independent component analysis (Group-ICA), Functional-connectivity, Graph metrics, Eigen-vector centrality, Amplitude of low-frequency fluctuation (ALFF) and fractional amplitude of low-frequency fluctuations (fALFF) based methods with more than 94.99% precision and 95.67% sensitivity for different subject groups. The results demonstrate the effectiveness of the proposed ROFA parameters (frequencies) as adequate biomarkers of Alzheimer's disease.
C1 [Garg, Gaurav] BrainAl Res Pvt Ltd, Embedded & Robot, Kanpur, Uttar Pradesh, India.
   [Prasad, Girijesh; Coyle, Damien] Ulster Univ, Sch Comp & Intelligent Syst, Magee Campus, Derry, Londonderry, North Ireland.
   [Garg, Lalit] Univ Malta, Fac Informat & Commun Technol, Msida, Malta.
   [Miyakoshi, Makoto] Univ Calif San Diego, Swartz Ctr Computat Neurosci, Inst Neural Computat, San Diego, CA 92103 USA.
   [Nakai, Toshiharu] Natl Ctr Geriatr & Gerontol NCGG, Neuroimaging & Informat Lab Niinf, Obu, Japan.
C3 Ulster University; University of Malta; University of California System;
   University of California San Diego; National Center for Geriatrics &
   Gerontology
RP Garg, G (corresponding author), BrainAl Res Pvt Ltd, Embedded & Robot, Kanpur, Uttar Pradesh, India.
EM gauravgarg@braina.live; g.prasad@ulster.ac.uk; lalit.garg@um.edu.mt;
   mmiyakoshi@ucsd.edu; toshi@ncgg.go.jp; dh.coyle@ulster.ac.uk
RI Garg, Lalit/AAE-6453-2019; Nakai, Toshi/KFS-9314-2024; Coyle,
   Damien/D-1161-2013
OI Garg, Lalit/0000-0002-3868-0481; Nakai, Toshi/0000-0003-3960-8585;
   Prasad, Girijesh/0000-0003-3284-9589; Garg, Gaurav/0000-0001-8489-1266;
   Coyle, Damien/0000-0002-4739-1040
CR [Anonymous], 2011, INT J BIOELECTROMAGN
   [Anonymous], 2008, J APPL QUANT METHODS
   Ashburner J., 2012, SPM8 MANUAL FIL METH
   Bajaj S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064466
   Baron JC, 2001, NEUROIMAGE, V14, P298, DOI 10.1006/nimg.2001.0848
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Binnewijzend MAA, 2012, NEUROBIOL AGING, V33, P2018, DOI 10.1016/j.neurobiolaging.2011.07.003
   Buxton RB, 1998, MAGNET RESON MED, V39, P855, DOI 10.1002/mrm.1910390602
   Carugo O, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-380
   Chai XQJ, 2012, NEUROIMAGE, V59, P1420, DOI 10.1016/j.neuroimage.2011.08.048
   Challis E, 2015, NEUROIMAGE, V112, P232, DOI 10.1016/j.neuroimage.2015.02.037
   Chen Chien-Chung, 2008, P63
   Chetelat G, 2003, NEUROIMAGE, V18, P525, DOI 10.1016/S1053-8119(02)00026-5
   Cole DM, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00008
   Coupé P, 2012, NEUROIMAGE-CLIN, V1, P141, DOI 10.1016/j.nicl.2012.10.002
   Dai ZJ, 2012, NEUROIMAGE, V59, P2187, DOI 10.1016/j.neuroimage.2011.10.003
   de Vos F, 2018, NEUROIMAGE, V167, P62, DOI 10.1016/j.neuroimage.2017.11.025
   Dimitriadou E, 2004, ARTIF INTELL MED, V31, P57, DOI 10.1016/j.artmed.2004.01.010
   Dorum ES, 2017, NEUROIMAGE, V148, P364, DOI 10.1016/j.neuroimage.2017.01.048
   Fiandaca MS, 2014, ALZHEIMERS DEMENT, V10, pS196, DOI 10.1016/j.jalz.2014.04.015
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Friston KJ., 1994, HUMAN BRAIN MAPPING, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Garg G, 2013, J NEUROSCI METH, V215, P71, DOI 10.1016/j.jneumeth.2013.02.015
   Garg L, 2009, COMP MED SY, P118
   Gibbons JD., 2011, Nonparametric Statistical Inference, P977
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   Greicius MD, 2009, CEREB CORTEX, V19, P72, DOI 10.1093/cercor/bhn059
   Griffanti L, 2016, NEUROIMAGE, V124, P704, DOI 10.1016/j.neuroimage.2015.09.021
   Hampel H, 2010, NAT REV DRUG DISCOV, V9, P560, DOI 10.1038/nrd3115
   Hayasaka S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00880
   Hoptman MJ, 2010, SCHIZOPHR RES, V117, P13, DOI 10.1016/j.schres.2009.09.030
   Koch W, 2012, NEUROBIOL AGING, V33, P466, DOI 10.1016/j.neurobiolaging.2010.04.013
   Lemaître H, 2005, NEUROIMAGE, V26, P900, DOI 10.1016/j.neuroimage.2005.02.042
   Li JJ, 2013, CEREB CORTEX, V23, P542, DOI [10.1093/cercor/bhs034, 10.1093/cercor/bhs410]
   Li R, 2012, HUM BRAIN MAPP, V33, P1076, DOI 10.1002/hbm.21269
   Liu MH, 2014, NEUROINFORMATICS, V12, P381, DOI 10.1007/s12021-013-9218-x
   Mezer A, 2009, NEUROIMAGE, V45, P1117, DOI 10.1016/j.neuroimage.2008.12.015
   Duc NT, 2020, NEUROINFORMATICS, V18, P71, DOI 10.1007/s12021-019-09419-w
   Parmar H, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.5.056001
   Peng SL, 2014, NEUROIMAGE, V98, P176, DOI 10.1016/j.neuroimage.2014.04.078
   Prvulovic D, 2011, PROG NEUROBIOL, V95, P557, DOI 10.1016/j.pneurobio.2011.05.008
   Qureshi MNI, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00008
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Riedl, 2012, INTRINSIC FUNCTIONAL
   Rorden C, 2000, BEHAV NEUROL, V12, P191, DOI 10.1155/2000/421719
   Salvador R, 2007, NEUROIMAGE, V35, P83, DOI 10.1016/j.neuroimage.2006.12.001
   Schroeter ML, 2009, NEUROIMAGE, V47, P1196, DOI 10.1016/j.neuroimage.2009.05.037
   Song XW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025031
   Spangenberg SM, 2000, WIRELESS PERS COMMUN, V13, P27, DOI 10.1023/A:1008848916834
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Weiner Michael W, 2012, Alzheimers Dement, V8, pS1, DOI [10.1016/j.jalz.2013.05.1769, 10.1016/j.jalz.2011.09.172]
   WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
   Wolz R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025446
   Yang H, 2007, NEUROIMAGE, V36, P144, DOI 10.1016/j.neuroimage.2007.01.054
NR 54
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41953
EP 41977
DI 10.1007/s11042-022-13523-6
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000843995800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nagalakshmi, P
AF Nagalakshmi, P.
TI An ingenious ROBD system to slay invasion attack for profitable spectrum
   utilization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoS-quality of service; PU-primary user; SU-secondary user;
   ILM-iterative learning model
ID COGNITIVE RADIO NETWORKS; MANAGEMENT; SCHEME
AB Despite the cognitive radio network is the emerging technology for avoiding the underutilization of spectrum by allowing secondary users (SU) to share with the licensed band of the primary user (PU), it has its disadvantages such as QoS degradation, connection unavailability, Denial of service and bandwidth waste due to false signal injecting by the secondary users. Moreover, howbeit existing techniques have mitigated the underutilization of spectrum band, it has brought degradation to primary users due to lack of cooperative optimal sensing. To solve these problems, this work proposed a Reservation Optimized Bias Decomposition system (ROBD) to sense the available spectrum and reserve the spectrum based on user needs and employ slots to share a shared transmission resource, resulting in greater spectrum usage. By reducing the false signal into a series of smallest feasible sub-problems and solving them analytically, optimized bias decomposition techniques are used to discover and eliminate the internally injected false signal. As a result, issues like QoS deterioration, connection unavailability, denial of service, and bandwidth wastage has been removed. If the crumbled signal has high bias and variance when tested with the trained model it would be filtered this leads to less packet drop and high quality of service. The proposed method has obtained a higher throughput of 4.6052 and a low packet drop of 28.47 bits/sec, such a way the proposed method outperforms the other existing techniques.
C1 [Nagalakshmi, P.] Panacorp Software Solut, Nagercoil 629001, Tamil Nadu, India.
RP Nagalakshmi, P (corresponding author), Panacorp Software Solut, Nagercoil 629001, Tamil Nadu, India.
EM nagaleshmip17@gmail.com
CR Akyildiz IF, 2008, IEEE COMMUN MAG, V46, P40, DOI 10.1109/MCOM.2008.4481339
   Ali A, 2017, IEEE COMMUN SURV TUT, V19, P1277, DOI 10.1109/COMST.2016.2631080
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anandakumar H, 2018, INTELL AUTOM SOFT CO, V24, P843, DOI 10.1080/10798587.2017.1364931
   Anandakumar H, 2017, CLUSTER COMPUT, V20, P1505, DOI 10.1007/s10586-017-0798-3
   [Anonymous], 2009, IEEE T WIREL COMMUN
   Awe OP, 2018, IEEE ACCESS, V6, P25377, DOI 10.1109/ACCESS.2018.2825603
   Chen K, 2020, IEEE ACCESS, V8, P185136, DOI 10.1109/ACCESS.2020.3027375
   Dannana Suresh, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P497, DOI 10.1007/978-981-10-7566-7_49
   Eappen G, 2020, PHYS COMMUN-AMST, V40, DOI 10.1016/j.phycom.2020.101091
   Elnahas O, 2018, IEEE ACCESS, V6, P11086, DOI 10.1109/ACCESS.2018.2810107
   Ghasemi A, 2008, IEEE COMMUN MAG, V46, P32, DOI 10.1109/MCOM.2008.4481338
   Kar S, 2017, WIRELESS PERS COMMUN, V97, P2523, DOI 10.1007/s11277-017-4621-5
   Karimi M, 2020, IET COMMUN, V14, P3135, DOI 10.1049/iet-com.2019.1369
   Li ZQ, 2010, IEEE T VEH TECHNOL, V59, P383, DOI 10.1109/TVT.2009.2031181
   Liang YC, 2008, IEEE T WIREL COMMUN, V7, P1326, DOI 10.1109/TWC.2008.060869
   Ma J, 2008, IEEE T WIREL COMMUN, V7, P4502, DOI 10.1109/T-WC.2008.070941
   Mapunya S, 2018, L N INST COMP SCI SO, V223, P60, DOI 10.1007/978-3-319-74439-1_6
   Mummoorthy A, 2012, INT J ENG RES DEV, V4
   Niyato D, 2008, IEEE T WIREL COMMUN, V7, P2651, DOI 10.1109/TWC.2008.070073
   Pandit S, 2017, WIREL NETW, V23, P497, DOI 10.1007/s11276-015-1171-1
   Sultana A, 2017, PEER PEER NETW APPL, V10, P1113, DOI 10.1007/s12083-016-0465-0
   Tavares, 2017, BAYESIAN ESTIMATORS
   Thakur S, 2020, IET COMMUN, V14, P1090, DOI 10.1049/iet-com.2018.5791
   Vimal S, 2019, CLUSTER COMPUT, V22, P10491, DOI 10.1007/s10586-017-1092-0
   Wang L, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P809, DOI 10.1109/PACRIM.2011.6032998
   Wang MW, 2020, IOP CONF SER-MAT SCI, V719, DOI 10.1088/1757-899X/719/1/012045
   Wang Q, 2011, I C NETWORK PROTOCOL
   Wei XL, 2017, IEEE COMMUN SURV TUT, V19, P765, DOI 10.1109/COMST.2016.2631146
   Wu QH, 2013, IEEE T WIREL COMMUN, V12, P516, DOI 10.1109/TWC.2012.122212.111638
   Xing YP, 2006, IEEE ICC, P4420
   Xu XM, 2017, IET COMMUN, V11, P335, DOI 10.1049/iet-com.2016.0702
   Yücek T, 2009, IEEE COMMUN SURV TUT, V11, P116, DOI 10.1109/SURV.2009.090109
   Zeng PECY., 2008, IEEE T WIREL COMMUN, V7, P13261337
   Zhang DY, 2017, IEEE T VEH TECHNOL, V66, P831, DOI 10.1109/TVT.2016.2551721
   Zhang W, 2009, IEEE T WIREL COMMUN, V8, P5761, DOI 10.1109/TWC.2009.12.081710
   Zhao WJ, 2021, IEEE SYST J, V15, P3391, DOI 10.1109/JSYST.2020.3002941
   Zheng SK, 2013, IEEE T WIREL COMMUN, V12, P1774, DOI 10.1109/TWC.2013.030413.120735
NR 41
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7079
EP 7104
DI 10.1007/s11042-022-13631-3
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840595400001
DA 2024-07-18
ER

PT J
AU Hailemariam, WW
   Gupta, P
AF Hailemariam, Workneh Wolde
   Gupta, Pallavi
TI Compressed sensing based fingerprint imaging system using a chaotic
   model-based deterministic sensing matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Fingerprint image; Sparse representation;
   Optimization; Encryption; Chaotic model
ID OVERCOMPLETE DICTIONARIES; ENCRYPTION SCHEME; SENSOR; RECOVERY; FOURIER;
   RECONSTRUCTION; IMPLEMENTATION; ARRAY
AB A secured compressed sensing (CS) systems design approach uses a novel deterministic sensing matrix to sense and transmit fingerprint images. The performance of the CS system was studied in detail by varying CS and security parameters. The sampling and sparse coefficient are the parameters considered from compressed sensing, whereas the encryption key is from the security scheme. The simultaneous compression and encryption has been achieved by multiplying the sparse modeled data with the proposed deterministic partial bounded orthogonal sensing matrix. A chaotic model-based permutation is applied to scramble the DCT matrix rows to build the sensing matrix. Recovering and decryption of the compressed image are accomplished with the help of the L-1 optimization method. The experimental test shows that a sparse vector of 121 widths has been recovered by taking about 25 samples. This indicates that up to 1 : 5 compression ratio is supported without damaging the fingerprint minutiae. If only compression is required without encryption, up to a 1 : 16 ratio can be achieved. The peak signal-to-noise ratio (PSNR) is 27.65 dB for both compression ratios under fulfilments of all necessary security requirements. The 7.20 value of the entropy, histogram analysis, and the correlation analysis show the proposed scheme possesses adequate randomness. Furthermore, the ability of the system resistance against attacks is proved by 100% NPCR (Net Pixel Change Rate) and 0.92% UACI (Unified Average Changing Intensity) values.
C1 [Hailemariam, Workneh Wolde; Gupta, Pallavi] Sharda Univ, Greater Noida, Uttar Pradish, India.
C3 Sharda University
RP Hailemariam, WW (corresponding author), Sharda Univ, Greater Noida, Uttar Pradish, India.
EM worknehwolde11@gmail.com; pallavi.gupta2@sharda.ac.in
RI Wolde, Workneh/GQP-2997-2022
OI Wolde, Workneh/0000-0001-5051-2547
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Aharon M, 2006, LINEAR ALGEBRA APPL, V416, P48, DOI 10.1016/j.laa.2005.06.035
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   ALLEN JB, 1977, P IEEE, V65, P1558, DOI 10.1109/PROC.1977.10770
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2001, SCIENTIFICWORKING GR
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Bakiri M, 2018, COMPUT SCI REV, V27, P135, DOI 10.1016/j.cosrev.2018.01.002
   Candes E.J., 2005, 1 MAGIC RECOVERY SPA
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chao LY, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106082
   Chen GQ, 2010, MICROBIOL MONOGR, V14, P1, DOI 10.1007/978-3-642-03287_5_1
   Djelouat H, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101649
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Fan HJ, 2020, NEURAL COMPUT APPL, V32, P12771, DOI 10.1007/s00521-020-04724-x
   Fan HJ, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.1321
   FISHMAN GS, 1986, SIAM J SCI STAT COMP, V7, P1058, DOI 10.1137/0907072
   Gangopadhyay D, 2014, IEEE J SOLID-ST CIRC, V49, P426, DOI 10.1109/JSSC.2013.2284673
   Hashad FG, 2019, MULTIMED TOOLS APPL, V78, P27351, DOI 10.1007/s11042-019-7580-x
   Hopper T., 1992, DCC '92. Data Compression Conference (Cat. No.92TH0436-6), P309, DOI 10.1109/DCC.1992.227450
   Hopper T, 1993, IAFISIC0110V2 FED BU
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Javidi B, 1999, OPT ENG, V38, P9, DOI 10.1117/1.602074
   Jiang XY, 2017, IEEE T ULTRASON FERR, V64, P1401, DOI 10.1109/TUFFC.2017.2703606
   Jung SM, 2005, IEEE J SOLID-ST CIRC, V40, P1745, DOI 10.1109/JSSC.2005.852019
   Kharratzadeh M, 2017, IEEE T INFORM THEORY, V63, P3333, DOI 10.1109/TIT.2017.2686428
   Komarinski P., 2005, Automated fingerprint identification systems (AFIS)
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Kwon K, 2016, J DISP TECHNOL, V12, P77, DOI 10.1109/JDT.2015.2456641
   Li RP, 2021, MULTIMED TOOLS APPL, V80, P30583, DOI 10.1007/s11042-020-08802-z
   Li XJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P947
   Liu D, 2019, BIOMED SIGNAL PROCES, V49, P221, DOI 10.1016/j.bspc.2018.12.019
   Liu JC, 2012, IEEE SENS J, V12, P1004, DOI 10.1109/JSEN.2011.2167748
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1
   Maltoni D., 2009, HDB FINGERPRINT RECO
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mehta G, 2013, 2013 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION AND COMPUTING (ICCC), P485, DOI 10.1109/ICCC.2013.6731703
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Nomura T, 2000, OPT ENG, V39, P2031, DOI 10.1117/1.1304844
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Polanía LF, 2015, IEEE J BIOMED HEALTH, V19, P508, DOI 10.1109/JBHI.2014.2325017
   Polat Ö, 2018, COMPUT ELECTR ENG, V71, P173, DOI 10.1016/j.compeleceng.2018.07.017
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Ravelomanantsoa A, 2015, IEEE T INSTRUM MEAS, V64, P3405, DOI 10.1109/TIM.2015.2459471
   Rudelson M, 2008, COMMUN PUR APPL MATH, V61, P1025, DOI 10.1002/cpa.20227
   RUELLE D, 1971, COMMUN MATH PHYS, V20, P167, DOI 10.1007/BF01646553
   Sato N, 2005, IEEE T ELECTRON DEV, V52, P1026, DOI 10.1109/TED.2005.846342
   Shah AA, 2020, J REAL-TIME IMAGE PR, V17, P2139, DOI 10.1007/s11554-020-01008-4
   Shao GQ, 2014, IEEE T IMAGE PROCESS, V23, P489, DOI 10.1109/TIP.2013.2287996
   Sharma Annu, 2020, Procedia Computer Science, V171, P1698, DOI 10.1016/j.procs.2020.04.182
   Shen Q, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143081
   Sivapalan S., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P567, DOI 10.1109/DICTA.2011.101
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sun CL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081848
   Tang YL, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6665702
   Tawfic I, 2015, COMPUT METH PROG BIO, V122, P437, DOI 10.1016/j.cmpb.2015.09.010
   Thomos N, 2006, IEEE T IMAGE PROCESS, V15, P54, DOI 10.1109/TIP.2005.860338
   Vidyasagar M, 2016, IEEE DECIS CONTR P, P5091, DOI 10.1109/CDC.2016.7799048
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie YQ, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090819
   Yung-Shih Hsiung, 2011, TRANSDUCERS 2011 - 2011 16th International Solid-State Sensors, Actuators and Microsystems Conference, P24, DOI 10.1109/TRANSDUCERS.2011.5969123
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhao CD, 2014, SCI WORLD J, DOI 10.1155/2014/473178
NR 72
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6885
EP 6915
DI 10.1007/s11042-022-13444-4
EA AUG 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Garg, M
   Ubhi, JS
   Aggarwal, AK
AF Garg, Mallika
   Ubhi, Jagpal Singh
   Aggarwal, Ashwani Kumar
TI Neural style transfer for image steganography and destylization with
   supervised image to image translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural style transfer; GAN; Image reconstruction; Information hiding;
   Steganalysis; StegoExpose; pix2pix
ID ALGORITHM
AB Today, a lot of information is being shared electronically in a way or another. Despite the advancements in technology used for data transfer, the reliable transmission of sensitive data is still a major challenge that need to be addressed. In this paper, we propose a steganographic technique to generate a stego image using the Neural Style Transfer (NST) algorithm that maintain the perceptual quality of the stego image with maximum capacity payload. Along with this, we propose to recover the secret content from generated stego image with minimal distortion. So, to recover the secret image from the generated stego image, destylization is performed using conditional Generative Adversarial Networks (cGANs). The proposed destyling GAN is forced to learn the embedded secret information using a loss function that learns the same representation as in the embedding NST algorithm. This whole framework of embedding and extraction of secret image is evaluated for Imagenet dataset and later tested on the PASCAL VOC12 dataset. The algorithm outperforms in terms of Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Visual Information Fidelity (VIF) with 44.175 dB, 0.9958, and 0.954 respectively for the Imagenet dataset. Also, the proposed algorithm is more robust against StegExpose with 0.529, area under the curve (AUC).
C1 [Garg, Mallika] Indian Inst Technol, Dept Elect & Commun Engn, Roorkee 247667, Uttarakhand, India.
   [Ubhi, Jagpal Singh] St Longowal Inst Engn & Technol, Elect & Commun Engn Dept, Longowal 148106, Punjab, India.
   [Aggarwal, Ashwani Kumar] St Longowal Inst Engn & Technol, Elect & Instrumentat Engn Dept, Longowal 148106, Punjab, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Sant Longowal Institute of Engineering &
   Technology (SLIET); Sant Longowal Institute of Engineering & Technology
   (SLIET)
RP Garg, M (corresponding author), Indian Inst Technol, Dept Elect & Commun Engn, Roorkee 247667, Uttarakhand, India.
EM mallika@ec.iitr.ac.in
RI Aggarwal, Ashwani Kumar/E-9682-2015
OI Aggarwal, Ashwani Kumar/0000-0002-8748-0785
CR [Anonymous], 2013, J COMPUT COMMUN
   [Anonymous], 2018, P EUR C COMP VIS ECC
   Baagyere EY, 2020, IEEE ACCESS, V8, P100438, DOI 10.1109/ACCESS.2020.2997838
   Baluja S, 2019, ADV NEURAL INF PROC, V30
   Baluja S, 2017, ADV NEUR IN, V30
   Bhattacharyya S., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P36, DOI 10.1109/WICT.2011.6141214
   Biradar RL, 2016, SURVEY PAPER STEGANO, V4
   Boehm B, ARXIV
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen BL, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102664
   Chen HY, 2020, IEEE WINT CONF APPL, P2152, DOI [10.1109/WACV45572.2020.9093489, 10.1109/wacv45572.2020.9093489]
   Chu C, 2017, ARXIV
   Duan XT, 2020, IEEE ACCESS, V8, P170174, DOI 10.1109/ACCESS.2020.3024193
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Everingham M, 2012, PATTERN ANAL STAT MO, V2007, P1
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Garg M, 2021, Autonomous driving and advanced driver-assistance systems (ADAS), P233
   Garg M, 2019, EASYCHAIR
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys L. A., 2015, arXiv
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Ghosh S, 2021, PATTERN RECOGN LETT, V144, P13, DOI 10.1016/j.patrec.2021.01.012
   Hayes J, 2017, ADV NEUR IN, V30
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jiang Du, 2022, Personal and Ubiquitous Computing, P1215, DOI 10.1007/s00779-019-01268-3
   Jiang D, 2019, CLUSTER COMPUT, V22, P13261, DOI 10.1007/s10586-018-1844-5
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Ke Y, 2019, MULTIMED TOOLS APPL, V78, P13805, DOI 10.1007/s11042-018-6640-y
   Khatun A., 2020, J COMPUTER COMMUNICA, V8, P127, DOI DOI 10.4236/JCC.2020.84010
   Kumar P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P995, DOI 10.1109/ICASSP39728.2021.9413989
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Li YJ, 2017, ADV NEUR IN, V30
   Li YZ, 2017, ADV NEUR IN, V30
   Lin ZN, 2018, IEEE T INF FOREN SEC, V13, P1854, DOI 10.1109/TIFS.2018.2806741
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Olatunji JR, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105699
   Radford A., 2015, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Sharifzadeh M, 2020, IEEE T INF FOREN SEC, V15, P867, DOI 10.1109/TIFS.2019.2929441
   Sharma K., 2019, ARXIV
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Sun Y, 2019, J REAL-TIME IMAGE PR, V16, P635, DOI 10.1007/s11554-019-00849-y
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Van TP, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P410, DOI [10.1109/ISCIT.2019.8905216, 10.1109/iscit.2019.8905216]
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Wang ZH, 2019, LECT NOTES COMPUT SC, V11954, P3, DOI 10.1007/978-3-030-36711-4_1
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Westfeld A, 2000, 3 INT WORKSHOP, V99
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xintao D, 2019, ARXIV
   Xu CM, 2020, IEEE T IMAGE PROCESS, V29, P9060, DOI 10.1109/TIP.2020.3023853
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Zhang Kevin, 2019, ARXIV
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhong N, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033005
   Zhou Zhi-li, 2016, Journal of Applied Sciences - Electronics and Information Engineering, V34, P527, DOI 10.3969/j.issn.0255-8297.2016.05.005
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 72
TC 26
Z9 26
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6271
EP 6288
DI 10.1007/s11042-022-13596-3
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000837590100006
DA 2024-07-18
ER

PT J
AU Wang, X
   Du, YT
   Verberne, S
   Verbeek, FJ
AF Wang, Xue
   Du, Youtian
   Verberne, Suzan
   Verbeek, Fons J.
TI Fine-grained label learning in object detection with weak supervision of
   captions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained label learning; Object detection; Weakly-supervised
   learning; Semantic mapping; Curriculum learning
AB This paper addresses the task of fine-grained label learning in object detection with the weak supervision of auxiliary information attached to images. Most of the recent work focused on the label prediction for objects in the same category space as in training data under the fully-supervised learning framework and cannot be expanded to the learning of more fine-grained categories that have not been defined in training sets. In this paper, we propose a new weakly-supervised learning approach, called label inference curriculum network (LICN), to detecting objects and learning their fine-grained category labels based on supervision of captions via curriculum learning. First, we build a semantic mapping based on embedding techniques and a knowledge base to measure the correspondence between coarse labels and fine-grained label proposals; second, we introduce a label inference curriculum network, which ranks the order of training samples by the complexity of samples. We construct two datasets, namely FG-COCO and FGs-COCO, consisting of both coarse and fine-grained labels based on MS COCO and Visual Genome to train and test our approach. Experimental results demonstrate the effectiveness of our proposed LICN model, and LICN-E2C achieves an improvement of 1.7% mAP with 0.5:0.05:0.95 IoU compared with the LICN-C2E on the FG-sCOCO test dataset.
C1 [Wang, Xue; Du, Youtian] Xi An Jiao Tong Univ, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
   [Wang, Xue; Verberne, Suzan; Verbeek, Fons J.] Leiden Univ, Leiden Inst Adv Comp Sci, Niels Bohrweg 1, NL-2333 CA Leiden, Netherlands.
C3 Xi'an Jiaotong University; Leiden University; Leiden University - Excl
   LUMC
RP Du, YT (corresponding author), Xi An Jiao Tong Univ, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM nimowangxue1989@stu.xjtu.edu.cn; duyt@mail.xjtu.edu.cn;
   s.verberne@liacs.leidenuniv.nl; f.j.verbeek@liacs.leidenuniv.nl
RI Verberne, Suzan/K-3993-2019
OI Verberne, Suzan/0000-0002-9609-9505; Du, Youtian/0000-0002-1714-3433
FU China Scholarship Council [201906280464]; National Key RD Program
   [2018AAA0101501]; National Natural Science Foundation [61375040,
   61772415]
FX China Scholarship Council (No. 201906280464), the National Key R&D
   Program (No. 2018AAA0101501) and the National Natural Science Foundation
   (61375040, 61772415), of China.
CR Ahmed A, 2021, J ELECTR ENG TECHNOL, V16, P1143, DOI 10.1007/s42835-020-00650-z
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bhujade Stuti, 2022, Emerging Technologies in Computer Engineering: Cognitive Computing and Intelligent IoT: 5th International Conference, ICETCE 2022, Revised Selected Papers. Communications in Computer and Information Science (1591), P336, DOI 10.1007/978-3-031-07012-9_29
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Buonviri A., 2019, AEROSP CONF PROC, DOI DOI 10.1109/aero.2019.8742216
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545
   Du W, 2019, J SIGNAL PROCESS SYS, V91, P521, DOI 10.1007/s11265-018-1355-x
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139
   Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9
   Hacohen G, 2019, ARXIV
   Jerbi A, 2020, ARXIV
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li CL, 2017, LECT NOTES COMPUT SC, V10637, P326, DOI 10.1007/978-3-319-70093-9_34
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Misra I, 2016, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2016.320
   Oquab M., 2015, PROC CVPR IEEE, P685
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Thomas C, 2019, ADV NEUR IN, V32
   Tian Jiu-le, 2010, Journal of Jilin University (Information Science Edition), V28, P602
   Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141
   Wang J, 2018, INT C PATT RECOG, P2416, DOI 10.1109/ICPR.2018.8546088
   Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27
   Ye KR, 2019, IEEE I CONF COMP VIS, P9685, DOI 10.1109/ICCV.2019.00978
   Zakraoui J, 2021, MULTIMED TOOLS APPL, V80, P27423, DOI 10.1007/s11042-021-11038-0
   Zhang M, 2018, ARXIV
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 40
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6557
EP 6579
DI 10.1007/s11042-022-13592-7
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000836761900001
OA Green Published
DA 2024-07-18
ER

PT J
AU Lethikim, N
   Nguyentrang, T
   Vovan, T
AF Lethikim, Ngoc
   Nguyentrang, Thao
   Vovan, Tai
TI A new image classification method using interval texture feature and
   improved Bayesian classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Extraction; Image; Interval data; Overlap distance
ID COOCCURRENCE; COLOR
AB In this paper, a novel technique for image classification is proposed with the three main contributions. First, we give the texture extraction technique for each image to have the two-dimensional interval based on the Grey Level Co-occurrence matrices. Second, the automatic fuzzy clustering algorithm for interval data to determine the prior probability for the classification problem by Bayesian method is created. Finally, the new principle to classify for image is established. Combining the above three improvements, we have the effective method to classify the images. In addition, the proposed method can be performed rapidly for the real data by the established Matlab procedure. Four image data sets with the different characters are used to illustrate the proposed method, and to compare to the well-known algorithms like Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Fisher method, Naive Bayes, Multi-Supported Vector Machine (Multi-SVM), Convolutional Neural Networks (CNN), and VGG-19. The results show that the proposed method has the good and stable empirical error, and give the outstanding result about time cost.
C1 [Lethikim, Ngoc] Van Lang Univ, Fac Engn, Ho Chi Minh City, Vietnam.
   [Nguyentrang, Thao] Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.
   [Nguyentrang, Thao] Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
   [Vovan, Tai] Can Tho Univ, Coll Nat Sci, Can Tho City, Vietnam.
C3 Van Lang University; Ton Duc Thang University; Ton Duc Thang University;
   Can Tho University
RP Vovan, T (corresponding author), Can Tho Univ, Coll Nat Sci, Can Tho City, Vietnam.
EM ngoc.ltk@vlu.edu.vn; nguyentrangthao@tdtu.edu.vn; vvtai@ctu.edu.vn
RI Thao, Nguyen-Trang/HNI-7249-2023
OI Thao, Nguyen-Trang/0000-0003-2635-5371; Tai, Vovan/0000-0002-1343-4647
FU Ministry of Education and Training in Vietnam [B2022-TCT-03]
FX This research is funded by Ministry of Education and Training in Vietnam
   under grant number B2022-TCT-03.
CR Ali L, 2021, NEURAL COMPUT APPL, V33, P2783, DOI 10.1007/s00521-020-05157-2
   ALSULTAN KS, 1993, PATTERN RECOGN, V26, P1357, DOI 10.1016/0031-3203(93)90141-I
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 1996, DESCRIPTION LIBOR SP
   [Anonymous], 2008, INT J COMPUT SCI SEC
   [Anonymous], COMPUT VIS PATTERN R
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Pham BT, 2019, GEOCARTO INT, V34, P316, DOI 10.1080/10106049.2017.1404141
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Che-Ngoc H, 2022, ANN OPER RES, V312, P99, DOI 10.1007/s10479-020-03823-1
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x
   Fisher RA, 1970, STAT METHODS RES WOR, P66, DOI DOI 10.1007/978-1-4612-4380-9_6
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Isa NEMd., 2019, Bulletin of Electrical Engineering and Informatics, V8, P269, DOI 10.11591/eei.v8i1.1402
   Jardine MA, 2018, COMPUT GEOSCI-UK, V111, P105, DOI 10.1016/j.cageo.2017.11.005
   Khaldi B, 2019, IET IMAGE PROCESS, V13, P1401, DOI 10.1049/iet-ipr.2018.6440
   Khan MN, 2019, TRANSPORT RES REC, V2673, P221, DOI 10.1177/0361198119842105
   Lethikim N, 2023, COMMUN STAT-SIMUL C, V52, P2194, DOI 10.1080/03610918.2021.1900248
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Mohebian R, 2018, J GEOPHYS ENG, V15, P1953, DOI 10.1088/1742-2140/aac099
   Murphy K. P., 2006, NAIVE BAYES CLASSIFI
   Hoang ND, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102843
   Ren Y., 2009, In the eighth Australasian data mining conference, V101, P35
   Scott DW, 2015, WILEY SER PROBAB ST, P1, DOI 10.1002/9781118575574
   Sevik U, 2019, IET IMAGE PROCESS, V13, P2018, DOI 10.1049/iet-ipr.2018.5899
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Van TV, 2018, SANKHYA SER B, V80, P19, DOI 10.1007/s13571-018-0159-0
   Tai VV, 2018, STAT THEORY RELAT FI, V2, P150, DOI [10.1080/24754269.2018.1528420, DOI 10.1080/24754269.2018.1528420]
   Nhu VH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155047
   Vo-Van T, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P733, DOI 10.1109/FSKD.2017.8393365
   Vovan T, 2021, ANN OPER RES, V303, P359, DOI 10.1007/s10479-020-03606-8
   Wang PW, 2014, J MACH LEARN RES, V15, P1523
   Wang Y, 2019, CURR BIOINFORM, V14, P282, DOI 10.2174/1574893614666190304125221
   Yulita I, 2020, J PHYS C SERIES, V1577
   Zhang X, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071474
NR 40
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36473
EP 36488
DI 10.1007/s11042-022-13531-6
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000836525000009
DA 2024-07-18
ER

PT J
AU Longjam, T
   Kisku, DR
   Gupta, P
AF Longjam, Teressa
   Kisku, Dakshina Ranjan
   Gupta, Phalguni
TI Multi-scripted Writer Independent Off-line Signature Verification using
   Convolutional Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-scripted; Writer independent; Offline signature verification; CNN
ID RECOGNITION; SELECTION
AB Signature is a biometrics trait widely used for personal verification in financial and most other organizations where financial and relevant types of transactions are done manually with signed authorized papers. A signature verification system aims to verify the minor structural differences between genuine and forged signatures, as most skilled forgery signatures look similar to their respective genuine signatures with specific deformations. Signature verification in a multi-cultural country like India is challenging in both writer-independent and script-independent scenarios where the Indian population uses multiple scripts to write their signatures. This paper reports a writer-independent offline signature verification system that uses Convolutional Neural Network (CNN) architecture for feature extraction and classification. The objective of the proposed work is to model a CNN-based adaptable system to verify multi-scripted offline signatures. The model has been trained and tested on two publicly available databases, viz. CEDAR and BH-Sig260, which consist of Hindi, Bengali, and English signatures. Individual signature classes of unique scripts and a combination of these scripts have been considered for testing the proposed model that determines verification accuracies of 90%, 95%, 98.33%, and 93.33%, respectively. Experimental results are compelling, and the proposed model outperforms the verification accuracies of some well-known models.
C1 [Longjam, Teressa] Natl Inst Technol Manipur, Langol, Manipur, India.
   [Kisku, Dakshina Ranjan] Natl Inst Technol Durgapur, Durgapur, W Bengal, India.
   [Gupta, Phalguni] GLA Univ, Mathura, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur; National Institute of Technology (NIT System);
   National Institute of Technology Durgapur; GLA University
RP Longjam, T (corresponding author), Natl Inst Technol Manipur, Langol, Manipur, India.
EM teressalongjam@gmail.com; drkisku@cse.nitdgp.ac.in; pg@gla.ac.in
RI Kisku, Dakshina Ranjan/E-1680-2013
OI Kisku, Dakshina Ranjan/0000-0003-1116-2972
CR Banerjee D, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115756
   Batista L, 2012, PATTERN RECOGN, V45, P1326, DOI 10.1016/j.patcog.2011.10.011
   Bertolini D, 2010, PATTERN RECOGN, V43, P387, DOI 10.1016/j.patcog.2009.05.009
   Chanu MM, 2021, J AMB INTEL HUM COMP, V12, P6911, DOI 10.1007/s12652-020-02336-w
   Dargan S, 2020, SOFT COMPUT, V24, P10111, DOI 10.1007/s00500-019-04525-y
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Guerbai Y, 2015, PATTERN RECOGN, V48, P103, DOI 10.1016/j.patcog.2014.07.016
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Ismail MA, 2000, PATTERN RECOGN, V33, P1727, DOI 10.1016/S0031-3203(99)00047-3
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Jahandad SMS, 2019, OFFLINE SIGNATURE VE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2020, ARCH COMPUT METHOD E, V27, P577, DOI 10.1007/s11831-019-09332-0
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN INTELLIGENT AND COMPUTING IN ENGINEERING (RICE III)
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar M, 2017, P NATL A SCI INDIA A, V87, P137, DOI 10.1007/s40010-016-0284-y
   Kumar M, 2016, P NATL A SCI INDIA A, V86, P405, DOI 10.1007/s40010-016-0277-x
   Liu L, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108009
   Longjam T, 2017, 2017 7TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED)
   Mizukami Y, 2002, PATTERN RECOGN LETT, V23, P1569, DOI 10.1016/S0167-8655(02)00121-6
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2019, SOFT COMPUT, V23, P13603, DOI 10.1007/s00500-019-03897-5
   Pachon-Suescun C, 2019, INT J ELECT COMPUTER, V9, P3314
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P72, DOI 10.1109/DAS.2016.48
   Rivard D, 2013, INT J DOC ANAL RECOG, V16, P83, DOI 10.1007/s10032-011-0180-6
   Roy S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03592-0
   Shen Y., 2002, 24 INT C INF TECHN I
   Sounak D, 2017, PATTERN RECOGN LETT
   Souza VLF, 2018, 2018 7TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P212, DOI 10.1109/BRACIS.2018.00044
   Wan Q, 2021, INT C PATT RECOG, P3853, DOI 10.1109/ICPR48806.2021.9413091
   Yilmaz MB, 2016, INFORM FUSION, V32, P109, DOI 10.1016/j.inffus.2016.02.003
   Zhang XQ, 2017, COMPUT ASSIST SURG, V22, P267, DOI 10.1080/24699322.2017.1389405
   Zheng YC, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108008
NR 36
TC 5
Z9 5
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5839
EP 5856
DI 10.1007/s11042-022-13392-z
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500010
DA 2024-07-18
ER

PT J
AU Radanliev, P
   De Roure, D
AF Radanliev, Petar
   De Roure, David
TI New and emerging forms of data and technologies: literature and
   bibliometric review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE New and emerging forms of data; Literature review; Bibliometric review;
   Spatiotemporal data; Time-stamped data; Open data; Real-time data;
   High-dimensional data; 68 M11 (Internet topics)
ID BIG DATA; PREDICTION; INTERNET; VEHICLE; MACHINE; THINGS
AB With the increased digitalisation of our society, new and emerging forms of data present new values and opportunities for improved data driven multimedia services, or even new solutions for managing future global pandemics (i.e., Disease X). This article conducts a literature review and bibliometric analysis of existing research records on new and emerging forms of multimedia data. The literature review engages with qualitative search of the most prominent journal and conference publications on this topic. The bibliometric analysis engages with statistical software (i.e. R) analysis of Web of Science data records. The results are somewhat unexpected. Despite the special relationship between the US and the UK, there is not much evidence of collaboration in research on this topic. Similarly, despite the negative media publicity on the current relationship between the US and China (and the US sanctions on China), the research on this topic seems to be growing strong. However, it would be interesting to repeat this exercise after a few years and compare the results. It is possible that the effect of the current US sanctions on China has not taken its full effect yet.
C1 [Radanliev, Petar; De Roure, David] Univ Oxford, Oxford E Res Ctr, Dept Engn Sci, Oxford, England.
C3 University of Oxford
RP Radanliev, P (corresponding author), Univ Oxford, Oxford E Res Ctr, Dept Engn Sci, Oxford, England.
EM petar.radanliev@oerc.ox.ac.uk
RI Radanliev, Petar/L-7509-2015; De Roure, David/D-6785-2011
OI Radanliev, Petar/0000-0001-5629-6857; De Roure,
   David/0000-0001-9074-3016
FU ESRC; EPSRC [EP/S021779/1] Funding Source: UKRI
FX This work was funded by the ESRC [grant number:].
CR Akter L., 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-021-00551-6
   Al-Rakhami MS, 2021, medRxiv
   Allam Z, 2019, CITIES, V89, P80, DOI 10.1016/j.cities.2019.01.032
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bajoudah S, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P339, DOI 10.1109/Blockchain.2019.00053
   Benkhelifa F, 2020, IEEE T WIREL COMMUN, V19, P2699, DOI 10.1109/TWC.2020.2967697
   Berente N, 2019, INFORM SYST RES, V30, P50, DOI 10.1287/isre.2018.0774
   Binpeng Song, 2020, Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery. Advances in Intelligent Systems and Computing (AISC 1075), P604, DOI 10.1007/978-3-030-32591-6_65
   Brandao Antonio, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 930), P515, DOI 10.1007/978-3-030-16181-1_49
   Chan CA, 2019, IEEE INT CONF COMM, DOI 10.1109/ICCW.2019.8756663
   Chanson M, 2019, J ASSOC INF SYST, V20, P1274, DOI 10.17705/1jais.00567
   Chen TJ, 2020, INT J AD HOC UBIQ CO, V33, P109, DOI 10.1504/IJAHUC.2020.105463
   Conrad FG, 2021, SOC SCI COMPUT REV, V39, P489, DOI 10.1177/0894439319875692
   Couldry N, 2019, TELEV NEW MEDIA, V20, P336, DOI 10.1177/1527476418796632
   Couper MP, 2017, ANNU REV SOCIOL, V43, P121, DOI 10.1146/annurev-soc-060116-053613
   Dai HN, 2020, ENTERP INF SYST-UK, V14, P1279, DOI 10.1080/17517575.2019.1633689
   Daniel B, 2019, BRIT J EDUC TECHNOL, V50, P101, DOI 10.1111/bjet.12595
   Das S, 2019, 1 INT C ADV SCI ENG
   Din S, 2019, FUTURE GENER COMP SY, V91, P611, DOI 10.1016/j.future.2017.12.059
   Nguyen DD, 2019, 2019 GLOBAL IOT SUMMIT (GIOTS), DOI 10.1109/giots.2019.8766346
   Eck A, 2021, SOC SCI COMPUT REV, V39, P484, DOI 10.1177/0894439319883393
   Eltoweissy M, 2019, 2019 INTERNATIONAL CONFERENCE ON INNOVATION AND INTELLIGENCE FOR INFORMATICS, COMPUTING, AND TECHNOLOGIES (3ICT)
   Farahani B., 2020, Healthcare iot, intelligent internet of things: from device to fog and cloud, P515, DOI DOI 10.1007/978-3-030-30367-9_11
   Ferdib-Al-Islam, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P445, DOI 10.1109/ICREST51555.2021.9331108
   Ghosh S, 2020, IEEE T NETW SCI ENG, V7, P2271, DOI 10.1109/TNSE.2019.2941754
   Giannopoulou A., 2019, ERASMUS LAW REV, V12, P1
   Hall W, 2019, PETRAS IOT DATA MANA
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Hasson SG, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P829, DOI 10.1145/3341161.3345642
   Heikinheimo V, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6030085
   Helbing D., 2019, Towards Digital Enlightenment. Essays on the Dark and Light Sides of the Digital Revolution, V73, P98, DOI [DOI 10.1007/978-3-319-90869-4, 10.1007/978-3-319-90869-4_7, DOI 10.1007/978-3-319-90869-4_7]
   Huang K, 2020, IEEE INTERNET THINGS, V7, P882, DOI 10.1109/JIOT.2019.2945921
   Ishmaev Georgy, 2020, Philosophy and Technology, V33, P411, DOI DOI 10.1007/S13347-019-00361-Y
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jan B, 2019, COMPUT ELECTR ENG, V75, P275, DOI 10.1016/j.compeleceng.2017.12.009
   Javaid A, 2020, LECT NOTE NETW SYST, V97, P173, DOI 10.1007/978-3-030-33506-9_16
   Johnson TP, 2017, SPRING GEOGR, P113, DOI 10.1007/978-3-319-40902-3_7
   Kale AP, 2019, COMPUT ELECTRON AGR, V161, P225, DOI 10.1016/j.compag.2018.04.027
   Kalo M, 2020, SPATIOTEMPORAL ANALYSIS OF AIR POLLUTION AND ITS APPLICATION IN PUBLIC HEALTH, P169, DOI 10.1016/B978-0-12-815822-7.00008-X
   Kowal DR, 2020, J COMPUT GRAPH STAT, V29, P629, DOI 10.1080/10618600.2019.1710837
   Krentz T, 2019, INT SYMP OBJECT COMP, P151, DOI 10.1109/ISORC.2019.00037
   Kurt MN, 2021, IEEE T PATTERN ANAL, V43, P2463, DOI 10.1109/TPAMI.2020.2970410
   Lawrenz S, 2019, 2019 INTERNATIONAL CONFERENCE ON BLOCKCHAIN TECHNOLOGY (ICBCT 2019), P55, DOI 10.1145/3320154.3320165
   Liu CH, 2020, COMPUTING, V102, P573, DOI 10.1007/s00607-019-00746-z
   Liu CT, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11174557
   Mao WC, 2019, IEEE INFOCOM SER, P1837, DOI [10.1109/INFOCOM.2019.8737571, 10.1109/infocom.2019.8737571]
   Miller PV, 2017, PUBLIC OPIN QUART, V81, P205, DOI 10.1093/poq/nfx008
   Moor L, 2019, IEEE IPCCC, DOI 10.1109/ipccc47392.2019.8958742
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Mwaba J, 2020, PLOS NEGLECT TROP D, V14, DOI 10.1371/journal.pntd.0008227
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Park JH, 2019, VISUAL COMPUT, V35, P191, DOI 10.1007/s00371-017-1461-y
   Perboli G, 2019, IEEE ENABL TECHNOL, P27, DOI 10.1109/WETICE.2019.00014
   Probst D, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-0416-x
   Qiu J, 2020, IEEE INTERNET THINGS, V7, P4682, DOI 10.1109/JIOT.2020.2969326
   Raghavan S, 2020, LECT NOTES ELECTR EN, V603, P393, DOI 10.1007/978-981-15-0058-9_38
   RAHMAN MH, 2020, ICC 2020 2020 IEEE I, P1, DOI DOI 10.1109/GCAIOT51063.2020.9345874
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rehman MHU, 2019, FUTURE GENER COMP SY, V99, P247, DOI 10.1016/j.future.2019.04.020
   Rinaldi S, 2019, I S PRECIS CLOCK SYN
   Sachdev D., 2019, Journal of Management (JOM), V6, P66, DOI [DOI 10.34218/JOM.6.1.2019.008, 10.34218/jom.6.1.2019.008]
   Safial IA., 2019, INF ENG ELECT BUS, V2, P21
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sajan KK, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL WORKSHOP ON CHALLENGES IN ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR INTERNET OF THINGS (AICHALLENGEIOT '19), P19, DOI 10.1145/3363347.3363364
   Sorlie Jan-Terje, 2019, Economics of Grids, Clouds, Systems, and Services. 16th International Conference, GECON 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11819), P127, DOI 10.1007/978-3-030-36027-6_11
   Tang L, 2020, NAT METHODS, V17, P129, DOI 10.1038/s41592-020-0750-y
   Teng HJ, 2019, FUTURE GENER COMP SY, V94, P351, DOI 10.1016/j.future.2018.11.039
   Wang SH, 2019, FUTURE GENER COMP SY, V94, P160, DOI 10.1016/j.future.2018.10.034
   Wang T, 2020, IEEE T IND INFORM, V16, P3531, DOI 10.1109/TII.2019.2920277
   Xia JH, 2020, EARTH SCI INFORM, V13, P185, DOI 10.1007/s12145-019-00404-0
   Xie P, 2020, INFORM FUSION, V59, P1, DOI 10.1016/j.inffus.2020.01.002
   Xu XL, 2019, FUTURE GENER COMP SY, V95, P522, DOI 10.1016/j.future.2018.12.055
   Yan L, 2019, 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA & SMART CITY (ICITBS), P289, DOI 10.1109/ICITBS.2019.00076
   Yearwood M, 2018, BIG DATA NEW ALTERNA
   Zheng ZG, 2020, IEEE INTERNET THINGS, V7, P2640, DOI 10.1109/JIOT.2019.2955503
   Zhou LJ, 2020, IEEE ACCESS, V8, P52452, DOI 10.1109/ACCESS.2020.2979597
NR 85
TC 37
Z9 37
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2887
EP 2911
DI 10.1007/s11042-022-13451-5
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000832843900004
PM 35968410
OA Green Submitted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Wang, JR
   Zhang, H
   Hou, PF
   Jia, XC
AF Wang, Jianrong
   Zhang, Hao
   Hou, Pengfei
   Jia, Xinchun
TI A novel prediction model of desulfurization efficiency based on improved
   FCM-PLS-LSSVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster analysis; Fuzzy C-Means clustering; PLS-LSSVM; Wet
   desulfurization; Soft measurement technology
ID SUPPORT VECTOR MACHINE; MASS-TRANSFER MODEL; LEAST-SQUARES;
   NEURAL-NETWORK; NOX EMISSIONS; SO2; SIMULATION; PARAMETERS; REGRESSION
AB During the desulfurization process of coal-fired power plants, there are many related parameters that affect the desulfurization efficiency. So it is very difficult to measure the desulfurization efficiency directly. In this paper, in order to reflect the relationship between monitoring process parameters and desulfurization efficiency better, a novel prediction model of desulfurization efficiency based on improved FCM-PLS-LSSVM is established. Firstly, cluster analysis is used by improved an fuzzy C-Means (FCM) clustering algorithm to implement the preliminary classification. Secondly, in order to extract the principal components as optimal inputs of the model, the partial least squares (PLS) regression method is adopted to analyze the process factors which affect the efficiency of wet desulfurization of the flue. Then, using the least square support vector machine (LSSVM) to carry out regression prediction according to above optimization methods. Finally, numerical simulation results show that the mean absolute error (MAE) of the prediction result of the improved FCM-PLS-LSSVM model based on cluster analysis is less than 0.026.
C1 [Wang, Jianrong] Shanxi Univ, Sch Math Sci, Taiyuan 030006, Peoples R China.
   [Wang, Jianrong] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
   [Zhang, Hao] China Mobile Commun Grp Shandong Co Ltd, Qingdao Branch, Govt & Enterprise Customer Dept, Qingdao 266071, Peoples R China.
   [Hou, Pengfei; Jia, Xinchun] Shanxi Univ, Sch Automat & Software, Taiyuan 030013, Peoples R China.
C3 Shanxi University; Tianjin University; China Mobile; Shanxi University
RP Wang, JR (corresponding author), Shanxi Univ, Sch Math Sci, Taiyuan 030006, Peoples R China.; Wang, JR (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
EM wangjr@sxu.edu.cn
FU National Natural Science Foundation of China [61973201]; China
   Postdoctoral Science Foundation [2021M692400]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61973201), China Postdoctoral Science Foundation (Grant No.
   2021M692400).
CR Arabloo M, 2015, J TAIWAN INST CHEM E, V50, P123, DOI 10.1016/j.jtice.2014.12.005
   Azid IA, 2000, TENCON IEEE REGION, pB512
   Bao JR, 2019, IEEE ACCESS, V7, P97117, DOI 10.1109/ACCESS.2019.2929316
   Bian C, 2020, ENERGY, V191, DOI 10.1016/j.energy.2019.116538
   Binsawad MH, 2020, IEEE ACCESS, V8, P29125, DOI 10.1109/ACCESS.2020.2972225
   Brogren C, 1997, CHEM ENG SCI, V52, P3085, DOI 10.1016/S0009-2509(97)00126-7
   Brogren C., 1997, MODELS WET SCRUBBING
   Chen B, 2022, COLD REG SCI TECHNOL, V193, DOI 10.1016/j.coldregions.2021.103415
   Cheng HX, 2017, CHIN AUTOM CONGR, P5917, DOI 10.1109/CAC.2017.8243841
   Cheng L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051215
   Cherkassky Vladimir, 2007, Learning from data: Concepts, theory, and methods
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui SW., 2017, THERMAL POWER GENERA, V46, P81
   Eden D, 1998, CHEM-ING-TECH, V70, P160, DOI 10.1002/cite.330700124
   Eden D, 1998, CHEM ENG TECHNOL, V21, P56, DOI 10.1002/(SICI)1521-4125(199801)21:1<56::AID-CEAT56>3.0.CO;2-9
   GB, 2011, 132232011 GB MIN ENV
   GERBEC M, 1995, COMPUT CHEM ENG, V19, pS283, DOI 10.1016/0098-1354(95)00086-H
   Gu YP, 2011, J PROCESS CONTR, V21, P1040, DOI 10.1016/j.jprocont.2011.06.001
   Guo YS, 2019, J AIR WASTE MANAGE, V69, P565, DOI 10.1080/10962247.2018.1551252
   Handl J, 2007, IEEE T EVOLUT COMPUT, V11, P56, DOI 10.1109/TEVC.2006.877146
   Hong F, 2022, ENERGY, V238, DOI 10.1016/j.energy.2021.121659
   Hong WP., 2013, J POWER ENG, V4, P295
   Huang JQ, 2019, IEEE ACCESS, V7, P82681, DOI 10.1109/ACCESS.2019.2922777
   Jiang F, 2016, INFORM SCIENCES, V332, P167, DOI 10.1016/j.ins.2015.11.005
   Jin J, 2019, IEEE T GEOSCI REMOTE, V57, P3064, DOI 10.1109/TGRS.2018.2880193
   Kalantariasl A, 2021, UPSTREAM OIL GAS TEC, V7, DOI 10.1016/j.upstre.2021.100057
   Kamari A, 2016, J PETROL SCI ENG, V137, P87, DOI 10.1016/j.petrol.2015.10.034
   Kurnaz G, 2022, URBAN CLIM, V41, DOI 10.1016/j.uclim.2021.101051
   Lee, 1994, AUTOMATED KNOWLEDGE
   Li GQ, 2013, CHEMOMETR INTELL LAB, V126, P11, DOI 10.1016/j.chemolab.2013.04.012
   Liu SY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071520
   Lv Y, 2013, ENERGY, V55, P319, DOI 10.1016/j.energy.2013.02.062
   Maji P, 2021, IEEE T CYBERNETICS, V51, P3641, DOI 10.1109/TCYB.2019.2925130
   Marengo E, 2006, ENVIRON SCI TECHNOL, V40, P272, DOI 10.1021/es0517466
   Pai TY, 2015, APPL MATH MODEL, V39, P1513, DOI 10.1016/j.apm.2014.09.017
   Radojevic D, 2019, ATMOS POLLUT RES, V10, P621, DOI 10.1016/j.apr.2018.11.004
   Ren JY., 2013, AUTOMATION APPL, V12, P20
   Shams SR, 2021, URBAN CLIM, V37, DOI 10.1016/j.uclim.2021.100837
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tan P, 2016, J CHEM ENG JPN, V49, P211, DOI 10.1252/jcej.15we066
   Valera VY, 2021, CHEM ENG RES DES, V170, P1, DOI 10.1016/j.cherd.2021.03.008
   Wang F, 2018, CONTROL ENG PRACT, V80, P26, DOI 10.1016/j.conengprac.2018.08.003
   Warych J, 2002, CHEM ENG TECHNOL, V25, P427, DOI 10.1002/1521-4125(200204)25:4<427::AID-CEAT427>3.3.CO;2-O
   Warych J, 2001, IND ENG CHEM RES, V40, P2597, DOI 10.1021/ie0005708
   WINDHAM MP, 1982, IEEE T PATTERN ANAL, V4, P357, DOI 10.1109/TPAMI.1982.4767266
   Wold S., 1983, Pattern Regression: Finding and Using Regularities in Multivariate Data
   Xie PR, 2020, ENERGY, V190, DOI 10.1016/j.energy.2019.116482
   Xu DG, 2016, CHEMOMETR INTELL LAB, V154, P112, DOI 10.1016/j.chemolab.2016.03.029
   Yu HY, 2021, J CLEAN PROD, V324, DOI 10.1016/j.jclepro.2021.129170
   Yu S, 2019, IEEE ACCESS, V7, P118931, DOI 10.1109/ACCESS.2019.2933437
   Yuan ZW, 2021, FUEL, V289, DOI 10.1016/j.fuel.2020.119748
   Zhao X, 2021, INT J CONTROL AUTOM, V19, P3731, DOI 10.1007/s12555-020-0529-z
   Zhou H, 2012, ENG APPL ARTIF INTEL, V25, P147, DOI 10.1016/j.engappai.2011.08.005
NR 53
TC 1
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5685
EP 5708
DI 10.1007/s11042-022-13401-1
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000832844000012
DA 2024-07-18
ER

PT J
AU Pastel, S
   Marlok, J
   Bandow, N
   Witte, K
AF Pastel, Stefan
   Marlok, Josua
   Bandow, Nicole
   Witte, Kerstin
TI Application of eye-tracking systems integrated into immersive virtual
   reality and possible transfer to the sports sector-A systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Virtual reality; Eye-tracking; Visual perception; Gaze behavior;
   Head-mounted display
ID PERCEPTUAL SKILL; GAZE BEHAVIOR; ANTICIPATION; EXPERT; INFORMATION;
   PERFORMANCE; TECHNOLOGY; FIGHTERS; EXERCISE; SOCCER
AB In recent years, Virtual Reality (VR) has become a valuable tool in rehabilitation and sports training applications. New technologies offer opportunities to combine various systems and use them for sports-related scientific purposes. For instance, examining the visual perception of athletes within a standardized environment could be helpful to understand the differences between novices and experts in their visual behavior and could further reveal possible training applications for enhancing athletes' visual attention. The current systematic literature review thematizes the importance of eye-tracking (ET) systems' usage integrated into head-mounted displays (HMDs) in virtual environments for further inclusion in sports-related usage. An overview of possible implementations is given, and additional recommendations for using the combined technic regarding sports are made. Although only one study examined gaze behavior during sports activity within a standardized virtual environment, 38 relevant papers were identified using the ET systems integrated into the HMDs, which ideas can be transferred to the sports sector. The increased usability and fidelity in the virtual environment enabled through the combined technology were illustrated, and different approaches were listed in using and calculating gaze parameters. This literature review examines the possibility of integrating ET in VR, which can be further used to improve usability, interaction methods, image presentation, and visual perception analyses within future physical training scenarios. The compiled studies have shown that the existing methods are feasible due to the performance of the integrated ET systems but still need to be improved for practical use.
C1 [Pastel, Stefan; Marlok, Josua; Bandow, Nicole; Witte, Kerstin] Otto Von Guericke Univ, Dept Sports Engn & Movement Sci, Inst Sports Sci 3, Magdeburg, Germany.
C3 Otto von Guericke University
RP Pastel, S (corresponding author), Otto Von Guericke Univ, Dept Sports Engn & Movement Sci, Inst Sports Sci 3, Magdeburg, Germany.
EM stefan.pastel@ovgu.de
OI Pastel, Stefan/0000-0002-3662-2683; Witte, Kerstin/0000-0001-8711-9335
FU German Research Foundation (DFG) [WI 1456/22 - 1]
FX Open Access funding enabled and organized by Projekt DEAL. The study was
   financed by the German Research Foundation (DFG) under grant WI 1456/22
   - 1.
CR Alder D, 2016, J SPORT EXERCISE PSY, V38, P93, DOI 10.1123/jsep.2015-0145
   Alder D, 2014, HUM MOVEMENT SCI, V37, P167, DOI 10.1016/j.humov.2014.07.002
   Alghamdi N, 2019, INT J ADV COMPUT SC, V10, P60
   Appelbaum LG, 2018, INT REV SPORT EXER P, V11, P160, DOI 10.1080/1750984X.2016.1266376
   Bandow N, 2016, THESIS FAKULTAT HUMA
   Bandow N, 2020, J MARTIAL ARTS RES B, V3, DOI [10.15495/ojs_25678221_33_159, DOI 10.15495/OJS_25678221_33_159]
   Bier B, 2018, NEUROPSYCHOLOGY, V32, P597, DOI 10.1037/neu0000417
   Bischof WF, 2020, J VISION, V20, DOI 10.1167/jov.20.7.23
   Bishop DT, 2017, EUR J SPORT SCI, V17, P160, DOI 10.1080/17461391.2016.1216169
   Bozkir E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P597, DOI 10.1109/VR50410.2021.00085
   Broadbent DP, 2015, EUR J SPORT SCI, V15, P322, DOI 10.1080/17461391.2014.957727
   Broscheid KC, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10090643
   Causer J, 2010, MED SCI SPORT EXER, V42, P1599, DOI 10.1249/MSS.0b013e3181d1b059
   Chow-Wing-Bom H, 2020, VISION RES, V169, P49, DOI 10.1016/j.visres.2019.10.012
   Chugh S, 2021, INT C PATT RECOG, P2210, DOI 10.1109/ICPR48806.2021.9412066
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Cohen MA, 2020, P NATL ACAD SCI USA, V117, P13821, DOI 10.1073/pnas.1922294117
   Deemer AD, 2018, OPTOMETRY VISION SCI, V95, P694, DOI 10.1097/OPX.0000000000001278
   Delvigne V, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P10, DOI 10.1109/AIVR50618.2020.00012
   Dorner R., 2019, Virtual und Augmented Reality (VR/AR)-Grundlagen und Methoden der Virtuellen und Augmentierten Realitat, V2nd
   Dorner R., 2013, Virtual und augmented reality (VR AR): Grundlagen und Methoden der virtuellen und augmentierten Realitat, DOI [10.1007/978-3-642-28903-3, DOI 10.1007/978-3-642-28903-3]
   Ehrlich JR, 2017, AM J OPHTHALMOL, V176, P26, DOI 10.1016/j.ajo.2016.12.021
   Fujiwara K, 2009, INT J SPORTS MED, V30, P647, DOI 10.1055/s-0029-1220732
   Galvan Debarba Henrique., 2020, IEEE Transactions on Visualization and Computer Graphics (2020), P1, DOI DOI 10.1109/TVCG.2020.3025175
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Guixeres J, 2013, J UNIVERS COMPUT SCI, V19, P1199
   Hagemann N, 2006, J SPORT EXERCISE PSY, V28, P143, DOI 10.1123/jsep.28.2.143
   Haskins AJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71125-4
   Hessels RS, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.180502
   Htike HM, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.10.26
   Hu ZM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P543, DOI [10.1109/VRW50115.2020.0-153, 10.1109/VRW50115.2020.00123]
   Iskander J, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102883
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kim JY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103461
   Kim YR, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P333, DOI 10.1145/2993369.2996330
   Klinghammer M, 2016, VISION RES, V129, P13, DOI 10.1016/j.visres.2016.10.004
   Kloss, 2020, ZUKUNFT CONSUMER TEC, P33
   Kredel R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01845
   LaValle Steven., 2019, Virtual reality
   Lee KF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071917
   Lee TL, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10121016
   Lee Y, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020104
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Li CJ, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P665, DOI 10.1109/VRW52623.2021.00215
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Liu C, 2020, COMPUT GRAPH-UK, V89, P1, DOI 10.1016/j.cag.2020.04.005
   Liu H, 2020, ACTA PSYCHOL, V210, DOI 10.1016/j.actpsy.2020.103142
   Llanes-Jurado J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174956
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Loffing F., 2017, EYE TRACKING SPITZEN
   Luidolt LR, 2020, IEEE T VIS COMPUT GR, V26, P3557, DOI 10.1109/TVCG.2020.3023604
   Mann DL, 2019, J VISION, V19, DOI 10.1167/19.14.28
   Mann DTY, 2007, J SPORT EXERCISE PSY, V29, P457, DOI 10.1123/jsep.29.4.457
   Matsangidou M, 2019, PSYCHOL SPORT EXERC, V41, P218, DOI 10.1016/j.psychsport.2018.07.004
   Mattar AAG, 2005, NEURON, V46, P153, DOI 10.1016/j.neuron.2005.02.009
   Mehrfard A, 2019, ARXIV
   Meng XX, 2020, IEEE T VIS COMPUT GR, V26, P1972, DOI 10.1109/TVCG.2020.2973442
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Mikhailenko M, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.697032
   Milazzo N, 2016, J SPORT SCI, V34, P1547, DOI 10.1080/02640414.2015.1122824
   Murray NG, 2020, J NEUROTRAUM, V37, P340, DOI 10.1089/neu.2019.6595
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   O'Neill EC, 2011, INVEST OPHTH VIS SCI, V52, P3976, DOI 10.1167/iovs.10-6912
   Olade I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102944
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pastel S, 2021, J MOTOR BEHAV, V53, P693, DOI 10.1080/00222895.2020.1843390
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Pastel S, 2021, VIRTUAL REAL-LONDON, V25, P175, DOI 10.1007/s10055-020-00449-3
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Piras A, 2014, INT J SPORTS SCI COA, V9, P185, DOI 10.1260/1747-9541.9.1.185
   Piras A, 2011, COGN PROCESS, V12, P245, DOI 10.1007/s10339-011-0406-z
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Polevoy G, 2017, INT J APPL EXERC PHY, V6, P1, DOI 10.22631/ijaep.v6i4.175
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Rosalie SM, 2013, Q J EXP PSYCHOL, V66, P1951, DOI 10.1080/17470218.2013.770044
   Roth T, 2017, J EYE MOVEMENT RES, V10, DOI 10.16910/jemr.10.5.2
   Ryu D, 2016, J VISION, V16, DOI 10.1167/16.2.2
   Savelsbergh GJP, 2005, ERGONOMICS, V48, P1686, DOI 10.1080/00140130500101346
   Schorer J, 2013, APPL PSYCHOPHYS BIOF, V38, P185, DOI 10.1007/s10484-013-9224-7
   Sherman WR, 2019, MKS COMP GRAPH GEOME, P1
   Shi PT, 2020, COMPUT GRAPH-UK, V91, P83, DOI 10.1016/j.cag.2020.06.007
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101167
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101153
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201350
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Vansteenkiste P, 2015, ERGONOMICS, V58, P712, DOI 10.1080/00140139.2014.990524
   Vater C, 2020, INT REV SPORT EXER P, V13, P81, DOI 10.1080/1750984X.2019.1582082
   Vignais N, 2015, HUM MOVEMENT SCI, V39, P12, DOI 10.1016/j.humov.2014.10.006
   Vine SJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00008
   Ward P, 2003, J SPORT EXERCISE PSY, V25, P93, DOI 10.1123/jsep.25.1.93
   Weier M, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3238301
   Wender CLA, 2019, MED SCI SPORT EXER, V51, P2088, DOI 10.1249/MSS.0000000000002016
   Yang TH, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P482, DOI 10.1109/VRW52623.2021.00123
   Zhu HP, 2011, MED HYPOTHESES, V76, P646, DOI 10.1016/j.mehy.2011.01.022
   Zhu Q, 2020, WINT SIMUL C PROC, P2424, DOI 10.1109/WSC48552.2020.9384065
   Ziv G, 2017, INT J AVIAT PSYCHOL, V26, P75, DOI 10.1080/10508414.2017.1313096
NR 101
TC 13
Z9 13
U1 12
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4181
EP 4208
DI 10.1007/s11042-022-13474-y
EA JUL 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828935800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, N
   Sharma, KP
   Mangla, M
   Rani, R
AF Sharma, Nonita
   Sharma, K. P.
   Mangla, Monika
   Rani, Rajneesh
TI Breast cancer classification using snapshot ensemble deep learning model
   and t-distributed stochastic neighbor embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Classification; Feature reduction; Snapshot ensemble;
   Deep learning; t-Distributed Stochastic Neighbor Embedding; Ensembling
ID PREDICTION; BENIGN
AB The current work aims to analyse the historical data pertaining to breast cancer to detect and predict the disease. For the same, authors employ t-distributed stochastic neighbor embedding (t-SNE), a well-established dimensionality reduction method. The authors also suggest implementing the snapshot ensembling technique to create an efficient model that potentially assists medical professionals in disease diagnosis. Employing t-SNE enables the generation of improved scatter plots in addition to cost optimization. Further, the current manuscript also uses a snapshot ensemble deep learning framework that integrates the predictions through various base models leading to accuracy enhancement. The proposed model is implemented on the Wisconsin Breast Cancer Dataset(WBCD) that is openly accessible at UCI Machine Repository. During the experimental evaluation, proposed model yields an accuracy of 86.6%,higher than the state-of-art models like averaging, weighted averaging, stacked ensemble, and Polyak Rupert that yield an accuracy of 81%, 81.7%, 84.7%, and 82.2% respectively and hence establishes the competence of proposed model. The obtained result is highly encouraging and resultantly opens the avenue for implementing the proposed model in real life at large.
C1 [Sharma, Nonita] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Sharma, K. P.; Rani, Rajneesh] Dr BR Ambedkar Natl Inst Technol, Jalandhar, Punjab, India.
   [Mangla, Monika] Dwarkadas J Sanghvi Coll Engn, Mumbai, Maharashtra, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); National
   Institute of Technology (NIT System); Dr B R Ambedkar National Institute
   of Technology Jalandhar
RP Sharma, N (corresponding author), Indira Gandhi Delhi Tech Univ Women, Delhi, India.
EM nonitashama@igdtuw.ac.in; sharmakp@nitj.ac.in; manglamona@gmail.com;
   ranir@nitj.ac.in
RI Mangla, Monika/D-9198-2016
OI Mangla, Monika/0000-0002-1752-7226
CR Abdar M, 2019, MEASUREMENT, V146, P557, DOI 10.1016/j.measurement.2019.05.022
   Alam KMR, 2020, NEURAL COMPUT APPL, V32, P8675, DOI 10.1007/s00521-019-04359-7
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ashiba HI, 2021, MULTIMED TOOLS APPL, V80, P9333, DOI 10.1007/s11042-020-10131-0
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Bunte K, 2012, NEUROCOMPUTING, V90, P23, DOI 10.1016/j.neucom.2012.02.034
   Chaurasia V, 2018, J ALGORITHMS COMPUT, V12, P119, DOI 10.1177/1748301818756225
   Doreswamy, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P501, DOI 10.1109/ICATCCT.2015.7456936
   Eshlaghy AbbasToloie., 2013, Journal of Health and Medicine Information, V4, P124, DOI DOI 10.4172/2157-7420.1000124
   Fakoor R., 2013, P 30 INT C MACH LEAR, P3937
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gupta Puja, 2020, Procedia Computer Science, V171, P593, DOI 10.1016/j.procs.2020.04.064
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hooda R, 2019, MULTIMED TOOLS APPL, V78, P31515, DOI 10.1007/s11042-019-07984-5
   Howlader N., 2019, SEER Cancer Statistics Review, 1975-2016
   Huang G., 2017, ARXIV170400109
   Jing W, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00771
   Kumar V, 2020, LECT NOTE DATA ENG, V37, P435, DOI 10.1007/978-981-15-0978-0_43
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Loshchilov I., 2017, INT C LEARN REPR
   Mandal S.K., 2017, International Journal Of Engineering And Computer Science, V6, P20388
   Mekha Panuwat, 2019, 2019 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT-NCON), P343, DOI 10.1109/ECTI-NCON.2019.8692297
   Nguyen QH, 2019, INT CONF SYST SCI EN, P250, DOI [10.1109/ICSSE.2019.8823106, 10.1109/icsse.2019.8823106]
   Osman AH, 2020, IEEE ACCESS, V8, P39165, DOI 10.1109/ACCESS.2020.2976149
   Sanghoon Lee, 2019, 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Proceedings, P2549, DOI 10.1109/BIBM47256.2019.8983317
   Selvathi D, 2018, L N COMPUT VIS BIOME, V25, P159, DOI 10.1007/978-3-319-61316-1_8
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Wang H., 2015, IIE ANN C P, P818
   Wang Q, 2021, IEEE T IND ELECTRON, V68, P1684, DOI 10.1109/TIE.2020.2969072
   Wang Q, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2929
   Wild CP, 2020, WORLD CANC REPORT CA, DOI DOI 10.3945/AN.116.012211
   WILLIAM H, 1990, P NATL ACAD SCI USA, V87, P9193
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 39
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4011
EP 4029
DI 10.1007/s11042-022-13419-5
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446600003
DA 2024-07-18
ER

PT J
AU Khera, S
   Turk, N
   Kaur, N
AF Khera, Sonam
   Turk, Neelam
   Kaur, Navdeep
TI HC-WSN: a Hibernated Clustering based framework for improving energy
   efficiency of wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficiency; Hierarchical clustering; LEACH; Network lifetime;
   Wireless Sensor Networks
ID LIFE-SPAN; MAXIMIZE; SCHEME
AB Whether it is Internet of Things for smart homes & industrial units or surveillance of inaccessible terrain, Wireless Sensor Networks (WSNs) are penetrating at a very fast pace in variety of applications. This increase in span of WSN implementation has accelerated research in the field. Energy efficiency, life time improvement, reducing production costs, data security and node mobility are some of the key areas of interest. This paper evaluates clustering-based methodologies already proposed for improving energy efficiency of sensor networks. The gaps in the methodologies have been identified and have been addressed through the new methodology Hibernated Clustering Wireless Sensor Networks (HC-WSN) proposed in this research work. The proposed methodology improves period of operation of individual sensor node followed by improvement in overall network lifetime. The simulation results show that our proposed scheme surpasses the existing schemes in terms of lifespan of individual nodes, average energy and throughput. Moreover, the proposed methodology prolongs the lifespan of WSNs and as well as of individual nodes.
C1 [Khera, Sonam; Turk, Neelam] JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.
   [Kaur, Navdeep] Sri Guru Granth Sahib World Univ, Dept Comp Sci, Fatehgarh Sahib, Punjab, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Khera, S (corresponding author), JC Bose Univ Sci & Technol, Dept Elect Engn, YMCA, Faridabad, India.; Kaur, N (corresponding author), Sri Guru Granth Sahib World Univ, Dept Comp Sci, Fatehgarh Sahib, Punjab, India.
EM sonamkhattar@yahoo.co.in; neelamturk@gmail.com; drnavdeep.iitr@gmail.com
OI Turk, Neelam/0000-0001-8653-9223; Khera, Sonam/0000-0002-6621-2503
CR Adil M, 2020, IEEE ACCESS, V8, P163209, DOI 10.1109/ACCESS.2020.3020310
   Adil M, 2020, IEEE ACCESS, V8, P148510, DOI 10.1109/ACCESS.2020.3015941
   Akan OB, ALGORITHMS PROTOCOLS, P105
   Amini N, 2007, CAN CON EL COMP EN, P1086
   Chunjuan Wei, 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P1659, DOI 10.1109/ICCSNT.2011.6182285
   Gast M. S., 2002, 802.11 Wireless Networks The Definitive Guide
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Hu H, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P266, DOI 10.1109/ICITE.2017.8056922
   Khera Sonam, 2020, International Journal of Advanced Intelligence Paradigms, V16, P190
   Lindsey S, 2002, AEROSP CONF PROC, P1125, DOI 10.1109/aero.2002.1035242
   Liu XX, 2012, KSII T INTERNET INF, V6, P1735, DOI 10.3837/tiis.2012.07.001
   Munadi R, 2016, APWIMOB 2015 IEEE AS, P142
   Nataf E, 2012, ARXIV ABS12092234
   Tan ND, 2015, 2015 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES - RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P180, DOI 10.1109/RIVF.2015.7049896
   Qing L, 2006, COMPUT COMMUN, V29, P2230, DOI 10.1016/j.comcom.2006.02.017
   Raghatate M., 2014, INT J WIREL MOB NETW, V6, P33, DOI [10.5121/ijwmn.2014.6503, DOI 10.5121/IJWMN.2014.6503]
   Razaque A, 2016, 2016 IEEE LONG ISL S
   Shih E., 2001, PROC 7 ANN ACMIEEE I, P272
   Soro S., 2005, IEEE INT PAR DISTR P
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
   Zivanov Z, 2008, COMPUT SCI INF SYST, V5, P109
NR 22
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3879
EP 3894
DI 10.1007/s11042-022-13446-2
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000826828100005
DA 2024-07-18
ER

PT J
AU Kumar, VDA
   Ruphitha, SV
   Kumar, A
   Kumar, A
   Raja, L
   Singhal, A
AF Kumar, V. D. Ambeth
   Ruphitha, S. V.
   Kumar, Abhishek
   Kumar, Ankit
   Raja, Linesh
   Singhal, Achintya
TI An effective method for predicting postpartum haemorrhage using deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning techniques; CNN; ZFnet; VGG-16net
ID MANAGEMENT; DIAGNOSIS; PREVENTION; EPIDEMIOLOGY
AB Postpartum haemorrhage is a type of blood loss that occurs after the birth of a baby. When you lose more than 500 ml of blood, your blood pressure drops, and you may suffer and die as a result. Deep learning techniques can predict postpartum hemorrhage earlier. As a result, we would be able to save the human. This paper discusses various types of deep learning techniques. This paper focuses on the concept of Convolutional neural networks and divides it into two sections: ZFnet and VGG-16net. By comparing the results of two nets, we can determine which of the techniques is best for predicting postpartum hemorrhage at an earlier stage. This study will be more beneficial to pregnant women in the future. The paper focuses on two nets that are said to be more useful and to be a standardized technique that also helps to give relevant medicine to patients at the appropriate time. In this paper, the algorithm is used for the VGG-16net, and the Confusion matrix is used for both nets to improve performance. Many metrics are used in this research to improve accuracy and results. Finally, the convolutional neural network concept of VGG-16net produced better results than ZF-net.
C1 [Kumar, V. D. Ambeth; Ruphitha, S. V.] Anna Univ, Dept Comp Sci & Engn, Panimalar Engn Coll, Chennai, Tamil Nadu, India.
   [Kumar, Abhishek] JAIN Deemed Univ, Sch Comp Sci & IT, Bangalore, Karnataka, India.
   [Kumar, Ankit] Swami Keshvanand Inst Technol Management & Gramot, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Raja, Linesh] Manipal Univ Jaipur, Dept Comp Applicat, Jaipur, Rajasthan, India.
   [Singhal, Achintya] Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi, Uttar Pradesh, India.
C3 Anna University; Anna University Chennai; Jain University; Manipal
   University Jaipur; Banaras Hindu University (BHU)
RP Raja, L (corresponding author), Manipal Univ Jaipur, Dept Comp Applicat, Jaipur, Rajasthan, India.
EM vdambethkumar@panimalar.ac.in; ruphitha@pecteam.in;
   k.abhishek@jainuniversity.ac.in; iiita.ankit@gmail.com;
   lineshraja@gmail.com; achintya@bhu.ac.in
RI Kumar, Abhishek/G-7260-2018; KUMAR/AAG-3938-2019; Kumar, Dr. VD
   Ambeth/HHZ-8023-2022; (M22AI860), Abhishek Kumar/HMD-9092-2023; Singhal,
   Achintya/P-8973-2019
OI Kumar, Abhishek/0000-0002-9925-8137; KUMAR/0000-0001-7722-2398; Singhal,
   Achintya/0000-0003-0242-2031
CR AbirSaha, 2017, J OBSTET GYNECOLOGY, V31, P1
   Adegoke O., 2020, J BMC PREGNANCY CHIL, V20, P1, DOI [10.1186/s12884-019-2665-0, DOI 10.1186/S12884-019-2665-0]
   Alalfy M, 2020, J MATERN-FETAL NEO M, V33, P1459, DOI [10.1080/14767058.2018.1519796, 10.1080/14767058.2018.1471594]
   Anderson JM, 2007, AM FAM PHYSICIAN, V75, P875
   Bateman BT, 2010, ANESTH ANALG, V110, P1368, DOI 10.1213/ANE.0b013e3181d74898
   Bhardwaj A, 2015, EXPERT SYST APPL, V42, P4611, DOI 10.1016/j.eswa.2015.01.065
   Chandraharan E, 2017, BMJ-BRIT MED J, V358, DOI 10.1136/bmj.j3875
   Christina Rini R., 2019, INT J SCI TECHNOLOGY
   Das R, 2009, EXPERT SYST APPL, V36, P7675, DOI 10.1016/j.eswa.2008.09.013
   Dildy GA, 2002, CLIN OBSTET GYNECOL, V45, P330, DOI 10.1097/00003081-200206000-00005
   El-Refaey H, 2003, BRIT MED BULL, V67, P205, DOI 10.1093/bmb/ldg016
   Eshlaghy AbbasToloie., 2013, Journal of Health and Medicine Information, V4, P124, DOI DOI 10.4172/2157-7420.1000124
   Feduniw S, 2020, GINEKOL POL, V91, P38, DOI 10.5603/GP.2020.0009
   Gao YB, 2018, IEEE ACCESS, V6, P52277, DOI 10.1109/ACCESS.2018.2869790
   Hema Kumar S, 2019, INT J SCI TECHNOLOGY
   Islam M.A., 2017, Int. J. Comput. Appl., V180, P7, DOI [10.5120/ijca2017916020, DOI 10.5120/IJCA2017916020]
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kominiarek MA, 2007, SEMIN PERINATOL, V31, P159, DOI 10.1053/j.semperi.2007.03.001
   Leduc D, 2009, J OBSTET GYNAECOL CA, V31, P980, DOI 10.1016/S1701-2163(16)34329-8
   Medjahed Seyyid Ahmed, 2015, International Journal of Intelligent Systems and Applications, V7, P1, DOI 10.5815/ijisa.2015.05.01
   Mehmood RM, 2017, IEEE ACCESS, V5, P14797, DOI 10.1109/ACCESS.2017.2724555
   Mousa HA., 2014, J COCHRANE DATABASE, V2, P1
   Nyflot LT, 2017, BMC PREGNANCY CHILDB, V17, DOI 10.1186/s12884-016-1217-0
   Pavord S, 2015, BLOOD, V125, P2759, DOI 10.1182/blood-2014-10-512608
   Perveen S, 2019, IEEE ACCESS, V7, P1365, DOI 10.1109/ACCESS.2018.2884249
   Punt MC, 2020, HAEMOPHILIA, V26, P216, DOI 10.1111/hae.13927
   Qin JM, 2020, IEEE ACCESS, V8, P20991, DOI 10.1109/ACCESS.2019.2963053
   Ramanathan G, 2006, J OBSTET GYNAECOL CA, V28, P967, DOI 10.1016/S1701-2163(16)32308-8
   RANCOGZ, 2011, MAN POSTP HAEM PPH, P1
   Rani PR, 2017, J CLIN DIAGN RES, V11, pQE1, DOI 10.7860/JCDR/2017/22659.9463
   Rouse DJ, 2013, OBSTET GYNECOL, V122, P693, DOI 10.1097/AOG.0b013e3182a2c357
   Samant P, 2018, COMPUT METH PROG BIO, V157, P121, DOI 10.1016/j.cmpb.2018.01.004
   Surbek D, 2020, ARCH GYNECOL OBSTET, V301, P627, DOI 10.1007/s00404-019-05374-8
   Vásquez-Morales GR, 2019, IEEE ACCESS, V7, P152900, DOI 10.1109/ACCESS.2019.2948430
   Weeks A, 2015, BJOG-INT J OBSTET GY, V122, P202, DOI 10.1111/1471-0528.13098
   Wetta LA, 2013, AM J OBSTET GYNECOL, V209, DOI 10.1016/j.ajog.2013.03.011
   Wu CX, 2018, IEEE ACCESS, V6, P20021, DOI 10.1109/ACCESS.2018.2823979
   Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012
   Zhang SX, 2019, IEEE ACCESS, V7, P12319, DOI 10.1109/ACCESS.2018.2871626
   Zheng BC, 2014, EXPERT SYST APPL, V41, P1476, DOI 10.1016/j.eswa.2013.08.044
   Zou L, 2017, IEEE ACCESS, V5, P23626, DOI 10.1109/ACCESS.2017.2762703
NR 41
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41881
EP 41898
DI 10.1007/s11042-021-11622-4
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700019
DA 2024-07-18
ER

PT J
AU Patil, S
   Sasikala, M
AF Patil, Savitha
   Sasikala, M.
TI Segmentation and identification of medicinal plant through weighted KNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Folio leaf dataset; Medicinal plant leaf images; Weighted KNN model;
   Classification; Feature extraction
ID CLASSIFICATION; FEATURES; SHAPE
AB Medicinal plants can provide immense contribution towards the growth of modern medicine and pharmaceutical industries to protect people from current deadly diseases like cancer and cardiovascular diseases. However, presence of thousands of plant species globally and similarity in their features like color, texture and shape makes their identification critical and immensely challenging. Moreover, utilization of traditional methods to classify plant leaf under expert's guidance is costly, challenging and time taking process. Therefore, in this article, a Weighted KNN Classification (WKNNC) Model is adopted for the accurate identification of plant leaf images based on machine learning techniques.High quality morphological and discriminative features are obtained by using Region of Interest (ROI) images which is extracted from segmentation process. The proposed WKNNC model works upon Local Intensity Relation (LIR) and directional group encoding method to obtain high quality features. Further, the obtained feature weights provide high classification accuracy. Folio Leaf dataset is utilized to evaluate performance of proposed WKNNC model. The obtained classification accuracy is compared against several state-of-art-techniques and proposed EKNNC model outperforms all of them.
C1 [Patil, Savitha] Sharnbasva Univ, Dept Comp Sci & Engn, Kalburgi, India.
   [Sasikala, M.] Godutai Engn Coll Women, Dept Elect & Elect Engn, Kalburgi, India.
RP Patil, S (corresponding author), Sharnbasva Univ, Dept Comp Sci & Engn, Kalburgi, India.
EM savitha019@gmail.com; sasi_mum@rediffmail.com
RI MUNGAMURI, SASIKALA/KHT-6658-2024
CR Ahmed A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237645
   Anami BS., 2010, INT J COMPUT APPL, V6, P45
   [Anonymous], 1999, WHO MONOGRAPHS SELEC
   Azlah MAF, 2019, COMPUTERS, V8, DOI 10.3390/computers8040077
   Chaudhury A, 2020, IEEE ACM T COMPUT BI, V17, P1042, DOI 10.1109/TCBB.2018.2873611
   Durairajah V, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS (CRC), P6, DOI 10.1109/CRC.2018.00011
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Journal of Botany, 2014, J BOT
   Karami N., 2017, CANC PRESS, V3, P22, DOI [10.15562/tcp.41, DOI 10.15562/TCP.41]
   Kumar M, 2019, IEEE ACCESS, V7, P163912, DOI 10.1109/ACCESS.2019.2952176
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Lulekal E, 2008, J ETHNOBIOL ETHNOMED, V4, DOI 10.1186/1746-4269-4-10
   Muneer A, 2020, IEEE ACCESS, V8, P196747, DOI 10.1109/ACCESS.2020.3034033
   Patil AA., 2016, INT J ENG TRENDS TEC, V8, P359, DOI [10.14445/22315381/IJETT-V35P273, DOI 10.14445/22315381/IJETT-V35P273]
   Pushpanathan K, 2021, ARTIF INTELL REV, V54, P305, DOI 10.1007/s10462-020-09847-0
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Thanikkal JG, 2020, IEEE SENS J, V20, P13103, DOI 10.1109/JSEN.2020.3002909
   Wang LiJun Wang LiJun, 2015, Journal of Beijing Forestry University, V37, P55
   Wang X, 2020, IEEE ACCESS, V8, P39175, DOI 10.1109/ACCESS.2020.2976117
   Wang ZB, 2016, NEURAL COMPUT APPL, V27, P899, DOI 10.1007/s00521-015-1904-1
   Yang XB, 2020, IEEE ACCESS, V8, P151555, DOI 10.1109/ACCESS.2020.3017560
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
   Zhang SW, 2020, NEUROCOMPUTING, V408, P246, DOI 10.1016/j.neucom.2019.09.113
   Zheng Y., 2018, TRANSCHIN SOC AGR MA, V49, P354, DOI [10.6041/j.issn.1000-1298.2018.S0.047, DOI 10.6041/J.ISSN.1000-1298.2018.S0.047]
   [郑一力 Zheng Yili], 2017, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V48, P30
NR 26
TC 3
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2805
EP 2819
DI 10.1007/s11042-022-13201-7
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000825737800001
DA 2024-07-18
ER

PT J
AU Song, B
   Tian, Y
   Al-Nabhan, N
AF Song, Biao
   Tian, Yuan
   Al-Nabhan, Najla
TI Simultaneous <i>p</i>- and <i>s</i>-orders <i>minmax</i> robust locality
   preserving projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Locality preserving projection; Dimension reduction (DR); Data analysis
   problems
ID PRINCIPAL COMPONENT ANALYSIS; DIMENSIONALITY REDUCTION; DISCRIMINANT;
   RECOGNITION; FACE; NORM
AB This paper proposes a new method of locality preserving projection (LPP), which replaces the squared L2-norm minimization and maximization distances in the objective of conventional LPPW. The proposed method is termed as Simultaneous p- and s-orders Minmax Robust Locality Preserving Projection (psRLPP), which is robust to outlier samples. Then, we design an efficient iterative algorithm to solve the objective problem of psRLPP. At each iteration, our method ends with solving a trace ratio problem rather inexact ratio trace problem. We also conduct some insightful analysis on the existence of local minimum and the convergence of the proposed algorithm. These characteristics make our psRLPP more intuitive and powerful than the most up-to-date method, robust LPP via p-order minimization (RLPP) which considers only the p-order minimization of the L2-norm distance and requires transforming the original trace ratio problem in each iteration into an inexact ratio problem in the solving of projection vectors. Theoretical insights and effectiveness of our method is further supported by promising experimental results for clustering.
C1 [Song, Biao] Nanjing Univ Informat Sci & Technol, Nanjing, Peoples R China.
   [Tian, Yuan] Nanjing Inst Technol, Nanjing, Peoples R China.
   [Al-Nabhan, Najla] King Saud Univ, Riyadh, Saudi Arabia.
C3 Nanjing University of Information Science & Technology; Nanjing
   Institute of Technology; King Saud University
RP Tian, Y (corresponding author), Nanjing Inst Technol, Nanjing, Peoples R China.
EM ytian@njit.edu.cn
OI tian, yuan/0000-0002-2307-8201
FU Natural Science Foundation of the Jiangsu Higher Education Institute of
   China [20KJB413001, YKJ201922]; Innovative Training Program for College
   Students of Jiangsu Province [201911276014Z]; Deanship of Scientific
   Research at King Saud University [RG-1441-331]; Startup Foundation for
   Introducing Talent of Nan-jing University of Information Science and
   Technology [2019r030]
FX The authors extend their appreciation to the Natural Science Foundation
   of the Jiangsu Higher Education Institute of China (20KJB413001), talent
   research start-up fund project (YKJ201922), the Innovative Training
   Program for College Students of Jiangsu Province (Grant No.
   201911276014Z), and the Deanship of Scientific Research at King Saud
   University for funding this work through research group no. RG-1441-331.
   This work was also supported by Startup Foundation for Introducing
   Talent of Nan-jing University of Information Science and Technology
   (Grant No.2019r030).
CR [Anonymous], HANDWRITTEN DIGIT DA
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2007, IEEE I CONF COMP VIS, P222
   Dornaika F, 2016, IEEE T CYBERNETICS, V46, P206, DOI 10.1109/TCYB.2015.2399456
   Fu LY, 2022, IEEE T NEUR NET LEAR, V33, P130, DOI 10.1109/TNNLS.2020.3027588
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Kwak N, 2014, IEEE T CYBERNETICS, V44, P594, DOI 10.1109/TCYB.2013.2262936
   Lai ZH, 2017, IEEE T CYBERNETICS, V47, P3733, DOI 10.1109/TCYB.2016.2578642
   Lu GF, 2010, PATTERN RECOGN, V43, P3572, DOI 10.1016/j.patcog.2010.04.007
   Lu JW, 2011, NEUROCOMPUTING, V74, P3760, DOI 10.1016/j.neucom.2011.06.024
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nie FP, 2021, IEEE T PATTERN ANAL, V43, P2086, DOI 10.1109/TPAMI.2019.2961877
   Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160
   Peng R, 2019, P 2019 ANN ACM SIAM
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang H, 2015, AAAI CONF ARTIF INTE, P3059
   Yale, FAC DAT
   Yan H, 2018, PATTERN RECOGN, V74, P434, DOI 10.1016/j.patcog.2017.09.035
   Ye QL, 2019, IEEE T NEUR NET LEAR, V30, P3818, DOI 10.1109/TNNLS.2019.2944869
   Ye QL, 2018, IEEE T NEUR NET LEAR, V29, P4494, DOI 10.1109/TNNLS.2017.2749428
   Ye QL, 2018, NEURAL NETWORKS, V105, P393, DOI 10.1016/j.neunet.2018.05.020
   Ye QL, 2018, IEEE T CIRC SYST VID, V28, P114, DOI 10.1109/TCSVT.2016.2596158
   Yu GX, 2012, PATTERN RECOGN, V45, P1119, DOI 10.1016/j.patcog.2011.08.024
   Zhang HM, 2020, IEEE T IMAGE PROCESS, V29, P3132, DOI 10.1109/TIP.2019.2957925
   Zhou GY, 2021, IEEE T CYBERNETICS, V51, P1666, DOI 10.1109/TCYB.2019.2931957
NR 34
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42513
EP 42526
DI 10.1007/s11042-021-11393-y
EA JUL 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700025
DA 2024-07-18
ER

PT J
AU Sidhom, O
   Ghazouani, H
   Barhoumi, W
AF Sidhom, Ones
   Ghazouani, Haythem
   Barhoumi, Walid
TI Subject-dependent selection of geometrical features for spontaneous
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Feature extraction; Geometrical features;
   Face-based feature selection; Subject-dependency
ID FACIAL EXPRESSION RECOGNITION; INFORMATION
AB Facial expressions are among the most powerful ways to reveal the emotional state. Therefore, Facial Expression Recognition (FER) has been widely introduced to wide fields of applications, such as security, psychotherapy, neuromarketing, and advertisement. Feature extraction and selection are two essential key issues for the design of efficient FER systems. However, most of the previous studies focused on implementing static feature selection methods. Although these methods have shown promising results, they still present weaknesses, especially when dealing with spontaneous expressions. This is mainly due to the specificity of each face, which makes the facial emotion display differs from one subject to another. To address this problem, we propose a face-based dynamic feature selection of two geometric features sub-classes, namely linear and eccentricity features. This combination provides a better understanding of the facial transformation during the emotion display. Moreover, the suggested selection method takes into consideration the subject's general facial structure, muscle movements, and head position. The performed experiments, using the CK+ and the DISFA datasets, have showed that the proposed method outperforms the state-of-the-art techniques and maintains superior performance with cross-dataset validation. In fact, the accuracy of facial expression recognition by the proposed method reaches 97.72% and 91,26% on the CK+ and the DISFA datasets, respectively.
C1 [Sidhom, Ones; Ghazouani, Haythem; Barhoumi, Walid] Univ Tunis El Manar, Inst Super Informat, Res Team Intelligent Syst Imaging & Artificial Vi, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
   [Ghazouani, Haythem; Barhoumi, Walid] Univ Carthage, Ecole Natl Ingenieurs Carthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
C3 Universite de Tunis-El-Manar; Universite de Carthage
RP Barhoumi, W (corresponding author), Univ Tunis El Manar, Inst Super Informat, Res Team Intelligent Syst Imaging & Artificial Vi, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.; Barhoumi, W (corresponding author), Univ Carthage, Ecole Natl Ingenieurs Carthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
EM ones.sidhom@fst.utm.tn; haythem.ghazouani@enicar.u-carthage.tn;
   walid.barhoumi@enicarthage.rnu.tn
RI Barhoumi, Walid/C-6576-2014; Ghazouani, Haythem/N-1013-2014
OI Barhoumi, Walid/0000-0003-2123-4992; Ghazouani,
   Haythem/0000-0002-6521-5024
CR Amminger GP, 2012, SCHIZOPHRENIA BULL, V38, P1030, DOI 10.1093/schbul/sbr015
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 1965, The expression of emotions in man and animal
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Bandrabur A, 2015, INT C INTELL COMP CO, P379, DOI 10.1109/ICCP.2015.7312688
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bartlett MS, 2004, IEEE SYS MAN CYBERN, P592
   Beh KX, 2019, 2019 IEEE 15TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2019), P192, DOI [10.1109/CSPA.2019.8696059, 10.1109/cspa.2019.8696059]
   Bejaoui H, 2019, MULTIMED TOOLS APPL, V78, P22773, DOI 10.1007/s11042-019-7632-2
   Bejaoui H, 2017, LECT NOTES COMPUT SC, V10617, P39, DOI 10.1007/978-3-319-70353-4_4
   Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Butalia A., 2012, International Journal of Modern Engineering Research, P1449
   Candra H, 2016, IEEE ENG MED BIO, P423, DOI 10.1109/EMBC.2016.7590730
   Cao NT., 2016, INT J COMPUT VIS ROB, V6, P223, DOI DOI 10.1504/IJCVR.2016.077353
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   Chen M, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/5608340
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta S, 2017, ADV INTELL SYST, V459, P619, DOI 10.1007/978-981-10-2104-6_55
   Desrosiers PA, 2016, INT C PATT RECOG, P961, DOI 10.1109/ICPR.2016.7899760
   Dibeklioglu H, 2015, IEEE T MULTIMEDIA, V17, P279, DOI 10.1109/TMM.2015.2394777
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   Ekman P., 2009, Telling lies: Clues to deceit in the marketplace, politics, and marriage
   Ekman P., 1978, Facial action coding system
   Ekundayo OS, 2021, IEEE ACCESS, V9, P136944, DOI 10.1109/ACCESS.2021.3113464
   Fernandes JD, 2016, SIBGRAPI, P347, DOI [10.1109/SIBGRAPI.2016.52, 10.1109/SIBGRAPI.2016.055]
   Ferreira AJ, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P35, DOI 10.1007/978-1-4419-9326-7_2
   Fölster M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00030
   Friedman J.H., 1996, Another approach to polychotomous classification
   Gharsalli S, 2015, VISAPP 2015 10 INT C, V2, DOI 10.5220/0005312804240431
   Ghazouani H, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107173
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Gidudu A, 2007, ARXIV 07112914
   Goren D, 2006, VISION RES, V46, P1253, DOI 10.1016/j.visres.2005.10.028
   Guo H, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00202
   Gupta O, 2018, PATTERN RECOGN, V76, P25, DOI 10.1016/j.patcog.2017.10.017
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Hall M. A., 2000, P 17 INT C MACH LEAR, P359, DOI DOI 10.5555/645529.657793
   Hamelin N, 2017, J RETAIL CONSUM SERV, V36, P103, DOI 10.1016/j.jretconser.2017.01.001
   Hassaballah M., 2019, Recent Advances in Computer Vision, P33
   He MH, 2013, INT CONF AFFECT, P79, DOI 10.1109/ACII.2013.20
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huynh XP, 2017, IEEE INT CONF COMP V, P3065, DOI 10.1109/ICCVW.2017.362
   IQBAL MT, 2020, IEEE T AFFECT COMPUT
   Jia S, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.580287
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M. M., 2020, COMPUT METHODS DATA, V1227, P207
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Lee SH, 2016, PATTERN RECOGN, V54, P52, DOI 10.1016/j.patcog.2015.12.016
   Li LL, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P85, DOI 10.1145/3317640.3317662
   Ligang Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1027, DOI 10.1109/ICME.2012.97
   Littlewort G, 2006, J MULTIMED, V1, DOI 10.4304/jmm.1.6.22-35
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liu JH, 2021, APPL SCI-BASEL, V11
   Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Makhmudkhujaev F, 2019, TURK J ELECTR ENG CO, V27, P516, DOI 10.3906/elk-1804-58
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Miao Y-Q, 2012, CROSS DOMAIN FACIAL, V2012
   Namba S, 2017, CURR PSYCHOL, V36, P593, DOI 10.1007/s12144-016-9448-9
   Novakovic J., 2011, THEORY APPL MATH COM, V1, P11
   Park S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041199
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rabiu H, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-213
   Sadeghi H, 2013, IRAN CONF MACH, P159, DOI 10.1109/IranianMVIP.2013.6779970
   Sagonas, 2013, FACIAL POINT ANNOTAT
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Said CP, 2011, PHILOS T R SOC B, V366, P1660, DOI 10.1098/rstb.2010.0351
   Samadiani N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081863
   Saxen F, 2017, IEEE INT CONF COMP V, P3073, DOI 10.1109/ICCVW.2017.363
   Sen D, 2019, MULTIMED TOOLS APPL, V78, P10287, DOI 10.1007/s11042-018-6537-9
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen L., 2004, ADABOOST GABOR FEATU
   Shreem Salam Salameh, 2012, Journal of Theoretical and Applied Information Technology, V46, P1034
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Song F, 2010, INT C SYST SCI ENG D, P27, DOI [DOI 10.1109/ICSEM.2010.14, 10.1109/ICSEM.2010.14]
   Sormaz M, 2016, VISION RES, V127, P1, DOI 10.1016/j.visres.2016.07.002
   Tingfan Wu, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P889, DOI 10.1109/FG.2011.5771369
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Valstar M., 2010, Proceedings of 3rd intern. workshop on EMOTION (satellite of LREC): Corpora for research on emotion and affect, P65
   Valstar M, 2006, IEEE C COMPUT VIS PA, DOI 10.1109/CVPRW.2006.85
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Wang SF, 2015, MACH VISION APPL, V26, P219, DOI 10.1007/s00138-015-0657-2
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zraqou J., 2013, 2013 Second International Conference on E-Learning and E-Technologies in Education (ICEEE 2013), P304, DOI 10.1109/ICeLeTE.2013.6644393
NR 94
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2635
EP 2661
DI 10.1007/s11042-022-13380-3
EA JUL 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819704400004
DA 2024-07-18
ER

PT J
AU Li, JF
   Li, X
AF Li, Junfeng
   Li, Xiao
TI Study on no-reference video quality assessment method incorporating dual
   deep learning networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality assessment; Dual networks; Feature fusion; Deep learning
ID PREDICTION; IMAGE; STATISTICS
AB The quality assessment of user-generated content (UGC) videos is a challenge. Unlike synthetic videos, these videos are then susceptible to various distortions caused by the external environment during the generation process. This paper proposes a video quality assessment method (VQA) incorporating a dual-depth network architecture. First, the diversity of video acquisition information is ensured by global average pooling and global standard deviation pooling under the InceptionV3 network and ResNet50 network, and video frame quality scores are obtained under bidirectional GRU networks. Second, in the spatial-temporal domain, a temporal memory block is constructed by exploiting human temporal memory and content-dependent effects to obtain components of video quality. Meanwhile, a Gaussian distribution is also added to the spatial domain to reduce the effect of content variation. Finally, extensive experiments are conducted using the KoNViD-1 k and LIVEVQC databases. The experimental results show that the metrics Spearman's rank-order correlation (SROCC) and Pearson's linear correlation coefficient (PLCC) are 0.7786 and 0.7759 in the overall performance,which 2.87% and 0.52% higher than Tang, respectively. This verifies the validity of the model. In addition, the cross-validation experiments show that the present model also has strong generalization ability.
C1 [Li, Junfeng; Li, Xiao] Zhejiang Sci Tech Univ, Fac Mech Engn & Automat, Hangzhou, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Li, JF (corresponding author), Zhejiang Sci Tech Univ, Fac Mech Engn & Automat, Hangzhou, Peoples R China.
EM ljf2003@zstu.edu.cn
RI li, junfeng/HLQ-0728-2023
FU National Natural Science Foundation of China [61374022]; Zhejiang
   Provincial Basic Public Welfare Research Project of China [LGF22F030001,
   LGG19F03001]
FX This work was supported by National Natural Science Foundation of China
   (Grant No: 61374022) and by Zhejiang Provincial Basic Public Welfare
   Research Project of China (Grant No: LGF22F030001 and LGG19F03001).
CR Ahn S, 2018, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2018.8451450
   Bampis CG, 2019, IEEE T CIRC SYST VID, V29, P2256, DOI 10.1109/TCSVT.2018.2868262
   Bampis CG, 2018, IEEE T IMAGE PROCESS, V27, P3316, DOI 10.1109/TIP.2018.2815842
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1083, DOI 10.1109/LSP.2017.2705423
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen BL, 2022, IEEE T CIRC SYST VID, V32, P1903, DOI 10.1109/TCSVT.2021.3088505
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Chung Junyoung, 2014, ARXIV14123555
   Dendi SVR, 2020, IEEE T IMAGE PROCESS, V29, P5612, DOI 10.1109/TIP.2020.2984879
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ebenezer JP, 2021, IEEE T IMAGE PROCESS, V30, P8059, DOI 10.1109/TIP.2021.3112055
   Fan Q, 2019, MULTIMED TOOLS APPL, V78, P31019, DOI 10.1007/s11042-017-4848-x
   Fu H., 2021, P INT C CULT OR SCI, P305
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Götz-Hahn F, 2021, IEEE ACCESS, V9, P72139, DOI 10.1109/ACCESS.2021.3077642
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hosu V, 2017, INT WORK QUAL MULTIM
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14
   Kingma D. P., 2014, arXiv
   Korhonen J, 2019, IEEE T IMAGE PROCESS, V28, P5923, DOI 10.1109/TIP.2019.2923051
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Li B, 2022, INT T ELECTR ENERGY, V2022, DOI 10.1155/2022/9880284
   Li DQ, 2021, INT J COMPUT VISION, V129, P1238, DOI 10.1007/s11263-020-01408-w
   Li DQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2351, DOI 10.1145/3343031.3351028
   Li MW, 2022, NONLINEAR DYNAM, V107, P2447, DOI 10.1007/s11071-021-07139-y
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Liu Y, 2021, IEEE T MULTIMEDIA, V1
   Manasa K, 2016, IEEE T IMAGE PROCESS, V25, P2480, DOI 10.1109/TIP.2016.2548247
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pandremmenou K, 2015, PROC SPIE, V9394, DOI 10.1117/12.2077709
   Saad M., 2013, P INT WORKSH VID PRO, P47
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinno Z, 2019, IEEE T IMAGE PROCESS, V28, P612, DOI 10.1109/TIP.2018.2869673
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang JP, 2020, IEEE I C VI COM I PR, P156, DOI 10.1109/vcip49819.2020.9301757
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Video VOOMO, 2000, FIN REP VID QUAL EXP
   Wainwright MJ, 2000, ADV NEUR IN, V12, P855
   Xu JT, 2014, IEEE IMAGE PROC, P491, DOI 10.1109/ICIP.2014.7025098
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yi FW, 2021, IEEE IMAGE PROC, P1414, DOI 10.1109/ICIP42928.2021.9506420
   Ying ZQ, 2021, PROC CVPR IEEE, P14014, DOI 10.1109/CVPR46437.2021.01380
   Zhou W, 2020, IEEE I C VI COM I PR, P338, DOI 10.1109/vcip49819.2020.9301764
NR 51
TC 3
Z9 3
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3081
EP 3100
DI 10.1007/s11042-022-13383-0
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819342400002
DA 2024-07-18
ER

PT J
AU Barbary, M
   Abd El-azeem, MH
AF Barbary, Mohamed
   Abd El-azeem, Mohamed H.
TI Non-ellipsoidal extended targets tracking from image observations based
   on ECK-MB-sub-random matrices filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extended targets tracking; Stealth targets; Sub-random matrices;
   Cubature Kalman MB filter; TBD
ID PROBABILITY HYPOTHESIS DENSITY; MULTI-BERNOULLI FILTER; JOINT DETECTION;
   ALGORITHM; GAMMA
AB Joint detection and tracking of multiple extended objects from image observations is a challenging radar technology; especially for small back-scattering objects such as extended stealth targets (ESTs). This work provides a new approach for the ESTs tracking under the non-linear Gaussian system based on track-before-detect (TBD) approach. The sequential Monte Carlo multi-Bernoulli (SMC-MB) filter provides a good framework to cope with TBD approach. However, the SMC-MB filter suffers from the particles' degradation problem seriously; especially for ETs tracking. Recently, the Cubature Kalman MB (CK-MB) filter which employs a third-degree spherical-radical cubature rule has been proposed to handle the nonlinear models, the CK-MB filter is more accurate and more principled in mathematical terms compared to SMC-MB filter. To this point, we address a TBD of ESTs with extended CK (ECK)-MB filter based on random matrices model (RMM), which is an efficient way to track ellipsoidal ESTs. In RMM-ESTs scenarios, although the extension ellipsoid is efficient, it may not be accurate enough because of lacking useful information, such as size, shape and orientation. Therefore, we introduce a filter composed of sub-ellipses; each one is represented by a RMM. The results confirm the effectiveness and robustness of the proposed ECK-Sub-RMM-MB-TBD filter.
C1 [Barbary, Mohamed] Alexandria Univ, Dept Elect Engn, Alexandria, Egypt.
   [Barbary, Mohamed] EADF, Res & Dev Dept Radar Syst, Cairo, Egypt.
   [Abd El-azeem, Mohamed H.] Arab Acad Sci Technol & Maritime Transport, Dept Elect & Commun, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University; Egyptian Knowledge
   Bank (EKB); Arab Academy for Science, Technology & Maritime Transport
RP Barbary, M (corresponding author), Alexandria Univ, Dept Elect Engn, Alexandria, Egypt.; Barbary, M (corresponding author), EADF, Res & Dev Dept Radar Syst, Cairo, Egypt.
EM mbarbary300@gmail.com
RI barbary, mohamed/E-8412-2015
CR Arasaratnam I, 2009, IEEE T AUTOMAT CONTR, V54, P1254, DOI 10.1109/TAC.2009.2019800
   Barbary M, 2015, IET RADAR SONAR NAV, V9, P802, DOI 10.1049/iet-rsn.2014.0308
   Beard M, 2016, IEEE T SIGNAL PROCES, V64, P1638, DOI 10.1109/TSP.2015.2505683
   Chen JG, 2015, IET RADAR SONAR NAV, V9, P324, DOI 10.1049/iet-rsn.2014.0093
   Errasti-Alcala B, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   Granström K, 2015, IEEE T GEOSCI REMOTE, V53, P6617, DOI 10.1109/TGRS.2015.2444794
   Granstrom K., 2017, J ADV INFORM FUSION, V12, P139
   Hu Q, 2019, IET SIGNAL PROCESS, V13, P443, DOI 10.1049/iet-spr.2018.5125
   Jiang TY, 2016, DIGIT SIGNAL PROCESS, V59, P76, DOI 10.1016/j.dsp.2016.08.002
   Lan J, 2014, IEEE T SIGNAL PROCES, V62, P2450, DOI 10.1109/TSP.2014.2309561
   Liang ZB, 2020, DIGIT SIGNAL PROCESS, V99, DOI 10.1016/j.dsp.2020.102669
   Liang ZB, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192473
   Liu M, 2014, 17 INT C INF FUS FUS
   Liu R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194187
   Liu Z, 2019, IEEE ACCESS, V7, P103678, DOI 10.1109/ACCESS.2019.2931470
   Ma DD, 2016, IET RADAR SONAR NAV, V10, P272, DOI 10.1049/iet-rsn.2015.0081
   Ristic B, 2013, IEEE T SIGNAL PROCES, V61, P3406, DOI 10.1109/TSP.2013.2257765
   Salim IM, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013021
   Vo BT, 2012, IEEE T AERO ELEC SYS, V48, P1385, DOI 10.1109/TAES.2012.6178069
   Vo BN, 2010, IEEE T SIGNAL PROCES, V58, P5129, DOI 10.1109/TSP.2010.2050482
   Wang HH, 2019, J ENG-JOE, V2019, P7667, DOI 10.1049/joe.2019.0670
   Wang LP, 2019, IEEE ACCESS, V7, P129584, DOI 10.1109/ACCESS.2019.2940027
   Wieneke M, 2014, IEEE T AERO ELEC SYS, V50, P2199, DOI 10.1109/TAES.2014.120114
   Yan B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040881
   Yan B, 2017, IET SIGNAL PROCESS, V11, P674, DOI 10.1049/iet-spr.2016.0582
   Yang JL, 2013, IET RADAR SONAR NAV, V7, P101, DOI 10.1049/iet-rsn.2012.0184
   Zhang YQ, 2018, SIGNAL PROCESS, V149, P88, DOI 10.1016/j.sigpro.2018.03.002
   Zhang YQ, 2016, KNOWL-BASED SYST, V95, P125, DOI 10.1016/j.knosys.2015.12.008
   Zong P, 2016, IEEE SENS J, V16, P1428, DOI 10.1109/JSEN.2015.2499268
NR 29
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3269
EP 3302
DI 10.1007/s11042-022-13324-x
EA JUN 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000814956100003
DA 2024-07-18
ER

PT J
AU Gupta, SK
   Nain, N
AF Gupta, Sandeep Kumar
   Nain, Neeta
TI Review: Single attribute and multi attribute facial gender and age
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Multi attribute; Face; Age estimation; Gender classification; Regression
ID FACE-RECOGNITION; CLASSIFICATION; FUSION; CNN; FEATURES; PREDICTION;
   FRAMEWORK; IMAGES
AB Facial age and gender recognition have vital applications as consumer profile prediction, social media advertisement, human-computer interaction, image retrieval system, demographic profiling, customized advertisement systems, security and surveillance. This paper presents a study on Single Attribute (Attribute: either Gender or Age) and Multi-Attribute (both Gender and Age) prediction model. We present a review for facial age estimation and gender classification methods based on conventional as well as deep learning approaches developed so far with analysis of their pros, cons and insights for future research. Moreover, this study also enlists the databases used for benchmarking results with their properties for both constrained and unconstrained environment.
C1 [Gupta, Sandeep Kumar; Nain, Neeta] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Gupta, SK (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
EM sandeepmbm@gmail.com; nnain.cse@mnit.ac.in
RI Gupta, Sandeep Kumar/K-3806-2016
OI Gupta, Sandeep Kumar/0000-0002-5911-1771
CR Abbas Hawraa, 2018, Computational Visual Media, V4, P17, DOI 10.1007/s41095-017-0097-1
   Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   Agbo-Ajala O, 2020, IEEE ACCESS, V8, P162800, DOI 10.1109/ACCESS.2020.3022039
   Agbo-Ajala Olatunbosun, 2020, ScientificWorldJournal, V2020, P1289408, DOI 10.1155/2020/1289408
   Alamri T, 2013, INT C INFO SCI APPL
   Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   Amelio A, 2019, INT S FORMAL METHODS, P162
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, JAPANESE SMOKERS FAC
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Aslam A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053023
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bissoon T., 2013, 2013 INT C AD SCI TE, P1, DOI 10.1109/icastech.2013.6707489
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86
   Chikkala R, 2019, INT ARAB J INF TECHN, V16, P30
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cottrell G.W., 1991, Advances in Neural Information Processing Systems, V3, P564
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Deb D, 2018, INT CONF BIOMETR, P225, DOI 10.1109/ICB2018.2018.00042
   Debgupta Rajdeep, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P517, DOI 10.1007/978-981-15-1286-5_44
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40
   Ferguson E, 2017, SCI JUSTICE, V57, P58, DOI 10.1016/j.scijus.2016.08.005
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011
   Guo GD, 2012, STUD COMPUT INTELL, V409, P101
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Gurnani A, 2019, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2019.00094
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hong LJ, 2013, INT CONF MACH LEARN, P370, DOI 10.1109/ICMLC.2013.6890496
   Hsu GSJ, 2017, IEEE COMPUT SOC CONF, P540, DOI 10.1109/CVPRW.2017.81
   Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524
   Jia S, 2016, INT CONF DAT MIN WOR, P462, DOI [10.1109/ICDMW.2016.0072, 10.1109/ICDMW.2016.45]
   Khan A, 2005, INT J KNOWL-BASED IN, V9, P1
   Khan K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020328
   Kim HC, 2006, PATTERN RECOGN LETT, V27, P618, DOI 10.1016/j.patrec.2005.09.027
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lee JH, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P162, DOI 10.1109/MIPR.2018.00036
   Leng XM, 2008, IEEE IMAGE PROC, P1656, DOI 10.1109/ICIP.2008.4712090
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Li ZF, 2009, INTERNATIONAL RESEARCH CONFERENCE OF RESOURCES UTILIZATION AND ENVIRONMENTAL EFFECTIVENESS, P45
   Liao HB, 2019, MULTIMED TOOLS APPL, V78, P2181, DOI 10.1007/s11042-018-6342-5
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu XH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010146
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu L, 2009, INT CONF ACOUST SPEE, P1065, DOI 10.1109/ICASSP.2009.4959771
   Luu K., 2011, 2011 INT JOINT C BIO, P1
   Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Moeini H, 2017, J VIS COMMUN IMAGE R, V42, P1, DOI 10.1016/j.jvcir.2016.11.002
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Cirne MVM, 2017, IEEE SYS MAN CYBERN, P2006, DOI 10.1109/SMC.2017.8122913
   Osman OF, 2019, IEEE TETCI, V3, P271, DOI 10.1109/TETCI.2018.2864554
   Pan HY, 2018, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR.2018.00554
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pirozmand P, 2011, J MATH COMPUT SCI-JM, V2, P233
   Ramesha K., 2010, FEATURE EXTRACTION B
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   Shin M, 2017, IEEE ROMAN, P567, DOI 10.1109/ROMAN.2017.8172359
   Simanjuntak F, 2020, ADV INTELL SYST COMP, V943, P444, DOI 10.1007/978-3-030-17795-9_33
   Somanath G, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130517
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Taheri S, 2019, NEUROCOMPUTING, V329, P300, DOI 10.1016/j.neucom.2018.10.071
   Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182
   Uricar M, 2016, IEEE COMPUT SOC CONF, P730, DOI 10.1109/CVPRW.2016.96
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   Wang F, 2017, IEEE INT CONF AUTOMA, P173, DOI 10.1109/FG.2017.30
   Wang JG, 2010, I C CONT AUTOMAT ROB, P1860, DOI 10.1109/ICARCV.2010.5707370
   Wang XL, 2017, IEEE INT CONF AUTOMA, P566, DOI 10.1109/FG.2017.141
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10
   Yildirim M. E., 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: VISAPP 2016, P108
   Yoo B, 2018, IEEE SIGNAL PROC LET, V25, P808, DOI 10.1109/LSP.2018.2822241
   Zhang K, 2020, IEEE T CIRC SYST VID, V30, P3140, DOI 10.1109/TCSVT.2019.2936410
   Zhang K, 2017, IEEE ACCESS, V5, P22492, DOI 10.1109/ACCESS.2017.2761849
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
NR 103
TC 6
Z9 6
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1289
EP 1311
DI 10.1007/s11042-022-12678-6
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000811421000001
PM 35729932
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Hassan, MU
   Niu, DM
   Zhang, MX
   Zhao, XY
AF Hassan, Muhammad Umair
   Niu, Dongmei
   Zhang, Mingxuan
   Zhao, Xiuyang
TI Asymmetric hashing based on generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hashing; Generative adversarial network; Image retrieval; Supervised
   learning
AB In the era of big data, social media, large-scale video, image, and text data is produced every day. The approximate nearest neighbor (ANN) search has drawn significant attention for content-based image retrieval applications to ensure retrieval quality and computational efficiency. Hashing has become a cutting-edge technology for image retrieval and big data applications due to its low-storage and high-computational efficiency. Hashing algorithms are useful for mapping images into short binary codes and generating a similar binary code for similar data points from the database. Many supervised/unsupervised hashing methods have been deployed for retrieving the query points from the database images, and many recently developed methods can achieve a higher accuracy regarding image retrieval performance. However, the current state-of-the-art algorithms can only improve binary code hashing, and the retrieval performance of binary representation is not good. To overcome this issue, we propose an asymmetric learning method that generates the hash codes. This work proposes a novel asymmetric learning-based generative adversarial network (AGAN) for image retrieval, which integrates the feature learning with hashing to an end-to-end learning framework. Moreover, to equip with the binary representation of image retrieval; we propose three loss functions, i.e., encoder loss, generator loss, and discriminator loss, which significantly improve retrieval performance. The extensive experiments show that our proposed method outperformed several state-of-the-art methods.
C1 [Hassan, Muhammad Umair; Niu, Dongmei; Zhao, Xiuyang] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan, Peoples R China.
   [Hassan, Muhammad Umair] Norwegian Univ Sci & Technol NTNU, Dept ICT & Nat Sci, Alesund, Norway.
   [Zhang, Mingxuan] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Sichuan, Peoples R China.
C3 University of Jinan; Norwegian University of Science & Technology
   (NTNU); Southwest Jiaotong University
RP Zhao, XY (corresponding author), Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan, Peoples R China.
EM mumairhsn@gmail.com; dniu_ujn@hotmail.com; ujn_mingxuanzhang@qq.com;
   zhaoxy@ujn.edu.cn
RI Hassan, Mohammad/GZA-7507-2022; Hassan, Ali/HSI-1092-2023; Hassan,
   Mohammad/KDM-9524-2024; Hassan, Muhammad/GWZ-4054-2022
OI Hassan, Mohammad/0000-0002-1712-0004; 
FU National Nature Science Foundation of China [62102163]; Natural Science
   Foundation of Shandong Province [ZR2019MF013, ZR2019BF026, ZR2020KF015]
FX This research was supported by the National Nature Science Foundation of
   China (No. 62102163) and the Natural Science Foundation of Shandong
   Province (Nos. ZR2019MF013, ZR2019BF026, ZR2020KF015).
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Andoni A, 2015, ACM S THEORY COMPUT, P793, DOI 10.1145/2746539.2746553
   [Anonymous], 2012, NIPS
   [Anonymous], 2013, NeurIPS
   Becker C, 2013, LECT NOTES COMPUT SC, V8149, P526, DOI 10.1007/978-3-642-40811-3_66
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chatfield K., 2020, ARXIV 14053531
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Krizhevsky A., 2020, Learning multiple layers of features from tiny
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li FL, 2021, KNOWL-BASED SYST, V219, DOI 10.1016/j.knosys.2021.106851
   Li W-J., 2020, ARXIV 151103855
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu H, 2016, AAAI CONF ARTIF INTE, P1258
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Ma L, 2020, NEUROCOMPUTING, V380, P115, DOI 10.1016/j.neucom.2019.11.009
   Magliani F, 2018, LECT NOTES COMPUT SC, V11241, P541, DOI 10.1007/978-3-030-03801-4_47
   Norouzi M, 2012, ADV NEURAL INFORM PR
   Odena A, 2017, PR MACH LEARN RES, V70
   Radford A., 2020, ARXIV 151106434
   Shen FM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1522, DOI 10.1145/3123266.3123345
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shi XS, 2017, AAAI CONF ARTIF INTE, P2541
   Somasundaram A., 2016, P 1 INT C RES ENG CO
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Tang JH, 2018, IEEE T NEUR NET LEAR, V29, P6154, DOI 10.1109/TNNLS.2018.2816743
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   Weiss, 2009, ADV NEURAL INFORM PR
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie D, 2020, IEEE T IMAGE PROCESS, V29, P3626, DOI 10.1109/TIP.2020.2963957
   Xu RC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1354, DOI 10.1145/3123266.3123392
   Zhang L, 2013, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2013.208
   Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
NR 50
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 389
EP 405
DI 10.1007/s11042-022-13141-2
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318300003
DA 2024-07-18
ER

PT J
AU Xian, YJ
   Wang, XY
   Zhang, YQ
   Yan, XP
   Leng, ZY
AF Xian, Yongjin
   Wang, Xingyuan
   Zhang, Yingqian
   Yan, Xiaopeng
   Leng, Ziyu
TI A novel chaotic image encryption with FSV based global bit-level chaotic
   permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal sorting vector; FSV based global bit-level chaotic permutation;
   Chaotic image encryption; Bit-level permutation
ID SEMI-TENSOR PRODUCT; ALGORITHM; CRYPTANALYSIS; SYSTEM
AB A novel chaotic image encryption cryptosystem presented in this paper employs a newly proposed fractal sorting vector (FSV) and FSV based global bit-level chaotic permutation (FSV-GBCP). The proposed FSV had irregularity, self-similarity, and iterability, suiting for the construction of chaotic image encryption methods of any size. Based on FSV, the global bit-level permutation effectively improved the security of the cryptographic system. The experiment results and comparisons with other bit-level permutation encryption methods show that the proposed has short runtime and good encryption effect. Therefore, the cryptosystem is sufficient to achieve the desired level of security. The newly proposed FSV and FSV-GBCP have played the positive role in promoting the field of image encryption, and this research direction is worthy of further study and attention.
C1 [Xian, Yongjin; Wang, Xingyuan; Yan, Xiaopeng; Leng, Ziyu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zhang, Yingqian] Xiamen Univ Malaysia, Sch Elect Engn & Artificial Intelligence, Sepang 43900, Malaysia.
C3 Dalian Maritime University; Guangxi Normal University; Xiamen University
   Malaysia Campus
RP Xian, YJ; Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM matxyj@163.com; xywang@dlmu.edu.cn
RI Wang, Yifan/KDO-8319-2024; feng, feng/KBR-1814-2024; Wang,
   Xing-yuan/I-6353-2015; Wang, Ling/AGR-4917-2022; , Yongjin/AAQ-6737-2021
OI Wang, Ling/0000-0003-0272-2974; , Yongjin/0000-0003-1921-049X
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City 20 Universities
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS20-M-02]
FX This study was supported by the National Natural Science Foundation of
   China (No: 61672124), Password Theory Project of the 13th Five-Year Plan
   National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), and Jinan City 20 Universities Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Alawida M, 2019, SIGNAL PROCESS, V164, P249, DOI 10.1016/j.sigpro.2019.06.013
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Es-Sabry M, 2020, SOFT COMPUT, V24, P3829, DOI 10.1007/s00500-019-04151-8
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V155, P630, DOI 10.1016/j.procs.2019.08.089
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P584, DOI 10.1016/j.procs.2019.11.043
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P491, DOI 10.1016/j.procs.2019.11.059
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P503, DOI 10.1016/j.procs.2019.11.057
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li JF, 2018, OPT LASER ENG, V102, P170, DOI 10.1016/j.optlaseng.2017.11.001
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500160
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Peng HP, 2020, IEEE INTERNET THINGS, V7, P2432, DOI 10.1109/JIOT.2019.2957747
   Popoff S, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1078
   Sarkar A, 2021, MULTIMED TOOLS APPL, V80, P799, DOI 10.1007/s11042-020-09375-7
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Shanthakumari R, 2020, MULTIMED TOOLS APPL, V79, P3975, DOI 10.1007/s11042-019-7584-6
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 39
TC 13
Z9 13
U1 8
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 407
EP 426
DI 10.1007/s11042-022-13280-6
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806683100001
DA 2024-07-18
ER

PT J
AU Shuwandy, ML
   Zaidan, BB
   Zaidan, AA
AF Shuwandy, M. L.
   Zaidan, B. B.
   Zaidan, A. A.
TI Novel authentication of blowing voiceless password for android
   smartphones using a microphone sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microphone sensor; Voiceless password; Smartphone authentication;
   Android operating system
AB This study proposed novel authentication of blowing voiceless password for Android smartphones. Experiments were conducted in three stages. First, a microphone sensor was used to solve the problems of eavesdropping of voice passwords and decoding passwords through lip movement (even behind a wall). Second, a Huawei tablet T1-701u device was used to test the developed authentication app. Third, pattern analysis was utilised by two metrics (i.e. false rejection rate [FRR] and false acceptance rate [FAR]) to analyse usability. Moreover, the usability of previous authentication schemes was experimented upon using two experimental settings (i.e. controlled and uncontrolled). Age group comparison was made to enrich the analysis and provide a comprehensive insight for usability with sample size (n = 211; male = 150 and female = 61 participants). Discussion results show the following: (1) The remember rate of the first uncontrolled mode is 8.22%. (2) The remember rate of the controlled mode is 42.30%. Imposters were incapable of infiltrating phone authentication. The air blown into the microphone was not observed by imposters. Thus, imposters were unable to imitate the blowing. (3) With a microphone sensor, the FAR was lower than the FRR. (4) The average result across all age groups for both genders is 22.36%. This result is promising because it considers the environmental settings and restrictions made during the experiment.
C1 [Shuwandy, M. L.] Univ Pendidikan Sultan Idris, Dept Comp, Tanjong Malim, Perak, Malaysia.
   [Zaidan, B. B.] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr Coll Future, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
   [Zaidan, A. A.] British Univ Dubai BUiD, Fac Engn & IT, Dubai, U Arab Emirates.
C3 Universiti Pendidikan Sultan Idris; National Yunlin University Science &
   Technology
RP Zaidan, AA (corresponding author), British Univ Dubai BUiD, Fac Engn & IT, Dubai, U Arab Emirates.
EM aws.alaa@gmail.com
RI zaidan, bilal/AAJ-7841-2021; Albahri,, A. S./F-7289-2010; Shuwandy,
   Moceheb Lazam/W-8970-2019
OI Shuwandy, Moceheb Lazam/0000-0001-6257-7874; zaidan,
   bilal/0000-0001-7412-8267
CR Abate AF, 2019, IEEE T SYST MAN CY-S, V49, P469, DOI 10.1109/TSMC.2017.2698258
   Adib F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818072
   Ali Z, 2016, 2016 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2016), P272, DOI 10.1109/SPW.2016.29
   [Anonymous], 2013, P INT C ADV MOB COMP
   Aviv AJ, 2012, 28TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2012), P41
   Bajrami G, 2011, PROCEEDINGS OF THE 2011 3RD INTERNATIONAL WORKSHOP ON SECURITY AND COMMUNICATION NETWORKS (IWSCN 2011), P23, DOI 10.1109/IWSCN.2011.6827713
   Chen HX, 2020, IEEE INTERNET THINGS, V7, P2152, DOI 10.1109/JIOT.2019.2959203
   Chen SX, 2014, MOBISYS'14: PROCEEDINGS OF THE 12TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P109, DOI 10.1145/2594368.2594373
   Dandachi G, 2013, I CON ADV BIOMED ENG, P235, DOI 10.1109/ICABME.2013.6648891
   Derawi Mohammad O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P312, DOI 10.1109/IIHMSP.2010.84
   Ehatisham-ul-Haq M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092043
   Fawaz K, 2020, System and method for authenticating voice commands for a voice assistant.Pdf, Patent No. [US10566007B2, 10566007]
   Feng T, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P206, DOI 10.4108/icst.mobicase.2014.257767
   Feng T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P154, DOI 10.1109/THS.2013.6698992
   Guerra-Casanova J, 2012, INT J INF SECUR, V11, P65, DOI 10.1007/s10207-012-0154-9
   Guerra-Casanova J, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413560065
   Haque MM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P735, DOI 10.1109/THS.2013.6699095
   Hoang T, 2013, J INF PROCESS SYST, V9, P333, DOI 10.3745/JIPS.2013.9.2.333
   Hussain M, 2016, PERVASIVE MOB COMPUT, V25, P1, DOI 10.1016/j.pmcj.2015.12.001
   Lee WH, 2015, COMM COM INF SC, V576, P160, DOI 10.1007/978-3-319-27668-7_10
   Ling Z, 2016, IEEE INFOCOM SER
   Liu Q, 2016, INT CONF SYST INFORM, P324, DOI 10.1109/ICSAI.2016.7810976
   Lyu C, 2015, IEEE INT CONF MOB, P172, DOI 10.1109/MASS.2015.33
   Maghsoudi J, 2016, EUR INTELL SECUR INF, P184, DOI [10.1109/EISIC.2016.047, 10.1109/EISIC.2016.32]
   Muaaz M, 2015, LECT NOTES COMPUT SC, V9520, P731, DOI 10.1007/978-3-319-27340-2_90
   Nguyen H, 2016, GEN AUTHENTICATION S, DOI 386407
   Nickel C, 2011, BIOSIG5766
   Nickel C, 2013, IEEE AERO EL SYS MAG, V28, P29, DOI 10.1109/MAES.2013.6642829
   Nixon KW, 2013, ASIA S PACIF DES AUT, P384, DOI 10.1109/ASPDAC.2013.6509626
   Park JG, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P113
   Petry NM, 2002, GERONTOLOGIST, V42, P92, DOI 10.1093/geront/42.1.92
   Pisani PH, 2017, INTELL DATA ANAL, V21, P353, DOI 10.3233/IDA-150403
   Pisani PH, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P336, DOI 10.1109/BRACIS.2014.67
   Rahman F, 2014, 2014 IEEE EIGHTH INTERNATIONAL CONFERENCE ON SOFTWARE SECURITY AND RELIABILITY - COMPANION (SERE-C 2014), P121, DOI 10.1109/SERE-C.2014.30
   Roshandel M, 2015, EMERGING PERSPECTIVE, DOI 10.4018/978-1-4666-8583-3.ch003
   Sanzgiri Ameya, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P879, DOI 10.1109/ICCNC.2013.6504205
   Seongil Lee, 2012, 2012 15th International Conference on Network-Based Information Systems (NBiS 2012), P760, DOI 10.1109/NBiS.2012.136
   Shih DH, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P31, DOI 10.1109/ICCSS.2015.7281144
   Shila DM, 2016, 2016 IEEE SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY (HST)
   Shuwandy ML, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1149-5
   Sun ZW, 2016, SECUR COMMUN NETW, V9, P1359, DOI 10.1002/sec.1422
   Wang GH, 2016, IEEE T MOBILE COMPUT, V15, P2907, DOI 10.1109/TMC.2016.2517630
   Wang H, 2015, SENSOR BASED USER AU, Patent No. 168185
   Wei T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P130, DOI 10.1145/2789168.2790119
   Witte H, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P29, DOI 10.1109/EST.2013.38
   Yang HJ, 2015, IEEE ICC, P7139, DOI 10.1109/ICC.2015.7249465
   Zheng N, 2014, I C NETWORK PROTOCOL, P221, DOI 10.1109/ICNP.2014.43
   Zhong Y, 2015, INT CONF BIOMETR THE
   Zhu J, 2013, INT CONF COMPUT NETW
NR 49
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44207
EP 44243
DI 10.1007/s11042-022-13264-6
EA JUN 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000804560400003
DA 2024-07-18
ER

PT J
AU Dhall, S
   Gupta, S
AF Dhall, Sangeeta
   Gupta, Shailender
TI Quantum based robust and swift hybrid security mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Confusion; Diffusion; Key scheduling algorithm; Lifting
   wavelet transform (LWT); Quantum; Steganography
ID MULTIPLE WATERMARKING; MEDICAL IMAGES
AB Intact communication of covert information is the key requirement of all the applications like medical, military, business transactions. For that matter need for a proficient security mechanism is apparent. This paper proposes a hybrid design containing Quantum based confusion and diffusion processes followed by Lifting Wavelet Transform (LWT) steganography mechanism. Moreover, a provisional compression mechanism is also employed. Secret data is initially checked for the frequency of characters, which is the decisive factor for the inclusion of compression operation. This data undergoes a bit-level confusion stage, with the help of a random key generated by Quantum based key scheduling algorithm. The subsequent process is diffusion, in which each perplexed bit undergoes XOR operation with random keys generated by a centralized key generation mechanism. Finally, this data is embedded into the Lifting Wavelet Transformed cover image. The mingled data bits are stored at random locations of carrier Image, ready to commune in an insecure site. The usage of simple and effective stages provides time efficiency, robustness, and power of confidentiality predominantly in a highly effective way compared to the available mechanism. Implementation using MATLAB shows that secret information is highly secure.
C1 [Dhall, Sangeeta; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM sangeeta_dhall@yahoo.co.in; shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   [Anonymous], 2014, 2014 INT C INFORMATI
   Bal SN, 2021, J KING SAUD UNIV-COM, V33, P552, DOI 10.1016/j.jksuci.2018.04.006
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Chaudhary Divya, 2016, International Journal of Information Privacy, Security and Integrity, V2, P216
   Dhall Sangeeta, 2016, International Journal of Computer Network and Information Security, V8, P67, DOI 10.5815/ijcnis.2016.06.08
   Dhall S, 2021, MULTIMED TOOLS APPL, V80, P18069, DOI 10.1007/s11042-021-10531-w
   Dhall S, 2020, MULTIMED TOOLS APPL, V79, P1987, DOI 10.1007/s11042-019-08223-7
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gholipour M, 2011, COMM COM INF SC, V166, P161
   Jain Yamini, 2018, Cyber Security. Proceedings of CSI 2015. Advances in Intelligent Systems and Computing (AISC 729), P131, DOI 10.1007/978-981-10-8536-9_14
   Jain Y, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON RECENT DEVELOPMENTS IN CONTROL, AUTOMATION & POWER ENGINEERING (RDCAPE), P220, DOI [10.1109/RDCAPE47089.2019.8979017, 10.1109/rdcape47089.2019.8979017]
   Kannammal A, 2014, INT J IMAG SYST TECH, V24, P111, DOI 10.1002/ima.22086
   Kumar Nain A., 2013, INT J COMPUT NETW CO, V5, P173, DOI [10.5121/ijcnc.2013.5414, DOI 10.5121/IJCNC.2013.5414]
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Moizuddin M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ANTI-CYBER CRIMES (ICACC), P98, DOI 10.1109/Anti-Cybercrime.2017.7905271
   Nivedhitha R, 2012, INT J ENG TRENDS TEC, P6
   Panwar P, 2021, MULTIMED TOOLS APPL, V80, P8039, DOI 10.1007/s11042-020-10083-5
   Shankar K, 2015, PROCEDIA COMPUT SCI, V70, P462, DOI 10.1016/j.procs.2015.10.080
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   TAUHID A., 2019, Journal of Information Security, V10, P117, DOI DOI 10.4236/JIS.2019.103007
   Tayal N., 2016, INT J COMPUTER NETWO, V3, P13
   Tayal N, 2017, MULTIMED TOOLS APPL, V76, P24063, DOI 10.1007/s11042-016-4111-x
   Wrona K, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P239, DOI 10.1109/WF-IoT.2016.7845511
   Yan Y., 2000, APPROACH INTEGER WAV, V5, P3
NR 31
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43727
EP 43752
DI 10.1007/s11042-022-13244-w
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805509400007
DA 2024-07-18
ER

PT J
AU Wang, WX
   Li, LM
   Zhen, Z
AF Wang, Weixing
   Li, Limin
   Zhen, Zhou
TI Road extraction in vague images on gray scale consistency and improved
   MSR and D-S evidence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vague aerial image; Road detection; MSR; Dark channel prior; Gray scale
   consistency; D-S evidence
ID AERIAL IMAGES; ENHANCEMENT; WEATHER
AB Road detection on aerial and remote sensing vague images is a hard task. In this paper, an automatic road detection method for the vague images is proposed. The method firstly uses an improved MSR algorithm to enhance image, and it automatically takes different scales in different image regions, based on the image depths obtained by the dark channel prior algorithm. Then the enhanced image is roughly segmented on the principle of the local gray scale consistency, in that, an eight-neighborhood template is considered as a processing unit in which a threshold is utilized for all the neighboring pixels of the detecting pixel. Finally, the Dempster-Shafer (D-S) evidence for road features is applied to finalize road tracing in the binary image, where, the road features include length, width, aspect ratio and fullness rate, all the parameters are obtained in the least external rectangle of a road segment, and then the detected roads are regulated. In experiments, 300 vague road images were selected for testing, by comparing to several traditional algorithms and recent semantic methods, the testing results show that the new method is satisfactory, and the detection accuracy is up to 89%.
C1 [Wang, Weixing; Li, Limin] Wenzhou Univ, Sch Elect & Elect Engn, Wenzhou 325035, Peoples R China.
   [Zhen, Zhou] Luoyang Normal Univ, Sch Informat Technol, Luoyang Henan 471934, Peoples R China.
C3 Wenzhou University; Luoyang Normal University
RP Wang, WX; Li, LM (corresponding author), Wenzhou Univ, Sch Elect & Elect Engn, Wenzhou 325035, Peoples R China.
EM wangwx@chd.edu.cn; lilimin@wzu.edu.cn
FU National Natural Science Fund in China [61170147]; National Natural
   Science Key Fund in China [U1401252]; Zhejiang Provincial Natural
   Science Foundation of China [LTY22F020003]
FX This research is financially supported by the National Natural Science
   Fund in China (grant no. 61170147) and the National Natural Science Key
   Fund in China (grant no. U1401252), and Zhejiang Provincial Natural
   Science Foundation of China (Grant No. LTY22F020003).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen JJ, 2021, MULTIMED TOOLS APPL, V80, P16473, DOI 10.1007/s11042-020-08921-7
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Ding L, 2021, IEEE T GEOSCI REMOTE, V59, P426, DOI 10.1109/TGRS.2020.2994150
   Fan LX, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716658599
   Feng DJ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13244974
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Gray M., 1988, COMPUT AIDED DESIGN, V20, P109, DOI [10.1016/0010-4485(88)90060-7, DOI 10.1016/0010-4485(88)90060-7]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He RJ, 2021, IEEE T IND ELECTRON, V68, P8687, DOI 10.1109/TIE.2020.3013783
   He ZW, 2020, IEEE T MULTIMEDIA, V22, P1042, DOI 10.1109/TMM.2019.2937688
   Hong G.-S., 2018, Journal of Multimedia Information. System, V5, P9, DOI [10.9717/JMIS.2018.5.1.9, DOI 10.9717/JMIS.2018.5.1.9]
   Hong ZL, 2018, IEEE ACCESS, V6, P46988, DOI 10.1109/ACCESS.2018.2867210
   Hu J, 2007, IEEE T GEOSCI REMOTE, V45, P4144, DOI 10.1109/TGRS.2007.906107
   Hu KL, 2017, J INTELL FUZZY SYST, V32, P1775, DOI 10.3233/JIFS-152381
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jaouen V, 2019, IEEE T IMAGE PROCESS, V28, P3075, DOI 10.1109/TIP.2018.2881838
   Kim BG, 2003, PATTERN RECOGN LETT, V24, P2995, DOI 10.1016/S0167-8655(03)00160-0
   Pandian SK, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6279
   Lamphar H, 2020, J QUANT SPECTROSC RA, V251, DOI 10.1016/j.jqsrt.2020.107060
   Lian RB, 2020, IEEE J-STARS, V13, P5489, DOI 10.1109/JSTARS.2020.3023549
   Liu K, 2021, THESIS CHANGAN U CHI
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Mcclean S, 2006, EVIDENCE DEMPSTERSHA, DOI [10.1002/0471667196.ess1039.pub2, DOI 10.1002/0471667196.ESS1039.PUB2]
   Movaghati S, 2010, IEEE T GEOSCI REMOTE, V48, P2807, DOI 10.1109/TGRS.2010.2041783
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NS, 2018, OPTIK, V163, P99, DOI 10.1016/j.ijleo.2018.02.067
   Parthasarathy S., 2012, NATL C COMMUNICATION, P1, DOI DOI 10.1109/NCC.2012.6176791
   Prahara A., 2021, INT J ARTIF INTELL R, V4, P107, DOI [10.29099/ijair.v4i2.179, DOI 10.29099/IJAIR.V4I2.179]
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shafer Glenn, 1976, A mathematical theory of evidence, V42, DOI DOI 10.2307/J.CTV10VM1QB
   Udomhunsakul S, 2004, P SOC PHOTO-OPT INS, V5239, P26, DOI 10.1117/12.508365
   Wang WX, 2021, CONSTR BUILD MATER, V271, DOI 10.1016/j.conbuildmat.2020.121885
   Wang WX, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S021969132050037X
   Wang WX, 2020, OPT LASER TECHNOL, V128, DOI 10.1016/j.optlastec.2020.106220
   Wang WX, 2020, CONSTR BUILD MATER, V237, DOI 10.1016/j.conbuildmat.2019.117750
   Wang WX, 2019, J TRAFFIC TRANSP ENG, V6, P535, DOI 10.1016/j.jtte.2019.10.001
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Wang WX, 2011, OPT ENG, V50, DOI 10.1117/1.3662398
   Xin J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212499
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Yoon T, 2002, P SOC PHOTO-OPT INS, V4545, P320, DOI 10.1117/12.453690
   Zhang SY, 2014, TRANSP LETT, V6, P197, DOI 10.1179/1942787514Y.0000000025
   Zhao QH, 2020, INT J REMOTE SENS, V41, P6183, DOI 10.1080/01431161.2020.1736731
   Zhou LY, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S021800142154032X
   Zhuang PX, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104171
NR 49
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43657
EP 43678
DI 10.1007/s11042-022-12994-x
EA MAY 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800436600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Roy, S
   Chandra, A
AF Roy, Subhabrata
   Chandra, Abhijit
TI On the detection of Alzheimer's disease using fuzzy logic based majority
   voter classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease (AD); Cerebro spinal fluid (CSF); Fuzzy logic; Grey
   matter (GM); Healthy control (HC); Magnetic resonance imaging (MRI);
   Majority voter classifier; Mild cognitive impairment (MCI); White matter
   (WM)
ID SEGMENTATION
AB Alzheimer's disease (AD) is considered to be one of the most frequent neurogenerative dementia in the elderly population. In order to improve the quality of life span, early detection of AD has drawn significant attention to the researchers throughout the globe. To this aim, this paper makes a novel attempt to classify the brain MRI images into three classes viz. Alzheimer's disease (AD), mild cognitive impairment (MCI) and healthy control (HC) using the volumetric information of white matter (WM), grey matter (GM) and cerebro spinal fluid (CSF). This classification has been accomplished with the help of fuzzy logic based approach followed by a majority voter classifier. Our proposition is finally tested over several brain MRI images collected from ADNI dataset. Supremacy of our proposition has strongly been established by measuring its performance parameters such as accuracy, sensitivity and specificity and subsequently been compared with many of the state-of-the-art methods. Simulation results have shown an average improvement of approximately 6.5%, 6.9% and 4% over a number of existing works in terms of accuracy, sensitivity and specificity respectively.
C1 [Roy, Subhabrata; Chandra, Abhijit] Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata 700106, India.
C3 Jadavpur University
RP Chandra, A (corresponding author), Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata 700106, India.
EM subhabrata_ece@yahoo.com; abhijit922@yahoo.co.in
OI Roy, Dr. Subhabrata/0000-0003-4201-2539
FU Ministry of Electronics & Information Technology; Sir Visvesvaraya Young
   Faculty Research Fellowship (YFRF) scheme [MEITY-PHD-3191]
FX This research work is funded by Ministry of Electronics & Information
   Technology, Govt. of India under Sir Visvesvaraya Young Faculty Research
   Fellowship (YFRF) scheme (Unique Awardee No. MEITY-PHD-3191).
CR Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bateman RJ, 2011, ALZHEIMERS RES THER, V3, DOI 10.1186/alzrt59
   Chandra A, 2017, MULTIMED TOOLS APPL, V76, P23957, DOI 10.1007/s11042-016-4149-9
   Demirhan A, 2015, I S BIOMED IMAGING, P126, DOI 10.1109/ISBI.2015.7163832
   Feng CY, 2019, IEEE ACCESS, V7, P63605, DOI 10.1109/ACCESS.2019.2913847
   Frozza RL, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00037
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghosh S, 2019, MULTIMED TOOLS APPL, V78, P12465, DOI 10.1007/s11042-018-6773-z
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Haouas I, 2021 IEEE INT C DESI, P16
   Khvostikov A, 2018, ARXIV 180105968
   Konar A., 2006, Computational intelligence: principles, techniques and applications
   Krashenyi I, 2015, 2015 SIGN PROC S SPS, P14
   Krashenyi I, 2016, 2016 IEEE 36 INT C E
   Lee B, 2019, IEICE T INF SYST, VE102D, P1384, DOI 10.1587/transinf.2018EDP7393
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu MH, 2018, NEUROINFORMATICS, V16, P295, DOI 10.1007/s12021-018-9370-4
   Ma XY, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00243
   Manjón JV, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00030
   NP KT, 2018, 2018 2 INT C TRENDS
   Patterson C, 2018, The state of the art of dementia research: New frontiers World Alzheimer Report 2018
   Rutegård MK, 2019, CANCER IMAGING, V19, DOI 10.1186/s40644-019-0237-1
   Sadeghi N, 2008, I S BIOMED IMAGING, P408, DOI 10.1109/ISBI.2008.4541019
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Telagarapu Prabhakar, 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P331, DOI 10.1109/CETIC4.2018.8530943
   Valverde S, 2017, MED IMAGE ANAL, V35, P446, DOI 10.1016/j.media.2016.08.014
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zekri F, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P490, DOI 10.1109/FSKD.2014.6980883
NR 32
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43145
EP 43161
DI 10.1007/s11042-022-13184-5
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900005
DA 2024-07-18
ER

PT J
AU Jawahar, M
   Prassanna, J
   Ravi, V
   Anbarasi, LJ
   Jasmine, SG
   Manikandan, R
   Sekaran, R
   Kannan, S
AF Jawahar, Malathy
   Prassanna, J.
   Ravi, Vinayakumar
   Anbarasi, L. Jani
   Jasmine, S. Graceline
   Manikandan, R.
   Sekaran, Ramesh
   Kannan, Suthendran
TI Computer-aided diagnosis of COVID-19 from chest X-ray images using
   histogram-oriented gradient features and Random Forest classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Classification; Random Forest; HOG; Features extraction
ID CORONAVIRUS
AB The decision-making process is very crucial in healthcare, which includes quick diagnostic methods to monitor and prevent the COVID-19 pandemic disease from spreading. Computed tomography (CT) is a diagnostic tool used by radiologists to treat COVID patients. COVID x-ray images have inherent texture variations and similarity to other diseases like pneumonia. Manually diagnosing COVID X-ray images is a tedious and challenging process. Extracting the discriminant features and fine-tuning the classifiers using low-resolution images with a limited COVID x-ray dataset is a major challenge in computer aided diagnosis. The present work addresses this issue by proposing and implementing Histogram Oriented Gradient (HOG) features trained with an optimized Random Forest (RF) classifier. The proposed HOG feature extraction method is evaluated with Gray-Level Co-Occurrence Matrix (GLCM) and Hu moments. Results confirm that HOG is found to reflect the local description of edges effectively and provide excellent structural features to discriminate COVID and non-COVID when compared to the other feature extraction techniques. The performance of the RF is compared with other classifiers such as Linear Regression (LR), Linear Discriminant Analysis (LDA), K-nearest neighbor (kNN), Classification and Regression Trees (CART), Random Forest (RF), Support Vector Machine (SVM), and Multi-layer perceptron neural network (MLP). Experimental results show that the highest classification accuracy (99. 73%) is achieved using HOG trained by using the Random Forest (RF) classifier. The proposed work has provided promising results to assist radiologists/physicians in automatic COVID diagnosis using X-ray images.
C1 [Jawahar, Malathy] CSIR Cent Leather Res Inst, Leather Proc Technol Div, Chennai 600020, Tamil Nadu, India.
   [Prassanna, J.; Anbarasi, L. Jani; Jasmine, S. Graceline] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
   [Manikandan, R.] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
   [Sekaran, Ramesh] Velgapudi Ramakrishna Siddhartha Engn Coll, Dept Informat Technol, Vijayawada, India.
   [Kannan, Suthendran] Kalasalingam Acad Res & Educ, Dept Informat Technol, Srivilliputhur, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Leather Research Institute (CLRI); Vellore Institute of
   Technology (VIT); VIT Chennai; Prince Mohammad Bin Fahd University;
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Velagapudi Ramakrishna Siddhartha Engineering College; Kalasalingam
   Academy of Research & Education
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM malathyj@clrires.in; prassanna.j@vit.ac.in; vravi@pmu.edu.sa;
   janianbarasi.1@vit.ac.in; graceline.jasmine@vit.ac.in;
   srmanim75@g-mail.com; sramsaran1989@gmail.com; k.suthendran@klu.ac.in
RI Jawahar, Dr. Malathy/AGF-0084-2022; Ravi, Vinayakumar/L-4202-2018;
   Suthendran, K./ABE-6015-2021; Sekaran, Dr. Ramesh/AAQ-8876-2020; L,
   J/JEF-9564-2023; l, j/JVZ-8480-2024; Ramachandran,
   Manikandan/B-2783-2014
OI Jawahar, Dr. Malathy/0000-0001-6865-2097; Suthendran,
   K./0000-0002-7030-4398; Sekaran, Dr. Ramesh/0000-0002-6668-2142;
   Ramachandran, Manikandan/0000-0001-6116-2132; L, JANI
   ANBARASI/0000-0002-8904-2236
FU CSIR-CLRI [A/2022/LPT/MLP/1667]
FX Malathy Jawahar acknowledges CSIR-CLRI for conducting this research work
   (A/2022/LPT/MLP/1667).
CR Ahmed A, 2019, PNEUMONIA SAMPLE XRA
   [Anonymous], 2020, Covid-19 chest x-ray database
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Bahoura M, 2001, IEEE SIGNAL PROC LET, V8, P10, DOI 10.1109/97.889636
   Barman U, 2022, J KING SAUD UNIV-COM, V34, P2938, DOI 10.1016/j.jksuci.2020.01.005
   Batool FE, 2024, MULTIMED TOOLS APPL, V83, P14959, DOI 10.1007/s11042-020-08851-4
   Breiman L., 2001, Mach. Learn., V45, P5
   Chen JJ, 2020, ENGINEERING-PRC, V6, P1153, DOI 10.1016/j.eng.2020.02.006
   Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1148/radiol.2020200230, 10.1007/s00330-019-06574-1]
   Cortegiani A, 2020, J CRIT CARE, V57, P279, DOI 10.1016/j.jcrc.2020.03.005
   Darlenski R, 2020, CLIN DERMATOL, V38, P785, DOI 10.1016/j.clindermatol.2020.03.012
   Hall LO, ARXIV PREPRINT ARXIV
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S., 1994, NEURAL NETWORKS COMP
   Holland Michael, 2020, Vis J Emerg Med, V19, P100740, DOI 10.1016/j.visj.2020.100740
   Hosseiny M, 2020, AM J ROENTGENOL, V214, P1078, DOI 10.2214/AJR.20.22969
   Hou J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95680-6
   Huang Z, 2010, 2010 2 INT C COMP EN, V7
   Islam Md Milon, 2020, SN Comput Sci, V1, P320, DOI 10.1007/s42979-020-00335-4
   Janeliukstis R, 2020, NONDESTRUCT TEST EVA, V35, P48, DOI 10.1080/10589759.2019.1635594
   Jawahar M., 2021, INVENTIVE COMPUTATIO, DOI [10.1007/978-981-33-4305-4_15, DOI 10.1007/978-981-33-4305-4_15]
   Kermany Daniel, 2018, Mendeley Data, V2
   Lai CC, 2020, J MICROBIOL IMMUNOL, V53, P404, DOI 10.1016/j.jmii.2020.02.012
   Lau H, 2020, J MICROBIOL IMMUNOL, V53, P454, DOI 10.1016/j.jmii.2020.03.013
   Li C, 2020, INFECT GENET EVOL, V82, DOI 10.1016/j.meegid.2020.104285
   Li ZY, 2020, BRAIN BEHAV IMMUN, V88, P916, DOI 10.1016/j.bbi.2020.03.007
   Lippi G, 2020, CLIN CHIM ACTA, V506, P145, DOI 10.1016/j.cca.2020.03.022
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Özcan C, 2020, TURK J ELECTR ENG CO, V28, P182, DOI 10.3906/elk-1904-7
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Rahbari D, 2020, PEER PEER NETW APPL, V13, P104, DOI 10.1007/s12083-019-00721-7
   Rahman T., 2020, COVID-19 radiography dataset
   Rizal RA, 2020, SINKRON, V15, P692
   Rodriguez-Morales AJ, 2020, TRAVEL MED INFECT DI, V34, DOI 10.1016/j.tmaid.2020.101623
   Sahin EK, 2020, GEOCARTO INT, V35, P341, DOI 10.1080/10106049.2018.1516248
   Sharon jJ, 2018, 2018 5 HCT INFORM TE
   Shereen MA, 2020, J ADV RES, V24, P91, DOI 10.1016/j.jare.2020.03.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Sousa RT, 2013, PROCEDIA COMPUT SCI, V18, P2579, DOI 10.1016/j.procs.2013.05.444
   Tan J, 2020, MED IMAGING 2020 COM, V11314
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Tuncer T, 2020, CHEMOMETR INTELL LAB, V203, DOI 10.1016/j.chemolab.2020.104054
   Ullah Shah Muhammad Azmat, 2021, SN Comput Sci, V2, P18, DOI 10.1007/s42979-020-00401-x
   Yang P, 2020, J INFECTION, V80, P684, DOI 10.1016/j.jinf.2020.02.024
   Zhang JF, 2020, INT J INFECT DIS, V97, P212, DOI 10.1016/j.ijid.2020.03.007
   Zu ZY, 2020, RADIOLOGY, V296, pE15, DOI 10.1148/radiol.2020200490
NR 47
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40451
EP 40468
DI 10.1007/s11042-022-13183-6
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793007000002
PM 35572385
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Popov, PA
   Laganière, R
AF Popov, Pavel A.
   Laganiere, Robert
TI Long Hands gesture recognition system: 2 step gesture recognition with
   machine learning and geometric shape analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SVM; Adaboost; HOG; Hand gesture recognition; MobileNets; Neural
   network; Shape signature; Contour shape analysis; Adaptive colour
   segmentation
ID COMMUNICATION; TRACKING
AB A two stage real-time hand gesture recognition system is presented. It combines a machine learning trained detection step with a colour processing contour shape validation step. The detection step is done with either Adaboost Cascades or Support Vector Machines using HOG features. The system achieves a low false positive rate and a sufficient true positive rate necessary for robust real-time performance. It performs well compared to MobileNets a state of the art Neural Network for mobile real-time applications.
C1 [Popov, Pavel A.; Laganiere, Robert] Univ Ottawa, Ottawa, ON K1N 6N5, Canada.
   [Popov, Pavel A.] CNR, Ottawa, ON K1A 0R6, Canada.
C3 University of Ottawa; National Research Council Canada
RP Popov, PA (corresponding author), Univ Ottawa, Ottawa, ON K1N 6N5, Canada.; Popov, PA (corresponding author), CNR, Ottawa, ON K1A 0R6, Canada.
EM Pavel.Popov@nrc-cnrc.gc.ca; laganier@eecs.uottawa.ca
RI Laganiere, Robert/H-9138-2013
OI Popov, Pavel/0000-0003-1127-0842
FU Natural Sciences and Engineering Research Council; Mitacs; Ontario
   Graduate Scholarships
FX The authors would like to thank the Natural Sciences and Engineering
   Research Council, Mitacs, and Ontario Graduate Scholarships, for their
   support in funding this project.
CR Adthya V., 2020, Procedia Computer Science, V171, P2353, DOI 10.1016/j.procs.2020.04.255
   Agrawal, 2011, MULTIMEDIA SIGNAL PR
   Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   [Anonymous], 2013, ADV SOFTW ENG, DOI DOI 10.1155/2013/707248
   [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174264
   Bernardis P, 2006, NEUROPSYCHOLOGIA, V44, P178, DOI 10.1016/j.neuropsychologia.2005.05.007
   Bhowmick S, 2015, 2015 IEEE 2 INT C RE
   Chen L-M., 2013, 2012 8 INT C, V284-287, P490
   Chen Y., 1947, RES IMPLEMENTATION S, P1951
   Chernyshov V., 2016, Pattern Recognition and Image Analysis, V26, P368, DOI 10.1134/S1054661816020048
   Chochai P, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P931, DOI 10.1109/ROBIO.2014.7090452
   Ciuffani BM., 2017, 9 IBA BACH THES C 20
   Cook SW, 2018, ENHANCING LEARNING H, V69
   Costanzo C., 2003, Proceedings International Parallel and Distributed Processing Symposium, DOI 10.1109/IPDPS.2003.1213222
   Crisnapati PN, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEM (ICORIS), P263, DOI [10.1109/ICORIS.2019.8874892, 10.1109/icoris.2019.8874892]
   Dagnes N, 2018, MACH VISION APPL, V29, P789, DOI 10.1007/s00138-018-0933-z
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dollr P, 2010, PROC IEEE COMPUT SOC
   Fan X, 2016, PATTERN RECOGN LETT, V83, P395, DOI 10.1016/j.patrec.2016.07.005
   Fu XG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P838, DOI 10.1109/SmartCity.2015.172
   Ghosh DK, 2015, INT CONF COMM SYST, P1094, DOI 10.1109/CSNT.2015.18
   Ghosh DK, 2016, SIGNAL IMAGE VIDEO P, V10, P655, DOI 10.1007/s11760-015-0790-4
   Goldin-Meadow S, 1999, TRENDS COGN SCI, V3, P419, DOI 10.1016/S1364-6613(99)01397-2
   Guo J, 2013, IEEE IMAGE PROC, P4108, DOI 10.1109/ICIP.2013.6738846
   Han MM, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P287, DOI 10.1109/SNPD.2016.7515915
   Hasan H, 2014, ARTIF INTELL REV, V41, P147, DOI 10.1007/s10462-011-9303-1
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsieh CC, 2015, J REAL-TIME IMAGE PR, V10, P357, DOI 10.1007/s11554-012-0295-0
   Hu KN, 2019, IEEE IMAGE PROC, P3422, DOI [10.1109/ICIP.2019.8803472, 10.1109/icip.2019.8803472]
   Huang DA, 2015, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.2015.7298666
   Hui Li, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P271, DOI 10.1109/IHMSC.2012.75
   Hwang CL, 2011, C PROC IEEE INT C SY
   Inmoonnoy V, 2017, MESSAGE NOTIFICATION
   Islam MZ, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P324, DOI [10.1109/iciev.2019.8858563, 10.1109/ICIEV.2019.8858563]
   Jalab HA., 2015, P 5 NAT S INF TECHN, P1
   Kapidis G, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P922, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00185
   Kerdvibulvech C., 2015, Pattern Recognition and Image Analysis, V25, P437, DOI 10.1134/S1054661815030098
   Khamis S, 2015, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2015.7298869
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Krauss RM, 1996, ADV EXP SOC PSYCHOL, V28, P389, DOI 10.1016/S0065-2601(08)60241-5
   Lee J., 2004, HAND, V1513, P1516
   Lekova AK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P505, DOI 10.1109/ICIIP.2013.6707644
   Li CY, 2017, IEEE INT CONF COMP V, P631, DOI 10.1109/ICCVW.2017.80
   Liu CY, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P229, DOI [10.1109/itnec.2019.8729147, 10.1109/ITNEC.2019.8729147]
   Liu JQ, 2019, IEEE IMAGE PROC, P375, DOI [10.1109/ICIP.2019.8802970, 10.1109/icip.2019.8802970]
   Liu Y., 2008, STATIC HAND GESTURE, V517, P521
   Liu Z., 2014, VISUAL GESTURE RECOG, DOI [10.1109/SMC.2014.6974231, DOI 10.1109/SMC.2014.6974231]
   Messom Christopher H., 2009, International Journal of Intelligent Systems Technologies and Applications, V7, P40, DOI 10.1504/IJISTA.2009.025105
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Mueller F, 2018, PROC IEEE COMPUT SOC, P4959
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   Nguyen DD., 2016, KINECT GESTURE RECOG, V395, P400
   Nölker C, 2002, IEEE T NEURAL NETWOR, V13, P983, DOI 10.1109/TNN.2002.1021898
   Oberweger M., 2015, Hands deep in deep learning for hand pose estimation, P21, DOI DOI 10.1177/0093650215617505
   Pang Y, 2014, DISTRIBUTED OBJECT D, V44
   Panwar M, 2012, COMPUTING COMMUNICAT, P16
   Park G, 2020, IEEE T VIS COMPUT GR, V26, P1891, DOI 10.1109/TVCG.2020.2973057
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Popov PA, 2018, GR CASCADE SYSTEM DE
   Popov PA, 2015, LONG HANDS GESTURE R
   Popov PA, GR PAINT APP PRESENT
   Popov PA, LONG HANDS GESTURE R
   Popov PA, 2020, REAL TIME 2D STATIC, DOI [10.20381/ruor-25778, DOI 10.20381/RUOR-25778]
   Popov PA, 2018, GR SVM SYSTEM DEMONS
   Popov PA, 2020, LONG HANDS GESTURE R
   Popov PA, 2019, HAND GESTURE RECOGNI
   Qian C., 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145
   Raheja J. L., 2016, Pattern Recognition and Image Analysis, V26, P434, DOI 10.1134/S1054661816020164
   Rautaray SiddharthSwarup., 2012, INT J INTELLIGENT SY, V5, P56, DOI DOI 10.5815/IJISA.2012.05.08
   Rautaray SS, 2012, TECHNOLOGY ENHANCED, P16
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Roy K., 2017, DEEP LEARNING BASED, V640, P649
   Rumyantsev O, 2012, IMAGE PROCESS
   Sahoo JP, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P221, DOI 10.1109/iSES47678.2019.00056
   Sefat MS, 2015, 2 INT C EL ENG INF C, P2123
   Sepas-Moghaddam A, 2020, IET BIOMETRICS, V9, P58, DOI 10.1049/iet-bmt.2019.0001
   Sheenu Joshi G, 2015, INT C COMP COMM AUT
   Spruyt V, 2013, IMAGE PROCESSING ICI
   Spruyt V, 2012, IEEE IMAGE PROC, P149, DOI 10.1109/ICIP.2012.6466817
   Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Uwineza J., 2019, LNAI
   Nguyen VT, 2014, PROCEDIA COMPUT SCI, V39, P154, DOI 10.1016/j.procs.2014.11.023
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wang F, 2016, IEEE ANN INT CONF CY, P115, DOI 10.1109/CYBER.2016.7574806
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Wu W, EGOCENTRIC FINGERTIP
   Xingbao Meng, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P2593, DOI 10.1109/ICSAI.2012.6223584
   Yang ZQ, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P931, DOI 10.1109/ITNEC.2016.7560498
   Yanguo Zhao, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1715, DOI 10.1109/ROBIO.2012.6491215
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Yewale, 2011, 2011 INT C EM TRENDS, V1998
   Yuan Q, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P250
NR 95
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40311
EP 40342
DI 10.1007/s11042-022-12870-8
EA MAY 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Naz, S
   Bibi, K
   Ahmad, R
AF Naz, Saeeda
   Bibi, Kiran
   Ahmad, Riaz
TI DeepSignature: fine-tuned transfer learning based signature verification
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Offline signature verification; Deep learning; Transfer learning; CNN
ID DEEP; IDENTIFICATION; FEATURES
AB With the rapid advancement in computer science and information technology, the demand for authentication of a person in different organizations, institutions, banks or online trading, etc. is increasing day by day. Similarly, signature verification and recognition systems are frequently used for forgery and fraud detection. Signature authentication and verification have been important bio-metric traits for many decades. In this article, Convolutional Neural Network (CNN) architectures namely AlexNet, GoogleNet, ResNet, MobileNet, and DenseNet are examined and compared. Further, a fine-tuned transfer learning-based approach is also investigated to verify and identify the offline images of signatures. The evaluation has been done using Persian signatures of different persons using the UTSig dataset as a benchmark. The experimental analyses demonstrate that DenseNet architecture outperformed the other architectures of CNN.
C1 [Naz, Saeeda; Bibi, Kiran] Govt Girls Postgrad Coll 1 Abbottabad, Comp Sci Dept, Higher Educ Dept, Kp, Pakistan.
   [Ahmad, Riaz] Shaheed Benazir Bhutto Univ, Comp Sci Dept, Sheringal, KP, Pakistan.
RP Naz, S (corresponding author), Govt Girls Postgrad Coll 1 Abbottabad, Comp Sci Dept, Higher Educ Dept, Kp, Pakistan.
EM saeedanaz292@gmail.com; zara44831@gmail.com; riaz77@gmail.com
RI Ahmad, Riaz/AAV-2148-2021
OI Ahmad, Riaz/0000-0003-2465-8221
CR AbdelRaouf A, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P319, DOI 10.1109/ICCES.2018.8639437
   Ahmad R, 2021, PATTERN RECOGN LETT, V152, P93, DOI 10.1016/j.patrec.2021.09.014
   Alajrami E., 2020, Int. J. Acad. Multidiscip. Res, V3, P39, DOI 10.1016/j.patcog.2017.05.012
   Alvarez G., 2016, OFFLINE SIGNATURE VE
   Ashraf A, 2021, MULTIMED TOOLS APPL, V80, P30117, DOI 10.1007/s11042-020-10331-8
   Chaabouni S, 2019, J VIS COMMUN IMAGE R, V60, P79, DOI 10.1016/j.jvcir.2019.02.004
   Cozzens B, SIGNATURE VERIFICATI
   FOROUSHANI AN, 2020, 2020 IEEE INT S CIRC, P1, DOI DOI 10.1109/ISCAS45731.2020.9181250
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Hafemann LG, 2016, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2016.7900092
   Hafemann LG, 2016, IEEE IJCNN, P2576, DOI 10.1109/IJCNN.2016.7727521
   Justino E., 2000, International Workshop on Document Analysis Systems, P211
   Kamran I, 2021, FUTURE GENER COMP SY, V117, P234, DOI 10.1016/j.future.2020.11.020
   Karouni A, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.027
   Khalajzadeh H., 2012, International Journal of Engineering Research and Technology, V1
   Kiani V, 2009, INT J IMAGE PROCESS, P3
   Liwicki M, 2011, PROC INT CONF DOC, P1480, DOI 10.1109/ICDAR.2011.294
   Mersa O., 2019, 2019 INT C PATTERN R, P268, DOI [10.1109/PRIA. 2019.8785979, DOI 10.1109/PRIA.2019.8785979]
   Naseer A, 2020, NEURAL COMPUT APPL, V32, P839, DOI 10.1007/s00521-019-04069-0
   Naz S, 2022, MULTIMEDIA SYST, V28, P85, DOI 10.1007/s00530-021-00797-3
   Naz S, 2017, NEUROCOMPUTING, V243, P80, DOI 10.1016/j.neucom.2017.02.081
   Naz S, 2017, NEURAL COMPUT APPL, V28, P219, DOI 10.1007/s00521-015-2051-4
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Rani R, 2016, GENETIC ALGORITHM US
   Razzak I, 2022, IEEE ACM T COMPUT BI, V19, P1225, DOI 10.1109/TCBB.2020.3039358
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rehman A, 2022, MULTIMEDIA SYST, V28, P1339, DOI 10.1007/s00530-020-00736-8
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   Ruiz V, 2020, NEUROCOMPUTING, V374, P30, DOI 10.1016/j.neucom.2019.09.041
   Soleimani A, 2016, 2016 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P147, DOI 10.1109/ICCKE.2016.7802131
   Soleimani A, 2017, IET BIOMETRICS, V6, P1, DOI 10.1049/iet-bmt.2015.0058
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Wencheng C., 2017, International Conference on Advanced Hybrid Information Processing, P33
NR 35
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38113
EP 38122
DI 10.1007/s11042-022-12782-7
EA APR 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700010
DA 2024-07-18
ER

PT J
AU Agarwal, N
   Tayal, DK
AF Agarwal, Nidhi
   Tayal, Devendra K.
TI FFT based ensembled model to predict ranks of higher educational
   institutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prediction system; University ranking; Entity ensemble model; Machine
   learning; Hybrid model; Bagging; Fast fourier transformation
ID UNIVERSITY RANKINGS; CLASSIFICATION; IMPACT
AB Predicting international rankings has always been a demanding area for Universities and Higher Educational Institutions (HEIs) all over the world in the recent decade. In this research work, a novel tool EnFftRP (Ensembled Fast Fourier Transformed Ranking Prediction) is developed for predicting international ranks of various universities and HEIs. It uses a hybrid ensembled model in duology with the Fast Fourier Transformation (FFT). Ensemble model improves the prediction accuracies which are elevated further using FFT. The fourier processing algorithm, being an influential computational concept for data anatomy is a novel approach applied to the ensembled model. A combination of six base models Decision Tree, Support Vector Machine, Multilayer Perceptron, K-Nearest Neighbour, Random Forest and Logistic Regression are deployed for the construction of ensembled model. The data set being used is Shanghai World Ranking University Dataset for 14 years ranging from 2005 to 2018. It is split into training and test data set. The training data set is considered from year 2005-2014 and the test dataset from 2015 to 2018. It is empirically established that proposed tool produces highly promising prediction parameters as accuracies (95%), specificities (94.41%), sensitivities (95.54%), Productively Predicted Values (94.94%), Non-Productively Predicted Values (95.07%), F1-score (97.40%) and Kappa score (0.90) as compared to obtained by similar models like RSFT and others. To the best of our knowledge, till now no tool exists which can predict the ranks of HEIs with this much high predictive power.
C1 [Agarwal, Nidhi; Tayal, Devendra K.] IGDTUW, Comp Sci & Engn, Delhi, India.
   [Agarwal, Nidhi] KIET Grp Inst, Ghaziabad, Uttar Pradesh, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); KIET Group
   of Institutions
RP Tayal, DK (corresponding author), IGDTUW, Comp Sci & Engn, Delhi, India.
EM nidhiagarwal82@gmail.com; devendrakumartayal@gmail.com
RI AGARWAL, NIDHI/AIA-5341-2022; AGARWAL, NIDHI/GPX-4804-2022
OI AGARWAL, NIDHI/0000-0002-9044-8989; 
CR Abedini M, 2019, GEOCARTO INT, V34, P1427, DOI 10.1080/10106049.2018.1499820
   Abramo G, 2015, J INFORMETR, V9, P915, DOI 10.1016/j.joi.2015.09.001
   Agrawal, 2017, J ENV SCI COMPUTER S, V6, P122
   Ahmed FS, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02509-7
   [Anonymous], 2021, SHANGHAI WORLD U RAN
   [Anonymous], 2015, TIMES WORLD U RANKIN
   [Anonymous], 2021, QS WORLD U RANKINGS
   [Anonymous], 2015, Ranking Web of University
   Ashidi N., 2005, APPL SOFT COMPUT, V11, P1466
   Basha AJ, 2021, J AMB INTEL HUM COMP, V12, P6189, DOI 10.1007/s12652-020-02188-4
   BASHIR S, 2018, COMPUT INTELL-US, V32
   Pham BT, 2019, CATENA, V175, P203, DOI 10.1016/j.catena.2018.12.018
   Björneborn L, 2004, J AM SOC INF SCI TEC, V55, P1216, DOI 10.1002/asi.20077
   Brentan BM, 2017, J COMPUT APPL MATH, V309, P532, DOI 10.1016/j.cam.2016.02.009
   Çakur MP, 2015, SCIENTOMETRICS, V103, P813, DOI 10.1007/s11192-015-1586-6
   Calero-Medina C, 2008, RES EVALUAT, V17, P71, DOI 10.3152/095820208X280907
   Chen XB, 2021, MULTIMED TOOLS APPL, V80, P23073, DOI 10.1007/s11042-020-09103-1
   Das R, 2009, EXPERT SYST APPL, V36, P7675, DOI 10.1016/j.eswa.2008.09.013
   Deshmukh, 2017, J EMERGING TECHNOLOG, V6, P38
   Ji Y, 2015, ENERG BUILDINGS, V97, P33, DOI 10.1016/j.enbuild.2015.03.048
   Jiang XW, 2020, ARAB J SCI ENG, V45, P9859, DOI 10.1007/s13369-020-04758-2
   Huang CK, 2020, QUANT SCI STUD, V1, P445, DOI 10.1162/qss_a_00031
   Khamala, 2018, WEBOMETRICS RANKING
   Khurana A, 2020, MULTIMED TOOLS APPL, V79, P23821, DOI 10.1007/s11042-020-09013-2
   Kovacs Peter, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5839, DOI 10.1109/ICASSP.2014.6854723
   Kunosic, 2014, WIRELESS COMMUNICATI, V25, DOI 10.5772/intechopen87207
   Laradji IH, 2015, INFORM SOFTWARE TECH, V58, P388, DOI 10.1016/j.infsof.2014.07.005
   Ma YY, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02816-z
   Madasu A, 2020, MULTIMED TOOLS APPL, V79, P6313, DOI 10.1007/s11042-019-08409-z
   Marginson S., 2007, Journal of Studies in International Education, V11, P306, DOI [10.1177/1028315307303544, DOI 10.1177/1028315307303544]
   Maruf S, 2016, ARAB J SCI ENG, V41, P951, DOI 10.1007/s13369-015-1945-x
   Meho LI, 2020, QUANT SCI STUD, V1, P824, DOI 10.1162/qss_a_00045
   Mingers J, 2017, SCIENTOMETRICS, V113, P1627, DOI 10.1007/s11192-017-2532-6
   Moed HF, 2017, SCIENTOMETRICS, V110, P967, DOI 10.1007/s11192-016-2212-y
   Mosavi, 2020, IEEE ACCESS, DOI 10.1109/ACCESS20203014816
   Moskovkin V.M., 2013, MIDDLE EAST J SCI RE, V18, P1656, DOI DOI 10.5829/idosi.mejsr.2013.18.11.70120
   Naqvi SR., 2014, J ELECT ENG ED, V56, P162
   Odan FK, 2012, J WATER RES PLAN MAN, V138, P245, DOI 10.1061/(ASCE)WR.1943-5452.0000177
   Pan H, 2020, MULTIMED TOOLS APPL, V79, P31451, DOI 10.1007/s11042-020-09475-4
   Pedregosa F., 2005, LEARN RES, V12
   Piro FN, 2016, SCIENTOMETRICS, V109, P2263, DOI 10.1007/s11192-016-2056-5
   Qureshi MS, 2021, SCIENTOMETRICS, V126, P8331, DOI 10.1007/s11192-021-04138-z
   Robinson-Garcia N, 2019, RES EVALUAT, V28, P232, DOI 10.1093/reseval/rvz014
   Samiee K, 2015, IEEE T BIO-MED ENG, V62, P541, DOI 10.1109/TBME.2014.2360101
   Sebti A, 2017, MULTIMED TOOLS APPL, V76, P23589, DOI 10.1007/s11042-016-4129-0
   Selten F, 2020, QUANT SCI STUD, V1, P1109, DOI 10.1162/qss_a_00052
   Sheeja NK, 2018, GLOB KNOWL MEM COMMU, V67, P154, DOI 10.1108/GKMC-11-2017-0087
   Singh K, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01613-7
   Tabassum A, 2017, INT CONF KNOWL SMART, P126, DOI 10.1109/KST.2017.7886119
   Tsai CL, 2016, ENERG BUILDINGS, V127, P301, DOI 10.1016/j.enbuild.2016.05.083
   Uslu B, 2020, HIGH EDUC, V80, P949, DOI 10.1007/s10734-020-00527-0
   Viji C, 2021, J AMB INTEL HUM COMP, V12, P6527, DOI 10.1007/s12652-020-02267-6
   Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29
   Winster SG, 2021, J AMB INTEL HUM COMP, V12, P5709, DOI 10.1007/s12652-020-02373-5
   Yang AYQ, 2020, MULTIMED TOOLS APPL, V79, P18767, DOI 10.1007/s11042-020-08746-4
   Ying, 2015, J ELECT ENG ED, P1
   Yumng, 2015, J ELECT ENG ED, P1
   Zhang J, 2017, IEEE ACCESS, V5, P10674, DOI 10.1109/ACCESS.2017.2706318
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
   Zhenhai, 2012, J YANBIAN U NATURAL, V38
NR 60
TC 4
Z9 4
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34129
EP 34162
DI 10.1007/s11042-022-13180-9
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679100002
DA 2024-07-18
ER

PT J
AU Dey, R
   Bhattacharjee, D
   Krejcar, O
AF Dey, Ratnadeep
   Bhattacharjee, Debotosh
   Krejcar, Ondrej
TI Detection of images degraded by rain using image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IQA; Quality metric for rainy images; Weather degradation; Security and
   surveillance; Detection of degraded scenes; No-reference IQA
ID NATURAL SCENE STATISTICS
AB Various weather conditions degrade images, and hence the quality of the images is compromised to a large extent. Atmospheric conditions like Rain, Fog, Haze, Mist, etc., degrade scenes, and the scene's acquisition results in noisy images. The noisy images have less visibility than regular images. Therefore, the images degraded by the weather conditions need some special attention before processing them. Otherwise, the processing of noisy images using the same process applied for noise-free images cannot find the desired results. Hence, the identification of images degraded by weather conditions is essential before further processing. Rain is one of the most complex atmospheric conditions that degraded images. In the case of rain, water droplets present in the air are visible, wherein,in other atmospheric conditions, water droplets cannot be seen. In rainy images, the large size of water droplets in the air causes more complex degradation. This research paper has proposed a technique for detecting images degraded by rain using an image quality assessment approach. We have used no-reference image quality assessment techniques for this work. We have proposed an image quality metric specially designed for the images degraded by rain. We have used the proposed metric along with other state-of-the-art metrics for identifying rainy images. Our proposed technique has been evaluated using a public dataset containing about 1500 images. We found promising results by applying our technique to that dataset to detect images degraded by rain. This technique can help security and surveillance applications, where the automatic selection of degraded frames is crucial.
C1 [Dey, Ratnadeep; Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Maulik Rd, Kolkata 700032, India.
   [Bhattacharjee, Debotosh; Krejcar, Ondrej] Univ Hradec Kralove, Fac Informat & Management, Ctr Basic & Appl Sci, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
   [Krejcar, Ondrej] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
C3 Jadavpur University; University of Hradec Kralove; Universiti Teknologi
   Malaysia
RP Dey, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Maulik Rd, Kolkata 700032, India.
EM ratnadipdey@gmail.com; debotoshb@hotmail.com; ondrej.krejcar@uhk.cz
RI Bhattacharjee, Debotosh/Q-4065-2019; Bhattacharjee,
   Debotosh/L-8521-2015; Krejcar, Ondrej/A-8639-2008
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Krejcar, Ondrej/0000-0002-5992-2574
FU DRDO, GoI [ERIP/ER/DG-Med & CoS/990116507/M/01/1716]; DST, GOI
   [INT/AUSTRIA/BMWF/P-25/2018]; SPARC project - MHRD, GOI [231]; Grant
   Agency of Excellence, University of Hradec Kralove, Faculty of
   Informatics and Management, Czech Republic
FX The first author is grateful to the DRDO, GoI, for providing Junior
   Research Fellowship (JRF) (Letter No. ERIP/ER/DG-Med &
   CoS/990116507/M/01/1716. The authors are thankful forthe IndoAustrian
   joint project grant No. INT/AUSTRIA/BMWF/P-25/2018 funded by the DST,
   GOI, and the SPARC project (ID: 231) funded by MHRD, GOI. This work was
   also supported in part by the project of Grant Agency of Excellence,
   University of Hradec Kralove, Faculty of Informatics and Management,
   Czech Republic.
CR [Anonymous], 2020, IMAGE DERAINING DATA
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Cunningham P., 2007, MULTIPLE CLASSIFIER, V34, P1, DOI DOI 10.1145/3459665
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P946, DOI 10.1109/GlobalSIP.2014.7032260
   HEARST MA, IEEE INTELL SYST APP
   Jiang K, 2021, IEEE T CIRC SYST VID, V31, P3981, DOI 10.1109/TCSVT.2020.3044887
   Khare V, 2016, INT C PATT RECOG, P4023, DOI 10.1109/ICPR.2016.7900263
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Ong E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P545
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Suthaharan S, 2009, SIGNAL PROCESS, V89, P1647, DOI 10.1016/j.sigpro.2009.02.007
   TIAN L, 2013, IEEE INT C BIOINFORM, pNI354
   Tong, 2004, P IEEE INT C IM PROC, P24
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Yang LP, 2016, IEEE IMAGE PROC, P2042, DOI 10.1109/ICIP.2016.7532717
NR 28
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35445
EP 35461
DI 10.1007/s11042-022-13041-5
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000784679300018
DA 2024-07-18
ER

PT J
AU Yan, L
   Wang, XC
   Wu, ZK
AF Yan, Lun
   Wang, Xingce
   Wu, Zhongke
TI Example-oriented full mandible reconstruction based on principal
   component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mandible reconstruction; Example-oriented method; Principal component
   analysis; 3D reconstruction
ID COMPUTER-AIDED-DESIGN; SKULL; SHAPE; ACCURACY; SURGERY
AB The human mandible reconstruction is widely used in medical cosmetology, criminal investigation, archaeology and anthropology. This study is devoted to rapidly reconstructing 3D personalized mandibles, especially when the mandible is severely damaged or totally lost. An example-oriented method based on principal component analysis (PCA) is used to reconstruct the 3D shapes of mandibles. The predictor variable is an input cranium, while the response variables is a full mandible. The linear relationship between the cranium and mandible is obtained based on a number of skull samples, which is used as prior knowledge. The PCA method reduces the dimensionality of the skull data to improve the accuracy and speed of the reconstruction process. Experiments are conducted based on 215 skull models in the Chinese craniofacial database established in the study of craniofacial morphology informatics at Beijing Normal University. In our experiments, parameters are modified to help improve the reconstruction results. The proposed method exhibits higher accuracy than state-of-the-art methods according to comparison experiments results. Moreover, this method is robust to various types of input data and noise. Results indicate the proposed method is a fast and feasible tool for reconstructing 3D customized full mandibles.
C1 [Yan, Lun; Wang, Xingce; Wu, Zhongke] Beijing Normal Univ BNU, Sch Artificial Intelligence, 19 Xinjiekou Wai St, Beijing, Peoples R China.
RP Wu, ZK (corresponding author), Beijing Normal Univ BNU, Sch Artificial Intelligence, 19 Xinjiekou Wai St, Beijing, Peoples R China.
EM zwu@bnu.edu.cn
RI Han, Yang/JVN-5921-2024
FU National Nature Science Foundation of China [62072045, 61972041];
   National Key R&D Program of China [2020YFC1523302]; Innovation&Transfer
   Fund of Peking University Third Hospital [BYSYZHKC2021110]
FX This research was partially supported by the National Nature Science
   Foundation of China (No. 62072045, No. 61972041), National Key R&D
   Program of China (No. 2020YFC1523302) and Innovation&Transfer Fund of
   Peking University Third Hospital (No. BYSYZHKC2021110).
CR [Anonymous], 2018, 12TH INTERNATIONAL CONFERENCE ELEKTRO 2018
   Ao Shao-yong, 2016, Jiepou Xuebao, V47, P129
   Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212
   Buonamici F., 2018, COMPUTER AIDED DESIG, V16, P103, DOI [10.14733/cadaps.2019.103-112, DOI 10.14733/cadaps.2019.103-112]
   Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Chong CS, 2006, J CRANIOFAC SURG, V17, P344, DOI 10.1097/00001665-200603000-00024
   Ciocca L, 2015, J CRANIO MAXILL SURG, V43, P28, DOI 10.1016/j.jcms.2014.10.005
   Dean D, 2003, J CRANIOFAC SURG, V14, P819, DOI 10.1097/00001665-200311000-00002
   Dean D, 2003, INT CONGR SER, V1256, P710, DOI 10.1016/S0531-5131(03)00514-4
   Deng QQ, 2011, FORENSIC SCI INT, V208, P95, DOI 10.1016/j.forsciint.2010.11.011
   Duan FQ, 2014, IEEE T INF FOREN SEC, V9, P1322, DOI 10.1109/TIFS.2014.2332981
   Figueirido B, 2010, J EVOLUTION BIOL, V23, P2579, DOI 10.1111/j.1420-9101.2010.02117.x
   Fuessinger MA, 2018, INT J COMPUT ASS RAD, V13, P519, DOI 10.1007/s11548-017-1674-6
   Hierl Th., 2006, Journal of Computing and Information Technology - CIT, V14, P65, DOI 10.2498/cit.2006.01.07
   Khatib B, 2018, J ORAL MAXIL SURG, V76, P580, DOI 10.1016/j.joms.2017.10.017
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Marreiros FMM, 2016, INT J COMPUT ASS RAD, V11, P2217, DOI 10.1007/s11548-016-1454-8
   Memoli F., 2004, P 2004 EUR ACM SIGGR, V71, P33, DOI [10.1145/1057432.1057436, DOI 10.1145/1057432.1057436]
   Mohammed M, 2016, CUSTOMISED DESIGN DE, P1708
   Ota Y, 1999, JPN J CLIN ONCOL, V29, P256, DOI 10.1093/jjco/29.5.256
   Semper-Hogg W, 2017, J CRANIO MAXILL SURG, V45, P461, DOI 10.1016/j.jcms.2016.12.020
   Shui WY, 2017, COMPUT BIOL MED, V90, P33, DOI 10.1016/j.compbiomed.2017.08.023
   van Baar GJC, 2018, ORAL ONCOL, V84, P52, DOI 10.1016/j.oraloncology.2018.07.004
   Zhu XY, 2019, J ORAL MAXIL SURG, V77, DOI 10.1016/j.joms.2018.10.023
NR 24
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34009
EP 34026
DI 10.1007/s11042-022-12454-6
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300009
DA 2024-07-18
ER

PT J
AU Sathish, C
   Rubavathi, CY
AF Sathish, C.
   Rubavathi, C. Yesubai
TI A survey on Blockchain mechanisms (BCM) based on internet of things
   (IoT) applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things (IoT); Blockchain mechanisms (BCM); Smart home; Smart
   grid; And intelligent traffic system (ITS)
ID SECURITY; PRIVACY; ARCHITECTURE; TECHNOLOGY; MANAGEMENT; FRAMEWORK;
   NETWORK; SYSTEM; SCHEME
AB The Internet of Things (IoT), fast-growing smart equipment and high-speed networks, has become generally embraced and popular. Most IoT devices are nevertheless easy to hack and compromise. In general, the processors, storage, and network capacity of these IoT devices are limited. The security issues of this situation are exacerbated by several violations of safety policies. There have been suggestions and/or utilization of different security strategies and approaches. Blockchain mechanisms can be used as part of a security framework to protect many IoT-oriented applications as it ensures integrity and privacy even when datasets are released to the public. Hence, the paper elaborately surveyed common security issues in IoT architecture and the paper explores the key features of the blockchain. Along with the work proficiently investigates the technology behind bitcoin and how the blockchain solves many security issues in IoT applications. Thus the paper is concluded by providing the upsurges and limitations of various IoT with Blockchain technologies and their recent trends more precisely.
C1 [Sathish, C.] Govt Coll Engn, Dept Comp Sci & Engn, Bodinayakanur, Tamil Nadu, India.
   [Rubavathi, C. Yesubai] Francis Xavier Engn Coll, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
RP Sathish, C (corresponding author), Govt Coll Engn, Dept Comp Sci & Engn, Bodinayakanur, Tamil Nadu, India.
EM sathishgcebodi@gmail.com; yesubaicharles@gmail.com
RI 孙, 鹏举/AGZ-7658-2022
CR Aderibole A, 2020, IEEE ACCESS, V8, P43177, DOI 10.1109/ACCESS.2020.2977149
   Alam Tanweer, INT J SCI TECHNOLOGY, V9
   Alqassem I, 2014, IN C IND ENG ENG MAN, P1244, DOI 10.1109/IEEM.2014.7058837
   Latif RAM, 2022, MULTIMED TOOLS APPL, V81, P26609, DOI 10.1007/s11042-020-10087-1
   Amoozadeh M, 2015, IEEE COMMUN MAG, V53, P126, DOI 10.1109/MCOM.2015.7120028
   [Anonymous], 2017, IJARCCE, DOI DOI 10.17148/IJARCCE.2017.61022
   Badr S, 2018, PROCEDIA COMPUT SCI, V141, P159, DOI 10.1016/j.procs.2018.10.162
   Balaji BS, 2020, ENERGIES, V13, DOI 10.3390/en13071795
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5
   Caro Miguel Pincheira, 2018, 2018 IoT Vertical and Topical Summit on Agriculture - Tuscany (IOT Tuscany), DOI 10.1109/IOT-TUSCANY.2018.8373021
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Chaudhary R, 2019, COMPUT SECUR, V85, P288, DOI 10.1016/j.cose.2019.05.006
   Crosby M, 2016, APPL INNOV REV, V2, P6, DOI DOI 10.21626/innova/2016.1/01
   Danzi P, 2017, INT CONF SMART GRID, P45, DOI 10.1109/SmartGridComm.2017.8340713
   Das ML, 2015, LECT NOTES COMPUT SC, V8956, P33, DOI 10.1007/978-3-319-14977-6_3
   Davcev D., 2018, 8 INT C ADV COMP EL, P51, DOI DOI 10.15224/978-1-63248-144-3-37
   Deep G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204444
   Dorri Ali, 2017, 2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI), P173, DOI 10.1145/3054977.3055003
   Dorri A., 2016, Blockchain in Internet of Things: Challenges and Solutions
   Dorri A, 2017, INT CONF PERVAS COMP
   Dwivedi AD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020326
   Eyal I, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P45
   Ezell S., 2010, Intelligent Transportation Systems
   Feng Q, 2020, IEEE T IND INFORM, V16, P4146, DOI 10.1109/TII.2019.2948053
   Fernández-Caramés TM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153319
   Fu YG, 2019, IEEE ACCESS, V7, P144202, DOI 10.1109/ACCESS.2019.2945078
   Gao JB, 2018, IEEE ACCESS, V6, P9917, DOI 10.1109/ACCESS.2018.2806303
   Gao WY, 2020, J COMPUT APPL MATH, V372, DOI 10.1016/j.cam.2020.112724
   Garlapati Shravan, 2020, ARXIV PREPRINT ARXIV
   Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x
   Guan ZT, 2018, IEEE COMMUN MAG, V56, P82, DOI 10.1109/MCOM.2018.1700401
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hîrtan LA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030791
   Hîrtan LA, 2018, IEEE INT C COMPUT, P177, DOI 10.1109/CSE.2018.00032
   Ho G, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P461, DOI 10.1145/2897845.2897886
   Huang YB, 2010, 2010 INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION AND 2010 ASIA-PACIFIC CONFERENCE ON INFORMATION TECHNOLOGY AND OCEAN ENGINEERING: CICC-ITOE 2010, PROCEEDINGS, P330, DOI 10.1109/CICC-ITOE.2010.91
   Islam A, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI [10.1109/punecon46936.2019.9105677, 10.1109/CICN.2019.01]
   Ismail L, 2019, IEEE ACCESS, V7, P149935, DOI 10.1109/ACCESS.2019.2947613
   Jaiswal S, 2017, ADV INTELL SYST, V508, P419, DOI 10.1007/978-981-10-2750-5_44
   Kabra N, 2020, FUTURE GENER COMP SY, V102, P574, DOI 10.1016/j.future.2019.08.035
   Kang JW, 2019, IEEE T VEH TECHNOL, V68, P2906, DOI 10.1109/TVT.2019.2894944
   Kaur A., 2020, Cryptocurrencies and blockchain technology applications, P25, DOI DOI 10.1002/9781119621201.CH2
   Khan R, 2012, 10TH INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY (FIT 2012), P257, DOI 10.1109/FIT.2012.53
   Kim M, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P335, DOI 10.1109/IEMCON.2018.8615007
   Kim S, 2018, ADV COMPUT, V111, P43, DOI 10.1016/bs.adcom.2018.03.010
   Kumar M.V., 2017, Adv. Sci. Technol. Lett, V146, P125, DOI [10.14257/astl.2017.146.22, DOI 10.14257/ASTL.2017.146.22]
   Kumar SA, 2016, P ANN HICSS, P5772, DOI 10.1109/HICSS.2016.714
   Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008
   Lee Y, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-0214-5
   Lei A, 2017, IEEE INTERNET THINGS, V4, P1832, DOI 10.1109/JIOT.2017.2740569
   Li SC, 2017, SECURING THE INTERNET OF THINGS, P97, DOI 10.1016/B978-0-12-804458-2.00005-6
   Li XH, 2019, IEEE ACCESS, V7, P22011, DOI 10.1109/ACCESS.2019.2898265
   Li YH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092483
   Lin J, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON CROWD SCIENCE AND ENGINEERING (ICCSE 2018), DOI 10.1145/3265689.3265692
   Longo F, 2019, COMPUT IND ENG, V136, P57, DOI 10.1016/j.cie.2019.07.026
   Lu ZJ, 2019, IEEE T VLSI SYST, V27, P2792, DOI 10.1109/TVLSI.2019.2929420
   Lucena P., 2018, Proceedings of the Symposium on Foundations and Applications of Blockchain (FAB 18), P1
   Luo B, 2020, IEEE T VEH TECHNOL, V69, P2034, DOI 10.1109/TVT.2019.2957744
   Maskey SR, 2020, INT CONF PERVAS COMP, DOI 10.1109/percomworkshops48775.2020.9156237
   McCallig J, 2019, INT J ACCOUNT INF SY, V33, P47, DOI 10.1016/j.accinf.2019.03.004
   Mengelkamp E, 2018, COMPUT SCI-RES DEV, V33, P207, DOI 10.1007/s00450-017-0360-9
   Mettler M, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P520
   Minoli D, 2020, INTERNET THINGS-NETH, V10, DOI 10.1016/j.iot.2019.100147
   Mondal S, 2019, IEEE INTERNET THINGS, V6, P5803, DOI 10.1109/JIOT.2019.2907658
   Mylrea M, 2017, 2017 RESILIENCE WEEK (RWS), P18, DOI 10.1109/RWEEK.2017.8088642
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Oh SR, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P305
   Patil A.S., 2017, ADV COMPUTER SCI UBI, P1162, DOI DOI 10.1007/978-981-10-7605-3_185
   Peppet SR, 2014, TEX LAW REV, V93, P85
   Qu C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092784
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Salah K, 2019, IEEE ACCESS, V7, P73295, DOI 10.1109/ACCESS.2019.2918000
   Saleh MS, 2015, INT CONF SMART GR C, P195, DOI 10.1109/ICSGCE.2015.7454295
   Sanzgiri A., 2016, P 11 ANN CYB INF SEC, P1
   Sassone V., 2018, A blockchain-based infrastructure for reliable and cost-effective IoT-aided smart grids, DOI 10.1049/cp.2018.004
   Sharma PK, 2019, IEEE T IND INFORM, V15, P4197, DOI 10.1109/TII.2018.2887101
   She W, 2019, IEEE ACCESS, V7, P62058, DOI 10.1109/ACCESS.2019.2916345
   Shen GX, 2011, 2011 OPTICAL FIBER COMMUNICATION CONFERENCE AND EXPOSITION (OFC/NFOEC) AND THE NATIONAL FIBER OPTIC ENGINEERS CONFERENCE
   Singh M., 2017, ARXIV170809721
   Singh S, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719844159
   Song XL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051253
   Sultan Karim, 2018, 11th IADIS International Conference. Information Systems 2018. Proceedings, P49
   Tahir M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12176960
   Tantidham T, 2019, INT CONF PERVAS COMP, P888, DOI [10.1109/percomw.2019.8730816, 10.1109/PERCOMW.2019.8730816]
   Tayal A, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4696
   Tian F, 2017, I C SERV SYST SERV M
   Tongrang Fan, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P110, DOI 10.1109/ICNIDC.2010.5657908
   Valtanen K, 2019, IEEE ACCESS, V7, P25690, DOI 10.1109/ACCESS.2019.2900514
   Vora J, 2018, IEEE GLOBE WORK
   Wang S, 2018, IEEE T COMPUT SOC SY, V5, P942, DOI 10.1109/TCSS.2018.2865526
   Wang ZJ, 2020, AUTOMAT CONSTR, V111, DOI 10.1016/j.autcon.2019.103063
   Xie C, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P45, DOI 10.1109/BIGCOM.2017.43
   Xu J, 2019, IEEE INTERNET THINGS, V6, P8770, DOI 10.1109/JIOT.2019.2923525
   Xu XW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2017), P243, DOI 10.1109/ICSA.2017.33
   Xue JT, 2018, KSII T INTERNET INF, V12, P6057
   Ying Zhang, 2011, 2011 International Conference on Electrical and Control Engineering, P4109, DOI 10.1109/ICECENG.2011.6057290
   Yinghui Huang, 2010, Proceedings of the 2010 International Conference on Intelligent Control and Information Processing (ICICIP 2010), P483, DOI 10.1109/ICICIP.2010.5564232
   Yu YJ, 2019, ENERGIES, V12, DOI 10.3390/en12101952
   Yuan Y, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2663, DOI 10.1109/ITSC.2016.7795984
   Yue X, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0574-6
   Zhang J, 2016, IEEE ACCESS, V4, P9239, DOI 10.1109/ACCESS.2016.2645904
   Zhang MH, 2012, INT SYM COMPUT INTEL, P294, DOI 10.1109/ISCID.2012.81
   Zhang P, 2017, MATER LETT, V195, P1, DOI 10.1016/j.matlet.2017.02.077
   Zheng J, 2011, IEEE COMMUN MAG, V49, P30, DOI 10.1109/MCOM.2011.6069706
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhou ZY, 2019, IEEE TETCI, V3, P205, DOI 10.1109/TETCI.2018.2880693
NR 106
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33419
EP 33458
DI 10.1007/s11042-022-12784-5
EA APR 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784913800001
DA 2024-07-18
ER

PT J
AU Thukroo, IA
   Bashir, R
   Giri, KJ
AF Thukroo, Irshad Ahmad
   Bashir, Rumaan
   Giri, Kaiser J.
TI A review into deep learning techniques for spoken language
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Spoken language identification; Gaussian mixture model; Support vector
   machine; Hidden Markov model; Deep neural networks; Artificial neural
   network; Feed-forward neural network; Recurrent neural network;
   Convolutional neural network; Ensemble learning; hybridization
   approaches; Mel frequency cepstral coefficient features
ID FEATURE-SELECTION METHOD; NEURAL-NETWORKS; FRONT-END; RECOGNITION;
   CLASSIFICATION; INFORMATION; SPEAKER; MODEL
AB Information Technology has touched new vistas for a couple of decades mostly to simplify the day-to-day life of the humans. One of the key contributions of Information Technology is the application of Artificial Intelligence to achieve better results. The advent of artificial intelligence has given rise to a new branch of Natural Language Processing (NLP) called Computational Linguistics, which generates frameworks for intelligently manipulating spoken language knowledge and has brought human-machine onto a new stage. In this context, speech has arisen to be one of the imperative forms of interfaces, which is the basic mode of communication for us, and generally the most preferred one. Language identification, being the front-end for various natural language processing tasks, plays an important role in language translation. Owing to this, the focus has been given on the field of speech recognition involving the identification & recognition of languages by a machine. Spoken language identification is the identification of language present in a speech segment despite its size (duration & speed), ambiance (topic & emotion), and moderator (gender, age, demographic region). This paper has investigated various existing spoken language identification models implemented using different deep learning approaches, datasets, and performance measures utilized for their analysis. It also highlights the main features and challenges faced by these models. A comprehensive comparative study of deep learning techniques has been carried out for spoken language identification. Moreover, this review analyzes the efficiency of the spoken language models that can help the researchers to propose new language identification models for speech signals.
C1 [Thukroo, Irshad Ahmad; Bashir, Rumaan; Giri, Kaiser J.] Islamic Univ Sci & Technol, Dept Comp Sci, Awantipora, JK, India.
RP Bashir, R (corresponding author), Islamic Univ Sci & Technol, Dept Comp Sci, Awantipora, JK, India.
EM thukrooirshad@gmail.com; rumaan.bashir@islamicuniversity.edu.in;
   kaiser.giri@islamicuniversity.edu.in
CR Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1
   Albadr MAA, 2020, CIRC SYST SIGNAL PR, V39, P4596, DOI 10.1007/s00034-020-01388-9
   Albadr MAA, 2019, INT J SPEECH TECHNOL, V22, P711, DOI 10.1007/s10772-019-09621-w
   Albawi S, 2017, I C ENG TECHNOL
   Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081
   [Anonymous], 2005, Ethnologue: Languages of the world
   Bartz C, 2017, LECT NOTES COMPUT SC, V10639, P880, DOI 10.1007/978-3-319-70136-3_93
   Bastanfard A, 2019 5 C KNOWL BAS E, P592
   Bastanfard A, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349583
   Bastos AF, 2020, IEEE POW ENER SOC GE, DOI 10.1109/pesgm41954.2020.9281989
   Buhmann MD, 2001, ACT NUMERIC, V9, P1, DOI 10.1017/S0962492900000015
   Buscema M, 1998, SUBST USE MISUSE, V33, P233, DOI 10.3109/10826089809115863
   Cai WC, 2019, INT CONF ACOUST SPEE, P5991, DOI [10.1109/ICASSP.2019.8682386, 10.1109/icassp.2019.8682386]
   Chowdhury AA, 2020, J EXP THEOR ARTIF IN, V32, P111, DOI 10.1080/0952813X.2019.1631392
   Das A, 2020, IEEE ACCESS, V8, P181432, DOI 10.1109/ACCESS.2020.3028241
   Das H.S., 2019, Intelligent Speech Signal Processing, P81
   Das HS, 2019, INT J SPEECH TECHNOL, V22, P67, DOI 10.1007/s10772-018-09582-6
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Deshwal D, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107289
   Ferrer Luciana, 2016, IEEE/ACM Transactions on Audio, Speech and Language Processing, V24, P105, DOI 10.1109/TASLP.2015.2496226
   Fine T. L., 2006, Feedforward Neural Network Methodology
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Ganapathy S, 2014, 15 ANN C INT SPEECH
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Gelly G, 2016, INTERSPEECH, P3231, DOI 10.21437/Interspeech.2016-180
   Geng W, 2016, INTERSPEECH, P2944, DOI 10.21437/Interspeech.2016-686
   Gonzalez-Dominguez J., 2014, P INT 2014 SING 1418, P2155, DOI DOI 10.21437/INTERSPEECH.2014-483
   Guha S, 2020, IEEE ACCESS, V8, P182868, DOI 10.1109/ACCESS.2020.3028121
   Heracleous P, 2018, EUR SIGNAL PR CONF, P2265, DOI 10.23919/EUSIPCO.2018.8553347
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hori C, 2016, INTERSPEECH, P3236, DOI 10.21437/Interspeech.2016-1171
   Jin M, 2017, END TO END DNN CNN C
   Jothilakshmi S, 2012, DIGIT SIGNAL PROCESS, V22, P544, DOI 10.1016/j.dsp.2011.11.008
   Kim H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072225
   Lee CH, 2008, SPRINGER HDB SPEECH, P785
   Lei Y, 2014, APPL CONVOLUTIONAL N
   Li HZ, 2013, P IEEE, V101, P1136, DOI 10.1109/JPROC.2012.2237151
   Liu B, 2016, ARXIV PREPRINT ARXIV
   Lopez-Moreno I, 2016, COMPUT SPEECH LANG, V40, P46, DOI 10.1016/j.csl.2016.03.001
   Lounis K., 2020, Proceedings of the 2nd International Workshop on Automated and Verifiable Software System Development, P1
   Lu XG, 2017, COMPUT SPEECH LANG, V44, P48, DOI 10.1016/j.csl.2017.01.006
   Ma B, 2007, IEEE T AUDIO SPEECH, V15, P2053, DOI 10.1109/TASL.2007.902861
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   Masumura R, 2017, INT CONF ACOUST SPEE, P5260, DOI 10.1109/ICASSP.2017.7953160
   Miao XX, 2019, INTERSPEECH, P4080, DOI 10.21437/Interspeech.2019-1256
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Montavon Gregoire., 2009, Proc. NIPS Workshop on deep learning for Speech Recognition and Related Applications, P1
   Morchid M, INT J SPEECH TECHNOL, P1
   Morchid M, 2017, INTERSPEECH, P3316, DOI 10.21437/Interspeech.2017-357
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Muthusamy YK, 1994, IEEE SIGNAL PROC MAG, V11, P33, DOI 10.1109/79.317925
   Navrátil J, 2001, IEEE T SPEECH AUDI P, V9, P678, DOI 10.1109/89.943345
   Peché M, 2009, SAIEE AFR RES J, V100, P97, DOI 10.23919/SAIEE.2009.8531857
   Poncelet J, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101142
   Qiang YH, 2019, J LOW FREQ NOISE V A, V38, P1439, DOI 10.1177/1461348419830210
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Sharma V., 2012, INT J ADV RES COMPUT, V2
   Shen P, 2020, IEEE-ACM T AUDIO SPE, V28, P2674, DOI 10.1109/TASLP.2020.3023627
   Sim KC, 2008, IEEE T AUDIO SPEECH, V16, P1029, DOI 10.1109/TASL.2008.924150
   Song Y, 2015, INT CONF ACOUST SPEE, P4200, DOI 10.1109/ICASSP.2015.7178762
   Torres-Carrasquillo PA, 2002, INT CONF ACOUST SPEE, P757
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Ultsch A., 1993, INFORM CLASSIFICATIO, P307
   Vasan D, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101748
   Veisi H., 2021, J Signal Data Process, V17, P67, DOI [10.29252/jsdp.17.4.67, DOI 10.29252/JSDP.17.4.67]
   Vuddagiri RK, 2018, EXPERT SYST APPL, V110, P290, DOI 10.1016/j.eswa.2018.06.004
   Wong, 2004, AUTOMATIC SPOKEN LAN
   Wu WL, 2010, COMPUT SPEECH LANG, V24, P358, DOI 10.1016/j.csl.2009.05.002
   Yasmin G, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113575
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Zissman MA, 2001, SPEECH COMMUN, V35, P115, DOI 10.1016/S0167-6393(00)00099-6
NR 73
TC 5
Z9 5
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32593
EP 32624
DI 10.1007/s11042-022-13054-0
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782551600002
DA 2024-07-18
ER

PT J
AU Chen, BH
   Yang, X
AF Chen, Binghuang
   Yang, Xin
TI Small obstacles image detection and classification for driver assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Object detection; Small obstacle; YOLO; Intelligent
   auxiliary system
ID LOCALIZATION; RECOGNITION; SYSTEMS
AB Small obstacles can cause big accidents, even if the vehicle is equipped with an intelligent auxiliary system. In order to detect four kinds of small obstacles quickly and accurately, this paper proposes an optimized neural network algorithm based on YOLOv3. K-Means+ is used to determine the prior box and enhance the adaptability of the YOLO scale. For the data samples imbalance, loss function of YOLO is improved to increase the precision of the prediction box. In addition, a special classification and counting algorithm is proposed to get results quickly and visually. The experimental results show that the our method can classify and locate four kinds of small obstacles more accurately and faster.
C1 [Chen, Binghuang; Yang, Xin] Fujian Univ Technol, Sch Elect Elect Engn & Phys, 33 Xueyuan Rd, Fuzhou, Peoples R China.
C3 Fujian University of Technology
RP Chen, BH (corresponding author), Fujian Univ Technol, Sch Elect Elect Engn & Phys, 33 Xueyuan Rd, Fuzhou, Peoples R China.
EM chenbh@fjut.edu.cn
OI Chen, Binghuang/0000-0001-9104-6677
CR Aziz S, 2018, PROCEDIA COMPUT SCI, V127, P146, DOI 10.1016/j.procs.2018.01.109
   Bazzi A, 2017, 2017 SENSORS NETWORKS SMART AND EMERGING TECHNOLOGIES (SENSET)
   Bochkovskiy A., 2020, PREPRINT
   Chen BH, 2020, J ELECTR ENG TECHNOL, V15, P441, DOI 10.1007/s42835-019-00230-w
   Choi J, 2019, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2019.00059
   Feng ZH, 2019, IEEE SIGNAL PROC LET, V26, P450, DOI 10.1109/LSP.2019.2895291
   Gu X, 2020, TRAFFIC INJ PREV, V21, P234, DOI 10.1080/15389588.2020.1734581
   Ibrahim A, 2018, SIGNAL IMAGE VIDEO P, V12, P711, DOI 10.1007/s11760-017-1212-6
   Körez A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010083
   Lakshmi Muddana A., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P27, DOI 10.1007/978-981-13-3600-3_3
   Li FL, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1517-9
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Luo JX, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037680
   Perrine KA, 2020, J TRANSP GEOGR, V82, DOI 10.1016/j.jtrangeo.2019.102547
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shi PZ, 2021, IEEE T IND INFORM, V17, P3292, DOI 10.1109/TII.2020.3030620
   Shit RC, 2020, IET INTELL TRANSP SY, V14, P480, DOI 10.1049/iet-its.2019.0321
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun SQ, 2020, IEEE SIGNAL PROC MAG, V37, P98, DOI 10.1109/MSP.2020.2978507
   Weon IS, 2020, IEEE ACCESS, V8, P65599, DOI 10.1109/ACCESS.2020.2982681
   Ye XY, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103978
   Zhou LH, 2020, IEEE T VEH TECHNOL, V69, P3604, DOI 10.1109/TVT.2020.2969427
NR 24
TC 3
Z9 3
U1 2
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30785
EP 30795
DI 10.1007/s11042-022-12706-5
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700009
DA 2024-07-18
ER

PT J
AU Masood, F
   Boulila, W
   Alsaeedi, A
   Khan, JS
   Ahmad, J
   Khan, MA
   Rehman, SU
AF Masood, Fawad
   Boulila, Wadii
   Alsaeedi, Abdullah
   Khan, Jan Sher
   Ahmad, Jawad
   Khan, Muazzam A.
   Rehman, Sadaqat Ur
TI A novel image encryption scheme based on Arnold cat map, Newton-Leipnik
   system and Logistic Gaussian map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlinearity; Chaos; Permutation; Pseudo-random number sequence;
   Logistic Gaussian chaotic system; Newton-Leipnik system; S-box
ID S-BOX; CRYPTANALYSIS; PERMUTATION; CONFUSION
AB In the existing literature, numerous chaos-based multimedia encryption schemes have been presented. Benefiting from inherent properties such as ergodicity and key-sensitivity; this can potentially improve non-linearity in encrypted data. This paper introduces a hybrid scheme that encrypt color images using multiple chaotic maps such as the two-dimensional Arnold cat map (ACM), Newton-Leipnik dynamic system (NLDS), and a modified version of the Logistic Gaussian chaotic system (LOGAS). To make the scheme plaintext dependent, the input parameters (keys) of the chaotic maps are determined by passing the plaintext color image layers through SHA-512. Initially, the color image layers are shuffled by applying two-dimensional Arnold map scrambling. The permuted pixels were encrypted through a pseudo-random number sequences (PRNS) generated from the NLDS. To strengthen the suggested approach's security level, the modified LOGAS were utilized to generate dynamic substitution boxes (S-boxes) to substitute the encrypted pixels. Moreover, the proposed approach is tested through various statistical tests. The adjacent pixel correlation and entropy value are close to 0 and 8, respectively. The NPCR and UACI tests values are 99% and 33%, respectively. The encrypted images histograms are flat which is close to optimal value, and the computational time is less than 2.0 sec for the proposed scheme. Thus, these findings indicate the effectiveness and better reliability of the proposed system.
C1 [Masood, Fawad] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Masood, Fawad] Yangzhou Univ, Coll Informat Engn, Yangzhou 225009, Jiangsu, Peoples R China.
   [Boulila, Wadii] Prince Sultan Univ, Robot & Internet Of Things Lab, Prince Sultan, Saudi Arabia.
   [Boulila, Wadii] Univ Manouba, Natl Sch Comp Sci, RIADI Lab, Manouba, Tunisia.
   [Alsaeedi, Abdullah] Taibah Univ, Dept Comp Sci, Coll Comp Sci & Engn, Medina 42353, Saudi Arabia.
   [Khan, Jan Sher] Gaziantep Univ, Dept Elect & Elect Engn, TR-27310 Gaziantep, Turkey.
   [Ahmad, Jawad] Edinburgh Napier Univ, Sch Comp, Napier, Scotland.
   [Khan, Muazzam A.] Quaid I Azam Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Rehman, Sadaqat Ur] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
C3 Yangzhou University; Prince Sultan University; Universite de la Manouba;
   Taibah University; Gaziantep University; Edinburgh Napier University;
   Quaid I Azam University; Tsinghua University
RP Khan, JS (corresponding author), Gaziantep Univ, Dept Elect & Elect Engn, TR-27310 Gaziantep, Turkey.
EM jskm893@gmail.com
RI Alsaeedi, Abdullah Ahmad/HDM-0570-2022; Boulila, Wadii/AGY-5718-2022;
   Khan, Muazzam A. Khan/AAF-1494-2020; Ahmad, Jawad/AAC-3119-2020
OI Alsaeedi, Abdullah Ahmad/0000-0002-7974-7638; Boulila,
   Wadii/0000-0003-2133-0757; Khan, Muazzam A. Khan/0000-0001-6140-1201;
   Ahmad, Jawad/0000-0001-6289-8248; Masood, Fawad/0000-0002-5788-4228;
   Khan, Jan Sher/0000-0003-2580-5641
CR Ahmad J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030350
   Ahmad J, 2018, COMPUT SCI ELECTR, P208, DOI 10.1109/CEEC.2018.8674208
   Ahmad J, 2017, NEURAL COMPUT APPL, V28, pS953, DOI 10.1007/s00521-016-2405-6
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P13951, DOI 10.1007/s11042-015-2973-y
   [Anonymous], 1949, MATH MODEL COMMUNICA
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Butt KK, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22111276
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen E, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500468
   Driss Kaouthar, 2020, 2020 International Conference on UK-China Emerging Technologies (UCET), DOI 10.1109/UCET51115.2020.9205378
   El Hanouti I, 2020, 2020 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS), DOI 10.1109/ICDS50568.2020.9268715
   El Hanouti I, 2021, MULTIMED TOOLS APPL, V80, P12077, DOI 10.1007/s11042-020-10153-8
   El Hanouti I, 2021, MULTIMED TOOLS APPL, V80, P4975, DOI 10.1007/s11042-020-09815-4
   Elkandoz MT, 2019, SIG P ALGO ARCH ARR, P290, DOI [10.23919/SPA.2019.8936718, 10.23919/spa.2019.8936718]
   Elkandoz MT, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGIES AND NETWORKING (COMMNET), P128, DOI 10.1109/commnet.2019.8742370
   Farrag S, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGIES AND NETWORKING (COMMNET), P38
   Farwa S, 2017, INT J ADV COMPUT SC, V8, P360
   Haider D, 2019, COMPUT ELECTR ENG, V75, P16, DOI 10.1016/j.compeleceng.2019.02.011
   Khan J., 2015, 2015 6 INT C MODELIN, P1
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0016-5
   Lai Q, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20010012
   LEIPNIK RB, 1981, PHYS LETT A, V86, P63, DOI 10.1016/0375-9601(81)90165-1
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liang YQ, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100963
   Masood F, 2022, SOFT COMPUT, V26, P7461, DOI 10.1007/s00500-021-06459-w
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Masood F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111893
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Masood J, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY TRENDS (ITT 2020), P42, DOI [10.1109/itt51279.2020.9320785, 10.1109/ITT51279.2020.9320785]
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Munir N, 2021, IEEE ACCESS, V9, P105678, DOI 10.1109/ACCESS.2021.3099004
   Munir N, 2021, INTEGRATION, V79, P41, DOI 10.1016/j.vlsi.2021.03.004
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Ozkaynak F., 2019, Chaotic Modeling Simulation, V1, P49
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Podlubny I., 1998, FRACTIONAL DIFFERENT
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Shah SA, 2021, IEEE SENS J, V21, P3669, DOI 10.1109/JSEN.2020.3022564
   Shah SA, 2019, IEEE AERO EL SYS MAG, V34, P26, DOI 10.1109/MAES.2019.2933971
   Shah SA, 2019, INT J NUMER MODEL EL, V32, DOI 10.1002/jnm.2632
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang GN, 2003, PHYS LETT A, V318, P388, DOI 10.1016/j.physleta.2003.09.042
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119660
   Wu YQ, 2020, INT J COOP INF SYST, V29, DOI 10.1142/S0218843020400067
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yang XD, 2020, NEURAL COMPUT APPL, V32, P855, DOI 10.1007/s00521-019-04037-8
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 61
TC 16
Z9 16
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30931
EP 30959
DI 10.1007/s11042-022-12844-w
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700003
DA 2024-07-18
ER

PT J
AU Chen, WJ
   Gao, Y
   Chen, AB
   Zhou, GX
   Wang, JW
   Yang, XB
   Jiang, RD
AF Chen, Wenjie
   Gao, Yuan
   Chen, Aibin
   Zhou, Guoxiong
   Wang, Jianwu
   Yang, Xiaobo
   Jiang, RunDong
TI Remote sensing scene classification with multi-spatial scale frequency
   covariance pooling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Redundant learning; Scene classification; Gabor filter; Covariance
   pooling
ID OBJECT DETECTION
AB To address the problem of redundant learning in remote sensing scene classification, a method of multi-space-scale frequency covariance pooling (MSFCP) is proposed in this study. Specifically, a Gabor filter is introduced to the network which reduced redundant learning in ordinary convolution filters and enhanced the robustness of the network to external interference. Secondly, reducing redundant information in low-frequency components via dividing the feature map output by the first layer into high and low-frequencies and performing average pooling for low-frequency information. Next, the introduction of the Octave Convolution (OctConv) operation realized self-update and information interaction of high and low-frequency characteristics. Finally, the global covariance pooling is performed on the output feature map to enhance the representation ability of the entire network and boost the classification effect. Our method performed an accuracy value of 99.35 +/- 0.28 (%) on the UC Merced Land Use dataset. The experimental results demonstrate that the proposed MSFCP method achieves better classification performance and lower network model complexity than other methods, which significantly reduces the demand for computing power. Hence, a good trade-off is achieved between experimental accuracy and computational resource consumption.
C1 [Chen, Wenjie; Gao, Yuan; Chen, Aibin; Zhou, Guoxiong; Wang, Jianwu; Yang, Xiaobo; Jiang, RunDong] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.
   [Chen, Wenjie; Gao, Yuan; Chen, Aibin; Zhou, Guoxiong; Wang, Jianwu; Yang, Xiaobo; Jiang, RunDong] Cent South Univ Forestry & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha 410004, Peoples R China.
   [Chen, Wenjie; Gao, Yuan; Chen, Aibin; Zhou, Guoxiong; Wang, Jianwu; Yang, Xiaobo; Jiang, RunDong] Huangfeng Bridge State Owned Forest Farm, Zhuzhou 412000, Youxian County, Peoples R China.
   [Chen, Aibin] Cent South Univ Forestry & Technol, Changsha 410000, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology; Central South University of
   Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.; Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha 410004, Peoples R China.; Chen, AB (corresponding author), Huangfeng Bridge State Owned Forest Farm, Zhuzhou 412000, Youxian County, Peoples R China.; Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Changsha 410000, Hunan, Peoples R China.
EM 5708111@qq.com
RI wang, jianwu/KBB-3546-2024; Yang, Xiaobo/Y-6895-2019
OI Yang, Xiaobo/0000-0003-0684-8419; Zhou, Guoxiong/0000-0002-5142-4845
FU National 948 Project of China: Forest Fire Prediction and Fire Fighting
   Resource Dispatching Technology [2014-4-09]; National Natural Science
   Foundation of China [61602528]; Hunan Provincial Natural Science
   Foundation of China [2017JJ3527]; Graduate Innovation Fund of Central
   South University of Forestry and Technology [20183033]
FX This work was supported by the National 948 Project of China: Forest
   Fire Prediction and Fire Fighting Resource Dispatching Technology under
   Grant 2014-4-09, National Natural Science Foundation of China (Grant no.
   61602528), the Hunan Provincial Natural Science Foundation of China
   (Grant no. 2017JJ3527), and Graduate Innovation Fund of Central South
   University of Forestry and Technology (20183033).
CR Chaib S, 2016, IEEE GEOSCI REMOTE S, V13, P147, DOI 10.1109/LGRS.2015.2501383
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, INT GEOSCI REMOTE SE, P767, DOI 10.1109/IGARSS.2016.7729193
   Cheng G, 2015, IET COMPUT VIS, V9, P639, DOI 10.1049/iet-cvi.2014.0270
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Fang ZZ, 2016, INT GEOSCI REMOTE SE, P2610, DOI 10.1109/IGARSS.2016.7729674
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He NJ, 2020, IEEE T NEUR NET LEAR, V31, P1461, DOI 10.1109/TNNLS.2019.2920374
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4
   Jiang BT, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P128, DOI 10.1109/IAEAC.2018.8577603
   Kapoor R, 2019, MULTIMED TOOLS APPL, V78, P23281, DOI 10.1007/s11042-019-7574-8
   Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105
   Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228
   LI Xiaobin, 2019, RADIO ENG, V49, P265
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Meshgini Saeed., 2012, INT J COMPUTER THEOR, V4, P767, DOI DOI 10.7763/IJCTE.2012.V4.574
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Othmana E, 2016, INT J REMOTE SENS, V37, P2149, DOI 10.1080/01431161.2016.1171928
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang EK, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061130
   Wang SD, 2020, IEEE T IMAGE PROCESS, V29, P5396, DOI 10.1109/TIP.2020.2983560
   Wu H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050436
   [许夙晖 Xu Suhui], 2016, [测绘学报, Acta Geodetica et Cartographica Sinica], V45, P834
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yao W, 2016, IEEE J-STARS, V9, P2279, DOI 10.1109/JSTARS.2016.2536143
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhao B, 2016, ISPRS J PHOTOGRAMM, V116, P73, DOI 10.1016/j.isprsjprs.2016.03.004
   Zheng XW, 2013, IEEE GEOSCI REMOTE S, V10, P652, DOI 10.1109/LGRS.2012.2216499
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P6207, DOI 10.1109/TGRS.2015.2435801
   Zhu QQ, 2017, IEEE T GEOSCI REMOTE, V55, P5525, DOI 10.1109/TGRS.2017.2709802
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
NR 45
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30413
EP 30435
DI 10.1007/s11042-022-12603-x
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900008
DA 2024-07-18
ER

PT J
AU Chen, CH
   Li, HY
AF Chen, Chien-Hsiung
   Li, Hongyu
TI Effects of time affordance and operation mode on a smart microwave oven
   touch-sensitive user Interface design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Touchscreen interface; Time affordance; Microwave oven; Progress clue;
   Smart; Intuition
ID TOUCHSCREEN; DISCOMFORT
AB Smart homes have revolutionized our daily lives. With today's fast-paced lifestyle, pursuing a high quality of life has become many people's goal and motivation. The purpose of this study is to investigate the user interface design of smart microwave ovens pertinent to time affordance and operation mode. A 2 x 3 mixed factorial design was planned to help explore whether different time affordances (i.e., high and low) and operation modes (i.e., traditional, touch, and smart) may affect users' task performance and subjective evaluation. Using the convenience sampling method, 24 adults were recruited to participate in the experiment. The experimental data were collected pertinent to task performance, the system usability scale, and through questionnaires created using a 7-point Likert scale, and semi-structured interviews. The generated results revealed that: (1) there was a significant difference in the time affordance. Multiple time information cues can help reduce uncertainty, providing high time affordance to the participants. (2) There were significant differences among different operation modes. A simple and intuitive "smart" type is in line with user expectations. (3) The overall analysis of task performance and satisfaction consistently showed that high time affordance is better than low time affordance in all aspects, and the "smart" type had the best task performance. (4) The user interface design should be followed by users' experience and the features of the touch product. Partially smart and custom function adjustments may effectively improve the user's control of smart products.
C1 [Chen, Chien-Hsiung; Li, Hongyu] Natl Taiwan Univ Sci & Technol, Dept Design, Taipei 106335, Taiwan.
C3 National Taiwan University of Science & Technology
RP Li, HY (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Design, Taipei 106335, Taiwan.
EM hongyuli521@gmail.com
CR [Anonymous], 2007, APPLE REINVENTS PHON
   CHEBAT JC, 1993, PERCEPT MOTOR SKILL, V77, P995, DOI 10.2466/pms.1993.77.3.995
   Chen ANK, 2018, INFORM MANAGE-AMSTER, V55, P558, DOI 10.1016/j.im.2017.12.001
   Chen LH, 2017, PROC CIRP, V60, P470, DOI 10.1016/j.procir.2017.02.015
   Conn A. P., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P186
   Evans SK, 2017, J COMPUT-MEDIAT COMM, V22, P35, DOI 10.1111/jcc4.12180
   Gaver W. W., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P17, DOI 10.1145/143457.371596
   Gaver W.W., 1991, P SIGCHI C HUMAN FAC, P79, DOI DOI 10.1145/108844.108856
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Harrison C, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P115
   Hye, 2016, INDIAN J SCI TECHNOL, V9, P1
   Johnson E.A., 1965, Electronics Letters, V1, P219
   Kang H, 2014, ERGONOMICS, V57, P1397, DOI 10.1080/00140139.2014.924574
   Kl?gl F., 2014, MULTIAGENT SYSTEMS, P51
   Leahy M., 1990, Human Factors and Ergonomics Society Annual Meeting Proceedings, V34, P370
   Lee CS, 2010, COMPUT HUM BEHAV, V26, P572, DOI 10.1016/j.chb.2009.12.009
   Li H., 2020, ADV INTELLIGENT SYST, V1217, P77, DOI [10.1007/978-3-030-51828-8_11, DOI 10.1007/978-3-030-51828-8_11]
   Li HY, 2021, IEEE SENS J, V21, P21956, DOI 10.1109/JSEN.2021.3101666
   Li HY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020384
   Myers Brad A., 1985, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI'85, P11, DOI [DOI 10.1145/317456.317459, 10.1145/1165385.317459, 10.1145/317456.317459]
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   Orphanides AK, 2017, APPL ERGON, V61, P116, DOI 10.1016/j.apergo.2017.01.013
   OSUNA EE, 1985, J MATH PSYCHOL, V29, P82, DOI 10.1016/0022-2496(85)90020-3
   Roy S., 2021, the book series Design for TomorrowVolume 2, Smart Innovation, Systems and Technologies, V222, P293, DOI [10.1007/978, DOI 10.1007/978]
   Schulz L, 2018, BRAIN COGNITION, V124, P37, DOI 10.1016/j.bandc.2018.03.012
   Shin DH, 2017, TELEMAT INFORM, V34, P1826, DOI 10.1016/j.tele.2017.05.013
   Shin GS, 2011, ERGONOMICS, V54, P733, DOI 10.1080/00140139.2011.592604
   Siek KA, 2005, LECT NOTES COMPUT SC, V3585, P267, DOI 10.1007/11555261_24
   Still JD, 2013, DESIGN STUD, V34, P285, DOI 10.1016/j.destud.2012.11.005
   Wang Q, 2021, BIOMED OPT EXPRESS, V12, P5305, DOI 10.1364/BOE.431096
   Wang Q, 2021, IEEE SENS J, V21, P13685, DOI 10.1109/JSEN.2021.3071882
   You HC, 2007, DESIGN STUD, V28, P23, DOI 10.1016/j.destud.2006.07.002
   Young JG, 2012, WORK, V41, P81, DOI 10.3233/WOR-2012-1337
   Zakay D., 1989, Time and human cognition: A life-span perspective, P365, DOI [10.1016/S01664115(08)61047-X, DOI 10.1016/S0166-4115(08)61047-X]
   Zhen, 1993, COGNITIVE PSYCHOL TH
NR 35
TC 0
Z9 0
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28633
EP 28650
DI 10.1007/s11042-022-12818-y
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900011
DA 2024-07-18
ER

PT J
AU Rahmani, AM
   Azhir, E
   Naserbakht, M
   Mohammadi, M
   Aldalwie, AHM
   Majeed, MK
   Karim, STH
   Hosseinzadeh, M
AF Rahmani, Amir Masoud
   Azhir, Elham
   Naserbakht, Morteza
   Mohammadi, Mokhtar
   Aldalwie, Adil Hussein Mohammed
   Majeed, Mohammed Kamal
   Taher Karim, Sarkhel H.
   Hosseinzadeh, Mehdi
TI Automatic COVID-19 detection mechanisms and approaches from medical
   images: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE COVID-19; Medical image; Artificial intelligence; Machine learning;
   Literature review
ID CLASSIFICATION; DIAGNOSIS; SELECTION
AB Since early 2020, Coronavirus Disease 2019 (COVID-19) has spread widely around the world. COVID-19 infects the lungs, leading to breathing difficulties. Early detection of COVID-19 is important for the prevention and treatment of pandemic. Numerous sources of medical images (e.g., Chest X-Rays (CXR), Computed Tomography (CT), and Magnetic Resonance Imaging (MRI)) are regarded as a desirable technique for diagnosing COVID-19 cases. Medical images of coronavirus patients show that the lungs are filled with sticky mucus that prevents them from inhaling. Today, Artificial Intelligence (AI) based algorithms have made a significant shift in the computer aided diagnosis due to their effective feature extraction capabilities. In this survey, a complete and systematic review of the application of Machine Learning (ML) methods for the detection of COVID-19 is presented, focused on works that used medical images. We aimed to evaluate various ML-based techniques in detecting COVID-19 using medical imaging. A total of 26 papers were extracted from ACM, ScienceDirect, Springerlink, Tech Science Press, and IEEExplore. Five different ML categories to review these mechanisms are considered, which are supervised learning-based, deep learning-based, active learning-based, transfer learning-based, and evolutionary learning-based mechanisms. A number of articles are investigated in each group. Also, some directions for further research are discussed to improve the detection of COVID-19 using ML techniques in the future. In most articles, deep learning is used as the ML method. Also, most of the researchers used CXR images to diagnose COVID-19. Most articles reported accuracy of the models to evaluate model performance. The accuracy of the studied models ranged from 0.84 to 0.99. The studies demonstrated the current status of AI techniques in using AI potentials in the fight against COVID-19.
C1 [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu, Yunlin, Taiwan.
   [Azhir, Elham] Mobile Telecommun Co Iran, Res & Dev Ctr, Tehran, Iran.
   [Naserbakht, Morteza] Iran Univ Med Sci, Psychosocial Hlth Res Inst, Mental Hlth Res Ctr, Tehran, Iran.
   [Mohammadi, Mokhtar] Coll Engn & Comp Sci, Dept Informat Technol, Erbil, Kurdistan Regio, Iraq.
   [Aldalwie, Adil Hussein Mohammed] Cihan Univ, Fac Engn, Dept Commun & Comp Engn, Erbil, Kurdistan Regio, Iraq.
   [Majeed, Mohammed Kamal] Tishk Int Univ, Fac Appl Sci, Informat Technol Dept, Erbil, Iraq.
   [Taher Karim, Sarkhel H.] Univ Halabja, Coll Sci, Comp Dept, Halabja, Iraq.
   [Taher Karim, Sarkhel H.] Sulaimani Polytech Univ, Tech Coll Informat, Comp Networks Dept, Sulaymaniyah, Iraq.
   [Hosseinzadeh, Mehdi] Univ Human Dev, Comp Sci, Sulaymaniyah, Iraq.
C3 National Yunlin University Science & Technology; Iran University of
   Medical Sciences; Cihan University-Erbil; Tishk International
   University; Sulaimani Polytechnic University
RP Hosseinzadeh, M (corresponding author), Univ Human Dev, Comp Sci, Sulaymaniyah, Iraq.
EM hosseinzadeh.m@iums.ac.ir
RI Mohammed, Adil Hussein/ABA-3424-2021; Hosseinzadeh, Mehdi/GWV-3822-2022;
   Rahmani, Amir Masoud/K-2702-2013; naserbakht, morteza/KEI-7181-2024
OI Mohammed, Adil Hussein/0000-0002-6531-2051; Rahmani, Amir
   Masoud/0000-0001-8641-6119; mohammadi, mokhtar/0000-0002-1393-5062
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abdel-Basset M, 2020, IEEE ACCESS, V8, P79521, DOI 10.1109/ACCESS.2020.2990893
   Abdulkareem KH, 2021, IEEE INTERNET THINGS, V8, P15919, DOI 10.1109/JIOT.2021.3050775
   Adly AS, 2020, J MED INTERNET RES, V22, DOI 10.2196/19104
   Ahmed Faizan, 2021, ACM Digital Government: Research and Practice, V2, DOI 10.1145/3431804
   Al-Waisy AS, 2021, CMC-COMPUT MATER CON, V67, P2409, DOI 10.32604/cmc.2021.012955
   Albahli AS, 2021, CMC-COMPUT MATER CON, V67, P1613, DOI 10.32604/cmc.2021.014265
   Albahri OS, 2020, J INFECT PUBLIC HEAL, V13, P1381, DOI 10.1016/j.jiph.2020.06.028
   Alsharif W, 2021, RADIOGRAPHY, V27, P682, DOI 10.1016/j.radi.2020.09.010
   [Anonymous], 2020, PEDIATR MED RODZ, V16, P9, DOI 10.15557/PiMR.2020.0003
   [Anonymous], 2020, HDB COVID 19 PREVENT
   [Anonymous], 2009, Technical report
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arabi H, 2020, EUR J HYBRID IMAG, V4, DOI 10.1186/s41824-020-00086-8
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Blbas HT., 2022, CIHAN U ERBIL SCI J, V6, P1
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Chen Amy, 2020, CSBio2020: CSBio '20: Proceedings of the Eleventh International Conference on Computational Systems-Biology and Bioinformatics, P93, DOI 10.1145/3429210.3429213
   Chen JG, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3465398
   Dong D, 2021, IEEE REV BIOMED ENG, V14, P16, DOI 10.1109/RBME.2020.2990959
   El-kenawy ESM, 2020, IEEE ACCESS, V8, P179317, DOI 10.1109/ACCESS.2020.3028012
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Harapan H, 2020, J INFECT PUBLIC HEAL, V13, P667, DOI 10.1016/j.jiph.2020.03.019
   Harshavardhan A., 2020, MATER TODAY-PROC
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Huang XY, 2020, ARTIF INTELL MED, V110, DOI 10.1016/j.artmed.2020.101981
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Kannan S, 2020, ARCH CLIN INFECT DIS, V15, DOI 10.5812/archcid.103232
   Khan AH, 2020, SMART INNOV SYST TEC, V169, P1, DOI [10.1007/978-981-15-1616-0_1, 10.1007/s41870-020-00495-9]
   Kitchenham Barbara, 2004, Joint Technical Report, V2004, P1
   Lalmuanawma S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110059
   Mahfouz MA, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101985
   Makris Antonios, 2020, SETN 2020: Proceedings of the 11th Hellenic Conference on Artificial Intelligence, P60, DOI 10.1145/3411408.3411416
   Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691
   Mohammed MA, 2021, CMC-COMPUT MATER CON, V66, P3289, DOI 10.32604/cmc.2021.012874
   Mohammed MA, 2020, IEEE ACCESS, V8, P99115, DOI 10.1109/ACCESS.2020.2995597
   Ozsahin I, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/9756518
   Padma T., 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P589, DOI 10.1109/ICOSEC49089.2020.9215257
   Pandit MK, 2021, RADIOGRAPHY, V27, P483, DOI 10.1016/j.radi.2020.10.018
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santosh KC, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01562-1
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Shuja J, 2021, APPL INTELL, V51, P1296, DOI 10.1007/s10489-020-01862-6
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Srivastava S, 2020, INT J SYST ASSUR ENG, V11, P350, DOI 10.1007/s13198-019-00863-0
   Nguyen T, 2020, PROC SPIE, V11413, DOI 10.1117/12.2558475
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Varela-Santos S, 2021, INFORM SCIENCES, V545, P403, DOI 10.1016/j.ins.2020.09.041
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu X, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101913
NR 55
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28779
EP 28798
DI 10.1007/s11042-022-12952-7
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900002
PM 35382107
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Othmani, M
AF Othmani, Mohamed
TI A vehicle detection and tracking method for traffic video based on
   faster R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Object tracking; Convolutional neural networks;
   Feature network; Region proposal network; Deep learning
ID NEURAL-NETWORKS
AB In this paper we present a vehicle detection and tracking method for traffic video analysis based on deep learning technology. Indeed, with the rapid development of deep neural networks, vision-based approaches for vehicle tracking by detection have significantly advanced compared to existing approaches. Therefore, the proposed method is composed of three deep neural networks: Feature Network, Region Proposal Network (RPN) and detection network. The Feature Network is used to pre-train and convert video frame to feature maps using a specific convolutional neural network. The RPN network is a an additional convolutional neural network that slides on the feature map and provides a set of bounding boxes that has high probability of containing any object. Finally, a detection Network based on Region-based Convolutional Neural Network (R-CNN) is in charge of assigning a class and bounding box to each region of interest. The main idea of object tracking is to use region of interest for frame-by-frame tracking by extracting features from the current frame then using object detection from the previous frame to regress their detections in the current frame. Experiment results prove that the proposed method provide a high accuracy rate compared with existing methods.
C1 [Othmani, Mohamed] Gafsa Univ, Fac Sci, Comp Sci Dept, Gafsa, Tunisia.
   [Othmani, Mohamed] Qassim Univ, Appl Coll, Dept Appl Nat Sci, Buraydah, Saudi Arabia.
C3 Universite de Gafsa; Qassim University
RP Othmani, M (corresponding author), Gafsa Univ, Fac Sci, Comp Sci Dept, Gafsa, Tunisia.; Othmani, M (corresponding author), Qassim Univ, Appl Coll, Dept Appl Nat Sci, Buraydah, Saudi Arabia.
EM mohamed.othmani@yahoo.fr
CR [Anonymous], 2020, GTI VEH DATA
   [Anonymous], COMPUT VIS PATTERN R
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bottou L, 2014, P NEUR INF PROC SYST
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Dubey SR, 2020, IEEE T NEUR NET LEAR, V31, P4500, DOI 10.1109/TNNLS.2019.2955777
   Elkerdawi S.M., 2014, ROB 1 IB ROB C ADV R, V1, P381
   Gao YB, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020226
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2013, ARXIV13112524, V39, P98
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gupta D.K., 2021, ADV COMMUNICATION CO, V668, DOI 10.1007/978-981-15-5341-7_82
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang DY, 2017, J VIS COMMUN IMAGE R, V46, P250, DOI 10.1016/j.jvcir.2017.04.006
   Huang G, 2016, CHIN CONT DECIS CONF, P4438, DOI 10.1109/CCDC.2016.7531784
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2017, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2017.101
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M., 2021, ADV COMMUNICATION CO, P1503
   Laopracha N, 2019, VEHICLE DETECTIONTHR, P7
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Lu X, 2020, VIDEO OBJECT SEGMENT, V12348
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Bautista CM, 2016, IEEE REGION 10 SYMP, P277, DOI 10.1109/TENCONSpring.2016.7519418
   Miller N, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P269, DOI 10.1109/CRV.2015.42
   Mouna B, 2019, INT C INT THINGS EMB, P2019, DOI DOI 10.1109/IINTEC48298.2019.9112137
   Nishani E, 2017, MEDD C EMBED COMPUT, P242
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Qian ZM, 2013, LECT NOTES ELECTR EN, V256, P137, DOI 10.1007/978-3-642-38466-0_16
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saxena A, 2021, ADV COMMUNICATION CO, P1069, DOI DOI 10.1007/978-981-15-5341-7_81
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun DQ, 2015, I S INTELL SIG PR, P52
   Sun SJ, 2015, CHIN CONT DECIS CONF, P1888, DOI 10.1109/CCDC.2015.7162227
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang H, 2014, SCI WORLD J, DOI 10.1155/2014/647380
   Xie HH, 2015, PROCEEDINGS 2015 SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS ISDEA 2015, P927, DOI 10.1109/ISDEA.2015.233
   Xu YZ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081325
   Yang ZH, 2016, INT C PATT RECOG, P633, DOI 10.1109/ICPR.2016.7899705
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
NR 48
TC 10
Z9 11
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28347
EP 28365
DI 10.1007/s11042-022-12715-4
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644000002
DA 2024-07-18
ER

PT J
AU Katna, R
   Kalsi, K
   Gupta, S
   Yadav, D
   Yadav, AK
AF Katna, Rishabh
   Kalsi, Kashish
   Gupta, Srajika
   Yadav, Divakar
   Yadav, Arun Kumar
TI Machine learning based approaches for age and gender prediction from
   tweets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter dataset; Author profiling; NLP; Age prediction; Gender
   prediction; TF-IDF
AB Author profiling is the process of analysing textual data to extract information about various personality traits of the author. It has both commercial and social implications. Many approaches have been proposed in past to increase the accuracy of the extracted information. In this paper, we applied natural language processing and machine-learning approach for author profiling. NLP techniques like Tokenization, lemmatization, word and char n-grams are used in integration with machine learning classifiers like logistic regression (LR), random forest (RF), decision tree (DT) and support vector machine (SVM). The proposed method obtained an accuracy of 81.2%, 79.8%, 63.2% and 88.0% for the four classifiers respectively for gender prediction and 72.5%, 68.1%, 53.7% and 81.0% respectively for age prediction i.e. SVM outperformed the other classifiers with an accuracy of 88.0% for gender prediction and 81.0% for age prediction.
C1 [Katna, Rishabh; Kalsi, Kashish; Gupta, Srajika; Yadav, Divakar; Yadav, Arun Kumar] NIT Hamirpur, Dept Comp Sci & Engn, Hamirpur 177005, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), NIT Hamirpur, Dept Comp Sci & Engn, Hamirpur 177005, HP, India.
EM rishabhkatna2228@gmail.com; kalsi.kashish@gmail.com;
   srajika49@gmail.com; ayadav@nith.ac.in; divakaryadav@nith.ac.in
RI Yadav, DIVAKAR/AAF-1777-2020; YADAV, ARUN KUMAR/AAS-6212-2021
OI Yadav, DIVAKAR/0000-0001-6051-479X; YADAV, ARUN
   KUMAR/0000-0001-9774-7917
CR Alowibdi Jalal S., 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P739
   Alowibdi JS, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 1, P365, DOI 10.1109/ICMLA.2013.74
   [Anonymous], 2004, LREC
   [Anonymous], 2011, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing
   [Anonymous], 2003, Text, DOI [10.1515/text.2003.014, DOI 10.1515/TEXT.2003.014]
   ARIES EJ, 1983, SEX ROLES, V9, P1183, DOI 10.1007/BF00303101
   Arroju M., 2015, 6 C LABS EVALUATION, P23
   Bonaccorso G., 2017, MACHINE LEARNING ALG
   Chaffey D., 2017, Digital marketing excellence: Planning and optimizing and integrating online marketing, V5th, DOI DOI 10.4324/9781315640341
   Daneshvar S., 2018, P 9 INT C CLEF ASS C
   Heilbrun Carolyn., 1988, WRITING WOMANS LIFE
   Herring S.C., 2004, P 37 HAWAII INT C SY
   Herring SC, 2006, J SOCIOLING, V10, P439, DOI 10.1111/j.1467-9841.2006.00287.x
   Jennifer C, 2015, WOMEN MEN LANGUAGE, DOI [10.4324/9781315645612, DOI 10.4324/9781315645612]
   Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612
   Littlestone N., 1988, Machine Learning, V2, P285, DOI 10.1023/A:1022869011914
   Ljubesic N, 2017, P 2 WORKSHOP NLP COM, DOI [10.18653/v1/W17-2901, DOI 10.18653/V1/W17-2901]
   Mendenhall T C, 1887, Science, V9, P237, DOI 10.1126/science.ns-9.214S.237
   Okuno Syunya, 2014, 2014 IEEE International Conference on Big Data (Big Data), P52, DOI 10.1109/BigData.2014.7004491
   Peersman Claudia, 2011, P 3 INT WORKSH SEARC, P37, DOI DOI 10.1145/2065023.2065035
   Pennebaker J. W., 2001, LINGUISTIC INQUIRY W, P71
   Rangel F., 2018, Work. Notes Papers CLEF, V2125, P1
   Rangel Francisco, 2016, CEUR Workshop Proceedings, V2016, P750
   Rao D., 2010, P 2 INT WORKSHOP SEA, P37, DOI DOI 10.1145/1871985.1871993
   Rexha A, 2018, SCIENTOMETRICS, V115, P223, DOI 10.1007/s11192-018-2661-6
   Rose C., 2011, Proceedings of the 5th ACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, LaTeCH@ACL 2011, 24 June, 2011, Portland, Oregon, USA, P115
   Savicki V, 2006, J COMPUT-MEDIAT COMM, V2
   Sezerer E, 2019, ARXIV PREPRINT ARXIV
   Sezerer E, 2018, CEUR WORKSHOP P
   Tillery Denise., 2005, J TECH WRIT COMMUN, V35, P273, DOI [10.2190/MRQQ-K2U6-LTQU-0X56, DOI 10.2190/MRQQ-K2U6-LTQU-0X56]
   Yadav Divakar, 2020, DSAI 2020: 9th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, P61, DOI 10.1145/3439231.3439262
NR 31
TC 2
Z9 2
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27799
EP 27817
DI 10.1007/s11042-022-12920-1
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100010
DA 2024-07-18
ER

PT J
AU Xia, DW
   Zheng, YL
   Bai, Y
   Yan, XB
   Hu, Y
   Li, YT
   Li, HQ
AF Xia, Dawen
   Zheng, Yongling
   Bai, Yu
   Yan, Xiaobo
   Hu, Yang
   Li, Yantao
   Li, Huaqing
TI A parallel grid-search-based SVM optimization algorithm on Spark for
   passenger hotspot prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual analytics; Data visualization; Passenger hotspot prediction;
   Parallel SVM optimization algorithm; Spark
ID TRAFFIC FLOW PREDICTION; VISUAL ANALYTICS; DEMAND; NETWORKS
AB Predicting passenger hotspots helps drivers quickly pick up travelers, reduces cruise expenses, and maximizes revenue per unit time in intelligent transportation systems. To improve the accuracy and robustness of passenger hotspot prediction (PHP), this paper proposes a parallel Grid-Search-based Support Vector Machine (GS-SVM) optimization algorithm on Spark, which provides an efficient methodology to search for passengers in a complex urban traffic network quickly. Specifically, to effectively locate passenger hotspots, an urban road network is gridded on the Spark parallel distributed computing platform. Moreover, to enhance the accuracy of PHP, the grid search (GS) approach is employed to optimize the radial basis function (RBF) of the support vector machine (SVM), and the cross-validation method is utilized to find out the global optimal parameter combination. Finally, the SVM optimization algorithm is implemented on Spark to improve the robustness of PHP. In particular, the proposed GS-SVM algorithm is applied to successfully predict passenger hotspots. By analyzing seven groups of data sets and comparing with serval state-of-the-art algorithms including autoregressive integrated moving average (ARIMA), support vector regression (SVR), long short-term memory (LSTM), and convolutional neural network (CNN), the results of an empirical study indicate that the MAPE value of our GS-SVM algorithm is lower than that of comparative algorithms at least 78.4%.
C1 [Xia, Dawen; Zheng, Yongling; Bai, Yu; Yan, Xiaobo] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Yantao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Chongqing University; Southwest University -
   China
RP Xia, DW (corresponding author), Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.; Li, HQ (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI tong, li/KDO-7821-2024; Chen, YiJun/KFS-9282-2024; Wang,
   Zixi/KEI-0077-2024
OI Li, Huaqing/0000-0001-6310-8965; Xia, Dawen/0000-0002-0151-9643
FU National Natural Science Foundation of China [61762020, 62162012,
   61773321, 62072061, 62173278]; Science and Technology Talents Fund for
   Excellent Young of Guizhou [QKHPTRC20195669]; Science and Technology
   Support Program of Guizhou [QKHZC2021YB531]; Scientific Research
   Platform Project of Guizhou Minzu University [[2021]04]
FX This work described in this paper was supported in part by the National
   Natural Science Foundation of China (Grant nos. 61762020, 62162012,
   61773321, 62072061, and 62173278), the Science and Technology Talents
   Fund for Excellent Young of Guizhou (Grant no. QKHPTRC20195669), the
   Science and Technology Support Program of Guizhou (Grant no.
   QKHZC2021YB531), and the Scientific Research Platform Project of Guizhou
   Minzu University (Grant no. GZ-MUSYS[2021]04).
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Bashir M, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3886
   Boeing G, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2019.09.009
   Chen L, 2020, NEUROCOMPUTING, V413, P444, DOI 10.1016/j.neucom.2020.07.009
   Gong YL, 2019, J SUPERCOMPUT, V75, P5966, DOI 10.1007/s11227-019-02894-7
   Hao SY, 2019, TRANSPORT RES C-EMER, V107, P287, DOI 10.1016/j.trc.2019.08.005
   Huang ZF, 2019, IEEE INT CONF MOB DA, P144, DOI 10.1109/MDM.2019.00-63
   Jamil MS, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH), P23, DOI 10.1109/ICSITech.2017.8257080
   Ke JT, 2017, TRANSPORT RES C-EMER, V85, P591, DOI 10.1016/j.trc.2017.10.016
   Kim T, 2020, TRANSPORT RES C-EMER, V120, DOI 10.1016/j.trc.2020.102786
   Kuang L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111265
   Li ML, 2021, J CLEAN PROD, V304, DOI 10.1016/j.jclepro.2021.127139
   Li W, 2021, NEUROCOMPUTING, V427, P50, DOI 10.1016/j.neucom.2020.11.032
   Li W, 2019, IEEE ACCESS, V7, P126037, DOI 10.1109/ACCESS.2019.2939401
   Li XL, 2012, FRONT COMPUT SCI-CHI, V6, P111, DOI 10.1007/s11704-011-1192-6
   Li XF, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102419
   Liu DC, 2015, IEEE INT C INTELL TR, P1831, DOI 10.1109/ITSC.2015.297
   Liu H, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE, COMPUTER TECHNOLOGY AND TRANSPORTATION (ISCTT 2020), P198, DOI 10.1109/ISCTT51595.2020.00042
   Liu LQ, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P432, DOI 10.1109/ICTIS.2017.8047802
   Liu SY, 2013, IEEE T INTELL TRANSP, V14, P1586, DOI 10.1109/TITS.2013.2263225
   Luo HM, 2021, J TRAFFIC TRANSP ENG, V8, P83, DOI 10.1016/j.jtte.2019.07.002
   Markou I, 2019, TRANSPORT RES C-EMER, V102, P73, DOI 10.1016/j.trc.2019.03.001
   Mouratidis K, 2021, CITIES, V115, DOI 10.1016/j.cities.2021.103229
   Mridha S, P 2017 IEEE ACM INT, P27
   Mu B, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P176, DOI [10.1109/CCET48361.2019.8989132, 10.1109/ccet48361.2019.8989132]
   Niu K, 2019, IEEE T VEH TECHNOL, V68, P4122, DOI 10.1109/TVT.2018.2880007
   Ou JJ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1185, DOI 10.1145/3340531.3411874
   Peng H, 2020, INFORM SCIENCES, V521, P277, DOI 10.1016/j.ins.2020.01.043
   Qin L, 2019, NEUROCOMPUTING, V356, P244, DOI 10.1016/j.neucom.2019.04.061
   Qu BT, 2020, IEEE T INTELL TRANSP, V21, P653, DOI 10.1109/TITS.2019.2897776
   Saadallah A, 2020, IEEE T KNOWL DATA EN, V32, P234, DOI 10.1109/TKDE.2018.2883616
   Sai JC, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P74, DOI 10.1109/DSC.2016.36
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Shen JF, 2020, INT J SPEECH TECHNOL, V23, P481, DOI 10.1007/s10772-020-09710-1
   Silva RA, 2019, MULTIMED TOOLS APPL, V78, P32805, DOI 10.1007/s11042-019-08012-2
   Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8
   García FT, 2019, MULTIMED TOOLS APPL, V78, P29783, DOI 10.1007/s11042-018-6285-x
   Wang HB, 2017, IEEE INT CONF ELECTR, P153, DOI 10.1109/ICEIEC.2017.8076533
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xia DW, 2018, COMPLEXITY, DOI 10.1155/2018/2818251
   Xu J, 2018, IEEE T INTELL TRANSP, V19, P2572, DOI 10.1109/TITS.2017.2755684
   Yan B, 2017, IEEE INT CONGR BIG, P282, DOI 10.1109/BigDataCongress.2017.43
   Yang X, 2021, INFORM SCIENCES, V566, P347, DOI 10.1016/j.ins.2021.02.036
   Yu H, 2019, IEEE T INTELL TRANSP, V20, P3888, DOI 10.1109/TITS.2019.2923964
   Zhang S, 2017, J TRANSP GEOGR, V61, P72, DOI 10.1016/j.jtrangeo.2017.04.009
   Zhao TY, 2018, IEEE T IMAGE PROCESS, V27, P4740, DOI 10.1109/TIP.2018.2845118
   Zhao WT, 2019, IEEE ACCESS, V7, P114496, DOI 10.1109/ACCESS.2019.2935504
   Zhou YR, 2020, INFORM SCIENCES, V513, P372, DOI 10.1016/j.ins.2019.10.071
NR 49
TC 9
Z9 10
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27523
EP 27549
DI 10.1007/s11042-022-12077-x
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800007
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI Dual image watermarking using a multi-level thresholding and selective
   zone-quantization for copyright protection, authentication and recovery
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Robust and fragile approaches; Wavelet-packets
   decomposition; Authentication and recovery
ID FRAGILE WATERMARKING; COLOR IMAGES; DIGITAL WATERMARKING; SCHEME;
   ROBUSTNESS; DCT
AB Image watermarking has been developed, recently, to meet the various concerns in multimedia copyright protection and forgery detection due to the explosive growth in multimedia sharing applications. In this work, a novel dual color image watermarking is developed for copyright protection, authentication and recovery applications. The proposed scheme is semifragile with three main pillars: a) the utilization of the WPT features for mark embedding by creating the so-called nested WPT trees, b) the insertion of the optimizing stage, before embedding, to aid proper selection of the scheme parameters for both robust and fragile mark bits), and, c) the development of the multi-level thresholding and selective quantization procedure that aims at modifying the nominated WPT locations only when required. Here, the input color image is split into its three color RGB triplets that are applied sequentially to WPT, then, nested trees that link the color triplets are created. Two watermarks are embedded into the obtained nested trees in a dual-watermarking approach. Here, the image digests are prepared, in the YCbCr domain, and used for recovery purposes. An optimizing procedure is developed to determine the proper locations, within each tree, for embedding of the digests for recovery purposes. At the extraction stage, the extracted robust mark bits are linked to the extracted authentication mark bits to construct the final extracted robust watermark, while the authentication mark bits are stepped forward to be used for authentication and recovery applications by mining the hidden image digest bits. Experimental results have shown that the proposed scheme has a high imperceptibility performance and could survive severe unintentional attacks. In case of intentional attacks, the scheme has shown a high forgery detection accuracy and recovery performance.
C1 [Al-Otum, Hazem Munawer] Jordan Univ Sci & Technol, Fac Engn, EE Dept, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, Fac Engn, EE Dept, Irbid, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Al-Otum HM, 2021, MULTIMED TOOLS APPL, V80, P11739, DOI 10.1007/s11042-020-10368-9
   Al-Otum HM, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102726
   Al-Otum HM, 2019, MULTIMED TOOLS APPL, V78, P2199, DOI 10.1007/s11042-018-6328-3
   Bhatnagar G, 2012, SADHANA-ACAD P ENG S, V37, P371, DOI 10.1007/s12046-012-0081-5
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Chemak C, 2007, P 2007 SUMM COMP SIM, P1201
   Chung KL, 2017, INFORM SCIENCES, V420, P386, DOI 10.1016/j.ins.2017.08.064
   Cong J, 2006, LECT NOTES COMPUT SC, V3980, P921
   El Tokhy MS, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106932
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Guo JM, 2018, ASIAPAC SIGN INFO PR, P1091, DOI 10.23919/APSIPA.2018.8659732
   Habib M, 2005, LECT NOTES ARTIF INT, V3682, P548
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Hu WW, 2019, IEEE ACCESS, V7, P121303, DOI 10.1109/ACCESS.2019.2937390
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Liu KC, 2014, IET IMAGE PROCESS, V8, P363, DOI 10.1049/iet-ipr.2013.0284
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Natarajan Mohananthini, 2014, International Journal of Computer Network and Information Security, V6, P28, DOI 10.5815/ijcnis.2014.07.04
   Ouazzane H., 2013, P 10 IEEE INT MULT S
   Patel H.A., 2018, ADV COMPUTER COMPUTA, P455, DOI DOI 10.1007/978-981-10-3773-3_44
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Radharani S., 2011, INT J COMPUTER APPL, V23, P29, DOI DOI 10.5120/2868-3716
   Rawat S, 2012, OPT COMMUN, V285, P2563, DOI 10.1016/j.optcom.2012.01.067
   Ray A, 2020, INT J MULTIMED INF R, V9, P249, DOI 10.1007/s13735-020-00197-9
   Rosales-Roldan L, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P528, DOI 10.1109/TSP.2015.7296319
   Saini L. K., 2014, ARXIV PREPRINT ARXIV, V2, P4
   Sharkas M, 2005, PROC WRLD ACAD SCI E, V5, P136
   Shen H, 2012, COMPUT ELECTR ENG, V38, P1310, DOI 10.1016/j.compeleceng.2011.11.012
   Shih FY., 2017, DIGITAL WATERMARKING, P292, DOI [10.1201/9781315121109, DOI 10.1201/9781315121109]
   Sikder I, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P881, DOI 10.1109/ECACE.2017.7913027
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P6389, DOI 10.1007/s11042-015-3198-9
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Thirugnanam G, 2010, INT J SIGNAL IMAGE P, V1
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Ullah R, 2013, COMPUT ELECTR ENG, V39, P2019, DOI 10.1016/j.compeleceng.2013.04.024
   Wu KX, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P668
   Xie G, 2006, IEICE T INF SYST, VE89D, P1173, DOI 10.1093/ietisy/e89-d.3.1173
   Yaoran Huo, 2019, 2019 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia), P2865, DOI 10.1109/ISGT-Asia.2019.8881663
   Ying QC, 2019, MATH BIOSCI ENG, V16, P4788, DOI 10.3934/mbe.2019241
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zhang YF, 2019, CIRC SYST SIGNAL PR, V38, P5135, DOI 10.1007/s00034-019-01112-2
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 51
TC 3
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25787
EP 25828
DI 10.1007/s11042-022-11920-5
EA MAR 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772731900001
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Wang, Y
   Zhang, ZL
   Tan, YC
AF Liu, Zhengyi
   Wang, Yuan
   Zhang, Zhili
   Tan, Yacheng
TI BGRDNet: RGB-D salient object detection with a bidirectional gated
   recurrent decoding network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; RGB-D; Bi-GRU; Depth guided; Self-attention
ID FUSION; ATTENTION; IMAGE
AB Traditional U-Net framework generates multi-level features by the successive convolution and pooling operations, and then decodes the saliency cue by progressive upsampling and skip connection. The multi-level features are generated from the same input source, but quite different with each other. In this paper, we explore the complementarity among multi-level features, and decode them by Bi-GRU. Since multi-level features are different in the size, we first propose scale adjustment module to organize multi-level features into sequential data with the same channel and resolution. The core unit SAGRU of Bi-GRU is then devised based on self-attention, which can effectively fuse the history and current input. Based on the designed SAGRU, we further present the bidirectional decoding fusion module, which decoding the multi-level features in both down-top and top-down manners. The proposed bidirectional gated recurrent decoding network is applied in the RGB-D salient object detection, which leverages the depth map as a complementary information. Concretely, we put forward depth guided residual module to enhance the color feature. Experimental results demonstrate our method outperforms the state-of-the-art methods in the six popular benchmarks. Ablation studies also verify each module plays an important role.
C1 [Liu, Zhengyi; Wang, Yuan; Zhang, Zhili; Tan, Yacheng] Anhui Univ, Sch Comp Sci & Technol, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei, Peoples R China.
C3 Anhui University
RP Liu, ZY (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei, Peoples R China.
EM liuzywen@ahu.edu.cn; wangyuan.ahu@qq.com; 528419003@qq.com;
   tan.yacheng@qq.com
OI Liu, Zhengyi/0000-0003-3265-823X
FU Natural Science Foundation of Anhui Province [1908085MF182]; University
   Natural Science Research Project of Anhui Province [KJ2019A0034]
FX This work is supported by Natural Science Foundation of Anhui Province
   (1908085MF182) and University Natural Science Research Project of Anhui
   Province(KJ2019A0034).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ahmadi M, 2021, MULTIMED TOOLS APPL, V80, P11917, DOI 10.1007/s11042-020-10185-0
   [Anonymous], 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, DOI DOI 10.1109/CVPR.2016.257
   Ballas Nicolas, 2015, ARXIV151106432
   Bani N.T., 2019, ELECTRON LIBR
   Bardhan S, 2019, LECT NOTES COMPUT SC, V11954, P162, DOI 10.1007/978-3-030-36711-4_15
   Bardhan Sayanti, 2020, P IEEECVF C COMPUTER, P356
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P8407, DOI 10.1109/TIP.2020.3014734
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen Q, 2021, RGB D SALIENT OBJECT
   Chen Q, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107740
   Chen S., 2020, ECCV, P520, DOI DOI 10.1007/978-3-030-58598-3_31
   Chen Sihan, 2021, ARXIV210110801
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Cheng Y, 2014, IEEE INT CON MULTI
   Cho K., 2014, ARXIV14061078
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng D, 2017, PROC INT C DIGIT IMA, P1
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HM, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1050, DOI 10.1109/ICASSP39728.2021.9413957
   Huang Z, 2021, NEUROCOMPUTING, V452, P200, DOI 10.1016/j.neucom.2021.04.053
   Jiang B, 2021, IEEE T MULTIMEDIA, V23, P1343, DOI 10.1109/TMM.2020.2997184
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kingma D. P., 2014, arXiv
   Li B, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P818
   Li B, 2019, IEEE I CONF COMP VIS, P8518, DOI 10.1109/ICCV.2019.00861
   Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Liao GB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2436, DOI 10.1145/3394171.3413523
   Liu N., 2020, ARXIV201005537
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Miao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P374, DOI 10.1007/978-3-030-58604-1_23
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Nie D., 2020, P AS C COMP VIS
   Niu YZ, 2020, IEEE T IMAGE PROCESS, V29, P9496, DOI 10.1109/TIP.2020.3028170
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Ouerhani N, 2000, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2000.905356
   Pahuja A., 2019, CVPR, P27
   Pan L, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103964
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Peng P, 2020, ARXIV201200437
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi ZN, 2020, IEEE SIGNAL PROC LET, V27, P1755, DOI 10.1109/LSP.2020.3026954
   Sun L, 2020, IEEE ROBOT AUTOM LET, V5, P5558, DOI 10.1109/LRA.2020.3007457
   Sun ZQ, 2022, IEEE T CYBERNETICS, V52, P12140, DOI 10.1109/TCYB.2021.3081731
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang S-T, 2016, AS C COMP VIS, P20
   Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Wang Y, 2020, P AS C COMP VIS, P1
   Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Weng ZK, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-020-00544-0
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Xu YF, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114596
   Yarlagadda S. Kalyan, 2021, ARXIV210206882
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Yu-HuanWu Yun, 2020, ARXIV201213095
   Zeng J, 2019, PROC CVPR IEEE, P6146, DOI 10.1109/CVPR.2019.00631
   Zhang Chi, 2021, IEEE Transactions on Image Processing
   Zhang M, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4107, DOI [10.1145/3394171.3413969, 10.1145/33941713413969]
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang PP, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107130
   Zhang QJ, 2021, IEEE T IMAGE PROCESS, V30, P1305, DOI 10.1109/TIP.2020.3042084
   Zhang XY, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102997
   Zhang YF, 2021, NEUROCOMPUTING, V423, P463, DOI 10.1016/j.neucom.2020.10.079
   Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959
   Zhao JW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1745, DOI 10.1145/3394171.3413855
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhao X., ARXIV210112482, V2021
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou WJ, 2020, IEEE SIGNAL PROC LET, V27, P800, DOI 10.1109/LSP.2020.2993471
   Zhou XF, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103888
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
NR 95
TC 3
Z9 3
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25519
EP 25539
DI 10.1007/s11042-022-12799-y
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200002
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Wang, Y
   Wu, JH
   Hassan, M
   Pang, W
   Lv, LL
   Wang, LP
   Cui, HH
AF Zhou, You
   Wang, Ye
   Wu, Junhui
   Hassan, Muhammad
   Pang, Wei
   Lv, Lili
   Wang, Liupu
   Cui, Honghua
TI ErythroidCounter: an automatic pipeline for erythroid cell detection,
   identification and counting based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone marrow erythroid cell; Deep learning; Cell detection; Cell
   classification
ID CLASSIFICATION
AB The detection, identification and counting of bone marrow erythroid cells are vital for evaluating the health status and therapeutic schedules of patients with leukemia or hematopathy. However, traditional methods used in hospitals are still based on chemical reagent staining, manual detection and counting with the help of laboratory equipment. And therefore, these methods are time-consuming, laborious, and tedious. The development of deep learning in the field of image processing makes it possible for effective automated detection and classification of erythroid cells. In this research, we proposed a pipeline called ErythroidCounter, which is based on deep learning approaches to perform fully automated detection and classification of erythroid cells. ErythroidCounter is composed of the detection and extraction module (DEM) followed by classification and counting module (CCM). DEM adapts RetinaNet to locate and detect erythroid cells, and it transmits the detected cell images into CCM, while CCM is based on the DenseNet-121 architecture to perform classification and counting., which has close match in terms of classification accuracy compared to manual examination. When classifying erythroid cells, the ErythroidCounter achieved an accuracy of 86.33%, recall of 87.45%, precision of 87.16%, and F1 score of 87.30%. When detecting erythroid cells, ErythroidCounter achieved an precision of 90.7%, recall of 91.3%, and F1 score of 90.9%. EythroidCounter is robust to underlying color images, cell densities, and cell positions. To the best of our knowledge, this is the first automatic approach for erythroid cell detection, classification, and counting in real clinical scenarios, and it can be used as an assistive tool for medical examinations.
C1 [Zhou, You; Wang, Ye; Wu, Junhui; Hassan, Muhammad; Wang, Liupu] Jilin Univ, 2699 Qianjin St, Changchun, Peoples R China.
   [Pang, Wei] Heriot Watt Univ, Edinburgh, Midlothian, Scotland.
   [Lv, Lili; Cui, Honghua] Second Hosp Jilin Univ, Changchun, Peoples R China.
C3 Jilin University; Heriot Watt University; Jilin University
RP Zhou, Y (corresponding author), Jilin Univ, 2699 Qianjin St, Changchun, Peoples R China.
EM zyou@jlu.edu.cn
RI Wang, Ye/GWQ-7482-2022; Hassan, Muhammad/CAJ-4023-2022
OI Hassan, Muhammad/0000-0001-8303-8351; Pang, Wei/0000-0002-1761-6659
FU National Natural Science Foundation of China [61772227, 61972174,
   61972175]; Science and Technology Development Foundation of Jilin
   Province [20180201045GX, 20200201300JC, 20200401083GX, 20200201163JC];
   Jilin Development and Reform Commission Fund [2020C020-2]
FX This research is supported by the National Natural Science Foundation of
   China (Grants Nos. 61772227, 61972174, 61972175), Science and Technology
   Development Foundation of Jilin Province (No. 20180201045GX,
   20200201300JC, 20200401083GX, 20200201163JC), the Jilin Development and
   Reform Commission Fund (No. 2020C020-2).
CR Acharjee S, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P525, DOI 10.1109/ICEEOT.2016.7755669
   Acharya V, 2018, MED BIOL ENG COMPUT, V56, P483, DOI 10.1007/s11517-017-1708-9
   Bhattacharjee R, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P383, DOI 10.1109/ISPCC.2015.7375060
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Choi JW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189259
   Dai JF, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Girshick R, 2014, ARXIV13112524V3
   Habibzadeh M, 2013, LECT NOTES ARTIF INT, V7895, P263, DOI 10.1007/978-3-642-38610-7_25
   Hari J, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON DEVICES, CIRCUITS AND SYSTEMS (ICDCS)
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jiang M, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418570069
   Kaur P, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2574
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lou JY, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1391, DOI 10.1109/CISP-BMEI.2016.7852934
   Qin FW, 2018, COMPUT METH PROG BIO, V162, P243, DOI 10.1016/j.cmpb.2018.05.024
   Rabbani T., 2005, P ISPRS WORKSH LAS S, V36, P60, DOI 10.1.1.118.1736
   Redmon A., 2017, P IEEE C COMP VIS PA, P7263, DOI 10.1109/cvpr.2017.690
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   SERMANET P, 2014, ARXIV13126229V4
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Venkatalakshmi B, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P267
   Wang QW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218808
   Xu MJ, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005746
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
   Zhou M, 2021, FRONT PEDIATR, V9, DOI 10.3389/fped.2021.693676
NR 40
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25541
EP 25556
DI 10.1007/s11042-022-12209-3
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200006
DA 2024-07-18
ER

PT J
AU Ghosh, R
AF Ghosh, Rajib
TI A recurrent neural network based deep learning model for text and
   non-text stroke classification in online handwritten Devanagari document
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online handwritten document; Text; non-text stroke classification;
   Devanagari script; RNN; LSTM; BLSTM
ID RECOGNITION
AB It is very common for human beings to include both text and non-text data in a handwritten document. Text portion contains alphabets, digits, and mathematical symbols, whereas non-text portion includes various graphical entities like flow chart, transition diagram, etc. This paper proposes a novel method for online handwritten text and non-text stroke classification with text written in Devanagari script, the most popular script in India, using two different architectures of artificial Recurrent Neural Network (RNN)-long-short term memory (LSTM) and bidirectional long-short term memory (BLSTM). In the present work, the classifier classifies an ink as text or non-text stroke when a sequence of strokes of any online handwritten document of both text and non-text data is presented to it. Various structural and directional features related to online handwriting have been extracted from the basic strokes of text and non-text data. The system has been trained in both LSTM and BLSTM architecture based classification platforms. Experiment has also been performed using Convolutional Neural Network (CNN) to make a comparative performance analysis with RNN classifier based results. The classification performance of the present work has been evaluated using a self-generated dataset and it outperforms the CNN based results as well as the existing studies available in the literature in this regard.
C1 [Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR Awal AM, 2014, PATTERN RECOGN LETT, V35, P68, DOI 10.1016/j.patrec.2012.10.024
   Blanchard J, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P148, DOI 10.1109/IWFHR.2004.78
   Bresler M, 2014, INT CONF FRONT HAND, P563, DOI 10.1109/ICFHR.2014.100
   Delaye A, 2015, PATTERN RECOGN, V48, P1197, DOI 10.1016/j.patcog.2014.10.022
   Delaye A, 2014, PATTERN RECOGN, V47, P959, DOI 10.1016/j.patcog.2013.04.017
   Delaye A, 2013, PROC INT CONF DOC, P1007, DOI 10.1109/ICDAR.2013.202
   Feng GH, 2009, PATTERN RECOGN, V42, P3215, DOI 10.1016/j.patcog.2009.01.031
   Ghosh R., 2019, SADHANA-ACAD P ENG S, V44, P8, DOI [10.1007/s12046-018-0990-z, DOI 10.1007/S12046-018-0990-Z]
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P163, DOI 10.1109/ICSCCC.2018.8703200
   Ghosh R, 2018, INT CONF FRONT HAND, P517, DOI 10.1109/ICFHR-2018.2018.00096
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Liwicki M, 2007, PROC INT CONF DOC, P447
   Mochida K, 2004, INT J PATTERN RECOGN, V18, P1173, DOI 10.1142/S0218001404003708
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Phan,TV, 2014, INT CONF FRONT HAND, P23, DOI 10.1109/ICFHR.2014.12
   Van Phan T, 2016, PATTERN RECOGN, V51, P112, DOI 10.1016/j.patcog.2015.07.012
   Zhou XD, 2007, PROC INT CONF DOC, P377
   Zhou XD, 2009, PATTERN RECOGN, V42, P2077, DOI 10.1016/j.patcog.2008.10.019
NR 20
TC 5
Z9 5
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24245
EP 24263
DI 10.1007/s11042-022-12767-6
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549500002
DA 2024-07-18
ER

PT J
AU Abd El Salam, NH
   Ismael, AH
   Xiong, SW
AF Abd El Salam, Nada Hussien
   Ismael, Ahmed Hamdy
   Xiong, Shengwu
TI Adaptive PVD-MPK encoding method in transform domain with a modified
   side match method against dynamic and constant attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel value difference-Mobile phone keyword (PVD-MPK); Adaptive rang
   table; Integer wavelet transform (IWT); A modification side match method
ID DATA HIDING METHOD; STEGANOGRAPHIC METHOD; IMAGE STEGANOGRAPHY; DIGITAL
   IMAGES; SCHEME; LSB
AB This paper presents a novel image steganography technique that uses a mixture of pixel value differences and mobile phone keyword (PVD-MPK) encoding based on adaptive range tables and a modified side match method to conceal a secret message in either the spatial domain or an integer-wavelet-transform (IWT) based transform domain of the cover image. First, the method uses IWT instead of discrete wavelet transform (DWT) to achieve accurate extraction of secret bits. Then, the low-low (LL) sub-band is divided into nonoverlapping 2 x 2 coefficient blocks that are used as an embedding region. Second, the first coefficient of each block is paired with surrounding coefficients in three directions. Then, the diagonal and vertical directions, respectively, are selected for embedding a secret message using the PVD-MPK method and for embedding a secret message using a modified side match method if the difference between the new coefficient pixels in the diagonal direction is equal to or greater than a threshold (predefined by users or automatically determined by image analysis) to check whether or not this block is an edge or sharpest block. Experimental results show that the performance of the proposed method is superior to that of existing methods in terms of both data hiding capacity and image quality. The proposed method can reach a maximum of 1,223,949 bits with a PSNR value of 44.12 dB in the spatial domain and 337,304 bits with a PSNR value of 42.48 dB in the transform domain. Furthermore, NPCR, UACI, information entropy, and CC values were 99.62, 28.16, 7.997, and - 0.0041, respectively, so it maintains a good level of security and is challenging to be detected with human vision.
C1 [Abd El Salam, Nada Hussien; Xiong, Shengwu] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.
   [Abd El Salam, Nada Hussien; Ismael, Ahmed Hamdy] Minia Univ, Fac Sci, Comp Sci Dept, El Minia 61111, Egypt.
   [Xiong, Shengwu] Univ Technol, Sanya Sci & Educ Innovat Pk Wuhan, Sanya 572000, Peoples R China.
C3 Wuhan University of Technology; Egyptian Knowledge Bank (EKB); Minia
   University
RP Xiong, SW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.; Xiong, SW (corresponding author), Univ Technol, Sanya Sci & Educ Innovat Pk Wuhan, Sanya 572000, Peoples R China.
EM xiongsw@whut.edu.cn
RI Xiong, Shou-Mei/A-4225-2009
FU NSFC [62176194, 62101393]; Major project of IoV [2020AAA001]; Sanya
   Science and Education Innovation Park ofWuhan University of Technology
   [2021KF0031]; CSTC [cstc2021jcyj-msxmX1148]; Open Project of Wuhan
   University of Technology Chongqing Research Institute [ZL2021-6]
FX This work was in part supported by NSFC (Grant No. 62176194, Grant No.
   62101393), the Major project of IoV (Grant No. 2020AAA001), Sanya
   Science and Education Innovation Park ofWuhan University of Technology
   (Grant No. 2021KF0031), CSTC (Grant No. cstc2021jcyj-msxmX1148) and the
   Open Project of Wuhan University of Technology Chongqing Research
   Institute (ZL2021-6).
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang K.-C, 2007, 2007 IEEE INT C SYST
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Darabkh KA, 2017, INF TECHNOL CONTROL, V46, P16, DOI 10.5755/j01.itc.46.1.15253
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Ibrahim A-HSS, 2014, THESIS MINIA U
   Joo JC, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/249826
   Jung KH, 2016, ADV SCI LETT, V22, P2471, DOI 10.1166/asl.2016.7805
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P127, DOI 10.1007/s11554-017-0719-y
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kang S, 2020, MULTIMED TOOLS APPL, V79, P21155, DOI 10.1007/s11042-020-08925-3
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lin CC, 2011, COMPUT STAND INTER, V33, P477, DOI 10.1016/j.csi.2011.02.003
   Liu HH, 2019, MULTIMED TOOLS APPL, V78, P12157, DOI 10.1007/s11042-018-6766-y
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Redely H. S. Manjunatha, 2011, International Journal of Advanced Networking and Applications, V3, P1203
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Shaik A, 2018, CIRC SYST SIGNAL PR, V37, P4907, DOI 10.1007/s00034-018-0790-z
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Thanekar SA, 2013, 2013 IEEE INT C COMP
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wu DC, 2020, IEEE OPEN J COMP SOC, V1, P12, DOI 10.1109/OJCS.2020.2984473
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xu WL, 2016, DISPLAYS, V42, P36, DOI 10.1016/j.displa.2016.03.002
   Yang C., 2006, P INT COMP S TAIP TA
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
NR 48
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23493
EP 23532
DI 10.1007/s11042-022-11995-0
EA MAR 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800029
DA 2024-07-18
ER

PT J
AU Mishra, A
   Gupta, P
   Tewari, P
AF Mishra, Annu
   Gupta, Pankaj
   Tewari, Peeyush
TI Global U-net with amalgamation of inception model and improved kernel
   variation for MRI brain image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global U-Net; Batch normalization; Residual links; Maxout
ID FUSION
AB In this work, we propound the Global Inception U-Nets, that consist of suppled non-local accretion blocks, that could be used in clinical image segmentation especially for MRI segmentation of brain tumour images. The non-local accretion blocks can be positioned in U-Net as image size-conservation blocks along with the down-sampling and up-sampling layers. The fundamental research in this work involved use of the inception model to assort brain images. We have also used variant sized filters. The idea behind using these types of filters, was that the variant sized filters helps the neural network become sturdy towards the change in the scale. We start by drawing out deep activation features. This is applied on the overall image as well as on the image patches of distinct scales. The image in the encoder side is filtered in parallel by multi sized kernels. The output from every single filter undergoes batch normalisation (BN) and the outputs are summed up with a Maxout unit. This approach shrinks the spatial information of the outputs and introduces competition among the kernels. Then activations of image patches are brought together by using extra Maxpool operation with the convolution layer and after convolution layer too. Thus, we get a contemporary image representation by merging both the Maxpool and inception model activations.
C1 [Mishra, Annu] BIT Mesra, Dept Comp Sci, Noida, India.
   [Gupta, Pankaj] BIT Mesra, Dept Comp Sci, Ranchi, Bihar, India.
   [Tewari, Peeyush] BIT Mesra, Dept Math, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra; Birla Institute of Technology
   Mesra; Birla Institute of Technology Mesra
RP Mishra, A (corresponding author), BIT Mesra, Dept Comp Sci, Noida, India.
EM phdcs10059.19@bitmesra.ac.in
RI mishra, annu/KIL-4498-2024; Tewari, Peeyush/AEL-2395-2022; Gupta,
   Pankaj/U-8212-2017
OI Tewari, Peeyush/0000-0002-7719-374X; mishra, annu/0000-0001-9442-0601;
   Gupta, Pankaj/0000-0001-8508-7958
CR Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Alfanol B, 2007, LECT NOTES COMPUT SC, V4816, P117
   Alom MZ, 2018, PROC NAECON IEEE NAT, P228, DOI 10.1109/NAECON.2018.8556686
   [Anonymous], 2013, ICML
   [Anonymous], 2015, Batch-normalized maxout network in network
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chavan S, 2017, ADV INTEL SYS RES, V137, P627
   Croisille P, FREE BREATHING DIFFU
   Erdem F., 2020, International Journal of Environment and Geoinformatics, V2020, P221, DOI DOI 10.30897/IJEGEO.684951
   Gai D, 2019, IEEE ACCESS, V7, P85413, DOI 10.1109/ACCESS.2019.2925424
   Goceri E, 2019, INT CONF IMAG PROC, DOI 10.1109/ipta.2019.8936087
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   HU Y, 2018, ARXIV180708920
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar NN, LINEAR WEIGHTED NONS
   Liu XB, 2018, MED BIOL ENG COMPUT, V56, P1565, DOI 10.1007/s11517-018-1796-1
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Manessi F, 2018, INT C PATT RECOG, P657, DOI 10.1109/ICPR.2018.8546129
   Moeskops P, 2018, NEUROIMAGE-CLIN, V17, P251, DOI 10.1016/j.nicl.2017.10.007
   Nair RR, 2021, MULTIMED TOOLS APPL, V80, P19079, DOI 10.1007/s11042-020-10439-x
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prasad S, 2020, J ENG RES, V8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZY, 2020, AAAI CONF ARTIF INTE, V34, P6315
   Yadav SP, 2020, CMES-COMP MODEL ENG, V122, P303, DOI 10.32604/cmes.2020.08459
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Yadav Satya Prakash, 2019, IEIE Transactions on Smart Processing & Computing, V8, P265, DOI 10.5573/IEIESPC.2019.8.4.265
   Yogalakshmi G, 2020, 2020 11 INT C COMP C, P1
   Zhang S, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106354
NR 33
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23339
EP 23354
DI 10.1007/s11042-022-12094-w
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800019
DA 2024-07-18
ER

PT J
AU Adouani, A
   Ben Henia, WM
   Lachiri, Z
AF Adouani, Amal
   Ben Henia, Wiem Mimoun
   Lachiri, Zied
TI A comparison of face detection methods using spontaneous videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; AdaBoost; Haar-like; Viola; John's algorithm; CNN; HOG;
   LBP; SVM; Video processing; Computer vision
ID HAAR-LIKE FEATURES; RECOGNITION; DATABASE; SCALE
AB Real time face detection techniques are needed in a wide range of fields. Therefore, developing a high, accurate and efficient near-real-time face detection method has become a major concern for both industrial and research communities. This paper introduces a critical comparison to a variety of face-detection methods, namely, (1) Haar-like cascade, (2) Linear Binary Pattern cascade (LBP), (3) Histogram of Oriented Gradients with Support Vector Machine (HOG) and (4) Convolutional Neural Network based algorithms (CNN) using video sequences rather than static images. Different experiments were conducted to evaluate the performance of these techniques on constraint and spontaneous video sequences from the database for Remote Collaborative and Affective Interactions (RECOLA) and the Database for Emotion Analysis using Physiological Signals (DEAP). The experimental results show that CNN based algorithm is more efficient compared to other approaches. It achieves an average detection rate of 99.99% for the DEAP database and 84.23% for the RECOLA database. However, it is the slowest when it comes to detecting faces with an average number of frames per second (FPS) of 2.12 and 2.58. Meanwhile LBP method is the fastest among the proposed methods with an average FPS of 25.58 and 33.79.
C1 [Adouani, Amal; Ben Henia, Wiem Mimoun; Lachiri, Zied] Univ Tunis El Manar, Natl Sch Engineers Tunis, Elect Engn Dept, SITI Lab, BP 37 Belvdre, Tunis 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Adouani, A (corresponding author), Univ Tunis El Manar, Natl Sch Engineers Tunis, Elect Engn Dept, SITI Lab, BP 37 Belvdre, Tunis 1002, Tunisia.
EM amal.adouani@gmail.com; mimoun.wiem@gmail.com; zied.lachiri@enit.rnu.tn
CR Acasandrei L, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P641, DOI 10.1109/HPCC.2014.121
   Alobaidi WH, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), P28
   [Anonymous], 2002, P ADV NEURAL INFORM
   Artan Y, 2012, 2012 WESTERN NEW YORK IMAGE PROCESSING WORKSHOP (WNYIPW), P45, DOI 10.1109/WNYIPW.2012.6466644
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Chawla D, 2018, LECT NOTE DATA ENG, V4, P127, DOI 10.1007/978-981-10-4600-1_12
   Dagnes N, 2019, INT J INTERACT DES M, V13, P1617, DOI 10.1007/s12008-019-00582-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Du H, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P135, DOI 10.1109/CIS2018.2018.00037
   Erdem CE, 2011, INT CONF ACOUST SPEE, P1497, DOI 10.1109/ICASSP.2011.5946777
   Filali H, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo-yun Z., 2010, 2010 INT C COMP APPL
   Hadid A., 2008, FACE ANAL USING LOCA, P347
   Hernández-Durán M, 2015, LECT NOTES COMPUT SC, V9370, P70, DOI 10.1007/978-3-319-24261-3_6
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Hu L, 2015, LECT NOTES ELECTR EN, V336, P431, DOI 10.1007/978-3-662-46469-4_46
   Huang DY, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P609, DOI 10.1109/WAINA.2018.00153
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Ji Z, 2016, IEEE IMAGE PROC, P1474, DOI 10.1109/ICIP.2016.7532603
   Kikuchi T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3036, DOI 10.1109/ICASSP.2018.8461853
   Kim Y, 2017, ANN IEEE SYM FIELD P, P202, DOI 10.1109/FCCM.2017.48
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S., 2016, 2016 IEEE INT C CONS, P1
   Li J, 2017, I S INTELL SIG PROC, P7, DOI 10.1109/ISPACS.2017.8265636
   Li QL, 2016, I C SOFTWARE KNOWL I, P464, DOI 10.1109/SKIMA.2016.7916267
   Li SZ, 2002, 2ND INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, PROCEEDINGS, P172, DOI 10.1109/DEVLRN.2002.1011834
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu C, 2003, PROC CVPR IEEE, P587
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Martinez A., 1998, AR FACE DATABASE
   McElroy D, 2013, ASTRON ASTROPHYS, V550, DOI 10.1051/0004-6361/201220465
   Mishra D, 2013, 2013 INTERNATIONAL CONFERENCE ON GREEN COMPUTING, COMMUNICATION AND CONSERVATION OF ENERGY (ICGCE), P276, DOI 10.1109/ICGCE.2013.6823444
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Munikrishna DC, 2018, INT CONF INTEL INFOR, P321, DOI 10.1109/ICIIBMS.2018.8549957
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oualla M, 2016, COLLOQ INF SCI TECH, P471
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Qin HW, 2016, PROC CVPR IEEE, P3456, DOI 10.1109/CVPR.2016.376
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shan An, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1946, DOI 10.1109/ICAL.2009.5262624
   Shishi Duan, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P483, DOI 10.1109/ICIG.2013.97
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Singh H., 2016, 2016 INT C EM TECHN, P1
   Sun H, 2012, FAST FACE DETECTION, V124, P511
   Suse Viorel, 2015, 2015 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P1, DOI 10.1109/ReConFig.2015.7393281
   Triantafyllidou Danai, 2016, 2016 23rd International Conference on Pattern Recognition (ICPR). Proceedings, P3560, DOI 10.1109/ICPR.2016.7900186
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JJ, 2017, 2017 INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP), P34, DOI 10.1109/ICVISP.2017.10
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Xia YZ, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P375, DOI 10.1109/FSKD.2015.7381971
   Yanagisawa H, 2018, PROC INT WORKSH ADV
   Yang HC, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P766, DOI 10.1109/3PGCIC.2015.14
   Ye XY, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P504, DOI 10.1109/ICCT.2015.7399887
   Yeong-Hyeon Byeon, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P975, DOI 10.1007/978-981-10-0557-2_93
   Yi S, 2014, IEEE SYM EMBED SYST, P98, DOI 10.1109/ESTIMedia.2014.6962350
   Zhang C., 2010, A survey of recent advances in face detection
   Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zheng Jun, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P421, DOI 10.1109/ICEMI.2017.8265841
   Zhou YQ, 2018, IEEE INT CONF AUTOMA, P769, DOI 10.1109/FG.2018.00121
NR 74
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23163
EP 23191
DI 10.1007/s11042-022-12781-8
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770205800008
DA 2024-07-18
ER

PT J
AU Fang, PF
   Liu, H
   Wu, CM
   Liu, M
AF Fang, Pengfei
   Liu, Han
   Wu, Chengmao
   Liu, Min
TI A block image encryption algorithm based on a hyperchaotic system and
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaotic system; Generative adversarial networks; Block image
   encryption
ID CHAOS; MATRIX; MAP
AB To address the problems of existing image encryption algorithms based on chaotic systems, such as the weak resistance to attack, the unstable performance of the chaotic system, and the small size of the key space, a new block image encryption algorithm based on a new hyperchaotic system and generative adversarial networks (GANs) is proposed in this paper. First, a new hyperchaotic system with an improved chaotic dynamic performance and key space is designed. Then, to ensure the security and efficiency of whole-image block encryption, the new hyperchaotic system is combined with the nonlinear parallel processing mechanism of the neural network, key stream, generative adversarial networks and an improved generalized Feistel structure to scramble and diffuse the plaintext image at the pixel level to obtain the ciphertext image. The experimental results show that the proposed encryption algorithm has a large key space, high security and robustness and resistance to common attacks. At the same time, the proposed method provides a new idea for the combination of chaotic systems and neural networks in image encryption.
C1 [Fang, Pengfei; Liu, Han] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Peoples R China.
   [Wu, Chengmao] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710061, Peoples R China.
   [Liu, Min] Australian Natl Univ, Sch Engn & Comp Sci, Canberra, ACT 0200, Australia.
C3 Xi'an University of Technology; Xi'an University of Posts &
   Telecommunications; Australian National University
RP Liu, H (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Peoples R China.
EM liuhan@xaut.edu.cn
RI Liu, Han/HMD-9231-2023; Liu, Han/A-8156-2008
OI Liu, Han/0000-0002-5269-8477; Liu, Han/0000-0002-6618-1380; Liu,
   Min/0000-0003-3112-0999; Wu, Chengmao/0000-0002-5881-4723; Fang,
   Pengfei/0000-0003-2739-0996
FU National Natural Science Foundation of China [61973248]; Key Project of
   Shaanxi Key Research and Development Program [2018ZDXM-GY-089]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61973248 and the Key Project of Shaanxi Key Research
   and Development Program under Grant 2018ZDXM-GY-089.
CR Anwar MS, 2020, EUR PHYS J-SPEC TOP, V229, P1343, DOI 10.1140/epjst/e2020-900250-6
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Chowdhury SN, 2020, EUR PHYS J-SPEC TOP, V229, P1299, DOI 10.1140/epjst/e2020-900166-7
   Ding LN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030310
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Dong EZ, 2019, NONLINEAR DYNAM, V95, P3219, DOI 10.1007/s11071-018-04751-3
   Dong YX, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6674948
   Elmanfaloty RA, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/7647421
   Fang PF, 2021, IEEE ACCESS, V9, P18497, DOI 10.1109/ACCESS.2020.3040573
   Fang PF, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6691547
   Feng Y, 2020, EUR PHYS J-SPEC TOP, V229, P1279, DOI 10.1140/epjst/e2020-900097-0
   Hamdi B, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750064X
   Hou CG, 2020, MOD PHYS LETT A, V35, DOI 10.1142/S021773232050145X
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hu Y., 2020, J APPL MATH PHYS, V8, P1814
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Huang W, 2021, IEEE ACCESS, V9, P41704, DOI 10.1109/ACCESS.2021.3065453
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jiang X, 2021, OPT COMMUN, V484, DOI 10.1016/j.optcom.2020.126683
   Krishnamoorthi S, 2021, NONLINEAR DYNAM, V104, P1627, DOI 10.1007/s11071-021-06346-x
   Li XJ, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107074
   Li YA, 2021, ORPHANET J RARE DIS, V16, DOI 10.1186/s13023-021-01698-4
   Liu BY, 2016, IEEE INT SYMP CIRC S, P1326, DOI 10.1109/ISCAS.2016.7527493
   Lu JQ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/1457419
   Midoun MA, 2021, OPT LASER ENG, V139, DOI 10.1016/j.optlaseng.2020.106485
   Mousavi M, 2021, MULTIMED TOOLS APPL, V80, P13157, DOI 10.1007/s11042-020-10440-4
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   Nezhad SYD, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165661
   Peng YX, 2021, RESULTS PHYS, V24, DOI 10.1016/j.rinp.2021.104106
   Pino RE, 2013, SPIE DEFENSE SECURIT
   Platas-Garza MA, 2021, CHINESE J PHYS, V71, P22, DOI 10.1016/j.cjph.2020.11.014
   Prakash P, 2020, CIRC SYST SIGNAL PR, V39, P4259, DOI 10.1007/s00034-020-01367-0
   Rayappan D, 2021, WIREL NETW, V27, P981, DOI 10.1007/s11276-020-02486-x
   Saad W, 2021, T I MEAS CONTROL, V43, P1858, DOI 10.1177/0142331220981326
   Sarkar P, 2021, ADV MATH COMMUN, V15, P257, DOI 10.3934/amc.2020057
   Smaoui N, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6382532
   Sun FM, 2021, IEEE INTERNET THINGS, V8, P1636, DOI 10.1109/JIOT.2020.3014646
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Teh JS, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/9040518
   Vieira RM, 2021, J ALLOY COMPD, V857, DOI 10.1016/j.jallcom.2020.157811
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wang XY, 2020, IEEE ACCESS, V8, P174463, DOI 10.1109/ACCESS.2020.3024869
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wu HZ, 2021, OPT LASER ENG, V138, DOI 10.1016/j.optlaseng.2020.106454
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xian YJ, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106202
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P22135, DOI 10.1007/s11042-021-10807-1
   Yadav VK, 2020, CLUSTER COMPUT, V23, P2517, DOI 10.1007/s10586-019-03025-w
   Yang FF, 2020, CHINA COMMUN, V17, P21, DOI 10.23919/JCC.2020.05.003
   Ye GD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87427-0
   You L, 2020, SOFT COMPUT, V24, P12413, DOI 10.1007/s00500-020-04683-4
   Zhang XC, 2019, INT J OPT, V2019, DOI 10.1155/2019/3594534
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhang Y, 2020, INFORM SCIENCES, V526, P180, DOI 10.1016/j.ins.2020.03.054
   Zhao HX, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166307
   Zhou S, 2021, PHYSICA A, V563, DOI 10.1016/j.physa.2020.125478
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
NR 65
TC 6
Z9 6
U1 9
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21811
EP 21857
DI 10.1007/s11042-022-12092-y
EA MAR 2022
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800011
DA 2024-07-18
ER

PT J
AU Fayaz, S
   Parah, SA
   Qureshi, GJ
AF Fayaz, Sheezan
   Parah, Shabir A.
   Qureshi, G. J.
TI Underwater object detection: architectures and algorithms - a
   comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Object detection; Light absorption; Light scattering; Deep-learning
ID IMAGE; NETWORKS; ROBOT
AB Underwater object detection is an essential step in image processing and it plays a vital role in several applications such as the repair and maintenance of sub-aquatic structures and marine sciences. Many computer vision-based solutions have been proposed but an optimal solution for underwater object detection and species classification does not exist. This is mainly because of the challenges presented by the underwater environment which mainly include light scattering and light absorption. The advent of deep learning has enabled researchers to solve various problems like protection of the subaquatic ecological environment, emergency rescue, reducing chances of underwater disaster and its prevention, underwater target detection, spooring, and recognition. However, the advantages and shortcomings of these deep learning algorithms are still unclear. Thus, to give a clearer view of the underwater object detection algorithms and their pros and cons, we proffer a state-of-the-art review of different computer vision-based approaches that have been developed as yet. Besides, a comparison of various state-of-the-art schemes is made based on various objective indices and future research directions in the field of underwater object detection have also been proffered.
C1 [Fayaz, Sheezan; Parah, Shabir A.] Univ Kashmir, Dept Elect, Srinagar, India.
   [Fayaz, Sheezan; Parah, Shabir A.] Univ Kashmir, Inst Technol, Srinagar, India.
   [Qureshi, G. J.] Govt J & K, Higher Educ Dept, Srinagar, India.
C3 University of Kashmir; University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect, Srinagar, India.; Parah, SA (corresponding author), Univ Kashmir, Inst Technol, Srinagar, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912; Fayaz, Sheezan/0009-0002-9913-3753
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Alberto GG., 2017, ARXIV PREPRINT ARXIV
   Meda-Campaña JA, 2018, IEEE ACCESS, V6, P31968, DOI 10.1109/ACCESS.2018.2846483
   [Anonymous], 2019, 4 INT C CYB CYBCONF
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2018, 2018 INT C INF EL CO
   Aquino G, 2020, IEEE ACCESS, V8, P46324, DOI 10.1109/ACCESS.2020.2979141
   Beijbom O, 2012, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2012.6247798
   Bell Robert M, 2007, Acm Sigkdd Explorations Newsletter, V9, P75, DOI [10.1145/1345448.1345465, DOI 10.1145/1345448.1345465]
   Biswas S, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P154, DOI 10.1109/ICCWAMTIP.2015.7493965
   Bochkovskiy A., 2020, PREPRINT
   BROOKS G, 1992, SIGPLAN NOTICES, V27, P1, DOI [10.13334/j.0258-8013.pcsee.213043, 10.1145/143103.143108]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen L, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207506
   Chen YK, 2019, ADV NEUR IN, V32
   Chiang HS, 2019, IEEE ACCESS, V7, P103255, DOI 10.1109/ACCESS.2019.2929266
   CHIEN CF, 2018, P 2018 E MAN DES COL, P1
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cui SX, 2020, APPL COMPUT INTELL S, V2020, DOI 10.1155/2020/3738108
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Rubio JD, 2009, IEEE T FUZZY SYST, V17, P1296, DOI 10.1109/TFUZZ.2009.2029569
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Du X, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2347
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Duarte AC, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761315
   Ducournau A, 2016, IAPR WORKS PATTERN
   Duo ZJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161921
   Elawady M, 2014, THESIS HARIOT WATT U
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Furlán F, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.590371
   García JC, 2010, ANN IEEE SYST CONF, P71, DOI 10.1109/SYSTEMS.2010.5482454
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Han FL, 2020, J SENSORS, V2020, DOI 10.1155/2020/6707328
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang H, 2019, NEUROCOMPUTING, V337, P372, DOI 10.1016/j.neucom.2019.01.084
   Hyun Ah Song, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P466, DOI 10.1007/978-3-642-42054-2_58
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia JC, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P172, DOI 10.1109/ICMV.2009.51
   Jianyuan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11402, DOI 10.1109/CVPR42600.2020.01142
   Knausgård KM, 2022, APPL INTELL, V52, P6988, DOI 10.1007/s10489-020-02154-9
   Koreitem K, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P101, DOI 10.1109/CRV.2016.53
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavery PS, 2013, MAR ECOL PROG SER, V494, P121, DOI 10.3354/meps10554
   Law H., 2019, Cornernet-lite: Efficient keypoint based object detection
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Le THN, 2016, IEEE COMPUT SOC CONF, P46, DOI 10.1109/CVPRW.2016.13
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MY, 2013, IEEE INT CONF AUTOMA
   Liu S., 2019, CVPR
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2018, 2018 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZX, 2016, ANNU REV CONTROL, V41, P71, DOI 10.1016/j.arcontrol.2016.04.018
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Luo YX, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1019, DOI 10.1109/CISP.2013.6745205
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Marr Bernard., Key milestones of Waymo - Google's self-driving cars
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Qin HW, 2015, OCEANS-IEEE
   Rashwan A, 2019, IEEE INT CONF COMP V, P2025, DOI 10.1109/ICCVW.2019.00252
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rubio JD, 2021, IEEE T NEUR NET LEAR, V32, P3510, DOI 10.1109/TNNLS.2020.3015200
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma A, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P524, DOI 10.1109/CONFLUENCE.2016.7508176
   SHARMA P., 2018, A Step-by-Step Introduction to the Basic Object Detection Algorithms (Part 1)
   Simonyan K., 2014, 14091556 ARXIV
   Sun FH, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2879, DOI 10.1109/WCICA.2014.7053185
   Sung M, 2017, OCEANS-IEEE
   Swart S, 2016, AFR J MAR SCI, V38, P525, DOI 10.2989/1814232X.2016.1251971
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Takagi M, 2016, J ROBOT MECHATRON, V28, P397, DOI 10.20965/jrm.2016.p0397
   Tan M, 2019, P BRIT MACH VIS C BM
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Villon S, 2016, LECT NOTES COMPUT SC, V10016, P160, DOI 10.1007/978-3-319-48680-2_15
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang Y, 2013, P 2013 SPIE INT S PH, V8905
   Wenwei Xu, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P313, DOI 10.1109/CSCI46756.2018.00067
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang YT, 2018, IEEE GEOSCI REMOTE S, V15, P207, DOI 10.1109/LGRS.2017.2780843
   Yang YT, 2016, IEEE GEOSCI REMOTE S, V13, P1960, DOI 10.1109/LGRS.2016.2618941
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Yuan XF, 2018, IEEE T IND INFORM, V14, P3235, DOI 10.1109/TII.2018.2809730
   Yuh J, 2011, INTEL SERV ROBOT, V4, P221, DOI 10.1007/s11370-011-0096-5
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
NR 126
TC 20
Z9 24
U1 32
U2 231
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20871
EP 20916
DI 10.1007/s11042-022-12502-1
EA MAR 2022
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000001
DA 2024-07-18
ER

PT J
AU Korichi, A
   Slatnia, S
   Aiadi, O
   Khaldi, B
AF Korichi, Aicha
   Slatnia, Sihem
   Aiadi, Oussama
   Khaldi, Belal
TI A generic feature-independent pyramid multilevel model for Arabic
   handwriting recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic handwriting recognition; Arabic literal amount recognition; BSIF;
   LPQ; AHDB; Multi-level; Pyramid multi-level
ID CHARACTER-RECOGNITION; SYSTEM
AB Over the last decade, several image features extraction schemes such as multi-level (ML) and pyramid multi-level (PML) have been proposed. Generally speaking, features extracted using ML and PML are considered more faithful than those extracted by considering the entire image. In spite of that, numerous issues are encountered when using these schemes for features extraction. As instance, ML considers a single scale at each level, whereas, PML considers a single level at each scale, which can degrade the recognition outcomes. To overcome these issues, we propose a new scheme which we refer to as Generic feature-Independent pyramid multilevel model (GFIPML). GFIPML takes advantages of both ML and PML and considers multiple levels on different scales. The proposed model is feature-Independent and can be used with the large arsenal of existing features. We apply GFIPML for recognizing Arabic literal amounts, which is a challenging task due to the inherent properties of Arabic handwriting. While most of literature works have considered structural features which are sensitive to word deformations, we opt for using Local Phase Quantization (LPQ) and Binarized Statistical Image Feature (BSIf). To further enhance the recognition yields, we combine LPQ with multiple BSIf features, each with a different filter size. We conduct extensive experiments on the public AHDB dataset. The obtained results have proven the efficiency of the proposed scheme against ML and PML as well as the relevant state of the art methods including deep learning-based ones.
C1 [Korichi, Aicha; Slatnia, Sihem] Univ Mohammed Khider Biskra, LINFI Lab, Khider Biskra, Algeria.
   [Aiadi, Oussama; Khaldi, Belal] Univ Kasdi Merbah Ouargla, Depertment Comp Sci, Ouargla, Algeria.
C3 Universite Mohamed Khider Biskra; Universite Kasdi Merbah Ouargla
RP Korichi, A (corresponding author), Univ Mohammed Khider Biskra, LINFI Lab, Khider Biskra, Algeria.
EM aicha.korichi@univ-biskra.dz; sihem.slatnia@univ-biskra.dz;
   o_aiadi@hotmail.com; bilel.khaldi@gmail.com
RI aiadi, oussama/AAW-7992-2021; Khaldi, Belal/Q-5220-2019
OI Khaldi, Belal/0000-0002-4905-5139; KORICHI, Aicha/0000-0001-6824-4536
CR Ahmad I, 2013, J COMPUT SCI TECH-CH, V28, P285, DOI 10.1007/s11390-013-1332-6
   Ahmad I, 2012, LECT NOTES COMPUT SC, V7324, P141, DOI 10.1007/978-3-642-31295-3_17
   Al-Ma'adeed S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P485, DOI 10.1109/IWFHR.2002.1030957
   Al-Nuzaili Qais, 2016, International Journal of Intelligent Systems Technologies and Applications, V15, P240
   Al-Nuzaili QA., 2017, INT J COMPUT VIS ROB, V7, P99, DOI [10.1504/IJCVR.2017.081243, DOI 10.1504/IJCVR.2017.081243]
   Al-Nuzaili Q, 2018, LECT NOTE DATA ENG, V5, P369, DOI 10.1007/978-3-319-59427-9_40
   Alma'adeed S, 2004, BCS CONFERENCE S, P33
   [Anonymous], 2009, Advanced Pattern Recognition Technologies with Applications to Biometrics
   [Anonymous], 2015, INT J APPL ENG RES
   [Anonymous], 2018, 2018 INT C SIGNAL IM
   Aouadi N., 2016, International Journal of Computing Information Sciences, V12, P17
   Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   Assayony Mohammed O., 2018, International Journal of Computing and Digital Systems, V7, P35, DOI 10.12785/ijcds/0701004
   Bekhouche SE, 2017, EXPERT SYST APPL, V80, P297, DOI 10.1016/j.eswa.2017.03.030
   Bekhouche SE, 2015, 3RD INTERNATIONAL CONFERENCE ON CONTROL, ENGINEERING & INFORMATION TECHNOLOGY (CEIT 2015)
   CHERIET M, 2007, CHARACTER RECOGNITIO, P1
   El Qacimy B., 2014, INT J COMPUTER SCI I, V11, P27
   El qacimy B, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2015), P241, DOI 10.1109/EITech.2015.7162979
   El-Melegy M, 2019, LECT NOTES COMPUT SC, V11868, P169, DOI 10.1007/978-3-030-31321-0_15
   Eltay M, 2020, IEEE ACCESS, V8, P89882, DOI 10.1109/ACCESS.2020.2994248
   Farah N, 2006, ENG APPL ARTIF INTEL, V19, P29, DOI 10.1016/j.engappai.2005.05.005
   Fink O, 2020, IEEE T IND ELECTRON
   Hassen H, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P79, DOI 10.1109/ASAR.2017.8067764
   Hicham El Moubtahij, 2017, Journal of Electrical Systems and Information Technology, V4, P387, DOI 10.1016/j.jesit.2016.07.005
   Huang L, 2007, LECT NOTES COMPUT SC, V4844, P680
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kessentini Y, 2009, THESIS
   Khorsheed MS, 2002, PATTERN ANAL APPL, V5, P31, DOI 10.1007/s100440200004
   Korichi A, 2020, 2020 21 INT AR C INF, P1
   Lamsaf Asmae, 2021, Innovations in Smart Cities Applications. Proceedings of the 5th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (LNNS 183), P1490, DOI 10.1007/978-3-030-66840-2_112
   Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102
   Maalej R, 2020, MULTIMED TOOLS APPL, V79, P17969, DOI 10.1007/s11042-020-08740-w
   Menasria A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033024
   Mudhsh M, 2017, INFORMATION, V8, DOI 10.3390/info8030105
   Najadat HM, 2019, INT CONF INFORM COMM, P147, DOI 10.1109/iacs.2019.8809122
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Qawasmeh Yasser, 2020, International Journal of Advanced Intelligence Paradigms, V16, P203
   Raghavendra R, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0022-z
   Rathgeb C, 2016, INT CONF IMAG PROC
   Simons G. F., 2017, Ethnologue: Languages of the World, V20th
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1581, DOI 10.1109/TNNLS.2018.2868836
   Zaiz F, 2016, ENG APPL ARTIF INTEL, V56, P222, DOI 10.1016/j.engappai.2016.09.005
NR 43
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20719
EP 20739
DI 10.1007/s11042-022-11979-0
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000007
DA 2024-07-18
ER

PT J
AU Hassan, NM
   Hamad, S
   Mahar, K
AF Hassan, Nada M.
   Hamad, Safwat
   Mahar, Khaled
TI Mammogram breast cancer CAD systems for mass detection and
   classification: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE CAD system; Breast cancer; Mammogram; Mass; Detection; Classification
ID COMPUTER-AIDED DETECTION; CONVOLUTIONAL NEURAL-NETWORKS; SCREENING
   MAMMOGRAPHY; DIGITAL MAMMOGRAMS; DIAGNOSIS SYSTEM; SEGMENTATION
AB Although there is an improvement in breast cancer detection and classification (CAD) tools, there are still some challenges and limitations that need more investigation. The significant development in machine learning and image processing techniques in the last ten years affected hugely the development of breast cancer CAD systems especially with the existence of deep learning models. This survey presents in a structured way, the current deep learning-based CAD system to detect and classify masses in mammography, in addition to the conventional machine learning-based techniques. The survey presents the current publicly mammographic datasets, also provides a dataset-based quantitative comparison of the most recent techniques and the most used evaluation metrics for the breast cancer CAD systems. The survey provides a discussion of the current literature and emphasizes its pros and limitations. Furthermore, the survey highlights the challenges and limitations in the current breast cancer detection and classification techniques.
C1 [Hassan, Nada M.] Arab Acad Sci & Technol, Coll Comp & Informat Technol, Cairo, Egypt.
   [Hamad, Safwat] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
   [Mahar, Khaled] Arab Acad Sci & Technol, Coll Comp & Informat Technol, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Arab Academy for Science, Technology &
   Maritime Transport; Egyptian Academy of Scientific Research & Technology
   (ASRT); Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian
   Knowledge Bank (EKB); Arab Academy for Science, Technology & Maritime
   Transport
RP Hassan, NM (corresponding author), Arab Acad Sci & Technol, Coll Comp & Informat Technol, Cairo, Egypt.
EM nadamahmoud@aast.edu
RI Hamad, Safwat/HDO-3487-2022
OI Hamad, Safwat/0000-0002-1338-8724; Hassan, Nada/0000-0003-3005-5857
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abdel Rahman Anas S., 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P271, DOI 10.1109/ICIoT48696.2020.9089535
   Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Aboutalib SS, 2018, CLIN CANCER RES, V24, P5902, DOI 10.1158/1078-0432.CCR-18-1115
   Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774
   Agnes SA, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1494-z
   Al-antari MA, 2020, ADV EXP MED BIOL, V1213, P59, DOI 10.1007/978-3-030-33128-3_4
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6
   Al-Bayati Moumena, 2013, ADV BREAST CANC RES, V2, P72, DOI DOI 10.4236/ABCR.2013.23013
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Ali EA, 2019, EGYPT J RADIOL NUC M, V50, DOI 10.1186/s43055-019-0052-5
   ANDERSSON I, 1978, AM J ROENTGENOL, V130, P349, DOI 10.2214/ajr.130.2.349
   Ansar W., 2020, INT S INTELLIGENT CO, V1187, P11, DOI [DOI 10.1007/978-3-030-43364-2_2, 10.1007/978-3-030-43364-2_2]
   Ataollahi M R, 2015, J Med Life, V8, P6
   Baker JA, 2003, AM J ROENTGENOL, V181, P1083, DOI 10.2214/ajr.181.4.1811083
   Berment H, 2014, DIAGN INTERV IMAG, V95, P124, DOI 10.1016/j.diii.2013.12.010
   Cao HC, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106033
   CHAN HP, 1987, MED PHYS, V14, P538, DOI 10.1118/1.596065
   Chen ZL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182397
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Dong M, 2015, J DIGIT IMAGING, V28, P613, DOI 10.1007/s10278-015-9778-4
   Du H., 2019, IMAGE VIDEO PROCESSI, DOI DOI 10.48550/ARXIV.1912.07517
   Elmore JG, 2005, JAMA-J AM MED ASSOC, V293, P1245, DOI 10.1001/jama.293.10.1245
   Eltoukhy MM, 2010, 2010 INT C INT ADV S, DOI [10.1109/icias.2010.5716125, DOI 10.1109/ICIAS.2010.5716125]
   Eltoukhy MM, 2012, COMPUT BIOL MED, V42, P123, DOI 10.1016/j.compbiomed.2011.10.016
   Ertosun MG, 2015, IEEE INT C BIOINFORM, P1310, DOI 10.1109/BIBM.2015.7359868
   Freer TW, 2001, RADIOLOGY, V220, P781, DOI 10.1148/radiol.2203001282
   Ganesan K, 2013, COMPUT METH PROG BIO, V110, P48, DOI 10.1016/j.cmpb.2012.10.020
   García-Manso A, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/213794
   George M. Jayesh, 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P408, DOI 10.1109/ICCS1.2017.8326032
   Geras KJ., 2017, High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks
   Glasmachers T., 2017, P 9 ASIAN C MACHINE, P17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gur D, 2004, J NATL CANCER I, V96, P185, DOI 10.1093/jnci/djh067
   Halling-Brown MD, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2020200103
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355
   Ke L, 2010, INT CONF BIOMED, P354, DOI 10.1109/BMEI.2010.5639515
   Kissane J., 2020, RADIOLOGY FUNDAMENTA, P139, DOI [10.1007/978-3-030-22173-7_23, DOI 10.1007/978-3-030-22173-7_23]
   Kulkarni DA., 2010, INT J COMPUT APPL, V5, P12, DOI [10.5120/919-1297, DOI 10.5120/919-1297]
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Levy D., 2016, Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks, (Nips)
   Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3
   Liu XM, 2016, PROC SPIE, V10033, DOI 10.1117/12.2244627
   Liu YH, 2022, IEEE T PATTERN ANAL, V44, P5947, DOI 10.1109/TPAMI.2021.3085783
   Llobet R, 2005, LECT NOTES COMPUT SC, V3523, P495
   Lopez M., 2012, 15 INT C EXP MECH, V1215
   Lotter W, 2017, LECT NOTES COMPUT SC, V10553, P169, DOI 10.1007/978-3-319-67558-9_20
   LUSTED LB, 1955, NEW ENGL J MED, V252, P580, DOI 10.1056/NEJM195504072521405
   Michaelson J., 2003, J. Womens Imaging, V5, P3, DOI DOI 10.1097/00130747-200302000-00002
   Misra Subhasis, 2010, Adv Surg, V44, P87
   Mohanty F, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106266
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Muduli D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101912
   Mughal B, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11523-8
   Nalawade Yojana V, 2009, Indian J Radiol Imaging, V19, P282, DOI 10.4103/0971-3026.57208
   Platania R, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P536, DOI 10.1145/3107411.3107484
   Punitha S., 2018, Future Computing and Informatics Journal, V3, P348, DOI 10.1016/j.fcij.2018.10.005
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rejani Y.I.A., 2009, International Journal on Computer Science and Engineering, V1, P127, DOI DOI 10.48550/ARXIV.0912.2314
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Shams S, 2018, LECT NOTES COMPUT SC, V11071, P859, DOI 10.1007/978-3-030-00934-2_95
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shen RB, 2020, NEUROCOMPUTING, V393, P27, DOI 10.1016/j.neucom.2020.01.099
   Shie CK, 2015, IEEE ENG MED BIO, P711, DOI 10.1109/EMBC.2015.7318461
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   SICKLES EA, 1986, AM J ROENTGENOL, V147, P1149, DOI 10.2214/ajr.147.6.1149
   Slavine NV, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293604
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Suhail Z, 2018, MED BIOL ENG COMPUT, V56, P1475, DOI 10.1007/s11517-017-1774-z
   Sun H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab5745
   Varughese LS., 2013, INT J RES ENG TECHNO, V02, P421, DOI DOI 10.15623/IJRET.2013.0212070
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Welch HG, 2016, NEW ENGL J MED, V375, P1438, DOI 10.1056/NEJMoa1600249
   Wu E, 2018, LECT NOTES COMPUT SC, V11040, P98, DOI 10.1007/978-3-030-00946-5_11
   Yan Y, 2019, IEEE ENG MED BIO, P6738, DOI [10.1109/embc.2019.8857167, 10.1109/EMBC.2019.8857167]
   Yuanyi Zhong, 2020, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1275, DOI 10.1109/WACV45572.2020.9093498
   Zaidi S. S. A., 2021, ARXIV PREPRINT ARXIV
   Zhang Q, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/9496259
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou X-H., 2011, STAT METHODS DIAGNOS, DOI DOI 10.1002/9780470906514
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu W, 2016, DEEP MULTIINSTANCE N, DOI [10.1101/095794, DOI 10.1101/095794]
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 94
TC 40
Z9 41
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20043
EP 20075
DI 10.1007/s11042-022-12332-1
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600008
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhou, FB
   Zhao, HL
   Zhang, YN
   Zhang, Q
   Liang, LJ
   Li, YY
   Duan, ZD
AF Zhou, Fangbo
   Zhao, Huailin
   Zhang, Yani
   Zhang, Qing
   Liang, Lanjun
   Li, Yaoyao
   Duan, Zuodong
TI COMAL: compositional multi-scale feature enhanced learning for crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Crowd density estimation; Convolutional neural network;
   Multi-scale feature learning
AB Accurately modeling the crowd's head scale variations is an effective way to improve the counting accuracy of the crowd counting methods. Most counting networks apply a multi-branch network structure to obtain different scales of head features. Although they have achieved promising results, they do not perform very well on the extreme scale variation scene due to the limited scale representability. Meanwhile, these methods are prone to recognize background objects as foreground crowds in complex scenes due to the limited context and high-level semantic information. We propose a compositional multi-scale feature enhanced learning approach (COMAL) for crowd counting to handle the above limitations. COMAL enhances the multi-scale feature representations from three aspects: (1) The semantic enhanced module (SEM) is developed for embedding the high-level semantic information to the multi-scale features; (2) The diversity enhanced module (DEM) is proposed to enrich the variety of crowd features' different scales; (3) The context enhanced module (CEM) is designed for strengthening the multi-scale features with more context information. Based on the proposed COMAL, we develop a crowd counting network under the encoder-decoder framework and perform extensive experiments on ShanghaiTech, UCF_CC_50, and UCF-QNRF datasets. Qualitative and quantitive results demonstrate the effectiveness of the proposed COMAL.
C1 [Zhou, Fangbo; Zhao, Huailin; Liang, Lanjun; Li, Yaoyao] Shanghai Inst Technol, Sch Elect & Elect Engn, Shanghai, Peoples R China.
   [Zhang, Yani; Zhang, Qing] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai, Peoples R China.
   [Duan, Zuodong] Beijing Inst Technol, Sch Mechatron Engn, Sci & Technol Electromech Dynam Control Lab, Beijing, Peoples R China.
C3 Shanghai Institute of Technology; Shanghai Institute of Technology;
   Beijing Institute of Technology
RP Zhao, HL (corresponding author), Shanghai Inst Technol, Sch Elect & Elect Engn, Shanghai, Peoples R China.
EM zhao_huailin@yahoo.com
RI Zhao, Huailin/H-6597-2018
OI zhou, fang bo/0000-0002-3131-8973
FU Natural Science Foundation of Shanghai [19ZR1455300]; National Natural
   Science Foundation of China [61806126]
FX This work is supported by Natural Science Foundation of Shanghai under
   Grant No. 19ZR1455300, and National Natural Science Foundation of China
   under Grant No. 61806126.
CR Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cao JM, 2020, MULTIMED TOOLS APPL, V79, P2837, DOI 10.1007/s11042-019-08467-3
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen C, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107744
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen XY, 2019, IEEE WINT CONF APPL, P1941, DOI 10.1109/WACV.2019.00211
   Cholakkal H, 2019, PROC CVPR IEEE, P12389, DOI 10.1109/CVPR.2019.01268
   Deb D, 2018, IEEE COMPUT SOC CONF, P308, DOI 10.1109/CVPRW.2018.00057
   Di K, 2018, ARXIV PREPRINT ARXIV
   Fu HY, 2014, MULTIMED TOOLS APPL, V73, P273, DOI 10.1007/s11042-013-1608-4
   Gao G., 2020, ARXIV
   Gao J., 2019, ARXIV190702724
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Guo D, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1823, DOI 10.1145/3343031.3350881
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Junyu Gao, 2019, ARXIV PREPRINT ARXIV
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Laradji IH, 2018, LECT NOTES COMPUT SC, V11206, P560, DOI 10.1007/978-3-030-01216-8_34
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Moustafa AN, 2020, MULTIMED TOOLS APPL, V79, P20689, DOI 10.1007/s11042-020-08840-7
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Pandey A, 2020, MULTIMED TOOLS APPL, V79, P17837, DOI 10.1007/s11042-020-08754-4
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Sam DB, 2018, ARXIV PREPRINT ARXIV
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi ML, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON INDUSTRIAL ARTIFICIAL INTELLIGENCE (IAI 2019), DOI 10.1109/iciai.2019.8850794
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   SOMAYAJI SRK, 2020, IEEE GLOBE WORK
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang JW, 2017, ACTA OPHTHALMOL, V95, pE10, DOI 10.1111/aos.13227
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang SZ, 2020, NEUROCOMPUTING, V404, P227, DOI 10.1016/j.neucom.2020.04.139
   Wang SZ, 2017, LECT NOTES COMPUT SC, V10636, P260, DOI 10.1007/978-3-319-70090-8_27
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu XJ, 2019, INT CONF ACOUST SPEE, P2382, DOI [10.1109/ICASSP.2019.8683744, 10.1109/icassp.2019.8683744]
   Xie YJ, 2020, IEEE IMAGE PROC, P1531, DOI 10.1109/ICIP40778.2020.9191086
   Xu CF, 2019, IEEE I CONF COMP VIS, P8381, DOI 10.1109/ICCV.2019.00847
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
   Zou Z, 2020, MULTIMED TOOLS APPL, V79, P29145, DOI 10.1007/s11042-020-09541-x
NR 67
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20541
EP 20560
DI 10.1007/s11042-022-12249-9
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600017
PM 35291715
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhu, H
   Huang, L
   Wei, ZQ
   Zhang, WF
   Cai, HH
AF Zhu, Hui
   Huang, Lei
   Wei, Zhiqiang
   Zhang, Wenfeng
   Cai, Huanhuan
TI Learning camera invariant deep features for semi-supervised person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Semi-supervised learning; Camera invariant;
   Camera information; Pseudo label
ID NEURAL-NETWORK
AB In this paper, we focus on the semi-supervised person re-identification (re-ID) task, where the training data includes some labeled data and most unlabeled data. Since the re-ID task is used for cross-camera scenes, learning camera invariant deep features become critical. We propose a novel end-to-end semi-supervised person re-ID method by introducing the context information, i.e., the camera information (camera ID) which could be easily collected without any manual annotation. Specifically, we design a camera-based hard triplet loss for (pseudo-) labeled data to learn the camera invariant features. The loss not only learns the similar features between the cross-camera anchor and the hard positive sample but also learns the distinguishing features between the within-camera anchor and the hard negative sample. For unlabeled data, we use both diversity loss and similarity loss to diversify unlabeled data features and mine similar samples. And we design an adaptive feature fusion module, which could adaptively combine the Global Average Pooling (GAP) and Global Max Pooling (GMP) features to learn person-specific discriminative information in a global-local manner. Furthermore, to validate the effectiveness of our approach, we conduct extensive experiments on two large-scale image re-ID datasets, including Market-1501 and DukeMTMC-reID. The experimental results demonstrate that our approach outperforms the state-of-the-art method by 4.8% on Market-1501, and 7.2% on DukeMTMC-reID.
C1 [Zhu, Hui; Huang, Lei; Wei, Zhiqiang; Zhang, Wenfeng; Cai, Huanhuan] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Peoples R China.
C3 Ocean University of China
RP Huang, L (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM huangl@ouc.edu.cn
RI wei, zhiqiang/M-8868-2013
OI Huang, Lei/0000-0003-4087-3677
FU National Natural Science Foundation of China [61872326, 61672475];
   Shandong Provincial Natural Science Foundation [ZR2019MF044]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61872326, No. 61672475); Shandong Provincial Natural Science
   Foundation (ZR2019MF044).
CR Bak S, 2017, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR.2017.171
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen, 2018, ABS180807301 CORR
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Huang Houjing, 2018, ABS181211369 CORR
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu CG, 2021, IEEE T SYST MAN CY-S, V51, P2894, DOI 10.1109/TSMC.2019.2917547
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Ma F, 2017, PR MACH LEARN RES, V70
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Nie J, 2019, IEEE ACCESS, V7, P15007, DOI 10.1109/ACCESS.2019.2894347
   Pawan Kumar M., 2010, NIPS
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shi WW, 2018, LECT NOTES COMPUT SC, V11209, P311, DOI 10.1007/978-3-030-01228-1_19
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P32079, DOI 10.1007/s11042-020-09569-z
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhang XQ, 2021, IEEE T PATTERN ANAL, V43, P238, DOI 10.1109/TPAMI.2019.2929043
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhang YZ, 2020, MULTIMED TOOLS APPL, V79, P28603, DOI 10.1007/s11042-020-09427-y
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu XP, 2019, IEEE INT CONF COMP V, P1079, DOI 10.1109/ICCVW.2019.00138
NR 58
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18671
EP 18692
DI 10.1007/s11042-022-12581-0
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800009
DA 2024-07-18
ER

PT J
AU Pugazhenthi, A
   Sebastian, S
   Rohith, G
   Kumar, LS
AF Pugazhenthi, A.
   Sebastian, Sruthy
   Rohith, G.
   Kumar, Lakshmi Sutha
TI Significant full reference image segmentation evaluation: a survey in
   remote sensing field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; INSAT-3D; Evaluation metrics; Clustering algorithm;
   Qualitative evolution; Quantitative evolution; Machine learning
   algorithm
ID QUALITY ASSESSMENT; CLUSTERS; FUSION
AB Image segmentation is a crucial step in remote sensing application, as it breaks down a larger image into smaller chunks, which contains useful information. Although there are several image segmentation algorithms available, evaluation of the algorithms is challenging. Furthermore, the evaluation of image segmentation can elucidate the best image segmentation algorithm for a single image or a group of image or a whole class of image. This paper explores and evaluates the benefits and the drawbacks of various qualitative and quantitative image segmentation evaluation metrics used in remote sensing applications. For all the metrics, a quantitative set of values for good and bad segmentation is provided. In addition, some image segmentation algorithms such as Multi Otsu Threshold, K Means clustering, Fuzzy C Means clustering, Improved K Means clustering (IFCM), Improved Fuzzy C Means clustering, Naive Bayes classifier, K Nearest Neighbor, Decision Tree (DT) and Random Forest classifier are used in the experimental comparison of metrics. The qualitative and quantitative satellite image segmentation evaluation using the mentioned algorithms is measured. The results are analyzed to strengthen the impact of different metrics on the segmentation algorithms. In both qualitative and quantitative analysis, the IFCM outperformed the other unsupervised machine learning algorithms and the DT outperformed the other supervised machine learning algorithms. The effectiveness of the provided metrics in the remote sensing field is validated.
C1 [Pugazhenthi, A.; Sebastian, Sruthy; Rohith, G.; Kumar, Lakshmi Sutha] Natl Inst Technol Puducherry, Dept Elect & Commun Engn, Pondicherry, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry
RP Pugazhenthi, A (corresponding author), Natl Inst Technol Puducherry, Dept Elect & Commun Engn, Pondicherry, India.
EM pugazh1989@gmail.com
RI Rohith, Gorrepati/ABH-7282-2020; Kumar, Lakshmi Sutha/P-9990-2019;
   Annadurai, Pugazhenthi/J-8186-2019
OI Rohith, Gorrepati/0000-0003-1081-027X; Annadurai,
   Pugazhenthi/0000-0002-3601-6747; Kumar, Lakshmi
   Sutha/0000-0002-9069-3132
CR Andréfouët S, 2000, INT J REMOTE SENS, V21, P1925, DOI 10.1080/014311600209832
   Athi, 2021, IM QUAL MEAS
   Bezdek JC, 2016, IEEE T FUZZY SYST, V24, P1500, DOI 10.1109/TFUZZ.2016.2540063
   Chen GH, 2006, IEEE IMAGE PROC, P2929, DOI 10.1109/ICIP.2006.313132
   Chen ZZ, 2019, IEEE T IMAGE PROCESS, V28, P5785, DOI 10.1109/TIP.2019.2922072
   Choudhry MS, 2016, PROCEDIA COMPUT SCI, V89, P749, DOI 10.1016/j.procs.2016.06.052
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dey V, 2010, INT ARCH PHOTOGRAMM, V38, P31
   Draper C, 2013, REMOTE SENS ENVIRON, V137, P288, DOI 10.1016/j.rse.2013.06.013
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Gao B, 2015, IEEE GEOSCI REMOTE S, V12, P2341, DOI 10.1109/LGRS.2015.2477500
   Gao H, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102427
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Hai YZ., 2006, 12 INT MULT MOD C, DOI 10.1109/MMMC.2006.1651364
   Halkidi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P187, DOI 10.1109/ICDM.2001.989517
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Imamura K, 2011, SIGNAL PROCESSING IM, DOI 10.1007/978-3-642-27183-0_1
   Khair U, 2017, J PHYS CONF SER, V930, DOI 10.1088/1742-6596/930/1/012002
   Kragic D., 2015, HOUSEHOLD SERVICE RO, P397, DOI [10.1016/B978-0-12-8008812.00018-9, DOI 10.1016/B978-0-12-8008812.00018-9]
   Li WY, 2020, IEEE T GEOSCI REMOTE, V58, P8490, DOI 10.1109/TGRS.2020.2988265
   Liu XF, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P814, DOI 10.1109/CISP.2013.6745277
   Lu T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131588
   Matkovic K., 2005, Computational Aesthetics, P159
   MEILA M, 2003, LECT NOTES COMPUTER
   Memon F, 2015, MEHRAN UNIV RES J EN, V34, P379
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Neto A.M., 2013, IEEE Proceedings of the 13th International Conference on Mobile Robots and Competitions (Robotica 2013), P1, DOI [10.1109/Robotica.2013.6623521, DOI 10.1109/ROBOTICA.2013.6623521]
   Ossama O, 2011, EGYPT INFORM J, V12, P45, DOI 10.1016/j.eij.2011.02.007
   Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277
   Prabha D S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9i8/87907
   Pradhan B, 2020, IEEE ACCESS, V8, P121942, DOI 10.1109/ACCESS.2020.3006914
   Pugazhenthi A, 2020, IET IMAGE PROCESS, V14, P1273, DOI 10.1049/iet-ipr.2018.5271
   Pugazhenthi A., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1279, DOI 10.1109/ICCSP.2014.6950057
   Rohith G, 2021, VISUAL COMPUT, V37, P1965, DOI 10.1007/s00371-020-01957-8
   Rohlf F.J., 1974, Annual Rev Ecol Syst, V5, P101, DOI 10.1146/annurev.es.05.110174.000533
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang PP, 2020, IEEE J-STARS, V13, P2161, DOI 10.1109/JSTARS.2020.2995158
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZB, 2020, ARTIF INTELL REV, V53, P5637, DOI 10.1007/s10462-020-09830-9
   Wei SD, 2008, IEEE T IMAGE PROCESS, V17, P2227, DOI 10.1109/TIP.2008.2004615
   Wen F, 2018, IEEE GEOSCI REMOTE S, V15, P1090, DOI 10.1109/LGRS.2018.2829028
   Xu, 2012, STUDIES FUZZINESS SO, P279, DOI [10.1007/978-3-642-28406-9_1, DOI 10.1007/978-3-642-28406-9_1]
   Zalik KR, 2011, PATTERN RECOGN LETT, V32, P221, DOI 10.1016/j.patrec.2010.08.007
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6
NR 48
TC 3
Z9 3
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17959
EP 17987
DI 10.1007/s11042-022-12769-4
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000009
DA 2024-07-18
ER

PT J
AU Afif, M
   Ayachi, R
   Said, Y
   Pissaloux, E
   Atri, M
AF Afif, Mouna
   Ayachi, Riadh
   Said, Yahia
   Pissaloux, Edwige
   Atri, Mohamed
TI An efficient object detection system for indoor assistance navigation
   using deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor navigation; Blind and visually impaired persons; Deep learning;
   Deep convolutional neural networks (DCNN); Indoor object detection
ID RECOGNITION; TRACKING
AB Building new systems used for indoor objects detection and indoor assistance navigation presents a very crucial task especially in artificial intelligence and computer science fields. The number of blind and visually impaired persons (VIP) is increasing day by day. In order to help this category of persons, we propose to develop a new indoor object-detection system based on deep convolutional neural networks (DCNNs). The proposed system is developed based on the one-stage neural network RetinaNet. In order to train and evaluate the developed system, we propose to build a new indoor objects dataset which also presents 11,000 images containing 24 indoor landmark objects highly valuable for indoor assistance navigation. The proposed dataset provides a high intra and inter-class variation and various challenging conditions which aim to build a robust detection system for blind and visually impaired people (VIP) mobility. Experimental results prove the high detection performances of the developed indoor objects detection and recognition system. We obtained a detection accuracy reaching up to 98.75% mAP and 62 FPS as a detection speed.
C1 [Afif, Mouna; Ayachi, Riadh; Said, Yahia] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect E E, Monastir, Tunisia.
   [Said, Yahia] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Pissaloux, Edwige] Univ Rouen Normandy, LITIS Lab, Rouen, France.
   [Pissaloux, Edwige] Univ Rouen Normandy, CNRS FR 3638, Rouen, France.
   [Atri, Mohamed] King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
C3 Universite de Monastir; Northern Border University; Universite de Rouen
   Normandie; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Information Sciences & Technologies (INS2I); Universite de
   Rouen Normandie; King Khalid University
RP Afif, M (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect E E, Monastir, Tunisia.
EM mouna.afif@outlook.fr
RI ATRI, Mohamed/C-4069-2014; Said, Yahia/A-7333-2018; Ayachi,
   Riadh/AAU-2160-2020
OI ATRI, Mohamed/0000-0001-8528-5647; Said, Yahia/0000-0003-0613-4037;
   Ayachi, Riadh/0000-0003-4683-9592
FU Deputyship for Research & Innovation, Ministry of Education in Saudi
   Arabia [IF_2020_NBU_206]
FX The authors extend their appreciation to the Deputyship for Research &
   Innovation, Ministry of Education in Saudi Arabia for funding this
   research work through the project number "IF_2020_NBU_206".
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   AFIF M, 2018, INT C SCI EL TECHN I, P364, DOI DOI 10.1007/978-3-030-21005-2_35
   Afif M, 2020, NEURAL PROCESS LETT, V51, P2265, DOI 10.1007/s11063-020-10197-9
   Afif M, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON MEASUREMENTS & NETWORKING (M&N 2019)
   [Anonymous], 2013, VIS IMP BLINDN
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Bai Z, 2015, PROCEDIA COMPUT SCI, V53, P391, DOI 10.1016/j.procs.2015.07.316
   Baimukashev D, 2019, MACH LEARN KNOW EXTR, V1, P883, DOI 10.3390/make1030051
   Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188
   Buyval A, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268809
   Chae HW, 2016, INT CONF UBIQ ROBOT, P405, DOI 10.1109/URAI.2016.7734070
   Ding W, 2016, OPTIK, V127, P9095, DOI 10.1016/j.ijleo.2016.06.126
   Ding X, 2017, 2017 23 INT C AUT CO, P1
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Faragher RM, 2012, IEEE POSITION LOCAT, P120, DOI 10.1109/PLANS.2012.6236873
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang LX, 2016, ADV INTELL SYST COMP, V302, P859, DOI 10.1007/978-3-319-08338-4_62
   Kingma D. P., 2014, arXiv
   Legge GE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076783
   Li C, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P449, DOI 10.1109/ICACI.2018.8377501
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu PC, 2018, NONLINEAR DYNAM, V94, P1803, DOI 10.1007/s11071-018-4458-9
   Mei S, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013023
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Satyawana S, 2016, SCI ENG TECHNOL, V67
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CQ, 2017, IEEE INT C INT ROBOT, P109, DOI 10.1109/IROS.2017.8202145
   Zhang XC, 2015, IEEE SYS MAN CYBERN, P1458, DOI 10.1109/SMC.2015.258
   Zia S, 2017, IEEE INT CONF COMP V, P887, DOI 10.1109/ICCVW.2017.109
NR 32
TC 5
Z9 5
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16601
EP 16618
DI 10.1007/s11042-022-12577-w
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100006
DA 2024-07-18
ER

PT J
AU Dhiman, B
   Kumar, Y
   Kumar, M
AF Dhiman, Bhumica
   Kumar, Yogesh
   Kumar, Munish
TI Fruit quality evaluation using machine learning techniques: review,
   motivation and future perspectives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Feature extraction; Fruit quality detection; Machine
   learning; Quality detection
ID IMAGE-ANALYSIS; CLASSIFICATION; SEGMENTATION; DEFECTS; RECOGNITION;
   MANGOES; SYSTEM
AB In the field of agriculture and food processing, quality evaluation is a significant parameter to increase benefits and accommodations for individual life. The presence of diseases and pesticides is additionally the major factor that emerges the need for quality evaluation. Although it can be done manually, some inconsistencies and high costs led to the invention of automatic systems. The automation makes the same process more consistent and time-efficient. Fruit quality detection identifies the defects in fruits by uploading fruit images to the system. Till now, many researchers have used different techniques for quality detection based on image features and have worked on the improvement of quality parameters. The structure of this article comprises an introduction, motivation for doing this work, a background that entails block diagram, benefits, feature extraction, and classification techniques for fruit quality assessment. In view of the earlier research, the various kinds of features, namely, shape, size, color, or texture are extracted, and for classification, different machine learning methods are applied such as k-nearest neighbors, support vector machine, neural network, etc. In this article, a comparison of different techniques has been carried out that are put forward by researchers for fruit quality detection. A review of the number of papers is presented that emphasizes popular machine learning models for fruit quality classification.
C1 [Dhiman, Bhumica; Kumar, Yogesh] Ind Univ, Ind Inst Technol & Engn, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM yogesh.arora10744@gmail.com; munishcse@gmail.com
RI kumar, yogesh/AAD-8469-2021; Kumar, Munish/P-7756-2018
OI kumar, yogesh/0000-0002-2879-0441; Kumar, Munish/0000-0003-0115-1620
CR Al Ohali Y, 2011, J KING SAUD UNIV-COM, V23, P29, DOI 10.1016/j.jksuci.2010.03.003
   Ashok V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P308, DOI 10.1109/IC3I.2014.7019807
   Azizah LM, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P242, DOI 10.1109/ICCSCE.2017.8284412
   Balan PS., 2018, INT J RES APPL SCI E, V6, P217, DOI [10.22214/ijraset.2018.3035, DOI 10.22214/IJRASET.2018.3035]
   Bargoti S, 2017, J FIELD ROBOT, V34, P1039, DOI 10.1002/rob.21699
   Cavallo DP, 2019, COMPUT ELECTRON AGR, V156, P558, DOI 10.1016/j.compag.2018.12.019
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   da Costa AZ, 2020, BIOSYST ENG, V190, P131, DOI 10.1016/j.biosystemseng.2019.12.003
   Dhakate M, 2015, NAT CONF COMPUT VIS
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Dubey SR, 2015, J INTELL SYST, V24, P405, DOI 10.1515/jisys-2014-0079
   Gao HS, 2010, IFIP ADV INF COMM TE, V317, P133
   Gómez-Sanchis J, 2012, EXPERT SYST APPL, V39, P780, DOI 10.1016/j.eswa.2011.07.073
   Hameed K, 2018, IMAGE VISION COMPUT, V80, P24, DOI 10.1016/j.imavis.2018.09.016
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Itakura K, 2019, HORTICULTURAE, V5, DOI 10.3390/horticulturae5010002
   Jawale D, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1080, DOI 10.1109/ICCSP.2017.8286542
   Kamavisdar P., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1005
   Kanakaraddi S, 2014, P INT C ADV ENG TECH, P46
   Keresztes B, 2018, P 14 INT C PREC AGR, P1, DOI DOI 10.3897/ZOOKEYS.792.25683
   Kestur R, 2019, ENG APPL ARTIF INTEL, V77, P59, DOI 10.1016/j.engappai.2018.09.011
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khoje S., 2013, Int J Eng Technol, V5, P3251, DOI DOI 10.1016/J.POSTHARVBIO.2013.02.016
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lu HF, 2011, J FOOD ENG, V104, P149, DOI 10.1016/j.jfoodeng.2010.12.007
   Mishra V.K., 2017, SAMRIDDHI: A Journal of Physical Sciences, Engineering and Technology, V9, P21
   Muresan H, 2018, ACTA U SAPIEN INFORM, V10, P26, DOI 10.2478/ausi-2018-0002
   Naik S, 2019, P INT C SUST COMP SC, P670
   Naik S., 2017, INT J COMPUTER APPL, V170, P22, DOI DOI 10.5120/IJCA2017914937
   Nandi CS, 2016, IEEE SENS J, V16, P6387, DOI 10.1109/JSEN.2016.2580221
   Naranjo-Torres J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103443
   Nie FP, 2021, IEEE T NEUR NET LEAR, V32, P1547, DOI 10.1109/TNNLS.2020.2984958
   Pandey R., 2013, International Journal of Computer Applications (0975 - 8887), V81, P29, DOI DOI 10.5120/14209-2455
   Pujari J. D., 2014, Acta Technologica Agriculturae, V17, P29
   Rokunuzzaman M., 2013, Agricultural Engineering International: CIGR Journal, V15, P173
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Saldaña Erick, 2013, Braz. J. Food Technol., V16, P254
   Pereira LFS, 2018, COMPUT ELECTRON AGR, V145, P76, DOI 10.1016/j.compag.2017.12.029
   Sendin K, 2018, FOOD CHEM, V243, P311, DOI 10.1016/j.foodchem.2017.09.133
   Sengupta S., 2014, International Journal of Computer Science and Information Technologies, V5, P4638
   Shao LH, 2017, J FOOD MEAS CHARACT, V11, P1969, DOI 10.1007/s11694-017-9579-1
   Unay D, 2006, POSTHARVEST BIOL TEC, V42, P271, DOI 10.1016/j.postharvbio.2006.06.010
   Varjao JOR., 2019, Int J Adv Struct Eng, V6, P59, DOI [10.22161/ijaers.678, DOI 10.22161/IJAERS.678]
   Vasumathi MT., 2019, INT J RECENT TECHNOL, V7, P556
   Vaviya H., 2019, SSRN ELECT J, DOI [10.2139/ssrn.3368903, DOI 10.2139/SSRN.3368903]
   Rivera NV, 2014, BIOSYST ENG, V122, P91, DOI 10.1016/j.biosystemseng.2014.03.009
   Wang L, 2014, P INT CONF BUS INTEL, P44, DOI 10.1109/BIFE.2013.11
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Yamamoto K, 2014, SENSORS-BASEL, V14, P12191, DOI 10.3390/s140712191
   Zaborowicz M, 2017, SCI HORTIC-AMSTERDAM, V218, P222, DOI 10.1016/j.scienta.2017.02.001
   Zhu NY, 2018, INT J AGR BIOL ENG, V11, P32, DOI 10.25165/j.ijabe.20181104.4475
NR 51
TC 17
Z9 18
U1 17
U2 105
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16255
EP 16277
DI 10.1007/s11042-022-12652-2
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600006
DA 2024-07-18
ER

PT J
AU Zhao, JC
   Wang, YH
   Li, MY
   Zhang, QW
AF Zhao, Jinchao
   Wang, Yihan
   Li, Mingying
   Zhang, Qiuwen
TI Fast coding unit size decision based on deep reinforcement learning for
   versatile video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CU size decision; Reinforcement learning; Deep reinforcement learning;
   Markov decision processing
ID FAST CU PARTITION
AB Video coding has long been looking for a more available approach than the greedy method. The quad-tree with nested multi-type tree (QTMT) structure including quad-tree (QT) and multi-type tree (MTT) results in highly coding complexity in Versatile Video Coding (VVC). In addition, the rapid progress in deep learning (DL) is attracting increasing attention in the video coding community. Therefore, this paper proposes a fast Coding Unit (CU) splitting decision method based on Deep reinforcement learning (DRL) for VVC to decrease the coding complexity. Specifically, the 32 x 32 CU for splitting is considered as a Markov decision process (MDP), the CU splitting situations at a certain node as state, the splitting modes decision as actions, the reduction or increase in rate-distortion (RD) cost as the immediate rewards or punishments, and the encoder as an agent to make coding decisions successively. The simulation results demonstrate that the coding time reduction (CTR) of the proposed approach can lead to a reduction of about 54.38% while maintaining coding performance, which can realize a trade-off between the complexity reduction and coding efficiency.
C1 [Zhao, Jinchao; Wang, Yihan; Li, Mingying; Zhang, Qiuwen] Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Zhang, QW (corresponding author), Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
EM zhangqwen@126.com
RI wang, yihan/HTN-8802-2023
FU National Natural Science Foundation of China [61771432, 61302118]; Basic
   Research Projects of Education Department of Henan [21zx003, 20A880004];
   Key Research and Development Program of Henan [202102210179]
FX This work was supported in part by the National Natural Science
   Foundation of China No.61771432, and 61302118, the Basic Research
   Projects of Education Department of Henan No. 21zx003, and 20A880004,
   and the Key Research and Development Program of Henan No. 202102210179.
CR Amestoy T, 2020, IEEE T IMAGE PROCESS, V29, P1313, DOI 10.1109/TIP.2019.2938670
   Amna M, 2020, J REAL-TIME IMAGE PR, V17, P1971, DOI 10.1007/s11554-020-00998-5
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bjotegaard G., 2001, VCEGM33
   Bouaafia S, 2020, J REAL-TIME IMAGE PR, V17, P185, DOI 10.1007/s11554-019-00936-0
   Boyce J., 2018, JVETJ1010
   Bross B, 2020, IEEE T CIRC SYST VID, V30, P1226, DOI 10.1109/TCSVT.2019.2949619
   Chen J., 2019, P 2019 IEEE VIS COMM, P1
   Chen JON, 2019, INT CONF SYST SCI EN, P308, DOI [10.1109/ICSSE.2019.8823436, 10.1109/icsse.2019.8823436]
   Chen JJ, 2021, IEEE T CYBERNETICS, V51, P5993, DOI 10.1109/TCYB.2019.2960762
   Chen K, 2018, 2018 14TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P864
   Chung CH, 2017, I S INTELL SIG PROC, P570, DOI 10.1109/ISPACS.2017.8266543
   Correa G, 2014, IEEE I C ELECT CIRC, P239, DOI 10.1109/ICECS.2014.7049966
   De-Luxán-Hernández S, 2018, IEEE INT SYM MULTIM, P135, DOI 10.1109/ISM.2018.00032
   Fan J., 2020, LEARNING DYNAMICS CO, P486, DOI DOI 10.48550/ARXIV.1901.00137
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Jin ZP, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Katayama T, 2018, CONFERENCE PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P115, DOI 10.1109/INFOCT.2018.8356852
   Kim K, 2019, IEEE T CIRC SYST VID, V29, P1462, DOI 10.1109/TCSVT.2018.2839113
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/ICIP.2019.8803421, 10.1109/icip.2019.8803421]
   Li N, 2019, J VIS COMMUN IMAGE R, V60, P276, DOI 10.1016/j.jvcir.2019.02.021
   Lin TL, 2018, IEEE INT C ELECTR TA
   Park SH, 2019, IEEE ACCESS, V7, P172597, DOI 10.1109/ACCESS.2019.2956196
   REN W, 2019, P IEEE WIR COMM NETW, P1
   Segall A, 2017, JVETH1002 ITUT ISOIE
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Wang Z, 2017, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2017.70
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yu XY, 2015, IEEE IMAGE PROC, P1285, DOI 10.1109/ICIP.2015.7351007
   Zhang QW, 2020, IEEE ACCESS, V8, P203516, DOI 10.1109/ACCESS.2020.3036858
   Zhang QW, 2021, MULTIMEDIA SYST, V27, P1, DOI 10.1007/s00530-020-00688-z
   Zhang QW, 2020, IEEE ACCESS, V8, P117539, DOI 10.1109/ACCESS.2020.3004580
   Zhao JC, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8883214
   Zhu LW, 2018, IEEE T BROADCAST, V64, P681, DOI 10.1109/TBC.2017.2762470
NR 39
TC 2
Z9 2
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16371
EP 16387
DI 10.1007/s11042-022-12558-z
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600004
DA 2024-07-18
ER

PT J
AU Coupet, M
   Urruty, T
   Leelanupab, T
   Naudin, M
   Bourdon, P
   Maloigne, CF
   Guillevin, R
AF Coupet, Matthieu
   Urruty, Thierry
   Leelanupab, Teerapong
   Naudin, Mathieu
   Bourdon, Pascal
   Maloigne, Christine Fernandez
   Guillevin, Remy
TI A multi-sequences MRI deep framework study applied to glioma
   classfication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-sequences; MRI; Glioma classification; Deep leaning model; Model
   interpretability
ID NEURAL-NETWORKS; SEGMENTATION
AB Glioma is one of the most important central nervous system tumors, ranked 15th in the most common cancer for men and women. Magnetic Resonance Imaging (MRI) represents a common tool for medical experts to the diagnosis of glioma. A set of multi-sequences from an MRI is selected according to the severity of the pathology. Our proposed approach aims moreto create a computer-aided system that is capable of helping morethe expert diagnose the brain gliomas. moreWe propose a supervised learning regime based on a convolutional neural network based framework and transfer learning techniques. Our research morefocuses on the performance of different pre-trained deep learning models with respect to different MRI sequences. We highlight the best combinations of such model-MRI sequence couple for our specific task of classifying healthy brain against brain with glioma. moreWe also propose to visually analyze the extracted deep features for studying the existing relation of the MRI sequences and models. This interpretability analysis gives some hints for medical expert to understand the diagnosis made by the models. Our study is based on the well-known BraTS datasets including multi-sequence images and expert diagnosis.
C1 [Coupet, Matthieu; Urruty, Thierry] Univ Poitiers, XLIM Lab, UMR CNRS 7252, Poitiers, France.
   [Coupet, Matthieu; Urruty, Thierry; Naudin, Mathieu; Bourdon, Pascal; Maloigne, Christine Fernandez; Guillevin, Remy] Univ Poitiers, Common Lab CNRS Siemens, I3M, Poitiers, France.
   [Coupet, Matthieu; Urruty, Thierry; Naudin, Mathieu; Bourdon, Pascal; Maloigne, Christine Fernandez; Guillevin, Remy] Hosp Poitiers, Poitiers, France.
   [Leelanupab, Teerapong] King Mongkuts Inst Technol Ladkrabang KMITL, Fac Informat Technol, Bangkok 10520, Thailand.
   [Naudin, Mathieu; Bourdon, Pascal; Maloigne, Christine Fernandez; Guillevin, Remy] Univ Poitiers Hosp, CHU, Poitiers, France.
   [Guillevin, Remy] Univ Poitiers, UMR CNRS 7348, DACTIM MIS LMA Lab, Poitiers, France.
C3 Universite de Poitiers; Universite de Poitiers; Universite de Poitiers;
   King Mongkuts Institute of Technology Ladkrabang; CHU Poitiers;
   Universite de Poitiers; Universite de Poitiers
RP Leelanupab, T (corresponding author), King Mongkuts Inst Technol Ladkrabang KMITL, Fac Informat Technol, Bangkok 10520, Thailand.
EM teerapong@it.kmitl.ac.th
RI Naudin, Mathieu/AGF-6727-2022
OI Urruty, Thierry/0000-0003-1339-1920; Leelanupab,
   Teerapong/0000-0002-8117-0612
FU Academic Melting Pot Program from the King Mongkut's Institute of
   Technology Ladkrabang (KMITL); Alzheimer's Disease Neuroimaging
   Initiative (ADNI) (National Institutes of Health) [U01 AG024904]; DOD
   ADNI (Department of Defense) [W81XWH-12-2-0012]; National Institute on
   Aging; National Institute of Biomedical Imaging and Bioengineering;
   AbbVie; Alzheimer's Association; Alzheimer's Drug Discovery Foundation;
   Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company;
   CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli
   Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd; Genentech, Inc.;
   Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy
   Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research
   & Development LLC.; Lumosity; Lundbeck; Merck Co., Inc.; Meso Scale
   Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis
   Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier;
   Takeda Pharmaceutical Company; Transition Therapeutics; Canadian
   Institutes of Health Research
FX This work was supported in part by the Academic Melting Pot Program from
   the King Mongkut's Institute of Technology Ladkrabang (KMITL) for the
   fiscal year 2019.; Data collection and sharing for this project was
   funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI)
   (National Institutes of Health Grant U01 AG024904) and DOD ADNI
   (Department of Defense award numberW81XWH-12-2-0012). ADNI is funded by
   the National Institute on Aging, the National Institute of Biomedical
   Imaging and Bioengineering, and through generous contributions from the
   following: AbbVie, Alzheimer's Association; Alzheimer's Drug Discovery
   Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers
   Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan
   Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La
   Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE
   Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &
   Development, LLC.; Johnson & Johnson Pharmaceutical Research &
   Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale
   Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis
   Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier;
   Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian
   Institutes of Health Research is providing funds to support ADNI
   clinical sites in Canada. Private sector contributions are facilitated
   by the Foundation for the National Institutes of Health
   (www.fnih.org).The grantee organization is the Northern California
   Institute for Research and Education, and the study is coordinated by
   the Alzheimer's Therapeutic Research Institute at the University of
   Southern California. ADNI data are disseminated by the Laboratory for
   Neuro Imaging at the University of Southern California.
CR Abdul Khalid N., 2011, INT J COMPUTER SCI E, V3, P980
   [Anonymous], 2018, ARXIV180100415
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bahrami K, 2017, MED PHYS, V44, P1661, DOI 10.1002/mp.12132
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Benou A, 2017, MED IMAGE ANAL, V42, P145, DOI 10.1016/j.media.2017.07.006
   Bergeest J.P., 2008, Bildverarbeitung fur die Medizin 2008, P36
   Bermudez C, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293515
   Betancur J, 2019, J NUCL MED, V60, P664, DOI 10.2967/jnumed.118.213538
   Betancur J, 2018, JACC-CARDIOVASC IMAG, V11, P1654, DOI 10.1016/j.jcmg.2018.01.020
   Chen T, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.650629
   Chen W, 2019, LECT NOTES COMPUT SC, V11384, P358, DOI 10.1007/978-3-030-11726-9_32
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Cho HH, 2017, IEEE ENG MED BIO, P3081, DOI 10.1109/EMBC.2017.8037508
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Citak-Er F, 2018, COMPUT BIOL MED, V99, P154, DOI 10.1016/j.compbiomed.2018.06.009
   Coupet Matthieu, 2020, Neural Information Processing. 27th International Conference, ICONIP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12532), P113, DOI 10.1007/978-3-030-63830-6_10
   Dequidt P, 2021, EXPLORING RADIOLOGIC
   Dequidt P, 2019, I CON ADV BIOMED ENG, P20, DOI 10.1109/icabme47164.2019.8940295
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Feng Y, 2018, ARXIV181107491
   Ge CJ, 2018, IEEE ENG MED BIO, P5894, DOI 10.1109/EMBC.2018.8513556
   Goodenberger ML, 2012, CANCER GENET-NY, V205, P613, DOI 10.1016/j.cancergen.2012.10.009
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Jäger F, 2009, IEEE T MED IMAGING, V28, P137, DOI 10.1109/TMI.2008.2004429
   Kalaiselvi T, 2015, NAT C NEW HOR COMP I, V1, P140
   Kalaiselvi T, 2020, INT J IMAG SYST TECH, V30, P926, DOI 10.1002/ima.22433
   Kauffmann J, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107198
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   KLEIHUES P, 1995, GLIA, V15, P211, DOI 10.1002/glia.440150303
   Kline TL, 2017, J DIGIT IMAGING, V30, P442, DOI 10.1007/s10278-017-9978-1
   Korfiatis Panagiotis, 2017, J Digit Imaging, V30, P622, DOI 10.1007/s10278-017-0009-z
   Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4
   Li HL, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00491
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Makropoulos A, 2018, NEUROIMAGE, V170, P231, DOI 10.1016/j.neuroimage.2017.06.074
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Montavon G., 2019, EXPLAINABLE INTERPRE, V11700, P193, DOI [10.1007/978-3-030-28954-6_10, DOI 10.1007/978-3-030-28954-6_10]
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pereira Sergio, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P131, DOI 10.1007/978-3-319-30858-6_12
   Ramon A.J., 2018, 2018 IEEE nuclear science symposium and medical imaging conference proceedings (NSS/MIC), P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roser M, 2020, CANC OUR WORLD DATA
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samek Wojciech, 2019, EXPLAINABLE INTERPRE
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Sun Jian, 2016, ADV NEURAL INFORM PR, P10
   Sun XF, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0064-y
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   TAJBAKHSH N, 2017, ADV COMPUT VIS PATT
   Tan MX, 2019, PR MACH LEARN RES, V97
   Urbanska K, 2014, WSPOLCZESNA ONKOL, V18, P307, DOI 10.5114/wo.2014.40559
   Wang SS, 2016, I S BIOMED IMAGING, P514, DOI 10.1109/ISBI.2016.7493320
   Wason R, 2018, COGN SYST RES, V52, P701, DOI 10.1016/j.cogsys.2018.08.023
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
NR 65
TC 7
Z9 8
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13563
EP 13591
DI 10.1007/s11042-022-12316-1
EA FEB 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000762173600006
PM 35250358
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Patil, BM
   Burkpalli, V
AF Patil, Bhagya M.
   Burkpalli, Vishwanath
TI Segmentation of cotton leaf images using a modified chan vese method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deformable model; Geometric; Parametric; Cotton leaf images; Modified
   chan vese
ID FORCE; MODEL; FIELD
AB Segmenting the leaf images from the complex background is the current research topic. So, in this paper, we propose an algorithm to segment the leaf image from the natural background. Diverse methods exist in the literature, like region-based, edge-based, clustered-based, deformable models. Among these, deformable models are more advantageous, which leads to the use of the method for leaf segmentation. There are two types of deformable models, namely geometric and parametric models. The geometric model has many advantages over the parametric model; hence, we present the comparative study of the proposed model and other well-known algorithms. The proposed method combines the chan vese method with the level set method without re-initialization. It also uses bilateral filtering to remove the noise from the image for more vital image information, which helps in the fast evolution process. The main objective of the method is to segment a leaf from natural background. For our study, the model used the cotton leaf database with nearly 300 images. The results show that the proposed model modified chan vese method gives better results than other state-of-the-art performance parameters. The proposed method parameters Precision, Recall, Sensitivity, Specificity, Accuracy., Jaccard Index, F1 score values are 0.9685, 0.9949, 0.9949, 0.9817, 0.8897,0.9388 respectively.
C1 [Patil, Bhagya M.] REVA Univ, Sch CSA, Bengaluru, India.
   [Burkpalli, Vishwanath] PDA Coll Engn, Dept Informat Sci & Engn, Kalaburgi, India.
C3 REVA University; Poojya Dodappa Appa College of Engineering
RP Patil, BM (corresponding author), REVA Univ, Sch CSA, Bengaluru, India.
EM patil.bhagya@gmail.com; vishwacmd@gmail.com
CR Agrawal P., 2016, ARTIF INTELL
   Bell J., 2019, LEAF SEGMENTATION CL
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Cerutti G., 2011, GUIDING ACTIVE CONTO
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   De Vylder J, 2011, INT C COMP VIS COMP
   Deenan Suryaprabha, 2020, Journal of the Institution of Engineers (India): Series C (Mechanical, Production, Aerospace and Marine Engineering), V101, P807, DOI 10.1007/s40032-020-00592-5
   Fang JX, 2019, IEEE ACCESS, V7, P97492, DOI 10.1109/ACCESS.2019.2929659
   Foulonneau A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P413
   Gao LW, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104924
   Grand-Brochier M, 2013, P INT WORKSH VID IM
   Huang XC, 2014, C IND ELECT APPL, P1091, DOI 10.1109/ICIEA.2014.6931327
   Jamaludin S, 2016, J TEKNOL, V78, P13
   Jia DY, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102516
   Kalaivani S, 2020, MULTIMED TOOLS APPL, V79, P9145, DOI 10.1007/s11042-018-7126-7
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kuo KT, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212536
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   Li CM, 2005, PROC CVPR IEEE, P430
   Li YF, 2005, 2005 INT C NEUR NETW, V2
   [梁广顺 Liang Guangshun], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P2231
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mandal D., 2014, ADV COMPUTING NETWOR, V27
   Nesaratnam R J, 2015, 2015 INT C INN INF E, P1, DOI [10.1109/ICIIECS.2015.7193115, DOI 10.1109/ICIIECS.2015.7193115]
   Ning JF, 2007, PATTERN RECOGN LETT, V28, P58, DOI 10.1016/j.patrec.2006.06.014
   Niu C., 2016, COMPUTER COMPUTING T
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3
   Shantkumari M, 2021, MULTIMED TOOLS APPL, V80, P8861, DOI 10.1007/s11042-020-09853-y
   Singh J., 2018, INT C ISMAC COMP VIS
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Srikham M, 2012, INT C PATT RECOG, P1989
   Sun G, 2018, PLANT DIS RECOGNITIO
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Tiilikainen NikolasPetteri., 2007, A comparative study of active contour snakes, P21
   Wu Y, 2010, 2010 20 INT C PATT R
   Xu C, 2006, ACTIVE CONTOURS DEFO
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
   Zhibin Wang, 2018, Information Processing in Agriculture, V5, P1, DOI 10.1016/j.inpa.2017.09.005
NR 40
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15419
EP 15437
DI 10.1007/s11042-022-12436-8
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600005
DA 2024-07-18
ER

PT J
AU Yang, H
   Alsadoon, A
   Prasad, PWC
   Al-Dala'in, T
   Rashid, TA
   Maag, A
   Alsadoon, OH
AF Yang, Hui
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Dala'in, Thair
   Rashid, Tarik A.
   Maag, Angelika
   Alsadoon, Omar Hisham
TI Deep learning neural networks for emotion classification from text:
   enhanced leaky rectified linear unit activation and weighted loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Emotion classification; Text mining;
   Rectified linear unit; deep learning
ID SENTIMENT ANALYSIS; RECOGNITION; DROPOUT
AB Accurate emotion classification for online reviews is vital for business organizations to gain deeper insights into markets. Although deep learning has been successfully implemented in this area, accuracy and processing time are still major problems preventing it from reaching its full potential. This paper proposes an Enhanced Leaky Rectified Linear Unit activation and Weighted Loss (ELReLUWL) algorithm for enhanced text emotion classification and faster parameter convergence speed. This algorithm includes the definition of the inflection point and the slope for inputs on the left side of the inflection point to avoid gradient saturation. It also considers the weight of samples belonging to each class to compensate for the influence of data imbalance. Convolutional Neural Network (CNN) combined with the proposed algorithm to increase the classification accuracy and decrease the processing time by eliminating the gradient saturation problem and minimizing the negative effect of data imbalance, demonstrated on a binary sentiment problem. All work was carried out using supervised deep learning. The results for accuracy and processing time are obtained by using different datasets and different review types. The results show that the proposed solution achieves better classification performance in different data scenarios and different review types. The proposed model takes less convergence time to achieve model optimization with seven epochs against the current convergence time of 11.5 epochs on average. The proposed solution improves accuracy and reduces the processing time of text emotion classification. The solution provides an average class accuracy of 96.63% against a current average accuracy of 91.56%. It also provides a processing time of 23.3 milliseconds compared to the current average processing time of 33.2 milliseconds. Finally, this study solves the issues of gradient saturation and data imbalance. It enhances overall average class accuracy and decreases processing time.
C1 [Yang, Hui; Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair; Maag, Angelika] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./P-3473-2019;
   Rashid, Tarik A./HLX-0184-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; Rashid, Tarik A./0000-0002-8661-258X; Alsadoon,
   Omar Hisham/0000-0001-7797-6392
CR [Anonymous], 2015, Effective LSTMs for target-dependent sentiment classification
   Bengio Y, 2000, NEURAL COMPUT, V12, P1889, DOI 10.1162/089976600300015187
   Bose Ranjit, 2011, International Journal of Business Intelligence Research, V2, P1, DOI 10.4018/jbir.2011100101
   Chatterjee A, 2019, COMPUT HUM BEHAV, V93, P309, DOI 10.1016/j.chb.2018.12.029
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Colneric N, 2020, IEEE T AFFECT COMPUT, V11, P433, DOI 10.1109/TAFFC.2018.2807817
   Dhaoui C, 2017, J CONSUM MARK, V34, P480, DOI 10.1108/JCM-03-2017-2141
   Phan DA, 2021, IEEE T AFFECT COMPUT, V12, P682, DOI 10.1109/TAFFC.2018.2885304
   Gu XD, 2017, NEURAL PROCESS LETT, V46, P581, DOI 10.1007/s11063-017-9605-7
   Hanafy M, 2018, LECT NOTES ARTIF INT, V11081, P281, DOI 10.1007/978-3-319-99978-4_22
   Hara K, 2015, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2015.7280578
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Jain VK, 2018, INT J ENTERP INF SYS, V14, P77, DOI 10.4018/IJEIS.2018040105
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002
   Kraus M, 2017, DECIS SUPPORT SYST, V104, P38, DOI 10.1016/j.dss.2017.10.001
   Lin DZ, 2018, NEUROCOMPUTING, V272, P258, DOI 10.1016/j.neucom.2017.06.078
   Liu B, 2020, J AMB INTEL HUM COMP, V11, P451, DOI 10.1007/s12652-018-1095-6
   Macêdo D, 2019, EXPERT SYST APPL, V124, P271, DOI 10.1016/j.eswa.2019.01.066
   Mahmoudi N, 2018, DECIS SUPPORT SYST, V112, P23, DOI 10.1016/j.dss.2018.06.002
   Minglei Li, 2017, IEEE Transactions on Affective Computing, V8, P443, DOI [10.1080/10298436.2017.1309197, 10.1109/TAFFC.2017.2723012]
   Mohammad SM, 2013, ARXIV PREPRINT ARXIV
   Mou Lili, 2016, TRANSFERABLE ARE NEU
   Mundra S, 2017, LECT NOTES ARTIF INT, V10235, P337, DOI 10.1007/978-3-319-57529-2_27
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Poernomo A, 2018, NEURAL NETWORKS, V104, P60, DOI 10.1016/j.neunet.2018.03.016
   Qian S, 2018, NEUROCOMPUTING, V272, P204, DOI 10.1016/j.neucom.2017.06.070
   Randhawa S, 2021, MULTIMED TOOLS APPL, V80, P4729, DOI 10.1007/s11042-020-09900-8
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steno P, 2021, J SUPERCOMPUT, V77, P3840, DOI 10.1007/s11227-020-03418-4
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Sun X, 2020, MULTIMED TOOLS APPL, V79, P5439, DOI 10.1007/s11042-018-5748-4
   Sun X, 2020, MULTIMED TOOLS APPL, V79, P9687, DOI 10.1007/s11042-018-5665-6
   Sun X, 2016, NEUROCOMPUTING, V210, P227, DOI 10.1016/j.neucom.2016.02.077
   Tang Y, 2015, DEEP LEARNING USING
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Wu HB, 2017, INFORM PROCESS MANAG, V53, P547, DOI 10.1016/j.ipm.2016.10.003
   Xiong SF, 2018, NEUROCOMPUTING, V275, P2459, DOI 10.1016/j.neucom.2017.11.023
   Xu RF, 2015, COGN COMPUT, V7, P226, DOI 10.1007/s12559-015-9319-y
   Yang J, 2018, ALGORITHMS, V11, DOI 10.3390/a11030028
   Yoo S, 2018, EXPERT SYST APPL, V105, P102, DOI 10.1016/j.eswa.2018.03.055
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zhang ZF, 2018, NEUROCOMPUTING, V275, P1407, DOI 10.1016/j.neucom.2017.09.080
   Zhao HZ, 2018, APPL INTELL, V48, P1707, DOI 10.1007/s10489-017-1028-7
NR 50
TC 3
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15439
EP 15468
DI 10.1007/s11042-022-12629-1
EA FEB 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600023
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ri, GI
   Kim, SJ
   Kim, MS
AF Ri, Gwang-Il
   Kim, Song-Jun
   Kim, Man-Su
TI Improved BM3D method with modified block-matching and multi-scaled
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block matching; KL divergence; Entropy; 3D filtering; Multi-scaled image
ID SPARSE; MINIMIZATION
AB BM3D-based denoising has been showing high performance in restoring images damaged by additive white noise and there has been intense research on this method and its variants. In this paper, we make three improvements on BM3D (Block-matching and 3-dimensional filtering). Block matching performs poor and affect denoising performance, especially if noise intensity is high. In the paper, we first proposed a new block similarity metric that accounts for characteristic of noise contained in the observed images in order to guarantee accuracy of block matching even in presence of high intensity noise. Second, block size is a crucial hyperparameter for BM3D. The optimal block size varies with the characteristic of images. However, it is difficult to determine such an optimal block size. We proposed a method to mitigate this difficulty in determining optimal block sizes by combining BM3D and multi-scaled images. Finally, in Aggregation of BM3D, the same weight is assigned to every block in three-dimensional structures. In fact, however, the degree with which noise is removed in each block is different. We presented a method of assigning different weights to blocks according to their respective denoising degrees. Experimental results show that the proposed method is competitive with BM3D and even many of state-of-the-art methods. Actually, it brings about 0.1 similar to 0.6 dB pickup in the PSNR (Peak Signal to Noise Ratio) value. Also, we recommend that it may get better results by applying ideas proposed in this paper individually to state-of-the-art methods.
C1 [Ri, Gwang-Il; Kim, Song-Jun; Kim, Man-Su] Kim Il Sung Univ, Fac Math, Pyongyang, North Korea.
RP Ri, GI (corresponding author), Kim Il Sung Univ, Fac Math, Pyongyang, North Korea.
EM gi.ri@iyongnamsan.edu.kp
CR Abramov SK, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2977788
   Alkinani M.H., 2016, Mathematics for Applications, V5, P93
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chavan P, 2015, INT J SCI ENG TECHNO, V4
   Dabov K., 2008, PROC 2008 INT WORKSH
   Dabov K, 2006, PROC SPIE ELECTRO IM, V5
   Dabov K., 2009, Signal Processing with Adaptive Sparse Structured Representations (SPARS'09)
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai T, 2017, IMAGE PROCESS ICIP 2
   Dai T, 2015, IEEE IMAGE PROC, P4406, DOI 10.1109/ICIP.2015.7351639
   Danielyan A, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P41, DOI 10.1109/LNLA.2009.5278404
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   He N, 2016, MULTIMED TOOLS APPL, V75, P2579, DOI 10.1007/s11042-015-2471-2
   Jain P, 2017, MULTIMED TOOLS APPL, V76, P1659, DOI 10.1007/s11042-015-3154-8
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Katkovnik V, 2017, EURASIP 2017 25 EUR, P748
   Knaus C, 2015, SIAM J IMAGING SCI, V8, P1396, DOI 10.1137/140978879
   Knaus C, 2013, IEEE IMAGE PROC, P440, DOI 10.1109/ICIP.2013.6738091
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Li YJ, 2017, IET IMAGE PROCESS, V11, P1197, DOI 10.1049/iet-ipr.2016.1110
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Poderico M., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P423, DOI 10.1109/MMSP.2010.5662058
   Singh R., 2017, IEEE T IMAGE PROCESS, V6, P7
   Singh V., 2017, IJARC, V8, P78, DOI [10.26483/ijarcs.v8i8.4614, DOI 10.26483/IJARCS.V8I8.4614]
   Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Zhang X., 2021, PROCEED IEEE INT C C, P2862, DOI [10.1109/CVPR.2014.366, DOI 10.1109/CVPR.2014.366]
   Zhang YZ, 2012, APPL MECH MATER, V220-223, P1715, DOI 10.4028/www.scientific.net/AMM.220-223.1715
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
   Zou BJ, 2018, J COMPUT SCI TECH-CH, V33, P838, DOI 10.1007/s11390-018-1859-7
NR 34
TC 7
Z9 7
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12661
EP 12679
DI 10.1007/s11042-022-12270-y
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600005
DA 2024-07-18
ER

PT J
AU Sandula, P
   Okade, M
AF Sandula, Pavan
   Okade, Manish
TI Compressed domain video zoom motion analysis utilizing CURL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zooming camera; CURL; Camera motion; Compressed domain; Block motion
   vectors; H.264 codec
ID CAMERA MOTION; MODEL; CLASSIFICATION; DESCRIPTOR
AB This paper explores the application of the concept of CURL borrowed from vector calculus to the zoom motion detection and classification problems. The interframe block motion vectors extracted from the compressed bitstream form the input to the proposed method. These block motion vectors are analyzed by partitioning the motion vector field into 4 representative quadrants followed by quantizing the block motion vectors into 3 levels and converting the block motion vectors into complex motion vector space. The resultant vector for each of the 4 quadrants is estimated followed by estimating the velocity vector between the quadrants. The CURL of the velocity field is then estimated whose magnitude essentially provides the area enclosed between the resultant quadrant motion vectors which are utilized for separating the zooming and non-zooming camera types. The zooming camera frames are further classified into zoom-in and zoom-out types utilizing the direction information (anti-clockwise/clockwise) extracted from CURL of the velocity field. The novelty here stems from the fact that a concept borrowed from vector calculus is being applied to the zoom motion analysis problem. Although handcrafted features from CURL are utilized we demonstrate its superiority over existing methods including a deep learning architecture where we show the robustness of the proposed features extracted from CURL in the presence of noise. Experimental validation carried out utilizing block motion vectors extracted using Exhaustive Search Motion Estimation algorithm as well as H.264 decoded block motion vectors demonstrate superior performance for the proposed method both in terms of detection accuracy as well as computational complexity in comparison to existing techniques.
C1 [Sandula, Pavan; Okade, Manish] Natl Inst Technol Rourkela, Rourkela, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Sandula, P (corresponding author), Natl Inst Technol Rourkela, Rourkela, Odisha, India.
EM pavannit4@gmail.com
OI Okade, Manish/0000-0003-1500-2693
FU SERB, Government of India [ECR/2016/000112]
FX This research work is supported by SERB, Government of India under grant
   No ECR/2016/000112.
CR Abdollahian G, 2008, IEEE IMAGE PROC, P693, DOI 10.1109/ICIP.2008.4711849
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YM, 2010, IEEE SIGNAL PROC LET, V17, P197, DOI 10.1109/LSP.2009.2036879
   Deng Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P534, DOI 10.1109/ICIP.1997.638826
   Duan LY, 2006, IEEE T MULTIMEDIA, V8, P323, DOI 10.1109/TMM.2005.864344
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Ghosh S, 2017, IEEE INT C INT ROBOT, P1026, DOI 10.1109/IROS.2017.8202271
   Guironnet M, 2006, 14 EUR SIGN PROC C, P1
   Hasan MA, 2014, IEEE T CIRC SYST VID, V24, P1682, DOI 10.1109/TCSVT.2014.2345933
   Jin R, 2002, INT C PATT RECOG, P859, DOI 10.1109/ICPR.2002.1048160
   Kesana V, 2019, SIGNAL IMAGE VIDEO P, V13, P879, DOI 10.1007/s11760-019-01424-5
   Kilicarslan M, 2019, IEEE T INTELL TRANSP, V20, P522, DOI 10.1109/TITS.2018.2819827
   Kreyszig E., 2000, Advanced Engineering Mathematics, V8th
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   NAKAYA Y, 1994, IEEE T CIRC SYST VID, V4, P339, DOI 10.1109/76.305878
   Okade M, 2016, IEEE T CIRC SYST VID, V26, P453, DOI 10.1109/TCSVT.2015.2412772
   Po LM, 2010, IEEE T CIRC SYST VID, V20, P1625, DOI 10.1109/TCSVT.2010.2087474
   Sandula P, 2019, INT C RANG TECHN ICO, P1
   Sandula P., 2019, 2019 NATL C COMM NCC, P1
   Schoeffmann K, 2009, IEEE INT CON MULTI, P1831
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yuan H, 2010, IEEE SIGNAL PROC LET, V17, P787, DOI 10.1109/LSP.2010.2055051
   Zhang ZW, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132670
NR 25
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12759
EP 12776
DI 10.1007/s11042-022-12363-8
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600002
DA 2024-07-18
ER

PT J
AU Chan, VS
   Haron, HNH
   Isham, MIB
   Bin Mohamed, F
AF Chan, Vei Siang
   Haron, Habibah Norehan Hj
   Isham, Muhammad Ismail Bin Mat
   Bin Mohamed, Farhan
TI VR and AR virtual welding for psychomotor skills: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Augmented reality; Virtual reality; Engineering education;
   Human-computer interaction; Psychomotor domain; Systematic review
ID AUGMENTED REALITY; SIMULATORS
AB Virtual reality (VR) and augmented reality (AR) continue to play an important role in vocational training in the current pandemic and Industrial Revolution 4.0 era. Welding is one of the highly demanded vocational skills for various manufacturing and construction industries. Students need to undergo many practical sessions to become skilful welders. However, conventional training is very costly in terms of material, time, and infrastructure. Hence, we explore the intervention of VR and AR in welding training, which includes the research purposes, VR and AR technologies, and welding concepts and activities. We performed a comprehensive search of articles from the year 2000 to 2021. After filtering through inclusion criteria and full-text assessment, a total of 42 articles were coded and evaluated. While there has been growth in VR and AR welding training research, there is little discussion in their effectiveness for supporting distance learning, and most studies targeted entry-level students. Our main contributions are classifying primary functions in the virtual welding workshops and their adaptation to the psychomotor domain. We hope these results can empower the research community to develop and improve the VR and AR system and evaluation instruments to support vocational training, especially during this pandemic.
C1 [Chan, Vei Siang; Isham, Muhammad Ismail Bin Mat; Bin Mohamed, Farhan] Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu 81310, Johor, Malaysia.
   [Haron, Habibah Norehan Hj] Univ Teknol Malaysia, Razak Fac Technol & Informat, Kuala Lumpur 54100, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia
RP Chan, VS (corresponding author), Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu 81310, Johor, Malaysia.; Haron, HNH (corresponding author), Univ Teknol Malaysia, Razak Fac Technol & Informat, Kuala Lumpur 54100, Malaysia.
EM vschan2@live.utm.my; habibahharon.kl@utm.my; mismail.m.isham@gmail.com;
   farhan@utm.my
RI Chan, Vei Siang/HSH-7222-2023; bin Mohamed, Farhan/AAR-1026-2021; Haron,
   Habibah Norehan/K-8363-2012
OI Haron, Habibah Norehan/0000-0003-3079-9119; Chan, Vei
   Siang/0000-0003-0276-0233
FU Ministry of Education (MOE) through Fundamental Research Grant Scheme
   [FRGS/1/2018/TK03/UTM/02/16, R.K130000.7856.5F114]
FX This work was supported by the Ministry of Education (MOE) through
   Fundamental Research Grant Scheme (FRGS/1/2018/TK03/UTM/02/16) with vote
   no: R.K130000.7856.5F114.
CR Agrawal R, 2020, ISS '20 COMPANION: COMPANION PROCEEDINGS OF THE 2020 CONFERENCE ON INTERACTIVE SURFACES AND SPACES, P23, DOI 10.1145/3380867.3426199
   Ali AA, 2019, IEEE T LEARN TECHNOL, V12, P321, DOI 10.1109/TLT.2019.2926727
   Angel-Urdinola DF, 2021, META ANAL ASSESSES E, DOI [10.1596/1813-9450-9587, DOI 10.1596/1813-9450-9587]
   [Anonymous], 2021, Mater Today Proc., V47, P7184
   Baglow L, 2019, GUIDELINES DEVELOPIN, P112
   Baskoro AS, 2015, INT C ADV COMP SCI I, P269, DOI 10.1109/ICACSIS.2015.7415194
   Benson R.A., 2016, INT J CONTROL THEORY, V9, P1235
   Bharath V.G., 2017, INT J MECH ENG TECHN, V8, P132
   Bickerstaff, 2015, THESIS NW STATE U LO
   Bohnart E. R., 2018, Welding, Principles and Practices
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Byrd AP, 2015, WELD J, V94, p389S
   Cen L, 2020, IEEE T LEARN TECHNOL, V13, P283, DOI 10.1109/TLT.2019.2937525
   Chambers TL, 2012, VIRTUAL REAL-LONDON, V16, P45, DOI 10.1007/s10055-010-0170-x
   Chibani Djaber, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P293, DOI 10.1109/CCSSP49278.2020.9151477
   Chung CC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101673
   Dalto L. D., 2010, P INT C ADV WELD SCI, P587
   de Armas C, 2020, MULTIMED TOOLS APPL, V79, P3495, DOI 10.1007/s11042-019-08141-8
   Dujovic M, 2020, SINT 2020 INT SCI C, P181
   Fast K, 2012, 2010357 NSRP ASE
   Hill B, 2010, PERD TRENDS ANAL, P1
   Huang CY, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su122310044
   Ipsita A, 2021, C HUM FACT COMP SYST, P1
   Isharyani M E., 2020, Proceedings of the International Conference on Engineering and Information Technology for Sustainable Industry, P1, DOI [10.1145/3429789.3429812, DOI 10.1145/3429789.3429812]
   Jae-Hyung Ko, 2019, 2019 IEEE International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH). Proceedings, P29, DOI 10.1109/ICACEH48424.2019.9041844
   Jo D., 2009, P 16 ACM S VIRT REAL, P269
   Jo Dongsik, 2011, P 10 INT C VIRT REAL, P339, DOI [10.1145/2087756., DOI 10.1145/2087756]
   Karstensen S., 2020, NORD J VOCAT ED TRAI, V10, P95, DOI [10.3384/njvet.2242-458x.2010195, DOI 10.3384/NJVET.2242-458X.2010195]
   Knoke B, 2021, COMPUT APPL ENG EDUC, V29, P1191, DOI 10.1002/cae.22378
   Kobayashi K., 2003, ENTERTAIN COMPUT, V112, P389, DOI DOI 10.1007/978-0-387-35660-0
   Lavrentieva OO, 2019, CEUR WORKSHOP PROCEE, V2547, P201
   Liang ZX, 2008, MATER SCI FORUM, V575-578, P709, DOI 10.4028/0-87849-392-1.709
   Liu YK, 2015, PROC IEEE INT SYMP, P131, DOI 10.1109/ISIE.2015.7281456
   Liyang, 2018, IOP C SERIES MAT SCI
   Mellet-d'Huart D., 2009, Themes Sci. Technol. Educ, V2, P185
   Millers Electric Mfg. Co Training Department, 2016, INTROD WELD
   Mohamed F, 2010, THEORY PRACTICE COMP, P175, DOI DOI 10.2312/LOCALCHAPTEREVENTS/TPCG/TPCG10/175-182
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moreno R, 2007, EDUC PSYCHOL REV, V19, P309, DOI 10.1007/s10648-007-9047-2
   Okimoto MLLR, 2015, PROCEDIA MANUF, V3, P6223, DOI 10.1016/j.promfg.2015.07.739
   Papakostas C, 2022, EDUC INF TECHNOL, V27, P791, DOI 10.1007/s10639-020-10418-7
   Price A. H., 2019, P 2019 C IND ED COLL
   Seabery, 2021, SOLD AUGM TRAIN TECH
   Siang CV, 2017, 2017 IEEE CONFERENCE ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IC3E), P73, DOI 10.1109/IC3e.2017.8409241
   Simpson E J., 1971, Behavioral objectives in curriculum development: Selected readings and bibliography, V60, P1
   Stone RT, 2013, WELD J, V92, p167S
   Stone RT, 2011, HUM FACTORS, V53, P558, DOI 10.1177/0018720811413389
   The Lincoln Electric Company, 2021, VRTEX 360 VIRT WELD
   Torres F, 2017, EURASIA J MATH SCI T, V13, P521, DOI 10.12973/eurasia.2017.00629a
   Torres-Guerrero F, 2019, LECT N MECH ENG, P319, DOI 10.1007/978-3-030-18715-6_27
   Wang YZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P191, DOI 10.1109/VECIMS.2009.5068891
   White SA, 2011, VIRTUAL REAL-LONDON, V15, P69, DOI 10.1007/s10055-010-0162-x
   Xie BK, 2015, P IEEE VIRT REAL ANN, P309, DOI 10.1109/VR.2015.7223419
   Yang U, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P150, DOI 10.1109/CW.2010.68
   Yao J., 2017, PAT WELD J, V2017, P19, DOI [10.15407/tpwj2017.06.04, DOI 10.15407/TPWJ2017.06.04]
   Yap HJ, 2014, THOUSAND FACES VIRTU, P87, DOI [10.5772/57353, DOI 10.5772/57353]
NR 56
TC 14
Z9 14
U1 11
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12459
EP 12493
DI 10.1007/s11042-022-12293-5
EA FEB 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400002
PM 35221778
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Li, PC
AF Li, Panchi
TI Quantum implementation of the classical Canny edge detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image processing; Quantum Canny edge detector; Non-maxima
   suppression; Double threshold processing; Quantum multiplier; Quantum
   divider
ID IMAGE ENCRYPTION SCHEME; WATERMARK STRATEGY; REPRESENTATION; ALGORITHM
AB Edge detection is a basic problem in digital image processing. Its purpose is to detect the pixels whose gray level changes obviously in the neighborhood. The Canny edge detector is currently the most popular edge detection tool. This paper studies the specific implementation of Canny detector in the quantum computing paradigm. For Gaussian smoothing filtering and Sobel sharpening operators, we have designed a new method called "Translation, Stacking and Weighted Summation", which can make full use of the parallelism of quantum computing to accelerate its classical counterpart and avoid convolution operation. For the gradient and angle calculations required for edge detection, we design new operators such as addition, multiplication and division of signed number by introducing the binary complement description of gray-scale value. For the non-maximum suppression and double threshold processing required for edge detection, we have separately designed the quantum circuits that implement these tasks by introducing quantum complement comparators. Complexity analysis shows that the quantum Canny edge detector has exponential speedup compared to its classical counterpart. The implementation of the Canny edge detector based on quantum computing is the main contribution of this paper. The simulation on the classical computer verifies the correctness of the quantum Canny edge detection results.
C1 [Li, Panchi] Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
C3 Northeast Petroleum University
RP Li, PC (corresponding author), Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
EM lipanchi@vip.sina.com
FU National Natural Science Foundation of China [61702093]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61702093).
CR Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   [Anonymous], 2011, 2011 IEEE 7 INT S IN, DOI DOI 10.1109/WISP.2011.6051718
   [Anonymous], 2008, PRINCIPLE COMPUTER C
   BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457
   Beach G, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P39
   Caraiman S, 2015, QUANTUM INF PROCESS, V14, P1693, DOI 10.1007/s11128-015-0932-1
   Chris L., 2003, arXiv:quant-ph/0309070, P1
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2129-x
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2131-3
   Gong LH, 2016, INT J THEOR PHYS, V55, P3234, DOI 10.1007/s10773-016-2954-6
   Gonzalez RC, 2010, DIGITAL IMAGE PROCES, P736
   Heidari S, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1694-8
   Heidari S, 2017, INT J QUANTUM INF, V15, DOI 10.1142/S0219749917500393
   Heidari S, 2016, INT J THEOR PHYS, V55, P4205, DOI 10.1007/s10773-016-3046-3
   Iliyasu AM, 2012, INFORM SCIENCES, V186, P126, DOI 10.1016/j.ins.2011.09.028
   Iliyasu AM, 2011, INT J QUANTUM INF, V9, P1459, DOI 10.1142/S0219749911008015
   Jiang N, 2016, INT J THEOR PHYS, V55, P4501, DOI 10.1007/s10773-016-3073-0
   Jiang N, 2016, QUANTUM INF PROCESS, V15, P3543, DOI 10.1007/s11128-016-1364-2
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1735, DOI 10.1007/s11128-015-0986-0
   Jiang N, 2015, INT J THEOR PHYS, V54, P1021, DOI 10.1007/s10773-014-2294-3
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1545, DOI 10.1007/s11128-014-0749-3
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1223, DOI 10.1007/s11128-013-0721-7
   Latorre J I, 2005, Image compression and entanglement
   Le Phuc Q., 2010, IAENG International Journal of Applied Mathematics, V40, P113
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li PC, 2018, INT J THEOR PHYS, V57, P3242, DOI 10.1007/s10773-018-3841-0
   Li PC, 2018, INT J THEOR PHYS, V57, P1516, DOI 10.1007/s10773-018-3678-6
   Li PC, 2018, INT J QUANTUM INF, V16, DOI 10.1142/S021974991850020X
   Li PC, 2017, INT J THEOR PHYS, V56, P1961, DOI 10.1007/s10773-017-3341-7
   Li PC, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1577-z
   Li PC, 2016, QUANTUM INF PROCESS, V15, P4415, DOI 10.1007/s11128-016-1413-x
   Miyake S, 2016, QUANTUM INF PROCESS, V15, P1849, DOI 10.1007/s11128-016-1260-9
   Naseri M, 2017, OPTIK, V139, P77, DOI 10.1016/j.ijleo.2017.03.091
   Qu ZG, 2017, INT J THEOR PHYS, V56, P3543, DOI 10.1007/s10773-017-3519-z
   Qu ZG, 2017, INT J THEOR PHYS, V56, P3460, DOI 10.1007/s10773-017-3512-6
   Sang JZ, 2016, QUANTUM INF PROCESS, V15, P4441, DOI 10.1007/s11128-016-1411-z
   Shen W., 2014, Advances in Intelligent Systems and Computing, V298, P243
   Song XH, 2014, QUANTUM INF PROCESS, V13, P1765, DOI 10.1007/s11128-014-0768-0
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Sun B, 2013, J ADV COMPUT INTELL, V17, P404, DOI 10.20965/jaciii.2013.p0404
   Vedral V, 1996, PHYS REV A, V54, P147, DOI 10.1103/PhysRevA.54.147
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   [王冬 Wang Dong], 2012, [计算机科学, Computer Science], V39, P302
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   Yan F, 2018, THEOR COMPUT SCI, V752, P71, DOI 10.1016/j.tcs.2017.12.025
   Yan F, 2017, INT J QUANTUM INF, V15, DOI 10.1142/S0219749917300017
   Yan F, 2015, INT J THEOR PHYS, V54, P2893, DOI 10.1007/s10773-015-2524-3
   Yan F, 2015, QUANTUM INF PROCESS, V14, P1675, DOI 10.1007/s11128-014-0912-x
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P3477, DOI 10.1007/s11128-013-0612-y
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P2765, DOI 10.1007/s11128-013-0561-5
   Yuan SZ, 2014, QUANTUM INF PROCESS, V13, P1353, DOI 10.1007/s11128-014-0733-y
   Zhang WW, 2013, INT J THEOR PHYS, V52, P504, DOI 10.1007/s10773-012-1354-9
   Zhang WW, 2013, QUANTUM INF PROCESS, V12, P793, DOI 10.1007/s11128-012-0423-6
   Zhang Y, 2015, QUANTUM INF PROCESS, V14, P1573, DOI 10.1007/s11128-014-0842-7
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
   Zhou RG, 2015, QUANTUM INF PROCESS, V14, P1717, DOI 10.1007/s11128-015-0964-6
   Zhou RG, 2013, INT J THEOR PHYS, V52, P1802, DOI 10.1007/s10773-012-1274-8
NR 63
TC 4
Z9 6
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11665
EP 11694
DI 10.1007/s11042-022-12337-w
EA FEB 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400014
DA 2024-07-18
ER

PT J
AU Koul, S
   Kumar, M
   Khurana, SS
   Mushtaq, F
   Kumar, K
AF Koul, Saboor
   Kumar, Munish
   Khurana, Surinder Singh
   Mushtaq, Faisel
   Kumar, Krishan
TI An efficient approach for copy-move image forgery detection using
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery; Digital image; MICC-F2000; CNN; Deep learning
ID DETECTION ALGORITHM; LOCALIZATION
AB Digital imaging has become elementary in this novel era of technology with unconventional image forging techniques and tools. Since, we understand that digital image forgery is possible, it cannot be even presented as a piece of evidence anywhere. Dissecting this fact, we must dig unfathomable into the issue to help alleviate such derelictions. Copy-move and splicing of images to create a forged one prevail in this monarchy of digitalization. Copy-move involves copying one part of the image and pasting it to another part of the image while the latter involves merging of two images to significantly change the original image and create a new forged one. In this article, a novel slant using a convolutional neural network (CNN) has been proposed for automatic detection of copy-move forgery detection. For the experimental work, a benchmark dataset namely, MICC-F2000 is considered which consists of 2000 images in which 1300 are original and 700 are forged. The experimental results depict that the proposed model outperforms the other traditional methods for copy-move forgery detection. The results of copy-move forgery were highly promising with an accuracy of 97.52% which is 2.52% higher than the existing methods.
C1 [Koul, Saboor; Khurana, Surinder Singh; Mushtaq, Faisel] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
   [Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Dept Informat Technol, Chandigarh, India.
C3 Central University of Punjab; Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
EM munishcse@gmail.com
RI Kumar, Krishan/F-6049-2016; Kumar, Munish/P-7756-2018; Mushtaq,
   Faisel/GLS-2838-2022
OI Kumar, Krishan/0000-0001-9877-0238; Kumar, Munish/0000-0003-0115-1620;
   Mushtaq, Faisel/0000-0002-2554-654X
CR Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al Azrak FM, 2020, MULTIMED TOOLS APPL, V79, P18221, DOI 10.1007/s11042-019-08162-3
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Baabou S, 2019, I C SCI TECH AUTO CO, P485, DOI [10.1109/sta.2019.8717226, 10.1109/STA.2019.8717226]
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Dadkhah S, 2017, INT CONF IMAG VIS
   Elkasrawi S, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P146, DOI 10.1109/DAS.2014.48
   Elsharkawy ZF, 2019, MULTIMED TOOLS APPL, V78, P21585, DOI 10.1007/s11042-019-7206-3
   Gebhardt J., 2014, P 12 INT C DOC AN RE
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   KASHYAP A., 2017, International Journal of Applied Engineering Research, V12, P4747
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Lewis JA, 2014, FORENSIC DOCUMENT EXAMINATION: FUNDAMENTALS AND CURRENT TRENDS, P35, DOI 10.1016/B978-0-12-416693-6.00003-5
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P20739, DOI 10.1007/s11042-019-7342-9
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Nirmala G., 2019, P INT C COMM SIGN PR, P441
   Patgar S. V., 2014, P INT C CONT COMP IN
   Paul KH, 2020, ADV INTELL SYST COMP, V944, P234, DOI 10.1007/978-3-030-17798-0_20
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2014, 2014 11TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD), DOI 10.1109/SSD.2014.6808907
   Shafait F, 2008, INT J DOC ANAL RECOG, V11, P81, DOI 10.1007/s10032-008-0071-7
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Singh A, 2018, MULTIMED TOOLS APPL, V77, P28949, DOI 10.1007/s11042-018-6075-5
   Thuong Le-Tien, 2019, International Journal of Machine Learning and Computing, V9, P181, DOI 10.18178/ijmlc.2019.9.2.784
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Yadav JA., 2017, INT J ENG DEV RES, V5, P732
NR 32
TC 19
Z9 19
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11259
EP 11277
DI 10.1007/s11042-022-11974-5
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200003
DA 2024-07-18
ER

PT J
AU Kumar, A
AF Kumar, Amit
TI Vision-less autonomous tracking and landing of a micro aerial vehicle on
   a slow maneuvering ground moving target using distance sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proportional navigation; Aerial vehicle; Target tracking; Trajectory
   generation
ID PROPORTIONAL NAVIGATION; ROBOTIC INTERCEPTION
AB Camera and GPS technologies are often used in aerial vehicles for autonomous tracking and landing on ground moving vehicles. However, these technologies limit the accuracy of an aerial vehicle especially in critical landing situations. As a result, additional sensors may require to achieve higher precision specially while landing on slightly maneuvering target. This paper presents a novel approach for tracking and then smooth and accurate landing of a quadcopter on slow or non-maneuvering ground moving target. In the present approach, the quadcopter does not use camera or any other vision sensor which required heavy processing. The quadcopter is equipped with a rotating ultrasonic sensor which continuously senses the ground moving target in an open and obstacle free environment. The Euclidean distance between the initial positions of the quadcopter and the target were kept less than the range of the used ultrasonic sensor. The maximum velocity of the quadcopter is assumed faster than the target to ensure the target in the quadcopter's sensing range during the operation. The performance of the quadcopter is observed in terms of the time taken and the distance travelled in tracking phase and landing phase. The simulation results are further verified by the hardware results in real-time environment.
C1 [Kumar, Amit] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota 302017, India.
RP Kumar, A (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota 302017, India.
EM amit@iiitkota.ac.in
OI Kumar, Amit/0000-0002-0777-7715
CR Aguilar WG, 2017, LECT NOTES COMPUT SC, V10306, P596, DOI 10.1007/978-3-319-59147-6_51
   Anand A, 2020, STUD COMPUT INTELL, V863, P102, DOI 10.1007/978-3-030-34152-7_8
   Arasavali N., 2019, INT J RECENT TECHNOL, V8, P2672
   Arrigo J, 2019, P ARR AVA, V2019, P1
   Borowczyk A, 2017, J GUID CONTROL DYNAM, V40, P2373, DOI 10.2514/1.G002703
   Clark MJ, 2017, THESIS EMBRY RIDDLE
   Eatemadi M., 2017, Int. J. Appl. Oper. Res, V7, P77
   Gee T, 2016, INT CONF IMAG VIS, P104
   GHOSE D, 1994, IEEE T AERO ELEC SYS, V30, P229, DOI 10.1109/7.250423
   Keshmiri M, 2010, 2010 15TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P212, DOI 10.1109/MMAR.2010.5587234
   Kumar A, 2019, INT J AUTOM COMPUT, V16, P491, DOI 10.1007/s11633-018-1151-x
   Kumar A, 2017, INT J CONTROL AUTOM, V15, P1351, DOI 10.1007/s12555-015-0166-0
   Mehrandezh M, 1999, ROBOT AUTON SYST, V28, P295, DOI 10.1016/S0921-8890(99)00044-5
   Mehrandezh M, 2000, IEEE T SYST MAN CY A, V30, P238, DOI 10.1109/3468.844351
   Mohamed N, 2020, TECHNOL FORECAST SOC, V153, DOI 10.1016/j.techfore.2018.05.004
   Palafox PR, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132661
   Pi CH, 2020, CONTROL ENG PRACT, V95, DOI 10.1016/j.conengprac.2019.104222
   Radoglou-Grammatikis P, 2020, COMPUT NETW, V172, DOI 10.1016/j.comnet.2020.107148
   Roberts C., 2016, GPS GUIDED AUTONOMOU
   ROSA G. D. C., 2016, Sci Bull Nav Acad, V19, P39
   Safadinho D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030613
   Sani MF, 2019, TURK J ELECTR ENG CO, V27, P1821, DOI 10.3906/elk-1809-204
   Sariçiçek I, 2015, APPL MATH MODEL, V39, P3939, DOI 10.1016/j.apm.2014.12.010
   Sawalakhe PV., 2020, INT J RECENT TECHNOL, V8, P672
   Shahrin MR., 2018, INT J ENG TECHNOL, V7, P179, DOI [10.14419/ijet.v7i4.11.20797, DOI 10.14419/IJET.V7I4.11.20797]
   Singhal G., 2018, Preprints, P2018110601, DOI DOI 10.20944/PREPRINTS201811.0601.V1
   Song YY, 2012, APPL MECH MATER, V110-116, P5249, DOI 10.4028/www.scientific.net/AMM.110-116.5249
   Soria PR, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050700
   Sravanthi G., 2017, INT J PURE APPL MATH, V114, P429
   Tan RY, 2014, UNMANNED SYST, V2, P157, DOI 10.1142/S2301385014500101
   Xing BY, 2019, INT J AEROSPACE ENG, V2019, DOI 10.1155/2019/4723869
   Yang CD, 1997, IEEE T AERO ELEC SYS, V33, P949, DOI 10.1109/7.599315
   Yinka-Banjo C., 2019, Autonomous Vehicles, P107, DOI DOI 10.5772/INTECHOPEN.89488
NR 33
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35261
EP 35281
DI 10.1007/s11042-021-11860-6
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000756332700024
DA 2024-07-18
ER

PT J
AU Han, XZ
   Lu, F
   Tian, GH
AF Han, Xiangzu
   Lu, Fei
   Tian, Guohui
TI Efficient 3D CNNs with knowledge transfer for sign language recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Efficient 3D CNNs; Knowledge transfer;
   Sequence-to-sequence
ID SCALE GESTURE RECOGNITION; FUSION
AB Heavy 3D CNNs for spatiotemporal modeling have gained impressive performance in sign language recognition (SLR). However, as for memory/computation cost, heavy 3D CNNs are expensive and unsuitable for real-time applications. In this paper, we seek for efficient spatiotemporal modeling with respect to model size and speed for both isolated and continuous SLR. Specifically, we first build several efficient 3D CNNs including 3D-MobileNets, 3D-ShuffleNets, and X3Ds. Then, we further boost the performance by designing a random knowledge distillation strategy (RKD) which concurrently considers the temperature of the distillation process, the ratio of true labels to soft labels, and multi-teacher networks to transfer the knowledge from larger teacher models for isolated SLR. We finally apply these lightweight models as spatiotemporal feature extractors in the framework of attention-based sequence-to-sequence for the more challenging continuous SLR. In our experiments, the best 16-frame MobileNetv2-1.0-S obtains 95.12% test accuracy on the isolated CSL-500 dataset, and the efficient sequence-to-sequence framework obtains 2.2 Word Error Rate (WER) on the CSL-continuous dataset. The experimental results achieve competitive performance across all datasets while being 10s to 100s faster than the state-of-the-art methods.
C1 [Han, Xiangzu; Lu, Fei; Tian, Guohui] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
C3 Shandong University
RP Lu, F (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM lawyerlf@sdu.edu.cn
FU National Natural Science Foundation of China [61973187, 61773239]
FX This work was surpported by the National Natural Science Foundation of
   China (Nos.61973187, 61773239).
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Camgoz Necati Cihan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10020, DOI 10.1109/CVPR42600.2020.01004
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Dean J., 2015, NIPS DEEP LEARNING R
   Debevc M, 2011, MULTIMED TOOLS APPL, V54, P181, DOI 10.1007/s11042-010-0529-8
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P744
   Guo D, 2018, AAAI CONF ARTIF INTE, P6845
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo B, 2019, AAAI CONF ARTIF INTE, P3779
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holzinger A, 2021, INFORM FUSION, V71, P28, DOI 10.1016/j.inffus.2021.01.008
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang J, 2019, IEEE T CIRC SYST VID, V29, P2822, DOI 10.1109/TCSVT.2018.2870740
   Huang JJ, 2018, AAAI CONF ARTIF INTE, P6951
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Köpüklü O, 2019, IEEE INT CONF COMP V, P1910, DOI 10.1109/ICCVW.2019.00240
   Li YN, 2019, PATTERN RECOGN LETT, V119, P187, DOI 10.1016/j.patrec.2017.12.003
   Li YA, 2018, IEEE T CIRC SYST VID, V28, P2956, DOI 10.1109/TCSVT.2017.2749509
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma WR, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417851
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Molchanov P., 2016, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P4207, DOI DOI 10.1109/CVPR.2016.456
   Pigou L, 2015, LECT NOTES COMPUT SC, V8925, P572, DOI 10.1007/978-3-319-16178-5_40
   Pu JF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P885
   Pu JF, 2019, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2019.00429
   Ramsay T., 2021, IEEE T PATTERN ANAL
   Romero A., 2014, ARXIV14126550
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen Zhiqiang, 2020, ARXIV200908453
   Sutskever I, 2014, ADV NEUR IN, V27
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaswani A, 2017, ADV NEUR IN, V30
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1483, DOI 10.1145/3240508.3240671
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xiao QK, 2019, MULTIMED TOOLS APPL, V78, P15335, DOI 10.1007/s11042-018-6939-8
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou H, 2020, AAAI CONF ARTIF INTE, V34, P13009
   Zhou H, 2019, IEEE INT CON MULTI, P1282, DOI 10.1109/ICME.2019.00223
NR 53
TC 7
Z9 8
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10071
EP 10090
DI 10.1007/s11042-022-12051-7
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800017
DA 2024-07-18
ER

PT J
AU Ishrat, M
   Abrol, P
AF Ishrat, Mohsina
   Abrol, Pawanesh
TI Visual search analysis using parametric fixations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fixations; Visual search; Fixation parameters
ID EYE-MOVEMENTS; SIMILARITY; ATTENTION; DURATION; TRACKING
AB Eye movement analysis has been an important area of research. The analysis of eye movements could help in better understanding of human preferences, behavioral pattern and viewing sequences. Eye movement analysis involves scanpath tracking which is the path traversed by movement of eyes. Scanpath comprises of two major components that are fixations and saccades. Fixations are the common events studied for understanding behavioral tendencies whereas saccades have generally been referred as corrective random eye movements that cannot contribute to human behavioral understanding. The constant viewing of a region or an object in a visual scene for a certain period of time is termed as fixation that has been generally analyzed in terms of associated parameters. The most common parameters analyzed include, number of fixations and duration of fixations. The analysis of fixations has been a part of many research areas that include scene perception, visual search, marketing, diagnostic and interactive applications. Visual search has been a prominent research area wherein a given target objects is to be found amidst group of distracters in a displayed scene/image. The distractions could be due to presence of similar looking objects, low variation of color or higher number of heterogeneous objects. In this paper, fixations have been analyzed in terms of different fixation parameters during experiments of visual search. A total of three experiments of visual search have been conducted. The experiments have been conducted in a sequence, for understanding the impact of distractions during visual search on parameters of fixations and thereby eye movements. The identified parameters include 'number of fixations, 'total fixation duration', 'maximum fixation duration' and 'total search time'. A total of three distractions present in images i.e. low chromatic variation, presence of multiple heterogeneous objects and high target- distracter similarity have been analyzed. Eye movement data of forty one subjects has been captured using a remote eye tracking setup. It has been found that visual images with high target and non target object similarity have higher impact on fixation parameters and thus eye movements. The distractions in the form of low chromatic variations and presence of multiple heterogenic objects in images have almost similar impact on eye movements. The results indicate that searching in images with high similarity between target and non target objects has been difficult for subjects in comparison to images with high heterogenic component and low chromatic variation. Also, result of parameter (maximum fixation duration) shows different results on images that have been easy for subjects to search, in comparison to difficult visual search. The obtained results could lead to better development and optimization of user oriented applications using remote eye tracking systems.
C1 [Ishrat, Mohsina; Abrol, Pawanesh] Univ Jammu J&K, Dept Comp Sci & IT, Jammu, India.
C3 University of Jammu
RP Ishrat, M (corresponding author), Univ Jammu J&K, Dept Comp Sci & IT, Jammu, India.
EM mohsina.ishrat@gmail.com; pawanesh.abrol@gmail.com
OI Ishrat, Mohsina/0000-0002-9298-4291
CR Aksum KM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.562995
   Alexander RG, 2012, VISION RES, V54, P20, DOI 10.1016/j.visres.2011.12.004
   [Anonymous], 2013, P INT C MOB SYST APP
   Boettcher SEP, 2015, ATTEN PERCEPT PSYCHO, V77, P1132, DOI 10.3758/s13414-015-0858-9
   Brown AM, 2011, J VISION, V11, DOI 10.1167/11.12.2
   Brunyé TT, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0159-2
   BULLING A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI DOI 10.1109/TPAMI.2010.86
   Cho J, 2019, J EXP PSYCHOL HUMAN, V45, P1455, DOI 10.1037/xhp0000686
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   De Santis A, 2009, COMPUT METH PROG BIO, V96, P1, DOI 10.1016/j.cmpb.2009.03.010
   Drew T, 2017, J VISION, V17, DOI 10.1167/17.11.5
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hilchey MD, 2019, PSYCHON B REV, V26, P506, DOI 10.3758/s13423-019-01569-x
   Hooge LTC, 1996, PERCEPT PSYCHOPHYS, V58, P969, DOI 10.3758/BF03206825
   Hulleman J, 2017, BEHAV BRAIN SCI, V40, P1, DOI 10.1017/S0140525X15002794
   Ishrat M, 2020, MULTIMED TOOLS APPL, V79, P24393, DOI 10.1007/s11042-020-09117-9
   JACOB RJK, 1991, ACM T INFORM SYST, V9, P152, DOI 10.1145/123078.128728
   JACOBS AM, 1986, PERCEPT PSYCHOPHYS, V39, P47, DOI 10.3758/BF03207583
   Kaul O, 2016, P ACM S APPL PERC, P134
   Kübler TC, 2017, BEHAV RES METHODS, V49, P1048, DOI 10.3758/s13428-016-0765-6
   MacAskill MR, 2016, CURR OPIN NEUROL, V29, P61, DOI 10.1097/WCO.0000000000000274
   Majaranta P., 2019, EYE MOV RES, V1, P97
   Modi N, 2022, DISABIL REHABIL-ASSI, V17, P605, DOI 10.1080/17483107.2020.1817992
   MOFFITT K, 1980, PERCEPT PSYCHOPHYS, V27, P370, DOI 10.3758/BF03206127
   Nagy AL, 2003, VISION RES, V43, P1541, DOI 10.1016/S0042-6989(03)00234-7
   Näsänen R, 2003, DISPLAYS, V24, P137, DOI 10.1016/j.displa.2003.09.003
   Neider MB, 2006, VISION RES, V46, P2217, DOI 10.1016/j.visres.2006.01.006
   NOTON D, 1971, SCIENCE, V171, P308, DOI 10.1126/science.171.3968.308
   Pomplun M, 2001, VISION RES, V41, P2757, DOI 10.1016/S0042-6989(01)00145-6
   Pomplun M, 2013, J VISION, V13, DOI 10.1167/13.3.24
   Poynter W, 2013, VISION RES, V89, P32, DOI 10.1016/j.visres.2013.07.002
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Ruotolo F, 2020, J EXP PSYCHOL HUMAN, V46, P66, DOI 10.1037/xhp0000696
   Schulte-Mecklenbeck M., 2017, HDB PROCESS TRACING
   SCINTO LFM, 1986, ACTA PSYCHOL, V62, P263, DOI 10.1016/0001-6918(86)90091-0
   Tatler BW, 2010, I-PERCEPTION, V1, P7, DOI 10.1068/i0382
   Vlaskamp BNS, 2005, EXP BRAIN RES, V167, P246, DOI 10.1007/s00221-005-0032-z
   Wolfe JM, 2020, ANNU REV VIS SCI, V6, P539, DOI [10.1146/annurev-vision-091718-015048, 10.1146/annurev-vision-091718015048]
   Wolfe JM, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0058
   Ye CY, 2020, COGN TECHNOL WORK, V22, P603, DOI 10.1007/s10111-019-00584-1
NR 41
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10007
EP 10022
DI 10.1007/s11042-022-12377-2
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800007
DA 2024-07-18
ER

PT J
AU Hanif, MK
   Zimmermann, KH
   Anees, A
AF Hanif, Muhammad Kashif
   Zimmermann, Karl-Heinz
   Anees, Asad
TI Accelerating all-pairs shortest path algorithms for bipartite graphs on
   graphics processing units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shortest path; Graphs; Bipartite graphs; Graphics processing unit; CUDA;
   Parallelization
ID TRANSPORTATION APPLICATIONS
AB Bipartite graphs are used to model and represent many real-world problems in biological and physical sciences. Finding shortest paths in bipartite graphs is an important task and has numerous applications. Different dynamic programming based solutions to find the shortest paths exists which differ on complexity and structure of graph. The computational complexity of these algorithms is a major concern. This work formulates the parallel versions of Floyd-Warshall and Torgasin-Zimmermann algorithms to compute the shortest paths in bipartite graphs efficiently. These algorithms are mapped to graphics processing unit using tropical matrix product. The performance for different realizations and parameters are compared for Floyd-Warshall and Torgasin-Zimmermann algorithms. Parallel implementation of Torgasin-Zimmermann algorithm attained a speed-up factor of almost 274 when compared with serial Floyd-Warshall algorithm for random-generated undirected graphs.
C1 [Hanif, Muhammad Kashif] Govt Coll Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Zimmermann, Karl-Heinz] Hamburg Univ Technol, Inst Embedded Syst, D-21071 Hamburg, Germany.
   [Anees, Asad] Univ Technol, Inst Math, Clausthal Zellerfeld, Germany.
C3 Government College University Faisalabad; Hamburg University of
   Technology; TU Clausthal
RP Hanif, MK (corresponding author), Govt Coll Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM mkashifhanif@gcuf.edu.pk; k.zimmermann@tuhh.de;
   asad.anees@tu-clausthal.de
RI Zimmermann, Karl-Heinz Zimmermann Prof. Dr./AAA-9123-2022
OI Hanif, Muhammad Kashif/0000-0001-5150-2228
CR ALI MKM, 1993, IEEE T NEURAL NETWOR, V4, P941, DOI 10.1109/72.286889
   Araújo F, 2001, IEEE T NEURAL NETWOR, V12, P1067, DOI 10.1109/72.950136
   Asratian A S., 1998, Bipartite graphs and their applications, V131
   Bellman R., 1956, ROUTING PROBLEM
   Cha YY, 1997, ROBOT CIM-INT MANUF, V13, P145, DOI 10.1016/S0736-5845(96)00037-3
   Chabini I, 1998, TRANSPORT RES REC, P170
   Chan TM, 2007, ACM S THEORY COMPUT, P590, DOI 10.1145/1250790.1250877
   CHEN L, 1995, INFORM PROCESS LETT, V55, P259, DOI 10.1016/0020-0190(95)00084-P
   Chen YL, 2000, TRANSPORT RES B-METH, V34, P241, DOI 10.1016/S0191-2615(99)00023-5
   COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2
   Cormen T.H., 2009, Introduction to Algorithms, P651
   Dehghan A, 2019, IEEE T INFORM THEORY, V65, P3778, DOI 10.1109/TIT.2019.2895356
   DESAULNIERS G, 1995, IEEE T ROBOTIC AUTOM, V11, P819, DOI 10.1109/70.478429
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Dragan FF, 2005, J ALGORITHMS, V57, P1, DOI 10.1016/j.jalgor.2004.09.002
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Foulds L. R., 2012, Graph Theory Applications
   Fu L, 2006, COMPUT OPER RES, V33, P3324, DOI 10.1016/j.cor.2005.03.027
   Ghoseiri K, 2010, APPL SOFT COMPUT, V10, P1237, DOI 10.1016/j.asoc.2009.09.014
   Hanif, 2014, THESIS TU HAMBURG HA
   Hanif MK, 2017, COMPUTING, V99, P1105, DOI 10.1007/s00607-017-0557-6
   Harish P, 2007, LECT NOTES COMPUT SC, V4873, P197
   HASSIN R, 1992, MATH OPER RES, V17, P36, DOI 10.1287/moor.17.1.36
   Ho CW, 1999, INFORM PROCESS LETT, V69, P87, DOI 10.1016/S0020-0190(98)00195-1
   Hougardy S, 2010, INFORM PROCESS LETT, V110, P279, DOI 10.1016/j.ipl.2010.02.001
   Humayun A., 2017, INT J COMPUT SCI INF, V14, P220
   Hwu W.-m, 2016, Programming Massively Parallel Processors: A Hands-On Approach
   JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993
   Katz Gary J., 2008, Proceedings of the EUROGRAPHICS/ACM SIGGRAPH Conference on Graphics Hardware, P47
   Lund BD, 2010, ARXIVABS10014108 COR
   Mikhalkin G, 2006, arXiv:math.AG/0601041, P827
   Nath R, 2010, INT J HIGH PERFORM C, V24, P511, DOI 10.1177/1094342010385729
   NVIDIA, 2016, NVIDIA CUDA COMP UN
   Okuyama Tomohiro, 2012, International Journal of High Performance Computing and Networking, V7, P87, DOI 10.1504/IJHPCN.2012.046384
   Pachter Lior, 2005, ALGEBRAIC STAT COMPU
   Richter-Gebert J, 2005, CONTEMP MATH, V377, P289
   Roditty L, 2011, ACM T ALGORITHMS, V7, DOI 10.1145/2000807.2000813
   ROMANI F, 1980, INFORM PROCESS LETT, V11, P134, DOI 10.1016/0020-0190(80)90128-3
   Seidel R., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P745, DOI 10.1145/129712.129784
   STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411
   Takaoka T, 2013, J COMB OPTIM, V25, P326, DOI 10.1007/s10878-012-9550-3
   Takaoka T, 2010, LECT NOTES COMPUT SC, V6509, P195, DOI 10.1007/978-3-642-17461-2_16
   TORGASSIN S, 2013, CENTRAL EUROPEAN J C, V3, P149
   WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107
   Weisstein EW, 2002, COMPLETE BIPARTITE G
   Yu F, 2010, PHYSICA A, V389, P629, DOI 10.1016/j.physa.2009.10.005
NR 46
TC 1
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9549
EP 9566
DI 10.1007/s11042-022-12066-0
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000753241100004
DA 2024-07-18
ER

PT J
AU Jebadass, JR
   Balasubramaniam, P
AF Jebadass, J. Reegan
   Balasubramaniam, P.
TI Low light enhancement algorithm for color images using intuitionistic
   fuzzy sets with histogram equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram equalization; Image enhancement; Intuitionistic fuzzy sets
ID CONTRAST ENHANCEMENT; NUTRIENT DEFICIENCY; SEGMENTATION; LOGIC
AB In this work, a new fuzzy logic-based algorithm is proposed for the enhancement of low light color images. A generalization of a fuzzy set known as an intuitionistic fuzzy set (IFS) is used in this paper, which expresses the evidence of the support, opposition, and hesitation simultaneously. To generate non-membership degrees, Yager's generating function is used. Again entropy formula is used to generate non-membership degrees for improving the quality of the enhanced image derived by the proposed method. In the experimental section, the proposed method is compared with other existing methods like histogram equalization, contrast limited adaptive histogram equalization, histogram specification approach, discrete cosine transform coefficient, brightness preserving dynamic fuzzy histogram equalization, and intuitionistic fuzzy image. The experimental results revealed that the proposed method gives better results than the other existing methods. Performances are evaluated using entropy and structural similarity index. A comparative analysis of the quality of enhanced images shows that the proposed method performs better than several existing methods.
C1 [Jebadass, J. Reegan; Balasubramaniam, P.] Gandhigram Rural Inst Deemed Univ, Dept Math, Gandhigram 624302, Tamil Nadu, India.
C3 Gandhigram Rural Institute
RP Balasubramaniam, P (corresponding author), Gandhigram Rural Inst Deemed Univ, Dept Math, Gandhigram 624302, Tamil Nadu, India.
EM reeganmail@gmail.com; balugru@gmail.com
RI P, Balasubramaniam/O-3041-2013; Jebadass, Reegan/GRJ-8331-2022
FU University Grants Commission - Special Assistance Program (Department of
   Special Assistance - I), New Delhi, India [F. 510/7/DSA-1/2015 (SAP-I)]
FX This work was supported by University Grants Commission - Special
   Assistance Program (Department of Special Assistance - I), New Delhi,
   India, File No. F. 510/7/DSA-1/2015 (SAP-I).
CR [Anonymous], 2015, Electrical Computer Engineering: An International Journal
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Balasubramaniam P, 2016, NONLINEAR DYNAM, V83, P849, DOI 10.1007/s11071-015-2372-y
   Balasubramaniam P, 2014, INFORM FUSION, V20, P21, DOI 10.1016/j.inffus.2013.10.011
   Balasubramaniam P., 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P112, DOI 10.1007/978-3-319-03844-5_12
   Burillo P, 1996, FUZZY SET SYST, V78, P305, DOI 10.1016/0165-0114(96)84611-2
   Bustince H, 2000, FUZZY SET SYST, V114, P485, DOI 10.1016/S0165-0114(98)00279-6
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Fari Muhammad Abubakar, 2012, INT J SCI RES, V1, P15
   Hamnandlu M, 2006, IEEE T IMAGE PROCESS, V15, P2956, DOI 10.1109/TIP.2006.877499
   Hu J, 2012, INTELL AUTOM SOFT CO, V18, P1145, DOI 10.1080/10798587.2008.10643318
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang G, 2015, OPTIK, V126, P5656, DOI 10.1016/j.ijleo.2015.08.173
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Mittal P., 2018, Soft comput: Theories and Applications, V742, P537
   Nair MS, 2011, SIGNAL IMAGE VIDEO P, V5, P69, DOI 10.1007/s11760-009-0143-2
   Pal SK., 1989, IEEE T SYST MAN CYB, V11, P500
   Panetta K, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.021117
   Radhika C., 2016, Notes IFS, V22, P19
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Sharma S., 2015, INT J COMPUT APPL, V111, P0975
   Tirupal T, 2019, IRAN J FUZZY SYST, V16, P33
   Varatharajan R, 2018, MOB NETW APPL, P1, DOI DOI 10.1007/S11036-018-1057-4
   Wadhwa A, 2021, MULTIMED TOOLS APPL, V80, P21595, DOI 10.1007/s11042-021-10743-0
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yussof W., 2013, International Journal of Interactive Digital Media, V1, P1
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 31
TC 27
Z9 28
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8093
EP 8106
DI 10.1007/s11042-022-12087-9
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750341800001
DA 2024-07-18
ER

PT J
AU Chen, XQ
   Chen, HX
   Xu, XL
   Luo, LJ
   Biancardo, SA
AF Chen, Xinqiang
   Chen, Huixing
   Xu, Xianglong
   Luo, Lijuan
   Biancardo, Salvatore Antonio
TI Ship tracking for maritime traffic management via a data quality control
   supported framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual ship tracking; Data quality control; Kalman filter; Traffic
   situation awareness; Maritime traffic management
ID AIS DATA; PREDICTION
AB Ship trajectory in maritime surveillance videos provides crucial on-site traffic information (e.g., ship speed, traffic volume, density) to help maritime traffic situation awareness and management in the smart ship era. To that aim, many focuses are paid to track ships from maritime videos by exploring distinct visual features from maritime images, which may fail under complex maritime environment interference (occlusion, sea clutter interference, etc.). The study proposes a novel video-based ship tracking framework with the help of Multi-view learning model and data quality control procedure. First, we obtain raw ship positions from maritime images with particle filter and Multi-view learning models. Then, a data quality control procedure is implemented to suppress ship tracking outliers with the help of Kalman filter. Finally, we verify our proposed model performance on three typical maritime traffic situations (ship occlusion, sea clutter interference and small ship tracking).
C1 [Chen, Xinqiang; Chen, Huixing; Xu, Xianglong] Fudan Univ, Inst Atmospher Sci, Shanghai, Peoples R China.
   [Luo, Lijuan] Shanghai Int Studies Univ, Sch Business & Management, Shanghai, Peoples R China.
   [Biancardo, Salvatore Antonio] Federico II Univ Naples, Dept Civil Construct & Environm Engn, Naples, Italy.
C3 Fudan University; Shanghai International Studies University; University
   of Naples Federico II
RP Luo, LJ (corresponding author), Shanghai Int Studies Univ, Sch Business & Management, Shanghai, Peoples R China.
EM luolijuan@shisu.edu.cn
RI BIANCARDO, SALVATORE ANTONIO/AAY-4539-2020
FU National Key R&D Program of China [2019YFB1600602]; National Natural
   Science Foundation of China [52102397, 52071200, 51978069, 52072237,
   62073212, 71942003]; Shanghai Planning Office of Philosophy and Social
   Science [2019EGL018]; Shanghai Committee of Science and Technology,
   China [18DZ1206300]; China Postdoctoral Science Foundation [2021M700790]
FX This work was jointly supported by the National Key R&D Program of China
   (2019YFB1600602), National Natural Science Foundation of China
   (52102397, 52071200, 51978069, 52072237, 62073212, 71942003), Shanghai
   Planning Office of Philosophy and Social Science (2019EGL018), Shanghai
   Committee of Science and Technology, China (18DZ1206300), China
   Postdoctoral Science Foundation (2021M700790).
CR Cao XF, 2020, MULTIMED TOOLS APPL, V79, P9177, DOI 10.1007/s11042-018-7138-3
   Chen XQ, 2021, PHYSICA A, V565, DOI 10.1016/j.physa.2020.125574
   Chen XQ, 2020, IEEE SENS J, V20, P14317, DOI 10.1109/JSEN.2020.3007809
   Chen XQ, 2020, J NAVIGATION, V73, P813, DOI 10.1017/S0373463319000900
   Chen XQ, 2019, J NAVIGATION, V72, P176, DOI 10.1017/S0373463318000504
   Chen Z, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P449, DOI 10.1109/ICIVC.2017.7984596
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Hu HM, 2019, IEEE T IMAGE PROCESS, V28, P2882, DOI 10.1109/TIP.2019.2891901
   Huang Y, 2020, IEEE INTERNET THINGS, V7, P10794, DOI 10.1109/JIOT.2020.2989398
   Jiang M, 2021, IEEE T CIRC SYST VID, V31, P3154, DOI 10.1109/TCSVT.2020.3037947
   Kang X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040821
   Lang HT, 2018, IEEE GEOSCI REMOTE S, V15, P439, DOI 10.1109/LGRS.2018.2792683
   Liu RW, 2021, OCEAN ENG, V235, DOI 10.1016/j.oceaneng.2021.109435
   Liu Y, 2019, IEEE GEOSCI REMOTE S, V16, P281, DOI 10.1109/LGRS.2018.2869561
   Liu YC, 2019, CYBERNET SYST, V50, P539, DOI 10.1080/01969722.2019.1630566
   Maresca S, 2014, IEEE T GEOSCI REMOTE, V52, P5056, DOI 10.1109/TGRS.2013.2286741
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Mittal M, 2019, IEEE ACCESS, V7, P33240, DOI 10.1109/ACCESS.2019.2902579
   Pallotta G, 2013, ENTROPY-SWITZ, V15, P2218, DOI 10.3390/e15062218
   Park S, 2017, IEEE GEOSCI REMOTE S, V14, P969, DOI 10.1109/LGRS.2017.2691741
   Shao ZF, 2020, IEEE T CIRC SYST VID, V30, P781, DOI 10.1109/TCSVT.2019.2897980
   Shu YQ, 2018, OCEAN ENG, V169, P529, DOI 10.1016/j.oceaneng.2018.09.022
   Silvas E, 2016, IEEE T VEH TECHNOL, V65, P4118, DOI 10.1109/TVT.2016.2546338
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Tu EM, 2018, IEEE T INTELL TRANSP, V19, P1559, DOI 10.1109/TITS.2017.2724551
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P3931, DOI 10.1109/TGRS.2014.2388355
   Wu B, 2021, RELIAB ENG SYST SAFE, V209, DOI 10.1016/j.ress.2021.107466
   Wu B, 2021, MARIT POLICY MANAG, V48, P299, DOI 10.1080/03088839.2020.1791994
   Xiu SP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061317
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yu Y, 2021, OCEAN COAST MANAGE, V203, DOI 10.1016/j.ocecoaman.2020.105446
   Zhang Sr Y., 2020, 12 INT C MACH VIS IC
   Zhang WB, 2022, IEEE T INTELL TRANSP, V23, P7919, DOI 10.1109/TITS.2021.3074564
   Zhang WB, 2020, OCEAN ENG, V210, DOI 10.1016/j.oceaneng.2020.107545
   Zhou Y, 2019, IEEE T SIGNAL PROCES, V67, P3676, DOI 10.1109/TSP.2019.2917812
NR 35
TC 3
Z9 3
U1 7
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7239
EP 7252
DI 10.1007/s11042-022-11951-y
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700005
DA 2024-07-18
ER

PT J
AU Mehtab, S
   Yan, WQ
AF Mehtab, Sabeeha
   Yan, Wei Qi
TI Flexible neural network for fast and accurate road scene perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Road scene perception; Autonomous vehicles;
   Self-driving car; YOLOv5
AB Accurate object detection on the road is the most important requirement of autonomous vehicles. Extensive work has been accomplished for car, pedestrian, and cyclist detection; however, comparatively, very few efforts have been put into 2D object detection. In this article, a dynamic approach is investigated to design a perfect unified neural network that could achieve the best results based on our available hardware. The proposed architecture is based on CSPNet for feature extraction in an end-to-end way. The net extracts visual features by using backbone subnet, visual object detection is based on a feature pyramid network (FPN). In order to increase the net flexibility, an auto-anchor generating method is applied to the detection layer that makes the net suitable for any datasets. For fine-tuning the net, activation, optimization, and loss functions are considered along with multiple check points. The proposed net is trained and tested based on the benchmark KITTI dataset. Our extensive experiments show that the proposed model for visual object detection is superior to others, where other nets output very low accuracy for pedestrian and cyclist detection, our proposed model achieves 99.3% recall rate based on our dataset.
C1 [Mehtab, Sabeeha; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM dcsyanwq@gmail.com
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Ahmed S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112335
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cao JW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164646
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Choi D., 2019, On Empirical Comparisons of Optimizers for Deep Learning
   Condat R., 2020, 2020 IEEE 23 INT C I, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hou YL, 2018, INFRARED PHYS TECHN, V94, P69, DOI 10.1016/j.infrared.2018.08.029
   Hu QC, 2018, IEEE T CIRC SYST VID, V28, P1358, DOI 10.1109/TCSVT.2017.2648850
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kim KJ, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P405
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li GF, 2020, IEEE ACCESS, V8, P211164, DOI 10.1109/ACCESS.2020.3036620
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YZ, 2021, IEEE T SYST MAN CY-S, V51, P4716, DOI 10.1109/TSMC.2019.2945053
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sang J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124272
   Shah M, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P787, DOI 10.1109/ICCONS.2017.8250570
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song H., 2018, 2018 IEEE 19th Workshop on Control and Modeling for Power Electronics (COMPEL), P1, DOI DOI 10.23919/ELINFOCOM.2018.8330547
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tourani Ali, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P119, DOI 10.1109/PRIA.2019.8785988
   Tumas P, 2018, 2018 OPEN CONFERENCE OF ELECTRICAL, ELECTRONIC AND INFORMATION SCIENCES (ESTREAM)
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang K, 2019, IEEE ACCESS, V7, P22554, DOI 10.1109/ACCESS.2019.2894764
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051089
   Wei Y, 2019, MATH COMPUT SIMULAT, V155, P130, DOI 10.1016/j.matcom.2017.12.011
   Wilson AC, 2017, ADV NEUR IN, V30
   World Health Organization (WHO), 2018, WHO 2018 GLOB STAT R
   Yang Zhang, 2018, 2018 27th International Conference on Computer Communication and Networks (ICCCN), DOI 10.1109/ICCCN.2018.8487401
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang XY, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417749949
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 49
TC 5
Z9 5
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7169
EP 7181
DI 10.1007/s11042-022-11933-0
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700007
OA hybrid
DA 2024-07-18
ER

PT J
AU Mishra, A
   Shaikh, SH
   Sanyal, R
AF Mishra, Atul
   Shaikh, Soharab Hossain
   Sanyal, Ratna
TI Context based NLP framework of textual tagging for low resource language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Part of speech; Software framework; HMM ANN; RNN; Information retrieval
AB Understanding the context of any phrase or extracting relationships requires part of speech tagging (POS). This article proposes an RNN-based POS tagger and compares its performance with some of the existing POS tagging methods. We present novel LSTM-based RNN architecture for POS tagging. The study attempts to determine the usefulness of machine learning and deep learning techniques for tagging part-of-speech of words for the low-resource Hindi language, which is an Indo-Aryan language spoken mostly in India. During the experiments, different deep learning architecture (ANN and RNN) and machine learning methods (HMM, SVM, DT) have been used. A multi-representational treebank and an open-source dataset have been used for the performance analysis of the proposed framework. The experimental results in terms of macro-measured variables have shown better results compared to some state-of-the-art methods.
C1 [Mishra, Atul; Shaikh, Soharab Hossain] BML Munjal Univ, Kapriwas, Haryana, India.
   [Sanyal, Ratna] NIIT Univ, Comp Sci & Engn, Neemrana, Rajasthan, India.
C3 BML Munjal University; NIIT University, Rajasthan
RP Mishra, A (corresponding author), BML Munjal Univ, Kapriwas, Haryana, India.
EM atul.mishra.17pd@bmu.edu.in; soharab.hossain@bmu.edu.in;
   ratna.sanyal@niituniveisity.in
RI Mishra, Atul/S-4428-2019; Hossain Shaikh, Soharab/AAF-6303-2019
OI Hossain Shaikh, Soharab/0000-0003-3409-8467
CR Abdulkareem Mustafa, 2017, Journal of Theoretical and Applied Information Technology, V95, P403
   Akbik Alan, 2018, P 27 INT C COMP LING, P1638
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   [Anonymous], 1996, P 4 WORKSHOP VERY LA
   [Anonymous], 2017, P 21 C COMP NAT LANG, DOI 10.18653/v1/K17-1024
   Ball K, 2020, P 2018 C EMP METH NA, P3084, DOI [10.18653/v1/d18-1347, DOI 10.18653/V1/D18-1347]
   Bandyopadhyay S, 2006, ADV PATTERN RECOGNIT, P384, DOI [10.1142/9789812772381_0065, DOI 10.1142/9789812772381_0065]
   Baskaran, 2006, P NLPAI MACH LEARN C, P6
   Bhargav-Spantzel A., 2006, P 2 ACM WORKSH DIG I, P1, DOI [DOI 10.1145/1179529.1179531, 10.1145/1179529.1179531]
   Bhat Irshad, 2018, P 2018 C N AM CHAPTE, V1, P987, DOI [DOI 10.18653/V1/N18-1090, 10.18653/v1/N18-1090]
   Bhat R.A., 2017, Handbook of linguistic annotation, P659
   Bhattu SN, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3380967
   Bohmova A., 2003, Treebanks, P103
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Chaudhary JR., 2018, INT J SCI RES SCI EN, V4, P1480
   Chiplunkar K, 2021, ADV INTELLIGENT SYST, P133, DOI [10.1007/978-981-15-5679-1_13, DOI 10.1007/978-981-15-5679-1_13]
   Chollet F., GITHUB KERAS TEAM KE
   Dalal A, 2006, P NLPAI MACH LEARN C, P1
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Gadde SPK, 2008, ICON 2008 INT C NAT
   Garg Navneet., 2012, Proceedings_of_COLING_2012:_Demonstration_Papers, P163
   Grave E, WORD VECTORS 157 LAN
   Gupta V, 2019, STUDIES FUZZINESS SO, P117, DOI [10.1007/978-3-030-03131-2_7, DOI 10.1007/978-3-030-03131-2_7]
   Han HY, 2018, MULTIMED TOOLS APPL, V77, P21265, DOI 10.1007/s11042-017-5529-5
   Joshi N., 2013, Computer Science Information Technology, P341, DOI [10.5121/csit.2013.3639, DOI 10.5121/CSIT.2013.3639]
   Kalyanathaya K. P., 2019, Int. J. Recent Technol. Eng., V7, P199
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kumar D., 2010, International Journal of Computer Applications, V6, P1
   Leevy JL, 2020, J BIG DATA-GER, V7, DOI [10.1186/s40537-020-00312-x, 10.1186/s40537-020-00382-x]
   Lim K, 2020, IEEE ACCESS, V8, P195184, DOI 10.1109/ACCESS.2020.3033979
   LTRC, LANG TECHN RES CTR H
   Magerman David M., 1995, ACL, P276, DOI DOI 10.3115/981658.981695
   Mishra P., 2017, P 14 INT C NATURAL L, P50
   Narayan R., 2014, IFAC Proceedings, V47, P519
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Opitz Juri., 2019, arXiv preprint arXiv:1911.03347
   Patel, 2021, ARXIV210106949
   Plank B, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P412
   Pota M, 2019, KNOWL-BASED SYST, V164, P309, DOI 10.1016/j.knosys.2018.11.003
   Ramesh SH, 2016, ARXIV PREPRINT ARXIV
   Shrivastava M, 2008, 6 INT C NAT LANG PRO
   Silfverberg M., 2007, ACL, V21, P259
   Singh SK, 2019, MULTIMED TOOLS APPL, V78, P32109, DOI 10.1007/s11042-019-07995-2
   Straka Milan, 2019, ARXIV190807448
   Sukhadeve PP, 2012, LNCS, P310, DOI [10.1007/978-3-642-27317-9_32, DOI 10.1007/978-3-642-27317-9_32]
   Suppa M., 2021, P 8 WORKSHOP BALTO S, P105
   Tesfagergish SG, 2020, INF TECHNOL CONTROL, V49, P482, DOI 10.5755/j01.itc.49.4.26808
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   van Nguyen M, EACL 2021, P80
   Wu CR, 2020, MULTIMED TOOLS APPL, V79, P11399, DOI 10.1007/s11042-019-08513-0
   Wu ZY, 2015, MULTIMED TOOLS APPL, V74, P9909, DOI 10.1007/s11042-014-2164-2
   Xia Fei, 2009, 7 INT C NAT LANG PRO, P14
NR 52
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35655
EP 35670
DI 10.1007/s11042-021-11884-y
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000743891900006
DA 2024-07-18
ER

PT J
AU Debnath, S
   Roy, R
   Changder, S
AF Debnath, Soma
   Roy, Ratnakirti
   Changder, Suvamoy
TI Photo classification based on the presence of diagonal line using
   pre-trained DCNN VGG16
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Diagonal line detection; Image aesthetic
   evaluation; Photographic compositions; Pre-trained DCNN VGG16; Transfer
   learning
ID VISUAL QUALITY ASSESSMENT; AESTHETIC ANALYSIS; ENHANCEMENT; IMAGES;
   SYSTEM
AB The diagonal line is one of the important linear components in a photograph. It contributes significantly towards improving the aesthetic perception and rendering high scores by enhancing the sense of direction. Automatic detection of diagonal lines in a photograph can link to numerous real-time applications like on-site guidance to amateur photographers by finding the presence of diagonal lines, aesthetic evaluation of photographs in various photography competitions, searching similar photographs containing diagonal lines from any database without manual labelling, and so on. A deep dive into the related literature reveals that very rare research has been conducted in the mentioned area. This paper presents a novel VGG16 Deep Convolutional Neural Network (DCNN) based approach to find diagonal lines in a photograph. The proposed approach classifies digital photographs into two categories: photographs containing diagonal lines or not by the application of transfer learning. The proposed model is implemented on the ground truth dataset of 5,683 images and the satisfactory results have been achieved. The contribution of the paper is significant due to the fact that the existence of a similar classifier for digital photographs is zero in the literature. The proposed work also contributes towards the generation of the diagonal line image dataset called Diagonal-line Containing Image (DCI) which will be useful for future research in the domain.
C1 [Debnath, Soma; Changder, Suvamoy] NIT Durgapur, Dept CSE, Durgapur, India.
   [Roy, Ratnakirti] Dr BC Roy Engn Coll Durgapur, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Dr. B. C. Roy Engineering College
RP Debnath, S (corresponding author), NIT Durgapur, Dept CSE, Durgapur, India.
EM sd.16ca1102@phd.nitdgp.ac.in; rroy.nitdgp@gmail.com;
   suvamoy.changder@cse.nitdgp.ac.in
CR Aydin TO, 2015, IEEE T VIS COMPUT GR, V21, P31, DOI 10.1109/TVCG.2014.2325047
   Bhattacharya S., 2010, P 18 ACM INT C MULTI, P271
   Bishop Andrew, 2014, Evolutionary and Biologically Inspired Music, Sound, Art and Design. Third European Conference, EvoMUSART 2014. Revised Selected Papers: LNCS 8601, P62, DOI 10.1007/978-3-662-44335-4_6
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Datta Ritendra., 2010, Proceedings of the international conference on Multimedia information retrieval, P421, DOI DOI 10.1145/1743384.1743457
   Guo GJ, 2018, IEEE T MULTIMEDIA, V20, P2073, DOI 10.1109/TMM.2018.2794262
   Islam MB, 2017, MULTIMED TOOLS APPL, V76, P9517, DOI 10.1007/s11042-016-3561-5
   Jin X, 2019, IET COMPUT VIS, V13, P206, DOI 10.1049/iet-cvi.2018.5249
   Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399
   Kao YY, 2016, SIGNAL PROCESS-IMAGE, V47, P500, DOI 10.1016/j.image.2016.05.004
   Lan K, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P295, DOI 10.1109/SSCI.2015.51
   Lee HJ, 2017, IEEE T MULTIMEDIA, V19, P1921, DOI 10.1109/TMM.2017.2687759
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Lu P, 2019, SIGNAL PROCESS-IMAGE, V72, P105, DOI 10.1016/j.image.2018.12.007
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Marchesotti L, 2015, INT J COMPUT VISION, V113, P246, DOI 10.1007/s11263-014-0789-2
   Matsuda Y., 1995, Asakura Shoten, V2
   Mei-Chen Yeh, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P91, DOI 10.1109/ICCE-TW.2014.6904116
   Moon P, 1944, J OPT SOC AM, V34, P46, DOI 10.1364/JOSA.34.000046
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539
   Pramila A, 2017, MULTIMED TOOLS APPL, V76, P16063, DOI 10.1007/s11042-016-3895-z
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H-H, 2011, SCENIC PHOTOQUALITY, P1213
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Suler J., 2013, Photographic psychology: Image and Psyche
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P85, DOI 10.1109/34.899949
   Wang WN, 2015, SIGNAL PROCESS-IMAGE, V39, P499, DOI 10.1016/j.image.2015.07.006
   Yang JC, 2019, SIGNAL PROCESS-IMAGE, V78, P51, DOI 10.1016/j.image.2019.05.011
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Zhang C, 2018, SIGNAL PROCESS-IMAGE, V67, P12, DOI 10.1016/j.image.2018.05.006
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhang J, 2020, INKTHETICS COMPREHEN
   Zhang T, 2014, AESTHETIC APPEAL DEP, P81
   Zhang TT, 2020, IEEE ACCESS, V8, P13467, DOI 10.1109/ACCESS.2020.2966523
   Zhang XD, 2019, SIGNAL PROCESS-IMAGE, V78, P42, DOI 10.1016/j.image.2019.05.021
   Zhao MQ, 2016, SIGNAL PROCESS-IMAGE, V47, P511, DOI 10.1016/j.image.2016.05.009
   Zhu XH, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P222, DOI 10.1109/HPCSim.2016.7568339
NR 42
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22527
EP 22548
DI 10.1007/s11042-021-11557-w
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000740429700009
DA 2024-07-18
ER

PT J
AU Wang, L
   Wang, XF
   Hawbani, A
   Xiong, Y
   Zhang, X
AF Wang, Lin
   Wang, Xingfu
   Hawbani, Ammar
   Xiong, Yan
   Zhang, Xu
TI D<SUP>2</SUP>F: discriminative dense fusion of appearance and motion
   modalities for end-to-end video classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal fusion; Video classification; Attention; Convolution neural
   network (CNN); Optical flow fields; Complementary features
ID RECOGNITION
AB Recently, two-stream networks with multi-modality inputs have shown to be of vital importance for state-of-the-art video understanding. Previous deep systems typically employ a late fusion strategy, however, despite its simplicity and effectiveness, the late strategy might experience insufficient fusion due to that it performs fusion across modalities only once and treats each modality equally without discrimination. In this paper, we propose a Discriminative Dense Fusion ((DF)-F-2) network, addressing these limitations by densely inserting an attention-based fusion block at each layer. We experiment with two typical action classification benchmarks and three popular classification backbones, where our proposed module consistently outperforms state-of-the-art baselines by noticeable margins. Specifically, the two-stream VGG16, ResNet and I3D achieve accuracy of [93.5%, 69.2%], [94.6%, 70.5%], [94.1%, 72.3%] with (DF)-F-2 on [UCF101, HMDB51], respectively, with absolute gains of [5.5%, 9.8%], [5.13%, 9.91%], and [0.7%, 5.9%] compared with their late fusion counterparts. The qualitative performance also demonstrates that our model can learn more informative complementary representation.
C1 [Wang, Lin; Wang, Xingfu; Hawbani, Ammar; Xiong, Yan] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
   [Zhang, Xu] Natl Comp Network Emergency Response Tech Ctr Chi, Chengdu 610072, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Hawbani, A (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
EM xiaquhet@mail.ustc.edu.cn; wangxfu@ustc.edu.cn; anmande@ustc.edu.cn
RI Hawbani, Ammar/S-3356-2019
OI Hawbani, Ammar/0000-0002-1069-3993; wang, lin/0000-0002-9944-5151
FU Fundamental Research Funds for the Central Universities [WK2150110007,
   WK2150110012]; National Natural Science Foundation of China [61772490,
   61472382, 61472381, 61572454]
FX This paper is supported by the Fundamental Research Funds for the
   Central Universities (No. WK2150110007 and WK2150110012) and by the
   National Natural Science Foundation of China (No. 61772490, 61472382,
   61472381, and 61572454).
CR Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   [Anonymous], 2014, Advances in neural information processing systems
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF COMP V, P3179, DOI 10.1109/ICCVW.2017.376
   Bo Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14421, DOI 10.1109/CVPR42600.2020.01444
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Duan B, 2021, IEEE WINT CONF APPL, P4012, DOI 10.1109/WACV48630.2021.00406
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Goyal P, 2020, CROSS MODAL LEARNING
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Kalfaoglu M. Esat, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P731, DOI 10.1007/978-3-030-68238-5_48
   Katsaggelos AK, 2015, P IEEE, V103, P1635, DOI 10.1109/JPROC.2015.2459017
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khowaja SA, 2020, NEURAL COMPUT APPL, V32, P10423, DOI 10.1007/s00521-019-04578-y
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li Ang, 2020, ARXIV200500214
   Li YN, 2019, PATTERN RECOGN LETT, V119, P187, DOI 10.1016/j.patrec.2017.12.003
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Mai SJ, 2020, AAAI CONF ARTIF INTE, V34, P164
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Rashed H, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P165, DOI 10.5220/0007248301650172
   Riva M, 2020, INT CONF ACOUST SPEE, P4407, DOI [10.1109/ICASSP40776.2020.9053535, 10.1109/icassp40776.2020.9053535]
   Roitberg A, 2019, IEEE COMPUT SOC CONF, P198, DOI 10.1109/CVPRW.2019.00029
   Saha S, 2020, ARXIV PREPRINT ARXIV
   Sarma D., 2020, ARXIV200708847
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SJ, 2020, IEEE T IMAGE PROCESS, V29, P3957, DOI 10.1109/TIP.2020.2967577
   Soomro K, 2012, COMPUT VIS PATTERN R
   Sterpu G, 2020, SHOULD WE HARD CODE
   Su R, 2019, PROC CVPR IEEE, P12008, DOI 10.1109/CVPR.2019.01229
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   WENG X, 2019, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1905.02540
   Xiao JY, 2020, IEEE INT CONF AUTOMA, P364, DOI 10.1109/FG47880.2020.00132
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Yao LY, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106713
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang DJ, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107312
   Zhao JJ, 2019, PROC CVPR IEEE, P9927, DOI 10.1109/CVPR.2019.01017
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 46
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12157
EP 12176
DI 10.1007/s11042-021-11247-7
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000740429700020
DA 2024-07-18
ER

PT J
AU Yang, M
   Wu, J
   Niu, XW
AF Yang, Mei
   Wu, Jin
   Niu, Xiaowei
TI Camera module Lens blemish detection based on neural network
   interpretability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera module lens; Blemish detection; Class activation map;
   Self-attention model; Global average pooling
ID SURFACE; SYSTEM
AB Lens blemish detection is an important link in camera module production. Automatic blemish detection for camera module Lens is a challenging task, owing to sparse defect data, fast product update and low contrast between blemish and background. In this paper, A types of lens blemish detection models of camera module, named SA-LensNet, is developed using global average pooling (GAP) and Self-attention Mechanism, based on neural network visualization. The models developed are based on convolutional neural networks (CNN), and a class activation map (CAM) technique is applied to localize blemish regions without using region-level human annotations based on CNN classification network. The model has accuracy of 99% and recall of 98.7% in the module lenses classification (with and without blemish), localizing exact defect regions of blemish as well. Comparative experiments of several methods show that the proposed model has strong robustness and generalization ability for the detection of blemish.
C1 [Yang, Mei; Wu, Jin; Niu, Xiaowei] Chongqing Three Gorges Univ, Key Lab Elect & Informat, Chongqing, Peoples R China.
C3 Chongqing Three Gorges University
RP Yang, M (corresponding author), Chongqing Three Gorges Univ, Key Lab Elect & Informat, Chongqing, Peoples R China.
EM 20140046@sanxiau.edu.cn
FU Science and Technology Research Program of Chongqing Municipal Education
   Commission [KJZD-M201901201]
FX The authors gratefully acknowledge the support of this research by the
   Science and Technology Research Program of Chongqing Municipal Education
   Commission (No. KJQN201801213), and the Science and Technology Research
   Program of Chongqing Municipal Education Commission (Grant No.
   KJZD-M201901201).
CR [Anonymous], GLOBAL CMOS IMAGE SE
   Bang HT, 2020, COMPOS STRUCT, V246, DOI 10.1016/j.compstruct.2020.112405
   Bochkovskiy Alexey, 2020, DARKNET OPEN SOURCE
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Cha YJ, 2018, COMPUT-AIDED CIV INF, V33, P731, DOI 10.1111/mice.12334
   Chang F., 2019, MEAS SCI TECHNOL, V125905, P1
   Chen QL., 2020, FORG STAMP TECHNOL, V6, P168
   Chen SZ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P491, DOI 10.1109/CISP.2008.177
   Chen SH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238725
   Chu MX, 2018, CHEMOMETR INTELL LAB, V176, P108, DOI 10.1016/j.chemolab.2018.03.014
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao YP, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101825
   Han YF, 2019, MEASUREMENT, V145, P600, DOI 10.1016/j.measurement.2019.05.103
   He D, 2019, OPT LASER ENG, V117, P40, DOI 10.1016/j.optlaseng.2019.01.011
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang Jie-xian, 2010, Optics and Precision Engineering, V18, P2443, DOI 10.3788/OPE.20101811.2443
   Jb W, 2014, THESIS SHENYANG LIGO
   Ketkar N., 2017, Deep Learning with Python, P1
   Kingam DP, 2015, 3 INT C LEARN REPR S
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Ai-xing, 2007, Journal of Chongqing University of Posts and Telecommunication (Natural Science Edition), V19, P442
   Lin H, 2019, J INTELL MANUF, V30, P2525, DOI 10.1007/s10845-018-1415-x
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Napoletano P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010209
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park JK, 2016, INT J PR ENG MAN-GT, V3, P303, DOI 10.1007/s40684-016-0039-x
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Perkins, 1986, IEEE T PAMI, V8, P584
   Pierre S, 2014, ARXIV13126229V4CSCV
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi XK, 2004, OPT LASER ENG, V41, P901, DOI 10.1016/S0143-8166(03)00058-7
   Sun J, 2019, IEEE T INSTRUM MEAS, V68, P4787, DOI 10.1109/TIM.2019.2899478
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang H, 2017, CHIN OPT, V10, P438, DOI 10.3788/CO.20171004.0438
   Wang J, 2017, IEEE INFOCOM SER
   Wang Y, 2018, IOP C SER EARTH ENV, V108, DOI 10.1088/1755-1315/108/2/022025
   Wu ZL, 2018, INT J ADV MANUF TECH, V94, P3473, DOI 10.1007/s00170-017-0549-x
   Xi JQ, 2017, APPL OPTICS, V56, P184, DOI 10.1364/AO.56.000184
   Xu Guo-sheng, 2013, Applied Mechanics and Materials, V325-326, P1431, DOI 10.4028/www.scientific.net/AMM.325-326.1431
   Yu JB, 2016, IEEE T SEMICONDUCT M, V29, P33, DOI 10.1109/TSM.2015.2497264
   Yu ZY, 2017, LECT NOTES COMPUT SC, V10528, P417, DOI 10.1007/978-3-319-68345-4_37
   Yun JP, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.5.053108
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhai Dong, 2014, Electronic Science and Technology, V27, P160
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou K, 2016, DESTECH TRANS COMP
   [周显恩 Zhou Xian'en], 2016, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V30, P702
   Zhou XE, 2020, IEEE T IND INFORM, V16, P2189, DOI 10.1109/TII.2019.2935153
NR 53
TC 2
Z9 2
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5373
EP 5388
DI 10.1007/s11042-021-11716-z
EA DEC 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000731372000001
DA 2024-07-18
ER

PT J
AU Raikwar, SC
   Tapaswi, S
   Chakraborty, S
AF Raikwar, Suresh Chandra
   Tapaswi, Shashikala
   Chakraborty, Soumendu
TI Bounding function for fast computation of transmission in single image
   dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dark channel prior (DCP); Dehazing; Image enhancement; Image
   restoration; Transmission; Visibility
ID MODEL
AB There exist multiple dehazed images corresponding to a single hazy image due to ill-posed nature of single image dehazing (SID), making it a challenging problem. Usually, the SID used atmospheric scattering model (ASM) to obtain haze-free image from a hazy image. According to ASM, recovery of lost visibility depends upon accurate transmission. The proposed method presents a linear multiplicative bounding function (MBF) for estimation of difference channel (DC) to compute the value of transmission. The results obtained by the MBF has been compared with renowned SID methods. The accuracy of the proposed MBF has been proved by visual and objective evaluation of the dehazed images.
C1 [Raikwar, Suresh Chandra] Thapar Inst Engn & Technol, Patiala 147001, Punjab, India.
   [Tapaswi, Shashikala] ABV Indian Inst Informat Technol & Management, Gwalior, Madhya Pradesh, India.
   [Chakraborty, Soumendu] Indian Inst Informat Technol, Lucknow, Uttar Pradesh, India.
C3 Thapar Institute of Engineering & Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Raikwar, SC (corresponding author), Thapar Inst Engn & Technol, Patiala 147001, Punjab, India.
EM sureshc.rwr@gmail.com
RI TAPASWI, SHASHIKALA/AGZ-7714-2022; Chakraborty, Soumendu/ABA-2031-2020
OI Chakraborty, Soumendu/0000-0002-8778-8229
CR [Anonymous], 2018, IEEE T MULTIMEDIA, DOI DOI 10.1109/TMM.2018.2807593
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jha DK, 2016, IET COMPUT VIS, V10, P331, DOI 10.1049/iet-cvi.2014.0449
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CS, 2020, IEEE T SUSTAIN ENERG, V11, P1370, DOI 10.1109/TSTE.2019.2926147
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Ling ZG, 2017, NEUROCOMPUTING, V224, P82, DOI 10.1016/j.neucom.2016.10.050
   Liu SL, 2017, COMPUT ELECTR ENG, V62, P345, DOI 10.1016/j.compeleceng.2016.11.021
   Lu HM, 2016, IEEE IMAGE PROC, P1998, DOI 10.1109/ICIP.2016.7532708
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2004, THESIS NEW YORK
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Raikwar SC, 2020, VISUAL COMPUT, V36, P191, DOI 10.1007/s00371-018-1596-5
   Raikwar SC, 2020, MULTIMED TOOLS APPL, V79, P891, DOI 10.1007/s11042-019-08120-z
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang JZ, 2016, IEEE T MULTIMEDIA, V18, P1000, DOI 10.1109/TMM.2016.2544099
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang MM, 2018, IEEE T MULTIMEDIA, V20, P3008, DOI 10.1109/TMM.2018.2820327
   Yuan F, 2018, IEEE T IMAGE PROCESS, V27, P4395, DOI 10.1109/TIP.2018.2837900
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 46
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5349
EP 5372
DI 10.1007/s11042-021-11752-9
EA DEC 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000731372100001
DA 2024-07-18
ER

PT J
AU Benrais, L
   Baha, N
AF Benrais, Lamine
   Baha, Nadia
TI High level visual scene classification using background knowledge of
   objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene classification; Background knowledge; Statistical collection;
   Object saliency; Ranking functions
ID IMAGE CLASSIFICATION; REPRESENTATION; FRAMEWORK; TEXT
AB This paper introduces a novel and simple approach of high-level scene classification. Knowing that objects are the essence of any given scene, the proposed method uses them to construct a well-structured background knowledge, which is composed of ranking functions and a statistical collection, in order to support the scene classification process. Since not all objects are relevant, only the most salient ones are identified and used in computing the appropriate scene category. To prove the efficiency of the proposed method, experiments are conducted on state of the art datasets: MIT Indoor, SUN900, SUN2012, SUN397 and LabelMe+.Comparisons with other methods were also introduced. The obtained results are reported and discussed.
C1 [Benrais, Lamine; Baha, Nadia] Univ Sci & Technol USTHB, Comp Sci Dept, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Benrais, L (corresponding author), Univ Sci & Technol USTHB, Comp Sci Dept, Algiers, Algeria.
EM mbenrais@usthb.dz; nbahatouzene@usthb.dz
CR Abkenar MR, 2019, 2019 IEEE INT S CIRC
   Aditya S, 2017, AAAI CONF ARTIF INTE, P5028
   Aditya S, 2018, COMPUT VIS IMAGE UND, V173, P33, DOI 10.1016/j.cviu.2017.12.004
   Alajaji Dalal A., 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P77, DOI 10.1109/CDMA47397.2020.00019
   Ali N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203339
   Anbarasu B, 2018, DEFENCE SCI J, V68, P129, DOI 10.14429/dsj.68.10504
   [Anonymous], 2011, INDOOR SCENE RECOGNI
   [Anonymous], 2016, VIDEO ENG
   Bagschik G, 2018, IEEE INT VEH SYM, P1813, DOI 10.1109/IVS.2018.8500632
   Bai X, 2018, IEEE ACCESS, V6, P66322, DOI 10.1109/ACCESS.2018.2878899
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Cakir F, 2011, COMPUT VIS IMAGE UND, V115, P1483, DOI 10.1016/j.cviu.2011.07.007
   Choi MJ, 2012, PATTERN RECOGN LETT, V33, P853, DOI 10.1016/j.patrec.2011.12.004
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Donadello I., 2018, THESIS U TRENTO
   Donadello LS, 2017, ARXIV PREPRINT ARXIV
   Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Feng JF, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/5169675
   Finn C, 2018, ADV NEUR IN, V31
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu Q, 2020, GRAPH MODELS, V110, DOI 10.1016/j.gmod.2020.101073
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Ganesan A, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0030-9
   He XD, 2017, IEEE SIGNAL PROC MAG, V34, P109, DOI 10.1109/MSP.2017.2741510
   Hotz L, 2005, KI, V19
   Hu Anthony, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P767, DOI 10.1007/978-3-030-58517-4_45
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190
   Isola P., 2011, PROC CVPR IEEE, V2011, P145, DOI [DOI 10.1109/CVPR.2011.5995721, 10.1109/CVPR.2011.5995721]
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Kojima R, 2016, APPL ARTIF INTELL, V30, P181, DOI 10.1080/08839514.2016.1156461
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Li YB, 2019, PATTERN RECOGN, V90, P436, DOI 10.1016/j.patcog.2019.02.005
   Liu BD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050518
   Lu JX, 2020, IEEE T IMAGE PROCESS, V29, P4927, DOI 10.1109/TIP.2020.2975957
   Madaan N, 2020, INT CONF COMMUN SYST, DOI 10.1109/comsnets48256.2020.9027399
   Mary N. Ani Brown, 2021, Inventive Communication and Computational Technologies. Proceedings of ICICCT 2020. Lecture Notes in Networks and Systems (LNNS 145), P229, DOI 10.1007/978-981-15-7345-3_19
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   PANGERCIC D, 2009, P INT C ADV ROB ICAR
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Perera S, 2019, IEEE COMPUT SOC CONF, P800, DOI 10.1109/CVPRW.2019.00108
   Pham L, 2019, 2019 AES INTERNATIONAL CONFERENCE ON AUDIO FORENSICS
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rafique Adnan Ahmed, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P225, DOI 10.1109/ICAEM.2019.8853721
   Ramesh B, 2019, SOFT COMPUT, V23, P2429, DOI 10.1007/s00500-017-2939-2
   Rangel JC, 2016, ADV ROBOTICS, V30, P758, DOI 10.1080/01691864.2016.1164621
   REITER R, 1989, ARTIF INTELL, V41, P125, DOI 10.1016/0004-3702(89)90008-8
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Russell C, 2015, LABELME ANNOTATION T
   Rust NC, 2020, TRENDS COGN SCI, V24, P557, DOI 10.1016/j.tics.2020.04.001
   SADEGHI MA, 2011, PROC CVPR IEEE, P1745
   Savchenko AV, 2019, LECT NOTES COMPUT SC, V11555, P422, DOI 10.1007/978-3-030-22808-8_41
   Triantafillou E, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang, INTERDISCIPLINARY EV, P59
   Wu R, 2015, 2015 IEEE MAGNETICS CONFERENCE (INTERMAG), DOI 10.1109/INTMAG.2015.7156582
   Xia SF, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101072
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Zeng D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050734
   Zhang MY, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000900
   Zhang P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010108
   Zhao B, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020157
   Zitnick CL, 2016, IEEE T PATTERN ANAL, V38, P627, DOI 10.1109/TPAMI.2014.2366143
NR 74
TC 3
Z9 3
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3663
EP 3692
DI 10.1007/s11042-021-11701-6
EA NOV 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000720222500001
DA 2024-07-18
ER

PT J
AU Li, JJ
   Han, Y
   Zhang, M
   Li, G
   Zhang, BH
AF Li, Jianjun
   Han, Yu
   Zhang, Ming
   Li, Gang
   Zhang, Baohua
TI Multi-scale residual network model combined with Global Average Pooling
   for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-scale; Global average pooling; Residual network; Interaction
   recognition
ID NEURAL-NETWORKS; REPRESENTATION; BEHAVIOR
AB Human Action Recognition is a research hotspot in the field of computer vision. However, due to the complexity of the environment and the diversity of actions, Human Action Recognition still faces many challenges. At the same time, traditional CNN has problems such as single feature scale, decreased accuracy of deep network, and excessive network parameters. Aiming at the above research problems, this paper proposes a novel residual network model based on Multi-scale Feature Fusion and Global Average Pooling. The model uses a Multi-scale Feature Fusion module to extract feature information of different scales, enriches spatial-time information. At the end of the network, Global Average Pooling is used to instead of a Fully Connected layer. Compared with a Fully Connected layer, Global Average Pooling will dilute the combination of the relative positions of different features. Therefore, the features trained by convolution are more effective. In addition, Global Average Pooling can realize direct mapping between output channels and feature categories to reduce excessive model parameters. The model in this paper is verified on the UT-interaction dataset, UCF11 (YouTube Action dataset), UCF101 dataset and CAVIAR dataset. The results show that compared with the state-of-the-art approaches, this approach has high recognition accuracy and excellent robustness, and has excellent performance on datasets with complex backgrounds and diverse action categories.
C1 [Li, Jianjun; Han, Yu; Zhang, Ming; Li, Gang; Zhang, Baohua] Inner Mongolia Univ Sci & Technol, Sch Elect & Informat Engn, 7 Arding St, Baotou, Peoples R China.
C3 Inner Mongolia University of Science & Technology
RP Li, JJ (corresponding author), Inner Mongolia Univ Sci & Technol, Sch Elect & Informat Engn, 7 Arding St, Baotou, Peoples R China.
EM xidianjj@163.com
RI zhang, ming/E-3364-2013
OI zhang, ming/0000-0003-2638-9002; Li, jianjun/0000-0003-3003-8344
FU National Natural Science Foundation of China [61663036]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No: 62066036) and the National Natural Science Foundation
   of China (Grant No: 61663036).
CR Afsar P, 2015, EXPERT SYST APPL, V42, P6935, DOI 10.1016/j.eswa.2015.05.023
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Chen C., 2019, COMPUT TECHNOL DEV, V29, P157
   Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Diba A., 2017, Temporal 3D ConvNets: New architecture and transfer learning for video classification
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   [郭文慧 Guo Wenhui], 2019, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V32, P882
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Javidani A, 2018, LEARNING REPRESENTAT
   Javidani A, 2018, IRAN CONF ELECTR ENG, P1629, DOI 10.1109/ICEE.2018.8472580
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Kong Yu., 2014, Computer Vision-ECCV 2014 Workshops. Springer, P29
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Lin M, 2014, 2014 INT C LEARN REP
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Michalakis K, 2018, IEEE CONSUM ELECTR M, V7, P64, DOI 10.1109/MCE.2018.2797638
   Pan Y, 2019, AAAI CONF ARTIF INTE, P4683
   Park E, 2016, IEEE WINT CONF APPL
   Pham HH, 2017, LEARNING RECOGNIZING
   Ren QH, 2018, NEUROCOMPUTING, V316, P95, DOI 10.1016/j.neucom.2018.07.055
   Robert F, 2001, CAVIAR CONTEXT AWARE
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ryoo M, 2010, UT INTERACTION DATAS
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Trabelsi R, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300937
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tran Du, 2017, ARXIV170805038
   Wang DH, 2020, NEURAL NETWORKS, V131, P215, DOI 10.1016/j.neunet.2020.07.028
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang L, 2018, IEEE ACCESS, V6, P50788, DOI 10.1109/ACCESS.2018.2869751
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xin RY, 2020, TSINGHUA SCI TECHNOL, V25, P447, DOI 10.26599/TST.2019.9010055
   Xu WR, 2017, IEEE T MULTIMEDIA, V19, P1494, DOI 10.1109/TMM.2017.2674622
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang SG, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3090343
NR 54
TC 12
Z9 13
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1375
EP 1393
DI 10.1007/s11042-021-11435-5
EA OCT 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000702205000001
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Kamal, ST
   Darwish, MM
AF Hosny, Khalid M.
   Kamal, Sara T.
   Darwish, Mohamed M.
TI A color image encryption technique using block scrambling and chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Scrambling; Chaos
ID DNA ENCRYPTION; ALGORITHM; SYSTEM; MAP; ROBUST; COMBINATION; SCHEME
AB Images are very important forms of data that are widely used nowadays. Every day, millions of grey and color images are transferred via the web. Protecting these images from unauthorized persons is an important issue. Image encryption is one of the image-securing techniques. One advantage of using encryption is that the plain image is converted to an unrecognized one. Also, the plain image is restored without any loss of information. In this paper, a color image encryption technique using blocks scrambling and chaos is presented. First, the plain image is decomposed into three channels: R, G, and B. Then, each channel is divided into sub-images and blocks. Our encryption algorithm depends on two main steps: scrambling and diffusion. First, the pixels' arrangement in sub-images and blocks is changed, and then scrambling between sub-images is done to get the scrambled image. Then, in diffusion, the scrambled image diffuses using the logistic map to get the encrypted image. The experimental results show that our proposed algorithm has good performance in encrypting color images.
C1 [Hosny, Khalid M.] Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
   [Kamal, Sara T.; Darwish, Mohamed M.] Assiut Univ, Dept Comp Sci, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
EM k_hosny@yahoo.com
RI Tarik, Sara/GXN-0388-2022; Darwish, SMIEEE, M. M. F./AAE-5964-2021;
   Hosny, Khalid M./B-1404-2008
OI Darwish, SMIEEE, M. M. F./0000-0001-9782-8813; Hosny, Khalid
   M./0000-0001-8065-8977
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abdel-Aziz MM, 2021, MULTIMED TOOLS APPL, V80, P12641, DOI 10.1007/s11042-020-10217-9
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091497
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Suri S, 2019, J AMB INTEL HUM COMP, V10, P2277, DOI 10.1007/s12652-018-0825-0
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 40
TC 65
Z9 65
U1 17
U2 159
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 505
EP 525
DI 10.1007/s11042-021-11384-z
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695454400006
DA 2024-07-18
ER

PT J
AU Liu, SX
   Long, W
   Li, YY
   Cheng, H
AF Liu, Shouxin
   Long, Wei
   Li, Yanyan
   Cheng, Hong
TI Low-light image enhancement based on membership function and gamma
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Low-light image; HSV color space; Adaptive gamma
   correction; Membership function
ID QUALITY ASSESSMENT; CONTRAST ENHANCEMENT; ALGORITHM; FUSION
AB The aim of low-light image enhancement algorithms is to improve the luminance of images. However, existing low-light image enhancement algorithms inevitably cause an enhanced image to be over- or underenhanced and cause color distortion, both of which prevent the enhanced images from obtaining satisfactory visual effects. In this paper, we proposed a simple but effective low-light image enhancement algorithm based on a membership function and gamma correction (MFGC). First, we convert the image from the RGB (red, green, blue) color space to the HSV (hue, saturation, value) color space and design a method to achieve the self-adaptation computation of traditional membership function parameters. Then, we use the results of the membership function as the gamma value and adjust coefficient c of the gamma function based on the characteristics of different images with different gray levels. Finally, we design a linear function to avoid underenhancement. The experimental results show that our method not only has lower computational complexity but also greatly improves the brightness of low-light areas and addresses uneven brightness. The images enhanced using the proposed method have better objective and subjective image quality evaluation results than other state-of-the-art methods.
C1 [Liu, Shouxin; Long, Wei; Li, Yanyan; Cheng, Hong] Sichuan Univ, Sch Mech Engn, Chengdu, Peoples R China.
C3 Sichuan University
RP Liu, SX (corresponding author), Sichuan Univ, Sch Mech Engn, Chengdu, Peoples R China.
EM liushouxin163@yeah.net
OI Liu, Shouxin/0000-0003-2706-0313
FU Science and Technology Department of Sichuan Province, People's Republic
   of China [2020JDRC0026]
FX This work was supported by Science and Technology Department of Sichuan
   Province, People's Republic of China (No. 2020JDRC0026).
CR Ashiba MI, 2019, MULTIMED TOOLS APPL, V78, P27771, DOI 10.1007/s11042-018-7086-y
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Cao JC, 2019, SIGNAL PROCESS-IMAGE, V78, P388, DOI 10.1016/j.image.2019.07.018
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Cheng H, 2020, MULTIMED TOOLS APPL, P1
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Deng H, 2017, IEEE T BIO-MED ENG, V64, P1803, DOI 10.1109/TBME.2016.2624306
   Deng H, 2016, IET IMAGE PROCESS, V10, P701, DOI 10.1049/iet-ipr.2016.0035
   Dhal KG, 2019, IJST-T ELECTR ENG, V43, P645, DOI 10.1007/s40998-019-00175-w
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kallel F, 2017, IEEE T NANOBIOSCI, V16, P666, DOI 10.1109/TNB.2017.2771350
   Kansal S, 2019, MULTIMED TOOLS APPL, V78, P25241, DOI 10.1007/s11042-019-07744-5
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li CL, 2020, IEEE ACCESS, V8, P169887, DOI 10.1109/ACCESS.2020.3023485
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li Z, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.3010966
   Lyu WJ, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102797
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mouzai M, 2020, MED BIOL ENG COMPUT, V58, P1177, DOI 10.1007/s11517-020-02122-y
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Srinivas K, 2020, IET IMAGE PROCESS, V14, P668, DOI 10.1049/iet-ipr.2019.0781
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wu YH, 2019, IET IMAGE PROCESS, V13, P2448, DOI 10.1049/iet-ipr.2018.6208
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Yun HJ, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8598917
   Zhenlin Wang, 2019, 2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1541, DOI 10.1109/IAEAC47372.2019.8997617
   Zhou ZY, 2020, NEURAL COMPUT APPL, V32, P6455, DOI 10.1007/s00521-018-3893-3
   Zhu WH, 2018, SIGNAL PROCESS, V145, P193, DOI 10.1016/j.sigpro.2017.12.001
NR 41
TC 4
Z9 4
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22087
EP 22109
DI 10.1007/s11042-021-11505-8
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000693494700006
DA 2024-07-18
ER

PT J
AU Manisha
   Kumar, N
AF Manisha
   Kumar, Nitin
TI CBRC: a novel approach for cancelable biometric template generation
   using random permutation and Chinese Remainder Theorem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure; Secret; Cover; Performance; Inter; Intra; Cross; Correlation
ID EFFICIENT; SCHEMES
AB Cancelable Biometrics is a challenging research field in which a cancelable template corresponding to a biometric is generated without affecting the performance. These cancelable templates can be generated using various methods given in literature. However, the qualitative and quantitative performance of these methods is not satisfactory. To address this concern, here we propose a novel cancelable biometric template generation method based on Random Permutation and Chinese Remainder Theorem. In the proposed approach, cancelable biometric template is generated by employing secret image i.e. the original biometric and cover image(s) i.e. any other image(s). Random permutation provides visual protection against the original biometric but preserves the intensity values. Chinese Remainder Theorem is used as a transformation function on the output of random permutation step so as to ensure the intensity values are not revealed to any intruder. The proposed method generates Cancelable Biometric templates in the form of Secret Shares and is suitable for gray as well as color images. To demonstrate the efficacy of the proposed method, extensive experiments have been performed on eight different datasets viz.Carreira-Perpinan ear (CP) (gray and color), University of Tehran IRIS (UTIRIS) (color), Olivetti Research Laboratory face (ORL) (gray), Mathematical Analysis of Images ear (AMI) (color), Aleix Martinez and Robert Benavente face (AR) (color), and Indian Institute of Technology Delhi iris (IITD) (gray and color). Qualitative and quantitative analysis of the generated templates shows that the performance of the proposed method is best when considered simultaneously than several state-of-the-art methods. The main advantages of the proposed method include (i) no glimpses of the original biometric in the cancelable template, (ii) no storage of original biometric during enrolment (iii) the proposed method works for both gray as well as color images and (iv) no image registration is required.
C1 [Manisha; Kumar, Nitin] Natl Inst Technol, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, N (corresponding author), Natl Inst Technol, Srinagar, Uttarakhand, India.
EM manisharawatphd@nituk.ac.in; nitin@nituk.ac.in
OI Rawat, Dr. Manisha/0000-0002-6382-247X
FU Ministry of Human Resource Development; Uttarakhand State Council for
   Science and Technology, Dehradun, Uttarakhand, India
   [D-05/18-19/15202/1]
FX Ms. Manisha is thankful to Ministry of Human Resource Development, Govt.
   of India for providing research fellowship. Dr. Nitin Kumar is thankful
   to Uttarakhand State Council for Science and Technology, Dehradun,
   Uttarakhand, India for providing financial support for this research
   work (Sanction No. UCS & T/R & D-05/18-19/15202/1 dated 28-09-2018)
CR Abidi M., 2010, Design and Technology of Integrated Systems in Nanoscale Era (DTIS), 2010 5th International Conference on, P1
   Camenisch J, 1997, LECT NOTES COMPUT SC, V1294, P410
   Cherabit Noureddine, 2012, Sci. Technol, V2, P114, DOI [DOI 10.5923/J.SCIT.20120205.02, 10.5923/j.scit.20120205.02.]
   Choudhury B, 2016, IEEE ST CONF RES DEV
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Gandhare WZ, 2010, ARXIV PREPRINT ARXIV
   Ghany KKA, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P941, DOI 10.1109/ASONAM.2012.167
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Karabat Cagatay, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P65, DOI 10.1109/SIU.2009.5136333
   Kaur H, 2017, P WORLD C ENG COMP S, V1
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kim J, 2018, INT C PATT RECOG, P3108, DOI 10.1109/ICPR.2018.8545565
   Kumar N, 2018, APPL INTELL, V48, P2824, DOI 10.1007/s10489-017-1117-7
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Manisha Kumar N, 2020, INTELLIGENT COMPUTIN, V1230, DOI [10.1007/978-3-030-52243-8_38, DOI 10.1007/978-3-030-52243-8_38]
   Meetei TC, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Naor M, 1995, P ADV CRYPT EUR, P1
   Nazari S, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P925, DOI 10.1109/ISTEL.2014.7000835
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Paul P. P., 2012, Proceedings of the 2012 11th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC), P43, DOI 10.1109/ICCI-CC.2012.6311208
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Raja KB, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2098, DOI 10.23919/ICIF.2018.8455809
   Rathgeb C., 2015, INT WORKSH BIOM FOR, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Ross A, 2010, BIOMETRIC TECHNOLOGY, V7667, P766
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sinduja R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P650
   Tan F, 2009, TENCON IEEE REGION, P900
   Wang S, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1682, DOI 10.1109/CISP.2013.6743947
   Xu DC, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P2421, DOI 10.1109/ICMA.2009.5246046
   Xu WH, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P412, DOI 10.1109/ISECS.2008.100
   Yang WC, 2018, IEEE ACCESS, V6, P36939, DOI 10.1109/ACCESS.2018.2844182
   You L, 2017, CHINESE J ELECTRON, V26, P236, DOI 10.1049/cje.2017.01.009
   Zuo JY, 2008, INT C PATT RECOG, P2925
NR 38
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22027
EP 22064
DI 10.1007/s11042-021-11284-2
EA AUG 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000691718600005
DA 2024-07-18
ER

PT J
AU Rath, A
   Mishra, D
   Panda, G
   Satapathy, SC
AF Rath, Adyasha
   Mishra, Debahuti
   Panda, Ganapati
   Satapathy, Suresh Chandra
TI An exhaustive review of machine and deep learning based diagnosis of
   heart diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE CVD; Detection of HD using ML; Diagnosis of HD; Review and analysis of
   HD; IoT based HD; CNN in HD detection
ID DECISION-SUPPORT-SYSTEM; FEATURE-SELECTION; NEURAL-NETWORKS;
   CARDIOVASCULAR-DISEASE; MEDICAL DIAGNOSIS; CLASSIFICATION; PREDICTION;
   ALGORITHM; IDENTIFICATION; PLATFORM
AB In comparison to other diseases, the number of deaths on Heart Disease (HD) is the highest across the globe. The trend of death due to HD is still rising which has become a constant source of concern amongst the human beings. The researchers and doctors are putting tremendous efforts to save the life from HD. It is observed from the literature that a large number of researchers are currently carrying out their research work in various aspects of HD. Among those the early detection and diagnosis of HD are currently the focus area of research. Appropriate, reliable, accurate, robust and affordable HD detection scheme is the ultimate goal for saving the lives of the people. In this research, articles on HD detection and diagnosis published in recent past have been collected and critically analysed. The outcome of the analysis is presented in various tabular forms for easy understanding and further use. The paper would provide a thorough knowledge on standard data source on HD, the feature extraction, selection and reduction methods and Machine Learning (ML) and Deep Learning (DL) based classification schemes. The categorization of published articles and the various performance measures employed have been presented which would develop interest amongst new researchers working in the area of detection or classification of HD. The best performing technique in each category of has been listed. The research challenges and future scope of work are also provided to facilitate further research work in this promising area.
C1 [Rath, Adyasha; Mishra, Debahuti] Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar 751030, Odisha, India.
   [Panda, Ganapati] CV Raman Global Univ, Dept Elect & Tele Commun, Bhubaneswar 752054, Odisha, India.
   [Satapathy, Suresh Chandra] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 Siksha 'O' Anusandhan University; Kalinga Institute of Industrial
   Technology (KIIT)
RP Panda, G (corresponding author), CV Raman Global Univ, Dept Elect & Tele Commun, Bhubaneswar 752054, Odisha, India.
EM adyasharath1996@gmail.com; debahutimishra@soa.ac.in;
   ganapati.panda@gmail.com; suresh.satapathyfcs@kiit.ac.in
RI Panda, Ganapati/AFP-7044-2022
OI Panda, Ganapati/0000-0002-3555-5685; Mishra,
   Debahuti/0000-0002-6827-6121; Rath, Adyasha/0000-0002-4079-1914
CR Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Al-Makhadmeh Z, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.043
   Ali SA, 2020, IEEE ACCESS, V8, P65947, DOI 10.1109/ACCESS.2020.2985646
   Sanz JA, 2014, APPL SOFT COMPUT, V20, P103, DOI 10.1016/j.asoc.2013.11.009
   Avci E, 2009, EXPERT SYST APPL, V36, P10618, DOI 10.1016/j.eswa.2009.02.053
   Avci E, 2009, EXPERT SYST APPL, V36, P2873, DOI 10.1016/j.eswa.2008.01.030
   Babaoglu I, 2010, EXPERT SYST APPL, V37, P3177, DOI 10.1016/j.eswa.2009.09.064
   Basçiftçi F, 2011, EXPERT SYST APPL, V38, P14037, DOI 10.1016/j.eswa.2011.04.211
   Bashir S, 2014, ARAB J SCI ENG, V39, P7771, DOI 10.1007/s13369-014-1315-0
   Bozkurt B, 2018, COMPUT BIOL MED, V100, P132, DOI 10.1016/j.compbiomed.2018.06.026
   Chabchoub S, 2018, BIOCYBERN BIOMED ENG, V38, P251, DOI 10.1016/j.bbe.2017.12.002
   Chen JM, 2019, IEEE ACCESS, V7, P120831, DOI 10.1109/ACCESS.2019.2937875
   Das R, 2009, EXPERT SYST APPL, V36, P7675, DOI 10.1016/j.eswa.2008.09.013
   Deng MQ, 2018, NEURAL NETWORKS, V100, P70, DOI 10.1016/j.neunet.2018.01.009
   Devi RL, 2020, J SUPERCOMPUT, V76, P6533, DOI 10.1007/s11227-019-02873-y
   Dominguez-Morales JP, 2018, IEEE T BIOMED CIRC S, V12, P24, DOI 10.1109/TBCAS.2017.2751545
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V29, P685, DOI 10.1007/s00521-016-2604-1
   Ghosh SK, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103632
   Gia TN, 2019, FUTURE GENER COMP SY, V93, P198, DOI 10.1016/j.future.2018.10.029
   Guo CY, 2020, IEEE ACCESS, V8, P59247, DOI 10.1109/ACCESS.2020.2981159
   Hanbay D, 2009, EXPERT SYST APPL, V36, P4232, DOI 10.1016/j.eswa.2008.04.010
   Huang JS, 2019, IEEE ACCESS, V7, P92871, DOI 10.1109/ACCESS.2019.2928017
   Ibn Hasan N, 2019, BIOMED SIGNAL PROCES, V52, P128, DOI 10.1016/j.bspc.2019.04.005
   Javeed A, 2019, IEEE ACCESS, V7, P180235, DOI 10.1109/ACCESS.2019.2952107
   Kahramanli H, 2008, EXPERT SYST APPL, V35, P82, DOI 10.1016/j.eswa.2007.06.004
   Khan MA, 2020, IEEE ACCESS, V8, P122259, DOI 10.1109/ACCESS.2020.3006424
   Khan MA, 2020, IEEE ACCESS, V8, P34717, DOI 10.1109/ACCESS.2020.2974687
   Khatibi V, 2010, EXPERT SYST APPL, V37, P8536, DOI 10.1016/j.eswa.2010.05.022
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Kurt I, 2008, EXPERT SYST APPL, V34, P366, DOI 10.1016/j.eswa.2006.09.004
   Kwak C, 2012, IET SIGNAL PROCESS, V6, P326, DOI 10.1049/iet-spr.2011.0170
   Kwon JM, 2019, ECHOCARDIOGR-J CARD, V36, P213, DOI 10.1111/echo.14220
   Li JP, 2020, IEEE ACCESS, V8, P107562, DOI 10.1109/ACCESS.2020.3001149
   Magesh G, 2021, EVOL INTELL, V14, P583, DOI 10.1007/s12065-019-00336-0
   Meng YW, 2020, IEEE J BIOMED HEALTH, V24, P878, DOI 10.1109/JBHI.2019.2922178
   Mishra M, 2019, IEEE T INSTRUM MEAS, V68, P3211, DOI 10.1109/TIM.2018.2872387
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Muthukaruppan S, 2012, EXPERT SYST APPL, V39, P11657, DOI 10.1016/j.eswa.2012.04.036
   Nahar J, 2013, EXPERT SYST APPL, V40, P96, DOI 10.1016/j.eswa.2012.07.032
   Nazari S, 2018, EXPERT SYST APPL, V95, P261, DOI 10.1016/j.eswa.2017.11.001
   Long NC, 2015, EXPERT SYST APPL, V42, P8221, DOI 10.1016/j.eswa.2015.06.024
   Nilashi M, 2020, INT J FUZZY SYST, V22, P1376, DOI 10.1007/s40815-020-00828-7
   Oresko JJ, 2010, IEEE T INF TECHNOL B, V14, P734, DOI 10.1109/TITB.2010.2047865
   Orphanou K, 2016, IEEE J BIOMED HEALTH, V20, P944, DOI 10.1109/JBHI.2015.2420534
   Papadaniil CD, 2014, IEEE J BIOMED HEALTH, V18, P1138, DOI 10.1109/JBHI.2013.2294399
   Raj S, 2020, IEEE T CONSUM ELECTR, V66, P106, DOI 10.1109/TCE.2020.2981511
   Saeidi A, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101775
   Salah IB, 2020, BIOMED SIGNAL PROCES, V57
   Sarmah SS, 2020, IEEE ACCESS
   Schmidt SE, 2015, IEEE T BIO-MED ENG, V62, P2611, DOI 10.1109/TBME.2015.2432129
   Sengur A., 2020, EXPERT SYST APPL, V35, P222
   Shao YE, 2014, APPL SOFT COMPUT, V14, P47, DOI 10.1016/j.asoc.2013.09.020
   Shilaskar S, 2013, EXPERT SYST APPL, V40, P4146, DOI 10.1016/j.eswa.2013.01.032
   Tao R, 2019, IEEE T BIO-MED ENG, V66, P1658, DOI 10.1109/TBME.2018.2877649
   Vankara J, 2020, INT J SPEECH TECHNOL, V23, P31, DOI 10.1007/s10772-020-09670-6
   Vivekanandan T, 2017, COMPUT BIOL MED, V90, P125, DOI 10.1016/j.compbiomed.2017.09.011
   Wang HR, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1511-2
   Wang JK, 2020, IEEE ACCESS, V8, P37124, DOI 10.1109/ACCESS.2020.2975377
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Yasin M, 2017, IEEE T CIRCUITS-I, V64, P2624, DOI 10.1109/TCSI.2017.2694968
NR 60
TC 7
Z9 8
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36069
EP 36127
DI 10.1007/s11042-021-11259-3
EA AUG 2021
PG 59
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000691718600003
DA 2024-07-18
ER

PT J
AU Huang, YB
   Li, H
   Wang, Y
   Xie, YR
   Zhang, QY
AF Huang, Yi-bo
   Li, Hao
   Wang, Yong
   Xie, Yi-rong
   Zhang, Qiu-yu
TI A high security BioHashing encrypted speech retrieval algorithm based on
   feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Biometric template; BioHashing; K-means-KNN;
   Improved Marotto chaos measurement matrix; SPM chaotic map
ID TRANSFORM
AB In order to solve the problem of plaintext data leakage, and to improve the diversity and security of biometric template, this paper proposes a high security BioHashing encrypted speech retrieval algorithm based on feature fusion, and introduces K-means-KNN fusion algorithm to classify. Firstly, the features of speech are extracted through FFT and IFFT. Secondly, the fused features are classified and a single mapping secret key is assigned to each class. The improved Marotto chaos measurement matrix is generated by the secret key, and the BioHashing sequences are generated by iterating the measurement matrix with the feature data. Then, the speech clips are classified and a single mapping secret key is assigned to each class. The SPM(sine map and piece wise linear chaotic map) chaotic sequence is generated by the secret key and the speech clips are encrypted by the sequence. Finally, hash indexes and encrypted speech clips are uploaded to the cloud, the normalized Hamming distance algorithm is used for matching retrieval on the user terminal. Experimental results show that the algorithm not only effectively prevents plaintext data leakage, but also achieves 100% retrieval accuracy for the original speech clips. Moreover, there are 18 classes of biometric templates, which have good security and key revocability.
C1 [Huang, Yi-bo; Li, Hao; Wang, Yong; Xie, Yi-rong] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@nwnu.edu.cn; lhnwnu@163.com; 15737315638@163.com;
   yirongxie@126.com; zhangqylz@163.com
RI zhang, qiu/GXG-5600-2022
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Youth Science
   and Technology Fund of Gansu Province of China [1606RJYA274]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Youth Science and Technology Fund of Gansu Province
   of China(No.1606RJYA274).
CR Abdul W, 2020, COMPUT J, V63, P479, DOI 10.1093/comjnl/bxz047
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Bai L, 2020, INFORM FUSION, V61, P36, DOI 10.1016/j.inffus.2020.03.009
   Chen DQ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P531
   Das Debashis, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P195, DOI 10.1007/978-981-13-9042-5_17
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Huang YB, 2020, MULTIMED TOOLS APPL, V79, P24889, DOI 10.1007/s11042-020-09211-y
   Huang YB, 2020, IEEE ACCESS, V8, P34140, DOI 10.1109/ACCESS.2020.2974029
   Jiang YT, 2019, MULTIMED TOOLS APPL, V78, P30011, DOI 10.1007/s11042-018-6802-y
   Karst SM, 2018, NAT BIOTECHNOL, V36, P190, DOI 10.1038/nbt.4045
   Kashif M, 2020, J DIGIT IMAGING, V33, P971, DOI 10.1007/s10278-020-00338-w
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Li D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18566-6
   Li X, 2020, IEEE SYST J, V14, P39, DOI 10.1109/JSYST.2019.2899580
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin CY, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105995
   Melnykov V, 2020, J CLASSIF, V37, P97, DOI 10.1007/s00357-019-09314-8
   Murthy YVS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177849
   Nayak S, 2020, OPTIK, V212, DOI 10.1016/j.ijleo.2020.164675
   Palma D, 2020, IEEE ACCESS, V8, P118978, DOI 10.1109/ACCESS.2020.3005460
   Pradhan J, 2020, VISUAL COMPUT, V36, P1847, DOI 10.1007/s00371-019-01773-9
   Revathi A, 2019, MULTIMED TOOLS APPL, V78, P1569, DOI 10.1007/s11042-018-6258-0
   Revathi B, 2018, J KING SAUD UNIV-COM, P1319
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P18339, DOI 10.1007/s11042-019-7208-1
   Shen YM, 2020, INFORM SCIENCES, V539, P145, DOI 10.1016/j.ins.2020.05.114
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Song XY, 2019, IEEE SENS J, V19, P6309, DOI 10.1109/JSEN.2019.2892443
   Wallnöfer J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36543-5
   Yang FF, 2019, PHYS SCRIPTA, V94, DOI 10.1088/1402-4896/ab0033
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P29775, DOI 10.1007/s11042-020-09446-9
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2019, TURK J ELECTR ENG CO, V27, P1719, DOI 10.3906/elk-1808-161
   Zhang QY, 2018, EFFICIENT RETRIEVAL, V9
   Zhou LQ, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920503273
   Zou FH, 2018, MULTIMED TOOLS APPL, V77, P3677, DOI 10.1007/s11042-017-5219-3
NR 42
TC 5
Z9 6
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33615
EP 33640
DI 10.1007/s11042-021-11412-y
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687012300002
DA 2024-07-18
ER

PT J
AU Zhang, W
   Han, WJ
   Zhu, ZL
   Yu, H
AF Zhang, Wei
   Han, Weijie
   Zhu, Zhiliang
   Yu, Hai
TI An ultrahigh-resolution image encryption algorithm using random
   super-pixel strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Ultrahigh resolution images; Super-pixels;
   Pseudo-random diffusion path; Parallelism
ID CELLULAR-AUTOMATA; CHAOTIC SYSTEM; SCHEME; MAP; PERMUTATION; TRANSFORM;
   DIFFUSION; DWT
AB Almost all existing image encryption algorithms are only suitable for low-resolution images in the standard image library. When they are used to encrypt high-resolution images, they will inevitably suffer from inefficiency or program crashes. Inspired by the super-pixel concept in image processing, in this paper, a new image encryption algorithm using PRSP (Pseudo Random Super Pixel) strategy and KBCA (Key-based Cellular Automata) is proposed. Both scrambling and diffusion are implemented in parallel to improve the efficiency of encryption algorithm when encrypting ultra-high resolution images. Besides, random diffusion path is designed to ensure the security of encryption algorithm. Simulations are carried out using CUDA (Compute Unified Device Architecture) platform, and simulation results show the high efficiency and security of our algorithm.
C1 [Zhang, Wei; Han, Weijie; Zhu, Zhiliang; Yu, Hai] Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Han, WJ (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.
EM veejayhan@163.com
RI YU, Hai/E-6831-2018
OI YU, Hai/0000-0002-8024-1781
FU National Natural Science Foundation of China [61977014, 61902056,
   61603082]; Fundamental Research Funds for the Central Universitie
   [N2017011, N2017016]
FX This research was supported by the National Natural Science Foundation
   of China(Grant Nos. 61977014, 61902056, 61603082), the Fundamental
   Research Funds for the Central Universitie (Grant Nos. N2017011,
   N2017016).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Castro JCH, 2005, MATH COMPUT SIMULAT, V68, P1, DOI 10.1016/j.matcom.2004.09.001
   Çavusoglu Ü, 2019, CLUSTER COMPUT, V22, P1211, DOI 10.1007/s10586-018-02895-w
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao WJ, 2019, OPTIK, V185, P917, DOI 10.1016/j.ijleo.2019.02.007
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Han YJ, 2010, OPT COMMUN, V283, P1690, DOI 10.1016/j.optcom.2009.12.060
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kumar R, 2017, OPT LASER TECHNOL, V95, P51, DOI 10.1016/j.optlastec.2017.03.041
   Lee WK, 2018, NONLINEAR DYNAM, V92, P575, DOI 10.1007/s11071-018-4076-6
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li CH, 2018, MULTIMED TOOLS APPL, V77, P19193, DOI 10.1007/s11042-017-5391-5
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Patro KAK, 2019, LECT NOTES ELECTR EN, V556, P143, DOI 10.1007/978-981-13-7091-5_13
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tian ZQ, 2016, NEUROCOMPUTING, V215, P128, DOI 10.1016/j.neucom.2015.06.114
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2017, J VIS COMMUN IMAGE R, V48, P77, DOI 10.1016/j.jvcir.2017.06.005
   WOLFRAM S, 1986, ADV APPL MATH, V7, P123, DOI 10.1016/0196-8858(86)90028-X
   WOLFRAM S, 1984, NATURE, V311, P419, DOI 10.1038/311419a0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Zhang W, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050504
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
NR 51
TC 1
Z9 1
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33429
EP 33454
DI 10.1007/s11042-021-11096-4
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512900006
DA 2024-07-18
ER

PT J
AU Nitaj, A
   Ariffin, MRK
   Adenan, NNH
   Merenda, DS
   Ahmadian, A
AF Nitaj, Abderahmanne
   Ariffin, Muhammad Rezal Kamel
   Adenan, Nurul Nur Hanisah
   Merenda, Domenica Stefania
   Ahmadian, Ali
TI Exponential increment of RSA attack range via lattice based
   cryptanalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; RSA; Cryptanalysis; Coppersmith's technique; Integer
   factorization
ID FINDING SMALL ROOTS; POLYNOMIAL EQUATIONS
AB The RSA cryptosystem comprises of two important features that are needed for encryption process known as the public parameter e and the modulus N. In 1999, a cryptanalysis on RSA which was described by Boneh and Durfee focused on the key equation ed - k Phi(N) = 1 and e of the same magnitude to N. Their method was applicable for the case of d < N-0.292 via Coppersmith's technique. In 2012, Kumar et al. presented an improved Boneh-Durfee attack using the same equation which is valid for any e with arbitrary size. In this paper, we present an exponential increment of the two former attacks using the variant equation ea - Phi(N)b = c. The new attack breaks the RSA system when a and vertical bar c vertical bar are suitably small integers. Moreover, the new attack shows that the BonehDurfee attack and the attack of Kumar et al. can be derived using a single attack. We also showed that our bound manage to improve the bounds of Ariffin et al. and Bunder and Tonien.
C1 [Nitaj, Abderahmanne] Normandie Univ, UNICAEN, CNRS, LMNO, F-14000 Caen, France.
   [Ariffin, Muhammad Rezal Kamel; Adenan, Nurul Nur Hanisah] Univ Putra Malaysia, Inst Math Res, Serdang 43400, Selangor Darul, Malaysia.
   [Ariffin, Muhammad Rezal Kamel] Univ Putra Malaysia, Fac Sci, Dept Math, Serdang 43400, Selangor Darul, Malaysia.
   [Merenda, Domenica Stefania] Mediterranea Univ Reggio Calabria, DiGiS & Decis Lab, I-89125 Reggio Di Calabria, Italy.
   [Ahmadian, Ali] Natl Univ Malaysia, Inst IR 4 0, Bangi 43600, Malaysia.
   [Ahmadian, Ali] Near East Univ, Dept Math, Mersin 10, Nicosia, Trnc, Turkey.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Caen
   Normandie; Universiti Putra Malaysia; Universiti Putra Malaysia;
   Universita Mediterranea di Reggio Calabria; Universiti Kebangsaan
   Malaysia; Near East University
RP Ariffin, MRK (corresponding author), Univ Putra Malaysia, Inst Math Res, Serdang 43400, Selangor Darul, Malaysia.; Ariffin, MRK (corresponding author), Univ Putra Malaysia, Fac Sci, Dept Math, Serdang 43400, Selangor Darul, Malaysia.
EM rezal@upm.edu.my; ali.ahmadian@ukm.edu.my
RI Ahmadian, Ali/N-3697-2015; Adenan, Hanisah/KVX-8726-2024
OI Ahmadian, Ali/0000-0002-0106-7050; 
FU Mediterranea Universiti of Reggio Calabria (UNIRC) Research Grant
   [UPM/INSPEM/700-3/1/GERAN ANTARABA NGSA/6380071-10065]; Putra Grant
   [GP-IPS/2018/9657300]
FX The research was supported by Mediterranea Universiti of Reggio Calabria
   (UNIRC) Research Grant (UPM/INSPEM/700-3/1/GERAN ANTARABA
   NGSA/6380071-10065). The present research was partially supported by the
   Putra Grant with Project Number GP-IPS/2018/9657300.
CR [Anonymous], 1979, Technical Report
   Ariffin MRK, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010002
   Blinder M, 2017, MALAYS J MATH SCI, V11, P45
   Blömer J, 2004, LECT NOTES COMPUT SC, V2947, P1
   Boneh D, 1999, LECT NOTES COMPUT SC, V1592, P1
   Coppersmith D, 1997, J CRYPTOL, V10, P233, DOI 10.1007/s001459900030
   Coron JS, 2004, LECT NOTES COMPUT SC, V3027, P492
   de Weger B, 2002, APPL ALGEBR ENG COMM, V13, P17, DOI 10.1007/s002000100088
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Galbraith SD, 2012, MATHEMATICS OF PUBLIC KEY CRYPTOGRAPHY, P1, DOI 10.1017/CBO9781139012843
   Herrmann M, 2010, LECT NOTES COMPUT SC, V6056, P53
   Hinek M., 2009, Cryptography and Network Security Series
   Hoffstein J., 2008, An Introduction to Mathematical Cryptography, V1
   Howgrave-Graham N, 1997, LECT NOTES COMPUT SC, V1355, P131, DOI 10.1007/BFb0024458
   Jochemsz E, 2006, LECT NOTES COMPUT SC, V4284, P267
   LENSTRA AK, 1982, MATH ANN, V261, P515, DOI 10.1007/BF01457454
   May A., 2003, Ph.D. diss
   Narasimam, 2012, INT J COMPUT, V49, P39, DOI [10.5120/7880-1190, DOI 10.5120/7880-1190]
   Nitaj A, 2009, LECT NOTES COMPUT SC, V5580, P98, DOI 10.1007/978-3-642-02384-2_7
   QUISQUATER JJ, 1982, ELECTRON LETT, V18, P905, DOI 10.1049/el:19820617
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sun HM, 1999, LECT NOTES COMPUT SC, V1716, P150
   Takagi T, 2004, IEICE T FUND ELECTR, VE87A, P94
   WIENER MJ, 1990, IEEE T INFORM THEORY, V36, P553, DOI 10.1109/18.54902
NR 24
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36607
EP 36622
DI 10.1007/s11042-021-11335-8
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000685156200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, XH
   Zhu, XY
AF Chen, Xiuhong
   Zhu, Xingyu
TI Nonnegative spectral clustering and adaptive graph-based matrix
   regression for unsupervised image feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matrix regression; Nonnegative spectral clustering; Adaptive graph;
   Unsupervised feature selection; Convergence and complexity
ID DIMENSIONALITY REDUCTION; FACE RECOGNITION; FRAMEWORK
AB Matrix regression model can directly take matrix data as input data, and its loss function is defined by left and right regression matrices. The spectral clustering-based matrix regression model can perform feature selection for unsupervised images. However, the graph weight matrix used in the existing spectral clustering models is predefined, which is often inaccurate, especially for noisy images. Moreover, they do not consider the preservation of local structure of image samples in transformation space. To this end, we propose a nonnegative spectral clustering and adaptive graph-based matrix regression model for unsupervised image feature selection. This model can make the prediction label matrix as smooth as possible on the whole graph, and the graph weight matrix can be adaptively learned instead of being predefined as fixed matrix. Thus, the accurate local structure of the sample data is preserved in transformation space and the discriminative information of these pseudo class labels can be revealed. Finally, we devise an efficient optimization algorithm to solve the proposed problem and analyze the computational complexity and convergence of the algorithm. Some experimental results on several datasets also show the effectiveness and superiority of our proposed method.
C1 [Chen, Xiuhong; Zhu, Xingyu] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
   [Chen, Xiuhong] Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Chen, XH (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.; Chen, XH (corresponding author), Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi, Jiangsu, Peoples R China.
EM xiuhongc@jiangnan.edu.cn
RI zhu, xing/KIG-6278-2024; 陈, 秀宏/ABF-7245-2021
OI 陈, 秀宏/0000-0001-7600-1673; Zhu, Xingyu/0009-0001-5533-3414
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 1993, NEURAL NETWORKS PATT
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D., 2010, KDD, P333
   Chen XJ, 2017, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2017.227
   Chen XH, 2020, IET IMAGE PROCESS, V14, P1740, DOI 10.1049/iet-ipr.2019.1404
   Chen XH, 2020, IEEE ACCESS, V8, P62855, DOI 10.1109/ACCESS.2020.2983829
   Cheung YM, 2009, IEEE T KNOWL DATA EN, V21, P1798, DOI 10.1109/TKDE.2009.23
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Du XZ, 2016, SIGNAL PROCESS, V120, P754, DOI 10.1016/j.sigpro.2014.12.027
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Gabriel KR, 1998, BIOMETRIKA, V85, P689, DOI 10.1093/biomet/85.3.689
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hou C., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1324, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-224
   Hou CP, 2017, IEEE T IMAGE PROCESS, V26, P4255, DOI 10.1109/TIP.2017.2713948
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Hou CP, 2014, PATTERN RECOGN, V47, P454, DOI 10.1016/j.patcog.2013.07.002
   Hou CP, 2013, IEEE T IMAGE PROCESS, V22, P340, DOI 10.1109/TIP.2012.2214044
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lai ZH, 2011, NEURAL COMPUT APPL, V20, P565, DOI 10.1007/s00521-011-0577-7
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li XL, 2019, IEEE T NEUR NET LEAR, V30, P1587, DOI 10.1109/TNNLS.2018.2868847
   Li Z., 2012, PROC C ASS ADV ARTIF, P1026, DOI DOI 10.1609/AAAI.V26I1.8289
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Mallah C.D., 2013, COMPUTATIONAL RES, V1, P1
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pereira RB, 2018, ARTIF INTELL REV, V49, P57, DOI 10.1007/s10462-016-9516-4
   Qian JJ, 2015, PATTERN RECOGN, V48, P3145, DOI 10.1016/j.patcog.2015.04.017
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shen JB, 2019, IEEE T NEUR NET LEAR, V30, P2637, DOI 10.1109/TNNLS.2018.2885591
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang LP, 2008, IEEE T NEURAL NETWOR, V19, P1267, DOI 10.1109/TNN.2008.2000395
   Wang SJ, 2014, IEEE T IMAGE PROCESS, V23, P920, DOI 10.1109/TIP.2013.2297020
   Weston J, 2001, ADV NEUR IN, V13, P668
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P924, DOI 10.1109/TPAMI.2020.3013379
   Ye M, 2020, PROC CVPR IEEE, P5456, DOI 10.1109/CVPR42600.2020.00550
   Yuan HL, 2019, PATTERN RECOGN, V89, P119, DOI 10.1016/j.patcog.2019.01.014
   Zhao Z, 2010, TR10007 ARIZONA STAT
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu RF, 2019, NEURAL NETWORKS, V111, P35, DOI 10.1016/j.neunet.2018.12.008
NR 53
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32885
EP 32904
DI 10.1007/s11042-021-11191-6
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000683216100001
DA 2024-07-18
ER

PT J
AU Sobiecki, A
   van Dijk, J
   Folkertsma, H
   Telea, A
AF Sobiecki, Andre
   van Dijk, Julius
   Folkertsma, Hidde
   Telea, Alexandru
TI Does face restoration improve face verification?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face verification; Face restoration; Face recognition; Image processing;
   Machine learning; Pattern recognition
ID REPRESENTATION; EIGENFACES
AB Methods for face verification works reasonably well on face images with standardized (frontal) face positions and good spatial resolution. However such methods have significant challenges on poor resolution images, poor lighting conditions and not standard (frontal) face positions. In this paper, we survey the capability of existing face restoration and verification methods, with the aim of understanding how useful face restoration methods are for face verification. We propose a qualitative and quantitative comparison benchmark, and apply it on eight methods for face restoration and six methods for face verification, on several real-world low-quality images from a surveillance context, and outline observed advantages and limitations. Experiments shows that each restoration method can affect each face verification method differently, with fewer than the half of face restoration methods helping face verification. Interestingly, some face restoration methods with less good qualitative evaluation helped face verification the most. Experiments also show that face verification works less good if the resolution decreases.
C1 [van Dijk, Julius; Folkertsma, Hidde; Telea, Alexandru] Univ Groningen, Groningen, Netherlands.
   [Telea, Alexandru] Univ Utrecht, Utrecht, Netherlands.
C3 University of Groningen; Utrecht University
EM sobieckiandre@gmail.com
RI Sobiecki, André/A-2859-2015
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Campisi P, 2001, BLIND IMAGE DECONVOL
   CAREY S, 1977, SCIENCE, V195, P312, DOI 10.1126/science.831281
   Champandard A J, 2016, NEURAL ENHANCE SUPER
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Han D, 2015, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR.2015.7299136
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Jia Z, 2015, MULTIMED TOOLS APPL, V74, P1845, DOI 10.1007/s11042-013-1721-4
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Matsushita Y, 2014, IEEE IMAGE PROC, P4562, DOI 10.1109/ICIP.2014.7025925
   Ning X, 2020, CONCURR COMP-PRACT E, P1
   Ning X, 2018, IEEE T IMAGE PROCESS, V27, P2575, DOI 10.1109/TIP.2018.2806229
   Praveenbalaji D, 2020, INT CONF ADVAN COMPU, P1449, DOI [10.1109/icaccs48705.2020.9074246, 10.1109/ICACCS48705.2020.9074246]
   Redmon J., 2018, P IEEE C COMP VIS PA
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sensalire M, 2008, P ACM SOFTVIS
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sobiecki A, 2010, 4 EUR C COMP MECH PA
   Sobiecki A, 2011, 7 WORKSH VIS COMP CU
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Van S, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P101, DOI 10.5220/0006552401010112
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang L, 2006, IEEE T PAMI, P905
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yuzhikov V, 2015, SMARTDEBLUR DECONVOL
   Zhang C, 2010, C ELECT INSUL DIEL P
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 44
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32863
EP 32883
DI 10.1007/s11042-021-11167-6
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000683255500001
OA Green Published
DA 2024-07-18
ER

PT J
AU Ervural, S
   Ceylan, M
AF Ervural, Saim
   Ceylan, Murat
TI Classification of neonatal diseases with limited thermal Image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Infrared thermography (IRT);
   Neonatal diseases; Classification; Data augmentation
ID LOW-BIRTH-WEIGHT; INFRARED THERMOGRAPHY; THERMOREGULATION; TEMPERATURE;
   INFANTS; EXPERIENCE; NEWBORNS; SYSTEM; NEC; CT
AB Evaluation of body temperature and thermal symmetry in neonates is important in monitoring health conditions and predicting potential risks. With thermography, which is a harmless and noncontact method, diseases in neonates can be detected at an early stage using appropriate artificial intelligence techniques. Medical imaging is limited due to neonates' sensitivity to the thermal environment. This study proposes a classification model for classification problems with limited data (specifically, neonatal diseases) using data augmentation and artificial intelligence methodology. In the study, a multi-class classification was performed by combining images produced by data augmentation and employing the ability of convolutional neural networks to learn important features from the images, with 4 classes ranging from 8 to 16 newborns in each class. That is, there are four classes: 34 neonatal with abdominal, cardiovascular, and pulmonary abnormalities and 10 neonatal undiagnosed (premature). The dataset was created by taking 20 images from each of the 44 neonates. To test the performance of the proposed method, six different data separation experiments were conducted. Although the best classification accuracy is 94%, the 89% value obtained in the experiment when the model was tested with image samples of babies that had not been used in training the model is more significant for the model.
C1 [Ervural, Saim] KTO Karatay Univ, Elect Elect Engn Dept, Akabe Mh Alaaddin Kap Cd 130, Konya, Turkey.
   [Ceylan, Murat] Konya Tech Univ, Elect Elect Engn Dept, Alaaddin Keykubat Yerleskesi, Konya, Turkey.
C3 KTO Karatay University; Konya Technical University
RP Ervural, S (corresponding author), KTO Karatay Univ, Elect Elect Engn Dept, Akabe Mh Alaaddin Kap Cd 130, Konya, Turkey.
EM saim.ervural@karatay.edu.tr; mceylan@ktun.edu.tr
OI ervural, saim/0000-0003-4104-1928
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [215E019]
FX This study was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK, project number: 215E019).
CR Abbas AK, 2012, INFRARED PHYS TECHN, V55, P538, DOI 10.1016/j.infrared.2012.07.001
   Abbas AK., 2008, COLOR IMAGE PROCESSI
   Alan B, 2010, ANATOL J CARDIOL, V10, P9, DOI 10.5152/akd.2010.114
   Amalu W., 2006, Medical Devices and Systems, V3rd
   [Anonymous], 2011, NEWBORN DEATH ILLNES
   [Anonymous], 2020, INFARED THERMOGRAPHY
   APGAR V, 1953, Curr Res Anesth Analg, V32, P260
   Apiliogullari B, 2011, J INT MED RES, V39, P2436, DOI 10.1177/147323001103900645
   Arora N, 2008, AM J SURG, V196, P523, DOI 10.1016/j.amjsurg.2008.06.015
   Bach V, 2019, SLEEP MED, V60, P26, DOI 10.1016/j.sleep.2018.12.026
   Bagavathiappan S., 2008, The British Journal of Diabetes Vascular Disease, V8, P102, DOI DOI 10.1177/14746514080080020901
   Bahadue FL, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001456.pub2
   BARNES R. BOWLING, 1963, SCIENCE, V140, P870, DOI 10.1126/science.140.3569.870
   Bouzida N, 2009, J THERM BIOL, V34, P120, DOI 10.1016/j.jtherbio.2008.11.008
   CAMPBELL M, 1970, BRIT HEART J, V32, P633
   Caplan MS, 2001, PEDIATR RES, V49, P647, DOI 10.1203/00006450-200105000-00007
   Cherkas LF, 2003, J RHEUMATOL, V30, P720
   Christidis Iris, 2003, Gynaekologisch-Geburtshilfliche Rundschau, V43, P31, DOI 10.1159/000067168
   CLARK RP, 1980, J PHYSIOL-LONDON, V302, P323
   COSH J A, 1970, Rheumatology and Physical Medicine, V10, P342, DOI 10.1093/rheumatology/10.7.342
   Dalla Vecchia LK, 1998, ARCH SURG-CHICAGO, V133, P490, DOI 10.1001/archsurg.133.5.490
   Deng ZS, 2005, P ANN INT IEEE EMBS, P7525
   Frize M., 2013, WORLD C MED PHYS BIO, P1309
   Heimann K, 2013, J PERINAT MED, V41, P613, DOI 10.1515/jpm-2012-0239
   Herry CL, 2012, IFMBE PROC, V37, P191
   Hug L, 2019, LANCET GLOB HEALTH, V7, pE710, DOI 10.1016/S2214-109X(19)30163-9
   Jones BF, 1998, IEEE T MED IMAGING, V17, P1019, DOI 10.1109/42.746635
   Knobel RB, 2011, BIOL RES NURS, V13, P274, DOI 10.1177/1099800411403467
   Knobel-Dail RB, 2017, J THERM BIOL, V69, P118, DOI 10.1016/j.jtherbio.2017.06.005
   Konak M, 2019, CUKUROVA MED J, V44, P425, DOI 10.17826/cumj.458835
   Kontos M, 2011, CLIN RADIOL, V66, P536, DOI 10.1016/j.crad.2011.01.009
   Kurath-Koller S, 2015, EVID-BASED COMPL ALT, V2015, DOI 10.1155/2015/571857
   Lahiri BB, 2012, INFRARED PHYS TECHN, V55, P191, DOI 10.1016/j.infrared.2012.01.001
   Liu J, 2014, MEDICINE, V93, DOI 10.1097/MD.0000000000000197
   Maldague XPV, 2001, WILEY MICRO, pXV
   Modest M.F., 2021, Radiative Heat Transfer, Vsecond
   Mosalli R, 2009, ANN PEDIAT CARDIOL, V2, P120, DOI 10.4103/0974-2069.58313
   Ng WK, 2009, J REPROD MED, V54, P698
   Nur R, 2014, THESIS CARLETON U
   Offit PA, 2002, PEDIATRICS, V109, P124, DOI 10.1542/peds.109.1.124
   Ornek AH, 2018, URSI TURK 9 SCI C KO
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103044
   Oya A, 1997, J PERINAT MED, V25, P447, DOI 10.1515/jpme.1997.25.5.447
   POMERANCE JJ, 1977, PEDIATRICS, V59, P345
   RASOR JS, 1993, EUR UROL, V24, P411
   Rice HE., 2010, J SURG RES, V1, P61
   Rondó PHC, 2003, EUR J CLIN NUTR, V57, P266, DOI 10.1038/sj.ejcn.1601526
   Savasci D., 2019, CLASSIFICATION TECHN, P1, DOI DOI 10.1016/B978-0-12-818004-4.00001-7
   Savasci D, 2018, SIG PROCESS COMMUN
   Saxena AK, 2008, EUR J PEDIATR, V167, P757, DOI 10.1007/s00431-007-0583-z
   Sherman RA, 1996, J REHABIL RES DEV, V33, P377
   Shevelev IA, 1998, PROG NEUROBIOL, V56, P269, DOI 10.1016/S0301-0082(98)00038-0
   Taylor AM, 2008, PEDIATR RADIOL, V38, pS433, DOI 10.1007/s00247-008-0843-8
   Tchervenkov CI, 2006, CARDIOL YOUNG, V16, P339, DOI 10.1017/S1047951106000291
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   THOMPSON JE, 1978, IEEE T MICROW THEORY, V26, P573, DOI 10.1109/TMTT.1978.1129441
   Topalidou A, 2019, BMC PREGNANCY CHILDB, V19, DOI 10.1186/s12884-019-2533-y
   van Lennep M, 2019, NAT REV DIS PRIMERS, V5, DOI 10.1038/s41572-019-0077-0
   Vyas HV, 2012, RADIOGRAPHICS, V32, P87, DOI 10.1148/rg.321105764
   WILL RK, 1992, BRIT J RHEUMATOL, V31, P337
NR 60
TC 4
Z9 4
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9247
EP 9275
DI 10.1007/s11042-021-11391-0
EA AUG 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000682496300001
DA 2024-07-18
ER

PT J
AU Li, C
   Huang, Q
   Li, X
   Wu, QH
AF Li, Chang
   Huang, Qian
   Li, Xing
   Wu, Qianhan
TI Human action recognition based on multi-scale feature maps from depth
   video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Laplacian pyramid; Multi-scale motion
   representation; Extreme learning machine
ID MOTION; SCALE; CLASSIFICATION; INFORMATION; TEXTURE
AB Human action recognition is an active research area in computer vision. Although great progress has been made, previous methods mostly recognize actions from depth video sequences at only one scale, and thus they often neglect multi-scale spatial changes that provide additional information in practical applications. In this paper, we present a novel framework with a multi-scale mechanism to improve scale diversity of motion features. We propose a multi-scale feature map called Laplacian pyramid depth motion images(LP-DMI). First, We employ depth motion images (DMI) as the templates to generate the multi-scale static representation of actions. Then, we caculate LP-DMI to enhance multi-scale dynamic information of motions and reduce redundant static information in human bodies. We further extract the multi-granularity descriptor called LP-DMI-HOG to provide more discriminative features. Finally, we utilize extreme learning machine (ELM) for action classification. The proposed method yeilds the recognition accuracy of 93.41%, 85.12%, 91.94% on the public MSRAction3D, UTD-MHAD and DHA dataset. Through extensive experiments, we prove that our method outperforms the state-of-the-art benchmarks.
C1 [Li, Chang; Huang, Qian; Li, Xing; Wu, Qianhan] Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
C3 Hohai University
RP Huang, Q (corresponding author), Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
EM lichang@hhu.edu.en; huangqian@hhu.edu.cn; lixing@hhu.edu.cn;
   wuqianhan@hhu.edu.cn
RI Li, Chang/IAP-6667-2023; Huang, Qian/GPX-9488-2022; li,
   xing/GYA-4502-2022; Huang, Qian/GPX-9181-2022
OI Li, Chang/0000-0002-1705-0149; Huang, Qian/0000-0001-5625-0402
FU National Key Research and Development Program of China [2018YFC0407905];
   fundamental research funds of China for central universities
   [B200202188]
FX This work is partly supported by the National Key Research and
   Development Program of China under grant no. 2018YFC0407905, and the
   fundamental research funds of China for central universities under grant
   no. B200202188.
CR Ahmad Z, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER COMMUNICATIONS (ITCC 2019), P1, DOI 10.1145/3355402.3355419
   Alpatov AV, 2018, MEDD C EMBED COMPUT, P579
   Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulbul MF, 2019, MULTIMED TOOLS APPL, V78, P21085, DOI 10.1007/s11042-019-7365-2
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen C, 2015, LECT NOTES COMPUT SC, V9474, P613, DOI 10.1007/978-3-319-27857-5_55
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Tran DT, 2020, APPL INTELL, V50, P1468, DOI 10.1007/s10489-019-01572-8
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Gu Y, 2018, 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P395, DOI 10.1109/WCICA.2018.8630370
   HOU CX, 2020, SENSORS-BASEL, V20, DOI DOI 10.3390/S20185180
   Hou YH, 2018, IEEE ACCESS, V6, P2206, DOI 10.1109/ACCESS.2017.2782258
   Huang GB, 2004, IEEE IJCNN, P985
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kim HG, 2019, IEEE T CONSUM ELECTR, V65, P349, DOI 10.1109/TCE.2019.2924177
   Li ST, 2018, IEEE J-STARS, V11, P3312, DOI 10.1109/JSTARS.2018.2856741
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li X, 2020, MULTIMED TOOLS APPL, V79, P35761, DOI 10.1007/s11042-020-09593-z
   Li ZF, 2019, MULTIMED TOOLS APPL, V78, P19587, DOI 10.1007/s11042-019-7356-3
   Min YC, 2020, PROC CVPR IEEE, P5760, DOI 10.1109/CVPR42600.2020.00580
   Nguyen XS, 2018, MULTIMED TOOLS APPL, V77, P21617, DOI 10.1007/s11042-017-5593-x
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   PADILLALOPEZ JR, 2014, ARXIV14077390
   Peng W, 2021, IEEE SIGNAL PROC LET, V28, P244, DOI 10.1109/LSP.2021.3049691
   Rahmani H, 2016, PATTERN RECOGN LETT, V72, P62, DOI 10.1016/j.patrec.2015.07.015
   Sujee R, 2018, INT CONF COMP COMMUN
   Sun B, 2019, MULTIMED TOOLS APPL, V78, P6329, DOI 10.1007/s11042-018-6370-1
   Tan ZG, 2020, IEEE T IND INFORM, V16, P1591, DOI 10.1109/TII.2019.2929055
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Trelinski J, 2019, LECT NOTES ARTIF INT, V11509, P91, DOI 10.1007/978-3-030-20915-5_9
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Vishwakarma D., 2017, Int. J. Comput. Vis. Robot., V7, P454, DOI 10.1504/IJCVR.2017.084991
   Vishwakarma DK, 2015, ADV ROBOTICS, V29, DOI 10.1080/01691864.2015.1061701
   Vishwakarma DK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P336
   Vishwakarma D. K., 2012, 4 INT C INTELLIGENT, P1, DOI DOI 10.1109/IHCI.2012.6481804
   Wan MH, 2019, SOFT COMPUT, V23, P5511, DOI 10.1007/s00500-018-3207-9
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Wiliem A., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P270, DOI 10.1109/DICTA.2010.55
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Yang R, 2014, ASIAN C COMPUTER VIS, P37
   Yang TJ, 2020, IEEE ACCESS, V8, P135118, DOI 10.1109/ACCESS.2020.3006067
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2017, IEEE T PATTERN ANAL, V39, P1028, DOI 10.1109/TPAMI.2016.2565479
   Yang Z, 2017, MULTIMED TOOLS APPL
   Yanwen Teng, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P2205, DOI 10.1109/GreenCom-iThings-CPSCom.2013.416
   Yao GL, 2019, APPL INTELL, V49, P2017, DOI 10.1007/s10489-018-1347-3
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
NR 63
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32111
EP 32130
DI 10.1007/s11042-021-11193-4
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000677229000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liang, W
   Xu, PF
   Guo, L
   Bai, H
   Zhou, Y
   Chen, F
AF Liang, Wei
   Xu, Pengfei
   Guo, Ling
   Bai, Heng
   Zhou, Yang
   Chen, Feng
TI A survey of 3D object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; 3D object detection; Deep learning; Autonomous driving
   technology; Point cloud
ID NETWORKS; SIFT
AB Due to the rapid development of science and technology, object detection has become a promising research direction in computer vision. In recent years, most object detection frameworks proposed in the existing research are 2D. However, 2D object detection cannot take three-dimensional space into account, resulting in its inability to be used to solve problems in real world. Hence, we conduct this 3D object detection survey in the hope that 3D object detection methods can be better applied to the contexts of intelligent video surveillance, robot navigation and autonomous driving technology. There exist various 3D object detection methods while in this paper we only focus on the popular deep learning based methods. We divide these approaches into four categories according to the input data category. Besides, we discuss the innovations of these frames and compare their experimental results in terms of accuracy. Finally, we indicate the technical difficulties associated with current 3D object detection and discuss future research directions.
C1 [Liang, Wei; Xu, Pengfei; Guo, Ling; Bai, Heng; Zhou, Yang; Chen, Feng] Northwest Univ, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Guo, L (corresponding author), Northwest Univ, Xian 710127, Shaanxi, Peoples R China.
EM 1223861831@qq.com; pfxu@nwu.edu.cn; lingo@nwu.edu.cn
FU National Natural Science Foundation of China [61973250, 61802306,
   61973249, 61702415, 61902318, 61876145]; Scientific research plan for
   servicing local area of Shaanxi province education department [19JC038,
   19JC041]; Key Research and Development Program of Shaanxi [.2019GY-012,
   2021GY-077]
FX This research was supported in part by the National Natural Science
   Foundation of China under grant agreements Nos. 61973250, 61802306,
   61973249, 61702415, 61902318, 61876145. Scientific research plan for
   servicing local area of Shaanxi province education department: 19JC038,
   19JC041. Key Research and Development Program of Shaanxi
   (Nos.2019GY-012, 2021GY-077).
CR Ahmed, 2020, C COMP VIS PATT REC
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Bay H, 2006, SURF SPEEDED ROBUST
   Beltrán J, 2018, IEEE INT C INTELL TR, P3517, DOI 10.1109/ITSC.2018.8569311
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A., 2012, CVPR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jrgensen E., 2019, MONOCULAR 3D OBJECT
   Ke Y, 2004, PROC CVPR IEEE, P506
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   LLC W, 2019, WAYM OP DAT AUT DRIV
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Ming Liang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11550, DOI 10.1109/CVPR42600.2020.01157
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Ng M, 2020, 2020 IEEE CVF C COMP
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qian R, 2020, 2020 IEEE CVF C COMP
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shafiee MohammadJavad., 2017, Fast YOLO: A fast you only look once system for real-time embedded object detection in video
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sindagi VA, 2019, IEEE INT CONF ROBOT, P7276, DOI [10.1109/ICRA.2019.8794195, 10.1109/icra.2019.8794195]
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Sun J, 2020, DISP R CNN STEREO 3D
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang J., 2019, IEEE ACCESS, VPP, P1, DOI [10.1109/ACCESS.2019.2900225, DOI 10.1109/ACCESS.2019.2900225]
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y., 2018, PSEUDO LIDAR VISUAL
   Wang Y., 2020, 2020 IEEE CVF C COMP
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhou J., 2019, IEEE WCNC, P1, DOI [DOI 10.1109/wcnc.2019.8885523, DOI 10.1109/CISP-BMEI48845.2019.8965844]
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 65
TC 14
Z9 14
U1 6
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29617
EP 29641
DI 10.1007/s11042-021-11137-y
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000669309500002
DA 2024-07-18
ER

PT J
AU Zhang, JX
   Zeng, XQ
AF Zhang, Juxiao
   Zeng, Xiaoqin
TI Multi-touch gesture recognition of Braille input based on Petri Net and
   RBF Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Input method of Braille; Petri Net; RBF Net; Multiple touch gesture
   recognition
ID TEXT ENTRY METHOD; PERFORMANCE
AB The development of information accessibility is receiving more and more attention. One challenging task for the blind is to input Braille while by no way could they sense the location information on touch screens. The existing Braille input methods are suffering from problems including inaccurate positioning and lack of interactive prompts. In this paper, touch gestures are recognized by trained RBF network while combined gestures are modeled by Petri net that introduces logic, timing and spatial relationship description. By doing so, the Braille input concerning multi-touch gesture recognition is then implemented. The experimental results show that the method is effective and blind people can friendly Braille Input with almost real-time interaction. The input method makes full use of the inherent logic of Braille, making the blind easy to learn and remember, providing a new method for human-computer interaction between the blind and the touch screen.
C1 [Zhang, Juxiao; Zeng, Xiaoqin] Hohai Univ, Coll Comp & Informat, Nanjing 210038, Jiangsu, Peoples R China.
   [Zhang, Juxiao] Nanjing Normal Univ Special Educ, Coll Informat, Math Sci, Nanjing 210038, Jiangsu, Peoples R China.
C3 Hohai University; Nanjing Normal University of Special Education
RP Zhang, JX (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 210038, Jiangsu, Peoples R China.; Zhang, JX (corresponding author), Nanjing Normal Univ Special Educ, Coll Informat, Math Sci, Nanjing 210038, Jiangsu, Peoples R China.
EM 3301611@qq.com
RI zhang, juxiao/GZA-9107-2022
OI zhang, juxiao/0000-0002-4274-6359
FU Major Programs of Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China [19KJA310002]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [17KJD520006]; Programs of Sign Language & Braille of China Disabled
   Persons' Federation [CLM2020-01]
FX This work was supported by The Major Programs of Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China (No.
   19KJA310002) , The Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China (No. 17KJD520006) and The Programs of
   Sign Language & Braille of China Disabled Persons' Federation (No.
   CLM2020-01).
CR Alnfiai M, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P161, DOI 10.1145/2982142.2982161
   Alnfiai M, 2017, PROCEDIA COMPUT SCI, V109, P257, DOI 10.1016/j.procs.2017.05.349
   Frey B, 2011, LECT NOTES COMPUT SC, V6767, P19, DOI 10.1007/978-3-642-21666-4_3
   Fuccella V, 2014, IEEE T HUM-MACH SYST, V44, P511, DOI 10.1109/THMS.2014.2314447
   Fukatsu Yoshitomo, 2013, P 15 INT C HUM COMP, P161
   Hu, 2014, BeiJing, Patent No. [103870008A, 103870008]
   Izonin I, 2019, 2019 IEEE 2ND UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON-2019), P1037, DOI 10.1109/UKRCON.2019.8879905
   Jalaliniya S., 2015, ADJ P 2015 ACM INT J, P873, DOI DOI 10.1145/2800835.2804336
   Jim HY, 2011, THESIS EAST CHINA NO
   Kumar V., 2013, 2012 4 INT C INT C I, P1
   Laisheng Z., 2019, MODERN ELECT TECHNIQ, P93
   Li QC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SYSTEM AND SOFTWARE RELIABILITY (ISSSR), P68, DOI [10.1109/ISSSR.2016.020, 10.1109/ISSSR.2016.14]
   Li Wen-sheng, 2011, Chinese Journal of Liquid Crystals and Displays, V26, P194, DOI 10.3788/YJYXS20112602.0194
   Liu Feng, 2011, Computer Engineering, V37, P225, DOI 10.3969/j.issn.1000-3428.2011.07.076
   Mascetti S, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P295
   Mattheiss E, 2015, J ASSIST TECHNOL, V9, P147, DOI 10.1108/JAT-10-2014-0028
   Nicolau Hugo, 2010, P 28 ANN EUROPEAN C, P19
   Oliveira J, 2011, LECT NOTES COMPUT SC, V6946, P100, DOI 10.1007/978-3-642-23774-4_10
   Park IC., 2019, IEEE T CIRCUITS-I, P1
   Rzecki K, 2019, LECT NOTES ARTIF INT, V11508, P608, DOI 10.1007/978-3-030-20912-4_55
   Shin H, 2015, I SYMP CONSUM ELECTR, P120, DOI 10.1109/ICCE.2015.7066345
   Siqueira J, 2016, P INT COMP SOFTW APP, P608, DOI 10.1109/COMPSAC.2016.5
   Tkachenko Roman, 2019, Mobile Web and Intelligent Information Systems. 16th International Conference (MobiWIS 2019). Proceedings: Lecture Notes in Computer Science (LNCS 11673), P267, DOI 10.1007/978-3-030-27192-3_21
   Vatavu RD, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4667, DOI 10.1145/3025453.3025941
   Wang, 2013, A Braille input method based on gesture recognition: JiangSu, Patent No. [102929394A, 102929394]
   Wang, 2012, COMPUT SCI, V39, P522
   [王德鑫 Wang Dexin], 2010, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V23, P408
   Yan Xiliang, 2017, Computer Engineering and Applications, V53, P246, DOI 10.3778/j.issn.1002-8331.1512-0030
   Yu TZH., 2013, DESIGN IMPLEMENTATIO
   Yu YJ, 2020, ADV INTELL SYST, V928, P462, DOI 10.1007/978-3-030-15235-2_68
   [张居晓 Zhang Juxiao], 2015, [计算机应用与软件, Computer Applications and Software], V32, P231
NR 31
TC 2
Z9 2
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19395
EP 19413
DI 10.1007/s11042-021-11156-9
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000669172500002
DA 2024-07-18
ER

PT J
AU Florindo, JB
AF Florindo, Joao B.
TI Reorganizing local image features with chaotic maps: an application to
   texture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Texture recognition; Image descriptors; Local binary
   patterns
ID CLASSIFICATION; SCALE
AB Texture images are those where the focus of the analysis is on the spatial arrangement of pixels (primitives or textons) rather than on particular objects in the scene. The recognition of such images is naturally challenging as those primitives can be perceived in different manners depending on the image context. Despite the recent success of convolutional neural networks in texture recognition, model-based descriptors are still competitive, especially when we do not have access to large amounts of annotated data for training and the interpretation of the model is an important issue. Among the model-based approaches, fractal geometry has been one of the most popular, especially in biological applications. Nevertheless, fractals are part of a much broader family of models, which are the non-linear operators, studied in chaos theory. This scenario raises the question whether techniques from the broader area of chaos theory could be useful in texture modeling. Those techniques have been used for a long time in image cryptography, but studies on modeling in a broad sense have been scarce in the literature. In this context, we propose here a chaos-based local descriptor for texture recognition. More specifically, we map the image into the three-dimensional Euclidean space, iterate a chaotic map over this three-dimensional structure and convert it back to the original image. From such chaos-transformed image at each iteration we collect local descriptors (here we use local binary patters) and those descriptors compose the feature representation of the texture. The performance of our method was verified on the classification of benchmark databases and in the identification of Brazilian plant species based on the texture of the leaf surface. The achieved results confirmed our expectation of a competitive performance, even when compared with some learning-based modern approaches in the literature.
C1 [Florindo, Joao B.] Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Florindo, JB (corresponding author), Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
EM jbflorindo@ime.unicamp.br
RI Florindo, Joao/S-5823-2019
OI Florindo, Joao/0000-0002-0071-0227
FU National Council for Scientific and Technological Development, Brazil
   (CNPq) [301480/2016-8, 423292/2018-8];  [Serra-1812-26426]
FX This work was supported by the Serrapilheira Institute (grant number
   Serra-1812-26426). J. B. Florindo also gratefully acknowledges the
   financial support from National Council for Scientific and Technological
   Development, Brazil (CNPq) (Grants #301480/2016-8 and #423292/2018-8).
CR Al-Shemarry MS, 2020, IEEE T INTELL TRANSP, V21, P553, DOI 10.1109/TITS.2019.2897990
   [Anonymous], 1987, Chaos: Making a New Science
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Casanova D, 2009, INT J IMAG SYST TECH, V19, P236, DOI 10.1002/ima.20201
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chandramouli K, 2006, IEEE IMAGE PROC, P3001, DOI 10.1109/ICIP.2006.312968
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   da Silva NR, 2015, NEUROCOMPUTING, V149, P1560, DOI 10.1016/j.neucom.2014.08.036
   Dai XY, 2017, PROC CVPR IEEE, P6100, DOI 10.1109/CVPR.2017.646
   Donahue J, 2014, PR MACH LEARN RES, V32
   Florindo JB, 2018, INFORM SCIENCES, V459, P36, DOI 10.1016/j.ins.2018.05.037
   Florindo JB, 2017, INFORM SCIENCES, V415, P142, DOI 10.1016/j.ins.2017.06.022
   Florindo JB, 2011, CHAOS, V21, DOI 10.1063/1.3650233
   Gonçalves WN, 2016, INFORM SCIENCES, V364, P51, DOI 10.1016/j.ins.2016.04.052
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo YQ, 2010, MATH COMPUT MODEL, V51, P1408, DOI 10.1016/j.mcm.2009.10.023
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kannala J, 2012, INT C PATT RECOG, P1363
   Ke Q, 2014, NEUROCOMPUTING, V125, P184, DOI 10.1016/j.neucom.2012.10.039
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leguizamón S, 2010, COMM COM INF SC, V112, P522
   Liu L, 2011, LECT NOTES COMPUT SC, V6492, P383, DOI 10.1007/978-3-642-19315-6_30
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maritz MF, 2020, CHAOS, V30, DOI 10.1063/1.5125097
   MCLACHLAN G., 2004, WILEY SER PROB STAT
   Nathan D, 2020, COMPUT GEOSCI-UK, V136, DOI 10.1016/j.cageo.2019.104396
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Quan YH, 2014, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2014.28
   Song TC, 2018, IEEE T CIRC SYST VID, V28, P1565, DOI 10.1109/TCSVT.2017.2671899
   Song Y, 2017, IEEE I CONF COMP VIS, P4922, DOI 10.1109/ICCV.2017.526
   Taraschi G, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123651
   Timofte R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.93
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xu Y, 2009, PROC CVPR IEEE, P573, DOI 10.1109/CVPRW.2009.5206741
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Xue J, 2018, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2018.00065
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
   Yu WB, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS, ELECTRONICS AND CONTROL (ICCSEC), P1108, DOI 10.1109/ICCSEC.2017.8446823
   Yu Wanbo, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P2264
   Zhai W, 2019, IEEE I CONF COMP VIS, P3612, DOI 10.1109/ICCV.2019.00371
   Zhang H, 2017, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR.2017.309
   Zhao L, 2001, IEEE T NEURAL NETWOR, V12, P1375, DOI 10.1109/72.963774
NR 57
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29177
EP 29197
DI 10.1007/s11042-021-10959-0
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664414400002
DA 2024-07-18
ER

PT J
AU Khan, N
   Akram, MU
   Shah, A
   Alghamdi, NS
   Khan, SA
AF Khan, Nusratullah
   Akram, Muhammad Usman
   Shah, Asadullah
   Alghamdi, Norah Saleh
   Khan, Shoab Ahmed
TI Capturing the real customer experience based on the parameters in the
   call detail records
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Call Detail Records (CDRs); Customer experience Management Index (CEMI);
   Mobile switching Centre (MSC)
AB Customer Experience-Management (CEM) has emerged as a key differentiator in recent fierce market of telecommunication. A positive customer experience leads to increased loyalty, lower churn rate, more recommendations and optimistic word of mouth. In this era of technology, digital data has become an asset of any business. This paper proposes a technique that calculates the Customer Experience Management Index (CEMI) of subscribers of cellular network services providers by using their Call Detail Records (CDRs). In the first phase, CDR Dataset of subscribers, using the same cellular network operators, is collected. In the second phase, a close-ended telephonic survey is prepared and conducted on these subscribers of targeted valued community or social network. Six attributes of telecommunication service are selected i.e. network coverage, voice call quality, drop call rate, Short Message Service delivery, internet service and call setup duration. The subscribers are requested to grade each attribute as per their experience while using that service and to rate the service collectively in order to identify the overall experience. Genetic Algorithm (GA) is applied to optimize the weights for each attribute to eventually formulate a mathematical model for CEMI calculation. The proposed technique uses the difference between weighted attributes based on calculated CEMI and actual CEMI provided during survey process as cost function for GA which updates weights in such a way to have minimal value of this cost function. Same attributes are selected from CDRs and they are graded on the same scale which is used in survey based on the events and flags presented in the CDRs. While concluding the results, the obtained optimized weights are applied to the technical attributes of the CDRs data set and the CEMI is calculated. The proposed technique calculates the CEMI in real-time with an accuracy of 84.5 % and error of 0.248.
C1 [Khan, Nusratullah] Yanbu Univ Coll, Dept Comp Sci, Yanbu, Saudi Arabia.
   [Akram, Muhammad Usman; Khan, Shoab Ahmed] Natl Univ Sci & Technol, Islamabad, Pakistan.
   [Shah, Asadullah] Int Islamic Univ Malaysia, Gombak, Malaysia.
   [Alghamdi, Norah Saleh] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Riyadh 11671, Saudi Arabia.
C3 National University of Sciences & Technology - Pakistan; International
   Islamic University Malaysia; Princess Nourah bint Abdulrahman University
RP Alghamdi, NS (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Riyadh 11671, Saudi Arabia.
EM nosalghamdi@pnu.edu.sa
RI Alghamdi, Norah/AEB-0746-2022
OI Alghamdi, Norah/0000-0001-6421-6001; Shah, Asadullah/0000-0002-9149-328X
FU Deanship of Scientific Research at Princess Nourah bint Abdulrahman
   University through the Fast-track Research Funding Program
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through the Fast-track
   Research Funding Program.
CR [Anonymous], 2013, ETSI TS 148 008 V11
   [Anonymous], 2015, SASSTAT 14 1 USERS G
   Berry Leonard L., 2007, Quality Progress, V40, P26
   Bhutto R., 2007, J INDEP STUD RES, V5, P19, DOI [10.31384/jisrmsse/2007.05.1.1, DOI 10.31384/JISRMSSE/2007.05.1.1]
   Carbone LP., 1994, MARK MANAG, V3, P8
   Day R.L., 1977, Toward a theory of consumer complaining behavior in consumer and industrial buying behavior
   ETSI, 1996, Digital Cellular Telecommunications System (Phase 2+); Channel Coding
   ETSI T, 2015, DIG CELL TEL MULT M
   Fox B, 2013, TELECOMS FUTURE IS S
   Gentile Chiara, 2007, European Management Journal, V25, P395, DOI 10.1016/j.emj.2007.08.005
   Jony, 2013, THESIS AALTO U
   Khansari N., 2017, 2017 4 IEEE INT C EN, P1
   Kim MK, 2004, TELECOMMUN POLICY, V28, P145, DOI 10.1016/j.telpol.2003.12.003
   Malviya R., 2012, A value based approach to improve Customer Experience
   Manning H, 2016, CUSTOMER EXPERIENCE
   Meyer C., 2007, Understanding customer experience
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pezeshki V, 2009, MEAS BUS EXCELL, V13, P82, DOI 10.1108/13683040910943072
   Reber E.E., 1988, Technical Report TR-0200 (4230-46)-3
   Richardson A., 2010, Harvard Business Review, V15, P2
   Shaw C., 2005, BUILDING GREAT CUSTO
   Shrivastava P., 2016, INT J ENG COMPUT SCI, V5, P15677, DOI [10.18535/ijecs/v5i2.5, DOI 10.18535/IJECS/V5I2.5]
   Smith S, 2013, INT J MARKET RES, V55, P357, DOI 10.2501/IJMR-2013-034
   Subramanian P., 2016, INT J CONCEPT COMPUT, V4, P1
NR 25
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28439
EP 28461
DI 10.1007/s11042-021-10897-x
EA JUN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658077800003
DA 2024-07-18
ER

PT J
AU Kaur, A
   Puri, V
   Verma, K
   Bhondekar, AP
   Shashvat, K
AF Kaur, Arshpreet
   Puri, Vinod
   Verma, Karan
   Bhondekar, Amol P.
   Shashvat, Kumar
TI Identification of inter-ictal activity in novel data by bagged
   prediction method using beta and gamma waves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epilepsy; Electro encephalography; Bagged classifier; Beta wave; Gamma
   wave
ID SEIZURE DETECTION; EPILEPTIC SEIZURES; CLASSIFICATION; ENTROPY; PATTERN
AB Diagnosis of epilepsy primarily involves understanding cautious patient history and assessment of EEG (Electro Encephalography), which is an essential diagnostic support tool. It captures the electrical activity in the brain, which enables the neurologist to look for the presence of epileptiform patterns for which brain waves (Delta, Theta, Alpha, Beta, and Gamma) are studied thoroughly. The Delta (0-4 Hz), Theta (4-8 Hz), and Alpha (8- < 13 Hz) waves are interpreted visually with proficiency; however, the interpretation of Beta (13-35 Hz) and Gamma (36-44 Hz) presents a grave challenge because of their high-frequency nature. The objective of this study was to find out if these waves incorporate features essential for the identification of inter-ictal activity. The bandpass filter was used to extract beta and gamma frequency from the complete EEG signal. Five nonlinear features were extracted out from two, and four-second segments of Beta and Gamma waves. Bagged Tree Classifier is used to categorize the segments into controlled and inter-ictal activity. Data from a total of forty-two patients were used in this study; twenty-three patients with different types of epilepsy and nineteen controlled patients. For two-second segments, we achieved 91.3% classification accuracy, and for four-second segments, we achieved 93.1%. This is improvement from the previous work available in the literature where the segment length of 23.6 s has been used by researchers; with respect to use of public data. Also, the contribution of these brain waves have not been studied independently.
C1 [Kaur, Arshpreet; Shashvat, Kumar] DIT Univ, Dehra Dun, Uttarakhand, India.
   [Puri, Vinod] Super Special Paediat Hosp & Post Grad Teaching I, Noida, India.
   [Verma, Karan] Natl Inst Technol, Delhi, India.
   [Bhondekar, Amol P.] Cent Sci Instruments Org, Chandigarh, India.
C3 DIT University; National Institute of Technology (NIT System); National
   Institute of Technology Delhi; Council of Scientific & Industrial
   Research (CSIR) - India; CSIR - Central Scientific Instruments
   Organisation (CSIO)
RP Kaur, A (corresponding author), DIT Univ, Dehra Dun, Uttarakhand, India.
EM arshpreet@nitdelhi.ac.in; vpuri01@gmail.com; karanverma@nitdelhi.ac.in;
   amolbhondekar@csio.res.in; shashvat@dituniversity.ac.in
RI Verma, Karan/AAD-3240-2022; Kaur, Arshpreet/HKW-3018-2023; Bhondekar,
   Amol P/A-6551-2011; Shashvat, Kumar/J-6737-2019
OI Kaur, Arshpreet/0000-0002-5157-5870; Shashvat,
   Kumar/0000-0003-4227-7625; Verma, Dr. Karan/0000-0002-7675-0444
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Al-Angari HM, 2007, IEEE T BIO-MED ENG, V54, P1900, DOI 10.1109/TBME.2006.889772
   Amudhan S, 2015, ANN INDIAN ACAD NEUR, V18, P263, DOI 10.4103/0972-2327.160093
   Aydin S, 2009, ANN BIOMED ENG, V37, P2626, DOI 10.1007/s10439-009-9795-x
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burioka N, 2005, CLIN EEG NEUROSCI, V36, P21, DOI 10.1177/155005940503600106
   Divya S, 2015, INT J TRENDS ENG TEC, V3, P68
   Geethanjali P., 2016, EPILEPTIC SEIZURE DE
   Gotman J, 1985, Electroencephalogr Clin Neurophysiol Suppl, V37, P133
   Hekim M, 2016, TURK J ELECTR ENG CO, V24, P285, DOI 10.3906/elk-1306-164
   Jaiswal AK, 2017, BIOMED SIGNAL PROCES, V34, P81, DOI 10.1016/j.bspc.2017.01.005
   Jukic S, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091481
   Kaplan, 2017, CLIN NEUROPHYSIOL PR
   Kaur A, 2020, TRAIT SIGNAL, V37, P279, DOI 10.18280/ts.370214
   Kaur A, 2019, CURR PHARM BIOTECHNO, V20, P755, DOI 10.2174/1389201020666190618112715
   Kumar Y, 2014, SIGNAL IMAGE VIDEO P, V8, P1323, DOI 10.1007/s11760-012-0362-9
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Muthukumaraswamy SD, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00138
   Panych L.P., 1990, Clinical Neurophysiology of Epilepsy, P361
   Patidar S, 2017, BIOMED SIGNAL PROCES, V34, P74, DOI 10.1016/j.bspc.2017.01.001
   Pradhan N, 1996, COMPUT BIOMED RES, V29, P303, DOI 10.1006/cbmr.1996.0022
   Puspita JW, 2018, J PHYS CONF SER, V943, DOI 10.1088/1742-6596/943/1/012030
   Raghu S, 2017, COGN NEURODYNAMICS, V11, P51, DOI 10.1007/s11571-016-9408-y
   Raghu S, 2017, EXPERT SYST APPL, V89, P205, DOI 10.1016/j.eswa.2017.07.029
   Saiby M, 2018, J MED ENG TECHNOL, V0, P1
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sharma M, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400036
   Sharma M, 2017, PATTERN RECOGN LETT, V94, P172, DOI 10.1016/j.patrec.2017.03.023
   Sharma R, 2015, EXPERT SYST APPL, V42, P1106, DOI 10.1016/j.eswa.2014.08.030
   Sharma RR, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2018.2882622
   Sharmila A., 2018, Journal of Medical Engineering & Technology, V42, P1, DOI 10.1080/03091902.2017.1394389
   Siska B, 2021, CLASSIFY EPILEPTIC E, V11, DOI 10.18178/ijmlc.2021.11.2.1031
   Siuly, 2011, COMPUT METH PROG BIO, V104, P358, DOI 10.1016/j.cmpb.2010.11.014
   Swami P, 2016, EXPERT SYST APPL, V56, P116, DOI 10.1016/j.eswa.2016.02.040
   Tiwari AK, 2017, IEEE J BIOMED HEALTH, V21, P888, DOI 10.1109/JBHI.2016.2589971
   Tzallas A T, 2007, Comput Intell Neurosci, P80510, DOI 10.1155/2007/80510
   Tzimourta KD, 2019, HEALTH TECHNOL-GER, V9, P135, DOI 10.1007/s12553-018-0265-z
   Valenti P, 2006, J NEUROSCI METH, V150, P105, DOI 10.1016/j.jneumeth.2005.06.005
   Wang YF, 2018, IET CIRC DEVICE SYST, V12, P108, DOI 10.1049/iet-cds.2017.0216
   Webber WRS, 1996, ELECTROEN CLIN NEURO, V98, P250, DOI 10.1016/0013-4694(95)00277-4
   Xiang J, 2015, J NEUROSCI METH, V243, P18, DOI 10.1016/j.jneumeth.2015.01.015
   You S, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105472
   Yu J., 2019, EPILEPTIC SEIZURE CL
   Yuedong Song, 2010, Journal of Biomedical Science & Engineering, V3, P556, DOI 10.4236/jbise.2010.36078
NR 44
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19795
EP 19811
DI 10.1007/s11042-021-11035-3
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000656077100001
DA 2024-07-18
ER

PT J
AU Thiruthuvanathan, MM
   Krishnan, B
AF Thiruthuvanathan, Michael Moses
   Krishnan, Balachandran
TI Multimodal emotional analysis through hierarchical video summarization
   and face tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Deep neural networks; Face detection; Viola Jones;
   Emotional intelligence; Entropy; Hierarchical summarization
ID RECOGNITION; WILD
AB The era of video data has fascinated users into creating, processing, and manipulating videos for various applications. Voluminous video data requires higher computation power and processing time. In this work, a model is developed that can precisely acquire keyframes through hierarchical summarization and use the keyframes to detect faces and assess the emotional intent of the user. The key-frames are used to detect faces using recursive Viola-Jones algorithm and an emotional analysis for the faces extracted is conducted using an underlying architecture developed based on Deep Neural Networks (DNN). This work has significantly contributed in improving the accuracy of face detection and emotional analysis in non-redundant frames. The number of frames selected after summarization was less than 30% using the local minima extraction. The recursive routine introduced for face detection reduced false positives in all the video frames to lesser than 2%. The accuracy of emotional prediction on the faces acquired through the summarized frames, on Indian faces achieved a 90%. The computational requirement scaled down to 40% due to the hierarchical summarization that removed redundant frames and recursive face detection removed false localization of faces. The proposed model intends to emphasize the importance of keyframe detection and use them for facial emotional recognition.
C1 [Thiruthuvanathan, Michael Moses; Krishnan, Balachandran] CHRIST Deemed Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
C3 Christ University
RP Thiruthuvanathan, MM (corresponding author), CHRIST Deemed Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
EM michael.moses@christuniversity.in; Balachandran.k@christuniversity.in
RI K, Balachandran/AAT-9856-2020; Moses, Michael/AAL-8525-2021
OI K, Balachandran/0000-0002-9051-8801; Moses, Michael/0000-0001-7124-3956
CR Ahad MAR, 2018, APPL SOFT COMPUT
   Akram, 2018, P IEEE INT C INF AUT, P1
   Alameda-Pineda X, 2019, COMPUT VIS PATT REC, P1
   Balachran K., 2019, P INT C DAT SCI COMM, P1, DOI 10.1109/IconDSC.2019.8816901
   Engoor S, 2020, INT CONF ADVAN COMPU, P795, DOI [10.1109/icaccs48705.2020.9074318, 10.1109/ICACCS48705.2020.9074318]
   Fei MJ, 2018, MULTIMED TOOLS APPL, V77, P11957, DOI 10.1007/s11042-017-4843-2
   Geng TY, 2018, NEURAL COMPUT APPL, V30, P3243, DOI 10.1007/s00521-017-2918-7
   Gharaee Z, 2017, APPL SOFT COMPUT, V59, P574, DOI 10.1016/j.asoc.2017.06.007
   Gong BQ, 2014, ADV NEUR IN, V27
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Gunawardena P, 2021, J REAL-TIME IMAGE PR, V18, P1457, DOI 10.1007/s11554-020-00957-0
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Happy SL, 2017, IEEE T AFFECT COMPUT, V8, P131, DOI 10.1109/TAFFC.2015.2498174
   Karimi V, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1725, DOI 10.1109/TELFOR.2012.6419560
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Lan SY, 2018, PROC CVPR IEEE, P6771, DOI 10.1109/CVPR.2018.00708
   Lu WY, 2019, IEEE INT C INT ROBOT, P82, DOI 10.1109/ICRIS.2019.00029
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Nawaratne R, 2018, FUTURE GENER COMP SY, V86, P421, DOI 10.1016/j.future.2018.02.049
   Panda R, 2017, PROC CVPR IEEE, P4274, DOI 10.1109/CVPR.2017.455
   Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Salih H, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P692, DOI 10.1109/I-SMAC.2017.8058267
   SANCHEZ JG, 2017, EMOTIONS AFFECT HUMA, V1, P255
   Singh, 2018, P 5 INT C ADV COMP N, pS383
   Singh Shivendra, 2019, INT S SIGN PROC INT, P150
   Sini Raj P, 2017, INT J PURE APPL MATH, V114, P71
   Tang H, 2019, IEEE IMAGE PROC, P4449, DOI [10.1109/icip.2019.8803654, 10.1109/ICIP.2019.8803654]
   Tautkute I, 2018, IEEE COMPUT SOC CONF, P1959, DOI 10.1109/CVPRW.2018.00246
   Thiruthuvanathan M., 2020, INT J INTELL ENG SYS, V13, P31
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhang BQ, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P217, DOI 10.1145/2993148.2993173
   Zhang YJ, 2020, PATTERN RECOGN LETT, V130, P376, DOI 10.1016/j.patrec.2018.07.030
NR 36
TC 8
Z9 8
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35535
EP 35554
DI 10.1007/s11042-021-11010-y
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000654112900005
DA 2024-07-18
ER

PT J
AU Hum, YC
   Tan, HR
   Tee, YK
   Yap, WS
   Tan, TS
   Salim, MIM
   Lai, KW
AF Hum, Yan Chai
   Tan, Hou Ren
   Tee, Yee Kai
   Yap, Wun She
   Tan, Tian Swee
   Salim, Maheza Irna Mohd
   Lai, Khin Wee
TI The development of skin lesion detection application in smart handheld
   devices using deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Skin cancer screening; Skin lesion detection; Multimedia-based
   healthcare systems; Smartphone app; Teledermatology; Deep learning;
   ISICskin lesionsdataset
ID CUTANEOUS MELANOMA; SELF-EXAMINATION; SEGMENTATION; DIAGNOSIS;
   CLASSIFICATION; ARCHITECTURES; IMAGES
AB Early detection of malignant skin lesions improves patient survival rates. Conventional self-detection method for public invariably suffers from limitations: subjectivity, inaccuracy, and expert dependent variability. Therefore, this study presents a detailed development workflow to establish a multimedia-based healthcare systems using computational intelligence, specifically, a mobile application with skin lesion detection capability by integrating state-of-the-art deep learning frameworks that facilitates the global users to execute malignant skin lesions self-detection using a smartphone. We applied transfer learning on various object detection models using ISIC skin lesions dataset with TensorFlow Object Detection API. The selected object detection model is SSD MobileNetV2 with 93.9% of evaluation accuracy. The trained object detection model has been successfully integrated into the mobile application using Firebase ML Kit and has reported low detection time on smartphones. The mobile application has tested to be compatible with various Android versions and screen sizes after we experimented with Firebase Test Lab using seven different smartphones. The trained deep learning model and mobile application development project can be obtained from Github (https://github.com/UTARSL1/).
C1 [Hum, Yan Chai; Tan, Hou Ren; Tee, Yee Kai] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Ctr Healthcare Sci & Technol, Dept Mechatron & Biomed Engn, Kajang, Selangor, Malaysia.
   [Yap, Wun She] Univ Tunku Abdul Rahman, Dept Elect & Elect Engn, Lee Kong Chian Fac Engn & Sci, Kajang, Selangor, Malaysia.
   [Tan, Tian Swee; Salim, Maheza Irna Mohd] Univ Teknol Malaysia, Fac Engn, Sch Biomed Engn & Hlth Sci, BioInspired Device & Tissue Engn Res Grp, Skudai 81300, Johor, Malaysia.
   [Lai, Khin Wee] Univ Malaya, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Tunku Abdul Rahman (UTAR); Universiti Tunku Abdul Rahman
   (UTAR); Universiti Teknologi Malaysia; Universiti Malaya
RP Hum, YC (corresponding author), Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Ctr Healthcare Sci & Technol, Dept Mechatron & Biomed Engn, Kajang, Selangor, Malaysia.
EM humyc@utar.edu.my
RI Tan, Tian Swee/G-6916-2013; Tee, Yee Kai/O-1677-2015; Hum, Yan
   Chai/H-9021-2018; Yap, Wun-She/ABB-5158-2021; Lai, Khin Wee/A-2997-2011;
   SALIM, MAHEZA IRNA MOHAMAD/N-2407-2013
OI Tee, Yee Kai/0000-0002-0263-6358; Hum, Yan Chai/0000-0002-9657-8311;
   Lai, Khin Wee/0000-0002-8602-0533; tian swee, tan/0000-0001-5826-6467;
   SALIM, MAHEZA IRNA MOHAMAD/0000-0003-1704-8636
FU UTAR Research Fund [IPSR/RMC/UTARRF/2020-C1/H02]
FX This research was supported by UTAR Research Fund
   (IPSR/RMC/UTARRF/2020-C1/H02).
CR Abbasi NR, 2004, JAMA-J AM MED ASSOC, V292, P2771, DOI 10.1001/jama.292.22.2771
   Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612
   Adegun AA, 2020, IEEE ACCESS, V8, P7160, DOI 10.1109/ACCESS.2019.2962812
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Albahar MA, 2019, IEEE ACCESS, V7, P38306, DOI 10.1109/ACCESS.2019.2906241
   Amelard R, 2015, IEEE T BIO-MED ENG, V62, P820, DOI 10.1109/TBME.2014.2365518
   [Anonymous], 2020, Skin cancer facts statistics
   Asari VK, 2019, MOBILE MULTIMEDIAIMA, P11
   Bi L, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107502
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Bränström R, 2002, J AM ACAD DERMATOL, V46, P667, DOI 10.1067/mjd.2002.120463
   Chamberlain AJ, 2003, J AM ACAD DERMATOL, V48, P694, DOI 10.1067/mjd.2003.216
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CLARK WH, 1989, JNCI-J NATL CANCER I, V81, P1893, DOI 10.1093/jnci/81.24.1893
   COCO, 2020, COCO COMM OBJ CONT
   DeepAI, 2020, JACCARD INDEX
   Doben AR, 2009, SURG CLIN N AM, V89, P713, DOI 10.1016/j.suc.2009.03.003
   Fanconi, 2020, SKIN CANC MALIGNANT
   Farberg AS, 2017, DERMATOL CLIN, V35, pXV, DOI 10.1016/j.det.2017.06.019
   Firebase, 2020, FIR TEST LAB
   FRIEDMAN RJ, 1985, CA-CANCER J CLIN, V35, P130, DOI 10.3322/canjclin.35.3.130
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glazer AM, 2017, DERMATOL CLIN, V35, P409, DOI 10.1016/j.det.2017.06.001
   Goyal M., 2018, REGION INTEREST DETE
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   Harangi B, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102041
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Iandola, 2017, ABS16020 ARXIV
   Ignatov A, 2019, LECT NOTES COMPUT SC, V11133, P288, DOI 10.1007/978-3-030-11021-5_19
   International Skin Imaging Collaboration (ISIC), 2010, INT SKIN IM COL MEL
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jerant AF, 2000, AM FAM PHYSICIAN, V62, P357
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khawas C., 2018, Int. J. Comput. Appl., V179, P49, DOI DOI 10.5120/IJCA2018917200
   Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002
   Krizhevsky A., 2012, NEURAL INF PROCESS S, V25, P1, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lodde G, 2020, HAUTARZT, V71, P63, DOI 10.1007/s00105-019-04514-0
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Mahbod A, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105725
   McWhirter JE, 2013, J AM ACAD DERMATOL, V69, P47, DOI 10.1016/j.jaad.2013.01.031
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Meng LK, 2019, CURR MED IMAGING, V15, P983, DOI 10.2174/1573405615666190724101600
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Pai K, 2019, TENCON IEEE REGION, P1794, DOI [10.1109/TENCON.2019.8929461, 10.1109/tencon.2019.8929461]
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pereira PMM, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101765
   Reddy N, 2018, INT CONF BIOMETR THE
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sandler Mark, 2018, MobileNetV2: the next generation of on-device computer vision networks
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Soviany Petru, 2018, 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC). Proceedings, P209, DOI 10.1109/SYNASC.2018.00041
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taqi A. M., 2019, INT J ADV RES, V3, P5, DOI DOI 10.5281/ZENODO.3264022
   Tensorflow, 2020, TENSORFLOW OBJ DET A
   Tensorflow-Lite, 2020, DEPL MACH LEARN MOD
   Thomas L, 1998, DERMATOLOGY, V197, P11, DOI 10.1159/000017969
   Tsao H, 2015, J AM ACAD DERMATOL, V72, P717, DOI 10.1016/j.jaad.2015.01.025
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Verma N., 2018, INT J APPL ENG RES, V13, P12527
   Wang XZ, 2020, INT J MACH LEARN CYB, V11, P747, DOI 10.1007/s13042-020-01096-5
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhang QR, 2019, NEUROCOMPUTING, V323, P37, DOI 10.1016/j.neucom.2018.09.038
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zisserman A, 2006, INT J COMPUT VISION
NR 87
TC 4
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41579
EP 41610
DI 10.1007/s11042-021-11013-9
EA MAY 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000650124400004
DA 2024-07-18
ER

PT J
AU Rhayma, H
   Makhloufi, A
   Hamam, H
   Ben Hamida, A
AF Rhayma, Hanen
   Makhloufi, Achraf
   Hamam, Habib
   Ben Hamida, Ahmed
TI Semi-fragile watermarking scheme based on perceptual hash function (PHF)
   for image tampering detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-fragile watermarking; Perceptual hash; JPEG2000; Index modulation
   quantification; Authentication
AB The increasing performances of personal computers, as well as software of image processing, enable the easy manipulation of digital media content. Unfortunately, this easy manipulation makes the detection of changes in the multimedia content a very difficult task. Digital watermarking is among the most appropriate techniques to verify the integrity of multimedia content. In this paper, we propose a semi-fragile watermarking scheme for JPEG2000 image self-authentication that ensuring the robustness of the watermark against the compression attacks generated by the JPEG2000 encoder itself. The scheme is combined with the JPEG2000 encoder by embedding the generated watermark into the host image during the JPEG2000 compression process. To generate the watermark we suppose to use a perceptual hash function (PHF) operating on discrete wavelet coefficients of the host image. The proposed watermark generation process leads the system to verify the integrity of the image without the need to any file except for the watermarked image. The watermark is embedded during the JPEG2000 compression process after Discrete Wavelet Transform (DWT) step into the approximation sub-band coefficients of the five wavelet decomposition using Index Modulation Quantification (QIM), and can be extracted during image decoding. To prove the authentication of the image, the system compares the extracted watermark with the new watermark generated from the received image. Experimental results show that our proposed approach has not only an extremely high accuracy of tampering detection but also a relatively very high resistance against JPEG2000 compression attacks.
C1 [Rhayma, Hanen; Makhloufi, Achraf; Ben Hamida, Ahmed] Univ Sfax, ATMS Adv Technol Med & Signals, Enis, Sfax, Tunisia.
   [Hamam, Habib] Univ Moncton, Fac Engn, Moncton, NB, Canada.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University of Moncton
RP Rhayma, H (corresponding author), Univ Sfax, ATMS Adv Technol Med & Signals, Enis, Sfax, Tunisia.
EM rhayma_hanen@yahoo.fr
RI Hamam, Habib/C-1761-2019
OI Hamam, Habib/0000-0002-5320-1012
CR Ahn, 2015, INT J MACH LEARN CYB
   Boneh Dan, 2015, A graduate course in applied cryptography
   Cachin, 2005, ENCY CRYPTOGRAPHY SE, P1
   Djebbar F., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P409, DOI 10.1109/INNOVATIONS.2011.5893859
   Djebbar Fatiha, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P212, DOI 10.1109/IIHMSP.2010.60
   Djebbar F., 2010, 2010 2nd International Conference on Industrial Mechatronics and Automation (ICIMA 2010), P422, DOI 10.1109/ICINDMA.2010.5538279
   Djebbar F, 2013, SECUR COMMUN NETW, V6, P961, DOI 10.1002/sec.644
   El Sawda Rami, 2007, 2007 International Conference on Future Generation Communication and Networking, P594
   Erra, 2004, WATERMARKING
   Hamam H, 2013, FPGA IMPLEMENTATION
   Hamam H, 2010, OPT LETT, V35, P4175, DOI 10.1364/OL.35.004175
   Hmida, 2018, IEEE ATSIP
   Kalker T., 2006, NETWORK, V153, P2005
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   LENG L, 2015, MULTIMED TOOLS APPL
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li Z, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P627
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Meerwald P, 2001, QUANTIZATION WATERMA
   Muller, 2006, JPEG2000 BASED SECUR
   Ntantogian C, 2019, COMPUT SECUR, V84, P206, DOI 10.1016/j.cose.2019.03.011
   Oriyano Sean-Philip, 2010, INT J COMPUT APPL, V1, P73
   Poornima R., 2013, Int. JComput. Sci. Engin. Survey., V4, P23, DOI [10.5121/ijcses.2013.4102, DOI 10.5121/IJCSES.2013.4102]
   Prasad, 2018, SAUDI J BUSINESS MAN
   Preneel B, 1999, LECT NOTES COMPUT SC, V1561, P158, DOI 10.1007/3-540-48969-X_8
   Rekik Siwar., 2012, International Journal of Computer Science and Security, V6, P79
   Rhayma H, 2019, MULTIMED TOOLS APPL, V78, P14067, DOI 10.1007/s11042-019-7244-x
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Singh, 2018, INT J SCI RES COMPUT, V3
   Suto, 2002, QUANTITIVE SEMIFRAGI
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu, 2003, FLEXIBLE SCALABLE AU
NR 35
TC 10
Z9 10
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26813
EP 26832
DI 10.1007/s11042-021-10886-0
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648855400004
DA 2024-07-18
ER

PT J
AU Manikandan, V
   Amirtharajan, R
AF Manikandan, V.
   Amirtharajan, Rengarajan
TI On dual encryption with RC6 and combined logistic tent map for grayscale
   and DICOM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RC6; DICOM; Dual encryption; Multimedia; Medical image
AB Sensitive multimedia information of all forms is encrypted, with key, before storage and transmission, to protect from illegal use and data manipulation. Since digital images are larger, it's crucial to encrypt the content, specifically in medical images effectively. In medical image diagnosis, even a small manipulation of data may lead to misinterpretation. This paper addresses this concern by devising an algorithm suitable for encrypting DICOM and other types of images. RC6 cipher is used for encrypting the approximation coefficients (LL), obtained by applying the Haar wavelet transform on the plain image and combined with the redistributed (confused) detailed coefficients (LH, HL, HH). Generation of keys through governing equations of Combined Logistical Tent map, adds to the robustness of the algorithm against attacks. This algorithm works well for all types of images, including DICOM. Among several image databases available, 30 different modalities of images have been taken for experimentation, and promising results have been achieved. Results show that on an average, for an image of bit-depth eight, the proposed encryption algorithm provides the PSNR of 9.0955 dB, the entropy of 7.9990 bits for an encrypted image and, with a UACI of 33.4549 and NPCR of 99.6129, the algorithm could effectively defy the statistical and differential attacks.
C1 [Manikandan, V.; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Veerappan, Manikandan/HNS-8576-2023; Amirtharajan,
   Rengarajan/C-6471-2011
OI Veerappan, Manikandan/0000-0001-8501-5743; Amirtharajan,
   Rengarajan/0000-0003-1574-3045
FU Department of Science & Technology, New Delhi [SR/FST/ET-II/2018/221]
FX Authors thank the Department of Science & Technology, New Delhi for the
   FIST funding (SR/FST/ET-II/2018/221). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work.
CR Banu SA, 2021, FRONT INFORM TECH EL, V22, P940, DOI 10.1631/FITEE.2000071
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2020, MIDAS ULTRASOUND 3D
   [Anonymous], 2020, KERCKHOFFS CRYPTOGRA
   [Anonymous], 2020, MIDAS HEAD AXIAL DIC
   [Anonymous], 2020, PATIENT CONTRIBUTED
   [Anonymous], 2019, RC6 RC5 TEST VECTORS
   [Anonymous], 2001, Image Databases
   ARROYO D, 2008, INADEQUACY LOGISTIC
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Benssalah M, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMMUNICATIONS IN NETWORK TECHNOLOGIES (SACONET), P222, DOI 10.1109/SaCoNeT.2018.8585512
   Bentoutou Y, 2020, ADV SPACE RES, V66, P176, DOI 10.1016/j.asr.2019.09.027
   Boussif M, 2020, IET IMAGE PROCESS, V14, P1209, DOI 10.1049/iet-ipr.2019.0042
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Diamond LPH, 2017, PHYS 221A LECT NOTES, V16, P1
   DICOM Library, 2020, DICOM LIB AN SHAR VI
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu XQ, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2827165
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hsiao HI, 2015, SIGNAL PROCESS, V113, P169, DOI 10.1016/j.sigpro.2015.01.024
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jakimoski G, 2001, PHYS LETT A, V291, P381, DOI 10.1016/S0375-9601(01)00771-X
   Kang XJ, 2019, IEEE ACCESS, V7, P114459, DOI 10.1109/ACCESS.2019.2930183
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Lakshmi C, 2021, NEURAL COMPUT APPL, V33, P6671, DOI 10.1007/s00521-020-05447-9
   Lawnik Marcin, 2018, Journal of Physics: Conference Series, V1141, DOI 10.1088/1742-6596/1141/1/012132
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li SJ, 2001, PHYS LETT A, V290, P127, DOI 10.1016/S0375-9601(01)00612-0
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu WY, 2015, MATH PROBL ENG, V2015
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Rivest R, 1998, RC6 BLOCK CIPHER 1 A
   Rubo medical, 2019, SAMPL DICOM FIL
   Summary E., 2001, ANAL RC6
   Tresor LO, 2019, IEEE ACCESS, V7, P103463, DOI 10.1109/ACCESS.2019.2929244
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xu J, 2019, IEEE ACCESS, V7, P167904, DOI 10.1109/ACCESS.2019.2952140
   Yavuz E, 2019, OPT LASER TECHNOL, V114, P224, DOI 10.1016/j.optlastec.2019.01.043
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhao CF, 2020, NONLINEAR DYNAM, V100, P679, DOI 10.1007/s11071-020-05526-5
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 52
TC 8
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23511
EP 23540
DI 10.1007/s11042-021-10943-8
EA MAY 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000646558000002
DA 2024-07-18
ER

PT J
AU Han, XF
   Yan, XY
   Sun, SJ
AF Han, Xian-Feng
   Yan, Xin-Yu
   Sun, Shi-Jie
TI Novel methods for noisy 3D point cloud based object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; Object recognition; Noise reduction; G3DF; IGNF; LVFH;
   LESF
ID SURFACE; HISTOGRAMS
AB 3D point cloud based object recognition becomes increasingly important in the last few years, as the widely use of point cloud over the low-cost 3D sensors have developed rapidly. However, the obtained 3D point cloud is inevitably contaminated with noise due to physical and environmental factors, which has a negative impact on recognition task. To address this problem, a complete object recognition framework for 3D noisy point cloud is presented into which a pre-processing step of filtering is integrated for the first time. In the filtering phase, our two proposed approaches, named Guided 3D Point Cloud Filter (G3DF) and Iterative Guidance Normal Filter (IGNF), are taken into account to produce high-quality point cloud model. Then, on the basis of advantages of local-based and global-based descriptors, a new type of feature descriptor, called Local-to-Global Histogram (LGH), is proposed, which contains Local Viewpoint Feature Histogram (LVFH) and Local Ensemble of Shape Function (LESF). Experimental results show that the comprehensive classification performance yielded by using proposed filters and descriptors is competitive compared to other state-of-the-art combinations. In particularly, the composition of G3DF and LVFH is more suited for real-time applications.
C1 [Han, Xian-Feng] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Yan, Xin-Yu] Tianjin Univ, Tianjin 300072, Peoples R China.
   [Sun, Shi-Jie] Changan Univ, Xian 710064, Shaanxi, Peoples R China.
C3 Southwest University - China; Tianjin University; Chang'an University
RP Han, XF (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
EM xianfenghan@swu.edu.cn; xinyuyan@tju.edu.cn; shijiesun@chd.edu.cn
OI Han, Xianfeng/0000-0002-4869-4537
FU National Natural Science Foundation of China [62002299]; Natural Science
   Foundation of Chongqing of China [cstc2020jcyj-msxmX0126]; Fundamental
   Research Funds for the Central Universities [SWU120005]
FX This research was supported by the National Natural Science Foundation
   of China (No. 62002299), and the Natural Science Foundation of Chongqing
   of China (No. cstc2020jcyj-msxmX0126), and the Fundamental Research
   Funds for the Central Universities (No. SWU120005)
CR Aldoma A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alexandre LA, 2012, IEEE INT C INT ROB S
   Behley J, 2012, IEEE INT CONF ROBOT, P4391, DOI 10.1109/ICRA.2012.6225003
   Bo Liefeng, 2011, IEEE INT CONF ROBOT
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Desouza, 2014, AS C COMP
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Han XF., 2017, MULTIMED TOOLS APPL, V77, P1
   Han XF., 2017, MILITARY MED RES, V77, P1
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Kasaei SH, 2016, PATTERN RECOGN LETT, V83, P312, DOI 10.1016/j.patrec.2016.07.006
   Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Rente PD, 2019, IEEE T MULTIMEDIA, V21, P284, DOI 10.1109/TMM.2018.2859591
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Tabia H, 2015, IEEE T MULTIMEDIA, V17, P1591, DOI 10.1109/TMM.2015.2457676
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Vincze, 2012, JOINT DAGM GERM ASS
   Wang PS, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818068
   Wu PF, 2017, IEEE T MULTIMEDIA, V19, P266, DOI 10.1109/TMM.2016.2612761
   Xiao G-Q, 2020, ARXIV180202297V2
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhao H, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107272
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 37
TC 6
Z9 6
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26121
EP 26143
DI 10.1007/s11042-021-10794-3
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645187800001
DA 2024-07-18
ER

PT J
AU Elshahaby, H
   Rashwan, M
AF Elshahaby, Hossam
   Rashwan, Mohsen
TI A system for detection of moving caption text in videos: a news use case
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caption text; News applications; Text localization; Text detection; Text
   enhancement; Text recognition; Super-resolution; Autoencoder; OCR; Deep
   neural network
AB Extraction of news text captions aims at a digital understanding of what is happening in a specific region during a certain period that helps in better communication between different nations because we can easily translate the plain text from one language to another. Moving text captions causes blurry effects that are a significant cause of text quality impairments in the news channels. Most of the existing text caption detection models do not address this problem in a way that captures the different dynamic motion of captions, gathers a full news story among several frames in the sequence, resolves the blurring effect of text motion, offers a language-independent model, or provides it as an end-to-end solution for the community to use. We process the frames coming in sequence and extract edge features using either the Hough transform or our color-based technique. We verify text existence using a Convolutional Neural Network (CNN) text detection pre-trained model. We analyze the caption motion status using hybrid pre-trained Recurrent Neural Network (RNN) of Long Short-Term Memory (LSTM) type model and correlation-based model. In case the motion is determined to be horizontal rotation, there are two problems. First, it means that text keeps rotating with no stop resulting in a high blurring effect that affects the text quality and consequently resulting in low character recognition accuracy. Second, there are successive news stories which are separated by the channel logo or long spaces. We managed to solve the first problem by deblurring the text image using either Bicubic Spline Interpolation (BSI) technique or the Denoising Autoencoder Neural Network (DANN). We solved the second problem using a Point Feature Matching (PFM) technique to match the existing channel logo with the channels' logo database (ground truth). We evaluate our framework using Abbyy (R) SDK as a standalone tool used for text recognition supporting different languages.
C1 [Elshahaby, Hossam; Rashwan, Mohsen] Cairo Univ, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University
RP Elshahaby, H (corresponding author), Cairo Univ, Cairo, Egypt.
EM hossam.elshahaby@gmail.com
OI Elshahaby, Hossam/0000-0003-1178-5491
CR Alabed, 2018, THESIS CAIRO U
   Chandrahasa B, 2018, ARXIV181202475V1
   Chen LH, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500092
   Lat A, 2018, 24 INT C PATT REC, DOI 10.1007/978-3-030-57058-3_11
   Li HP, 2000, INT C PATT RECOG, P847, DOI 10.1109/ICPR.2000.905546
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XY, 2019, IEEE CUST INTEGR CIR, DOI 10.1109/CICC.2019.8780229
   Luo B, 2003, IEEE IMAGE PROC, P297
   Majeed S., 2020, INT C EMERG TRENDS S, P1
   Milanfar P, 2005, THESIS U CALIFORIA
   Mirza A, 2018, PROCEEDINGS OF THE 2ND MEDITERRANEAN CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (MEDPRAI-2018), P70, DOI 10.1145/3177148.3180098
   Moradi M, 2010, 2010 6 IR C MACH VIS, P1
   Shi Y, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080833
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wongso Rini, 2018, Procedia Computer Science, V135, P331, DOI 10.1016/j.procs.2018.08.181
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yu Zhong, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P96, DOI 10.1109/ICIP.1999.822862
   Zedan K., 2016, PROC 2 INT C INTELL, V533, P383
   Zhang H, 2017, IEEE VISUAL COMMUNIC
   Zhang X, 2019, INT C DOC AN REC ICD
NR 20
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25607
EP 25631
DI 10.1007/s11042-021-10856-6
EA APR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642389300003
DA 2024-07-18
ER

PT J
AU Hui, KF
   Ganaa, ED
   Zhan, YZ
   Shen, XJ
AF Hui, Kai-fa
   Ganaa, Ernest Domanaanmwi
   Zhan, Yong-zhao
   Shen, Xiang-jun
TI Robust deflated canonical correlation analysis via feature factoring for
   multi-view image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CCA; Matrix approximation; Dimension reduction; Multi-view; Noise
   suppression; Image classification
ID FEATURE-SELECTION; REDUCTION; FUSION; SYSTEM
AB Canonical Correlation Analysis (CCA) and its kernel versions (KCCA) are well-known techniques adopted in feature representation and classification for images. However, their performances are significantly affected when the images are noisy and in multiple views. In this paper, the method of robust deflated canonical correlation analysis via feature factoring for multi-view image classification is proposed. In this method, a feature factoring matrix is introduced to measure proximities between each feature vector in the dimension and projection vector, through this we evaluate the contribution of each feature to the whole feature space. Therefore, we can assign specific weights to different features accordingly to suppress the noisy data. As images are captured in multi-view usually, we also propose a deflated CCA method to build multiple factoring matrices with respect to multiple projection vectors. In this way, we weigh the degree of importance of each feature in each projection respectively to get a better feature representation for multi-view images. Experimental results on several datasets such as ORL, COIL and USPS, demonstrate that our method can improve classification performance compared to other state-of-the-art CCA methods.
C1 [Hui, Kai-fa; Ganaa, Ernest Domanaanmwi; Zhan, Yong-zhao; Shen, Xiang-jun] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Zhan, Yong-zhao] Jiangsu Engn Res Ctr Big Data Ubiquitous Percept, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Zhan, YZ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM yzzhan@ujs.edu.cn
RI Ganaa, Ernest Domanaanmwi/O-5746-2019; jin, li/IWU-4648-2023
OI Ganaa, Ernest Domanaanmwi/0000-0002-2161-7435; 
FU National Natural Science Foundation of China [61672268]
FX This research was supported in part by National Natural Science
   Foundation of China (Grant No. 61672268).
CR Ambusaidi MA, 2016, IEEE T COMPUT, V65, P2986, DOI 10.1109/TC.2016.2519914
   [Anonymous], 2019, Advances in neural information processing systems
   Bai Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030432
   Cai J, 2017, ENG APPL ARTIF INTEL, V64, P33, DOI 10.1016/j.engappai.2017.05.016
   Chen GY, 2017, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP.2017.8296253
   Chiba Y, 2019, ACOUST SCI TECHNOL, V40, P406, DOI 10.1250/ast.40.406
   CHOW TWS, 2008, NEW FEATURE SELECTIO, V38, P499, DOI DOI 10.1109/TSMCB.2007.914707
   El-Manzalawy Y, 2018, 2018 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P67
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Ganaa ED, 2019, LECT NOTES COMPUT SC, V11903, P479, DOI 10.1007/978-3-030-34113-8_40
   Gao QX, 2020, AAAI CONF ARTIF INTE, V34, P3938
   Hossain MZ, 2016, NEUROCOMPUTING, V173, P855, DOI 10.1016/j.neucom.2015.08.040
   Huang S, 2020, IEEE T SIGNAL PROCES
   HUANG WK, 2020, SCI REP-UK, V10
   Imtiaz H, 2017, IEEE GLOB CONF SIG, P283, DOI 10.1109/GlobalSIP.2017.8308649
   Khan HN, 2019, IEEE ACCESS, V7, P165724, DOI 10.1109/ACCESS.2019.2953318
   Kusetogullari H, 2020, NEURAL COMPUT APPL, V32, P16505, DOI 10.1007/s00521-019-04163-3
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li MM, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113277
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Ma L, 2017, IEEE GEOSCI REMOTE S, V14, P409, DOI 10.1109/LGRS.2016.2645710
   Maeda K, 2019, INT CONF ACOUST SPEE, P3936, DOI [10.1109/ICASSP.2019.8682060, 10.1109/icassp.2019.8682060]
   Manco-Vásquez J, 2017, T EMERG TELECOMMUN T, V28, DOI 10.1002/ett.2896
   Mandal A, 2018, IEEE T CYBERNETICS, V48, P1229, DOI 10.1109/TCYB.2017.2685625
   Mudunuri SP, 2019, IEEE T INF FOREN SEC, V14, P886, DOI 10.1109/TIFS.2018.2868173
   Neloy AA, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P350, DOI 10.1145/3318299.3318377
   Rasiwasia Nikhil., 2010, P ACM INT C MULTIMED, P251
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Shen XJ, 2019, IEEE GEOSCI REMOTE S, V16, P1150, DOI 10.1109/LGRS.2019.2892491
   Shi ZR, 2017, J ENG-JOE, DOI 10.1049/joe.2016.0296
   Tang C, 2019, AAAI CONF ARTIF INTE, P5101
   Uzel B, 2020, LITHOS, V352, DOI 10.1016/j.lithos.2019.105305
   Vu H, 2017, IEEE INT C SYST
   Wang Z, 2020, PATTERN RECOGN, V99, DOI 10.1016/j.patcog.2019.107050
   Xu P, 2018, NEUROCOMPUTING, V278, P75, DOI 10.1016/j.neucom.2017.05.099
   Yadav C., 2019, Advances in Neural Information Processing Systems, V32, P13443
   Yang XH, 2021, IEEE T KNOWL DATA EN, V33, P2349, DOI 10.1109/TKDE.2019.2958342
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Zhan BS, 2019, LECT NOTES COMPUT SC, V11956, P576, DOI 10.1007/978-3-030-37429-7_59
   Zhang R, 2019, INFORM FUSION, V50, P158, DOI 10.1016/j.inffus.2018.11.019
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang SH, 2020, IEEE T IMAGE PROCESS, V29, P3213, DOI 10.1109/TIP.2019.2957939
   Zhu YM, 2020, IEEE ACCESS, V8, P115228, DOI 10.1109/ACCESS.2020.3002810
NR 46
TC 2
Z9 2
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24843
EP 24865
DI 10.1007/s11042-021-10736-z
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700007
DA 2024-07-18
ER

PT J
AU Choudhury, A
   Sarma, KK
AF Choudhury, Ananya
   Sarma, Kandarpa Kumar
TI A CNN-LSTM based ensemble framework for in-air handwritten Assamese
   character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-air handwriting recognition; Human computer interaction; Ligature;
   Markov random field; Convolutional neural network; Long short-term
   memory
AB In-air handwriting is a contemporary human computer interaction (HCI) technique which enables users to write and communicate in free space in a simple and intuitive manner. Air-written characters exhibit wide variations depending upon different writing styles of users and their speed of articulation, which presents a great challenge towards effective recognition of linguistic characters. So, in this paper we have proposed an ensemble model for in-air handwriting recognition which is based on convolutional neural network (CNN) and a long short-term memory neural network (LSTM-NN). The method collaborates overall character trajectory appearance modeling and temporal trajectory feature modeling for efficient recognition of varied types of air-written characters. In contrast to two-dimensional handwriting, in-air handwriting generally involves writing of characters interlinked by a continuous stroke, which makes segregation of intended writing activity from insignificant connecting motions an intricate task. So, a two-stage statistical framework is incorporated in the system for automatic detection and extraction of relevant writing segments from air-written characters. Identification of writing events from a continuous stream of air-written data is accomplished by formulating a Markov Random Field (MRF) model, while the segmentation of writing events into meaningful handwriting segments and redundant parts is performed by implementation of a Mahalanobis distance (MD) classifier. The proposed approach is assessed on an air-written character dataset comprising of Assamese vowels, consonants and numerals. The experimental results connote that our hybrid network can assimilate more information from the air-writing patterns and hence offer better recognition performance than the state-of-the-art approaches.
C1 [Choudhury, Ananya; Sarma, Kandarpa Kumar] Gauhati Univ, Dept Elect & Commun Engn, Gauhati, Assam, India.
C3 Gauhati University
RP Choudhury, A (corresponding author), Gauhati Univ, Dept Elect & Commun Engn, Gauhati, Assam, India.
EM ananya.apr@gmail.com
RI Sarma, Kandarpa Kumar/AAA-2036-2019; Sarma, Kandarpa Kumar/C-3675-2012
OI Sarma, Kandarpa Kumar/0000-0002-6236-0461; Sarma, Kandarpa
   Kumar/0000-0002-6236-0461; Choudhury, Ananya/0000-0003-2278-6860
CR Agarwal C, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P539, DOI 10.1109/ACPR.2015.7486561
   Alam MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020376
   Amma C., 2010, P 1 AUGM HUM INT C, P1
   Amma C, 2012, IEEE INT SYM WRBL CO, P52, DOI 10.1109/ISWC.2012.21
   Ayachi N, 2015, INT CONF COMM SYST, P505, DOI 10.1109/CSNT.2015.95
   Behera SK, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P314, DOI 10.23919/MVA.2017.7986864
   Bradski G., 2008, LEARNING OPENCV
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P436, DOI 10.1109/THMS.2015.2492599
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Chen YM, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2026, DOI 10.1109/ROBIO.2015.7419071
   Chiang CC, 2017, PATTERN RECOGN, V61, P15, DOI 10.1016/j.patcog.2016.07.018
   Choudhury A, 2019, LECT NOTES COMPUT SC, V11941, P575, DOI 10.1007/978-3-030-34869-4_63
   Choudhury A, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P98, DOI 10.1109/SPIN.2018.8474285
   Crivelli T, 2006, PROC SPIE, V6315, DOI 10.1117/12.674648
   Davies ER, 2012, COMPUTER AND MACHINE VISION: THEORY, ALGORITHMS, PRACTICALITIES, 4TH EDITION, P1
   DeCarlo LT, 1997, PSYCHOL METHODS, V2, P292, DOI 10.1037/1082-989X.2.3.292
   Duda RO., 1973, PATTERN RECOGN
   Elmezain M., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P131, DOI 10.1109/ISSPIT.2010.5711749
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Frolova D, 2013, IEEE T CYBERNETICS, V43, P871, DOI 10.1109/TSMCB.2012.2217324
   Gan J, 2019, NEURAL COMPUT APPL, V31, P3155, DOI 10.1007/s00521-017-3260-9
   Gan JR, 2020, IEEE T SYST MAN CY-S, V50, P2741, DOI 10.1109/TSMC.2018.2827937
   GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268
   Hu JT, 2015, INT C CONTR AUTOMAT, P1885, DOI 10.1109/ICCAS.2015.7364671
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar P, 2017, IEEE SENS J, V17, P1293, DOI 10.1109/JSEN.2016.2643165
   Leo M, 2017, COMPUT VIS IMAGE UND, V154, P1, DOI 10.1016/j.cviu.2016.09.001
   Li S. Z., 2009, Markov random field modeling in image analysis
   Liang ZQ, 2008, SENSORS-BASEL, V8, P5106, DOI 10.3390/s8085106
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Mukherjee S, 2019, EXPERT SYST APPL, V136, P217, DOI 10.1016/j.eswa.2019.06.034
   Murata T, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/278460
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rahman Adil, 2020, Pattern Recognition. 5th Asian Conference, ACPR 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12046), P76, DOI 10.1007/978-3-030-41404-7_6
   Ren HQ, 2017, IEEE INT CON MULTI, P841, DOI 10.1109/ICME.2017.8019443
   Rosin PL, 2006, COMPUT VIS IMAGE UND, V103, P101, DOI 10.1016/j.cviu.2006.04.002
   Roy P, 2018, INT CONF FRONT HAND, P404, DOI 10.1109/ICFHR-2018.2018.00077
   Sarma KK, 2019, HANDMADE TEACHING MA, P294, DOI [10.4018/978-1-5225-6240-5.ch013, DOI 10.4018/978-1-5225-6240-5.CH013]
   Saunders H., 1989, PROBABILITY RANDOM V
   Schick A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P217
   Smith S.W., 1997, SCI ENG GUIDE DIGITA
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Wang QPA, 2008, J PHYS A-MATH THEOR, V41, DOI 10.1088/1751-8113/41/6/065004
   Wilson J.N., 2000, HDB COMPUTER VISION
   Xu SB, 2016, IEEE SYS MAN CYBERN, P1510, DOI 10.1109/SMC.2016.7844452
   Yang C, 2016, ELECTRON LETT, V52, P1679, DOI 10.1049/el.2016.0841
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19
NR 52
TC 9
Z9 9
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35649
EP 35684
DI 10.1007/s11042-020-10470-y
EA MAR 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000635488800001
DA 2024-07-18
ER

PT J
AU Gupta, A
   Yadav, D
AF Gupta, Anishka
   Yadav, Divakar
TI A novel approach to perform context-based automatic spoken document
   retrieval of political speeches based on wavelet tree indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic speech recognition; Deep neural networks; Hidden markov
   models; Gaussian mixture models; Information retrieval; Wavelet trees;
   Indexing; TF-IDF; Cosine similarity
AB Spoken document retrieval for a specific context is a very trending and interesting area of research. It makes it convenient for users to search through archives of speech data, which is not possible manually as it is very time consuming and expensive. In the current article, we focus on performing the same for political speeches, delivered in a variety of environments. The technique used here takes an archive of spoken documents (audio files) as input and performs automatic speech recognition (ASR) on it to derive the textual transcripts, using deep neural networks (DNN), hidden markov models (HMM) and Gaussian mixture models (GMM). These transcriptions are further pruned for indexing by applying certain pre-processing techniques. Thereafter, it builds time and space efficient index of the documents using wavelet trees for its retrieval. The constructed index is searched through to find the count of occurrences of the words in the query, fired by the users. These counts are then utilized to calculate the term frequency - inverse document frequency (TF-IDF) scores, and then the similarity score of the query with each document is calculated using cosine similarity method. Finally, the documents are ranked based on these scores in the order of relevance. Therefore, the proposed system develops a speech recognition system and introduces a novel indexing scheme, based on wavelet trees for retrieving data.
C1 [Gupta, Anishka; Yadav, Divakar] Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
EM anishka0107@gmail.com; divakaryadav@nith.ac.in
RI Yadav, DIVAKAR/AAF-1777-2020
OI Yadav, DIVAKAR/0000-0001-6051-479X
CR Arora S., 2012, International Journal of Computer Applications, V60, P34, DOI DOI 10.5120/9722-4190
   Boruah S, 2013, STUDY HMM BASED SPEE, P1, DOI [10.1109/ICCIC.2013.6724147, DOI 10.1109/ICCIC.2013.6724147]
   Brisaboa NR, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/DEXA.2007.118
   Chelba C, 2006, AUTOMATIC SPOKEN DOC, DOI 10.3115/1614101.1614105
   FAUST FC, 2008, LECT NOTES COMPUT SC, V5280, P176
   Ferragina P, 2006, LECT NOTES COMPUT SC, V4051, P560, DOI 10.1007/11786986_49
   GAGIE T, 2010, THEORET COMPUT SCI, P426
   Gowri S., 2014, INT C MATH SCI, P174, DOI DOI 10.21437/INTERSPEECH.2017-1284
   Graefe G, 2010, FOUND TRENDS DATABAS, V3, P203, DOI 10.1561/1900000028
   Grossi R, 2003, SIAM PROC S, P841
   Grossi R., 2011, 2011 First International Conference on Data Compression, Communications and Processing, P210, DOI 10.1109/CCP.2011.16
   Gunawan D, 2018, J PHYS CONF SER, V978, DOI 10.1088/1742-6596/978/1/012120
   Gurusamy Vairaprakash, 2017, INT J SCI RES DEV, V5, P2321
   Hauptmann, 2006, ENCY LANGUAGE LINGUI, DOI 10.1016/B0-08-044854-2/00922-6
   Hiemstra D, 2003, TRCTIT0009
   Juang BH, 2000, P IEEE, V88, P1142, DOI 10.1109/5.880077
   Kalra P, 2013, INT J COMPUT APPL, V66, P14, DOI [10.5120/11088-6039, DOI 10.5120/11088-6039]
   LEE CH, 1990, INT CONF ACOUST SPEE, P721, DOI 10.1109/ICASSP.1990.115885
   Mahapatra A.K., 2011, Int. Journal of Computer Science, V8, P384
   Malki Z, 2016, INT J ADV COMPUT SC, V7, P132
   Platek, 2014, THESIS CHARLES U PRA
   Porter MF, 2001, Snowball: a language for stemming algorithms
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Psutka J, 2001, 7 EUR C SPEECH COMM, P1813
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Rosnan S., 2019, P 2019 4 INT C WORKS, P1
   Saini B, 2014, INT J ADV FDN RES CO, V1, P57
   Salgado-Garza L, 2004, USE AUTOMATIC SPEECH, V3287, P381, DOI [10.1007/978-3-540-30463-047, DOI 10.1007/978-3-540-30463-047]
   Sanderson M, 2012, P IEEE, V100, P1444, DOI 10.1109/JPROC.2012.2189916
   Shah, 2016, HASH BASED OPTIMIZAT, P1, DOI [10.1109/INVENTIVE.2016.7823270, DOI 10.1109/INVENTIVE.2016.7823270]
   Tiken M., 2016, SCI TECHNOL J, P152, DOI DOI 10.22232/STJ.2016.04.02.10
   Variani E, 2017, INTERSPEECH, P1641, DOI 10.21437/Interspeech.2017-1284
   Waris, 2018, ACOUSTIC MODELING AU, P1408, DOI [10.1109/ICECA.2018.8474889, DOI 10.1109/ICECA.2018.8474889]
   Wechsler M, 2000, INFORM RETRIEVAL, V3, P173, DOI 10.1023/A:1026512724855
   Yadav AK, 2016, INT J INF RETR RES, V6, P16, DOI 10.4018/IJIRR.2016100102
NR 35
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22209
EP 22229
DI 10.1007/s11042-021-10800-8
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790600001
DA 2024-07-18
ER

PT J
AU Sung, CS
   Park, JY
AF Sung, Chang-Soo
   Park, Joo Yeon
TI Design of an intelligent video surveillance system for crime prevention:
   applying deep learning technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance system; Deep learning; Artificial intelligence; Crime
   prevention
AB As the security threat and crime rate have been increased all over the globe, the video surveillance system using closed-circuit television (CCTV) has become an essential tool for many security-related applications and is widely used in many areas as a monitoring system. However, most of the data collected by the video surveillance system is used as evidence of objective data after crime and disaster have occurred. And, often time, video surveillance systems tend to be used in a passive manner due to the high cost and human resources. The video surveillance system should actively respond to detect crime and accidents in advance through real-time monitoring and immediately transmit data in case of an accident. This study proposes developing an intelligent video surveillance system that can actively monitor in real-time without human input. In solving the problems of the existing video surveillance system, deep learning technology will be carried through the data processing model design to visualize data for crime detection after building an artificial intelligence server and video surveillance camera. In addition, this design proposes an intelligent surveillance system to quickly and effectively detect crimes by sending a video image and notification message to the web through real-time processing.
C1 [Sung, Chang-Soo] Dongguk Univ Seoul, Dept Technol Entrepreneurship, Seoul 04620, South Korea.
   [Park, Joo Yeon] Murdoch Univ, Discipline Informat Technol Media & Commun, Murdoch, WA 6150, Australia.
C3 Dongguk University; Murdoch University
RP Park, JY (corresponding author), Murdoch Univ, Discipline Informat Technol Media & Commun, Murdoch, WA 6150, Australia.
EM redsun44@dongguk.edu; jooyeon.park@murdoch.edu.au
OI Park, Joo Yeon/0000-0002-5231-5405
CR Al-Araji SR, 2013, IEEE INT NEW CIRC
   Allied Telesis, INT VID SURV REC TRE
   Barhm Mukhtaj S., 2011, Modern Approaches in Applied Intelligence. Proceedings 24th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems (IEA/AIE 2011), P511, DOI 10.1007/978-3-642-21827-9_52
   Carpenter AE, 2017, ARXIV180409548V2
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   Chollet F., 2017, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   Gibert X, 2017, IEEE T INTELL TRANSP, V18, P153, DOI 10.1109/TITS.2016.2568758
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Gupta, 2019, J RECENT TECHNOL ENG, V8, P939
   Jain Harsh, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P193, DOI 10.1109/ICESC48915.2020.9155832
   Ju YW, 2013, INT J SECUR APPL, V7, P113, DOI 10.14257/ijsia.2013.7.5.09
   Kelemen, 2019, STUDIES IN BIG DATA
   Kim YS, 2015, BIGDAS 15 P 2015 INT, P208
   Kumar V, 2015, PROMOTING SOCIAL CHA, P75
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei J, 2019, MULTIMED TOOLS APPL, V78, P27703, DOI 10.1007/s11042-019-07892-8
   Li LY, 2008, IEEE T SYST MAN CY B, V38, P1254, DOI 10.1109/TSMCB.2008.927265
   Little DD, 2013, COMPUTER SCI TODAY R
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Mathworks, 2020, DEEP LEARN WHAT IS D
   Matiolanski A, 2016, MULTIMED TOOLS APPL, V75, P10513, DOI 10.1007/s11042-015-2697-z
   Morioka K, 2010, INT J SMART SENS INT, V3, P338, DOI 10.21307/ijssis-2017-396
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Mwiti Derrick, 2019, HEARTBEAT
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nielsen A, 2017, DAILY UNIVERSE 0628
   Niu L., 2019, INT ARCH PHOTOGRAMME
   Ogle RI, 2018, 2018 5 INT C INF COM
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Qi L, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090959
   Rai M, 2018, INTELLIGENT VIDEO SU, DOI 10.5772/intechopen.76444
   Rajpoot QM, 2014, IFIP ADV INF COMM TE, V428, P169
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross G., 2013, P IEEE COMP SOC C CO, P1
   Saravi S, 2019, WATER-SUI, V11, DOI 10.3390/w11050973
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Sur C, 2019, MULTIMED TOOLS APPL, V78, P32187, DOI 10.1007/s11042-019-08021-1
   Turchini F, 2018, INVENTIONS-BASEL, V3, DOI 10.3390/inventions3040069
   Vincent J, 2018, VERGE 0123
   Vishnu VCM, 2018, CLUSTER COMPUT, V21, P135, DOI 10.1007/s10586-017-0974-5
   Wiliem A, 2012, COMPUT VIS IMAGE UND, V116, P194, DOI 10.1016/j.cviu.2011.10.001
   Yang H.-M., 2019, INT J SOC HUMANIST C, V3, P148, DOI [10.1504/IJSHC.2019.101598, DOI 10.1504/IJSHC.2019.101598]
   Zablocki M., 2014, Journal of Theoretical and Applied Computer Science, V8, P13
   Zhang P, 2012, MULTIMEDIA SYST, V18, P175, DOI 10.1007/s00530-011-0247-8
NR 46
TC 10
Z9 10
U1 6
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34297
EP 34309
DI 10.1007/s11042-021-10809-z
EA MAR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000632315900003
DA 2024-07-18
ER

PT J
AU Zou, BW
   Gofuku, A
AF Zou, Bowen
   Gofuku, Akio
TI Evaluation of operation state for operators in NPP Main control room
   using human behavior recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Operation state evaluation; Human behavior recognition; Behavioral
   coding analysis
ID HUMAN RELIABILITY-ANALYSIS
AB The cognitive state of the main control room (MCR) operator is the state of cognitive progress. This paper proposes a video analysis method to assist in the analysis of the operation state. A behavioral coding method is presented for the feature extraction of the MCR operator, and the time-line analysis method is used to continuously sample the operator's postures and actions. OpenPose algorithm and ST-GCN method are used for the recognition of the operator's behavior. The level of consciousness and cognition is analyzed based on the operator's body language and used to evaluate the level of mental stress in performance shaping factors (PSF). A case is presented for the feasibility analysis of the operation state evaluation method. The results of the video analysis help recognize the operator's bad or error behavior and improve the operator's operation state.
C1 [Zou, Bowen] South China Univ Technol, Sch Elect Power, Guangzhou 510641, Peoples R China.
   [Zou, Bowen; Gofuku, Akio] Okayama Univ, Grad Sch Interdisciplinary Sci & Engn Hlth Syst, Okayama 7008530, Japan.
C3 South China University of Technology; Okayama University
RP Zou, BW (corresponding author), South China Univ Technol, Sch Elect Power, Guangzhou 510641, Peoples R China.; Zou, BW (corresponding author), Okayama Univ, Grad Sch Interdisciplinary Sci & Engn Hlth Syst, Okayama 7008530, Japan.
EM zoubowen@hrbeu.edu.cn
OI Zou, Bowen/0000-0002-5467-409X
CR Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cooper G., 1990, AUSTR J ED TECHNOLOG, V6, P108, DOI [DOI 10.14742/AJET.2322, 10.14742/AJET.2322]
   De FF, 2018, HUMAN FACTORS RELIAB
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   HANNAMAN GW, 1988, RELIAB ENG SYST SAFE, V22, P235, DOI 10.1016/0951-8320(88)90076-2
   Harada Taku, 2014, International Journal of Software Science and Computational Intelligence, V6, P1, DOI 10.4018/ijssci.2014010101
   Hayashi, 1984, HUMAN RELIABILITY EN
   Hollnagel E., 1998, Cognitive Reliability and Error Analysis Method (CREAM), DOI DOI 10.1016/B978-008042848-2/50001-4
   Korte B., 1997, Body Language in Literature
   Lean Y, 2012, HUM FACTOR ERGON MAN, V22, P177, DOI 10.1002/hfm.20269
   Li PC, 2019, ADV INTELL SYST COMP, V778, P68, DOI 10.1007/978-3-319-94391-6_7
   Lindsay Peter H., 2013, Human information processing: An introduction to psychology
   Mangold, 2017, INTERACT US GUID
   Noldus Information Technology, 2019, INNOVATIVE SOLUTIONS
   Pease Barbara., 2008, DEFINITIVE BOOK BODY
   Pyy P., 2000, VTT PUBLICATIONS, V4, P2
   Rowlands, 2011, BODY LANGUAGE REPRES
   Salvendy G, 2012, HUM FACTORS ERGON, pXIII
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K., 2012, ARXIV12120402CS
   Stokes A.F., 2017, FLIGHT STRESS STRESS
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   Swain D., 1983, HDB HUMAN RELIABILIT
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   University of Central Florida, UCF101 ACT REC DAT S
   Xie B., 2000, INT J COGNITIVE ERGO, V4, P213, DOI DOI 10.1207/S15327566IJCE04033
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yoshikawa, 1993, IFAC P VOLUMES, V26, P569, DOI [10.1016/S1474-6670(17)49190-7, DOI 10.1016/S1474-6670(17)49190-7]
   Zou YH, 2017, NUCL ENG TECHNOL, V49, P335, DOI 10.1016/j.net.2017.01.011
NR 32
TC 3
Z9 3
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21809
EP 21821
DI 10.1007/s11042-021-10799-y
EA MAR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848100003
DA 2024-07-18
ER

PT J
AU Kong, WZ
   Song, XL
   Sun, JF
AF Kong, Wanzeng
   Song, Xulin
   Sun, Junfeng
TI Emotion recognition based on sparse representation of phase
   synchronization features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Electroencephalogram (EEG); Phase synchronization;
   Sparse representation based classification (SRC)
ID FEATURE-EXTRACTION; AFFECTIVE SPACE; EEG; CLASSIFICATION
AB Emotion recognition based on Electroencephalogram (EEG) has attracted much attention in brain-computer interaction. However, most existing methods usually focus on amplitude and spectrum of the EEG signal, leading to sub-optimal performances due to the insufficiency in modelling the complex intrinsic information of neural integration. To address this issue, this paper proposes to capitalize on the largely neglected phase synchronization (PS) between EEG channels which reflects the intrinsic rhythmic interactions between different channels in neural integration. Specifically, this paper develops a simple and novel feature extraction method which calculates the PS based sparse representation features to analyze emotion states. First, the EEG phase synchronization indexes (PSI) of all channel pairs are estimated as features to distinguish different emotions, since certain topographical maps on PSI reveal specific emotion states. Then principal component analysis is performed to eliminate redundant and noisy features in PSI. Finally, Sparse Representation based Classification (SRC) furtherly emphasize emotion-related features and restrain useless features. For the benchmark affective EEG dataset DEAP, the proposed method based on no-overlapping EEG features achieve an average accuracy of 94.5%, 87.61%, and 67.04% for the classification tasks respectively on two, three and four emotions, demonstrating the superiority over state-of-the-art emotion classification methods.
C1 [Kong, Wanzeng] Hangzhou Dianzi Univ, Coll Comp Sci, Hangzhou, Peoples R China.
   [Song, Xulin] Nanjing Univ Sci & Technol, Coll Comp Sci & Engn, Nanjing, Peoples R China.
   [Sun, Junfeng] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai, Peoples R China.
C3 Hangzhou Dianzi University; Nanjing University of Science & Technology;
   Shanghai Jiao Tong University
RP Kong, WZ (corresponding author), Hangzhou Dianzi Univ, Coll Comp Sci, Hangzhou, Peoples R China.; Sun, JF (corresponding author), Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai, Peoples R China.
EM kongwanzeng@hdu.edu.cn; jfsun@sjtu.edu.cn
RI ; Sun, Junfeng/D-1590-2010
OI Kong, Wanzeng/0000-0002-0113-6968; Sun, Junfeng/0000-0002-7614-7127
FU National Natural Science Foundation of China [U1909202, U20B2074];
   Science and Technology Program of Zhejiang Province [2018C04012,
   2017C33049]; Key Laboratory of Brain Machine Collaborative Intelligence
   of Zhejiang Province [2020E10010]
FX This research was supported by National Natural Science Foundation of
   China (Grant nos. U1909202 and U20B2074), Science and Technology Program
   of Zhejiang Province (2018C04012, 2017C33049), Key Laboratory of Brain
   Machine Collaborative Intelligence of Zhejiang Province (2020E10010).
CR Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   [Anonymous], 2010, PRINCIPAL COMPONENT, DOI DOI 10.1007/B98835
   [Anonymous], 2001, LIBSVM LIB SUPPORT V
   Bhagwat AR, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P366, DOI 10.1109/CAST.2016.7914996
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming, P1
   Candra H, 2015, IEEE ENG MED BIO, P6030, DOI 10.1109/EMBC.2015.7319766
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chang A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00327
   Chao H, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/9750904
   Christie IC, 2004, INT J PSYCHOPHYSIOL, V51, P143, DOI 10.1016/j.ijpsycho.2003.08.002
   Chung SY, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1768
   Costa T, 2006, NEUROSCI LETT, V406, P159, DOI 10.1016/j.neulet.2006.06.039
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Gonuguntla V, 2016, IEEE ENG MED BIO, P4515, DOI 10.1109/EMBC.2016.7591731
   Gonuguntla V, 2015, IEEE ENG MED BIO, P2896, DOI 10.1109/EMBC.2015.7318997
   Huang H., 2019, IEEE IC COMP COM NET
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Huang YR, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2107451
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Kim MK, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/573734
   Koelstra S., 2012, DEAP DATASET
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Kong WZ, 2017, NEUROCOMPUTING, V219, P474, DOI 10.1016/j.neucom.2016.09.057
   Lee YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095415
   Li Mu, 2009, Annu Int Conf IEEE Eng Med Biol Soc, V2009, P1323, DOI 10.1109/IEMBS.2009.5334139
   LIN YP, 2009, IEEE T BIO-MED ENG
   Liu Y., 2013, T COMPUTATIONAL SCI, P101
   Liu YS, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P302, DOI 10.1109/CW.2013.52
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Miskovic V, 2010, BRAIN RES, V1362, P102, DOI 10.1016/j.brainres.2010.09.102
   Moriguchi Y, 2014, SOC COGN AFFECT NEUR, V9, P591, DOI 10.1093/scan/nst030
   Plutchik Robert, 2003, EM LIF PERSP PSYCH E
   Rahman MA, 2020, EGYPT INFORM J, V21, P23, DOI 10.1016/j.eij.2019.10.002
   RUSSELL JA, 1979, J PERS SOC PSYCHOL, V37, P345, DOI 10.1037/0022-3514.37.3.345
   SCHELLBERG D, 1990, INT J PSYCHOPHYSIOL, V9, P279, DOI 10.1016/0167-8760(90)90060-Q
   Shin Y, 2015, COMPUT BIOL MED, V66, P29, DOI 10.1016/j.compbiomed.2015.08.017
   Shin Y, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056002
   Sun JF, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/239210
   Sun JF, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046219
   Surguladze SA, 2012, TRANSL PSYCHIAT, V2, DOI 10.1038/tp.2011.69
   Tang YY, 2011, IEEE ENG MED BIO, P1717, DOI 10.1109/IEMBS.2011.6090492
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu HY, 2016, IEEE INT WORKSH MULT
   Yu H, 2010, IEEE ENG MED BIO, P2439, DOI 10.1109/IEMBS.2010.5626084
   Zheng W. L., 2016, ARXIV160102197
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 49
TC 7
Z9 7
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21203
EP 21217
DI 10.1007/s11042-021-10716-3
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628487800001
DA 2024-07-18
ER

PT J
AU Zheng, J
   Hu, HP
AF Zheng, Jun
   Hu, Hanping
TI A symmetric image encryption scheme based on hybrid analog-digital
   chaotic system and parameter selection mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic cryptography; Dynamical degradation; Hybrid chaotic system;
   Parameter selection mechanism; Image encryption
AB In recent years, various chaos-based image encryption algorithms have been proposed to meet the growing demand for real-time secure image transmission. However, chaotic system that is the core component of chaos-based cryptosystem usually degrades under finite computing precision, causing many security issues. In this paper, a novel cryptosystem with analog-digital hybrid chaotic model is proposed. Firstly, the analog Chen chaotic system and the digital Logistic map are adopted to depict the capability of the hybrid model, in which analog system is used to perturb digital system. Dynamic analyses demonstrate that the hybrid method has better complexity, larger chaotic parameter range and good ability to counteract dynamical degradation. The chaos-based key streams generated by the perturbed Logistic map are more suitable for image encryption. Secondly, a parameter selection mechanism is introduced to increase security. The state variables of Chen chaotic system and cipher image are involved in parameter selection process to dynamically change the parameter of the perturbed Logistic map. The involvement of cipher image makes the key streams relevant to plain image and can resist known/chosen-plaintext attacks. Performance, security and comparison analyses indicate that this cryptosystem has high security, low time complexity, and ability to resist common attacks.
C1 [Zheng, Jun; Hu, Hanping] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
   [Hu, Hanping] Minist Educ, Key Lab Image Informat Proc & Intelligent Control, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Hu, HP (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.; Hu, HP (corresponding author), Minist Educ, Key Lab Image Informat Proc & Intelligent Control, Wuhan 430074, Peoples R China.
EM zjhh@hust.edu.cn; husthhh@qq.com
FU National Key R&D Program of China [2017YFB0802000]; Cryptography
   Theoretical Research of National Cryptography Development Fund
   [MMJJ20170109]; Key R&D Program of Hubei Province [2020BAB104]
FX This work was supported by the National Key R&D Program of China [grant
   number 2017YFB0802000]; and the Cryptography Theoretical Research of
   National Cryptography Development Fund [grant number MMJJ20170109]; and
   the Key R&D Program of Hubei Province [grant number 2020BAB104].
CR Abdulla A. A., 2015, Ph.D. dissertation
   Alawida M, 2019, NONLINEAR DYNAM, V96, P601, DOI 10.1007/s11071-019-04809-w
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Biswas MR, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102363
   Bouhous A, 2018, OPT LASER TECHNOL, V108, P162, DOI 10.1016/j.optlastec.2018.06.052
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Fu C, 2016, INT J COMPUT SCI ENG, V12, P113
   Gao X., 2019, COMPLEXITY, V2019, P1
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Gong LH, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501424
   Hanis S, 2018, MULTIMED TOOLS APPL, V77, P6897, DOI 10.1007/s11042-017-4606-0
   Hu HP, 2014, COMMUN NONLINEAR SCI, V19, P1970, DOI 10.1016/j.cnsns.2013.10.031
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Lin CY, 2012, SIGNAL PROCESS, V92, P2159, DOI 10.1016/j.sigpro.2012.02.002
   Liu LF, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501036
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Mu Y., 2019, INT J HIGH PERFORM C, V14, P333, DOI [10.1504/IJHPCN.2019.102133, DOI 10.1504/IJHPCN.2019.102133]
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Paar C., 2009, UNDERSTANDING CRYPTO
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Skrobek A, 2007, PHYS LETT A, V363, P84, DOI 10.1016/j.physleta.2006.10.081
   Som S, 2015, NONLINEAR DYNAM, V80, P615, DOI 10.1007/s11071-015-1893-8
   Su YR, 2019, SIGNAL PROCESS-IMAGE, V72, P134, DOI 10.1016/j.image.2018.12.008
   Tang JY, 2019, MULTIMED TOOLS APPL, V78, P24765, DOI 10.1007/s11042-019-7602-8
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang CF, 2018, COMPLEXITY, DOI 10.1155/2018/9818520
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2009, IEEC 2009: FIRST INTERNATIONAL SYMPOSIUM ON INFORMATION ENGINEERING AND ELECTRONIC COMMERCE, PROCEEDINGS, P418, DOI 10.1109/IEEC.2009.93
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang FF, 2019, IEEE ACCESS, V7, P118188, DOI 10.1109/ACCESS.2019.2937126
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zheng J, 2018, NONLINEAR DYNAM, V94, P1535, DOI 10.1007/s11071-018-4440-6
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 56
TC 16
Z9 17
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20883
EP 20905
DI 10.1007/s11042-021-10751-0
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627245100002
DA 2024-07-18
ER

PT J
AU Lin, CY
   Chen, TS
   Chen, JN
   Chen, CY
AF Lin, Chen-Yi
   Chen, Tung-Shou
   Chen, Jeanne
   Chen, Chih-Yu
TI Personalized live streaming channel recommendation based on most similar
   neighbors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live streaming platforms; Recommender systems; Stickiness; Personal
   preferences
AB With the rapid development of mobile network technology, an increasing number of viewers are watching channels through live streaming platforms, and thousands upon thousands of channels are broadcasting on the platforms as well. To create a better user environment, it is required to provide accurate channel recommendation services for viewers. The current channel recommendation method clusters viewers with similar channel preferences into the same group and gives the channel recommendation based on the preferences of all the viewers in the same group. However, viewers in the same group still have slight differences in channel preferences, the recommended channels of the method may not necessarily meet the needs of viewers. To improve the accuracy of channel recommendation, we propose a channel recommendation technique, named n-Most Similar Neighbor algorithm (n-MSN), which considers the preferences of the n viewers with most similar preferences to accurately predict the channels that might be of interest to other viewers. In the experiments, we analyze the currently popular live streaming platform, Twitch; the results confirm that the effectiveness and the efficiency of the n-MSN algorithm are better than those of the existing channel recommendation methods, and the accuracy of the n-MSN algorithm is relatively stable compared with the existing methods.
C1 [Lin, Chen-Yi] Natl Taichung Univ Sci & Technol, Dept Informat Management, Taichung, Taiwan.
   [Chen, Tung-Shou; Chen, Jeanne; Chen, Chih-Yu] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Taichung University of Science & Technology; National Taichung
   University of Science & Technology
RP Chen, JN (corresponding author), Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM cylin@nutc.edu.tw; tschen@nutc.edu.tw; jeanne@nutc.edu.tw;
   s1810632013@gms.nutc.edu.tw
FU Ministry of Science and Technology of Republic of China [MOST
   107-2221-E-025-008, MOST 108-2221-E-025-007]
FX This work was supported by the Ministry of Science and Technology of
   Republic of China under grant MOST 107-2221-E-025-008 and MOST
   108-2221-E-025-007.
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Das M, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P203
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Dimopoulos C, 2000, IEEE T EVOLUT COMPUT, V4, P93, DOI 10.1109/4235.850651
   Dong X, 2017, AAAI CONF ARTIF INTE, P1309
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Huang JL, 2015, INT C CONS EL TAIW
   Jain Gourav, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P343, DOI 10.1007/978-981-15-0751-9_32
   Jooa J, 2016, PROCEDIA COMPUT SCI, V91, P944, DOI 10.1016/j.procs.2016.07.115
   Karkali M, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1117
   Kim E, 2011, IEEE T BROADCAST, V57, P674, DOI 10.1109/TBC.2011.2161409
   Kim S-W, 2015, 9 INT C UB INF MAN C, V60, P1
   KING JR, 1980, INT J PROD RES, V18, P213, DOI 10.1080/00207548008919662
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Kotiloglu S, 2017, TOURISM MANAGE, V62, P76, DOI 10.1016/j.tourman.2017.03.005
   Lin CY, 2019, MULTIMED TOOLS APPL, V78, P1999, DOI 10.1007/s11042-018-6323-8
   Onuma K, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P657
   Tewari AS, 2018, EXPERT SYST APPL, V97, P70, DOI 10.1016/j.eswa.2017.12.019
   Xu M, 2013, 7 ACM C REC SYST, P285
   Yang TW, 2013, CONF TECHNOL APPL, P188, DOI 10.1109/TAAI.2013.46
   Yang Y, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
   Zhou W, 2019, INFORM PROCESS MANAG, V56, P955, DOI 10.1016/j.ipm.2019.02.002
NR 25
TC 0
Z9 0
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19867
EP 19883
DI 10.1007/s11042-021-10684-8
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000624399500005
DA 2024-07-18
ER

PT J
AU Evangelin, LN
   Fred, AL
AF Evangelin, L. Nisha
   Fred, A. Lenin
TI Securing recognized multimodal biometric images using cryptographic
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometric images; Cryptographic; ECC; Multiple shares; VSC
ID VISUAL CRYPTOGRAPHY; AUTHENTICATION; FINGERPRINT; FUSION; ALGORITHM;
   SCHEME; FACE
AB The security of recognized biometric images keeps sensitive data from the vindictive behavior in transmission. An optional technique to guarantee the secrecy and abnormal state of security is cryptography. The protection of biometrics images raises significant worries, specifically if calculations over biometric information are performed at untrusted servers. In our previous work, the multimodal biometric images are recognized dependent on optimal features. To ensure these recognized images, a cryptographic strategy is proposed in this investigation. At first, the recognized images are given to the progressive cryptographic method which is utilized to the secret image is shared safely and furthermore, its data is kept up with the most extreme classification. In this research work, various shadows have been produced from one image with the assistance of the Visual Shadow Creation (VSC) Process. The different shadows are utilized to move the secret image by utilizing the encryption and decoding process by methods for Elliptic Curve Cryptography (ECC). The proposed method offers better security for shadows and reduced the fraudulent shares of the secret image. The performance investigation of the proposed cryptographic demonstrates the high security, adequacy, and power compared with existing cryptographic algorithms. The abovementioned systems are actualized in MATLAB programming.
C1 [Evangelin, L. Nisha] Sathyabama Univ, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Fred, A. Lenin] Mar Ephraem Coll Engn & Technol, Marthandam, India.
C3 Sathyabama Institute of Science & Technology
RP Evangelin, LN (corresponding author), Sathyabama Univ, Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM nishaevangelin0187@gmail.com
RI Fred, Lenin/AAU-9556-2021
OI FRED, A.LENIN/0000-0002-6551-4796
CR Abdolrahimpour H, 2017, INT ADV RES J SCI EN, V4, P58, DOI [10.17148/IARJSET.2017.4313, DOI 10.17148/IARJSET.2017.4313]
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abualigah LMQ., 2019, FEATURE SELECTION EN, DOI 10.1007/978-3-030-10674-4
   Ali Z, 2018, FUTURE GENER COMP SY, V85, P76, DOI 10.1016/j.future.2018.02.040
   Allaoui M, 2018, EXPERT SYST APPL, V102, P44, DOI 10.1016/j.eswa.2018.02.018
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bedi P, 2012, PROC TECH, V4, P612, DOI 10.1016/j.protcy.2012.05.098
   Chang JJY, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2030024
   Dixit S, 2014, INT CONF COMM SYST, P847, DOI 10.1109/CSNT.2014.176
   Evangelin LN, 2019, MULTIMED TOOLS APPL, V78, P31077, DOI 10.1007/s11042-019-07918-1
   Gupta D, 2018, COMPUT ELECTR ENG, V68, P412, DOI 10.1016/j.compeleceng.2018.04.014
   Gupta S, 2019, COMPUT SECUR, V83, P122, DOI 10.1016/j.cose.2019.01.007
   Haddada LR, 2017, SIGNAL PROCESS-IMAGE, V55, P23, DOI 10.1016/j.image.2017.03.008
   Hamidi H, 2019, FUTURE GENER COMP SY, V91, P434, DOI 10.1016/j.future.2018.09.024
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Khan MK, 2008, NEUROCOMPUTING, V71, P3026, DOI 10.1016/j.neucom.2007.12.017
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li P, 2017, SOFT COMPUT, V21, P4349, DOI 10.1007/s00500-016-2066-5
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Malan DJ, 2004, 2004 FIRST ANNUAL IEEE COMMUNICATIONS SOCIETY CONFERENCE ON SENSOR AND AD HOC COMMUNICATIONS AND NETWORKS, P71, DOI 10.1109/SAHCN.2004.1381904
   Pavesic N, 2006, STUD CLASS DATA ANAL, P630, DOI 10.1007/3-540-31314-1_77
   Saevanee H, 2015, COMPUT SECUR, V53, P234, DOI 10.1016/j.cose.2015.06.001
   Sarier ND, 2017, LECT NOTES COMPUT SC, V10232, P90, DOI 10.1007/978-3-319-57186-7_8
   Sarier ND, 2018, FUTURE GENER COMP SY, V80, P112, DOI 10.1016/j.future.2017.09.078
   Sasaki M, 2018, IEEE T INF FOREN SEC, V13, P356, DOI 10.1109/TIFS.2017.2750104
   Saudy NF, 2019, AIN SHAMS ENG J, V10, P587, DOI 10.1016/j.asej.2018.11.007
   Shankar K, 2017, CHINA COMMUN, V14, P118, DOI 10.1109/CC.2017.7868160
   Shankar K, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501383
   Sujatha E, 2018, WIRELESS PERS COMMUN, V99, P23, DOI 10.1007/s11277-017-5034-1
   Vidya BS, 2019, ALEX ENG J, V58, P103, DOI 10.1016/j.aej.2018.12.008
   Walia GS, 2019, EXPERT SYST APPL, V116, P364, DOI 10.1016/j.eswa.2018.08.036
   Wang F, 2009, OPTO-ELECTRON REV, V17, P59, DOI 10.2478/s11772-008-0054-8
   Xiang C, 2016, SOFT COMPUT, V20, P3735, DOI 10.1007/s00500-015-1759-5
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
NR 41
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18735
EP 18752
DI 10.1007/s11042-021-10541-8
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400006
DA 2024-07-18
ER

PT J
AU Pei, BY
   Peng, Y
   Luo, Y
AF Pei, Baoying
   Peng, Yu
   Luo, Yong
TI A method of detecting defects of smart meter LCD screen based on LSD and
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LCD; LSD; CNN; Template matching; Electric quantity identification
AB In order to detect the defects of smart meter liquid crystal display (LCD) screen quickly and accurately, this paper proposes a method based on line segment detector (LSD) and deep learning. Characters of smart meter LCD screen can be divided into two types: ordinary characters and digital tube characters. Convolutional neural network (CNN) is used to locate and identify the ordinary characters. Since there may be certain missing segment in digital tube characters, conventional text detection methods are not applicable, and template matching method is used for detecting them. Compared with the whole screen, the digital tube area is very small, and the relative positions of the digital tube characters of smart meter of most manufacturers are nearly the same, so the detection rate of the template matching method is extremely high and the method can be commonly used. The whole detection process is as follows: First, horizontal straight lines got by LSD are used for tilt correction. Secondly, CNN is used to locate and identify an ordinary character of the meter screen to determine whether it is missing or not. Then, whether there are missing segments in the digital tube area is determined by template matching method. At last, the experimental results show that the accuracy of the method for detecting the character defects of LCD screen is about 96%, and the accuracy of the electric quantity identification function of the method is about 97%.
C1 [Pei, Baoying; Peng, Yu; Luo, Yong] Zhengzhou Univ, Coll Elect Engn, Zhengzhou 450001, Peoples R China.
C3 Zhengzhou University
RP Luo, Y (corresponding author), Zhengzhou Univ, Coll Elect Engn, Zhengzhou 450001, Peoples R China.
EM luoyong@zzu.edu.cn
RI LUO, YONG/AAN-5732-2020
OI LUO, YONG/0000-0002-9901-5805
CR Al Mahmud N., 2020, INT J MULTIMEDIA APP, V12, P17, DOI [10.5121/ijma.2020.12402, DOI 10.5121/IJMA.2020.12402]
   Cha YJ, 2016, AUTOMAT CONSTR, V71, P181, DOI 10.1016/j.autcon.2016.06.008
   Chen L, 2018, 2018 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MACHINE LEARNING (SPML 2018), P166, DOI 10.1145/3297067.3297073
   Chunlei R, 2013, RES ENERGY METER DET
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guiping D, 2015, LECT NOTES ELECT ENG, P197
   He Bei, 2014, Electrical Measurement and Instrumentation, V51, P25
   Hongyi J, 2017, COMP KNOWL TECHNOL, P213
   Kiranyaz S, 2020, NEUROCOMPUTING, V411, P291, DOI 10.1016/j.neucom.2020.05.063
   Li WC, 2011, IEEE T IND INFORM, V7, P136, DOI 10.1109/TII.2009.2034844
   Min YZ, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0241-y
   Neogi N, 2014, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2014-50
   SAHA S, 2011, PLOS ONE
   Sharma H, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920503157
   Sheng W, 2019, DESIGN IMPLEMENTATIO
   Shengcheng W, 2018, MACHINE VISION INSPE
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Song R, 2018, J PHYS C SER
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Tong W, 2020, RES INTELLIGENT DETE
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang W, 2009, 2009 2 INT C IM SIGN, P1
   Wojna Z, 2017, PROC INT CONF DOC, P844, DOI 10.1109/ICDAR.2017.143
   Xie Gang, 2015, Computer Engineering and Applications, V50, P247, DOI 10.3778/j.issn.1002-8331.1203-0401
   Yang Na, 2014, Journal of Information Engineering University, V15, P215, DOI 10.3969/j.issn.1671-0673.2014.02.015
   Yang SW, 2014, OPTIK, V125, P2671, DOI 10.1016/j.ijleo.2013.11.070
   Yang YY, 2021, NEUROCOMPUTING, V419, P108, DOI 10.1016/j.neucom.2020.07.110
   Yongqing C., 2014, TOOL ENG, V12, P77
   Yu P, 2019, METHOD DETECTING DEF
NR 29
TC 4
Z9 5
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35955
EP 35972
DI 10.1007/s11042-020-10481-9
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000617861300001
DA 2024-07-18
ER

PT J
AU Altay, SY
   Ulutas, G
AF Altay, Seyma Yucel
   Ulutas, Guzin
TI Self-adaptive step firefly algorithm based robust watermarking method in
   DWT-SVD domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Robustness; DWT; SVD; Self-adaptive step firefly
   algorithm; Fibonacci-Lucas transform
ID DISCRETE WAVELET TRANSFORM; IMAGE WATERMARKING; SCHEME
AB Digital image watermarking, a data hiding method has become widespread to prohibit illegal use of personal files lately. In this study, a robust Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) based technique is proposed for copyright protection. The cover image is firstly decomposed into sub-bands by DWT. Low frequency sub-band is then divided into non-overlapping blocks. Blocks where watermark will be embedded are selected depending on their standard deviation values. Selected blocks are transformed to U, S, and V matrices by SVD. Watermark is embedded into the second row value in the first column of U component obtained by SVD. Embedding scaling factor is determined by Self-Adaptive Step Firefly Algorithm (SASFA) to balance robustness and transparency that are contradictory to each other. Firefly Algorithm (FA) is a simple, easy to implement, and flexible algorithm but it can pass over the global optimum or get trapped at local optimum. Therefore, SASFA, which constitutes the next step of each firefly based on its previous and present situations is used for global exploration of the solution space. Fibonacci-Lucas Transform (FLT) is applied to binary watermark to provide the security of watermarking scheme. Achieved scrambled watermark bits are used in embedding process. Performance of the proposed scheme is measured by using Bit Error Rate (BER), Normalized Correlation (NC), and Peak Signal-to-Noise Ratio (PSNR). Experimental results prove that the method has high robustness level against attacks and a good visual quality.
C1 [Altay, Seyma Yucel] Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkey.
   [Ulutas, Guzin] Karadeniz Tech Univ, Fac Engn, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Ataturk University; Karadeniz Technical University
RP Altay, SY (corresponding author), Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkey.
EM seyma.yucel@atauni.edu.tr; gulutas@ktu.edu.tr
RI yucel, seyma/ABC-3890-2021; Ulutas, Guzin/ABI-4484-2020
OI YUCEL ALTAY, Seyma/0000-0002-7460-3993
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Ali ES, 2015, NEURAL COMPUT APPL, V26, P1321, DOI 10.1007/s00521-014-1796-5
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Altay SY, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P1, DOI [10.1109/UBMK.2019.8907217, 10.1109/ubmk.2019.8907217]
   Ansari IA, 2018, ARAB J SCI ENG, V43, P4085, DOI 10.1007/s13369-017-2777-7
   Ansari IA, 2016, ADV INTELL SYST COMP, V437, P411, DOI 10.1007/978-981-10-0451-3_38
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Aslantas V, 2009, ADV ELECT ENG COMPUT, P147
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Giri Kaiser J, 2015, IJ IMAGE GRAPH SIGNA, P47
   Gunjal BaisaL., 2010, Journal of Emerging Trends in Computing and Information Sciences, V2, P37
   Gupta G, 2015, INT CONF CONTEMP, P70, DOI 10.1109/IC3.2015.7346655
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Ijyas VPT, 2014, WIRELESS PERS COMMUN, V79, P565, DOI 10.1007/s11277-014-1873-1
   Jun Zhang, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1356, DOI 10.1109/ICMLC.2012.6359562
   Kaur R, 2015, WIRELESS PERS COMMUN, V80, P1547, DOI 10.1007/s11277-014-2099-y
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Kumar S, 2012, ARXIV1210591
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei M., 2012, INT J DIGIT CONTENT, V6, P255, DOI [10.4156/jdcta.vol6.issue21.29, DOI 10.4156/JDCTA.VOL6.ISSUE21.29]
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Loukhaoukha K, 2013, J OPTIM, V2013, DOI 10.1155/2013/921270
   Loukhaoukha K, 2009, 2009 11TH CANADIAN WORKSHOP ON INFORMATION THEORY, P177, DOI 10.1109/CWIT.2009.5069549
   Luo HJ, 2011, RADIOENGINEERING, V20, P525
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mingzhi C., 2013, J MULTIMED, V8, P299
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patel M, 2013, INT J ADV RES COMPUT, V3
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rahebi J, 2016, MED BIOL ENG COMPUT, V54, P453, DOI 10.1007/s11517-015-1330-7
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   Yang X. S., 2008, Nature-Inspired Metaheuristic Algorithms, DOI DOI 10.1001/JAMA.1994.03520100096046
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yu SH, 2013, J APPL MATH, DOI 10.1155/2013/832718
   Zhang LN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163230
   [周亚训 ZHOU Yaxun], 2011, [光电工程, Opto-Electronic Engineering], V38, P80
NR 45
TC 13
Z9 14
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23457
EP 23484
DI 10.1007/s11042-020-10251-7
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000615174300011
DA 2024-07-18
ER

PT J
AU Lu, ZH
   Yan, Y
   Wang, SH
AF Lu, Zhihai
   Yan, Yan
   Wang, Shui-Hua
TI CMB-net: a deep convolutional neural network for diagnosis of cerebral
   microbleeds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cerebral microbleed; Susceptibility-weighted image; Computer aided
   diagnosis; Convolutional neural network
ID COMPUTER-AIDED DETECTION
AB Cerebral microbleed (CMB) is related to cerebral vascular diseases. In this paper, we propose the use of deep convolutional neural network to implement CMB automatic diagnosis based on brain susceptibility-weighted images (SWIs). First of all, a sliding neighborhood method was employed to get 13,031 samples for training and testing. Then, an 18-layer CMB-Net was designed to classify the samples as CMB or non-CMB. The CMB-Net was trained by RMSprop based on the five-fold cross- validation. The total running time of the five-fold cross-validation was merely 184.79 s, and the average testing accuracy reached 98.39%, which was better than several recently published methods. The results suggested that our CMB-Net was accurate in detecting CMB.
C1 [Lu, Zhihai] Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.
   [Yan, Yan; Wang, Shui-Hua] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
C3 Nanjing Normal University; University of Leicester
RP Wang, SH (corresponding author), Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
EM luzhihai@njnu.edu.cn; yanyan899@outlook.com; shuihuawang@ieee.org
RI Wang, shuihua/G-7326-2016
OI Wang, shuihua/0000-0003-4713-2791
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); British Heart Foundation Accelerator Award, UK;
   Fundamental Research Funds for the Central Universities [CDLS-2020-03];
   Key Laboratory of Child Development and Learning Science (Southeast
   University), Ministry of Education
FX The paper is supported by Priority Academic Program Development of
   Jiangsu Higher Education Institutions (PAPD), British Heart Foundation
   Accelerator Award, UK; Fundamental Research Funds for the Central
   Universities (CDLS-2020-03); Key Laboratory of Child Development and
   Learning Science (Southeast University), Ministry of Education.
CR Barnes SRS, 2011, MAGN RESON IMAGING, V29, P844, DOI 10.1016/j.mri.2011.02.028
   Bian W, 2013, NEUROIMAGE-CLIN, V2, P282, DOI 10.1016/j.nicl.2013.01.012
   Chen YC, 2019, J DIGIT IMAGING, V32, P766, DOI 10.1007/s10278-018-0146-z
   Fazlollahi A, 2015, COMPUT MED IMAG GRAP, V46, P269, DOI 10.1016/j.compmedimag.2015.10.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinz P, 2019, IEEE T INFORM THEORY, V65, P7304, DOI 10.1109/TIT.2019.2927252
   Hong J, 2019, MACH VISION APPL, V30, P1123, DOI 10.1007/s00138-019-01029-5
   Hong J, 2020, MULTIMED TOOLS APPL, V79, P15151, DOI 10.1007/s11042-018-6862-z
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuijf HJ, 2012, NEUROIMAGE, V59, P2266, DOI 10.1016/j.neuroimage.2011.09.061
   Momeny M, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111204
   Reddy RVK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P45, DOI 10.1109/ICCONS.2018.8662969
   Ruder S., 2016, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2019, J MED IMAG HEALTH IN, V9, P2012, DOI 10.1166/jmihi.2019.2692
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2016, INT C PAR DISTRIB SY, P1229, DOI [10.1109/ICPADS.2016.164, 10.1109/ICPADS.2016.0166]
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2009, SENSORS-BASEL, V9, P7516, DOI 10.3390/s90907516
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
NR 31
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19195
EP 19214
DI 10.1007/s11042-021-10566-z
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000615174300005
DA 2024-07-18
ER

PT J
AU Zhu, XD
   Li, YF
   Sun, J
   Chen, HJ
   Zhu, JL
AF Zhu, Xiaodi
   Li, Yanfeng
   Sun, Jia
   Chen, Houjin
   Zhu, Jinlei
TI Unsupervised domain adaptive person re-identification via camera penalty
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Unsupervised domain adaptive; Camera penalty
AB Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to adapt the model trained on a labeled source domain to an unlabeled target domain. For pseudo-label-based UDA methods, pseudo label noise is the main problem for model degradation and cross-camera problem is one main factor to cause this noise. In this paper, a novel camera penalty learning (CPL) UDA person re-ID method is proposed to address this problem. The possibility of selecting wrong negative sample and positive sample is relatively high in conventional triplet loss due to cross-camera problem. To alleviate this problem, a camera-penalty-based triplet loss (PTL) is designed. It adds camera-ID-penalty to conventional triplet loss to reduce sample distance imbalance, thereby improving the quality of pseudo labels. In order to reduce the dependence on pseudo labels and improve the robustness, a camera-penalty-neighborhood loss (PNL) is designed and combined with the push loss (PL). The PNL minimizes the distance between one image and its camera-penalty-weighted neighbors. The PL maximizes the distances among all images. The proposed CPL model achieves considerable results of 87.4%/70.7% and 75.2%/59.0% Rank-1/ mAP on DukeMTMC-reID-to-Market-1501 and Market-1501-to-DukeMTMC-reID UDA tasks.
C1 [Zhu, Xiaodi; Li, Yanfeng; Sun, Jia; Chen, Houjin; Zhu, Jinlei] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Zhu, Jinlei] Synth Elect Technol Co Ltd, Jinan, Peoples R China.
C3 Beijing Jiaotong University
RP Li, YF (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM yf.li@bjtu.edu.cn
RI Zhu, Jinlei/AAL-1886-2020
OI Zhu, Xiaodi/0000-0002-1322-7269
FU National Nature Science Foundation of China [61872030]; Major Science
   and Technology Innovation Project of Shandong Province [2019TSLH0206]
FX This study was funded by the National Nature Science Foundation of China
   [grant number 61872030] and Major Science and Technology Innovation
   Project of Shandong Province [grant number 2019TSLH0206].
CR Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge Yixiao, 2020, ARXIV200306650
   Genç A, 2019, MULTIMED TOOLS APPL, V78, P5843, DOI 10.1007/s11042-018-6409-3
   Hermans Alexander, 2017, ARXIV170307737
   Li H-S, 2020, 2020 INT C LEARN REP
   Li K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1492, DOI 10.1145/3240508.3240674
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu JL, 2019, IEEE ACCESS, V7, P114021, DOI 10.1109/ACCESS.2019.2933910
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Ren CX, 2020, IEEE T INF FOREN SEC, V15, P1290, DOI 10.1109/TIFS.2019.2939750
   Shao J, 2020, 2020 EUR C COMP VIS
   Shen C, 2019, IEEE T CIRC SYST VID, V29, P3016, DOI 10.1109/TCSVT.2018.2872503
   Sikdar A, 2020, PATTERN RECOGN LETT, V129, P279, DOI 10.1016/j.patrec.2019.11.032
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Xian YQ, 2018, IET COMPUT VIS, V12, P1219, DOI 10.1049/iet-cvi.2018.5103
   Xie GS, 2020, IEEE T NEUR NET LEAR, V31, P4290, DOI 10.1109/TNNLS.2019.2953675
   Xie GS, 2017, IEEE T CIRC SYST VID, V27, P1263, DOI 10.1109/TCSVT.2015.2511543
   Yang F, 2021, IEEE J EM SEL TOP P, V9, P4026, DOI 10.1109/JESTPE.2020.2970335
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 37
TC 3
Z9 3
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15215
EP 15232
DI 10.1007/s11042-021-10589-6
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613993900005
DA 2024-07-18
ER

PT J
AU Ulutas, G
   Ustubioglu, B
AF Ulutas, Guzin
   Ustubioglu, Beste
TI Underwater image enhancement using contrast limited adaptive histogram
   equalization and layered difference representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CLAHE; LDR; Contrast correction; Color correction
ID COLOR CORRECTION
AB Underwater images, which have low contrast and visibility as a result of selective attenuation based on the wavelength of the light passing through water, needs some corrections to extract meaningful information from them. In this paper, we aim to combine two different approaches; global and local contrast enhancement techniques, to obtain better visual quality while enhancing image contrasts on underwater images. While global technique (LDR) ensures the overall enhancement of the image, local technique (CLAHE) considers local brightness features of the image in RGB color space. The proposed method also applies local color correction on underwater image. While methods in the literature apply various approaches on the global histogram of channels, our method divides underwater image into non-overlapping sub-blocks and apply histogram equalization on them. The method uses HSV color space and especially S, V components for color correction. The results of the qualitative analysis show that it produces very good images, in contrast, color, and detail compared to other enhancement methods. The proposed method also decreases the effect of under- and over-enhanced areas and the blue-green effect on the output image. However, the visibility of the objects in the images are increased by color correction. For quantitative analysis, the proposed method produces the highest average value of entropy (7.83), EMEE (32.06), EME (40.97), average gradient (152.55), and Sobel count (130393) for 200 underwater images.
C1 [Ulutas, Guzin; Ustubioglu, Beste] Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
C3 Karadeniz Technical University
RP Ustubioglu, B (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
EM guzin@ieee.org; bustubioglu@ktu.edu.tr
RI USTUBIOGLU, Beste/AAJ-8187-2021; Ulutas, Guzin/ABI-4484-2020
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   [Anonymous], 2015, INT J COMPUTER APPL
   [Anonymous], 2009, Int. J. Graphics Vis. Image Process. (GVIP)
   Çelebi AT, 2012, EXPERT SYST APPL, V39, P800, DOI 10.1016/j.eswa.2011.07.077
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Eustice R, 2002, PROCEEDINGS OF THE 2002 INTERNATIONAL SYMPOSIUM ON UNDERWATER TECHNOLOGY, P141, DOI 10.1109/UT.2002.1002415
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   GORDON HR, 1989, LIMNOL OCEANOGR, V34, P1389, DOI 10.4319/lo.1989.34.8.1389
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Iqbal K., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P1703, DOI 10.1109/ICSMC.2010.5642311
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Le, 2019, J COMPUTER VISION IM
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lei J., 2018, IEEE T CIRCUITS SYST
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li L., 2017, J OPT, P121
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Sun LH, 2020, INT GEOL REV, V62, P1094, DOI 10.1080/00206814.2019.1669079
   Trung-Nghia Le, 2014, Virtual, Augmented and Mixed Reality. Applications of Virtual and Augmented Reality. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8526, P51, DOI 10.1007/978-3-319-07464-1_5
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   Wu J, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATIONS, VOLS 1-4, CONFERENCE PROCEEDINGS, P1817
   Xi Qiao, 2017, Information Processing in Agriculture, V4, P206, DOI 10.1016/j.inpa.2017.06.001
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 41
TC 29
Z9 32
U1 6
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15067
EP 15091
DI 10.1007/s11042-020-10426-2
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000001
DA 2024-07-18
ER

PT J
AU Escobar, JJM
   Matamoros, OM
   Reyes, IL
   Padilla, RT
   Hernández, LC
AF Escobar, Jesus Jaime Moreno
   Matamoros, Oswaldo Morales
   Reyes, Ixchel Lina
   Padilla, Ricardo Tejeida
   Hernandez, Liliana Chanona
TI Defining a no-reference image quality assessment by means of the
   self-affine analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Self-affine analysis; Signal processing;
   Wavelet transform
AB In this paper we propose a novel Blind Image Quality Assessment via Self-Affine Analysis (BIQSAA) method by considering the wavelet transform as a linear operation that decomposes a complex signal into elementary blocks at different scales or resolutions. BIQSAA decomposes a distorted image into a set of wavelet planes omega(lambda, phi) of different spatial frequencies lambda and spatial orientations phi, and it transforms these wavelet planes into one-dimension vector omega using a Hilbert scanning. From the vector omega there were obtained their wavelet coefficient fluctuations estimated by the inverse of the Hurst exponent in decibels, whose scaling-law or fractal behavior was obtained by applying Fractal Geometry or Self-Affine Analysis. The scaling exponents calculated for the coefficient fluctuation behavior of Image Lena at 24bpp, at 1.375bpp, and at 0.50bpp were H-24bpp = 0.0395, H-1.375bpp = 0.0551, and H-0.50bpp = 0.0612, respectively. Our experiments show that BIQSAA algorithm improves in 14.36% the Human Visual System correlation, respect to the four state-of-the-art No-Reference Image Quality Assessments.
C1 [Escobar, Jesus Jaime Moreno; Matamoros, Oswaldo Morales; Reyes, Ixchel Lina; Hernandez, Liliana Chanona] Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Zacatenco, Mexico City, DF, Mexico.
   [Padilla, Ricardo Tejeida] Inst Politecn Nacl, Escuela Super Turismo, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico; Instituto Politecnico Nacional
   - Mexico
RP Escobar, JJM (corresponding author), Inst Politecn Nacl, Escuela Super Ingn Mecan & Elect, Unidad Zacatenco, Mexico City, DF, Mexico.
EM jemoreno@esimez.mx
RI TEJEIDA-PADILLA, RICARDO/AFB-6216-2022; Moreno Escobar, Jesus
   Jaime/Y-1886-2019
OI Moreno Escobar, Jesus Jaime/0000-0003-4032-0511
FU Instituto Poliecnico Nacional ofMexico [20200638, 20200324, 20202061];
   Consejo Nacional de Ciencia y Tecnologia of Mexico; Secreteria de
   Investigacion y Posgrado
FX This article is supported by Instituto Poliecnico Nacional ofMexico by
   means of projects No. 20200638, 20200324, and 20202061 and granted by
   Secreteria de Investigacion y Posgrado, and Consejo Nacional de Ciencia
   y Tecnologia of Mexico. The research described in this work was carried
   out at Escuela Superior de Ingenieria Mecanica y Electrica of the
   Instituto Politecnico Nacional, Campus Zacatenco. The authors of this
   article thank Lic. Pedro Arrechea Alfaro (Head of the Human Resources
   Department) the for his support in carrying it out.
CR BB, 1999, MULTIFRACTALS 1 F NO
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Hong GS, 2016, MULTIMED TOOLS APPL, V75, P15229, DOI 10.1007/s11042-015-2455-2
   Kavitha S, 2017, SOFT COMPUT, V21, P3307, DOI 10.1007/s00500-015-2009-6
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moreno J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061442
   Park D-J., 2003, FAST IMAGE SEGMENTAT, DOI [10.1016/S0167-8655(03)00160-0, DOI 10.1016/S0167-8655(03)00160-0]
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Thyagharajan KK, 2018, ADV ELECTR COMPUT EN, V18, P87, DOI 10.4316/AECE.2018.03012
   Wang SQ, 2016, IEEE J EM SEL TOP C, V6, P532, DOI 10.1109/JETCAS.2016.2598756
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang XC, 2020, IET IMAGE PROCESS, V14, P384, DOI 10.1049/iet-ipr.2019.0750
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 17
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14305
EP 14320
DI 10.1007/s11042-020-10245-5
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400008
PM 33500679
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Pandey, C
   Baghel, N
   Dutta, MK
   Srivastava, A
   Choudhary, N
AF Pandey, Chandrasen
   Baghel, Neeraj
   Dutta, Malay Kishore
   Srivastava, Ashish
   Choudhary, Nandlal
TI Machine learning approach for automatic diagnosis of Chlorosis in
   <i>Vigna mungo</i> leaves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agricultural biotechnology; Disease classification; Image processing;
   Chlorosis
ID MOSAIC-INDIA-VIRUS; 1ST REPORT; DISEASES; IDENTIFICATION;
   CLASSIFICATION; SEGMENTATION
AB Viral infection in crops is something that may lead to a huge loss in crop yield as there are no known recovery procedures. Also, at the onset of yellowing in a leaf, no observable changes occur in leaf structure and geometry. Therefore, the manual inspection and diagnosis of such diseases by the framers in agricultural fields are difficult on a large scale. The automatic artificial intelligence-based tool can be used for early-stage diagnosis of viral growth, where the symptoms may be available in certain parts like leaves. An automatic computer vision-based method is proposed for the identification of yellow disease, also called Chlorosis, in a prominent leguminous crop like Vigna mungo. The proposed method involves fully automatic partitioning of plant leaves, followed by feature extraction in the spatial domain and disease prediction using a support vector machine (SVM) learned upon several training samples. The method is entirely automatic and non-destructive which can predict the classification of plant health category with an accuracy rate of 95.69% with low computation complexity. This accuracy and computational complexity can be used in real-time situations for a large scale of Vigna mungo plantation using drones and remote camera.
C1 [Pandey, Chandrasen; Baghel, Neeraj; Dutta, Malay Kishore] Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
   [Srivastava, Ashish; Choudhary, Nandlal] Amity Univ, Amity Inst Virol & Immunol, Noida, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Amity University Noida
RP Dutta, MK (corresponding author), Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
EM developer.chandrasen@gmail.com; nbaghel777@gmail.com;
   malaykishoredutta@gmail.com; assrivastava10@amity.edu;
   nandlalc@gmail.com
RI Choudhary, Nandlal/AAV-2206-2021
OI Choudhary, Nandlal/0000-0002-4914-1643; Pandey,
   Chandrasen/0000-0002-7031-1619; Baghel, Neeraj/0000-0002-0081-6224;
   Dutta, Malay Kishore/0000-0003-2462-737X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Aït-Sahalia Y, 2019, J AM STAT ASSOC, V114, P287, DOI 10.1080/01621459.2017.1401542
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Bashir S., 2012, IOSR J Electron Commun Eng, V2, P31, DOI [10.9790/2834-0263134, DOI 10.9790/2834-0263134]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dhaygude SB., 2013, IJAREEIE, V2, P599
   Dunham, 2006, DATA MINING INTRO AD
   Feng GC, 2003, PATTERN RECOGN, V36, P977, DOI 10.1016/S0031-3203(02)00114-0
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Ghaiwat S.N., 2014, International Journal of Recent Advances in Engineering Technology, V2, P1
   Gohl B., 1982, ALIMENTS BETAIL SOUS
   Hussain M, 2004, PLANT PATHOL, V53, P518, DOI 10.1111/j.1365-3059.2004.01037.x
   India Brand Equity Foundation, 2017, Analysis about Indian agriculture industry, market size, Export &amp; Investment Opportunity
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kagan A, 1998, STAT PROBABIL LETT, V38, P329, DOI 10.1016/S0167-7152(98)00041-8
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kulkarni AH., 2012, Inter J Modern Eng Res, V2, P3661
   Kumar S, 2018, SUSTAIN COMPUTING IN, DOI DOI 10.1016/J.SUSCOM.2018.10.004
   Kumar S, 2017, BIOCATAL AGRIC BIOTE, V11, P183, DOI 10.1016/j.bcab.2017.07.004
   Lu X, 2015, 2015 IEEE INT C AC S
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Meunkaewjinda A, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P513, DOI 10.1109/ECTICON.2008.4600483
   Naimuddin K, 2011, PHYTOPATHOL MEDITERR, V50, P94
   Nanni L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083554
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patil SB., 2011, Int. J. Eng. Technol, V3, P297, DOI DOI 10.7763/IJET.2011.V3.241
   Powers D., 2008, EVALUATION PRECISION
   Qazi J, 2006, PLANT PATHOL, V55, P818, DOI 10.1111/j.1365-3059.2006.01475.x
   Reddy B. V. Bhaskara, 2015, Archives of Phytopathology and Plant Protection, V48, P345, DOI 10.1080/03235408.2014.888874
   Saran S, 2000, INDIAN J ANIM SCI, V70, P526
   Sengar N, 2018, COMPUTING, V100, P1189, DOI 10.1007/s00607-018-0638-1
   Shahid MS, 2012, AUSTRALAS PLANT DIS, V7, P85, DOI 10.1007/s13314-012-0055-9
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Singh Alpna, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P187, DOI 10.1109/IC3A48958.2020.233294
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Tan JH, 2010, INFRARED PHYS TECHN, V53, P120, DOI 10.1016/j.infrared.2009.10.006
   Zhang CL, 2017, INT J AGR BIOL ENG, V10, P74, DOI 10.3965/j.ijabe.20171002.2166
NR 42
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13407
EP 13427
DI 10.1007/s11042-020-10309-6
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300005
DA 2024-07-18
ER

PT J
AU Nguyen, TD
   Le, HD
AF Nguyen, Tuan Duc
   Le, Huu Dung
TI A reversible data hiding scheme based on (5,3) Hamming code using extra
   information on overlapped pixel blocks of grayscale images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Hamming code; Ensemble classifier; High
   capacity; Overlapped pixel block
AB In this paper, we propose a reversible data hiding scheme using (5, 3) Hamming code. A cover image is partitioned into blocks of five pixels. An adjusted (5, 3) Hamming code method is then applied to find a possible modification position in these blocks to conceal message bits. The estimated position is used to determine the started pixel in the next block and this pixel may belong to the current block of pixels. This means that the overlapped pixel blocks are employed in the proposed scheme to hide secret data. As a result, the proposed scheme provides an average embedding payload reaches to 1.2 bits per pixel (bpp). The embedding positions are also utilized as a secret key to protect the hidden message from extracting attacks and extra information in the image recovering process. An original image can be recovered with no error after an extraction process has been completed. The experiment results obtained from 10,000 natural images in BOWS-2 prove that the proposed scheme can achieve a higher embedding rate, better stego-image perceptual quality, and higher security against detection and extraction attacks compared with the existing approaches.
C1 [Nguyen, Tuan Duc; Le, Huu Dung] Hanoi Open Univ, Hanoi, Vietnam.
RP Nguyen, TD (corresponding author), Hanoi Open Univ, Hanoi, Vietnam.
EM nguyenductuan@hou.edu.vn; huudungle@hou.edu.vn
OI DUC TUAN, NGUYEN/0000-0001-5261-271X
FU Hanoi Open University
FX We gratefully acknowledge Hanoi Open University for financial support.
CR Abbasi R, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8981240
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   ABDULLA AA, 2014, STEGANOGRAPHY BASED
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen K, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010051
   Chin-Cheng Chang, 2018, Journal of Software, V13, P1, DOI 10.17706/jsw.13.1.1-17
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Fridrich, 2001, RELIABLE DETECTION L, V27, DOI 10.1145/1232454.1232466
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P763, DOI 10.1007/s11042-016-4230-4
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P115, DOI 10.1007/s11554-017-0674-7
   Kim C, 2015, LECT NOTES COMPUT SC, V9023, P588, DOI 10.1007/978-3-319-19321-2_45
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Liang HY, 2013, J APPL RES TECHNOL, V11, P259, DOI 10.1016/S1665-6423(13)71536-0
   Lin J, 2020, IEEE ACCESS, V8, P21534, DOI 10.1109/ACCESS.2019.2962230
   Liu HH, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0458-z
   Lu TC, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120764
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Wang HY, 2019, IEEE ACCESS, V7, P38337, DOI 10.1109/ACCESS.2019.2906500
   Wang JX, 2019, IEEE ACCESS, V7, P35564, DOI 10.1109/ACCESS.2019.2903079
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang P, 2020, IEEE ACCESS, V8, P28902, DOI 10.1109/ACCESS.2020.2972622
   WU X, 2020, SIGNAL PROCESS, V175
   Wu XT, 2020, MULTIMED TOOLS APPL, V79, P23425, DOI 10.1007/s11042-020-09098-9
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
NR 32
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13099
EP 13120
DI 10.1007/s11042-020-10347-0
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000003
DA 2024-07-18
ER

PT J
AU Selim, GEI
   Hemdan, EE
   Shehata, AM
   El-Fishawy, NA
AF Selim, Gamal Eldin I.
   Hemdan, E. Z. Z. El-Din
   Shehata, Ahmed M.
   El-Fishawy, Nawal A.
TI Anomaly events classification and detection system in critical
   industrial internet of things infrastructure using machine learning
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Industrial control system; Data science; Classification and detection;
   Machine learning; Critical infrastructure; Industrial internet of
   things; Cyber-attacks
AB Industrial Control System is used in the industrial process for reducing the human factor burden and handling the complex industrial system process and communications between them efficiently. Internet of Things (IoT) is the fusion of devices and sensors by an information network to enable new and autonomous capabilities. The integration of IoT with industrial applications known as the Industrial Internet of Things (IIoT). The IIoT is found in several critical infrastructures such as water distribution networks. Nowadays, ICS is vulnerable to using the Internet connection to enable industrial IoT sensors to communicate with each other in Real-Time. Therefore, this paper presents an analytical study of detecting anomalies, malicious activities, and cyber-attacks in a cyber-physical of critical water infrastructure in the IIoT infrastructure. The study uses various machine learning algorithms to classify the anomaly events including several attacks and IIoT hardware failures. A real-world dataset covering 15 anomaly situations of normal system activity was analyzed for the research review of the proposed approach. The test situations involved a wide array of incidents from hardware breakdown to water SCADA device sabotage. To classify the malicious activity, various machine learning methods, such as Logistic Regression (LR), Linear Discriminant Analysis (LDA), k-nearest neighbours (KNN), Naive Bayes (NB), Support Vector Machine (SVM), and Classification and Regression Tree (CART) are used. The results show that CART and NB have the best results for accuracy, precision, recall, and F1-score.
C1 [Selim, Gamal Eldin I.; Hemdan, E. Z. Z. El-Din; Shehata, Ahmed M.; El-Fishawy, Nawal A.] Menoufia Univ, Comp Sci & Engn Deptartment, Fac Elect Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Comp Sci & Engn Deptartment, Fac Elect Engn, Menoufia, Egypt.
EM Gamal.eldin@el-eng.menofia.edu.eg; ezzvip@yahoo.com;
   am.Shehata@el-eng.menofia.edu.eg; nelfishawy@hotmail.com
OI El-Fishawy, Nawal/0000-0001-9098-5541
CR Abbasi M, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/7641073
   Abbasi M, 2020, J GRID COMPUT, V18, P43, DOI 10.1007/s10723-020-09507-1
   Abbasi M, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1617-8
   Adepu S, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P449, DOI 10.1145/2897845.2897855
   Amin S, 2013, IEEE T CONTR SYST T, V21, P1679, DOI 10.1109/TCST.2012.2211874
   Amin S, 2013, IEEE T CONTR SYST T, V21, P1963, DOI 10.1109/TCST.2012.2211873
   [Anonymous], 2020, SIMPLE GUIDE CONFUSI
   Anthi E., 2018, Pulse: An adaptive intrusion detection for the Internet of Things
   Brun O, 2018, COMM COM INF SC, V821, P79, DOI 10.1007/978-3-319-95189-8_8
   Cardenas A. A., 2011, P 6 ACM S INF COMP C, P355, DOI DOI 10.1145/1966913.1966959
   Chen F, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/431047
   Cheng L, 2017, ANN COMPUT SECURITY, P315, DOI 10.1145/3134600.3134640
   Colbert EJM, 2016, Cyber-Security of SCADA and Other Industrial Control Systems, V66
   D'angelo G, 2015, APPL SOFT COMPUT, V36, P408, DOI 10.1016/j.asoc.2015.07.029
   Diro AA, 2018, FUTURE GENER COMP SY, V82, P761, DOI 10.1016/j.future.2017.08.043
   El-Din HE, 2017, STUD BIG DATA, V25, P109, DOI 10.1007/978-3-319-53472-5_5
   Essa YM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1250-4
   Hemdan E.E.-D., 2016, Proceedings of IEEE International Conference on Emerging Technological Trends in Computing, Communications and Electrical Engineering, ICETT 2016, P1
   Hemdan EED, 2013, PROCEEDING 3 INT C A
   Hemdan EE, 2018, LECT NOTE DATA ENG, V14, P39, DOI 10.1007/978-3-319-70688-7_2
   Hindy Hanan, 2019, Computer Security. ESORICS 2018 International Workshops, CyberICPS 2018 and SECPRE 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11387), P3, DOI 10.1007/978-3-030-12786-2_1
   I Selim Gamal Eldin, 2019, MENOUFIA J ELECT ENG, V28, P343
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Laso PM, 2017, DATA BRIEF, V14, P186, DOI 10.1016/j.dib.2017.07.038
   Lin WM, 2020, WIREL NETW, DOI 10.1007/s11276-020-02345-9
   Lippmann RP, 2000, Em: Proceedings-DARPA Information Survivability Conference and Exposition, DISCEX 2000, V2, P12, DOI DOI 10.1109/DISCEX.2000.821506
   Liu X, 2018, IEEE T IND INFORM, V14, P3801, DOI 10.1109/TII.2018.2836150
   Mathur A, 2018, CPSS'18: PROCEEDINGS OF THE 4TH ACM WORKSHOP ON CYBER-PHYSICAL SYSTEM SECURITY, pVIII, DOI 10.1145/3198458.3198468
   Menon VG, 2022, INTERNET THINGS-NETH, V18, DOI 10.1016/j.iot.2020.100213
   Mitchell R, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2542049
   Pahl MO, 2018, INT CONF NETW SER, P72
   Pajouh NH, 2019, IEEE T EMERG TOP COM, V7, P314, DOI 10.1109/TETC.2016.2633228
   Randhawa K, 2018, IEEE ACCESS, V6, P14277, DOI 10.1109/ACCESS.2018.2806420
   Sheppard K, 2012, INTRO PYTHON ECONOME
   Shon T, 2007, INFORM SCIENCES, V177, P3799, DOI 10.1016/j.ins.2007.03.025
NR 36
TC 23
Z9 24
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12619
EP 12640
DI 10.1007/s11042-020-10354-1
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100009
DA 2024-07-18
ER

PT J
AU Li, LL
   Ma, HB
   Jia, ZH
   Si, YJ
AF Li, Liangliang
   Ma, Hongbing
   Jia, Zhenhong
   Si, Yujuan
TI A novel multiscale transform decomposition based multi-focus image
   fusion framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiscale transform; Multi-focus image fusion; NSCT; Difference image;
   Energy of the gradient
ID ENHANCEMENT; ROBUST; FILTER; MODEL
AB In this work, we propose a novel multiscale transform decomposition model for multi-focus image fusion to get a better fused performance. The motivation of the proposed fusion framework is to make full use of the decomposition characteristics of multiscale transform. The nonsubsampled contourlet transform (NSCT) is firstly used to decompose the source multi-focus images into low-frequency (LF) and several high-frequency (HF) bands to separate out the two basic characteristics of source images, i.e., principal information and edge details. The common "average" and "max-absolute" fusion rules are performed on low- and high-frequency components, respectively, and a basic fusion image is generated. Then the difference images between the basic fused image and the source images are calculated, and the energy of the gradient (EOG) of difference images are utilized to refine the basic fused image by integrating average filter and median filter. Visual and quantitative using fusion metrics like VIFF, Q(S), MI, Q(AB/F), SD, Q(PC) and running time comparisons to state-of-the-art algorithms demonstrate the out-performance of the proposed fusion technique.
C1 [Li, Liangliang; Ma, Hongbing] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Si, Yujuan] Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.
C3 Tsinghua University; Xinjiang University; Jilin University
RP Ma, HB (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM hbma@tsinghua.edu.cn
RI Yu, Chongxiu/KDM-7354-2024; Li, Chun/KBC-9591-2024
OI Yu, Chongxiu/0000-0002-8221-6221; Li, Liangliang/0000-0001-7354-7494
FU Shanghai Aerospace Science and Technology Innovation Fund
   [SAST2019-048]; National Natural Science Foundation of China [U1803261,
   61665012]
FX This work was supported by the Shanghai Aerospace Science and Technology
   Innovation Fund under Grant No. SAST2019-048; the National Natural
   Science Foundation of China under Grant Nos. U1803261 and 61665012.
CR Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Cao LY, 2020, MULTIMED TOOLS APPL, V79, P11213, DOI 10.1007/s11042-018-6269-x
   Ch MMI, 2019, MULTIDIM SYST SIGN P, V30, P2199, DOI 10.1007/s11045-019-00646-7
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Chen YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112356
   Chen Y, 2020, ENG COMPUTATION, V37, P1557, DOI 10.1108/EC-06-2019-0287
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chu TY, 2020, INT J REMOTE SENS, V41, P4588, DOI 10.1080/01431161.2020.1723175
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Du J, 2020, INT J IMAG SYST TECH, V30, P271, DOI 10.1002/ima.22367
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hayat N, 2020, MULTIMED TOOLS APPL, V79, P25067, DOI 10.1007/s11042-020-09190-0
   He KJ, 2019, SOFT COMPUT, V23, P4685, DOI 10.1007/s00500-018-3118-9
   Hu Q, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115758
   Huang XH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21121135
   Kaur M, 2021, J AMB INTEL HUM COMP, V12, P2483, DOI 10.1007/s12652-020-02386-0
   Li B, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105794
   Li LL, 2020, MULTIMED TOOLS APPL, V79, P24303, DOI 10.1007/s11042-020-09154-4
   Li LL, 2020, J MED IMAG HEALTH IN, V10, P1785, DOI 10.1166/jmihi.2020.3111
   Li LL, 2019, J MED IMAG HEALTH IN, V9, P1815, DOI 10.1166/jmihi.2019.2827
   Li LL, 2019, MULTIMED TOOLS APPL, V78, P18077, DOI 10.1007/s11042-019-7203-6
   Li LL, 2018, INT J IMAG SYST TECH, V28, P124, DOI 10.1002/ima.22264
   Li LJ, 2020, INT J ORAL SCI, V12, DOI 10.1038/s41368-020-0078-6
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li Y, 2020, MULTIMEDIA TOOLS APP
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu SQ, 2019, IEEE ACCESS, V7, P56367, DOI 10.1109/ACCESS.2019.2900376
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Mustafa HT, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115864
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Ramlal SD, 2019, INT J IMAG SYST TECH, V29, P146, DOI 10.1002/ima.22310
   Shreyamsha Kumar B.K., 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI DOI 10.1007/S11760-013-0556-9
   Singh R, 2012, J MED IMAG HEALTH IN, V2, P168, DOI 10.1166/jmihi.2012.1080
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P593, DOI 10.1109/TIM.2019.2902808
   Tan W, 2019, APPL OPTICS, V58, P3064, DOI 10.1364/AO.58.003064
   Wang DY, 2019, MULTIMED TOOLS APPL, V78, P8927, DOI 10.1007/s11042-018-6685-y
   Wang KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082169
   Yang Y, 2010, J X-RAY SCI TECHNOL, V18, P157, DOI 10.3233/XST-2010-0243
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang LH, 2020, MULTIMED TOOLS APPL, V79, P13647, DOI 10.1007/s11042-019-08586-x
   Zhang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107325
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhong Z, 2020, MULTIMED TOOLS APPL, V79, P26225, DOI 10.1007/s11042-020-09044-9
   Zhou JC, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2950949
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
NR 64
TC 16
Z9 16
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12389
EP 12409
DI 10.1007/s11042-020-10462-y
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038100008
DA 2024-07-18
ER

PT J
AU Sun, YJ
   Zhang, H
   Wang, XY
   Wang, MX
AF Sun, Yu-jie
   Zhang, Hao
   Wang, Xing-yuan
   Wang, Ming-xu
TI Bit-level color image encryption algorithm based on coarse-grained
   logistic map and fractional chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Fractional systems; Coarse-grained; Bit-level; Color
   image
AB A novel color image encryption algorithm based on coarse-grained fractional chaotic system signals is proposed in this paper. First, color images are divided into three channels, which are encrypted based on the corresponding three states of the chaotic system. Second, the chaotic systems are defined as fractional chaotic, in which the fractional order enlarges the parameter space. Third, the fractional chaotic signals are handled with unfixed coarse-grained methods instead of being utilized directly. In addition, the original image and the chaotic signals are divided into bit signals from the pixel values, and the high and low bits are encrypted, respectively. To demonstrate the effectiveness and robustness of the proposed color image encryption algorithm, its properties, including the key space, information entropy, correlation analysis, key sensitivity, and resistance to differential attacks, are provided using a numerical simulation.
C1 [Sun, Yu-jie] BeiJing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Zhang, Hao] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
   [Wang, Xing-yuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Ming-xu] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Beijing Institute of Technology; Taiyuan University of Technology;
   Dalian Maritime University; Dalian University of Technology
RP Zhang, H (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
EM zhangh545@126.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61702356, 61672124,
   61503375, 61701070]; Password Theory Project of the 13th Five-Year Plan
   National Cryptography Development Fund [MMJJ20170203]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61702356, 61672124, 61503375 and 61701070), the Password
   Theory Project of the 13th Five-Year Plan National Cryptography
   Development Fund (No: MMJJ20170203).
CR Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   CAPUTO M, 1967, GEOPHYS J ROY ASTR S, V13, P529, DOI 10.1111/j.1365-246X.1967.tb02303.x
   Chang YF, 2013, NEUROQUANTOLOGY, V11, P527
   Chen CS, 2013, J SYST SOFTWARE, V86, P100, DOI 10.1016/j.jss.2012.07.020
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Cramer JA, 2006, J CHEMOMETR, V20, P447, DOI 10.1002/cem.1003
   Diaconu AV, 2016, INT CONF COMM, P411, DOI 10.1109/ICComm.2016.7528310
   Faragallah OS, 2017, OPT QUANT ELECTRON, V49, DOI 10.1007/s11082-017-0909-7
   Haq T., 2020, OPTIK, V217
   Huang X., 2020, J NETW INTELL, V5, P10
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Kawashima M, 1985, Kangogaku Zasshi, V49, P1092
   Kol'tsov NI, 2018, RUSS J PHYS CHEM B+, V12, P590, DOI 10.1134/S1990793118030259
   Li JF, 2018, OPT LASER ENG, V102, P170, DOI 10.1016/j.optlaseng.2017.11.001
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Pasquini C, 2019, IEEE SIGNAL PROC MAG, V36, P101, DOI 10.1109/MSP.2018.2887214
   Suryanto Y, 2017, MULTIMED TOOLS APPL, V76, P16831, DOI 10.1007/s11042-016-3954-5
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Wang X. T., 2019, DATA SCI PATTERN REC, V3, P12
   Wang XY, 2012, INT J MOD PHYS C, V23, DOI 10.1142/S0129183112500672
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2012, OPT COMMUN, V285, P562, DOI 10.1016/j.optcom.2011.10.098
   Wang ZH, 2019, INT J MOB COMPUT MUL, V10, P1, DOI 10.4018/IJMCMC.2019010101
   Weidenmüller HA, 2009, REV MOD PHYS, V81, P539, DOI 10.1103/RevModPhys.81.539
   Wu T.Y., 2018, J INF HIDING MULTIM, V9, P1050
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SJ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P423, DOI 10.1109/ICIVC.2017.7984591
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/216048
NR 34
TC 10
Z9 10
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12155
EP 12173
DI 10.1007/s11042-020-10373-y
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606409000006
DA 2024-07-18
ER

PT J
AU Rahmanian, M
   Shayegan, MA
AF Rahmanian, Mina
   Shayegan, Mohammad Amin
TI Handwriting-based gender and handedness classification using
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Demographic handwriting; Gender classification; Handedness
   classification; CNNs; IAM database; KHATT database; Data augmentation;
   Deep learning
ID PERFORMANCE; FEATURES
AB Demographical handwritings classification has many applications in various disciplines such as biometrics forensics, psychology, archeology, etc. Finding the best features for differentiating subclasses (e.g. men and women) is one of the major problems in handwriting based demographical classification. Convolutional Neural Networks (CNNs) advanced models have a higher capacity in extracting appropriate features compared to traditional models. In this paper, the ability and capacity of deep CNNs in automatic classification of two handwriting based demographical problems, i.e. gender and handedness classification, have been examined by using advanced CNNs; DenseNet201, InceptionV3, and Xception. Two databases, IAM (English texts) and KHATT (Arabic texts) have been employed in this study. The achieved results showed that the proposed CNNs architectures performed well in improving classification results, with 84% accuracy (1.27% improvement) for gender classification using the IAM database, and 99.14% accuracy (28.23% improvement) for handedness classification using the KHATT database.
C1 [Rahmanian, Mina; Shayegan, Mohammad Amin] Islamic Azad Univ, Fac Engn, Dept Comp, Shiraz Branch, Shiraz, Iran.
C3 Islamic Azad University
RP Shayegan, MA (corresponding author), Islamic Azad Univ, Fac Engn, Dept Comp, Shiraz Branch, Shiraz, Iran.
EM Minarahmanian17@gmail.com; Shayegan@iaushiraz.ac.ir
RI Shayegan, Mohammad Amin/AAO-3765-2021
OI Shayegan, Mohammad Amin/0000-0001-7394-4772
CR Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Akbari Y, 2017, IMAGE VISION COMPUT, V59, P17, DOI 10.1016/j.imavis.2016.11.017
   Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   Al-Maadeed S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0097-y
   Al-Maadeed S, 2013, IEEE GCC CONF EXHIB, P119, DOI 10.1109/IEEEGCC.2013.6705761
   Bi N, 2019, PATTERN RECOGN LETT, V121, P123, DOI 10.1016/j.patrec.2018.05.005
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Bouadjenek N, 2017, IET BIOMETRICS, V6, P429, DOI 10.1049/iet-bmt.2016.0140
   Bouadjenek N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA) PROCEEDINGS, P220
   Bouadjenek N, 2016, APPL SOFT COMPUT, V46, P980, DOI 10.1016/j.asoc.2015.10.021
   Bouadjenek N, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P311, DOI 10.1109/DAS.2016.27
   Bouadjenek N, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P43, DOI 10.1109/SOCPAR.2014.7007979
   Caligiuri MP, 2012, NEUOSCIENCE HANDWRIT
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dorffierger S, 2009, BEHAV BRAIN RES, V198, P165, DOI 10.1016/j.bbr.2008.10.033
   Francks C, 2003, AM J HUM GENET, V72, P499, DOI 10.1086/367548
   Gattal A, 2018, EXPERT SYST APPL, V99, P155, DOI 10.1016/j.eswa.2018.01.038
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Illouz E, 2018, LECT NOTES COMPUT SC, V11141, P613, DOI 10.1007/978-3-030-01424-7_60
   Kaljahi MA, 2018, WORKSH DOC AN REC, P119
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P10997
   Kushki A, 2011, J AUTISM DEV DISORD, V41, P1706, DOI 10.1007/s10803-011-1206-0
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liwicki M, 2005, PROC INT CONF DOC, P956, DOI 10.1109/ICDAR.2005.132
   Liwicki M, 2007, PROC 13 C GRAPHONOMI, P179
   Liwicki M, 2011, PATTERN ANAL APPL, V14, P87, DOI 10.1007/s10044-010-0178-6
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Mirza A, 2016, INT CONF FRONT HAND, P395, DOI [10.1109/ICFHR.2016.0080, 10.1109/ICFHR.2016.75]
   Morera A, 2018, COMPLEXITY, DOI 10.1155/2018/3891624
   Navya BJ, 2018, INT CONF FRONT HAND, P392, DOI 10.1109/ICFHR-2018.2018.00075
   Ponti MA, 2017, SIBGRAPI, P17, DOI 10.1109/SIBGRAPI-T.2017.12
   Rosenblum S, 2013, HUM MOVEMENT SCI, V32, P363, DOI 10.1016/j.humov.2012.12.008
   Schomaker L, 2008, ADV BIOMETRICS, P247, DOI 10.1007/978-1-84628-921-7_13
   Schröter A, 2003, DEMENT GERIATR COGN, V15, P132, DOI 10.1159/000068484
   Siddiqi I, 2015, PATTERN ANAL APPL, V18, P887, DOI 10.1007/s10044-014-0371-0
   Stenroos O., 2017, Master's Thesis
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan J, 2016, INT CONF FRONT HAND, P578, DOI [10.1109/ICFHR.2016.0111, 10.1109/ICFHR.2016.104]
   TEULINGS HL, 1991, HUM MOVEMENT SCI, V10, P315, DOI 10.1016/0167-9457(91)90010-U
   VANGALEN GP, 1990, J EXP PSYCHOL HUMAN, V16, P755, DOI 10.1037/0096-1523.16.4.755
   Xiao ZL, 2021, MULTIMED TOOLS APPL, V80, P16283, DOI 10.1007/s11042-020-08858-x
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
NR 45
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35341
EP 35364
DI 10.1007/s11042-020-10170-7
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000605119700003
DA 2024-07-18
ER

PT J
AU Binder, S
   Iannone, A
   Leibner, C
AF Binder, Susanne
   Iannone, Andrea
   Leibner, Chad
TI Biometric technology in "no-gate border crossing solutions" under
   consideration of privacy, ethical, regulatory and social acceptance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Border security; Impact assessment; Ethics; Privacy
AB Biometric technologies have become the main focus in the design of state-of-the-art border security solutions. While respective research in the field of multimedia vision has been centred around improving quality and accuracy of identity recognition, the impact of such technologies upon society and legal regulations still remains a topic unaddressed, specifically within the engineering community. Research in technology can and in some respect must include collaboration with social sciences and social practice. Building on participation in the EU funded research project PERSONA [18] (Privacy, Ethical, Regulatory and SOcial No-gate crossing point solutions Acceptance), authors of this paper look at the challenges associated with biometrics-based solutions in no-gate border crossing point scenarios. This included the procedures needed for the assessment of their social, ethical, privacy and regulatory acceptance, particularly in view of the impact on both, the passengers and border control authorities as well as the potential pitfalls of biometric technology due to fraudulent activities. In consultation with the collaborating border control authorities, the paper reports on the formal assessment of biometric technologies for real-world acceptance to cope with the increasing demand of global travellers crossing state borders.
C1 [Binder, Susanne] MultiMedia & Vis Lab, London E1 4NS, England.
   [Binder, Susanne] Queen Mary Univ London, London, England.
   [Iannone, Andrea] CyberEthicsLab, Via Antonio Salandra 18, I-00187 Rome, Italy.
   [Leibner, Chad] Minist Publ Secur, Baalei Hamelacha 41, IL-72558 Ramle, Israel.
C3 University of London; Queen Mary University London
RP Binder, S (corresponding author), MultiMedia & Vis Lab, London E1 4NS, England.; Binder, S (corresponding author), Queen Mary Univ London, London, England.
EM s.binder@qmul.ac.uk; a.iannone@cyberethicslab.com; chad@police.gov.il
FU European Union [787123]; H2020 Societal Challenges Programme [787123]
   Funding Source: H2020 Societal Challenges Programme
FX The work leading to this publication has been funded by the European
   Union Horizon 2020 research and innovation program under grant agreement
   No. 787123 (PERSONA RIA project).
CR [Anonymous], 2018, Tech Republic
   [Anonymous], 2017, The Guardian
   Anzar STM, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-10
   Brownsword R., 2008, Regulating Technologies: Legal Futures, Regulatory Frames and Technological Fixes
   Carnevale A, 2016, ROBOT AUTON SYST, V86, P144, DOI 10.1016/j.robot.2016.08.027
   Dariusz Kloza DS, 2017, INTERSENTIA CAMBRIDG, V4, P45
   Dommering E., 2006, CODING REGULATION, V12
   Fraser AHN, 2004, REDISTRIBUTION RECOG
   Habermas Jurgan., 1992, FACTS NORMS
   MAGNETO consortium, 2018, MAGNETO H2020 PROJ
   Morosan C, 2011, TRAVEL TOURISM RESEA
   PERSONA consortium, 2019, PERSONA H2020 PROJ
   Poel I. v. d, 2013, TRANSLATING VALUES D
   Rubins U, 2011, 15 NORD BALT C BIOM
   Scherhag U, 2017, 2017 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Turkle Sherry., 2015, Reclaiming Conversation: The Power of Talk in a Digital Age
NR 16
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23665
EP 23678
DI 10.1007/s11042-020-10266-0
EA DEC 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000603535000001
PM 33390767
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Nayyar, A
   Singh, R
AF Nayyar, Anand
   Singh, Rajeshwar
TI IEEMARP- a novel energy efficient multipath routing protocol based on
   ant Colony optimization (ACO) for dynamic sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks (WSN); Ant colony optimization (ACO); Energy
   efficient routing; DSDV; DSR; Basic ACO; ACEAMRA; AntChain; EMCBR; IACR;
   AntQHSeN; FACOR; ANTALG; Swarm intelligence; Packet delivery ratio;
   End-to-end delay; Throughput
AB In the past few years, research and development in Wireless Sensor networks (WSNs) have gained momentum due to its numerous applications in agriculture, industrial manufacturing, military surveillance, environmental monitoring, consumer electronics, medical & healthcare, disaster recovery operations etc. Dynamic WSNs offer a robust blend of distributed sensing, computing and communication. Dynamic sensor networks are characterized by large scale deployment, dynamic and unstructured topology, power limitations, less memory and limited computational capabilities. Sensor nodes deployed in real-time environment's for sensing data have power-limitations which hampers the overall performance of WSNs. So, the only obvious solution is to propose an energy efficient routing protocol to optimize WSN real-time performance. Different specialists have proposed various directing conventions for WSNs dependent on Fuzzy Logic, Genetic Algorithms, Meta-Heuristics, and other improvement strategies. However, every solution suggested till date has its advantages and limitations. In this paper, our primary objective is to utilize Swarm-Intelligence based approach i.e. "Ant Colony Optimization (ACO)", for routing protocol development. Ant colony optimization (ACO) based approach gives optimal solution in terms of efficient routing path determination, energy efficiency and delivering high performance in terms of packet delivery and throughput. In this paper, we propose a novel energy efficient ACO based multipath routing protocol for WSN i.e. IEEMARP (Improvised Energy Efficient Multipath ACO based Routing Protocol). The proposed protocol works in three phases (Neighbor Discovery via Link Knowledge, Packet Transmission via exponentially weighted moving average method and ACKR packet delivery for assuring end-to-end delivery. To validate the performance of the protocol proposed, extensive simulations were conducted using NS-2.35-allinone simulator on diverse parameters like (PDR), throughput, routing overhead, energy consumption and end-to-end delay. In addition to this, the performance of protocol is compared with traditional routing protocols like Basic ACO, DSDV and DSR and other ACO based WSN protocols like ACEAMR, AntChain, EMCBR, IACR, AntHQSeN, FACOR and ANTALG. Simulation based results, clearly states that as compared to Basic ACO, DSDV and DSR, the performance of WSN network is improvised to around 10% in all performance metrics via IEEMARP routing protocol. And as compared to ACEAMR, AntChain, EMCBR and IACR, IEEMARP performs 20% better in overall functionality and almost 10-12% better as compared to AntHQSeN, FACOR, ANTLAG routing protocols in varied WSN scenarios. It is also observed that IEEMARP protocol is highly efficient in TCP packet transmission from source to destination node.
C1 [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
   [Singh, Rajeshwar] Doaba Grp Coll, Nawanshahr, Punjab, India.
C3 Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
EM anandnayyar@duytan.edu.vn; rajeshwar.rajata@gmail.com
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146
CR Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Amiri E, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/768936
   Anand N., 2017, Am J Intell Syst, V7, P19
   [Anonymous], 2018, ADV SWARM INTELLIGEN
   [Anonymous], 2018, INT C IND NETWORKS I
   Bansal J. C., EVOLUTIONARY SWARM I
   Blum C, 2005, PHYS LIFE REV, V2, P353, DOI 10.1016/j.plrev.2005.10.001
   Camilo T, 2006, LECT NOTES COMPUT SC, V4150, P49, DOI 10.1007/11839088_5
   Deepika D, 2013, J PROC IJARCSEE, V3
   Ding NN, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P1636
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, P53, DOI 10.1109/4235.585892
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Dorigo M, 2010, INT SER OPER RES MAN, V146, P227, DOI 10.1007/978-1-4419-1665-5_8
   Doss S, 2018, IEEE ACCESS, V6, P56954, DOI 10.1109/ACCESS.2018.2868544
   Günes M, 2002, INT CONF PARA PROC, P79, DOI 10.1109/ICPPW.2002.1039715
   Gupta A, 2014, INT J ADV RES COMPUT, V2
   Gupta A, 2014, APPROACHES COMBATING
   Hans S, 2014, INT C ADV COMPUT COM, P372, DOI 10.1109/ACCT.2014.19
   Hassanien A.E., 2018, SWARM INTELLIGENCE P
   Hussein O, 2003, IEEE IPCCC, P281, DOI 10.1109/PCCC.2003.1203709
   Kaur M., 2013, INT J EMERG TRENDS T, V2, P196
   Kaur M, 2014, 2014 5TH INTERNATIONAL CONFERENCE CONFLUENCE THE NEXT GENERATION INFORMATION TECHNOLOGY SUMMIT (CONFLUENCE), P359, DOI 10.1109/CONFLUENCE.2014.6949280
   Khan S, 2012, WIRELESS SENSOR NETWORKS: CURRENT STATUS AND FUTURE TRENDS, P1, DOI 10.1201/b13092
   Kumar A., 2014, INT J SCI ENG RES IJ, V5, P440
   Kumar Sandeep, 2019, International Conference on Innovative Computing and Communications. Proceedings of ICICC-2018. Lecture Notes in Networks and Systems (LNNS 56), P187, DOI 10.1007/978-981-13-2354-6_21
   Kumar S., 2014, EMERGING TRENDS COMP, P157
   Maniezzo V, 2002, OPERAT RES COMP SCI, V15, P469
   Mirjalili S., 2020, NATURE INSPIRED OPTI, P7, DOI 10.1007/978-3-030-12127-3 _ 2
   Mohan BC, 2012, EXPERT SYST APPL, V39, P4618, DOI 10.1016/j.eswa.2011.09.076
   Mohanty S. D., 2018, Swarm Intelligence Methods for Statistical Regression
   Mondal S., 2018, Industry Interactive Innovations in Science, Engineering, and Technology, P163
   Nayyar Anand, 2019, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2018. Lecture Notes in Networks and Systems (LNNS 55), P165, DOI 10.1007/978-981-13-2324-9_17
   Nayyar Anand, 2014, International Journal of Wireless Networks and Broadband Technologies, V3, P33, DOI 10.4018/ijwnbt.2014070103
   Nayyar A., 2012, Proceedings of the 2012 Second International Conference on Advanced Computing & Communication Technologies (ACCT 2012), P561, DOI 10.1109/ACCT.2012.104
   Nayyar A., 2013, INT J ADV RES COMPUT, V3
   Nayyar A., 2017, J. Adv. Math. Comput. Sci, V20, P1, DOI [10.9734/BJMCS/2017/32215, DOI 10.9734/BJMCS/2017/32215]
   Nayyar A, 2017, IMPROVISED ENERGY EF
   Nayyar A., 2014, IJRCCT, V3, P111
   Nayyar A., 2017, IEEMARP IMPR EN EFF, P3
   Nayyar A., 2015, J WIRELESS NETWORKIN, V5, P19
   Nayyar A., 2016, REV COMPUT ENG RES, V3, P55, DOI [10.18488/journal.76/2016.3.3/76.3.55.64, DOI 10.18488/JOURNAL.76/2016.3.3/76.3.55.64]
   Nayyar A., 2016, COMPREHENSIVE REV AN
   Nayyar A., 2012, INT J ADV RES COMPUT
   Nayyar A., 2018, Advances in swarm intelligence for optimizing problems in computer science, P1, DOI DOI 10.1201/9780429445927
   Nayyar A, 2019, ADV INTELL SYST, V839, P513, DOI 10.1007/978-981-13-1274-8_38
   Nayyar A, 2017, INT J ADV COMPUT SC, V8, P148
   Nayyar A, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P1493
   Nayyar Anand., 2018, Advances in swarm intelligence for optimizing problems in computer science, P53
   Nayyar Gupta, 2014, IJRCCT, V3, P104
   Patel M, 2004, ICWN'04 & PCC'04, VOLS, 1 AND 2, PROCEEDINGS, P447
   Peng SH, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P578, DOI 10.1109/ICINFA.2008.4608066
   Potdar V, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS: WAINA, VOLS 1 AND 2, P636, DOI 10.1109/WAINA.2009.192
   Rao S. S., 1979, IEEE T SYST MAN CYB, V9, P447
   Rawat P, 2014, J SUPERCOMPUT, V68, P1, DOI 10.1007/s11227-013-1021-9
   Shah RC, 2002, IEEE WCNC, P350, DOI 10.1109/WCNC.2002.993520
   Sharma N., 2014, INT J CURR ENG TECHN, V4, P1503
   Sharma N., 2014, INT J APPL INNOVATIO, V3, P441
   Sharma S., 2014, INT J EMERG TRENDS T, V3, P91
   Sharma S., 2014, REV ROUTING TECHNIQU
   Singh G, 2014, J NETW COMPUT APPL, V45, P151, DOI 10.1016/j.jnca.2014.07.006
   Stutzle Thomas., 2009, International Conference on Evolutionary Multi-Criterion Optimization, P2
   Sun YJ, 2017, IEEE COMMUN LETT, V21, P1317, DOI 10.1109/LCOMM.2017.2672959
   Suseendran G, 2019, ADV INTELL SYST, V839, P437, DOI 10.1007/978-981-13-1274-8_33
   Xia SZ, 2009, 2009 SECOND INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING: KAM 2009, VOL 3, P198, DOI 10.1109/KAM.2009.68
NR 66
TC 23
Z9 23
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35221
EP 35252
DI 10.1007/s11042-019-7627-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900029
DA 2024-07-18
ER

PT J
AU Wu, C
   Hu, SM
   Lee, CH
   Xiao, J
AF Wu, Chao
   Hu, Simon
   Lee, Chun-Hsiang
   Xiao, Jun
TI Multi-platform data collection for public service with Pay-by-Data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-platform data collection; User data privacy; Pay by data; Public
   data service
ID LOCATION PRIVACY
AB In order to establish efficient public services (e.g., traffic management, demand forecasting, traffic prediction), it's necessary to build a supportive data collection, specially multi-platform user data collection (e.g., data of user's journey information), to provide training data for building models. However, several issues hinders such paradigm to be deployed in real world. Firstly, we need to achieve the balance between data collection and user privacy protection. Secondly, it's crucial to motive the users to contribute their data. Thirdly, we need to design a data pricing mechanism to promote data sharing. In this paper, we try to solve these issues by extending the Pay-by-data model, which is an explicit data-service exchange protocol. Based on this, we propose a system framework to support large-scale public service.
C1 [Wu, Chao] Zhejiang Univ, Sch Publ Affairs, MMW BLDG,866 Yuhangtang Rd, Hangzhou 310058, Peoples R China.
   [Wu, Chao] Imperial Coll London, Data Sci Inst, London, England.
   [Hu, Simon] Zhejiang Univ, Sch Civil Engn, Hangzhou, Peoples R China.
   [Hu, Simon] Imperial Coll London, Transport & Environm Lab, London, England.
   [Lee, Chun-Hsiang] Imperial Coll London, Dept Comp, London, England.
   [Xiao, Jun] Zhejiang Univ, Coll Comp Sci, Hangzhou 310000, Peoples R China.
C3 Zhejiang University; Imperial College London; Zhejiang University;
   Imperial College London; Imperial College London; Zhejiang University
RP Xiao, J (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310000, Peoples R China.
EM chao.wu@zju.edu.cn; junx@cs.zju.edu.cn
RI Hu, Simon/A-5882-2009
OI Hu, Simon/0000-0002-9832-6679
CR [Anonymous], 2003, P INT 2003 9 IFIP TC
   Cheng R, 2006, LECT NOTES COMPUT SC, V4258, P393
   de Montjoye Y-A, SCI REPORTS
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Felt AP, 2012, P 8 S USABLE PRIVACY, P1, DOI DOI 10.1145/2335356.2335360
   Gedik B, 2005, INT CON DISTR COMP S, P620, DOI 10.1109/ICDCS.2005.48
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Liang F, 2018, IEEE ACCESS, V6, P15132, DOI 10.1109/ACCESS.2018.2806881
   Machanavajjhala A., 2006, P 22 INT C DAT ENG, P24, DOI DOI 10.1109/ICDE.2006.1
   NARAYANAN A., ARXIVCS0610105
   Nauman M., 2010, P 5 ACM S INF COMP C, V10, P328, DOI [10.1145/1755688.1755732, DOI 10.1145/1755688.1755732]
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Petrie C, 2016, IEEE INTERNET COMPUT, V20, P92, DOI 10.1109/MIC.2016.31
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Van Grove J, VB MOBILE, V14
   Vukovic Maja., 2010, Proceedings of the 12th ACM International Conference Adjunct Papers on Ubiquitous Computing - Adjunct. Ubicomp '10 Adjunct, P523, DOI DOI 10.1145/1864431.1864504
   Wagner Daniel T., 2014, ACM SIGMETRICS Performance Evaluation Review, V41, P53
   Wilson K, 2009, CAN MED ASSOC J, V180, P829, DOI [10.1503/cmaj.1090215, 10.1503/cmaj.090215]
   Yiu ML, 2008, PROC INT CONF DATA, P366, DOI 10.1109/ICDE.2008.4497445
NR 20
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33503
EP 33518
DI 10.1007/s11042-019-07919-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000011
DA 2024-07-18
ER

PT J
AU Luqman, H
   El-Alfy, EM
   BinMakhashen, GM
AF Luqman, Hamzah
   El-Alfy, El-Sayed M.
   BinMakhashen, Galal M.
TI Joint space representation and recognition of sign language
   fingerspelling using Gabor filter and convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-machine interaction; Sign language; Hand gesture; Gabor filter;
   Deep learning; Multimodal recognition systems
ID CLASSIFICATION; TRANSFORM; AUGMENTATION; FEATURES; IMAGES
AB In this work, we are proposing a new technique for visual recognition of fingerspelling of a sign language by fusing multiple spatial and spectral representations of manual gesture images using a convolutional neural network. This problem is gaining prominence in communication between hearing-impaired people and human-machine interaction. The proposed technique computes Gabor spectral representations of spatial images of hand sign gestures and uses an optimized convolutional neural network to classify the gestures in the joint space into corresponding classes. Various ways to combine both types of modalities are explored to identify the model that improves the robustness and recognition accuracy. The proposed system is evaluated using three databases (MNIST-ASL, ArSL, and MUASL) under different conditions and the attained results outperformed the state-of-the-art techniques.
C1 [Luqman, Hamzah; El-Alfy, El-Sayed M.; BinMakhashen, Galal M.] King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP El-Alfy, EM (corresponding author), King Fahd Univ Petr & Minerals, Dhahran 31261, Saudi Arabia.
EM alfy@kfupm.edu.sa
RI BinMakhashen, Galal M/U-4220-2019; El-Alfy, El-Sayed/G-3103-2011
OI BinMakhashen, Galal M/0000-0002-5111-9760; El-Alfy,
   El-Sayed/0000-0001-6279-9776
FU King Fahd University of Petroleum and Minerals
FX The authors would like to thank King Fahd University of Petroleum and
   Minerals for support during this work. Spacial thanks to the journal
   Editorial board and anonymous reviewers for their constructive comments
   that have significantly helped improve the content and presentation of
   the work.
CR Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   Aljahdali S, 2012, INT CONF MULTIMED, P125
   [Anonymous], 2012, P ACCV 12
   [Anonymous], 2011, Res Lett Inf Math Sci
   [Anonymous], 2017, USING DEEP CONVOLUTI
   [Anonymous], 2014, TENCON 2014 2014 IEE
   BinMakhashen GM, 2012, LECT NOTES COMPUT SC, V7667, P410, DOI 10.1007/978-3-642-34500-5_49
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chakraborty D, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION TECHNOLOGY (IAIT2018), DOI 10.1145/3291280.3291783
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chevtchenko SF, 2018, EXPERT SYST APPL, V92, P170, DOI 10.1016/j.eswa.2017.09.046
   Chu RF, 2007, LECT NOTES COMPUT SC, V4844, P22
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ghazanfar L, 2018, ARABIC ALPHABETS SIG
   Gunther Manuel, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. Proceedings 22nd International Conference on Artificial Neural Networks, P411, DOI 10.1007/978-3-642-33269-2_52
   Hazratov S, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P1, DOI 10.1109/tiptekno.2019.8894914
   Hinton G. E., 2012, 12070580 ARXIV
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Islam MR, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2018), P115, DOI 10.1109/ICFSP.2018.8552044
   Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858
   Jasim M, 2014, 2014 INT C INFORMATI, P1, DOI DOI 10.1109/ICIEV.2014.7136001
   Liu Y, 2012, PROCEDIA ENGINEER, V29, P1678, DOI 10.1016/j.proeng.2012.01.194
   Luqman H., 2017, P INT C RELIABLE INF, P297
   Luqman H, 2019, UNIVERSAL ACCESS INF, V18, P939, DOI 10.1007/s10209-018-0622-8
   Makarov I, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P204, DOI 10.1145/3316782.3316786
   Mehri M, 2017, INT J DOC ANAL RECOG, V20, P1, DOI 10.1007/s10032-016-0278-y
   Mohandes M, 2005, ISSPA 2005: The 8th International Symposium on Signal Processing and its Applications, Vols 1 and 2, Proceedings, P86
   Mohandes M, 2014, IEEE T HUM-MACH SYST, V44, P551, DOI 10.1109/THMS.2014.2318280
   Mohandes M., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), P479, DOI 10.1109/ICTTA.2004.1307840
   Mohandes MA, 2013, ARAB J SCI ENG, V38, P669, DOI 10.1007/s13369-012-0378-z
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   Nair A. V, 2013, INT J COMPUT APPL, V73, P33, DOI DOI 10.5120/13037-0260
   Pan TY, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P64, DOI 10.1109/BigMM.2016.44
   Paul Soumi, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P775, DOI 10.1007/978-981-13-7403-6_68
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rajadell O, 2013, IEEE GEOSCI REMOTE S, V10, P860, DOI 10.1109/LGRS.2012.2226426
   Ranga V, 2018, J ENG SCI TECHNOL, V13, P2655
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Rathi D, 2018, ARXIV180506618
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Sadek MI, 2017, NAT RADIO SCI CO, P380, DOI 10.1109/NRSC.2017.7893499
   Shanableh T, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P597
   Shivashankara S, 2017, INT J SCI RES ENG TE, V6, P1013
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sidig AAI, 2017, PROCEDIA COMPUT SCI, V117, P2, DOI 10.1016/j.procs.2017.10.087
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Wang H., 2017, On the Origin of Deep Learning
   Xu Y, 2019, PATTERN RECOGN LETT, V128, P131, DOI 10.1016/j.patrec.2019.08.022
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2015, NEUROCOMPUTING, V147, P307, DOI 10.1016/j.neucom.2014.06.058
   Youdong Ding, 2011, 2011 International Conference on Multimedia Technology, P3171
   Zamani M, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P398, DOI 10.1109/ICCKE.2014.6993442
   Zhang D., 2000, P 1 IEEE PAC RIM C M
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
NR 59
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10213
EP 10234
DI 10.1007/s11042-020-09994-0
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590232500001
DA 2024-07-18
ER

PT J
AU Li, B
   Yuan, JF
   Ye, YX
   Lu, YJ
   Zhang, CY
   Tian, Q
AF Li, Bo
   Yuan, Juefei
   Ye, Yuxiang
   Lu, Yijuan
   Zhang, Chaoyang
   Tian, Qi
TI 3D sketching for 3D object retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D sketching; Kinect; Sketch-based 3D model retrieval; Convolutional
   neural networks
ID SEARCH; MODELS
AB Sketching provides the most natural way to provide a visual search query for visual object search. However, how to draw 3D sketches in a three-dimensional space and how to use a hand-drawn 3D sketch to search similar 3D models are not only interesting and novel, but also challenging research topics. In this paper, we try to answer them by initiating a novel study on 3D sketching and build a 3D sketching system which allows users to freely draw 3D sketches in the air and demonstrate its promising potentials in related applications such as collecting 3D sketch data and conducting 3D sketch-based 3D model retrieval. By utilizing the 3D sketching system, we collect a 3D sketch dataset, build a 3D sketch-based 3D model retrieval benchmark, and organize a Eurographics Shape Retrieval Contest (SHREC) track on 3D sketch-based shape retrieval based on the benchmark. We investigate 3D sketch and model matching problems and propose a novel 3D sketch-based model retrieval algorithm CNN-SBR based on Convolutional Neural Networks (CNNs) and achieve the best performance in the SHREC track. We wish that the 3D sketching system, the 3D sketch-based model retrieval benchmark, and the proposed 3D sketch-based model retrieval algorithm CNN-SBR will further promote sketch-based shape retrieval and its applications. We have made all of these publicly available on the project homepage: http://orca.st.usm.edu/similar to bli/SBR16/project.html.
C1 [Li, Bo; Yuan, Juefei] Univ Southern Mississippi, Sch Comp Sci & Comp Engn, Long Beach, MS USA.
   [Ye, Yuxiang; Lu, Yijuan] Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
   [Zhang, Chaoyang] Univ Southern Mississippi, Sch Comp Sci & Comp Engn, Hattiesburg, MS 39406 USA.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA.
C3 University of Southern Mississippi; Texas State University System; Texas
   State University San Marcos; University of Southern Mississippi;
   University of Texas System; University of Texas at San Antonio (UTSA)
RP Lu, YJ (corresponding author), Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
EM bo.li@usm.edu; juefei.yuan@usm.edu; ricky.ye14@gmail.com;
   lu@txstate.edu; chaoyang.zhang@usm.edu; qi.tian@utsa.edu
RI Yuan, Juefei/HJI-9440-2023; Li, bo/IWL-9318-2023; LU,
   YIJUAN/GNM-8769-2022; Li, Ye/JBS-2949-2023; Zhang,
   Chaoyang/JPK-5044-2023; Li, Kun/JLL-6505-2023
OI LU, YIJUAN/0000-0002-9855-8365; Li, Kun/0000-0002-3638-2974; LI,
   BO/0000-0002-3330-8103
FU Army Research Office [W911NF-12-1-0057]; NSF [OCI-1062439, CRI-1305302,
   CNS-1358939]; University of Southern Mississippi Faculty Startup Funds
   Award; NVIDIA Corporation
FX This work is supported by Army Research Office grant W911NF-12-1-0057 to
   Dr. Yijuan Lu and Dr. Qi Tian, by NSF CRI-1305302, NSF CNS-1358939 and
   NSF OCI-1062439 to Dr. Yijuan Lu, and by the University of Southern
   Mississippi Faculty Startup Funds Award to Dr. Bo Li. We gratefully
   acknowledge the support from NVIDIA Corporation for the donation of the
   Titan X/Xp GPUs used in this research.
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 1989, P ADV NEURAL INFORM
   [Anonymous], 2009, Found. Trends Hum.-Comput. Interact, DOI DOI 10.1561/1100000013
   [Anonymous], 1995, INTRO KALMAN FILTER
   [Anonymous], 2011, P 16 INT C INT US IN
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 1979, MATH SCI ENG
   Araújo C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323004
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Beecks C, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2018), P230, DOI 10.1109/FiCloud.2018.00041
   Beecks C, 2016, INT J SEMANT COMPUT, V10, P5, DOI 10.1142/S1793351X16400018
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Dai GX, 2018, IEEE T IMAGE PROCESS, V27, P3374, DOI 10.1109/TIP.2018.2817042
   Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Giunchi D, 2018, P JOINT S COMPUTATIO, P1
   Giunchi D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P559, DOI 10.1109/VR.2018.8446609
   Ha D, 2017, ARXIV 1704 03477
   Henshilwood CS, 2018, NATURE, V562, P115, DOI 10.1038/s41586-018-0514-3
   Herot C. F., 1976, Computer Graphics, V10, P97, DOI 10.1145/965143.563294
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Jabal MFA, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P709, DOI 10.1109/ICIME.2009.56
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Jolliffe L., 2002, Principal Component Analysis
   Jung A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2749458
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Li B, 2016, 3DOR, P47
   Li B., 2013, EUR WORKSH 3D OBJ RE, P89, DOI DOI 10.2312/3DOR/3DOR13/089
   Li B, 2014, EUR WORKSH 3D OBJ RE, P121
   Li B, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P555, DOI 10.1145/2671188.2749349
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li Y, 2017, INT J COMPUT VISION, V122, P169, DOI 10.1007/s11263-016-0963-9
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Lu T, 2005, COMPUT AIDED DESIGN, V37, P1053, DOI 10.1016/j.cad.2004.11.004
   Nealen Andrew., 2007, ACM SIGGRAPH 2007 courses, P42
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Paoli CD, 2015, ACM T GRAPHIC, V34, P126
   Radenovic F, 2018, EUROPEAN C COMPUTER
   Sahillioglu Y, 2017, IEEE COMPUT GRAPH, V37, P88, DOI 10.1109/MCG.2017.4031063
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Seddati O, 2017, DEEPSKETCH 3 MULTIME
   Seddati Omar, 2015, CONT BAS MULT IND CB, P1, DOI DOI 10.1109/CBMI.2015.7153606
   Seddati Omar, 2016, CBMI 2016, P1, DOI DOI 10.1109/CBMI.2016.7500261
   Sedmidubsky J, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P5, DOI 10.1145/3323873.3326589
   Shao C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185541
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sipiran I, 2017, VISUAL COMPUT, V33, P1571, DOI 10.1007/s00371-016-1301-5
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Song YZ., 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/IPDPS.2016.126
   Sousa P, 2009, J VIS COMMUN IMAGE R, V20, P71, DOI 10.1016/j.jvcir.2008.11.005
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sutherland I. E., 1964, P SHAR DES AUT WORKS, DOI [DOI 10.1177/003754976400200514, 10.1177/003754976400200514]
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Veltkamp RC, 2007, TECHNICAL REPORT 950
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Xie J, 2017, PROC CVPR IEEE, P3615, DOI 10.1109/CVPR.2017.385
   Ye Y, 2016, INT C PATT RECOG, P2936, DOI 10.1109/ICPR.2016.7900083
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Yu Q, 2015, BRIT MACH VIS C, P71
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu Qian., 2017, International Journal of Computer Vision (IJCV)
   Zeleznik RobertC., 2007, ACM SIGGRAPH 2007 CO, DOI DOI 10.1145/1281500.1281530
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
NR 78
TC 6
Z9 6
U1 12
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9569
EP 9595
DI 10.1007/s11042-020-10033-1
EA NOV 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300002
DA 2024-07-18
ER

PT J
AU Ramya, P
   Rajeswari, R
AF Ramya, P.
   Rajeswari, R.
TI Human action recognition using distance transform and entropy based
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Silhouettes; Distance transform; Entropy;
   Neural networks
ID VIDEO-SURVEILLANCE SYSTEM; HUMAN ACTION CATEGORIES; SILHOUETTE;
   HISTOGRAMS; SEQUENCES; CNN
AB Human action recognition based on silhouette images has wide applications in computer vision, human computer interaction and intelligent surveillance. It is a challenging task due to the complex actions in nature. In this paper, a human action recognition method is proposed which is based on the distance transform and entropy features of human silhouettes. In the first stage, background subtraction is performed by applying correlation coefficient based frame difference technique to extract silhouette images. In the second stage, distance transform based features and entropy features are extracted from the silhouette images. The distance transform based features and entropy features provide the shape and local variation information. These features are given as input to neural networks to recognize various human actions. The proposed method is tested on three different datasets viz., Weizmann, KTH and UCF50. The proposed method obtains an accuracy of 92.5%, 91.4% and 80% for Weizmann, KTH and UCF50 datasets respectively. The experimental results show that the proposed method for human action recognition is comparable to other state-of-the-art human action recognition methods.
C1 [Ramya, P.; Rajeswari, R.] Bharathiar Univ, Dept Comp Applicat, Coimbatore, Tamil Nadu, India.
C3 Bharathiar University
RP Rajeswari, R (corresponding author), Bharathiar Univ, Dept Comp Applicat, Coimbatore, Tamil Nadu, India.
EM rajeswari@buc.edu.in
RI Rajeswari, R/AAP-7251-2021
OI , Rajeswari/0000-0002-2803-1429
FU UGC
FX The authors are thankful to Bharathiar University for valuable support.
   The first author is also thankful to UGC for the grants provided through
   RGNF scheme.
CR Ahmad M, 2006, INT C PATT RECOG, P263
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   [Anonymous], 2010, BMVC
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Batra D, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P161
   Ben Hamida A, 2016, MULTIMED TOOLS APPL, V75, P17187, DOI 10.1007/s11042-015-2987-5
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Cheema S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1302, DOI 10.1109/ICCVW.2011.6130402
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chun S, 2016, IET COMPUT VIS, V10, P250, DOI 10.1049/iet-cvi.2015.0233
   Cilla R, 2014, EXPERT SYST, V31, P354, DOI 10.1111/exsy.12040
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Feng Q, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-015-1627-x
   Gerónimo D, 2014, INT C PATT RECOG, P4630, DOI 10.1109/ICPR.2014.792
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Grundmann M, 2008, P 19 INT C PATT REC
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Jalal A, 2017, INT J INTERACT MULTI, V4, P54, DOI 10.9781/ijimai.2017.447
   Junejo IN, 2014, VISUAL COMPUT, V30, P259, DOI 10.1007/s00371-013-0842-0
   Keles H, 2017, ACTION RECOGNITION U, DOI [10.1109/EUROCON.2017.8011107, DOI 10.1109/EUR0C0N.2017.8011107]
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P35827, DOI 10.1007/s11042-020-09408-1
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Kong YQ, 2018, MULTIMED TOOLS APPL, V77, P13643, DOI 10.1007/s11042-017-4979-0
   Kushwaha AKS, 2017, MULTIMEDIA SYST, V23, P451, DOI 10.1007/s00530-016-0505-x
   Lai KT, 2010, LECT NOTES COMPUT SC, V6134, P439
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liang B, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P76
   Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001
   Maity S, 2017, IETE J RES, V63, P160, DOI 10.1080/03772063.2016.1242383
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   PAGLIERONI DW, 1992, CVGIP-GRAPH MODEL IM, V54, P56, DOI 10.1016/1049-9652(92)90034-U
   Pehlivan S, 2014, IMAGE VISION COMPUT, V32, P237, DOI 10.1016/j.imavis.2014.01.006
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramya P, 2016, PROCEDIA COMPUT SCI, V93, P478, DOI 10.1016/j.procs.2016.07.236
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Reddy KK, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P106, DOI 10.1109/AVSS.2012.40
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Saner CK, 2015, NANOTECHNOL REV, V4, P129, DOI 10.1515/ntrev-2015-0002
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Sharma MK, 2020, MULTIMED TOOLS APPL, V79, P11237, DOI 10.1007/s11042-020-08786-w
   Shen ZH, 2010, PROCEEDINGS OF ANNUAL CONFERENCE OF CHINA INSTITUTE OF COMMUNICATIONS, P168
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Ullah A., 2020, DEEP LEARNING COMPUT, P127, DOI DOI 10.1201/9781351003827-5
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vishwakarma DK, 2016, AEU-INT J ELECTRON C, V70, P341, DOI 10.1016/j.aeue.2015.12.016
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Weinland D., 2008, CVPR, P1
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Yi Y, 2018, VISUAL COMPUT, V34, P391, DOI 10.1007/s00371-016-1345-6
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P21471, DOI 10.1007/s11042-019-08457-5
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
NR 67
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8147
EP 8173
DI 10.1007/s11042-020-10140-z
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000583128600008
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, X
   Zhang, YF
   Guo, YQ
   Zhou, DK
AF Yang, Xin
   Zhang, Yifan
   Guo, Yingqing
   Zhou, Dake
TI An image super-resolution deep learning network based on multi-level
   feature extraction module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Deep learning; Convolutional neural network; Loss
   function
AB Due to the lack of depth of the super-resolution (SR) method based on shallow networks, the feature maps of different convolutional layers have similar receptive fields, so that the performance improvement is not obvious. To solve this problem effectively, we propose an image SR reconstruction deep model based on a new multi-level feature extraction module in this paper. The method constructs an improved multi-level feature extraction module using the dense connection to obtain a deeper network and richer hierarchical feature maps for the SR task. In addition, we apply the loss function combined with the perceptual characteristics to improve the visual effect of the reconstructed image. Experiments show that the proposed method works well at reconstructed images with different magnification.
C1 [Yang, Xin; Zhang, Yifan; Guo, Yingqing; Zhou, Dake] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yang, X (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
EM yangxin@nuaa.edu.cn; Yifan_88@163.com; gyq_93@163.com;
   dakzhou@nuaa.edu.cn
RI zhong, jing/KBP-7800-2024; WANG, YONGJIA/KFQ-4823-2024
OI Yang, Xin/0000-0003-0445-6497
FU National Natural Science Foundation of China [61573182]; Fundamental
   Research Funds for the Central Universities [NS2020025]
FX This research was supported by the National Natural Science Foundation
   of China (61573182) and by the Fundamental Research Funds for the
   Central Universities (NS2020025).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Anwar S., 2017, ARXIV171202933
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chaudhry AM, 2019, SIGNAL IMAGE VIDEO P, V13, P237, DOI 10.1007/s11760-018-1350-5
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fanaee F, 2019, SIGNAL IMAGE VIDEO P, V13, P79, DOI 10.1007/s11760-018-1330-9
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, INT C PATT RECOG, P2670, DOI 10.1109/ICPR.2018.8545648
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan S., 2018, SYNTHESIS LECT COMPU, V8, P1, DOI DOI 10.2200/S00822ED1V01Y201712COV015
   Kim J., P IEEE C COMPUTER VI, P1637
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kumar A, 2016, PR MACH LEARN RES, V48
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lillesand T., 2015, Remote sensing and image interpretation
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Sundar KJA, 2017, SIGNAL IMAGE VIDEO P, V11, P357, DOI 10.1007/s11760-016-0952-z
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang X., 2018, ARXIV180405448
   Xie C, 2019, SIGNAL IMAGE VIDEO P, V13, P557, DOI 10.1007/s11760-018-1382-x
   Yang SY, 2014, IEEE T IMAGE PROCESS, V23, P2793, DOI 10.1109/TIP.2014.2319742
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y., 2018, ARXIV PREPRINT ARXIV
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu SJ, 2019, SIGNAL IMAGE VIDEO P, V13, P331, DOI 10.1007/s11760-018-1361-2
NR 42
TC 12
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7063
EP 7075
DI 10.1007/s11042-020-09958-4
EA OCT 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582308600002
DA 2024-07-18
ER

PT J
AU Zhou, PC
   Zhao, ZP
   Zhang, K
   Li, C
   Wang, CB
AF Zhou, Peichi
   Zhao, Zipeng
   Zhang, Kang
   Li, Chen
   Wang, Changbo
TI An end-to-end model for chinese calligraphy generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Calligraphy; Generative models; Font style transfer; Deep learning
AB A Chinese calligraphy copybook usually has a limited number of Chinese characters, far from a whole set of characters needed for typesetting. Therefore, there is a need to develop complete sets of Chinese calligraphy libraries for well-known calligrapher styles. This paper proposes an end-to-end network for character generation based on specific calligraphy styles. Specifically, a style transfer network is designed to transfer the style of characters, and a content supplement network is designed to capture the details of stylish strokes. Our model can generate high-quality calligraphy images without manually annotating data. To verify the generated calligraphy styles, a new dataset is constructed for experimental comparison between our method and two other baseline methods. Moreover, a user study is conducted to evaluate our generated calligraphy from a visual perspective. When the experiment participants are asked to distinguish the real calligraphy from generated samples, the correct rate was 53.5%. The results show that the calligraphy styles generated by our model are almost indistinguishable from the original works.
C1 [Zhou, Peichi; Zhao, Zipeng; Li, Chen; Wang, Changbo] East China Normal Univ, Shanghai, Peoples R China.
   [Zhang, Kang] Univ Texas Dallas, Richardson, TX 75083 USA.
C3 East China Normal University; University of Texas System; University of
   Texas Dallas
RP Wang, CB (corresponding author), East China Normal Univ, Shanghai, Peoples R China.
EM 52184501009@stu.ecnu.edu.cn; kzhang@utdallas.edu; cbwang@sei.ecnu.edu.cn
CR Agostinelli F, 2016, 3 INT C LEARN REPR
   [Anonymous], 2016, ICML
   [Anonymous], 2016, NIPS Workshop on Adversarial Training
   Badrinarayanan V, 2015, ARXIVABS150507293
   Dmitry U, 2016, ARXIVABS160708022
   Gatys L., 2015, NIPS
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hwang Y, 2014, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2014.427
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jiang Y, 2019, AAAI CONF ARTIF INTE, P4015
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Li W, 2018, 2018 INT C ADV CONTR
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu PY, 2017, PROC INT CONF DOC, P1095, DOI 10.1109/ICDAR.2017.181
   Mehdi M, 2014, ARXIVABS14111784
   Mirza M, 2018, ARXIVABS181204451
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taigman Y, 2016, 5 INT C LEARN REPR
   Wu SJ, 2020, ARXIVABS200512500
   Yang S, 2017, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR.2017.308
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zong A, 2014, AAAI CONF ARTIF INTE, P3024
NR 31
TC 4
Z9 4
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6737
EP 6754
DI 10.1007/s11042-020-09709-5
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581952100002
DA 2024-07-18
ER

PT J
AU Ullah, S
   Bhatti, N
   Qasim, T
   Hassan, N
   Zia, M
AF Ullah, Sami
   Bhatti, Naeem
   Qasim, Tehreem
   Hassan, Najmul
   Zia, Muhammad
TI Weakly-supervised action localization based on seed superpixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action localization; Action recognition; Feature extraction; Seed
   superpixels
ID HUMAN ACTION RECOGNITION
AB In this paper, we present action localization based on weak supervision with seed superpixels. In order to benefit from the superpixel segmentation and to learn a priori knowledge we select the seed superpixels from the action and non-action areas of few video frames of an action sequence equally. We compute correlation, joint entropy and joint histogram as the features of the video frame superpixels based on the optical flow magnitudes and intensity information. An SVM is trained with the action and non-action seed superpixels features and is used to classify the video frame superpixels as action and non-action. The superpixels classified as action provide the action localization. The localized action superpixels are used to recognize the action class by the Dendrogram-SVM based on the already extracted features. We evaluate the performance of the proposed approach for action localization and recognition using UCF sports and UCF-101 actions datasets, which demonstrates that the seed superpixels provide effective action localization and in turn facilitates to recognize the action class.
C1 [Ullah, Sami; Bhatti, Naeem; Qasim, Tehreem; Hassan, Najmul; Zia, Muhammad] Quaid I Azam Univ, Dept Elect, COMSIP Lab, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Bhatti, N (corresponding author), Quaid I Azam Univ, Dept Elect, COMSIP Lab, Islamabad 45320, Pakistan.
EM nbhatti@qau.edu.pk
RI Ullah, Sami/IAM-8005-2023
CR Abidi SR, ARXIV150708363
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aljanabi MA, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1626, DOI 10.1109/CompComm.2017.8322815
   [Anonymous], ARXIV12120402
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Dedeoglu Y, 2006, LECT NOTES COMPUT SC, V3979, P64
   Del Pero L, 2017, INT J COMPUT VISION, V121, P303, DOI 10.1007/s11263-016-0939-9
   Guermeur Y, 2000, IEEE IJCNN, P183, DOI 10.1109/IJCNN.2000.860770
   Islam S, 2018, SIGNAL IMAGE VIDEO P, V12, P853, DOI 10.1007/s11760-017-1228-y
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liu CW, 2016, IEEE T CYBERNETICS, V46, P2596, DOI 10.1109/TCYB.2015.2482970
   Liu S, 2017, INT CONF MACH LEARN, P299
   Liu YN, 2018, 2018 WRC SYMPOSIUM ON ADVANCED ROBOTICS AND AUTOMATION (WRC SARA), P1, DOI 10.1109/WRC-SARA.2018.8584214
   Ma F, ARXIV200306845
   Ma SG, 2018, INT J COMPUT VISION, V126, P314, DOI 10.1007/s11263-016-0980-8
   Ma SG, 2013, IEEE I CONF COMP VIS, P2744, DOI 10.1109/ICCV.2013.341
   Mahbub U, 2014, SIGNAL IMAGE VIDEO P, V8, P243, DOI 10.1007/s11760-013-0533-3
   Malvestio M, 2019, ENTHYMEMA, P1, DOI 10.13130/2037-2426/11917
   Mettes P, ARXIV170709143
   Mettes P, 2019, INT J COMPUT VISION, V127, P263, DOI 10.1007/s11263-018-1120-4
   Mettes P, 2017, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2017.476
   Mettes P, 2016, LECT NOTES COMPUT SC, V9909, P437, DOI 10.1007/978-3-319-46454-1_27
   Mettes Pascal, 2018, ARXIV180702800
   Oszust M, 2017, SIGNAL IMAGE VIDEO P, V11, P1261, DOI 10.1007/s11760-017-1083-x
   Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Su YT, 2019, MULTIMED TOOLS APPL, V78, P767, DOI 10.1007/s11042-018-5657-6
   Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341
   Tran D., 2012, ADV NEURAL INFORM PR, P350
   van Gemert Jan C., 2015, BMVC, V2, P4
   Xu WR, 2019, NEUROCOMPUTING, V333, P351, DOI 10.1016/j.neucom.2019.01.008
   Yang J, 2017, IEEE I CONF COMP VIS, P2176, DOI 10.1109/ICCV.2017.237
   Yu J, 2014, NEUROCOMPUTING, V131, P200, DOI 10.1016/j.neucom.2013.10.024
   Zhang HL, 2019, MULTIMED TOOLS APPL, V78, P9919, DOI 10.1007/s11042-018-6622-0
   Zhou Z, 2015, IEEE T MULTIMEDIA, V17, P512, DOI 10.1109/TMM.2015.2404779
NR 40
TC 2
Z9 2
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6203
EP 6220
DI 10.1007/s11042-020-09992-2
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578275300003
DA 2024-07-18
ER

PT J
AU Meikap, S
   Jana, B
AF Meikap, Sudipta
   Jana, Biswapati
TI Improved center-folding based directional pixel value ordering for
   reversible data hiding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Center-folding; Directional
   pixel-value-ordering; Embedding capacity; Steganalysis; Steganographic
   attacks
ID DIFFERENCE EXPANSION; PVO
AB In the context of Reversible Data Hiding scheme (RDH), twin image-based methods have been widely used in recent years. Pixels of any cover image block are organized in ascending order and then modify the largest and smallest pixel to embed hidden information exploiting Pixel Value Ordering (PVO) techniques. The DPVO (Directional PVO) has been utilized in three orientations such as a horizontal, vertical and crosswise line applied one after other. Meanwhile, center folding method compresses the valuable hidden information and then embedded it within pixels of dual stego-images through averaging. The proposed scheme embed more than two data bits positions in any row of the image block which is possible by introducing a new parameter alpha, which was not reported by other PVO based RDH schemes. The Embedding Capacity (EC) is improved without compromising visual quality when the secret information is embedded using the center folding strategy combining with the DPVO scheme. The proposed method uses different image block sizes to demonstrate the relationship between the data hiding rate with visual quality of the stego image. The experimental outcomes indicate that the suggested method is suitable to embed high amount of hidden data with a good visual quality, that can be assured by comparing with other state-of-the-art methods. The intended result highlighted some impressive sublime features in the field of image identification, manipulation and forgery detection in which technical life stunts. This system profits enormously from numerous aspects of government and the private sector including education, economic protection, defence, intellectual property rights.
C1 [Meikap, Sudipta] Hijli Coll, Dept Comp Sci, Paschim Medinipur 721306, W Bengal, India.
   [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Meikap, S (corresponding author), Hijli Coll, Dept Comp Sci, Paschim Medinipur 721306, W Bengal, India.
EM sudiptameikap@gmail.com; biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li SH, 2007, J DATABASE MANAGE, V18, P1, DOI 10.4018/jdm.2007100101
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Lu TC, 2021, SOFT COMPUT, V25, P161, DOI 10.1007/s00500-020-05129-7
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Meikap S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0659-1
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Nottingham Trent University, UCID IM DAT
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   University of California Berkeley, BERK SEGM DAT BENCHM
   University of Southern California, USC SIPI IMAGE DATAB
NR 29
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5617
EP 5652
DI 10.1007/s11042-020-09823-4
EA OCT 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600002
DA 2024-07-18
ER

PT J
AU Ko, D
   Lee, S
   Park, J
AF Ko, Dongbeom
   Lee, Seunghwa
   Park, Jeongmin
TI A study on manufacturing facility safety system using multimedia tools
   for cyber physical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth Image Camera; Multimedia Tools; 3D Simulation; Cyber-Physical
   Systems; Autonomic Computing; MTConnect
ID HUMAN-ROBOT COLLABORATION; ARCHITECTURE; MODEL
AB This paper applies depth images and a 3D simulation to introduce a safety system for manufacturing facilities. Smart systems have recently become an important topic for use in the manufacturing industry, and these are now being developed with newly-introduced A.I.-based technologies. Smart manufacturing systems introduced with A.I. enable more efficient production than before, but these offer limited improvements at first. To further enhance production, collaborative intelligence can combine human creativity with the speed and accuracy of the equipment, complementing the shortcomings of each production method. However, collaboration in existing facilities requires new safety measures for workers because there is a higher propensity for accidents due to collisions. A recent study on worker-equipment collisions has shortcomings in that a collision between workers and equipment is inevitable because whether or not a collision occurs with a worker is checked only by using a sensor inside the robot. Therefore, this study installs a depth image camera outside the equipment, not a sensor inside, and the system can produce simulations in advance in a virtual environment before finalizing the design of the operation and equipment. A comparison of a simulation to the actual movement of a robot arm toward the point of collision with a worker confirmed an error of about 10.048 cm. Through this, it is possible to detect worker-equipment collision in advance.
C1 [Ko, Dongbeom; Park, Jeongmin] Korea Polytech Univ, Dept Comp Engn, 237 Sangidaehak Ro, Siheung Si 15073, Gyeonggi Do, South Korea.
   [Lee, Seunghwa] Baekseok Univ, Div Informat & Commun, 76 Munam Ro, Cheonan Si 31065, Chungcheongnam, South Korea.
C3 Korea Polytechnic University; Baekseok University
RP Park, J (corresponding author), Korea Polytech Univ, Dept Comp Engn, 237 Sangidaehak Ro, Siheung Si 15073, Gyeonggi Do, South Korea.
EM dbko112@gmail.com; sh.lee@bu.ac.kr; jmpark@kpu.ac.kr
OI Ko, Dongbeom/0000-0002-6488-7291
FU National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [2017R1A2B4011243]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT) (No.
   2017R1A2B4011243).
CR Aivaliotis P, 2019, ROBOT CIM-INT MANUF, V59, P346, DOI 10.1016/j.rcim.2019.05.001
   Al-Hami M, 2019, MULTIMED TOOLS APPL, V78, P3609, DOI 10.1007/s11042-018-6931-3
   Anderl R, 2015, AT-AUTOM, V63, P753, DOI 10.1515/auto-2015-0025
   [Anonymous], 2009, AUTONOMIC COMPUTING
   AsSadhan B, 2020, MULTIMED TOOLS APPL, V79, P12727, DOI 10.1007/s11042-020-08653-8
   Bagheri B, 2015, IFAC PAPERSONLINE, V48, P1622, DOI 10.1016/j.ifacol.2015.06.318
   Bratukhin A, 2011, IEEE T IND INFORM, V7, P740, DOI 10.1109/TII.2011.2167155
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   De Santis A, 2008, MECH MACH THEORY, V43, P253, DOI 10.1016/j.mechmachtheory.2007.03.003
   Edrington B, 2014, PROC CIRP, V22, P92, DOI 10.1016/j.procir.2014.07.148
   Ghosh D, 2007, DECIS SUPPORT SYST, V42, P2164, DOI 10.1016/j.dss.2006.06.011
   Gustaysson P, 2018, PROC CIRP, V72, P123, DOI 10.1016/j.procir.2018.03.156
   Heo YJ, 2019, IEEE ROBOT AUTOM LET, V4, P740, DOI 10.1109/LRA.2019.2893400
   Hu F, 2016, FUTURE GENER COMP SY, V56, P449, DOI 10.1016/j.future.2015.06.006
   Iarovyi S, 2016, P IEEE, V104, P1142, DOI 10.1109/JPROC.2015.2509498
   Jiang YC, 2018, IEEE ACCESS, V6, P47374, DOI 10.1109/ACCESS.2018.2866403
   Jin X, 2017, IEEE T AUTOMAT CONTR, V62, P6058, DOI 10.1109/TAC.2017.2652127
   Kim KD, 2012, P IEEE, V100, P1287, DOI 10.1109/JPROC.2012.2189792
   Kim TH, 2019, PROCEDIA COMPUT SCI, V151, P600, DOI 10.1016/j.procs.2019.04.081
   Kumara WGCW, 2017, MULTIMED TOOLS APPL, V76, P11687, DOI 10.1007/s11042-016-3327-0
   Lin WY, 2015, MULTIMED TOOLS APPL, V74, P3155, DOI 10.1007/s11042-013-1776-2
   Lins T, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106193
   Liu C, 2019, J MANUF SYST, V51, P61, DOI 10.1016/j.jmsy.2019.04.006
   Liu C, 2018, PROC CIRP, V72, P492, DOI 10.1016/j.procir.2018.03.059
   Liu HY, 2020, J MANUF SYST, V54, P24, DOI 10.1016/j.jmsy.2019.11.001
   Lu CH, 2018, IEEE T HUM-MACH SYST, V48, P380, DOI 10.1109/THMS.2018.2844119
   Mao YH, 2011, SYST ENG PROC, V1, P213, DOI 10.1016/j.sepro.2011.08.034
   Mitrea D, 2018, IEEE ACCESS, V6, P50245, DOI 10.1109/ACCESS.2018.2869346
   Monostori L, 2016, CIRP ANN-MANUF TECHN, V65, P621, DOI 10.1016/j.cirp.2016.06.005
   Networking and Information Technology Research and Development, 2015, CYBER PHYS SYSTEMS
   Park J, 2015, CLUSTER COMPUT, V18, P587, DOI 10.1007/s10586-014-0414-8
   Vinh PC, 2016, FUTURE GENER COMP SY, V56, P140, DOI 10.1016/j.future.2015.04.017
   Quintas J, 2017, IEEE T HUM-MACH SYST, V47, P323, DOI 10.1109/THMS.2016.2634923
   Robla S, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-88
   Robla-Gómez S, 2017, IEEE ACCESS, V5, P26754, DOI 10.1109/ACCESS.2017.2773127
   Shanzhi Chen, 2017, IEEE Communications Standards Magazine, V1, P70, DOI 10.1109/MCOMSTD.2017.1700015
   Stern H, 2017, PROCEDIA MANUF, V9, P151, DOI 10.1016/j.promfg.2017.04.030
   Stock D, 2019, PROC CIRP, V81, P393, DOI 10.1016/j.procir.2019.03.068
   Vorndamme Jonathan, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4754, DOI 10.1109/ICRA.2017.7989552
   Witsch M, 2012, IEEE T IND INFORM, V8, P311, DOI 10.1109/TII.2012.2186585
   Zeadally S, 2019, IEEE ACCESS, V7, P171126, DOI 10.1109/ACCESS.2019.2956124
   Zhu KP, 2018, IEEE-ASME T MECH, V23, P2579, DOI 10.1109/TMECH.2018.2834622
NR 42
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34553
EP 34570
DI 10.1007/s11042-020-09925-z
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000573572200002
DA 2024-07-18
ER

PT J
AU Ye, MJ
   Hu, CH
   Wan, LG
   Lei, GH
AF Ye, Meng-Jun
   Hu, Chang-Hui
   Wan, Li-Guang
   Lei, Gai-Hui
TI Fast single sample face recognition based on sparse representation
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single sample face recognition; ESRC; Positive sparse coefficient based
   ESRC; Large positive sparse coefficient based ESRC
ID TRAINING SAMPLE
AB The extended sparse representation classification (ESRC) is one of the benchmark classification algorithms in the field of single sample face recognition (SSFR). However, when there are many single training samples, the execution time of ESRC cannot be acceptable in real face recognition systems. We assume the similarity principle of sparse representation under valid SSFR as that, if the test image is more similar to certain single training sample, the corresponding sparse coefficient of this single training sample may be larger, and the representation residual of this single training sample may be smaller. Based on this assumption, we propose the fast ESRC method to tackle many single training samples problem. Firstly, we propose the positive sparse coefficient based ESRC (PESRC) that selects to compute representation residuals of single training samples whose sparse coefficients of ESRC are positive. Then, we propose the statistical analysis of the sparse coefficient ratio, which is used to develop the large positive sparse coefficient based ESRC (LESRC) that calculates representation residuals of the single training samples corresponding to large positive sparse coefficients of PESRC. Finally, the experiment results on Extended Yale B, AR, CMU PIE and VGGFace2 face databases indicate that the proposed PESRC and LESRC can significantly improve the computation efficiency of ESRC. On our platform, the execution time of recognizing only one test image for ESRC or VGG + ESRC is over 130 s (the execution time of ESRC and VGG + ESRC are 562.71 s and 135.02 s) under 9125 single training samples, whereas the execution times of PESRC, LESRC, VGG + PESRC, and VGG + LESRC are 2.20s, 0.23 s, 0.71 s, and 0.03 s respectively.
C1 [Ye, Meng-Jun; Wan, Li-Guang; Lei, Gai-Hui] Hubei Normal Univ, Coll Mechatron Control Engn, Huangshi 435002, Hubei, Peoples R China.
   [Hu, Chang-Hui] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Peoples R China.
   [Hu, Chang-Hui] Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Nanjing 210023, Peoples R China.
C3 Hubei Normal University; Nanjing University of Posts &
   Telecommunications; Nanjing University of Posts & Telecommunications
RP Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Peoples R China.; Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Nanjing 210023, Peoples R China.
EM hchnjupt@126.com
OI Hu, Chang-Hui/0000-0002-7291-4931
FU National Natural Science Foundation of China [61802203]; Natural Science
   Foundation of Jiangsu Province [BK20180761]; China Postdoctoral Science
   Foundation Funded Project [2019 M651653]; Jiangsu Planned Projects for
   Postdoctoral Research Funds [2019 K124]; Nanjing University of Posts and
   Telecommunications Science Foundation [NY218119]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.61802203), Natural Science Foundation of Jiangsu
   Province (Grant No. BK20180761), China Postdoctoral Science Foundation
   Funded Project (Grant No.2019 M651653), Jiangsu Planned Projects for
   Postdoctoral Research Funds (No.2019 K124), and the Nanjing University
   of Posts and Telecommunications Science Foundation (Grant No. NY218119).
CR Abdelmaksoud M, 2020, IEEE ACCESS, V8, P102212, DOI 10.1109/ACCESS.2020.2999030
   Benavente R, 1998, 24 COMP VIS CTR
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Fan ZZ, 2020, MULTIMED TOOLS APPL, V79, P7319, DOI 10.1007/s11042-019-08211-x
   Fan ZZ, 2018, PATTERN RECOGN, V76, P1, DOI 10.1016/j.patcog.2017.10.001
   Gao SH, 2015, INT J COMPUT VISION, V111, P365, DOI 10.1007/s11263-014-0750-4
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He MJ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107113
   Lahasan B, 2019, ARTIF INTELL REV, V52, P949, DOI 10.1007/s10462-017-9578-y
   Li LP, 2020, MULTIMED TOOLS APPL, V79, P23325, DOI 10.1007/s11042-020-08965-9
   Li Q, 2019, PATTERN RECOGN LETT, V128, P459, DOI 10.1016/j.patrec.2019.10.015
   Liao MM, 2020, NEUROCOMPUTING, V373, P35, DOI 10.1016/j.neucom.2019.09.025
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Mokhayeri F, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107129
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Peng YL, 2018, MACH VISION APPL, V29, P991, DOI 10.1007/s00138-018-0941-z
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P504
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wei CP, 2015, IEEE T IMAGE PROCESS, V24, P1722, DOI 10.1109/TIP.2015.2409738
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang L, 2020, IEEE T IMAGE PROCESS, V29, P1016, DOI 10.1109/TIP.2019.2938307
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
   Zhuang LS, 2013, PROC CVPR IEEE, P3546, DOI 10.1109/CVPR.2013.455
   Zou GF, 2020, MULTIMED TOOLS APPL, V79, P23571, DOI 10.1007/s11042-020-09076-1
NR 31
TC 4
Z9 4
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3251
EP 3273
DI 10.1007/s11042-020-09855-w
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571253200002
DA 2024-07-18
ER

PT J
AU Yu, XL
   Xu, CE
   Dou, BN
   Wang, YT
AF Yu, Xiaoling
   Xu, Chungen
   Dou, Bennian
   Wang, Yuntao
TI Multi-user search on the encrypted multimedia database: lattice-based
   searchable encryption scheme with time-controlled proxy re-encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data security; Searchable encryption; Lattice assumption;
   Multi-user search; Time control
ID PUBLIC-KEY ENCRYPTION; KEYWORD GUESSING ATTACKS; SECURE
AB Multimedia cloud storage which saves the huge storage overhead of local devices has attracted considerable attention. However, due to the lack of physical control of data, the privacy protection of data on the multimedia cloud has become one of the main concerns of users. Public-key encryption with keywords search (PEKS) is a technique that can keep the privacy and searchability of data in the cloud. In this paper, we present a PEKS with time-controlled proxy re-encryption model which allows the data owner to delegate the access right of the encrypted multimedia database to other users, to achieve the time-controlled multi-user search. Furthermore, it is designed to resist keywords guessing attack and support conjunctive keywords search. Compared with previous works which require a time server to generate a time seal for the generation of the search token, this model embeds the time information of accessing the encrypted database into public and secret key pairs of data users, which saves the managing overhead and reduces the security risks resulting from an extra server. In addition, most existing PEKS schemes were constructed based on the hardness of classical mathematical problems which can be broken by quantum computers. To address this issue, a lattice-based PEKS scheme based on the above model is proposed, which can be considered as the candidate for protecting multimedia data security in the quantum era.
C1 [Yu, Xiaoling; Xu, Chungen; Dou, Bennian] Nanjing Univ Sci & Technol, Sch Sci, Nanjing 210094, Peoples R China.
   [Wang, Yuntao] Japan Adv Inst Sci & Technol, Sch Informat Sci Secur & Networks, Nomi, Ishikawa 9231292, Japan.
C3 Nanjing University of Science & Technology; Japan Advanced Institute of
   Science & Technology (JAIST)
RP Xu, CE (corresponding author), Nanjing Univ Sci & Technol, Sch Sci, Nanjing 210094, Peoples R China.
EM xuchung@njust.edu.cn
RI Xu, Chungen/AAE-3042-2022; Wang, Yuntao/AFS-4057-2022; Xu,
   Chungen/B-7969-2016
OI Xu, Chungen/0000-0001-9380-5913; YU, Xiaoling/0000-0003-4860-7517; Wang,
   Yuntao/0000-0002-2872-4508
FU Fundamental Research Funds for the Central Universities [30918012204]
FX The authors would like to thank the support from Fundamental Research
   Funds for the Central Universities (No.30918012204), China. The authors
   also gratefully acknowledge the helpful comments and suggestions of
   other researchers for improving the presentation.
CR Agrawal S, 2010, LECT NOTES COMPUT SC, V6223, P98, DOI 10.1007/978-3-642-14623-7_6
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Ajtai M., 1999, Automata, Languages and Programming. 26th International Colloquium, ICALP'99. Proceedings (Lecture Notes in Computer Science Vol.1644), P1
   Alwen J, 2011, THEOR COMPUT SYST, V48, P535, DOI 10.1007/s00224-010-9278-3
   [Anonymous], IEEE T DEPENDABLE SE
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Brakerski Z, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P575
   Byun JW, 2006, LECT NOTES COMPUT SC, V4165, P75
   Cash D, 2010, LECT NOTES COMPUT SC, V6110, P523
   Chen RM, 2015, LECT NOTES COMPUT SC, V9144, P59, DOI 10.1007/978-3-319-19962-7_4
   Chen YL, 2018, IEICE T COMMUN, VE101B, P1798, DOI 10.1587/transcom.2017EBP3274
   Chunxiang Gu, 2015, Cloud Computing and Big Data. Second International Conference, CloudCom-Asia 2015. Revised Selected Papers: LNCS 9106, P335, DOI 10.1007/978-3-319-28430-9_25
   Fang LM, 2013, INFORM SCIENCES, V238, P221, DOI 10.1016/j.ins.2013.03.008
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Gordon SD, 2010, LECT NOTES COMPUT SC, V6477, P395, DOI 10.1007/978-3-642-17373-8_23
   Huang Q, 2017, INFORM SCIENCES, V403, P1, DOI 10.1016/j.ins.2017.03.038
   Li YB, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978575
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Rhee HS, 2010, J SYST SOFTWARE, V83, P763, DOI 10.1016/j.jss.2009.11.726
   Shao J, 2010, INFORM SCIENCES, V180, P2576, DOI 10.1016/j.ins.2010.03.026
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Sun LX, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9124-0
   Wang HG, 2014, IEEE COMMUN MAG, V52, P73, DOI 10.1109/MCOM.2014.6766088
   Wang XA, 2012, J SYST SOFTWARE, V85, P643, DOI 10.1016/j.jss.2011.09.035
   Xu L, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P122, DOI 10.1145/3321705.3329814
   Xu LL, 2019, J NETW COMPUT APPL, V128, P11, DOI 10.1016/j.jnca.2018.12.003
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Yang Y, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4211
   Yang Y, 2016, IEEE T INF FOREN SEC, V11, P746, DOI 10.1109/TIFS.2015.2509912
   Zhang XJ, 2021, IEEE T DEPEND SECURE, V18, P1019, DOI 10.1109/TDSC.2019.2914117
   Zhang XJ, 2018, WIRELESS PERS COMMUN, V100, P907, DOI 10.1007/s11277-018-5357-6
NR 31
TC 5
Z9 5
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3193
EP 3211
DI 10.1007/s11042-020-09753-1
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200014
DA 2024-07-18
ER

PT J
AU Aggarwal, A
   Kumar, M
AF Aggarwal, Akarsh
   Kumar, Manoj
TI Image surface texture analysis and classification using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface texture classification; Deep learning; Convolution neural
   network; Pattern classification
ID DEFECTS; FEATURES; COLOR
AB Recently, the classification of surface textures is carried out using various modelling approaches. To analyse the surface texture, most of the techniques uses large amount of training data which adds up to considerable computational cost. However, the implementation of various neural network models also requires significant amount of training images to classify surface textures. In the proposed paper, a deep learning-based model is presented using convolution neural network (CNN). Further, this model is divided into two sub models knowing model-1 and model-2. The approach is designed with customized parameters configuration to classify surface texture using a smaller number of training samples. The image feature vectors are generated using statistical operations to compute the physical appearance of the surface and a CNN model is used to classify the generated surfaces with appropriate labels into classes. The Kylberg Texture dataset is used to evaluate the proposed models using 16 texture classes. The advantage of proposed models over pre-trained networks is that the entire models is customized according to specific training requirements. Further, to demonstrate the state-of-the-art results, the proposed approach is compared with other existing techniques. Our experimental results are better than the conventional techniques and achieves an accuracy of 92.42% for model-1 and 96.36% for model-2. In addition, the proposed models maintain balance between accuracy and computational cost.
C1 [Aggarwal, Akarsh] Univ Bristol, Bristol, Avon, England.
   [Kumar, Manoj] Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 University of Bristol; University of Petroleum & Energy Studies (UPES)
RP Kumar, M (corresponding author), Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
EM aakarsh.aggarwal2@gmail.com; wss.manojkumar@gmail.com
RI KUMAR, MANOJ/P-7489-2014
OI KUMAR, MANOJ/0000-0001-5113-0639; Aggarwal, Akarsh/0000-0002-0713-0129
CR Aggarwal T, 2020, SMART SUSTAIN BUILT, V9, P711, DOI 10.1108/SASBE-06-2019-0076
   [Anonymous], 2023, ARTIF INTELL APPL, DOI DOI 10.47852/BONVIEWAIA2202293
   Brownlee Jason., 2019, Gentle Introduction to the Adam Optimization Algorithm for Deep Learning
   Chang HS, 2005, IEEE T IMAGE PROCESS, V14, P145, DOI 10.1109/TIP.2004.840706
   Chantler M, 2005, INT J COMPUT VISION, V62, P83, DOI 10.1007/s11263-005-4636-3
   Chatra K, 2019, WIRELESS PERS COMMUN, V108, P1513, DOI 10.1007/s11277-019-06482-z
   Chen Lin, 2017, [Computational Visual Media, 计算可视媒体], V3, P83
   Chen Z, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2632, DOI 10.1109/IJCNN.2011.6033562
   Cho M., 2020, ARXIV200300697, V3, P7
   Chondronasios A, 2016, INT J ADV MANUF TECH, V83, P33, DOI 10.1007/s00170-015-7514-3
   Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Ferreira A, 2017, EXPERT SYST APPL, V84, P1, DOI 10.1016/j.eswa.2017.04.053
   Gibert X, 2017, IEEE T INTELL TRANSP, V18, P153, DOI 10.1109/TITS.2016.2568758
   Goyal V., 2019, J ADV RES DYN CONTRO, V11, P253
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hanzaei SH, 2017, PATTERN RECOGN, V66, P174, DOI 10.1016/j.patcog.2016.11.021
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2002, IEEE T SYST MAN CY B, V32, P553, DOI 10.1109/TSMCB.2002.1033176
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P12451, DOI 10.1007/s11042-018-6775-x
   Kylberg G, BLUE SERIES, V35
   Labati RD, 2018, PATTERN RECOGN LETT, V113, P58, DOI 10.1016/j.patrec.2017.04.001
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu C, 2019, PATTERN RECOGN, V85, P90, DOI 10.1016/j.patcog.2018.08.002
   Mäenpää T, 2003, PATTERN ANAL APPL, V6, P169, DOI 10.1007/s10044-002-0179-1
   Mallik-Goswami B, 2000, TEXT RES J, V70, P758, DOI 10.1177/004051750007000902
   Park JK, 2016, INT J PR ENG MAN-GT, V3, P303, DOI 10.1007/s40684-016-0039-x
   Shin BS, 2015, PATTERN RECOGN, V48, P3333, DOI 10.1016/j.patcog.2014.10.011
   Tao X, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091575
   Thompson EM, 2018, PATTERN RECOGN, V82, P1, DOI 10.1016/j.patcog.2018.04.028
   Veerashetty S, 2019, MULTIMED TOOLS APPL, P1
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Xie YH, 2015, OPTIK, V126, P2231, DOI 10.1016/j.ijleo.2015.05.101
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 40
TC 32
Z9 32
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1289
EP 1309
DI 10.1007/s11042-020-09520-2
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700007
DA 2024-07-18
ER

PT J
AU Ren, YM
   Yang, J
   Zhang, QN
   Guo, ZQ
AF Ren, Yongmei
   Yang, Jie
   Zhang, Qingnian
   Guo, Zhiqiang
TI Ship recognition based on Hu invariant moments and convolutional neural
   network for video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ship recognition; Convolutional neural network; Hu invariant moments;
   Wavelet transform; Image segmentation
ID CLASSIFICATION; FEATURES
AB To solve the issue with automatic recognition of ship images in video surveillance system, this study proposes a ship recognition approach based on Hu invariant moments and Convolutional Neural Network (CNN). Ship image is firstly denoised using improved threshold function of Wavelet Transform (WT) and then segmented via iterative auto-threshold segmentation algorithm to extract the ship area in the image. After that improved CNN is applied to further extract features of ship images. At the same time the image is divided into sub-images horizontally where Hu invariant moments is extracted. The Hu invariant moments of each sub-image are concatenated into a composite vector as the Hu invariant moments of the whole image, which are integrated with spatial location information. The last step is to fuse the CNN features and Hu invariant moments to obtain discriminative feature representation. Hu invariant moments which are invariant to translation, rotation and scaling are used to supplement the shape and contour information of the ship images. And Softmax function is applied to automatically recognize ship images in the output layer. Two fusion methods have been applied to verify the effectiveness of the proposed approach based on feature extraction at different levels. Experimental results show that the first fusion method achieves highest recognition accuracy in self-built dataset and visible and infrared spectrums (VAIS) dataset, up to 98.28% and 92.80% respectively. Recognition accuracy of the second fusion method is also higher than existing methods. Moreover, results obtained from F1-score and confusion matrix further validate the effectiveness of the proposed approach.
C1 [Ren, Yongmei; Yang, Jie; Guo, Zhiqiang] Wuhan Univ Technol, Sch Informat Engn, Hubei Key Lab Broadband Wireless Commun & Sensor, Wuhan 430070, Peoples R China.
   [Ren, Yongmei] Hunan Inst Technol, Sch Elect & Informat Engn, Hengyang 421002, Peoples R China.
   [Zhang, Qingnian] Wuhan Univ Technol, Sch Transportat, Wuhan 430070, Peoples R China.
C3 Wuhan University of Technology; Hunan Institute of Technology; Wuhan
   University of Technology
RP Ren, YM (corresponding author), Wuhan Univ Technol, Sch Informat Engn, Hubei Key Lab Broadband Wireless Commun & Sensor, Wuhan 430070, Peoples R China.; Ren, YM (corresponding author), Hunan Inst Technol, Sch Elect & Informat Engn, Hengyang 421002, Peoples R China.
EM 2264924701@qq.com
RI Yang, Jie/JCD-9867-2023
OI Ren, Yongmei/0000-0001-6282-6308
FU National Nature Science Foundation of China [51879211]; Scientific
   Research Project of the Hunan Provincial Education Department [18C0900]
FX This work was supported by the National Nature Science Foundation of
   China (Grant No. 51879211), and the Scientific Research Project of the
   Hunan Provincial Education Department (Grant No. 18C0900).
CR Akilan T, 2018, IET IMAGE PROCESS, V12, P1102, DOI 10.1049/iet-ipr.2017.0232
   Al Shalabi L., 2006, Journal of Computer Sciences, V2, P735, DOI 10.3844/jcssp.2006.735.739
   Arguedas VF, 2015, IEEE IMAGE PROC, P3866, DOI 10.1109/ICIP.2015.7351529
   Bentes C, 2018, IEEE J OCEANIC ENG, V43, P258, DOI 10.1109/JOE.2017.2767106
   Cao XF, 2020, MULTIMED TOOLS APPL, V79, P9177, DOI 10.1007/s11042-018-7138-3
   Cheng G, 2016, PROC CVPR IEEE, P2884, DOI 10.1109/CVPR.2016.315
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng GH, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P158, DOI 10.1109/CIS.2015.46
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Dong C, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030400
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Du QW, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P414, DOI 10.1109/ICTIS.2017.8047799
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feineigle PA, 2007, P ASS UNM VEH SYST I, P249
   Gallego AJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040511
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang LH, 2018, MULTIMED TOOLS APPL, V77, P13363, DOI 10.1007/s11042-017-4952-y
   Jain P, 2017, MULTIMED TOOLS APPL, V76, P1659, DOI 10.1007/s11042-015-3154-8
   Kang M, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080860
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li ZZ, 2019, J ENG-JOE, V2019, P7343, DOI 10.1049/joe.2019.0422
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010063
   Palaz D, 2019, SPEECH COMMUN, V108, P15, DOI 10.1016/j.specom.2019.01.004
   Qin CX, 2018, MATER SCI ENG, V452, P042199, DOI 10.1088/1757-899X/452/4/042199
   Rainey K, 2016, PROC SPIE, V9844, DOI 10.1117/12.2229366
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shi QQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040419
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JL, 2018, CHIN CONTR CONF, P7354
   Song Q, 2016, PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON CONTROL SCIENCE AND SYSTEMS ENGINEERING (ICCSSE), P64, DOI 10.1109/CCSSE.2016.7784354
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang QC, 2018, IEEE J BIOMED HEALTH, V22, P184, DOI 10.1109/JBHI.2017.2685586
   Wang YY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092929
   [徐芳 Xu Fang], 2018, [传感器与微系统, Transducer and Microsystem Technology], V37, P43
   Zhang Difei, 2016, INFRARED LASER ENG, V45, P167, DOI DOI 10.3788/IRLA201645.1018006
   Zhang EH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102153
   Zhang Mabel M., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301291
   Zhuo L, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051222
NR 45
TC 19
Z9 21
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1343
EP 1373
DI 10.1007/s11042-020-09574-2
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700005
DA 2024-07-18
ER

PT J
AU Han, L
   Piao, JY
   Tong, YN
   Yu, B
   Lan, PY
AF Han, Li
   Piao, Jingyu
   Tong, Yuning
   Yu, Bing
   Lan, Pengyan
TI Deep learning for non-rigid 3D shape classification based on informative
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape classification; Deep learning; Non-rigid 3D shape; View-based 3D
   shape recognition; Bag-of-features
ID SIMILARITY
AB In order to enhance the discernment of features in view-based 3D shape recognition, we propose a joint convolutional neural network (CNN) learning model based on informative images. It learns deep features from intrinsic feature images and extrinsic 2D views, and generates a synthetic feature vector via weighted aggregation and refinement process, which has achieved remarkable improvement in non-rigid 3D shape classification. Our joint CNNs model contains three parts: the first part is the geometry-based feature generation unit. We provide a discriminative BoF (bag of features) image descriptor and construct CNN framework to learn the geometric features of the model. The second part is the view-based feature generation unit. We establish a parallel CNN to extract spatial features from optimized 2D views. The third part is a score generation and refinement unit, which automatically learns the weighted scores of geometric features and spatial features. Finally, the aggregated feature is refined in a CNN framework and serves as an informative shape descriptor for recognition task. The experimental results demonstrate that our deep features have the strong discerning ability. Thus, better performance and robustness can be obtained compared to state-of-the-art methods.
C1 [Han, Li; Piao, Jingyu; Tong, Yuning; Yu, Bing; Lan, Pengyan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Han, L (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
EM hl_dlls@dl.cn
OI Han, Li/0000-0002-0975-9908
FU NSFC [61702246]; Liaoning province [2019lsktyb-084, 2020JH4/10100045];
   fund of Dalian Science and Technology [2019J12GX038]
FX We would like to thank the anonymous reviewers for their helpful
   comments. The research presented in this paper is supported by a grant
   from NSFC (61702246), grants from research project of Liaoning province
   (2019lsktyb-084, 2020JH4/10100045) and a fund of Dalian Science and
   Technology (2019J12GX038).
CR [Anonymous], 2015, P INT C INT ROB SYST
   [Anonymous], 2017, P CVPR
   [Anonymous], 2015, P ICCV
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Bu SH, 2014, IEEE MULTIMEDIA, V21, P38, DOI 10.1109/MMUL.2014.52
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Ghodrati Hamed, 2016, International Journal of Multimedia Information Retrieval, V5, P151, DOI 10.1007/s13735-016-0103-x
   Ghodrati H, 2017, APPL INTELL, V47, P44, DOI 10.1007/s10489-016-0880-1
   Guo HY, 2016, IEEE T IMAGE PROCESS, V25, P5526, DOI 10.1109/TIP.2016.2609814
   Han L, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.1.010501
   Han ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3707, DOI 10.1109/TIP.2017.2704426
   Lavoue G., 2011, Eurographics Conference on 3D Object Retrieval, P41, DOI DOI 10.2312/3DOR/3DOR11/041-048
   Leng B, 2018, IEEE T VIS COMPUT GR
   Litman R, 2014, COMPUT GRAPH FORUM, V33, P127, DOI 10.1111/cgf.12438
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Luciano P, 2017, CELL DISCOV, V3, DOI 10.1038/celldisc.2017.40
   Masoumi M, 2017, J VIS COMMUN IMAGE R, V43, P198, DOI 10.1016/j.jvcir.2017.01.001
   Masoumi M, 2016, PATTERN RECOGN LETT, V83, P339, DOI 10.1016/j.patrec.2016.04.009
   Matsuda T, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P100, DOI 10.1109/BigMM.2015.66
   Mohamed W, 2016, APPL INTELL, V45, P213, DOI 10.1007/s10489-015-0746-y
   Ovsjanikov Maks, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P320, DOI 10.1109/ICCVW.2009.5457682
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Qi Charles R, 2018, P CVPR
   RAWAT AS, 2019, ADV NEUR IN, V32
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rustamov R, P S GEOM PROC, P225
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Toldo R., 2009, Proceedings of the 2nd Eurographics Conference on 3D Object Retrieval, P21
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Wan LL, 2017, VISUAL COMPUT, V33, P1497, DOI 10.1007/s00371-016-1293-1
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Xie J, 2016, COMPUT VIS PATTERN R
   Ye JB, 2016, VISUAL COMPUT, V32, P553, DOI 10.1007/s00371-015-1071-5
   Yi L, 2019, P SIGGR AS
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhou Y, 2019, LECT NOTES COMPUT SC, V11901, P566, DOI 10.1007/978-3-030-34120-6_46
NR 44
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 973
EP 992
DI 10.1007/s11042-020-09764-y
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900008
DA 2024-07-18
ER

PT J
AU Callemein, T
   Roussel, T
   Diba, A
   De Feyter, F
   Boes, W
   Van Eycken, L
   Van Gool, L
   Van Hamme, H
   Tuytelaars, T
   Goedemé, T
AF Callemein, Timothy
   Roussel, Tom
   Diba, Ali
   De Feyter, Floris
   Boes, Wim
   Van Eycken, Luc
   Van Gool, Luc
   Van Hamme, Hugo
   Tuytelaars, Tinne
   Goedeme, Toon
TI Show me where the action is! Automatic capturing and timeline generation
   for reality TV.
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous PTZ steering; Event timeline; Sound recognition; Facial
   recognition; Action recognition; Reality TV
AB Reality TV shows have gained popularity, motivating many production houses to bring new variants for us to watch. Compared to traditional TV shows, reality TV shows have spontaneous unscripted footage. Computer vision techniques could partially replace the manual labour needed to record and process this spontaneity. However, automated real-world video recording and editing is a challenging topic. In this paper, we propose a system that utilises state-of-the-art video and audio processing algorithms to, on the one hand, automatically steer cameras, replacing camera operators and on the other hand, detect all audiovisual action cues in the recorded video, to ease the job of the film editor. This publication has hence two main contributions. The first, automating the steering of multiple Pan-Tilt-Zoom PTZ cameras to take aesthetically pleasing medium shots of all the people present. These shots need to comply with the cinematographic rules and are based on the poses acquired by a pose detector. Secondly, when a huge amount of audio-visual data has been collected, it becomes labour intensive for a human editor retrieve the relevant fragments. As a second contribution, we combine state-of-the-art audio and video processing techniques for sound activity detection, action recognition, face recognition, and pose detection to decrease the required manual labour during and after recording. These techniques used during post-processing produce meta-data allowing for footage filtering, decreasing the search space. We extended our system further by producing timelines uniting generated meta-data, allowing the editor to have a quick overview. We evaluated our system on three in-the-wild reality TV recording sessions of 24 hours (x 8 cameras) each taken in real households.
C1 [Callemein, Timothy; Roussel, Tom; Diba, Ali; De Feyter, Floris; Boes, Wim; Van Eycken, Luc; Van Gool, Luc; Van Hamme, Hugo; Tuytelaars, Tinne; Goedeme, Toon] Katholieke Univ Leuven, St Katelijne Waver, Belgium.
C3 KU Leuven
RP Callemein, T (corresponding author), Katholieke Univ Leuven, St Katelijne Waver, Belgium.
EM timothy.callemein@kuleuven.be
RI Goedemé, Toon/KIJ-1779-2024; Callemein, Timothy/Y-6964-2019; Van hamme,
   Hugo/D-6581-2012; Tuytelaars, Tinne/B-4319-2015
OI Goedemé, Toon/0000-0002-7477-8961; Callemein,
   Timothy/0000-0001-7461-8071; Van hamme, Hugo/0000-0003-1331-5186; Boes,
   Wim/0000-0001-7344-6116; De Feyter, Floris/0000-0003-2690-0181;
   Tuytelaars, Tinne/0000-0003-3307-9723
CR Al-Hadrusi MS, 2016, IEEE INT SYM MULTIM, P333, DOI [10.1109/ISM.2016.0073, 10.1109/ISM.2016.34]
   [Anonymous], 2007, ACM MM
   [Anonymous], 2018, ABS180406655 CORR
   [Anonymous], 2016, ARXIV160800182
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Callemein T, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P47, DOI 10.23919/MVA.2017.7986769
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Choi I, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112302
   Courtney PG, 2015, IEEE COMP SEMICON
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Diba A, 2019, HOLISTIC LARGE SCALE
   Diba A., 2018, P IEEE C COMP VIS PA, P1117
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gaidon A, 2013, TEMPORAL LOCALIZATIO
   Gemmeke J. F., 2017, P IEEE ICASSP NEW OR
   Girdhar R., 2017, PROC CVPR IEEE, P971, DOI DOI 10.1109/CVPR.2017.337
   Guo Y, 2016, INT J AEROSPACE ENG, V2016, DOI 10.1155/2016/2942686
   GYGLI M, 2015, PROC CVPR IEEE, P3090, DOI DOI 10.1109/CVPR.2015.7298928
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou Y., 2018, P DET CLASS AC SCEN, P78
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Hulens D, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P371, DOI 10.1109/CRV.2014.57
   Inoue K, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030024
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iqbal T, 2018, EUR SIGNAL PR CONF, P2255, DOI 10.23919/EUSIPCO.2018.8553198
   Joe Yue-Hei Ng, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1616, DOI 10.1109/WACV.2018.00179
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Mesaros A, 2018, IEEE-ACM T AUDIO SPE, V26, P379, DOI 10.1109/TASLP.2017.2778423
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Plumbley M. D., 2018, P DET CLASS AC SCEN
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rameau F, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P397
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Sharma Vivek, 2019, INT C AUT FAC GEST R
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tapaswi M, 2014, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2014.111
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tran Du, 2017, ARXIV170805038
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Virtanen T., 2017, P DET CLASS AC SCEN
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2014, LECT NOTES COMPUT SC, V8692, P640, DOI 10.1007/978-3-319-10593-2_42
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiong B, 2015, IEEE I CONF COMP VIS, P4525, DOI 10.1109/ICCV.2015.514
   Xu YL, 2010, AUTON ROBOT, V29, P53, DOI 10.1007/s10514-010-9188-x
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Yan J, 2019, INT CONF ACOUST SPEE, P755, DOI [10.1109/icassp.2019.8682376, 10.1109/ICASSP.2019.8682376]
   Yi Dong, 2014, ARXIV14117923
   YOUDEN WJ, 1950, CANCER-AM CANCER SOC, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 77
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 383
EP 408
DI 10.1007/s11042-020-09616-9
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565480700007
OA hybrid
DA 2024-07-18
ER

PT J
AU Bozkurt, F
   Köse, C
   Sari, A
AF Bozkurt, Ferhat
   Kose, Cemal
   Sari, Ahmet
TI A texture-based 3D region growing approach for segmentation of ICA
   through the skull base in CTA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D vessel segmentation; Carotid artery segmentation; Texture-based
   region growing; Skull base; Computed tomography angiography
ID LUMEN SEGMENTATION; CEREBRAL-ARTERIES; MRI SEGMENTATION; IMAGES;
   ALGORITHMS; FEATURES
AB The internal carotid artery (ICA) segmentation is a complicated task at skull base in computed tomography angiography (CTA) images. The ICA enters into from skull cavity and shows close proximity to bone and surrounding soft tissues. For this reason, there exists a robust intensity overlap between vessels, bone and other surrounding tissues. Thus, these similar objects are not separated properly in images only according to the intensity level. In this paper, a texture-based 3D region growing approach is proposed and applied to the ICA through the skull base. The main contribution of this study is that the method does not ask for an extra computed tomography scan for bone masking. Moreover, the method dynamically sets the segmentation parameters according to texture knowledge. The proposed method was evaluated by the experiments on 15 actual clinical data. The performance evaluations were performed by comparing the automatic outputs with manual segmentations which are done by two radiologist observers. As a result, dice similarity rate of 89% was achieved together with 99% accuracy and 0.32 mm mean surface distance (Msd) for ICA segmentation through the skull base. The results show that the average overlap for the observers are similar. The proposed texture-based approach decreases significantly explosions, over-segmentations and increases rate of area overlap, sensitivity, precision at skull base. Therefore, the method is clinically useful and has potential to segment carotid arteries at skull base efficiently.
C1 [Bozkurt, Ferhat] Ataturk Univ, Dept Comp Engn, Fac Engn, Erzurum, Turkey.
   [Kose, Cemal] Karadeniz Tech Univ, Dept Comp Engn, Fac Engn, Trabzon, Turkey.
   [Sari, Ahmet] Karadeniz Tech Univ, Dept Radiol, Fac Med, Trabzon, Turkey.
C3 Ataturk University; Karadeniz Technical University; Karadeniz Technical
   University
RP Bozkurt, F (corresponding author), Ataturk Univ, Dept Comp Engn, Fac Engn, Erzurum, Turkey.
EM fbozkurt@atauni.edu.tr; ckose@ktu.edu.tr; asari@ktu.edu.tr
RI Bozkurt, Ferhat/GYR-3398-2022
OI Bozkurt, Ferhat/0000-0003-0088-5825; SARI, Prof. Dr.
   Ahmet/0000-0002-7452-083X
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], 2013, Ann. BMVA, DOI [10.1155/2013/325903, DOI 10.1155/2013/325903]
   [Anonymous], 1989, Anatomy and Surgery of the Cavernous Sinus, DOI [DOI 10.1007/978-3-7091-6942-1, DOI 10.1007/978-3-7091-6942-1_2]
   [Anonymous], 2004, VISUALIZATION TOOLKI
   Behrens S, 2013, LECT NOTES COMPUT SC, V8142, P237, DOI 10.1007/978-3-642-40602-7_25
   Beutel J., 2000, Handbook of Medical Imaging
   Bevk M, 2002, COMP MED SY, P239, DOI 10.1109/CBMS.2002.1011383
   Bowyer K., 2000, Handbook of Medical Imaging SPIE 2, P567
   Bozkurt F, 2018, EXPERT SYST APPL, V93, P358, DOI 10.1016/j.eswa.2017.10.041
   Caldemeyer KS, 1997, RADIOGRAPHICS, V17, P1123, DOI 10.1148/radiographics.17.5.9308106
   Chenoune Y, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103489
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cuisenaire O, 2009, J MIDAS
   Dogra J., 2020, Recent AdvComput Sci Commun, V13, P362, DOI 10.2174/2213275912666181207152633
   Dogra J, 2020, IET IMAGE PROCESS, V14, P84, DOI 10.1049/iet-ipr.2018.6615
   Dogra J, 2020, VISUAL COMPUT, V36, P875, DOI 10.1007/s00371-019-01698-3
   Dong H, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P642, DOI 10.1109/CSA.2013.155
   Duda R., 1973, Pattern Classification and Scene Analysis
   Eichkitz CG, 2013, COMPUT GEOSCI-UK, V60, P176, DOI 10.1016/j.cageo.2013.07.006
   Freiman M, 2009, NEARLY AUTOMATIC VES
   Gall A, 2017, THESIS
   Gambino O, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS 2010), P146, DOI 10.1109/CISIS.2010.118
   Goswami S., 2015, Int.J. Comput. Appl., V132, P40
   Gülsün MA, 2010, PROC SPIE, V7625, DOI 10.1117/12.845638
   Hameeteman K, 2011, MED IMAGE ANAL, V15, P477, DOI 10.1016/j.media.2011.02.004
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hassan M, 2019, COMPUT METH PROG BIO, V175, P179, DOI 10.1016/j.cmpb.2019.04.026
   Hedblom A., 2013, BLOOD VESSEL SEGMENT
   Jainish GR, 2020, MULTIMED TOOLS APPL, V79, P22337, DOI 10.1007/s11042-020-08958-8
   Jeon BK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICIP.2000.899802
   Jodas DS, 2016, COMPUT BIOL MED, V79, P233, DOI 10.1016/j.compbiomed.2016.10.021
   Kang CC, 2009, 2009 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P69
   Kavitha AR, 2016, IMAGING SCI J, V64, P285, DOI 10.1080/13682199.2016.1178412
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Kirbas C, 2004, ACM COMPUT SURV, V36, P81, DOI 10.1145/1031120.1031121
   Krissian K, 2009, MINIMAL COST PATH LE
   Kumar KN, 2015, CMES-COMP MODEL ENG, V107, P201
   Lesage D, 2009, MED IMAGE ANAL, V13, P819, DOI 10.1016/j.media.2009.07.011
   Lv TL, 2019, MULTIMED TOOLS APPL, V78, P17051, DOI 10.1007/s11042-018-7087-x
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Manniesing R, 2008, RADIOLOGY, V247, P841, DOI 10.1148/radiol.2473070436
   Manniesing R, 2007, PROC SPIE, V6512, DOI 10.1117/12.705201
   Mille J, 2009, CAROTID LUMEN SEGMEN
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P71, DOI 10.1016/j.cmpb.2018.02.001
   Mozaffarian D, 2015, CIRCULATION, V131, pE29, DOI 10.1161/CIR.0000000000000152
   Netter FH., 2017, Atlas of Human Anatomy: Digital eBook
   Ni JJ, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103639
   Park A, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.5600
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Prabha D S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9i8/87907
   Qazi Imtnan-Ul-Haque, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1537
   Rai G. N. Harikrishna, 2010, ARXIV10013735
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Saad NM, 2012, LECT NOTES ENG COMP, P674
   Schaap M, 2007, LECT NOTES COMPUT SC, V4792, P562
   Schroeder W., 2005, FEBS Lett, V525, P53
   Sen Y., 2015, THESIS
   Sheldrick RC, 2015, J CHILD PSYCHOL PSYC, V56, P936, DOI 10.1111/jcpp.12442
   Shim H, 2006, COMPUT METH PROG BIO, V84, P135, DOI 10.1016/j.cmpb.2006.09.001
   Smith N.B., 2010, Introduction to Medical Imaging: Physics, Engineering and Clinical Applications
   Stoitsis J, 2008, IEEE ENG MED BIO, P3146, DOI 10.1109/IEMBS.2008.4649871
   Tamilarasi M, 2013, INT CONF COMP COMMUN
   Tang H, 2013, MED PHYS, V40, DOI 10.1118/1.4802751
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Ugarriza LG, 2009, IEEE T IMAGE PROCESS, V18, P2275, DOI 10.1109/TIP.2009.2025555
   Ukwatta E, 2013, IEEE T MED IMAGING, V32, P770, DOI 10.1109/TMI.2013.2237784
   Valencia LF, 2009, CAROTID ARTERIES SEG
   Wachter I., 2009, THESIS UCL
   Wang CM, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P356, DOI 10.1109/IS3C.2014.99
   Wolf I, 2005, MED IMAGE ANAL, V9, P594, DOI 10.1016/j.media.2005.04.005
   Wong WC, 2009, PRINCIPAL CURVES TEC
   Wu J, 2008, INT CONF BIOMED, P263, DOI 10.1109/BMEI.2008.352
   Xie XH, 2005, LECT NOTES COMPUT SC, V3687, P404
   Xin Yang, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P241, DOI 10.1109/BHI.2012.6211555
   Xue Zhiyun, 2012, AMIA Annu Symp Proc, V2012, P1023
   Yaganoglu M, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7040050
   Yoo T.S., 2004, Insight into images: principles and practice for segmentation, registration, and image analysis
   Yushkevich PA, 2016, IEEE ENG MED BIO, P3342, DOI 10.1109/EMBC.2016.7591443
   Zahoor S, 2020, CURR MED IMAGING, V16, P1187, DOI 10.2174/1573405616666200406110547
   Zanaty EA, 2013, COMPUT SCI INF SYST, V10, P1319, DOI 10.2298/CSIS120604050Z
   Zhang DH, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL II, P149
   Zhang M, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105159
   Zhang YN, 2019, J APPL MATH, V2019, DOI 10.1155/2019/7172860
   Zhang Y, 2007, AIP CONF PROC, V952, P57, DOI 10.1063/1.2816644
   Zouqi M, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR IMAGE PROCESSING, P33, DOI 10.1109/CIIP.2009.4937877
   Zuluaga MA, 2009, P CAR LUM SEGM STEN
NR 88
TC 2
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33253
EP 33278
DI 10.1007/s11042-020-09690-z
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000005
DA 2024-07-18
ER

PT J
AU Lavín-Delgado, JE
   Solís-Pérez, JE
   Gómez-Aguilar, JF
   Escobar-Jiménez, RF
AF Lavin-Delgado, J. E.
   Solis-Perez, J. E.
   Gomez-Aguilar, J. F.
   Escobar-Jimenez, R. F.
TI Fractional speeded up robust features detector with the Caputo-Fabrizio
   derivative
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional calculus; Speeded-up robust feature; Caputo-Fabrizio
   derivative; Interest point detection; Image matching
AB In this research, a fractional-order method for distinctive keypoints detection and to the image matching based on the Caputo-Fabrizio derivative and in the Speeded-Up Robust Feature (SURF) algorithm is presented and experimentally tested. The main advantage of introducing the fractional-order derivative is the improvement of the texture details detection, by combining this derivative with the SURF algorithm, the images feature extraction is improved to reach accurate images matching. The proposed method is compared experimentally with conventional SURF and SIFT algorithms. The experimental results showed that the proposed method has a high capacity for detecting points of interest in a region of the image with low contrast and weak texture.
C1 [Lavin-Delgado, J. E.; Solis-Perez, J. E.; Escobar-Jimenez, R. F.] CENIDET, Tecnol Nacl Mexico, Interior Internado Palmira S-N, Cuernavaca 62490, Morelos, Mexico.
   [Gomez-Aguilar, J. F.] CENIDET, Tecnol Nacl Mexico, CONACyT, Interior Internado Palmira S-N, Cuernavaca 62490, Morelos, Mexico.
RP Gómez-Aguilar, JF (corresponding author), CENIDET, Tecnol Nacl Mexico, CONACyT, Interior Internado Palmira S-N, Cuernavaca 62490, Morelos, Mexico.
RI Escobar-Jiménez, Ricardo Fabricio/X-1721-2019; Solís-Pérez, Jesús
   Emmanuel/ABD-4028-2020; Lavín Delgado, Jorge Enrique/HHS-1077-2022
OI Escobar-Jiménez, Ricardo Fabricio/0000-0003-3367-6552; Solís-Pérez,
   Jesús Emmanuel/0000-0002-4729-9949; Lavin Delgado, Jorge
   Enrique/0000-0003-3632-3373; Gomez-Aguilar, J.F./0000-0001-9403-3767
FU CONACyT; CONACyT: Catedras CONACyT para jovenes investigadores 2014;
   SNI-CONACyT
FX Jorge Enrique Lavin Delgado and Jesus Emmanuel Solis Perez acknowledges
   the support provided by CONACyT through the assignment post-doctoral and
   doctoral fellowship, respectively. Jose Francisco Gomez Aguilar
   acknowledges the support provided by CONACyT: Catedras CONACyT para
   jovenes investigadores 2014. Jose Francisco Gomez Aguilar and Ricardo
   Fabricio Escobar Jimenez acknowledges the support provided by
   SNI-CONACyT.
CR Alhwarin Faraj., 2008, BCS Int. Acad. Conf, P178
   [Anonymous], 2000, Fract. Calc. Appl. Anal, V3, P359, DOI DOI 10.1016/J.JCP.2009.01.014)
   Atangana A, 2018, MATH MODEL NAT PHENO, V13, DOI 10.1051/mmnp/2018010
   Bay H, 2006, THESIS
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BROWN M., 2002, BRIT MACHINE VISION, P656, DOI [10.5244/C.16.23, DOI 10.5244/C.16.23]
   Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918
   Kai W, 2011, P INT C COMP SCI INF, P255
   Lavín-Delgado JE, 2020, CIRC SYST SIGNAL PR, V39, P1419, DOI 10.1007/s00034-019-01200-3
   Li AM, 2017, PROCEDIA COMPUT SCI, V107, P306, DOI 10.1016/j.procs.2017.03.110
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Podlubny I., 1999, MATH SCI ENG, V198, P340
   Sarwas G, 2017, SIG P ALGO ARCH ARR, P349, DOI 10.23919/SPA.2017.8166891
   Sváb J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR PRACTICAL ROBOT APPLICATIONS (TEPRA 2009), P35, DOI 10.1109/TEPRA.2009.5339646
   Tavazoei MS, 2020, EUR PHYS J-SPEC TOP, V229, P887, DOI 10.1140/epjst/e2020-900238-8
   Toufik M, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11717-0
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xu K, 2019, J AMB INTEL HUM COMP, V10, P3297, DOI 10.1007/s12652-018-1055-1
   Zhang G, 2016, 2015 INT DES ENG TEC
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 21
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32957
EP 32972
DI 10.1007/s11042-020-09547-5
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000567296900004
DA 2024-07-18
ER

PT J
AU Yan, XH
   Yan, WQ
   Liu, LT
   Lu, YL
AF Yan, Xuehu
   Yan, Wei Qi
   Liu, Lintao
   Lu, Yuliang
TI Penrose tiling for visual secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image sharing; Visual secret sharing; Penrose tiling; Vector image
ID CRYPTOGRAPHY SCHEME; RECOVERY
AB Visual secret sharing (VSS) has the advantage that the decryption is based on our human visual system without participation of any computational devices. However, traditional VSS schemes are only for sharing raster images with regard to pixels, which lead to that the secret image will be aliased when enlarged and its pixels are shared in rectangular way only. In this paper, we will introduce a VSS scheme for vectorized images based on Penrose tiling. Penrose tiling is with the merits of vectorization and nonperiodicity. These properties are applied to the proposed scheme so as to share those vectorized images; the basic unit of secret sharing could be any graphical shapes instead of pixels or rectangular regions only in the traditional methods. Our experiments show the effectiveness of the proposed scheme.
C1 [Yan, Xuehu; Liu, Lintao; Lu, Yuliang] Natl Univ Defense Technol, Hefei 230037, Peoples R China.
   [Yan, Xuehu; Liu, Lintao; Lu, Yuliang] Anhui Prov Key Lab Cyberspace Secur Situat Awaren, Hefei 230037, Peoples R China.
   [Yan, Wei Qi] Auckland Univ Technol, Auckland 1142, New Zealand.
C3 National University of Defense Technology - China; Auckland University
   of Technology
RP Yan, XH (corresponding author), Natl Univ Defense Technol, Hefei 230037, Peoples R China.; Yan, XH (corresponding author), Anhui Prov Key Lab Cyberspace Secur Situat Awaren, Hefei 230037, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]; Key Program of
   the National University of Defense Technology [ZK-17-02-07]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work is supported by the National Natural
   Science Foundation of China (Grant Number: 61602491) and the Key Program
   of the National University of Defense Technology (Grant Number:
   ZK-17-02-07).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   CHAVAN PV, 2014, ELECT ELECT COMPUTER
   Cheng Y., 2017, MULTIMEDIA TOOLS APP
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   DAIRYKO M, 2013, SPECTRUM PENROSE LAP
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   DEBRUIJN NG, 1981, P K NED AKAD A MATH, V84, P39
   Frank NP, 2008, EXPO MATH, V26, P295, DOI 10.1016/j.exmath.2008.02.001
   Fu ZX, 2014, LECT NOTES COMPUT SC, V8389, P109, DOI 10.1007/978-3-662-43886-2_8
   Grunbaum B, 1987, AM MATH MONTHLY
   Guo T, 2017, INT J DIGIT CRIME FO, V9, P38, DOI 10.4018/IJDCF.2017040104
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   Komargodski I, 2017, J CRYPTOL, V30, P444, DOI 10.1007/s00145-015-9226-0
   Li L, 2017, CLUSTER COMPUTING
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li YN, 2018, IEEE SIGNAL PROC LET, V25, P140, DOI 10.1109/LSP.2017.2777881
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P16461, DOI 10.1007/s11042-017-5215-7
   Liu YX, 2018, INFORM SCIENCES, V453, P21, DOI 10.1016/j.ins.2018.04.043
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Lu PJ, 2007, SCIENCE, V315, P1106, DOI 10.1126/science.1135491
   Luo H, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P609, DOI 10.1109/ISDA.2007.123
   Miao FY, 2015, IEEE T INF FOREN SEC, V10, P889, DOI 10.1109/TIFS.2014.2384393
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Penrose R, 1974, B I MATH ITS APPL, P10
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Stinson D. R., 1992, Designs, Codes and Cryptography, V2, P357, DOI 10.1007/BF00125203
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang GY, 2016, INT J DIGIT CRIME FO, V8, P85, DOI 10.4018/IJDCF.2016070106
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang W, 2017, LECT NOTES COMPUT SC, V10431, P406, DOI 10.1007/978-3-319-64185-0_30
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344438
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Yan X, 2020, IEEE T INFORM FORENS
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yang C, 2017, ADV WIREL TECHNOL TE, P1, DOI 10.4018/978-1-5225-1712-2
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Zhou Z, 2020, ACM T MULTIMEDIA COM
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zou S, 2014, INFORM THEORETIC APP
NR 49
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32693
EP 32710
DI 10.1007/s11042-020-09568-0
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900001
DA 2024-07-18
ER

PT J
AU Jarraya, SK
   Masmoudi, M
   Hammami, M
AF Jarraya, Salma Kammoun
   Masmoudi, Marwa
   Hammami, Mohamed
TI A comparative study of Autistic Children Emotion recognition based on
   patio-Temporal and Deep analysis of facial expressions features during a
   Meltdown Crisis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autism; Meltdown crisis; Facial expressions; Compound emotions;
   Spatio-temporal Features; CNN
ID SELECTION TECHNIQUES
AB The recognition of human emotion is a significant contribution to many computer vision appli-cations. Despite its importance, this work is the first one towards an automatic Autistic Children emotion recognition system to ensure their security during meltdown crisis. The current solutions to handle a meltdown crisis are based on a preventive approach. Indeed, Meltdown symptoms are determined by abnormal facial expressions related to compound emotions. To provide for this correspondence, we experimentally evaluate, in this paper, hand-crafted Geometric Spatio-Temporal and Deep features of realistic autistic children facial expressions. Towards this end, we compared the Compound Emotion Recognition (CER) performance for different combinations of these features, and we determined the features that best distinguish a Compound Emotion (CE) of autistic children during a meltdown crisis from the normal state. We used "Meltdown crisis"(1)dataset to conduct our experiments on realistic Meltdown / Normal scenarios of autistic children. In this evaluation, we show that the gathered features can lead to very encouraging performances through the use ofRandom Forestclassifier (91.27%) with hand-crafted features. Moreover, classifiers trained on deep features fromInceptionResnetV2show higher performance (97.5%) with supervised learning techniques.
C1 [Jarraya, Salma Kammoun; Masmoudi, Marwa; Hammami, Mohamed] Univ Sfax, Mir Cl Lab, Sfax, Tunisia.
   [Jarraya, Salma Kammoun] King Abdulaziz Univ, Fac Comp & Informat Technol, CS Dept, Jeddah, Saudi Arabia.
   [Hammami, Mohamed] Sfax Univ, Fac Sci, Dept Comp Sci, Sfax, Tunisia.
C3 Universite de Sfax; King Abdulaziz University; Universite de Sfax;
   Faculty of Sciences Sfax
RP Masmoudi, M (corresponding author), Univ Sfax, Mir Cl Lab, Sfax, Tunisia.
EM smohamad1@kau.edu.sa; marwa.masmoudi19@gmail.com;
   Mohamed.Hammami@fss.rnu.tn
OI Masmoudi, Marwa/0000-0002-5248-8525
CR Ahmed W., 2013, PAPG ANN TECHNICAL C, P1
   Alaoui AEK, 2017, MATH ENSEIGNEMENT MA
   [Anonymous], 2016, P INT J COMP SCI MOB
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Anwar S., 2016, IAEMR
   Bennie M, 2016, AUTISM AWARENESS
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Control D, 2018, PREVENTION
   Dettmers T, 2019, FULL HARDWARE GUIDE
   Du SC, 2015, DIALOGUES CLIN NEURO, V17, P443
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Durmusoglu A, 2016, INT CONF SYST SIGNAL, P41
   Gianessi P, 2019, IFIP ADV INF COMM TE, P239, DOI 10.1007/978-3-030-30000-5_31
   Guha T, 2015, INT CONF ACOUST SPEE, P803, DOI 10.1109/ICASSP.2015.7178080
   Guo JZ, 2018, IEEE ACCESS, V6, P26391, DOI 10.1109/ACCESS.2018.2831927
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaiswal S, 2017, IEEE INT CONF AUTOMA, P762, DOI 10.1109/FG.2017.95
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LaPlante D, 2000, J NONVERBAL BEHAV, V24, P211, DOI 10.1023/A:1006641104653
   LeCun Y., 1995, NEURAL NETW STAT MEC, V261, P276
   Liawatimena S, 2018, 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL CONFERENCE (INAPR), P108, DOI 10.1109/INAPR.2018.8627007
   Liliana D., 2018, Int. J. Pure Appl. Math, V118, P3159
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Martinez AM, 2017, CURR OPIN PSYCHOL, V17, P27, DOI 10.1016/j.copsyc.2017.06.009
   Mehmood I, 2019, IEEE INTERNET THINGS, V6, P9246, DOI 10.1109/JIOT.2019.2896151
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Salmam F. Z., 2018, INT J EL COMP ENG SY, V8, P52, DOI DOI 10.11591/IJECE.V8I1.PP52-59
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RupeshKumar., 2015, CoRR
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tasnim N, 2018, THESIS
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Ul Haque MI, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P546, DOI 10.1109/IEMCON.2018.8614802
   Villacampa O., 2015, Feature Selection and Classification Methods for Decision Making: A Comparative Analysis
   Wang S.J., 2010, Frontiers in Neurology, V1, P1, DOI DOI 10.3389/FNEUR.2010.00016
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YD, 2014, KNOWL-BASED SYST, V64, P22, DOI 10.1016/j.knosys.2014.03.015
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3017608
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 57
TC 15
Z9 15
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 83
EP 125
DI 10.1007/s11042-020-09451-y
EA AUG 2020
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000562697400005
DA 2024-07-18
ER

PT J
AU Yadav, SS
   Jadhav, SM
AF Yadav, Samir S.
   Jadhav, Shivajirao M.
TI Thermal infrared imaging based breast cancer diagnosis using machine
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Machine learning; Thermal infrared image; CNN
ID TEXTURE FEATURES; SEGMENTATION; MAMMOGRAPHY; IMAGES
AB The human's temperature is little known and important to the diagnosis of diseases, according to most researchers and health workers.In ancient medicine, doctors may treat patients with wet mud or slurry clay. The part that would dry up first was considered the diseased part when either of these spread over the body. This can be done today with thermal cameras generating pictures with electromagnetic frequencies. Inflammation and blockage areas that predict cancer without radiation or touch may be detected by thermography. It can be used before any visible symptoms occur as a great advantage in medical testing. Machine learning (ML) is used in this paper as statistical techniques to give software programs the capacity to learn from information without being directly coded. ML can help to do so by learning these thermal scans and identifying suspected areas where a doctor needs to research more. Thermal photography is a comparatively better alternative to other methods that need sophisticated equipment, enabling machines to provide an easier and more effective approach to clinics and hospitals.
C1 [Yadav, Samir S.] Dr Babasaheb Ambedkar Technol Univ, Raigad, Lonere, India.
   [Jadhav, Shivajirao M.] Dr Babasaheb Ambedkar Technol Univ, Dept Informat Technol, Raigad, Lonere, India.
C3 Dr. Babasaheb Ambedkar Technological University; Dr. Babasaheb Ambedkar
   Technological University
RP Yadav, SS (corresponding author), Dr Babasaheb Ambedkar Technol Univ, Raigad, Lonere, India.
EM ssyadav@dbatu.ac.in; smjadhav@dbatu.ac.in
RI Jadhav, Shivajirao/HII-4313-2022; Yadav, Samir/AAW-4449-2020
OI Yadav, Samir/0000-0002-8880-9685
CR Acharya UR, 2012, J MED SYST, V36, P1503, DOI 10.1007/s10916-010-9611-z
   Agravat RR, 2019, TENCON IEEE REGION, P31, DOI [10.1109/tencon.2019.8929497, 10.1109/TENCON.2019.8929497]
   [Anonymous], 2019, Global Action Plan on Physical Activity 2018-2030: More Active People for a Healthier World
   Bettegowda C, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3007094
   Cano F, 2018, PROC SPIE, V10975, DOI 10.1117/12.2511647
   Cho N, 2017, JAMA ONCOL, V3, P1495, DOI 10.1001/jamaoncol.2017.1256
   de Oliveira NPD, 2020, CANCER EPIDEMIOL, V64, DOI 10.1016/j.canep.2019.101660
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Elias T, 2019, VISUAL LAB METHODOLO
   Erdoan R. T, 2019, 74 SESS 3 4 M AM PM
   Etehadtavakol M, 2019, MED BIOL ENG COMPUT, V57, P379, DOI 10.1007/s11517-018-1876-2
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Foa E.B., 2008, PROLONGED EXPOSURE T, DOI DOI 10.1093/MED:PSYCH/9780195331745.001.0001
   Frize M, 2003, ENG MED BIOL SOC ANN, P234
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gerasimova E, 2014, FRONT PHYSIOL, V5, DOI 10.3389/fphys.2014.00176
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Hafiz Abdul Mueed, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P161, DOI 10.1007/978-981-13-7166-0_16
   Hamidinekoo A, 2018, MED IMAGE ANAL, V47, P45, DOI 10.1016/j.media.2018.03.006
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jaeger BM, 2016, CLIN OBSTET GYNECOL, V59, P336, DOI 10.1097/GRF.0000000000000202
   Janghel R. R., 2010, 2010 3rd International Conference on Information Sciences and Interaction Sciences (ICIS), P89, DOI 10.1109/ICICIS.2010.5534716
   Fernández-Ovies FJ, 2019, LECT N BIOINFORMAT, V11466, P514, DOI 10.1007/978-3-030-17935-9_46
   Jones GW, 2007, POPUL DEV REV, V33, P453, DOI 10.1111/j.1728-4457.2007.00180.x
   Joshi AV, 2020, DEEP LEARNING MACHIN, P117
   Kadam VJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1397-z
   Karim CN., 2018, MED TECHNOL J, V2, P245, DOI [10.26415/2572-004X-vol2iss3p245-254, DOI 10.26415/2572-004X-VOL2ISS3P245-254]
   Khan S, 2017, ASIAPAC SIGN INFO PR, P1661, DOI 10.1109/APSIPA.2017.8282299
   Kösüs N, 2010, J TURK-GER GYNECOL A, V11, P152, DOI 10.5152/jtgga.2010.24
   Kremer J.M., 2017, Characterization of axenic immune deficiency in Arabidopsis thaliana
   Leaf C, 2004, FORTUNE, V149, P76
   Liu K, 2018, IEEE ACCESS, V6, P23722, DOI 10.1109/ACCESS.2018.2817593
   Lu YP, 2014, IEEE IJCNN, P1739, DOI 10.1109/IJCNN.2014.6889415
   Lunenfeld B, 2013, BEST PRACT RES CL OB, V27, P643, DOI 10.1016/j.bpobgyn.2013.02.005
   Maestre CR, JUPYTER NOTEBOOK THE
   Mahmoudzadeh E, 2015, INFRARED PHYS TECHN, V72, P19, DOI 10.1016/j.infrared.2015.06.012
   Mambou SJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092799
   Maxim LD, 2014, INHAL TOXICOL, V26, P811, DOI 10.3109/08958378.2014.955932
   McKinney W, 2012, NumPy, and IPython
   Milosevic M, 2014, EXCLI J, V13, P1204
   Moher D, 2004, MEASURING QUALITY BR
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Oliphant T.E., 2019, NUMPY N DIMENSIONAL
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qi H., 2012, MED MED RES, V38, p13.1
   Qi HR, 2001, P ANN INT IEEE EMBS, V23, P2866, DOI 10.1109/IEMBS.2001.1017386
   Rahman MM, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRICAL INFORMATION AND COMMUNICATION TECHNOLOGY (EICT), P217, DOI 10.1109/EICT.2015.7391949
   Rampun A, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010014
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santana Maíra Araújo de, 2018, Res. Biomed. Eng., V34, P45, DOI 10.1590/2446-4740.05217
   Schaefer G, 2009, PATTERN RECOGN, V42, P1133, DOI 10.1016/j.patcog.2008.08.007
   Selle JJ, 2018, QUANT INFR THERM J, V15, P194, DOI 10.1080/17686733.2018.1426137
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Silva LF, 2016, COMPUT METH PROG BIO, V130, P142, DOI 10.1016/j.cmpb.2016.03.002
   Silva LF, 2015, STUD HEALTH TECHNOL, V216, P746, DOI 10.3233/978-1-61499-564-7-746
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   ul Hassan M, 2018, Neurohive
   Upadhyay RP, 2012, IRAN J PUBLIC HEALTH, V41, P1
   Vikhe PS, 2018, MULTIMED TOOLS APPL, V77, P23777, DOI 10.1007/s11042-018-5681-6
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yao XL, 2014, ASIAN BIOMED, V8, P11, DOI 10.5372/1905-7415.0801.257
NR 63
TC 22
Z9 22
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13139
EP 13157
DI 10.1007/s11042-020-09600-3
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000562697400009
DA 2024-07-18
ER

PT J
AU Bordoloi, M
   Chatterjee, PC
   Biswas, SK
   Purkayastha, B
AF Bordoloi, Monali
   Chatterjee, Preetam Chayan
   Biswas, Saroj Kumar
   Purkayastha, Biswajit
TI Keyword extraction using supervised cumulative TextRank
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyword extraction; Supervised learning; Supervised term weighting;
   Vector space model; Graph based model; Machine learning classifiers
AB Keyword extraction is a major step to extract plenty of valuable and meaningful information from the rich source of World Wide Web (W.W.W.). Different keyword extraction algorithms are proposed with their own advantages and disadvantages. Vector Space Model (VSM) algorithms prove quite effective for keyword extraction, but do not emphasize on the class label information of classified data. Supervised Term Weighting (STW) algorithms address this problem, but suffer from high dimensionality. Besides, they do not incorporate semantic relationship between terms. To address these problems, Graph Based Models (GBM) are introduced. However, they also use unsupervised learning. Hence, this paper proposes a Keyword Extraction using Supervised Cumulative TextRank (KESCT) technique that explores the benefits of both VSM and GBM techniques. The proposed algorithm modifies TextRank by incorporating a novel Unique Statistical Supervised Weight (USSW) to include class label information of classified data. To emphasize on the relatedness between terms, the mutual information between terms is also included. The proposed algorithm is validated using four review datasets and results are compared with traditional TextRank and its variants using Support Vector Machine (SVM) classifier, Naive-Bayes (NB) classifier and an ensemble classifier. Experimental results mark the efficacy of the proposed algorithm over existing algorithms.
C1 [Bordoloi, Monali; Chatterjee, Preetam Chayan; Biswas, Saroj Kumar; Purkayastha, Biswajit] NIT Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Bordoloi, M (corresponding author), NIT Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
EM monali.bordoloi@gmail.com; pree14m@gmail.com; bissarojkum@yahoo.com;
   biswajit_purakayastha@hotmail.com
RI Bordoloi, Monali/AGS-1758-2022
OI Bordoloi, Monali/0000-0002-0685-9268
CR [Anonymous], 2014, INT J COMPUT APPL
   Beliga S, 2015, J INF ORGAN SCI, V39, P1
   Benghuzzi H, 2020, INT J COMPUT SCI INF, V18
   Biswas SK, 2018, EXPERT SYST APPL, V97, P51, DOI 10.1016/j.eswa.2017.12.025
   Bordegoni M, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON OLFACTION AND ELECTRONIC NOSE (ISOEN 2019), P133, DOI 10.1109/isoen.2019.8823224
   Bordoloi M, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0536-8
   Boudin F., 2013, INT JOINT C NAT LANG, P834
   Canhasi E, 2016, INT J ELECT COMPUT E, V6, P2088
   Chen KW, 2016, EXPERT SYST APPL, V66, P245, DOI 10.1016/j.eswa.2016.09.009
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Duari S, 2019, INFORM SCIENCES, V477, P100, DOI 10.1016/j.ins.2018.10.034
   El-Khair I.A., 2009, ENCY DATABASE SYSTEM
   Fernandez A.M., 2018, IEEE Transactions on Knowledge and Data Engineering
   Gollapudi S., 2006, Proceedings of the 15th ACM international conference on Information and knowledge management, P475
   Guo ZF, 2020, P I MECH ENG G-J AER, V234, P1259, DOI 10.1177/0954410019900722
   Hassan S, 2007, INT J SEMANT COMPUT, V1, P421, DOI 10.1142/S1793351X07000263
   Islam MR, 2008, 2008 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY: ICCIT 2008, VOLS 1 AND 2, P256
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Li H, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P495
   Li SQ, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND APPLICATIONS (WCNA2017), P133, DOI 10.1145/3180496.3180620
   Liu Y, 2009, EXPERT SYST APPL, V36, P690, DOI 10.1016/j.eswa.2007.10.042
   Lu Yao, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P452
   Malliaros FD, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1473, DOI 10.1145/2808797.2808872
   Mihalcea, 2004, P EMNLP, P401, DOI DOI 10.3115/1219044.1219064
   Nie JY, 2002, WORKSH MATH FORM MET
   Porter M. F., 2006, ALGORITHM SUFFIX STR
   Ren FJ, 2013, INFORM SCIENCES, V236, P109, DOI 10.1016/j.ins.2013.02.029
   Saki M, 2017, IRAN CONF ELECTR ENG, P1481, DOI 10.1109/IranianCEE.2017.7985277
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shouyou Song, 2019, 2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC). Proceedings, P536, DOI 10.1109/DSC.2019.00087
   Shouzhong T, 2016, J CHINA U POSTS TELE, V23, P40
   Stein Benno, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P527, DOI 10.1145/1277741.1277832
   Tavoli R, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P773, DOI 10.1109/TSP.2013.6614043
   Wu J, 2019, ENERG ENV RES CHINA, P1, DOI 10.1007/978-981-10-8750-9
   Wu JG, 2020, J SUPERCOMPUT, V76, P636, DOI 10.1007/s11227-019-03047-6
   Zhang Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS), P623, DOI 10.1109/ICWS.2015.88
   Zhang Y, 2020, SIGNAL TRANSDUCT TAR, V5, DOI 10.1038/s41392-020-0145-7
   Zhou Qingyun, 2020, 2020 International Conference on Computer Engineering and Application (ICCEA), P359, DOI 10.1109/ICCEA50009.2020.00084
NR 38
TC 7
Z9 10
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31467
EP 31496
DI 10.1007/s11042-020-09335-1
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100008
DA 2024-07-18
ER

PT J
AU Yan, FT
   Hu, YH
   Jia, JY
   Ai, ZH
   Tang, K
   Shi, ZC
   Liu, X
AF Yan, Fengting
   Hu, Yonghao
   Jia, Jinyuan
   Ai, Zihao
   Tang, Kai
   Shi, Zhicai
   Liu, Xiang
TI Interactive WebVR visualization for online fire evacuation training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire evacuation; WebVR; BIM lightweight; Smoke lightweight; TC-eACO
   algorithm
AB Online training is necessary for public fire escaping with the development of WebVR (Virtual Realization on Web). However, the online real-time fire training could not implemented in WebVR for the large-scale public scenario because of the huge size of VR fire scenario data, the low network transmission speed, and the slowly rendering ability of Web browser. To solve these bottlenecks, we propose a suite of solution for WebVR online fire training. Firstly, we implement a series of lightweight technologies to compress the large-scale scene data. The huge BIM (Building Information Modeling) volume data could be compressed by as much as 10 times. Then, we propose a kind of FDS (Fire Dynamic Simulator) smoking data lightweight mechanism to compress huge volume smoke data, which can be reduced by as much as 30 times. Thirdly, we adopt the multithread loading mechanism to accelerate WebVR fire scenario lightweight data. Finally, we collect the escape traces from history fire evacuation of the public, who wear the VR devices. Based on the valuable traces, we propose the TC-eACO algorithm to plan crowd optimal evacuation paths. At the same time, we implement a prototype system based on TC-eACO for WebVR fire evacuation training, with which the user just needs to surf the internet and take part in the fire evacuation training. The experimental results demonstrate that the solutions we proposed are feasible for online fire evacuation training not only in subway stations but also in other types of buildings.
C1 [Yan, Fengting; Shi, Zhicai; Liu, Xiang] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201826, Peoples R China.
   [Hu, Yonghao; Jia, Jinyuan] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
   [Ai, Zihao] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Jilin 130022, Jilin, Peoples R China.
   [Tang, Kai] Hong Kong Univ Sci & Technol, Hong Kong 999077, Peoples R China.
   [Shi, Zhicai] Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
C3 Shanghai University of Engineering Science; Tongji University; Changchun
   University of Science & Technology; Hong Kong University of Science &
   Technology
RP Yan, FT (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201826, Peoples R China.
EM yanfengting20080@163.com
RI Tang, Kai/E-4816-2010; Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829
FU Key Research Projects of Central University of Basic Scientific Research
   Funds for Cross Cooperation [201510-02, 201710-04]
FX The authors appreciate the comments and suggestions of all the anonymous
   reviewers, whose comments help the authors significantly in their
   revising the paper. We thank Ming Li for her contribution in language
   modification of this paper. This work is supported by the Key Research
   Projects of Central University of Basic Scientific Research Funds for
   Cross Cooperation (201510-02 and 201710-04).
CR Beata PA, 2018, FIRE TECHNOL, V54, P995, DOI 10.1007/s10694-018-0723-1
   Benkoussas B, 2016, J FUNDAM APPL SCI, V8, P401, DOI 10.4314/jfas.v8i2.16
   Benkoussas B., 2015, NAT TECHNOL, V12, P45
   Chen W, 2017, J VISUAL-JAPAN, V20, P651, DOI 10.1007/s12650-016-0416-0
   Cheng JT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P963, DOI 10.1109/ICInfA.2016.7831958
   Chiu YP, 2016, ARTIF LIFE ROBOT, V21, P232, DOI 10.1007/s10015-016-0277-6
   Diez H. V., 2016, P 21 INT C WEB3D TEC, P43, DOI [https://doi.org/10.1145/2945292.2945296, DOI 10.1145/2945292.2945296]
   Inthavong K, 2017, J VISUAL-JAPAN, V20, P125, DOI 10.1007/s12650-016-0386-2
   Kim TJ, 2018, MULTIMED TOOLS APPL, V77, P30089, DOI 10.1007/s11042-018-6181-4
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   Lin J, 2020, SAFETY SCI, V122, DOI 10.1016/j.ssci.2019.104540
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Rodríguez MB, 2014, WEB3D 2014, P7
   Shi JY, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/3604369
   Song WQ, 2020, ENERGY, V194, DOI 10.1016/j.energy.2019.116847
   Wang ZJ, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/6943234
   Wen JH, 2019, VISUAL COMPUT, V35, P1279, DOI 10.1007/s00371-018-1514-x
   Xie C, 2016, J VISUAL-JAPAN, V19, P475, DOI 10.1007/s12650-015-0324-8
   Xu Z, 2014, ADV ENG SOFTW, V68, P1, DOI 10.1016/j.advengsoft.2013.10.004
   Xu Z, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102995
   Yan FT, 2019, FRONT INFORM TECH EL, V20, P1061, DOI 10.1631/FITEE.1700548
   Yan FT, 2019, J INTERNET TECHNOL, V20, P521, DOI 10.3966/160792642019032002019
   Zhou XP, 2019, MULTIMED TOOLS APPL, V78, P28575, DOI 10.1007/s11042-018-5820-0
NR 23
TC 10
Z9 13
U1 7
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31541
EP 31565
DI 10.1007/s11042-020-08863-0
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100009
DA 2024-07-18
ER

PT J
AU Dutta, K
   Bhattacharjee, D
   Nasipuri, M
AF Dutta, Koushik
   Bhattacharjee, Debotosh
   Nasipuri, Mita
TI SpPCANet: a simple deep learning-based feature extraction approach for
   3D face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face image; Sparse principal component analysis filter; Binary
   hashing; Block-wise histogram; Lightweight deep network
ID SELECTION; PCANET
AB A Sparse Principal Component Analysis Network (SpPCANet) based feature extraction is proposed here for 3D face recognition. The network consists of three basic components: (1) Multistage sparse principal component analysis filters, (2) Binary hashing, and (3) Block-wise histogram computation. Here, the sparse principal component analysis is used to learn multistage filter banks at the convolution stage, which is followed by binary hashing for indexing and block-wise histogram for pooling. Finally, a linear support vector machine (SVM) is used for classifying the features extracted by SpPCANet. The proposed network SpPCANet is a lightweight deep learning network. Three well-known 3D face databases, namely, Frav3D, Bosphorus3D, and Casia3D, are used for validating the proposed system. This proposed network has been extensively studied by varying different parameters, such as the number of filters at the convolution layer and the size of filters at the convolution layer and size of non-overlapping blocks at the pooling layer. Handling all types of variation of faces available in Frav3D, Bosphorus3D, and Casia3D databases, the system has acquired 96.93%, 98.54%, and 88.80% recognition rates, respectively.
C1 [Dutta, Koushik; Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Comp Sci & Engn, 188 Raja SC Maulik Rd, Kolkata 700032, India.
C3 Jadavpur University
RP Dutta, K (corresponding author), Jadavpur Univ, Comp Sci & Engn, 188 Raja SC Maulik Rd, Kolkata 700032, India.
EM koushik.it.22@gmail.com; debotoshb@hotmail.com; mitanasipuri@gmail.com
RI Dutta, Koushik Nandan/HJA-9904-2022; Bhattacharjee,
   Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
FU Ministry of Electronics and Information Technology (MeitY), Govt. of
   India
FX The first author is grateful to the Ministry of Electronics and
   Information Technology (MeitY), Govt. of India, for the grant of the
   Visvesvaraya doctorate fellowship award. The authors are also thankful
   to CMATER laboratory of the Department of Computer Science and
   Engineering, Jadavpur University, Kolkata, LIndia, for providing the
   necessary infrastructure for this work.
CR Alain G, 2014, J MACH LEARN RES, V15, P3563
   Alyüz N, 2008, LECT NOTES COMPUT SC, V5372, P57, DOI 10.1007/978-3-540-89991-4_7
   [Anonymous], 2014, P ICC 2014 COMP NETW
   [Anonymous], 2014, ICTACT J IMAGE VIDEO, DOI DOI 10.21917/IJIVP.2014.0108
   Bagchi P, 2015, TENCON IEEE REGION
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chandrakala M, 2018, INT J ENG ADV TECHNO, V8, P284
   Chhatrala R, 2017, IMAGE ANAL, V27, P525, DOI DOI 10.1134/S1054661817030075
   Chouchane Ammar, 2015, International Journal of Intelligent Systems Technologies and Applications, V14, P50
   Chouchane A, 2014, P 4 INT C IM PROC TH, DOI 10.1109/IPTA.2014.7001925
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Dutta Koushik, 2019, Advanced Computing and Systems for Security. Advances in Intelligent Systems and Computing (AISC 883), P175, DOI 10.1007/978-981-13-3702-4_11
   Dutta K, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P99, DOI 10.1109/ICITISEE.2016.7803055
   Gilani SZ, 2016, INT C DIG IM COMP TE
   Huang DM, 2016, LECT NOTES COMPUT SC, V9865, P179, DOI 10.1007/978-3-319-45835-9_16
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Li BJ, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2404, DOI 10.1109/ITSC.2016.7795943
   Li CX, 2017, MULTIMED TOOLS APPL, V76, P17055, DOI 10.1007/s11042-016-3670-1
   Ng CJ, 2015, ASIAPAC SIGN INFO PR, P761, DOI 10.1109/APSIPA.2015.7415375
   Ouamane Abdelmalik, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P130
   Parvathy SB, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND COMMUNICATIONS (ICCSC), P127, DOI 10.1109/COMPSC.2014.7032634
   Ratyal N, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3547416
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sghaier S, 2018, INT J AMBIENT COMPUT, V9, P60, DOI 10.4018/IJACI.2018010104
   Soltanpour S, 2017, IEEE IMAGE PROC, P2811, DOI 10.1109/ICIP.2017.8296795
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1039, DOI 10.1109/ICDSP.2015.7252036
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tong M, 2020, NEURAL COMPUT APPL, V32, P5285, DOI 10.1007/s00521-019-04030-1
   Tong M, 2019, NEURAL COMPUT APPL, V31, P7447, DOI 10.1007/s00521-018-3554-6
   Tong M, 2019, NEUROCOMPUTING, V325, P90, DOI 10.1016/j.neucom.2018.09.086
   Wang X, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-51
   Werghi N, 2013, IEEE IMAGE PROC, P3710, DOI 10.1109/ICIP.2013.6738765
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan YZ, 2020, EUR J OPER RES, V281, P559, DOI 10.1016/j.ejor.2018.09.018
   Zhang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100120
   Zheng DP, 2016, LECT NOTES COMPUT SC, V9772, P300, DOI 10.1007/978-3-319-42294-7_26
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 44
TC 10
Z9 11
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31329
EP 31352
DI 10.1007/s11042-020-09554-6
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400005
DA 2024-07-18
ER

PT J
AU Yin, SL
   Li, H
   Liu, DS
   Karim, S
AF Yin, Shoulin
   Li, Hang
   Liu, Desheng
   Karim, Shahid
TI Active contour modal based on density-oriented BIRCH clustering method
   for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Density-oriented BIRCH; Active contour
   model; Energy function
ID MODEL; REGION; GRAPH
AB Currently, medical image segmentation has attracted more attention from researchers, which can assist in medical diagnosis. However, in the process of traditional medical image segmentation, it is sensitive to the initial contour and noise, which is difficult to deal with the weak edge image, complex iterative process. In this paper, we propose a new medical image segmentation method, which adopts density-oriented BIRCH (balanced iterative reducing and clustering using hierarchies) clustering method to modify active contour model and improve the robustness of noise. The BIRCH is a multi-stage clustering method using clustering feature tree. The improved model can effectively deal with the gray non-uniformity of real medical images. And we also introduce a new energy function in active contour model to make the contour curve approach to the edge, and finally stay at the edge of the image to complete the object segmentation. Experimental results show that this new model can overcome the influence of complex background on medical image segmentation and improve the speed and accuracy of medical segmentation results.
C1 [Yin, Shoulin; Li, Hang] Shenyang Normal Univ, Software Coll, Shenyang 110034, Peoples R China.
   [Liu, Desheng] Jiamusi Univ, Coll Informat & Elect Technol, Jiamusi 154007, Heilongjiang, Peoples R China.
   [Karim, Shahid] ILMA Univ, Dept Comp Sci, Karachi, Pakistan.
C3 Shenyang Normal University; Jiamusi University
RP Li, H (corresponding author), Shenyang Normal Univ, Software Coll, Shenyang 110034, Peoples R China.
EM yslinhit@163.com; lihangsoft@163.com; zdhlds@163.com;
   shahidhit@yahoo.com
RI Karim, Shahid/AAO-1087-2020; Yin, Shoulin/IZE-4876-2023; Yin,
   Shoulin/AAQ-6430-2021
OI Karim, Shahid/0000-0001-9986-5052; Yin, Shoulin/0000-0002-5367-1372; Li,
   Hang/0000-0002-1230-4007
FU Heilongjiang Province science found for returnees [LC2017027]; Jiamusi
   University Science and Technology Innovation Team Construction Project
   [CXTDPY-2016-3]; Basic Research Project of Heilongjiang Province
   Department Of Education [:2016-kyywf-0547]
FX This research was funded by Heilongjiang Province science found for
   returnees (grant number: LC2017027), Jiamusi University Science and
   Technology Innovation Team Construction Project (grant number:
   CXTDPY-2016-3), Basic Research Project of Heilongjiang Province
   Department Of Education (grant number:2016-kyywf-0547).
CR Bai X, 2009, INT S ADV VIS COMP
   Bonini S, 2014, MATH STAT METHODS AC
   Boskovitz V, 2002, IEEE T FUZZY SYST, V10, P247, DOI 10.1109/91.995125
   Chen YF, 2017, KNOWL-BASED SYST, V120, P57, DOI 10.1016/j.knosys.2016.12.023
   Fan XC, 2016, COMPUT MATH APPL, V71, P2272, DOI 10.1016/j.camwa.2015.11.003
   Gan YZ, 2015, MED PHYS, V42, P14, DOI 10.1118/1.4901521
   Gong XP, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103973
   Guo Q, 2015, CHINESE J ELECTRON, V24, P802, DOI 10.1049/cje.2015.10.023
   Huo GY, 2017, IEEE T CYBERNETICS, V47, P855, DOI 10.1109/TCYB.2016.2530786
   Koh J, 2010, IEEE ENG MED BIO, P3117, DOI 10.1109/IEMBS.2010.5626097
   Lee J, 2018, MED PHYS, V45, P1178, DOI 10.1002/mp.12763
   Li B, 2010, CHINESE J ELECTRON, V19, P451
   Liu Jie, 2017, J Inf Hiding Multimed Signal Process, V8, P12
   Lu X, 2019, CVPR19
   Madan S, 2016, PATTERN ANAL APPL, V19, P1023, DOI 10.1007/s10044-015-0472-4
   Miao J, 2018, IMAGE DETECT QUAL, V80, P1
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Petke J, 2010, LECT NOTES COMPUT SC, V6308, P398, DOI 10.1007/978-3-642-15396-9_33
   Singh E, 2018, IEEE T COMPUT AID D, P1
   Sun GD, 2019, IEICE T INF SYST, VE102D, P1073, DOI 10.1587/transinf.2018EDP7322
   Teng L, 2019, INT J IMAGE DATA FUS, V10, P327, DOI 10.1080/19479832.2019.1604574
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang HJ, 2010, INT C MACH VIS HUM M
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang XH, 2019, MULTIMED TOOLS APPL, V78, P33921, DOI 10.1007/s11042-019-08073-3
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Yin SL, 2019, INT J IMAGE DATA FUS, V10, P146, DOI 10.1080/19479832.2018.1487886
   Yin SL, 2018, IEEE ACCESS, V6, P26069, DOI 10.1109/ACCESS.2018.2834960
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang L, 2010, IEEE INT C SIGN PROC
   Zhang M., 2017, SOFT COMPUT, V23, P1, DOI DOI 10.1038/CDDIS.2017.467.PMID:28981116
NR 34
TC 52
Z9 53
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31049
EP 31068
DI 10.1007/s11042-020-09640-9
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900003
DA 2024-07-18
ER

PT J
AU Hassan, SA
   Sayed, MS
   Abdalla, M
   Rashwan, MA
AF Hassan, Shayma'a A.
   Sayed, Mohammed S.
   Abdalla, Mahmoud, I
   Rashwan, Mohsen A.
TI Breast cancer masses classification using deep convolutional neural
   networks and transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram images; Computer-aided diagnosis; Mass classification; Deep
   learning; Transfer learning; Deep convolutional neural network
ID AIDED DIAGNOSIS SYSTEM; DIGITAL MAMMOGRAMS; IMAGE
AB With the recent advances in the deep learning field, the use of deep convolutional neural networks (DCNNs) in biomedical image processing becomes very encouraging. This paper presents a new classification model for breast cancer masses based on DCNNs. We investigated the use of transfer learning from AlexNet and GoogleNet pre-trained models to suit this task. We experimentally determined the best DCNN model for accurate classification by comparing different models, which vary according to the design and hyper-parameters. The effectiveness of these models were demonstrated using four mammogram databases. All models were trained and tested using a mammographic dataset from CBIS-DDSM and INbreast databases to select the best AlexNet and GoogleNet models. The performance of the two proposed models was further verified using images from Egyptian National Cancer Institute (NCI) and MIAS database. When tested on CBIS-DDSM and INbreast databases, the proposed AlexNet model achieved an accuracy of 100% for both databases. While, the proposed GoogleNet model achieved accuracy of 98.46% and 92.5%, respectively. When tested on NCI images and MIAS databases, AlexNet achieved an accuracy of 97.89% with AUC of 98.32%, and accuracy of 98.53% with AUC of 98.95%, respectively. GoogleNet achieved an accuracy of 91.58% with AUC of 96.5%, and accuracy of 88.24% with AUC of 94.65%, respectively. These results suggest that AlexNet has better performance and more robustness than GoogleNet. To the best of our knowledge, the proposed AlexNet model outperformed the latest methods. It achieved the highest accuracy and AUC score and the lowest testing time reported on CBIS-DDSM, INbreast and MIAS databases.
C1 [Hassan, Shayma'a A.; Sayed, Mohammed S.; Abdalla, Mahmoud, I] Zagazig Univ, Dept Elect & Commun Engn, Zagazig, Egypt.
   [Sayed, Mohammed S.] Egypt Japan Univ Sci & Technol, Dept Elect & Commun Engn, Alexandria, Egypt.
   [Abdalla, Mahmoud, I] IAEMS Int Acad Engn & Media Sci, Giza, Egypt.
   [Rashwan, Mohsen A.] Cairo Univ, Dept Elect & Commun Engn, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Egypt-Japan University of Science & Technology; Egyptian
   Knowledge Bank (EKB); Cairo University
RP Hassan, SA (corresponding author), Zagazig Univ, Dept Elect & Commun Engn, Zagazig, Egypt.
EM shafayad@zu.edu.eg; mohammed.sayed@ejust.edu.eg; mrashwan@rdi-eg.ai
OI Ahmed, Shaymaa/0000-0003-4886-2315
CR Abbas A, 2020, IEEE ACCESS, V8, P74901, DOI 10.1109/ACCESS.2020.2989273
   Abbas Q, 2016, COMPUTERS, V5, DOI 10.3390/computers5040028
   Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4
   Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409
   Agnes SA, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1494-z
   Al-antari M.A., 2020, ADV EXPT MED BIOL, V1213
   Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   American Cancer Society, 2019, Cancer treatment and survivorship facts figures 20192021
   Arora R, 2020, MED BIOL ENG COMPUT, V58, P1199, DOI 10.1007/s11517-020-02150-8
   Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Gardezi SJS, 2019, J MED INTERNET RES, V21, DOI 10.2196/14464
   Hassan SA, 2019, MULTIMED TOOLS APPL, V78, P20239, DOI 10.1007/s11042-019-7358-1
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Khan FA, 2020, MULTIMED TOOLS APPL, V79, P34545, DOI 10.1007/s11042-020-08768-y
   Khan SU, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27515-w
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Michelucci U., 2019, Advanced Applied Deep Learning: Convolutional Neural Networks and Object Detection, DOI 10.1007/978-1-4842-4976-5
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shu X, 2020, IEEE T MED IMAGING, V39, P2246, DOI 10.1109/TMI.2020.2968397
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Sundararajan D., 2017, Digital Image Processing: A Signal Processing and Algorithmic Approach
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   World Health Organization, 2019, BREAST CANC
   Zhang HB, 2020, INFORM SCIENCES, V539, P461, DOI 10.1016/j.ins.2020.05.080
NR 37
TC 38
Z9 38
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30735
EP 30768
DI 10.1007/s11042-020-09518-w
EA AUG 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300005
DA 2024-07-18
ER

PT J
AU Singh, R
   Rana, PS
   Jindal, N
AF Singh, Rakesh
   Rana, Prashant Singh
   Jindal, Neeru
TI A novel approach for detecting roundabouts in maps based on analysis of
   core map data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Roundabout; Maps; Machine learning
AB Approaches for detecting roundabouts in maps are heavily dependent on looking at the problem from a machine-learning powered computer vision perspective. In this paper, we propose a fresh approach, taking core map data into account, that supplements existing techniques in a phenomenal way thereby significantly reducing the machine learning effort involved. As a direct consequence, our approach filters the training set to greatly reduce the scope of the ML problem resulting in increased accuracy. At the core of the proposed approach is the fact that data fields, which are used to describe maps, encapsulate geometric details about map points. If interpreted correctly, these details can be used to identify various map features including roundabouts. The proposed approach has two parts. First, an algorithm has been proposed which interprets core map data to identify roundabouts. This algorithm correctly detects roundabouts in more than 80% of the cases. Then, the remaining less than 20% cases are run through a machine learning model having extremely high accuracy because of a very specific training set. This results in an overall roundabout detection rate of more than 97%. Using this approach, we have succeeded in saving thousands of man-hours towards manual roundabout verification and correction.
C1 [Singh, Rakesh; Rana, Prashant Singh] Thapar Inst Engn & Technol, Dept Comp Sci, Patiala, Punjab, India.
   [Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Singh, R (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci, Patiala, Punjab, India.
EM f25527180@gmail.com; prashant.singh@thapar.edu; neeru.jindal@thapar.edu
RI Rana, Prashant Singh/AAE-1784-2019
OI Rana, Prashant Singh/0000-0002-0142-7925; Singh,
   Rakesh/0000-0003-4125-638X
CR Ali MAH, 2019, IEEE T VEH TECHNOL, V68, P2176, DOI 10.1109/TVT.2019.2893878
   [Anonymous], WHAT LAN SHOULD I US
   Boichis N, 2000, INT ARCH PHOTOGRAMME, VXXXIII, P27
   Boichis N, 1998, INT ARCH PHOTOGRAMM, VXXXII, P19
   Bordes J.-B., 2006, ISPRS ANKARA TURKEY, VXXXVI, P1
   Brandin M., 2019, U.S. Patent, Patent No. 10259322
   Chai Z, 2007, TECHNOL GANSU CHINA, V23, P176
   Choksuriwong A, 2005, IEEE IMAGE PROC, P713
   De Gunst M, 1996, THESIS
   Cuenca LG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102386
   Gerke M, 2006, THESIS
   Gribov A, 2017, PROC INT CONF DOC, P15, DOI 10.1109/ICDAR.2017.255
   Hels T, 2007, ACCIDENT ANAL PREV, V39, P300, DOI 10.1016/j.aap.2006.07.008
   Herslund MB, 2003, ACCIDENT ANAL PREV, V35, P885, DOI 10.1016/S0001-4575(02)00095-7
   Hofmann H, 2017, U.S. Patent, Patent No. [9,672,759, 9672759]
   Jorge F., 2012, THESIS
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   LEE EH, 1973, SIAM REV, V15, P120, DOI 10.1137/1015004
   Li X., 2017, INT ARCH PHOTOGRAMME, V42
   Muñoz-Organero M, 2017, J ADV TRANSPORT, DOI 10.1155/2017/3802807
   Park H, 2001, COMPUT AIDED DESIGN, V33, P967, DOI 10.1016/S0010-4485(00)00133-0
   Ravanbakhsh M, 2009, P CMRT 09, P19
   Robinson B.W., 2000, Roundabouts: An Informational Guide
   Robusto C.C., 1957, Am. Math. Mon, V64, P38, DOI [DOI 10.2307/2309088, 10.2307/2309088]
   Sacchi E, 2011, TRANSPORT RES REC, P253, DOI 10.3141/2265-28
   Veness C., 2012, MOVABLE TYPE SCRIPTS
   Zaverucha QA, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P758
   Zhao M, 2017, IEEE INT VEH SYM, P908, DOI 10.1109/IVS.2017.7995831
   Zinoune C, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P123, DOI 10.1109/IVS.2012.6232245
NR 29
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30785
EP 30811
DI 10.1007/s11042-020-09558-2
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300002
DA 2024-07-18
ER

PT J
AU Ul Haq, E
   Huang, JJ
   Li, K
   Ul Haq, H
AF Ul Haq, Ejaz
   Huang, Jianjun
   Li, Kang
   Ul Haq, Hafeez
TI Human detection and tracking with deep convolutional neural networks
   under the constrained of noise and occluded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Detection; Deep learning; Data augmentation techniques
ID PEDESTRIAN DETECTION; EFFICIENT; IMAGE
AB Human detection and tracking is a key aspect in surveillance system due to its importance in timely identification of person, recognition of human activity and scene analysis. Convolutional neural networks have been widely used approach in detection and tracking related tasks. In this paper, a robust framework is presented for the human detection and tracking in noisy and occluded environments with the aid of data augmentation techniques. In addition, a softmax layer and integrated loss function is used to improve the detection and classification performance of the proposed model. The primary focus is to perform the human detection task in unconstrained environments. The implemented system outperforms the state-of-the-arts methods which can be validated from the experimental results.
C1 [Ul Haq, Ejaz; Huang, Jianjun; Li, Kang] Shenzhen Univ, Sch Elect & Informat Engn, ATR Key Lab, Shenzhen, Peoples R China.
   [Ul Haq, Hafeez] Fujian Normal Univ, Fuzhou, Peoples R China.
C3 Shenzhen University; Fujian Normal University
RP Huang, JJ (corresponding author), Shenzhen Univ, Sch Elect & Informat Engn, ATR Key Lab, Shenzhen, Peoples R China.
EM huangjin@szu.edu.cn
RI Haq, Ejaz Ul/HGU-9669-2022; UL Haq, Ejaz/IVH-6840-2023; Huang,
   Jianjun/AAB-3051-2019
OI UL Haq, Ejaz/0000-0002-0099-0708; Huang, Jianjun/0000-0001-7040-3591; ,
   Hafeez Ul Haq/0000-0001-9331-4700
CR An FP, 2020, VISUAL COMPUT, V36, P483, DOI 10.1007/s00371-019-01635-4
   [Anonymous], 2015, SPA 2015 SIGN PROC
   [Anonymous], 2015, 2015 IEEE S SER, DOI DOI 10.1109/SSCI.2015.39
   [Anonymous], 2007, 2007 IEEE INT C ROB
   [Anonymous], 2010, PARASITE VECTOR, DOI DOI 10.1186/1756-3305-3-51
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Chahyati D, 2017, PROCEDIA COMPUT SCI, V124, P167, DOI 10.1016/j.procs.2017.12.143
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Coltuc D, 1999, P IEEE INT C IM PROC, P150
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Farhadi A, 2016, YOLO9000 BETTER FAST
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Flores-Calero M, 2019, IEEE LAT AM T, V17, P1552, DOI [10.1109/tla.2019.8931190, 10.1109/TLA.2019.8931190]
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo K, 2017, CAAI T INTELL TECHNO, V2, P39, DOI 10.1016/j.trit.2017.03.001
   Hajizadeh MA, 2011, P 7 IR C MACH VIS IM, P1
   Huang C, 2017, ARXIV170106054
   Jen TC, 2005, P IEEE INT C IM PROC, P1
   Jeon HM, 2019, IEEE IND ELEC, P144, DOI 10.1109/IECON.2019.8927417
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Kim B, 2020, SOFT COMPUT, V24, P17081, DOI 10.1007/s00500-020-04999-1
   Kim S, 2019, IEEE ACCESS, V7, P12415, DOI 10.1109/ACCESS.2019.2892425
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu J, 2017, IEEE IJCNN, P2056, DOI 10.1109/IJCNN.2017.7966103
   Liu S., 2019, GOOGLE PATENT
   Luo P, 2013, P IEEE INT C COMP VI
   Lv JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P465, DOI 10.1016/j.image.2016.03.011
   Madbouly A. M. M, 2015, IJCSI INT J COMPUTER, V12, P87
   Mateus A, 2019, ROBOT AUTON SYST, V113, P23, DOI 10.1016/j.robot.2018.12.007
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Renu Chebrolu Koti Naga, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0838, DOI 10.1109/ICCSP.2019.8698101
   Ribeiro D, 2016, ARXIV160704441
   Rivera AR, 2012, IEEE T IMAGE PROCESS, V21, P3967, DOI 10.1109/TIP.2012.2198667
   Said YF, 2019, INT J COMPUT SCI NET, V19, P9
   Selvaraj A, 2020, COMPUT INTELL-US, V36, P1569, DOI 10.1111/coin.12292
   Sun XX, 2019, J ENG-JOE, V2019, P6799, DOI 10.1049/joe.2019.0542
   Supreeth HSG, 2018, SIGNAL IMAGE VIDEO P, V12, P1097, DOI 10.1007/s11760-018-1259-z
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Dinh TT, 2018, 2018 19TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P281, DOI 10.1109/SNPD.2018.8441055
   Wang WT, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051866
   Wang X., 2019, C BIOMETRIC RECOGNIT
   Xu CC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5761414
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yang Z, 2016, ADV SEM MAN C
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
NR 53
TC 12
Z9 12
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30685
EP 30708
DI 10.1007/s11042-020-09579-x
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300003
DA 2024-07-18
ER

PT J
AU Cuevas, C
   Quilón, D
   García, N
AF Cuevas, Carlos
   Quilon, Daniel
   Garcia, Narciso
TI Techniques and applications for soccer video analysis: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soccer; Football; Survey; Review; Overview; State-of-the-art; FIFA;
   Application; Method; Strategy; Event detection; Player tracking; Ball
   tracking; Game analysis; Team performance
ID AUTOMATIC PLAYER DETECTION; EVENT DETECTION; BALL DETECTION; TECHNICAL
   PERFORMANCE; BAYESIAN NETWORK; KALMAN FILTER; SPORTS VIDEO; ELITE
   SOCCER; TEAM SUCCESS; TRACKING
AB Nowadays, soccer is the most popular sport in our society, followed by millions of people. Consequently, many video analysis applications have been developed in the last years to provide information that can be useful for viewers, referees, coaches and players. Some of these applications are focused on specific tasks, such as detecting players, segmenting the field of play, or registering the broadcast images. On the other hand, there are applications aimed at performing tasks of a higher level, such as event detection or game analysis. Here, the most meaningful techniques and applications that have been proposed throughout the last two decades to analyze soccer video sequences are surveyed. The aim of the paper is not to compare the existing techniques, but to represent a comprehensive and organized showcase for the state-of-the-art in the field: as such, it provides a thorough review of the existing types of soccer analysis applications and the techniques used in each one of them, along with the apparent recent technical trends identified from the most recent works, and discuses the challenges in soccer analysis that still remain unsolved.
C1 [Cuevas, Carlos; Quilon, Daniel; Garcia, Narciso] Univ Politecn Madrid, Informat Proc & Telecommun Ctr, Grp Tratamiento Imagenes GTI, Madrid 28040, Spain.
   [Cuevas, Carlos; Quilon, Daniel; Garcia, Narciso] Univ Politecn Madrid, ETSI Telecomunicac, Madrid 28040, Spain.
C3 Universidad Politecnica de Madrid; Centro de I+D+I en Procesado de la
   Informacion Telecomunicaciones (IPT); Universidad Politecnica de Madrid
RP Cuevas, C (corresponding author), Univ Politecn Madrid, Informat Proc & Telecommun Ctr, Grp Tratamiento Imagenes GTI, Madrid 28040, Spain.; Cuevas, C (corresponding author), Univ Politecn Madrid, ETSI Telecomunicac, Madrid 28040, Spain.
EM ccr@gti.ssr.upm.es
RI Cuevas, Carlos/Z-3173-2019; García, Narciso/E-8603-2011
OI Cuevas, Carlos/0000-0001-9873-8502; García, Narciso/0000-0002-0397-894X
FU Ministerio de Ciencia, Innovacion y Universidades (AEI/FEDER) of the
   Spanish Government [TEC2016-75981]
FX This work has been partially supported by the Ministerio de Ciencia,
   Innovacion y Universidades (AEI/FEDER) of the Spanish Government under
   project TEC2016-75981 (IVME).
CR Al-Ali A., 2017, 2017 6 INT C INF COM, P1, DOI [10.1109/ICTA.2017.8336015, DOI 10.1109/ICTA.2017.8336015]
   Ali M. M. N., 2012, ADV SCI TECHNOLOGY L, V16, P39
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2008, P 2008 INT C CONT IM
   [Anonymous], 2018, ARXIV180404527
   [Anonymous], 2001, P IEEE INT C MULT EX, DOI DOI 10.1109/ICME.2001.1237822
   [Anonymous], 2013, International Journal of Computer Science in Sport
   [Anonymous], 2012, Int J Adv Res Comput Eng Technol
   [Anonymous], 2005, Nonlinear Signal Processing: A Statistical Approach
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Assfalg J, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P825, DOI 10.1109/ICME.2002.1035909
   Athanesious J., 2013, INT J ADV RES COMPUT, V2, P1298
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Bandyopadhyay K., 2017, Legacies of great men in world soccer: Heroes, icons, legends.
   Barros RML, 2007, J SPORT SCI MED, V6, P233
   Bayar M, 2010, IEEE INT CON MULTI, P578, DOI 10.1109/ICME.2010.5583864
   Beetz M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2066
   Beetz Michael., 2006, AAMAS, P42
   Berjón D, 2018, PATTERN RECOGN, V74, P156, DOI 10.1016/j.patcog.2017.09.009
   Bialkowski A, 2016, IEEE T KNOWL DATA EN, V28, P2596, DOI 10.1109/TKDE.2016.2581158
   Bialkowski A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P9, DOI 10.1109/ICDMW.2014.167
   Bialkowski A, 2014, IEEE DATA MINING, P725, DOI 10.1109/ICDM.2014.133
   Blake A, 1997, ADV NEUR IN, V9, P361
   Bozorgpour A, 2015, IRAN CONF ELECTR ENG, P787, DOI 10.1109/IranianCEE.2015.7146320
   Bracewell R. N, 1986, FOURIER TRANSFORM IT, V3rd
   Carling C, 2008, SPORTS MED, V38, P839, DOI 10.2165/00007256-200838100-00004
   Castellano J, 2014, SPORTS MED, V44, P701, DOI 10.1007/s40279-014-0144-3
   Chavan K, 2016, INDIAN J GYNECOL ONC, V14, DOI 10.1007/s40944-016-0061-5
   Chen SC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P265, DOI 10.1109/ICME.2004.1394176
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Collet C, 2013, J SPORT SCI, V31, P123, DOI 10.1080/02640414.2012.727455
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cuevas C, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107278
   Cuevas C, 2008, PROC SPIE, V6811
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P41, DOI 10.1016/j.cviu.2016.07.001
   D'Orazio T, 2004, PATTERN RECOGN, V37, P393, DOI 10.1016/S0031-3203(03)00228-0
   D'Orazio T, 2002, INT C PATT RECOG, P210, DOI 10.1109/ICPR.2002.1044654
   D'Orazio T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P559, DOI 10.1109/AVSS.2009.69
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   D'Orazio T, 2009, COMPUT VIS IMAGE UND, V113, P622, DOI 10.1016/j.cviu.2008.01.010
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   da Silva R, 2014, PHYSICA A, V398, P56, DOI 10.1016/j.physa.2013.12.008
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Ding XF, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P608
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Eldib MY, 2009, IEEE IMAGE PROC, P4345, DOI 10.1109/ICIP.2009.5413649
   Esmin Ahmed A. A., 2014, Natural Language Processing and Information Systems. 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014. Proceedings: LNCS 8455, P220
   Fakhar B, 2019, MULTIMED TOOLS APPL, V78, P16995, DOI 10.1007/s11042-018-7083-1
   Fani M, 2017, IEEE ACCESS, V5, P27322, DOI 10.1109/ACCESS.2017.2769140
   Fernandez-Navarro J, 2016, J SPORT SCI, V34, P2195, DOI 10.1080/02640414.2016.1169309
   Figueroa PJ, 2006, IMAGE VISION COMPUT, V24, P363, DOI 10.1016/j.imavis.2005.12.012
   Figueroa PJ, 2006, COMPUT VIS IMAGE UND, V101, P122, DOI 10.1016/j.cviu.2005.07.006
   Fradua L, 2013, J SPORT SCI, V31, P573, DOI 10.1080/02640414.2012.746722
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gerke S, 2017, COMPUT VIS IMAGE UND, V159, P105, DOI 10.1016/j.cviu.2017.04.010
   Habtemariam B, 2013, IEEE J-STSP, V7, P461, DOI 10.1109/JSTSP.2013.2256772
   Hagras, 2017, 2017 IEEE INT C FUZZ, P1
   Halin Alfian Abdul, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P410, DOI 10.1109/ICSIPA.2009.5478688
   Halin AA, 2013, INT ARAB J INF TECHN, V10, P493
   Harris C., 1988, ALVEY VISION C, P147151
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hasan M, 2018, J INF SCI, V44, P443, DOI 10.1177/0165551517698564
   Hashimoto S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1889, DOI 10.1109/ICME.2006.262924
   Hayet JB, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P493
   Hennessy L, 2018, STRENGTH COND J, V40, P83, DOI 10.1519/SSC.0000000000000386
   Homayounfar N., 2016, ARXIV160402715
   Homayounfar N, 2017, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR.2017.427
   Hong Yang., 2018, Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology, P1
   Hossein-Khani J, 2011, 2011 NINTH IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS WORKSHOPS (ISPAW), P147, DOI 10.1109/ISPAW.2011.41
   Hosseini MS, 2013, APPL SOFT COMPUT, V13, P846, DOI 10.1016/j.asoc.2012.10.007
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   Iwase S, 2004, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2004.1333881
   Jai-Andaloussi S, 2014, 2014 IEEE/ACM INTERNATIONAL SYMPOSIUM ON BIG DATA COMPUTING (BDC), P1, DOI 10.1109/BDC.2014.20
   Jiang HH, 2016, PROC INT C TOOLS ART, P490, DOI [10.1109/ICTAI.2016.0081, 10.1109/ICTAI.2016.78]
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Kaewbuadee P, 2016, INT JOINT C COMP SCI, P1
   Kamble PR, 2019, OPTO-ELECTRON REV, V27, P58, DOI 10.1016/j.opelre.2019.02.003
   Kamble PR, 2019, ARTIF INTELL REV, V52, P1655, DOI 10.1007/s10462-017-9582-2
   Kang CH, 2006, ICDM 2006: Sixth IEEE International Conference on Data Mining, Workshops, P377
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kataoka H., 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1985
   Khan YS, 2015, INT J ADV COMPUT SC, V6, P256
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kia M, 2016, INT J COMPUT SCI NET, V16, P1
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kim H, 2003, P IM VIS COMP PALM N, P159
   Kim JY, 2009, I C COMP GRAPH IM VI, P367, DOI 10.1109/CGIV.2009.87
   Kim W, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102683
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Komorowski Jacek, 2019, ARXIV191205445
   Lago C, 2009, J SPORT SCI, V27, P1463, DOI 10.1080/02640410903131681
   Lee J, 2017, FED CONF COMPUT SCI, P643, DOI 10.15439/2017F104
   Leo M, 2008, LECT NOTES COMPUT SC, V5099, P263, DOI 10.1007/978-3-540-69905-7_30
   Leo M, 2013, MACH VISION APPL, V24, P1561, DOI 10.1007/s00138-013-0518-9
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li WW, 2014, 2014 10TH INTERNATIONAL CONFERENCE ON HETEROGENEOUS NETWORKING FOR QUALITY, RELIABILITY, SECURITY AND ROBUSTNESS (QSHINE), P1, DOI [10.1109/QSHINE.2014.6928651, 10.4108/icst.qshine.2014.256294]
   Link D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179953
   Linnemann A, 2013, IEEE IMAGE PROC, P1316, DOI 10.1109/ICIP.2013.6738271
   Liu HY, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P128, DOI 10.1109/JCAI.2009.22
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lizza JP, 2018, DIAMETROS, P1, DOI 10.13153/diam.1172
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu K, 2018, COMPUTER VISION IMAG
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   del Campo VL, 2018, PSYCHOL SPORT EXERC, V37, P139, DOI 10.1016/j.psychsport.2018.03.004
   Mackenzie R, 2013, J SPORT SCI, V31, P639, DOI 10.1080/02640414.2012.746720
   Manafifard M, 2017, COMPUT VIS IMAGE UND, V159, P19, DOI 10.1016/j.cviu.2017.02.002
   Manafifard M, 2017, MULTIMED TOOLS APPL, V76, P12251, DOI 10.1007/s11042-016-3625-6
   Martín R, 2014, MULTIMED TOOLS APPL, V73, P1617, DOI 10.1007/s11042-013-1659-6
   McHale IG, 2018, EUR J OPER RES, V268, P339, DOI 10.1016/j.ejor.2018.01.018
   Memmert D., 2018, Deutsche Zeitschrift Fur Sportmedizin, V2018, P65, DOI [DOI 10.5960/DZSM.2018.322, 10.5960/dzsm.2018.322]
   Memmert D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210191
   Memmert D, 2017, SPORTS MED, V47, P1, DOI 10.1007/s40279-016-0562-5
   Muthuraman K, 2018, ARXIV180406438
   Naemura M, 2000, IEEE T BROADCAST, V46, P181, DOI 10.1109/11.892154
   Nguyen N, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P344, DOI 10.1109/ISM.2012.69
   Nguyen NT, 2014, STUD COMPUT INTELL, V511, P1, DOI 10.1007/978-3-319-01571-2_1
   Nichols J., 2012, Summarizing sporting events using Twitter, P189, DOI DOI 10.1145/2166966.2166999
   Nieto M, 2009, IEEE IMAGE PROC, P4097, DOI 10.1109/ICIP.2009.5413709
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Nuñez JR, 2008, INT CONF SYST SIGNAL, P279, DOI 10.1109/IWSSIP.2008.4604421
   Oh S, 2009, IEEE T AUTOMAT CONTR, V54, P481, DOI 10.1109/TAC.2009.2012975
   Pallavi V, 2008, J VIS COMMUN IMAGE R, V19, P426, DOI 10.1016/j.jvcir.2008.06.007
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Pappalardo L, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3343172
   Patel B, 2012, INT J COMPUT SCI NET, V12, P100
   POWELL MJD, 1965, COMPUT J, V7, P303, DOI 10.1093/comjnl/7.4.303
   Quilon D, 2015, IEEE INT S CONS EL I, P1
   Raghuram M, 2016, IEEE CAN C EL COMP E, P1
   Rao MU, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P344, DOI 10.1109/ICCSP.2015.7322903
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Rein R, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3108-2
   Ren JC, 2009, COMPUT VIS IMAGE UND, V113, P633, DOI 10.1016/j.cviu.2008.01.007
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Ryoo M, 2018, MULTIMED TOOLS APPL, V77, P15603, DOI 10.1007/s11042-017-5137-4
   Sabirin H, 2015, IEICE T INF SYST, VE98D, P1580, DOI 10.1587/transinf.2014EDP7313
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sampaio J, 2012, INT J SPORTS MED, V33, P395, DOI 10.1055/s-0031-1301320
   Sarkar S., 2019, P IEEE C COMP VIS PA
   Sigari M.-H., 2015, Int. J. Comput. Graph., V6, P13
   Sigari MH, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P101, DOI 10.1109/AISP.2015.7123487
   Spagnolo P, 2007, SIGMAP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P129
   Sukhwani M, 2017, ARXIV170609193
   Sverrisson S, 2019, LECT NOTES COMPUT SC, V11482, P399, DOI 10.1007/978-3-030-20205-7_33
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Theagarajan R, 2020, IEEE T CIRCUITS SYST
   Theagarajan R, 2018, P IEEE CVF C COMP VI, P1749
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Tong XF, 2004, INT C PATT RECOG, P795, DOI 10.1109/ICPR.2004.1333892
   Tong XF, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899419
   Tsai PS, 2007, MACH VISION APPL, V18, P289, DOI 10.1007/s00138-006-0058-7
   Varley MC, 2017, SCI MED FOOTBALL, V1, P18, DOI 10.1080/02640414.2016.1230676
   Wan K, 2004, INT C PATT RECOG, P973, DOI 10.1109/ICPR.2004.1334691
   Wang ZK, 2017, IEEE T CIRC SYST VID, V27, P1104, DOI 10.1109/TCSVT.2016.2515280
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Xu M, 2005, IEE P-VIS IMAGE SIGN, V152, P232, DOI 10.1049/ip-vis:20041257
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang G, 2018, RES SPORTS MED, V26, P158, DOI 10.1080/15438627.2018.1431539
   Yang Y, 2017, J VIS COMMUN IMAGE R, V46, P81, DOI 10.1016/j.jvcir.2017.03.008
   Yao Q, 2017, INT CONF ACOUST SPEE, P1612, DOI 10.1109/ICASSP.2017.7952429
   Yao Q, 2016, IEEE IMAGE PROC, P1185, DOI 10.1109/ICIP.2016.7532545
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu J, 2019, INT C MULT MOD MMM, P377
   Yu J, 2018, IEEE C MULT INF PROC
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P522
   Yu XG, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1811
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang LJ, 2018, LECT NOTES ARTIF INT, V11013, P438, DOI 10.1007/978-3-319-97310-4_50
   Zhu Guan, 2007, P57, DOI 10.1201/9781420052275.ch3
   Zubiaga Arkaitz., 2012, Proceedings of the 23rd ACM Conference on Hypertext and Social Media, P319, DOI DOI 10.1145/2309996.2310053
NR 177
TC 20
Z9 20
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29685
EP 29721
DI 10.1007/s11042-020-09409-0
EA AUG 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300005
DA 2024-07-18
ER

PT J
AU Prabhakar, M
   Purushothaman, R
   Awasthi, DP
AF Prabhakar, Maheswari
   Purushothaman, Raja
   Awasthi, Durga Prasad
TI Deep learning based assessment of disease severity for early blight in
   tomato crop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Precision agriculture; Deep learning; CNN; ResNet101; Foldscope;
   Fungicide
AB Assessment of disease severity is one of the major challenges which helps in the prediction of yield quantitatively and to decide the control factors that improve the yield of any crop. Hence a perfect system is essential to measure the severity level of the disease in order to improve its productivity. An intelligent state of the art technique i.e., deep learning plays an inevitable role in most of the real-time applications including smart farming. Tomato crops are frequently affected by a dangerous fungal disease i.e., early blight, resulting in 100% production loss to farmers. In this work, an identification of early blight disease in tomato leaves is performed by a recently invented paper microscope named Foldscope. Further, a deep Residual Network101 (ResNet101) of Convolutional Neural Network (CNN) architecture is used to measure the severity level of early blight disease in tomato leaves. The dataset in the model is trained by using an open database i.e., PlantVillage dataset for mild, moderate, and severely diseased leaves along with healthy tomato leaves. The results of ResNet101 architecture is compared with other pre-trained CNN such as Visual Geometry Group16 (VGG16), VGG19, GoogLeNet, AlexNet, and ResNet50. Among these networks, the deep ResNet101 architecture has achieved the highest accuracy of 94.6%. Finally, a case study has been conducted based on the estimated severity levels and the required fungicide treatment is also prescribed.
C1 [Prabhakar, Maheswari; Purushothaman, Raja] SASTRA Deemed Univ, Sch Mech Engn, Thanjavur 613401, Tamil Nadu, India.
   [Awasthi, Durga Prasad] Coll Agr, Dept Plant Pathol, Lembucherra 799210, Tripura, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Purushothaman, R (corresponding author), SASTRA Deemed Univ, Sch Mech Engn, Thanjavur 613401, Tamil Nadu, India.
EM raja_sastra@yahoo.com
RI Awasthi, Durga/KRO-8308-2024; P., Raja/AAV-7707-2020
OI Awasthi, Durga/0000-0002-4114-6319; Prabhakar,
   Maheswari/0000-0003-0888-1116
FU Department of Biotechnology (DBT), Government of India
   [BT/IN/Indo-US/Foldscope/39/2015]
FX This research was funded by "Department of Biotechnology (DBT),
   Government of India, BT/IN/Indo-US/Foldscope/39/2015 dated 20.03.2018".
CR Adhikari P, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18102019
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Atabay Habibollah Agh, 2017, Journal of Theoretical and Applied Information Technology, V95, P6800
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Cruz A, 2019, COMPUT ELECTRON AGR, V157, P63, DOI 10.1016/j.compag.2018.12.028
   Cybulski JS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098781
   Desta M, 2015, ETHIOPIA J PLANT PAT, V6, DOI [10.4172/2157-7471.1000268, DOI 10.4172/2157-7471.1000268]
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Golhani Kamlesh, 2018, Information Processing in Agriculture, V5, P354, DOI 10.1016/j.inpa.2018.05.002
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hughes D., 2015, ABS151108060 CORR
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Maheswari P, 2018, 2018 IEEE 4TH INTERNATIONAL SYMPOSIUM IN ROBOTICS AND MANUFACTURING AUTOMATION (ROMA)
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Owomugisha G, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P158, DOI [10.1109/ICMLA.2016.126, 10.1109/ICMLA.2016.0034]
   Singh AK, 2018, TRENDS PLANT SCI, V23, P883, DOI 10.1016/j.tplants.2018.07.004
   Wang GQ, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2373818
   Wiatowski T, 2018, IEEE T INFORM THEORY, V64, P1845, DOI 10.1109/TIT.2017.2776228
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
NR 23
TC 25
Z9 26
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28773
EP 28784
DI 10.1007/s11042-020-09461-w
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300007
DA 2024-07-18
ER

PT J
AU Fadel, SG
   Torres, RD
AF Fadel, Samuel G.
   Torres, Ricardo da S.
TI Neural relational inference for disaster multimedia retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Neural networks; Information retrieval; Natural
   language processing; Multimodal
AB Events around the world are increasingly documented on social media, especially by the people experiencing them, as these platforms become more popular over time. As a consequence, social media turns into a valuable source of data for understanding those events. Due to their destructive potential, natural disasters are among events of particular interest to response operations and environmental monitoring agencies. However, this amount of information also makes it challenging to identify relevant content pertaining to those events. In this paper, we use a relational neural network model for identifying this type of content. The model is particularly suitable for unstructured text, that is, text with no particular arrangement of words, such as tags, which is commonplace in social media data. In addition, our method can be combined with a CNN for handling multimodal data where text and visual data are available. We perform experiments in three different scenarios, where different modalities are evaluated: visual, textual, and both. Our method achieves competitive performance in both modalities by themselves, while significantly outperforms the baseline on the multimodal scenario. We also demonstrate the behavior of the proposed method in different applications by performing additional experiments in the CUB-200-2011 multimodal dataset.
C1 [Fadel, Samuel G.] Univ Estadual Campinas, Inst Comp, Ave Albert Einstein 1251, BR-13083852 Campinas, Brazil.
   [Torres, Ricardo da S.] NTNU Norwegian Univ Sci & Technol, Fac Informat Technol & Elect Engn, Dept ICT & Nat Sci, Alesund, Norway.
C3 Universidade Estadual de Campinas; Norwegian University of Science &
   Technology (NTNU)
RP Fadel, SG (corresponding author), Univ Estadual Campinas, Inst Comp, Ave Albert Einstein 1251, BR-13083852 Campinas, Brazil.
EM samuel.fadel@ic.unicamp.br; ricardo.torres@ntnu.no
OI Fadel, Samuel/0000-0002-4459-4336
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES),
   Brazil [001, 88881.145912/2017-01]; CNPq [307560/2016-3]; FAPESP
   [2017/24005-2, 2014/12236-1, 2015/24494-8, 2016/50250-1, 2017/20945-0];
   FAPESP-Microsoft Virtual Institute [2013/50155-0, 2013/50169-1,
   2014/50715-9]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES), Brazil, Finance Code 001, and grant
   #88881.145912/2017-01. Authors are grateful to CNPq (grant
   #307560/2016-3), FAPESP (grants #2017/24005-2, #2014/12236-1,
   #2015/24494-8, #2016/50250-1, and #2017/20945-0), and the
   FAPESP-Microsoft Virtual Institute (grants #2013/50155-0, #2013/50169-1,
   and #2014/50715-9).
CR Ahmad K, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095726
   AHMAD S, 2017, MED WORKSH DUBL IR
   [Anonymous], 2017, P 2017 C EMP METH NA, DOI DOI 10.18653/V1/D17-1254
   Bird S., 2009, NATURAL LANGUAGE PRO
   BISCHKE B, 2017, P MED 2017 WORKSH, V1984
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   DAO MS, 2017, P MED WORKSH DUBL IR
   Dourado JR, 2019, ALGORITHMS, V12, DOI 10.3390/a12090190
   FU X, 2017, P MED WORKSH DUBL IR
   HANIF M, 2017, P MED WORKSH DUBL IR
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jou B., 2016, Proceedings of the 24th ACM International Conference on Multimedia
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   KORNBLITH S, ARXIV180508974
   Li LS, 2018, J MACH LEARN RES, V18
   LOPEZFUENTES L, 2017, P MED WORKSH DUBL IR
   Melis G., 2017, ARXIV170705589
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Reddi S. J., 2018, INT C LEARN REPR
   Said N, 2019, MULTIMED TOOLS APPL, V78, P31267, DOI 10.1007/s11042-019-07942-1
   Santoro A, 2017, ADV NEUR IN, V30
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   TKACHENKO N, 2017, P MED WORKSH DUBL IR
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Werneck RD, 2018, IEEE IMAGE PROC, P1048, DOI 10.1109/ICIP.2018.8451011
   Zaheer Manzil, 2017, Advances in neural information processing systems, P3391
NR 28
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26735
EP 26746
DI 10.1007/s11042-020-09272-z
EA JUL 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549799000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Arshaghi, A
   Ashourian, M
   Ghabeli, L
AF Arshaghi, Ali
   Ashourian, Mohsen
   Ghabeli, Leila
TI Feature selection based on buzzard optimization algorithm for potato
   surface defects detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Buzzard optimization algorithm; Global optimization; Potato defect
   detection; Feature selection; Image processing
ID OBJECT-BASED CLASSIFICATION
AB Different methods of feature selection find the best subdivision from the candidate subset. In all methods, based on the application and the type of the definition, a subset is selected as the answer; which can optimize the value of an evaluation function. The large number of features, high spatial and temporal complexity, and even reduced accuracy are common problems in such systems. Therefore, research needs to be performed to optimize these systems. In this paper, for increasing the classification accuracy and reducing their complexity; feature selection techniques are used. In addition, a new feature selection method by using the buzzard optimization algorithm (BUOZA) is proposed. These features would be used in segmentation, feature extraction, and classification steps in related applications; to improve the system performance. The results of the performed experiment on the developed method have shown a high performance while optimizing the system's working parameters.
C1 [Arshaghi, Ali; Ghabeli, Leila] Islamic Azad Univ, Cent Tehran Branch, Dept Elect Engn, Tehran, Iran.
   [Ashourian, Mohsen] Islamic Azad Univ, Majlesi Branch, Dept Elect Engn, Esfahan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Ashourian, M (corresponding author), Islamic Azad Univ, Majlesi Branch, Dept Elect Engn, Esfahan, Iran.
EM ali.arshaghi@gmail.com; ashourian@iaumajlesi.ac.ir; lghabeli@gmail.com
RI Ashourian, Mohsen/N-4052-2019; Arshaghi, Ali/GLR-5601-2022; arshaghi,
   ali/AGY-7877-2022
OI Arshaghi, Ali/0000-0002-3281-1938; 
CR Adeli A, 2018, APPL INTELL, V48, P1609, DOI 10.1007/s10489-017-0989-x
   Adeli A, 2012, LECT NOTES COMPUT SC, V7654, P365, DOI 10.1007/978-3-642-34707-8_37
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Arshaghi A., 2019, Majlesi Journal of Electrical Engineering, V13, P83
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dorigo M., 2010, COMPUTATIONAL INTELL, V1, P28, DOI DOI 10.1109/MCI.2006.329691
   Fan D-P, 2018, ECCV 2018
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Haykin S., 1994, NEURAL NETWORKS COMP
   Isik S., 2014, International Journal of Applied Mathematics, Electronics and Computers, V3, P1, DOI [10.18100/ijamec.60004, DOI 10.18100/IJAMEC.60004]
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Kavzoglu T, 2015, REMOTE SENS LETT, V6, P834, DOI 10.1080/2150704X.2015.1084550
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Lal TN, 2006, STUD FUZZ SOFT COMP, V207, P137
   Laliberte AS, 2012, INT J APPL EARTH OBS, V15, P70, DOI 10.1016/j.jag.2011.05.011
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   [李晓磊 Li Xiaolei], 2002, [系统工程理论与实践, Systems Engineering-Theory & Practice], V22, P32
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu DS, 2010, REMOTE SENS LETT, V1, P187, DOI 10.1080/01431161003743173
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Moradi P, 2015, ENG APPL ARTIF INTEL, V44, P33, DOI 10.1016/j.engappai.2015.05.005
   Naeini AA, 2018, IEEE GEOSCI REMOTE S, V15, P379, DOI 10.1109/LGRS.2017.2789194
   Panchal P. M., 2013, Int J Innovat Res, V1, P323
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Sarkar S., 2019, ADV PARTICLE SWARM O, V1030, P82, DOI [10.1007/978-981-13-8578-0_7, DOI 10.1007/978-981-13-8578-0_7]
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Yazdani D, 2013, APPL SOFT COMPUT, V13, P2144, DOI 10.1016/j.asoc.2012.12.020
   Zhang J, 2020, IEEE CVF CVPR 2020
   Zhang J, 2020, IEEE CVPR 2020
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 41
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26623
EP 26641
DI 10.1007/s11042-020-09236-3
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700005
DA 2024-07-18
ER

PT J
AU Takahashi, M
   Yokozawa, S
   Mitsumine, H
   Itsuki, T
   Naoe, M
   Funaki, S
AF Takahashi, Masaki
   Yokozawa, Shinsuke
   Mitsumine, Hideki
   Itsuki, Tetsuya
   Naoe, Masato
   Funaki, Satoshi
TI Real-time visualization of sword trajectories in fencing matches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object tracking; Machine learning; Fencing
AB We developed a system called Sword Tracer that visualizes sword trajectories in fencing matches. Sword Tracer tracks the tips of the swords in the image coordinates and visualizes their movements with computer graphics (CGs). It measures each sword's position in the infrared (IR) image by detecting IR light reflected from retroreflective tape placed on the tip of the sword. It uses only a single camera and a single marker at the tip, so the system is compact enough to be used in official fencing matches. It accurately detects the tips of the swords by using supervised machine learning and tracks them by predicting their positions in the next frame. The trajectory CGs of the sword tips can be composited on the broadcast image in real-time. Sword Tracer was first used for a broadcast at the All Japan Fencing Championships in December 2017 and has since been used for four other broadcast programs and five exhibition events from 2018 to 2020. TV viewers and guests at the events approved of this new video effect because it helped them to follow the fast-moving swords and gain a better understanding of the swordplay.
C1 [Takahashi, Masaki; Yokozawa, Shinsuke; Mitsumine, Hideki; Itsuki, Tetsuya; Naoe, Masato; Funaki, Satoshi] Japan Broadcasting Corp NHK, Shibuya Ku, 2-1-1 Jinnan, Tokyo, Japan.
C3 NHK Japan Broadcasting Corp
RP Takahashi, M (corresponding author), Japan Broadcasting Corp NHK, Shibuya Ku, 2-1-1 Jinnan, Tokyo, Japan.
EM takahashi.m-iu@nhk.or.jp
OI Takahashi, Masaki/0000-0002-4337-0074
CR [Anonymous], [No title captured]
   [Anonymous], 2006, BMVC
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], C COMP VIS PATT REC
   Anusha G., 2014, P INT J ENG TRENDS T, V11, P133, DOI DOI 10.14445/22315381/IJETT-V11P226
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Chen HT, 2012, MULTIMED TOOLS APPL, V60, P641, DOI 10.1007/s11042-011-0833-y
   Chen W, 2016, INT C PATT RECOG, P1821, DOI 10.1109/ICPR.2016.7899901
   Chockalingam A., 2018, P IEEE 87 VEH TECHN, P1
   Godec M., 2011, P INT C COMP VIS ICC
   Guerra-Filho G.B., 2005, J THEORETICAL APPL I, VRITA 12, P61
   Held M, 2016, FRONT BEHAV NEUROSCI, V10, DOI 10.3389/fnbeh.2016.00186
   Henriques J.F., 2012, P EUR C COMP VIS ECC
   Iman I., 2015, P PATT REC IM AN IPR
   Kalal Z, 2010, P INT C PATT REC ICP
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Morais E., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P174, DOI 10.1109/SIBGRAPI.2012.32
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rezaee H., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P397, DOI 10.1109/IEEEGCC.2011.5752541
   Santiago C.B., 2010, Portugal: International Conference on Coastal Conservation and Management'10, 11-17 April, P1, DOI DOI 10.1109/AIS.2010.5547021
   Shapiro L.G., 2003, Computer Vision, Vsecond
   Spagnolo P, 2013, P 1 IEEE INT WORKSH
   Takahashi M, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 TALKS, DOI 10.1145/3214745.3214770
   Takahashi M, 2018, MULTIMED TOOLS APPL, V77, P23729, DOI 10.1007/s11042-018-5694-1
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Thmasi C, 1991, CMUCS91132
   Thomas G, 2009, COMPUTER, V42, P42, DOI 10.1109/MC.2009.238
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26411
EP 26425
DI 10.1007/s11042-020-09249-y
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548791400001
DA 2024-07-18
ER

PT J
AU He, GQ
   Zhang, QQ
   Zhang, HX
   Xu, YL
   Fan, JP
AF He, Guiqing
   Zhang, Qiqi
   Zhang, Haixi
   Xu, Yuelei
   Fan, Jianping
TI A concept ontology triplet network for learning discriminative
   representations of fine-grained classes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metric learning; Two-layer ontology loss; Concept ontology structure;
   Bilinear
ID IMAGE; CLASSIFICATION; PREDICTION; FEATURES
AB Triplet network is an efficient method of metric learning, but with the increase of the number of fine-grained images and sample categories, the training of Triplet network is more and more challengeable. In order to solve this problem, this paper proposes an algorithm that effectively combine Concept Ontology Structure with the Triplet network trained of Two-layer Ontology Loss. It not only utilizes semantic knowledge to guide the Concept Ontology Structure of the network, but also makes use of the relationship between the layers to make the network more effective to see the triplets, which enhances the separability of the learned features. At the same time, we also use the bilinear function jointly trained with the Triplet network to enhance the image details, further improving the performance of the network. Finally, the effectiveness of the proposed algorithm is also proved by the results of classification experiments on the fine-grained image databases - Orchid and Fashion60.
C1 [He, Guiqing; Zhang, Qiqi; Zhang, Haixi] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
   [Xu, Yuelei] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian, Peoples R China.
   [Fan, Jianping] Univ North Carolina Charlotte, Charlotte, NC USA.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; University of North Carolina; University of North Carolina
   Charlotte
RP He, GQ (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM guiqing_he@nwpu.edu.cn; zhangqiqii@hotmail.com; zh.haixi@gmail.com;
   xuyuelei@nwpu.edu.cn; jfan@uncc.edu
RI xu, ye/JYO-6282-2024; Huang, yuexu/JDD-1638-2023; Zhang,
   Haixi/HGB-7131-2022
OI xu, ye/0009-0007-9798-2723; He, Guiqing/0000-0001-7267-2373
FU National Nature Science Foundation of China [61402368]; Aerospace
   Science and Technology Innovation Foundation of China [2017ZD53047,
   20175896]; Common Technology Foundation for Pre-research and Development
   of Equipment in the 13th Five-Year Plan [41412010402]; Seed Foundation
   of Innovation and Creation for Graduate Students in Northwestern
   Polytechnical University [ZZ2019166]
FX This research was funded by the National Nature Science Foundation of
   China (NO.61402368), Aerospace Science and Technology Innovation
   Foundation of China (NO.2017ZD53047 and NO.20175896), Common Technology
   Foundation for Pre-research and Development of Equipment in the 13th
   Five-Year Plan (NO.41412010402), the Seed Foundation of Innovation and
   Creation for Graduate Students in Northwestern Polytechnical University
   (NO.ZZ2019166).
CR [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44
   Cai LH, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPANION TECHNOLOGY (ICCT)
   CHEN W, 2017, MULTITASK DEEP NETWO
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Yunpeng., 2017, IJCAI
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Fan JP, 2017, IEEE T IMAGE PROCESS, V26, P1923, DOI 10.1109/TIP.2017.2667405
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1665, DOI 10.1109/TMM.2014.2321530
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hinton G., 2015, COMPUT SCI, P1, DOI [DOI 10.48550/ARXIV.1503.02531, 10.48550/arXiv.1503.02531]
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang ZZ, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P310, DOI 10.1109/BigMM.2017.72
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LIN M., 2013, Network in Network, CoRR
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Nguyen M, 2015, INT CONF IMAG VIS
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   ROY D, 2018, P IEEE
   Ruder S, 2017, ARXIV170605098, DOI DOI 10.48550/ARXIV.1706.05098
   Sankaranarayanan S., 2016, 2016 IEEE 8th international conference on biometrics theory, applications and systems (BTAS), P1
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shun Zhang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P497, DOI 10.1007/978-3-319-48890-5_49
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sohn Kihyuk., 2016, Advances in Neural Information Processing Systems, P1857, DOI DOI 10.5555/3157096.3157304
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sukhbaatar Sainbayar, 2014, Training convolutional networks with noisy labels
   Sun M, 2013, IEEE I CONF COMP VIS, P265, DOI 10.1109/ICCV.2013.40
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang C, 2017, IEEE INT CONF COMP V, P1907, DOI 10.1109/ICCVW.2017.225
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE IPCCC
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Ying L, 2016, NEURAL COMPUT APPL, V27, P111, DOI 10.1007/s00521-014-1567-3
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2018, IEEE VTS VEH TECHNOL
   Zhang H, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225100
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641
NR 57
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25189
EP 25214
DI 10.1007/s11042-020-09090-3
EA JUL 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544580800003
DA 2024-07-18
ER

PT J
AU Long, JS
   Ma, GZ
   Liu, H
   Song, EM
   Hung, CC
   Xu, XY
   Jin, RC
   Zhuang, YZ
   Liu, DY
   Ma, GZ
   Song, EM
AF Long, Jiaosong
   Ma, Guangzhi
   Liu, Hong
   Song, Enmin
   Hung, Chih-Cheng
   Xu, Xiangyang
   Jin, Renchao
   Zhuang, Yuzhou
   Liu, DaiYang
   Ma, Guangzhi
   Song, Enmin
TI Cascaded hybrid residual U-Net for glioma segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glioma segmentation; Deep learning; Hybrid; U-Net; BRATS
AB Glioma segmentation is critical for making surgical plans. Recently, the traditional glioma segmentation method is less competitive with two deep learning segmentation strategies: the patch-based method which focuses more on the local feature for each pixel, and the image-based method which fully leverages the global feature and captures the overall shape, size and other characteristics of the lesion in a neighborhood of a pixel. In this study, we investigate and integrate the advantages of 2-D and 3-D image-based architectures, and propose a new convolutional neural network called the Cascaded Hybrid Residual U-Net (CHR-U-Net) for MRI glioma segmentation. The CHR-U-Net exploits both the 2D local features as well as the 3D global spatial contextual information simultaneously. In the first-level of CHR-U-Net, the R-2D-U-Net combines the 2D-U-Net and the residual unit for quick lesion area detecting without any miss. To prevent from missing false-positive pixels, the output of R-2D-U-Net is resampled by using the hard-mining to collect more possible false-positive samples. In the second-level of CHR-U-Net, the axial, coronal, and sagittal 3D-U-Nets are trained to predict whether pixels belong to the area of glioma. The results of three 3D-U-Nets are fused to improve the accuracy and reduce false positives. The database of 2017 BRATS challenge were used in our experiments for the verification. The Dices and Sensitivities of Enhancing, Whole, and Core areas were calculated. The Dices are 0.73, 0.90, and 0.83 and the Sensitivities are 0.83, 0.90, and 0.82, respectively, for the axial, coronal, and sagittal 3D-U-Nets. Experimental results show that the proposed model significantly improves the performance of glioma segmentation.
C1 [Long, Jiaosong; Ma, Guangzhi; Liu, Hong; Song, Enmin; Xu, Xiangyang; Jin, Renchao; Zhuang, Yuzhou; Liu, DaiYang; Ma, Guangzhi; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Hung, Chih-Cheng] Kennesaw State Univ, Coll Comp & Software Engn, Atlanta, GA USA.
C3 Huazhong University of Science & Technology; University System of
   Georgia; Kennesaw State University
RP Ma, GZ; Song, EM (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM maguangzhi@hust.edu.cn; esong@hust.edu.cn
RI Zhang, Jing/HII-4294-2022; Zhuang, Yuzhou/HCG-9998-2022; Xu,
   Xiangyang/N-9292-2014
OI Xu, Xiangyang/0000-0002-9713-0535
FU National Key R&D program of China [2017YFC0112804]; National Natural
   Science Foundation of China [81671768]
FX This research was financially supported by the National Key R&D program
   of China (Grant No. 2017YFC0112804) and the National Natural Science
   Foundation of China (No. 81671768).
CR [Anonymous], P MULT BRAIN TUM IM
   [Anonymous], MULTIMODAL BRAIN TUM
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Davy A., 2014, BRATS MICCAI 2014, P1
   DVOAK P, 2016, LOCAL STRUCTURE PRED, P59
   Farahani K., 2014, Brats 2014 Challenge Manuscripts
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holland EC, 2001, CURR OPIN NEUROL, V14, P683, DOI 10.1097/00019052-200112000-00002
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   HUSSAIN S, 2017, NEUROCOMPUTING, V282
   Hussain S, 2017, IEEE ENG MED BIO, P1998, DOI 10.1109/EMBC.2017.8037243
   Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38
   Kamnitsas K, 2016, LECT NOTES COMPUT SC, V10154, P138, DOI 10.1007/978-3-319-55524-9_14
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Karnan Marcus, 2010, International Journal of Computer and Network Security, V2, P6
   KAYALBAY B, 2017, CNN BASED SEGMENTATI
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HC, 2019, COMPUT BIOL MED, V108, P150, DOI 10.1016/j.compbiomed.2019.03.014
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meier R, 2014, P MICCAI BRATS CHALL, DOI [10.13140/2.1.3766.7846, DOI 10.13140/2.1.3766.7846]
   MEIER RA, 2013, HYBRID MODEL MULTIMO, P31
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   MONTGOMERY D, 1992, J R STAT SOC C, V32, P94, DOI DOI 10.2307/2348054
   Noori M, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P269, DOI [10.1109/iccke48569.2019.8964956, 10.1109/ICCKE48569.2019.8964956]
   PAN X, 2016, NEUROCOMPUTING, V229
   Pinto A, 2015, IEEE ENG MED BIO, P3037, DOI 10.1109/EMBC.2015.7319032
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   RICHMOND DL, 2015, COMPUTER SCI
   Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Samei E, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.031209
   Sikka K, 2009, MAGN RESON IMAGING, V27, P994, DOI 10.1016/j.mri.2009.01.024
   SINGH A, 2011, INT J COMPUT THEOR E, V4, P1002
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Urban G, 2014, Multi-Modal Brain Tumor Segmentation Using Deep Convolutional Neuroal Networks. MICCAI BraTS (Brain Tumor Segmentation) Challenge, Proceedings, P31
   Valverde S, 2017, NEUROIMAGE, V155, P159, DOI 10.1016/j.neuroimage.2017.04.034
   Wang G., 2018, AUTOMATIC BRAIN TUMO, P178, DOI [10.1007/978-3-319-75238-9_16, DOI 10.1007/978-3-319-75238-9_16]
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
   ZIKIC D, 2012, INT C MED IM COMP CO
NR 47
TC 8
Z9 9
U1 5
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24929
EP 24947
DI 10.1007/s11042-020-09210-z
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200004
DA 2024-07-18
ER

PT J
AU Mahmood, A
AF Mahmood, Awais
TI Arabic speaker recognition system based on phoneme fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic speaker recognition; Consonants; MA-MDLA; Shortest utterance;
   Phonemes; Vowels
AB With the increasing number and popularity of smart devices in the past few decades, especially those that execute different types of health-related applications, their security is a growing concern. Biometric authentication can be used for device security, and speaker recognition (SR) is one of its elegant forms. In this study, an SR system is developed for the security of smart devices, which identifies a person from the shortest utterance of Arabic language, achieving the highest SR rate, by using the benchmark Linguistic Data Consortium (LDC) Arabic dataset. This study focuses on the use of the consonants and vowels of the Arabic language. It is observed that certain consonants or a fusion of certain consonants in Arabic language helps to ascertain the speaker's identity efficiently. The shortest utterance that better presents the speaker's identity by using such consonants is revealed. The system was analyzed by using different numbers of consonants and achieved the maximum (100%) SR rate using a fusion of only three consonants of the Arabic language. These consonants or their combinations can be used to develop text for any speaker-based authentication system.
C1 [Mahmood, Awais] King Saud Univ, Coll Appl Comp Sci, Al Muzahmiyya Campus, Riyadh, Saudi Arabia.
C3 King Saud University
RP Mahmood, A (corresponding author), King Saud Univ, Coll Appl Comp Sci, Al Muzahmiyya Campus, Riyadh, Saudi Arabia.
EM mawais@ksu.edu.sa
FU deanship of scientific research at King Saud University [RG-1439-039]
FX The authors extend their appreciation to the deanship of scientific
   research at King Saud University for funding this work through research
   group number RG-1439-039.
CR Algabri M, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/6986391
   Alkhouli M, 1990, ALASWAAT ALAGHAWAIYA
   Alotaibi Y.A, 2007, INT S SIGN PROC INF
   Alotaibi YA, 2010, COMPUT SPEECH LANG, V24, P219, DOI 10.1016/j.csl.2009.04.005
   Alsulaiman Mansour, 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P303, DOI 10.1109/ICDIM.2010.5664673
   Alsulaiman M, 2009, RES REPORT
   Alsulaiman M, 2009, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2009), P330
   Anusuya MA, 2011, INT J SPEECH TECHNOL, V14, P99, DOI 10.1007/s10772-010-9088-7
   Daqrooq K, 2008, 5 INT MULT SYST SIGN, P1
   Doddington G., 2001, P EUROSPEECH, P2521
   El-Gamal MA, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P625
   ELIMAM YA, 1989, IEEE T ACOUST SPEECH, V37, P1829, DOI 10.1109/29.45531
   Elmisery F.E, 2005, P 17 INT C MICR ICM, P130
   Harrag A, 2010, ARAB J SCI ENG, V35, P7
   Hussain SJ, 2002, SICE 2002: PROCEEDINGS OF THE 41ST SICE ANNUAL CONFERENCE, VOLS 1-5, P2682
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Mahmood A, 2019, CLUSTER COMPUT, V22, P2145, DOI 10.1007/s10586-018-2030-5
   Nofal M, 1999, P IEEE PAC RIM C COM, P400
   Oumaour-Sayoud S, 2003, P ISCA TUT RES WORKS
   Rabiner L.R, 2007, INTRO DIGITAL SPEECH
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   Rose P, 2002, TAYL & FRAN FORENS S, P1
   Sakka Z., 2004, 2004 First International Symposium on Control, Communications and Signal Processing. (IEEE Cat. No.04EX814), P37
   Shah S.M, 2014, INT C OP SOURC SYST
   Stolcke A, 2008, P OD 08
   Tolba H, 2011, ALEX ENG J, V50, P43, DOI 10.1016/j.aej.2011.01.007
NR 26
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15043
EP 15060
DI 10.1007/s11042-020-08893-8
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000543285000001
DA 2024-07-18
ER

PT J
AU Asadianfam, S
   Shamsi, M
   Kenari, AR
AF Asadianfam, Shiva
   Shamsi, Mahboubeh
   Rasouli Kenari, Abdolreza
TI Big data platform of traffic violation detection system: identifying the
   risky behaviors of vehicle drivers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Behavior-based safety; Risky behavior; Traffic violation
   detection; Traffic surveillance cameras
ID SAFETY MANAGEMENT; DATA ANALYTICS; ACCIDENTS; IMPLEMENTATION;
   TECHNOLOGY; EXPERIENCE; FRAMEWORK; MODEL; LANE
AB Since the traffic data has a high volume, high diversity and high speed of production, the traditional systems cannot process them accurately. In this paper, a big data based system was designed and implemented for identifying the offenders' behaviors. The proposed Traffic Violation Detection System (TVD system) included four main phases which were described using the MAPE methodology. In the monitor phase, unstructured data, such as videos captured by traffic control cameras as well as the images and the descriptions provided by traffic officers, were collected. In the analysis phase, the knowledge base of unsafe driving behaviors was created and classified. In this phase, a standard Work Breakdown Structure for unsafe behaviors was created by the experts in traffic control. In the Plan phase, in order to detect unsafe driving behaviors related to police descriptions for collected images, and to detect unsafe behaviors from video cameras, Behavior-Based Safety process with Map/ Reduce technique and Vector Space Model (VSM) were employed. In the last phase, all types of data, including the structured data and the multimedia/unstructured data, along with the types and details of violations, were stored on the Hadoop Distributed File System. The prototype of the proposed TVD system was successfully implemented for a few common violations. The results showed that by applying big data technologies, the driving violations could be detected more accurately using the combination of the structured and unstructured data. The results indicate that compared to the sequential program, Hadoop only with a single slave-node decreases the processing time of big data by more than 70%. Also, by increasing the number of slave nodes from 1 to 7 in the police descriptions and images of surveillance cameras, the processing time reduces by 60.87% and 70%, respectively. Thus, the TVD performance increases by more than 75% as the number of data nodes boosts. Based on the results, it can be concluded that by identifying unsafe driving behaviors, it is possible to diminish traffic accidents and the damage caused by them at a satisfactory level. Also, the authors decided to compare these studies in terms of qualitative criteria, such as fieldwork and behavioral identification, and quantitative criteria.
C1 [Asadianfam, Shiva] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
   [Shamsi, Mahboubeh; Rasouli Kenari, Abdolreza] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
C3 Islamic Azad University
RP Shamsi, M (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
EM sh_asadianfam_stu@qom-iau.ac.ir; shamsi@qut.ac.ir; rasouli@qut.ac.ir
RI Shamsi, Mahboubeh/AFI-9693-2022; Rasouli Kenari,
   Abdolreza/AAC-5678-2022; Asadianfam, Shiva/ABF-1231-2021; Shamsi,
   Mahboubeh/AAF-4417-2022
OI Shamsi, Mahboubeh/0000-0003-1238-4315; Rasouli Kenari,
   Abdolreza/0000-0003-4817-9380; Asadianfam, Shiva/0000-0002-0062-7079;
   Shamsi, Mahboubeh/0000-0003-1238-4315
CR Ahmadi S., 2011, Q J TRAFFIC MANAG ST, P13
   Aliane N, 2014, SENSORS-BASEL, V14, P22113, DOI 10.3390/s141122113
   [Anonymous], 2015, HADOOP THE DEFINITIV
   [Anonymous], 2011, BIG DATA NEXT FRONTI
   Bakhtiyari M, 2012, SAFETY SCI, V50, P1480, DOI 10.1016/j.ssci.2012.01.015
   Bener A, 2006, INT J CRASHWORTHINES, V11, P459, DOI 10.1533/ijcr.2005.0116
   Bremond F, 2006, BEHAV RES METHODS, V38, P416, DOI 10.3758/BF03192795
   Cárdenas-Benítez N, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050599
   Chauvin C, 2013, ACCIDENT ANAL PREV, V59, P26, DOI 10.1016/j.aap.2013.05.006
   Chen DW, 2012, PROCEDIA ENGINEER, V43, P528, DOI 10.1016/j.proeng.2012.08.092
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chen T, 2016, IEEE T VEH TECHNOL, V65, P4006, DOI 10.1109/TVT.2015.2500275
   Chi S, 2011, COMPUT-AIDED CIV INF, V26, P368, DOI 10.1111/j.1467-8667.2010.00690.x
   Computing I.A, 2005, WHIT PAP ARCH BLUEPR
   Cox S, 2004, SAFETY SCI, V42, P825, DOI 10.1016/j.ssci.2004.03.002
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de la Escalera A, 2004, IEEE T INTELL TRANSP, V5, P57, DOI 10.1109/TITS.2004.828173
   De Mauro A, 2018, INFORM PROCESS MANAG, V54, P807, DOI 10.1016/j.ipm.2017.05.004
   Elotmani S, 2014, MULT COMP SYST ICMCS
   Geller E.S., 2001, Keys to behavior-based safety
   Goh YM, 2009, J CONSTR ENG M, V135, P1181, DOI 10.1061/(ASCE)CO.1943-7862.0000093
   Gowsikhaa D, 2014, ARTIF INTELL REV, V42, P747, DOI 10.1007/s10462-012-9341-3
   Guo SY, 2016, ACCIDENT ANAL PREV, V93, P299, DOI 10.1016/j.aap.2015.09.024
   Hajeb S, 2013, INT J SCI ENG INVEST, P1
   Hartford T, 2002, TECHNICAL INFORM PAP
   Hu HY, 2014, J CHIN INST ENG, V37, P995, DOI 10.1080/02533839.2014.912777
   Iglesia D.G, 2014, MAPE K FORMAL TEMPLA
   Ismail F, 2012, PROCD SOC BEHV, V35, P586, DOI 10.1016/j.sbspro.2012.02.125
   James L., 2000, ROAD RAGE AGGRESSIVE
   Jin Z., 2018, Environment Modeling-Based Requirements Engineering for Software Intensive Systems
   Kasaei SHM, 2011, INT SEC INF C EISIC
   Klubsuwan K, 2013, 2013 4 INT C INT SYS
   Krishnan A, 2009, INT TRANSP SYST 2009
   Kunfeng W, 2007, VEH EL SAF ICVES IEE
   Li H, 2015, SAFETY SCI, V75, P107, DOI 10.1016/j.ssci.2015.01.013
   Lingard H, 1997, J SAFETY RES, V28, P243, DOI 10.1016/S0022-4375(97)00010-8
   Lu WS, 2019, RESOUR CONSERV RECY, V141, P264, DOI 10.1016/j.resconrec.2018.10.039
   Mehta P, 2018, INFORM PROCESS MANAG, V54, P145, DOI 10.1016/j.ipm.2017.11.002
   Metari S, 2013, MACH VISION APPL, V24, P159, DOI 10.1007/s00138-011-0381-5
   Moura R, 2017, SAFETY SCI, V99, P196, DOI 10.1016/j.ssci.2017.05.001
   Nguyen V, 2018, ENG SCI TECHNOL, V21, P822, DOI 10.1016/j.jestch.2018.06.006
   Nielsen K, 2015, SAFETY SCI, V71, P142, DOI 10.1016/j.ssci.2013.11.015
   Ou G, 2012, P 2012 IEEE WIC ACM, V03
   Pakgohar A, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.126
   Pourmahalam N, 2010, J TRAFFIC MANAG STUD, V19, P13
   Qian HH, 2011, INTEL SYST CONTR AUT, V51, P1, DOI 10.1007/978-94-007-1137-2
   Rakotonirainy A, 2014, PERVASIVE MOB COMPUT, V14, P147, DOI 10.1016/j.pmcj.2014.06.004
   REASON J, 1990, ERGONOMICS, V33, P1315, DOI 10.1080/00140139008925335
   REBER RA, 1984, IND RELAT, V23, P119, DOI 10.1111/j.1468-232X.1984.tb00881.x
   Sallah M, 2011, ROAD SIGN DETECTION
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Secundo G, 2017, J INTELLECT CAP, V18, P242, DOI 10.1108/JIC-10-2016-0097
   Shalini RT, 2009, SAFETY SCI, V47, P973, DOI 10.1016/j.ssci.2008.10.021
   Shvachko K, 2010, IEEE S MASS STOR SYS
   Sigarari MH, 2013, J VISUAL MACHINE IMA, V1
   Phung SL, 2016, COMPUT VIS IMAGE UND, V149, P186, DOI 10.1016/j.cviu.2016.01.011
   Tao D, 2017, ACCIDENT ANAL PREV, V99, P228, DOI 10.1016/j.aap.2016.12.009
   Bui-Minh T, 2012, INT CONF CONTR AUTO, P120, DOI 10.1109/ICCAIS.2012.6466570
   Thien HT, 2015, SENSORS-BASEL, V15, P16040, DOI 10.3390/s150716040
   Verma S, 2018, INFORM PROCESS MANAG, V54, P791, DOI 10.1016/j.ipm.2018.01.004
   WHO, 2015, Global status report on road safety 2015
   Yeow PHP, 2014, SAFETY SCI, V70, P429, DOI 10.1016/j.ssci.2014.07.016
   Yi SC, 2015, COMPUT ELECTR ENG, V42, P23, DOI 10.1016/j.compeleceng.2015.01.002
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
NR 64
TC 11
Z9 12
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24645
EP 24684
DI 10.1007/s11042-020-09099-8
EA JUN 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542539200002
DA 2024-07-18
ER

PT J
AU Jin, X
   Ning, N
   Han, R
   Li, XD
   Zhang, XK
AF Jin, Xin
   Ning, Ning
   Han, Rui
   Li, Xiaodong
   Zhang, Xiaokun
TI Complex object relighting via split-then-composition by semantics and
   materials
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex object relighting; Illumination transfer; Semantic parsing and
   composition; Material parsing and composition; Patch match warping;
   Local and global transfer
AB Complex object illumination transfer is a special challenge in computer vision. In our paper, we put forward a method for complex object illumination transfer. Firstly, the input object image was divided into object components by semantic analysis, to find the reference object images consistent with the object component material in the physical world by material analysis. Material has a great influence on the illumination transfer of object image, so the use of material analysis can greatly reduce the influence of material on the illumination transfer in the later stage. Next, a block matching algorithm was used to deform each reference object image and made it match with each component shape of the input object image. Then, each component of the input object image and each warped reference object image were illuminated by local and global transfer model. Finally, semantic analysis was used to synthesize the re-illumination components of the input object image to obtain the re-illumination input object image. The experimental results prove that the method could make a good effect on the illumination transfer. Our main contribution is the use of semantic and material analysis to split complex objects into simple objects, and skillfully combine semantic and material parsing and composition, block matching algorithm, local and global light migration model to achieve the relighting of complex objects.
C1 [Jin, Xin; Ning, Ning; Han, Rui; Li, Xiaodong; Zhang, Xiaokun] Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
   [Jin, Xin] State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
C3 Beijing Electronic Science & Technology Institute
RP Li, XD (corresponding author), Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
EM lxdbesti@163.com
RI Ning, Ning/JKH-8565-2023; ning, ning/KGK-7423-2024; li,
   xiaofeng/GXF-9442-2022; jin, xin/GQZ-5811-2022; liang,
   liang/IAO-8518-2023; li, xiao/HJP-5134-2023; li, xiao/GSN-6181-2022
FU National Natural Science Foundation of China [61701008, 61772047]; Open
   Project Program of State Key Laboratory of Cryptology [MMKFKT201804];
   Beijing Natural Science Foundation [19L2040]; Open Project Program of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University [VRLAB2019C03]; Fundamental Research Funds for the Central
   Universities [328201907]
FX Parts of the results and figures presented in this paper have previously
   appeared in our previous work [12]. We add more technical details and
   experimental results in this version. This work is partially supported
   by the National Natural Science Foundation of China (grant numbers
   61701008, 61772047), the Open Project Program of State Key Laboratory of
   Cryptology (grant number MMKFKT201804), the Beijing Natural Science
   Foundation (grant number 19L2040), the Open Project Program of State Key
   Laboratory of Virtual Reality Technology and Systems, Beihang University
   (grant number VRLAB2019C03) and the Fundamental Research Funds for the
   Central Universities (grant number 328201907).
CR Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Chabert C.-F., 2006, SIGGRAPH 06 SKETCHES, P76
   Chen XW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2369962
   Chen XW, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4936-0
   Chen XW, 2012, COMPUT GRAPH FORUM, V31, P1425, DOI 10.1111/j.1467-8659.2012.03138.x
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Jin X, 2017, INT S ART INT ROB KI, P37
   Jin X, 2019, OPT LASER TECHNOL, V110, P7, DOI 10.1016/j.optlastec.2017.11.008
   Jin X, 2016, I C VIRTUAL REALITY, P235, DOI 10.1109/ICVRV.2016.46
   Jin X, 2010, LECT NOTES COMPUT SC, V6314, P101, DOI 10.1007/978-3-642-15561-1_8
   Li X, 2019, 3 EAI INT C ROB SENS
   Lu H, 2018, FUTUR GENER COMPUT S, P82
   Lu H., 2019, CONET COGNITIVE OCEA
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Quan Q, 2016, BRAZ ARCH BIOL TECHN, V59, DOI 10.1590/1678-4324-2016160506
   Quan Z, 2017, MULTIMED TOOLS APPL, V12, P1
   Quan Z, 2018, WORLD WIDE WEB, V22, P1
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shih YC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508419
   Xiaowu Chen, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P450, DOI 10.1109/CAD/Graphics.2011.19
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhou Q, 2018, MULTIMED TOOLS APPL, V1-29, P11
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24185
EP 24197
DI 10.1007/s11042-020-09071-6
EA JUN 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200001
DA 2024-07-18
ER

PT J
AU Chen, JY
   Zhan, YW
   Cao, HY
AF Chen, Jiayi
   Zhan, Yinwei
   Cao, Huiying
TI Iterative deviation filter for fixed-valued impulse noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise removal; Noise detection; Median filter; Correlation;
   Distribution; Deviation filter
ID MEDIAN-MEAN FILTER; SALT
AB An iterative deviation filter for fixed-valued impulse noise removal is proposed, with the aim to overcome the defects of existing filters, and further improve the denoising performance. In the proposed filter, a noise detection method based on the extreme intensity values and the deviation of neighbor pixels is proposed, i.e., the pixels with the extreme intensity and differ greatly from the mean of neighbor pixels, are identified as noises. A noise removal method based on the minimum deviation of neighbor pixels is proposed, i.e., the intensity of one neighbor noise free pixel, which is closest to the mean of neighbor noise free pixels, is used as estimated intensity of noisy pixel under consideration. Furthermore, the noise removal strategy performs iteratively and takes full advantage of the previous denoising results. Simulation results show that the proposed method has better denoising performance than the existing distinguished filters in terms of visual representation, peak signal to noise ratio and structural similarity index.
C1 [Chen, Jiayi; Cao, Huiying] Guangdong Med Univ, Sch Biomed Engn, Zhanjiang 524023, Guangdong, Peoples R China.
   [Zhan, Yinwei] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
C3 Guangdong Medical University; Guangdong University of Technology
RP Zhan, YW (corresponding author), Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
EM beyond38@163.com; ywzhan@gdut.edu.cn; 543439415@qq.com
RI chen, jia/JLM-4733-2023; Chen, Jia/HQZ-3908-2023; chen,
   jia/JDW-7660-2023; chen, jiayi/IAP-9353-2023; Chen, Jiayi/GZM-5106-2022
OI chen, jiayi/0009-0009-0528-5475; 
FU National Natural Science Foundation of China [61170320]; Guangdong
   Provincial Science and Technology Program [2017B010110015]; Project of
   Science and Technology Program of Guangzhou [201604016034]; Medical
   Scientific Research Foundation of Guangdong Province in China [B2018190]
FX We would like to thank the editors and anonymous reviewers for their
   constructive suggestions to the improvements of this paper. This work
   was supported by the National Natural Science Foundation of China [grant
   number 61170320]; the Guangdong Provincial Science and Technology
   Program [grant number 2017B010110015]; the Project of Science and
   Technology Program of Guangzhou [grant number 201604016034]; the Medical
   Scientific Research Foundation of Guangdong Province in China [grant
   number B2018190].
CR Balasubramanian G, 2016, AEU-INT J ELECTRON C, V70, P471, DOI 10.1016/j.aeue.2016.01.013
   Ben Said A, 2016, DIGIT SIGNAL PROCESS, V58, P115, DOI 10.1016/j.dsp.2016.07.017
   Charalampidis D, 2010, IEEE T IMAGE PROCESS, V19, P882, DOI 10.1109/TIP.2009.2038823
   Chen Jiayi, 2017, Journal of Nanjing University of Science and Technology, V41, P307, DOI 10.14177/j.cnki.32-1397n.2017.41.03.006
   Chung KL, 2018, MULTIMED TOOLS APPL, V77, P16477, DOI 10.1007/s11042-017-5216-6
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Habib M, 2016, AEU-INT J ELECTRON C, V70, P689, DOI 10.1016/j.aeue.2016.02.005
   Khan S, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0502-z
   Lin TC, 2006, IEEE T CIRCUITS-I, V53, P1057, DOI 10.1109/TCSI.2006.869897
   Park H, 2015, IEICE T INF SYST, VE98D, P721, DOI 10.1587/transinf.2014EDL8144
   RAMAMOORTHY K, 2014, INT J SYST SIGNAL CO, V7, P36
   Sadi F, 2010, COMPUT BIOL MED, V40, P109, DOI 10.1016/j.compbiomed.2009.11.007
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
   Vijaykumar VR, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033011
   VILLAR SA, 2016, J MATH IMAGING VIS, V58, P1
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Wang Y, 2016, IMAGING SCI J, V64, P15, DOI 10.1080/13682199.2015.1104068
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan C, 2015, OPTIK, V126, P1598, DOI 10.1016/j.ijleo.2015.05.032
   Zhang CB, 2015, OPTIK, V126, P956, DOI 10.1016/j.ijleo.2015.02.085
   Zhang Z, 2018, SIGNAL PROCESS, V147, P173, DOI 10.1016/j.sigpro.2018.01.027
NR 24
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23695
EP 23710
DI 10.1007/s11042-020-09123-x
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539857100002
DA 2024-07-18
ER

PT J
AU Sundaram, R
   Ravichandran, KS
   Jayaraman, P
   Venkatraman, B
AF Sundaram, Ramakrishnan
   Ravichandran, K. S.
   Jayaraman, Premaladha
   Venkatraman, B.
TI A novel hybrid segmentation approach for optic papilla detection in high
   resolution fundus images of retina
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optic papilla; Enhancement; Segmentation; Entropy; Distance; Contour
ID NERVE HEAD; VESSEL SEGMENTATION; DISK DETECTION
AB The paper proposes a novel method for segmenting optic papilla (OP) from the high-resolution fundus (HRF) image. For diagnosing eye-related diseases like Glaucoma, Diabetic Retinopathy, fine changes in OP must be examined. To examine the OP, its region should be exactly segmented from the fundus images of the retina. Major problems in accurately segmenting the OP are: 1) features of OP and exudates are similar and 2) the region behind the optic nerve head is difficult to locate. To overcome these problems and acquire precise segmentation a novel hybrid segmentation algorithm is developed using morphological image processing techniques and entropy filtering. A novelregion selection algorithm based on Euclidean distanceis proposed to remove the regions around the OP. When these regions are removed, the papilla region can be located easily. Then, active contour is applied to segment the OP. Most of the researchers have done OP localization than segmentation. The proposed method automatically locates the OP and segments it from the image. The proposed algorithm is evaluated by computing sensitivity, specificity, and accuracy. These metrics are computed using the proposed segmentation results against the ground truth data. To check the efficiency of the proposed algorithm, it is tested with low-resolution images in DRIONS. The proposed algorithm achieves 99.45% and 99.51% of accuracy for HRF and DRIONS datasets respectively.
C1 [Sundaram, Ramakrishnan; Ravichandran, K. S.; Jayaraman, Premaladha] SASTRA Deemed Univ, Sch Comp, Comp Vis & Soft Comp Lab, Thanjavur, India.
   [Venkatraman, B.] IGCAR, Hlth Safety & Environm Grp, Kalpakkam, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA); Indira
   Gandhi Centre for Atomic Research (IGCAR)
RP Ravichandran, KS (corresponding author), SASTRA Deemed Univ, Sch Comp, Comp Vis & Soft Comp Lab, Thanjavur, India.
EM raviks@it.sastra.edu
RI Ravichandran, Kattur Soundarapandian/AAG-7319-2019; Jayaraman,
   Premaladha/AAE-7440-2021; Sundaram, Ramakrishnan/JEZ-7092-2023
OI Ravichandran, Kattur Soundarapandian/0000-0003-2397-461X; Sundaram,
   Ramakrishnan/0000-0001-7485-3805
FU Department of Science and Technology, India [SR/FST/ETI-349/2013]
FX We, the authors would like to thank the Department of Science and
   Technology, India for their financial support through Fund for
   Improvement of S &T Infrastructure (FIST) programme
   (SR/FST/ETI-349/2013). We, the authors sincerely thank the SASTRA
   Deemed-to-be University for providing an excellent infrastructure to
   carry out the research work.
CR Abdullah M, 2016, PEERJ, V4, DOI 10.7717/peerj.2003
   Ahmed MI, 2015, SIGNAL IMAGE VIDEO P, V9, P77, DOI 10.1007/s11760-012-0412-3
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   [Anonymous], 2012, Telkomnika, DOI [DOI 10.12928/TELKOMNIKA.V10I3.833, 10.12928/telkomnika.v10i3.833]
   Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng J, 2011, IEEE ENG MED BIO, P6224, DOI 10.1109/IEMBS.2011.6091537
   Chrástek R, 2005, MED IMAGE ANAL, V9, P297, DOI 10.1016/j.media.2004.12.004
   Dashtbozorg B, 2015, COMPUT BIOL MED, V56, P1, DOI 10.1016/j.compbiomed.2014.10.009
   Dehghani A, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-19
   Fan Z, 2018, IEEE J BIOMED HEALTH, V22, P224, DOI 10.1109/JBHI.2017.2723678
   Fleming AD, 2007, PHYS MED BIOL, V52, P331, DOI 10.1088/0031-9155/52/2/002
   Foracchia M, 2004, IEEE T MED IMAGING, V23, P1189, DOI 10.1109/TMI.2004.829331
   Fraga A., 2011, Computer Aided Systems Theory - EUROCAST 2011. 13th International Conference. Revised Selected Papers, P584, DOI 10.1007/978-3-642-27549-4_75
   Gao LL, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P719
   Guo XX, 2017, SIGNAL IMAGE VIDEO P, V11, P1115, DOI 10.1007/s11760-017-1065-z
   Hamahashi S, 2008, U.S. Patent, Patent No. [7,460,702, 7460702]
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Lupascu CA, 2008, COMP MED SY, P17, DOI 10.1109/CBMS.2008.15
   Niemeijer M, 2005, BMVC
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   Rust Caterina, 2017, Current Directions in Biomedical Engineering, V3, P533, DOI 10.1515/cdbme-2017-0113
   Shree TDV, 2018, PROCEDIA COMPUT SCI, V125, P157, DOI 10.1016/j.procs.2017.12.022
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sun JY, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/528626
   Tobin KW, 2007, IEEE T MED IMAGING, V26, P1729, DOI 10.1109/TMI.2007.902801
   Welfer D, 2013, PATTERN RECOGN LETT, V34, P476, DOI 10.1016/j.patrec.2012.12.011
   Welfer D, 2010, COMPUT BIOL MED, V40, P124, DOI 10.1016/j.compbiomed.2009.11.009
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yin FS, 2011, IEEE ENG MED BIO, P2626, DOI 10.1109/IEMBS.2011.6090724
   Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326
   Zahoor MN, 2017, COMM COM INF SC, V723, P38, DOI 10.1007/978-3-319-60964-5_4
   Zhang D, 2012, P 21 INT C PATT REC
   Zhu XL, 2008, IEEE ENG MED BIO, P3546, DOI 10.1109/IEMBS.2008.4649971
NR 37
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23531
EP 23545
DI 10.1007/s11042-020-09173-1
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539519000004
DA 2024-07-18
ER

PT J
AU Wu, XT
   Yang, CN
   Liu, YW
AF Wu, Xiaotian
   Yang, Ching-Nung
   Liu, Yen-Wei
TI High capacity partial reversible data hiding by hamming code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Partial reversible data hiding; Hamming code; High
   capacity; Error correcting; Syndrome decoding
ID PLUS K; IMAGES; WATERMARKING; EXPANSION
AB A high capacity partial reversible data hiding (PRDH) is introduced in this paper. First of all, an original image is converted to a cover image by the proposed image transformation algorithm. The image transformation algorithm adopts (7,4) Hamming code and minimal pairwise square error to ensure that the generated cover image is an almost distortion-free original image. The secret bits are embedded into the cover image by flipping and modifying the cover bits with respect to the syndrome generated by Hamming code. When the secret bits are extracted from the stego image, it can be transformed back to a cover image by the error-correcting ability provided by Hamming code. And this is the so-called partial reversible property. The visual performance and embedding capacity of the proposed method are theoretical analyzed. According to the experimental and theoretical results, high embedding capacity with acceptable visual performance is achieved by the proposed method. More specifically, the embedding rate is 10.5 times of Jana et al.'s method and Yang et al.'s proposed PRDH, and 3.5 times of Yang et al. 's modified PRDH.
C1 [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
   [Yang, Ching-Nung; Liu, Yen-Wei] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Jinan University; National Dong Hwa University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.; Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM wxt.sysu@gmail.com; cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
FU National Natural Science Foundation of China [61972179, 61602211];
   Guangdong Basic and Applied Basic Research Foundation [2020A1515011476];
   Science and Technology Program of Guangzhou, China [201707010259];
   Fundamental Research Funds for the Central Universities; MOST through
   Pervasive Artificial Intelligence Research (PAIR) Labs, Taiwan
   [109-2634-F-259-001]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61972179 and 61602211), Guangdong Basic and Applied
   Basic Research Foundation (Grant No. 2020A1515011476), Science and
   Technology Program of Guangzhou, China (Grant No. 201707010259),
   Fundamental Research Funds for the Central Universities, and MOST under
   contracts 109-2634-F-259-001 through Pervasive Artificial Intelligence
   Research (PAIR) Labs, Taiwan.
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Giboulot Q, 2019, IEEE SIGNAL PROC LET, V26, P1339, DOI 10.1109/LSP.2019.2929435
   Golabi S, 2018, INFORM SCIENCES, V447, P104, DOI 10.1016/j.ins.2018.02.073
   Hong T, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9181275
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim C, 2019, KSII T INTERNET INF, V13, P6159, DOI 10.3837/tiis.2019.12.020
   Kim C, 2019, MULTIMED TOOLS APPL, V78, P17995, DOI 10.1007/s11042-018-7101-3
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, DIGIT SIGNAL PROCESS, V78, P284, DOI 10.1016/j.dsp.2018.03.016
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Ren HL, 2019, SIGNAL PROCESS, V165, P268, DOI 10.1016/j.sigpro.2019.07.020
   Su WG, 2019, MULTIMED TOOLS APPL, V78, P7927, DOI 10.1007/s11042-018-6410-x
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   YANG C, 2019, MULTIMED TOOLS APPL, P1
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
   YIN Z, 2019, IEEE T MULTIMEDIA
   Zhang RY, 2012, IEEE T INFORM THEORY, V58, P7272, DOI 10.1109/TIT.2012.2217072
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 43
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23425
EP 23444
DI 10.1007/s11042-020-09098-9
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539166300002
DA 2024-07-18
ER

PT J
AU Li, LP
   Peng, YL
   Liu, SG
AF Li, Liping
   Peng, Yali
   Liu, Shigang
TI Compound dictionary learning based classification method with a novel
   virtual sample generation Technology for Face Recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Dictionary learning; Virtual samples; Small sample
   size problem
ID SPARSE REPRESENTATION; COLLABORATIVE REPRESENTATION; OVERCOMPLETE
   DICTIONARIES; LINEAR-REGRESSION; CROWD EVACUATION; K-SVD; IMAGE;
   ALGORITHM; MODEL
AB Face recognition has earned its high reputation for many years since its considerable advances. However, it is still faced with the challenge of the small sample size problem. With the inspiration of the axis-symmetrical property of human faces, we propose a novel virtual sample synthesis strategy to address the issue of limited training samples. It is noteworthy that the novel algorithm can produce symmetry-based virtual face images, in which the pixels in symmetric parts of the face image were exchanged. And it is mathematically very tractable and quite easy to implement. In addition, considering the fact that dictionary learning (DL) based classification methods have excellent learning ability, we incorporate the virtual samples to learn virtual dictionary so as to enhance the accuracy of face recognition. Differing from conventional learning algorithms, the proposed method provides new insights into two crucial parts. Firstly, it proposes an originally creative idea and algorithm to automatically generate symmetry-based virtual samples and obtain virtual dictionary. Secondly, the original dictionary and virtual dictionary are integrated to construct the compound dictionary learning based classification in the way of adaptive weighted fusion. In this paper, we take the axis-symmetrical nature of faces into consideration and design a framework to generate compound dictionary, where more satisfactory classification accuracy can be achieved than the original dictionary learning methods, referred as, the locality-constrained and label embedding dictionary learning (LCLE-DL). Moreover, the experimental results demonstrate the superior performance of the proposed method in comparison with state-of-the-art dictionary learning methods.
C1 [Li, Liping; Peng, Yali; Liu, Shigang] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   [Li, Liping; Peng, Yali; Liu, Shigang] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
C3 Shaanxi Normal University
RP Peng, YL (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.; Peng, YL (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
EM yidap@foxmail.com; pengyl@snnu.edu.cn; shgliu_sx@163.com
RI Li, LiPing/HKE-9058-2023
FU National Natural Science Foundation of China [61873155, 61672333];
   Transfer and Promotion Plan of Scientific and Technological Achievements
   of Shaanxi Province [2019CGXNG-019]; National Natural Science Foundation
   of Shaanxi Province [2018JM6050]; Key Science and Technology Program of
   Shaanxi Province [2016GY-081]
FX This work is supported by the National Natural Science Foundation of
   China (No.61873155, 61672333), Transfer and Promotion Plan of Scientific
   and Technological Achievements of Shaanxi Province (No.2019CGXNG-019),
   the National Natural Science Foundation of Shaanxi Province
   (No.2018JM6050), the Key Science and Technology Program of Shaanxi
   Province, (No.2016GY-081).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Du B, 2016, IEEE T IMAGE PROCESS, V25, P5345, DOI 10.1109/TIP.2016.2601268
   Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360
   Guo HJ, 2019, MULTIMED TOOLS APPL, V78, P3, DOI 10.1007/s11042-017-4920-6
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jung HC, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P272
   Ke JC, 2018, J MOD OPTIC, V65, P367, DOI 10.1080/09500340.2017.1380854
   Ke J, 2017, J MOD OPTIC, V64, P2289, DOI 10.1080/09500340.2017.1357850
   Khan SA, 2014, J INTELL FUZZY SYST, V27, P3131, DOI 10.3233/IFS-141270
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Li K, 2016, PATTERN RECOGN, V51, P59, DOI 10.1016/j.patcog.2015.08.008
   Li K, 2015, IEEE T CYBERNETICS, V45, P1401, DOI 10.1109/TCYB.2014.2351831
   Li LJ, 2018, ARTIF INTELL REV, V50, P1, DOI 10.1007/s10462-016-9537-z
   Li ZM, 2019, NEURAL NETWORKS, V119, P93, DOI 10.1016/j.neunet.2019.07.013
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liu H, 2018, APPL SOFT COMPUT, V68, P360, DOI 10.1016/j.asoc.2018.04.015
   Liu H, 2018, INFORM SCIENCES, V436, P247, DOI 10.1016/j.ins.2018.01.023
   Liu SG, 2020, IEEE ACCESS, V8, P8668, DOI 10.1109/ACCESS.2019.2960928
   Liu SG, 2019, J COMPUT SCI-NETH, V31, P45, DOI 10.1016/j.jocs.2018.12.002
   Liu SG, 2017, IET COMPUT VIS, V11, P319, DOI 10.1049/iet-cvi.2016.0186
   Liu SG, 2016, J MOD OPTIC, V63, P1181, DOI 10.1080/09500340.2015.1133857
   Liu SG, 2016, SIGNAL PROCESS, V124, P141, DOI 10.1016/j.sigpro.2015.09.033
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Liu ZH, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107456
   Liu ZH, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105768
   Liu ZH, 2017, NEURAL PROCESS LETT, V45, P913, DOI 10.1007/s11063-016-9550-x
   Lu CW, 2014, IEEE T IMAGE PROCESS, V23, P837, DOI 10.1109/TIP.2013.2287602
   Ma LY, 2013, IEEE T MED IMAGING, V32, P1277, DOI 10.1109/TMI.2013.2255883
   Peng YL, 2020, NEUROCOMPUTING, V398, P505, DOI 10.1016/j.neucom.2019.05.103
   Peng YL, 2019, INT J MACH LEARN CYB, V10, P2229, DOI 10.1007/s13042-018-0862-1
   Peng YL, 2020, PATTERN RECOGN LETT, V130, P99, DOI 10.1016/j.patrec.2018.09.008
   Peng YL, 2019, J COMPUT SCI-NETH, V33, P11, DOI 10.1016/j.jocs.2019.03.003
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Peng YL, 2019, IET COMPUT VIS, V13, P172, DOI 10.1049/iet-cvi.2018.5096
   Peng YL, 2018, PATTERN RECOGN LETT, V116, P170, DOI 10.1016/j.patrec.2018.10.016
   Peng YL, 2018, MACH VISION APPL, V29, P991, DOI 10.1007/s00138-018-0941-z
   Peng YL, 2018, NEURAL PROCESS LETT, V48, P313, DOI 10.1007/s11063-017-9721-4
   Peng YL, 2018, SIGNAL PROCESS, V147, P101, DOI 10.1016/j.sigpro.2018.01.013
   Peng YL, 2018, IEEE ACCESS, V6, P488, DOI 10.1109/ACCESS.2017.2767907
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sadeghi M, 2014, IEEE T SIGNAL PROCES, V62, P883, DOI 10.1109/TSP.2013.2295062
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HH, 2019, MULTIMED TOOLS APPL, V78, P16945, DOI 10.1007/s11042-018-6888-2
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wu S, 2014, OPTIK, V125, P3530, DOI 10.1016/j.ijleo.2014.01.057
   Xu C, 2016, IEEE T IMAGE PROCESS, V25, P1495, DOI 10.1109/TIP.2016.2524207
   Xu Y, 2017, INFORM SCIENCES, V375, P171, DOI 10.1016/j.ins.2016.09.059
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang JY, 2015, COMPUT GRAPH FORUM, V34, P89, DOI 10.1111/cgf.12699
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Yang Y, 2019, IEEE T IMAGE PROCESS, V28, P302, DOI 10.1109/TIP.2018.2867740
   Zhang GY, 2018, MULTIMED TOOLS APPL, V77, P7171, DOI 10.1007/s11042-017-4627-8
   Zhang KY, 2018, MULTIMED TOOLS APPL, V77, P32243, DOI 10.1007/s11042-018-6110-6
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhu XN, 2018, MULTIMED TOOLS APPL, V77, P3105, DOI 10.1007/s11042-017-4943-z
NR 64
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23325
EP 23346
DI 10.1007/s11042-020-08965-9
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977700001
DA 2024-07-18
ER

PT J
AU Hashia, B
   Mir, AH
AF Hashia, Bazila
   Mir, Ajaz Hussain
TI Texture features' based classification of MR images of normal and
   herniated intervertebral discs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Herniation; Nucleus pulposus; Annulus fibrosus; GLRLM; GLCM; GLDM; SVM;
   KNN; BPNN
ID SEGMENTATION
AB Disc herniation is considered as a very common spine abnormality resulting in severe pain in back and legs. Besides it has great impact on economy of suffering patients also there is a concern about the shortage of radiologists and hence demand for computer aided diagnosis system. In this paper statistical texture features have been used for the classification of a normal intervertebral disc and a herniated intervertebral disc from MRI sequences acquired in sagittal plane. The main objective of this work was to appraise about the capability of texture features obtained from the intervertebral disc MR images and distinguish between normal intervertebral disc and herniated intervertebral disc using three different classifiers, namely, BPNN, KNN and SVM. The regions of interest (ROI) from patients with herniated discs were extracted by experienced radiologist from SKIMS institute, Srinagar. Three techniques where applied to each ROI to obtain texture features, which are, grey level run length matrix (GLRLM), grey level co-occurrence matrix (GLCM), and grey level difference method (GLDM). The results obtained show that GLRLM texture features ascertain a good discrimination capability to differentiate between a normal intervertebral disc and a herniated disc when SVM was used. Texture features extracted from GLCM present a good discrimination ability to differentiate between a normal intervertebral disc and a herniated disc when K-NN and BPNN classifiers were used. It is found that the selected set of features of the GLCM can discriminate a normal intervertebral disc from a herniated one, much accurately, on using K-NN and BPNN classifiers. On comparing the classification accuracies of K-NN and BPNN it is found that BPNN gives better results. K-NN is a simple algorithm to understand and implement but is slower because it starts learning from the testing data. As far as SVM is considered, selected set of features of GLRLM discriminates a normal intervertebral disc from a herniated one with good classification accuracy as compared to the others.
C1 [Hashia, Bazila; Mir, Ajaz Hussain] Natl Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, Jammu & Kashmir, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Hashia, B (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Srinagar 190006, Jammu & Kashmir, India.
EM samr_hashia@yahoo.co.in; ahmir@rediffmail.com
RI Mir, Ajaz Hussain/AAU-1265-2020; Hashia, Bazila/AAB-6376-2021
OI Mir, Ajaz Hussain/0000-0001-9777-0850; 
CR Al Kafri AS, 2017, LECT NOTES ARTIF INT, V10363, P107, DOI 10.1007/978-3-319-63315-2_10
   Alawneh K, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P286, DOI 10.1109/IACS.2015.7103190
   Ali KH., 2016, INT J COMP SCI INFOR, V14, P666
   Alomari RS, 2011, IEEE T MED IMAGING, V30, P1, DOI 10.1109/TMI.2010.2047403
   Alomari RS, 2010, INT J COMPUT ASS RAD, V5, P287, DOI 10.1007/s11548-009-0396-9
   Alomari RajaS., 2014, Lecture Notes in Computational Vision and Biomechanics, V17, P87, DOI [DOI 10.1007/978-3-319-07269-2_8, DOI 10.1007/978-3-319-07269, 10.1007/978-3-319-07269]
   Alomari RS, 2011, P 4 INT S APPL SCI B, P145
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen C, 2015, IEEE T MED IMAGING, V34, P1719, DOI 10.1109/TMI.2015.2403285
   Chevrefils C, 2007, LECT NOTES COMPUT SC, V4633, P1017
   CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008
   Dokare I., 2014, ENG TRENDS TECHNOL, V10, P19
   Galloway MM, 1974, 75 NASA
   García G, 2012, J DIGIT IMAGING, V25, P369, DOI 10.1007/s10278-011-9417-7
   Ghosh S, 2011, IEEE ENG MED BIO, P5068, DOI 10.1109/IEMBS.2011.6091255
   Ghosh S, 2011, PROC SPIE, V7963, DOI 10.1117/12.878055
   Ghosh S, 2011, I S BIOMED IMAGING, P1179, DOI 10.1109/ISBI.2011.5872612
   Gibbs P, 2003, MAGN RESON MED, V50, P92, DOI 10.1002/mrm.10496
   Giger ML, 2001, COMP AID DIAGN MED I
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hing Esther, 2008, Natl Health Stat Report, P1
   Jntu K. V. R., 2009, ACAD INFORM MANAGEME, V13, P52, DOI [10.1053/smrv.2000.0116, DOI 10.1053/SMRV.2000.0116]
   Kim JK, 1999, IEEE T MED IMAGING, V18, P231, DOI 10.1109/42.764896
   KIM KY, 1993, INT ORTHOP, V17, P241
   Koh J, 2012, INT J COMPUT ASS RAD, V7, P861, DOI 10.1007/s11548-012-0674-9
   Koh J, 2011, I S BIOMED IMAGING, P1467, DOI 10.1109/ISBI.2011.5872677
   Koh J, 2010, PROC SPIE, V7624, DOI 10.1117/12.844386
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lashari SA, 2013, PROC TECH, V11, P548, DOI 10.1016/j.protcy.2013.12.227
   McCulloch W.S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   MIR AH, 1995, IEEE ENG MED BIOL, V14, P781, DOI 10.1109/51.473275
   Neighbor N, 1991, NORMS NN PATTERN CLA
   Palaniappan R, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-223
   Raja'S A, 2010, MED IMAGING 2010 COM, V7624
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Smitha P., 2011, International conference on VLSI, Communication Intrumrnataiom, P34
   Tsai MD, 2004, COMPUT MED IMAG GRAP, V28, P307, DOI 10.1016/j.compmedimag.2004.05.001
   Valavanis IK, 2007, P ANN INT IEEE EMBS, P3741, DOI 10.1109/IEMBS.2007.4353145
   VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6
   Vince DG, 2000, COMPUT MED IMAG GRAP, V24, P221, DOI 10.1016/S0895-6111(00)00011-2
   Wang LY, 2009, LECT NOTES COMPUT SC, V5552, P374, DOI 10.1007/978-3-642-01510-6_43
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
NR 44
TC 8
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15171
EP 15190
DI 10.1007/s11042-018-7011-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900048
DA 2024-07-18
ER

PT J
AU Jiao, ZQ
   Cai, M
   Ming, XL
   Cao, Y
   Zou, L
   Wang, SH
AF Jiao, Zhuqing
   Cai, Min
   Ming, Xuelian
   Cao, Yin
   Zou, Ling
   Wang, Shui-Hua
TI Module dividing for brain functional networks by employing betweenness
   efficiency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain functional network; Betweenness efficiency; Girvan-Newman
   algorithm; Modularity; Module dividing
ID CONVOLUTIONAL NEURAL-NETWORK; EFFECTIVE CONNECTIVITY; COMMUNITY
   STRUCTURE; RECONSTRUCTION; ARCHITECTURE; CLASSIFIER; DYNAMICS; IMAGES
AB Traditional researches assume that brain functional networks are static during the entire scanning process of functional magnetic resonance image (fMRI) in the resting state. However, it is not difficult to ignore the dynamic interaction patterns of brain regions that essentially change across time. In this study, we take the internal weight information of the brain functional network as a calculation condition of module dividing for brain functional networks. The concept of betweenness efficiency is firstly proposed to improve Girvan-Newman (GN) algorithm for a better module dividing result, and the maximum modularity is used as a criterion to classify the brain functional network modules of normal subjects. The effect of the improved method is verified by controlling subjects, parameters, environment and other conditions. Then, the improved method was utilized to separate the modules in brain functional networks of normal subjects, and the template was used to divide the functional network of Alzheimer's disease (AD) patients and mild cognitive impairment (MCI) sufferers. The shortest path length of each module is calculated, and the experimental results are compared with the original GN and weighted GN algorithm improved by Newman. The experimental results demonstrate that, the maximum modularity of the improved method is higher while the dividing effect is better under the same conditions. Meanwhile, the conclusion is consistent with the existing research results when the proposed method is applicable to the analysis of the shortest path length. These results illustrate the viewpoint that the proposed method of module dividing is feasible in the analysis of modular structure of brain functional network.
C1 [Jiao, Zhuqing; Cai, Min; Ming, Xuelian; Zou, Ling] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
   [Cao, Yin] Nanjing Med Univ, Dept Neurol, Changzhou Peoples Hosp 2, Changzhou 213003, Peoples R China.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
   [Wang, Shui-Hua] Univ Leicester, Dept Informat, Univ Rd, Leicester LE1 7RH, Leics, England.
C3 Changzhou University; Nanjing Medical University; Loughborough
   University; University of Leicester
RP Jiao, ZQ; Zou, L (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.; Wang, SH (corresponding author), Univ Leicester, Dept Informat, Univ Rd, Leicester LE1 7RH, Leics, England.
EM jzq@cczu.edu.cn; zouling@cczu.edu.cn; shuihuawang@ieee.org
RI Jiao, Zhuqing/JDD-4102-2023; Wang, shuihua/G-7326-2016
OI Wang, shuihua/0000-0003-4713-2791
CR Chang C, 2010, NEUROIMAGE, V50, P81, DOI 10.1016/j.neuroimage.2009.12.011
   Chen XB, 2017, HUM BRAIN MAPP, V38, P5019, DOI 10.1002/hbm.23711
   Chen XB, 2017, NEUROINFORMATICS, V15, P271, DOI 10.1007/s12021-017-9330-4
   Echávarri C, 2011, BRAIN STRUCT FUNCT, V215, P265, DOI 10.1007/s00429-010-0283-8
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Hutchison RM, 2013, HUM BRAIN MAPP, V34, P2154, DOI 10.1002/hbm.22058
   Jiao ZQ, 2014, J SUPERCOMPUT, V67, P806, DOI 10.1007/s11227-013-1010-z
   Jiao ZQ, 2018, MULTIMED TOOLS APPL, V77, P22689, DOI 10.1007/s11042-017-5163-2
   Jiao ZQ, 2018, COMPUT ELECTR ENG, V69, P740, DOI 10.1016/j.compeleceng.2018.01.010
   Jiao ZQ, 2017, INT J SENS NETW, V24, P90, DOI 10.1504/IJSNET.2017.10005733
   Jiao ZQ, 2017, J MED IMAG HEALTH IN, V7, P407, DOI 10.1166/jmihi.2017.2029
   Jiao ZQ, 2017, FRONT BIOSCI-LANDMRK, V22, P1634, DOI 10.2741/4562
   Jiao ZQ, 2017, CNS NEUROL DISORD-DR, V16, P44, DOI 10.2174/1871527314666161124120040
   Jiao ZQ, 2016, INT J SENS NETW, V21, P197, DOI 10.1504/IJSNET.2016.078374
   Kaiser M, 2011, NEUROIMAGE, V57, P892, DOI 10.1016/j.neuroimage.2011.05.025
   Koch W, 2012, NEUROBIOL AGING, V33, P466, DOI 10.1016/j.neurobiolaging.2010.04.013
   Laurienti P, 2009, MODULARITY MAPS REVE
   Li HJ, 2018, CHAOS SOLITON FRACT, V110, P20, DOI 10.1016/j.chaos.2018.02.009
   Li HJ, 2016, IEEE T KNOWL DATA EN, V28, P2349, DOI 10.1109/TKDE.2016.2563425
   Li HJ, 2014, EPL-EUROPHYS LETT, V108, DOI 10.1209/0295-5075/108/68009
   Li HJ, 2015, PHYS REV E, V91, DOI 10.1103/PhysRevE.91.012801
   Li HJ, 2016, J SYST SCI COMPLEX, V29, P1071, DOI 10.1007/s11424-015-4145-6
   [李晓佳 LI Xiaojia], 2008, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V5, P19
   Lord LD, 2017, PHILOS T R SOC A, V375, DOI 10.1098/rsta.2016.0283
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Nigam S, 2016, J NEUROSCI, V36, P670, DOI 10.1523/JNEUROSCI.2177-15.2016
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Salvador R, 2005, CEREB CORTEX, V15, P1332, DOI 10.1093/cercor/bhi016
   Stam CJ, 2007, CEREB CORTEX, V17, P92, DOI 10.1093/cercor/bhj127
   Stam CJ, 2009, BRAIN, V132, P213, DOI 10.1093/brain/awn262
   Sun JF, 2011, J COMPLEX SYST COMPL, V7, P74
   Tobia MJ, 2017, HUM BRAIN MAPP, V38, P6185, DOI 10.1002/hbm.23821
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Wang JH, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00016
   Wang K. C., 2016, SCI B, V61, P3022, DOI DOI 10.1360/N972016-00585
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   [王鑫 Wang Xin], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P978
   Yang Z, 2016, CEREB CORTEX, V26, P2341, DOI 10.1093/cercor/bhw027
   Zhang Y, 2008, PROG ELECTROMAGN RES, V83, P185, DOI 10.2528/PIER08051403
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, J ELECTROMAGNET WAVE, V25, P1081, DOI 10.1163/156939311795762024
   Zhang YD, 2009, PROG ELECTROMAGN RES, V94, P83, DOI 10.2528/PIER09041905
   Zhang Y, 2017, MINERALS-BASEL, V7, DOI 10.3390/min7060102
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhang YD, 2013, SENSORS-BASEL, V13, P4029, DOI 10.3390/s130404029
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   [赵学武 Zhao Xuewu], 2016, [科学通报, Chinese Science Bulletin], V61, P2035
NR 56
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15253
EP 15271
DI 10.1007/s11042-018-7125-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900051
DA 2024-07-18
ER

PT J
AU Kim, TK
AF Kim, Tae-Kook
TI A mobile multimedia content handoff scheme based on proxy mobile IPv6
   for VR/AR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content delivery network (CDN); Content distributed networks; Proxy
   mobile IPv6 (PMIPv6); Handoff; YouTube; Virtual reality (VR); Augmented
   reality (AR)
ID MANAGEMENT; NETWORKS
AB This paper proposes a novel mobile multimedia content handoff scheme for a content delivery network (CDN) based on proxy mobile IPv6 (PMIPv6). PMIPv6 is a network-based mobility management protocol. In PMIPv6, when a mobile node (MN) that is currently receiving content from one domain moves into neighboring domain, it can maintain its existing session seamlessly. However, when the MN moves continuously, the content delivery path may become long, potentially leading to heavy network traffic and degradation of the quality of service (QoS) through delay and jitter. The proposed handoff scheme (PMIPv6-CDN Handoff) selects an optimal content server as a mobile node (MN) moves in a handoff and receives content. This scheme offers several benefits such as routing path optimization and a reduced transmission delay. Therefore, it can be applied to virtual reality (VR) and augmented reality (AR) services, which are sensitive to transmission delay.
C1 [Kim, Tae-Kook] Tongmyong Univ, Dept Informat & Commun Engn, 428 Sinseon Ro, Busan 48520, South Korea.
C3 Tongmyong University
RP Kim, TK (corresponding author), Tongmyong Univ, Dept Informat & Commun Engn, 428 Sinseon Ro, Busan 48520, South Korea.
EM leader@tu.ac.kr
CR [Anonymous], CONTENT DISTRIBUTION
   [Anonymous], 2008, RFC 5213
   Cho K, 2011, IEEE COMMUN MAG, V49, P156, DOI 10.1109/MCOM.2011.6035830
   Chung JM, 2013, IEEE WIREL COMMUN, V20, P112
   Dilley J, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/MIC.2002.1036038
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Kim T, 2016, MULTIMED TOOLS APPL, V75, P12693, DOI 10.1007/s11042-015-3077-4
   Kim T, 2015, MULTIMED TOOLS APPL, V74, P1697, DOI 10.1007/s11042-014-2215-8
   Kim T, 2014, IEICE T FUND ELECTR, VE97A, P907, DOI 10.1587/transfun.E97.A.907
   Kong KS, 2008, IEEE WIREL COMMUN, V15, P36, DOI 10.1109/MWC.2008.4492976
   Kurose J, 2013, COMPUTER NETWORKING, P588
   Lai ZQ, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P409, DOI 10.1145/3117811.3117815
   Lazar I., 2001, IT Professional, V3, P47, DOI 10.1109/6294.946620
   Lee JH, 2013, IEEE T IND ELECTRON, V60, P1077, DOI 10.1109/TIE.2012.2198035
   Pathan M, 2008, LECT NOTES ELECTR EN, V9, P3
   Soto I, 2010, IPJ, P1
   Sun LY, 2018, MULTIMED TOOLS APPL, V77, P29013, DOI 10.1007/s11042-018-6091-5
   Tian Y, 2018, MULTIMED TOOLS APPL, V77, P16561, DOI 10.1007/s11042-017-5228-2
   Vakali A, 2003, IEEE INTERNET COMPUT, V7, P68, DOI 10.1109/MIC.2003.1250586
NR 19
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16501
EP 16515
DI 10.1007/s11042-019-7573-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600039
DA 2024-07-18
ER

PT J
AU Kwon, KS
   Jeong, HY
   Kim, DG
AF Kwon, Ki-Sung
   Jeong, Hwa-Young
   Kim, Dong-Gun
TI RETRACTED: AR/VR drama contents for Korean literature by story bank
   (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Korean drama; Digital contents; Yadam story; AR; VR based drama; Korean
   literature
AB Digital contents are utilized in various fields. However, in order for digital contents to be a valuable service and a meaningful resource in the industrial field, the completeness and reliability of the story that becomes the source of the content is very important. Recently, AR/VR drama is recording and showing to user using digital contents from Korean literature. This paper aims to suggest ways to utilize the story told Korean cultural contents as commercial digital contents. And we propose a way to make AR/VR based drama recording using the digital contents and show it to user. To achieve this, the Korean cultural contents are classified into keyword and group, and the story-bank which is the method of finding new literature data that forms a content-based main prototype are structured. A source for drama story which enables the utilization of digital contents stored in story-bank through search and purchase of users was proposed.
C1 [Kwon, Ki-Sung; Jeong, Hwa-Young; Kim, Dong-Gun] Kyung Hee Univ, Humanitas Coll, Dondaemungu Hoegidong 1, Seoul, South Korea.
C3 Kyung Hee University
RP Kim, DG (corresponding author), Kyung Hee Univ, Humanitas Coll, Dondaemungu Hoegidong 1, Seoul, South Korea.
EM rnjsrltjd400@naver.com; hyjeong@khu.ac.kr; dehi@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Alam MF, 2017, J NETW COMPUT APPL, V89, P109, DOI 10.1016/j.jnca.2017.03.022
   An S-b, 2012, ACAD POPULAR NARRATI, V28, P257
   Arora G, 2005, ELECTRON COMMER R A, V4, P250, DOI 10.1016/j.elerap.2005.03.001
   Chang E-j, 2017, GLOBAL CULTURE CONTE, V31, P193
   Choi Y-h, 2008, KOREA HUMANITIES CON, V11, P71
   Ham B-h, 2007, WOORI LIT SOC, V22, P149
   Hong S-n, 2017, WOORI LIT SOC, V53, P125
   Jeon D-J, 2012, USING DIGITAL STORYT
   Kang M-j, 2013, SOC KOREAN CLASSICAL, V27, P177
   Kim P-k, 2015, TRADITIONAL CREATION
   Kumar S, 2017, J IND ENG CHEM, V48, P133, DOI 10.1016/j.jiec.2016.12.031
   Lee K-o, 2012, SOC KOREAN LANGUAGE, V115, P289
   León M, 2010, PROCD SOC BEHV, V9, DOI 10.1016/j.sbspro.2010.12.244
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Li YM, 2010, DECIS SUPPORT SYST, V50, P243, DOI 10.1016/j.dss.2010.08.027
   Lin SJ, 2009, J NETW COMPUT APPL, V32, P589, DOI 10.1016/j.jnca.2008.08.003
   Na YJ, 2010, DECIS SUPPORT SYST, V50, P243, DOI [10.1016/j.dss.2010.08.027, DOI 10.1016/J.DSS.2010.08.027]
   Shin IC, 2010, ACAD KOREAN STUDIES, V33.3, P7
   Shin IC, 2006, SOC KOREAN LIT CHINE, V6, P337
   Xu YQ, 2019, COMPUT HUM BEHAV, V95, P307, DOI 10.1016/j.chb.2018.10.021
   Yoon Hc, 2000, STORY OPERATING SYST
   이규훈, 2008, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V8, P119
NR 22
TC 1
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16731
EP 16749
DI 10.1007/s11042-019-08336-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600052
DA 2024-07-18
ER

PT J
AU Li, LQ
   Pan, XP
   Yang, HH
   Liu, ZB
   He, YB
   Li, ZM
   Fan, YX
   Cao, ZW
   Zhang, LH
AF Li, Lingqiao
   Pan, Xipeng
   Yang, Huihua
   Liu, Zhenbing
   He, Yubei
   Li, Zhongming
   Fan, Yongxian
   Cao, Zhiwei
   Zhang, Longhao
TI Multi-task deep learning for fine-grained classification and grading in
   breast cancer histopathological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task deep learning; Histopathological image classification;
   Fine-grained; Convolutional neural network; Breast cancer
AB Fine-grained classification and grading of breast cancer (BC) histopathological images are of great value in clinical application. However, automatic classification and grading of BC histopathological images are complicated by (1) small inter-class variance and large intra-class variance exist in BC histopathological images, and (2) features extracted from similar histopathological images with different magnification are quite different. To address these issues, an improved deep convolution neural network model is proposed and the procedure can be divided into three main stages. Firstly, in the representation learning process, multi-class recognition task and verification task of image pair are combined. Secondly, in the feature extraction process, a prior knowledge is built, which is "the variances in feature outputs between different subclasses is relatively large while the variance between the same subclass is small." Additionally, the prior information that histopathological images with different magnification belong to the same subclass are embedded in the feature extraction process, which contributes to less sensitive with image magnification. The experimental results based on three different histopathological image datasets show that the performance of the proposed method is better than state of the art, with better robustness and generalization ability.
C1 [Li, Lingqiao; Pan, Xipeng; Yang, Huihua; Li, Zhongming; Cao, Zhiwei; Zhang, Longhao] Beijing Univ Posts & Telecommun, Sch Automat, 10 Xitucheng Rd, Beijing, Peoples R China.
   [Li, Lingqiao; Yang, Huihua; Liu, Zhenbing; Fan, Yongxian] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, 1 Jinji Rd, Qixing Dist, Guilin, Peoples R China.
   [He, Yubei] Univ Melbourne, Sch Comp & Informat Syst, Melbourne, Vic, Australia.
C3 Beijing University of Posts & Telecommunications; Guilin University of
   Electronic Technology; University of Melbourne
RP Yang, HH (corresponding author), Beijing Univ Posts & Telecommun, Sch Automat, 10 Xitucheng Rd, Beijing, Peoples R China.; Yang, HH (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, 1 Jinji Rd, Qixing Dist, Guilin, Peoples R China.
EM 54pe@163.com; pxp201@bupt.edu.cn; yhh@bupt.edu.cn; zbliu@guet.edu.cn
RI Li, Lingqiao/HNQ-2741-2023; Yang, Huihua/ABI-3520-2020
OI Li, Lingqiao/0000-0001-9402-0421; Yang, Huihua/0000-0001-6334-4044
CR Akbar S, 2017, DEEP LEARNING MED AN
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Codella N, 2016, P SPIE MED IMAGING 2
   Dimitropoulos K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185110
   Dozat T., 2016, ICLR WORKSHOP
   Garud H, 2017, IEEE COMPUT SOC CONF, P828, DOI 10.1109/CVPRW.2017.115
   Gupta V, 2017, LECT NOTES COMPUT SC, V10550, P160, DOI 10.1007/978-3-319-67543-5_16
   Gupta V, 2017, LECT NOTES COMPUT SC, V10425, P354, DOI 10.1007/978-3-319-64698-5_30
   Gupta V, 2017, IEEE COMPUT SOC CONF, P769, DOI 10.1109/CVPRW.2017.107
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li YJ, 2018, MOBILE NETW APPL, V23, P352, DOI 10.1007/s11036-017-0933-7
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   Pan XP, 2018, WORLD WIDE WEB, V21, P1721, DOI 10.1007/s11280-017-0520-7
   Pan XP, 2017, NEUROCOMPUTING, V229, P88, DOI 10.1016/j.neucom.2016.08.103
   Song Y, 2017, MED IMAGE COMPUTING
   Song Y, 2017, I S BIOMED IMAGING, P600, DOI 10.1109/ISBI.2017.7950592
   Spanhol FA, 2017, IEEE SYS MAN CYBERN, P1868, DOI 10.1109/SMC.2017.8122889
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Stewart B. W., 2003, World Cancer Report
   Sun Y, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang D., 2016, ARXIV PREPRINT ARXIV
   Wang D, 2011, NEUROCOMPUTING, V74, P2745, DOI 10.1016/j.neucom.2011.03.047
   Wang P, 2016, SIGNAL PROCESS, V122, P1, DOI 10.1016/j.sigpro.2015.11.011
   Wei B, 2017, 2017 IEEE 2 INT C CL
   Weiming Zhi, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10637, P669, DOI 10.1007/978-3-319-70093-9_71
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yuan JF, 2018, CANCER BIOMARK, V23, P1, DOI 10.3233/CBM-170901
   Zhang ST, 2016, MED IMAGE ANAL, V33, P98, DOI 10.1016/j.media.2016.06.010
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhang YG, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-17
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
NR 50
TC 52
Z9 54
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14509
EP 14528
DI 10.1007/s11042-018-6970-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900011
OA Bronze
DA 2024-07-18
ER

PT J
AU Liang, HN
   Fleming, C
   Man, KL
AF Liang, Hai-Ning
   Fleming, Charles
   Man, Ka Lok
TI Personal Mobile devices at work: factors affecting the adoption of
   security mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal mobile devices; Usable security; Work and personal life;
   Awareness of security; Privacy risks; Secured data
ID USER ACCEPTANCE; INFORMATION-TECHNOLOGY; DETERMINANTS; AWARENESS
AB This research examines the use of personal mobile devices at work and what factors affect people's adoption of enhanced levels of security mechanisms for their devices. Mobile devices make the delineation between work and personal life less clear or even non-existent. Mobile devices, such as smartphones and tablets and in the foreseeable future together with smartwatches and smart glasses, will be inseparable to people, whether they be at work or outside. Alongside with their devices being brought into work environments, they will be used to carry out activities that are work related and very likely to host company-sensitive information within them. The mobile nature of the devices means they frequently operate in insecure environments, providing numerous opportunities for attackers to obtain critical information and use it for unwanted purposes. This can pose a dilemma for companies given that, on the one hand, they cannot stop their employees from using their personal devices for work-related activities and storing company-sensitive data and, on the other, attacks to steal data from devices are constantly growing in terms of sophistication, frequently, and effectiveness. In this research, we want to understand better the usage patterns of people bringing their devices to work and their predisposition to adopt secure mechanisms to protect the data found in their devices. We aim to find what factors impact the adoption of these mechanisms. The results indicate there are a number of factors that can predict their adoption, which are useful for designers of interfaces with security in mind and companies who would like to see their employees adopt more sophisticated and better methods to secure data located in these devices.
C1 [Liang, Hai-Ning; Man, Ka Lok] Xian Jiaotong Liverpool Univ, AI Univ Res Ctr AI URC, Suzhou, Peoples R China.
   [Liang, Hai-Ning; Fleming, Charles; Man, Ka Lok] Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, AI Univ Res Ctr AI URC, Suzhou, Peoples R China.; Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
RI Man, Ka Lok/K-7013-2013
OI Liang, Hai-Ning/0000-0003-3600-8955
CR Allam S, 2014, COMPUT SECUR, V42, P56, DOI 10.1016/j.cose.2014.01.005
   [Anonymous], 27 IFIP INT INF SEC
   [Anonymous], ANN COMP SEC APPL C
   Ben-Asher N, 2011, P MOBILEHCI 2011 STO
   Benbasat I, 2007, J ASSOC INF SYST, V8, P211, DOI 10.17705/1jais.00126
   Biddle R, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333114
   Chau P. T. K., 1996, Journal of Management Information Systems, V13, P185
   Cheong SN, 2014, EXPERT SYST APPL, V41, P3561, DOI 10.1016/j.eswa.2013.10.060
   Chesney T., 2006, An Interdisciplinary Journal on Humans in ICT Environments, V2, P225, DOI [DOI 10.17011/HT/URN.2006520, 10.17011/ht/urn.2006520]
   Chiang H -Y, 2013, P 15 INT C HUM COMP
   Chiasson S, 2009, INT J INF SECUR, V8, P387, DOI 10.1007/s10207-009-0080-7
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   Cisco, 2015, BYOD INS 2013
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Fishbein Martin., 1975, Attitude, Intention and Behavior: An Introduction to Theory and Research
   Fleming C, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P764, DOI 10.1109/CSE.2014.157
   Fleming C, 2012, IEEE ICC
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Furnell SM, 2006, COMPUT SECUR, V25, P27, DOI 10.1016/j.cose.2005.12.004
   Furnell S, 2007, COMPUT SECUR, V26, P434, DOI 10.1016/j.cose.2007.06.003
   Ha I, 2007, INFORM MANAGE-AMSTER, V44, P276, DOI 10.1016/j.im.2007.01.001
   Kaasinen E., 2011, HUMAN COMPUTER INTER, P80, DOI [10.4018/978-1-60960-499-8.ch005, DOI 10.4018/978-1-60960-499-8.CH005]
   Ketabdar H, 2010, 4 INT C MOB UB COMP
   Kwon T, 2014, COMPUT SECUR, V42, P137, DOI 10.1016/j.cose.2013.12.001
   La Polla M, 2013, IEEE COMMUN SURV TUT, V15, P446, DOI 10.1109/SURV.2012.013012.00028
   Lee Y., 2003, Communications of the Association for Information Systems, V12, P752, DOI [DOI 10.17705/1CAIS.01250, 10.17705/1CAIS.01250]
   Legris P, 2003, INFORM MANAGE-AMSTER, V40, P191, DOI 10.1016/S0378-7206(01)00143-4
   Li Yuanquan, 2008, Tsinghua Science and Technology, V13, P273, DOI 10.1016/S1007-0214(08)70044-0
   Liang HN, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P754, DOI 10.1109/CSE.2014.155
   Liu Y, 2010, COMPUT EDUC, V55, P1211, DOI 10.1016/j.compedu.2010.05.018
   Maniar Nipan, 2008, Journal of Software, V3, P51, DOI 10.4304/jsw.3.4.51-61
   Mylonas A, 2013, COMPUT SECUR, V34, P47, DOI 10.1016/j.cose.2012.11.004
   Ponemon Institute, 2012, 2013 STAT ENDP
   PricewaterhouseCoopers, 2012, UK INF SEC BREACH SU
   Saade R.G., 2005, Journal of Issues in Informing Science and Information Technology, V2, P287
   Sadler K, 2006, P NORDICHI 2006
   Shaw K, 2004, DATA PDAS MOSTLY UNP, DOI [10.1002/0471250953.bi0107s05, DOI 10.1002/0471250953.BI0107S05]
   Siponen M. T., 2000, Information Management & Computer Security, V8, P31, DOI 10.1108/09685220010371394
   Tao H., 2008, International Journal of Network Security, V7, P273
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Wang YS, 2009, BRIT J EDUC TECHNOL, V40, P92, DOI 10.1111/j.1467-8535.2007.00809.x
   Yousafzai SY, 2007, J MODEL MANAG, V2, P251, DOI 10.1108/17465660710834453
   Yu Z, 2016, IEEE POW ENER SOC GE
   Yu Z, 2016, 2016 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P458, DOI 10.1109/APCCAS.2016.7804002
NR 46
TC 1
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16113
EP 16126
DI 10.1007/s11042-019-7349-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600017
DA 2024-07-18
ER

PT J
AU Rani, VMK
   Dhenakaran, SS
AF Rani, V. Mary Kiruba
   Dhenakaran, S. S.
TI RETRACTED: Classification of ultrasound breast cancer tumor images using
   neural learning and predicting the tumor growth rate (Retracted article.
   See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Ultrasound images; Breast cancer; Tumor growth; Image processing; Age;
   Blood group
AB Ultrasound breast cancer tumor growth model is dependence on the cancer tumor growth size on time. Breast cancer tumor progresses on its growth and evaluated to estimate the survival time. The volume of the tumor changes because of the cell growth and loss. This research deals with the primary or an initial stage of breast cancer patients and screening with periodical time. Image processing techniques, specifying the systematic learning for tumor classification are the pre mechanism. Processing the tumor for high visibility, noises are removed and cancer, non-cancerous features are learned by the system through neural network back prorogation for automatic prediction. The screening reactivity in terms of lesion density affects the growth of tumor size. Patients who have effected by breast cancer, images are learned, and the tumor size is observed in the tumor growth model. The relationship between the historical and statistical growth rate defines that patient with; b + blood group around the age of 28 to 56 have a possible of 20% growth of malignant tumors than benign tumors.
C1 [Rani, V. Mary Kiruba; Dhenakaran, S. S.] Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
C3 Alagappa University
RP Rani, VMK (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
EM marykirubarani@gmail.com; ssdarvind@yahoo.com
CR Abrahamsson L, 2015, BREAST CANCER RES, V17, DOI 10.1186/s13058-015-0614-z
   Anupriya K, 2018, PROC IEEE INT SOFT, P208
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   BalaAnand M, 2018, PROC IEEE INT SOFT, P92
   BalaAnand M, INT J TECHNOL ENG SY, V7, P157
   Benmazou S, 2018, 4 INT C ADV TECHNOLO, P1
   Helwan A, 2015, I CON ADV BIOMED ENG, P17, DOI 10.1109/ICABME.2015.7323240
   Jiang J, 2010, COMPUT MED IMAG GRAP, V34, P617, DOI 10.1016/j.compmedimag.2010.07.003
   Kaymak S, 2017, PROCEDIA COMPUT SCI, V120, P126, DOI 10.1016/j.procs.2017.11.219
   Liu Y, 2013, LECT NOTES COMPUTER
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Marcomini KD, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/7987212
   Mehdy MM, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2610628
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Pan Q, 2017, 2017 INTERNATIONAL CONFERENCE ON GREEN INFORMATICS (ICGI), P41, DOI 10.1109/ICGI.2017.31
   Rani V. Mary Kiruba, 2016, AUST J BASIC APPL SC, V10, P44
   Salguero AG, 2019, ADV INTELLIGENT SYST, V803
   Sivaparthipan CB, 2020, MULTIMED TOOLS APPL, V79, P8431, DOI 10.1007/s11042-018-6648-3
   Tike Thein Htet Thazin., 2015, Advanced Computing: An International Journal, V6, P1
   Vesal S, 2018, CLASSIFICATION BREAS, P1
   Xie X, 2016, PUBLIC LIB SCI PLOS, P11
NR 21
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16967
EP 16985
DI 10.1007/s11042-019-7487-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600064
DA 2024-07-18
ER

PT J
AU Zhou, YM
   Jiang, MJ
AF Zhou, Yi-Min
   Jiang, Meng-Jun
TI Comparison of inversion method of maize leaf area index based on UAV
   hyperspectral remote sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unmanned aerial vehicle; Hyperspectral remote sensing; Image; Corn leaf
   area index; Inversion
AB The current inversion method of maize leaf area index has the problems of long time-consuming inversion, high energy consumption, and low fitting coefficient between the prediction result and the actual result. For these problems, an inversion method of maize leaf area index based on UAV hyperspectral remote sensing is proposed in this paper. Acquisition of spectral image of maize leaf using ASD Field SpecPro FR Field Hyperspectral instrument and CCD Array detector in UAV remote Sensing system. Denoising and segmentation of corn leaf images using stationary wavelets, improved Snake and PSO methods.. The improved Snake model is used to achieve coarse convergence of target image contour after denoising. Through particle swarm optimization iterative algorithm, the optimal image segmentation point is found and the image segmentation is achieved. Based on the results of image denoising segmentation, the expressions of modified chlorophyll absorption ratio, normalized difference spectral index, and ratio-type spectral index are obtained. The correlation between the three indices and the maize leaf area index was analyzed. Finally, the maize leaf area index was obtained by using ratio-type spectral index. Experiments show that the proposed method has a comprehensive performance, and has a strong advantage over the current method.
C1 [Zhou, Yi-Min; Jiang, Meng-Jun] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Zhou, YM (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
EM yiminzhou@live.com
OI Zhou, Yimin/0000-0001-8692-9635
CR Garreta V, 2017, CLIM DYNAM, V35, P371
   Kubo H, 2016, GEOPHYS J INT, V204, P1601, DOI 10.1093/gji/ggv540
   [李翠娜 Li Cuina], 2016, [中国农业气象, Chinese Journal of Agrometeorology], V37, P479
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2019, MOBILE NETW APPL, V24, P5, DOI 10.1007/s11036-018-1134-8
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Mallet A, 2018, ELECTRON LETT, V5, P120
   Mustac M, 2016, GEOPHYS J INT, V204, P311, DOI 10.1093/gji/ggv458
   Nie S, 2016, IEEE J-STARS, V9, P3259, DOI 10.1109/JSTARS.2016.2554619
   Olm JM, 2011, DISCRETE CONT DYN-B, V15, P197, DOI 10.3934/dcdsb.2011.15.197
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Peng YF, 2017, COMPUT SIMUL, V34, P332
   Piessens R, 2017, ENVIRON PROG SUSTAIN, V36, P1517
   Shuai L, 2018, COMPLEXITY, V2018, P2016976
   [孙华 Sun Hua], 2016, [中南林业科技大学学报, Journal of Central South University of Forestry & Technology], V36, P11
   Wang HB, 2017, SPECTROSC SPECT ANAL, V37, P1489, DOI 10.3964/j.issn.1000-0593(2017)05-1489-08
   [王强 Wang Qiang], 2016, [中国矿业大学学报. 自然科学版, Journal of China University of Mining & Technology], V45, P623
   Wei XM, 2016, PLANT BREEDING, V135, P671, DOI 10.1111/pbr.12422
   Wu MF, 2017, J BIOMATER APPL, V32, P191, DOI 10.1177/0885328217713357
   Yoshida N, 2016, NUCL PHYS A, V570, P17
NR 21
TC 4
Z9 4
U1 9
U2 73
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16385
EP 16401
DI 10.1007/s11042-019-7318-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600032
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumar, N
   Jung, KH
AF Kumar, Rajeev
   Kumar, Neeraj
   Jung, Ki-Hyun
TI I-PVO based high capacity reversible data hiding using bin reservation
   strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE I-PVO; Reversible data hiding; Pixel value ordering; PVO; Bin
   reservation strategy
ID EXPANSION
AB Improved Pixel-Value-Ordering (I-PVO) based reversible data hiding scheme provides high-fidelity watermarked images with high data embedding capacity. In this paper, a new reversible data hiding scheme based on the I-PVO method is proposed to increase the data embedding capacity. The proposed scheme first divides the cover image into non-overlapping blocks of size 2 x 2 pixels uniformly, and then increases and decreases the values of highest and lowest pixels by one respectively. The proposed modification rules are used to reserve two bins which are used to increase the data hiding capacity. The pixels are sorted in ascending order to calculate two differences in the block. The difference values are calculated by considering pixel values along with their locations in the original block and are utilized to embed secret data in the highest and lowest pixel values using the proposed modification rules. While embedding the secret data, the pixel values are either increased/decreased or left unchanged according to the embedding bits. Thus, the proposed scheme embeds three bits per block in the cover image instead of two bits in the case of I-PVO on average. The experimental results show that the proposed scheme provides significantly higher data hiding capacity than the previous works.
C1 [Kumar, Rajeev; Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
   [Kumar, Neeraj] Jamia Milia Islamia Univ, Dept Elect & Commun, Delhi, India.
C3 Kyungil University; Jamia Millia Islamia
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
EM rajivgarg@outlook.com; neeraj.mohiwal@gmail.com; khanny.jung@gmail.com
RI Kumar, Rajeev/IUP-5006-2023; Kumar, Neeraj/L-3500-2016
OI Kumar, Rajeev/0000-0002-5000-7644; Kumar, Neeraj/0000-0002-3020-3947;
   Jung, Ki-Hyun/0000-0002-0662-8355
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2018R1D1A1A09081842]; Korea
   Research Fellowship Program through the National Research Foundation of
   Korea(NRF) - Ministry of Science and ICT [2019H1D3A1A01101687]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(NRF-2018R1D1A1A09081842) and Korea Research Fellowship Program
   through the National Research Foundation of Korea(NRF) funded by the
   Ministry of Science and ICT(2019H1D3A1A01101687)
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Kumar BS, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960006
   Kumar N, 2018, J CIRCUIT SYST COMP, V27, P175
   Kumar R., 2018, INT J MULTIMED INTEL, V3, P146, DOI [10.1504/IJMIS.2018.096356, DOI 10.1504/IJMIS.2018.096356]
   Kumar R, 2017, MULTIMED TOOLS APPL, V76, P979, DOI 10.1007/s11042-015-3069-4
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lu TC, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120764
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Xiang HY, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2585983
   Zhao W., 2018, J INF HIDING MULTIME, V9, P918
NR 24
TC 15
Z9 15
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22635
EP 22651
DI 10.1007/s11042-020-09069-0
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000559592700001
DA 2024-07-18
ER

PT J
AU Logeshwari, R
   Parvathy, LR
AF Logeshwari, R.
   Parvathy, L. Rama
TI Generating logistic chaotic sequence using geometric pattern to
   decompose and recombine the pixel values
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic chaotic sequence; Spirograph; Scrambling algorithm; Capacity
ID ENCRYPTION ALGORITHM; IMAGE; TRANSFORMATION; DIFFUSION
AB The Secret Sharing Scheme plays a vital role in cryptography which allows to transmit the secret digital information (image, video, audio, handwriting, etc.,) over a communication channel. This cryptographic technique involves encrypting the secret images into noisy shares and transmitted. The transmitted image shares are reconstructed using simple logical computation. In this paper, we propose a secure (n, n)- Multi-Secret-Sharing (MSS) scheme using image scrambling algorithm which is based on the logistic chaotic sequence generated using the secret key which is retrieved from the geometric pattern named as spirograph which drawn by the users with their private values. Also, decomposition and recombination of image pixels which points to change the position and values of the pixels. The experimental results estimate that the standard metrics NPCR, UACI, Entropy, Coefficient Correlation values proves the rigidness of the implemented algorithm.
C1 [Logeshwari, R.; Parvathy, L. Rama] Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Logeshwari, R.; Parvathy, L. Rama] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Parvathy, LR (corresponding author), Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.; Parvathy, LR (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
EM loge.shwari54@gmail.com; ramapaivathyl.sse@saveetha.com
RI L, Rama/AAM-1205-2021; L, Ramaparvathy/IWE-3683-2023
OI L, Rama/0000-0001-8645-254X; R, Logeshwari/0000-0002-6167-8996
CR Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   [Anonymous], 2004, CHINESE J STEREOLOGY
   [Anonymous], 2010, IJ NETWORK SECURITY
   Anto S. A., 2013, INT J SCI RES, V2, P77
   Borujeni SE, 2009, MATH PROBL ENG, V2009, DOI 10.1155/2009/762652
   ElLatif Abd AA, 2011, 2011 7 INT C INT INF
   Han FL, 2006, LECT NOTES COMPUT SC, V4115, P342
   Huang X, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/170372
   Li B, 2005, J CENT SOUTH UNIV T, V12, P278, DOI 10.1007/s11771-005-0414-1
   Logeshwari R, 2019, INT J INNOVATIVE TEC, V8, P1148
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Prasad M., 2011, COMPUTER SCI, P169, DOI 10.5121/csit.2011.1217
   Praveenkumar P, 2017, TELECOMMUN SYST, V65, P65, DOI 10.1007/s11235-016-0212-0
   Praveenkumar P, 2015, SECUR COMMUN NETW, V8, P3335, DOI 10.1002/sec.1257
   Praveenkumar P, 2015, COMPUT BIOL MED, V62, P264, DOI 10.1016/j.compbiomed.2015.04.031
   Praveenkumar P, 2015, AEU-INT J ELECTRON C, V69, P562, DOI 10.1016/j.aeue.2014.11.010
   Rama Parvathi L, 2019, INT J RECENT TECHNOL, V8, P223
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Shatheesh SI, 2011, INT C DISTR COMP INT
   Shen JB, 2005, LECT NOTES COMPUT SC, V3768, P270, DOI 10.1007/11582267_24
   Si Y., 2008, COMPUT TECHNOL DEV, V18, P74
   Sridevi R, 2016, ASIAN J SCI RES, V10, P10, DOI DOI 10.3923/ajsr.2017.10.23
   [王冬梅 Wang Dongmei], 2005, [浙江大学学报. 理学版, Journal of Zhejiang University], V32, P273
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   YE R, 2012, INT J COMPUT NETWORK, V4, P41
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 28
TC 37
Z9 37
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22375
EP 22388
DI 10.1007/s11042-020-08957-9
EA MAY 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534853900002
DA 2024-07-18
ER

PT J
AU Chahal, PK
   Pandey, S
   Goel, S
AF Chahal, Prabhjot Kaur
   Pandey, Shreelekha
   Goel, Shivani
TI A survey on brain tumor detection techniques for MR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor detection systems; Computer-aided diagnosis; Medical
   imaging; Magnetic resonance images; Segmentation; Classification
ID GAUSSIAN MIXTURE MODEL; SUPPORT VECTOR MACHINE; ACTIVE CONTOUR MODEL;
   C-MEANS ALGORITHM; OF-THE-ART; AUTOMATIC SEGMENTATION; TISSUE
   SEGMENTATION; CLUSTERING APPROACH; SLANTLET TRANSFORM; NEURAL-NETWORKS
AB One of the most crucial tasks in any brain tumor detection system is the isolation of abnormal tissues from normal brain tissues. Interestingly, domain of brain tumor analysis has effectively utilized the concepts of medical image processing, particularly on MR images, to automate the core steps, i.e. extraction, segmentation, classification for proximate detection of tumor. Research is more inclined towards MR for its non-invasive imaging properties. Computer aided diagnosis or detection systems are becoming challenging and are still an open problem due to variability in shapes, areas, and sizes of tumor. The past works of many researchers under medical image processing and soft computing have made noteworthy review analysis on automatic brain tumor detection techniques focusing segmentation as well as classification and their combinations. In the manuscript, various brain tumor detection techniques for MR images are reviewed along with the strengths and difficulties encountered in each to detect various brain tumor types. The current segmentation, classification and detection techniques are also conferred emphasizing on the pros and cons of the medical imaging approaches in each modality. The survey presented here aims to help the researchers to derive the essential characteristics of brain tumor types and identifies various segmentation/classification techniques which are successful for detection of a range of brain diseases. The manuscript covers most relevant strategies, methods, their working rules, preferences, constraints, and their future snags on MR image brain tumor detection. An attempt to summarize the current state-of-art with respect to different tumor types would help researchers in exploring future directions.
C1 [Chahal, Prabhjot Kaur; Pandey, Shreelekha] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Goel, Shivani] Bennett Univ, Sch Engn & Appl Sci, Dept Comp Sci, Greater Noida, India.
   [Goel, Shivani] Bennett Univ, Sch Engn & Appl Sci, Engn Dept, Greater Noida, India.
C3 Thapar Institute of Engineering & Technology
RP Chahal, PK (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM prabhjot_kaur@thapar.edu; shreelekha.pandey@thapar.edu;
   shivani.goel@bennett.edu.in
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Afshar P, 2018, IEEE IMAGE PROC, P1458, DOI 10.1109/ICIP.2018.8451759
   Ahmed KB, 2017, PROC SPIE, V10134, DOI 10.1117/12.2253982
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Akkus Z., 2016, ARXIV PREPRINT ARXIV
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Akkus Z, 2015, CANCER IMAGING, V15, P1, DOI 10.1186/s40644-015-0047-z
   Al-Dmour H, 2018, NEUROCOMPUTING, V275, P546, DOI 10.1016/j.neucom.2017.08.051
   Alex V, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041311
   Ali H, 2015, ARAB J SCI ENG, V40, P3173, DOI 10.1007/s13369-015-1791-x
   Ambroise C., 1995, SPATIAL CLUSTERING A
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Angulakshmi M, 2017, INT J IMAG SYST TECH, V27, P66, DOI 10.1002/ima.22211
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   [Anonymous], 2010, Leonardo J Sci
   [Anonymous], 2016, METALS
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025
   Bakas Spyridon, 2016, Brainlesion, V9556, P144, DOI [10.1007/978-3-319-30858-6_13, 10.1007/978-3-319-30858-6_1]
   Balafar MA, 2008, COMM COM INF SC, V15, P177
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Bauer S, 2011, I S BIOMED IMAGING, P2018, DOI 10.1109/ISBI.2011.5872808
   Bauer S, 2010, IEEE ENG MED BIO, P4080, DOI 10.1109/IEMBS.2010.5627302
   Baur C, 2019, LECT NOTES COMPUT SC, V11383, P161, DOI 10.1007/978-3-030-11723-8_16
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Benson CC, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P318, DOI 10.1109/ICACCI.2015.7275628
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   Bhandarkar SM, 1997, NEUROCOMPUTING, V14, P241, DOI 10.1016/S0925-2312(96)00048-3
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Chen H, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P301, DOI [10.1109/ICAIBD.2019.8836968, 10.1109/icaibd.2019.8836968]
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Chen Xiaoran, 2018, ARXIV180604972
   Chen YJ, 2009, COMPUT MED IMAG GRAP, V33, P510, DOI 10.1016/j.compmedimag.2009.04.009
   Chow DS, 2014, AM J NEURORADIOL, V35, P498, DOI 10.3174/ajnr.A3724
   CLARKE LP, 1991, MED PHYS, V18, P673
   Cobzas D, 2007, IEEE I CONF COMP VIS, P2354
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahab D., 2012, INT J IMAGE PROCESSI, V1, P1
   De AL, 2015, NEUROCOMPUTING, V149, P48, DOI 10.1016/j.neucom.2014.02.069
   DEEPA A, 2018, MULTIMED TOOLS APPL, P1
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Demirhan A, 2011, ENG APPL ARTIF INTEL, V24, P358, DOI 10.1016/j.engappai.2010.09.008
   Devi CN, 2015, COMPUT BIOL MED, V64, P163, DOI 10.1016/j.compbiomed.2015.06.016
   Diwakar M, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P53, DOI 10.1109/ICACCI.2013.6637146
   Dolz J, 2016, COMPUT MED IMAG GRAP, V52, P8, DOI 10.1016/j.compmedimag.2016.03.003
   Donoso R, 2010, LECT NOTES COMPUT SC, V6419, P63
   Drozdzal M, 2018, MED IMAGE ANAL, V44, P1, DOI 10.1016/j.media.2017.11.005
   Duda RO., 2012, Pattern classificatio
   Dvorak P., 2015, J. appl. res. technol, V13, P58
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   El-Gamal FEZA, 2018, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2018.8545196
   Epifanio I, 2002, IEEE T IMAGE PROCESS, V11, P859, DOI 10.1109/TIP.2002.801119
   Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7
   Foo JL, 2006, 20062 ISUHCI
   Gaillard AF, 2020, BRAIN TUMORS
   Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Gordillo N, 2010, INT C FUZZ SYST FUZZ, P1, DOI [DOI 10.1109/FUZZY.2010.5584178, 10.1109/FUZZY.2010.5584178.]
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Greenspan H, 2006, IEEE T MED IMAGING, V25, P1233, DOI 10.1109/TMI.2006.880668
   GUPTA MP, 2013, INT J COMPUTERS TECH, V5, P54
   Gupta N, 2017, SIGNAL PROCESS-IMAGE, V59, P18, DOI 10.1016/j.image.2017.05.013
   Gupta S. K., 2016, International Journal of Hospitality & Tourism Systems, V9, P1
   HASAN SK, 2018, ADV ELECT COMMUNICAT, P45
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Hu TM, 2005, PATTERN ANAL APPL, V8, P139, DOI 10.1007/s10044-005-0251-8
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Hussain S, 2017, IEEE ENG MED BIO, P1998, DOI 10.1109/EMBC.2017.8037243
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   IN A, 2016, PROCEDIA COMPUT SCI, V102, P317
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Ji ZX, 2016, J VIS COMMUN IMAGE R, V40, P611, DOI 10.1016/j.jvcir.2016.08.001
   Ji ZX, 2014, NEUROCOMPUTING, V134, P60, DOI 10.1016/j.neucom.2012.12.067
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   Juang LH, 2010, MEASUREMENT, V43, P941, DOI 10.1016/j.measurement.2010.03.013
   Kamboj A, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P599, DOI 10.1109/ICSCCC.2018.8703202
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kaus MR, 2001, RADIOLOGY, V218, P586, DOI 10.1148/radiology.218.2.r01fe44586
   Khotanlou H, 2009, FUZZY SET SYST, V160, P1457, DOI 10.1016/j.fss.2008.11.016
   Koley S, 2016, APPL SOFT COMPUT, V41, P453, DOI 10.1016/j.asoc.2016.01.022
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Lakare S., 2000, 3D SEGMENTATION TECH, P59
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Laukamp KR, 2019, EUR RADIOL, V29, P124, DOI 10.1007/s00330-018-5595-8
   Law AKW, 2002, P ANN INT IEEE EMBS, P1055, DOI 10.1109/IEMBS.2002.1106273
   Lee CH, 2005, LECT NOTES COMPUT SC, V3765, P469
   Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564
   Li CM, 2005, PROC CVPR IEEE, P430
   Liang Yan-Ling, 2014, Biomed Res Int, V2014, P512497, DOI 10.1155/2014/512497
   Lin D, 2016, NEUROCOMPUTING, V216, P700, DOI 10.1016/j.neucom.2016.08.039
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Logeswari T., 2010, INT J COMPUTER THEOR, V2, P591, DOI [10.7763/IJCTE.2010.V2.207, DOI 10.7763/IJCTE.2010.V2.207]
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   LOVELL BC, 2003, P 2003 APRS WORKSH D
   Luo S., 2003, APRS WORKSH DIG IM C
   Maitra M, 2008, MED ENG PHYS, V30, P615, DOI 10.1016/j.medengphy.2007.06.009
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Mathur N, 2016, PROCEDIA COMPUT SCI, V93, P431, DOI 10.1016/j.procs.2016.07.230
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   MCINERNEY T, 2000, HDB MED IMAGING PROC
   Mei PA, 2015, J NEUROL SCI, V359, P78, DOI 10.1016/j.jns.2015.10.032
   Mitchell T M, 2006, DISCIPLINE MACHINE L, V9
   MOHAMMED SJ, 2018, ENG TECHNOLOGY J PAR, V36, P160, DOI DOI 10.30684/ETJ.36.2B.12
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   MOHSEN H, 2012, IEEE 8 INT C INF SYS
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nambura A, 2017, APPL SOFT COMPUT, V54, P456, DOI 10.1016/j.asoc.2016.08.020
   Nie JX, 2009, COMPUT MED IMAG GRAP, V33, P431, DOI 10.1016/j.compmedimag.2009.04.006
   Nimeesha K.M., 2013, Int J Comput Sci Inf Technol Res Excell, V3, P60
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   PANDAV S, 2014, INT J ENG RES TECHNO
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pesteie M, 2019, IEEE T MED IMAGING, V38, P2807, DOI 10.1109/TMI.2019.2914656
   POPURI K, 2009, MED IMAGING 2009, V7259
   Prastawa M, 2003, ACAD RADIOL, V10, P1341, DOI 10.1016/S1076-6332(03)00506-3
   Priya K. M., 2016, 2016 INT C SIGNAL PR, P1
   PRIYA T, 2018, INT S SIGN PROC INT, P322
   Rajendran A, 2012, PROCEDIA ENGINEER, V30, P327, DOI 10.1016/j.proeng.2012.01.868
   Ratan R., 2009, INDIAN J SCI TECHNOL, V2, P11
   Reddick WE, 1997, IEEE T MED IMAGING, V16, P911, DOI 10.1109/42.650887
   Rohlfing T, 2005, TOP BIOMED ENGN, P435
   Ruan S, 2011, I S BIOMED IMAGING, P281, DOI 10.1109/ISBI.2011.5872406
   Ruan S, 2007, I S BIOMED IMAGING, P1236, DOI 10.1109/ISBI.2007.357082
   Rulaningtyas R, 2009, INSTR COMM INF TECHN, V3, P1
   Saad N.M., 2011, IEEE trans. on Signal and Image Processing Applications, P249, DOI [10.1109/icsipa.2011.6144092, DOI 10.1109/ICSIPA.2011.6144092]
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Saha S, 2016, EXPERT SYST APPL, V52, P50, DOI 10.1016/j.eswa.2016.01.005
   SALMAN Y, 2006, IEEE ENG MED BIOL 27, P7048
   Salman Yasser M., 2009, Journal of Biomedical Science & Engineering, V2, P16, DOI 10.4236/jbise.2009.21003
   Seiler C, 2009, RECENT ADVANCES IN THE 3D PHYSIOLOGICAL HUMAN, P133, DOI 10.1007/978-1-84882-565-9_9
   Shah S.A., 2015, BJHMR Br. J. Healthc. Med. Res, V2, P57, DOI [DOI 10.14738/JBEMI.24.1411, 10.14738/jbemi.24.1411]
   Shanthakumar P, 2015, COMPUT ELECTR ENG, V45, P302, DOI 10.1016/j.compeleceng.2015.05.011
   Shanthi KJ, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P422
   Singh L, 2012, LECT NOTES COMPUT SC, V7632, P94, DOI 10.1007/978-3-642-34123-6_9
   Sohn K., 2015, ADV NEURAL INFORM PR, P3483, DOI DOI 10.5555/2969442.2969628
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Subbanna N., 2012, PROC MICCAI BRAIN TU, P28
   Subbanna N, 2014, PROC CVPR IEEE, P400, DOI 10.1109/CVPR.2014.58
   Sujan M., 2016, Int. J. Comput. Appl., V153, P41, DOI DOI 10.5120/IJCA2016912177
   Sun WQ, 2016, PROC SPIE, V9788, DOI 10.1117/12.2216129
   Sung YC, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P1000, DOI 10.1109/ICOSP.2000.891695
   Szilágyi L, 2007, LECT NOTES COMPUT SC, V4633, P866
   Szwarc P, 2015, COMPUT MED IMAG GRAP, V46, P178, DOI 10.1016/j.compmedimag.2015.06.002
   Tanoori B, 2011, COMPUT BIOL MED, V41, P619, DOI 10.1016/j.compbiomed.2011.05.013
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Tseng KL, 2017, PROC CVPR IEEE, P3739, DOI 10.1109/CVPR.2017.398
   Vaidhya Kiran, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P181, DOI 10.1007/978-3-319-30858-6_16
   Vapnik V., 2013, The nature of statistical learning theory
   Vijayakumar C, 2007, COMPUT MED IMAG GRAP, V31, P473, DOI 10.1016/j.compmedimag.2007.04.004
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Vishnuvarthanan A, 2017, APPL SOFT COMPUT, V57, P399, DOI 10.1016/j.asoc.2017.04.023
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wong K-P., 2005, Handbook of Biomedical Image Analysis, P111, DOI DOI 10.1007/0-306-48606-7_3
   Xie K, 2005, EUR J RADIOL, V56, P12, DOI 10.1016/j.ejrad.2005.03.028
   Xue XJ, 2010, I S BIOMED IMAGING, P840, DOI 10.1109/ISBI.2010.5490117
   Yang Z, 2009, APPL SOFT COMPUT, V9, P80, DOI 10.1016/j.asoc.2008.03.009
   Yao J, 2006, IMAGE PROCESSING TUM, P79
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhou J, 2006, INT CONF ACOUST SPEE, P5411
   Zhu Y, 2012, ACAD RADIOL, V19, P977, DOI 10.1016/j.acra.2012.03.026
   Zöllner FG, 2012, Z MED PHYS, V22, P205, DOI 10.1016/j.zemedi.2012.03.007
NR 170
TC 53
Z9 53
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21771
EP 21814
DI 10.1007/s11042-020-08898-3
EA MAY 2020
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531793100003
DA 2024-07-18
ER

PT J
AU Singha, A
   Bhowmik, MK
   Bhattacherjee, D
AF Singha, Anu
   Bhowmik, Mrinal Kanti
   Bhattacherjee, Debotosh
TI Akin-based Orthogonal Space (AOS): a subspace learning method for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subspace; Orthogonalization; Akinity; Liability; Representative score;
   Custom VGG
ID CLASSIFIER; ALGORITHMS
AB A projection learning space is an approach to mapping a high-dimensional vector space to a lower dimensional vector space. In this paper, we proposed an algorithm, namely, AOS: Akin based Orthogonal Space. The algorithm is driven with two major targets - (i) to choose most representative image(s) from a group of face images of an individual, (ii) finally to produce a learning space which follows a Gaussian distribution to reduce the influence of grosses like non-Gaussianly distributed data noises, variations in facial expression and illumination. To improve the recognition performance, we proposed another approach i.e. fusion between AOS features and a custom VGG features. We justify the effectiveness of the proposed approaches over five benchmark face datasets using two classifiers. Experimental results show that the proposed learning algorithm has obtained maximum of 92.22% recognition rate, as well deep learning based fusion approch greatly improves the recognition accuracy. The comparative performances demonstrate that the proposed method could significantly outperform other relevant subspace learning methods.
C1 [Singha, Anu; Bhowmik, Mrinal Kanti] Tripura Univ, Dept Comp Sci & Engn, Agartala, India.
   [Bhattacherjee, Debotosh] Jadhavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Tripura University; Jadavpur University
RP Singha, A (corresponding author), Tripura Univ, Dept Comp Sci & Engn, Agartala, India.
EM anusingh5012@gmail.com; mrinalkantibhowmik@tripurauniv.in;
   debotosh@ieee.org
RI Bhowmik, Mrinal Kanti/AAY-8356-2020; Singha, Dr. Anu/AAY-8345-2021
OI Bhowmik, Mrinal Kanti/0000-0003-3451-191X; Singha,
   Anu/0000-0002-5149-0594
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhowmik MK, 2019, EXPERT SYST APPL, V116, P96, DOI 10.1016/j.eswa.2018.08.047
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cao C, 2015, J COMPUT SCI TECH-CH, V30, P499, DOI 10.1007/s11390-015-1540-3
   Cazzanti L., 2007, Proc. ICML, P137
   Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425
   Chen L, 2013, IEEE IMAGE PROC, P3367, DOI 10.1109/ICIP.2013.6738694
   Fagertun J, 2011, LECT NOTES COMPUT SC, V6688, P69, DOI 10.1007/978-3-642-21227-7_7
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Gantmacher F-R, 1959, THEORY MATRICES
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Hall P. M., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P286
   He X., 2004, IEEE T PAMI, V27, P328
   He XF, 2004, ADV NEUR IN, V16, P153
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hou CP, 2009, IEEE SIGNAL PROC LET, V16, P303, DOI 10.1109/LSP.2009.2014283
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kim TK, 2010, IEEE T IMAGE PROCESS, V19, P1067, DOI 10.1109/TIP.2009.2038621
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P756, DOI 10.1109/TCE.2011.5955219
   Kittler J., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P42
   Klami A, 2013, J MACH LEARN RES, V14, P965
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Liang JZ, 2017, IEEE ACCESS, V5, P17201, DOI 10.1109/ACCESS.2017.2741223
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Papachristou K, 2014, IEEE T IMAGE PROCESS, V23, P5683, DOI 10.1109/TIP.2014.2367321
   Phillips PJ, 2005, P IEEE COMP SOC C CO
   Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346
   Singha A, 2019, IEEE T CIRCUITS SYST
   Singha A, 2018, IEEE INT CONF ADV LE, P419, DOI 10.1109/ICALT.2018.00106
   Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494
   Tang LL, 2019, MULTIMED TOOLS APPL, V78, P32485, DOI 10.1007/s11042-019-07943-0
   Tang LL, 2019, MULTIMED TOOLS APPL, V78, P32007, DOI 10.1007/s11042-019-07897-3
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Wang SF, 2013, IEEE T AFFECT COMPUT, V4, P34, DOI 10.1109/T-AFFC.2012.32
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Weisstein E. W., MATHWORLD
   Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034, DOI 10.1109/TPAMI.2003.1217609
   WIGNER EP, 1958, ANN MATH, V67, P325, DOI 10.2307/1970008
   WILK MB, 1968, BIOMETRIKA, V55, P1
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Yang J, 2007, IEEE T SYST MAN CY B, V37, P1015, DOI [10.1109/TSMCB.2007.891541, 10.1109/TSMCB.2006.891541]
   Zhang L, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P217, DOI 10.1109/ICIAP.2007.4362782
NR 48
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35069
EP 35091
DI 10.1007/s11042-020-08892-9
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000531793100001
DA 2024-07-18
ER

PT J
AU Azza, AA
   Lian, SG
AF Azza, A. A.
   Lian, Shiguo
TI Multi-secret image sharing based on elementary cellular automata with
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SS; ISS; VSS; CA; MSIS; RECA
ID SCHEME
AB This paper presents a new Multi-Secret Image Sharing (MSIS) scheme with steganography, based on elementary cellular automata (ECA). A particular type of ECA, with behavior of generating some attractors which are called unary attractors, is used to share the secret images. The shares and the authentication strings, produced by a cryptographic hash function, are then embedded in color images using mod4-based operation in such a way that visual quality of stego are preserved as much as possible. The proposed scheme is verifiable as well, because a cryptographic hash function is used for secret images. Based on our experiments, the share images satisfy randomization which ensures the security of the proposed algorithm. Also, influence of similarity of some secret images is analyzed, the results ensures the completely deference between the shared images in the case of the similarity between two secret images. Moreover, the experimental results show that the embedded algorithm improves a good quality acceptable by a human eye of stego images. In addition, the proposed embedded algorithm has a good resistance against noise attack, and cropping attack. Compared with related secret sharing schemes, the proposed scheme provides most of desirable aspects such as verification, hiding shares, and also a linear computational complexity.
C1 [Azza, A. A.] Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Coll Sci & Human, Jubail Ind City, Saudi Arabia.
   [Azza, A. A.] Menoufia Univ, Fac Sci, Dept Math, Comp Sci, Shibin Al Kawm 32511, Egypt.
   [Lian, Shiguo] Huawei Technol, Cent Res Inst, Beijing, Peoples R China.
C3 Imam Abdulrahman Bin Faisal University; Egyptian Knowledge Bank (EKB);
   Menofia University; Huawei Technologies
RP Azza, AA (corresponding author), Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Coll Sci & Human, Jubail Ind City, Saudi Arabia.; Azza, AA (corresponding author), Menoufia Univ, Fac Sci, Dept Math, Comp Sci, Shibin Al Kawm 32511, Egypt.
EM aaaali@iau.edu.sa; asg_lian@163.com
RI A, Azza A/AAC-9225-2019
OI A, Azza A/0000-0001-8246-9790
CR Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   Ahmed M., 2017, INT C ADV INT SYST I, P832
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Alvarez G, 2008, INFORM SCIENCES, V178, P4382, DOI 10.1016/j.ins.2008.07.010
   Anghelescu P, 2005, PSEUDORANDOM PATTERN, P41
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chen C, 2017, MODERN FOOD SCI TECH, V33, P1
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   del Rey AM, 2005, APPL MATH COMPUT, V170, P1356, DOI 10.1016/j.amc.2005.01.026
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Esposito C, 2018, IEEE T IND INFORM, V14, P4972, DOI 10.1109/TII.2018.2853676
   Fúster-Sabater A, 2006, ACTA APPL MATH, V93, P215, DOI 10.1007/s10440-006-9041-6
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Hu WT, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/849768
   Jeon JC, 2008, MATH COMPUT SIMULAT, V79, P1197, DOI 10.1016/j.matcom.2007.09.006
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Kim HS, 2003, LNCS, V2802, P227
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Miros LS, 2008, INTELL INF SYST, P99
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Rukhin A, 2008, NIST SPECIAL PUBL, V1, P800
   Seredynski M, 2004, LECT NOTES COMPUT SC, V3305, P785
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Somanath T, 2009, INT J NETW SECUR, V8, P243
   Tso HK, 2008, OPT ENG, V47, DOI 10.1117/1.2955502
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yassein MB, 2016, FOUND SCI, V60, P67
   Yu L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P32, DOI 10.1109/CISP.2008.48
   Zarepour-Ahmadabadi J, 2018, MULTIMED TOOLS APPL, V77, P24073, DOI 10.1007/s11042-018-5717-y
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
NR 38
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21241
EP 21264
DI 10.1007/s11042-020-08823-8
EA MAY 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530228700001
DA 2024-07-18
ER

PT J
AU Chen, ZX
   Li, JD
   Liu, CY
AF Chen, Zhenxue
   Li, Jiadi
   Liu, Chengyun
TI Face hallucination with K-means plus plus dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-resolution; Face hallucination; K-means plus plus clustering; LARS;
   Dictionary pair
ID IMAGE SUPERRESOLUTION; RECOGNITION; RESOLUTION; SELECTION
AB Interested face regions have the low-resolution problem in the video surveillance because the distance between face and camera is far. Thus, the high-resolution (HR) faces need to be reconstructed from low-resolution (LR) faces for further processing. Typical face hallucination based on patch-wise sparse coding can achieve better results but have very high complexity for training. In order to reduce the complexity, this paper proposes a method which uses K-means++ clustering instead of sparse coding to obtain an over-complete dictionary pair. Then, the least angle regression (LARS) algorithm is utilized to calculate the coefficients and reconstruct the high-resolution faces. The experimental results show that proposed algorithm can effectively reduce complexity in condition of irregular LR faces. In addition, the comparisons also prove that the proposed method can improve the value of PSNR and SSIM in the same database.
C1 [Chen, Zhenxue; Li, Jiadi; Liu, Chengyun] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Chen, Zhenxue] Shandong Univ, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 Shandong University; Shandong University
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.; Chen, ZX (corresponding author), Shandong Univ, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
EM chenzhenxue@sdu.edu.cn; 476681287@qq.com; liuchengyun@sdu.edu.cn
RI YAN, LING/JXY-6904-2024; li, jiadi/HIR-6665-2022; luo,
   yuan/JLS-6416-2023; chen, qiang/JXY-6982-2024
OI Chen, Zhenxue/0000-0001-9637-5170
CR Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Gosling C, 2010, ENCY DISTANCES REFER
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Hornik K, 2012, J STAT SOFTW, V50, P1
   Huang KB, 2012, INT C PATT RECOG, P882
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2016, IEEE CONF COMPUT
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee H, 2007, DESC P M 3 6 DEC 200, P801
   Liong VE, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING (ICICS)
   Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1265, DOI 10.1109/TNNLS.2018.2861209
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan Y, 2019, IEEE ACCESS, V7, P16132, DOI 10.1109/ACCESS.2019.2894590
NR 34
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11685
EP 11698
DI 10.1007/s11042-019-08505-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400019
DA 2024-07-18
ER

PT J
AU Iqbal, CMM
   Riaz, MM
   Iltaf, N
   Ghafoor, A
   Ali, SS
AF Iqbal, M. Munawwar Ch
   Riaz, M. Mohsin
   Iltaf, Naima
   Ghafoor, Abdul
   Ali, Syed Sohaib
TI A multifocus image fusion using highlevel DWT components and guided
   filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Gradients; Guided filter; Majority filter; Weight map
AB It is often difficult and essential to distinguish between focused and de-focused structures in an image. To properly handle such structures, an image fusion technique is developed for multifocus images using high level discrete wavelet components and guided filter. The source images are decomposed using wavelet transform and high level components are processed using gradient magnitude and guided filters to obtain fusion weights to refine the fusion process. Variety of images obtained from standard datasets are used in the simulations to test performance of proposed technique. The fused image obtained using proposed technique outperforms visually and quantitatively as compared to existing techniques.
C1 [Iqbal, M. Munawwar Ch; Iltaf, Naima; Ghafoor, Abdul] Natl Univ Sci & Technol, Islamabad, Pakistan.
   [Riaz, M. Mohsin; Ali, Syed Sohaib] COMSATS Univ, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Riaz, MM (corresponding author), COMSATS Univ, Islamabad, Pakistan.
EM munawwar.phdcse@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   naima@mcs.edu.pk; abdulghafoor-mcs@nust.edu.pk;
   sohaib.ali@comsats.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Syed, Sohaib
   Ali/0000-0003-4795-7275; Ghafoor, Abdul/0000-0002-6117-3656
CR Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   [Anonymous], 2015, INT J SIGNAL PROCESS, DOI DOI 10.14257/IJSIP.2015.8.2.16
   Bavirisetti Durga Prasad, 2016, AIN SHAMS ENG J
   Cai JJ, 2017, INFRARED PHYS TECHN, V82, P85, DOI 10.1016/j.infrared.2017.01.026
   Chaudhary V, 2018, SIGNAL IMAGE VIDEO P, V12, P271, DOI 10.1007/s11760-017-1155-y
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Garnica-Carrillo A, 2018, SIGNAL IMAGE VIDEO P, P1
   Haghighat M., 2014, 2014 IEEE 8th Int. Conf. on Application of Information and Communication Technologies (AICT), P1, DOI DOI 10.1109/ICAICT.2014.7036000
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu SY, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6918381
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Mustafa HT, 2019, LECT NOTES ARTIF INT, V11508, P153, DOI 10.1007/978-3-030-20912-4_15
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang Y, 2017, SIGNAL IMAGE VIDEO P, V11, P439, DOI 10.1007/s11760-016-0979-1
   Zhan K., 2015, J INF HIDING MULTIME, V6, P600
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063004
   Zhang YX, 2019, SIGNAL IMAGE VIDEO P, V13, P727, DOI 10.1007/s11760-018-1402-x
   Zhang YX, 2014, SIGNAL PROCESS, V105, P84, DOI 10.1016/j.sigpro.2014.05.015
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
NR 28
TC 13
Z9 13
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12817
EP 12828
DI 10.1007/s11042-020-08661-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700003
DA 2024-07-18
ER

PT J
AU Jin, X
   Han, Q
   Li, XD
   Wu, CQ
   Sun, HB
   Liu, RJ
AF Jin, Xin
   Han, Qing
   Li, Xiaodong
   Wu, Chuanqiang
   Sun, Hongbo
   Liu, Ruijun
TI Efficient blind face recognition in the cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy protection; Face recognition; Sparse representation; Cloud
   computing; Homomorphic encryption; Deep neural network; Deep learning
AB Nowadays, with the maturity and wide application of face recognition technology, the recognition accuracy, recognition efficiency, and data security have attracted people's attention. However, when face recognition is performed, face information is completely exposed to the cloud server without any protection measures. Therefore, a series of problems caused by insecure face information is coming. Can we find a way to prevent uncontrolled use of facial information without cloud protection and improve recognition efficiency and accuracy? Given this situation, we have proposed two options. The first requires a third-party library; the second does not require a third-party library. The first scheme is efficient privacy preserving face identification in the cloud through sparse representation, which relies on the third-party face image database, and the first scheme is simply referred to as SRBased. The second scheme is efficient privacy preserving face identification in the cloud based on deep neural network, which does not depend on the third-party face image database, and the second scheme is simply referred to as DNNBased. Both schemes can be divided into two parts: client and cloud server. The client is responsible for acquiring face images, and the server is responsible for recognizing and calculating. Through homomorphic encryption and OT protocol, secure face recognition is realized. In the whole recognition process, the server does not need to decrypt the image data. In the two schemes, the client and the server will not get any information from each other. Even if the third party intercepts the ciphertext in the transmission process, it will not get any information under the premise of private key security. Therefore, the two schemes can achieve the purpose of protecting privacy and security. The experimental results show that the efficiency of the two schemes is greatly improved compared with SCiFI schemes. The second scheme improves recognition accuracy greatly.
C1 [Jin, Xin; Li, Xiaodong; Sun, Hongbo] Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
   [Jin, Xin; Li, Xiaodong; Wu, Chuanqiang] CETC Big Data Res Inst Co Ltd, Guiyang 550022, Guizhou, Peoples R China.
   [Jin, Xin; Li, Xiaodong] Big Data Applicat Improving Govt Governance Capab, Guiyang 550022, Guizhou, Peoples R China.
   [Jin, Xin; Li, Xiaodong; Liu, Ruijun] Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
   [Han, Qing] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; Beijing Technology &
   Business University; Xidian University
RP Li, XD (corresponding author), Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.; Li, XD (corresponding author), CETC Big Data Res Inst Co Ltd, Guiyang 550022, Guizhou, Peoples R China.; Li, XD (corresponding author), Big Data Applicat Improving Govt Governance Capab, Guiyang 550022, Guizhou, Peoples R China.; Li, XD (corresponding author), Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing 100048, Peoples R China.
EM lxd@besti.edu.cn
RI liang, liang/IAO-8518-2023; li, xiao/GSN-6181-2022; li,
   xiao/HJP-5134-2023; han, qing/KCZ-0174-2024; li, xiaofeng/GXF-9442-2022;
   Han, Qing-Long/B-6635-2013; jin, xin/GQZ-5811-2022; Liu,
   Ruijun/AAA-4250-2020
OI Han, Qing-Long/0000-0002-7207-0716; Liu, Ruijun/0000-0003-4871-8989
CR Luong A, 2013, IEEE WORK APP COMP, P238, DOI 10.1109/WACV.2013.6475024
   [Anonymous], 2017, P IEEE C COMP VIS PA
   H Wang, 2018, ARXIV180109414
   Harn L, 1991, OBLIVIOUS TRANSFER P
   Jin X, 2015, LECT NOTES COMPUT SC, V9428, P160, DOI 10.1007/978-3-319-25417-3_20
   Li X, 2018, 8 INT C VIRT REAL VI
   Liao X, 2017, DATA EMBEDDING DIGIT
   Liao X, 2016, MULTIMEDIA TOOLS APP
   Liao X, 2017, MULTIMEDIA TOOLS APP, V77
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Ma YK, 2017, IEEE ACCESS, V5, P16532, DOI 10.1109/ACCESS.2017.2737544
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Runhua S, 2014, ACTA ELECT SINICA, V42, P2273
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
NR 18
TC 2
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12533
EP 12550
DI 10.1007/s11042-019-08280-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400056
DA 2024-07-18
ER

PT J
AU Malik, A
   Wang, HX
   Chen, YL
   Khan, AN
AF Malik, Asad
   Wang, Hong-Xia
   Chen, Yanli
   Khan, Ahmad Neyaz
TI A reversible data hiding in encrypted image based on prediction-error
   estimation and location map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Cloud computing; Image encryption;
   Prediction-error; Image recovery
ID HIGH-CAPACITY; WATERMARKING; PROTECTION
AB In recent decades, visual privacy of digital data has gained much attention from the researchers, especially in cloud-based services. The efficacy of Reversible Data Hiding in Encrypted Images (RDHEI) cannot be ignored as it meets the requirements of visual privacy and data security. Generally, it comprises three different stakeholders namely content owner, data hider, and receiver. The original image is encrypted, by the content owner, using encryption function. After encryption, there is still a possibility for the data hider/cloud-owner to embed the additional data in it. At the receiver end, the embedded data and the original image are recovered losslessly. In our proposed RDHEI scheme, the room is reserved for the data hider before image encryption, by the content owner. Firstly, the image is preprocessed using the prediction-error estimation method to create spare space. Next, the location map is created to capture the information whether a particular location can be used for embedding or not. After this, image encryption is done through standard stream cipher and the compressed location map is embedded. Furthermore, the data hider (without having any knowledge of the original image and the encryption key) embeds the additional data into the Most Significant Bits (MSBs) of the assigned locations using the data hiding key. Finally, at the receiver's side, the additional data is recovered flawlessly using the data hiding key and the location map. And the original image is reconstructed with the help of the decryption key and the location map. Besides, the approximate image is recovered using the decryption key without the use of location map. Experimental results validate that our proposed scheme outperforms most of the existing schemes in terms of embedding capacity and reconstructed image quality. Additionally, the quality of recovered image without using data hiding key, that is the image recovered prior to losslessly recovered image, is relatively better than most of the methods used in recent works.
C1 [Malik, Asad; Chen, Yanli] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.
   [Wang, Hong-Xia] Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
   [Khan, Ahmad Neyaz] Univ Elect Sci & Technol China, Chengdu 611731, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University; University of
   Electronic Science & Technology of China
RP Wang, HX (corresponding author), Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
EM asad@my.swjtu.edu.cn; hxwang@scu.edu.cn; yanli027@163.com;
   ahmadnk@std.uestc.edu.cn
RI Li, Yan/JUU-5189-2023; Malik, Asad/AAD-8494-2020; KHAN, AHMAD
   NEYAZ/AAT-9018-2020; Wang, Hongxia/AAE-2135-2022
OI Malik, Asad/0000-0002-9976-3563; KHAN, AHMAD NEYAZ/0000-0002-2783-4190; 
CR [Anonymous], 2011, P 13 INF HID C PRAG
   Barni M, 2001, IEEE COMMUN MAG, V39, P90, DOI 10.1109/MCOM.2001.940043
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Di FQ, 2018, MULTIMED TOOLS APPL, V77, P20917, DOI 10.1007/s11042-017-5498-8
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Lin J, 2019, J INF HIDING MULTIME, V10, P408
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2019, INT J DIGIT CRIME FO, V11, P46, DOI 10.4018/IJDCF.2019010104
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2013, ADV INTEL SYS RES, V84, P869
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tian HW, 2013, IEEE T CYBERNETICS, V43, P2190, DOI 10.1109/TCYB.2013.2245415
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yao H, 2018, IEEE ACCESS, V6, P40569, DOI 10.1109/ACCESS.2018.2858858
   Yi S, 2016, IEEE SYS MAN CYBERN, P4819, DOI 10.1109/SMC.2016.7844991
   Yin Z., 2014, SCI WORLD J, V2014
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang S, 2014, J APPL MATH, DOI 10.1155/2014/861782
   Zhang W, 2019, J REAL-TIME IMAGE PR, V16, P697, DOI 10.1007/s11554-018-0811-y
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 39
TC 32
Z9 33
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11591
EP 11614
DI 10.1007/s11042-019-08460-w
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LJ2WK
UT WOS:000530029800003
DA 2024-07-18
ER

PT J
AU Saha, S
   Chakraborty, A
   Chatterjee, A
   Dhargupta, S
   Ghosal, SK
   Sarkar, R
AF Saha, Shaswata
   Chakraborty, Anuran
   Chatterjee, Agneet
   Dhargupta, Souvik
   Ghosal, Sudipta Kr
   Sarkar, Ram
TI Extended exploiting modification direction based steganography using
   hashed-weightage Array
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Cover image; Hashing; Embedding capacity; Payload
ID IMAGE; SUBSTITUTION
AB Steganography is the method of hiding secret message information in various cover media like text, image, audio, video and others without raising suspicion to intruders about the existence of any such information. Exploiting Modification Direction (EMD) based image steganography is a steganographic technique designed by Zhang and Wang in 2006 that yields minute distortion of the cover image. In this paper, an Extended EMD based steganography using Hashed-Weightage Array abbreviated as EEMDHW has been proposed. 2(KN)-ary numbers are embedded in every K pixels of the cover image, where N denotes the number of bits embedded in each pixel. Thus, the payload is purely variable in this technique. Embedding is performed using dynamic weightage array. This array is made pseudo random by applying eliminative hashing technique on the message pixels. Experimental results show that the technique is superior to other state-of-the-art techniques in terms of embedding capacity (payload) and has reduced quality distortion of cover image. Steganalysis using RS attack shows that the embedding done by the proposed method cannot be detected upto 3 bits per pixel (bpp) embedding rate.
C1 [Saha, Shaswata; Chakraborty, Anuran; Chatterjee, Agneet; Dhargupta, Souvik; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Ghosal, Sudipta Kr] Nalhati Govt Polytech, Dept Comp Sci & Technol, Pin 731243, Nalhati, India.
C3 Jadavpur University
RP Ghosal, SK (corresponding author), Nalhati Govt Polytech, Dept Comp Sci & Technol, Pin 731243, Nalhati, India.
EM sudipta.ghosal@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; SAHA, SHASWATA/0000-0003-1834-0495
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abdulla A. A., 2015, EXPLOITING SIMILARIT
   Abdulla AA., 2014, LECT NOTES COMPUTER, DOI [10.1007/978-3-319-14054-4_10, DOI 10.1007/978-3-319-14054-4_10]
   Al Ataby AA, 2011, P 4 INT C DEV ESYSTE, DOI [10.1109/DeSE.2011.13, DOI 10.1109/DESE.2011.13]
   Alia M. A., 2010, EUR J SCI RES
   [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   [Anonymous], 2014, 2014 INT C INFORMATI
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Carpentieri B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5322
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang C.-C., 2005, Advances in Multimedia Information Processing-PCM 2004, P731, DOI DOI 10.1007/978-3-540-30543-991
   Chang C. C., 2007, P 3 INT C INT INF HI, DOI [10.1109/IIHMSP.2007.4457590, DOI 10.1109/IIHMSP.2007.4457590]
   Chatterjee A, 2020, MULTIMED TOOLS APPL, V79, P11747, DOI 10.1007/s11042-019-08472-6
   Chaudhary D., 2015, INT J BIG DATA SECUR, DOI [10.21742/ijbdsi.2015.2.2.01, DOI 10.21742/IJBDSI.2015.2.2.01]
   Dhargupta S, 2019, MULTIMED TOOLS APPL, V78, P17589, DOI 10.1007/s11042-018-7123-x
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Ghasemi E., 2011, IMECS 2011 INT MULTI
   Ghosal SK, 2019, J INF SECUR APPL, V46, P320, DOI 10.1016/j.jisa.2018.04.003
   Hamid N., 2012, INT J COMPUT SCI SEC
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   HUYNH NT, 2016, INDIAN J SCI TECHNOL, V9, pNI272, DOI DOI 10.17485/ijst/2016/v9i28/92733
   Leng HS, 2019, MULTIMED TOOLS APPL, V78, P18363, DOI 10.1007/s11042-019-7228-x
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YJ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010019
   Mao Q, 2015, IET IMAGE PROCESS, V9, P1073, DOI 10.1049/iet-ipr.2015.0065
   Pan ZB, 2015, IET IMAGE PROCESS, V9, P22, DOI 10.1049/iet-ipr.2014.0310
   Rabie T., 2012, 4 INT C NETW DIG TEC, P217, DOI DOI 10.1007/978-3-642-30567-2_18
   Rehman A, 2019, J INF SCI, V45, P767, DOI 10.1177/0165551518816303
   Saha S, 2018, ELECTRON LETT, V54, P498, DOI 10.1049/el.2017.3336
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Tayal N, 2017, MULTIMED TOOLS APPL, V76, P24063, DOI 10.1007/s11042-016-4111-x
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Yaseen Z.F., P 2019 2 SCI C COMP, P75, DOI [10.1109/SCCS.2019.8852625, DOI 10.1109/SCCS.2019.8852625]
   Yin ZX, 2015, IET IMAGE PROCESS, V9, P300, DOI 10.1049/iet-ipr.2014.0159
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 38
TC 12
Z9 12
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20973
EP 20993
DI 10.1007/s11042-020-08951-1
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529466500001
DA 2024-07-18
ER

PT J
AU Mahmoud, AM
   Karamti, H
   Hadjouni, M
AF Mahmoud, Abeer M.
   Karamti, Hanen
   Hadjouni, Myriam
TI A hybrid late fusion-genetic algorithm approach for enhancing CBIR
   performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; CBIR; Late fusion; Global descriptors
ID FEATURE-SELECTION; IMAGE; RETRIEVAL; FEATURES; COLOR; SHAPE;
   CLASSIFICATION; ADAPTATION; DESCRIPTOR; MODEL
AB Accurate discrimination of images features is a main success factor towards efficient content-based image retrieval systems. These features can be extracted using local and/or global descriptors. Researchers efforts showed that, hybrid descriptors reported superior results compared to methods that use single descriptor, where hybridization certainly complements benefits from different perspectives. Genetic Algorithm (GA) is a heuristic computational intelligence approach that can be used to achieve the optimal satisfactory user image retrieval requests. In this paper, a new hybrid efficient and effective evolutionary retrieval approach (CBIR-GAF) based on late fusion of four global descriptors is proposed. Each descriptor produces a list of retrieved similar images to user query image and if these lists are merged correctly by late fusion, the results are improved. Thus, GA occurs to assign different weights to each retrieved image while merging, and then it optimizes these weights with a suitable fitness function to select optimum heterogeneous retrieved images. The proposed approach is evaluated on two benchmark datasets (Inria Holidays and Oxford5k), and reported a promising results where it enhanced the average accuracy in comparison of literature techniques.
C1 [Mahmoud, Abeer M.; Karamti, Hanen; Hadjouni, Myriam] Princess Nourah bint Abdulrahman Univ, Dept Comp Sci, Coll Comp & Informat Sci, POB 84428, Riyadh, Saudi Arabia.
   [Mahmoud, Abeer M.] Ain Shams Univ, Dept Comp Sci, Fac Comp & Informat Sci, Cairo, Egypt.
   [Karamti, Hanen] Univ Sfax, MIRACL Lab, ISIMS, BP 242, Sfax 3021, Tunisia.
   [Hadjouni, Myriam] Univ Sousse, Higher Inst Comp Sci & Telecom ISITCom, Sousse, Tunisia.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Ain Shams University; Universite de Sfax; Multimedia, InfoRmation
   Systems & Advancing Computing Laboratory (MIRACL); Universite de Sousse
RP Mahmoud, AM (corresponding author), Princess Nourah bint Abdulrahman Univ, Dept Comp Sci, Coll Comp & Informat Sci, POB 84428, Riyadh, Saudi Arabia.; Mahmoud, AM (corresponding author), Ain Shams Univ, Dept Comp Sci, Fac Comp & Informat Sci, Cairo, Egypt.
EM ammahmoud@pnu.edu.sa; karamti.hanen@gmail.com; Hadjouni.myriam@gmail.com
RI Hadjouni, Myriam/AHA-0671-2022
OI Hadjouni, Myriam/0000-0001-9070-6821; M.Mahmoud,
   Abeer/0000-0002-0362-0059; karamti, hanen/0000-0001-5162-2692
FU Deanship of Scientific Research at Princess Nourah bint Abdulrahman
   University through the Fast-track Research Funding Program
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through the Fast-track
   Research Funding Program.
CR Al-Sahaf H, 2017, IEEE T EVOLUT COMPUT, V21, P83, DOI 10.1109/TEVC.2016.2577548
   Ali N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157428
   [Anonymous], 2016, PROC INT C LEARN REP
   [Anonymous], 2008, PATTERN RECOGNIT
   [Anonymous], 2016, ECCV
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   [Anonymous], 2017, 2017 2 IEEE INT C
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Barley A., 2014, Journal of Data Analysis and Information Processing, V02, P67, DOI DOI 10.4236/JDAIP.2014.23009
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belattar K, 2018, INT J APPL METAHEUR, V9, P48, DOI 10.4018/IJAMC.2018040103
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Boparai NK, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P944, DOI 10.1109/NGCT.2015.7375260
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cieplinski L., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P11
   Ciocca G, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061408
   De K, 2018, IMAGE ANAL STEREOL, V37, P105, DOI 10.5566/ias.1534
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Galí M, 2012, EXPEDICION DE CIRCUNNAVEGACION MALASPINA 2010: CAMBIO GLOBAL Y EXPLORACION DE LA BIODIVERSIDAD DEL OCEANO: LIBRO BLANCO DE METODOS Y TECNICAS DE TRABAJO OCEANOGRAFICO, P243
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2019, IEEE INTERNET THINGS
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gopal N, 2015, NAT CONF COMPUT VIS
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Karamti H, 2018, MULTIMED TOOLS APPL, V77, P5475, DOI 10.1007/s11042-017-4463-x
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kurchaniya D, 2017, INT RES J ENG TECHNO, V4, P2395
   Li L, 2018, SURVEY RECENT ADV TE, P1801
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madhavi KV, 2016, PROCEDIA COMPUT SCI, V79, P254, DOI 10.1016/j.procs.2016.03.033
   Mehmood Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8217250
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mukherjee A., 2016, INT J INNOV RES COMP, V4, P20142
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ortiz-Jaramillo B, 2010, 10 QUANT INFR THERM
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Radenovic F, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P587, DOI 10.1145/2671188.2749366
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Razavian A. S., 2015, P ICLR
   Razavian AS, 2016, JITE T MTA
   Said GAENA, 2014, INT J ADV COMPUT SC, V5, P1
   Salem ABM, 2003, ADV SOFT COMP, P221
   Sharma P, 2017, OPTIK, V145, P346, DOI 10.1016/j.ijleo.2017.04.102
   Stathopoulos S, 2015, COMPUT MED IMAG GRAP, V39, P27, DOI 10.1016/j.compmedimag.2014.05.009
   Teran L, 2014, LECT NOTES COMPUT SC, V8689, P159, DOI 10.1007/978-3-319-10590-1_11
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P7633, DOI 10.1007/s11042-016-3416-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CH, 2009, PATTERN RECOGN, V42, P386, DOI 10.1016/j.patcog.2008.08.019
   Wu H, 2017, J SENSORS, V2017, DOI 10.1155/2017/8513949
   Wu H, 2015, NEUROCOMPUTING, V147, P387, DOI 10.1016/j.neucom.2014.06.046
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zou YH, 2014, PATTERN RECOGN LETT, V38, P54, DOI 10.1016/j.patrec.2013.11.004
NR 64
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20281
EP 20298
DI 10.1007/s11042-020-08825-6
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558430400003
DA 2024-07-18
ER

PT J
AU Esmaeili, V
   Shahdi, SO
AF Esmaeili, Vida
   Shahdi, Seyed Omid
TI Automatic micro-expression apex spotting using Cubic-LBP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression; LBP-TOP; Cubic-LBP; Apex frame
ID LOCAL BINARY PATTERNS; OPTICAL-FLOW; RECOGNITION
AB The main way to communicate is through non-verbal expressions, although it could totally be manipulated by the person to give false expression. Unlike ordinary facial expressions, facial micro-expression has characterized by subtle movement and short duration of appearance which unleashes the true expression beyond the control of the person. Due to the nature of micro-expression which is very brief in time and low in intensity, prevalent methods could not come up with its challenges. One of the well-known dynamic texture descriptors is Local Binary Patterns on Three Orthogonal Planes (LBP-TOP) which mainly lacks in grabbing most vital information. To address this issue in this paper, we propose a novel feature extractor called Cubic-LBP that computes LBP on fifteen introduced planes. We demonstrate the effectiveness of these planes to find the apex frame where maximum facial movements within video sequences have occurred. Moreover, the whole process of spotting the apex frame in this paper is done automatically. Achieving results of apex frame spotting is satisfying on CASME and CASME II databases in comparison with most relevant state-of-the-art methods.
C1 [Esmaeili, Vida; Shahdi, Seyed Omid] Islamic Azad Univ, Qazvin Branch, Fac Elect Biomed & Mechatron Engn, Nokhbegan Blvd, Qazvin, Iran.
C3 Islamic Azad University
RP Shahdi, SO (corresponding author), Islamic Azad Univ, Qazvin Branch, Fac Elect Biomed & Mechatron Engn, Nokhbegan Blvd, Qazvin, Iran.
EM V.Esmaeili@qiau.ac.ir; shahdi@qiau.ac.ir
RI Shahdi, Seyed Omid/AAV-8113-2021; Esmaeili, Vida/AAB-9907-2022
OI Shahdi, Seyed Omid/0000-0002-1827-1883; Esmaeili,
   Vida/0000-0002-1840-8659
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   ALLAERT B, 2018, COMPUTER VISION PATT
   [Anonymous], 2014, P 2014 ASIAN C COMPU
   [Anonymous], 2019, Computer Aided Design and Applications
   [Anonymous], 2016, ASIAN C COMPUTER VIS
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   Bhall RK, 2015, Int J Educ Sci Res Rev (IJESRR), V2
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison C, 2014, TRANSLATION AS COLLABORATION: VIRGINIA WOOLF, KATHERINE MANSFIELD AND S. S. KOTELIANSKY, P111
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Guo YJ, 2014, IEEE IJCNN, P3473, DOI 10.1109/IJCNN.2014.6889620
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li Xueyi, 2013, ScientificWorldJournal, V2013, P624512, DOI 10.1155/2013/624512
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Ma HY, 2017, I S INTELL SIG PROC, P281, DOI 10.1109/ISPACS.2017.8266489
   Merghani W, 2018, COMPUTER VISION PATT
   Moilanen A, 2014, INT C PATT RECOG, P1722, DOI 10.1109/ICPR.2014.303
   Nonis F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183904
   Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Ruiz Ruiz Jorge Carlos, 2013, ISRN Biotechnol, V2013, P341974, DOI 10.5402/2013/341974
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Yan WJ, 2013, IEEE INT CONF AUTOMA
   Yan WJ, 2015, LECT NOTES COMPUT SC, V8925, P296, DOI 10.1007/978-3-319-16178-5_20
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 33
TC 13
Z9 15
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20221
EP 20239
DI 10.1007/s11042-020-08737-5
EA APR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526210000001
DA 2024-07-18
ER

PT J
AU Arunkumar, P
   Shantharajah, P
AF Arunkumar, P.
   Shantharajah, P.
TI Implementation of enhanced canny recognition algorithm and non - natural
   neural system based speech fusion for sightless persons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-processing; Segmentation; Feature extraction; Text detection; Speech
   fusion
AB Along with the rapid development of information technology, the sightless persons have numerous visual difficulties in doing their day by day activities. In this technological world, we have many resources for the human to live their life, still blind peoples suffers a lot for their survival in this hi-tech world. Through computing the solution can be obtained for their independent survival to the blind peoples. This paper implements a powerful speech fusion system with to support the sightless persons. This system produces the text image documents as voice.
C1 [Arunkumar, P.] Sona Coll Technol, Dept Master Comp Applicat, Salem, India.
   [Shantharajah, P.] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 Sona College of Technology; Vellore Institute of Technology (VIT); VIT
   Vellore
RP Arunkumar, P (corresponding author), Sona Coll Technol, Dept Master Comp Applicat, Salem, India.
EM arundotmca@gmail.com; spshantharaj@gmail.com
OI Shantharajah, SP/0000-0001-5211-0066
CR [Anonymous], 2012, INT J SOFT COMPUTING
   [Anonymous], 2015, INT J ADV RES COMPUT
   Cha JS, 2013, INT J BIOSCIENCE BIO, V5
   Gawari H, 2014, J ENG RES APPL, V4
   Ilah A, 2013, INT J SMART SENSING, V6
   Khan S, 2015, INT J COMPUTER SCI I, V5
   Nandish MS, 2014, J ENG TRENDS TECHNOL, V10
   Natarajan B, 2014, INT REV COMPUTERS SO, V9
   Saini V, 2012, INTERNET J MED UPDAT, V7, P3
   Tan QF, 2012, IEEE T AUDIO SPEECH, V20, P1337, DOI 10.1109/TASL.2011.2178596
   Tan QF, 2011, IEEE T AUDIO SPEECH, V19, P2418, DOI 10.1109/TASL.2011.2136337
   Vijayasarathi R, 2012, J COMPUTER ENG IOSRJ, V4
   Wankhade KV, 2013, INT J ENG INNOVATIVE, V2
NR 13
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9117
EP 9130
DI 10.1007/s11042-019-7517-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600040
DA 2024-07-18
ER

PT J
AU Li, R
AF Li, Rong
TI RETRACTED: Evaluation and simulation of medical sports health equipment
   multimedia image based on information asymmetry theory (Retracted
   article. See vol. 82, pg. 19109, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Medical multimedia image; Information asymmetry theory; Sports health
   equipment; Process simulation; Effect evaluation
ID REGULARITY; MODELS
AB Virtual reality technology, information asymmetry theory and artificial intelligence technology are introduced into the evaluation of medical image effects of sports health equipment. This paper studies the overall framework and evaluation methods of medical imaging evaluation system for large complex exercise equipment. Firstly, based on the HLA characteristics, a simulation model and structural framework for the medical image evaluation process of large complex sports health equipment are proposed. Secondly, a sports health equipment based on the theory of information asymmetry was established. The theoretical framework of medical image effect analysis uses the relevant principles, models and methods in information asymmetry theory to systematically classify, identify and analyze medical image problems of sports health equipment. Finally, from the perspective of information asymmetry, the focus is on rent-seeking risk, adverse selection risk, moral risk cause, and the game relationship between actors. Finally, the main risk assessment index system based on the three is established and verified by experiments. The method is effective and reasonable.
C1 [Li, Rong] Shanxi Agr Univ, Sch Phys Educ, Jinzhong 030801, Shanxi, Peoples R China.
C3 Shanxi Agricultural University
RP Li, R (corresponding author), Shanxi Agr Univ, Sch Phys Educ, Jinzhong 030801, Shanxi, Peoples R China.
EM lirongdada@126.com
CR Baxa MC, 2014, P NATL ACAD SCI USA, V111, P15396, DOI 10.1073/pnas.1407768111
   Bayat B, 2015, NAT HAZARDS, V76, P515, DOI 10.1007/s11069-014-1499-3
   Che XD, 2015, VISUAL COMPUT, V31, P853, DOI 10.1007/s00371-015-1119-6
   Chen C, 2014, IEEE T POWER ELECTR, V29, P3679, DOI 10.1109/TPEL.2013.2282621
   Chen MC, 2018, ACTA MATH APPL SIN-E, V34, P398, DOI 10.1007/s10255-018-0740-3
   Cheng M, 2016, Electr. J. Differential Equat., V2016, P1
   DeHaan A, 2013, AM J SPORT MED, V41, P1140, DOI 10.1177/0363546513478578
   Ebrahimi Kamal, 2015, Glob J Health Sci, V7, P250, DOI 10.5539/gjhs.v7n6p250
   Gebremariam SY, 2014, ENVIRON MODELL SOFTW, V61, P121, DOI 10.1016/j.envsoft.2014.07.004
   Hu JX, 2019, J BRAZ SOC MECH SCI, V41, DOI 10.1007/s40430-018-1535-4
   Huang DN, 2014, BIOMED REP, V2, P452, DOI 10.3892/br.2014.282
   Jiang L, 2016, SERV BUS, V10, P301, DOI 10.1007/s11628-015-0269-y
   Kerosuo H, 2013, EUR J ORTHODONT, V35, P183, DOI 10.1093/ejo/cjs087
   Krichene H, 2018, J ECON INTERACT COOR, V13, P511, DOI 10.1007/s11403-017-0191-6
   Laugesen J, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4333
   Li CJ, 2018, WIRELESS PERS COMMUN, V103, P897, DOI 10.1007/s11277-018-5486-y
   Li Xiangfei, 2017, [Journal of Systems Science and Information, 系统科学与信息学报], V5, P556
   Liu D, 2016, J HARBIN I TECHNOL E, V23, P23
   Lonic D, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02250-w
   Lu SQ, 2018, ZAMM-Z ANGEW MATH ME, V98, P1574, DOI 10.1002/zamm.201700080
   Marotta G, 2014, APPETITE, V74, P107, DOI 10.1016/j.appet.2013.12.003
   Maru S, 2014, EUR J CARDIOVASC NUR, V22, P1466
   Nestel D, 2018, MED EDUC, V52, P139, DOI 10.1111/medu.13505
   Ripetskiy Andrey, 2018, Key Engineering Materials, V771, P91, DOI 10.4028/www.scientific.net/KEM.771.91
   Roberts ET, 2015, HEALTH SERV OUTCOME, V15, P241, DOI 10.1007/s10742-015-0141-5
   Royer L, 2017, MED IMAGE ANAL, V35, P582, DOI 10.1016/j.media.2016.09.004
   Salisbury DJ, 2014, GEOPHYS RES LETT, V41, P1616, DOI 10.1002/2014GL059246
   Salpakoski A, 2014, J AM MED DIR ASSOC, V15, P361, DOI 10.1016/j.jamda.2013.12.083
   Sayer AM, 2014, ATMOS CHEM PHYS, V14, P11493, DOI 10.5194/acp-14-11493-2014
   Sheikh M, 2017, PRACTICE, V33, P1
   van Bloemendaal M, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1604-x
   Xergia SA, 2015, SPORTS HEALTH, V7, P217, DOI 10.1177/1941738114529532
   Yang H, 2014, TRAFFIC INJ PREV, V15, P424, DOI 10.1080/15389588.2013.823165
NR 33
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9957
EP 9976
DI 10.1007/s11042-019-07883-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600013
DA 2024-07-18
ER

PT J
AU Ran, Q
   Xu, XD
   Zhao, SZ
   Li, W
   Du, Q
AF Ran, Qiong
   Xu, Xiaodong
   Zhao, Shizhi
   Li, Wei
   Du, Qian
TI Remote sensing images super-resolution with deep convolution networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing imagery; Super-resolution; Convolution neural network
ID RESOLUTION
AB Remote sensing image data have been widely applied in many applications, such as agriculture, military, and land use. It is difficult to obtain remote sensing images in both high spatial and spectral resolutions due to the limitation of implements in image acquisition and the law of energy conservation. Super-resolution (SR) is a technique to improve the resolution from a low-resolution (LR) to a high-resolution (HR). In this paper, a novel deep convolution network (DCN) SR method (SRDCN) is proposed. Based on hierarchical architectures, the proposed SRDCN learns an end-to-end mapping function to reconstruct an HR image from its LR version; furthermore, extensions of SRDCN based on residual learning and multi scale version are investigated for further improvement,namely Developed SRDCN(DSRDCN) and Extensive SRDCN(ESRDCN). Experimental results using different types of remote sensing data (e.g., multispectral and hyperspectral) demonstrate that the proposed methods outperform the traditional sparse representation based methods.
C1 [Ran, Qiong; Xu, Xiaodong; Zhao, Shizhi; Li, Wei] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Mississippi State, MS 39762 USA.
C3 Beijing University of Chemical Technology; Mississippi State University
RP Ran, Q (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM ranqiong@mail.buct.edu.cn; hsuxu820@gmail.com; 8114771@qq.com;
   du@ece.msstate.edu
RI du, qian/GYJ-7090-2022; Du, Qian/AAB-8840-2022; LI, WEI/ABD-5001-2021
OI Du, Qian/0000-0001-8354-7500
CR Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   [Anonymous], REMOTE SENS BASEL
   [Anonymous], APPL INTELL
   Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Burger H., 2012, CVPR
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen C, 2012, CONF REC ASILOMAR C, P608, DOI 10.1109/ACSSC.2012.6489079
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gou SP, 2014, IEEE J-STARS, V7, P4784, DOI 10.1109/JSTARS.2014.2328596
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Kasetkasem T, 2005, REMOTE SENS ENVIRON, V96, P302, DOI 10.1016/j.rse.2005.02.006
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li F, 2010, IEEE T GEOSCI REMOTE, V48, P1270, DOI 10.1109/TGRS.2009.2031636
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Pan ZX, 2013, IEEE T GEOSCI REMOTE, V51, P4864, DOI 10.1109/TGRS.2012.2230270
   Rhee S, 1999, OPT ENG, V38, P1348, DOI 10.1117/1.602177
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun WW, 2017, IEEE T GEOSCI REMOTE, V55, P4032, DOI 10.1109/TGRS.2017.2686842
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yuan Y, 2017, IEEE J-STARS, V10, P1963, DOI 10.1109/JSTARS.2017.2655112
   Zhang HY, 2012, SIGNAL PROCESS, V92, P2082, DOI 10.1016/j.sigpro.2012.01.020
   Zhang P, 2011, CHINESE J CHEM ENG, V19, P1, DOI 10.1016/S1004-9541(09)60169-5
   Zhang YY, 2013, 2013 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC), P318, DOI 10.1109/DASC.2013.82
NR 38
TC 22
Z9 21
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8985
EP 9001
DI 10.1007/s11042-018-7091-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600032
DA 2024-07-18
ER

PT J
AU Saeed, F
   Paul, A
   Karthigaikumar, P
   Nayyar, A
AF Saeed, Faisal
   Paul, Anand
   Karthigaikumar, P.
   Nayyar, Anand
TI Convolutional neural network based early fire detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire; Machine learning; Adaboost-MLP; Adaboost-LBP; Convolutional Neural
   Network
ID FLAME DETECTION; IMAGE; ALGORITHM; COLOR
AB The detection of manmade disasters particularly fire is valuable because it causes many damages in terms of human lives. Research on fire detection using wireless sensor network and video-based methods is a very hot research topic. However, the WSN based detection model need fire happens and a lot of smoke and fire for detection. Similarly, video-based models also have some drawbacks because conventional algorithms need feature vectors and high rule-based models for detection. In this paper, we proposed a fire detection method which is based on powerful machine learning and deep learning algorithms. We used both sensors data as well as images data for fire prevention. Our proposed model has three main deep neural networks i.e. a hybrid model which consists of Adaboost and many MLP neural networks, Adaboost-LBP model and finally convolutional neural network. We used Adaboost-MLP model to predict the fire. After the prediction, we proposed two neural networks i.e. Adaboost-LBP model and convolutional neural network for detection of fire using the videos and images taken from the cameras installed for the surveillance. Adaboost-LBP model is to generate the ROIs from the image where emergencies exist Our proposed model results are quite good, and the accuracy is almost 99%. The false alarming rate is very low and can be reduced more using further training.
C1 [Saeed, Faisal] Kyungpook Natl Univ, 80 Daehak Ro, Daegu, South Korea.
   [Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, 80 Daehak Ro, Daegu, South Korea.
   [Karthigaikumar, P.] Anna Univ, Chennai 600025, Tamil Nadu, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
C3 Kyungpook National University; Kyungpook National University; Anna
   University; Anna University Chennai; Duy Tan University
RP Paul, A (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, 80 Daehak Ro, Daegu, South Korea.
EM bscsfaisal821@gmail.com; paul.editor@gmail.com;
   p.karthigaikumar@gmail.com; anandnayyar@duytan.edu.vn
RI Paul, Anand/V-6724-2017; Palanivel, Karthigaikumar/AAR-5414-2020;
   Nayyar, Anand/F-3732-2015; Saeed, Faisal/HNT-0710-2023
OI Paul, Anand/0000-0002-0737-2021; Nayyar, Anand/0000-0002-9821-6146;
   Saeed, Faisal/0000-0002-2822-1708; P,
   Karthigaikumar/0000-0003-4850-0090; Paul, Anand/0000-0003-3115-2325
CR [Anonymous], 2007, P C INF ACQ ICIA 07
   [Anonymous], 2015, EXTENDED CTR SYMMETR
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Bhattacharjee S, 2012, J SYST SOFTWARE, V85, P571, DOI 10.1016/j.jss.2011.09.015
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chino DYT, 2015, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2015.19
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Guo L, 2012, EXPERT SYST APPL, V39, P4274, DOI 10.1016/j.eswa.2011.09.106
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Han D, 2006, LECT NOTES COMPUT SC, V4292, P39
   Jiang B, 2017, J VIS COMMUN IMAGE R, V48, P356, DOI 10.1016/j.jvcir.2017.02.011
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu CB, 2004, INT C PATT RECOG, P134, DOI 10.1109/HPD.2004.1346686
   Lloret J, 2009, SENSORS-BASEL, V9, P8722, DOI 10.3390/s91108722
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Mueller M, 2013, IEEE T IMAGE PROCESS, V22, P2786, DOI 10.1109/TIP.2013.2258353
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   Rafei M, 2014, NEURAL NETW WORLD, V24, P31, DOI 10.14311/NNW.2014.24.002
   Saeed F, 2018, J SENS ACTUAR NETW, V7, DOI 10.3390/jsan7010011
   Son B, 2006, INT J COMPUT SCI NET, V6, P124
   Tao CY, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P150, DOI [10.1109/ICIICII.2016.68, 10.1109/ICIICII.2016.0045]
   Yang JC, 2017, IEEE T IND INFORM, V13, P2350, DOI 10.1109/TII.2017.2657545
   Yu LY, 2005, I C WIREL COMM NETW, P1214
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Zhang J., 2008, FRONTIERS CHINA, V3, P369, DOI [10.1007/s11461-008-0054-3.24N.U., DOI 10.1007/S11461-008-0054-3.24N.U]
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhang ZF, 2008, PROCEEDINGS OF 2008 INTERNATIONAL SEMINAR ON EDUCATION MANAGEMENT AND ENGINEERING, P760
NR 35
TC 58
Z9 61
U1 7
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9083
EP 9099
DI 10.1007/s11042-019-07785-w
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600038
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Zhang, M
   Cui, YX
   Zhang, DY
AF Zhang, Yafei
   Zhang, Man
   Cui, Yongxia
   Zhang, Dongyuan
TI Detection and tracking of human track and field motion targets based on
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Human track and field movement; Target detection; Target
   tracking; The background subtraction method
AB The detection and tracking of human moving objects is an important part of visual analysis of human movement and one of the important fields of computer vision. When using the existing methods to detect and track human track and field targets, there are some problems such as low detection accuracy, large target positioning error and low detection and tracking efficiency. A method of target detection and tracking in human track and field based on deep learning is proposed. The background subtraction method based on adaptive hybrid gaussian background model is used to detect the target. The read video image is denoised and smoothed. The holes in the foreground region are removed by morphological filtering, and the connected region of binary image is analyzed. Get the number and area of the connected areas. Human body area ratio and length-width ratio are used to classify and identify human body so as to complete the detection of human track and field sports target. Based on the structure of deep learning, combining the detection results of deep learning and LK tracking, PN learning was used to modify the parameters of the superposition automatic coding machine, avoiding the detection errors in deep learning and realizing the tracking of human track and field targets. Experimental results show that this method has higher detection accuracy, higher target positioning accuracy and higher detection and tracking efficiency.
C1 [Zhang, Yafei; Zhang, Man; Zhang, Dongyuan] Hebei Med Univ, Shijiazhuang, Hebei, Peoples R China.
   [Cui, Yongxia] Hebei Univ Engn, Handan, Peoples R China.
C3 Hebei Medical University; Hebei University of Engineering
RP Zhang, M (corresponding author), Hebei Med Univ, Shijiazhuang, Hebei, Peoples R China.
EM 18503241112@163.com
CR Chen T., 2016, WIREL NETW, V22, P1, DOI DOI 10.1007/S11276-015-0946-8
   Choi B, 2016, IEEE T SIGNAL PROCES, V64, P2660, DOI 10.1109/TSP.2016.2531634
   Chughtai B, 2017, UROLOGY, V99, P1, DOI 10.1016/j.urology.2016.08.023
   Geng PL, 2017, J TAIYUAN U TECHNOLO, V48, P963
   Gu SH, 2017, COMPUTER SIMULATION, V34, P266
   Gunes A, 2016, DIGIT SIGNAL PROCESS, V48, P246, DOI 10.1016/j.dsp.2015.09.020
   Kwon J, 2017, ELECTRON LETT, V53, P1358, DOI 10.1049/el.2017.2129
   Li FL, 2017, IET IMAGE PROCESS, V11, P833, DOI 10.1049/iet-ipr.2016.0931
   Li L, 2016, OPT ENG, V55, P103
   Liu X, 2018, ROBUST FRUIT COUNTIN, V26, P156
   [马也 Ma Ye], 2017, [红外技术, Infrared Technology], V39, P1038
   Marvasti FS, 2018, IET COMPUT VIS, V12, DOI 10.1049/iet-cvi.2017.0327
   Park JD, 2015, IEEE ACCESS, V3, P1408, DOI 10.1109/ACCESS.2015.2471935
   Shi J, 2017, J CHINA ACAD ELECT I, V12, P25
   Suhr JK, 2016, IEEE T IND ELECTRON, V63, P5687, DOI 10.1109/TIE.2016.2558480
   Xia KJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1116-1
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Xue YD, 2016, AUTOMATION INSTRUMEN, V26, P189
   Yi Meng, 2016, Computer Engineering and Applications, V52, P27, DOI 10.3778/j.issn.1002-8331.1601-0069
   Yuan Y, 2018, IEEE T SYST MAN CY-S, V48, P1885, DOI 10.1109/TSMC.2017.2704278
NR 20
TC 13
Z9 13
U1 3
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9543
EP 9563
DI 10.1007/s11042-019-08035-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600067
DA 2024-07-18
ER

PT J
AU Khan, MA
   Javed, K
   Khan, SA
   Saba, T
   Habib, U
   Khan, JA
   Abbasi, AA
AF Khan, Muhammad Attique
   Javed, Kashif
   Khan, Sajid Ali
   Saba, Tanzila
   Habib, Usman
   Khan, Junaid Ali
   Abbasi, Aaqif Afzaal
TI Human action recognition using fusion of multiview and deep features: an
   application to video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Multiview features; Deep features; Features
   fusion; Recognition
ID SELECTION; NETWORK; HISTORY; CNN
AB Human Action Recognition (HAR) has become one of the most active research area in the domain of artificial intelligence, due to various applications such as video surveillance. The wide range of variations among human actions in daily life makes the recognition process more difficult. In this article, a new fully automated scheme is proposed for Human action recognition by fusion of deep neural network (DNN) and multiview features. The DNN features are initially extracted by employing a pre-trained CNN model name VGG19. Subsequently, multiview features are computed from horizontal and vertical gradients, along with vertical directional features. Afterwards, all features are combined in order to select the best features. The best features are selected by employing three parameters i.e. relative entropy, mutual information, and strong correlation coefficient (SCC). Furthermore, these parameters are used for selection of best subset of features through a higher probability based threshold function. The final selected features are provided to Naive Bayes classifier for final recognition. The proposed scheme is tested on five datasets name HMDB51, UCF Sports, YouTube, IXMAS, and KTH and the achieved accuracy were 93.7%, 98%, 99.4%, 95.2%, and 97%, respectively. Lastly, the proposed method in this article is compared with existing techniques. The resuls shows that the proposed scheme outperforms the state of the art methods.
C1 [Khan, Muhammad Attique; Khan, Junaid Ali] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Javed, Kashif] SMME NUST, Dept Robot, Islamabad, Pakistan.
   [Khan, Sajid Ali; Abbasi, Aaqif Afzaal] Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Habib, Usman] FAST Natl Univ Comp & Emerging Sci NUCES, Chiniot Faisalabad Campus, Faisalabad, Pakistan.
C3 NITEC University; National University of Sciences & Technology -
   Pakistan; Quaid I Azam University; Prince Sultan University
RP Khan, SA (corresponding author), Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
EM sajidalibn@gmail.com
RI Khan, Junaid Ali/ABG-2756-2020; Abbasi, Aaqif Afzaal/AFG-9482-2022;
   khan, sajid/HGE-2406-2022; Saba, Tanzila/D-4593-2018; Khan, Dr. Muhammad
   Attique/AAX-2644-2021; Khan, Junaid Ali/JYP-3306-2024
OI Khan, Junaid Ali/0000-0003-2630-1744; Abbasi, Aaqif
   Afzaal/0000-0002-9982-1321; Saba, Tanzila/0000-0003-3138-3801; Khan, Dr.
   Muhammad Attique/0000-0002-6347-4890; habib, usman/0000-0003-4793-6239
CR Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   Aly S, 2019, MULTIMED TOOLS APPL
   Arshad H, 2019, INT J PARALLEL EMERG, V2019, P1
   Aurangzeb K, 2019, J MED IMAG HEALTH IN, V9, P662, DOI 10.1166/jmihi.2019.2611
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Pham HH, 2018, COMPUT VIS IMAGE UND, V170, P51, DOI 10.1016/j.cviu.2018.03.003
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Jalal A, 2019, J ELECTR ENG TECHNOL, V14, P455
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Khan MA, 2019, OPTIMIZED METHOD SEG
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan SA, 2019, FACIAL EXPRESSION RE
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li F., 2019, The International Conference on Cyber Security Intelligence and Analytics, P569
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Parisi G. I., 2020, ARXIV200105837
   Rahimi S, 2019, SIGNAL IMAGE VIDEO P, V13, P271, DOI 10.1007/s11760-018-1354-1
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sharif A, 2019, CONTROL ENG APPL INF, V21, P3
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Siddiqui S, 2018, INT J APPL PATTERN R, V5, P206, DOI 10.1504/IJAPR.2018.094815
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Wang P, 2019, PATTERN RECOGN, V91, P357, DOI 10.1016/j.patcog.2019.03.002
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wu JS, 2017, IEEE ACCESS, V5, P3322, DOI 10.1109/ACCESS.2017.2675478
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Zare A, 2019, PATTERN ANAL APPL, P1, DOI [10.3233/HAB-180343, DOI 10.3233/HAB-180343]
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhao R, 2019, PROC CVPR IEEE, P7725, DOI 10.1109/CVPR.2019.00792
NR 45
TC 98
Z9 98
U1 3
U2 110
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14885
EP 14911
DI 10.1007/s11042-020-08806-9
EA MAR 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000564453200002
DA 2024-07-18
ER

PT J
AU Elhoseny, M
   Oliva, D
   Osuna-Enciso, V
   Hassanien, AE
   Gunasekaran, M
AF Elhoseny, Mohamed
   Oliva, Diego
   Osuna-Enciso, Valentin
   Hassanien, Aboul Ella
   Gunasekaran, M.
TI Parameter identification of two dimensional digital filters using
   electro-magnetism optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two dimensional digital filters; Signal processing; Electro-magnetism
   optimization; Global optimization
ID OPTIMAL-DESIGN; ALGORITHM; SERVICES; MODEL
AB The design of Two-Dimensional Infinite Input Response Filters (2D IIR) is an important task in the field of signal processing. These filters are widely used in several areas of engineering as an important tool to eliminate undesired frequencies in high-noised signals. However, 2D IIR filters have parameters that need to be calibrated in order to obtain the best output, and finding these optimal values is not an easy task. On the other hand, Electro-magnetism Optimization (EMO) is a population-based technique which possess interesting convergence properties, it works following the electro-magnetism principles for solving complex optimization problems. This paper introduces an algorithm for the automatic parameter identification of 2D IIR filters using EMO, a process that is regarded as a multidimensional optimization problem. Experimental results are included to validate the efficiency of the proposed technique regarding accuracy, speed, and robustness.
C1 [Elhoseny, Mohamed] Mansoura Univ, Fac Comp & Informat, Mansoura, Egypt.
   [Oliva, Diego] Univ Guadalajara, CUCEI, Av Revoluc 1500, Guadalajara, Jalisco, Mexico.
   [Osuna-Enciso, Valentin] Univ Guadalajara, Av Nuevo Perifer 555, Tonala, Jalisco, Mexico.
   [Hassanien, Aboul Ella] Cairo Univ, Fac Comp & Informat, Cairo, Egypt.
   [Gunasekaran, M.] VIT Univ, Vellore, Tamil Nadu, India.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Universidad de
   Guadalajara; Universidad de Guadalajara; Egyptian Knowledge Bank (EKB);
   Cairo University; Vellore Institute of Technology (VIT); VIT Vellore
RP Elhoseny, M (corresponding author), Mansoura Univ, Fac Comp & Informat, Mansoura, Egypt.
EM mohamed_elhoseny@mans.edu.eg
RI Osuna-Enciso, Valentín/AAD-7533-2019; Oliva, Diego/A-3271-2016;
   Elhoseny, Mohamed/Q-5591-2017; Hassanien, Aboul ella/O-5672-2014;
   Osuna-Enciso, Valentin/CAH-3472-2022
OI Osuna-Enciso, Valentín/0000-0001-6844-9013; Oliva,
   Diego/0000-0001-8781-7993; Elhoseny, Mohamed/0000-0001-6347-8368;
   Hassanien, Aboul ella/0000-0002-9989-6681; Osuna-Enciso,
   Valentin/0000-0001-6844-9013
CR Abd Elaziz M, 2017, EXPERT SYST APPL, V90, P484, DOI 10.1016/j.eswa.2017.07.043
   Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   ABOTALEB A, 1984, IEEE T CIRCUITS SYST, V31, P801, DOI 10.1109/TCS.1984.1085572
   Aggarwal A, 2016, CIRC SYST SIGNAL PR, V35, P2213, DOI 10.1007/s00034-016-0283-x
   [Anonymous], 1996, Principles, Algorithms, and Applications
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   Birbil SI, 2004, J GLOBAL OPTIM, V30, P301, DOI 10.1007/s10898-004-8270-3
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Cowan E.W., 1968, Basic Electromagnetism
   Cuevas-Jiménez E., 2013, Ing. invest. y tecnol., V14, P125
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   Das S, 2007, ENG APPL ARTIF INTEL, V20, P1086, DOI 10.1016/j.engappai.2007.02.004
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Elhoseny M, 2018, EXPERT SYST APPL, V92, P142, DOI 10.1016/j.eswa.2017.09.008
   Getin a E, 1997, FFT ALGORITHM IEEE S, P60
   KAWAMATA M, 1994, IEEE IMAGE PROC, P780, DOI 10.1109/ICIP.1994.413421
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kockanat S, 2015, ARTIF INTELL REV, V44, P265, DOI 10.1007/s10462-014-9427-1
   Kumar M, 2016, ARAB J SCI ENG, V41, P3587, DOI 10.1007/s13369-016-2222-3
   Lu HC, 2000, SIGNAL PROCESS, V80, P1445, DOI 10.1016/S0165-1684(00)00048-7
   Lv C, 2017, MULTIDIM SYST SIGN P, V28, P1267, DOI 10.1007/s11045-016-0397-0
   Mladenov VM, 1994, IEEE T NEURAL NETWOR, V5, P2
   Mostajabi T, 2015, ARTIF INTELL REV, V44, P87, DOI 10.1007/s10462-013-9403-1
   Nair SS, 2017, CIRC SYST SIGNAL PR, V36, P1535, DOI 10.1007/s00034-016-0370-z
   Pham DT, 2010, INT J AUTOM COMPUT, V7, P399, DOI 10.1007/s11633-010-0520-x
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sajjad M, 2020, FUTURE GENER COMP SY, V108, P995, DOI 10.1016/j.future.2017.11.013
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Stewart J.V., 2001, INTERMEDIATE ELECTRO
   Tsai JT, 2009, EXPERT SYST APPL, V36, P6928, DOI 10.1016/j.eswa.2008.08.065
   Tzafestas S.G., 1986, MULTIDIMENSIONAL SYS
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yang YK, 2018, APPL INTELL, V48, P1689, DOI 10.1007/s10489-017-1034-9
   Yuan XH, 2017, J NETW SYST MANAG, V25, P21, DOI 10.1007/s10922-016-9379-7
NR 36
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5005
EP 5022
DI 10.1007/s11042-018-6095-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500043
DA 2024-07-18
ER

PT J
AU Hussain, DM
   Surendran, D
AF Hussain, D. Mansoor
   Surendran, D.
TI RETRACTED: Content based image retrieval using bees algorithm and
   simulated annealing approach in medical big data applications (Retracted
   article. See vol. 82, pg. 12739, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE CBIR; Cluster data image; Bees algorithm; Simulated annealing
ID HISTOGRAMS; SEMANTICS; COLOR
AB Content Based Image retrieval systems (CBIR) retrieve the image features from the massive databases using the retrival set [15]. The Extracted image set will be maintained in a secured repository to enhance the approach of submissive storage. The Stored image suspects a variance in the colour festo and colour shaping using the texture classification. The stored image has been retrieved formally from the massive databases using the traditional algorithms, but the secure futuristic behavior of image storage can be done from cluster formation it maintains the original copy of the image termed as cluster data image(CDI) [32]. Apart from former traditional algorithms to capture the image set features the proposed algorithm induces a novel scheme of metaheuristic algorithm named as bees algorithm has been surveyed for the retrieval sector. The efficiency can be best measured in cluster set images using the precision value measurement and the accuracy has been established with efficient diffusion algorithm based on normalization and medical applications are considered for same data set retrieval.
C1 [Hussain, D. Mansoor; Surendran, D.] Sri Krishna Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Sri Krishna College of Engineering & Technology
RP Hussain, DM (corresponding author), Sri Krishna Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM dmansoor.slm@gmail.com; d.surendran@gmail.com
CR Arevalillo-Herráez M, 2011, APPL SOFT COMPUT, V11, P1782, DOI 10.1016/j.asoc.2010.05.022
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Beligiannis G, 2004, IEEE SIGNAL PROC MAG, V21, P28
   Bugatti P.H, 2008, IEEE INT S, V10
   Chang CY, 2010, IEEE T INSTRUM MEAS, V59, P2315, DOI 10.1109/TIM.2009.2036410
   Chen YX, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P197, DOI 10.1109/ISSPA.2003.1224674
   Chinnasamy A, 2019, CLUSTER COMPUT, V22, P12795, DOI 10.1007/s10586-018-1760-8
   Delp EJ, 1979, COMMUN, VCOM-27, P1335
   Goldberg D.E., 1989, Genetic Algorithms in Search, Optimization, and Machine Learning
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Huang W, 2013, J DIGIT IMAGING, V26, P850, DOI 10.1007/s10278-013-9591-x
   Ilango SS, 2019, CLUSTER COMPUT, V22, P12169, DOI 10.1007/s10586-017-1571-3
   Kannan N, 2019, CLUSTER COMPUT, V22, P14709, DOI 10.1007/s10586-018-2384-8
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Long FH, 2003, SIG COM TEC, P1
   Mohanty AK, 2013, NEURAL COMPUT APPL, V22, P1151, DOI 10.1007/s00521-012-0881-x
   Mojsilovic A, 2001, IEEE IMAGE PROC, P18, DOI 10.1109/ICIP.2001.958942
   Nezamabadi-Pour H, 2004, PATTERN RECOGN LETT, V25, P1547, DOI 10.1016/j.patrec.2004.05.019
   Niblack W, 1993, IS T SPIE S EL IM SC
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Plantniotis KN, 2000, COLOR IMAGE PROCESSI
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Silva SFD, 2011, DECIS SUPPORT SYST, V51, P810, DOI DOI 10.1016/j.dss.2011.01.015
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Suganya R., 2012, American Journal of Applied Sciences, V9, P938
   Suresh A, 2018, WIRELESS PERS COMMUN, V103, P1239, DOI 10.1007/s11277-018-5504-0
   Suresh A, 2018, MULTIMED TOOLS APPL, V77, P27075, DOI 10.1007/s11042-018-5905-9
   Vimal S, 2019, CLUSTER COMPUT, V22, P10491, DOI 10.1007/s10586-017-1092-0
   Vimal Vimal S S, Asian J. Inform. Technol., V14 14, P4986, DOI 10.3923/ajit.2016.4986.4994 10.3923/ajit.2016.4986.4994
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Zhou XS, 2000, P SPIE
NR 34
TC 3
Z9 4
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3683
EP 3698
DI 10.1007/s11042-018-6708-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700031
DA 2024-07-18
ER

PT J
AU Karuna, Y
   Reddy, GR
AF Karuna, Yepuganti
   Reddy, G. Ramachandra
TI Broadband subspace decomposition of convoluted speech data using
   polynomial EVD algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polynomial EVD; Broadband subspace decomposition; Convolutive blind
   source separation; Strong decorrelation; Spectral majorization
ID BLIND SIGNAL SEPARATION
AB The Polynomial EVD (PEVD) was developed to achieve broadband subspace decomposition as a part of two-stage convolutive Blind Source Separation (BSS) algorithm. It has the ability to accomplish strong (total) decorrelation and spectral majorization on convolutive signals. We explore different algorithms for constructing FIR paraunitary (PU) matrices with the aim of performing broadband subspace decomposition. We adopt a set of new iterative PEVD algorithms for this task: a) Sequential matrix diagonalization (SMD) b) Maximum element sequential matrix diagonalization (ME-SMD). We also present a procedure to find out the total number of source signals in the convolved data, without having prior knowledge, based on the energy of individual polynomial eigen values. This helps us to find out exact signal and noise subspaces. To measure the performance of PEVD for broadband subspace decomposition, we use the diagonalization performance measure and subspace estimation measure. We present the results both for simulated data and for actual convolved speech data in the presence of noisy environment to show the effectiveness of the adopted algorithms over existing SBR2/SBR2C algorithms in the literature.
C1 [Karuna, Yepuganti; Reddy, G. Ramachandra] VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Karuna, Y (corresponding author), VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM karun@vit.ac.in; grreddy@vit.ac.in
CR [Anonymous], ADAPTIVE FILTER THEO, DOI DOI 10.1109/ISCAS.2017.8050871
   [Anonymous], IEEE 7 INT WORKSH CO
   Baxter PD, 2005, THESIS
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Delfosse N, 2000, IEEE T CIRCUITS-I, V47, P1056, DOI 10.1109/81.855461
   Gore D., 2003, INTRO SPACE TIME WIR
   Karuna Yepuganti, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P1397, DOI 10.1109/SCOPES.2016.7955670
   Klemm R, 1998, I ENG TECHNOLOGY, V11
   Lambert R.H., 2001, Proc. Int. Conf. Independent Component Analysis, P379
   Liu C, 2015, MANUFACTURING AND ENGINEERING TECHNOLOGY, P1, DOI 10.13462/j.cnki.mmtamt.2015.03.001
   McWhirter J.G., 2004, 12 ANN WORKSH AD SEN
   McWhirter JG, 2006, 14 EUR SIGN PROC C F, P1
   McWhirter JG, 2007, IEEE T SIGNAL PROCES, V55, P2158, DOI 10.1109/TSP.2007.893222
   Mulgrew B, 2003, DIGIT SIGNAL PROCESS, P382
   Pedersen MS., 2007, Multichannel Speech Processing Handbook
   Pope KJ, 1996, DIGIT SIGNAL PROCESS, V6, P17, DOI 10.1006/dspr.1996.0003
   Redif S, 2006, THESIS, V68
   Redif S, 2003, BROADBAND SUBSPACE D
   Redif S, 2017, SIGNAL PROCESS, V134, P76, DOI 10.1016/j.sigpro.2016.11.019
   Redif S, 2016, TURK J ELECTR ENG CO, V24, P2483, DOI 10.3906/elk-1401-19
   Redif S, 2015, IEEE T SIGNAL PROCES, V63, P81, DOI 10.1109/TSP.2014.2367460
   Redif S, 2011, IEEE T SIGNAL PROCES, V59, P5253, DOI 10.1109/TSP.2011.2163065
   REGALIA PA, 1992, IEEE T SIGNAL PROCES, V40, P2392, DOI 10.1109/78.157284
   REGALIA PA, 1995, INT CONF ACOUST SPEE, P1460, DOI 10.1109/ICASSP.1995.480559
   Sandmann A, 2017, 2017 ADVANCES IN WIRELESS AND OPTICAL COMMUNICATIONS (RTUWO), P1, DOI 10.1109/RTUWO.2017.8228495
   Tarokh V, 1998, IEEE T INFORM THEORY, V44, P744, DOI 10.1109/18.661517
   Tkacenko A, 2010, INT CONF ACOUST SPEE, P4074, DOI 10.1109/ICASSP.2010.5495751
   Tohidian M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-93
   Torkkola K, 1996, NEURAL NETWORKS FOR SIGNAL PROCESSING VI, P423, DOI 10.1109/NNSP.1996.548372
   Vaidyanathan P. P., 1993, MULTIRATE SYSTEMS FI
   Vaidyanathan PP, 1998, IEEE T SIGNAL PROCES, V46, P1528, DOI 10.1109/78.678466
   Weiss S., 1999, 33 AS C SIGN SYST CO, V1, P496, DOI [10.1109/ACSSC.1999.832379, DOI 10.1109/ACSSC.1999.832379]
   Weiss S, 2018, IEEE T SIGNAL PROCES, V66, P2659, DOI 10.1109/TSP.2018.2812747
NR 34
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5281
EP 5299
DI 10.1007/s11042-018-6416-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500060
DA 2024-07-18
ER

PT J
AU Tiwari, V
   Hashmi, MF
   Keskar, A
   Shivaprakash, NC
AF Tiwari, Varun
   Hashmi, Mohammad Farukh
   Keskar, Avinash
   Shivaprakash, N. C.
TI Virtual home assistant for voice based controlling and scheduling with
   short speech speaker identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud services; Gaussian mixture models; Internet of things; Principal
   component analysis; Speaker identification; Vector quantization
ID SMART HOME; RECOGNITION; NOISE; ARCHITECTURE; MACHINES; SECURITY;
   PRIVACY; MFCC
AB With the advancement of interface technologies in smart devices, voice-controlled assistants have quickly gained popularity. These assistants are designed to use voice commands to achieve a more human-friendly interaction. On these lines, we propose a cloud-connected voice based home assistant in this paper. It accepts voice commands to control or monitor devices in a home. It can understand and schedule device operations based on time or sensor data through a simple voice based approach. To enhance its capability, it is designed to identify the speakers. Mel-Frequency Cepstrum Coefficients (MFCC) in combination with other speech features are used as feature vector. We use Vector Quantization (VQ) and Principal Component Analysis (PCA) for dimensionality reduction of the feature vector, followed by Gaussian Mixture Model (GMM) for classification. The validation of the short speech speaker identification is carried out on a set of Indian speakers in an uncontrolled indoor environment. An accuracy greater than 92% is achieved for speech samples as small as 1 second. A database of more than 50 different commands per speaker is also created for validation of the proposed virtual assistant. IBM's Bluemix and Google's cloud service is used for speech to text conversion.
C1 [Tiwari, Varun; Keskar, Avinash] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, South Ambazari Rd, Nagpur 40010, Maharashtra, India.
   [Hashmi, Mohammad Farukh] Natl Inst Technol Campus, Dept Elect & Commun Engn, Warangal 506004, Telangana, India.
   [Shivaprakash, N. C.] Indian Inst Sci, Dept Instrumentat & Appl Phys, CV Raman Ave, Bengaluru 560012, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; National Institute of Technology (NIT
   System); National Institute of Technology Warangal; Indian Institute of
   Science (IISC) - Bangalore
RP Tiwari, V (corresponding author), Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, South Ambazari Rd, Nagpur 40010, Maharashtra, India.
EM varun.etrx@gmail.com
RI Kothari, Ashwin/AFG-0522-2022; Tiwari, Varun/AAF-7951-2020; HASHMI,
   MOHAMMAD FARUKH/W-1428-2019
OI Kothari, Ashwin/0000-0001-6149-5607; HASHMI, MOHAMMAD
   FARUKH/0000-0002-3808-9122; Keskar, Avinash/0000-0002-9660-1139
CR Ahmed E, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P472, DOI 10.1109/ICIEV.2016.7760048
   Al-Ali AKH, 2017, IEEE ACCESS, V5, P15400, DOI 10.1109/ACCESS.2017.2728801
   Alepis E, 2017, IEEE ACCESS, V5, P17841, DOI 10.1109/ACCESS.2017.2747626
   [Anonymous], LINCOLN LAB J
   Bijuraj L. V, 2013, P NAT C NEW HOR IT N, P169
   Bizjak J, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0511-y
   Chen C, 2017, PROCEEDINGS OF THE SIXTH NORTHEAST ASIA INTERNATIONAL SYMPOSIUM ON LANGUAGE, LITERATURE AND TRANSLATION, P503
   Cumani S, 2014, IEEE-ACM T AUDIO SPE, V22, P1590, DOI 10.1109/TASLP.2014.2341914
   Cumani S, 2012, IEEE T AUDIO SPEECH, V20, P1585, DOI 10.1109/TASL.2012.2186290
   Dobrowolski AP, 2011, SIGNAL PROCESSING AL, P1
   El Ayadi M, 2017, SPEECH COMMUN, V92, P52, DOI 10.1016/j.specom.2017.05.005
   Farrell KR, 1994, IEEE T SPEECH AUDI P, V2, P194, DOI 10.1109/89.260362
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Hossain MS, 2017, J PARALLEL DISTR COM, V103, P11, DOI 10.1016/j.jpdc.2016.10.005
   Huo ChunBao, 2009, 2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC 2009), P997, DOI 10.1109/ICICIC.2009.357
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Huete AJ, 2012, IEEE T SYST MAN CY C, V42, P561, DOI 10.1109/TSMCC.2011.2159201
   Jose AC, 2016, IEEE ACCESS, V4, P5776, DOI 10.1109/ACCESS.2016.2606478
   Kang B, 2017, IEEE T MULTI-SCALE C, V3, P206, DOI 10.1109/TMSCS.2017.2705683
   Kelly SDT, 2013, IEEE SENS J, V13, P3846, DOI 10.1109/JSEN.2013.2263379
   Matza A, 2014, IET SIGNAL PROCESS, V8, P860, DOI 10.1049/iet-spr.2013.0270
   Nakagawa S, 2012, IEEE T AUDIO SPEECH, V20, P1085, DOI 10.1109/TASL.2011.2172422
   Patané G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6
   Rafferty J, 2017, IEEE T HUM-MACH SYST, V47, P368, DOI 10.1109/THMS.2016.2641388
   Ranjan S, 2018, IEEE-ACM T AUDIO SPE, V26, P197, DOI 10.1109/TASLP.2017.2765832
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Ringnér M, 2008, NAT BIOTECHNOL, V26, P303, DOI 10.1038/nbt0308-303
   Roch M, 2002, IEEE T SPEECH AUDI P, V10, P315, DOI 10.1109/TSA.2002.800558
   Sadewa RA, 2015, 2015 3rd International Conference on Information and Communication Technology (ICoICT), P261, DOI 10.1109/ICoICT.2015.7231433
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Sahidullah M, 2013, IEEE SIGNAL PROC LET, V20, P149, DOI 10.1109/LSP.2012.2235067
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   Saunders J, 2016, IEEE T HUM-MACH SYST, V46, P27, DOI 10.1109/THMS.2015.2445105
   Schroeter C, 2013, IEEE INT CONF ROBOT, P1153, DOI 10.1109/ICRA.2013.6630717
   Son SC, 2016, IEEE T CONSUM ELECTR, V62, P10, DOI 10.1109/TCE.2016.7448557
   Song TY, 2017, IEEE INTERNET THINGS, V4, P1844, DOI 10.1109/JIOT.2017.2707489
   Garimella, 2012, IEEE SIGNAL PROC LET, V19, P841, DOI 10.1109/LSP.2012.2221706
   Stojmenski A, 2016, INT C INTELL COMP CO, P13, DOI 10.1109/ICCP.2016.7737115
   Tan ZH, 2010, IEEE J-STSP, V4, P798, DOI 10.1109/JSTSP.2010.2057192
   Tiwari V, 2017, ENG TECHNOL APPL SCI, V7, P1464
   Tiwari V, 2017, INT J ONLINE ENG, V13, P34, DOI 10.3991/ijoe.v13i02.6460
   Vogt R, 2010, IEEE T AUDIO SPEECH, V18, P1182, DOI 10.1109/TASL.2009.2031505
   Wu EY, 2016, INT C COMP SUPP COOP, P560, DOI 10.1109/CSCWD.2016.7566051
   Wu Zunjing, 2005, Tsinghua Science and Technology, V10, P158, DOI 10.1016/S1007-0214(05)70048-1
   Yan FR, 2016, IEEE ACCESS, V4, P5258, DOI 10.1109/ACCESS.2016.2607778
   Yang Hy, 2012, 2012 INT C MACH LEAR, V1, P321
   You CH, 2010, IEEE T AUDIO SPEECH, V18, P1300, DOI 10.1109/TASL.2009.2032950
NR 47
TC 11
Z9 11
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5243
EP 5268
DI 10.1007/s11042-018-6358-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500058
DA 2024-07-18
ER

PT J
AU Wu, YQ
   Xiao, XM
   Chen, RQ
   Ma, J
   Wang, XX
   Zhang, YN
   Zhao, B
   Li, B
AF Wu, Yaqian
   Xiao, Xiangming
   Chen, Rangqian
   Ma, Jun
   Wang, Xinxin
   Zhang, Yanan
   Zhao, Bin
   Li, Bo
TI Tracking the phenology and expansion of <i>Spartina alterniflora</i>
   coastal wetland by time series MODIS and Landsat images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt marsh vegetation; Spartina alterniflora; Phenology; Biological
   expansion; Coastal wetland; Remote sensing
ID SALT-MARSH VEGETATION; RICE PLANTING AREA; PADDY RICE;
   PHRAGMITES-AUSTRALIS; JIUDUANSHA WETLAND; YANGTZE ESTUARY; 8 OLI;
   DYNAMICS; SHANGHAI; CHINA
AB Accurate information on phenology of Spartina alterniflora is basic for observing its growing condition in native and invasive places. Remote sensing (RS) can be used to analyse and monitor vegetation at a large spatial and long time scale. In this study, RS is used to explore phenology of coastal wetland vegetation (Reed, Suaeda salsa and Spartina alterniflora) based on time series data of four spectral indices (SI): Normalized Difference Vegetation Index (NDVI); Enhanced Vegetation Index (EVI); Land Surface Water Index (LSWI) and Modified Normalized Difference Moisture Index (mNDWI). These SIs were calculated based on Moderate Resolution Imaging Spectroradiometer (MODIS) and Land Satellite (Landsat) images, respectively. Phenology (including growing season and non-growing season) of Spartina alterniflora based on SIs to track its dynamic expansion since it invaded in southern Yellow Sea (Jiangsu, Yancheng), China through observing Landsat sub-pixels in per MODIS pixel. We also developed a new phenology-based algorithm to identify Spartina alterniflora from 1984 to 2015. The results show that Spartina alterniflora has a longer growth circle (around 286 days in a year) and higher productivity (about 0.6-0.8 NDVI) than the other salt marsh vegetation. The way of observing vegetation phenology on RS, and then developing a new phenology-based algorithm to track coastal wetland including invasive species-like Spartina alterniflora can support the studies of biological expansion, coastal wetland biodiversity conservation, and even global carbon cycling and climate change further.
C1 [Wu, Yaqian; Xiao, Xiangming; Ma, Jun; Wang, Xinxin; Zhao, Bin; Li, Bo] Fudan Univ, Inst Biodivers Sci, China US Joint Lab Ecol Big Data, 2005 Songhu Rd, Shanghai 200438, Peoples R China.
   [Xiao, Xiangming] Univ Oklahoma, Ctr Spatial Anal, Dept Microbiol & Plant Biol, Norman, OK 73019 USA.
   [Chen, Rangqian] Chinese Acad Trop Agr Sci, RRI, Minist Agr, Danzhou Invest & Expt Stn Trop Cops,Danzhou City, Danzhou 571737, Hainan, Peoples R China.
   [Zhang, Yanan] Jiangsu Yancheng Wetland Natl Nat Reserve, Sci Res Management Sect, Yancheng 234005, Jiangsu, Peoples R China.
C3 Fudan University; University of Oklahoma System; University of Oklahoma
   - Norman; Chinese Academy of Tropical Agricultural Sciences; Ministry of
   Agriculture & Rural Affairs
RP Xiao, XM (corresponding author), Fudan Univ, Inst Biodivers Sci, China US Joint Lab Ecol Big Data, 2005 Songhu Rd, Shanghai 200438, Peoples R China.; Xiao, XM (corresponding author), Univ Oklahoma, Ctr Spatial Anal, Dept Microbiol & Plant Biol, Norman, OK 73019 USA.
EM lifuyoulfyab@163.com
RI Xiao, Xiao/IAN-3011-2023; xiao, xiang/GWU-6035-2022; Wang,
   Xinxin/ABD-5736-2020; Zhao, Bin/I-3651-2013; Li, Bo/B-8016-2010; Zhao,
   Bing/HNJ-6617-2023; Li, bo/IWL-9318-2023
OI Wang, Xinxin/0000-0001-8013-3660; Li, Bo/0000-0002-0439-5666; Xiao,
   Xiangming/0000-0003-0956-7428
CR [Anonymous], 2016, SCI REPORTS
   Armitage AR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125404
   Bao KS, 2016, CHINESE GEOGR SCI, V26, P755, DOI 10.1007/s11769-016-0835-9
   Barutot RA, 2011, BRAZ ARCH BIOL TECHN, V54, P91, DOI 10.1590/S1516-89132011000100012
   Beland M, 2016, REMOTE SENS ENVIRON, V182, P192, DOI 10.1016/j.rse.2016.04.024
   Cao MT, 2015, SUSTAINABILITY-BASEL, V7, P15617, DOI 10.3390/su71115617
   Chen BQ, 2017, ISPRS J PHOTOGRAMM, V131, P104, DOI 10.1016/j.isprsjprs.2017.07.011
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Dai XY, 2013, WETL ECOL MANAG, V21, P433, DOI 10.1007/s11273-013-9316-4
   Dong J, 2016, GEOPHYS RES LETT, V43, P3754, DOI 10.1002/2016GL068191
   Fisher JI, 2007, REMOTE SENS ENVIRON, V109, P261, DOI 10.1016/j.rse.2007.01.004
   Foga S, 2017, REMOTE SENS ENVIRON, V194, P379, DOI 10.1016/j.rse.2017.03.026
   Fragoso G, 2008, SCIENCE, V322, P1064, DOI 10.1126/science.1159973
   Gallagher FJ, 2008, ENVIRON POLLUT, V156, P699, DOI 10.1016/j.envpol.2008.06.013
   Gao ZG, 2006, ESTUAR COAST SHELF S, V69, P217, DOI 10.1016/j.ecss.2006.04.016
   Ghosh S, 2016, REMOTE SENS ENVIRON, V173, P39, DOI 10.1016/j.rse.2015.11.015
   Hinkle RL, 2005, ECOL ENG, V25, P240, DOI 10.1016/j.ecoleng.2005.04.011
   Hladik C, 2012, ESTUARINE COASTAL AM, V141, P47
   Huang HM, 2008, ESTUAR COAST SHELF S, V77, P47, DOI 10.1016/j.ecss.2007.09.003
   Huang H, 2007, ECOL ENG, V29, P164, DOI 10.1016/j.ecoleng.2006.06.005
   Isacch JP, 2006, J BIOGEOGR, V33, P888, DOI 10.1111/j.1365-2699.2006.01461.x
   Jin C, 2016, FRONT EARTH SCI-PRC, V10, P49, DOI 10.1007/s11707-015-0518-3
   Ju RT, 2016, BIOL INVASIONS, V18, P2229, DOI 10.1007/s10530-015-0981-5
   Kang XM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050391
   Kettenring KM, 2016, BIOL INVASIONS, V18, P2475, DOI 10.1007/s10530-016-1125-2
   Kirwan ML, 2012, NATURE, V489, P550, DOI 10.1038/nature11440
   Koltunov A, 2009, REMOTE SENS ENVIRON, V113, P2431, DOI 10.1016/j.rse.2009.07.005
   Kulawardhana RW, 2015, ESTUAR COAST SHELF S, V154, P48, DOI 10.1016/j.ecss.2014.12.032
   Li B, 2009, ECOL ENG, V35, P511, DOI 10.1016/j.ecoleng.2008.05.013
   Li L, 2015, REMOTE SENS-BASEL, V7, P1206, DOI 10.3390/rs70201206
   Li X, 2016, GEOMORPHOLOGY, V253, P328, DOI 10.1016/j.geomorph.2015.10.031
   Liao CZ, 2007, ECOSYSTEMS, V10, P1351, DOI 10.1007/s10021-007-9103-2
   Lin WP, 2015, REMOTE SENS-BASEL, V7, P10227, DOI 10.3390/rs70810227
   Liu HY, 2014, ECOL RES, V29, P905, DOI 10.1007/s11284-014-1181-y
   Lu JB, 2013, ECOL ENG, V52, P175, DOI 10.1016/j.ecoleng.2012.12.107
   Muñoz-Ortuño M, 2017, SCI TOTAL ENVIRON, V609, P370, DOI 10.1016/j.scitotenv.2017.07.140
   O'Connell JL, 2017, REMOTE SENS ENVIRON, V201, P34, DOI 10.1016/j.rse.2017.08.008
   O'Connell JL, 2015, REMOTE SENS-BASEL, V7, P16480, DOI 10.3390/rs71215837
   O'Donnell JPR, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060477
   Ouyang ZT, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067315
   Ouyang ZT, 2011, ECOL INFORM, V6, P136, DOI 10.1016/j.ecoinf.2011.01.002
   Pan YD, 2016, NATURE, V534, P483, DOI 10.1038/nature18450
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Qin YW, 2015, ISPRS J PHOTOGRAMM, V105, P220, DOI 10.1016/j.isprsjprs.2015.04.008
   Rankine C, 2017, ENVIRON RES LETT, V12, DOI 10.1088/1748-9326/aa838c
   Rogers JN, 2015, REMOTE SENS ENVIRON, V156, P264, DOI 10.1016/j.rse.2014.09.035
   Sakamoto T, 2007, REMOTE SENS ENVIRON, V109, P295, DOI 10.1016/j.rse.2007.01.011
   Schwarz C, 2014, J GEOPHYS RES-EARTH, V119, P385, DOI 10.1002/2013JF002900
   Simas T, 2001, ECOL MODEL, V139, P1, DOI 10.1016/S0304-3800(01)00226-5
   Singh N, 2016, FOOD CHEM, V197, P316, DOI 10.1016/j.foodchem.2015.10.035
   Strong DR, 2013, SPARTINA INTRO CONSE
   Sun C, 2016, INT J APPL EARTH OBS, V45, P27, DOI 10.1016/j.jag.2015.10.008
   Tian B, 2010, ECOL ENG, V36, P1383, DOI 10.1016/j.ecoleng.2010.06.016
   Verstraete MM, 2008, ADV SPACE RES, V41, P1773, DOI 10.1016/j.asr.2007.05.066
   Wan HW, 2014, SCI WORLD J, DOI 10.1155/2014/638296
   Wang AQ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135538
   Wang C, 2016, WETLANDS, V36, P229, DOI 10.1007/s13157-016-0732-0
   Wang ZS, 2017, INT J APPL EARTH OBS, V59, P104, DOI 10.1016/j.jag.2017.03.008
   Windham L, 2004, ENVIRON TOXICOL CHEM, V23, P1520, DOI 10.1897/03-284
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu XW, 2014, ECOL ENG, V73, P469, DOI 10.1016/j.ecoleng.2014.09.087
   Zhang GL, 2013, P NATL ACAD SCI USA, V110, P4309, DOI 10.1073/pnas.1210423110
   Zhang L, 2015, ENVIRON EARTH SCI, V73, P3961, DOI 10.1007/s12665-015-4197-x
   Zhang WL, 2011, PROCEDIA ENVIRON SCI, V10, P2472, DOI 10.1016/j.proenv.2011.09.385
   Zhang XY, 2003, REMOTE SENS ENVIRON, V84, P471, DOI 10.1016/S0034-4257(02)00135-9
   Zhang Y, 2016, REMOTE SENS ENVIRON, V183, P154, DOI 10.1016/j.rse.2016.05.015
   Zhao B, 2009, ECOL INDIC, V9, P346, DOI 10.1016/j.ecolind.2008.05.009
   Zheng ZS, 2016, ACTA OCEANOL SIN, V35, P26, DOI 10.1007/s13131-016-0831-z
   Zhijun MA, 2013, CONSERV BIOL, V28, P150
   Zhou YT, 2016, INT J APPL EARTH OBS, V46, P1, DOI 10.1016/j.jag.2015.11.001
   Zhu CM, 2016, ACTA OCEANOL SIN, V35, P35, DOI 10.1007/s13131-016-0836-7
   Zhu YH, 2015, REMOTE SENS-BASEL, V7, P12192, DOI 10.3390/rs70912192
   Zuo P, 2012, ECOL ENG, V40, P160, DOI 10.1016/j.ecoleng.2011.12.014
NR 73
TC 15
Z9 16
U1 24
U2 126
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5175
EP 5195
DI 10.1007/s11042-018-6314-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500054
DA 2024-07-18
ER

PT J
AU Chaturvedi, AK
   Shukla, PK
AF Chaturvedi, Anoop Kumar
   Shukla, Piyush Kumar
TI Effective watermarking technique using optimal discrete wavelet
   transform and sanitization technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Embedding; Discrete wavelet transform;
   Singular value decomposition; Oppositional grasshopper optimization
ID IMAGE WATERMARKING; FRAGILE WATERMARKING; AUTHENTICATION; ALGORITHM;
   DETECTOR
AB Nowadays, the communication progression is turn out to be easy and effectual than previous days because of the development of science and technology, which is supplying numerous advantages to the consumer. Consequently, the consumer can access and preserve their data in the effectual manner. However, some of the difficulties are presented to transmit the data from one place to another. To overcome the problem in this paper an effective secure data transmission is proposed using optimal discrete wavelet transform (ODWT) and sanitization Algorithm. The proposed work consist of two module namely, embedding and extraction. For embedding process, the secrete image bit is inserted into the original image. Similarly, in extraction process, the inserted bit is extracted from the watermarked image without any information loss. Here, sanitization approach is applied to secrete image to attain the secrete bit. The performance of the proposed scheme is analyzed through various constraints namely peak signal to noise ratio (PSNR) and normalized correlation (NC).
C1 [Chaturvedi, Anoop Kumar] LCNT, Comp Sci & Engn, Bhopal, India.
   [Shukla, Piyush Kumar] UIT RGPV, Dept Comp Sci & Engn, Bhopal, India.
C3 Rajiv Gandhi Technological University
RP Chaturvedi, AK (corresponding author), LCNT, Comp Sci & Engn, Bhopal, India.
EM anoopkkumarc0277@gmail.com
RI user, user/GLQ-6797-2022; SHukla, Piyush Kumar/AAB-3521-2021; Shukla,
   Dr. Piyush Kumar/GVT-3949-2022; Shukla, Piyush Kumar/AAA-1785-2020
OI SHukla, Piyush Kumar/0000-0002-3715-3882; Shukla, Dr. Piyush
   Kumar/0000-0002-3715-3882; 
CR Abuturab RM, 2016, ELSEVIER OPTICS LASE, P1
   AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   [Anonymous], EVID BASED COMPLEMEN
   [Anonymous], 2016, INT J COMPUT SCI MOB
   Bouslimia D, 2016, ELSEVIER SIGNAL PROC, P1
   Gonge SS, 2016, PROCEDIA COMPUT SCI, V89, P732, DOI 10.1016/j.procs.2016.06.046
   Hu H, 2016, ELSEVIER INT J ELECT, P1
   Kashyap N., 2012, INT J MODERN ED COMP, V4, P50, DOI [10.5815/ijmecs. 2012.03.07, DOI 10.5815/IJMECS.2012.03.07.[]
   Khandare S, 2016, PROCEDIA COMPUT SCI, V78, P698, DOI 10.1016/j.procs.2016.02.119
   Liu X, 2016, MOBILE NETW APPL, V21, P908, DOI 10.1007/s11036-016-0711-y
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Nayak MR, 2016, ELSEVIER INT J ELECT, V71, P1
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Shao Z., 2016, EXP MECH, P1
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Su P-C, 2016, ELSEVIER J VISUAL CO, P1
   Swamy T N, 2014, INT J ENG RES APPL, V4, P102
   Thien H-T, 2016, ELSEVIER EXPERT SYST, P1
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wójtowicz W, 2016, J VIS COMMUN IMAGE R, V38, P1, DOI 10.1016/j.jvcir.2016.02.006
   Zhi-qiua X, 2016, EFFECT EMOTIONAL MOT, P1
NR 25
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13161
EP 13177
DI 10.1007/s11042-020-08639-6
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515608600001
DA 2024-07-18
ER

PT J
AU Liu, DZ
   Shen, J
   Vijayakumar, P
   Wang, AX
   Zhou, TQ
AF Liu, Dengzhi
   Shen, Jian
   Vijayakumar, Pandi
   Wang, Anxi
   Zhou, Tianqi
TI Efficient data integrity auditing with corrupted data recovery for edge
   computing in enterprise multimedia security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge computing; Enterprise multimedia security; Data integrity auditing;
   Data recovery
AB Enterprise multimedia can provide various services for enterprises and staffs, such as minutes of the meeting, staff training and internal news release. The format of enterprise multimedia data includes images, videos, documents, etc. The diversity and complexity of the multimedia data content increase the difficulty of storage and processing of the data. Using the nearest edge nodes to store and process the enterprise multimedia data can reduce the investment of the local storage hardware, and improve the utilization rate of peripheral dispersing devices. However, edge nodes are not fully trusted. The lack of service managers in edge computing determines that the stored enterprise multimedia data suffers from many security threats. To guarantee the security of the multimedia data in enterprises, an efficient data integrity auditing scheme is proposed for edge computing in this paper that can be used in enterprise multimedia security. Note that the technology of the homomorphic authenticator is used to construct the proposed scheme, which determines that our scheme can provide data integrity auditing with high efficiency. To reduce the financial loss caused by data corrupted for enterprise, the enterprise multimedia data are backed up in the remote cloud. Moreover, the data storage structure of One-way Linked Information Table (OLIT) is used to store the history multimedia data for enterprise, which provides high efficiency of the data recovery. In security analysis, the correctness proof is provided, and the data update auditing and the replay attack resistance are also analyzed. Performance analysis shows that our scheme has low computational cost that can be employed in the practical enterprise multimedia security.
C1 [Liu, Dengzhi; Shen, Jian; Wang, Anxi; Zhou, Tianqi] Nanjing Univ Informat Sci & Technologys, Jiangsu Engn Ctr Network Monitoring, Nanjing, Peoples R China.
   [Shen, Jian] State Key Lab Cryptol, Beijing, Peoples R China.
   [Shen, Jian] Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen, Peoples R China.
   [Vijayakumar, Pandi] Univ Coll Engn Tindivanam, Dept Comp Sci & Engn, Tindivanam, India.
C3 Peng Cheng Laboratory
RP Shen, J (corresponding author), Nanjing Univ Informat Sci & Technologys, Jiangsu Engn Ctr Network Monitoring, Nanjing, Peoples R China.; Shen, J (corresponding author), State Key Lab Cryptol, Beijing, Peoples R China.; Shen, J (corresponding author), Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen, Peoples R China.
EM s_shenjian@126.com
RI Pandi, Vijayakumar/Y-4636-2019; Shen, Jian/AFL-0619-2022; shi,
   zhensheng/GXN-3967-2022; Zhou, Tianqi/GRN-8430-2022
OI Pandi, Vijayakumar/0000-0001-5451-8946; Shen, Jian/0000-0003-0519-9058
FU National Natural Science Foundation of China [U1836115, 61672295,
   61922045, 61672290]; Natural Science Foundation of Jiangsu Province
   [BK20181408]; Foundation of State Key Laboratory of Cryptology
   [MMKFKT201830]; Peng Cheng Laboratory Project of Guangdong Province
   [PCL2018KP004]; CICAEET fund; PAPD fund; Postgraduate Research &
   Practice Innovation Program of Jiangsu Province [SJKY19_0955]
FX This work is supported by the National Natural Science Foundation of
   China under Grants No. U1836115, No. 61672295, No. 61922045, No.
   61672290, the Natural Science Foundation of Jiangsu Province under Grant
   No. BK20181408, the Foundation of State Key Laboratory of Cryptology
   under Grant No. MMKFKT201830, the Peng Cheng Laboratory Project of
   Guangdong Province PCL2018KP004, the CICAEET fund, and the PAPD fund,
   the Postgraduate Research & Practice Innovation Program of Jiangsu
   Province under Grant SJKY19_0955.
CR Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Baheti A, 2014, INT CONF COMM SYST, P664, DOI 10.1109/CSNT.2014.139
   BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200
   BIMONTE S., 2005, 8th ACM International workshop on Data Warehousing and OLAP (DOLAP), P39
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Byun SC, 2003, ITRE2003: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: RESEARCH AND EDUCATION, P412
   Chang V, 2017, 2017 INT C ENG TECHN, P1
   Chang V, 2016, P IEEE 7 INT C CLOUD, P16
   Chang V, 2018, MULTIMED TOOLS APPL, V77, P17693, DOI 10.1007/s11042-017-5186-8
   Chen H, 2013, J APPL SIGNAL PROCES, V13, P1291
   Han JW, 1998, LECT NOTES ARTIF INT, V1394, P144
   Hsia CH, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.3.030402
   Hsia CH, 2018, IEEE SENS J, V18, P790, DOI 10.1109/JSEN.2017.2772799
   Hsia CH, 2017, MULTIMED TOOLS APPL, V76, P25179, DOI 10.1007/s11042-016-4296-z
   Jian S, 2020, IEEE T VEH TECHNOL, V69, P807, DOI 10.1109/TVT.2019.2946935
   Jiang H, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: COMPANION PROCEEDINGS (ICSE-COMPANION 2019), P232, DOI 10.1109/ICSE-Companion.2019.00090
   Juels A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P584
   Jung KD, 2017, MULTIMED TOOLS APPL, V76, P19983, DOI 10.1007/s11042-016-4016-8
   Li XY, 2017, IEEE ACCESS, V5, P393, DOI 10.1109/ACCESS.2016.2609884
   Liu DZ, 2020, J REAL-TIME IMAGE PR, V17, P175, DOI 10.1007/s11554-019-00887-6
   Liu DZ, 2018, INT J SENS NETW, V27, P95, DOI 10.1504/IJSNET.2018.092638
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Narang S, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P529, DOI 10.1109/ICME.2000.869655
   Pang HH, 2004, PROC INT CONF DATA, P560, DOI 10.1109/ICDE.2004.1320027
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Shacham H, 2008, LECT NOTES COMPUT SC, V5350, P90, DOI 10.1007/978-3-540-89255-7_7
   Shen J, 2019, IEEE T VEH TECHNOL, V68, P11213, DOI 10.1109/TVT.2019.2938968
   Shen J, 2020, IEEE T EMERG TOP COM, V8, P280, DOI 10.1109/TETC.2017.2776402
   Shen J, 2017, J INTERNET TECHNOL, V18, P833, DOI 10.6138/JIT.2017.18.4.20160415
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shi WS, 2016, COMPUTER, V49, P78, DOI 10.1109/MC.2016.145
   Tang SH, 2016, IEEE T COMPUT, V65, P2325, DOI 10.1109/TC.2015.2479609
   Tang SH, 2014, IEEE T PARALL DISTR, V25, P3253, DOI 10.1109/TPDS.2013.2297917
   Wang C, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4643
   Wang C, 2013, IEEE T COMPUT, V62, P362, DOI 10.1109/TC.2011.245
   Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183
   Xiao C, 2016, 2016 IEEE 3RD INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD), P148, DOI 10.1109/CSCloud.2016.37
   Yang K, 2013, IEEE T PARALL DISTR, V24, P1717, DOI 10.1109/TPDS.2012.278
   Zhang MW, 2018, J AMB INTEL HUM COMP, V9, P1889, DOI 10.1007/s12652-017-0672-4
   Zhou TQ, 2020, FUTURE GENER COMP SY, V108, P1307, DOI 10.1016/j.future.2018.04.008
NR 42
TC 12
Z9 13
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10851
EP 10870
DI 10.1007/s11042-019-08558-1
EA JAN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000515608600004
DA 2024-07-18
ER

PT J
AU Yi, CH
   Cho, JW
AF Yi, Chuho
   Cho, Jungwon
TI Improving the performance of multimedia pedestrian classification with
   images synthesized using a deep convolutional generative adversarial
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian classification; Multimedia; Synthetic images; DCGAN
AB Generative adversarial networks (GANs) are used to improve pedestrian identification performance and reduce labelling work, which is a significant burden on deep learning applications. As the input data are images, a deep convolutional generative adversarial network (DCGAN) is used, as the convolutional operation performs better than a typical GAN. The results produced using the proposed method are evaluated against the performance of a convolutional neural network according to the ratio of real and synthetic images generated as a result of training. Classification performance as a result of this ratio is analyzed; this will aid many developers who may use the results of this paper to train systems efficiently with less data.
C1 [Yi, Chuho] Dong Seoul Univ, Dept Elect, Seongnam 13117, South Korea.
   [Cho, Jungwon] Jeju Natl Univ, Dept Comp Educ, Jeju 63243, South Korea.
C3 Jeju National University
RP Cho, JW (corresponding author), Jeju Natl Univ, Dept Comp Educ, Jeju 63243, South Korea.
EM jwcho@jejunu.ac.kr
OI Cho, Jungwon/0000-0001-5746-9596
CR Chollet F, 2015, KERAS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gal Y., 2016, PMLR, V48, P1050, DOI DOI 10.5555/3045390.3045502
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Goodfellow I., 2014, COMMUN ACM
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He LH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P473, DOI 10.18653/v1/P17-1044
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Liang Zhao, 1999, Proceedings 199 IEEE/IEEJ/JSAI International Conference on Intelligent Transportation Systems (Cat. No.99TH8383), P298, DOI 10.1109/ITSC.1999.821070
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Oren Michael., 1997, PROC CVPR IEEE, P193, DOI DOI 10.1109/CVPR.1997.609319
   Radford A., 2016, INT C LEARN REPR
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Xu B., 2015, Empirical evaluation of rectified activations in convolutional network, DOI DOI 10.48550/ARXIV.1505.00853
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Zhang C., 2016, UNDERSTANDING DEEP L
NR 18
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34697
EP 34712
DI 10.1007/s11042-019-08545-6
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000574100700001
DA 2024-07-18
ER

PT J
AU Wary, A
   Neelima, A
AF Wary, Alongbar
   Neelima, Arambam
TI Ring decomposition based video copy detection using global ordinal
   measure features and local features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual hashing or fingerprinting; Video copy detection; Ring partition;
   Pre-classifier; Key-frame; OM; DCT; TIRI; HOG; SVD
ID STATISTICAL IMAGE FEATURES; ROBUST; COLOR; SCHEME
AB Visual hashing-based or fingerprinting-based video copy detection approach has been adopted numerously by the video search community due to significant escalation of manipulated copies of original videos over the Internet. Most of the existing video copy detection approaches are robust against the content-preserving distortions such as brightness enhancement and compression, but less robust against the geometric distortions such as rotation and scaling. To mitigate the problem of computation overhead is still challenging in video copy detection. Moreover, there exist a trade-off between discriminability and robustness properties in most of the existing copy detection approaches. In this paper, an effective and fast video copy detection method is presented by exploiting both spatial-temporal information to tackle the above-mentioned challenges. The novelty of proposed method lies in reducing the computation overhead by generating an intermediate candidate database that are similar to the query video using ring-based Ordinal Measure (OM). Then, distinct visual features based on Histogram of Oriented Gradient (HOG) and Singular Value Decomposition (SVD) are extracted from each key-frame of every scenes of the videos of an intermediate candidate database and a query video for copy detection. To avoid the creation of redundant key-frames, the video frames are grouped into different scenes based on Discrete Cosine Transform (DCT). To further preserve the spatial-temporal information, the Temporally Informative Representative Image (TIRI) is used to generate each key-frame of every scenes of videos. The experimental result shows that the proposed method is more efficient and robust against various distortions which outperforms the state-of-the-art copy detection approaches.
C1 [Wary, Alongbar; Neelima, Arambam] NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Wary, A (corresponding author), NIT Nagaland, Dept Comp Sci & Engn, Chumukedima 797103, Dimapur, India.
EM alongwar56@gmail.com; neelimaarambam@yahoo.co.in
RI Wary, Alongbar/GLV-0568-2022
OI Neelima, Arambam/0009-0003-2106-7757
CR [Anonymous], IEEE10 INT C IM SIGN
   [Anonymous], 2016, J. Signal Inf. Process, DOI [10.4236/jsip.2016.72010, DOI 10.4236/JSIP.2016.72010]
   [Anonymous], IEEE 6 INT C INF TEC
   [Anonymous], INF SYST TELECOMMUN
   Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Boukhari A, 2016, J VIS COMMUN IMAGE R, V34, P50, DOI 10.1016/j.jvcir.2015.10.015
   Britz D., 2017, P 2017 C EMPIRICAL M, P1442, DOI [10.18653/v1/D17-1151, DOI 10.18653/V1/D17-1151]
   Chen DY, 2013, J VIS COMMUN IMAGE R, V24, P544, DOI 10.1016/j.jvcir.2013.04.005
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Chen Q, 2011, SECUR COMMUN NETW, V4, P1369, DOI 10.1002/sec.264
   Chiu CY, 2013, NEUROCOMPUTING, V105, P70, DOI 10.1016/j.neucom.2012.04.036
   Chongtham C, 2018, IJST-T ELECTR ENG, V42, P107, DOI 10.1007/s40998-018-0052-x
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gu XG, 2013, INT CONF ACOUST SPEE, P1508, DOI 10.1109/ICASSP.2013.6637903
   Guiguang Ding, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P347, DOI 10.1109/ISM.2010.59
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   Hao YB, 2017, IEEE T MULTIMEDIA, V19, P1, DOI 10.1109/TMM.2016.2610324
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P17309, DOI 10.1007/s11042-017-5307-4
   Himeur Y, 2015, IEEE INT SYMP SIGNAL, P495, DOI 10.1109/ISSPIT.2015.7394386
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Karsh RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3639-6
   Kitanovski V., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P140, DOI 10.1109/EUVIP.2010.5699100
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Li JF, 2018, CHINA GEOL, V1, P5, DOI 10.31035/cg2018003
   Li JN, 2014, INT SYMP WIREL, P97, DOI 10.1109/WPMC.2014.7014798
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Liu L, 2007, INT CONF ACOUST SPEE, P973
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Mao JF, 2016, NEUROCOMPUTING, V173, P2022, DOI 10.1016/j.neucom.2015.09.001
   Neelima A, 2017, IMAGING SCI J, V65, P62, DOI 10.1080/13682199.2016.1260216
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Sadek RA, 2012, INT J ADV COMPUT SC, V3, P26
   Setyawan I, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY SYSTEMS AND INNOVATION (ICITSI), P111, DOI 10.1109/ICITSI.2014.7048247
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Sun R, 2017, OPTIK, V128, P139, DOI 10.1016/j.ijleo.2016.09.105
   Tasdemir Kasim, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3134, DOI 10.1109/ICPR.2010.767
   Thomas RM, 2015, PROCEDIA COMPUT SCI, V46, P1668, DOI 10.1016/j.procs.2015.02.106
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang RB, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P223, DOI 10.1109/BigMM.2016.12
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu PH, 2009, INT CONF ACOUST SPEE, P3465, DOI 10.1109/ICASSP.2009.4960371
   YANG JF, 1995, IEEE T IMAGE PROCESS, V4, P1141, DOI 10.1109/83.403419
   Zhang X, 2018, WIRELESS PERS COMMUN, V103, P401, DOI 10.1007/s11277-018-5450-x
   Zhijie Zhang, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P13, DOI 10.1109/ICAL.2010.5585375
NR 55
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8287
EP 8323
DI 10.1007/s11042-019-08412-4
EA JAN 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505414100002
DA 2024-07-18
ER

PT J
AU Waldekar, S
   Saha, G
AF Waldekar, Shefali
   Saha, Goutam
TI Analysis and classification of acoustic scenes with wavelet
   transform-based mel-scaled features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCASE; Environmental sounds; Haar function; MFCC; SVM
ID OF-FRAMES APPROACH; URBAN SOUNDSCAPES; SUFFICIENT MODEL; RECOGNITION
AB Analysis of audio from real-life environments and their categorization into different acoustic scenes can make context-aware devices and applications more efficient. Unlike speech, such signals have overlapping frequency content while spanning a much larger audible frequency range. Also, they are less structured than speech/music signals. Wavelet transform has good time-frequency localization ability owing to its variable-length basis functions. Consequently, it facilitates the extraction of more characteristic information from environmental audio. This paper attempts to classify acoustic scenes by a novel use of wavelet-based mel-scaled features. The design of the proposed framework is based on the experiments conducted on two datasets which have same scene classes but differ with regard to sample length and amount of data (in hours). It outperformed two benchmark systems, one based on mel-frequency cepstral coefficients and Gaussian mixture models and the other based on log mel-band energies and multi-layer perceptron. We also present an investigation on the use of different train and test sample duration for acoustic scene classification.
C1 [Waldekar, Shefali; Saha, Goutam] IIT Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Waldekar, S (corresponding author), IIT Kharagpur, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
EM shefaliw@ece.iitkgp.ernet.in; gsaha@ece.iitkgp.ernet.in
RI Saha, Goutam/AAH-6281-2020; Waldekar, Shefali/ABA-8480-2020
OI Saha, Goutam/0000-0001-6187-1684; Waldekar, Shefali/0000-0002-8945-9576
CR [Anonymous], IEEE AASP CHALL DET
   [Anonymous], 2013, IEEE Workshop on WASPAA, DOI DOI 10.1109/WASPAA.2013.6701819
   [Anonymous], 2016, IEEE AASP CHALL DET
   Aucouturier JJ, 2007, J ACOUST SOC AM, V122, P881, DOI 10.1121/1.2750160
   Barchiesi D, 2015, IEEE SIGNAL PROC MAG, V32, P16, DOI 10.1109/MSP.2014.2326181
   Bisot V, 2017, IEEE-ACM T AUDIO SPE, V25, P1216, DOI 10.1109/TASLP.2017.2690570
   BROWN GJ, 1994, COMPUT SPEECH LANG, V8, P297, DOI 10.1006/csla.1994.1016
   Brummer N., 2007, Focal multi-class: Toolkit for evaluation, fusion and calibration of multi-class recognition scorestutorial and user manual
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dubois D, 2006, ACTA ACUST UNITED AC, V92, P865
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Ghodasara V, 2015, SPEECH MUSIC CLASSIF
   Gowdy JN, 2000, INT CONF ACOUST SPEE, P1351, DOI 10.1109/ICASSP.2000.861829
   Kim K, 2000, IEEE SYS MAN CYBERN, P2891, DOI 10.1109/ICSMC.2000.884438
   Lagrange M, 2015, J ACOUST SOC AM, V138, pEL487, DOI 10.1121/1.4935350
   Li YX, 2018, MULTIMED TOOLS APPL, V77, P897, DOI 10.1007/s11042-016-4332-z
   Lyon RF, 2010, IEEE SIGNAL PROC MAG, V27, P131, DOI 10.1109/MSP.2010.937498
   Ma J., 2019, MULTIMEDIA TOOLS APP, P1
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mesaros A, 2017, IEEE-ACM T AUDIO SPE
   Mesaros A, 2018, 16 INT WORKSH AC SIG
   Mesaros A., 2017, P DCASE 2017 WORKSH
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Mun S., 2017, TECH REP
   Phan H, 2018, ARXIV181101095
   Rabaoui A, 2008, IEEE T INF FOREN SEC, V3, P763, DOI 10.1109/TIFS.2008.2008216
   Rakotomamonjy A, 2015, IEEE-ACM T AUDIO SPE, V23, P142, DOI 10.1109/TASLP.2014.2375575
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Tang G, 2018, MULTIMED TOOLS APPL, P1
   Ten Daubechies I., 1992, lecture on wavelets
   Tufekci Z., 2000, Proceedings of the IEEE SoutheastCon 2000. `Preparing for The New Millennium' (Cat. No.00CH37105), P116, DOI 10.1109/SECON.2000.845444
   Tzanetakis G., 2001, P C ACOUST MUSIC THE, V66
   Waldekar S., 2018, DIGITAL SIGNAL PROCE
   Waldekar S, 2018, INTERSPEECH, P3323, DOI 10.21437/Interspeech.2018-2083
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
NR 38
TC 11
Z9 12
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7911
EP 7926
DI 10.1007/s11042-019-08279-5
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356500003
DA 2024-07-18
ER

PT J
AU Brahimi, N
   Bouden, T
   Brahimi, T
   Boubchir, L
AF Brahimi, Nabila
   Bouden, Toufik
   Brahimi, Tahar
   Boubchir, Larbi
TI A novel and efficient 8-point DCT approximation for image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; DCT; Approximation; Fast algorithm; JPEG
ID DISCRETE COSINE; TRANSFORM; ALGORITHM
AB The Discrete Cosine Transform is widely used in the field of still image compression. Many integer approximations are given in the literature whereas the most of these transforms requires bit shift operations. This paper presents an efficient and low complexity integer approximation of the DCT for image compression. Our new approach involves replacing the bit shift elements of a variant of the Signed DCT transform by zeros, in order to eliminate the bit shift operations. As a result, all elements of the proposed transform are zeros and +/- 1. Indeed, the proposed transform retains all the characteristics of its original transform, such as orthogonality and high energy compaction capabilities, while generating computing cost savings. Experiments show that the proposed transform has a good compromise performance-computational complexity as well as state-of the-art DCT approximations. Moreover, an efficient algorithm primarily involving a small amount of arithmetical computation is well developed as no multiplications and bit-shift operations are required, with only 16 additions being involved.
C1 [Brahimi, Nabila] Univ Mohammed Seddik Benyahia, NDT Lab, Elect Dept, BP 98, Jijel 18000, Algeria.
   [Bouden, Toufik] Univ Mohammed Seddik Benyahia, NDT Lab, Automat Dept, BP 98, Jijel 18000, Algeria.
   [Brahimi, Tahar] Univ Mohammed Seddik Benyahia, L2E1 Lab, Elect Dept, BP 98, Jijel 18000, Algeria.
   [Boubchir, Larbi] Univ Paris 08, LIASD Res Lab, Dept Comp Sci, Paris, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis; Universite Paris-VIII
RP Brahimi, N (corresponding author), Univ Mohammed Seddik Benyahia, NDT Lab, Elect Dept, BP 98, Jijel 18000, Algeria.
EM nabila.brahimi@univ-jijel.dz; bouden_toufik@univ-jijel.dz;
   t.brahimi@gmail.com; boubehir@ai.univ-paris8.fr
RI Boubchir, Larbi/I-9623-2019; BRAHIMI, Nabila/JDW-4272-2023
OI Boubchir, Larbi/0000-0002-5668-6801; BRAHIMI, Nabila/0000-0002-7576-5281
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Almurib HAF, 2018, IEEE T COMPUT, V67, P149, DOI 10.1109/TC.2017.2731770
   [Anonymous], INT C SOFTW INT TECH
   Bayer FM, 2012, ELECTRON LETT, V48, P919, DOI 10.1049/el.2012.1148
   Bouguezel S, 2008, ELECTRON LETT, V44, P1249, DOI 10.1049/el:20082239
   Bouguezel S, 2013, IEEE T CIRCUITS-I, V60, P989, DOI 10.1109/TCSI.2012.2224751
   Bouguezel S, 2011, IEEE INT SYMP CIRC S, P2145
   Brahimi N., 2011, 2011 7th International Workshop on Systems, Signal Processing and their Applications (WOSSPA 2011), P71, DOI 10.1109/WOSSPA.2011.5931415
   Brahimi T, 2017, MULTIMED TOOLS APPL, V76, P16783, DOI 10.1007/s11042-016-3952-7
   Brahimi T, 2017, AEU-INT J ELECTRON C, V73, P183, DOI 10.1016/j.aeue.2017.01.008
   Brahimi T, 2009, DIGIT SIGNAL PROCESS, V19, P220, DOI 10.1016/j.dsp.2008.07.012
   Cintra RJ, 2011, IEEE SIGNAL PROC LET, V18, P579, DOI 10.1109/LSP.2011.2163394
   Coelho DFG, 2016, IET SIGNAL PROCESS, V10, P633, DOI 10.1049/iet-spr.2015.0175
   Ezhilarasi R, 2020, MULTIMED TOOLS APPL, V79, P8539, DOI 10.1007/s11042-018-5960-2
   Haweel RT, 2016, J VIS COMMUN IMAGE R, V40, P357, DOI 10.1016/j.jvcir.2016.07.003
   Haweel TI, 2001, SIGNAL PROCESS, V81, P2309, DOI 10.1016/S0165-1684(01)00106-2
   Jridi M, 2015, IEEE T CIRCUITS-I, V62, P449, DOI 10.1109/TCSI.2014.2360763
   LEE MH, 1986, IEEE T ACOUST SPEECH, V34, P1666, DOI 10.1109/TASSP.1986.1164972
   Miano J., 1999, Compressed image file formats: Jpeg, png, gif, xbm, bmp
   Oliveira RS, 2019, MULTIDIM SYST SIGN P, V30, P1363, DOI 10.1007/s11045-018-0601-5
   Potluri US, 2014, IEEE T CIRCUITS-I, V61, P1727, DOI 10.1109/TCSI.2013.2295022
   Rao KR, 2014, SIGNALS COMMUN TECHN, P51, DOI 10.1007/978-94-007-6742-3_3
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Sayood K, 2017, Introduction to data compression
   Senapati R, 2010, P ANN IEEE IND C IND, P1, DOI [10.1109/INDCON.2010.5712707, DOI 10.1109/INDCON.2010.5712707]
   TAMBOLI P, 2015, INT J ADV RES ELECT, V4, P6185
   Wahid KA, 2007, IEEE T CIRCUITS-II, V54, P700, DOI 10.1109/TCSII.2007.898891
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 29
TC 22
Z9 22
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7615
EP 7631
DI 10.1007/s11042-019-08325-2
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600002
DA 2024-07-18
ER

PT J
AU Christo, MS
   Vasanth, K
   Varatharajan, R
AF Christo, Mary Subaja
   Vasanth, K.
   Varatharajan, R.
TI A decision based asymmetrically trimmed modified winsorized median
   filter for the removal of salt and pepper noise in images and videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and pepper noise; Asymmetrically trimmed modified winsorized
   median; Detail preservation; Non linear filter
ID MEAN FILTER
AB A decision based asymmetrically trimmed Winsorized median for the removal of salt and pepper noise in images and videos is proposed. The proposed filter initially classifies the pixels as noisy and non noisy and later replaces the noisy pixels with asymmetrically trimmed modified winsorized median leaving the non noisy pixels unaltered. Exhaustive experiments were conducted on standard image database and the performance of the proposed filter was evaluated in terms of both quantitative and qualitatively with existing algorithm. It was found that the proposed algorithm was found to exhibit excellent noise suppression capabilities by preserving the fine information of the image even at higher noise densities. The performance of the proposed filter was found good even for videos.
C1 [Christo, Mary Subaja] Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 602105, Tamil Nadu, India.
   [Vasanth, K.] Vidya Jyothi Inst Technol, Dept ECE, Hyderabad, Telangana, India.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Varatharajan, R (corresponding author), Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM marysubaja@gmail.com; vasanthecek@gmail.com; varathu21@yahoo.com
RI Subaja, Mary/ABE-1984-2021; kishore babu, vasanth/A-4310-2017
OI kishore babu, vasanth/0000-0002-6886-5727; Christo, Mary
   Subaja/0000-0002-2702-9271
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   [Anonymous], P INT C EL COMM SYST
   [Anonymous], IEEE T SIGNAL PROCES
   [Anonymous], 2014, INT J APPL ENG RES
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Balasubramanian S, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1, P99
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jayasree PS, 2013, SIGNAL IMAGE VIDEO P, V7, P1145, DOI 10.1007/s11760-012-0368-3
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Nair MS, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P426, DOI 10.1109/CISP.2008.21
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Vasanth K, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P855
   Vasanth K, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1, DOI 10.1109/ICCICCT.2015.7475238
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Veerakumar T., 2012, INT J COMPUTER APPL, V39, P29, DOI DOI 10.5120/4874-7303
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 24
TC 37
Z9 38
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 415
EP 432
DI 10.1007/s11042-019-08124-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600017
DA 2024-07-18
ER

PT J
AU Hu, L
   Xiao, J
   Wang, Y
AF Hu, Liang
   Xiao, Jun
   Wang, Ying
TI Efficient and automatic plane detection approach for 3-D rock mass point
   clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Laser scanning; Plane detection; Rock mass; Region growing
ID HOUGH TRANSFORM; LIDAR DATA; CLASSIFICATION; RECONSTRUCTION;
   SEGMENTATION
AB The detection of planar regions from three-dimensional (3-D) laser scanning point clouds has become more and more significant in many scientific fields, including 3-D reconstruction, augmented reality and analysis of discontinuities. In rock engineering, planes extracted from rock mass point clouds are the foundational step to build 3-D numerical models of rock mass, which is significant in analysis of rock stability. In the past, several approaches have been proposed for detecting planes from TLS point clouds. However, these methods have difficulties in processing rock points because of the uniqueness of rock. This paper introduces a novel and efficient method for plane detection from 3-D rock mass point clouds. Firstly, after filtering the raw point clouds of rock mass acquired through laser scanning, the point cloud is split into some small voxels according to the specified resolution. Then, for the purpose of acquisition of high-quality growth units, an accurate coplanarity test process is used in each voxel. Meanwhile, the accurate neighborhood information can be built according to the result of coplanarity test. Finally, small voxels are clustered into a completed plane by region growing and the procedure of postprecessing. The performance of this method was tested in one icosahedron point cloud and three rock mass point clouds. Compared with the existing methods, the results demonstrate superior performance of our method in the field of plane detection.
C1 [Hu, Liang; Xiao, Jun; Wang, Ying] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Xiao, J (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM huliang13@mails.ucas.ac.cn; xiaojun@ucas.ac.cn; ywang@ucas.ac.cn
OI Xiao, Jun/0000-0002-1799-3948
FU Key Research Program of Frontier Sciences CAS [QYZDY-SSW-SYS004];
   Beijing Nova program [Z171100001117048]; Beijing science and technology
   project [Z181100003818019]; Open Research Fund of Key Laboratory of
   Space Utilization, Chinese Academy of Sciences; Strategic Priority
   Research Program of the Chinese Academy of Sciences [XDA23090304];
   National Natural Science Foundation of China [61471338, 61802362]; Youth
   Innovation Promotion Association CAS [2015361]
FX This work is supported by the Key Research Program of Frontier Sciences
   CAS (QYZDY-SSW-SYS004), Beijing Nova program (Z171100001117048), Beijing
   science and technology projectZ181100003818019, the Open Research Fund
   of Key Laboratory of Space Utilization, Chinese Academy of Sciences, the
   Strategic Priority Research Program of the Chinese Academy of Sciences
   (No. XDA23090304), National Natural Science Foundation of China
   (61471338, 61802362), and Youth Innovation Promotion Association CAS
   (2015361).
CR Abellán A, 2014, EARTH SURF PROC LAND, V39, P80, DOI 10.1002/esp.3493
   [Anonymous], CVPR
   [Anonymous], SIGGRAPH
   [Anonymous], COMPUT GRAPH FORUM
   [Anonymous], FAST PLANE DETECTION
   [Anonymous], INT JOINT C ART INT
   [Anonymous], 2010, P 2 INT C MACH CONTR
   Awwad TM, 2010, PHOTOGRAMM REC, V25, P5, DOI 10.1111/j.1477-9730.2009.00564.x
   Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3
   BRETAR F, 2005, P IAPR C MACH VIS AP, P452
   Deschaud J.-E., 2010, 3DPVT
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   Ferrero AM, 2009, ROCK MECH ROCK ENG, V42, P631, DOI 10.1007/s00603-008-0010-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forlani G, 2006, PATTERN ANAL APPL, V8, P357, DOI 10.1007/s10044-005-0018-2
   Gigli G, 2009, NAT HAZARD EARTH SYS, V9, P1759, DOI 10.5194/nhess-9-1759-2009
   Gigli G, 2011, INT J ROCK MECH MIN, V48, P187, DOI 10.1016/j.ijrmms.2010.11.009
   Gomes RK, 2016, COMPUT GEOSCI-UK, V90, P170, DOI 10.1016/j.cageo.2016.02.011
   Hähnel D, 2003, ROBOT AUTON SYST, V44, P15, DOI 10.1016/S0921-8890(03)00007-1
   He L, 2013, INT J ROCK MECH MIN, V64, P22, DOI 10.1016/j.ijrmms.2013.08.015
   Holz D, 2013, ADV INTELL SYST, V194, P61
   Hu L, 2020, VISUAL COMPUT, V36, P669, DOI 10.1007/s00371-019-01648-z
   Hu ZZ, 2017, MULTIMED TOOLS APPL, V76, P24343, DOI 10.1007/s11042-016-4192-6
   Junhao Xiao, 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P40, DOI 10.1109/MFI.2012.6343035
   Lato M, 2013, COMPUT GEOSCI-UK, V50, P106, DOI 10.1016/j.cageo.2012.06.014
   Lato MJ, 2012, INT J ROCK MECH MIN, V54, P150, DOI 10.1016/j.ijrmms.2012.06.003
   Leng XX, 2016, PHOTOGRAMM REC, V31, P166, DOI 10.1111/phor.12145
   Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020
   Liu J, 2014, OPTIK, V125, P2000, DOI 10.1016/j.ijleo.2013.03.176
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Nie G., 2019, 2019 IEEE INT C COMP, P3283
   Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729
   Riquelme AJ, 2014, COMPUT GEOSCI-UK, V68, P38, DOI 10.1016/j.cageo.2014.03.014
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Tarsha-Kurdi F., 2007, INT ARCH PHOTOGRAMME, V36, P407
   Umili G, 2013, COMPUT GEOSCI-UK, V51, P182, DOI 10.1016/j.cageo.2012.07.026
   Vöge M, 2013, ENG GEOL, V164, P155, DOI 10.1016/j.enggeo.2013.07.008
   Vosselman G., 2004, P INT SOC PHOTOGRAMM, V46, P33
   Wang JF, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P456, DOI 10.1109/ICARA.2015.7081191
   Wulder MA, 2012, REMOTE SENS ENVIRON, V121, P196, DOI 10.1016/j.rse.2012.02.001
   Xiao JH, 2013, ROBOT AUTON SYST, V61, P1641, DOI 10.1016/j.robot.2013.07.001
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Zeineldin RA, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P373, DOI 10.1109/SAI.2016.7556009
   Zhang M, 2012, ELECTRON LETT, V48, P764, DOI 10.1049/el.2012.0126
NR 46
TC 16
Z9 19
U1 5
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 839
EP 864
DI 10.1007/s11042-019-08189-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600035
DA 2024-07-18
ER

PT J
AU Singh, MK
   Singh, AK
   Singh, N
AF Singh, Mahesh K.
   Singh, A. K.
   Singh, Narendra
TI Multimedia utilization of non-computerized disguised voice and acoustic
   similarity measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-electronic disguised voice; Statistical analysis; Classifiers
ID SPEAKER VERIFICATION; FEATURES; IDENTIFICATION; SPEECH
AB In this paper, an identification of a speaker for multimedia application under non-electronically disguised voice is performed. In non-electronically disguised voice under physical variation of speech, it is a difficult task to identify the speaker in speech signal processing application area. Due to changes in the frequency spectrum of the speech signal during non- electronic disguising, some methods like Mel-frequency cepstrum coefficients (MFCC), delta Mel-frequency cepstrum coefficients (Delta MFCC) and double delta Mel-frequency cepstrum coefficients (Delta Delta MFCC) are used to specify the frequencies spectral property. A new algorithm developed, based on acoustic feature extraction by MFCC technique of text-dependent speech signal of all speaker's and changed their speech by six physical variation methods. The acoustic features which include the correlation coefficients and the mean value are extracted by the MFCC, Delta MFCC and Delta Delta MFCC feature extraction method. Thereafter, different classifiers based on feature extraction are used to classify the non-electronically disguised voice and normal voice.
C1 [Singh, Mahesh K.; Singh, Narendra] JUET, Dept ECE, Guna, MP, India.
   [Singh, A. K.] Thapar Inst Engn & Technol, Dept ECE, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, MK (corresponding author), JUET, Dept ECE, Guna, MP, India.
EM mahesh.092002.ece@gmail.com; ashutoshsingh79@yahoo.com;
   narendra.singh@juet.ac.in
RI Singh, MK/HMP-0689-2023; Singh, Narendra/AAH-5380-2021; Singh, Mahesh
   Kumar/JNT-1040-2023; Singh, Major/P-9790-2019
OI Singh, Mahesh Kumar/0000-0002-5007-3721; Singh,
   Major/0000-0002-0247-861X; Singh, Dr. Mahesh K./0009-0006-5036-6037;
   Singh, Dr. Mahesh K./0000-0002-0790-119X
CR Ahmad KS, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P105
   Ajmera PK, 2011, PATTERN RECOGN, V44, P2749, DOI 10.1016/j.patcog.2011.04.009
   Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007
   Almaadeed N, 2015, IET BIOMETRICS, V4, P18, DOI 10.1049/iet-bmt.2014.0011
   Cooke M, 2001, SPEECH COMMUN, V35, P141, DOI 10.1016/S0167-6393(00)00078-9
   CROCHIERE RE, 1981, P IEEE, V69, P300, DOI 10.1109/PROC.1981.11969
   Daqrouq K, 2015, APPL SOFT COMPUT, V27, P231, DOI 10.1016/j.asoc.2014.11.016
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Grimaldi M, 2008, IEEE T AUDIO SPEECH, V16, P1097, DOI 10.1109/TASL.2008.2001109
   Hanilçi C, 2012, IEEE SIGNAL PROC LET, V19, P163, DOI 10.1109/LSP.2012.2184284
   He JJ, 2016, INT CONF ACOUST SPEE, P321, DOI 10.1109/ICASSP.2016.7471689
   Jingxu C., 2004, P INT S COMP INF, V1, P96
   Kajarekar S. S., 2006, 2006 IEEE ODYSSEY TH, P1
   Kirchhübel C, 2013, APPL ERGON, V44, P694, DOI 10.1016/j.apergo.2012.04.016
   Koenig BE, 2012, J ACOUST SOC AM, V79, P2090
   KULDEEP SK, 2018, BULL ENVIRON PHARMAC, V7, P98
   Kunzel H., 2004, P OD 04 SPEAK LANG R, P1
   Kunzel HJ, 2016, FORENSIC LINGUIST, V3, P146
   Leemann A, 2015, SPEECH COMMUN, V75, P97, DOI 10.1016/j.specom.2015.10.002
   Nakagawa S, 2012, IEEE T AUDIO SPEECH, V20, P1085, DOI 10.1109/TASL.2011.2172422
   Padilla MT, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P913
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Rodman R., 1998, P CONSORTIUM SPEECH, P9
   Sahoo Tushar., 2014, International Journal of Image, Graphics and Signal Processing, V6, P27, DOI DOI 10.5815/IJIGSP.2014.06.04
   Saloni, 2016, International Journal of Image, Graphics and Signal Processing, V8, P29, DOI 10.5815/ijigsp.2016.10.04
   Seresht HR, 2017, CIRC SYST SIGNAL PR, V36, P3222, DOI 10.1007/s00034-016-0434-0
   Shantha R, 2012, INT C COMM TECHN SYS, V30, P319
   Singh MK, 2019, MULTIMED TOOLS APPL, V78, P29395, DOI 10.1007/s11042-018-6718-6
   Singh MK., 2018, Int J Pure Appl Math, V11, P241
   SOONG FK, 1987, AT&T TECH J, V66, P14, DOI 10.1002/j.1538-7305.1987.tb00198.x
   Waller SS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01814
   Wu HJ, 2014, IEEE T INF FOREN SEC, V9, P489, DOI 10.1109/TIFS.2014.2301912
   Wu HJ, 2013, INT CONF ACOUST SPEE, P3013, DOI 10.1109/ICASSP.2013.6638211
   Zhang CL, 2008, FORENSIC SCI INT, V175, P118, DOI 10.1016/j.forsciint.2007.05.019
   Zhu XL, 2007, IEEE T AUDIO SPEECH, V15, P1645, DOI 10.1109/TASL.2007.899236
NR 35
TC 12
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35537
EP 35552
DI 10.1007/s11042-019-08329-y
EA DEC 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000574618400001
DA 2024-07-18
ER

PT J
AU Ding, L
   Wang, Y
   Laganiere, R
   Luo, XB
   Fu, S
AF Ding, Lu
   Wang, Yong
   Laganiere, Robert
   Luo, Xinbin
   Fu, Shan
TI Multi-scale predictions fusion for robust hand detection and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand detection; Deep learning; Fully convolutional network; Region
   proposal network
AB In this paper, we present a multi-scale predictions fusion region-based Fully Convolutional Networks (MSPF-RFCN) to robustly detect and classify human hands under various challenging conditions. In our approach, the input image is passed through the proposed network to generate score maps, based on multi-scale predictions fusion. The network has been specifically designed to deal with small objects. It uses an architecture based on region proposals generated at multiple scales. Our method is evaluated on challenging hand datasets, namely the Vision for Intelligent Vehicles and Applications (VIVA) Challenge and the Oxford hand dataset. It is compared against recent hand detection algorithms. The experimental results demonstrate that our proposed method achieves state-of-the-art detection for hands of various sizes.
C1 [Ding, Lu] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
   [Wang, Yong; Laganiere, Robert] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.
   [Luo, Xinbin; Fu, Shan] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; University of Ottawa; Shanghai Jiao Tong
   University
RP Wang, Y (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.
EM ywang6@uottawa.ca
RI Ding, Lu/AAJ-2179-2020; Laganiere, Robert/H-9138-2013
OI , yong/0000-0001-6559-9550
CR Bambach S, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P351, DOI 10.1145/2818346.2820771
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Das N, 2015, IEEE INT C INTELL TR, P2953, DOI 10.1109/ITSC.2015.473
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Girshick R., 2015, IEEE Trans. on PAMI
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2017, P ICCV, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Le THN, 2017, IEEE COMPUT SOC CONF, P1203, DOI 10.1109/CVPRW.2017.159
   Le THN, 2016, INT C PATT RECOG, P573, DOI 10.1109/ICPR.2016.7899695
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu D, 2019, ARXIV190604634
   Liu W., 2015, ARXIV150604579
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santosh D, 2016, CVPR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Verbickas R., 2017, P IEEE C COMP VIS PA, P146
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou T, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1291, DOI 10.1109/ITSC.2016.7795723
NR 28
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35633
EP 35650
DI 10.1007/s11042-019-08080-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800062
DA 2024-07-18
ER

PT J
AU Zhang, LY
   Li, YD
   Zhang, JL
   Li, PQ
   Li, JY
AF Zhang, Leyuan
   Li, Yangding
   Zhang, Jilian
   Li, Pengqing
   Li, Jiaye
TI Nonlinear sparse feature selection algorithm via low matrix rank
   constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Kernel function; Subspace learning; Low rank
   representation; Sparse processing
ID UNSUPERVISED FEATURE-SELECTION
AB The characteristics of non-linear, low-rank, and feature redundancy often appear in high-dimensional data, which have great trouble for further research. Therefore, a low-rank unsupervised feature selection algorithm based on kernel function is proposed. Firstly, each feature is projected into the high-dimensional kernel space by the kernel function to solve the problem of linear inseparability in the low-dimensional space. At the same time, the self-expression form is introduced into the deviation term and the coefficient matrix is processed with low rank and sparsity. Finally, the sparse regularization factor of the coefficient vector of the kernel matrix is introduced to implement feature selection. In this algorithm, kernel matrix is used to solve linear inseparability, low rank constraints to consider the global information of the data, and self-representation form determines the importance of features. Experiments show that comparing with other algorithms, the classification after feature selection using this algorithm can achieve good results.
C1 [Zhang, Leyuan; Li, Yangding; Li, Pengqing; Li, Jiaye] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Zhang, Jilian] Jinan Univ, Coll Cyber Secur, Guangzhou 510000, Guangdong, Peoples R China.
C3 Guangxi Normal University; Jinan University
RP Li, YD (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM 846390062@qq.com; lyd271@126.com
RI wang, zhenhui/JMQ-0550-2023; Zhang, Leyuan/KEJ-5622-2024; Liu,
   Gui/JHU-8707-2023
FU China Key Research Program [2016YFB1000905]; Key Program of the National
   Natural Science Foundation of China [61836016]; Natural Science
   Foundation of China [61876046, 61573270, 81701780, 61672177]; Project of
   Guangxi Science and Technology [GuiKeAD17195062]; Guangxi Natural
   Science Foundation [2015GXNSFCB139011, 2017GXNSFBA198221]; Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing; Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents; Research Fund of Guangxi
   Key Lab of Multisource Information Mining Security
FX This work is partially supported by the China Key Research Program
   (Grant No: 2016YFB1000905); the Key Program of the National Natural
   Science Foundation of China (Grant No: 61836016); the Natural Science
   Foundation of China (Grants No: 61876046, 61573270, 81701780 and
   61672177); the Project of Guangxi Science and Technology
   (GuiKeAD17195062); the Guangxi Natural Science Foundation (Grant No:
   2015GXNSFCB139011, 2017GXNSFBA198221); the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; the Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents; and the Research Fund of
   Guangxi Key Lab of Multisource Information Mining & Security.
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], ISCID
   Bach F, 2008, ADV NEURAL INFORM PR, P2008
   Cai D., 2010, KDD, P333
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen X, 2017, 2017 IEEE CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2), P252
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Gu QQ, 2011, LECT NOTES ARTIF INT, V6911, P549, DOI 10.1007/978-3-642-23780-5_45
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Jawanpuria P, 2015, GEN HIERARCHICAL KER
   KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li J, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2016), P384
   Ling Charles X., 2004, P 21 INT C MACH LEAR, P69, DOI DOI 10.1109/TSMCB.2008.2007853
   Liu M, 2008, CALL OF PAPER PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING, P969
   Lu C., 2014, IEEE T IMAGE PROCESS, V24, P646
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Muller K, 2008, IEEE T NEURAL NETWOR, V12, P181
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Paruolo P, 1998, J AM STAT ASSOC, V95, P369
   Raskutti G, 2010, TECHNICAL REPORT, V13, P389
   Ravikumar P, 2009, J R STAT SOC B, V71, P1009, DOI 10.1111/j.1467-9868.2009.00718.x
   Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900
   Shin DH, 2015, INT VACUUM NANOELECT, P76, DOI 10.1109/IVNC.2015.7225538
   Suzuki T, 2013, ANN STAT, V41, P1381, DOI 10.1214/13-AOS1095
   Tan M, 2014, ULTRAHIGH DIMENSIONA
   Varma M., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P1065, DOI DOI 10.1145/1553374.1553510
   Wang Huazhong., 2006, Journal of Southern Yangtze University, V5, P500
   Xiao JT, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 2, P1044, DOI 10.1109/ICEMI.2015.7494381
   Yamada M, 2014, NEURAL COMPUT, V26, P185, DOI 10.1162/NECO_a_00537
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Zhang Chengqi, 2003, Association rule mining: models and algorithms, V2307
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014
   Zhao Z., 2007, SIAM INT C DATA MINI
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou Z.-H., 2016, Machine Learning
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Y, 2017, INT C NUMER SIMUL, P157, DOI 10.1109/NUSOD.2017.8010039
   Zhu Yingying, 2017, Med Image Comput Comput Assist Interv, V10435, P205, DOI 10.1007/978-3-319-66179-7_24
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 56
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33319
EP 33337
DI 10.1007/s11042-018-6909-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600034
DA 2024-07-18
ER

PT J
AU Zhang, WB
   Lu, JB
   Xu, XB
   Hou, XR
AF Zhang, Wenbo
   Lu, Jinbo
   Xu, Xiaobo
   Hou, Xiaorong
TI Estimation of atmospheric light based on gaussian distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image defog; Estimation of atmospheric light; Statistical clustering;
   Gaussian distribution; Image quality evaluation
ID IMAGE; DEPTH
AB Existing defogging algorithms use a small number of sample points to estimate the atmospheric light, which leads to poor defogging effect. To solve this problem, a novel Gaussian distribution based algorithm for atmospheric light estimation is proposed. The algorithm has the following features: it uses a brightness threshold to select the candidate points to increase the number of initial samples; it uses clustering algorithms to merge the point clusters for increasing the samples included in the candidate point cluster; it uses a proportional threshold to filter out unreasonable point clusters; it regards each candidate point cluster as a single light source and calculates their influence on surrounding pixels with a Gaussian-distribution-based model; and it uses an atmospheric light map (instead of a constant value) to restore the image. The experimental results suggest that the defogging results produced by the proposed algorithm look more natural than the original algorithm under subjective vision and the objective image quality evaluation indicators are also excellent.
C1 [Zhang, Wenbo; Lu, Jinbo; Hou, Xiaorong] Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu, Sichuan, Peoples R China.
   [Zhang, Wenbo; Xu, Xiaobo] China Elect Technol Cyber Secur Co Ltd, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Hou, XR (corresponding author), Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu, Sichuan, Peoples R China.
EM Stroot@163.com; 564276721@qq.com; xxb0620@163.com; houxr@uestc.edu.cn
OI Zhang, Wenbo/0000-0001-8590-8832
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   [Anonymous], 2014, IEEE International Conference on Computational Photography (ICCP)
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nayar SK, 1999, P 17 IEEE INT C COMP, V2
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   Park H, 2014, IEEE IMAGE PROC, P4502, DOI 10.1109/ICIP.2014.7025913
   Pouget V., 2017, IEEE T NEUR NET LEAR, V64, P13, DOI DOI 10.1109/TNNLS.2016.2521602
   Sun W, 2015, COMPUT ELECTR ENG, V46, P371, DOI 10.1016/j.compeleceng.2015.02.009
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   [吴迪 Wu Di], 2015, [自动化学报, Acta Automatica Sinica], V41, P221
   Zhang L, 2015, 2015 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE THEORY, SYSTEMS AND APPLICATIONS (CCITSA 2015), P177, DOI 10.1109/CCITSA.2015.55
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang WB, 2018, MULTIMED TOOLS APPL, V77, P2947, DOI 10.1007/s11042-017-4547-7
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 29
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33401
EP 33414
DI 10.1007/s11042-019-7401-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600038
DA 2024-07-18
ER

PT J
AU Zhong, Z
   Chen, L
AF Zhong, Zhi
   Chen, Long
TI Local structure preservation in Kernel space for feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Kernel method; Subspace learning; Sparse learning;
   Locality preserving projection
ID SPARSE REGRESSION
AB For many machine learning and data mining tasks in the information explosion environment, one is often confronted with very high dimensional heterogeneous data. Demands for new methods to select discrimination and valuable features that are beneficial to classification and cluster have increased. In this paper, we propose a novel feature selection method to jointly map original data from input space to kernel space and conduct both subspace learning (via locality preserving projection) and feature selection (via a sparsity constraint). Specifically, the nonlinear relationship between data is explored adequately through mapping data from original low-dimensional space to kernel space. Meanwhile, the subspace learning technique is leveraged to preserve available information of local structure in ambient space. Last, by restricting the sparsity of the coefficient matrix, the weight of some features is 0. As a result, we eliminate redundant and irrelevant features and thus make our method select informative and distinguishing features. By comparing our proposed method with some state-of-the-art methods, the experimental results demonstrate that the proposed method outperformed the comparisons in terms of clustering task.
C1 [Zhong, Zhi] Nanning Normal Univ, Sch Continuing Educ, Nannig 530299, Peoples R China.
   [Chen, Long] Nanning Normal Univ, Coll Comp & Informat Engn, Nannig 530299, Peoples R China.
C3 Nanning Normal University; Nanning Normal University
RP Chen, L (corresponding author), Nanning Normal Univ, Coll Comp & Informat Engn, Nannig 530299, Peoples R China.
EM 2823919387@qq.com; 1063477512@qq.com
OI Chen, Long/0000-0003-2814-8579
FU program of Research and development of intelligent logistics management
   system based on Beidou multifunctional information acquisition and
   monitoring terminal [2016AB04097]
FX This work was supported by the program of Research and development of
   intelligent logistics management system based on Beidou multifunctional
   information acquisition and monitoring terminal (Grant No: 2016AB04097).
CR Alamri AA, 2011, COMPUT IND ENG, V60, P236, DOI 10.1016/j.cie.2010.11.005
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Baudat G, 2003, NEUROCOMPUTING, V55, P21, DOI 10.1016/S0925-2312(03)00429-6
   Cai D., 2010, KDD, P333
   Chen Z, 2007, IC-BNMT 2007: PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY, P121
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gu QQ, 2011, LECT NOTES ARTIF INT, V6911, P549, DOI 10.1007/978-3-642-23780-5_45
   He X., 2005, Locality preserving projections
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Lai HJ, 2013, IEEE T COMPUT, V62, P1221, DOI 10.1109/TC.2012.62
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Nie F., 2010, NIPS
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Pouget V., 2017, IEEE T NEUR NET LEAR, V64, P13, DOI DOI 10.1109/TNNLS.2016.2521602
   Rahmani M, 2017, IEEE T SIGNAL PROCES, V65, P6260, DOI 10.1109/TSP.2017.2749215
   Rahmani M, 2017, IEEE T SIGNAL PROCES, V65, P2004, DOI 10.1109/TSP.2017.2649482
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song JK, 2016, IEEE T MULTIMEDIA, V18, P484, DOI 10.1109/TMM.2016.2515990
   Tabakhi S, 2014, ENG APPL ARTIF INTEL, V32, P112, DOI 10.1016/j.engappai.2014.03.007
   Wang SH, 2015, AAAI CONF ARTIF INTE, P470
   Wei Jia, 2018, 2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR). Proceedings, P1, DOI 10.1109/ICFHR-2018.2018.00010
   Yang Y, 2019, IEEE T KNOWL DATA EN, V31, P757, DOI 10.1109/TKDE.2018.2842190
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhi XB, 2018, KNOWL-BASED SYST, V153, P117, DOI 10.1016/j.knosys.2018.04.031
   Zhu LL, 2012, COMM COM INF SC, V321, P80
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu YY, 2017, LECT NOTES COMPUT SC, V10265, P158, DOI 10.1007/978-3-319-59050-9_13
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 37
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33339
EP 33356
DI 10.1007/s11042-018-6926-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600035
DA 2024-07-18
ER

PT J
AU Hatoum, MW
   Darazi, R
   Couchot, JF
AF Hatoum, Makram W.
   Darazi, Rony
   Couchot, Jean-Francois
TI Normalized blind STDM watermarking scheme for images and PDF documents
   robust against fixed gain attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Data hiding; Portable Document Format; Robustness
ID QUANTIZATION INDEX MODULATION; DITHER MODULATION; DIGITAL WATERMARKING;
   SPREAD-SPECTRUM; SYSTEM
AB Spread Transform Dither Modulation (STDM), a special case of Quantization Index Modulation (QIM), has been widely used in digital watermarking. STDM has good performance in robustness against re-quantization and random noise attacks, but it is largely vulnerable to the Fixed Gain Attack (FGA). In addition to digital images and videos watermarking applications, copyright protection for digital text such as Portable Document Format (PDF) has received particular attention and interest. In this paper, we modify the STDM watermarking scheme by making the quantization step dependent on the original samples during the embedding process and on the watermarked samples during the decoding process to resist the FGA attack and enhance the robustness against the Additive White Gaussian Noise (AWGN) attack and JPEG compression attack in both the spatial domain and frequency domain regardless of the source of elements used as cover work. Experimentations have been conducted distinctly on digital images and text PDF documents. The tested images were watermarked with a uniform fidelity, where SSIM is fixed to 0.982 and 0.953. Our approach achieves significant robustness against the FGA attack with an improvement of 98% in terms of Bit Error Rates (BER) compared to traditional STDM. As for the AWGN attack, an improvement of 21% is shown. The proposed method also presents robustness against a variety of filtering and geometric attacks, while preserving a high level of transparency.
C1 [Hatoum, Makram W.; Couchot, Jean-Francois] Univ Bourgogne Franche Comte, UMR 6174 CNRS, FEMTO ST Inst, Besancon, France.
   [Darazi, Rony] Antonine Univ, TICKET Lab, Hadat Baabda, Lebanon.
C3 Universite de Technologie de Belfort-Montbeliard (UTBM); Centre National
   de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering &
   Systems Sciences (INSIS); Universite de Franche-Comte
RP Hatoum, MW (corresponding author), Univ Bourgogne Franche Comte, UMR 6174 CNRS, FEMTO ST Inst, Besancon, France.
EM makram.hatoum@univ-fcomte.fr; rony.darazi@ua.edu.lb;
   jean-francois.couchot@univ-fcomte.fr
RI Couchot, Jean-François/H-5876-2019
OI Couchot, Jean-François/0000-0001-6437-5598
FU National Council for Scientific Research in Lebanon CNRS-L; Hubert
   Curien CEDRE programme; Agence Universitaire de la Francophonie AUF-PCSI
   programme; Labex ACTION program [ANR-11-LABX-01-01]
FX This work is partially funded with support from the National Council for
   Scientific Research in Lebanon CNRS-L, the Hubert Curien CEDRE
   programme, the Agence Universitaire de la Francophonie AUF-PCSI
   programme, and the Labex ACTION program (contract ANR-11-LABX-01-01).
CR Alizadeh-Fahimeh F., 2012, USING STEGANOGRAPHY
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bartolini F, 2004, IEEE T SIGNAL PROCES, V52, P2965, DOI 10.1109/TSP.2004.833868
   Bitar AW, 2017, MULTIMED TOOLS APPL, V76, P143, DOI 10.1007/s11042-015-3034-2
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Castiglione A, 2010, J SYST SOFTWARE, V83, P1813, DOI 10.1016/j.jss.2010.04.062
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P243, DOI 10.1109/ICIP.1996.560429
   Cox IJ., 2007, DIGITAL WATERMARKING
   Darazi R, 2010, INT CONF ACOUST SPEE, P1742, DOI 10.1109/ICASSP.2010.5495455
   Darazi R, 2009, IEEE INT WORKS INFOR, P1, DOI 10.1109/WIFS.2009.5386493
   Feng Y, 2018, IEEE TRUST BIG, P1020, DOI 10.1109/TrustCom/BigDataSE.2018.00144
   Filler Toma, 2011, INFORM HIDING
   Hatoum M.W., 2018, 3 IEEE INT MULT C EN, P1, DOI [10.1109/IMCET.2018.8603038, DOI 10.1109/IMCET.2018.8603038]
   Hatoum MW, 2018, P 15 INT JOINT C E B, P420, DOI [10.5220/0006899605860593, DOI 10.5220/0006899605860593]
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   ISO, 2008, ISO 32000-1:2008document management-portable document format-part 1: Pdf 1.7
   Jalil Z, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY, PROCEEDINGS, P230, DOI 10.1109/ICIMT.2009.11
   Jiang YL, 2013, AEU-INT J ELECTRON C, V67, P690, DOI 10.1016/j.aeue.2013.02.005
   Kuribayashi M, 2017, P INT C INT INF HID, P390
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Li Q, 2005, INT CONF ACOUST SPEE, P1, DOI 10.1109/MMSP.2005.248616
   Li QO, 2007, INT CONF ACOUST SPEE, P185
   Li X, 2011, IET INFORM SECUR, V5, P170, DOI 10.1049/iet-ifs.2010.0218
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Pérez-González F, 2005, IEEE T SIGNAL PROCES, V53, P3960, DOI 10.1109/TSP.2005.855407
   Por LY, 2008, P MATH COMPUTERS SCI
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Vellasques E, 2011, APPL SOFT COMPUT, V11, P5215, DOI 10.1016/j.asoc.2011.05.038
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Wan WB, 2013, IEEE IMAGE PROC, P4522, DOI 10.1109/ICIP.2013.6738931
   Wang YG, 2015, INFORM SCIENCES, V316, P40, DOI 10.1016/j.ins.2015.04.029
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Xia XG, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P548, DOI 10.1109/ICIP.1997.647971
   Yu D, 2008, IEEE IMAGE PROC, P449, DOI 10.1109/ICIP.2008.4711788
   Zhu XS, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1571, DOI 10.1109/ICCIAS.2006.295326
NR 38
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1887
EP 1919
DI 10.1007/s11042-019-08242-4
EA NOV 2019
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495944500005
DA 2024-07-18
ER

PT J
AU Sucharitha, G
   Senapati, RK
AF Sucharitha, G.
   Senapati, Ranjan Kumar
TI Biomedical image retrieval by using local directional edge binary
   patterns and Zernike moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local features; Global features; Local directional edge binary pattern;
   Zernike moments
ID FEATURE DESCRIPTOR; TEXTURE; CLASSIFICATION; EFFICIENT; FACE; MRI
AB This paper presents an efficient approach with the reduced length of feature vector for biomedical image retrieval by using global and local features of an image. In order to extract the local features, a new algorithm, local directional edge binary pattern (LDEBP) has been designed. It gathers information from all the possible directions, i.e., 0(0), 45(0), 90(0) and 135(0) for every pixel in the image. The directional information is calculated based on the sign code magnitudes of local differences from the center pixel to its directional pixels. For every pixel, four edges will be calculated by using all the directional information. Lower order Zernike moments are used for extracting the global and shape features of an image. The combination of shape and texture descriptors for biomedical image retrieval showed significant results compared to the state of the art algorithms like LDEP, ZM and LBDP on benchmark database like Emphysema-CT and OASIS-MRI.
C1 [Sucharitha, G.] ICFAI Fdn Higher Educ, Dept ECE, Fac Sci & Technol, Hyderabad, Telangana, India.
   [Senapati, Ranjan Kumar] VNR Vignana Jyothi Inst Engn Technol, Dept ECE, Hyderabad, Telangana, India.
C3 The ICFAI Foundation for Higher Education (IFHE); ICFAI Tech (Faculty of
   Science & Technology); Vallurupalli Nageswara Rao Vignana Jyothi
   Institute of Engineering &Technology (VNR VJIET)
RP Sucharitha, G (corresponding author), ICFAI Fdn Higher Educ, Dept ECE, Fac Sci & Technol, Hyderabad, Telangana, India.
EM sucharithasu@gmail.com
RI Senapati, Ranjan Kumar/ABD-5697-2020; G, sucharitha/AAT-5202-2021;
   Senapati, Ranjan Kumar/E-5677-2011
OI Senapati, Ranjan Kumar/0000-0003-3375-3378; G,
   sucharitha/0000-0002-3356-350X; 
CR Chen Z, 2010, IEEE T IMAGE PROCESS, V19, P205, DOI 10.1109/TIP.2009.2032890
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Felipe J. C., 2003, P 16 IEEE S COMP BAS
   He S, 2009, IEEE T BIO-MED ENG, V56, P1864, DOI 10.1109/TBME.2009.2017508
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Lazaridis M, 2013, SIGNAL PROCESS-IMAGE, V28, P351, DOI 10.1016/j.image.2012.04.001
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Peng SH, 2010, COMPUT BIOL MED, V40, P931, DOI 10.1016/j.compbiomed.2010.10.005
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   SONG J, 2017, ARXIV170802478
   Song J., 2018, AAAI
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Sucharitha G., 2017, INT J ELECTR COMPUT, V7, P1651
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Traina AJM, 2003, P 16 IEEE S COMP BAS
   ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51
   Unay D, 2010, IEEE T INF TECHNOL B, V14, P897, DOI 10.1109/TITB.2009.2038152
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Vipparthi SK, 2016, IET COMPUT VIS, V10, P182, DOI 10.1049/iet-cvi.2015.0035
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 36
TC 18
Z9 18
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1847
EP 1864
DI 10.1007/s11042-019-08215-7
EA NOV 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495944500007
DA 2024-07-18
ER

PT J
AU Jiang, D
   Li, GF
   Sun, Y
   Kong, JY
   Tao, B
AF Jiang, Du
   Li, Gongfa
   Sun, Ying
   Kong, Jianyi
   Tao, Bo
TI Gesture recognition based on skeletonization algorithm and CNN with ASL
   database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Layer-by-layer stripping theory; Skeletonization algorithm;
   Convolutional neural network; Gesture recognition; Big data
ID INTELLIGENT CONTROL; SIMULATION; TEMPERATURE; PARAMETERS; NETWORKS
AB In the field of human-computer interaction, vision-based gesture recognition methods are widely studied. However, its recognition effect depends to a large extent on the performance of the recognition algorithm. The skeletonization algorithm and convolutional neural network (CNN) for the recognition algorithm reduce the impact of shooting angle and environment on recognition effect, and improve the accuracy of gesture recognition in complex environments. According to the influence of the shooting angle on the same gesture recognition, the skeletonization algorithm is optimized based on the layer-by-layer stripping concept, so that the key node information in the hand skeleton diagram is extracted. The gesture direction is determined by the spatial coordinate axis of the hand. Based on this, gesture segmentation is implemented to overcome the influence of the environment on the recognition effect. In order to further improve the accuracy of gesture recognition, the ASK gesture database is used to train the convolutional neural network model. The experimental results show that compared with SVM method, dictionary learning + sparse representation, CNN method and other methods, the recognition rate reaches 96.01%.
C1 [Jiang, Du; Li, Gongfa; Kong, Jianyi] Wuhan Univ Sci & Technol, Minist Educ, Key Lab Met Equipment & Control Technol, Wuhan 430081, Hubei, Peoples R China.
   [Jiang, Du; Li, Gongfa] Wuhan Univ Sci & Technol, Res Ctr Biomimet Robot & Intelligent Measurement, Wuhan 430081, Hubei, Peoples R China.
   [Li, Gongfa; Tao, Bo] Wuhan Univ Sci & Technol, Inst Precis Mfg, Wuhan 430081, Hubei, Peoples R China.
   [Sun, Ying; Kong, Jianyi] Wuhan Univ Sci & Technol, Hubei Key Lab Mech Transmiss & Mfg Engn, Wuhan 430081, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology; Wuhan University of Science & Technology; Wuhan University
   of Science & Technology
RP Li, GF (corresponding author), Wuhan Univ Sci & Technol, Minist Educ, Key Lab Met Equipment & Control Technol, Wuhan 430081, Hubei, Peoples R China.; Li, GF (corresponding author), Wuhan Univ Sci & Technol, Res Ctr Biomimet Robot & Intelligent Measurement, Wuhan 430081, Hubei, Peoples R China.; Li, GF (corresponding author), Wuhan Univ Sci & Technol, Inst Precis Mfg, Wuhan 430081, Hubei, Peoples R China.
EM jiangdu@wust.edu.cn; ligongfa@wust.edu.cn; sunying65@wust.edu.cn;
   15697188659@wo.com.cn; taoboq@wust.edu.cn
FU National Natural Science Foundation of China [51575407, 51575338,
   51575412, 61273106, 51505349]; National Defense Pre-Research Foundation
   of Wuhan University of Science and Technology [GF201705]; Wuhan
   University of Science and Technology graduate students short-term study
   abroad special funds
FX This work was supported by grants of National Natural Science Foundation
   of China (Grant No. 51575407, 51575338, 51575412, 61273106, 51505349)
   and the Grants of National Defense Pre-Research Foundation of Wuhan
   University of Science and Technology (GF201705). This paper is funded by
   Wuhan University of Science and Technology graduate students short-term
   study abroad special funds.
CR Blaszczyk L, 2016, NUKLEONIKA, V61, P41, DOI 10.1515/nuka-2016-0003
   Bu XY, 2018, INT J GEN SYST, V47, P395, DOI 10.1080/03081079.2018.1462353
   Caselli NK, 2017, BEHAV RES METHODS, V49, P784, DOI 10.3758/s13428-016-0742-0
   Chang W, 2018, ARCH METALL MATER, V63, P659, DOI 10.24425/122391
   Chen DS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020253
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Fang YF, 2015, INT J HUM ROBOT, V12, DOI 10.1142/S0219843615500115
   Han F, 2018, SIGNAL PROCESS, V147, P35, DOI 10.1016/j.sigpro.2018.01.015
   He Y, 2018, STRENGTH MATER+, V50, P157, DOI 10.1007/s11223-018-9955-z
   He Y, 2019, CLUSTER COMPUT, V22, P10935, DOI 10.1007/s10586-017-1237-1
   Jiang D, 2019, CLUSTER COMPUT, V22, P13261, DOI 10.1007/s10586-018-1844-5
   Jin KH, 2017, IEEE T COMPUTATIONAL, V2, P480
   Li Bei, 2017, CLUSTER COMPUT, V22, P503
   LI G, 2017, CLUSTER COMPUT, V22, P2719, DOI DOI 10.1007/S10586-017-1435-X
   Li GF, 2015, DISCRETE CONT DYN-S, V8, P1223, DOI 10.3934/dcdss.2015.8.1223
   Li GF, 2015, ADV MECH ENG, V7, DOI 10.1177/1687814015589667
   Li GF, 2013, APPL MATH INFORM SCI, V7, P1051, DOI 10.12785/amis/070324
   Li GF, 2013, APPL MATH INFORM SCI, V7, P1043, DOI 10.12785/amis/070323
   Li GF, 2013, APPL MATH INFORM SCI, V7, P439, DOI 10.12785/amis/070203
   Li GF, 2012, INFORMATION-TOKYO, V15, P4487
   Liao CF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102159
   Luzanin O, 2014, ASSEMBLY AUTOM, V34, P94, DOI 10.1108/AA-03-2013-020
   Miao W, 2015, APPL COMPUT MATH-BAK, V14, P238
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Saha PK, 2018, IEEE T VIS COMPUT GR, V24, P2298, DOI 10.1109/TVCG.2017.2738023
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sun Y, 2018, MOBILE NETW APPL, V23, P797, DOI 10.1007/s11036-018-1008-0
   Sun YJ, 2019, NAT PROD RES, V33, P3485, DOI 10.1080/14786419.2018.1484461
   Xiong H., 2015, ADV MECH ENG, V9, P1
   Xiong HG, 2017, EUR J OPER RES, V257, P13, DOI 10.1016/j.ejor.2016.07.030
   YIN Q, 2017, DISCRETE CONTINUOU S, V8, P1415
   Zhong Xi, 2018, Journal of Computer Aided Design & Computer Graphics, V30, P173, DOI 10.3724/SP.J.1089.2018.16176
   Zhu X, 2017, BIOSCIENCE REP, V87, P149
NR 33
TC 131
Z9 134
U1 3
U2 105
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29953
EP 29970
DI 10.1007/s11042-018-6748-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200018
DA 2024-07-18
ER

PT J
AU Ju, JG
   Xing, JS
AF Ju, Jianguo
   Xing, Jinsheng
TI RETRACTED: Moving object detection based on smoothing three frame
   difference method fused with RPCA (Retracted article. See vol. 82, pg.
   12741, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Smoothing three-frame difference method; Robust principal component
   analysis; Moving object detection; Background extraction
AB In order to extract the human moving object more accurately and efficiently in the surveillance video, a moving object detection algorithm combining smoothing frame difference method and Robust Principal Component Analysis (RPCA) is proposed. In view of the "shadow" and "cavity" problems in the traditional three-frame difference method, each frame image converted into a gray image is first divided into a fuzzy set such as a smooth region, a texture region and an edge region, and the smooth region can reduce the sudden change of the light. The effect on the gray value, that is, the smoothing frame difference method; RPCA can achieve both data dimensionality reduction and high noise, spike noise rather than Gaussian distribution noise. The two algorithms are used in combination, and the background of the current frame of the RPCA extracted video is used as the intermediate frame of the smoothed frame difference method, and is respectively differentiated from the previous frame of the current frame and the current frame of the video, thereby avoiding the background pixel point. The influence eliminates the phenomenon of "cavity" and also contributes greatly to the reduction of noise. Video detection experiments in different scenarios show that it is more efficient and accurate than similar algorithms.
C1 [Ju, Jianguo; Xing, Jinsheng] Shanxi Normal Univ, Sch Math & Comp Sci, Linfen 041004, Shanxi, Peoples R China.
C3 Shanxi Normal University
RP Xing, JS (corresponding author), Shanxi Normal Univ, Sch Math & Comp Sci, Linfen 041004, Shanxi, Peoples R China.
EM jjg_1227@163.com; xjs19640408@163.com
RI ju, jianguo/ACW-7452-2022
FU Shanxi Nature Science foundation [2015011040]
FX This work is supported by Shanxi Nature Science foundation(Grant No.
   2015011040).The authors would like to thank the anonymous reviewers and
   the editor for the very instructive suggestions that led to the much
   improved quality of this paper.
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262
   Dai K, 2006, J IMAGE GRAPHICS, V11, P917
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Guo JJ, 2017, IOP CONF SER-MAT SCI, V242, DOI 10.1088/1757-899X/242/1/012115
   Huang X, 2013, J ECJTU
   Javed S, 2017, INT C PATT REC
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Meyer D, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P78, DOI 10.1109/ICIP.1997.631988
   Steiner JE, 2009, MON NOT R ASTRON SOC, V395, P64, DOI 10.1111/j.1365-2966.2009.14530.x
   Zhang JS, 2016, PROCEDIA COMPUT SCI, V91, P995, DOI 10.1016/j.procs.2016.07.132
   Zhang YX, 2014, SIGNAL PROCESS, V105, P84, DOI 10.1016/j.sigpro.2014.05.015
NR 12
TC 21
Z9 28
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29937
EP 29951
DI 10.1007/s11042-018-6710-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200017
DA 2024-07-18
ER

PT J
AU Manocha, A
   Singh, R
AF Manocha, Ankush
   Singh, Ramandeep
TI Computer vision based working environment monitoring to analyze
   Generalized Anxiety Disorder (GAD)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anxiety monitoring; Computer vision; Deep learning; 3D CNN; GRU; Medical
   assistance
ID HUMAN ACTION RECOGNITION
AB Ever advancing development in Computer Vision and Deep Learning has increased the efficacy of smart monitoring by analyzing and predicting the physical abnormalities and generating time-sensitive results. Based on the improved principles of smart monitoring and data processing, a novel computer vision assisted deep learning based posture monitoring system is proposed to predict Generalized Anxiety Disorder (GAD) oriented physical abnormalities of an individual from their working environment. We used deep learning-assisted 3D Convolutional Neural Network (CNN) technology for spatio-temporal feature extraction and Gated Recurrent Unit (GRU) model to exploit the extracted temporal dynamics for adversity scale determination. The alert-based decisions with the deliverance of the physical state helps to increase the utility of the proposed system in the healthcare or assistive-care domain. The proficiency of the system is also enhanced by storing the predicted anomaly scores in the local database of the system which can be further used for therapeutic purposes. To validate the prediction performance of the proposed system, extensive experiments are conducted on three challenging datasets, NTU RGB+D, UTD-MHAD and HMDB51. The proposed methodology achieved comparable performance by obtaining the mean accuracy of 91.88%, 94.28%, and 70.33%, respectively. Furthermore, the average prediction time taken by the proposed methodology is approximately 1.13 seconds which demonstrates the real-time monitoring efficiency of the system. The calculated outcomes show that the proposed methodology performs better contrasted with other contemporary studies for activity prediction, data processing cost, error rate, and time complexity.
C1 [Manocha, Ankush; Singh, Ramandeep] Lovely Profess Univ, Phagwara 144411, Punjab, India.
C3 Lovely Professional University
RP Manocha, A (corresponding author), Lovely Profess Univ, Phagwara 144411, Punjab, India.
EM ankushmanocha31@gmail.com; ramandeep.singh@lpu.co.in
RI Singh, Ramandeep/AAI-8987-2020; Manocha, Ankush/AEH-9532-2022
OI Manocha, Ankush/0000-0001-5054-1655; Singh,
   Ramandeep/0000-0001-5775-7993
CR Akula A, 2018, COGN SYST RES, V50, P146, DOI 10.1016/j.cogsys.2018.04.002
   [Anonymous], 2015, P IEEE COMP SOC C CO
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2018, FUSION APPEARANCE BA
   [Anonymous], 2020, [No title captured]
   [Anonymous], P 30 IEEE C COMP VIS
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Cai LQ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051218
   Cai LQ, 2018, IEEE ACCESS, V6, P20047, DOI 10.1109/ACCESS.2018.2822713
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen X, 2017, IEEE T CIRC SYST VID, V27, P19, DOI 10.1109/TCSVT.2016.2539758
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Donahue J, 2015, P IEEE COMP SOC C CO
   Feichtenhofer C, 2017, P 30 IEEE C COMP VIS
   Gao JF, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5157020
   Gupta A, 2014, P IEEE COMP SOC C CO
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Kuehne H., 2011, P INT C COMP VIS
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li B, 2012, P IEEE COMP SOC C CO
   Li R, 2012, P IEEE COMP SOC C CO
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Luo XC, 2018, AUTOMAT CONSTR, V94, P360, DOI 10.1016/j.autcon.2018.07.011
   Moon T, 2016, 2015 IEEE WORKSH AUT
   Neverova N, 2016, IEEE T PATTERN ANAL, V38, P1692, DOI 10.1109/TPAMI.2015.2461544
   Neverova N, 2016, IEEE ACCESS, V4, P1810, DOI 10.1109/ACCESS.2016.2557846
   Ng J.Y.H., 2015, P IEEE COMP SOC C CO
   Sacchi L, 2007, DATA MIN KNOWL DISC, V15, P217, DOI 10.1007/s10618-007-0077-7
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Wang J., 2014, P IEEE COMP SOC C CO
   Wang L, 2015, P IEEE COMP SOC C CO
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang X, 2015, ACTIONS TRANSFORMATI, DOI [10.1109/CVPR.2016.291, DOI 10.1109/CVPR.2016.291]
   Wang Y, 2017, P 30 IEEE C COMP VIS
   Yu W, 2013, ARCH ENVIRON OCCUP H, DOI [10.1080/19338244.2012.70124410.1080/19338244.2012.701244, DOI 10.1080/19338244.2012.70124410.1080/19338244.2012.701244]
   Zhang Z, 2013, P IEEE COMP SOC C CO
NR 43
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30457
EP 30484
DI 10.1007/s11042-019-7700-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200046
DA 2024-07-18
ER

PT J
AU Qiu, YG
   Gu, HH
   Sun, JY
   Duan, HT
   Luo, JH
AF Qiu, Yinguo
   Gu, Hehe
   Sun, Jiuyun
   Duan, Hongtao
   Luo, Juhua
TI Rich-information watermarking scheme for 3D models of oblique
   photography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rich-information watermarking; 3D models; Copyright protection;
   Reversible watermarking
ID ALGORITHM
AB The security issues of copyright information arise rapidly along with the widely application of 3D models of oblique photography. In this paper, a reversible watermarking scheme is proposed for 3D models of oblique photography, aiming at robustness enhancing and rich-information watermark embedding. To realize the goal of rich-information watermark embedding, an encoding method of original copyright information is designed based on QR code, which can shorten significantly the length of the final watermark data without affecting the copyright expression. A 3D point grouping method is designed and both watermark embedding and extraction are completed group by group, so that the robustness of this scheme under certain attacks can be enhanced, e.g., model segmentation, data compression, point randomly deleting, etc. Moreover, watermarks are embedded into spherical coordinates of 3D points so that the ability of the proposed scheme in resisting geometric transformation can be improved. Results of simulation experiments have demonstrated that the proposed scheme can support rich-information watermark embedding, and it has a satisfying robustness under common geometric and non-geometric attacks.
C1 [Qiu, Yinguo; Duan, Hongtao; Luo, Juhua] Chinese Acad Sci, Nanjing Inst Geog & Limnol, Key Lab Watershed Geog Sci, Nanjing 210008, Jiangsu, Peoples R China.
   [Gu, Hehe; Sun, Jiuyun] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Nanjing Institute of Geography & Limnology,
   CAS; China University of Mining & Technology
RP Qiu, YG (corresponding author), Chinese Acad Sci, Nanjing Inst Geog & Limnol, Key Lab Watershed Geog Sci, Nanjing 210008, Jiangsu, Peoples R China.
EM ygqiu@niglas.ac.cn
RI Qiu, Yinguo/IZD-6490-2023; Luo, Juhua/AHE-4173-2022; Duan,
   Hongtao/B-7210-2011
OI Duan, Hongtao/0000-0002-1985-2292; Sun, Jiuyun/0009-0007-2697-5673; Luo,
   Juhua/0000-0002-4615-6006
FU Major Science and Technology Program for Water Pollution Control and
   Treatment [2017ZX07603001]; Talent Start-up Project of NIGLAS
   [Y8SL031001-NIGLAS2018QD07]
FX This research is supported by the Major Science and Technology Program
   for Water Pollution Control and Treatment (Grant No. 2017ZX07603001) and
   the Talent Start-up Project of NIGLAS (Grant No.
   Y8SL031001-NIGLAS2018QD07).
CR Abdallah Alaa E., 2015, International Journal of Security and Networks, V10, P1, DOI 10.1504/IJSN.2015.068390
   [Anonymous], 2016, J INFORM HIDING MULT
   [Anonymous], J INF HIDING MULTIME
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   Cotting D, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P233, DOI 10.1109/SMI.2004.1314510
   Feng X, 2015, NAT C EL EL COMP ENG, P963, DOI [10.2991/nceece-15.2016.173, DOI 10.2991/NCEECE-15.2016.173]
   [冯小青 FENG Xiao-qing], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1534
   Kawano S, 2015, J JAPAN SOC PHOTOGRA, V54, P141, DOI [10.4287/jsprs.54.141, DOI 10.4287/JSPRS.54.141]
   Liu JX, 2011, ADV MATER RES-SWITZ, V314-316, P2064, DOI 10.4028/www.scientific.net/AMR.314-316.2064
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   Ohbuchi R, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P392, DOI 10.1109/CW.2004.70
   Ohbuchi R., 1997, Interactive Distributed Multimedia Systems and Telecommunication Services. 4th International Workshop, IDMS '97. Proceedings, P1, DOI 10.1007/BFb0000334
   Qi Xiangming, 2014, Journal of Computer Applications, V34, P1309
   Qiu YG, 2018, MULTIMED TOOLS APPL, V77, P23651, DOI 10.1007/s11042-018-5680-7
   Qiu YG, 2018, MULTIMED TOOLS APPL, V77, P6385, DOI 10.1007/s11042-017-4546-8
   [商静静 Shang Jingjing], 2016, [光学技术, Optical Technology], V42, P506
   Soliman MM, 2015, ADV INTELL SYST COMP, V323, P731, DOI 10.1007/978-3-319-11310-4_64
   Taniguchi K., 2017, J SIGNAL PROCESSING, V21, P195, DOI [10.2299/jsp.21.195, DOI 10.2299/JSP.21.195]
   Verhoeven G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8110918
   [王刚 Wang Gang], 2018, [地球信息科学学报, Journal of Geo-Information Science], V20, P738
   Wang Li-hui, 2011, Signal Processing, V27, P932
   Wang YP, 2009, IEEE T VIS COMPUT GR, V15, P285, DOI 10.1109/TVCG.2008.101
   Weng SW, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010049
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
NR 29
TC 3
Z9 6
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31365
EP 31386
DI 10.1007/s11042-019-07982-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000018
DA 2024-07-18
ER

PT J
AU Daneshfar, F
   Kabudian, SJ
AF Daneshfar, Fatemeh
   Kabudian, Seyed Jahanshah
TI Speech emotion recognition using discriminative dimension reduction by
   employing a modified quantum-behaved particle swarm optimization
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Dimension reduction; Quantum-behaved
   particle swarm optimization
ID STRESS RECOGNITION; FEATURES; CLASSIFICATION; EXTRACTION; NETWORK; PSO
AB In recent years, Speech Emotion Recognition (SER) has received considerable attention in affective computing field. In this paper, an improved system for SER is proposed. In the feature extraction step, a hybrid high-dimensional rich feature vector is extracted from both speech signal and glottal-waveform signal using techniques such as MFCC, PLPC, and MVDR. The prosodic features derived from fundamental frequency (f0) contour are also added to this feature vector. The proposed system is based on a holistic approach that employs a modified quantum-behaved particle swarm optimization (QPSO) algorithm (called pQPSO) to estimate both the optimal projection matrix for feature-vector dimension reduction and Gaussian Mixture Model (GMM) classifier parameters. Since the problem parameters are in a limited range and the standard QPSO algorithm performs a search in an infinite range, in this paper, the QPSO is modified in such a way that it uses a truncated probability distribution and makes the search more efficient. The system works in real-time and is evaluated on three standard emotional speech databases Berlin database of emotional speech (EMO-DB), Surrey Audio-Visual Expressed Emotion (SAVEE) and Interactive Emotional Dyadic Motion Capture (IEMOCAP). The proposed method improves the accuracy of the SER system compared to classical methods such as FA, PCA, PPCA, LDA, standard QPSO, wQPSO, and deep neural network, and also outperforms many state-of-the-art recent approaches that use the same datasets.
C1 [Daneshfar, Fatemeh; Kabudian, Seyed Jahanshah] Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
C3 Razi University
RP Kabudian, SJ (corresponding author), Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
EM Kabudian@razi.ac.ir
RI Daneshfar, Fatemeh/HNS-2848-2023; daneshfar, fatemeh/AAY-2960-2020
OI daneshfar, fatemeh/0000-0003-3150-3527
CR Albornoz EM, 2017, SOFT COMPUT, V21, P5145, DOI 10.1007/s00500-016-2110-5
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   BASHIRPOUR M, 2016, IRANIAN J ELECT ELEC, V12, P197
   BHARGAVA M, 2012, P INT C EM COMP INF
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   COSIMO AB, 2006, LECT NOTES COMPUTER, P38
   Darekar RV, 2018, BIOL INSPIR COGN ARC, V23, P35, DOI 10.1016/j.bica.2018.01.002
   Deb S, 2017, NATL CONF COMMUN
   Deb S, 2016, INT CO SIG PROC COMM
   Degottex G, 2014, 2014 IEEE INT C ACOU
   Deng J, 2014, IEEE SIGNAL PROC LET, V21, P1068, DOI 10.1109/LSP.2014.2324759
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Durrani AZ, 2017, INT BHURBAN C APPL S, P170, DOI 10.1109/IBCAST.2017.7868050
   Gangeh MJ, 2014, IEEE-ACM T AUDIO SPE, V22, P1056, DOI 10.1109/TASLP.2014.2319157
   Gharavian D, 2017, MULTIMED TOOLS APPL, V76, P2331, DOI 10.1007/s11042-015-3180-6
   Gharavian D, 2012, NEURAL COMPUT APPL, V21, P2115, DOI 10.1007/s00521-011-0643-1
   Ghosh S, 2016, INTERSPEECH, P3603, DOI 10.21437/Interspeech.2016-692
   Grimm M, 2007, SPEECH COMMUN, V49, P787, DOI 10.1016/j.specom.2007.01.010
   Haq S., 2011, MACHINE AUDITION PRI, P398, DOI DOI 10.4018/978-1-61520-919-4.CH017
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Huang YM, 2015, IET SIGNAL PROCESS, V9, P341, DOI 10.1049/iet-spr.2013.0446
   Huang ZW, 2015, FRONT INFORM TECH EL, V16, P358, DOI 10.1631/FITEE.1400323
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Idris Inshirah, 2016, Advances in Machine Learning and Signal Processing, MALSIP 2015. Proceedings: LNEE 387, P247, DOI 10.1007/978-3-319-32213-1_22
   Junqua J.C., 2012, Robustness in automatic speech recognition: fundamentals and applications, V341
   KABUDIAN J, 2008, 2008 IEEE INT C AC S
   Kadiri SR, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1324
   Kalinli O, 2016, INTERSPEECH, P3613, DOI 10.21437/Interspeech.2016-1557
   Keyvanrad M. A., 2014, ARXIV PREPRINT ARXIV
   Kim EH, 2009, IEEE-ASME T MECH, V14, P317, DOI 10.1109/TMECH.2008.2008644
   Li PC, 2018, INTERSPEECH, P3087, DOI 10.21437/Interspeech.2018-1242
   Li XA, 2010, LECT NOTES COMPUT SC, V6329, P180, DOI 10.1007/978-3-642-15597-0_20
   LI Y, 2015, 2015 INT C AFF COMP
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   LOTIFIDERESHGI R, 2017, 2017 IEEE INT C AC S
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   Mak M. W., 2016, TECHNICAL REPORT LEC
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   MIRHOSSEINI SH, 2014, 2014 4 INT C COMP KN
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562
   Moscola J, 2007, AEROSP CONF PROC, P3419
   Muthusamy H, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120344
   NEEKABADI A, 2018, 2018 4 IR C SIGN PRO
   Noroozi F, 2017, INT J SPEECH TECHNOL, V20, P239, DOI 10.1007/s10772-017-9396-2
   PANT M, 2008, P 10 ANN C GEN EV CO
   Papakostas M, 2017, COMPUTATION, V5, DOI 10.3390/computation5020026
   Park JS, 2009, IEEE T CONSUM ELECTR, V55, P1590, DOI 10.1109/TCE.2009.5278031
   POHJALAINEN J, 2014, AC SPEECH SIGN PROC
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Sheikhan M, 2013, NEURAL COMPUT APPL, V23, P215, DOI 10.1007/s00521-012-0814-8
   SHEKOFTEH Y, 2012, 20 IR C EL ENG ICEE2
   SHIRANI A, 2016, INT J IMAGE GRAPHICS, V8, P4
   Sidorov M, 2016, J SIB FED UNIV-MATH, V9, P518, DOI 10.17516/1997-1397-2016-9-4-518-523
   SINITH MS, 2015, 2015 IEEE RECENT ADV
   Song P, 2015, ELECTRON LETT, V51, P112, DOI 10.1049/el.2014.3339
   Stewart G. W., 1998, MATRIX ALGORITHMS, V1
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Sun J, 2011, PARTICLE SWARM OPTIM
   Sun YX, 2017, MULTIMED TOOLS APPL, V76, P8305, DOI 10.1007/s11042-016-3487-y
   Sun YX, 2015, INT J SPEECH TECHNOL, V18, P317, DOI 10.1007/s10772-015-9272-x
   Tzinis E, 2018, INTERSPEECH, P927, DOI 10.21437/Interspeech.2018-1377
   Tzinis E, 2017, INT CONF AFFECT, P190, DOI 10.1109/ACII.2017.8273599
   VASQUEZCORREA JC, 2016, SPEECH COMM 12 ITG S
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wang FP, 2017, I C DIELECT LIQUIDS
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Xi ML, 2008, APPL MATH COMPUT, V205, P751, DOI 10.1016/j.amc.2008.05.135
   Xu X, 2015, 2015 16TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY
   Yang N, 2017, INT J SPEECH TECHNOL, V20, P27, DOI 10.1007/s10772-016-9364-2
   Yapanel UH, 2008, SPEECH COMMUN, V50, P142, DOI 10.1016/j.specom.2007.07.006
   Yogesh CK, 2017, APPL SOFT COMPUT, V56, P217, DOI 10.1016/j.asoc.2017.03.013
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   YUNCU E, 2014, 2014 22 INT C PATT R
   Zaidan Noor Aina, 2016, Advances in Machine Learning and Signal Processing, MALSIP 2015. Proceedings: LNEE 387, P141, DOI 10.1007/978-3-319-32213-1_13
   Zao L, 2014, IEEE SIGNAL PROC LET, V21, P620, DOI 10.1109/LSP.2014.2311435
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang S, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54211
   Zhao Z, 2018, IEEE INT WORKS MACH
   Zheng WM, 2014, IEEE SIGNAL PROC LET, V21, P569, DOI 10.1109/LSP.2014.2308954
   Zong Y, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2537926
NR 84
TC 43
Z9 45
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1261
EP 1289
DI 10.1007/s11042-019-08222-8
EA OCT 2019
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492655700002
DA 2024-07-18
ER

PT J
AU Kumar, A
   Jaiswal, A
AF Kumar, Akshi
   Jaiswal, Arunima
TI Swarm intelligence based optimal feature selection for enhanced
   predictive sentiment accuracy on twitter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary grey wolf; Binary moth flame; Swarm intelligence; Meta-heuristic;
   Sentiment; Twitter
ID FLAME OPTIMIZATION ALGORITHM; CLASSIFICATION; MACHINE
AB A lot of uncertainty is generally associated with the micro-blog content, primarily due to the presence of noisy, heterogeneous, structured or unstructured data which may be high-dimensional, ambiguous, vague or imprecise. This makes feature engineering for predicting the sentiment arduous and challenging. Population-based meta-heuristics, especially the ones inspired by nature have been proposed in various pertinent studies for feature selection because of their probability to accept a less optimal solution and averting being stuck in local optimal solutions. This research demonstrates the use of two such swarm intelligence algorithms, namely, binary grey wolf and binary moth flame for feature optimization to enhance the sentiment classification performance accuracy. The study is conducted on tweets from two benchmark Twitter corpus (SemEval 2016 and SemEval 2017) and is initially analyzed using the conventional term frequency-inverse document frequency statistical weighting filter for feature extraction and subsequently using the swarm-based algorithms. The features are trained over five baseline classifiers namely, the Naive Bayesian, support vector machines, k-nearest neighbor, multilayer perceptron and decision tree. The results validate that the population-based meta-heuristic algorithms for feature subset selection outperform the baseline supervised learning algorithms. For the binary grey wolf algorithm, an average improvement of 9.4% in accuracy is observed with an approximate 20.5% average reduction in features. Also, for the binary moth flame algorithm, an average accuracy improvement of 10.6% is observed with an approximate 40% average reduction in features. The highest accuracy of 76.5% is observed for support vector machine with binary grey wolf optimizer on SemEval 2016 benchmark dataset.
C1 [Kumar, Akshi; Jaiswal, Arunima] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Delhi Technological University
RP Kumar, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM akshikumar@dce.ac.in; arunimajaiswal@gmail.com
RI Kumar, Akshi/Y-9314-2019
OI Kumar, Akshi/0000-0003-4263-7168
CR Allahyari M, 2017, P KDD BIGD
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2016, INDIAN J SCITECHNOL
   [Anonymous], 1975, ANAL BEHAV CLASS GEN
   Arias M, 2013, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542182.2542190
   Basari AH, 2013, PROCEDIA ENGINEER, V53, P453, DOI 10.1016/j.proeng.2013.02.059
   Beheshti Z., 2013, INT J ADV SOFT COMPU, V5, P1
   Bhatia M.P.S., 2008, J THEORET APPL INFOR, V4
   Burnap P, 2015, POLICY INTERNET, V7, P223, DOI 10.1002/poi3.85
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   Dhurve R, 2015, INT J SCI REIJSR, P2319
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Finn S, 2013, KUNSTL INTELL, V27, P17, DOI 10.1007/s13218-012-0227-y
   Gupta DK, 2015, LECT NOTES COMPUT SC, V9103, P220, DOI 10.1007/978-3-319-19581-0_20
   Hassanien AE, 2017, COMPUT ELECTRON AGR, V136, P86, DOI 10.1016/j.compag.2017.02.026
   Kassem II, 2017, FOODBORNE PATHOG DIS, V14, P29, DOI 10.1089/fpd.2016.2161
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kumar Akshi, 2020, International Journal of Information Technology, V12, P1159, DOI 10.1007/s41870-017-0072-1
   Kumar Akshi, 2012, International Journal of Intelligent Systems and Applications, V4, P1, DOI 10.5815/ijisa.2012.10.01
   Kumar A., 2012, P INT C COMPUTER SCI, P123
   KUMAR A, 2015, INT CONF CONTEMP, P285
   Kumar A., 2017, Proceedings of the Special Collection on eGovernment Innovations in India, P134
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Kumar A, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2018.08.006
   Kumar A, 2017, ADV INTELL SYST, V556, P693, DOI 10.1007/978-981-10-3874-7_66
   Kumar A, 2017, LECT NOTES ENG COMP, P472
   Kumar A, 2017, J INF ASSUR SECUR, V12, P146
   Kumar Akshi, 2012, International Journal of Computer Science Issues (IJCSI), V9, P372
   Lazar A., 2003, HEURISTIC KNOWLEDGE
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2015, APPL INTELL, V43, P150, DOI 10.1007/s10489-014-0645-7
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pang B., 2007, INFORM RETRIEVAL, V2, P1, DOI DOI 10.1561/1500000011
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Reddy S, 2017, SWARM INTELLIGENCE I
   Shahana PH, 2015, PROCEDIA COMPUT SCI, V46, P1585, DOI 10.1016/j.procs.2015.02.088
   Sinha N.K., 2000, Soft Computing and Intelligent Systems
   Sivanandam S.N., 2007, Principles of soft computing
   Stylios G., 2014, INT J COMPUT APPL, V87
   Sulis E, 2016, KNOWL-BASED SYST, V108, P132, DOI 10.1016/j.knosys.2016.05.035
   Sumathi T, 2014, J THEORET APPL INFOR, V66
   Tuarob S, 2014, J BIOMED INFORM, V49, P255, DOI 10.1016/j.jbi.2014.03.005
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zhang L, 2017, NEURAL COMPUT APPL, V28, P2795, DOI 10.1007/s00521-016-2204-0
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
NR 49
TC 27
Z9 27
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29529
EP 29553
DI 10.1007/s11042-019-7278-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700061
DA 2024-07-18
ER

PT J
AU Tang, T
   Li, L
AF Tang, Tong
   Li, Ling
TI A low delay rate control method for screen content coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; Screen content; HEVC; Buffer; Low delay
ID RATE CONTROL SCHEME; HEVC; QUALITY
AB Unlike conventional camera captured video (CCV), the screen content video (SCV) is generated by computer, like text, animation, or graphics. The SCV contents are discontinuous, as one abrupt frame is often followed by many static frames. These distinct characteristics bring challenges to the implementation of rate control in screen content coding (SCC). This paper proposes a low delay rate control method for SCC in HEVC (High Efficiency Video Coding). Firstly, a bit allocation scheme considering buffer status and picture complexity is proposed. Then, an R - MAD (Rate-Mean Absolute Difference)model is built to estimate frame QP (quantization parameter) according to allocated bits. Finally, a dynamical adjusting scheme is designed to fix the error of the estimated frame QP. Experimental results show that the proposed method could effectively avoid buffer overflow and improve the coding efficiency over the recommended rate control scheme in HEVC.
C1 [Tang, Tong] Chongqing Univ Posts & Telecommun, Commun Inst, Chongqing, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Li, Ling] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chinese Academy of
   Sciences; Institute of Software, CAS; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Tang, T (corresponding author), Chongqing Univ Posts & Telecommun, Commun Inst, Chongqing, Peoples R China.
EM ttly@mail.ustc.edu.cn; liling@iscas.ac.cn
RI TANG, TONG/KRO-7674-2024
OI Li, Ling/0000-0001-8877-9052
FU National Key Research and Development Program of China [2017YFA0700900,
   2017YFA0700903]; NSF of China [61672491, 61732020]
FX "This work is partially supported by the National Key Research and
   Development Program of China (under Grant 2017YFA0700900,
   2017YFA0700903), and the NSF of China (under Grants 61672491,
   61732020)."
CR Ahn Y.-J, 2015, JCTVCV0078
   [Anonymous], JCTVCP1006
   [Anonymous], 2015, JCTVCU0132
   [Anonymous], 2012, ITUTSG16 WP3
   [Anonymous], 2016, JCTVCX1015
   Baroncini V., 2017, JCTVCAA0040
   Bhoi SK, 2018, DIGIT COMMUN NETW, V4, P189, DOI 10.1016/j.dcan.2017.08.003
   Bjontegaard G., 2001, Document VCEG-M33
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   Guo YY, 2015, IEEE INT SYMP CIRC S, P1118, DOI 10.1109/ISCAS.2015.7168834
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Hu SD, 2011, IEEE T CIRC SYST VID, V21, P1152, DOI 10.1109/TCSVT.2011.2138810
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Li B, 2013, JCTVCM0036
   Li B, 2014, LAMDA DOMAIN BASED R, V23
   Li JH, 2015, IEEE ASME INT C ADV, P1, DOI 10.1109/AIM.2015.7222499
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li Z., 2003, P JOINT VID TEAM JVT
   Liu M, 2010, IEEE IMAGE PROC, P1277, DOI 10.1109/ICIP.2010.5653340
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Pitrey Y, 2009, IEEE INT SYM BROADB, P54
   Seo CW, 2013, IEEE T IMAGE PROCESS, V22, P2442, DOI 10.1109/TIP.2013.2251647
   Shiyang Li, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286597
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun L, 2014, IEEE INT SYMP CIRC S, P1933, DOI 10.1109/ISCAS.2014.6865539
   Tan YH, 2012, IEEE T CIRC SYST VID, V22, P1236, DOI 10.1109/TCSVT.2012.2198132
   Wang MH, 2015, IEEE IMAGE PROC, P2665, DOI 10.1109/ICIP.2015.7351286
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang S, 2018, CELL CYCLE, V17, P1146, DOI 10.1080/15384101.2018.1464848
   Wen JT, 2015, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2015.35
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiaohua Jian, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8091746
   Xie B, 2006, IEEE T CIRC SYST VID, V16, P56, DOI 10.1109/TCSVT.2005.856911
   Xu XZ, 2016, IEEE J EM SEL TOP C, V6, P409, DOI 10.1109/JETCAS.2016.2597645
   Yaoyao Guo, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457809
NR 38
TC 5
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28231
EP 28256
DI 10.1007/s11042-019-07910-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000065
DA 2024-07-18
ER

PT J
AU Gao, MM
   Wu, Y
   Nan, JC
   Cui, SY
AF Gao, Mingming
   Wu, Yue
   Nan, Jingchang
   Cui, Shuyang
TI Multimedia detection algorithm of malicious nodes in intelligent grid
   based on fuzzy logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless communication network; Internet of things; Malicious network
   attack; Trust model; Fuzzy logic
AB Intelligent grid transmits data by means of wireless communication. The wireless communication network is vulnerable to multiple kinds of network attacks. Trust model is considered to be an important way to defend against malicious network attacks in large-scale communication networks. Concerning the problem of node attack in smart grid, a trust model FLTM based on fuzzy logic is proposed. FLTM model makes full use of fuzzy logic system to deal with uncertainties, estimates the overall trust value of nodes, and then detects malicious nodes. Taking direct trust, indirect trust and historical trust as inputs, the output is the overall trust of the node. Experimental data show that the proposed FLTM model can detect malicious nodes effectively. In the later stage, the FLTM model is applied to routing, thus improving the performance of data transmission.
C1 [Gao, Mingming; Wu, Yue; Nan, Jingchang; Cui, Shuyang] Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao 125105, Liaoning, Peoples R China.
C3 Liaoning Technical University
RP Gao, MM (corresponding author), Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao 125105, Liaoning, Peoples R China.
EM gminmmg@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   [Anonymous], 2018, CAAI T INTELL TECHNO
   Braga RB, 2013, J NETW COMPUT APPL, V36, P274, DOI 10.1016/j.jnca.2012.06.002
   Fu L, 2011, INT C SYST SCI ENG D, P218
   Geraily M, 2012, INT C INT SYST MOD S, P102
   Guo G, 2015, INT C INTELLIGENT CO, P19
   Jieshan L., 2009, INT C COMPUTATIONAL, P1
   Li Y, 2013, MATH PROBL ENG, V2013, P708
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Qian C., 2018, INTELL TECHNOL, V3, P18, DOI DOI 10.1049/trit.2018.0007
   Sharma D, 2011, COMM COM INF SC, V169, P349
   Sim Min-Chol, 2013, WIRELESS SENSOR NETW, V5, P52, DOI DOI 10.4236/wsn.2013.53007
   Singh R, 2017, WIREL COMMUN MOB COM, P1, DOI 10.1155/2017/3548607
   Wang H, 2015, APPL RES COMPUTERS
   Wu R, 2015, INT J DISTRIB SENS N, V2015, P6
   Zarei M, 2009, 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS 2009), P233, DOI 10.1109/INCOS.2009.16
NR 16
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24011
EP 24022
DI 10.1007/s11042-019-7191-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900011
DA 2024-07-18
ER

PT J
AU Liu, L
   Zhang, B
   Zhang, HX
   Zhang, N
AF Liu, Li
   Zhang, Bin
   Zhang, Huaxiang
   Zhang, Na
TI Graph steered discriminative projections based on collaborative
   representation for Image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative representation; Graph embedding; Dimensionality reduction;
   Image recognition
ID PRESERVING PROJECTIONS
AB Dimensionality reduction techniques are commonly used for image recognition. We propose a graph steered dimensionality reduction method called Discriminative Projections based on Collaborative Representation (DPCR) by transforming the dimensionality reduction task into a graph embedding framework. DPCR utilizes the collaborative representation to construct within-class and between-class graphs. To improve the discriminative performance of dimensionality reduction, DPCR introduces the label information into graph building. The novel method not only avoids the difficulty of finding proper neighborhood but also inherits the merits of manifold learning methods and the robustness of collaborative representation techniques. Experiments on benchmark datasets demonstrate its effectiveness.
C1 [Liu, Li; Zhang, Bin; Zhang, Huaxiang; Zhang, Na] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University
RP Liu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM liuli_790209@163.com; smiling.face@qq.com; huaxzhang@163.com;
   962706805@qq.com
RI Zhang, Bin/IWU-4448-2023
OI Zhang, Bin/0000-0001-9214-1588
FU National Natural Science Foundation of China [61702310, 61772322]; Key
   Research and Development Foundation of Shandong Province [2016GGX101009]
FX The work is supported by the National Natural Science Foundation of
   China (No.61702310 and 61772322), the Key Research and Development
   Foundation of Shandong Province (No. 2016GGX101009).
CR [Anonymous], 2008, HDB DATA VISUALIZATI
   [Anonymous], 2003, NIPS
   [Anonymous], 2016, SYNTHESIS LECT INFOR
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cui H, 2020, PATTERN RECOGN LETT, V130, P174, DOI 10.1016/j.patrec.2018.08.033
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Jian Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P694, DOI 10.1109/ICPR.2010.175
   Lai J, 2013, IEEE IMAGE PROC, P3695, DOI 10.1109/ICIP.2013.6738762
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu X, 2018, T CIRC SYST VIDEO TE, V8, P38
   Liu XB, 2018, IEEE T CIRC SYST VID, V28, P2884, DOI 10.1109/TCSVT.2017.2781738
   Lu GF, 2016, J VIS COMMUN IMAGE R, V38, P11, DOI 10.1016/j.jvcir.2016.02.004
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sakai H, 2016, INT C COMP MEAS CONT, P52
   Tenenbaum JB, 1998, ADV NEUR IN, V10, P682
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang QQ, 2018, IEEE T NEUR NET LEAR, V29, P738, DOI 10.1109/TNNLS.2016.2636130
   Wang YX, 2017, IETE J RES, V63, P358, DOI 10.1080/03772063.2016.1274240
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Zhang HX, 2009, KNOWL-BASED SYST, V22, P477, DOI 10.1016/j.knosys.2009.06.009
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
NR 30
TC 7
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24501
EP 24518
DI 10.1007/s11042-018-7117-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900037
DA 2024-07-18
ER

PT J
AU Lu, JW
   Liu, GF
   Zheng, BL
   Zhao, Y
   Zheng, K
AF Lu, Junwen
   Liu, Guanfeng
   Zheng, Bolong
   Zhao, Yan
   Zheng, Kai
TI Social context-aware trust paths finding for trustworthy service
   provider selection in social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Trust; Service provider selection
ID SEARCH
AB Online Social Network (OSN) has been used to enhance service provision and service selection, where trust is one of the most important factors for the decision making of service consumers. Thus, a significant and challenging problem is how to effectively and efficiently find those social trust paths that can yield trustworthy trust evaluation results based on the requirements of a service consumer particularly in contextual OSNs which contains social contexts, like social relationships and social trust between participants, and social positions of participants. In this paper, we propose a new concept called Strong Social Graph (SSG), consisting of participants with strong social connections. We also propose an approach to identify SSGs, and propose a novel index method and a graph compression method for SSG. Then based on the compressed SSG and indices, we propose a new efficient and effective approximation algorithm, called SSG-MCBA by adopting the Monte Carlo method and our optimization search strategies. The experiments conducted onto two real social network datasets illustrate that SSG-MCBA greatly outperforms the state-of-the-art method in both efficiency and effectiveness.
C1 [Lu, Junwen] Xiamen Univ Technol, Engn Res Ctr Software Testing & Evaluat Fujian Pr, Xiamen, Fujian, Peoples R China.
   [Liu, Guanfeng] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
   [Zheng, Bolong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Zhao, Yan] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
   [Zheng, Kai] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
   [Zheng, Kai] Univ Elect Sci & Technol China, Big Data Res Ctr, Chengdu, Sichuan, Peoples R China.
C3 Xiamen University of Technology; Macquarie University; Huazhong
   University of Science & Technology; Soochow University - China;
   University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Liu, GF (corresponding author), Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
EM guanfeng.liu@mq.edu.au
RI yu, hui/KDO-3946-2024; Liu, Guanfeng/KHV-9757-2024
OI Liu, Guanfeng/0000-0001-8980-4950
CR Adler PS, 2001, ORGAN SCI, V12, P215, DOI 10.1287/orsc.12.2.215.10117
   [Anonymous], 2009, P 8 INT C AUT AG MUL
   [Anonymous], IEEE TCYB
   [Anonymous], 1986, Graph Theory
   [Anonymous], 2012, P 2012 ACM SIGMOD IN
   Berger, 1967, The Social Construction of Reality
   Chard K, 2012, IEEE T SERV COMPUT, V5, P551, DOI 10.1109/TSC.2011.39
   Chua F., 2010, Proc. of SIGKDD'10, P889
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Fan WF, 2014, PROC INT CONF DATA, P184, DOI 10.1109/ICDE.2014.6816650
   Gentle J, 2004, HDB COMPUTATIONAL ST
   Golbeck J., 2006, ACM Transactions on Internet Technology, V6, P497, DOI 10.1145/1183463.1183470
   Guanfeng Liu, 2011, Proceedings of the 2011 IEEE International Conference on Web Services (ICWS 2011), P41, DOI 10.1109/ICWS.2011.81
   Guanfeng Liu, 2010, 2010 IEEE 7th International Conference on Services Computing (SCC 2010), P130, DOI 10.1109/SCC.2010.47
   Korte R.F., 2003, ADV DEV HUM RESOUR, V5, P440, DOI [DOI 10.1177/1523422303257287, 10.1177/1523422303257287]
   Kuter U., 2007, AAAI, V7, P1377
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Lin CY, 2009, PROC INT CONF DATA, P1483, DOI 10.1109/ICDE.2009.140
   Liu G, 2014, ICWS 14
   Liu G., 2011, Proc. 25th AAAI Conf. Artificial Intell, P1222
   Liu G, 2012, TRUSTCOM 12
   Liu G., 2010, P 9 INT C AUT AG MUL, V1, P1575
   Liu GF, 2013, IEEE T SERV COMPUT, V6, P152, DOI 10.1109/TSC.2011.58
   Liu GF, 2010, AAAI CONF ARTIF INTE, P1391
   Liu LY, 2017, LECT NOTES COMPUT SC, V10538, P110, DOI 10.1007/978-3-319-68155-9_9
   Lo D., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM '11, P1013, DOI [10.1145/2063576.2063722, DOI 10.1145/2063576.2063722]
   McCallum A, 2007, J ARTIF INTELL RES, V30, P249, DOI 10.1613/jair.2229
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   Miller R.S., 2007, Intimate relationships, V4th
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Morton D, 2009, ENCY OPTIMIZATION, P2337
   POOL ID, 1978, SOC NETWORKS, V1, P5, DOI 10.1016/0378-8733(78)90011-4
   Shin Y, 2012, IEEE T KNOWL DATA EN, V24, P2203, DOI 10.1109/TKDE.2011.144
   Sun Z, 2012, PROC VLDB ENDOW, V5, P788, DOI 10.14778/2311906.2311907
   Tang J., 2008, SIGKDD, P990, DOI DOI 10.1145/1401890.1402008
   Tang Jiliang, 2012, KDD, P253, DOI [10.1145/2339530.2339574, DOI 10.1145/2339530.2339574]
   Wang GJ, 2011, FUTURE GENER COMP SY, V27, P529, DOI 10.1016/j.future.2010.04.015
   Wang L, 2018, J VIS COMMUN IMAGE R, V54, P213, DOI 10.1016/j.jvcir.2018.05.006
   Wang Y, 2013, WORLD WIDE WEB J
   Wang Y, 2007, 9TH IEEE INTERNATIONAL CONFERENCE ON E-COMMERCE TECHNOLOGY/4TH IEEE INTERNATIONAL CONFERENCE ON ENTERPRISE COMPUTING, E-COMMERCE AND E-SERVICES, P278, DOI 10.1109/CEC-EEE.2007.83
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Yao Y., 2013, P 22 INT C WORLD WID, P1467
   Zheng K, 2017, WORLD WIDE WEB, V20, P749, DOI 10.1007/s11280-016-0414-0
   Zhu L, 2016, IEEE TCYB, V47, P3941
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu Yuanyuan., 2012, EDBT, P456, DOI DOI 10.1145/2247596.2247650
NR 46
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24473
EP 24500
DI 10.1007/s11042-019-7158-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900036
DA 2024-07-18
ER

PT J
AU Singh, P
   Singh, AK
   Singh, P
   Kumari, S
   Sangaiah, AK
AF Singh, Pitam
   Singh, Ashish Kumar
   Singh, Priyamvada
   Kumari, Saru
   Sangaiah, Arun Kumar
TI Multimodal data modeling for efficiency assessment of social priority
   based urban bus route transportation system using GIS and data
   envelopment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transportation planning; Data envelopment analysis; GIS; social
   priority; Urban transport; Socially efficient route
ID ROAD SYSTEM; PERFORMANCE; DEA
AB Multimodal data modeling is fast growing area of research. It may used to combine the information from the different sources. The research interest in multimodal data modeling is increasingly attracting the attention in the field of transportation planning. In this study, multi-modal data is used to assess and design a socially efficient public transport bus route plan for the Allahabad city of Uttar Pradesh state, India. Data envelopment analysis (DEA) method is used for the efficiency assessment of existing 24 public transport bus routes by taking access point to locations of social facilities like as hospitals, shopping malls, colleges, coaching centers, schools, banks and the population, near to the particular route. Geographical Information System (GIS) technology is used for multimodal data modeling to design new more socially efficient routes for the existing roads of the city. DEAP Solver software is used for the evaluation of efficiency and rank for social priority routes and route number 15 and 24 are relative efficient route among the existing 24 routes. Finally, the social efficiency of existing public bus transport routes and newly designed routes are compared. We suggested ways to improve the performance of bus routes based on the social perspectives using multimodal data.
C1 [Singh, Pitam; Singh, Ashish Kumar] Motilal Nehru Natl Inst Technol Allahabad, Dept Math, Allahabad, Uttar Pradesh, India.
   [Singh, Priyamvada] Univ Allahabad, Dept Earth & Planetary Sci, Allahabad, Uttar Pradesh, India.
   [Kumari, Saru] CCS Univ, Dept Math, Meerut, Uttar Pradesh, India.
   [Sangaiah, Arun Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; University of Allahabad; Chaudhary Charan Singh
   University; Vellore Institute of Technology (VIT); VIT Vellore
RP Kumari, S (corresponding author), CCS Univ, Dept Math, Meerut, Uttar Pradesh, India.
EM pitams@mnnit.ac.in; ashish9039850137@gmail.com; priyam028@yahoo.com;
   saryusiirohi@gmail.com; arunkumarsangaiah@gmail.com
RI Kumari, Saru/K-2038-2019; Sangaiah, Arun Kumar/U-6785-2019
OI Kumari, Saru/0000-0003-4929-5383; Sangaiah, Arun
   Kumar/0000-0002-0229-2460; Singh, Pitam/0000-0001-9258-3132
FU Indian Council of Social Science Research (ICSSR), Ministry of Human
   Resource Development, Government of India [02/234/SC/2015-16/RPR]
FX This research work is supported financially by Indian Council of Social
   Science Research (ICSSR), Ministry of Human Resource Development,
   Government of India, through sanctionorder no. F.No.
   02/234/SC/2015-16/RPR.
CR Been HP, 1995, BUS ROUTE EVALUATION
   Bray S, 2014, PROCD SOC BEHV, V111, P770, DOI 10.1016/j.sbspro.2014.01.111
   CHARNES A, 1978, EUR J OPER RES, V2, P429, DOI 10.1016/0377-2217(78)90138-8
   Chen XM, 2009, TRANSPORT RES A-POL, V43, P722, DOI 10.1016/j.tra.2009.07.006
   Coelli T., 2011, DEAP V2 1 DATA ENVEL
   COOPER W.W., 1994, DATA ENVELOPMENT ANA
   Fancello G, 2013, PROCD SOC BEHV, V87, P163, DOI 10.1016/j.sbspro.2013.10.601
   Fancello G, 2014, PROCD SOC BEHV, V111, P780, DOI 10.1016/j.sbspro.2014.01.112
   Gagnepain P, 2002, RAND J ECON, V33, P605, DOI 10.2307/3087477
   Higashimoto Y., 2013, P E ASIA SOC TRANSPO, V9, P1
   IGI Global, 1988, WHAT IS GEOGR INF SY
   Karlaftis MG, 2004, EUR J OPER RES, V152, P354, DOI 10.1016/S0377-2217(03)00029-8
   Lao Y, 2009, PERFORMANCE EVALUATI
   Li JB, 2013, PROCD SOC BEHV, V96, P148, DOI 10.1016/j.sbspro.2013.08.020
   Lin J, 2008, TRANSPORT RES E-LOG, V44, P1086, DOI 10.1016/j.tre.2007.10.002
   Piacenza M, 2006, J PROD ANAL, V25, P257, DOI 10.1007/s11123-006-7643-7
   POLUS A, 1978, TRANSPORT RES, V12, P253, DOI 10.1016/0041-1647(78)90067-9
   Sheth C, 2007, TRANSPORT RES E-LOG, V43, P453, DOI 10.1016/j.tre.2005.09.010
   Tiwari G, 2003, SOCIAL DIMENSION TRA
   Yu MM, 2009, TRANSPORT RES E-LOG, V45, P501, DOI 10.1016/j.tre.2008.10.001
NR 20
TC 9
Z9 9
U1 8
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23897
EP 23915
DI 10.1007/s11042-018-6147-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900007
DA 2024-07-18
ER

PT J
AU Wang, HN
   Xiang, SY
   Gong, JK
AF Wang, Haoning
   Xiang, Shuiying
   Gong, Junkai
TI Multi-user image encryption algorithm based on synchronized random bits
   generator in semiconductor lasers network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-user secure encryption; Semiconductor laser; Information
   reconciliation; Physical random bits
ID CHAOS; SCHEME
AB A chaos-based public channel image encryption algorithm among three users is proposed, where the random bits (RBs) generated in a star-type chaotic laser network can be well synchronized and are used as the keys. The proposed algorithm is simple and efficient. Firstly, random bits with verified randomness are generated from the synchronized chaotic semiconductor lasers in a star-type network at a rate of 10Gb/s. Next, lower-triangular error-bits detection is employed to delete the different bits among all the parties over the public channel. Based on the synchronized RBs, the XOR operation is used to diffuse the plain image. Then the hash algorithm is used to get the control parameters matrix from the plain image, and 3D cat map is used to confuse the pixel position through the parameters matrix. Finally, the encrypted image is transmitted in the public channel. The performance tests results, such as key sensitivity, histogram, correlation, differential attack, robustness and entropy analysis, show that the suggested algorithm prevents a powerful computational eavesdropper. Besides, the running speed of this algorithm is linear with the size of plain image. These results open possibilities for multi-user secure communication application.
C1 [Wang, Haoning; Xiang, Shuiying; Gong, Junkai] Xidian Univ, State Key Lab Integrated Serv Networks, POB 119,2 South Taibai Rd, Xian 710071, Shanxi, Peoples R China.
   [Xiang, Shuiying] Xidian Univ, Sch Microelect, State Key Discipline Lab Wide Bandgap Semicond Te, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Xiang, SY (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, POB 119,2 South Taibai Rd, Xian 710071, Shanxi, Peoples R China.
EM jxxsy@126.com
FU National Natural Science Foundation of China [61674119, 61306061];
   National Postdoctoral Program for innovative Talents in China
   [BX201600118]; Young Talent fund of University Association for Science
   and Technology in Shaanxi, China [20160109]; China Postdoctoral Science
   Foundation [2017 M613072]; Natural Science Basic Research Plan in
   Shaanxi Province of China [2017JM6002, 2016JM6009]; China 111 Project
   [B08038]
FX National Natural Science Foundation of China (No. 61674119, No.
   61306061); National Postdoctoral Program for innovative Talents in China
   (BX201600118); The Young Talent fund of University Association for
   Science and Technology in Shaanxi, China (20160109); The project funded
   by China Postdoctoral Science Foundation (No. 2017 M613072); Natural
   Science Basic Research Plan in Shaanxi Province of China (No.
   2017JM6002, 2016JM6009); The China 111 Project (No. B08038).
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Argyris A, 2016, OPT EXPRESS, V24, P5600, DOI 10.1364/OE.24.005600
   Argyris A, 2015, SPIE OPTO INT SOC OP, V10
   Argyris A, 2016, J LIGHTWAVE TECHNOL, V34, P5325, DOI 10.1109/JLT.2016.2615870
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Chai X, 2016, MULTIMEDIA TOOLS APP, V76, P1
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dave S, 2012, TECHNOMETRICS, V36, P427
   Esposito C, 2018, IEEE T IND INFORM, V14, P4972, DOI 10.1109/TII.2018.2853676
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Heil T, 2001, PHYS REV LETT, V86, P795, DOI 10.1103/PhysRevLett.86.795
   Heiligenthal S, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.234102
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kanter I, 2010, OPT EXPRESS, V18, P18292, DOI 10.1364/OE.18.018292
   Kanter I, 2010, NAT PHOTONICS, V4, P58, DOI 10.1038/NPHOTON.2009.235
   Li JF, 2018, OPT LASER ENG, V102, P170, DOI 10.1016/j.optlaseng.2017.11.001
   Li W, 2015, EPL-EUROPHYS LETT, V112, DOI 10.1209/0295-5075/112/30007
   Li XZ, 2012, OPT LETT, V37, P2163, DOI 10.1364/OL.37.002163
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Porte X, 2016, OPT LETT, V41, P2871, DOI 10.1364/OL.41.002871
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang S, 2003, PHYS REV LETT, V90, DOI 10.1103/PhysRevLett.90.194101
   Wang LC, 2015, IEEE J QUANTUM ELECT, V51, P1, DOI 10.1109/JQE.2015.2409305
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wu JG, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15570
   Xiang SY, 2016, IEEE PHOTONIC TECH L, V28, P1988, DOI 10.1109/LPT.2016.2581310
   Xie YY, 2016, J LIGHTWAVE TECHNOL, V34, P5101, DOI 10.1109/JLT.2016.2606121
   Xue CP, 2015, OPT EXPRESS, V23, P14510, DOI 10.1364/OE.23.014510
   Yassein MB, 2019, FOUND SCI, V21, P1
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
NR 40
TC 5
Z9 6
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26181
EP 26201
DI 10.1007/s11042-019-07796-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700042
DA 2024-07-18
ER

PT J
AU Amirpour, H
   Ghanbari, M
   Pinheiro, A
   Pereira, M
AF Amirpour, Hadi
   Ghanbari, Mohammad
   Pinheiro, Antonio
   Pereira, Manuela
TI Motion estimation with chessboard pattern prediction strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Motion estimation; Dynamic search pattern;
   Prediction; PSNR
ID SEARCH ALGORITHM
AB Due to high correlations among the adjacent blocks, several algorithms utilize movement information of spatially and temporally correlated neighbouring blocks to adapt their search patterns to that information. In this paper, this information is used to define a dynamic search pattern. Each frame is divided into two sets, black and white blocks, like a chessboard pattern and a different search pattern is defined for each set. The advantage of this definition is that the number of spatially neighbouring blocks is increased for each current block and it leads to a better prediction for each block. Simulation results show that the proposed algorithm is closer to the Full-Search algorithm in terms of quality metrics such as PSNR than the other state-of-the-art algorithms while at the same time the average number of search points is less.
C1 [Amirpour, Hadi; Pinheiro, Antonio; Pereira, Manuela] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
   [Ghanbari, Mohammad] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 Universidade da Beira Interior; University of Tehran; University of
   Essex
RP Amirpour, H (corresponding author), Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
EM hadi.amirpour@gmail.com
RI Pereira, Manuela/Q-3456-2019; Ghanbari, Mohammad/L-4053-2019; Pinheiro,
   Antonio/B-2723-2012
OI Pereira, Manuela/0000-0002-8648-6464; Ghanbari,
   Mohammad/0000-0002-5482-8378; Pinheiro, Antonio/0000-0002-5968-9901;
   Amirpour, Hadi/0000-0001-9853-1720
FU FCT; FEDER-PT2020 partnership agreement [PTDC/EEI-PRO/2849/2014 -
   POCI-01-0145-FEDER-016693, UID/EEA/50008/2019]; Fundação para a Ciência
   e a Tecnologia [UID/EEA/50008/2013] Funding Source: FCT
FX This work is funded by FCT through national funds and co-funded by
   FEDER-PT2020 partnership agreement under the project
   PTDC/EEI-PRO/2849/2014 - POCI-01-0145-FEDER-016693, and under the
   project UID/EEA/50008/2019.
CR Al-Mualla M.E., 2002, VIDEO CODING MOBILE
   Amirpour H, 2013, 2013 8 IR MACH VIS I
   Amirpour H, 2016, SIGNAL IMAGE VIDEO P, V10, P1393, DOI 10.1007/s11760-016-0906-5
   [Anonymous], 1981, P NAT TEL C NEW ORL
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   Jakubowski M, 2013, OPTO-ELECTRON REV, V21, P86, DOI 10.2478/s11772-013-0071-0
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Khemiri R., 2016, IEEEIPAS 16, P1
   Kim BG, 2016, BASIC PREDICTION TEC
   Kuo TY, 1998, IEEE T CIRC SYST VID, V8, P705, DOI 10.1109/76.728412
   Lin LL, 2016, SIGNAL IMAGE VIDEO P, V10, P171, DOI 10.1007/s11760-014-0723-7
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Pan Z, 2017, MULTIMEDIA TOOLS APP
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P2447, DOI 10.1007/s11042-018-6353-2
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Puri A., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P1063
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Purnachand N., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P388
   Purwar RK, 2017, SIGNAL IMAGE VIDEO P, V11, P1001, DOI 10.1007/s11760-016-1050-y
   Purwar RK, 2013, SIGNAL IMAGE VIDEO P, V7, P151, DOI 10.1007/s11760-011-0283-z
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tourapis AM, 2001, P SOC PHOTO-OPT INS, V4310, P883
   Zhaohua Lin, 2009, 2009 IEEE International Symposium on Industrial Electronics (ISIE 2009), P1327, DOI 10.1109/ISIE.2009.5213777
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 26
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21785
EP 21804
DI 10.1007/s11042-019-7432-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400055
OA Green Published
DA 2024-07-18
ER

PT J
AU Dey, A
   Jenamani, M
   Thakkar, JJ
AF Dey, Atanu
   Jenamani, Mamata
   Thakkar, Jitesh J.
TI Cross-D-vectorizers: a set of feature-spaces for cross-domain sentiment
   analysis from consumer review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Sentiment analysis; N-grams; Cross domain; Maximum entropy; TFIDF
ID CLASSIFICATION; LEXICON
AB Supervised sentiment classification approaches require labeled training (source) and testing (target) dataset. Generation of such datasets demands substantial time and effort but cross-domain classification minimizes the effort by considering two different domains for source and target datasets. In this paper, we propose Cross-D-Vectorizers i.e., a set of three sentiment n-gram feature-spaces (Lexical-TFIDF, Lex-Delta-TFIDF and SEND) for the purpose of cross-domain analysis. We construct the features by extracting sentiment unigrams combination with intensifiers and negations from the source dataset. By utilizing an existing lexicon the scores of these features are computed in three different procedures. The scores for each feature are computed by multiplying sentiment value with corresponding TFIDF rating, Delta-TFIDF rating and feature-importance-values (FIV) respectively. Importance-value for each SEND (Sentiment wEight ofN-grams inDataset) feature is calculated by multiplying the number of times the feature appears in the review and the logarithm of its inverse frequency in the corpus. We experiment by using Maximum Entropy, Support Vector Machine and K-Nearest Neighbors classifiers on three benchmark datasets and one proposed dataset for cross-domain classification. Proposed approach show improved results in comparison with existing methods. The advantage of our approach is the complexity of system reduces by considering sentiment n-grams as domain independent features instead of any n-grams.
C1 [Dey, Atanu; Jenamani, Mamata; Thakkar, Jitesh J.] Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Dey, A (corresponding author), Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
EM atanu.dey@iitkgp.ac.in; mj@iem.iitkgp.ernet.in; jt@iem.iitkgp.ernet.in
RI Thakkar, Jitesh/AAD-6089-2019; Jenamani, Mamata/Q-6141-2016
OI Thakkar, Jitesh/0000-0001-6415-1981; Dey, Atanu/0000-0003-3477-3901
FU MHRD, Govt. of India [5-5/2014-TS.VII]; Dept. of Higher Education, New
   Delhi, India
FX We are grateful for the access to facilities of "E-Business Centre of
   Excellence" Lab at Indian Institute of Technology, Kharagpur. This work
   is supported by MHRD, Govt. of India, [Sanction Letter No.: F.No.
   5-5/2014-TS.VII, Dt; 04-09-2014], Dept. of Higher Education, New Delhi,
   India.
CR [Anonymous], 2009, ICWSM
   [Anonymous], 2014, Eighth Int. AAAI Conf. Weblogs Soc. Media
   [Anonymous], 2009, THESIS
   [Anonymous], 2012, P 1 INT WORKSH ISS S
   Arunachalam Ravi, 2013, P IJCNLP 2013 WORKSH, P23
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Bollegala D, 2016, IEEE T KNOWL DATA EN, V28, P398, DOI 10.1109/TKDE.2015.2475761
   Chen Y, 2014, USING ACM DL PAPER M
   Chen Y., 2017, THESIS
   Chen YH, 2017, OPTOELECTRON LETT, V13, P1, DOI 10.1007/s11801-017-6237-0
   Chidlovskii B., 2014, CLEF WORKING NOTES, P448
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Garcia-Diaz Jose Antonio, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 745), P305, DOI 10.1007/978-3-319-77703-0_31
   Han H., 2018, MULTIMED TOOLS APPL, P1
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Ji JL, 2018, LECT NOTES ARTIF INT, V10937, P681, DOI 10.1007/978-3-319-93034-3_54
   Li Y, 2015, MULTIMED TOOLS APPL, V74, P10177, DOI 10.1007/s11042-014-2158-0
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu YH, 2018, J INF SCI, V44, P594, DOI 10.1177/0165551517722741
   Luo BH, 2016, EXPERT SYST APPL, V44, P138, DOI 10.1016/j.eswa.2015.08.023
   Matsumoto S, 2005, PAKDD, V5
   Nigam K, 1999, IJCAI 99 WORKSH MACH, V1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Rosenthal Sara, 2017, P 11 INT WORKSH SEM, P502
   SPARCK-JONES K, 1973, INFORM STORAGE RET, V9, P619, DOI 10.1016/0020-0271(73)90043-0
   Taboada M, 2004, ANAL APPRAISAL AUTOM
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Wang L, 2018, J NETW COMPUT APPL, V101, P111, DOI 10.1016/j.jnca.2017.11.001
   Yang L, 2016, INFORM PROCESS LETT, V116, P623, DOI 10.1016/j.ipl.2016.04.009
   Yu L. C., 2018, J COMPUTER ASSISTED
NR 34
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23141
EP 23159
DI 10.1007/s11042-019-7553-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400043
OA Bronze
DA 2024-07-18
ER

PT J
AU Merghani, W
   Davison, AK
   Yap, MH
AF Merghani, Walied
   Davison, Adrian K.
   Yap, Moi Hoon
TI The implication of spatial temporal changes on facial micro-expression
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial micro-expression; Micro-expression recognition; Frame rate;
   Resolution; Temporal interpolation model
ID RECOGNITION
AB Facial micro-expression datasets lack consistency and standardisation, with different research groups using various experimental settings, in particular, where the datasets are varied in resolution and frame rates. To provide new insights into the roles of frame rate and resolution, we conduct an investigation into the use of different frame rates and resolution on current benchmark datasets (SMIC and CASME II). By using Temporal Interpolation Model, we subsample SMIC (original frame rate is 100 fps) to 50 fps and CASME II (original frame rate is 200 fps) into 100 fps and 50 fps. In addition, the resolution settings are adjusted to three scaling factors: 100% (original resolution), 75% and 50%. Three feature types are used to test the performance of these settings, which are Local Binary Patterns in Three Orthogonal Planes, 3D Histograms of Oriented Gradient and Histogram of Oriented Optical Flow. The results showed that the frame rate and resolution could affect the performance of micro-expression recognition, which behave distinctively dependent on feature types. This work provides new guidelines for future research in selecting frame rate, resolution and feature descriptors in micro-expressions recognition.
C1 [Merghani, Walied] Sudan Univ Sci & Technol, Comp Sci Dept, Khartoum, Sudan.
   [Davison, Adrian K.] Univ Manchester, Ctr Imaging Sci, Manchester, Lancs, England.
   [Yap, Moi Hoon] Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Manchester, Lancs, England.
C3 University of Manchester; Manchester Metropolitan University
RP Yap, MH (corresponding author), Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Manchester, Lancs, England.
EM M.Yap@mmu.ac.uk
RI Merghani, Walied/JYP-8084-2024; Merghani, Walied/JYP-7964-2024; Davison,
   Adrian/AAV-2268-2020
OI Davison, Adrian/0000-0002-6496-0209; Yap, Moi Hoon/0000-0001-7681-4287
CR [Anonymous], 2014, Proceedings of the Asian Conference on Computer Vision
   [Anonymous], 2014, P 2014 ASIAN C COMPU
   [Anonymous], 1999, FAST TRAINING SUPPOR
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], 2015, ARXIV151100423
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davison A.K., 2014, European conference on computer vision, P111
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Davison AK, 2018, IEEE INT CONF AUTOMA, P642, DOI 10.1109/FG.2018.00101
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Lee K, 2013, I S MOD ANAL SIM COM, P1, DOI 10.1109/MASCOTS.2013.8
   Li X, 2013, SCI WORLD J, DOI 10.1155/2013/364730
   Liu Y. -J., 2015, IEEE T AFFECTIVE COM
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yap MH, 2018, IEEE INT CONF AUTOMA, P675, DOI 10.1109/FG.2018.00106
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 28
TC 6
Z9 6
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21613
EP 21628
DI 10.1007/s11042-019-7434-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400048
OA hybrid
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Gao, ED
   Zhu, RX
   Wang, LF
AF Pan, Zhibin
   Gao, Erdun
   Zhu, Ruoxin
   Wang, Lingfei
TI A low bit-rate SOC-based reversible data hiding algorithm by using new
   encoding strategies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image compression; Search order coding (SOC);
   Vector quantization (VQ); Placeholder (PH) of repetition search point
ID SCHEME; COMPRESSION; SMVQ
AB Search order coding (SOC) benefits a lot from the correlation of neighboring blocks for vector quantization (VQ)-compressed images. SOC selects a number of different indices in its search path as candidate search order codes. In this work, we present a low bit-rate SOC-based reversible data hiding algorithm benefiting from novel encoding strategies which exploit the information of the placeholders. The blocks are classified into two categories by the placeholders, where different encoding strategies are designed, respectively. Firstly, for the block in smooth region, the placeholders in its neighborhood are employed to compress the VQ index. Secondly, for the block in complex region, SOC is employed to compress the VQ index. Finally, for the blocks that cannot be processed by its placeholders and SOC, an effective prediction method named accurate gradient selective prediction (AGSP) and Huffman coding are introduced. After encoding phase, the size of the output bit stream is reduced so that space is saved for data embedding. Experiment results show that our proposed method outperforms other state-of-the-art SOC-based algorithms in bit rate and embedding capacity.
C1 [Pan, Zhibin; Gao, Erdun; Zhu, Ruoxin; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of the National Laboratory of Pattern Recognition
   (NLPR) [201800030]
FX This work is supported in part by the Open Project Program of the
   National Laboratory of Pattern Recognition (NLPR) (Grant No. 201800030).
CR Ahn H, 2013, IEEE INT C COMPUT, P416, DOI 10.1109/CSE.2013.70
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P3537, DOI 10.1007/s11042-015-2463-2
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   Fridrich J, 2001, P ITCC
   Gersho A., 1992, Vector quantization and signal compression
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kieu TD, 2015, EXPERT SYST APPL, V42, P713, DOI 10.1016/j.eswa.2014.09.001
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   Lin YC, 1999, NATL COMPUTER S, P76
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V26, P14, DOI 10.1016/j.jvcir.2014.09.005
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin CB, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P48, DOI 10.1109/WCICA.2016.7578504
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Tang HJ, 2006, IEICE T INF SYST, VE89D, P2250, DOI 10.1093/ietisy/e89-d.7.2250
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
NR 34
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21223
EP 21244
DI 10.1007/s11042-019-7425-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400031
DA 2024-07-18
ER

PT J
AU Sezavar, A
   Farsi, H
   Mohamadzadeh, S
AF Sezavar, Amir
   Farsi, Hassan
   Mohamadzadeh, Sajad
TI Content-based image retrieval by combining convolutional neural networks
   and sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Deep learning; Convolutional neural
   networks; Sparse representation
ID COLOR; ALGORITHMS; SYSTEM
AB As stored data and images on memory disks increase, image retrieval has a necessary task on image processing. Although lots of researches have been reported for this task so far, semantic gap between low level features of images and human concept is still an important challenge on content-based image retrieval. For this task, a robust method is proposed by a combination of convolutional neural network and sparse representation, in which deep features are extracted by using CNN and sparse representation to increase retrieval speed and accuracy. The proposed method has been tested on three common databases on image retrieval, named Corel, ALOI and MPEG7. By computing metrics such as P(0.5), P(1) and ANMRR, experimental results show that the proposed method has achieved higher accuracy and better speed compared to state-of-the-art methods.
C1 [Sezavar, Amir; Farsi, Hassan; Mohamadzadeh, Sajad] Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
C3 University of Birjand
RP Farsi, H (corresponding author), Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
EM hfarsi@birjand.ac.ir
RI Farsi, hassan/AAF-5297-2021; mohamadzadeh, sajad/AAF-4605-2021
OI mohamadzadeh, sajad/0000-0002-9096-8626; farsi,
   hassan/0000-0001-6038-9757
CR Veganzones MA, 2012, IEEE J-STARS, V5, P488, DOI 10.1109/JSTARS.2012.2186629
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], J INF SYST TELECOMMU
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2013, MAJLESI J ELECT ENG
   [Anonymous], RITA
   [Anonymous], WORKSH VIS COMP WVC
   [Anonymous], MPEG 7 OV 2004
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], FEATURE EXTRACTION M
   [Anonymous], P IEEE C COMP VIS PA
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Farsi H, 2013, IET IMAGE PROCESS, V7, P212, DOI 10.1049/iet-ipr.2012.0203
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hiremath PS, 2006, INT J COMPUT SCI NET, V6, P124
   Ka-Man W, 2007, IEEE INT C IMAGE PRO
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li F, 2008, IEEE T MULTIMEDIA, V10, P1592, DOI 10.1109/TMM.2008.2004914
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Liu HL, 2017, PROCEDIA COMPUT SCI, V107, P749, DOI 10.1016/j.procs.2017.03.159
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mohamadzadeh S, 2016, IET COMPUT VIS, V10, P95, DOI 10.1049/iet-cvi.2015.0165
   Montagna R, 2012, IET IMAGE PROCESS, V6, P139, DOI 10.1049/iet-ipr.2010.0498
   Peng TQ, 2017, INT CONF ACOUST SPEE, P1742, DOI 10.1109/ICASSP.2017.7952455
   Qayyum A, 2017, NEUROCOMPUTING
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Varga D, 2016, IEEE SYS MAN CYBERN, P2636, DOI 10.1109/SMC.2016.7844637
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 38
TC 36
Z9 37
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20895
EP 20912
DI 10.1007/s11042-019-7321-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400016
DA 2024-07-18
ER

PT J
AU Bauman, B
   Seeling, P
AF Bauman, B.
   Seeling, P.
TI Spherical image QoE approximations for vision augmentation scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Quality of experience; Image quality; Quality of
   service; Electroencephalography
ID QUALITY ASSESSMENT; COGNITIVE LOAD; VIDEO; EXPERIENCE; SYSTEMS
AB Augmented Reality (AR) devices are commonly head-worn to overlay context-dependent information into the field of view of the device operators. One particular scenario is the overlay of still images, for which we evaluate the interplay of user ratings as Quality of Experience (QoE) with (i) the non-referential BRISQUE objective image quality metric as Quality of Service (QoS) and (ii) human subject dry electrode EEG signals gathered with a commercial off-the-shelf device. We employ basic machine learning approaches to perform QoE and QoS predictions based on this data. We find strong correlations for QoS inputs with aggregated user ratings as Mean Opinion Scores with spherical images. For subject-specific EEG portfolios, overall predictability of the QoE for both media types can be attained. Our overall results can be employed in practical scenarios by content and network service providers to optimize the user experience in augmented reality scenarios with a passive human in-the-loop in the future.
C1 [Bauman, B.; Seeling, P.] Cent Michigan Univ, Dept Comp Sci, Mt Pleasant, MI 48859 USA.
C3 Central Michigan University
RP Seeling, P (corresponding author), Cent Michigan Univ, Dept Comp Sci, Mt Pleasant, MI 48859 USA.
EM patrick.seeling@cmich.edu
RI Seeling, Patrick/M-3697-2013
OI Seeling, Patrick/0000-0003-2770-0675
FU Faculty Research and Creative Endeavors (FRCE) program at Central
   Michigan University [48146]
FX This material is based upon work supported by the Faculty Research and
   Creative Endeavors (FRCE) program at Central Michigan University under
   grant #48146.
CR Acqualagna L, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/2/026012
   [Anonymous], 2016, P 2016 IEEE INT C CO
   [Anonymous], 2013, White Paper
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   [Anonymous], 2017, P 9 INT C QUALITY MU
   Antons JN, 2014, T-LAB SER TELECOMMUN, P109, DOI 10.1007/978-3-319-02681-7_8
   Arampatzis A, 2009, P 18 ACM C INF KNOWL, DOI 10.1145/1645953.1646055
   Bauman B., 2017, P IEEE CONS COMM NET, P1
   Bauman B, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030040
   Blankertz Benjamin, 2016, Front Neurosci, V10, P530
   Bosse S, 2016, IEEE SYS MAN CYBERN, P2834, DOI 10.1109/SMC.2016.7844669
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Davis P, 2016, IEEE IMAGE PROC, P2420, DOI 10.1109/ICIP.2016.7532793
   Eiris Pereira R, 2019, ADV INFORM COMPUTING, P271
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Han Y, 2016, IEEE T BROADCAST, V62, P654, DOI 10.1109/TBC.2016.2529294
   He LH, 2014, INT J COMPUT MATH, V91, P2374, DOI 10.1080/00207160.2013.816415
   Holm A, 2009, THESCIENTIFICWORLDJO, V9, P639, DOI 10.1100/tsw.2009.83
   Irshad S., 2018, COMMUN COMPUT PHYS, VVolume 886, P349
   ITU-T, 2008, REC ITU T P 910 SUBJ
   ITU-T, 2012, REC ITU R BT 500 13
   Kroupi E, 2014, EUR SIGNAL PR CONF, P2135
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P70, DOI 10.1016/j.procs.2016.04.068
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lindemann Lea., 2011, Image Processing (ICIP), 2011 18th IEEE International Conference on, P3109, DOI DOI 10.1109/ICIP.2011.6116324
   Mazher M, 2017, IEEE ACCESS, V5, P14819, DOI 10.1109/ACCESS.2017.2731784
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moldovan AN, 2016, IEEE T BROADCAST, V62, P610, DOI 10.1109/TBC.2016.2570002
   Moon SE, 2017, IEEE T MULTIMEDIA, V19, P340, DOI 10.1109/TMM.2016.2614880
   NAGELKERKE NJD, 1991, BIOMETRIKA, V78, P691, DOI 10.1093/biomet/78.3.691
   Perrin AF, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1007, DOI 10.1145/2733373.2806387
   Plechawska-Wojcik M., 2017, STUDIA INFORM, V38, P17
   Nguyen QV, 2017, SA'17: SIGGRAPH ASIA 2017 COURSES, DOI 10.1145/3134472.3134516
   Reichl P, 2013, TELECOMMUN SYST, V52, P587, DOI 10.1007/s11235-011-9503-7
   Rein S, 2005, IEEE WIREL COMMUN, V12, P60, DOI 10.1109/MWC.2005.1404574
   Ruder MA, 2013, INT BLACK SEA CONF, P1, DOI 10.1109/BlackSeaCom.2013.6623371
   Scholler S, 2012, IEEE T IMAGE PROCESS, V21, P2619, DOI 10.1109/TIP.2012.2187672
   Seeling  P., 2016, P IEEE CONS COMM NET, P931
   Seeling P., 2015, P IEEE ICC WORKSH QU
   Seeling P, 2015, SIGNAL PROCESS-IMAGE, V33, P41, DOI 10.1016/j.image.2015.02.006
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Staelens N, 2012, IEEE T BROADCAST, V58, P187, DOI 10.1109/TBC.2012.2189334
   Xiao XP, 1999, IEEE NETWORK, V13, P8, DOI 10.1109/65.768484
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
NR 45
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18113
EP 18135
DI 10.1007/s11042-019-7171-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200036
DA 2024-07-18
ER

PT J
AU Kalmpourtzis, G
AF Kalmpourtzis, George
TI Developing kindergarten students' game design skills by teaching game
   design through organized game design interventions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game design; Human computer interaction; Participatory design; Design
   education; Serious games; Mathematics education
ID EDUCATIONAL GAME; SERIOUS GAMES; SIMULATIONS; TEACHERS; SYSTEM; PLAY;
   MOTIVATION; CHILDREN
AB Developing students' game design skills and the process of teaching game design acquire increasing research interest. The aim of this study was to (a) examine the impact of game design teaching interventions to kindergarten students and (b) examine the design of such interventions for teaching game design to students of this age. In that regard, this paper presents a teaching experiment, conducted with students in the early childhood. The experiment followed a quasi-experimental design, with a pre-test and a post-test and a focus and control groups. For a period of three months, only the focus group was presented with participatory game design activities while the control group followed the standard curriculum. During those interventions, students of the focus group worked on designing educational games about teaching pre-algebraic patterning to their peers. A mixed methods analysis was applied to analyze the results, which suggest that the facilitation of participatory game design activities has a positive impact on the development of game design skills. Additionally, this paper elaborates on issues that emerged through the study related to collaborative and individual work of students, difficulties in focusing on designing educational games and diversity of game proposals.
C1 [Kalmpourtzis, George] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Kalmpourtzis, G (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM gkalmpourtzis@playcompass.com
OI Kalmpourtzis, George/0000-0003-0761-6441
CR All A, 2016, COMPUT EDUC, V92-93, P90, DOI 10.1016/j.compedu.2015.10.007
   Allsop Y, 2016, BRIT J EDUC TECHNOL, V47, P665, DOI 10.1111/bjet.12251
   Amory A, 2007, ETR&D-EDUC TECH RES, V55, P51, DOI 10.1007/s11423-006-9001-x
   Pérez MEA, 2016, PROCEEDINGS 2016 INTERNATIONAL CONFERENCE ON MECHATRONICS, ELECTRONICS, AND AUTOMOTIVE ENGINEERING, (ICMEAE 2016), P90, DOI [10.1109/ICMEAE.2016.025, 10.1109/ICMEAE.2016.14]
   [Anonymous], YOUNG CHILDREN S ABI
   [Anonymous], P 9 NORD C HUM COMP
   [Anonymous], ED RES
   [Anonymous], COMPUTER LONG BEACH
   [Anonymous], 1998, DESIGN CHILDRENS TEC
   [Anonymous], 1996, TALKING MATH SUPPORT
   [Anonymous], CONSTRUCTIVISM PRACT
   [Anonymous], 2014, INT J CHILD COMPUTER, DOI DOI 10.1016/J.IJCCI.2015.07.002
   [Anonymous], 2014, CH 14 HUM FACT COMP, DOI DOI 10.1145/2559206.2581506
   [Anonymous], 2010, J COMPUT GAME CULT
   [Anonymous], ROLE ADULTS GIVING R
   [Anonymous], J MATH MODELLING APP
   [Anonymous], CONCEPTIONS CREATIVI
   [Anonymous], INTRO STAT METHODS S
   [Anonymous], INT J CHILD COMPUTER
   Arango-López J, 2019, TELEMAT INFORM, V38, P62, DOI 10.1016/j.tele.2018.08.005
   Bjerknes G., 1995, Scandinavian Journal of Information Systems, V7, P73
   Bodrova E, 2008, EUR EARLY CHILD EDUC, V16, P357, DOI 10.1080/13502930802291777
   Bonsignore E, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P11, DOI 10.1145/2930674.2930712
   Braghirolli LF, 2016, COMPUT HUM BEHAV, V58, P315, DOI 10.1016/j.chb.2015.12.063
   Brousseau G., 1997, Theory of didactical situations in mathematics
   Brousseau G., 2014, Theory of Didactical Situations in Mathematics
   Burgos D, 2007, COMPUT HUM BEHAV, V23, P2656, DOI 10.1016/j.chb.2006.08.002
   Chang KE, 2012, COMPUT EDUC, V58, P775, DOI 10.1016/j.compedu.2011.10.002
   Costa C, 2018, INT J GAME-BASED LEA, V8, P1, DOI 10.4018/IJGBL.2018040101
   Crespo S, 2008, J MATH TEACH EDUC, V11, P395, DOI 10.1007/s10857-008-9081-0
   Creswell J.W., 2013, RES DESIGN, DOI DOI 10.2307/3152153
   de Freitas S, 2006, COMPUT EDUC, V46, P249, DOI 10.1016/j.compedu.2005.11.007
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   Druin A., 1999, P SIGCHI C HUM FACT, P592, DOI DOI 10.1145/302979.303166
   Eerde H., 2013, Proceeding The First South East Asia Design/Development Research (SEADR) International Conference, P1
   Ellerton NF, 2013, EDUC STUD MATH, V83, P87, DOI 10.1007/s10649-012-9449-z
   Elverdam C., 2007, Games and Culture, V2, P3, DOI DOI 10.1177/1555412006286892
   Flick U., 2009, An introduction to qualitative research, V4th, P529
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Gonzales N.A., 1998, School Science and Mathematics, V98, P448, DOI 10.1111/j.1949-8594.1998.tb17437.x
   Gravemeijer K, 2009, ELEM SCHOOL J, V109, P510, DOI 10.1086/596999
   Guha M.L., 2013, INT J CHILD COMPUTER, V1, P14
   Guha ML, 2005, COMMUN ACM, V48, P39, DOI 10.1145/1039539.1039567
   Hainey T, 2016, COMPUT EDUC, V102, P202, DOI 10.1016/j.compedu.2016.09.001
   Hamlen KR, 2011, COMPUT HUM BEHAV, V27, P532, DOI 10.1016/j.chb.2010.10.001
   Hwang GJ, 2017, BRIT J EDUC TECHNOL, V48, P950, DOI 10.1111/bjet.12464
   Jean S, 2018, J ENVIRON MANAGE, V223, P1010, DOI 10.1016/j.jenvman.2018.05.021
   Kafai Y.B., 2012, Games, learning, and society: Learning and meaning in the digital age, P355, DOI [10.1017/CBO9781139031127.026, DOI 10.1017/CBO9781139031127.026]
   Kalmpourtzis G, 2019, BRIT J EDUC TECHNOL, V50, P846, DOI 10.1111/bjet.12607
   Kalmpourtzis G, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P123, DOI 10.1109/SMAP.2016.7753396
   Kalmpourtzis George, 2018, Educational Game Design Fundamentals: A Journey to Creating Intrinsically Motivating Learning Experiences
   Khaled R., 2014, IJCCI, V2, P93, DOI [DOI 10.1016/J.IJCCI.2014.03.001, 10.1016/j.ijcci.2014.03.001]
   Khaled Rilla., 2012, P DESIGNING INTERACT, P721, DOI [10.1145/2317956.2318065, DOI 10.1145/2317956.2318065]
   Klopfer E, 2005, TECHTRENDS, V49, P33, DOI 10.1007/BF02763645
   Lange-Nielsen Filip., 2012, Proceedings of the 4th International Conference on Fun and Games, P45
   Leonard J, 2016, J SCI EDUC TECHNOL, V25, P860, DOI 10.1007/s10956-016-9628-2
   Leung S.S., 1997, MATH EDUC RES J, V9, P5
   Leung SKS, 2013, EDUC STUD MATH, V83, P103, DOI 10.1007/s10649-012-9436-4
   Li Q, 2010, EDUC RES-UK, V52, P427, DOI 10.1080/00131881.2010.524752
   Maertens M., 2014, International Journal of Child-Computer Interaction, V2, P85
   Mazzone E., 2008, Proceedings, P290, DOI DOI 10.1145/1463160.1463192
   Mehta CyrusR., 1998, Encyclopedia of biostatistics, V2, P1411, DOI [10.1002/0470011815.b2a10019, DOI 10.1002/0470011815.B2A10019]
   Mulligan J, 2009, MATH EDUC RES J, V21, P33, DOI 10.1007/BF03217544
   Obikwelu C, 2013, ELECTRON J E-LEARN, V11, P49
   Papic MM, 2011, J RES MATH EDUC, V42, P237
   Patton M. Q., 2002, QUALITATIVE RES EVAL
   Petri G, 2017, COMPUT EDUC, V107, P68, DOI 10.1016/j.compedu.2017.01.004
   Poppelaars M, 2018, COMPUT HUM BEHAV, V83, P16, DOI 10.1016/j.chb.2018.01.019
   Read J.C., 2011, Proceedings of the 25th BCS Conference on Human-Computer Interaction (BCS-HCI '11), P163
   Romero M., 2017, Game-Based Learning Across the Lifespan, P1, DOI [DOI 10.1007/978-3-319-41797-4_1, 10.1007/978-3-319-4179]
   Salen Katie, 2004, RULES PLAY GAME DESI
   Schell J., 2014, The Art of Game Design: A book of lenses
   Schmidt J.A., 2010, INT ENCY ED, V3rd, P605
   Selter C, 2009, ZDM-MATH EDUC, V41, P619, DOI 10.1007/s11858-009-0203-7
   Shultz Colby Rebekah, 2017, Computers and Composition, V43, P55, DOI 10.1016/j.compcom.2016.11.002
   Shute VJ, 2015, COMPUT EDUC, V80, P58, DOI 10.1016/j.compedu.2014.08.013
   Siakavaras I., 2018, Research on e-Learning and ICT in education: Technological, pedagogical and instructional perspectives, P243, DOI [10.1007/978-3-319-95059-4_15, DOI 10.1007/978-3-319-95059-415]
   Silver EA, 2013, EDUC STUD MATH, V83, P157, DOI 10.1007/s10649-013-9477-3
   Stoyanova E., 1997, Extending and exploring students' problem solving via problem posing: A study of years 8 and 9 students involved in mathematics challenge and enrichment stages of Euler enrichment program for young Australians
   Tan J.L., 2011, Computers in Entertainment (CIE), V9, P2, DOI DOI 10.1145/1953005.1953007
   Tan JL, 2013, COMPUT EDUC, V64, P70, DOI 10.1016/j.compedu.2013.01.006
   Triantafyllakos G, 2011, COMPUT EDUC, V56, P227, DOI 10.1016/j.compedu.2010.08.002
   Umetsu T, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P124, DOI 10.1109/CIE.2002.1185882
   Winn Brian M, 2009, Handbook of research on effective electronic gaming in education, P1010, DOI DOI 10.4018/978-1-59904-808-6.CH058
   Yip J., 2013, P 12 INT C INTERACTI, P293, DOI DOI 10.1145/2485760.2485796
   Yip J., 2013, P 12 INT C INT DES C, P201, DOI DOI 10.1145/2485760.2485763
   Yu FY, 2005, INNOV EDUC TEACH INT, V42, P337, DOI 10.1080/14703290500062557
NR 87
TC 13
Z9 15
U1 4
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20485
EP 20510
DI 10.1007/s11042-019-7393-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800069
DA 2024-07-18
ER

PT J
AU Leng, HS
   Tseng, HW
AF Leng, Hui-Shih
   Tseng, Hsien-Wen
TI Generalize the EMD scheme on an n-dimensional hypercube with maximum
   payload
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Exploiting modification direction (EMD); n-dimensional
   hypercube
AB Data hiding is concerned with hiding secret data in cover media without raising suspicion about the existence of such information. In 2006, Zhang and Wang proposed a novel efficient steganographic method by exploiting modification direction (EMD). The EMD scheme provides little distortion and good stego-image quality. Then Kieu and Chang improved the EMD scheme by using eight modification directions for embedding more secret data at a time, and achieves payload with 4.5 bpp. In this study, a generalize EMD scheme is proposed based on an n-dimensional hypercube. It provides more higher payload. The experimental results show that the proposed method achieves payload with 4.75 bpp, which is better than any other published works while keeps good visual quality.
C1 [Leng, Hui-Shih] Changhua Univ Educ, Dept Math, 1 Jin De Rd, Changhua 50058, Changhua County, Taiwan.
   [Tseng, Hsien-Wen] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 41349, Taiwan.
C3 National Changhua University of Education; Chaoyang University of
   Technology
RP Tseng, HW (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 41349, Taiwan.
EM lenghs@cc.ncue.edu.tw; hwtseng@cyut.edu.tw
RI Tseng, Hsien-Wen/JUF-2625-2023
CR Chang C.-C., 2007, 3 INT C INT INF HID
   Chang C-C, 2008, 2008 3 INT C INN COM
   Chang CC, 2019, J REAL-TIME IMAGE PR, V16, P589, DOI 10.1007/s11554-018-0820-x
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen K-N, 2010, 2010 INT C COMP ASP
   Fan Wang, 2018, Procedia Computer Science, V131, P800, DOI 10.1016/j.procs.2018.04.265
   Fridrich J, 2001, P 2001 WORKSH MULT S
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kurup S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1982, DOI 10.1109/ICACCI.2015.7275908
   Lee C-F, 2018, J NETWORK INTELLIGEN, V3, P138
   Leng H.-S., 2017, ADV INTELLIGENT INFO, P29
   Leng H-S, 2017, 2017 IEEE 8 INT C AW
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lin ZM, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT GREEN BUILDING AND SMART GRID (IGBSG)
   Liu L, 2019, MULTIMED TOOLS APPL, V78, P10473, DOI 10.1007/s11042-018-6606-0
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Liu Y., 2017, P INT C VID IM PROC
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Liu YX, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2787803
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Turner LF, 1989, TURNER LF, V89, P8915
   Wang CC, 2018, MULTIMED TOOLS APPL, V77, P6327, DOI 10.1007/s11042-017-4541-0
   Weng Y-C, 2018, 2018 IEEE INT C APPL
   Xie XZ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020047
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 28
TC 8
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18363
EP 18377
DI 10.1007/s11042-019-7228-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200046
DA 2024-07-18
ER

PT J
AU Liu, ZD
   Zhou, WG
   Li, HQ
AF Liu, Zhandong
   Zhou, Wengang
   Li, Houqiang
TI Scene text detection with fully convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text detection; Semantic segmentation; Multi-orientation; Word
   stroke region; Text center block
AB Text detection in scene image has become a hot topic in computer vision and artificial intelligence research, due to its wide range of applications and challenges. Most state-of-the-art methods for text detection based on deep learning rely on text bounding box regression. These methods can not well handle the case that if the scene text is curved. In this paper, we propose a new framework for arbitrarily oriented text detection in natural images based on fully convolutional neural networks. The main idea is to represent a text instance by two forms: text center block and word stroke region. These two elements are detected by two fully convolutional networks, respectively. Final detections are produced by the word region surrounding box algorithm. The proposed method does not need to regress the extant bounding box of the text instance, mainly because the predicted text block region itself implicitly contains position and orientation information. Besides, our method can well handle text in different languages, arbitrary orientations, curved shape and various fonts. To validate the effectiveness of the proposed method, we perform experiments on three public datasets: MSRA-TD500, USTB-SV1K and ICDAR2013, and compare it with other state-of-the-art methods. Experiment results demonstrate that the proposed method achieves competitive results. Based on VGG-16, our method achieves an F-measure of 78.84% on MSRA-TD500, 59.34% on USTB-SV1K, and 88.21% on ICDAR2013.
C1 [Liu, Zhandong; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Li, HQ (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
EM lzd0825@mail.ustc.edu.cn; zhwg@ustc.edu.cn; lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013
FU Natural Science Foundation of China [61662082, U1703261, 61632019,
   61836011, 61390514]; Fundamental Research Funds for the Central
   Universities; Young Elite Scientists Sponsorship Program By CAST
   [2016QNRC001]
FX This work is supported in part to Zhandong Liu by Natural Science
   Foundation of China under contract No. 61662082 and No. U1703261, and in
   part to Dr. Wengang Zhou by Natural Science Foundation of China under
   contract No. 61632019, the Fundamental Research Funds for the Central
   Universities, and Young Elite Scientists Sponsorship Program By CAST
   (No. 2016QNRC001), and in part to Dr. Houqiang Li by Natural Science
   Foundation of China under contract No. 61836011 and No. 61390514.
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, IEEE ACCESS
   Bai Nong, 2016, ARXIV160609002
   Busta M, 2015, IEEE I CONF COMP VIS, P1206, DOI 10.1109/ICCV.2015.143
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   He DF, 2017, PROC CVPR IEEE, P474, DOI 10.1109/CVPR.2017.58
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   Huang L., 2015, Comput. Sci.
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Huh JH, 2016, J SUPERCOMPUT, V72, P1862, DOI 10.1007/s11227-016-1672-4
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang YY, 2018, INT C PATT RECOG, P3610, DOI 10.1109/ICPR.2018.8545598
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Khare V, 2017, MULTIMED TOOLS APPL, V76, P16625, DOI 10.1007/s11042-016-3941-x
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Nikoloudakis Y, 2016, IEEE CLOUD COMPUT, V3, P54, DOI 10.1109/MCC.2016.118
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Tian S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL SYMPOSIUM - FEMALE SURVIVAL AND DEVELOPMENT, P264
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yi C., 2011, International workshop on camera-based document analysis and recognition, P15
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 42
TC 16
Z9 17
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18205
EP 18227
DI 10.1007/s11042-019-7177-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200039
DA 2024-07-18
ER

PT J
AU Mazumdar, A
   Bora, PK
AF Mazumdar, Aniruddha
   Bora, Prabin Kumar
TI Estimation of lighting environment for exposing image splicing forgeries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Lighting estimation; PCA
ID DIGITAL FORGERIES; FACE RECOGNITION; ILLUMINATION; FORENSICS
AB This paper proposes a novel image forensics technique to detect splicing forgeries in digital images. The method is applicable to images containing two or more persons, where the near frontal views of the faces are available. Firstly, a low-dimensional lighting model is created from a set of front pose face images of a single individual under different directional lighting environments. For this, the set of images is decomposed using principal component analysis. This low-dimensional model, which captures the lighting variation in faces, is then used to estimate the lighting environment (LE) from a given near front pose face image. In a spliced image, the LE estimated from the spliced face will be different from that estimated from the original faces. Therefore, finding the inconsistencies among the LEs estimated from different faces could reveal the splicing forgery. The experimental results on Yale Face Database B and a set of authentic and forged real-life images show the efficacy of the proposed method.
C1 [Mazumdar, Aniruddha; Bora, Prabin Kumar] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Mazumdar, A (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
EM m.aniruddha@iitg.ac.in
CR [Anonymous], 1992, THESIS
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Epstein R., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P108, DOI 10.1109/PBMCV.1995.514675
   Fan W, 2012, EUR SIGNAL PR CONF, P1777
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gholap S., 2008, TENCON 2008 - 2008 IEEE Region 10 Conference, P1
   HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941
   Huang R, 2011, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2011.6115701
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson MK., 2005, ACM MULT SEC WORKSH, P1
   Kee E, 2010, IEEE INT WORKS INFOR
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu QZ, 2017, PATTERN RECOGN, V65, P35, DOI 10.1016/j.patcog.2016.12.010
   Mayer O, 2018, IEEE T INFORM FORENS
   Mazumdar A, 2016, P IND C COMP VIS GRA
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Riess C, 2015, LECT NOTES COMPUT SC, V9281, P3, DOI [10.1007/978-3-319-23222-5_1, 10.1007/978-3-319-23222-5]
   Saboia P., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1937, DOI 10.1109/ICIP.2011.6115850
   Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wang P, 2018, SIGNAL PROCESS-IMAGE, V64, P33, DOI 10.1016/j.image.2018.02.011
   Yuille A, 1999, INT J COMPUT VISION, V21, P99
NR 33
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19839
EP 19860
DI 10.1007/s11042-018-7147-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800041
DA 2024-07-18
ER

PT J
AU Najar, F
   Bourouis, S
   Bouguila, N
   Belghith, S
AF Najar, Fatma
   Bourouis, Sami
   Bouguila, Nizar
   Belghith, Safya
TI Unsupervised learning of finite full covariance multivariate generalized
   Gaussian mixture models for human activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multivariate generalized Gaussian; Mixture models; Covariance matrix
   estimation; Minimum message length; Human activity recognition
ID DISTRIBUTIONS; SELECTION; SCENE
AB We propose in this paper to recognize human activities through an unsupervised learning of finite multivariate generalized Gaussian mixture model. We address an important cue in finite mixture model which is the estimation of the mixture model's parameters for a full covariance matrix. We have developed a novel learning algorithm based on Fixed-point covariance matrix estimator combined with the Expectation-Maximization algorithm. Furthermore, we have proposed an appropriate minimum message length (MML) criterion to deal with model selection problem. We evaluated our proposed method on synthetic datasets and a challenging application namely : Human activity recognition from images and videos. The obtained resutls show clearly the merits of our proposed framework which has better capabilities with full covariance matrix when modeling correlated data.
C1 [Najar, Fatma; Belghith, Safya] Univ Tunis El Manar, ENIT, Lab RISC Robot Informat & Syst, Tunis 1002, Tunisia.
   [Bourouis, Sami] LR SITI Lab SignalImage & Technol Informat Tunis, Tunis, Tunisia.
   [Bourouis, Sami] Taif Univ, At Taif, Saudi Arabia.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Taif University; Concordia University - Canada
RP Najar, F (corresponding author), Univ Tunis El Manar, ENIT, Lab RISC Robot Informat & Syst, Tunis 1002, Tunisia.
EM fatma.najjar@enit.utm.tn
RI Bourouis, Sami/N-4995-2019; Najar, Fatma/ITU-2763-2023; Bouguila,
   Nizar/AAJ-2518-2020; Bouguila, Nizar/AGN-5929-2022
OI Bourouis, Sami/0000-0002-6638-7039; Belghith, Safya/0000-0001-7408-7848
CR Agusta Y, 2003, LECT NOTES ARTIF INT, V2903, P477
   [Anonymous], 2010, INT J COMPUT APPL
   [Anonymous], 2005, Statistical and Inductive Inference by Minimum Message Length
   [Anonymous], 2018, CAN CON EL COMP EN
   [Anonymous], 2009, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2009.5206800
   [Anonymous], TECH REP
   [Anonymous], 2004, P 2004WORKSHOP STAT
   Baxter RA, 2000, STAT COMPUT, V10, P5, DOI 10.1023/A:1008928315401
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI [10.1109/TPAMI.2007.1095, 10.1109/TPAMl.2007.1095]
   Bruno B., 2012, 2012 IEEE International Conference on Automation Science and Engineering (CASE 2012), P156, DOI 10.1109/CoASE.2012.6386410
   Calderara S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P141, DOI 10.1109/AVSS.2007.4425300
   Channoufi I, 2018, MULTIMED TOOLS APPL, V77, P25591, DOI 10.1007/s11042-018-5808-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Elguebaly T, 2015, LECT NOTES COMPUT SC, V9164, P159, DOI 10.1007/978-3-319-20801-5_17
   Elguebaly T, 2015, IMAGE VISION COMPUT, V34, P27, DOI 10.1016/j.imavis.2014.10.011
   Fan WT, 2014, MULTIMED TOOLS APPL, V70, P1685, DOI 10.1007/s11042-012-1191-0
   Hassen WF, 2018, IEEE CONF WIREL MOB
   Iosifidis A, 2014, IEEE IMAGE PROC, P1510, DOI 10.1109/ICIP.2014.7025302
   Kasarapu P, 2015, MACH LEARN, V100, P333, DOI 10.1007/s10994-015-5493-0
   KELKER D, 1970, SANKHYA SER A, V32, P419
   Kotz Samuel, 1975, A Modern Course on Statistical Distributions in Scientific Work, P247, DOI [10.1007/978-94-010-1842-5_20, DOI 10.1007/978-94-010-1842-5_20]
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pascal F, 2013, IEEE T SIGNAL PROCES, V61, P5960, DOI 10.1109/TSP.2013.2282909
   Peters C, 2014, ACM T ACCESS COMPUT, V5, DOI 10.1145/2579700
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Tanisik G, 2016, PATTERN RECOGN LETT, V73, P44, DOI 10.1016/j.patrec.2016.01.002
   VARANASI MK, 1989, J ACOUST SOC AM, V86, P1404, DOI 10.1121/1.398700
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
   Yao BP, 2012, LECT NOTES COMPUT SC, V7575, P173, DOI 10.1007/978-3-642-33765-9_13
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yin Zheng, 2012, 2012 19th IEEE International Conference on Image Processing (ICIP 2012), P785, DOI 10.1109/ICIP.2012.6466977
   Zhou BL, 2014, ADV NEUR IN, V27
NR 43
TC 31
Z9 31
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18669
EP 18691
DI 10.1007/s11042-018-7116-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200059
DA 2024-07-18
ER

PT J
AU Singh, H
   Kumar, A
   Balyan, LK
   Lee, HN
AF Singh, Himanshu
   Kumar, Anil
   Balyan, L. K.
   Lee, H. N.
TI Optimally sectioned and successively reconstructed histogram
   sub-equalization based gamma correction for satellite image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sub-histograms; Gamma Correction; Image quality enhancement; Adaptive
   thresholding; Peak signal to noise ratio (PSNR)
ID CONTRAST ENHANCEMENT; BRIGHTNESS
AB This paper presents an overall quality enhancement approach especially for dark or poorly illuminated images with a core objective to re-allocate the processed pixels using recursive histogram sub-division. An information preserved and image content based behavioral reconstruction inspired adaptive stopping criterion based on pixel-wise relative L(2-)norm basis (which itself is intuitively related to optimal PSNR value) is proposed in this paper, so that highly adaptive gamma value-set can be derived out of it for sufficient enhancement. Due to this adaptive behavior of the intensity distribution the gamma value-set when derived from it, is obviously highly adaptive and here individual gamma values are evaluated explicitly raised over reconstructed intensity values, unlike conventional gamma correction methods. This adaptiveness makes the entire methodology highly capable for covering a wide variety of images, due to which robustness of the algorithm also increases. The proposed methodology has been verified on various dark images. The simulation results authenticate the overall enhancement (contrast as well as entropy enhancement along with sharpness enhancement) achieved by the proposed has been found superior to other dark image enhancement techniques.
C1 [Singh, Himanshu] Indian Inst Informat Technol Design & Mfg Jabalpu, Elect & Commun Engn, Jabalpur, India.
   [Kumar, Anil; Balyan, L. K.] Indian Inst Informat Technol Design & Mfg Jabalpu, Jabalpur, India.
   [Lee, H. N.] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Information Technology Design &
   Manufacturing, Jabalpur; Gwangju Institute of Science & Technology
   (GIST)
RP Singh, H (corresponding author), Indian Inst Informat Technol Design & Mfg Jabalpu, Elect & Commun Engn, Jabalpur, India.
EM himanshu.iiitj@gmail.com; anilkdee@gmail.com; lokendra.balyan@gmail.com;
   heungno@gist.ac.kr
RI Kumar, Anil/HJB-2850-2022; KUMAR, ANIL/ACD-8340-2022; Boothapati, Anil
   Kumar/HHS-1813-2022; Kumar, Anil/Q-6680-2016; SINGH,
   HIMANSHU/AAT-6317-2020; Balyan, L K/AAV-2766-2021; Lee,
   Heung-No/CSV-9346-2022
OI Kumar, Anil/0000-0002-5817-5829; Kumar, Anil/0000-0002-3945-4646; SINGH,
   HIMANSHU/0000-0002-0410-0602; Balyan, L K/0000-0003-1695-2658; 
CR Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Huang SC, 2013, ENG APPL ARTIF INTEL, V26, P1487, DOI 10.1016/j.engappai.2012.11.011
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Lin SCF, 2016, OPTIK, V127, P407, DOI 10.1016/j.ijleo.2015.08.046
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P497, DOI 10.1109/ICDSP.2016.7868607
   Singh H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P128, DOI 10.1109/ICCSP.2016.7754552
   Singh H., 2018, P 2018 4 INT C REC A, P1
   Singh H., 2017, 22 ND INT C DIGITAL, P1, DOI [DOI 10.1109/ICDSP.2017.8096035, 10.1109/ICDSP.2017.8096035]
   Singh H, 2017, INT J RIVER BASIN MA, V15, P347, DOI 10.1080/15715124.2017.1300159
   Singh H, 2019, COMPUT ELECTR ENG, V75, P245, DOI 10.1016/j.compeleceng.2017.11.014
   Singh H, 2018, COMPUT ELECTR ENG, V70, P462, DOI 10.1016/j.compeleceng.2017.06.029
   Singh H, 2019, ADV INTELL SYST, V741, P633, DOI 10.1007/978-981-13-0761-4_61
   Singh H, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P129, DOI 10.1109/ICCSP.2018.8524564
   Singh H, 2018, INT J ELECTRON, V105, P1695, DOI 10.1080/00207217.2018.1477199
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Wong CY, 2016, J MOD OPTIC, V63, P1618, DOI 10.1080/09500340.2016.1163428
   Wong CY, 2016, J VIS COMMUN IMAGE R, V38, P802, DOI 10.1016/j.jvcir.2016.04.019
NR 26
TC 10
Z9 11
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20431
EP 20463
DI 10.1007/s11042-019-7383-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800067
DA 2024-07-18
ER

PT J
AU Chen, Y
   Hu, RM
   Xiao, J
   Xu, L
   Wang, ZY
AF Chen, Yu
   Hu, Ruimin
   Xiao, Jing
   Xu, Liang
   Wang, Zhongyuan
TI Multisource surveillance video data coding with hierarchical knowledge
   library
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance video data; Hierarchical knowledge extraction; Visual
   changes; Redundancy removal; Hybrid prediction
ID MULTIVIEW VIDEO; PREDICTION; HEVC
AB The rapidly increasing surveillance video data has challenged the existing video coding standards. Even though knowledge based video coding scheme has been proposed to remove redundancy of moving objects across multiple videos and achieved great coding efficiency improvement, it still has difficulties to cope with complicated visual changes of objects resulting from various factors. In this paper, a novel hierarchical knowledge extraction method is proposed. Common knowledge on three coarse-to-fine levels, namely category level, object level and video level, are extracted from history data to model the initial appearance, stable changes and temporal changes respectively for better object representation and redundancy removal. In addition, we apply the extracted hierarchical knowledge to surveillance video coding tasks and establish a hybrid prediction based coding framework. On the one hand, hierarchical knowledge is projected to the image plane to generate reference for I frames to achieve better prediction performance. On the other hand, we develop a transform based prediction for P/B frames to reduce the computational complexity while improve the coding efficiency. Experimental results demonstrate the effectiveness of our proposed method.
C1 [Chen, Yu; Hu, Ruimin; Xiao, Jing; Xu, Liang; Wang, Zhongyuan] Wuhan Univ, Natl Engn Res Ctr Multimedia & Software, Wuhan 430072, Hubei, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia & Software, Wuhan 430072, Hubei, Peoples R China.
EM hrm@whu.edu.cn
RI Wang, Zhongyuan/ABD-2189-2020
FU National Nature Science Foundation of China [61502348, 61671336,
   91738302]; Natural Science Foundation of Jiangsu Province [BK20180234];
   Open Research Fund of State Key Laboratory of Information Engineering in
   Sureying, Mapping and Remote Sensing, Wuhan University [17E03]; National
   Key R&D Program of China [2018YFB1201602]
FX This work was supported by the National Nature Science Foundation of
   China under Grant 61502348, 61671336, 91738302, by the Natural Science
   Foundation of Jiangsu Province under Grant BK20180234, by the Open
   Research Fund of State Key Laboratory of Information Engineering in
   Sureying, Mapping and Remote Sensing, Wuhan University under Grant
   17E03, by the National Key R&D Program of China under Grant
   2018YFB1201602.
CR Andersson P, 2018, JCI INSIGHT, V3, DOI 10.1172/jci.insight.122375
   [Anonymous], 2001, VCEGM33
   Au O., 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P84, DOI 10.1109/ICALIP.2012.6376591
   Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Chen C., 2012, P 20 ACM INT C MULT, P713, DOI DOI 10.1145/2393347.2396294
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Guo XQ, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON MATERIAL SCIENCE AND ENVIRONMENTAL ENGINEERING (MSEE 2013), P546
   Hakeem A., 2005, 13th Annual ACM International Conference on Multimedia, P608, DOI 10.1145/1101149.1101289
   Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P295, DOI [10.1109/ISM.2016.0065, 10.1109/ISM.2016.132]
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lin CY, 2018, IEEE T MULTIMEDIA, V20, P1209, DOI 10.1109/TMM.2017.2766043
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ma CY, 2017, IEEE IMAGE PROC, P270, DOI 10.1109/ICIP.2017.8296285
   Ng KT, 2010, IEEE T CIRC SYST VID, V20, P548, DOI 10.1109/TCSVT.2010.2041820
   Paul M, 2018, IEEE T BROADCAST, V64, P235, DOI 10.1109/TBC.2017.2781118
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Qi Wang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P285, DOI 10.1007/978-3-319-48890-5_28
   Shao ZF, 2018, IEEE T BIG DATA, V4, P105, DOI 10.1109/TBDATA.2017.2715815
   Shi Z, 2013, MULTIMEDIA EXPO ICME, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan TN, 1998, INT J COMPUT VISION, V27, P5, DOI 10.1023/A:1007924428535
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tsai TH, 2012, IEEE T MULTIMEDIA, V14, P669, DOI 10.1109/TMM.2011.2180705
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Wang HL, 2017, IEEE T MULTIMEDIA, V19, P908, DOI 10.1109/TMM.2016.2645398
   Weinzaepfel P, 2011, PROC CVPR IEEE, P337, DOI 10.1109/CVPR.2011.5995616
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu H, 2016, IEEE T IMAGE PROCESS, V25, P2684, DOI 10.1109/TIP.2016.2551366
   Xiao J, 2016, IEEE T MULTIMEDIA, V18, P1691, DOI 10.1109/TMM.2016.2581590
   Yang Y, 2019, IEEE T IMAGE PROCESS, V28, P302, DOI 10.1109/TIP.2018.2867740
   Yue HJ, 2013, IEEE T MULTIMEDIA, V15, P845, DOI 10.1109/TMM.2013.2239629
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P4511, DOI 10.1109/TIP.2014.2352036
NR 37
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14705
EP 14731
DI 10.1007/s11042-018-6825-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700026
DA 2024-07-18
ER

PT J
AU Li, YH
   Zhang, JW
   Chen, M
   Lei, HP
   Luo, GL
   Huang, Y
AF Li, Yuhua
   Zhang, Jianwei
   Chen, Ming
   Lei, Haopeng
   Luo, Guoliang
   Huang, Yan
TI Shape based local affine invariant texture characteristics for fabric
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fabric image retrieval; Texture representation; Local affine invariant
ID ROTATION; SCALE; CLASSIFICATION; CONTRAST; RECOGNITION; FEATURES;
   OBJECT; MODELS
AB The rapid growth of fabric images needs fast retrieval for related applications, such as fashion design. The goal of fabric image retrieval is to retrieve and rank relevant fabrics from a large scale fabric database to visually assist users' online shopping process in e-commerce. Most of existing solutions to this issue are not invariant with respect to 2D similarity or affine transformations, much less to 3D transformations of textured surface. In this paper, we propose a new search method with a shape based local affine invariant texture characteristics. By employing topographic map to represent fabric images, which is a complete, multi-scale and contrast invariant representation, the proposed method first obtains a tree of shapes from the topographic map. Then, a group of statistics is applied on these shapes to acquire a set of features that are invariant to 3D transformations. We finally represent these features combing relations between shapes, and based on the representation the similarity of pairs of fabric images can be estimated. To evaluate the performance of our algorithm, we conducted a series of experiments on a real-world fabric image dataset, and compared the proposed method with other previous ones. Experimental results demonstrate that the time of the proposed method spending in searching is less than 1 second, and meanwhile a higher PR score than others is obtained.
C1 [Li, Yuhua; Zhang, Jianwei; Chen, Ming; Huang, Yan] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450001, Henan, Peoples R China.
   [Lei, Haopeng] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
   [Luo, Guoliang] East China Jiaotong Univ, Nanchang 330022, Jiangxi, Peoples R China.
C3 Zhengzhou University of Light Industry; Jiangxi Normal University; East
   China Jiaotong University
RP Zhang, JW (corresponding author), Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450001, Henan, Peoples R China.
EM ing@zzuli.edu.cn; leihaopeng@163.com
RI Zhang, Jianwei/AAL-5062-2020
OI Li, Yuhua/0000-0002-1866-6607
FU National Natural Science Foundation of China [U1504608, 61672471,
   61762050, 61602222]; Jiangxi Natural Science Foundation [20161BAB212043]
FX This research is jointly supported by the National Natural Science
   Foundation of China (U1504608, 61672471, 61762050, 61602222), and the
   Jiangxi Natural Science Foundation (No. 20161BAB212043).
CR [Anonymous], 1982, IMAGE ANAL MATH MORP
   Bhatti N, 2018, MULTIMED TOOLS APPL, V77, P9111, DOI 10.1007/s11042-017-4808-5
   Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494
   Chandy DA, 2014, MULTIMED TOOLS APPL, V72, P2011, DOI 10.1007/s11042-013-1511-z
   Chen C, 1982, TECH REP
   Chen C.-h., 2010, Handbook of pattern recognition and computer vision, V27
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Davarzani R, 2015, SIGNAL PROCESS, V111, P274, DOI 10.1016/j.sigpro.2014.11.005
   DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921
   DAVIS LS, 1981, PATTERN RECOGN, V13, P219, DOI 10.1016/0031-3203(81)90098-4
   Dharmagunawardhana C, 2014, IMAGE VISION COMPUT, V32, P884, DOI 10.1016/j.imavis.2014.07.002
   Du JX, 2013, NEUROCOMPUTING, V116, P150, DOI 10.1016/j.neucom.2012.03.028
   Fletcher ND, 2005, COMPUT IMAGING VIS, V30, P367
   GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ji Z, 2013, NEUROCOMPUTING, V120, P15, DOI 10.1016/j.neucom.2012.02.054
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Julesz B., 1962, IEEE T INFORM THEORY, V8, P84, DOI DOI 10.1109/TIT.1962.1057698
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li YH, 2014, J ASSOC INF SCI TECH, V65, P2534, DOI 10.1002/asi.23136
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malathi T, 2017, MULTIMED TOOLS APPL, V76, P8449, DOI 10.1007/s11042-016-3414-2
   Mellor M, 2008, IEEE T PATTERN ANAL, V30, P52, DOI 10.1109/TPAMI.2007.1161
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   Nelson JDB, 2013, PATTERN RECOGN LETT, V34, P2166, DOI 10.1016/j.patrec.2013.08.003
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2018, MULTIMED TOOLS APPL, V77, P26469, DOI 10.1007/s11042-018-5871-2
   Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993
   Romeny B.ter Haar., 2003, FRONT END VISION MUL, V27
   Sandler R, 2009, INT J COMPUT VISION, V84, P308, DOI 10.1007/s11263-009-0237-x
   Shen J, 1997, P SOC PHOTO-OPT INS, V3208, P224, DOI 10.1117/12.290295
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Soille, 1999, SENSOR REV, V28, P800
   Song Y, 2018, NEUROCOMPUTING, V277, P53, DOI 10.1016/j.neucom.2017.01.113
   Sun AX, 2011, J AM SOC INF SCI TEC, V62, P2364, DOI 10.1002/asi.21659
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Xia GS, 2010, INT J COMPUT VISION, V88, P382, DOI 10.1007/s11263-009-0312-3
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
   Zhang Z, 2017, PATTERN RECOGN, V67, P263, DOI 10.1016/j.patcog.2017.02.021
   Zhu XX, 2011, 2011 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY AND HIGH DENSITY PACKAGING (ICEPT-HDP), P448
NR 48
TC 8
Z9 8
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15433
EP 15453
DI 10.1007/s11042-018-6936-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700056
DA 2024-07-18
ER

PT J
AU Liu, ZL
   Shan, GR
AF Liu, Zi-Long
   Shan, Guangrong
TI An improved reversible data hiding scheme using layered embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Layered embedding; Cyclic embedding;
   Bidirectional embedding
ID IMAGE WATERMARKING; DIFFERENCE EXPANSION; TRANSFORM
AB Reversible data hiding (RDH) embeds data into the original image content, and it can also losslessly recover the original image content after the embedded data is extracted. Some previous RDH algorithms, such as the algorithm proposed by Luo et al., generate a large amount of overhead information, which may affect data extraction and image recovery in the following phase. In this paper, we solve this problem by designing layered embedding, cyclic embedding and bidirectional embedding, as a result of which an improved scheme of Luo et al.'s algorithm is proposed. The proposed scheme can reduce the amount of overhead information by dozens of times, which is beneficial for increasing the embedding rate and PSNR value. Experimental results show that the performance of the improved scheme outperforms the algorithm proposed by Luo et al. and other previous RDH algorithms.
C1 [Liu, Zi-Long; Shan, Guangrong] Northwest Minzu Univ, Sch Math & Comp Sci, Lanzhou 730030, Gansu, Peoples R China.
C3 Northwest Minzu University
RP Liu, ZL (corresponding author), Northwest Minzu Univ, Sch Math & Comp Sci, Lanzhou 730030, Gansu, Peoples R China.
EM 163lzl163@163.com
FU basic scientific research project of the central university of Northwest
   Minzu University [31920150085]
FX This work was supported by the basic scientific research project of the
   central university of Northwest Minzu University (Project ID:
   31920150085).
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi NA, 2014, P 3 INT C ADV INF TE, P73
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2014, MISCELANEOUS GRAY LE
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen XY, 2015, MULTIMED TOOLS APPL, V74, P5747, DOI 10.1007/s11042-014-1881-x
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hiary S, 2017, MULTIMED TOOLS APPL, V76, P2131, DOI 10.1007/s11042-015-3161-9
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Liu XY, 2019, MULTIMED TOOLS APPL, V78, P6355, DOI 10.1007/s11042-018-6361-2
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wu H.-Z., 2016, PROC ACM WORKSHOP IN, P187
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
NR 38
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16311
EP 16328
DI 10.1007/s11042-018-6958-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500026
DA 2024-07-18
ER

PT J
AU Min, WD
   Zou, S
   Li, J
AF Min, Weidong
   Zou, Song
   Li, Jing
TI Human fall detection using normalized shape aspect ratio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human fall detection; Falling toward different directions; Indoor and
   outdoor environments; Normalized shape aspect ratio
ID MIXTURE MODEL; SURVEILLANCE; TRACKING; SYSTEM
AB In video surveillance, automatic human fall detection is important to protect vulnerable groups such as the elderly. When the camera layout varies, the shape aspect ratio (SAR) of a human body may change substantially. In order to rectify these changes, in this paper, we propose an automatic human fall detection method using the normalized shape aspect ratio (NSAR). A calibration process and bicubic interpolation are implemented to generate the NSAR table for each camera. Compared with some representative fall detection methods using the SAR, the proposed method integrates the NSAR with the moving speed and direction information to robustly detect human fall, as well as being able to detect falls toward eight different directions for multiple humans. Moreover, while most of the existing fall detection methods were designed only for indoor environment, experimental results demonstrate that this newly proposed method can effectively detect human fall in both indoor and outdoor environments.
C1 [Min, Weidong; Zou, Song; Li, Jing] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Min, Weidong] Nanchang Univ, Sch Software Engn, Nanchang 330029, Jiangxi, Peoples R China.
   [Li, Jing] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
C3 Nanchang University; Nanchang University; Chinese Academy of Sciences;
   Institute of Automation, CAS
RP Li, J (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.; Li, J (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
EM jingli@ncu.edu.cn
RI Min, Weidong/D-4585-2017
OI Zou, Song/0000-0002-5744-8792
FU National Natural Science Foundation of China [61463032, 61762061,
   61703198]; Natural Science Foundation of Jiangxi Province, China
   [20161ACB20004, 2018ACB21014]; Open Fund of State Key Laboratory
   ofManagement and Control for Complex Systems, Institute of Automation,
   Chinese Academy of Sciences [20180109]
FX This research was supported by National Natural Science Foundation of
   China under Grant 61463032, 61762061, 61703198, the Natural Science
   Foundation of Jiangxi Province, China under Grant 20161ACB20004 and
   2018ACB21014, and the Open Fund of State Key Laboratory ofManagement and
   Control for Complex Systems, Institute of Automation, Chinese Academy of
   Sciences, under Grant 20180109.
CR Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   Alwan Majd., 2006, 2006 2 INT C INFORM, V1, P1003, DOI DOI 10.1109/ICTTA.2006.1684511
   [Anonymous], 2018, IEEE T MULTIMEDIA
   Augustyniak P, 2014, SENSORS-BASEL, V14, P7831, DOI 10.3390/s140507831
   Bhattacharyya A, 1942, B CALCUTTA MATH SOC, V35, P99
   Chen ML, 2013, CSC CHINA PERSPECT, P1
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Cola G, 2015, IEEE SENS J, V15, P6640, DOI 10.1109/JSEN.2015.2464774
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Feng PM, 2014, INT CONF DIGIT SIG, P12, DOI 10.1109/ICDSP.2014.6900806
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Hazelhoff L, 2008, LECT NOTES COMPUT SC, V5259, P298, DOI 10.1007/978-3-540-88458-3_27
   Igual R, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-66
   Tra K, 2013, PROC INT CONF ADV, P95, DOI 10.1109/ATC.2013.6698085
   Lai CF, 2014, IEEE J BIOMED HEALTH, V18, P457, DOI 10.1109/JBHI.2014.2298467
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Li XR, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016680799
   Liu H, 2012, AASRI PROC, V1, P353, DOI 10.1016/j.aasri.2012.06.054
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Medrano C, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010117
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Rhuma Adel, 2013, Lecture Notes on Software Engineering, V1, P350, DOI 10.7763/LNSE.2013.V1.75
   Rimminen H, 2010, IEEE T INF TECHNOL B, V14, P1475, DOI 10.1109/TITB.2010.2051956
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Rougier C, 2013, IMAGE VISION COMPUT, V31, P246, DOI 10.1016/j.imavis.2012.11.003
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Tabar A.M., 2006, Proceedings of the 4th ACM InternationalWorkshop on Video Surveillance and Sensor Networks, P145, DOI [10.1145/1178782.1178804, DOI 10.1145/1178782.1178804]
   Tao J., 2005, Proc. Fifth International Conference on Information, P1590, DOI DOI 10.1109/ICICS.2005.1689327
   Xiao H-E, 2013, GAUSSIAN MIXTURE MOD, P234
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Yu M, 2012, IET COMPUT VIS, V6, P90, DOI 10.1049/iet-cvi.2011.0046
   Yu M., 2017, P 19 ACM INT C MULT, P416
   Zhu HY, 2017, IEEE I CONF COMP VIS, P5814, DOI 10.1109/ICCV.2017.619
   Zhuang XD, 2009, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.2009.4959522
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 38
TC 10
Z9 11
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14331
EP 14353
DI 10.1007/s11042-018-6794-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700010
DA 2024-07-18
ER

PT J
AU Wang, WC
   Ji, T
AF Wang, Wencheng
   Ji, Tao
TI Adaptive analysis method for particles image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adhesive particles; Mathematic morphology; Overlapping particles;
   Watershed method
ID AUTOMATIC SEGMENTATION; OBJECTS; CELLS
AB To address the adhesion problem that usually exists in particle image analysis, a kind of adaptive method is proposed in this paper. First, gray transformation and median filtering are conducted on a particle image. Then, the obtained target image is threshold segmented. In addition, distance transformation and watershed segmentation are performed on the binary image that was processed based on the mathematical morphology, and the watershed ridge line in the image can be obtained. The boundary in the adhesion region is extracted by performing an intersection calculation between the original image and the segmented target area. Finally, the parameters of single particles, such as the area, perimeter and particle diameter, are calculated, and particle image analysis is realized. Through experiments on images collected in the laboratory, it is shown that this method is simple and convenient and can be popularized in the industry.
C1 [Wang, Wencheng; Ji, Tao] Weifang Univ, Coll Informat & Control Engn, Weifang 261061, Peoples R China.
C3 Weifang University
RP Wang, WC (corresponding author), Weifang Univ, Coll Informat & Control Engn, Weifang 261061, Peoples R China.
EM wwcwfu@126.com
RI Wang, Wencheng/A-6146-2018
OI Wang, Wencheng/0000-0002-0888-9225
FU National Nature Science Foundation of China [61403283, 61876099];
   Shandong Provincial Natural Science Foundation, China [ZR2013FQ036];
   Technology Development Plan of Weifang City [201301015]
FX This work is supported by National Nature Science Foundation of China
   (Nos. 61403283, 61876099), Shandong Provincial Natural Science
   Foundation, China (No. ZR2013FQ036) and Technology Development Plan of
   Weifang City (No. 201301015). We are grateful to Dr. Zhenxue Chen for
   helping us to process the technical editing of the manuscript.
CR Cloppet F, 2010, PATTERN RECOGN LETT, V31, P755, DOI 10.1016/j.patrec.2010.01.022
   Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0
   Ding Y, 2012, ANNU REV ECOL EVOL S, V43, P345, DOI 10.1146/annurev-ecolsys-110411-160513
   Farhan M, 2013, PATTERN RECOGN, V46, P741, DOI 10.1016/j.patcog.2012.09.008
   Karvelis P, 2010, PATTERN RECOGN LETT, V31, P2474, DOI 10.1016/j.patrec.2010.08.002
   Kharma N, 2007, IET IMAGE PROCESS, V1, P39, DOI 10.1049/iet-ipr:20045262
   Lin C, 2017, MULTIMED TOOLS APPL, V76, P9565, DOI 10.1007/s11042-016-3563-3
   Long X, 2010, COMPUT BIOL MED, V40, P168, DOI 10.1016/j.compbiomed.2009.11.013
   Lu Y, 2008, MICROCOMPUTER INFORM, V23, P311
   Mukherjee DP, 2009, PATTERN RECOGN LETT, V30, P615, DOI 10.1016/j.patrec.2008.12.015
   Na S, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P563, DOI 10.1109/AICI.2009.211
   Nazlibilek S, 2014, MEASUREMENT, V55, P58, DOI 10.1016/j.measurement.2014.04.008
   Ren J, 2017, METABOLISM ROLES SPH, P1
   Salinas RA, 2005, IEE P-VIS IMAGE SIGN, V152, P1, DOI 10.1049/ip-vis:20050810
   Schmitt O, 2009, COMPUT VIS IMAGE UND, V113, P188, DOI 10.1016/j.cviu.2008.08.011
   Wang WC, 2018, IEEE SYST MAN CYBERN, V4, P24, DOI 10.1109/MSMC.2018.2794559
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Yang HG, 2014, PATTERN RECOGN, V47, P2266, DOI 10.1016/j.patcog.2013.11.004
   Yang Z, 2018, 2018 IEEE INT C CLOU
   Yang ZR, 2019, CANCER BIOL THER, V20, P212, DOI 10.1080/15384047.2018.1523847
   [赵君君 Zhao Junjun], 2017, [传感器与微系统, Transducer and Microsystem Technology], V36, P49
   Zhao X, 2017, J HENAN I SCI TECHNO, V45, P65
   Zhou Ying-li, 2003, Journal of Data Acquisition & Processing, V18, P460
NR 23
TC 4
Z9 4
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15317
EP 15333
DI 10.1007/s11042-018-6957-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700051
DA 2024-07-18
ER

PT J
AU Youbi, Z
   Boubchir, L
   Boukrouche, A
AF Youbi, Zineb
   Boubchir, Larbi
   Boukrouche, Abdelhani
TI Human ear recognition based on local multi-scale LBP features with
   city-block distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Human ear recognition; Feature extraction; MLBP; CTB
   distance
ID LOG-GABOR FILTER; BIOMETRICS; FACE; REPRESENTATION; CLASSIFICATION;
   VERIFICATION; SCALE
AB The use of the ear as a biometric modality has emerged in recent years. It makes it possible to differentiate people thanks to its stability over time and to the richness of its characteristics such as texture, color and size. This paper proposes a novel approach to ear recognition based on a variant of the Local Binary Pattern descriptor called Multi-scale Local Binary Pattern (MLBP). MLBP is calculated locally, by dividing the image into several equal blocks, to extract the ear features which will be used in the matching process to make a decision by detecting the similarities between the feature vectors using City-Block distance (CTB). The proposed method is evaluated on three reference ear databases: IIT Delhi I, IIT Delhi II and USTB-1. The analysis of the results obtained have clearly shown the robustness and the stability of the proposed ear recognition method which is highly competitive, achieving an attractive recognition performances in terms of identification rate at rank-1 up to: 98.40% for IIT Delhi I, 98.64% for IIT Delhi II, and 98.33% for USTB-1.
C1 [Youbi, Zineb; Boukrouche, Abdelhani] Univ 8 Mai 1945 Guelma, PI MIS Lab, Guelma, Algeria.
   [Boubchir, Larbi] Univ Paris 08, LIASD Res Lab, 2 Rue Liberte, F-93526 St Denis, France.
C3 Universite 8 Mai 1945 de Guelma; Universite Paris-VIII
RP Youbi, Z (corresponding author), Univ 8 Mai 1945 Guelma, PI MIS Lab, Guelma, Algeria.
EM y.zineb88@gmail.com; larbi.boubchir@ai.univ-paris8.fr;
   hani.boukrouche@pimis.net
RI Boubchir, Larbi/I-9623-2019
OI Boubchir, Larbi/0000-0002-5668-6801; youbi, zineb/0000-0002-3850-3434
CR Abaza A, 2013, SPIE DEFENSE SECURIT
   Aberni Y, 2018, J CIRCUITS SYSTEMS C
   Al-Tarhouni W, 2017, NEURAL COMPUTING APP
   Ammour B, 2018, IET BIOMETRICS, V7, P482, DOI 10.1049/iet-bmt.2017.0251
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   [Anonymous], 2008, THESIS
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   [Anonymous], 2008, HDB BIOMETRICS
   Arbab-Zavar B, 2008, INT C PATT RECOG, P2735
   ATAMAN E, 1980, IEEE T ACOUST SPEECH, V28, P415, DOI 10.1109/TASSP.1980.1163426
   Azmi AN, 2017, MULTIMED TOOLS APPL, V76, P15341, DOI 10.1007/s11042-016-3831-2
   Basit A, 2014, INT J COMPUT MATH, V91, P616, DOI 10.1080/00207160.2013.800194
   Benzaoui A, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.4.043109
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Bera A, 2017, MULTIMED TOOLS APPL, V76, P21451, DOI 10.1007/s11042-016-4075-x
   Bertillon A, 1890, LA PHOTOGRAPHIE JUDI
   Bhanu B, 2008, ADV PATTERN RECOGNIT, P1
   Boutellaa E, 2016, MULTIMED TOOLS APPL, V75, P5329, DOI 10.1007/s11042-015-2848-2
   Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202
   Chan TS, 2012, PATTERN RECOGN LETT, V33, P1870, DOI 10.1016/j.patrec.2011.11.013
   Chand, 2016, 2016 IEEE REG 10 C T
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Choras M, 2008, OPTO-ELECTRON REV, V16, P85, DOI 10.2478/s11772-007-0033-5
   Chowdhury DP, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0855-8
   Ghoualmi L, 2016, EXPERT SYST APPL, V57, P49, DOI 10.1016/j.eswa.2016.03.004
   Guermoui M, 2016, J ELECTRON IMAGING, V25
   Guermoui M, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.9.093105
   Hurley D., 2007, HDB BIOMETRICS, P131
   Hurley D. J., 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P25
   Hurley DJ, 2002, IMAGE VISION COMPUT, V20, P311, DOI 10.1016/S0262-8856(02)00003-3
   Iannarelli A., 1989, FORENSIC IDENTIFICAT
   Jacob L, 2014, ADV INTELL SYST, V264, P1, DOI 10.1007/978-3-319-04960-1_1
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Kumar A, 2013, PATTERN RECOGN, V46, P73, DOI 10.1016/j.patcog.2012.06.020
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Lishani A, 2018, MULTIMED TOOLS APPL, P1
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Mamta, 2013, EXPERT SYST APPL, V40, P6478, DOI 10.1016/j.eswa.2013.05.020
   MELTER RA, 1987, PATTERN RECOGN LETT, V6, P235, DOI 10.1016/0167-8655(87)90082-1
   Mu Z., 2009, USTB ear image database
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omara I, 2018, PROCEEDINGS OF 2018 8TH INTERNATIONAL CONFERENCE ON BIOSCIENCE, BIOCHEMISTRY AND BIOINFORMATICS (ICBBB 2018), P139, DOI 10.1145/3180382.3180409
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Raghavendra R, 2018, PATTERN RECOGN, V83, P416, DOI 10.1016/j.patcog.2018.06.008
   Raman R, 2018, MACH VISION APPL, P1
   Sarangi PP, 2018, MULTIMEDIA TOOLS APP
   Semwal VB, 2018, IEEE T AUTOM SCI ENG, V15, P104, DOI 10.1109/TASE.2016.2594191
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2016, IEEE SENS J, V16, P5805, DOI 10.1109/JSEN.2016.2570281
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Semwal VB, 2015, IEEE SENS J, V15, P2021, DOI 10.1109/JSEN.2015.2389525
   Semwal Vijay Bhaskar, 2018, MACH INTELL, P135
   Teoh ABJ, 2018, MULTIMED TOOLS APPL, V77, P27733, DOI 10.1007/s11042-018-5956-y
   Topi M, 2000, ROBUST TEXTURE CLASS, V3
   Victor B, 2002, INT C PATT RECOG, P429, DOI 10.1109/ICPR.2002.1044746
   Youbi Z, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P685, DOI 10.1109/TSP.2016.7760971
NR 59
TC 10
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14425
EP 14441
DI 10.1007/s11042-018-6768-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700014
DA 2024-07-18
ER

PT J
AU Chauhan, DS
   Singh, AK
   Adarsh, A
   Kumar, B
   Saini, JP
AF Chauhan, D. S.
   Singh, A. K.
   Adarsh, A.
   Kumar, B.
   Saini, J. P.
TI Combining Mexican hat wavelet and spread spectrum for adaptive
   watermarking and its statistical detection using medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DWT; Spread-spectrum; Probability distribution function; Cauchy
   statistical model; Medical image; LRT; WDR; PSNR; NC
ID SECURE MULTIPLE WATERMARKING; ROBUST; REGION
AB This paper present a secure medical image watermarking technique applying spread-spectrum concept in wavelet transform domain is proposed. In the first step, discrete wavelet transform(DWT) decomposes the cover medical image into four frequency sub-bands using Mexican hat as mother wavelet and then corresponding to each pixel of the binary watermark a pair of Pseudo-Noise (PN) is embedded into a horizontal (HL) and a vertical (LH) sub-band. In order to maintain the imperceptibility of the watermarked image, strength of the generated PN sequence pair is adjusted according to specified document to watermark ratio (DWR). For the extraction the watermark, statistical profile of DWT coefficients of watermarked image is determined and the obtained probability distribution function (pdf) is utilized for designing the watermark detection procedure. Proposed detector considers the best fitted Cauchy statistical model of heavy-tailed family, which accurately models the non-Gaussian DWT coefficients of an image. The robustness of the method is examined for various kinds of attacks with varying watermark to document ratio. Further, experimental results show that the proposed technique offer more robustness than other state-of-the-art method.
C1 [Chauhan, D. S.] Feroze Gandhi Inst Engn & Technol, Dept Elect & Commun Engn, Raebareli, UP, India.
   [Singh, A. K.] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
   [Adarsh, A.; Kumar, B.] Motilal Nehru Natl Inst Technol, Dept Elect & Commun Engn, Allahabad, UP, India.
   [Saini, J. P.] Bundelkhand Inst Engn & Technol, Dept Elect Engn, Jhansi, UP, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); Motilal Nehru National Institute of Technology;
   Bundelkhand Institute of Engineering & Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
EM digvijay.02@gmail.com; amit_245singh@yahoo.com;
   adarsh.abhinav@gmail.com; singhbasant@yahoo.com; jps_uptu@rediffmail.com
RI Singh, Ashwani/GQP-2566-2022; SINGH, ASHUTOSH KUMAR/KHY-2988-2024;
   Adarsh, Abhinav/AHE-2688-2022
OI Adarsh, Abhinav/0000-0003-0924-109X
CR Agung B. W. R., 2012, 2012 IEEE International Conference on Communication, Networks and Satellite (ComNetSat 2012), P167, DOI 10.1109/ComNetSat.2012.6380799
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Al-Qershi O. M., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P151, DOI 10.1109/ICITIS.2010.5688743
   [Anonymous], 2013, Chi-Squared Goodness of Fit Tests with Applications
   [Anonymous], 2006, REMOTE CARDIOLOGY CO
   Badshah G, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.1.017001
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Eggers JJ, 2001, SIGNAL PROCESS, V81, P239, DOI 10.1016/S0165-1684(00)00205-X
   Eswaraiah R, 2014, INT CONF COMM SYST, P896, DOI 10.1109/CSNT.2014.184
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Fawaz WA., 2016, RES J INF TECHNOL, V8, P88, DOI DOI 10.3923/RJIT.2016.88.97
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki Aggeliki L, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6328
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   Kannammal A, 2014, INT J IMAG SYST TECH, V24, P111, DOI 10.1002/ima.22086
   Kaur L, 2005, MED BIOL ENG COMPUT, V43, P33, DOI 10.1007/BF02345120
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   Kumar B, 2009, 2009 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRONIC AND PHOTONIC DEVICES AND SYSTEMS (ELECTRO-2009), P162
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Kwitt Roland, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2072
   Kwitt R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P33, DOI 10.1145/1411328.1411337
   Lam EY, 2004, IEE P-VIS IMAGE SIGN, V151, P203, DOI 10.1049/ip-vis:20040398
   Masek J, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P586, DOI 10.1109/TSP.2013.6614002
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Priya S., 2014, J APPL SCI, V14, P1638, DOI [10.3923/jas.2014.1638.1642, DOI 10.3923/jas.2014.1638.1642]
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, P NATL A SCI INDIA A, V85, P295, DOI 10.1007/s40010-014-0197-6
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
NR 38
TC 15
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12647
EP 12661
DI 10.1007/s11042-017-5348-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900002
DA 2024-07-18
ER

PT J
AU Kaur, R
   Juneja, M
   Mandal, AK
AF Kaur, Ravinder
   Juneja, Mamta
   Mandal, A. K.
TI A hybrid edge-based technique for segmentation of renal lesions in CT
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Renal lesion; Segmentation; Spatial FCM; IFCM; GAC; DRLSE; CT images
ID SPATIAL CONSTRAINTS; CLASSIFICATION; CANCER; TUMOR
AB The entire community of medical experts uses various imaging techniques as the precursor for disease diagnosis with the assistance of computer-aided diagnosis systems. In many cases, these imaging techniques savored the status of pivotal proof of occurrence for tissue abnormalities. One of the most important steps in the analysis of tissue using medical images is the correct approximation of position, size, and shape of the lesion which plays a significant role to decrease false positives count for effective diagnosis of renal lesions. This article suggests a hybrid segmentation technique based on two methods which include spatial intuitionistic fuzzy c-means clustering (SIFCM) that integrates spatial image details and, distance regularized level-sets method for extraction of renal lesions correctly and proficiently in computed tomography (CT) images. The proposed technique works by taking an approximation of region of interest (ROI) given by Spatial IFCM clustering (SIFCM) for correct demarcation of lesions. Further, the performance of the suggested technique is tested on the considered image dataset and compared with the other state-of-the-art segmentation techniques such as thresholding, region growing, level set, fuzzy c-means clustering (FCM), active contour without edges (ACWE), geodesic active contours (GAC), spatial FCM and intuitionistic FCM. To confirm the segmentation results, the ground truth marked by the expert radiologists was considered as a gold standard for comparison. The experimental outcomes reveal that the suggested technique yields the results close to the manual delineations of experts as compared to the other considered segmentation techniques and is able to segment lesion correctly and precisely. The suggested technique attains the better lesion segmentation, even for images with low-contrast and in the presence of noise components. Furthermore, it possesses the capability to control the parameters adaptively from SIFCM clustering method.
C1 [Kaur, Ravinder; Juneja, Mamta] Panjab Univ, UIET, Dept Comp Sci & Engn, Chandigarh, India.
   [Mandal, A. K.] PGIMER, Dept Urol, Chandigarh, India.
C3 Panjab University; Post Graduate Institute of Medical Education &
   Research (PGIMER), Chandigarh
RP Kaur, R (corresponding author), Panjab Univ, UIET, Dept Comp Sci & Engn, Chandigarh, India.
EM ravinder.kaur7@yahoo.com; mamtajuneja@pu.ac.in; drarupkumar@gmail.com
RI Kaur, Ravinder/AEN-2893-2022
OI Kaur, Ravinder/0000-0002-8535-6617; Juneja, Mamta/0000-0002-2611-9005
FU University Grant Commission (UGC), New Delhi, India
FX This research work has been funded by University Grant Commission (UGC),
   New Delhi, India. Additionally, the authors would like to thank Prof.
   Anupam Lal, Department of Radio-diagnosis, PGIMER, Chandigarh for his
   support in carrying out this research.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], SURFACES
   [Anonymous], EUR ASS UROL
   [Anonymous], INDIAN J SCI TECHNOL
   Archip N, 2007, ACAD RADIOL, V14, P1242, DOI 10.1016/j.acra.2007.05.025
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bluth EI, 2000, RADIOLOGY, V215, P791, DOI 10.1148/radiology.215.3.r00jn22791
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Campbell SC, 2009, J UROLOGY, V182, P1271, DOI 10.1016/j.juro.2009.07.004
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Choyke P L, 2000, Radiology, V215 Suppl, P721
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Graves D, 2010, FUZZY SET SYST, V161, P522, DOI 10.1016/j.fss.2009.10.021
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Kaur R, 2018, MULTIMED TOOLS APPL, V77, P22735, DOI 10.1007/s11042-017-5500-5
   Kaur R, 2018, ADV INTELL SYST, V518, P47, DOI 10.1007/978-981-10-3373-5_4
   Kim DY, 2004, ACTA RADIOL, V45, P791, DOI 10.1080/02841850410001312
   Lee HS, 2017, I S BIOMED IMAGING, P583, DOI 10.1109/ISBI.2017.7950588
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Linguraru MG, 2011, MED PHYS, V38, P5738, DOI 10.1118/1.3633898
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Park, 2015, International Journal of Computer Graphics Animation, V5, P1, DOI [10.5121/ijcga.2015.5101, DOI 10.5121/IJCGA.2015.5101]
   Siegel R L., 2016, CA Cancer J. Clin., V66
   Smith RA, 2017, CA-CANCER J CLIN, V67, P100, DOI 10.3322/caac.21392
   Summers RM, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P293, DOI 10.1109/ICIP.2001.958485
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Tolias YA, 1998, IEEE SIGNAL PROC LET, V5, P245, DOI 10.1109/97.720555
   Turner RM, 2017, UROL CLIN N AM, V44, P147, DOI 10.1016/j.ucl.2016.12.001
NR 30
TC 14
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12917
EP 12937
DI 10.1007/s11042-018-6421-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900012
DA 2024-07-18
ER

PT J
AU Ke, Y
   Zhang, MQ
   Liu, J
   Su, TT
   Yang, XY
AF Ke, Yan
   Zhang, Min-qing
   Liu, Jia
   Su, Ting-ting
   Yang, Xiao-yuan
TI Generative steganography with Kerckhoffs' principle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Generative steganography; Generative adversarial
   networks (GANs); Kerckhoffs' principle
AB The distortion in steganography that usually comes from the modification or recoding of the cover image during the embedding process. And it is the embedding distortion that leaves the steganalyzer with possible discrimination. Therefore, we propose generative steganography with Kerckhoffs' principle (GSK) in this paper. In GSK, the secret messages are generated by a cover image using a generator rather than embedded into the cover, which results in no modifications to the cover. To ensure security, the generators are trained to meet Kerckhoffs' principle based on generative adversarial networks (GANs). Everything about the GSK system is public knowledge for the receivers, except the extraction key. The secret messages can be outputted by the generator if and only if the extraction key and the cover image are both inputted. In the generator training procedures, there are two GANs (Message-GAN and Cover-GAN) that are designed to work jointly, making the generated results under the control of the extraction key and the cover image. We provide experimental results for the training process. We present an example of the working process by adopting a generator trained on the dataset MNIST, which demonstrates that GSK can use a cover image without any modification to generate messages. Furthermore, only meaningless results would be obtained without the extraction key or the cover image.
C1 [Ke, Yan; Zhang, Min-qing; Liu, Jia; Su, Ting-ting; Yang, Xiao-yuan] Engn Univ PAP, Key Lab Network & Informat Secur Chinese People A, Xian 710086, Shaanxi, Peoples R China.
RP Ke, Y (corresponding author), Engn Univ PAP, Key Lab Network & Informat Secur Chinese People A, Xian 710086, Shaanxi, Peoples R China.
EM 15114873390@163.com
RI Ke, Yan/HTS-4679-2023; Yan, Keyu/IXX-0343-2023
FU National Key R&D Program of China [2017YFB0802000]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2017YFB0802000.
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], ARXIV161009585V3
   [Anonymous], IST199910987 CERTIMA
   [Anonymous], ARXIV161006918V1
   [Anonymous], 2018, J INF HIDING MULTIME
   [Anonymous], 2018, Journal of Information Hiding and Multimedia Signal Processing
   [Anonymous], 2017, J INFORM HIDING MULT
   [Anonymous], 2004, Journal on Telecommunications & High Technology Law
   [Anonymous], 1883, Journal des Sciences Militaires
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Cayre F, 2005, IEEE T SIGNAL PROCES, V53, P3976, DOI 10.1109/TSP.2005.855418
   Cayre F, 2008, IEEE T INF FOREN SEC, V3, P1, DOI 10.1109/TIFS.2007.916006
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Radford A., 2015, ARXIV
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
NR 19
TC 11
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13805
EP 13818
DI 10.1007/s11042-018-6640-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900054
DA 2024-07-18
ER

PT J
AU Kim, K
   Ro, WW
AF Kim, Kyungah
   Ro, Won Woo
TI Contents-aware partitioning algorithm for parallel high efficiency video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Tiles; Clustering; Frame partitioning
ID HEVC; FRAMEWORK
AB We introduce a new parallelization method for high-efficiency video coding (HEVC), which resolves the shortcomings of the existing tile-based parallel processing method. The parallel HEVC performs encoding by dividing a frame into numerous parallel units. This decreases the compression efficiency compared with sequential HEVC, because it artificially breaks the data correlation within a frame, which is called the parallelization overhead. The traditional parallel techniques such as Tiles and wavefront parallel processing (WPP) inherently introduce a high parallelization overhead because they simply divide a frame statically without considering the contents of the frame. The proposed new parallel encoding scheme resolves such problems by partitioning a frame based on the meaningful contents. In order to analyze the correlations within a frame and define the contents, the features within a frame are first extracted and clustered. In the feature clustering algorithm, two factors are considered to balance the workload between parallel units: (1) the number of features in each cluster and (2) the number of coding tree units (CTU) occupied by each cluster. The frame is partitioned based on the result of clustering, and the partitions are encoded in parallel. The proposed scheme achieves a bit-saving of up to 7.21%, with an average of 3.71%, along with an average time-saving of 20.50% compared to the Tiles technique.
C1 [Kim, Kyungah; Ro, Won Woo] Yonsei Univ, Dept Elect & Elect Engn, Seoul, South Korea.
C3 Yonsei University
RP Ro, WW (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, Seoul, South Korea.
EM kyungah.kim@yonsei.ac.kr; wro@yonsei.ac.kr
FU Digital Media & Communication RD Team; Samsung Electronics Co., Ltd.;
   National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2018R1A2A2A05018941]
FX This work was funded by grants from the Digital Media & Communication
   R&D Team, Samsung Electronics Co., Ltd. and by the National Research
   Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP)(No. NRF-2018R1A2A2A05018941). Won Woo Ro is the corresponding
   author.
CR Ahn Y.-J., 2013, VISUAL COMMUN-US, P1
   [Anonymous], ARXIV170807077
   [Anonymous], 2008, VCEG-AI11
   Blumenberg C, 2013, PICT COD SYMP, P185, DOI 10.1109/PCS.2013.6737714
   Bossen F, 2013, HCTVCL1100 ISOICE IT
   Chan CH, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013006
   Chen BY, 2017, IEEE IPCCC
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Fuldseth A., 2011, JCTVCE408
   Georgakarakos G, 2015, 23RD EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED, AND NETWORK-BASED PROCESSING (PDP 2015), P137, DOI 10.1109/PDP.2015.61
   Henry F., 2011, JCTVCE196
   JIN X, 2016, TMM, V18, P2331, DOI DOI 10.1109/TMM.2016.2600439
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   McCann K., 2014, JCTVCQ1002 ISOIEC IT
   Migallón H, 2017, J SUPERCOMPUT, V73, P543, DOI 10.1007/s11227-016-1911-8
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   Nol PP, 2016, P 16 INT C COMP MATH, P989
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI 10.1098/rspl.1895.0041
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang XYJ, 2011, JCTVCF270
   Xie X, 2016, 29 INT C MICR MECH S
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, 30 INT C MICR MECH S
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhou M, 2012, APPL DIGITAL IMAGE P, V8499
NR 34
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11427
EP 11442
DI 10.1007/s11042-018-6619-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900015
DA 2024-07-18
ER

PT J
AU López-Monroy, AP
   Montes-y-Gómez, M
   Escalante, HJ
   González, FA
AF Pastor Lopez-Monroy, A.
   Montes-y-Gomez, Manuel
   Jair Escalante, Hugo
   Gonzalez, Fabio A.
TI Novel Distributional Visual-Feature Representations for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge-engineering; Pattern-recognition;
   Distributional-term-representations; Bag-of-Visual-Words
ID OBJECT; TEXTURE
AB The Bag-of-Visual-Words (BoVW) representation is a well known strategy to approach many computer vision problems. The idea behind BoVW is similar to the Bag-of-Words (BoW) used in text mining tasks: to build word histograms to represent documents. Regarding computer vision, most of the research has been devoted to obtain better visual words, rather than in improving the final representation. This is somewhat surprising, as there are many alternative ways of improving the BoW representation within the text mining community that can be applied in computer vision as well. This paper aims at evaluating the usefulness of Distributional Term Representations (DTRs) for image classification. DTRs represent instances by exploiting statistics of feature occurrences and co-occurrences along the dataset. We focus in the suitability and effectiveness of using well-known DTRs in different image collections. Furthermore, we devise two novel distributional strategies that learn appropriated groups of images to compute better suited distributional features. We report experimental results in several image datasets showing the effectiveness of the proposed DTRs over BoVW and other methods in the literature including deep learning based strategies. In particular we show the effectiveness of the proposed representations on image collections from narrow domains, where target categories are subclasses of a more general class (e.g., subclasses of birds, aircrafts, or dogs).
C1 [Pastor Lopez-Monroy, A.] Math Res Ctr CIMAT, Dept Comp Sci, Jalisco S-N, Guanajuato 36023, Gto, Mexico.
   [Pastor Lopez-Monroy, A.] Univ Houston, Dept Comp Sci, 4800 Calhoun Rd, Houston, TX 77004 USA.
   [Pastor Lopez-Monroy, A.; Montes-y-Gomez, Manuel; Jair Escalante, Hugo] INAOE, Comp Sci Dept, Luis Enrique Erro 1, Puebla 72840, Mexico.
   [Gonzalez, Fabio A.] Univ Nacl Colombia, Comp Syst & Ind Engn Dept, Cra 30 45 03 Ciudad Univ, Bogota, Colombia.
C3 University of Houston System; University of Houston; Instituto Nacional
   de Astrofisica, Optica y Electronica; Universidad Nacional de Colombia
RP López-Monroy, AP (corresponding author), Math Res Ctr CIMAT, Dept Comp Sci, Jalisco S-N, Guanajuato 36023, Gto, Mexico.; López-Monroy, AP (corresponding author), Univ Houston, Dept Comp Sci, 4800 Calhoun Rd, Houston, TX 77004 USA.; López-Monroy, AP (corresponding author), INAOE, Comp Sci Dept, Luis Enrique Erro 1, Puebla 72840, Mexico.
EM pastor.lopez@cimat.mx
RI Gonzalez, Fabio A/B-9502-2008; Escalante, Hugo Jair/AEP-0896-2022
OI Escalante, Hugo Jair/0000-0003-4603-3513; LOPEZ-MONROY, ADRIAN
   PASTOR/0000-0003-1018-4221
FU CONACyT [241306, 243957]; Redes Tematicas CONACyT en Tecnologias del
   Lenguaje (RedTTL) e Inteligencia Computacional Aplicada (RedICA)
FX This work was supported by CONACyT under grant 241306 and the
   scholarship 243957. H.J. Escalante was supported by Redes Tematicas
   CONACyT en Tecnologias del Lenguaje (RedTTL) e Inteligencia
   Computacional Aplicada (RedICA).
CR [Anonymous], SIGKDD EXPLORATIONS
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], 2004, P BRIT MACHINE VISIO
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2007 CLEF WORKSH
   [Anonymous], 2013, TECH REP
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], 2012, Long Papers
   [Anonymous], 2011, P 1 WORKSHOP FINE GR
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Chen G, 2015, IEEE WINT CONF APPL, P860, DOI 10.1109/WACV.2015.119
   Cruz-Roa Angel, 2011, J Pathol Inform, V2, pS4, DOI 10.4103/2153-3539.92031
   Cruz-Roa A, 2011, ARTIF INTELL MED, V52, P91, DOI 10.1016/j.artmed.2011.04.010
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Díaz G, 2012, MICROSC RES TECHNIQ, V75, P343, DOI 10.1002/jemt.21063
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feng Y., 2010, Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), P831
   Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215
   Gavves E, 2015, INT J COMPUT VISION, V111, P191, DOI 10.1007/s11263-014-0741-5
   Gosselin PH, 2014, PATTERN RECOGN LETT, V49, P92, DOI 10.1016/j.patrec.2014.06.011
   Jamil M., 2007, IEEE T INFORM EMERGI, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   Kanan C, 2014, IEEE WINT CONF APPL, P23, DOI 10.1109/WACV.2014.6836122
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Lavelli Alberto., 2004, CIKM 04, P615, DOI [DOI 10.1145/1031171.1031284, 10.1145/1031171.1031284]
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li ZX, 2011, PATTERN RECOGN LETT, V32, P441, DOI 10.1016/j.patrec.2010.11.001
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   López-Monroy AP, 2015, KNOWL-BASED SYST, V89, P134, DOI 10.1016/j.knosys.2015.06.024
   López-Monroy AP, 2013, PROC SPIE, V8922, DOI 10.1117/12.2034113
   López-Monroya AP, 2016, NEUROCOMPUTING, V175, P768, DOI 10.1016/j.neucom.2015.10.053
   Phan Xuan-Hieu, 2008, P 17 INT C WORLD WID, P91
   Quack Till., 2007, ICCV
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Su ZX, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P1, DOI 10.1109/SMI.2009.5170156
   Tirilly P., 2009, A review of weighting schemes for bag of visual words image retrieval
   Yang S., 2012, Advances in Neural Information Processing Systems, P3122
   Yuan JS, 2011, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2011.5995476
   Yuan Junsong, 2007, CVPR
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang Y, 2008, PROC CVPR IEEE, P125
   Zheng Q.-F., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P77
NR 56
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11313
EP 11336
DI 10.1007/s11042-018-6674-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900011
DA 2024-07-18
ER

PT J
AU Ravanbakhsh, N
   Mohammadi, M
   Nikooghadam, M
AF Ravanbakhsh, Niloofar
   Mohammadi, Mohadeseh
   Nikooghadam, Morteza
TI Perfect forward secrecy in VoIP networks through design a lightweight
   and secure authenticated communication scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Cryptanalysis; Key agreement; Lightweight design;
   Session initiation protocol (SIP)
ID SESSION INITIATION PROTOCOL; KEY AGREEMENT PROTOCOL; IMPROVEMENT
AB With the growth of the internet, development of IP based services has increased. Voice over IP (VoIP) technology is one of the services which works based on the internet and packet switching networks and uses this structure to transfer the multimedia data e.g. voices and images. Recently, Chaudhry et al., Zhang et al. and Nikooghadam et al. have presented three authentication and key agreement protocols, separately. However, in this paper, it is proved that the presented protocols by Chaudhry et al. and also Nikooghadam et al. do not provide the perfect forward secrecy, and the presented protocol by Zhang et al. not only is vulnerable to replay attack, and known session-specific temporary information attack, but also does not provide user anonymity, re-registration and revocation, and violation of fast error detection. Therefore, a secure and efficient two-factor authentication and key agreement protocol is presented. The security analysis proves that our proposed protocol is secure against various attacks. Furthermore, security of proposed scheme is formally analyzed using BAN logic and simulated by means of the AVISPA tool. The simulation results demonstrate security of presented protocol against active and passive attacks. The communication and computation cost of the proposed scheme is compared with previously proposed authentication schemes and results confirm superiority of the proposed scheme.
C1 [Ravanbakhsh, Niloofar; Mohammadi, Mohadeseh; Nikooghadam, Morteza] Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Razavi Khorasan, Iran.
RP Nikooghadam, M (corresponding author), Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Razavi Khorasan, Iran.
EM niloofar_ravanbakhsh@yahoo.com; mohadesehmohammadi@ymail.com;
   morteza.nikooghadam@gmail.com
RI Nikooghadam, Morteza/AAR-7984-2020
OI Nikooghadam, Morteza/0000-0003-3894-3103
CR [Anonymous], SCREEN
   [Anonymous], 2002, SIP SESSION INITIATI
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chaudhry SA, 2016, SECUR COMMUN NETW, V9, P5016, DOI 10.1002/sec.1672
   Chaudhry SA, 2015, SECUR COMMUN NETW, V8, P3782, DOI 10.1002/sec.1299
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P4485, DOI 10.1007/s11042-015-2487-7
   Franks J., 1999, HTTP AUTHENTICATION
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   Giri D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0145-7
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   He LJ, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0196-4
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Kumari S, 2018, J AMB INTEL HUM COMP, V9, P643, DOI 10.1007/s12652-017-0460-1
   Liu F, 2011, LECT NOTES COMPUT SC, V7025, P134, DOI 10.1007/978-3-642-24712-5_11
   Lu Y, 2016, ITC, P393
   Lu Y., 2015, MULTIMED TOOLS APPL, P1
   Lu YR, 2016, PEER PEER NETW APPL, V9, P449, DOI 10.1007/s12083-015-0363-x
   Mishra D, 2016, PEER PEER NETW APPL, V9, P171, DOI 10.1007/s12083-014-0321-z
   Mishra D, 2015, J INF SECUR APPL, V23, P28, DOI 10.1016/j.jisa.2015.06.003
   Mishra D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0154-6
   Nikooghadam M, 2017, MULTIMED TOOLS APPL, V76, P13401, DOI 10.1007/s11042-016-3704-8
   Odelu V, 2015, J INF SECUR APPL, V21, P1, DOI 10.1016/j.jisa.2015.01.001
   Pu Q, 2013, SECUR COMMUN NETW, V6, P340, DOI 10.1002/sec.568
   Ruan O, 2015, PERVASIVE MOB COMPUT, V24, P50, DOI 10.1016/j.pmcj.2015.06.008
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Sisalem D, 2006, IEEE NETWORK, V20, P26, DOI 10.1109/MNET.2006.1705880
   Sutrala AK, 2016, COMPUT METH PROG BIO, V135, P167, DOI 10.1016/j.cmpb.2016.07.028
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tsai J.L., 2009, Int J Netw Secur, V9, P12
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Xu DJ, 2017, IEEE INT CONF COMMUN, P998
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Yoon EJ, 2010, COMPUT COMMUN, V33, P1674, DOI 10.1016/j.comcom.2010.03.026
   Yoon EJ, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P642, DOI 10.1109/NISS.2009.137
   Zhang LP, 2016, J NETW COMPUT APPL, V59, P126, DOI 10.1016/j.jnca.2015.06.022
   Zhang LP, 2014, SECUR COMMUN NETW, V7, P2405, DOI 10.1002/sec.951
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
NR 47
TC 12
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11129
EP 11153
DI 10.1007/s11042-018-6620-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ding, JY
   Li, SO
   Wang, ZL
   Jiang, ZH
   Zhao, YX
   Wang, X
   He, MF
   Zhao, WN
   Yin, CH
AF Ding, Jiayuan
   Li, Siou
   Wang, Zhilong
   Jiang, Zihe
   Zhao, Yuexin
   Wang, Xue
   He, Mengfei
   Zhao, Weina
   Yin, Changhao
TI Brain MRI imaging mechanism based on deep visual information perception
   and dementia degree induction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MRI; Imaging; Deep visual information perception; Dementia degree
   induction
AB The traditional medical image recognition methods are limited by image resolution, image brightness and color processing parameters, and image quality evaluation is low. In particular, the incomplete visual information of medical images and the disorder of color structure make the complexity of human visual perception and recognition significantly increased and the accuracy is poor. In order to solve the above problems, this paper is based on the mechanism of deep brain information perception and dementia induced brain magnetic resonance imaging (BMI-DVDI). On the one hand, based on the depth fusion of the visual information system, the medical image depth vision system and its perception model with high precision and low complexity are designed for the two damage of medical image quality and the perception of visual information. On the other hand, the dementia model is designed by means of matrix representation of dementia image signal, screening of dementia sensing brain signal and image reconstruction. The model is helpful to solve the problems of image signal deformation, measurement precision of signal degree and reconstruction of image enhancement in brain magnetic resonance imaging. This model enhances the accuracy of brain diseases such as dementia. Then, we combine the sensing algorithm with the degree of dementia in the brain, and apply it to the MRI of the brain. Finally, through simulation experiments and nuclear magnetic resonance imaging experiments, the space complexity, time complexity, system execution efficiency and image quality evaluation are compared. The result is that the proposed algorithm has excellent performance.
C1 [Ding, Jiayuan; Jiang, Zihe; Zhao, Yuexin; Wang, Xue; He, Mengfei; Zhao, Weina; Yin, Changhao] Mudanjiang Med Univ, Hongqi Hosp, Dept Neurol, Mudanjiang, Peoples R China.
   [Ding, Jiayuan; Li, Siou; Wang, Zhilong; Jiang, Zihe; Zhao, Yuexin; Wang, Xue; He, Mengfei; Zhao, Weina; Yin, Changhao] Heilongjiang Prov Key Lab Cerebral Ischem Stroke, Mudanjiang, Heilongjiang, Peoples R China.
   [Li, Siou] Mudanjiang Med Univ, Hongqi Hosp, Dept Endocrinol, Mudanjiang, Heilongjiang, Peoples R China.
   [Wang, Zhilong] Mudanjiang Med Univ, Clin Coll 1, Mudanjiang, Peoples R China.
C3 Mudanjiang Medical University; Mudanjiang Medical University; Mudanjiang
   Medical University
RP Yin, CH (corresponding author), Mudanjiang Med Univ, Hongqi Hosp, Dept Neurol, Mudanjiang, Peoples R China.; Yin, CH (corresponding author), Heilongjiang Prov Key Lab Cerebral Ischem Stroke, Mudanjiang, Heilongjiang, Peoples R China.
EM yinchanghaoys@sina.com
FU National Natural Science Foundation of China [81771795]; Scientific
   research project of the health planning committee of Heilongjiang
   [2017-337]; Scientific research project of Mudanjiang Municipal Science
   and Technology Bureau [Z2016s0066]; Graduate Innovation fund project of
   Mudanjiang Medical University [2017YJSCX-05MY]
FX This work is supported in part by National Natural Science Foundation of
   China (81771795), Scientific research project of the health planning
   committee of Heilongjiang (2017-337), Scientific research project of
   Mudanjiang Municipal Science and Technology Bureau (Z2016s0066), and
   Graduate Innovation fund project of Mudanjiang Medical University
   (2017YJSCX-05MY).
CR [Anonymous], 2016, J BIOMEDICAL ENG MED, DOI DOI 10.14738/jbemi.31.1696
   [Anonymous], RADIO SCI
   Buckberg GD, 2016, EUR J CARDIO-THORAC, V29, P423
   Kodama T, 2005, PUBL ASTRON SOC JPN, V57, P309, DOI 10.1093/pasj/57.2.309
   Korolev S, 2017, IEEE INT S BIOM IM I
   Lee PH, 2016, INT J BEHAV MED, P1
   Matta F, 2016, MULT SIGN PROC 2008, P785
   Nardini M, 2016, DEVELOPMENTAL SCI, V19, P803, DOI 10.1111/desc.12327
   Pham CH, 2017, I S BIOMED IMAGING, P197, DOI 10.1109/ISBI.2017.7950500
   Prins D, 2016, ACTA OPHTHALMOL, V94, P113, DOI 10.1111/aos.12825
   Stockholm D, 2005, J MOL BIOL, V346, P215, DOI 10.1016/j.jmb.2004.11.039
   Vandermosten M, 2016, CURR OPIN BEHAV SCI, V10, P155, DOI 10.1016/j.cobeha.2016.06.007
   Vesper C, 2016, COGNITION, V153, P118, DOI 10.1016/j.cognition.2016.05.002
   Xia Y, 2016, NEUROCOMPUTING, V204, P189, DOI 10.1016/j.neucom.2015.08.125
   Yang J, 2018, J MED IMAG HEALTH IN, V8, P555, DOI 10.1166/jmihi.2018.2375
NR 15
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8841
EP 8859
DI 10.1007/s11042-018-6506-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800052
DA 2024-07-18
ER

PT J
AU Kumar, M
   Mohapatra, RN
   Agarwal, S
   Sathish, G
   Raw, SN
AF Kumar, Manish
   Mohapatra, R. N.
   Agarwal, Sajal
   Sathish, G.
   Raw, S. N.
TI A new RGB image encryption using generalized Vigenere-type table over
   symmetric group associated with virtual planet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual planet domain; Virtual planet rules; Virtual planet diffusion;
   Generalized Vigenere-type table; Image encryption
ID DNA-SEQUENCE OPERATION; ALGORITHM; CHAOS
AB The primary aim of this paper is to provide an efficient encryption algorithm for RGB images. A new, fast, and secure RGB image encryption algorithm using generalized Vigenere table over the symmetric group Sn associated with Virtual Planet Domain (VPD) is proposed. Also a new method to generate random key space using generalized Vigenere cipher is introduced. Randomness of the proposed key space has been verified by using NIST statistical test suite. A formula for the key space has also been obtained and it is shown that this key space resists brute force attack. The VPD has been designed to encode RGB image into VPD, which provides a fine interlacing among binary bit for each pixel. The proposed algorithm has been tested on standard RGB images. Robustness of the proposed algorithm has been successfully verified by using commonly known attacks (such as, differential, cropped, and noise, entropy attacks). Finally, the proposed technique has been compared with other existing algorithms and the data (shown in tables) confirm that the proposed algorithm is competitive and can resist exhaustive attacks efficiently.
C1 [Kumar, Manish; Agarwal, Sajal; Sathish, G.] Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
   [Mohapatra, R. N.] Univ Cent Florida, Dept Math, Orlando, FL 32816 USA.
   [Raw, S. N.] Natl Inst Technol Raipur, Dept Math, Raipur 492010, Chhattisgarh, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); State
   University System of Florida; University of Central Florida; National
   Institute of Technology (NIT System); National Institute of Technology
   Raipur
RP Kumar, M (corresponding author), Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM manish.math.bhu@gmail.com; ramm@mail.ucf.edu; sagarwal175@gmail.com;
   sathish90.india@gmail.com; shardaraw@gmail.com
RI Kumar, Manish/C-9163-2012
OI Kumar, Manish/0000-0003-2925-4218; Mohapatra, Ram/0000-0002-5502-3934
FU Science & Engineering Research Board, Government of India
   [YSS/2015/000930]
FX We thank to the two anonymous referees for their valuable comments. The
   first author is thankful to the Science & Engineering Research Board,
   Government of India for providing financial support through project file
   no. YSS/2015/000930.
CR [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   Awdun B, 2016, INT C SMART CIT SYST, P539
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gehani A., 2000, THEORET COMPUT SCI, V54, P23
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Malhotra R, 2001, P NATL ACAD SCI USA, V98, P12342, DOI 10.1073/pnas.231384098
   Mokhtar MA, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE), P12, DOI 10.1109/ICCCE.2014.17
   OZKAYNAK F, 2013, SIGNAL PROCESSING AN, V21, P1
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Pareek NK, 2011, INT J COMPUT APP NET, P42
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang JS, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P730, DOI 10.1109/SPAC.2017.8304370
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Y, 2012, RES DNA CRYPTOGRAPHY
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
NR 31
TC 8
Z9 8
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10227
EP 10263
DI 10.1007/s11042-018-6586-0
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400034
DA 2024-07-18
ER

PT J
AU Luo, LH
   Mo, JQ
AF Luo, Lihong
   Mo, Jianqing
TI A new Method for circular-screen movie production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Circular-screen movie; Panoramic video; Multi-Channel; Shooting; Playout
AB Currently, the main shooting equipment used for circular-screen movie production is the multichannel reflective camera system. However, this equipment is cumbersome, the playout method is complex, and the cost of production is very high. To overcome these shortcomings, this study proposes a panoramic video method for producing circular-screen movies. Three key problems of using the panoramic video method are studied and solved: panoramic video flattening, the hardware and software components of a panoramic circular-screen movie playout system, and a playout algorithm for panoramic circular-screen movies. The study gives an example of a panoramic circular-screen movie and compares the features of panoramic circular-screen movies and traditional circular-screen movies. The comparison shows that the equipment used for shooting panoramic circular-screen movie is lightweight, simple to operate, and low cost. These features will promote the development of circular-screen movies.
C1 [Luo, Lihong; Mo, Jianqing] Guangdong Univ Technol, Digital Media Dept, Guangzhou, Guangdong, Peoples R China.
C3 Guangdong University of Technology
RP Mo, JQ (corresponding author), Guangdong Univ Technol, Digital Media Dept, Guangzhou, Guangdong, Peoples R China.
EM luoleo98@163.com; qinggdut@163.com
FU Science and Technology Project of Guangdong Province of China
   [2016a040403110, 2017B010110008]; Natural Science Foundation of
   Guangdong Province of China [2015a030310112]
FX This work was supported by the Science and Technology Project of
   Guangdong Province of China (Grant No.2016a040403110 and
   No.2017B010110008), and Natural Science Foundation of Guangdong Province
   of China, (Grant No.2015a030310112).
CR Chen DQ, 2001, ADV MOTION PICTURE T, V6, P3
   Defarge A, 1997, French Patent, Patent No. [FR2744258-A1, 2744258]
   Donald H, 2014, COMPUTER GRAPHICS OP, P215
   Du XY, 2015, PROCEEDINGS OF THE ASME 34TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2015, VOL 8
   Geerds J, 2017, American Patent, Patent No. [US2017045814-A1, 2017045814]
   Ha JS, 2015, BASIC DESIG ART, V16, P509
   Han Jung Soo, 2016, [Journal of the Korea Convergence Society, 한국융합학회논문지], V7, P25, DOI 10.15207/JKCS.2016.7.1.025
   HTC Corp, 2017, American Patent, Patent No. [US2017054904-A1, 2017054904]
   Hua SG, 2004, P SOC PHOTO-OPT INS, V5444, P117, DOI 10.1117/12.561116
   Hua Shungang, 2006, Journal of Data Acquisition & Processing, V21, P434
   HUTCHINSON P, 2017, SIGHT SOUND, V27, P97
   Jung US, 2003, Korean Patent, Patent No. [KR409194-B, 409194]
   Li YX, 2017, ADV MOTION PICTURE T, V2, P8
   LIU TM, 2016, MULTIMEDIA
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQuarrie A, 2017, 19 IEEE VIRT REAL C
   Martin KW, 2015, J COLD WAR STUD, V17, P59, DOI 10.1162/JCWS_a_00597
   Moon D-h, 2013, J DIGIT CONT SOC, V14, P439, DOI [10.9728/dcs.2013.14.4.439, DOI 10.9728/DCS.2013.14.4.439]
   Shum HY, 2002, INT J COMPUT VISION, V48, P151, DOI 10.1023/A:1016051024520
   Tang Jin, 2002, Mini-Micro Systems, V23, P1363
   Wan NWAA, 2009, VIS INF BRIDG RES PR
   Xu W, 2013, MULTIMEDIA SYST, V19, P407, DOI 10.1007/s00530-013-0316-2
   Yang Lei, 2014, Infrared and Laser Engineering, V43, P985
NR 24
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9489
EP 9510
DI 10.1007/s11042-018-6552-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800082
DA 2024-07-18
ER

PT J
AU Ma, LS
   Chen, L
   Wang, SH
AF Ma, Lisha
   Chen, Lei
   Wang, Shihong
TI Security analysis of a reversible watermarking algorithm for encrypted
   images in wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security analysis; Reversible data hiding in encrypted images (RDH-EI);
   Chosen-plaintext attack; Differential cryptanalysis; Wavelet domain
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS
AB In recent years, reversible data hiding in encrypted images (RDH-EI) has attracted more and more attention, and many RDH-EI algorithms have been proposed. Scholars focus on improving embedded capacity and decreasing bit error rate, but the security issue of algorithms has not been paid enough attention to. However, the security of algorithms is a core problem. Recently, a RDH-EI algorithm based on compressed sensing and discrete wavelet transform is proposed. And considering the watermark embedding position keystream is related to the plain-image, the proposed algorithm is supposed to have high security. However, we find its security flaw, and by using chosen-plaintext attacks and differential cryptanalysis, we can extract all the encryption keys and all the embedding keys with merely 14 spatial images. In particular, compared with other methods, the number of images required in our method is independent of image size, which means that it requires less cost to break the algorithm. Finally, to resist the proposed attack, two improved suggestions are put forward. Simulation results demonstrate that the security of the improved algorithm is enhanced.
C1 [Ma, Lisha; Chen, Lei; Wang, Shihong] Beijing Univ Posts & Telecommun, Sch Sci, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wang, SH (corresponding author), Beijing Univ Posts & Telecommun, Sch Sci, Beijing 100876, Peoples R China.
EM shwang@bupt.edu.cn
CR Ahmad M, 2017, ADV INTELL SYST COMP, V515, P313, DOI 10.1007/978-981-10-3153-3_31
   Bouslimi D, 2016, IEEE ENG MED BIO, P2496, DOI 10.1109/EMBC.2016.7591237
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Di F, 2017, MULTIMED TOOLS APPL, V5, P1
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Ma K, 2014, IEEE T INF FOREN SEC, V3, P553
   Ong SY, 2014, SIGNAL PROCESS-IMAGE, V29, P135, DOI 10.1016/j.image.2013.09.001
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Shin S, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15181
   Topak E, 2005, PROC SPIE, V5681, P709, DOI 10.1117/12.586278
   Wang XH, 2016, INT J CHEM ENG, V2016, DOI 10.1155/2016/5217802
   Xiao D, 2017, MULTIMED TOOLS APPL, V76, P9265, DOI 10.1007/s11042-016-3532-x
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   YIN Z, 2017, MULTIMED TOOLS APPL, V76, P1, DOI DOI 10.1007/s11042-016-4049-z
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 26
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9827
EP 9843
DI 10.1007/s11042-018-6598-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400015
DA 2024-07-18
ER

PT J
AU Ma, XM
   Zhou, XW
   An, FP
AF Ma, Xingmin
   Zhou, Xianwei
   An, FengPing
TI Fast Bi-dimensional empirical mode decomposition(BEMD) based on variable
   neighborhood window method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Variable neighborhood window method; Disc window;
   Consistency of dimensions; Fast BEMD
ID EMD; COMBINATION; ALGORITHM
AB This paper presents a new method for BEMD. BEMD can decompose a source image into several two-dimensional intrinsic mode functions. During the image decomposition process, it is required to interpolate and draw the upper and lower envelopes. However, these interpolations and drawing the enveloping surface require a large amount of computing time and artificial screening. Thus, some scholars proposed the rapid realization of BEMD. Further, the window size being fixed during the decomposition process led to losses in the data-driven characteristics, adaptability and dimension consistency of the original BEMD. Therefore, this paper proposes a simple but effective means of keeping the original BEMD method features. The estimate reconstruction method is used to replace surface interpolation, and the variable neighborhood window method is adopted to replace the fixed neighborhood window method. In this article, an order filter is used to reconstruct the upper and lower envelopes, and then the filter size is obtained by using the fact that the image information itself is adaptively variable. Through an empirical analysis, this paper shows that this method can keep the original BEMD method's rapid decomposition, data-driven characteristics, adaptivity and consistency of scale.
C1 [Ma, Xingmin; Zhou, Xianwei] USTB, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
   [An, FengPing] Huai Yin Normal Univ, Huaian, Peoples R China.
C3 University of Science & Technology Beijing
RP Ma, XM (corresponding author), USTB, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
EM maxingmin1983@163.com; xwzhouli@sina.com; anfengping@163.com
RI zhou, xian/JYQ-9844-2024
OI AN, FENGPING/0000-0002-2220-2987; Xingmin, Ma/0000-0003-0508-2861
FU National Science Foundation Project of P. R. China [61701188];
   Foundation of Science and Technology on Information Assurance Laboratory
   [KJ-17-101]
FX This work is supported by National Science Foundation Project of P. R.
   China (No. 61701188) and the Foundation of Science and Technology on
   Information Assurance Laboratory (No. KJ-17-101).
CR An FP, 2015, INT J ANTENN PROPAG, V2015, DOI 10.1155/2015/769478
   Bhuiyan SMA, 2008, INT CONF ACOUST SPEE, P1313, DOI 10.1109/ICASSP.2008.4517859
   Bhuiyan SMA, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/728356
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Cai Biye, 2011, Computer Engineering and Applications, V47, P185, DOI 10.3778/j.issn.1002-8331.2011.23.052
   Cuiyun Li, 2011, Proceedings of the 2011 International Conference on Network Computing and Information Security (NCIS), P335, DOI 10.1109/NCIS.2011.163
   Damerval C, 2005, IEEE SIGNAL PROC LET, V12, P701, DOI 10.1109/LSP.2005.855548
   Ge Guangtao, 2010, Journal of Data Acquisition & Processing, V25, P195
   Haddadpour M, 2017, BIOMED J, V40, P219, DOI 10.1016/j.bj.2017.05.002
   He Z, 2013, IEEE T INSTRUM MEAS, V62, P889, DOI 10.1109/TIM.2013.2246917
   He Z, 2013, SIGNAL PROCESS, V93, P124, DOI 10.1016/j.sigpro.2012.07.009
   Hu JP, 2014, GRAPH MODELS, V76, P340, DOI 10.1016/j.gmod.2014.03.006
   Huang NE, 2003, P ROY SOC A-MATH PHY, V459, P2317, DOI 10.1098/rspa.2003.1123
   HUANG NE, 1995, P ROY SOC LOND A MAT, V454, P903, DOI DOI 10.1098/RSPA.1998.0193
   Kim D, 2012, IEEE SIGNAL PROC LET, V19, P191, DOI 10.1109/LSP.2012.2186566
   Liu HL, 2014, SCI WORLD J, DOI 10.1155/2014/819031
   Liu HL, 2014, SCI WORLD J, DOI 10.1155/2014/686754
   Liu ZX, 2005, IEEE SIGNAL PROC LET, V12, P33, DOI 10.1109/LSP.2004.839700
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   Nan Dong, 2011, Journal of Computer Applications, V31, P1552, DOI 10.3724/SP.J.1087.2011.01552
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Qiao LH, 2011, SCI CHINA INFORM SCI, V54, P2602, DOI 10.1007/s11432-011-4330-8
   Rilling Gabriel, 2003, IEEE EURASIP WORKSH, V3
   Trusiak M, 2012, P 18 CZECH POL SLOV
   Trusiak M, 2013, OPT EXPRESS, V21, P28359, DOI 10.1364/OE.21.028359
   Tran VT, 2013, MECH SYST SIGNAL PR, V38, P601, DOI 10.1016/j.ymssp.2013.02.001
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P339, DOI 10.1142/S1793536909000187
   Xiong Ch.-Zh., 2006, J ZHEJIANG UNIV SCI, V7, P1516, DOI 10.1631/jzus.2006.A1516
   Ye QH, 2012, PROCEDIA ENGINEER, V29, P1840, DOI 10.1016/j.proeng.2012.01.223
   Zhihua Yang, 2004, Proceedings. Third International Conference on Image and Graphics, P430
NR 31
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8889
EP 8910
DI 10.1007/s11042-018-6629-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800055
DA 2024-07-18
ER

PT J
AU Nandal, S
   Kumar, S
AF Nandal, Savita
   Kumar, Sanjeev
TI Single image fog removal algorithm in spatial domain using fractional
   order anisotropic diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airlight map; Anisotropic diffusion; Fractional-order partial
   derivative; Image defogging
ID OBJECT DETECTION; REGRESSION; FRAMEWORK; VISION; MODEL
AB This paper presents a novel image defogging algorithm using fractional-order anisotropic diffusion equation. The proposed algorithm uses the airlight map extracted from the foggy model as the initial image in the anisotropic diffusion process. The iterative diffusion process improves this airlight map. The anisotropic diffusion process is generalized to the order of any real number between [1, 2) using the Riemann-Liouville definition of the fractional order derivatives. The formulation of the iterative process is carried out in the spatial domain to have a simple and computationally efficient implementation. Simulation results validate that the proposed algorithm is outperforming over few of the existing algorithms. The comparison study is carried out using different metrics like contrast gain, colorfulness index, contrast-to-noise ratio and visible edges ratio.
C1 [Nandal, Savita; Kumar, Sanjeev] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Nandal, S (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM savi4.dma2014@iitr.ac.in; malikfma@iitr.ac.in
RI Kumar, Sanjeev/JTV-5459-2023; Kumar, Sanjeev/HKN-6866-2023
OI Kumar, Sanjeev/0000-0001-7728-3668
FU Indian Space Research organization; Ministry of Human Resources and
   Development
FX This work is partially supported by the Indian Space Research
   organization through their RESPOND scheme. One of the authors Savita
   Nandal is also thankful to Ministry of Human Resources and Development
   for financial support for carrying out her Ph.D. work.
CR [Anonymous], TPAMI
   [Anonymous], TPAMI
   [Anonymous], TPAMI
   [Anonymous], P ACM SIGGRAPH
   [Anonymous], TIP
   [Anonymous], ADV DIFFERENCE EQUAT
   [Anonymous], ARXIV171106787
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng G, 2013, ISPRS J PHOTOGRAMM, V85, P32, DOI 10.1016/j.isprsjprs.2013.08.001
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Huang YZ, 2016, MULTIMED TOOLS APPL, V75, P16315, DOI 10.1007/s11042-015-2932-7
   Janev M, 2011, MATH COMPUT MODEL, V54, P729, DOI 10.1016/j.mcm.2011.03.017
   Jiang H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100844
   Kamalaveni V, 2017, MULTIMED TOOLS APPL, V76, P18815, DOI 10.1007/s11042-016-4341-y
   Karasulu B, 2011, MULTIMED TOOLS APPL, V55, P677, DOI 10.1007/s11042-010-0591-2
   Kermani E, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-27
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prasath VBS, 2010, INT J REMOTE SENS, V31, P2091, DOI 10.1080/01431160903260965
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Tan R. T., 2008, PROC IEEE C COMPUT V, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IET IMAGE PROCESS, V6, P966, DOI 10.1049/iet-ipr.2011.0472
   Weickert J., 1996, COMPUTING WIEN SUPPL, V11, P221, DOI [DOI 10.1007/978-3-7091-6586-713, 10.1007/978-3-7091-6586-7_13, DOI 10.1007/978-3-7091-6586-7_13]
   Xie CH, 2017, SIGNAL IMAGE VIDEO P, V11, P705, DOI 10.1007/s11760-016-1013-3
   YOU YL, 1994, IEEE IMAGE PROC, P497, DOI 10.1109/ICIP.1994.413620
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
NR 32
TC 10
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10717
EP 10732
DI 10.1007/s11042-018-6576-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400053
DA 2024-07-18
ER

PT J
AU Yao, L
   Liu, ZK
   Wang, BF
AF Yao, Li
   Liu, Zhukui
   Wang, Bingfeng
TI 2D-to-3D conversion using optical flow based depth generation and
   cross-scale hole filling algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth extraction; 2D-to-3D; Dense optical flow; Cross-scale hole-filling
ID OBJECT REMOVAL; SYSTEM; SHAPE
AB 3D display has become the inevitable trend of display technology. Converting the traditional and classical 2D videos to 3D videos is an important and effective measure to solve the shortage of 3D contents. The major work about 2D-to-3D video conversion is how to extract depth information from the 2D video, and synthesize a new image from the existing viewpoint. We propose a depth extraction method based on dense edge-preserving optical flow from 2D videos, reducing the matching error in textureless regions. Moreover, we use the Gaussian Pyramid and Laplace Pyramid at cross scales to fill the holes in the image at new view point after 3D warping. The experiments show that our results outperform state-of-the-art methods in visual effect and statistics.
C1 [Yao, Li; Liu, Zhukui; Wang, Bingfeng] Southeast Univ, Coll Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Yao, Li] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Yao, L (corresponding author), Southeast Univ, Coll Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.; Yao, L (corresponding author), Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing, Jiangsu, Peoples R China.
EM Yao.li@seu.edu.cn; 229425962@qq.com; bingfengwang1992@gmail.com
OI yao, li/0000-0003-2930-8407
FU Industrial Prospective Project of Jiangsu Technology Department
   [BE2017081]
FX This work is supported by Industrial Prospective Project of Jiangsu
   Technology Department under Grant No. BE2017081.
CR [Anonymous], THESIS
   [Anonymous], HUM
   [Anonymous], IEEE T CONSUM ELECT
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2012, 2012 IEEE COMP SOC C
   [Anonymous], P 3DTV C TRUE VIS CA
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Assa J, 2007, COMPUT GRAPH FORUM, V26, P599, DOI 10.1111/j.1467-8659.2007.01083.x
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cheng CC, 2010, IEEE T CONSUM ELECTR, V56, P1739, DOI 10.1109/TCE.2010.5606320
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Hebborn AK, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P62, DOI 10.1109/ISMAR.2017.23
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Loh A. M., 2005, P BRIT MACH VIS C, P69
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Mark W. R., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P7, DOI 10.1145/253284.253292
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Pourazad MT, 2009, IEEE T CONSUM ELECTR, V55, P742, DOI 10.1109/TCE.2009.5174448
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shao M., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P530, DOI 10.1109/CVPR.1988.196286
   Taketomi Y, 2013, I S INTELL SIG PROC, P403, DOI 10.1109/ISPACS.2013.6704583
   Tam WJ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1869, DOI 10.1109/ICME.2006.262919
   Tao M, 2012, COMPUT GRAPH FORUM, V31, P345, DOI 10.1111/j.1467-8659.2012.03013.x
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Ward B, 2011, IEEE COMPUT GRAPH, V31, P36, DOI 10.1109/MCG.2010.103
   Wasserman L., 2004, ALL STAT CONCISE COU, V26
   Wei Q., 2005, International Conference, V7, P14
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Yao L, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P365, DOI 10.1145/2993369.2996351
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 51
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10543
EP 10564
DI 10.1007/s11042-018-6583-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400045
DA 2024-07-18
ER

PT J
AU Allili, MS
   Casemajor, N
   Talbi, A
AF Allili, Mohand Said
   Casemajor, Nathalie
   Talbi, Aymen
TI Multiple image copy detection and evolution visualisation using tree
   graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image copy detection; Image transformation; Copy evolution graph
ID FORGERY DETECTION
AB Image copy detection is an important problem for several applications such as detecting forgery to enforce copyright protection and intellectual property. One of the important problems following copy detection, however, is the assessment of the type of modifications undergone by an original image to form its copies. In this work, we propose a method for quantifying some of these modifications when multiple copies of the same image are available. We also propose an algorithm to estimate temporal precedence between images (i.e., the order of creation of the copies). Using the estimated relations, a tree graph is then built to visualize the history of evolution of the original image into its copies. Our work is important for ensuring better interpretation of image copies after their detection. It also lays a new ground for enhancing image indexing, dissemination analysis and search on the Web.
C1 [Allili, Mohand Said; Talbi, Aymen] Univ Quebec Outaouais, Dept Informat & Ingn, 101 St Jean Bosco, Gatineau, PQ J8X 3X7, Canada.
   [Casemajor, Nathalie] Inst Natl Rech Sci, Ctr Urbanisat Culture Soc, 385 Rue Sherbrooke Est, Montreal, PQ H2X 1E3, Canada.
C3 University of Quebec; University Quebec Outaouais; University of Quebec;
   Institut national de la recherche scientifique (INRS)
RP Allili, MS (corresponding author), Univ Quebec Outaouais, Dept Informat & Ingn, 101 St Jean Bosco, Gatineau, PQ J8X 3X7, Canada.
EM mohandsaid.allili@uqo.ca; nathalie.casemajor@ucs.inrs.ca; Tala07@uqo.ca
RI Allili, Mohand Said/AAB-2958-2022
OI Casemajor, Nathalie/0000-0001-7901-4859
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   University of Quebec en Outaouais
FX This work has been achieved thanks to the support of the Natural
   Sciences and Engineering Research Council of Canada (NSERC) and the
   University of Quebec en Outaouais. The authors would like to thank Rosa
   Iris Rodriguez Rovira and Karine Michaud Tessier for their collaboration
   in dataset collection and processing.
CR ALLILI M, 1964, TIP, V21, P1452, DOI DOI 10.1109/TIP.2011.2170701
   Allili MS, 2015, NEUROCOMPUTING, V167, P658, DOI 10.1016/j.neucom.2015.04.015
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2004, ACMMM
   [Anonymous], 2005, SIGMOD, DOI DOI 10.1145/1066157.1066243
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3
   Boulmerka A, 2015, IEEE IMAGE PROC, P3660, DOI 10.1109/ICIP.2015.7351487
   Boulmerka A, 2014, PATTERN RECOGN, V47, P1330, DOI 10.1016/j.patcog.2013.09.004
   Camargo JE, 2013, J VISUAL LANG COMPUT, V24, P53, DOI 10.1016/j.jvlc.2012.10.008
   Chen C, 2017, PROC CVPR IEEE, P1876, DOI 10.1109/CVPR.2017.203
   Cheng J, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P925, DOI 10.1145/2566486.2567997
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cox IJ., 2007, DIGITAL WATERMARKING
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Di Stefano L, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P322, DOI 10.1109/ICIAP.2003.1234070
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Faulkner A, 2017, ADOBE PHOTOSHOP CC C
   Fei-Fei L., 2004, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Glumov NI, 2011, OPTOELECTRON INSTRUM, V47, P207, DOI 10.3103/S8756699011030010
   Goel S, 2016, MANAGE SCI, V62, P180, DOI 10.1287/mnsc.2015.2158
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Gu Y, 2017, INFORM VISUAL, V16, P21, DOI 10.1177/1473871616630778
   Hsiao JH, 2007, IEEE T IMAGE PROCESS, V16, P2069, DOI 10.1109/TIP.2007.900099
   Hsu TC, 2011, IET INFORM SECUR, V5, P43, DOI 10.1049/iet-ifs.2008.0055
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ilsever M, 2012, PIXEL BASED CHANGE D
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Krishnan S, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P249, DOI 10.1145/2908131.2908155
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Manovich Lev, 2012, Media visualization: Visual techniques for exploring large media collections
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Ouyed O, 2018, NEUROCOMPUTING, V275, P1752, DOI 10.1016/j.neucom.2017.10.024
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Park J, 2012, PROC CVPR IEEE, P446, DOI 10.1109/CVPR.2012.6247707
   Petrou M. M., 2010, Image processing: the fundamentals
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Wang C, 2013, VISUALIZATION DATA A, P1
   Wang CL, 2015, INFORM VISUAL, V14, P183, DOI 10.1177/1473871613498519
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan LY, 2016, WORLD WIDE WEB, V19, P217, DOI 10.1007/s11280-015-0346-0
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   ZHANG D.-Q., 2004, PROC ACM INT C MULTI, P877, DOI DOI 10.1145/1027527.1027730
   ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   ZHAO W, 1991, TIP, V22, P980, DOI DOI 10.1109/TIP.2012.2226043
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 58
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6253
EP 6275
DI 10.1007/s11042-018-6350-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100059
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lee, JG
   Ko, YW
AF Lee, Jae Gu
   Ko, Young Woong
TI Retrieve similar cell images in OpenSlide file
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenSlide; Leveling; Tiling; Image sync; Feature extraction; Image
   similarity
ID FEATURES
AB Computer-based image analysis system enables efficient retrieval of similar images from large-size pathology database. In such a system, images are expressed based on visual content characteristics, and similarities between images are obtained by comparing the features. A pathology image is usually very huge and expressed as several layer of image quality called OpenSlide. To find similar cells from a OpenSlide file, we have to use high performance computer equiped with multi-core and large size memory. In this paper, we propose a method to find similar cell images with resource limited computer. For this purpose, we exploit several technique to minimize system resource requirement and adapt imaging process scheme that enhances the accuracy of finding similar cell images from a OpenSlide file. We adapt a leveling, tiling and sub tiling to the OpenSlide file and extracting the feature points accurately using the hybrid feature extracting algorithm that adapts advantages of ORB and Blob algorithm. Furthermore, grayscale and histogram schemes are used to improve the accuracy of finding similar pathology cell images. Experiment results show that the proposed system improves the performance of the system and increases the accuracy of finding similar images efficiently.
C1 [Lee, Jae Gu; Ko, Young Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
C3 Hallym University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM yuko@hallym.ac.kr
OI ko, young woong/0000-0002-6292-0799
FU Hallym University [HRF-201608-009]; National Research Foundation of
   Korea(NRF) - Ministry of Science, ICT and future Planning
   [2016H1D5A1910630]
FX This research was supported by Hallym University Research Fund,
   2016(HRF-201608-009) and this research was supported by Basic Science
   Research Program through the National Research Foundation of Korea(NRF)
   funded by the Ministry of Science, ICT and future Planning
   (2016H1D5A1910630).
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   [Anonymous], 2015, JAMA J AM MED ASSOC, DOI DOI 10.1001/JAMA.2015.1405
   Goode Adam, 2013, J Pathol Inform, V4, P27, DOI 10.4103/2153-3539.119005
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Jyothi B., 2015, 2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO), P1, DOI 10.1109/ISCO.2015.7282301
   Kumar A, 2015, IEEE J BIOMED HEALTH, V19, P1734, DOI 10.1109/JBHI.2014.2361318
   Leitloff J, 2010, IEEE T GEOSCI REMOTE, V48, P2795, DOI 10.1109/TGRS.2010.2043109
   Miksik O, 2011, IEEE INT CONF ROBOT
   Pan HW, 2014, IEEE J BIOMED HEALTH, V18, P574, DOI 10.1109/JBHI.2013.2274798
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Roy S, 2014, IEEE T BIO-MED ENG, V61, P2768, DOI 10.1109/TBME.2014.2329057
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Xu HM, 2017, IEEE T BIO-MED ENG, V64, P2475, DOI 10.1109/TBME.2017.2649485
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zheng YS, 2014, IEEE IMAGE PROC, P2304, DOI 10.1109/ICIP.2014.7025467
NR 16
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5269
EP 5285
DI 10.1007/s11042-017-5508-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100011
DA 2024-07-18
ER

PT J
AU Li, HH
   Wen, GH
   Zeng, HB
AF Li, Huihui
   Wen, Guihua
   Zeng, Haibin
TI Natural tongue physique identification using hybrid deep learning
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Tongue coating; Physique identification; Traditional
   Chinese Medicine (TCM)
ID COLOR; SEGMENTATION; DIAGNOSIS
AB Traditional Chinese Medicine (TCM) illustrates that the physique determines the susceptibility of human to certain diseases and treatment programs for illness. Tongue diagnosis is an important way to identify the physique, but now it is performed by the doctor's professional experience and the design of a questionnaire. Consequently, accurate physique identification cannot be obtained easily. In this paper, we propose a new method to identify the physique through wild tongue images using hybrid deep learning methods. It begins with constructing a large number of tongue images that are taken in natural conditions, instead of in a controlled environment. Based on the resulting database, a new method of tongue coating detection is put forward that applies a rapid deep learning method to complete the initial tongue coating detection, and then utilizes another deep learning method, a calibration neural network, to further improve the accuracy of tongue detection. Finally, an effective deep learning method is applied to identify the tongue physique. Experiments validate the proposed method, illustrating that physique identification can be performed well using hybrid deep learning methods.
C1 [Li, Huihui; Wen, Guihua; Zeng, Haibin] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Li, Huihui; Wen, Guihua] Guangdong Artificial Intelligence Engn Res Ctr Tr, Guangzhou, Guangdong, Peoples R China.
   [Zeng, Haibin] Guangdong Artificial Intelligence Engn Res Ctr Tr, Shenzhen, Peoples R China.
C3 South China University of Technology
RP Wen, GH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.; Wen, GH (corresponding author), Guangdong Artificial Intelligence Engn Res Ctr Tr, Guangzhou, Guangdong, Peoples R China.
EM 2977756@qq.com; crghwen@scut.edu.cn; 873532938@qq.com
OI LI, HUIHUI/0000-0003-0463-8178
FU China National Science Foundation [60973083, 61273363]; Science and
   Technology Planning Project of Guangdong Province [2014A010103009,
   2015A020217002]; Guangzhou Science and Technology Planning Project
   [201504291154480,201803010088]
FX This study was supported by China National Science Foundation (Grant
   Nos. 60973083 and 61273363), Science and Technology Planning Project of
   Guangdong Province (Grant Nos. 2014A010103009 and 2015A020217002), and
   Guangzhou Science and Technology Planning Project (Grant No.
   201504291154480,201803010088). We also thank LetPub (www.letpub.com) for
   its linguistic assistance during the preparation of this manuscript.
CR [Anonymous], CHIN J BASIC MED TRA
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], THESIS
   [Anonymous], BMC COMPLEMENT ALTER
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2002, CHIN ARCH TRADIT CHI
   [Anonymous], ZYYXH T157 2009 CHIN
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], HUMAN INTERFACE JAPA
   Bo P, 2004, IEEE T BIO-MED ENG, V51, P1803, DOI 10.1109/TBME.2004.831534
   Du Jian-qiang, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2499, DOI 10.1109/ICBBE.2008.958
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu MC, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0387-z
   Huang B, 2010, INFORM SCIENCES, V180, P312, DOI 10.1016/j.ins.2009.09.016
   Kamarudin ND, 2016, PROC SPIE, V0011, DOI 10.1117/12.2242404
   Kanawong Ratchadaporn, 2012, International Journal of Functional Informatics and Personalised Medicine, V4, P56, DOI 10.1504/IJFIPM.2012.050420
   Kim KK, 2008, 2008 SECOND INTERNATIONAL CONFERENCE ON FUTURE GENERATION COMMUNICATION AND NETWORKING SYMPOSIA, VOLS 1-5, PROCEEDINGS, P1, DOI 10.1109/FGCNS.2008.97
   Ko MM, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/508918
   Li FF, 2012, BMC COMPLEM ALTERN M, V12, DOI 10.1186/1472-6882-12-127
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li QL, 2009, COMPUT MED IMAG GRAP, V33, P217, DOI 10.1016/j.compmedimag.2008.12.004
   Lin F, 2016, MULTIMED TOOLS APPL, V75, P14203, DOI 10.1007/s11042-016-3363-9
   LO LC, 2012, EVID-BASED COMPL ALT, V2012, DOI DOI 10.1155/2012/505063
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Pang B, 2005, IEEE T MED IMAGING, V24, P946, DOI 10.1109/TMI.2005.850552
   Shi MJ, 2014, CHIN MED-UK, V9, DOI 10.1186/1749-8546-9-7
   Shi MJ, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-011-4428-z
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang XZ, 2013, IEEE T IMAGE PROCESS, V22, P5336, DOI 10.1109/TIP.2013.2284070
   Wang XZ, 2013, EXPERT SYST APPL, V40, P5854, DOI 10.1016/j.eswa.2013.04.031
   Wang XZ, 2010, IEEE T INF TECHNOL B, V14, P1355, DOI 10.1109/TITB.2010.2076378
   Wu KB, 2015, EXPERT SYST APPL, V42, P8027, DOI 10.1016/j.eswa.2015.06.032
   You MY, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P388, DOI 10.1109/IJCBS.2009.69
   Zhang B, 2014, IEEE T BIO-MED ENG, V61, P491, DOI 10.1109/TBME.2013.2282625
   Zhang JW, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P251, DOI 10.1109/ICCWAMTIP.2015.7493986
   Zhang L, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P324, DOI 10.1109/ICCI-CC.2013.6622262
   Zhuo L, 2016, NEUROCOMPUTING, V174, P815, DOI 10.1016/j.neucom.2015.10.008
   Zhuo L, 2014, NEUROCOMPUTING, V134, P111, DOI 10.1016/j.neucom.2012.12.080
NR 38
TC 15
Z9 20
U1 8
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6847
EP 6868
DI 10.1007/s11042-018-6279-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700020
DA 2024-07-18
ER

PT J
AU Luo, YM
   Xu, ZT
   Liu, PZ
   Du, YZ
   Guo, JM
AF Luo, Yanmin
   Xu, Zhitong
   Liu, Peizhong
   Du, Yongzhao
   Guo, Jingming
TI Combining fractal hourglass network and skeleton joints pairwise
   affinity for multi-person pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal hourglass network; Joints location heatmap regression; Skeleton
   joints pairwise affinity; Layered double-way inference; Multi-person
   pose estimation
AB Human pose estimation, especially multi-person pose estimation, is vital for understanding human abnormal behavior. In this paper, we develop a fractal hourglass model to automatically regress human body joints, and propose a layered double-way inference algorithm to calculate the affinity between neighboring skeleton joints. Firstly, the original hourglass resident unit was replaced and the candidate skeleton joints location heatmap regression process was described. And then, we determine the specific body joints location and optimize the regression results. Next, the double-way conditional probabilities between adjacent joints is defined as joints pairwise affinity, and is applied to match adjacent human body part. What's more, we adopt the spatial distance constraint to refine body joints matching result. Finally, we connect the best matching joints-pair, and iterate the process until all candidate joints are assigned into individual. Extensive experiments on the MPII multi-person subset and the COCO 2016 keypoints challenge show the effectiveness of our method, outperforming the second best method (Associative Embedding) by 0.45 and 1.20%.
C1 [Luo, Yanmin; Xu, Zhitong] Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Peoples R China.
   [Luo, Yanmin; Xu, Zhitong] Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit Xiamen City, 668 Jimei Ave, Xiamen 361021, Peoples R China.
   [Liu, Peizhong; Du, Yongzhao] Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou 362021, Fujian, Peoples R China.
   [Guo, Jingming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, 43 Keelung Rd, Taipei 10607, Taiwan.
C3 Huaqiao University; Huaqiao University; Huaqiao University; National
   Taiwan University of Science & Technology
RP Xu, ZT (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Peoples R China.; Xu, ZT (corresponding author), Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit Xiamen City, 668 Jimei Ave, Xiamen 361021, Peoples R China.
EM 1341403842@qq.com
FU National Natural Science Foundation of China [61605048]; Talent project
   of Huaqiao University [14BS215]; Quanzhou scientific and technological
   planning projects of Fujian, China [2015Z120]
FX This work was supported by the grants from National Natural Science
   Foundation of China (Grant No. 61605048), the Talent project of Huaqiao
   University (Grant No. 14BS215), and Quanzhou scientific and
   technological planning projects of Fujian, China (Grant No. 2015Z120).
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2015, ARXIV150203167
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46484-8_29
   [Anonymous], 2011, P ADV NEUR INF PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, ARXIV161105424
   [Anonymous], 2016, ARXIV161200137
   [Anonymous], 2016, ARXIV161108050
   [Anonymous], COURSERA NEURAL NETW
   [Anonymous], 2016, ARXIV161201465
   [Anonymous], COMPUT SCI
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], 2014, 2014 INT C LEARNING
   Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Chu Xiao, 2017, ARXIV170207432
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Guo YN, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574736
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Iqbal U, 2016, LECT NOTES COMPUT SC, V9914, P627, DOI 10.1007/978-3-319-48881-3_44
   Ke Shian-Ru., 2011, Distributed Smart Cameras (ICDSC), 2011 Fifth ACM/IEEE In- ternational Conference on, P1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Papandreou G., 2017, ARXIV170101779
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Shian-Ru Ke, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P489, DOI 10.1109/AVSS.2010.80
   Tao D., 2017, IEEE T CIRCUITS SYST, P1
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang, 2016, ESANN 2017 P, P589
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
NR 43
TC 1
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7341
EP 7363
DI 10.1007/s11042-018-6502-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700042
DA 2024-07-18
ER

PT J
AU Chen, JP
   Ying, PG
   Zou, M
AF Chen, Jinpeng
   Ying, Pinguang
   Zou, Ming
TI Improving music recommendation by incorporating social influence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Topological potential; Social influence; Meta-Path
AB In the past decades, a large number of music pieces are uploaded to the Internet every day through social networks, such as Last.fm, Spotify and YouTube, that concentrates on music and videos. We have been witnessing an ever-increasing amount of music data. At the same time, with the huge amount of online music data, users are facing an everyday struggle to obtain their interested music pieces. To solve this problem, music search and recommendation systems are helpful for users to find their favorite content from a huge repository of music. However, social influence, which contains rich information about similar interests between users and users' frequent correlation actions, has been largely ignored in previous music recommender systems. In this work, we explore the effects of social influence on developing effective music recommender systems and focus on the problem of social influence aware music recommendation, which aims at recommending a list of music tracks for a target user. To exploit social influence in social influence aware music recommendation, we first construct a heterogeneous social network, propose a novel meta path-based similarity measure called WPC, and denote the framework of similarity measure in this network. As a step further, we use the topological potential approach to mine social influence in heterogeneous networks. Finally, in order to improve music recommendation by incorporating social influence, we present a factor graphic model based on social influence. Our experimental results on one real world dataset verify that our proposed approach outperforms current state-of-the-art music recommendation methods substantially.
C1 [Chen, Jinpeng] Beijing Univ Posts & Telecommun, Sch Software Engn, Beijing 100876, Peoples R China.
   [Ying, Pinguang] Shanghai Univ Int Business & Econ, Sch WTO Res & Educ, Shanghai 200336, Peoples R China.
   [Zou, Ming] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Shanghai University of
   International Business & Economics; Beihang University
RP Chen, JP (corresponding author), Beijing Univ Posts & Telecommun, Sch Software Engn, Beijing 100876, Peoples R China.
EM jpchen@bupt.edu.cn
FU National Natural Science Foundation of China [61702043]; Fundamental
   Research Funds for the Central Universities [500417062]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61702043, and the Fundamental Research Funds for
   the Central Universities under Grant No. 500417062.
CR Aizenberg N., 2012, P 21 INT C WORLD WID, P1, DOI DOI 10.1145/2187836.2187838
   Althoff T, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P537, DOI 10.1145/3018661.3018672
   [Anonymous], P ACM KDD, DOI DOI 10.1145/1835804.1835837
   Ben-Elazar S, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P445, DOI 10.1145/3018661.3018718
   Bilanakos C, 2015, SOC SCI ELECT PUBL, V49, P1
   Chang HY, 2017, MULTIMED TOOLS APPL, V76, P19523, DOI 10.1007/s11042-015-3202-4
   Cheng Z, 2017, 26 INT JOINT C ART I, P3654
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P125, DOI 10.1145/2911451.2911491
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Cheng ZY, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1267, DOI 10.1145/2600428.2611187
   Craw S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1749
   Deng Z, 2013, PERSONALIZED VIDEO R, P1
   Ferwerda B., 2014, P UMAP
   Fujino H, 2017, ACM WORKSH EXPL SEAR, P55
   Gillhofer M, 2015, MULTIMEDIA MODELING
   Guo C, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P807, DOI 10.1145/2766462.2767808
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Hung HJ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P915, DOI 10.1145/2939672.2939758
   Ivanov S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P565, DOI 10.1145/3077136.3080788
   Jannach D, 2015, HITTING HITS GENERAT, P187
   Kaminskas M, 2013, ACM C REC SYST, P17
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Liu L, 2012, DATA MIN KNOWL DISC, V25, P511, DOI 10.1007/s10618-012-0252-3
   Lu Y, 2017, IEEE INT C DAT SCI C, P614
   Moshfeghi Y, 2011, INT ACM SIGIR C RES, P625
   Onori M., 2016, PROC EMPIRE RECSYS, VVolume 1680, P55
   Pálovics R, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P273, DOI 10.1145/2645710.2645723
   Qi Q., 2012, P 27 ANN ACM S APPL, P2008
   Sang JT, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700468
   Schedl M, 2015, EUR C IR RES ECIR 20, P339
   Schedl M, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P947, DOI 10.1145/2766462.2767763
   Schedl M, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P987, DOI 10.1145/2600428.2609491
   Seo YD, 2017, EXPERT SYST APPL, V69, P135, DOI 10.1016/j.eswa.2016.10.024
   Su JH, 2017, INTELL DATA ANAL, V21, pS195, DOI 10.3233/IDA-170878
   Sun JM, 2011, SOCIAL NETWORK DATA ANALYTICS, P177
   Tang W, 2011, JOINT EUR C MACH LEA
   Ugander J, 2012, P NATL ACAD SCI USA, V109, P5962, DOI 10.1073/pnas.1116502109
   Van den Oord A., 2013, P NIPS
   Wang D, 2016, INT C COMP WORLD WID, P125
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   Wen YT, 2017, ADV KNOWLEDGE DISCOV
   Yan M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/2671188.2749344
   Zhang J., 2013, INT JOINT C ART INT
   Zhang J, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700398
   Zhang QZ, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1917, DOI 10.1145/2983323.2983873
   Zheng ZB, 2013, IEEE T SERV COMPUT, V6, P289, DOI 10.1109/TSC.2011.59
NR 47
TC 17
Z9 21
U1 1
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2667
EP 2687
DI 10.1007/s11042-018-5745-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600003
DA 2024-07-18
ER

PT J
AU Kant, S
   Mahara, T
   Jain, VK
   Jain, DK
AF Kant, Surya
   Mahara, Tripti
   Jain, Vinay Kumar
   Jain, Deepak Kumar
TI Fuzzy logic based similarity measure for multimedia contents
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Recommendation system; Multimedia contents;
   Fuzzy logic; Similarity measure; Movie recommendation
ID COLLABORATIVE FILTERING FRAMEWORK; USER SIMILARITY; HU-FCF; SYSTEM;
   ALLEVIATE; ACCURACY; ITEM
AB Collaborative filtering is one of the mainstream approaches to provide recommendations in various online environments such as Ecommerce. Although this is a popular method for service recommendation, it still suffers from sparsity issue where only a small number of rating records are available for some new items or users in the system. Consequently, the accuracy of rate prediction is often compromised. Unlike the conventional collaborative filtering methods that directly compute the similarity between users, this paper presents a fuzzy logic based approach to refine the similarity obtained using traditional approaches like Pearson correlation, Cosine, Adjusted Cosine etc. Experiments were conducted on the two popular benchmark datasets and it shows that the proposed method obtains better prediction accuracy as compare to other traditional similarity measures.
C1 [Kant, Surya; Mahara, Tripti] Indian Inst Technol, Dept Polymer & Proc Engn, Roorkee 247667, Uttar Pradesh, India.
   [Jain, Vinay Kumar] JUET, Dept Comp Sci & Engn, Raghogarh, MP, India.
   [Jain, Deepak Kumar] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Kant, S (corresponding author), Indian Inst Technol, Dept Polymer & Proc Engn, Roorkee 247667, Uttar Pradesh, India.
EM suryak111@gmail.com
RI Mahara, Tripti/AFQ-7181-2022; Mahara, Tripti/AAR-9794-2020
OI Mahara, Tripti/0000-0001-5808-572X; kant, surya/0000-0002-5375-8187
CR Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   Anand D, 2011, EXPERT SYST APPL, V38, P5101, DOI 10.1016/j.eswa.2010.09.141
   [Anonymous], 2009, ACM SIGM 2009 C
   Birtolo C, 2013, EXPERT SYST APPL, V40, P6997, DOI 10.1016/j.eswa.2013.06.022
   Bobadilla J, 2010, KNOWL-BASED SYST, V23, P520, DOI 10.1016/j.knosys.2010.03.009
   Bobadilla J, 2012, INFORM PROCESS MANAG, V48, P204, DOI 10.1016/j.ipm.2011.03.007
   Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593
   Celma O, 2010, MUSIC RECOMMENDATION AND DISCOVERY, P185, DOI 10.1007/978-3-642-13287-2_9
   Cheng LC, 2014, APPL SOFT COMPUT, V18, P290, DOI 10.1016/j.asoc.2013.09.004
   Choi K, 2013, KNOWL-BASED SYST, V37, P146, DOI 10.1016/j.knosys.2012.07.019
   Czogala E., 2000, FUZZY NEUROFUZZY INT, DOI [10.1007/978-3-7908-1853-6, DOI 10.1007/978-3-7908-1853-6]
   Ekstrand Michael D., 2010, Foundations and Trends in Human-Computer Interaction, V4, P81, DOI 10.1561/1100000009
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jeong B, 2010, INFORM SCIENCES, V180, P602, DOI 10.1016/j.ins.2009.10.016
   Kant S, 2018, J COMPUT SCI-NETH, V25, P204, DOI 10.1016/j.jocs.2017.03.018
   Kant S, 2018, INT J SYST ASSUR ENG, V9, P173, DOI 10.1007/s13198-016-0500-9
   Kant V, 2012, PROCEDIA ENGINEER, V38, P939, DOI 10.1016/j.proeng.2012.06.118
   Son LH, 2015, ENG APPL ARTIF INTEL, V41, P207, DOI 10.1016/j.engappai.2015.02.003
   Leng YJ, 2016, KYBERNETES, V45, P434, DOI 10.1108/K-10-2014-0212
   Li JH, 2009, ADV INTEL SOFT COMPU, V62, P187
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Luo H, 2008, MACH LEARN, V72, P231, DOI 10.1007/s10994-008-5068-4
   Park YJ, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P11
   Patra BK, 2015, KNOWL-BASED SYST, V82, P163, DOI 10.1016/j.knosys.2015.03.001
   Pirasteh P, 2015, MOBILE NETW APPL, V20, P497, DOI 10.1007/s11036-014-0544-5
   Porcel C, 2009, EXPERT SYST APPL, V36, P5173, DOI 10.1016/j.eswa.2008.06.038
   Sanchez J. L., 2008, Second IEEE International Conference on Digital Ecosystems and Technologies (IEEE DEST 2008), P432, DOI 10.1109/DEST.2008.4635147
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Shi Lei., 2013, Proceedings of the 7th ACM Conference on Recommender Systems, P57
   Singh R., 2015, COMPLEX NETWORK APPR
   Son LH, 2014, EXPERT SYST APPL, V41, P6861, DOI 10.1016/j.eswa.2014.05.001
   Suryakant, 2016, PROCEDIA COMPUT SCI, V89, P450, DOI 10.1016/j.procs.2016.06.099
   Toscher A, 2008, P 2 KDD WORKSH LARG, V2008, P1
   Van Leekwijck W, 1999, FUZZY SET SYST, V108, P159, DOI 10.1016/S0165-0114(97)00337-0
   Yager RR, 2003, FUZZY SET SYST, V136, P133, DOI 10.1016/S0165-0114(02)00223-3
   Zhang Z, 2013, INFORM SCIENCES, V235, P117, DOI 10.1016/j.ins.2013.01.025
   Zhu XZ, 2014, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2014/07/P07004
NR 37
TC 6
Z9 7
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4107
EP 4130
DI 10.1007/s11042-017-5260-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200013
DA 2024-07-18
ER

PT J
AU Meng, YS
AF Meng, Yishuang
TI Establishment and application of Enterprise management maturity model
   based on multimedia data information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Data mining; Technology; Enterprise management; Model
   analysis; Framework construction; Multimedia information systems
AB Project management maturity model is a method and tool to help the project management organizations evaluate and improve their own project management level, and it has important guiding significance for enterprise project management practice in our country. This paper combines China's project management knowledge system and enterprise application characteristics, and we put forward the project process management maturity model based on the established evaluation index system, and expound the key practice in each level, finally this paper explores the method for passing through the project management maturity model of enterprise of our country. A maturity model can help organizations identify their location in specific knowledge areas and to improve them. Information resource management regards information as the main organizational resource. Therefore, we evaluate and improve the present situation of enterprise management, which plays a decisive role in the development of organizational information structure. Multimedia technology is a new information acquisition and processing technology. Multimedia sensor networks focus more on the collection and processing of large amount of data, such as audio, video, images and so on. We introduce the concept and characteristics of multimedia sensor network in this paper, and focus on the research progress at home and abroad and the challenges facing the multimedia sensor network, finally we analyze the current problems need to be solved, and the prospect of its future development trend. Besides this, we construct the multimedia data information systems to help better implementing the proposed model. The numerical verification proves the effectiveness of the proposed method.
C1 [Meng, Yishuang] Hunan Normal Univ, Tourism Coll, Changsha, Hunan, Peoples R China.
   [Meng, Yishuang] Cent South Univ, Sch Business, Postdoctoral Res Ctr, Changsha, Hunan, Peoples R China.
C3 Hunan Normal University; Central South University
RP Meng, YS (corresponding author), Hunan Normal Univ, Tourism Coll, Changsha, Hunan, Peoples R China.; Meng, YS (corresponding author), Cent South Univ, Sch Business, Postdoctoral Res Ctr, Changsha, Hunan, Peoples R China.
EM mengyishuangcn@yahoo.com
FU State Ethnic Affairs Commission Project [2017-GMC-013]; Hunan Education
   Department Project [17B175]; Young Professionals Project of China
   National Tourism Administration Operation System 2015; Young Social
   Sciences Academician Program of Hunan Normal University 2015
FX This paper is financially supported by the State Ethnic Affairs
   Commission Project (2017-GMC-013); Hunan Education Department Project
   (17B175); Young Professionals Project of China National Tourism
   Administration Operation System 2015; Young Social Sciences Academician
   Program of Hunan Normal University 2015.
CR Alnusair A, 2017, MULTIMED TOOLS APPL, P1
   Amato F, 2016, J VISUAL LANG COMPUT, V32, P35, DOI 10.1016/j.jvlc.2015.10.012
   [Anonymous], 2018, NEURAL COMPUTING APP
   Cui D, 2017, J MED IMAG HEALTH IN, V7, P994, DOI 10.1166/jmihi.2017.2127
   De Marsico M, 2017, MULTIMED TOOLS APPL, V76, P4849, DOI 10.1007/s11042-016-4024-8
   Gai KK, 2020, IEEE T CLOUD COMPUT, V8, P1212, DOI 10.1109/TCC.2016.2594172
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Ji RR, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3040934
   Kamal S, 2018, NEURAL COMPUT APPL, V29, P1015, DOI 10.1007/s00521-016-2513-3
   Li ZZ, 2017, J MED IMAG HEALTH IN, V7, P805, DOI 10.1166/jmihi.2017.2074
   Lou CJ, 2017, J MED IMAG HEALTH IN, V7, P1648, DOI 10.1166/jmihi.2017.2180
   Lv Z, 2016, INT CONF SYST INFORM, P710, DOI 10.1109/ICSAI.2016.7811045
   Mansouri I, 2018, NEURAL COMPUT APPL, V29, P873, DOI 10.1007/s00521-016-2492-4
   Mao Q, 2018, J MED IMAG HEALTH IN, V8, P72, DOI 10.1166/jmihi.2018.2235
   Moscato V, 2018, COMPREHENSIVE GUIDE, P269
   Pan ZB, 2016, MULTIMED TOOLS APPL, V75, P8595, DOI 10.1007/s11042-015-2773-4
   Priya JS, 2016, J MED IMAG HEALTH IN, V6, P1572, DOI 10.1166/jmihi.2016.1851
   Saveetha V, 2018, CLUSTER COMPUT, P1
   Thangarasu N, 2018, CLUSTER COMPUT, P1
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang Y, 2018, J MED IMAG HEALTH IN, V8, P602, DOI 10.1166/jmihi.2018.2309
   Wang YM, 2019, CLUSTER COMPUT, V22, P1189, DOI 10.1007/s10586-017-1199-3
   Wei Y, 2018, J MED IMAG HEALTH IN, V8, P494, DOI 10.1166/jmihi.2018.2307
   Xiahou JB, 2018, NEURAL COMPUT APPL, V29, P71, DOI 10.1007/s00521-016-2364-y
   Yavuz E, NEURAL COMPUTING APP, P1
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang ZH, 2016, J MED IMAG HEALTH IN, V6, P1233, DOI 10.1166/jmihi.2016.1904
   Zhu J, 2016, MULTIMED TOOLS APPL, V75, P14329, DOI 10.1007/s11042-016-3403-5
NR 29
TC 4
Z9 4
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4503
EP 4525
DI 10.1007/s11042-018-5999-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200031
DA 2024-07-18
ER

PT J
AU Babu, MS
   Vijayalakshmi, V
AF Babu, M. Sunil
   Vijayalakshmi, V.
TI A review on acute/sub-acute ischemic stroke lesion segmentation and
   registration challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Random forest; Arterial vessel spin labeling; Cerebral micro bleeds;
   Magnetic resonance imaging; Markov random field; Computed tomography
   angiography
ID AUTOMATED DELINEATION; BRAIN-LESION; IMAGES
AB The segmentation of lesion tissue in brain images of stroke patients serves to distinguish the degree of the affected tissues, to perform anticipation on its recovery, and to quantify its development in longitudinal reviews. Manual depiction, the present standard, is tedious and experiences high intra-and inter-observer differences. Because of limited scholastic investigations of ischemic stroke identification, the achievement rate to distinguish stroke is low utilizing just CT image. Combination of CT and MRI images makes a composite image which gives more data than any of the information signals. Image segmentation is accomplished by a Random forest (RF) classifier connected on an arrangement of image elements extricated from each voxel and its neighborhood. An underlying arrangement of marked voxels is required to begin the procedure, preparing an underlying RF. The most unverifiable unlabeled voxels are appeared to the human administrator to choose some of them for incorporation in the preparation set, retraining the RF classifier. These strategies give very accurate segmented tumor output with very low error rate and very high accuracy.
C1 [Babu, M. Sunil] Pondicherry Univ, Pondicherry Engn Coll, Dept Elect & Commun Engn, Pondicherry, India.
   [Vijayalakshmi, V.] Pondicherry Engn Coll, Dept Elect & Commun Engn, Pondicherry, India.
C3 Pondicherry University; Pondicherry Engineering College; Pondicherry
   Engineering College
RP Babu, MS (corresponding author), Pondicherry Univ, Pondicherry Engn Coll, Dept Elect & Commun Engn, Pondicherry, India.
EM sunil.babu.m@pec.edu
RI MELINGI, SUNIL BABU/AAP-7376-2020; Vijayalakshmi, V./AAQ-3372-2020
OI MELINGI, SUNIL BABU/0000-0001-8720-4062; Vijayalakshmi,
   V./0000-0002-7499-201X
CR Bienkowski P, 2010, NEUROSCI LETT, V478, P161, DOI 10.1016/j.neulet.2010.05.008
   Cai SS, 2016, RADIOLOGY CASE REPOR
   Cheng Chung Wan G, 2016, BEHAV BRAIN RES, V317, P251
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ghafurian S, 2017, NEUROCOMPUTING, V229, P100, DOI 10.1016/j.neucom.2016.07.070
   Gillebert CR, 2014, NEUROIMAGE-CLIN, V4, P540, DOI 10.1016/j.nicl.2014.03.009
   Jia HJ, 2012, COMPUT MED IMAG GRAP, V36, P139, DOI 10.1016/j.compmedimag.2011.09.001
   Liu SX, 2009, J BIOMED INFORM, V42, P1056, DOI 10.1016/j.jbi.2009.07.003
   Mah YH, 2014, CORTEX, V56, P51, DOI 10.1016/j.cortex.2012.12.008
   Mahapatra D, 2014, IEEE T IMAGE PROCESS, V23, P1504, DOI 10.1109/TIP.2014.2305073
   Maiora J, 2014, NEUROCOMPUTING, V126, P71, DOI 10.1016/j.neucom.2013.01.051
   Menze BH, 2016, IEEE T MED IMAGING, V35, P933, DOI 10.1109/TMI.2015.2502596
   Mitra J, 2014, NEUROIMAGE, V98, P324, DOI 10.1016/j.neuroimage.2014.04.056
   Moro V, 2016, CORTEX, V83, P62, DOI 10.1016/j.cortex.2016.07.001
   Mun JK, 2016, J NEUROL SCI, V369, P176, DOI 10.1016/j.jns.2016.08.024
   Prakash KNB, 2008, INT J COMPUT ASS RAD, V3, P559, DOI 10.1007/s11548-008-0260-3
   Rekik I, 2014, NEUROIMAGE-CLIN, V5, P332, DOI 10.1016/j.nicl.2014.07.009
   Rosales RL, 2016, J NEUROL SCI, V371, P6, DOI 10.1016/j.jns.2016.10.005
   Saad NM, 2017, P INT MULT ENG COMP, V1
   So RWK, 2017, PATTERN RECOGN, V62, P161, DOI 10.1016/j.patcog.2016.09.004
   Stille M, 2013, J NEUROSCI METH, V219, P27, DOI 10.1016/j.jneumeth.2013.06.003
   Sweeney EM, 2013, NEUROIMAGE-CLIN, V2, P402, DOI 10.1016/j.nicl.2013.03.002
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2017, IEEE T CIRC SYST VID, V27, P62, DOI 10.1109/TCSVT.2016.2539778
   Tateishi Y, 2016, J NEUROL SCI, V369, P77, DOI 10.1016/j.jns.2016.08.006
   van Asselen M, 2009, BRAIN COGNITION, V71, P287, DOI 10.1016/j.bandc.2009.07.012
   Wilke M, 2011, NEUROIMAGE, V56, P2038, DOI 10.1016/j.neuroimage.2011.04.014
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yu WM, 2017, PATTERN RECOGN, V63, P689, DOI 10.1016/j.patcog.2016.09.036
   Zhang T, 2012, J AFFECT DISORDERS, V136, pE83, DOI 10.1016/j.jad.2011.06.014
NR 30
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2481
EP 2506
DI 10.1007/s11042-018-6344-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700053
DA 2024-07-18
ER

PT J
AU Gao, Z
   Xue, KX
   Zhang, H
AF Gao, Zan
   Xue, Kai-Xin
   Zhang, Hua
TI Multi-view and multivariate gaussian descriptor for 3D object retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Image descriptors; Multi-view; Multivariate
   gaussian distribution
ID HUMAN ACTION RECOGNITION
AB 3D object retrieval is a hot research topic in computer vision domain, and several feature descriptors have been proposed, such as Zernike moments and HOG. However, multi-view images factor often be ignored in the feature extraction. Inspired by the Multivariate Gaussian descriptor and multi-view latent relationships, we propose a new feature descriptor called Multi-view and Multivariate Gaussian (MMG) Descriptor for 3D object retrieval. In detail, the local statistics of an image is characterized by using multivariate Gaussian distribution which is continuous and can effectively estimate different orders statistics in the local neighborhood. Furthermore, images from different perspectives are explored when extracting the characteristics of an object. Extensive experimental results on ETH dataset and 3Ddataset show that: 1) MMG descriptor is more suitable for 3D object retrieval than Zernike Moments and HOG whose performance is much better than that of other two descriptors; 2) The performance can also obtain some improvements when multi-view factor is considered. 3) When the different angles and number of images are chosen, their performances also have fluctuations.
C1 [Gao, Zan; Xue, Kai-Xin; Zhang, Hua] Minist Educ, Key Lab Comp Vis & Syst, Tianjin, Peoples R China.
   [Gao, Zan; Xue, Kai-Xin; Zhang, Hua] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology
RP Gao, Z (corresponding author), Minist Educ, Key Lab Comp Vis & Syst, Tianjin, Peoples R China.; Gao, Z (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM gaozan114@126.com; hzhang62@126.com
FU National Natural Science Foundation of China [61572357, 61202168];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [14JCZDJC31700, 13JCQNJC0040]; Tianjin Municipal Natural
   Science Foundation [13JCQNJC0040]; Country China Scholarship Council
   [201608120021]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61572357, No.61202168), Tianjin Research Program
   of Application Foundation and Advanced Technology (14JCZDJC31700 and
   13JCQNJC0040), Tianjin Municipal Natural Science Foundation
   (No.13JCQNJC0040) and Country China Scholarship Council
   (No.201608120021).
CR [Anonymous], J APPL MATH
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], P SIGIR
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018
   Baker A, 2002, AM MATH MON, V110, P446
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao Y, 2010, P ACM C MULT, P1711
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Z, 2017, NEUROCOMPUTING, V252, P67, DOI 10.1016/j.neucom.2016.01.126
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2017, J VISUAL COMMUNICATI
   Gao Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P117, DOI 10.1145/2964284.2967194
   Gao ZF, 2017, MED IMAGE ANAL, V37, P1, DOI 10.1016/j.media.2017.01.004
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Hall B.C, 2003, Lie Groups, Lie Algebras, and Representations; An Elementary Introduction
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2017, IEEE T KNOWL DATA EN, V29, P57, DOI 10.1109/TKDE.2016.2611584
   He XN, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P771, DOI 10.1145/2566486.2567975
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kumar A., 2011, P 28 INT C MACHINE L, P393
   Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816
   Li PH, 2013, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2013.212
   Li PH, 2012, LECT NOTES COMPUT SC, V7574, P469, DOI 10.1007/978-3-642-33712-3_34
   Li XC, 2015, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR.2015.7299151
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu J, 2016, NEUROCOMPUTING, V236
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Savarese S, 2007, IEEE I CONF COMP VIS, P1245
   Serra G, 2013, MODELING LOCAL DESCR, P709
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Tang J, 2017, INORGANIC AND ORGANOMETALLIC TRANSITION METAL COMPLEXES WITH BIOLOGICAL MOLECULES AND LIVING CELLS, P1, DOI 10.1016/B978-0-12-803814-7.00001-0
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Thomas Alexander., 2006, CVPR (2), P1589
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P781, DOI 10.1145/2964284.2964308
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhao XB, 2015, COMMUN STAT-THEOR M, V44, P5240, DOI 10.1080/03610926.2013.815207
NR 53
TC 1
Z9 1
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 555
EP 572
DI 10.1007/s11042-017-5270-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500031
DA 2024-07-18
ER

PT J
AU Li, SC
   Song, R
AF Li, Sanchun
   Song, Rui
TI Bilateral adaptive quantization in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding; Adaptive quantization; Scanning order;
   Transformed coefficient magnitude
ID VIDEO
AB In this paper, we proposed an adaptive quantization algorithm for High Efficiency Video Coding (HEVC) to boost the encoding performance. The transform coefficients in a Transform Unit (TU) inherit the energy concentration property. However, they are equally quantized before entropy coding. With equal quantization technique, the energy distribution of transform coefficients and the scanning pattern following the quantization stage is not properly considered. In order to quantize the coefficients adaptively, we proposed an improved algorithm to quantize the coefficients. For each coefficient, both the magnitude and its ordinal number scanned in entropy coding process are taken into account. The quantization parameter of each coefficient in a TU is adaptively calculated by the bilateral factors accordingly. We tested our method on the latest HM16.0. An average performance of -0.27% on BD-Rate and 7.07% computing time saving are achieved in the case of the commonly used Low Delay P configuration, which demonstrated the effectiveness of the proposed algorithm.
C1 [Li, Sanchun; Song, Rui] Xidian Univ, State Key Lab Integrated Serv Networks, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Song, R (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
EM ruiScientific@gmail.com
FU NSFC [61401337, 61222101]; Key Research and Development Program of
   Shaanxi province [2017KJXX-50]; 111 Project [B08038]; Key Laboratory of
   Infrared System Detection and Imaging Technology, Shanghai Institute of
   Technical Physics, Chinese Academy of Sciences
FX This work has been supported by NSFC Grant No. 61401337, 61222101, the
   Key Research and Development Program of Shaanxi province (2017KJXX-50),
   the 111 Project (B08038), and Key Laboratory of Infrared System
   Detection and Imaging Technology, Shanghai Institute of Technical
   Physics, Chinese Academy of Sciences. We would like to thank Ms. Yuan
   Jia from ISN lab of Xidian Univsity for her great help on paper
   revision, language editing and proof reading.
CR [Anonymous], 2001, VCEGM33
   [Anonymous], 2005, ADAPTIVE QUANTIZATIO
   [Anonymous], HEVC TEST MOD HM 16
   Budagavi M., 2014, PROC INT C HIGH EFFI, P141
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Gweon R, 2012, IEEE INT S BROADB MU, P1
   He J, 2015, IET IMAGE PROCESS, V9, P652, DOI 10.1049/iet-ipr.2014.0849
   He J, 2015, SIGNAL IMAGE VIDEO P, V9, P543, DOI 10.1007/s11760-013-0474-x
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Lee H, 2016, IEEE T CIRC SYST VID, V26, P107, DOI 10.1109/TCSVT.2015.2450151
   Liu TL, 2017, IEEE T NEUR NET LEAR, V28, P2129, DOI 10.1109/TNNLS.2016.2574748
   Liu TL, 2016, NEURAL COMPUT, V28, P2213, DOI 10.1162/NECO_a_00872
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Nam J, 2012, IEEE INT SYM BROADB
   Paul M, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1428, DOI 10.1109/ICACCI.2014.6968266
   Prangnell L, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P35, DOI 10.1109/PCS.2015.7170042
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Stankowski J, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P85, DOI 10.1109/PCS.2015.7170052
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Nguyen T, 2013, IEEE J-STSP, V7, P978, DOI 10.1109/JSTSP.2013.2278071
   Wang J, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/6138251
   Wang MH, 2015, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2015.7168682
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeo CH, 2013, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2013.6637940
NR 30
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2385
EP 2399
DI 10.1007/s11042-018-6312-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700048
DA 2024-07-18
ER

PT J
AU Safyan, M
   Ul Qayyum, Z
   Sarwar, S
   García-Castro, R
   Ahmed, M
AF Safyan, Muhammad
   Ul Qayyum, Zia
   Sarwar, Sohail
   Garcia-Castro, Raul
   Ahmed, Mehtab
TI Ontology-driven semantic unified modelling for concurrent activity
   recognition (OSCAR)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complete activity model; Personalized activity model; Adaptive system;
   Domain activity ontology; Concurrent activity recognition
ID KNOWLEDGE
AB Activity recognition has a vital role in smart home operations. One of the major challenges in object-sensor-based activity recognition is to learn the complete activity model derived from a generic activity model for sequential and parallel activities. Such challenge exists due to erratic degrees of dissimilar activities in which inhabitants perform activities in sequential and interleaved fashion while interacting with different objects. The proposed work focuses on recognizing a complete set of actions (of activity) by exploiting different knowledge engineering techniques, ontology-based temporal formalisms and data driven techniques. Semantic Segmentation has been employed to establish the generic activity model. The spurious semantic segmentation produced by sensor noise or erratic behaviour is removed by Allen's temporal formalism. Moreover, Tversky's feature-based similarity has been used to remove the highly similar spurious activities produced as a result of mistaken interactions with wrong home objects. The duration to perform activities varies among inhabitants; such duration intervals are identified dynamically using the proposed model in order to have a complete activity model. A comprehensive set of experiments has been carried out for evaluating the proposed model where the results based upon different metrics assert its effectiveness especially when compared with other contemporary techniques.
C1 [Safyan, Muhammad] Iqra Univ Islamabad, Islamabad, Pakistan.
   [Safyan, Muhammad; Ul Qayyum, Zia; Sarwar, Sohail] Univ Gujarat, Gujarat, Pakistan.
   [Garcia-Castro, Raul] Univ Politecn Madrid, Ontol Engn Grp, Madrid, Spain.
   [Ahmed, Mehtab] Govt Coll Univ, Lahore, Pakistan.
C3 Iqra University; Universidad Politecnica de Madrid; Government College
   University Lahore
RP Safyan, M (corresponding author), Iqra Univ Islamabad, Islamabad, Pakistan.
EM m.safyan@seecs.edu.pk
RI Sarwar, Sohail/KCJ-4936-2024; Castro, Raúl García/AAU-4456-2020
OI Sarwar, Sohail/0000-0001-7565-439X; Castro, Raúl
   García/0000-0002-0421-452X
CR Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], PERV COMP COMM WORKS
   [Anonymous], P 2015 IEEE INT C EL
   [Anonymous], SURVEY VISION BASED
   [Anonymous], PROPERTY BASED SEMAN
   [Anonymous], 2009, Pervasive Computing and Communications, DOI DOI 10.1109/PERCOM.2009.4912776
   Azkune G, 2015, EXPERT SYST APPL, V42, P3115, DOI 10.1016/j.eswa.2014.11.063
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Caragliu A, 2011, J URBAN TECHNOL, V18, P65, DOI 10.1080/10630732.2011.601117
   Chen LM, 2014, IEEE T HUM-MACH SYST, V44, P92, DOI 10.1109/THMS.2013.2293714
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Chen LM, 2009, INT J WEB INF SYST, V5, P410, DOI 10.1108/17440080911006199
   Cook D., 2009, P CHI WORKSHOP DEVEL, P1
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Díaz-Rodríguez N, 2014, SENSORS-BASEL, V14, P18131, DOI 10.3390/s141018131
   Gayathri KS, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P46, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.31
   Gayathri KS, 2015, COMPOSITE ACTIVITY R
   Georis B., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P46
   Gu T, 2011, IEEE T KNOWL DATA EN, V23, P1359, DOI 10.1109/TKDE.2010.184
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hakeem A, 2004, INT C PATT RECOG, P219, DOI 10.1109/ICPR.2004.1333743
   Helaoui R, 2011, PERVASIVE MOB COMPUT, V7, P660, DOI 10.1016/j.pmcj.2011.08.004
   Helaoui R, 2011, INT CONF PERVAS COMP, P1, DOI 10.1109/PERCOM.2011.5767586
   Hemalatha M, 2012, INT J WEB SEMANTIC T, V3, P1
   Khan S, 2014, J KING SAUD UNIV-COM, V26, P247, DOI 10.1016/j.jksuci.2014.03.010
   Liming Chen, 2012, IEEE Transactions on Knowledge and Data Engineering, V24, P961, DOI 10.1109/TKDE.2011.51
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   McKeever S, 2010, J AMB INTEL SMART EN, V2, P253, DOI 10.3233/AIS-2010-0071
   Meditskos G., 2015, JOINT P SSN TC ORDRI, P31
   Milea V, 2008, WEB ENG 2008 ICWE 08
   Nevatia R., 2004, Computer Vision and Pattern Recognition Workshop, P119
   Okeyo George, 2012, Ubiquitous Computing and Ambient Intelligence. 6th International Conference, UCAmI 2012. Proceedings, P322, DOI 10.1007/978-3-642-35377-2_44
   Pantelopoulos A, 2010, IEEE T SYST MAN CY C, V40, P1, DOI 10.1109/TSMCC.2009.2032660
   Riboni D, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1, DOI 10.1145/2971648.2971691
   Riboni D, 2011, PERS UBIQUIT COMPUT, V15, P271, DOI 10.1007/s00779-010-0331-7
   Singla Geetika, 2009, Int J Biosci Psychiatr Technol IJBSPT, V1, P25
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   van Kasteren T., 2011, ARCS 2011 VDE
   Welty C, 2006, FRONT ARTIF INTEL AP, V150, P226
   Ye J, 2015, PERVASIVE MOB COMPUT, V19, P47, DOI 10.1016/j.pmcj.2014.02.003
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
NR 47
TC 12
Z9 16
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2073
EP 2104
DI 10.1007/s11042-018-6318-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700036
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   El-Rabaie, ESM
   El-Halawany, M
   Abd El-Samie, FE
AF El-Shafai, Walid
   El-Rabaie, El-Sayed M.
   El-Halawany, M.
   Abd El-Samie, Fathi E.
TI Efficient multi-level security for robust 3D color-plus-depth HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC watermarking; Wavelet fusion; Homomorphic transform; SVD; DSWT;
   DCT; Chaotic encryption
ID WATERMARKING SCHEME; PARALLEL FRAMEWORK; VIDEO WATERMARKING; IMAGES
AB This paper presents two robust hybrid watermarking techniques for securing the Three-Dimensional High Efficiency Video Coding (3D-HEVC). The first watermarking technique is the homomorphic-transform-based Singular Value Decomposition (SVD) in Discrete Wavelet Transform (DWT) domain. The second watermarking technique is the three-level Discrete Stationary Wavelet Transform (DSWT) in Discrete Cosine Transform (DCT) domain. The objective of the two proposed hybrid watermarking techniques is to increase the immunity of the watermarked 3D-HEVC streams to attacks. Also, we propose a wavelet-based fusion technique to combine two depth watermark frames into one fused depth watermark frame. Then, the resultant fused depth watermark is encrypted using chaotic Baker map to increase the level of security. After that, the resultant chaotic encrypted fused depth watermark is embedded in the 3D-HEVC color frames using the proposed hybrid watermarking techniques to produce the watermarked 3D-HEVC streams. In addition to achieving multi-level security in the transmitted 3D-HEVC streams, the proposed hybrid techniques reduce the required bit rate for transmitting the color-plus-depth 3D-HEVC data over limited-bandwidth networks. The performance of the proposed hybrid techniques is compared with those of the state-of-the-art techniques. Extensive simulation results on standard 3D video sequences have been conducted in the presence of attacks. The obtained results confirm that the proposed hybrid fusion-encryption-watermarking techniques achieve not only a good perceptual quality with high Peak Signal-to-Noise Ratio (PSNR) values and less bit rate, but also high correlation coefficient values between the original and extracted watermarks in the presence of attacks. Furthermore, the proposed hybrid techniques improve the capacity of information embedding and the robustness without affecting the perceptual quality of the original 3D-HEVC frames. Indeed, the extraction of the encrypted, fused, primary, and secondary depth watermark frames is possible in the presence of attacks.
C1 [El-Shafai, Walid; El-Rabaie, El-Sayed M.; El-Halawany, M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM eng.waled.elshafai@gmail.com; elsayedelrabaie@gmail.com;
   mmohamedelhalawany@gmail.com; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Shafai, Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi N., 2014, LECT NOTES INFORM TH, V2, P151, DOI 10.12720/lnit.2.2.151-157
   [Anonymous], 2015, 12 LEARN TECHN C WEA
   [Anonymous], 2014, JOINT COLL TEAM 3D V
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2014, HEVC Reference Software HM 13.0
   [Anonymous], P IEEE INT S BROADB
   Bhimani J., 2017, 21 IEEE HIGH PERF EX
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Dutta T, 2013, NATL CONF COMMUN
   Esen E, 2011, IEEE T CIRC SYST VID, V21, P1130, DOI 10.1109/TCSVT.2011.2134770
   Franco-Contreras J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2761, DOI 10.1109/ICIP.2011.6116242
   Gao HJ, 2017, INT J ADV MANUF TECH, V93, P1473, DOI 10.1007/s00170-017-0528-2
   Gutub A, 2008, IEEE 5 INT WORKSH SI
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Joshi Amit M., 2016, P INT C DAT ENG COMM, P455
   Khalid Ahmad, 2017, Ph. D. Dissertation.
   KHAN F, 2007, 4 IEEE GCC C EXH, P5
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Noorkami M, 2005, IEEE IMAGE PROC, P1229
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ogawa K, 2015, I SYMP CONSUM ELECTR, P102, DOI 10.1109/ICCE.2015.7066337
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Qiu G, 2004, INT C PATT RECOG, P865
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang ZY, 2017, IEEE IPCCC
   Yang ZY, 2016, IEEE IPCCC
   Yaqing Niu, 2011, 2011 3rd European Workshop on Visual Information Processing, P211, DOI 10.1109/EuVIP.2011.6045546
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang J, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P46
NR 47
TC 29
Z9 30
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30911
EP 30937
DI 10.1007/s11042-018-6036-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600035
DA 2024-07-18
ER

PT J
AU Hu, JG
   Sun, ZX
   Sun, YH
   Shi, JL
AF Hu, Jiagao
   Sun, Zhengxing
   Sun, Yunhan
   Shi, Jinlong
TI Accumulative image categorization: a personal photo classification
   method for progressive collection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Online learning; Image clustering; Nearest class
   mean classifier; Progressive collection
ID ONLINE; SHAPE; SEGMENTATION; ANNOTATION; DISCOVERY; FEATURES; FUSION;
   MODELS
AB With the explosive growth of personal photos, an effective classification tool is becoming an urgent need to organize our progressive image collections. Facing the dynamically growing collections, we present a new method to categorize images effectively by integrating image clustering, incremental updating and user feedback together in an online framework. Considering the user burden and the user-specific preference during image classification, we propose several strategies to learn a customized classification model progressively for each user. Firstly, we use a multi-view learning method to learn the preferred classification perspective of the user. Secondly, we cluster similar images into groups according to user's preference, so that images in a group can be categorized simultaneously with high efficiency. Thirdly, we propose a multi-centroid nearest class mean classifier to online learn the user's preferred category granularity, and use it to classify the image groups. Unlike offline systems where pre-labeling and batch training often take hours or even days to perform, our approach is fully online. It can learn the classification model and classify newly acquired images alternately in no time. The sufficient experimental results and a user study demonstrate the effectiveness of the proposed method.
C1 [Hu, Jiagao; Sun, Zhengxing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Sun, Yunhan; Shi, Jinlong] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Peoples R China.
C3 Nanjing University; Jiangsu University of Science & Technology
RP Hu, JG (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM hujiagao@gmail.com
RI shi, jin/JCD-8826-2023; Sun, YunHan/AAD-7898-2020; shi,
   jin/KDO-7906-2024; Shi, JIn/JYP-1805-2024; Sun, Zhengxing/A-7411-2011
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; Innovation Fund of State Key Laboratory for Novel Software
   Technology [ZZKT2013A12, ZZKT2016A11]; Program for New Century Excellent
   Talents in University of China [NCET-04-04605]; Nanjing University
   Innovation and Creative Program for PhD candidate [2016013]
FX This work is supported by National High Technology Research and
   Development Program of China (No. 2007AA01Z334); National Natural
   Science Foundation of China (No. 61321491, 61272219); Innovation Fund of
   State Key Laboratory for Novel Software Technology (No. ZZKT2013A12,
   ZZKT2016A11); Program for New Century Excellent Talents in University of
   China (No. NCET-04-04605); Nanjing University Innovation and Creative
   Program for PhD candidate (No. 2016013).
CR Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   [Anonymous], MULTIMEDIA MODELING
   [Anonymous], 2011, P 19 ACM INT C MULTI
   Bergamo Alessandro., 2011, NIPS, P2088
   Biswas A, 2014, INT J COMPUT VISION, V108, P133, DOI 10.1007/s11263-013-0680-6
   Bruneau P, 2010, PATTERN RECOGN, V43, P485, DOI 10.1016/j.patcog.2009.03.024
   Bulò SR, 2016, PROC CVPR IEEE, P3985, DOI 10.1109/CVPR.2016.432
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Ciocca G, 2014, COMPUT VIS IMAGE UND, V122, P155, DOI 10.1016/j.cviu.2014.01.010
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Datta Piew., 1997, AAAI/IAAI, P82
   Dang-Nguyen DT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3103613
   Ebert Sandra., 2013, Computer Vision aAS ACCV 2012, volume 7724 of Lecture Notes in Computer Science, V7724, P232
   Faktor A, 2014, IEEE T PATTERN ANAL, V36, P1092, DOI 10.1109/TPAMI.2013.251
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Galleguillos C, 2014, INT J COMPUT VISION, V108, P115, DOI 10.1007/s11263-013-0679-z
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Grzeszick R, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550053
   Guntuku SC, 2016, IEEE T IMAGE PROCESS, V25, P3762, DOI 10.1109/TIP.2016.2576278
   Hoi SCH, 2013, MACH LEARN, V90, P289, DOI 10.1007/s10994-012-5319-2
   Hu JG, 2017, LECT NOTES COMPUT SC, V10114, P172, DOI 10.1007/978-3-319-54190-7_11
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin R, 2010, LECT NOTES ARTIF INT, V6331, P390
   Krizsan A, 2012, GENDER POLIT, P1
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li GR, 2015, NEUROCOMPUTING, V168, P327, DOI 10.1016/j.neucom.2015.05.093
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Lin L, 2018, IEEE T PATTERN ANAL, V40, P7, DOI 10.1109/TPAMI.2017.2652459
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Lovato P, 2014, IEEE T INF FOREN SEC, V9, P364, DOI 10.1109/TIFS.2014.2298370
   Lu ZW, 2010, LECT NOTES COMPUT SC, V6316, P1
   Lughofer E, 2018, IEEE T FUZZY SYST, V26, P292, DOI 10.1109/TFUZZ.2017.2654504
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Misra I, 2016, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2016.320
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678
   Royer A, 2015, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2015.7298746
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saffari A, 2010, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2010.5539937
   Shalev-Shwartz S, 2012, FOUND TRENDS MACH LE, V4, P107, DOI 10.1561/2200000018
   Shi ZY, 2017, IEEE T PATTERN ANAL, V39, P2525, DOI 10.1109/TPAMI.2016.2645157
   Shneiderman B, 2000, IEEE INFOR VIS, P88, DOI 10.1109/IV.2000.859742
   Song MF, 2015, COMPUT AIDED GEOM D, V35-36, P192, DOI 10.1016/j.cagd.2015.03.009
   Su Y, 2012, LECT NOTES COMPUT SC, V7585, P51, DOI 10.1007/978-3-642-33885-4_6
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wan J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2284
   Wu J, 2017, IEEE T MULTIMEDIA, V19, P1156, DOI 10.1109/TMM.2017.2652065
   Yuan Y, 2015, NEUROCOMPUTING, V168, P336, DOI 10.1016/j.neucom.2015.05.092
   Zhang FQ, 2015, COMPUT AIDED DESIGN, V58, P2, DOI 10.1016/j.cad.2014.08.008
   Zhang HW, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2637291
   Zhang JG, 2017, MULTIMEDIA SYST, V23, P63, DOI 10.1007/s00530-014-0416-7
   Zhu SH, 2016, NEUROCOMPUTING, V208, P136, DOI 10.1016/j.neucom.2016.02.072
NR 70
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32179
EP 32211
DI 10.1007/s11042-018-6152-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000030
DA 2024-07-18
ER

PT J
AU Huang, GH
   Pun, CM
AF Huang, Guoheng
   Pun, Chi-Man
TI On-line video multi-object segmentation based on skeleton model and
   occlusion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object segmentation; Skeleton model; Occlusion detection;
   Superpixel; On-line
ID SALIENCY DETECTION; REGIONS
AB In this work, we propose an approach for on-line video multi object segmentation based on skeleton model and occlusion detection. We consider the multi-object segmentation in every frame as a multi-class region merging based object segmentation. We then generate the initial object superpixels automatically using a skeleton model from the second frame. Moreover, we also propose an initial background superpixel prediction scheme. In case the occlusion to affect the final segmentation result, we propose an occlusion detection model based on optical flow. The experimental results show that our method is both robust in segmenting multi objects and efficient in execution time.
C1 [Huang, Guoheng] Guangdong Univ Technol, Sch Comp, Guangzhou, Guangdong, Peoples R China.
   [Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Taipa, Macau, Peoples R China.
C3 Guangdong University of Technology; University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Taipa, Macau, Peoples R China.
EM kevinwong@gdut.edu.cn; cmpun@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [093/2014/A2, 041/2017/A1]; project (2018-2020, Video Multi-object
   Co-segmentation Based on Superpixel, National Natural Science Foundation
   of China (NSFC)) [61702111]
FX This work was supported in part by the Research Committee of the
   University of Macau under Grants MYRG2015-00011-FST and
   MYRG2015-00012-FST, the Science and Technology Development Fund of Macau
   SAR under Grants 093/2014/A2 and 041/2017/A1, and the project
   (2018-2020, Video Multi-object Co-segmentation Based on Superpixel,
   National Natural Science Foundation of China (NSFC) Grant No. 61702111).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Brendel W, 2009, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2009.5459242
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dey TK, 2002, LECT NOTES COMPUT SC, V2461, P387
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Horn BertholdK.P., 1980, DETERMINING OPTICAL
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055
   Varas D, 2014, PROC CVPR IEEE, P3470, DOI 10.1109/CVPR.2014.444
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Willert V, 2005, LECT NOTES COMPUT SC, V3663, P9
   Xiaoyan Zhang, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P258, DOI 10.1109/ICCIS.2010.69
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
NR 27
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31313
EP 31329
DI 10.1007/s11042-018-6208-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600052
DA 2024-07-18
ER

PT J
AU Deng, C
   Song, JW
   Sun, RZ
   Cai, SH
   Shi, YX
AF Deng, Chao
   Song, Jinwei
   Sun, Ruizhi
   Cai, Saihua
   Shi, Yinxue
TI Gridwave: a grid-based clustering algorithm for market transaction data
   based on spatial-temporal density-waves and synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grid-based; Density-based; Data mining; Spatial-temporal clustering;
   Density-wave; Spatial-temporal synchronization; Market transaction data;
   Parallel computing
ID FAST SEARCH; DBSCAN; FIND
AB The notion of density has been widely used in many spatial-temporal (ST) clustering methods. This paper proposes the novel notion of an ST density-wave, which is an extension of the notion of density. It also presents a new grid-based ST clustering algorithm called Gridwave based on the notion of ST density-waves and ST synchronization. The proposed algorithm can be used to discover synchronized changes in density among various locations as well as distinguish ST events and noise from market transaction data. Based on the theory of small-world networks, our algorithm can be used to evaluate ST synchronized correlations among regions with respective to the ST density over the whole network. To improve its performance, the proposed algorithm was implemented using parallel computing. To verify its feasibility, a real large-scale market transaction dataset was used to demonstrate the ST synchronized correlations and the final clustering results. Although our algorithm is applied in a domain-specific case, we suggest that the clustering notion and method could be generalized for other domain applications with similar ST data.
C1 [Deng, Chao; Sun, Ruizhi; Cai, Saihua; Shi, Yinxue] China Agr Univ, Coll Informat & Elect Engn, 17 Tsinghua East Rd, Beijing, Peoples R China.
   [Deng, Chao] China Tobacco Guangxi Ind Co Ltd, 28 Beihu South Rd, Nanning, Peoples R China.
   [Song, Jinwei] Chinese Acad Sci, Natl Space Sci Ctr, 1 Nanertiao, Beijing, Peoples R China.
C3 China Agricultural University; China National Tobacco Corporation;
   Chinese Academy of Sciences; National Space Science Center, CAS
RP Sun, RZ (corresponding author), China Agr Univ, Coll Informat & Elect Engn, 17 Tsinghua East Rd, Beijing, Peoples R China.
EM sunruizhi@cau.edu.cn
OI Cai, Saihua/0000-0003-0743-1156
FU Chinese Universities Scientific Fund [2017XD001]; China Tobacco Guangxi
   Industrial Co., Ltd.
FX This work was supported in part by the Chinese Universities Scientific
   Fund, project number 2017XD001. The authors would also like to thank
   China Tobacco Guangxi Industrial Co., Ltd., for supporting this
   research.
CR Amaral LAN, 2000, P NATL ACAD SCI USA, V97, P11149, DOI 10.1073/pnas.200327197
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Bao-Zhi Qiu, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics (IEEE Cat. No. 05EX1059), P1509
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Birant D, 2007, DATA KNOWL ENG, V60, P208, DOI 10.1016/j.datak.2006.01.013
   Chen XY, 2008, INT CONF E BUS ENG, P780, DOI 10.1109/ICEBE.2008.54
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Gan JH, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P519, DOI 10.1145/2723372.2737792
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   Hinneburg A, 2007, LECT NOTES COMPUT SC, V4723, P70
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Huang DR, 2012, PHYSCS PROC, V24, P1166, DOI 10.1016/j.phpro.2012.02.174
   Kisilevich S, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P855, DOI 10.1007/978-0-387-09823-4_44
   Lee KM, 2017, WIRELESS PERS COMMUN, V93, P47, DOI 10.1007/s11277-016-3937-x
   Ma S, 2003, INT C WEB AG INF MAN, V2762, P2276
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Tsai CF, 2009, ELE COM ENG, P231
   Uncu O, 2006, IEEE SYS MAN CYBERN, P2976, DOI 10.1109/ICSMC.2006.384571
   Viswanath P, 2006, INT C PATT RECOG, P912
   Wang M, 2006, LECT NOTES ARTIF INT, V4093, P263
   Wang SL, 2016, CHINESE J ELECTRON, V25, P397, DOI 10.1049/cje.2016.05.001
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Zhou Shui-Geng, 2000, Journal of Software, V11, P735
   Zhu X., 2016, IEEE T NEURAL NETWOR, V26, P1263
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
NR 26
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29623
EP 29637
DI 10.1007/s11042-017-5441-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800024
DA 2024-07-18
ER

PT J
AU Gan, ZH
   Chai, XL
   Zhang, MH
   Lu, Y
AF Gan, Zhihua
   Chai, Xiuli
   Zhang, Miaohui
   Lu, Yang
TI A double color image encryption scheme based on three-dimensional
   brownian motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double color image encryption(DCIE); Three-dimensional (3D) Brownian
   motion; Confusion; Diffusion
ID CHAOTIC SYSTEM; FOURIER-TRANSFORM; ALGORITHM; MAP
AB Image encryption is an efficient technique for image protection. This paper presents a double color image encryption (DCIE) scheme based on three-dimensional (3D) Brownian motion. The architecture of diffusion, confusion and diffusion is adopted. The proposed algorithm firstly decomposes two color plain images into R, G, B components and bit planes, then conducts XOR operation between every bit plane and a key bit plane generated from carrier images; next, arranges all the bit planes into a 3D bit matrix, performs block-in 3D Brownian motion confusion and block confusion on it, which can permute the elements across bit planes and across plain images; finally, a subsequent diffusion process is utilized to improve the encryption effect. Simulation results and performance analyses illustrate that the proposed encryption scheme can simultaneously encrypt two color images into noise-like ones that have strong ability of resisting various known attacks.
C1 [Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli; Zhang, Miaohui] Henan Univ, Sch Comp & Informat Engn, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
   [Lu, Yang] Henan Univ, Res Dept, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Chai, XL (corresponding author), Henan Univ, Sch Comp & Informat Engn, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
EM gzhchai1980@126.com
OI chai, xiuli/0000-0001-5727-8933
FU Natural Science Foundation of China [41571417, U1604145, U1404618];
   National Science Foundation of the United States [CNS-1253424,
   ECCS-1202225]; Science and Technology Foundation of Henan Province of
   China [182102210027, 182102210238, 172102210186]; China Postdoctoral
   Science Foundation [2016M602235, 2015M582182]; Research Foundation of
   Henan University [xxjc20140006]
FX All the authors are deeply grateful to the editors for smooth and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant No. 41571417, U1604145 and U1404618),
   National Science Foundation of the United States (Grant No. CNS-1253424
   and ECCS-1202225), Science and Technology Foundation of Henan Province
   of China (Grant No. 182102210027, 182102210238, and 172102210186), China
   Postdoctoral Science Foundation (Grant No. 2016M602235 and 2015M582182)
   and the Research Foundation of Henan University (Grant No.
   xxjc20140006).
CR [Anonymous], DIGITAL IMAGE PROCES
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   Chen JX, 2014, OPT EXPRESS, V22, P7349, DOI 10.1364/OE.22.007349
   Di H, 2012, APPL OPTICS, V51, P1000, DOI 10.1364/AO.51.001000
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Li P, 2017, SOFT COMPUT, V21, P4349, DOI 10.1007/s00500-016-2066-5
   Lin C, 2012, OPT COMMUN, V285, P1023, DOI 10.1016/j.optcom.2011.10.046
   Liu JM, 2015, NONLINEAR DYNAM, V82, P2069, DOI 10.1007/s11071-015-2300-1
   Liu ZJ, 2013, OPT LASER TECHNOL, V47, P152, DOI 10.1016/j.optlastec.2012.09.007
   del Rey AM, 2016, EXPERT SYST APPL, V54, P379, DOI 10.1016/j.eswa.2016.02.001
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mohamed FK, 2014, OPT LASER TECHNOL, V64, P145, DOI 10.1016/j.optlastec.2014.05.012
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Shan MG, 2012, OPT COMMUN, V285, P4227, DOI 10.1016/j.optcom.2012.06.023
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Sui LS, 2015, OPT COMMUN, V354, P184, DOI 10.1016/j.optcom.2015.05.071
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wan YH, 2015, OPT COMMUN, V342, P95, DOI 10.1016/j.optcom.2014.12.044
   Wang Q, 2014, OPT COMMUN, V320, P12, DOI 10.1016/j.optcom.2014.01.041
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2016, OPT LASER ENG, V78, P8, DOI 10.1016/j.optlaseng.2015.09.008
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Wu JJ, 2016, OPT COMMUN, V359, P38, DOI 10.1016/j.optcom.2015.09.039
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu XJ, 2014, COMMUN NONLINEAR SCI, V19, P1884, DOI 10.1016/j.cnsns.2013.10.025
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu J, 2018, J NETW COMPUT APPL, V107, P113, DOI 10.1016/j.jnca.2018.01.014
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 52
TC 53
Z9 53
U1 0
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27919
EP 27953
DI 10.1007/s11042-018-5974-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500009
DA 2024-07-18
ER

PT J
AU He, LL
   Bai, HT
   Jiang, Y
   Ouyang, DT
   Jiang, SS
AF He, Lili
   Bai, Hongtao
   Jiang, Yu
   Ouyang, Dantong
   Jiang, Shanshan
TI Revised simplex algorithm for linear programming on GPUs with CUDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CUDA; GPU; Revised simplex algorithm; SIMD
ID SIMULATIONS; PERFORMANCE; IMPLEMENTATION
AB The revised simplex algorithm (RSA) is a typical algorithm for solving linear programming problems. Many theoretical modifications have been done to make the algorithm more efficient, but almost all of them were based on single-instruction single-data architecture processors (CPUs), which could not make full use of the inherent parallel characteristics of RSAs. We propose a novel single-instruction multiple-data architecture processor (GPU) based on the RSA in this paper. The intensive matrix manipulations of a traditional RSA are offloaded to the GPU, which helps to make full use of its powerful parallel processing ability. We implemented the GPU-based RSA on compute unified device architecture (CUDA). Numerical experiments on randomly generated linear programs show that the GPU-based RSA can not only find the correct optimal solutions, but can also reach a speed of up to 100 times as fast as that of a CPU-based RSA: it also runs 3 to 11 times as fast as MATLAB.
C1 [He, Lili; Bai, Hongtao; Jiang, Yu; Ouyang, Dantong; Jiang, Shanshan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Bai, Hongtao] Jilin Univ, Ctr Comp Fundamental Educ, Changchun 130012, Jilin, Peoples R China.
   [He, Lili; Bai, Hongtao; Jiang, Yu; Ouyang, Dantong; Jiang, Shanshan] Jilin Univ, Minist Educ, Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Bai, HT; Jiang, Y; Ouyang, DT (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Bai, HT (corresponding author), Jilin Univ, Ctr Comp Fundamental Educ, Changchun 130012, Jilin, Peoples R China.; Bai, HT; Jiang, Y; Ouyang, DT (corresponding author), Jilin Univ, Minist Educ, Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
EM baihongtao@263.net; jiangyuyou@126.com; ouyd@jlu.edu.cn
FU National Natural Science Foundation of China [51679105,
   61672261,51409117]; Jilin Province Department of Education Thirteen Five
   science and technology research projects [432, JJKH20170804KJ]
FX This work was supported in part by the National Natural Science
   Foundation of China (51679105, 61672261,51409117), Jilin Province
   Department of Education Thirteen Five science and technology research
   projects [2016] No. 432, [2017] No. JJKH20170804KJ.
CR Anderson JA, 2008, J COMPUT PHYS, V227, P5342, DOI 10.1016/j.jcp.2008.01.047
   [Anonymous], 9 INT C COMP AID DES
   Belleman RG, 2008, NEW ASTRON, V13, P103, DOI 10.1016/j.newast.2007.07.004
   Belloch JA, 2015, EXPERT SYST APPL, V42, P5607, DOI 10.1016/j.eswa.2015.02.056
   Demirel E, 2016, J CLEAN PROD, V112, P2101, DOI 10.1016/j.jclepro.2014.10.079
   Ezzati R, 2015, APPL MATH MODEL, V39, P3183, DOI 10.1016/j.apm.2013.03.014
   Fu Z., 2015, ENABLING PERSONALIZE, VPP, P1
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gobron S, 2007, MACH VISION APPL, V18, P331, DOI 10.1007/s00138-006-0065-8
   Guastaroba G, 2016, EUR J OPER RES, V251, P938, DOI 10.1016/j.ejor.2015.11.037
   Ho TY, 2008, PATTERN RECOGN, V41, P2684, DOI 10.1016/j.patcog.2008.01.018
   Jermain CL, 2016, J MAGN MAGN MATER, V401, P320, DOI 10.1016/j.jmmm.2015.10.054
   Leung CS, 2006, IEEE T IMAGE PROCESS, V15, P1031, DOI 10.1109/TIP.2005.863936
   Liu WG, 2007, LECT NOTES COMPUT SC, V4873, P185
   Liu W, 2007, IEEE T PARALL DISTR, V18, P1270, DOI 10.1109/TPDS.2007.1069
   Luh H, 2002, COMPUT OPER RES, V29, P195, DOI 10.1016/S0305-0548(00)00069-1
   Marziale L, 2007, DIGIT INVEST, V4, pS73, DOI 10.1016/j.diin.2007.06.014
   Melo D, 2016, PROCEDIA COMPUT SCI, V80, P951, DOI 10.1016/j.procs.2016.05.389
   Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Paparrizos K, 2003, COMPUT OPER RES, V30, P1383, DOI 10.1016/S0305-0548(02)00077-1
   Peercy M., 2006, SIGGRAPH 06 ACM SIGG, P184
   Qi HF, 2015, COMPUT OPTIM APPL, V60, P587, DOI 10.1007/s10589-014-9689-1
   Richter C, 2016, MATH INDUST, V23, P83, DOI 10.1007/978-3-319-30399-4_9
   Rocha P, 2015, OPERATIONS RES BIG D, P195
   Sanders J, 2010, CUDA EXAMPLE INTRO G
   Vieira H, 2005, COMPUT OPER RES, V32, P1983, DOI 10.1016/j.cor.2004.01.002
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Zhong ZC, 2015, 2015 INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC), P349, DOI 10.1109/ICNISC.2015.108
NR 29
TC 6
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30035
EP 30050
DI 10.1007/s11042-018-5947-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800049
DA 2024-07-18
ER

PT J
AU Ji, X
   Fang, X
   Shim, SH
AF Ji, Xu
   Fang, Xin
   Shim, Seung-Hyun
TI Design and development of a maintenance and virtual training system for
   ancient Chinese architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; BIM; Virtual display system; Ancient Chinese
   architecture
AB Ancient Chinese architecture is an important aspect of traditional Chinese culture and has been studied by many scholars around the world via historical documents, photographs, and three-dimensional models. In this paper, a building information model (BIM) and virtual reality (VR) and video analysing technology are used to develop a maintenance and virtual training system for ancient architecture. A digital ancient architecture model that includes a three-dimensional model and attributes is established, and the model can be visualized using a VR video processing system. Based on this system, we propose a method of fire detection in the maintenance system to ensure the safety of ancient buildings. After performing lightweight processing of the three-dimensional model, the Forge platform, which can achieve high-speed browsing via Web browsers, is used to perform the virtual construction, dismantling and other functions. By providing an immersive experience, users will develop a deeper understanding of ancient architectural structures and construction processes, which will accelerate research on ancient architecture.
C1 [Ji, Xu] Bengbu Univ, Dept Art Design, Bengbu 233030, Peoples R China.
   [Fang, Xin] Anhui Normal Univ, Wanjiang Coll, Dept Visual Art, Wuhu 241000, Peoples R China.
   [Shim, Seung-Hyun] Hanseo Univ, Dept Architecture, Chungnam 356706, South Korea.
C3 Bengbu University; Anhui Normal University; Hanseo University
RP Shim, SH (corresponding author), Hanseo Univ, Dept Architecture, Chungnam 356706, South Korea.
EM elder.jixu@outlook.com; fangxin201718@163.com; SeungHyunShim@outlook.com
RI fang, xin/JDW-3194-2023
OI fang, xin/0000-0001-9816-8466
CR [Anonymous], 2013, DEV MULTIDIMENSIONAL, DOI DOI 10.1007/978-3-642-36379-5_14
   Biljecki F, 2016, COMPUT ENVIRON URBAN, V59, P25, DOI 10.1016/j.compenvurbsys.2016.04.005
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Dehua P, 2011, DOUGONG
   Dore C, 2015, INT ARCH PHOTOGRAMM, V40-5, P351, DOI 10.5194/isprsarchives-XL-5-W4-351-2015
   Eastman C.M., 2008, BIM Handbook: A Guide to Building Information Modeling for Owners, Managers, Designers, Engineers and Contractors
   Francesco F, 2006, 3 INT C AUGM REAL VI, P139
   Fukuda T, 2015, ECAADE 2015: REAL TIME - EXTENDING THE REACH OF COMPUTATION, VOL 1, P665
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Kawamura T, 2012, P 8 INT C SEM SYST, P189
   Murphy Maurice, 2009, Structural Survey, V27, P311, DOI 10.1108/02630800910985108
   Murphy M, 2013, ISPRS J PHOTOGRAMM, V76, P89, DOI 10.1016/j.isprsjprs.2012.11.006
   Sicheng L, 2007, CHINESE ARCHITECTURA
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Volk R, 2014, AUTOMAT CONSTR, V38, P109, DOI 10.1016/j.autcon.2013.10.023
   Yan Yunyang, 2014, Journal of Frontiers of Computer Science and Technology, V8, P1271, DOI 10.3778/j.issn.1673-9418.1405037
   Yongfu T, 2012, CHINESE ANTIQUE ARCH
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
NR 21
TC 6
Z9 7
U1 7
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29367
EP 29382
DI 10.1007/s11042-018-5979-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800010
DA 2024-07-18
ER

PT J
AU Jian, MW
   Yin, YL
   Dong, JY
   Lam, KM
AF Jian, Muwei
   Yin, Yilong
   Dong, Junyu
   Lam, Kin-Man
TI Content-based image retrieval via a hierarchical-local-feature
   extraction scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network big data; Content-based image retrieval; Perception-based
   directional patch; Salient patch detection
ID PARTICLE SWARM OPTIMIZATION; SALIENCY DETECTION; SEGMENTATION;
   FRAMEWORK; REPRESENTATION; ALGORITHM; WAVELETS; REGIONS; FUSION
AB Recently, with the development of various camera sensors and internet network, the volume of digital images is becoming big. Content- based image retrieval ( CBIR), especially in network big data analysis, has attracted wide attention. CBIR systems normally search the most similar images to the given query example among a wide range of candidate images. However, human psychology suggests that users concern more about regions of their interest and merely want to retrieve images containing relevant regions, while ignoring irrelevant image areas ( such as the texture regions or background). Previous CBIR system on userinterested image retrieval generally requires complicated segmentation of the region from the background. In this paper, we propose a novel hierarchical- local- feature extraction scheme for CBIR, whereas complex image segmentation is avoided. In our CBIR system, a perceptionbased directional patch extraction method and an improved salient patch detection algorithm are proposed for local features extraction. Then, color moments and Gabor texture features are employed to index the salient regions. Extensive experiments have been performed to evaluate the performance of the proposed scheme, and experimental results show that the developed CBIR system produces plausible retrieval results.
C1 [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Software Engn, Jinan 250101, Shandong, Peoples R China.
   [Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University; Ocean
   University of China; Hong Kong Polytechnic University
RP Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
EM jiamnuweihk@163.com
RI Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China (NSFC) [61601427, 61602229,
   61771230]; Natural Science Foundation of Shandong Province [ZR2015FQ011,
   ZR2016FM40]; Shandong Provincial Key Research and Development Program of
   China [2017CXGC0701]; Fostering Project of Dominant Discipline and
   Talent Team of Shandong Province Higher Education Institutions
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61601427, 61602229, 61771230); Natural Science Foundation of
   Shandong Province (ZR2015FQ011, ZR2016FM40); Shandong Provincial Key
   Research and Development Program of China (NO. 2017CXGC0701); Fostering
   Project of Dominant Discipline and Talent Team of Shandong Province
   Higher Education Institutions.
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 1997, PHYS CHEMESTRY EMGIN, DOI DOI 10.1121/1.418074
   [Anonymous], GROUND TRUTH DAT DEP
   [Anonymous], 2018, AAAI
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2003, MULTIMEDIA INFORM RE
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Elleuch N, 2015, MULTIMED TOOLS APPL, V74, P1397, DOI 10.1007/s11042-014-1955-9
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fauqueur J, 2004, J VISUAL LANG COMPUT, V15, P69, DOI 10.1016/j.jvlc.2003.08.002
   Fauqueur J, 2002, REGION BASED RETRIEV
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gouet V, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P30, DOI 10.1109/IVL.2001.990853
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2194
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2009, J COMPUT, V4, P763
   Jiji GW, 2015, APPL SOFT COMPUT, V30, P650, DOI 10.1016/j.asoc.2015.01.058
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Lau HF, 2002, PATTERN RECOGN, V35, P2323, DOI 10.1016/S0031-3203(01)00230-8
   Liu F, 2015, NEUROCOMPUTING, V168, P599, DOI 10.1016/j.neucom.2015.05.065
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Muwei J, 2007, 8 ACIS INT C SNPD, P713
   Pavlidis T., 2008, ICPR
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012
   Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7
   Sebe N, 2001, IEEE C COMP VIS PATT
   Shen LL, 2008, MED IMAGE ANAL, V12, P375, DOI 10.1016/j.media.2007.12.004
   Sudhakar MS, 2014, APPL SOFT COMPUT, V22, P492, DOI 10.1016/j.asoc.2014.04.029
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
   Tsai HH, 2014, APPL SOFT COMPUT, V17, P127, DOI 10.1016/j.asoc.2013.12.003
   Vieux R, 2012, LECT NOTES COMPUT SC, V7131, P507
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xu YY, 2016, NEUROCOMPUTING, V171, P826, DOI 10.1016/j.neucom.2015.07.024
   Yang M, 2015, NEUROCOMPUTING, V168, P70, DOI 10.1016/j.neucom.2015.06.013
   Zhu YY, 2017, INFORM SCIENCES, V375, P246, DOI 10.1016/j.ins.2016.09.021
   Zhu ZX, 2015, INFORM SCIENCES, V298, P274, DOI 10.1016/j.ins.2014.11.045
NR 52
TC 24
Z9 24
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29099
EP 29117
DI 10.1007/s11042-018-6122-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500056
DA 2024-07-18
ER

PT J
AU Liu, Y
   Guo, YM
   Georgiou, T
   Lew, MS
AF Liu, Yu
   Guo, Yanming
   Georgiou, Theodoros
   Lew, Michael S.
TI Fusion that matters: convolutional fusion networks for visual
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep fusion networks; Locally-connected fusion; Image-level recognition;
   Pixel-level recognition; Transferring deep features
AB In recent years, deep learning has been successfully applied to diverse multimedia research areas, with the aim of learning powerful and informative representations for a variety of visual recognition tasks. In this work, we propose convolutional fusion networks (CFN) to integrate multi-level deep features and fuse a richer visual representation. Despite recent advances in deep fusion networks, they still have limitations due to expensive parameters and weak fusion modules. Instead, CFN uses 1 x 1 convolutional layers and global average pooling to generate side branches with few parameters, and employs a locally-connected fusion module, which can learn adaptive weights for different side branches and form a better fused feature. Specifically, we introduce three key components of the proposed CFN, and discuss its differences from other deep models. Moreover, we propose fully convolutional fusion networks (FCFN) that are an extension of CFN for pixel-level classification applied to several tasks, such as semantic segmentation and edge detection. Our experiments demonstrate that CFN (and FCFN) can achieve promising performance by consistent improvements for both image-level and pixel-level classification tasks, compared to a plain CNN. We release our codes on https://github.com/yuLiu24/CFN. Also, we make a live demo (goliath.liacs.nl) using a CFN model trained on the ImageNet dataset.
C1 [Liu, Yu; Guo, Yanming; Georgiou, Theodoros; Lew, Michael S.] Leiden Univ, Leiden Inst Adv Comp Sci, Niels Bohrweg 1, Leiden, Netherlands.
C3 Leiden University - Excl LUMC; Leiden University
RP Liu, Y (corresponding author), Leiden Univ, Leiden Inst Adv Comp Sci, Niels Bohrweg 1, Leiden, Netherlands.
EM y.liu@liacs.leidenuniv.nl; y.guo@liacs.leidenuniv.nl;
   t.k.georgiou@liacs.leidenuniv.nl; m.s.lew@liacs.leidenuniv.nl
FU LIACS Media Lab at Leiden University; China Scholarship Council
FX This work was supported mainly by the LIACS Media Lab at Leiden
   University and in part by the China Scholarship Council. We would like
   to thank NVIDIA for the donation of GPU cards.
CR Agrawal P, 2014, ANAL PERFORMANCE MUL
   [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2013, INT C NEURAL INFORM
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], 2015, P INT C COMP VIS ICC
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2016, BRIT MACH VIS C BMVC
   [Anonymous], 2008, IND C COMP VIS GRAPH
   [Anonymous], 2006, PROC IEEE C COMPUTER
   [Anonymous], ARXIV10060448 CORR
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2016, AAAI
   [Anonymous], P ACM INT C MULT RET
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], 2014, ECCV
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2009, Technical report
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2016, ARXIV160207261 CORR
   [Anonymous], INT C MULT MOD MMM
   [Anonymous], 2006, P IEEE COMPUTER SOC
   [Anonymous], 2015, ICLR
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 2015, INT C LEARN REPR ICL
   [Anonymous], P 5 ACM INT C MULT R
   [Anonymous], MULTIPLE HIERARCHICA
   [Anonymous], 2016, NEURAL INFORM PROCES
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2014, P EUR C COMP VIS ECC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], 2015, 2015 NEURAL INFORM P
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2014, P 22 ACM INT C MULT
   [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   De Brabandere Bert., 2016, Neural Information Processing Systems (NIPS)
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S., 2015, arXiv: Learning
   Jin XX, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901353
   Kim Jin-Hwa, 2016, Neural Information Processing Systems
   Krizhevsky A., 2012, NEURAL INFORM PROCES, V78, P523
   Lee C.Y., 2015, AISTATS
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu Y, 2016, IEEE CONF COMPUT
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Ou XY, 2017, MULTIMED TOOLS APPL, V76, P21281, DOI 10.1007/s11042-016-4057-z
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen WL, 2015, IEEE INFOCOM SER
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Yue-Hei Ng J, 2015, P IEEE C COMP VIS PA
NR 68
TC 14
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29407
EP 29434
DI 10.1007/s11042-018-5691-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800013
OA Green Published
DA 2024-07-18
ER

PT J
AU Alsmirat, MA
   Sarhan, NJ
AF Alsmirat, Mohammad A.
   Sarhan, Nabil J.
TI Cross-layer optimization for many-to-one wireless video streaming
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bandwidth allocation; Cross-layer optimization; Effective airtime
   estimation; Video streaming; Wireless networks; WLAN
ID SCALABLE VIDEO; PERFORMANCE ANALYSIS; RESOURCE-ALLOCATION;
   COMMUNICATION; NETWORKS; CAPACITY; EFFICIENCY; DELAY; MODEL
AB This paper develops a cross-layer optimization solution for video streaming from multiple sources to a central proxy station over a wireless network. The proposed solution manages the application rates and transmission opportunities of various video sources based on the dynamic network conditions in such a way that minimizes the overall video distortion. The solution includes a new online approach for estimating the effective network airtime and a new video bitrate-distortion model. We demonstrate the effectiveness of the proposed solution through extensive experiments. The results show that the proposed solution substantially enhances the perceptual video quality while reducing the power consumed by the video sources and that the solution is highly adaptable to the existence of interfering network traffic.
C1 [Alsmirat, Mohammad A.] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
   [Sarhan, Nabil J.] Wayne State Univ, Dept Elect & Comp Engn, Detroit, MI 48202 USA.
C3 Jordan University of Science & Technology; Wayne State University
RP Alsmirat, MA (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
EM masmirat@just.edu.jo; nabil@wayne.edu
OI Alsmirat, Mohammad/0000-0002-1071-7713; Sarhan,
   Nabil/0000-0002-0527-5666
CR Andreopoulos Y, 2006, IEEE J SEL AREA COMM, V24, P2104, DOI 10.1109/JSAC.2006.881614
   Budzisz L, 2014, IEEE COMMUN SURV TUT, V16, P2259, DOI 10.1109/COMST.2014.2329505
   Cheng WY, 2006, IEEE IMAGE PROC, P2473, DOI 10.1109/ICIP.2006.312778
   Chou CT, 2005, IEEE INFOCOM SER, P1584
   Cicalò S, 2014, IEEE T MULTIMEDIA, V16, P848, DOI 10.1109/TMM.2014.2300442
   Deng R, 2015, IEEE T MULTIMEDIA, V17, P1495, DOI 10.1109/TMM.2015.2456506
   Fu WH, 2013, IEEE T MOBILE COMPUT, V12, P136, DOI 10.1109/TMC.2011.247
   Ge Y, 2007, COMPUT NETW, V51, P1955, DOI 10.1016/j.comnet.2006.07.018
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P590, DOI 10.1109/TCSVT.2006.873154
   Hsu CH, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870126
   Huang J., 2006, P 15 INT PACK VID WO, P1
   Hui J, 2005, IEEE T COMMUN, V53, P1498, DOI 10.1109/TCOMM.2005.855013
   Khan S, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1580942
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Laufer R, 2016, IEEE ACM T NETWORK, V24, P1518, DOI 10.1109/TNET.2015.2415465
   Li CL, 2014, IEEE T CIRC SYST VID, V24, P1170, DOI 10.1109/TCSVT.2014.2302517
   Li ZN, 2014, TEXTS COMPUT SCI, P1, DOI 10.1007/978-3-319-05290-8
   Lu XA, 2003, IEEE J SEL AREA COMM, V21, P1738, DOI 10.1109/JSAC.2003.815682
   Mao GQ, 2013, IEEE T WIREL COMMUN, V12, P3883, DOI 10.1109/TWC.2013.-71113.121276
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Sarr C, 2008, IEEE T MOBILE COMPUT, V7, P1228, DOI 10.1109/TMC.2008.41
   Shah SH, 2005, MOBILE NETW APPL, V10, P199, DOI 10.1023/B:MONE.0000048555.72514.9a
   Sharrab Y, 2013, ACM MULTIMEDIA SYSTE
   Shirani S, 2000, IEEE T IMAGE PROCESS, V9, P1292, DOI 10.1109/83.847842
   Su GM, 2016, WIREL NETW, V22, P1571, DOI 10.1007/s11276-015-1028-7
   van der Schaar M, 2006, IEEE T MOBILE COMPUT, V5, P755, DOI 10.1109/TMC.2006.81
   Xiong L, 2007, COMPUT NETW, V51, P3047, DOI 10.1016/j.comnet.2007.01.002
   Yang Z., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P147, DOI 10.1145/1065983.1066017
   Yang Z, 2013, IEEE T CIRC SYST VID, V23, P212, DOI 10.1109/TCSVT.2012.2203216
   Ye Y, 2014, IEEE WIREL COMMUN, V21, P62, DOI 10.1109/MWC.2014.6882297
   Zhang HH, 2010, IEEE J SEL AREA COMM, V28, P344, DOI 10.1109/JSAC.2010.100406
   Zhao MC, 2015, IEEE T CIRC SYST VID, V25, P451, DOI 10.1109/TCSVT.2014.2357094
   Zhou L, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886776
   Zhou L, 2013, IEEE J SEL AREA COMM, V31, P981, DOI 10.1109/JSAC.2013.130516
NR 36
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24789
EP 24811
DI 10.1007/s11042-018-5698-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400010
DA 2024-07-18
ER

PT J
AU Dash, B
   Rup, S
   Mohapatra, A
   Majhi, B
   Swamy, MNS
AF Dash, Bodhisattva
   Rup, Suvendu
   Mohapatra, Anjali
   Majhi, Banshidhar
   Swamy, M. N. S.
TI Multi-resolution extreme learning machine-based side information
   estimation in distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding (DVC); Transform domain wyner-ziv video coding
   (TDWZ); Discrete wavelet transform (DWT); Side information (SI); Extreme
   machine learning (ELM); Structural similarity index (SSIM);
   Rate-distortion (RD)
ID MANY-CORE PROCESSORS; MOTION ESTIMATION; PARALLEL FRAMEWORK; CODEC;
   NETWORKS; DECODER; IMAGES
AB Context: Encoding of video frames in a traditional video coding architecture involves exhaustive computations due to the motion estimation (ME) task. Hence, it requires a considerable amount of computing aid, battery power, and resource memory. These codecs are not effective and reliable for applications like surveillance systems, wireless sensor networks, wireless camcorders, having scarcity in the availability of resources and computing ability. Therefore, in such scenarios, distributed video coding (DVC) represents a viable solution for power-constrained hand-held devices. DVC empowers the adaptability in distributing the complexity between the encoder and the decoder. Objective: Like any other building block, the decoder driven side information (SI) generation module plays a key role in a DVC codec. The efficacy of a DVC codec firmly relies on the quality of the SI generated at the decoder. SI is considered to be the facsimile of the original Wyner-Ziv (WZ) frame. Hence, the superior the quality of SI, improved is the efficiency of the codec. The primary objective of the present work is to enhance the quality of the SI frame so that the overall performance of the DVC is improved. To achieve this objective, this article deals with a hybrid SI generation scheme utilizing the principles of discrete wavelet transform (DWT) and extreme learning machine (ELM) algorithm in a transform domain-based DVC framework. Results: Exhaustive simulations have been carried out for some standard video sequences with the proposed and benchmark schemes. The proposed scheme is evaluated with respect to different performance metrics such as rate-distortion (RD), SI peak-signal-to- noise-ratio (PSNR) vs frame number, number of parity requests per SI frame, and so on. Experimental results and its analyses corroborate that the performance of the proposed technique surpasses as that of the benchmark schemes.
C1 [Dash, Bodhisattva; Rup, Suvendu; Mohapatra, Anjali] Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, Odisha, India.
   [Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Res Lab, Rourkela 769004, Odisha, India.
   [Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 International Institute of Information Technology, Bhubaneswar; National
   Institute of Technology (NIT System); National Institute of Technology
   Rourkela; Concordia University - Canada
RP Dash, B (corresponding author), Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, Odisha, India.
EM bdash.fac@gmail.com
RI Rup, Suvendu/AAQ-6535-2021
OI Rup, Suvendu/0000-0002-9407-0469
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Abou-Elailah A, 2013, IEEE T CIRC SYST VID, V23, P158, DOI 10.1109/TCSVT.2012.2203211
   [Anonymous], 2003, METHODS MULTIVARIATE
   [Anonymous], 2007, PICT COD S PCS 07
   Ascenso J, 2006, IEEE IMAGE PROC, P605, DOI 10.1109/ICIP.2006.312408
   Ascenso J, 2010, MULTIMED TOOLS APPL, V48, P381, DOI 10.1007/s11042-009-0316-6
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Ciuti Gastone, 2011, IEEE Rev Biomed Eng, V4, P59, DOI 10.1109/RBME.2011.2171182
   Dash B, 2017, MULTIMED TOOLS APPL, P1
   Deligiannis N, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530279
   Dufaux F, 2010, EURASIP J IMAGE VIDE, V2009, P508
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Gurav P, 2016, J ELECT COMMUN SYS, V1
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2003, IEEE T NEURAL NETWOR, V14, P274, DOI 10.1109/TNN.2003.809401
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang X, 2011, MICROSC MICROANAL, V17, P197, DOI 10.1017/S1431927610094456
   Luong HV, 2014, IEEE T IMAGE PROCESS, V23, P2804, DOI 10.1109/TIP.2014.2320364
   Luong HV, 2012, IEEE T IMAGE PROCESS, V21, P4782, DOI 10.1109/TIP.2012.2215621
   Jia Y, 2015, MULTIMED TOOLS APPL, V74, P1777, DOI 10.1007/s11042-013-1718-z
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Li R, 2016, IEICE T INF SYST, VE99D, P208, DOI 10.1587/transinf.2015EDP7027
   Liu W, 2010, IEEE T CIRC SYST VID, V20, P1863, DOI 10.1109/TCSVT.2010.2090424
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Martins R, 2010, IET IMAGE PROCESS, V4, P28, DOI 10.1049/iet-ipr.2008.0133
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Thao NTH, 2016, PROC INT CONF ADV, P339, DOI 10.1109/ATC.2016.7764802
   Ortega J.M., 1987, Matrix theory. The University Series in Mathematics
   Pereira F, 2009, DISTRIBUTED SOURCE CODING: THEORY, ALGORITHMS, AND APPLICATIONS, P189, DOI 10.1016/B978-0-12-374485-2.00013-5
   Petrazzuoli G., 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, P2342, DOI 10.1109/ICASSP.2010.5496075
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Qing LB, 2014, IEEE MULTIMEDIA, V21, P84, DOI 10.1109/MMUL.2014.48
   Rup S, 2013, OPTIK, V124, P4929, DOI 10.1016/j.ijleo.2013.03.152
   Rupa S, 2014, AEU-INT J ELECTRON C, V68, P201, DOI 10.1016/j.aeue.2013.08.005
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tagliasacchi M, 2006, IEEE IMAGE PROC, P593, DOI 10.1109/ICIP.2006.312405
   Taieb MH, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-168
   Varodayan D, 2008, SIGNAL PROCESS-IMAGE, V23, P369, DOI 10.1016/j.image.2008.04.009
   VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang YB, 2012, J VIS COMMUN IMAGE R, V23, P229, DOI 10.1016/j.jvcir.2011.10.001
NR 50
TC 2
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27301
EP 27335
DI 10.1007/s11042-018-5921-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500048
DA 2024-07-18
ER

PT J
AU Luo, DZ
   Wen, GH
   Li, DY
   Hu, Y
   Huan, EY
AF Luo, Dazhi
   Wen, Guihua
   Li, Danyang
   Hu, Yang
   Huan, Eryang
TI Deep-learning-based face detection using iterative bounding-box
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-view face detection; Cascade classifier; Face
   localization; Deep convolution neural network
ID RECOGNITION
AB Multi-view face detection in open environments is a challenging task due to the diverse variations of face appearances and occlusion. In the task of face detection, localization accuracy is one of the key factors. However, many of the existing methods do not pay enough attention to localization. Some of the current methods have applied localization techniques, but they have not fully realized its potential and realized more accurate localization. In this paper, we propose a deep cascaded detection method that iteratively exploits bounding-box regression, a localization technique, to approach the detection of potential faces in images. In addition, we consider the inherent correlation of classification and bounding-box regression and exploit it to further increase overall performance. In particular, our method leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict the existence of faces. Extensive experiments demonstrate the efficiency of our algorithm by comparing it with several popular face-detection algorithms on the widely used AFW and FDDB datasets.
C1 [Luo, Dazhi; Li, Danyang; Hu, Yang; Huan, Eryang] South China Univ Technol, Dept Comp Sci & Technol, Guangzhou, Guangdong, Peoples R China.
   [Wen, Guihua] South China Univ Technol, Sch Comp Sci & Technol, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Luo, DZ (corresponding author), South China Univ Technol, Dept Comp Sci & Technol, Guangzhou, Guangdong, Peoples R China.
EM luodazhi93@qq.com; 1102221491@qq.com; danyangedu@163.com;
   1132747923@qq.com; 2073119629@qq.com
RI li, danyang/HHS-3319-2022; Li, Dan/HJA-0406-2022
OI Hu, Yang/0000-0002-4856-5014
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], SURVEY FACE DETECTIO
   [Anonymous], PROC CVPR IEEE
   [Anonymous], FDDB BENCHMARK FACE
   [Anonymous], 2015, COMPUTER VISION PATT
   [Anonymous], MULTIVIEW FACE DETEC
   [Anonymous], 2014, DENSENET IMPLEMENTIN
   [Anonymous], ECCV WORKSH FAC DET
   Cellerino A, 2004, BRAIN RES BULL, V63, P443, DOI 10.1016/j.brainresbull.2004.03.010
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Felzenszwalb P., 2008, IEEE COMPUTER SOC C
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518
   Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   MARKU N, 2013, COMPUTER SCI, V14, P2657
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M, 2014, ACMIEEE INT CONF HUM, P390, DOI 10.1145/2559636.2566688
   Ramesha KBRK, 2010, International Journal on Computer Science and Engineering, V2, P14
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Yang H, 2014, CERAM INT, V40, P13903, DOI 10.1016/j.ceramint.2014.05.109
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 38
TC 7
Z9 8
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24663
EP 24680
DI 10.1007/s11042-018-5658-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400005
DA 2024-07-18
ER

PT J
AU Wang, HQ
   Zhu, HJ
   Zhao, Z
   Zhao, YF
   Wang, JH
AF Wang, Huiquan
   Zhu, Haojie
   Zhao, Zhe
   Zhao, Yanfeng
   Wang, Jinhai
TI The study on increasing the identification accuracy of waxed apples by
   hyperspectral imaging technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Correlation analysis; Classification; Waxed apples
ID FOOD SAFETY; BRUISES
AB Hyperspectral imaging technology is applied to nondestructive quality determination of agricultural and food products. It has a greater advantage of combining spatial image and spectral measurement which can determine both external and internal quality of the product. To increase the classification accuracy and stability of the prediction model, the spectral correlation analysis of each pixel was used to determine quality of the sample's hyperspectral image in this study. 400 hyperspectral image ROIs were extracted from 40 apples (20 apples with waxed and the other 20 apples without any waxed) were studied. Two effective wavelengths (806.85 nm, 1073.97 nm) were screened by spectral correlation analysis of pixels in 7 peak wave bands (639.90 nm, 806.85 nm, 973.80 nm, 1073.97 nm, 1197.99 nm, 1269.54 nm, 1441.26 nm). When the spectral correlation degree is less than 0.9 among all the pixels in the same sample, this sample data should be eliminated before inputting into the model training group. The least squares support vector machine (LS-SVM) model and BP neural network were used to establish the classification model between the hyperspectral image and waxed situation. The prediction result showed the classification accuracy was increased from 82% to 100% when the low-quality sample data for training were filtered by spectral correlation analysis. By evaluating the quality of the hyperspectral image measured, more reliable prediction results can be obtained, which can make the noninvasive discrimination of food safety come to the practice application sooner.
C1 [Wang, Huiquan; Zhu, Haojie; Zhao, Zhe; Zhao, Yanfeng; Wang, Jinhai] Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, Peoples R China.
   [Wang, Huiquan; Wang, Jinhai] Tianjin Med Elect Treating Technol Engn Ctr, Tianjin 300387, Peoples R China.
   [Zhao, Zhe] Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Zhao, Z; Wang, JH (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, Peoples R China.; Wang, JH (corresponding author), Tianjin Med Elect Treating Technol Engn Ctr, Tianjin 300387, Peoples R China.; Zhao, Z (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, Peoples R China.
EM huiquan85@126.com; zhaozhe@tjpu.edu.cn; tjpubme@126.com
FU Tianjin Application Basis & Front Technology Study Programs
   [14JCZDJC33100]; Chinese Postdoctoral Science Foundation [61]
FX The authors gratefully acknowledge the support from the Tianjin
   Application Basis & Front Technology Study Programs (No. 14JCZDJC33100)
   & Chinese Postdoctoral Science Foundation No.61.
CR [Anonymous], 2008, Sensing and Instrumentation for Food Quality and Safety, DOI DOI 10.1007/S11694-008-9039-Z
   Bao Yi-dan, 2015, Optics and Precision Engineering, V23, P349, DOI 10.3788/OPE.20152302.0349
   Baranowski P, 2012, J FOOD ENG, V110, P345, DOI 10.1016/j.jfoodeng.2011.12.038
   Cao F, 2011, SPECTROSC SPECT ANAL, V31, P920, DOI 10.3964/j.issn.1000-0593(2011)04-0920-04
   Cheng B, 2013, J DAQING NORMAL U, V33, P35
   DULL GG, 1989, J FOOD SCI, V54, P393, DOI 10.1111/j.1365-2621.1989.tb03090.x
   Feng YZ, 2012, CRIT REV FOOD SCI, V52, P1039, DOI 10.1080/10408398.2011.651542
   Gao JF, 2013, SPECTROSC SPECT ANAL, V33, P1922, DOI 10.3964/j.issn.1000-0593(2013)07-1922-05
   [郭燕 Guo Yan], 2012, [食品科学, Food Science], V33, P227
   He Y, 2006, J INFRARED MILLIM W, V25, P192
   Huang D.., 2013, INFRARED LASER ENG, V42, P279, DOI [10.3969/j.issn.1007-2276.2013.z2.001, DOI 10.3969/J.ISSN.1007-2276.2013.Z2.001]
   Huang WenQian Huang WenQian, 2013, Transactions of the Chinese Society of Agricultural Engineering, V29, P272
   Liu D, 2014, FOOD BIOPROCESS TECH, V7, P307, DOI 10.1007/s11947-013-1193-6
   Liu Y, 2015, J HAINAN NORMAL U, V28
   [孟一 Meng Yi], 2014, [食品科学, Food Science], V35, P156
   Qin JW, 2013, J FOOD ENG, V118, P157, DOI 10.1016/j.jfoodeng.2013.04.001
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tian Y, 2014, AGR MECH RES, V6, P1
   Wang Li Wang Li, 2010, Journal of Tea Science, V30, P115
   Wu D, 2012, INNOV FOOD SCI EMERG, V16, P361, DOI 10.1016/j.ifset.2012.08.003
   Xing J, 2005, POSTHARVEST BIOL TEC, V37, P152, DOI 10.1016/j.postharvbio.2005.02.015
   [徐赛 Xu Sai], 2015, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V46, P214
   YOU D, 2016, FUJIAN NONGYE XUEBAO, V31, P151, DOI DOI 10.19303/j.issn.1008-0384.2016.02.009
   Zhang BH, 2015, FOOD ANAL METHOD, V8, P2075, DOI 10.1007/s12161-015-0097-7
   Zhang BH, 2015, J FOOD ENG, V146, P143, DOI 10.1016/j.jfoodeng.2014.08.024
   Zhao JieWen Zhao JieWen, 2008, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V39, P106
NR 26
TC 2
Z9 2
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27505
EP 27516
DI 10.1007/s11042-018-5936-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500057
DA 2024-07-18
ER

PT J
AU Wang, MH
   Mai, JM
   Cai, RC
   Liang, Y
   Wan, H
AF Wang, Meihua
   Mai, Jiaming
   Cai, Ruichu
   Liang, Yun
   Wan, Hua
TI Single image deraining using deep convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deraining; image restoration; image enhancement; deep learning
ID REMOVAL; RAIN
AB A deep learning-based single image deraining algorithm is proposed in this work. Instead of modeling a rain layer as a linear function between the rain image and its clear version as previous works do, we directly formulate the clear image as the result of a non-linear mapping of thrain image. We construct a coarse deraining convolutional network and a refinement convolutional network to learn this non-linear mapping function. The coarse deraining network is trained to detect the rain streaks with different directions, and restore a raw derained result. The refinement network aims at refining the result according to the raw derained image and the original rain image. By combining the two networks, we are able to well-restore the rain-free image. Experimental results demonstrate that the proposed deraining method can produce high-quality clear images from both synthetic and real-world rain images, outperforming the state-of-the-art methods qualitatively and quantitatively.
C1 [Wang, Meihua; Mai, Jiaming; Liang, Yun; Wan, Hua] South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
   [Cai, Ruichu] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou, Guangdong, Peoples R China.
C3 South China Agricultural University; Guangdong University of Technology
RP Mai, JM (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
EM wangmeihua@scau.edu.cn; jiamingmai@163.com; cairuichu@gmail.com;
   sdliangyun@163.com; wanhua@scau.edu.com
RI cai, ruichu/AAX-7200-2021
FU National Natural Science Foundation of China [61202269, 61472089,
   61202293, 31600591]; Science and Technology Plan Project of Guangdong
   Province [2014A050503057, 2015A020209124, 2016A020210087]
FX This work is financially supported by National Natural Science
   Foundation of China (61202269, 61472089, 61202293, 31600591), Science
   and Technology Plan Project of Guangdong Province (2014A050503057,
   2015A020209124, 2016A020210087).
CR Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2005, IEEE C COMP VIS
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2013, IEEE INT C BIOINFORM
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Ren W, 2004, IEEE C COMP VIS PATT
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tripathi AK, 2014, SIGNAL IMAGE VIDEO P, V8, P1421, DOI 10.1007/s11760-012-0373-6
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
NR 23
TC 4
Z9 5
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25905
EP 25918
DI 10.1007/s11042-018-5825-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400055
DA 2024-07-18
ER

PT J
AU Rabie, T
   Baziyad, M
   Kamel, I
AF Rabie, Tamer
   Baziyad, Mohammed
   Kamel, Ibrahim
TI Enhanced high capacity image steganography using discrete wavelet
   transform and the Laplacian pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Laplacian pyramid; Curve fitting; High
   payload capacity; Steganography; Frequency-domain image hiding
ID MULTIPLE WATERMARKING; HIGH PAYLOAD; INFORMATION; ROBUST
AB This paper introduces a high capacity image hiding scheme with enhanced stego image quality. This new hiding scheme utilizes a multiscale Laplacian pyramid of the cover image in the Discrete Wavelet Transform (DWT) domain. Previous work either enhanced capacity at the expense of stego quality or improved stego quality albeit at lower capacities. The proposed scheme will utilize the high-frequency bands of the DWT of the cover image for increased hiding capacity while further extending the payload capacity by hiding in the lowest level Laplacian pyramid of the DWT low-frequency band using a curve-fitting adaptive region approach in the spectral magnitude discrete cosine transform domain. The proposed scheme results in enhanced visual fidelity as well as high capacities as compared to competing methods. Comparative experimental results will show that the proposed scheme outperforms recent methods in terms of payload capacity as well as various image quality measures. Resistance to data-loss and noise tampering, geometric distortions and Checkmark attacks, and steganalysis detection attacks will further demonstrate the robustness of the proposed scheme.
C1 [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
   [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; mbaziyad@sharjah.ac.ae; kamel@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
FX The authors would like to thank the anonymous reviewers for their
   valuable suggestions that contributed to the improvement of the original
   manuscript. Thanks also goes to those colleagues whose suggestions
   helped the overall presentaiton of this paper. This work was funded by
   the College of Graduate Studies and Research at the University of
   Sharjah.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], DEV TRENDS STEGANOGR
   [Anonymous], 2011, ENCY CRYPTOGRAPHY SE
   [Anonymous], MULTIMED TOOLS UNPUB
   [Anonymous], DIG IM STEG FFT APPR
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P INT C SYST CYB INF
   [Anonymous], METHODS
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2010, INT J COMPUT APPL
   [Anonymous], INT J NETWORK SECURI
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Bandyopadhyay D., 2014, Int J Secur Priv Trust Manage (IJSPTM), V3, P11, DOI [10.5121/ijsptm.2014.3102, DOI 10.5121/IJSPTM.2014.3102]
   Bhattacharyya S., 2012, International Journal of Computer Network and Information Security, V4, P27, DOI [DOI 10.5815/IJCNIS.2012.07.04, DOI 10.5815/IJCNIS2012.07.04]
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cole Eric, 2003, Hiding in Plain Sight: Steganography and the Art of Covert Communication
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Ibaida A, 2013, IEEE T BIO-MED ENG, V60, P3322, DOI 10.1109/TBME.2013.2264539
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin CH, 2009, PR ELECTROMAGN RES S, P327, DOI 10.1145/1516241.1516298
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Morkel T., 2005, ISSA, V1, P1
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parul M., 2014, International Journal of Recent Development in Engineering and Technology, V2, P75
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063001
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Rabie T, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P858, DOI 10.1109/CISP.2013.6745285
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   SONG WJ, 1988, IEEE T CIRCUITS SYST, V35, P1048, DOI 10.1109/31.1856
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Swain G., 2014, Int J Comput Sci Eng Tech, V5, P219
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 65
TC 26
Z9 26
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23673
EP 23698
DI 10.1007/s11042-018-5713-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900027
DA 2024-07-18
ER

PT J
AU Rajagopalan, S
   Rethinam, S
   Arumugham, S
   Upadhyay, HN
   Rayappan, JBB
   Amirtharajan, R
AF Rajagopalan, Sundararaman
   Rethinam, Sivaraman
   Arumugham, Sridevi
   Upadhyay, Har Narayan
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Networked hardware assisted key image and chaotic attractors for secure
   RGB image communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic attractors; Cellular automata; Random key
   image; Ring oscillator
ID ELEMENTARY CELLULAR-AUTOMATA; DNA-SEQUENCE OPERATION; ENCRYPTION
   ALGORITHM; MAP; SYSTEM; CRYPTOSYSTEM; STANDARD
AB In multimedia communication, significance of the images for data representation is noteworthy. In this context, secure transmission of images over open channel has become a challenging task. Creation of different strategies in improving the secure image transmission always has a demand. The proposed work suggests an RGB image encryption with the confluence of attractors and hardware triggered key image in which confusion and diffusion were accomplished by Lorenz, Lu and Cellular Automata attractors. The uniqueness of proposed encryption scheme is a key image generation module through cascaded Ring Oscillator circuit which creates M x N key image for diffusion of pixels. Facilitating the authenticated networked access to key image generation hardware enables the secure server-client architecture for a variety of secure image transfer applications. The proposed approach is a hardware - software codesign which possesses a good keyspace, improved key sensitivity and satisfies the various statistical parameters thus offering substantial resistance to differential, occlusion and chosen plaintext attacks on RGB images.
C1 [Rajagopalan, Sundararaman; Rethinam, Sivaraman; Arumugham, Sridevi; Upadhyay, Har Narayan; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Rajagopalan, S (corresponding author), SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM raman@ece.sastra.edu
RI ., R. Sivaraman/JDM-3125-2023; Amirtharajan, Rengarajan/C-6471-2011;
   Rayappan, John Bosco Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Sundararaman,
   Rajagopalan/0000-0003-3505-3260; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870; Rethinam, Sivaraman/0000-0001-9292-8524;
   Upadhyay, Har Narayan/0000-0002-1219-9649; ARUMUGHAM,
   SRIDEVI/0000-0002-5334-6510
FU SASTRA University through the Research & Modernization Fund [R&M / 0026
   / SEEE - 010 / 2012 - 13]
FX The authors wish to thank SASTRA University for providing infrastructure
   through the Research & Modernization Fund (Ref.No: R&M / 0026 / SEEE -
   010 / 2012 - 13) to carry out the research work.
CR Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   Avaroglu E, 2015, NONLINEAR DYNAM, V81, P189, DOI 10.1007/s11071-015-1981-9
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Elashry IF, 2012, INF SECUR J, V21, P193, DOI 10.1080/19393555.2011.654319
   Elkamchouchi HM, 2005, RAD SCI C 2005 NRSC, P277, DOI DOI 10.1109/NRSC.2005.194011
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Javale D, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P125, DOI 10.1109/HIS.2012.6421321
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Park M, 2015, MICROELECTRON J, V46, P1364, DOI 10.1016/j.mejo.2015.09.015
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SI Y., 2008, COMPUT TECHNOL DEV, V2, P21
   Sunar B, 2007, IEEE T COMPUT, V56, P109, DOI 10.1109/TC.2007.250627
   Tang QY, 2014, IEEE CUST INTEGR CIR, DOI 10.1109/CICC.2014.6946136
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2016, OPT LASER ENG, V86, P248, DOI 10.1016/j.optlaseng.2016.06.008
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
NR 30
TC 18
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23449
EP 23482
DI 10.1007/s11042-017-5566-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900018
DA 2024-07-18
ER

PT J
AU Zhou, KL
   Zhao, LP
   Lin, T
AF Zhou, Kailun
   Zhao, Liping
   Lin, Tao
TI A flexible and uniform string matching technique for general screen
   content coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding (HEVC); Audio video coding standard (AVS);
   Screen content coding (SCC); String matching
AB This paper proposes a flexible and uniform string matching technique named universal string matching (USM) for general screen content coding (SCC). USM uses two reference buffers for string matching: primary reference buffer (PRB) and secondary reference buffer (SRB), and includes three modes: general string (GS) mode, constrained string 1 (CS1) mode, and constrained string 2 (CS2) mode. PRB is used in GS mode and CS1 mode and SRB is used in GS mode and CS2 mode. Each of the three modes plays an essential role in SCC due to the diversity and comprehensiveness of the screen content. The experiments use HEVC SCC common test condition (CTC) for lossy coding. Compared with HEVC HM-16.6 + SCM-5.2 reference software of full frame search range for IBC and with ACT off, USM achieves an average Y BD-rate of -25.5% for four TGM (text and graphics with motion) test sequences from the SCC verification test suite and -5.5% for eight TGM test sequences from the HEVC SCC CTC test suite in all intra configuration with a small increase of encoding runtime and a small decrease of decoding runtime.
C1 [Zhou, Kailun; Lin, Tao] Tongji Univ, Coll Elect & Informat Engn, Inst VLSI, Shanghai 200092, Peoples R China.
   [Zhao, Liping] Shaoxing Univ, Dept Comp Sci & Engn, Shaoxing 312000, Peoples R China.
C3 Tongji University; Shaoxing University
RP Lin, T (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Inst VLSI, Shanghai 200092, Peoples R China.
EM lintao@tongji.edu.cn
FU National Natural Science Foundation of China [61601200]
FX This work is supported by the National Natural Science Foundation of
   China (No.61601200).
CR [Anonymous], 2011, JCTVCE145
   [Anonymous], 2015, JCTVCU1015
   [Anonymous], 2008, VCEG-AI11
   Bjontegaard G., 2001, Document VCEG-M33
   [陈先义 Chen Xianyi], 2015, [电子与信息学报, Journal of Electronics & Information Technology], V37, P2685
   Guo J, 2015, HCTVCV0097
   Guo L, 2014, IEEE INT C IM PROC I, DOI [10.1109/ICIP.2014.7026124, DOI 10.1109/ICIP.2014.7026124]
   ISO/IEC JTC, 2014, N14174 ISOIEC JTC1SC
   Joshi R, 2016, JCTVCW1005
   Li B, 2014, P IEEE VIS COMM IM P, DOI [10.1109/VCIP.2014.7051623, DOI 10.1109/VCIP.2014.7051623]
   Lin T, 2013, IEEE PICT COD S PCS, DOI [10.1109/PCS.2013.6737760, DOI 10.1109/PCS.2013.6737760]
   Lin T, 2009, IEEE WORKSH MULT SIG, DOI [10.1109/ICME.2009.5202873, DOI 10.1109/ICME.2009.5202873]
   Lin T, 2017, J ELECTRON INF TECHN, V39, P351, DOI 10.11999/JEIT160560
   Lin T, 2013, PICT COD SYMP, P369, DOI 10.1109/PCS.2013.6737760
   Lin T, 2013, INT J AD HOC UBIQ CO, V13, P96, DOI 10.1504/IJAHUC.2013.054174
   Lin T, 2013, IEEE T CIRC SYST VID, V23, P173, DOI 10.1109/TCSVT.2012.2223871
   Lin T, 2009, IEEE SIGNAL PROC LET, V16, P323, DOI 10.1109/LSP.2009.2014285
   Lin TC, 2014, INT J SCI EDUC, V36, P1346, DOI 10.1080/09500693.2013.864428
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Ma Z, 2014, IEEE T IMAGE PROCESS, V23, P4399, DOI 10.1109/TIP.2014.2346995
   Marpe D., 2006, IEEE IMAGE PROC, P3157, DOI DOI 10.1109/ICIP.2006.313039
   Pang C, 2013, JCTVCN0256
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Peng XL, 2016, IEEE T IMAGE PROCESS, V25, P5601, DOI 10.1109/TIP.2016.2612884
   Shuhui Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P566, DOI 10.1109/CISP.2010.5647270
   Tao Lin, 2009, Proceedings 2009 IEEE International Conference on Multimedia and Expo (ICME), P1805, DOI 10.1109/ICME.2009.5202873
   Wang SH, 2009, IEEE INT C IM SIGN P, DOI [10.1109/CISP.2009.5301019, DOI 10.1109/CISP.2009.5301019]
   Wang SH, 2015, MULTIMED TOOLS APPL, V74, P7753, DOI 10.1007/s11042-014-2021-3
   Wang SH, 2014, MULTIMED TOOLS APPL, V71, P1263, DOI 10.1007/s11042-012-1274-y
   Wang SH, 2013, IET IMAGE PROCESS, V7, P484, DOI 10.1049/iet-ipr.2012.0439
   Wang W, 2015, JCTVCT0126
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Yu H, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P40, DOI 10.1109/ICMA.2017.8015785
   Zeng W, 2000, P IEEE ICIP, DOI [10.1109/ICIP.2000.899448, DOI 10.1109/ICIP.2000.899448]
   Zhao L., 2016, JVETB0048
   Zhao LP, 2016, IEEE T MULTIMEDIA, V18, P339, DOI 10.1109/TMM.2015.2512539
   Zhao LP, 2015, JCTVCV0095
   Zhou KL, 2016, IEEE J EM SEL TOP C, V6, P560, DOI 10.1109/JETCAS.2016.2599876
   Zhou KL, 2015, JCTVCV0094
   Zhu W, 2013, IEEE PICT COD S PCS, DOI [10.1109/PCS.2013.6737761, DOI 10.1109/PCS.2013.6737761]
   Zhu WJ, 2015, IEEE T MULTIMEDIA, V17, P935, DOI 10.1109/TMM.2015.2428171
   Zhu WJ, 2014, IEEE T MULTIMEDIA, V16, P1316, DOI 10.1109/TMM.2014.2315782
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 43
TC 8
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23751
EP 23775
DI 10.1007/s11042-018-5624-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900030
DA 2024-07-18
ER

PT J
AU Abdullahi, SM
   Wang, HX
AF Abdullahi, Sani M.
   Wang, Hongxia
TI Robust enhancement and centroid-based concealment of fingerprint
   biometric data into audio signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric Data Concealment; Fingerprint Image; Embedding; Identity
   Authentication; Watermarking
ID WATERMARKING; IMAGE
AB Numerous issues are raised through the enhancement, transmission and storage of biometric data due to its high sensitivity and extremely crucial purpose. However, it might be impossible to recover if corrupted, counterfeited or hacked, thereby ruining the general aim of enhancing and securing it. In this paper, an 8-layered feature enhancement algorithm is proposed. The fingerprint image was enhanced and extracted using minutiae-based recognition system with the aim of eliminating all anomalies that comes with the image. The EQF (Effectiveness Quality Factor) and matching accuracy of the system all signifies efficiency and robustness of the enhancement scheme. In the other hand, a centroid-based audio watermarking is used to conceal the enhanced fingerprint biometric data into audio signals. The embedding algorithm starts by encrypting our enhanced image using chaotic logistic map prior to watermarking. It then proceeds with computing the centroid of the audio signal. DWT and DCT are performed on the sub-band which carries the centroid of each audio frame, thereby embedding the encrypted watermark bits into their domain. Achieved results from the performance evaluation of both contributions signify the efficiency of our proposed schemes. Moreover, some signal processing operations are also carried out on the watermarked signal and the outcome was intriguing as they were all counteracted.
C1 [Abdullahi, Sani M.; Wang, Hongxia] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Wang, HX (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
EM sani@my.swjtu.edu.cn; hxwang@home.swjtu.edu.cn
RI Wang, Hongxia/AAE-2135-2022; Abdullahi, Sani/HLH-2485-2023
OI Abdullahi, Sani/0000-0003-4962-2794
FU National Science Foundation of China (NSFC) [U1536110, 61402219]
FX The authors are grateful for the anonymous reviewers' insightful
   comments and valuable suggestions sincerely, which substantially improve
   the quality of this manuscript. Many thanks to Dr. Hong Zhao for his
   participation in technical editing of the manuscript. Our sincere
   appreciation also goes to Yi Chen for his valuable suggestion on
   improving the manuscript simulation based on reviewers' comments. This
   work is supported by the National Science Foundation of China (NSFC)
   under the grant Nos. U1536110, 61402219.
CR Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Alkhathami M, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1717, DOI 10.1109/CISP.2013.6743953
   Anil K.Jain., 2011, Introduction to Biometrics
   [Anonymous], P 55 ANN M ASS COMP
   [Anonymous], 2013, INTELLIGENT INTERACT, DOI DOI 10.1007/978-3-642-37463-0_25
   [Anonymous], 2020, Feature Extraction and Image Processing
   [Anonymous], 2016, IEEE T AUTOM SCI ENG
   [Anonymous], INT J COMPUT SCI COM
   [Anonymous], HDB FINGERPRINT RECO
   [Anonymous], 13871 INT TEL UN
   [Anonymous], 2016, MULTIMED TOOLS APPL
   [Anonymous], COMPUTERS SOC
   [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], MULTIPLE SYSTEMS
   [Anonymous], J DIGIT SIG PROCESS
   [Anonymous], FINGERPRINT MATCHING
   Bandur MV, 2013, 2013 21ST TELECOMMUNICATIONS FORUM (TELFOR), P506, DOI 10.1109/TELFOR.2013.6716277
   Bartunek JS, 2013, IEEE T IMAGE PROCESS, V22, P644, DOI 10.1109/TIP.2012.2220373
   Bas P, 2013, IEEE T INF FOREN SEC, V8, P1306, DOI 10.1109/TIFS.2013.2267960
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhatnagar G, 2012, IEEE T INSTRUM MEAS, V61, P876, DOI 10.1109/TIM.2011.2179330
   Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   El Bakrawy LM, 2011, ADV INTEL SOFT COMPU, V96, P249
   El- Khamy SE, 2016, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-4113-8,1-16, DOI 10.1007/S11042-016-4113-8,1-16]
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Gnanasivam P, 2010, PROCEDIA COMPUT SCI, V2, P133, DOI 10.1016/j.procs.2010.11.017
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jianchun He, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P1643, DOI 10.1109/CSSS.2012.411
   Jin Z, 2016, IEEE T SYST MAN CY-S, V46, P1415, DOI 10.1109/TSMC.2015.2499725
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Kaur A, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P509, DOI 10.1109/IC3I.2014.7019714
   Li CL, 2016, COMPUT ELECTR ENG, V54, P484, DOI 10.1016/j.compeleceng.2016.01.026
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu XG, 2016, AMB EXPRESS, V6, DOI 10.1186/s13568-016-0227-7
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Sankaran A, 2014, IEEE ACCESS, V2, P982, DOI 10.1109/ACCESS.2014.2349879
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang JW, 2015, IEEE SIGNAL PROC LET, V22, P390, DOI 10.1109/LSP.2014.2361212
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiang Ming, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1039, DOI 10.1109/ICISE.2009.31
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2015, J PHYS CONF SER, V660, DOI 10.1088/1742-6596/660/1/012026
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 59
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20753
EP 20782
DI 10.1007/s11042-017-5509-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300021
DA 2024-07-18
ER

PT J
AU Ali, M
   Dong, L
   Akhtar, R
AF Ali, Mushtaq
   Dong, Le
   Akhtar, Rizwan
TI Multi-panel medical image segmentation framework for image retrieval
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image class identification; Edge image; Connected component; Multi-panel
   image segmentation; Framework
AB The automatic segmentation of multi-panel medical images into sub-images improves the retrieval accuracy of medical image retrieval systems. However, the accuracy and efficiency of the available multi-panel medical image segmentation techniques are not satisfactory for multi-panel images containing homogenous color inter-panel borders and image boundary, heterogeneous color inter-panel borders, small size sub-images, or numerous number of sub-images. In order to improve the accuracy and efficiency, a Multi-panel Medical Image Segmentation Framework (MIS-Framework) is proposed and implemented based on locating the longest inter-panel border inside the boundary of the input image. We evaluated the proposed framework on a subset of imageCLEF 2013 dataset containing 2407 images. The proposed framework showed promising experimental results in terms of accuracy and efficiency on single panel as well as multi-panel image class identification and on sub-image separation as compared to the available techniques.
C1 [Ali, Mushtaq] Hazara Univ, Dept Informat Technol, Kpk, Pakistan.
   [Dong, Le] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
   [Akhtar, Rizwan] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
C3 University of Electronic Science & Technology of China; Jiangsu
   University
RP Ali, M (corresponding author), Hazara Univ, Dept Informat Technol, Kpk, Pakistan.
EM mushtaqyaqubi@hotmail.com; dongle@126.com; rizwanakhtarpk@gmail.com
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   [Anonymous], 1992, C4 5 PROGRAMS MACHIN
   Antani S, 2008, PROC SPIE, V6815, DOI 10.1117/12.766778
   Apostolova E, 2013, J AM SOC INF SCI TEC, V64, P893, DOI 10.1002/asi.22810
   Aucar JA, 2007, AM J SURG, V194, P734, DOI 10.1016/j.amjsurg.2007.08.036
   Cheng B, 2011, P SPIE ELECT IMAG 18
   Chhatkuli A, 2013, P SPIE
   Cooper MS, 2004, METHOD CELL BIOL, V77, P439
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168
   Divoli A, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009619
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2012, P 21 INT C PATT REC
   Liu Y, 2010, 16 INT C VIRT SYST M, P20
   Liu Y, 2016, P 30 AAAI C ART INT, V181
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lopez LD, 2012, BIOINF BIOM BIBM 201, P1
   Lopez LD, 2013, BMC SYST BIOL, V7, DOI 10.1186/1752-0509-7-S4-S8
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Preotiuc-Pietro Daniel, 2017, ACL
   Sandusky RJ, 2008, J AM SOC INF SCI TEC, V59, P970, DOI 10.1002/asi.20804
   Seco De Herrera AG, 2013, OVERVIEW IMAGE CLEF
   Yu Hong, 2006, AMIA Annu Symp Proc, P834
NR 26
TC 8
Z9 8
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20271
EP 20295
DI 10.1007/s11042-017-5453-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300001
DA 2024-07-18
ER

PT J
AU Annaby, MH
   Ayad, H
   Rushdi, MA
AF Annaby, Mahmoud H.
   Ayad, Hassan
   Rushdi, Muhammad A.
TI On security of image ciphers based on logic circuits and chaotic
   permutations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Reversible and irreversible circuits; Cryptanalysis;
   Permutation; Chaotic mappings; Fractional Fourier transform
ID DISCRETE FRACTIONAL FOURIER; ONLY MULTIMEDIA CIPHERS; REVERSIBLE LOGIC;
   QUANTITATIVE CRYPTANALYSIS; ENCRYPTION ALGORITHM; TRANSFORMS
AB This paper introduces a cryptanalysis of image encryption techniques that are using chaotic scrambling and logic gates/circuits. Chaotic scrambling, as well as general permutations are considered together with reversible and irreversible gates, including XOR, Toffoli and Fredkin gates. We also investigate ciphers based on chaotic permutations and balanced logic circuits. Except for the implementation of Fredkin's gate, these ciphers are insecure against chosen-plaintext attacks, no matter whether a permutation is applied globally on the image or via a block-by-block basis. We introduce a new cipher based on chaotic permutations, logic circuits and randomized Fourier-type transforms. The strength of the new cipher is statistically verified with standard statistical encryption measures.
C1 [Annaby, Mahmoud H.; Ayad, Hassan] Cairo Univ, Dept Math, Fac Sci, Giza 12613, Egypt.
   [Rushdi, Muhammad A.] Cairo Univ, Dept Biomed Engn & Syst, Fac Engn, Giza 12613, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Cairo University
RP Annaby, MH (corresponding author), Cairo Univ, Dept Math, Fac Sci, Giza 12613, Egypt.
EM mhannaby@sci.cu.edu.eg; ahassan@sci.cu.edu.eg; mrushdi@eng.cu.edu.eg
RI Rushdi, Muhammad/AAF-7785-2019
OI Ayad, Hassan/0000-0002-1305-7191
CR Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   Annaby MH, 2016, SIGNAL PROCESS-IMAGE, V49, P25, DOI 10.1016/j.image.2016.09.006
   [Anonymous], 2003, INTRO CHAOTIC DYNAMI
   [Anonymous], REVERSIBLE COMPUTING
   Benjamini Itai, 2005, STOC 05 P 37 ANN ACM, P244, DOI 10.1145/1060590.1060627
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Gupta P, 2006, IEEE T COMPUT AID D, V25, P2317, DOI 10.1109/TCAD.2006.871622
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hsue WL, 2015, IEEE T CIRCUITS-I, V62, P2594, DOI 10.1109/TCSI.2015.2468996
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li CQ, 2007, PHYS LETT A, V369, P23, DOI 10.1016/j.physleta.2007.04.023
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Morrison M, 2014, IEEE COMP SOC ANN, P253, DOI 10.1109/ISVLSI.2014.88
   Pei SC, 1997, OPT LETT, V22, P1047, DOI 10.1364/OL.22.001047
   Pei SC, 2006, IEEE SIGNAL PROC LET, V13, P329, DOI 10.1109/LSP.2006.871721
   Sam IS, 2011, LECT NOTES COMPUT SC, V6536, P290, DOI 10.1007/978-3-642-19056-8_22
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shende VV, 2003, IEEE T COMPUT AID D, V22, P710, DOI 10.1109/TCAD.2003.811448
   Tang Z, 2017, MULTIMED TOOLS APPL, V76
   Thapliyal H, 2006, MIDWEST SYMP CIRCUIT, P342
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Wong KW, 2009, STUD COMPUT INTELL, V184, P333
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76
NR 32
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20455
EP 20476
DI 10.1007/s11042-017-5439-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300007
DA 2024-07-18
ER

PT J
AU Gao, X
   Zhang, GY
   Lin, JC
   Liao, MH
AF Gao, Xing
   Zhang, Guangyu
   Lin, Juncong
   Liao, Minghong
TI Localized layout analysis for retargeting of heterogeneous images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous image; Localized layout analysis; Image retargeting
ID DOCUMENT; SEGMENTATION; MODEL
AB Heterogeneous paper documents (such as newspaper, magazine) are very common in our daily life. They are usually scanned and stored as images. Reading such images on a mobile device is very awkward, as they can only be partially displayed to ensure read-ability. The user needs to frequently switch among different portions of the image to read clearly. It would be very helpful if the system can automatically determine an appropriate reading area around the user's click position and retarget the area to the whole screen. In this paper, we propose a localized layout analysis method for retargeting of heterogeneous images. Once the user clicks on a fully displayed heterogeneous image, our method can automatically extract an appropriate rectangular region and scale the region to the whole screen for reading. The region is semantically meaningful, and the content is guaranteed to be clear enough when fully displayed on the screen. The experimental results show that our method can effectively avoid those tedious scale and translation operations when reading heterogeneous images, and thus improve the user's experience greatly.
C1 [Gao, Xing; Zhang, Guangyu; Lin, Juncong; Liao, Minghong] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
C3 Xiamen University
RP Lin, JC (corresponding author), Xiamen Univ, Software Sch, Xiamen, Peoples R China.
EM gaoxing@xmu.edu.cn; zhangguangyu@stu.xmu.edu.cn; jclin@xmu.edu.cn;
   liao@xmu.edu.cn
CR Agrawal Mudit, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1011, DOI 10.1109/ICDAR.2009.270
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chen K, 2013, PROC INT CONF DOC, P958, DOI 10.1109/ICDAR.2013.194
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586
   Gal R, 2006, FEATURE AWARE TEXTUR
   Jaekyu Ha, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P952, DOI 10.1109/ICDAR.1995.602059
   Karni Z, 2009, ENERGY BASED IMAGE D
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Lee SW, 2001, IEEE T PATTERN ANAL, V23, P1240, DOI 10.1109/34.969115
   Liu F, 2005, AUTOMATIC IMAGE RETA
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A, 2006, GAZE BASED INTERACTI
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Siegel S., 1956, Nonparametric statistics for the behavioral sciences
   Simon A, 1997, IEEE T PATTERN ANAL, V19, P273, DOI 10.1109/34.584106
   Smith Raymond W., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P241, DOI 10.1109/ICDAR.2009.257
   Suh B., 2003, AUTOMATIC THUMBNAIL
   Sun HM, 2005, PROC INT CONF DOC, P116
   Tran TH, 2016, MOD APPR SOL EARTH S, V11, P1, DOI 10.1007/978-3-319-25235-3
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21163
EP 21184
DI 10.1007/s11042-017-5405-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300037
DA 2024-07-18
ER

PT J
AU Ishizawa, F
   Sakamoto, M
   Nakajima, T
AF Ishizawa, Fumiko
   Sakamoto, Mizuki
   Nakajima, Tatsuo
TI Extracting intermediate-level design knowledge for speculating
   digital-physical hybrid alternate reality experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service design; Augmented reality; Virtual reality; Alternate reality
   experiences; Research through design; Design fiction; Intermediate-level
   design knowledge
ID FUTURE
AB This paper reports a process to derive intermediate-level knowledge as a service design and analysis framework for designing digital services to offer alternate reality experiences, and analyzes the possible opportunities and pitfalls of the framework. The user experience felt by refining the meaning of real space through virtuality is defined as alternate reality experiences. Alternate reality experiences are typically achieved by modifying our eyesight or replacing our five senses to others, and they make our world interactive by implicitly influencing human attitudes and behaviors. First, the paper extracts observations for deriving the intermediate-level knowledge through the discussions raised in exploration workshops. In the workshops, the three digital services that utilize diverse strategies to offer alternate reality experiences are chosen. The workshops' main focus is to examine how a person could have a sense of values in alternate reality experiences via the three digital services. Second, the paper shows how to derive the proposed service design and analysis framework from the extracted observations through expert analysis, then an overview of the framework is explained. Finally, the paper presents feasibility analysis of the proposed framework through a new digital service named Mindful Reminder as a case study for refining the service through focus group discussions. The approach described in the paper is to report a concrete process through which extracted observations can be converted into intermediate-level knowledge that can be used to design alternate reality experiences. Traditionally, the process for generating intermediate-level knowledge has not been well-documented; however, documenting the process is very important in theorizing the design of alternate reality experiences and helps effectively develop a variety of emerging advanced digital services that will offer alternate reality experiences in the future.
C1 [Ishizawa, Fumiko; Sakamoto, Mizuki; Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
C3 Waseda University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
EM f.ishizawa@dcl.cs.waseda.ac.jp; mizuki@dcl.cs.waseda.ac.jp;
   tatsuo@dcl.cs.waseda.ac.jp
CR Akasaki H, 2017, P 5 INT C DISTR AMB
   Akkil D, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971496
   Alexander C., 1977, PATTERN LANGUAGE TOW
   Allison A., 2006, Millennial monsters
   [Anonymous], 2013, PROC CHI 2013
   [Anonymous], 2009, PERVASIVE GAMES THEO
   [Anonymous], P 21 INT AC MINDTR C
   [Anonymous], 2007, P SIGCHI C HUM FACT
   [Anonymous], P INT C HUM FACT COM
   [Anonymous], ENRICHING URBAN SPAC
   Baudrillard Jean., 1998, CONSUMER SOC MYTHS S
   Bhaskar Michael., 2016, Curation: The Power of Selection in a World of Excess
   Boyd R.L., 2015, P 9 INT AAAI C WEB S, P31
   Cassone VI, 2017, P 21 INT AC MINDTR C
   Colley A, 2015, P 19 INT AC MINDTR C
   Corbin J., 2008, QUAL RES, DOI DOI 10.4135/9781452230153.N10
   Coulton P, 2016, P INT C DRS2016 FUT
   Curedale R, 2016, AFFINITY DIAGRAMS TO
   Dalsgaard Peter., 2014, P SIGCHI C HUM FACT
   Desmet PMA, 2013, INT J DES, V7, P5
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Dunne A., 2006, HERTZIAN TALES ELECT
   Dunne Anthony, 2013, SPECULATIVE EVERYTHI, DOI DOI 10.1093/JDH/EPV001
   Eaton G, 2001, EXPERT NOVICES DIFFE
   Forlano L, 2014, J URBAN TECHNOL, V21, P7, DOI 10.1080/10630732.2014.971525
   Forlizzi J., 2013, P 5 IASDR WORLD C DE
   Gaver B., 2012, INTERACTIONS, V19, P40
   Gaver W., 2003, P SIGCHI C HUM FACT
   Gaver WW, 1991, P SIGCHI C HUM FACT
   Godin Danny, 2014, P DRS 2014 C JUN 16
   Gonzatto RF, 2013, DIGIT CREAT, V24, P36, DOI 10.1080/14626268.2013.772524
   Hekler E. B., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems-CHI 13, P3307, DOI [DOI 10.1145/2470654, DOI 10.1145/2470654.2466452, 10.1145/2470654]
   Ho H, 2008, P IEEE 21 INT C MICR
   Höök K, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2362364.2362371
   Ikeuchi K, 2015, P 12 INT C ADV COMP
   Ikeuchi K, 2014, P 5 AUGM HUM INT C
   Ishizawa F, 2016, P 10 INT C UB COMP A
   Ishizawa F, 2017, P 6 INT C DES US EXP
   Kim H, 2014, INT J DES, V8, P1
   Kirby D, 2010, SOC STUD SCI, V40, P41, DOI 10.1177/0306312709338325
   Lawson B., 2005, How Designers Think
   Leitner M, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971515
   Lindley J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4032, DOI 10.1145/2858036.2858446
   Marshall P., 2013, SAGE HDB DIGITAL TEC, V1, P144
   Nakajima T, 2013, PERS UBIQUIT COMPUT, V17, P107, DOI 10.1007/s00779-011-0469-y
   Narumi T., 2012, P 2012 ACM ANN C HUM
   Niedderer K, 2016, INT J DES, V10, P67
   Norman DA, 2013, Basic Books
   Ostrom E., 1992, CRAFTING I SELF GOVE
   Paul CL, 2008, J USABILITY STUD, V4, P7
   Saffer D., 2005, The role of metaphor in interaction design
   Sakamoto M., 2015, P INT C DES US EXP U
   Sakamoto M, 2017, MULTIMED TOOLS APPL, V76, P12539, DOI 10.1007/s11042-016-3665-y
   Sakamoto M, 2016, MULTIMED TOOLS APPL, V75, P8289, DOI 10.1007/s11042-015-2751-x
   Sakamoto M, 2015, MULTIMED TOOLS APPL, V74, P11537, DOI 10.1007/s11042-014-2250-5
   Salovaara A, 2017, P INT C HUM FACT COM
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schouten B, 2016, PLAYABLE CITIES CITY
   Schwalk M, 2016, ADV ERGONOMIC DESIGN
   Sengers Phoebe, 2006, P 6 C DES INT SYST D
   Spence C, 2016, BRAIN COGNITION, V110, P53, DOI 10.1016/j.bandc.2015.08.006
   Stickdorn M., 2012, This is service design thinking: Basics, tools, cases
   Suzuki E., 2014, P 5 AUGM HUM INT C
   Suzuki K, 2012, SCI REP-UK, V2, DOI 10.1038/srep00459
   Takahashi M., 2015, ADJ P 2015 ACM INT J
   The Imagineers, 2010, WALT DISN IM
   Treanor M, 2011, P FDN DIGITAL GAMES
   Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133
   Wolfe A.K., 2014, Behavioral Change and Building Performance: Strategies for Significant, Persistent, and Measurable Institutional Change
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
NR 70
TC 8
Z9 8
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21329
EP 21370
DI 10.1007/s11042-017-5595-8
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300045
DA 2024-07-18
ER

PT J
AU Lee, SH
   Lee, EJ
   Hwang, WJ
   Kwon, KR
AF Lee, Suk-Hwan
   Lee, Eung-Joo
   Hwang, Won-Joo
   Kwon, Ki-Ryong
TI Reversible DNA data hiding using multiple difference expansions for DNA
   authentication and storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible DNAdata hiding; Data hiding on Noncoding DNA; DNA
   authentication; DNA storage; Difference expansion-multiple bits
   embedding; DNA numerical coding; False start codon prevention
ID WATERMARKING; PREDICTION; CAPACITY; GENOME
AB Recently the data hiding techniques on DNA sequence have attracted interest for DNA authentication and high-capacity DNA storage. However, since DNA sequence represents the primary information that directs the functions of organism, it is necessary for distortion-free DNA data hiding, so-called reversible DNA data hiding, with high capacity, low change rate of nucleotide bases, biological preservation, and reversibility. In this paper, we address two approaches of reversible DNA data hiding using multiple difference expansions. Reversible DNA data hiding should consider the string structure of a DNA sequence, the biological functionality, the efficient recovery, and the optimal embedding capacity. Our method converts the string sequence of four characters (A,T,C,G) of noncoding DNA sequences into decimal-coded values and embeds the watermark into coded value sequence using two approaches; DE-based multiple bits embedding (DE-MBE) using pairs of neighboring values and consecutive DE-MBE (CDE-MBE) using previous embedded coded values as the current estimated ones. Two approaches use comparison searching to prevent false start codons that produce false coding regions (exons) and embed multiple bits for maximal expandability of differences within the range of coded values. From experimental results using bacterial and archaeal sequences, we verified that our CDE-MBE have a higher embedding capacity of 1.13 times similar to 9.03times than conventional methods, and produce no false start codons, verify the security by secure numerical coding and recover the host sequence perfectly without a reference sequence. In particular, CDE-MBE has an embedding capacity that is two times greater than that of DE-MBE.
C1 [Lee, Suk-Hwan] Tongmyong Univ, Dept Informat Secur, Busan, South Korea.
   [Lee, Eung-Joo] Tongmyong Univ, Dept Informat Commun Engn, Busan, South Korea.
   [Hwang, Won-Joo] Inje Univ, Dept Informat Commun Engn, Gimhae, South Korea.
   [Kwon, Ki-Ryong] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Busan, South Korea.
C3 Tongmyong University; Tongmyong University; Inje University; Pukyong
   National University
RP Kwon, KR (corresponding author), Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Busan, South Korea.
EM skylee@tu.ac.kr; ejlee@tu.ac.kr; ichwang@inje.ac.kr; krkown@pknu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - the Ministry of Education, Science and Technology
   [NRF-NRF-2016R1D1A3B03931003, NRF-2017R1A2B2012456]; Brain Busan (BB21)
   project
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-NRF-2016R1D1A3B03931003 and
   NRF-2017R1A2B2012456) and also supported by Brain Busan (BB21) project.
CR Babatunde O.O., 2011, J ENG TECHNOLOGY RES, V3, P148
   Balado F, 2013, IEEE T INFORM THEORY, V59, P928, DOI 10.1109/TIT.2012.2219495
   Borda M, 2010, PROCEEDINGS OF THE 2010 8TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM), P451, DOI 10.1109/ICCOMM.2010.5509086
   Chen TD, 2007, LECT NOTES COMPUT SC, V4613, P84
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cox JPL, 2001, TRENDS BIOTECHNOL, V19, P247, DOI 10.1016/S0167-7799(01)01671-7
   Fu JT, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P868, DOI 10.1109/BMEI.2014.7002894
   Gibson DG, 2008, SCIENCE, V319, P1215, DOI 10.1126/science.1151721
   Gibson DG, 2010, SCIENCE, V329, P52, DOI 10.1126/science.1190719
   Goldman N, 2013, NATURE, V494, P77, DOI 10.1038/nature11875
   Heider D, 2008, BMC MOL BIOL, V9, DOI 10.1186/1471-2199-9-40
   Heider D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-176
   Heider D, 2011, CURR BIOINFORM, V6, P375, DOI 10.2174/157489311796904646
   Heider Dominik, 2009, BMC Res Notes, V2, P125, DOI 10.1186/1756-0500-2-125
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Hu Y, 2007, IEEE T CIRC SYST VID, V19, P250
   Huang YH, 2014, MULTIMED TOOLS APPL, V70, P1439, DOI 10.1007/s11042-012-1176-z
   Jupiter DC, 2010, PLOS PATHOG, V6, DOI 10.1371/journal.ppat.1000950
   Lee SH, 2014, INFORM SCIENCES, V273, P263, DOI 10.1016/j.ins.2014.03.039
   Lee SH, 2014, DIGIT SIGNAL PROCESS, V25, P173, DOI 10.1016/j.dsp.2013.11.010
   Lieff J, 2012, MIND MOL GENETICS NE
   Liss M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042465
   Ma GL, 2013, INT CONF BIOMED, P484, DOI 10.1109/BMEI.2013.6746991
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Risca VI, 2001, CRYPTOLOGIA, V25, P37, DOI 10.1080/0161-110191889761
   Shimanovsky B., 2002, Information Hiding. 5th International Workshop, IH 2002. Revised Papers (Lecture Notes in Computer Science Vol.2578), P373
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Tang Q, 2014, INT J DIGIT CRIME FO, V6, P1, DOI 10.4018/ijdcf.2014100101
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tulpan D, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/634832
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wong PC, 2003, COMMUN ACM, V46, P95, DOI 10.1145/602421.602426
   Yamamoto Masahito, 2008, Natural Computing, V7, P335, DOI 10.1007/s11047-008-9076-x
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zicheng Wang, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P946, DOI 10.1109/ICSESS.2013.6615462
NR 37
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19499
EP 19526
DI 10.1007/s11042-017-5379-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500028
DA 2024-07-18
ER

PT J
AU Duch, M
   Varas, D
   Rubió, JRM
   Ruiz-Hidalgo, J
   Marques, F
AF Maceira Duch, Marc
   Varas, David
   Morros Rubio, Josep Ramon
   Ruiz-Hidalgo, Javier
   Marques, Ferran
TI 3D hierarchical optimization for multi-view depth map coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene segmentation; Depth map segmentation; 3D representation;
   Rate-distortion optimization
ID VIDEO; IMAGE; REPRESENTATION
AB Depth data has a widespread use since the popularity of high resolution 3D sensors. In multi-view sequences, depth information is used to supplement the color data of each view. This article proposes a joint encoding of multiple depth maps with a unique representation. Color and depth images of each view are segmented independently and combined in an optimal Rate-Distortion fashion. The resulting partitions are projected to a reference view where a coherent hierarchy for the multiple views is built. A Rate-Distortion optimization is applied to obtain the final segmentation choosing nodes of the hierarchy. The consistent segmentation is used to robustly encode depth maps of multiple views obtaining competitive results with HEVC coding standards.
C1 [Maceira Duch, Marc; Ruiz-Hidalgo, Javier] Univ Politecn Cataluna, Image Proc Grp, C Jordi Girona 1-3, Barcelona, Spain.
   [Varas, David; Morros Rubio, Josep Ramon; Ruiz-Hidalgo, Javier] Univ Politecn Cataluna, C Jordi Girona 1-3, Barcelona, Spain.
   [Morros Rubio, Josep Ramon] Univ Politecn Cataluna, Telecommun, C Jordi Girona 1-3, Barcelona, Spain.
   [Marques, Ferran] Univ Politecn Cataluna, Dept Signal Theory & Commun, C Jordi Girona 1-3, Barcelona, Spain.
   [Marques, Ferran] Univ Politecn Cataluna, Elect Engn Sch ETSETB TelecomBCN, C Jordi Girona 1-3, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya; Universitat Politecnica de
   Catalunya; Universitat Politecnica de Catalunya; Universitat Politecnica
   de Catalunya; Universitat Politecnica de Catalunya
RP Duch, M (corresponding author), Univ Politecn Cataluna, Image Proc Grp, C Jordi Girona 1-3, Barcelona, Spain.
EM marc.maceira@upc.edu; david.varas@upc.edu; ramon.morros@upc.edu;
   j.ruiz@upc.edu; ferran.marques@upc.edu
RI Ruiz-Hidalgo, Javier/F-8137-2013
FU Spanish Ministerio de Economia y Competitividad [TEC2013-43935-R,
   TEC2016-75976-R]; European Regional Development Fund (ERDF)
FX This work has been developed in the framework of projects
   TEC2013-43935-R and TEC2016-75976-R, financed by the Spanish Ministerio
   de Economia y Competitividad and the European Regional Development Fund
   (ERDF)
CR [Anonymous], 2012, ECCV
   [Anonymous], DEPTH IMAGE BASED RE
   Barrera Fernando, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P194, DOI 10.1109/3DV.2014.57
   Charikar M, 2003, ANN IEEE SYMP FOUND, P524, DOI 10.1109/SFCS.2003.1238225
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Gao Y, 2016, IEEE T IMAGE PROCESS, V25, P134, DOI 10.1109/TIP.2015.2498400
   Glasner D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2385, DOI 10.1109/CVPR.2011.5995436
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Kowdle A, 2012, LECT NOTES COMPUT SC, V7576, P789, DOI 10.1007/978-3-642-33715-4_57
   Liang B, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P76
   Lucas LFR, 2015, IEEE T IMAGE PROCESS, V24, P4055, DOI 10.1109/TIP.2015.2456509
   Maceira M, 2016, MULTIMED TOOLS APPL, P1
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Micusik Branislav, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2906, DOI 10.1109/CVPRW.2009.5206535
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Özkalayci BO, 2014, IEEE T IMAGE PROCESS, V23, P5222, DOI 10.1109/TIP.2014.2360452
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rusanovskyy D, 2011, ISOIECJTC1SC29WG MPE
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Schwarz LA, 2011, 2011 IEEE WORKSH APP, P664
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Torres L, 1996, 2 GENERATION VIDEO C, P1
   Varas D, 2015, IEEE I CONF COMP VIS, P4579, DOI 10.1109/ICCV.2015.520
   Verleysen C, 2016, IEEE C COMP VIS PATT
   Wang AR, 2015, IEEE T IMAGE PROCESS, V24, P4459, DOI 10.1109/TIP.2015.2465133
   Yin F, 2015, IET COMPUT VIS, V9, P25, DOI 10.1049/iet-cvi.2013.0261
   Zhang J, 2011, ISOIECJTC1SC29WG11
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 36
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19869
EP 19894
DI 10.1007/s11042-017-5409-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500045
DA 2024-07-18
ER

PT J
AU Wang, Y
   Pan, ZB
   Li, R
   Zhou, ZL
AF Wang, Yang
   Pan, Zhibin
   Li, Rui
   Zhou, Zhili
TI New SMVQ scheme with exactly the same PSNR of VQ by introducing extend
   state codebook
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VQ; SMVQ; Image coding; Extend state codebook
ID VECTOR QUANTIZATION; SIDE MATCH; INDEX; COMPRESSION; QUANTIZERS;
   ALGORITHM; DESIGN; IMAGES
AB Side match vector quantization (SMVQ) is an effective coding technique and it has been widely used in low bit rate image compression and data hiding techniques. It utilizes the correlations between neighboring blocks to better generate a small fixed-size state codebook for each input vector. However, compared with vector quantization (VQ) scheme, the quality of SMVQ-coded image is substantially decreased when bit rate (BR) becomes low. This paper proposes a new side match vector quantization scheme which is based on using extend state codebook (ESCSMVQ). Experimental results show that comparing to conventional SMVQ, the bit rate of ESCSMVQ can be significantly reduced meanwhile keeping the exactly same quality of VQ-coded image.
C1 [Wang, Yang; Pan, Zhibin; Li, Rui] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
   [Zhou, Zhili] Nanjing Univ, Sch Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Wang, Y (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
EM wty2977892@126.com
RI Pan, Zhibin/I-8212-2012
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Open Research Fund of Key Laboratory of Spectral
   Imaging Technology, Chinese Academy of Sciences [LSIT201606D];
   Industrial Program of Zhejiang Province [2016C31090]; Key Science and
   Technology Program of Shaanxi Province [2016GY-097]
FX This work is supported in part by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), the Open
   Research Fund of Key Laboratory of Spectral Imaging Technology, Chinese
   Academy of Sciences (Grant No. LSIT201606D), the Industrial Program of
   Zhejiang Province (Grant No. 2016C31090) and the Key Science and
   Technology Program of Shaanxi Province (Grant No. 2016GY-097).
CR Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chen CC, 2010, SIGNAL PROCESS, V90, P2141, DOI 10.1016/j.sigpro.2010.01.018
   DUNHAM MO, 1985, IEEE T COMMUN, V33, P83, DOI 10.1109/TCOM.1985.1096198
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ma XX, 2015, IET IMAGE PROCESS, V9, P290, DOI 10.1049/iet-ipr.2014.0125
   Manohar K, 2017, MULTIMED TOOLS APPL, V4, P1
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Wang LF, 2017, MULTIMED TOOLS APPL, V76, P26225, DOI 10.1007/s11042-016-4108-5
   Wei HC, 2000, IEEE T CIRC SYST VID, V10, P51, DOI 10.1109/76.825858
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 15
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21571
EP 21588
DI 10.1007/s11042-017-5584-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300055
DA 2024-07-18
ER

PT J
AU Yang, B
   Liao, XF
AF Yang, Bo
   Liao, Xiaofeng
TI A new color image encryption scheme based on logistic map over the
   finite field Z<sub><i>N</i></sub>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption scheme; Chaotic systems; Logistic map; Information security;
   Finite field
ID ARNOLD CAT MAP; PERIOD DISTRIBUTION; FOURIER-TRANSFORM; ALGORITHM;
   PERMUTATION; DIFFUSION
AB In recent years, various image encryption algorithms based on chaotic systems have been proposed where the chaotic maps always work over the real domain. However, the traditional chaotic map over the real domain has a disadvantage, i.e., the calculation complexity of the floating point number can be doubled when implementing the map in computer. This leads to a greatly serious drawback for practical application. To overcome this problem effectively, in this paper, we generalize the chaotic Logistic map to the finite field, and find that there exists an automorphic mapping between two Logistic maps with the different control parameters over the finite field Z(N). Moreover, we adopt the sequences generated by the automorphic mapping to design a color image encryption scheme and do simulation experiments. Security and performance analyzes also show that the proposed scheme has very good properties which provide a strong guarantee for the algorithm efficiency. Therefore, the proposed scheme is feasible for implementing image and data encryption.
C1 [Yang, Bo; Liao, Xiaofeng] Southwest Univ, Chongqing Key Lab Nonlinear Circuits & Intelligen, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Chongqing Key Lab Nonlinear Circuits & Intelligen, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM yungbo@126.com; xfliao@swu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Key Research and Development Program of China [2016 YFB
   0800601]; National Natural Science Foundation of China [61472331];
   Talents of Science and Technology Promote Plan, Chongqing Science &
   Technology Commission
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016 YFB 0800601, in part by
   the National Natural Science Foundation of China under Grant 61472331,
   in part by the Talents of Science and Technology Promote Plan, Chongqing
   Science & Technology Commission.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Arroyo D, 2011, COMMUN NONLINEAR SCI, V16, P805, DOI 10.1016/j.cnsns.2010.04.031
   Chen F, 2013, IEEE T INFORM THEORY, V59, P3249, DOI 10.1109/TIT.2012.2235907
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li M, 2016, OPT LASER TECHNOL, V86, P33, DOI 10.1016/j.optlastec.2016.06.012
   Lima JB, 2014, SIGNAL PROCESS, V94, P521, DOI 10.1016/j.sigpro.2013.07.020
   Lima JB, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1071, DOI 10.1109/GlobalSIP.2015.7418362
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Mishra DC, 2014, FRACTALS, V22, P27
   Miyazaki T, 2013, P 30 S CRYPT INF SEC
   Miyazaki T, 2010, IEICE T FUND ELECTR, VE93A, P2258, DOI 10.1587/transfun.E93.A.2258
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Schneier B, 2015, APPL CRYPTOGRAPHY PR
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tong XJ, 2010, SCI CHINA INFORM SCI, V53, P191, DOI 10.1007/s11432-010-0010-3
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wu Y, 2011, J SELECTED AREAS TEL
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P3477, DOI 10.1007/s11128-013-0612-y
   Yin RM, 2012, SCI CHINA INFORM SCI, V55, P1162, DOI 10.1007/s11432-011-4401-x
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P78, DOI 10.1109/CICT.2015.134
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
NR 34
TC 47
Z9 47
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21803
EP 21821
DI 10.1007/s11042-017-5590-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300065
DA 2024-07-18
ER

PT J
AU Aldahdooh, A
   Barkowsky, M
   Le Callet, P
AF Aldahdooh, Ahmed
   Barkowsky, Marcus
   Le Callet, Patrick
TI Proof-of-concept: role of generic content characteristics in optimizing
   video encoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-aware coding; Video content features; Execution
   time(Complexity); HEVC; UHD
ID ERROR CONCEALMENT; MOTION ESTIMATION; DISTORTION OPTIMIZATION; MODE
   DECISION; ALGORITHM; COMPLEXITY
AB The influence of content characteristics on the efficiency of redundancy and irrelevance reduction in video coding is well known. Each new standard in video coding includes additional coding tools that potentially increase the complexity of the encoding process in order to gain further rate-distortion efficiency. In order to be versatile, encoder implementations often neglect the content dependency or they optimize the encoding complexity on a local scale, i.e. on a single frame or on the coding unit level without being aware of the global content type. In this contribution, an analysis is presented which coding tool settings of the recent High Efficiency Video Coding (HEVC) standard are most efficient for a given content type when balancing rate-distortion against computational complexity measured in encoding time. The content type is algorithmically determined, leading to a framework for rate-distortion-complexity based encoder parameter decision for any given video sequence. The implementability is demonstrated using a set of 35 Ultra-HD (UHD) sequences. The performance results and evaluations show that the encoding parameters may be predicted to optimize the video coding. For instance, predicting motion search range achieves complexity reduction of 36% on average when HEVC reference HM is used at a cost of bitrate (2%). When another HEVC coding standard software, x265, is used to predict the coding unit (CU) size, there is a reduction of 20% in bitrate and of 8% in distortion but there is a reduction of 6% in execution time.
C1 [Aldahdooh, Ahmed; Barkowsky, Marcus; Le Callet, Patrick] Univ Nantes, Lab Sci Numer Nantes LS2N, UMR 6004, Nantes, France.
C3 Nantes Universite
RP Aldahdooh, A (corresponding author), Univ Nantes, Lab Sci Numer Nantes LS2N, UMR 6004, Nantes, France.
EM Ahmed.Aldahdooh@univ-nantes.fr; Marcus.Barkowsky@univ-nantes.fr;
   Patrick.LeCallet@univ-nantes.fr
RI Le Callet, Patrick/F-5772-2010
FU Marie Sktodowska-Curie under the PROVISION (PeRceptually Optimised VIdeo
   CompresSION) project [608231]; FP7-PEOPLE-2013-ITN
FX This work is supported by the Marie Sktodowska-Curie under the PROVISION
   (PeRceptually Optimised VIdeo CompresSION) project bearing Grant Number
   608231 and Call Identifier: FP7-PEOPLE-2013-ITN.
CR Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   Aldahdooh A, 2016, COMPARING SIMPLE VID
   Aldandooh A, 2015, INT CONF SYST SIGNAL, P45, DOI 10.1109/IWSSIP.2015.7314173
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], IM PROC 2007 ICIP 20
   [Anonymous], ITU T H 265 HIGH EFF
   [Anonymous], DIGITAL VIDEO INDEXI
   [Anonymous], CD ROM P 2 INT WORKS
   [Anonymous], 1999, SUBJ VID QUAL ASS ME
   [Anonymous], P IPSN IEEE ACM
   [Anonymous], ICME 03 P 2003 INT C
   [Anonymous], 2016, P PICT COD S PCS
   [Anonymous], 3 3 ISOTROPIC GRADIE
   [Anonymous], 2015, INT J SIGNAL PROCESS
   [Anonymous], 2007, P 3 INT WORKSH VID P
   [Anonymous], P 7 INT WORKSH VID P
   [Anonymous], VAL OBJ MOD MULT QUA
   [Anonymous], P 5 INT WORKSH VID P
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2017, The Zettabyte Era: Trends and analysis
   [Anonymous], ACOUST SPEECH SIG PR
   [Anonymous], 2002, NATL TELECOMMUNICATI
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Cen S, 2003, IEEE T MULTIMEDIA, V5, P1, DOI 10.1109/TMM.2003.808825
   Cen YF, 2015, INFORM PROCESS LETT, V115, P719, DOI 10.1016/j.ipl.2015.04.001
   Chiu MY, 2010, IEEE T CONSUM ELECTR, V56, P895, DOI 10.1109/TCE.2010.5506017
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Corrêa G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P425, DOI 10.1109/PCS.2012.6213378
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He J, 2015, INT J GRID DISTRIB, V8, P289, DOI 10.14257/ijgdc.2015.8.4.28
   Huang SC, 2008, IEEE T BROADCAST, V54, P499, DOI 10.1109/TBC.2008.2001150
   Jie Leng, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P56, DOI 10.1109/CMSP.2011.167
   Kim JH, 2008, J VIS COMMUN IMAGE R, V19, P175, DOI 10.1016/j.jvcir.2007.09.001
   Li X, 2011, IEEE T CIRC SYST VID, V21, P957, DOI 10.1109/TCSVT.2011.2133750
   Nguyen VA, 2015, IEEE INT SYMP CIRC S, P1286, DOI 10.1109/ISCAS.2015.7168876
   Ortiz-Jaramillo B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013011
   Pinson MH, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-50
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Saponara S, 2006, IEEE T CONSUM ELECTR, V52, P232, DOI 10.1109/TCE.2006.1605052
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Song L, 2013, INT WORK QUAL MULTIM, P34, DOI 10.1109/QoMEX.2013.6603201
   Srinivasan G.N., 2008, Engineering and Technology, V36, P1264
   Su L, 2009, IEEE T CIRC SYST VID, V19, P477, DOI 10.1109/TCSVT.2009.2014017
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Yu J, 2001, PATTERN RECOGN LETT, V22, P1379, DOI 10.1016/S0167-8655(01)00085-X
   Zhang L, 2007, IEEE T CONSUM ELECTR, V53, P749, DOI 10.1109/TCE.2007.381755
   Zhang RF, 2004, IEEE T CONSUM ELECTR, V50, P335, DOI 10.1109/TCE.2004.1277882
   Zhao DY, 2015, OPTIK, V126, P4212, DOI 10.1016/j.ijleo.2015.08.035
   Zhu KF, 2013, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2013.6738011
NR 56
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16113
EP 16141
DI 10.1007/s11042-017-5180-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300004
DA 2024-07-18
ER

PT J
AU Rao, TR
   Xu, M
   Liu, HY
AF Rao, Tianrong
   Xu, Min
   Liu, Huiying
TI Generating affective maps for images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective map; Affective image classification; Visual saliency; Multiple
   instance learning
ID ATTENTION; MODEL
AB Affective image analysis, which estimates humans' emotion reflection on images, has attracted increasing attention. Most of the existing methods focus on developing efficient visual features according to theoretical and empirical concepts, and extract these features from an image as a whole. However, analyzing emotion from an entire image, can only extract the dominant emotion conveyed by the whole image, which ignores the affective differences existing among different regions within the image. This may reduce the performance of emotion recognition, and limit the range of possible applications. In this paper, we are the first to propose the concept of affective map, by which image emotion can be represented at region-level. In an affective map, the value of each pixel represents the probability of the pixel belonging to a certain emotion category. Two popular application exemplars, i.e. affective image classification and visual saliency computing, are explored to prove the effectiveness of the proposed affective map. Analyzing detailed image emotion at a region-level, the accuracy of affective image classification has been improved 5.1% on average. The Area Under the Curve (AUC) of visual saliency detection has been improved 15% on average.
C1 [Rao, Tianrong; Xu, Min] Univ Technol, FEIT, Sydney, NSW, Australia.
   [Liu, Huiying] Inst Infocomm Res, Comp Sci, Singapore, Singapore.
C3 University of Technology Sydney; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Xu, M (corresponding author), Univ Technol, FEIT, Sydney, NSW, Australia.
EM tianrong.rao@student.uts.edu.au; min.xu@uts.edu.au;
   liuhy@i2r.a-star.edu.sg
OI Xu, Min/0000-0001-9581-8849
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   ANTONISSE HJ, 1982, COMPUT VISION GRAPH, V19, P367, DOI 10.1016/0146-664X(82)90022-3
   Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Guo MW, 2014, NEUROCOMPUTING, V144, P184, DOI 10.1016/j.neucom.2014.04.054
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Lang PJ, 2008, INT AFFECTIVE PICTUR
   Lee MF, 2016, MULTIMED TOOLS APPL, V75, P15185, DOI 10.1007/s11042-014-2231-8
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Liu HY, 2016, IEEE T NEUR NET LEAR, V27, P1201, DOI 10.1109/TNNLS.2016.2553579
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Peters R.J., 2007, P IEEE C COMPUTER VI, P1
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Siersdorfer S., 2010, ACM MM, P715
   Solli M, 2009, LECT NOTES COMPUT SC, V5702, P573, DOI 10.1007/978-3-642-03767-2_70
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P1863, DOI 10.1007/s11042-013-1722-3
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P4679, DOI 10.1007/s11042-013-1830-0
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Xu M., 2008, Proceeding of the 16th ACM International Conference on Multimedia, P677, DOI DOI 10.1145/1459359.1459457
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Xu M, 2008, LECT NOTES COMPUT SC, V5353, P685
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Zhang H., 2015, Neurocomputing
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 40
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17247
EP 17267
DI 10.1007/s11042-017-5289-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300056
DA 2024-07-18
ER

PT J
AU Sun, Z
   Hu, ZP
   Wang, M
AF Sun, Zhe
   Hu, Zheng-ping
   Wang, Meng
TI Influenced factors reduction for robust facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Influenced factors reduction; Difference
   dictionary; Extended dictionary; Optimal training samples
ID SPARSE REPRESENTATION; FACE RECOGNITION; FEATURES; EMOTION; IMAGE;
   CLASSIFICATION; ALGORITHM
AB The performance of facial expression recognition (FER) would be degraded due to the influenced factors such as individual differences and limited number of training samples. Therefore, reducing the influenced factors in facial images may be useful for improving the performances of FER. In this paper, we propose to reduce the influenced factors for robust FER. First, we reduce the influences of individual differences by the auxiliary neutral dictionary and obtain the feature space which highlights the expression features. Then we exploit the difference training samples to synthesize the virtual training samples to alleviate the influenced factors of the limited training samples. Third, we combine the difference dictionary with virtual training samples to form the extended dictionary and select the optimal training samples from the extended dictionary. Finally, we exploit the optimal training samples based a"" (2)-norm representation algorithm for the classification.
C1 [Sun, Zhe; Hu, Zheng-ping; Wang, Meng] Yanshan Univ, Dept Informat Sci & Engn, Fac Elect & Commun, Qinhuangdao 066004, Peoples R China.
   [Wang, Meng] Taishan Univ, Fac Elect Engn, Dept Phys & Elect Engn, Tai An 271000, Shandong, Peoples R China.
C3 Yanshan University; Taishan University
RP Hu, ZP (corresponding author), Yanshan Univ, Dept Informat Sci & Engn, Fac Elect & Commun, Qinhuangdao 066004, Peoples R China.
EM hzp_ysu@163.com
FU National Natural Science Foundation of China [61071199, 61771420];
   Natural Science Foundation of Hebei Province of China [F2016203422];
   Postgraduate Innovation Project of Hebei Province [CXZZBS2017051]
FX This work is supported by National Natural Science Foundation of China
   (No. 61071199), National Natural Science Foundation of China under Grant
   (No. 61771420), Natural Science Foundation of Hebei Province of China
   (No. F2016203422), and Postgraduate Innovation Project of Hebei Province
   (No. CXZZBS2017051). The authors declare that there is no conflict of
   interests regarding the publication of this paper.
CR [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   [Anonymous], 2010, UCBEECS201013
   Blockmans B, 2015, INT J NUMER METH ENG, V102, P1162, DOI 10.1002/nme.4831
   Cotter SF, 2010, INT CONF ACOUST SPEE, P838, DOI 10.1109/ICASSP.2010.5494903
   EKMAN P, 1986, MOTIV EMOTION, V10, P159, DOI 10.1007/BF00992253
   Ekman P, 1998, EMOTION HUMAN FACE, V43, P45
   Geng Y., 2016, ARXIV160908417
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Kapoor R, 2015, IET COMPUT VIS, V9, P226, DOI 10.1049/iet-cvi.2013.0316
   Koç M, 2014, NEUROCOMPUTING, V131, P331, DOI 10.1016/j.neucom.2013.10.009
   Lee SH, 2016, PATTERN RECOGN, V54, P52, DOI 10.1016/j.patcog.2015.12.016
   Lee SH, 2014, IEEE T AFFECT COMPUT, V5, P340, DOI 10.1109/TAFFC.2014.2346515
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liu J, 2007, LECT NOTES COMPUT SC, V4778, P205
   Liu WF, 2012, I C CONT AUTOMAT ROB, P1402, DOI 10.1109/ICARCV.2012.6485394
   Liu WY, 2014, IEEE IMAGE PROC, P4241, DOI 10.1109/ICIP.2014.7025861
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Ma D, 2015, J COMPUT METHODS SCI, V15, P537, DOI 10.3233/JCM-150566
   Pablos SM, 2015, INTERACT COMPUT, V27, P99, DOI 10.1093/iwc/iwt057
   Mery D, 2015, PATTERN RECOGN LETT, V68, P260, DOI 10.1016/j.patrec.2015.05.005
   Min X, 2015, METALL MIN IND, V7, P186
   Ouamane A., 2015, Pattern Recognition and Image Analysis, V25, P603
   Ouyang Y, 2013, OPTIK, V124, P6827, DOI 10.1016/j.ijleo.2013.05.076
   Ruan J., 2014, J INFORM COMPUTATION, V11, P295
   Shao J, 2015, PATTERN RECOGN LETT, V65, P157, DOI 10.1016/j.patrec.2015.07.039
   Sharma A, 2010, NEUROCOMPUTING, V73, P1868, DOI 10.1016/j.neucom.2009.10.027
   Shikkenawis G, 2016, NEUROCOMPUTING, V173, P196, DOI 10.1016/j.neucom.2015.01.100
   Shiqing Zhang, 2012, WSEAS Transactions on Systems, V11, P440
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Vetter T, 1998, INT J COMPUT VISION, V28, P103, DOI 10.1023/A:1008058932445
   Wang QW, 2014, APPL MECH MATER, V511-512, P433, DOI 10.4028/www.scientific.net/AMM.511-512.433
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang Z, 2012, 2012 IEEE INFORMATION THEORY WORKSHOP (ITW), P222, DOI [10.1109/ICNC.2012.6234551, 10.1109/ITW.2012.6404663]
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yusuf R, 2016, ARTIF LIFE ROBOT, V21, P85, DOI 10.1007/s10015-016-0263-z
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 41
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16947
EP 16963
DI 10.1007/s11042-017-5264-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300043
DA 2024-07-18
ER

PT J
AU Terbeh, N
   Trigui, A
   Maraoui, M
   Zrigui, M
AF Terbeh, Naim
   Trigui, Aymen
   Maraoui, Mohsen
   Zrigui, Mounir
TI Correction of pathological speeches and assistance to learners with
   vocal disabilities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthy speech; Pathological speech; Probabilistic-phonetic model;
   Speech correction; Voice pathologies; Non-native speaker; Arabic
   vocabulary learning
AB This work describes a new methodology for correcting voice defects contained in the Arabic speeches and assisting learners of Arabic vocabulary. For this purpose, we follow four stages. The first step consists in localizing the vocal disabilities which degrade an Arabic voice signal, so we focus on comparing between a referenced probabilistic-phonetic model and a speaker model. Second, we differentiate two cases: Degraded speeches can be generated from pathological problems, or it can be produced by non arabophone learners. Hence, we compare between forced alignment scores. Third, we develop a new algorithm to correct pathological pronunciations. The last task is the conception of an application assisting learners of Arabic vocabulary in improving their pronunciation. The achieved results are encouraging. Moreover, learners of Arabic vocabulary have presented a good amelioration using the developed application. A lot of applications that design systems of voice signal processing can use our proposition.
C1 [Terbeh, Naim; Trigui, Aymen; Zrigui, Mounir] LaTICE Lab, Monastir, Tunisia.
   [Maraoui, Mohsen] Computat Math Lab, Monastir, Tunisia.
RP Terbeh, N (corresponding author), LaTICE Lab, Monastir, Tunisia.
EM naim.terbeh@gmail.com
RI Maraoui, Mohsen/AAG-8991-2020
OI , Naim/0000-0003-1146-1147
CR Ajibola AS, 2016, KOMPUTER DAN INFORM
   Alghamdi M, 2004, KING SAUD U J COMPUT, V16
   Aljawarneh Shadi, 2011, Network Security, V2011, P12, DOI 10.1016/S1353-4858(11)70026-5
   [Anonymous], P EACL 2009 WORKSH C
   Ayadi R, 2016, SCIENCE, V117
   Bassil Youssef, 2012, INT J ADV COMPUTER S, V3
   Belgacem M., 2011, THESIS
   Blanc-Brude T., 2004, THESIS
   Brehilin L., 2000, MODELES MARKOV CACHE
   Elshafei M., 2006, P 18 NAT COMP C RIYA
   Elshafei M, 2002, TECHNIQUES HIGH QUAL
   Haffar N, 2016, INT C ENG MIS ICEMIS
   Hawashin B, 2013, INT J COMPUT APPL, V83
   Kaki S., 1998, COLING ACL
   Majidnezhad V., 2012, IJCSI INT J COMPUTER, V9
   Majidnezhad V., 2013, INT J COMPUTER APPL, V62
   Maraoui M, 2012, INT J COMPUT PROC OR, V24
   Meddeb O, 2016, 2016 INTERNATIONAL CONFERENCE ON ENGINEERING & MIS (ICEMIS)
   Paquet P., 1997, UTILISATION RESEAUX
   Patané G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6
   Setlur AR, 1996, P INT C SPOK LANG PR
   Terbeh N., 2015, CICLING 2015
   Terbeh N, 2016, INT C ENG MIS ICEMIS
   Terbeh N., 2013, ICTA 2013
   Terbeh N, 2016, INT C COMP COLL INT
   Terbeh N., 2014, VERS CORRECTION AUTO
   Vu HH, 2015, 22 TRAITEMENT AUTOMA
   Wali Wafa, 2017, Vietnam Journal of Computer Science, V4, P51, DOI 10.1007/s40595-016-0080-2
   Zhou Z, 2006, P INT C SPOK LANG PR
NR 29
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17779
EP 17802
DI 10.1007/s11042-017-5447-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900012
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zhang, WM
   Liang, D
   Yu, NH
AF Yang, Yang
   Zhang, Weiming
   Liang, Dong
   Yu, Nenghai
TI A ROI-based high capacity reversible data hiding scheme with contrast
   enhancement for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Reversible data hiding; Image segmentation; Contrast
   enhancement; High capacity
ID INTEGER WAVELET TRANSFORM; DIFFERENCE EXPANSION; QUALITY ASSESSMENT;
   HISTOGRAM-MODIFICATION; WATERMARKING; PREDICTION; AUTHENTICATION;
   SIMILARITY; MECHANISM
AB In this paper, we attempt to investigate the secure archiving of medical images which are stored on semi-trusted cloud servers, and focus on addressing the complicated and challenging integrity control and privacy preservation issues. With the intention of protecting the medical images stored on a semi-trusted server, a novel ROI-based high capacity reversible data hiding (RDH) scheme with contrast enhancement is proposed in this paper. The proposed method aims at improving the quality of the medical images effectively and embedding high capacity data reversibly meanwhile. Therefore, the proposed method adopts "adaptive threshold detector" (ATD) segmentation algorithm to automatically separate the "region of interest" (ROI) and "region of non-interest" (NROI) at first, then enhances the contrast of the ROI region by stretching the grayscale and embeds the data into peak bins of the stretched histogram without extending the histogram bins. Lastly, the rest of the required large of data are embedded into NROI region regardless its quality. In addition, the proposed method records the edge location of the segmentation instead of recording the location of the overflow and underflow. The experiment shows that the proposed method can improve the quality of medical images obviously whatever in low embedding rate or high embedding rate when compared with other contrast-based RDH methods.
C1 [Yang, Yang; Liang, Dong] Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Anhui, Peoples R China.
   [Yang, Yang; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
EM skyyang@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; dliang@ahu.edu.cn;
   ynh@ustc.edu.cn
RI Dong, Liang/JZD-4605-2024
OI Yang, Yang/0000-0003-1048-7994
FU Natural Science Foundation of China [U1636201, 61572452, 61502007];
   Natural Science Research Project of Anhui province [1608085MF125]; China
   Postdoctoral Science Foundation [58, 2015M582015]; backbone teacher
   training program of Anhui University; Doctoral Scientific Research
   Foundation of Anhui University [J01001319]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201,61572452,61502007, in part by the Natural
   Science Research Project of Anhui province under Grant 1608085MF125, in
   part by the NO. 58 China Postdoctoral Science Foundation under Grant
   2015M582015, in part by the backbone teacher training program of Anhui
   University, in part by the Doctoral Scientific Research Foundation of
   Anhui University under Grant J01001319.
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   [Anonymous], P 42 ANN ALL C COMM
   Bao F, 2005, IEEE T INF TECHNOL B, V9, P554, DOI 10.1109/TITB.2005.855556
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Gao M.-Z., 2013, Adv. Intell. Syst. Appl., V2, P331, DOI [10.1007/978-3-642-35473-133, DOI 10.1007/978-3-642-35473-133]
   Gonzalez RC, 2004, DIGITAL IMAGE PROCES, P71
   Hiary S, 2016, MULTIMED TOOLS APPL, P1
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Jemmett DG, 2012, MED IMAGING ARCH DEL, P1
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pai PY, 2011, INFORM SCIENCES, V181, P1463, DOI 10.1016/j.ins.2010.12.007
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Yang Y, 2016, SIGNAL PROCESS, V120, P797, DOI 10.1016/j.sigpro.2015.03.019
   Yin ZX, 2016, SECUR COMMUN NETW, V9, P721, DOI 10.1002/sec.1275
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
NR 43
TC 39
Z9 42
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18043
EP 18065
DI 10.1007/s11042-017-4444-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900026
DA 2024-07-18
ER

PT J
AU Yi, Y
   Hu, P
   Deng, XK
AF Yi, Yang
   Hu, Pan
   Deng, Xiaokang
TI Human action recognition with salient trajectories and multiple kernel
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Bag-of-visual-words; Trajectories filter;
   Clustering; Multiple kernel learning
ID SPATIOTEMPORAL CONTEXT; FEATURES
AB Action recognition in videos plays an important role in the field of computer vision and multimedia, and there exist lots of challenges due to the complexity of spatial and temporal information. Trajectory-based approach has shown to be efficient recently, and a new framework and algorithm of trajectory space information based multiple kernel learning (TSI-MKL) is exploited in this paper. First, dense trajectories are extracted as raw features, and three saliency maps are computed corresponding to color, space, and optical flow on frames at the same time. Secondly, a new method combining above saliency maps is proposed to filter the achieved trajectories, by which a set of salient trajectories only containing foreground motion regions is obtained. Afterwards, a novel two-layer clustering is developed to cluster the obtained trajectories into several semantic groups and the ultimate video representation is generated by encoding each group. Finally, representations of different semantic groups are fed into the proposed kernel function of a multiple kernel classifier. Experiments are conducted on three popular video action datasets and the results demonstrate that our presented approach performs competitively compared with the state-of-the-art.
C1 [Yi, Yang; Hu, Pan; Deng, Xiaokang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Yi, Yang] Sun Yat Sen Univ, Xinhua Coll, Guangzhou 510520, Guangdong, Peoples R China.
   [Yi, Yang] Guangdong Prov Key Lab Big Data Anal & Proc, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Deng, XK (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM dengxk@mail2.sysu.edu.cn
RI Yi, Yang/AFP-5892-2022
FU National Natural Science Foundation of China [61672546, 61573385];
   Guangzhou Science and Technology Project [201707010127]
FX The paper is partly supported by National Natural Science Foundation of
   China with No. 61672546 and No. 61573385 and Guangzhou Science and
   Technology Project with No. 201707010127.
CR Achanta R., 2010, SLIC Superpixels
   Aihara K, 2015, MULTIMED TOOLS APPL, V74, P6303, DOI 10.1007/s11042-014-2112-1
   [Anonymous], P AS C COMP VIS
   [Anonymous], 7 INT C KNOWL SYST E
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], IEEE INT C CONS EL C
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], BRIT MACH VIS C
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], C NEUR INF PROC SYST
   Ballas N, 2013, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2013.336
   Fathi A., 2008, IEEE C COMPUTER VISI
   Feichtenhofer C, 2015, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2015.7298892
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gu YF, 2016, NEUROCOMPUTING, V173, P1630, DOI 10.1016/j.neucom.2015.09.035
   Guo ZX, 2013, IEEE IMAGE PROC, P3745, DOI 10.1109/ICIP.2013.6738772
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hsieh CY, 2017, MULTIMED TOOLS APPL, V76, P7575, DOI 10.1007/s11042-016-3407-1
   Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Ni BB, 2015, INT J COMPUT VISION, V111, P229, DOI 10.1007/s11263-014-0742-4
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   de Souza CR, 2016, LECT NOTES COMPUT SC, V9911, P697, DOI 10.1007/978-3-319-46478-7_43
   Rodriguez M. D., 2008, IEEE C COMPUTER VISI, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sheng BY, 2015, NEUROCOMPUTING, V158, P73, DOI 10.1016/j.neucom.2015.01.064
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Theodorakopoulos I, 2014, J VIS COMMUN IMAGE R, V25, P12, DOI 10.1016/j.jvcir.2013.03.008
   Tuia D, 2010, IEEE T GEOSCI REMOTE, V48, P3780, DOI 10.1109/TGRS.2010.2049496
   Vig E, 2012, IEEE IMAGE PROC, P1405, DOI 10.1109/ICIP.2012.6467132
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Yang J., 2015, Int. J. Signal Process. Image Process. Pattern Recognit, V8, P241, DOI [10.14257/ijsip.2015.8.1.21, DOI 10.14257/IJSIP.2015.8.1.21]
   Yi Y, 2017, EXPERT SYST APPL, V75, P44, DOI 10.1016/j.eswa.2017.01.008
   Yi Y, 2013, SIGNAL PROCESS, V93, P2932, DOI 10.1016/j.sigpro.2013.05.002
   Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001
NR 42
TC 7
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17709
EP 17730
DI 10.1007/s11042-017-5209-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900009
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhu, XD
   Qin, C
   Yang, CF
   Luo, XY
AF Zhang, Yi
   Zhu, Xiaodong
   Qin, Chuan
   Yang, Chunfang
   Luo, Xiangyang
TI Dither modulation based adaptive steganography resisting jpeg
   compression and statistic detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; JPEG compression resistant; Detection resistant; Dither
   modulation; Side information
ID WATERMARKING
AB In order to improve the JPEG compression resistant performance of the current steganogrpahy algorithms resisting statistic detection, an adaptive steganography algorithm resisting JPEG compression and detection based on dither modulation is proposed. Utilizing the adaptive dither modulation algorithm based on the quantization tables, the embedding domains resisting JPEG compression for spatial images and JPEG images are determined separately. Then the embedding cost function is constructed by the embedding costs calculation algorithm based on side information. Finally, the RS coding is combined with the STCs to realize the minimum costs messages embedding while improving the correct rates of the extracted messages after JPEG compression. The experimental results demonstrate that the algorithm can be applied to both spatial images and JPEG images. Compared with the current S-UNIWARD steganography, the message extraction error rates of the proposed algorithm after JPEG compression decrease from about 50 % to nearly 0; compared with the current JPEG compression and detection resistant steganography algorithms, the proposed algorithm not only possesses the comparable JPEG compression resistant ability, but also has a stronger detection resistant performance and a higher operation efficiency.
C1 [Zhang, Yi; Zhu, Xiaodong; Yang, Chunfang; Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
   [Zhang, Yi; Zhu, Xiaodong; Yang, Chunfang; Luo, Xiangyang] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; University of Shanghai for Science & Technology
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.; Luo, XY (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM tzyy4001@sina.com; zhuxd11@qq.com; qin@usst.edu.cn;
   chunfangyang@126.com; luoxy_icu@sina.com
RI Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU National Nature Science Foundation of China [U1636219, 61379151,
   61401512, 61572052]; Excellent Youth Foundation of Henan Province of
   China [144100510001]
FX This work was supported by the National Nature Science Foundation of
   China (Grant No. U1636219, 61379151, 61401512, and 61572052), the
   Excellent Youth Foundation of Henan Province of China (No.
   144100510001).
CR [Anonymous], 2000, Digital Watermarking
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Denemark T., 2015, PROC IEEE INT WORKSH, P1
   Filler T, 2011, P SPIE INT SOC OPTIC, V7880
   Filler T., 2010, P SPIE INT SOC OPT E, P175
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Liu WW, 2015, SECUR COMMUN NETW, V8, P1636, DOI 10.1002/sec.1111
   Luo WB, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P158, DOI 10.1109/IAI.2002.999910
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Miyazaki A, 2002, IEICE T FUND ELECTR, VE85A, P117
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shen CX, 2007, SCI CHINA SER F, V50, P273, DOI 10.1007/s11432-007-0037-2
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   [肖俊 Xiao Jun], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P552
   Zhang Y, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2016.7495547
   Zhang Y, 2016, SECUR COMMUN NETW, V9, P2957, DOI 10.1002/sec.1502
   Zhang Y, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P461, DOI 10.1109/ARES.2015.53
NR 28
TC 37
Z9 41
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17913
EP 17935
DI 10.1007/s11042-017-4506-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900019
DA 2024-07-18
ER

PT J
AU Ernawan, F
   Kabir, MN
   Zain, JM
AF Ernawan, Ferda
   Kabir, Muhammad Nomani
   Zain, Jasni Mohamad
TI Bit allocation strategy based on Psychovisual threshold in image
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit allocation; Psychovisual threshold; Image compression; Discrete
   cosine transform
ID VIDEO
AB Image compression leads to minimize the storage-requirement of an image by reducing the size of the image. This paper presents a bit allocation strategy based on psychovisual threshold in image compression considering a similar idea of audio coding. In the audio coding, a dynamic bit allocation to each signal is related to the concept of variable block coding and bit allocation is performed on either a short block or long block of sample signals. Similarity, in our technique, more bits are assigned to a local block with visually-significant low frequency order, and fewer, with visually-insignificant high frequency order. This paper presents a bit allocation strategy based on psychovisual threshold in image compression. A psychovisual threshold is developed by minimizing the visual impact on the image quality degradation in image frequency coding. This paper investigates the error generated by the discrete cosine transform and sets the maximum acceptable error as a psychovisual threshold. The average reconstruction error per pixel on frequency order is utilized to prescribe a set of bit allocations which provide a significant improvement on the quality of image reconstruction at relatively low bit rates. The experimental results show that our dynamic bit-allocation technique in image compression manages to overcome artifact images in the image output. The proposed bit allocation strategy improves the quality of image reconstruction by about 20% compared to JPEG compression. This bit allocation strategy is designed to replace the traditional role of the quantization process in image compression.
C1 [Ernawan, Ferda; Kabir, Muhammad Nomani; Zain, Jasni Mohamad] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Gambang 26300, Kuantan Pahang, Malaysia.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Ernawan, F (corresponding author), Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Gambang 26300, Kuantan Pahang, Malaysia.
EM ferda1902@gmail.com
RI Zain, Jasni Mohamad/AGU-3976-2022; Ernawan, Ferda/B-4214-2012; Zain,
   Jasni Mohamad/AAT-5170-2021; Kabir, Noman/M-4841-2016
OI Zain, Jasni Mohamad/0000-0003-2072-1510; Ernawan,
   Ferda/0000-0002-6779-1594; Kabir, Noman/0000-0003-2796-9324
FU Universiti Malaysia Pahang, Malaysia by UMP Research Grant Scheme
   [RDU160364]
FX The authors would like to express very special thanks to Universiti
   Malaysia Pahang, Malaysia for providing financial support of this
   research project by UMP Research Grant Scheme (RDU160364).
CR Abu N. A., 2015, SCI WORLD J, V2015, P001
   Abu N. A., 2014, APPL MATH SCI, V8, P6951
   Ahmed N, 1993, IEEE T COMPUT, V23
   Andra K, 2003, IEEE T CIRC SYST VID, V13, P209, DOI 10.1109/TCSVT.2003.809834
   [Anonymous], 2000, JTC1SC29WG1 ISOIEC
   [Anonymous], 2012, SC29WG1 ISOIEC
   Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   Beghdadi A, 2013, SIGNAL PROCESS-IMAGE, V28, P811, DOI 10.1016/j.image.2013.06.003
   Bovik AC, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P43, DOI 10.1016/B978-0-12-374457-9.00003-2
   Britanak V, 2010, SIGNAL PROCESS, V90, P536, DOI 10.1016/j.sigpro.2009.07.019
   Chen H, 2005, 18th International Conference on Systems Engineering, Proceedings, P270, DOI 10.1109/ICSENG.2005.28
   Chen YK, 2011, EXPERT SYST APPL, V38, P10183, DOI 10.1016/j.eswa.2011.02.071
   Cheng H, 2015, IEEE PAC RIM CONF CO, P52, DOI 10.1109/PACRIM.2015.7334808
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P3179, DOI 10.1109/TIP.2011.2158230
   Choi S, 2015, P WORLD C ENG
   Du B, 2017, IEEE T MULTIMEDIA, V19, P67, DOI 10.1109/TMM.2016.2608780
   Ernawan Ferda, 2013, Journal of Computer Science, V9, P716, DOI 10.3844/jcssp.2013.716.725
   Ernawan F., 2014, J THEORETICAL APPL I, V70, P566
   Ernawan F, 2014, ADV SCI LETT, V20, P26, DOI 10.1166/asl.2014.5255
   Ernawan F, 2014, ADV SCI LETT, V20, P70, DOI 10.1166/asl.2014.5316
   Gao W, 2016, IEEE T CIRC SYST VID, V26, P139, DOI 10.1109/TCSVT.2015.2444671
   Gelman A, 2012, IEEE T IMAGE PROCESS, V21, P4092, DOI 10.1109/TIP.2012.2201490
   Gockel H, 2002, J ACOUST SOC AM, V111, P2759, DOI 10.1121/1.1480422
   Hachicha W, 2014, IEEE IMAGE PROC, P5661, DOI 10.1109/ICIP.2014.7026145
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hunt O, 2004, P C IM VIS COMP NZ I
   Information Technology, 1994, JPEG DIG COMPR COD 1
   Kotz S., 2000, Extreme Value Distributions: Theory and Applications
   Lei JJ, 2017, MULTIMED TOOLS APPL, V76, P7661, DOI 10.1007/s11042-016-3413-3
   Malo J, 2006, IEEE T IMAGE PROCESS, V15, P68, DOI 10.1109/TIP.2005.860325
   Oizumi M, 2006, IEEE T CONSUM ELECTR, V52, P1021, DOI 10.1109/TCE.2006.1706502
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   PAN D, 1995, IEEE MULTIMEDIA, V2, P60, DOI 10.1109/93.388209
   Patchoo W, 2010, INT C EL ENG EL COMP, P1075
   Rahmalan Hidayah, 2010, Pattern Recognition and Image Analysis, V20, P505, DOI 10.1134/S1054661810040115
   Rajaei B, 2013, ANN TELECOMMUN, V68, P627, DOI 10.1007/s12243-013-0375-6
   Richter T, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.49
   Rodriguez-Sanchez, 2002, COMPUTER VISION GROU
   Sánchez-Hernández JJ, 2015, IEEE T MULTIMEDIA, V17, P1829, DOI 10.1109/TMM.2015.2470595
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Srinivasan S, 2007, 1N4183 JPEG WG
   Subramanian P., 2011, J COMPUT THEORY ENG, V3, P628
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wu G, 2010, INT C MULT INF NETW
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zadeh PB, 2010, MULTIMED TOOLS APPL, V49, P347, DOI 10.1007/s11042-009-0371-z
   Zhang XF, 2017, IEEE SIGNAL PROC LET, V24, P96, DOI 10.1109/LSP.2016.2641456
   Zhu YP, 2014, INT C PATT RECOG, P849, DOI 10.1109/ICPR.2014.156
NR 50
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13923
EP 13946
DI 10.1007/s11042-017-4999-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900037
DA 2024-07-18
ER

PT J
AU Jian, MW
   Qi, Q
   Dong, JY
   Sun, X
   Sun, YJ
   Lam, KM
AF Jian, Muwei
   Qi, Qiang
   Dong, Junyu
   Sun, Xin
   Sun, Yujuan
   Lam, Kin-Man
TI Saliency detection using quaternionic distance based weber local
   descriptor and level priors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weber descriptor; Saliency detection; Object cues; Directional cues
ID PARALLEL FRAMEWORK; HEVC; ATTENTION; FILTER
AB In this paper, a novel and efficient framework by exploiting Quaternionic Distance Based Weber Local Descriptor (QDWLD) and object cues is proposed for image saliency detection. In contrast to the existing saliency detection models, the advantage of the proposed approach is that it can combine quaternion number system and object cues simultaneously, which is independent of image contents and scenes. Firstly, QDWLD, which was initially designed for detecting outliers in color images, is used to represent the directional cues in an image. Meanwhile, two low-level priors, namely the Convex-Hull-Based center and color contrast cue of the image, are utilized and fused as an object-level cue. Finally, by combining QDWLD with object cues, a reliable saliency map of the image can be computed and estimated. Experimental results, based on two widely used and openly available database, show that the proposed method is able to produce reliable and promising salient maps/ estimations, compared to other state-of-the-art saliency-detection models.
C1 [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Jian, Muwei; Qi, Qiang; Dong, Junyu; Sun, Xin] Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266100, Peoples R China.
   [Sun, Yujuan] Ludong Univ, Coll Informat & Elect Engn, 186 Shixue Rd, Yantai 264025, Peoples R China.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Shandong University of Finance & Economics; Ocean University of China;
   Ludong University; Hong Kong Polytechnic University
RP Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.; Jian, MW (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266100, Peoples R China.
EM jianmuweihk@163.com
RI Sun, Xin/ADH-1623-2022; Jian, Muwei/Q-8319-2018
OI Sun, Xin/0000-0003-1870-9037; Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China (NSFC) [61601427,
   61602229]; Natural Science Foundation of Shandong Province
   [ZR2015FQ011]; China Postdoctoral Science Foundation [2016 M590659];
   Postdoctoral Science Foundation of Shandong Province [201603045];
   Qingdao Postdoctoral Science Foundation [861605040008]; Applied Basic
   Research Project of Qingdao [16-5-1-4-jch]; Fundamental Research Funds
   for the Central Universities [201511008, 30020084851]; Technology
   Cooperation Program of China (ISTCP) [2014DFA10410]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61601427, 61602229); Natural Science Foundation of Shandong
   Province (ZR2015FQ011); China Postdoctoral Science Foundation funded
   project (2016 M590659); Postdoctoral Science Foundation of Shandong
   Province (201603045); Qingdao Postdoctoral Science Foundation funded
   project (861605040008) and Applied Basic Research Project of Qingdao
   (16-5-1-4-jch); The Fundamental Research Funds for the Central
   Universities (201511008, 30020084851); & Technology Cooperation Program
   of China (ISTCP) (2014DFA10410).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Cai CH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P816, DOI 10.1109/ICIP.2000.899834
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Geng X, 2012, SIGNAL PROCESS, V92, P150, DOI 10.1016/j.sigpro.2011.06.015
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Guo LQ, 2014, INFORM SCIENCES, V273, P132, DOI 10.1016/j.ins.2014.03.037
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2016, ASIAPAC SIGN INFO PR
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jin LH, 2007, IEEE SIGNAL PROC LET, V14, P397, DOI 10.1109/LSP.2006.887840
   Jin LH, 2013, IEEE T CIRC SYST VID, V23, P741, DOI 10.1109/TCSVT.2012.2207272
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lei HJ, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417550102
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Li J, 2015, IET IMAGE PROCESS, V9, P977, DOI 10.1049/iet-ipr.2014.0803
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2011, IET IMAGE PROCESS, V5, P122, DOI 10.1049/iet-ipr.2009.0382
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Manipoonchelvi P, 2014, IET IMAGE PROCESS, V8, P519, DOI 10.1049/iet-ipr.2013.0434
   Oliva A., 2003, Image Processing, V1, P1
   Rahman I, 2016, MACH VISION APPL, V27, P893, DOI 10.1007/s00138-016-0754-x
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Wang A, 2017, IEEE SIGNAL PROCESS
   Wu W, 2017, IMPROVING PERFORMANC
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhong GY, 2016, VISUAL COMPUT, V32, P611, DOI 10.1007/s00371-015-1077-z
   Zhong SH, 2016, NEUROCOMPUTING, V207, P178, DOI 10.1016/j.neucom.2016.04.048
   Zhou JB, 2014, IET IMAGE PROCESS, V8, P804, DOI 10.1049/iet-ipr.2013.0599
   Zhou WH, 2014, IET COMPUT VIS, V8, P207, DOI 10.1049/iet-cvi.2013.0118
NR 45
TC 25
Z9 28
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14343
EP 14360
DI 10.1007/s11042-017-5032-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900055
DA 2024-07-18
ER

PT J
AU Kong, YQ
   Wei, ZG
   Huang, SS
AF Kong, Yongqiang
   Wei, Zhengang
   Huang, Shanshan
TI Automatic analysis of complex athlete techniques in broadcast taekwondo
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Athlete tracking; Features learning; Action recognition; Techniques
   analysis
ID SPORTS VIDEO; PERSONALIZED RETRIEVAL; MODEL
AB Athlete detection and action recognition in sports video is a very challenging task due to the dynamic and cluttered background. Several attempts for automatic analysis focus on athletes in many sports videos have been made. However, taekwondo video analysis remains an unstudied field. In light of this, a novel framework for automatic techniques analysis in broadcast taekwondo video is proposed in this paper. For an input video, in the first stage, athlete tracking and body segmentation are done through a modified Structure Preserving Object Tracker. In the second stage, the de-noised frames which completely contain the body of analyzed athlete from video sequence, are trained by a deep learning network PCANet to predict the athlete action of each single frame. As one technique is composed of many consecutive actions and each action corresponds a video frame, focusing on video sequences to achieve techniques analysis makes sense. In the last stage, linear SVM is used with the predicted action frames to get a techniques classifier. To evaluate the performance of the proposed framework, extensive experiments on real broadcast taekwondo video dataset are provided. The results show that the proposed method achieves state-of-the-art results for complex techniques analysis in taekwondo video.
C1 [Kong, Yongqiang] Ocean Univ China, Coll Informat Sci & Engn, Software Engn, Qingdao, Peoples R China.
   [Wei, Zhengang] Ocean Univ China, Inst Software Engn, Qingdao, Peoples R China.
   [Huang, Shanshan] Ocean Univ China, Qingdao, Peoples R China.
C3 Ocean University of China; Ocean University of China; Ocean University
   of China
RP Wei, ZG (corresponding author), Ocean Univ China, Inst Software Engn, Qingdao, Peoples R China.
EM kongyongqiang1992@gmail.com; wzgwzq@ouc.edu.cn; huangshaewd@gmail.com
RI huang, shan/JVN-1240-2024
OI Kong, Yongqiang/0000-0001-6793-2492
CR Afrouzian R, 2016, MULTIMED TOOLS APPL, V75, P6809, DOI 10.1007/s11042-015-2611-8
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   Archana M, 2016, ADV INTELL SYST, V384, P427, DOI 10.1007/978-3-319-23036-8_37
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen CM, 2015, MULTIMED TOOLS APPL, V74, P9573, DOI 10.1007/s11042-014-2137-5
   Chu WT, 2008, MULTIMED TOOLS APPL, V38, P27, DOI 10.1007/s11042-007-0145-4
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dao MS, 2010, MULTIMED TOOLS APPL, V50, P227, DOI 10.1007/s11042-009-0379-4
   Duh D.J., 2013, Intelligent Technologies and Engineering Systems, P123
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farajidavar N, 2012, IEEE INT C COMP VIS, P1548
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gastin PB, 2013, J SCI MED SPORT, V16, P589, DOI 10.1016/j.jsams.2013.01.007
   Ghasemzadeh H, 2011, IEEE SENS J, V11, P603, DOI 10.1109/JSEN.2010.2048205
   Gouwanda D, 2008, IFMBE PROC, V21, P715
   Kumar Susheel K., 2010, International Journal on Computer Science and Engineering, V02, P2996
   Li HJ, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P205, DOI 10.1109/ICIAP.2007.4362780
   Li HJ, 2010, IEEE T CIRC SYST VID, V20, P351, DOI 10.1109/TCSVT.2009.2035833
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   Ma SG, 2013, IEEE I CONF COMP VIS, P2744, DOI 10.1109/ICCV.2013.341
   Manera F., 2013, AST JAIIO, P152
   Mei T, 2008, MULTIMED TOOLS APPL, V40, P89, DOI 10.1007/s11042-007-0186-8
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Nitta N, 2005, MULTIMED TOOLS APPL, V25, P59, DOI 10.1023/B:MTAP.0000046382.62218.e1
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   Roh MC, 2008, PATTERN RECOGN, V41, P1124, DOI 10.1016/j.patcog.2007.07.013
   Simonyan K., 2014, 14091556 ARXIV
   Tao WJ, 2012, SENSORS-BASEL, V12, P2255, DOI 10.3390/s120202255
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Wang ZK, 2014, MULTIMED TOOLS APPL, V73, P519, DOI 10.1007/s11042-013-1619-1
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
NR 41
TC 13
Z9 13
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13643
EP 13660
DI 10.1007/s11042-017-4979-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900026
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Tao, XM
   Duan, YP
   Ge, N
AF Liu, XiJia
   Tao, XiaoMing
   Duan, YiPing
   Ge, Ning
TI Visual information assisted UAV positioning using priori remote-sensing
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote-sensing; Positioning; Priori information; Image feature
ID AIDED INERTIAL NAVIGATION; MODEL
AB The current satellite-based global positioning system and other radio-based positioning methods are either fragile or not entirely available to deal with the long-range guidance, especially for circumstances such as battlefield navigation, disaster response, humanitarian assistance, and so on. With the consideration, this paper presents a visual information assisted positioning scheme for inertial guided unmanned aerial vehicle (UAV) navigation. Firstly, historical remote-sensing images are introduced to generate a stable and distinctive priori information database. Secondly, improved robust SIFT-based visual feature extraction and registration techniques are applied for accurate and fast visual scene matching. Finally, on the basis of vehicle attitude and drifted inertial navigation information, an adaptive coarse-to-fine resolving scheme is designed for efficient real-time positioning response. The proposed scheme deals with automatic long-range guidance tasks with complex working conditions effectively, due to the optimized usage of visual priori information and the enhanced robustness of SIFT-based visual features. Numerical simulation results show that for long-range guidance task with average drifted inertial positioning deviation over 600m, the proposed scheme is capable to obtain meter-scale positioning precision using general commercial cameras.
C1 [Liu, XiJia; Tao, XiaoMing; Duan, YiPing; Ge, Ning] Tsinghua Univ, Dept Elect Engn, 1 Tsinghuayuan, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Tao, XM (corresponding author), Tsinghua Univ, Dept Elect Engn, 1 Tsinghuayuan, Beijing 100084, Peoples R China.
EM taoxm@tsinghua.edu.cn
RI Tao, Xiaoming/ABG-9019-2021; Ge, Ning/C-3524-2013; Tao,
   XiaoMing/A-9992-2010
OI Tao, Xiaoming/0000-0002-2406-0695; 
FU National Basic Research Project of China [2013CB329006]; National
   Natural Science Foundation of China (NSFC) [61622110, 61471220,
   91538107]
FX This work was supported by the National Basic Research Project of China
   (973) under grant number [2013CB329006]; and National Natural Science
   Foundation of China (NSFC) under grant number [61622110, 61471220,
   91538107].
CR [Anonymous], P 2015 IEEE 82 VEH T
   Bonebrake C, 2014, IEEE SECUR PRIV, V12, P82, DOI 10.1109/MSP.2014.40
   Cui YN, 2016, J SYST ENG ELECTRON, V27, P1207, DOI 10.21629/JSEE.2016.06.09
   Daakir M, 2015, INT ARCH PHOTOGRAMME
   DARPA, 2015, BREAKTHR TECHN NAT S
   Delaune J, 2016, ROBOT AUTON SYST, V78, P63, DOI 10.1016/j.robot.2016.01.007
   El-Melegy MT, 2014, NEURAL NETWORKS, V59, P23, DOI 10.1016/j.neunet.2014.06.010
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Grewal M.S., 2020, GLOBAL NAVIGATION SA, V4th
   Gui JJ, 2015, ADV ROBOTICS, V29, P1289, DOI 10.1080/01691864.2015.1057616
   He L, 2014, INT SYM COMPUT INTEL, DOI 10.1109/ISCID.2014.131
   Hou S., 2015, HDB SPACE SECURITY, P885, DOI DOI 10.1007/978-1-4614-2029-3_33
   Kortunov VI, 2015, 2015 IEEE 3RD INTERNATIONAL CONFERENCE ACTUAL PROBLEMS OF UNMANNED AERIAL VEHICLES DEVELOPMENTS (APUAVD), P284, DOI 10.1109/APUAVD.2015.7346622
   Lee JH, 2015, INT J CONTROL AUTOM, V13, P951, DOI 10.1007/s12555-014-0347-2
   Li B, 2011, PROC CVPR IEEE, P1737
   Liao X, 2015, 7 INT S COMP INT DES, P208
   Lin TY, 2013, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2013.120
   Liu Q, 2016, GEOMATICS SPATIAL IN
   Liu XJ, 2016, TSINGHUA SCI TECHNOL, V21, P552
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miller MM, 2010, TECH REP
   Morel JM, 2011, INVERSE PROBL IMAG, V5, P115, DOI 10.3934/ipi.2011.5.115
   Paul S, 2016, IEEE GEOSCI REMOTE S, V13, P1300, DOI 10.1109/LGRS.2016.2582528
   Ren HL, 2012, IEEE-ASME T MECH, V17, P210, DOI 10.1109/TMECH.2010.2095504
   Sazdovski V, 2015, AEROSP SCI TECHNOL, V40, P33, DOI 10.1016/j.ast.2014.09.019
   Smalling KM, 2015, TECH REP
   Tahar KN, 2016, INT ARCH PHOTOGRAMM, V41, P1037, DOI 10.5194/isprsarchives-XLI-B1-1037-2016
   Tang J, 2015, SENSORS-BASEL, V15, P16710, DOI 10.3390/s150716710
   Tanskanen P, 2015, IEEE INT C INT ROBOT, P6073, DOI 10.1109/IROS.2015.7354242
   Troiani C, 2015, ROBOT AUTON SYST, V69, P80, DOI 10.1016/j.robot.2014.08.006
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang QY, 2015, MEAS SCI TECHNOL, V26, DOI 10.1088/0957-0233/26/11/115101
   Yang FB, 2015, OPTIK, V126, P3061, DOI 10.1016/j.ijleo.2015.07.102
NR 33
TC 11
Z9 12
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14461
EP 14480
DI 10.1007/s11042-017-5039-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900060
DA 2024-07-18
ER

PT J
AU Malik, A
   Singh, S
   Kumar, R
AF Malik, Aruna
   Singh, Samayveer
   Kumar, Rajeev
TI Recovery based high capacity reversible data hiding scheme using
   even-odd embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Recovery strategy; Location map; Stego-image;
   Embedding layers
ID DIFFERENCE EXPANSION; IMAGES; WATERMARKING
AB There have been discussed various data hiding methods which can embed the secret data in an image. However, the image gets destroyed after extraction of the secret data at the receiving end. Thus, there exists a need to have data hiding methods which can recover the image after extraction of the secret data. Such types of schemes are called reversible data hiding schemes which are commonly used in sensitive military, legal, and medical applications. The existing reversible data hiding schemes either provide good hiding capacity but low quality stego-image or good quality stego-image but poor data hiding capacity because the stego-image quality and the hiding capacity are diametrically related metrics. To address this problem, we propose a high capacity reversible data hiding scheme using recovery strategy. It hides the secret data into a cover image in two phases. In the first phase, the cover image is scanned in a specific scan order andconstructs a location map in which even valued pixels are denoted by '1' and odd valued pixels by '0'. It embeds the secret data into every pixel of the image by changing its value at most by 1. The second phase repeats the process of the first phase embedding so that some of the pixels can berecovered to its original form as well as the secret data can further be embedded. Experimentally, it is proved that the proposed scheme provides good quality of stego-image and having the high data hiding capacity at the same time. Further, it is able to maintain the image quality even when the secret data is embedded in layers.
C1 [Malik, Aruna] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Singh, Samayveer] Bennett Univ, Dept Comp Sci Engn, Gr Noida, UP, India.
   [Kumar, Rajeev] Netaji Subhas Inst Technol, Dept Comp Engn, New Delhi, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Netaji Subhas University of
   Technology
RP Singh, S (corresponding author), Bennett Univ, Dept Comp Sci Engn, Gr Noida, UP, India.
EM arunacsrke@gmail.com; sammayveersingh@gmail.com;
   rajeevgargnsit@gmail.com
RI Malik, Aruna/GOH-0709-2022; Malik, Aruna/AAL-1997-2020; Singh,
   Samayveer/X-8119-2019
OI Malik, Aruna/0000-0003-1136-6828; Singh, Samayveer/0000-0002-4199-721X
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Artz D, 2001, IEEE INTERNET COMPUT, V5, P75, DOI 10.1109/4236.935180
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Carpenter B., 2002, COMPRESSION VIA ARIT
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Horng G, 2014, J INFORM HIDING MULT, V5, P152
   Huang HC, 2009, IEEE INT SYMP CIRC S, P1661, DOI 10.1109/ISCAS.2009.5118092
   Kumar R, 2016, Int J Multimed Intell Secur Inderscience
   Kumar R, 2017, CHEM REC, V17, P441, DOI 10.1002/tcr.201600108
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1090, DOI 10.1109/CCAA.2016.7813878
   Kumar R, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P53, DOI 10.1109/SPIN.2016.7566661
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Li SL, 2006, PATTERN RECOGN, V39, P1168, DOI 10.1016/j.patcog.2005.11.017
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Macq B., 2000, P EUSIPCO, P533
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Weng SW, 2008, INT J INNOV COMPUT I, V4, P351
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2011, P INT J ELECT COMMUN, V65, P814, DOI DOI 10.1016/J.AEUE.2011.01.014
   Yoo H.-M., 2009, LNCS NEURAL INFORM P
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 41
TC 36
Z9 37
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15803
EP 15827
DI 10.1007/s11042-017-5156-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200059
DA 2024-07-18
ER

PT J
AU Hong, MP
   Oh, K
AF Minh-Phuoc Hong
   Oh, Kyoungsu
TI Real-time motion blur using extruded triangles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time rendering; Motion blur; Visibility; Shading
AB Several algorithms have been introduced to render motion blur in real time by solving the visibility problem in the spatial-temporal domains. However, some algorithms render at interactive frame rates but have artifacts or noise. Therefore, we propose a new algorithm that renders real-time motion blur using extruded triangles. Our method uses two triangles in the previous frame and the current frame to make an extruded triangle then send it to rasterization. By using the standard rasterization, visibility determination is performed efficiently. To solve the occlusion between extruded triangles for a given pixel, we introduce a combination solution using a sorting in front-to-back order and bitwise operations in the spatial-temporal dimensions. This solution ensures that only non-occluded extruded triangles are shaded. We further improve performance of our algorithm using a coverage map.
C1 [Minh-Phuoc Hong; Oh, Kyoungsu] Room 509,50 Sadang Ro, Seoul 07027, South Korea.
RP Hong, MP (corresponding author), Room 509,50 Sadang Ro, Seoul 07027, South Korea.
EM hmphuoc1985@gmail.com; oks@ssu.ac.kr
CR Akenine-Möller T, 2007, GRAPHICS HARDWARE 2007: ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P7
   Andersson M, 2014, COMPUT GRAPH FORUM, V33, P341, DOI 10.1111/cgf.12303
   Barta P, 2011, P CESCG
   Burns Christopher A., 2013, Journal of Computer Graphics Techniques (JCGT), V2, P55
   Clarberg P, 2014, ACM T GRAPHIC
   Clarberg P., 2014, ACM T GRAPHIC, V33, P227
   Clarberg P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462022
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Grant C. W., 1985, Computer Graphics, V19, P79, DOI 10.1145/325165.325184
   Gribel C. J., 2010, P C HIGH PERF GRAPH, P163
   Guertin Jean-Philippe., 2014, HIGH PERFORMANCE GRA, P51
   Guertin JP, 2015, EUR S REND EXP ID IM
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Hassaskhah J., 2015, Journal of English and Education, V4, P45
   Karras T., 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Korein J., 1983, Computer Graphics, V17, P377, DOI 10.1145/964967.801168
   Laine S, 2014, ACM T GRAPHIC, V30
   Laine S, 2011, EFFICIENT TRIANGLE C
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2012, P 21 INT C PATT REC, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   McGuire M., 2011, Computer Graphics Archive
   McGuire M, 2010, REAL TIME STOCHASTIC
   McGuire Morgan., 2012, INTERACTIVE 3D GRAPH, P135
   Munkberg J., 2011, P ACM SIGGRAPH S HIG, P107
   Newell Martin E, 1972, P ACM ANN C, V1, P443
   Ragan-Kelley J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966396
   ROSADO G, 2007, GPU GEMS, V3, P575
   Salvi Marco., 2011, PROC ACM SIGGRAPH S, P119, DOI [10.1145/2018323.2018342, DOI 10.1145/2018323.2018342]
   Schmid J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778794
   Sousa T, 2013, ACM SIGGRAPH COURSE
   Sung K, 2002, IEEE T VIS COMPUT GR, V8, P144, DOI 10.1109/2945.998667
   Widmer S, 2016, COMPUT GRAPH FORUM, V35, P441, DOI 10.1111/cgf.13041
   Wu YJ, 2015, J INF SCI ENG, V31, P1071
   Yan LQ, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2816814
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
NR 41
TC 1
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13323
EP 13341
DI 10.1007/s11042-017-4949-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900012
DA 2024-07-18
ER

PT J
AU Sadhya, D
   Singh, SK
AF Sadhya, Debanjan
   Singh, Sanjay Kumar
TI Design of a cancelable biometric template protection scheme for
   fingerprints based on cryptographic hash functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Cancelable template; Cryptographic hash function;
   Fingerprint
ID SECURITY; PRIVACY
AB Enforcing security and privacy guarantees for biometric users via protecting their unique and personalized attributes is an important area of research. There are many properties desirable in a biometric template protection scheme, but unfortunately, all of the requirements are not simultaneously fulfilled. In our work, we have tried to address this issue by proposing a cancelable framework for fingerprints which simultaneously provides satisfactory system performance, strong security guarantees, and fast matching procedure. The core of our scheme essentially pivots around the use of cryptographic hash functions which provide the adequate levels of security in the framework. Prior to the hashing stage, we have employed an effective pre-alignment technique and a hexagonal grid based quantization scheme which allows us to overcome constraint such as intra-class variability. Finally, our scheme is made cancelable through traditional salting. We tested our framework on various fingerprint databases and found that the resulting system performances were comparable with other contemporary cancelable schemes (EERs of 5.8%, 5.3%, 15.8%, 14.5% were observed for FVC2002 DB1, DB2, FVC2004 DB1, DB2 databases under the stolen token scenario). Most importantly, we perfectly fulfill the unlinkability, cancelability and diversity requirements, which are verified both theoretically and empirically.
C1 [Sadhya, Debanjan; Singh, Sanjay Kumar] Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu University
   (BHU)
RP Sadhya, D (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM debanjan.sadhya@gmail.com; sks.cse@itbhu.ac.in
RI Singh, Sanjay Kumar/AAC-2031-2022; Singh, Sanjay
   Prithviraj/IQV-1492-2023; kumar, Sanjay/ITT-3680-2023
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762; 
CR Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242
   [Anonymous], INFORM TECHNOLOGY SE
   [Anonymous], INFORM TECHNOLOGY 2
   [Anonymous], CIB 2009 IEEE
   [Anonymous], 1979, THESIS STANFORD U ST
   Barreto P, 2000, 1 OP NESSIE WORKSH
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Dobbertin H., 1996, Fast Software Encryption. Third International Workshop Proceedings, P71
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Farooq F., 2007, Conference Proceedings presented in Signal Processing and Its Applications, P1
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Hermand Jean-Pierre, 2014, OCEANS 2014, DOI 10.1109/OCEANS-TAIPEI.2014.6964569
   Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826
   Jain Anil K., 2005, 2005 13th European Signal Processing Conference, P1
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Khovratovich D, 2012, LECT NOTES COMPUT SC, V7549, P244, DOI 10.1007/978-3-642-34047-5_15
   Lamberger Mario., 2011, IACR Cryptology ePrint Archive 2011, P37
   Lee CH, 2007, IEEE T SYST MAN CY B, V37, P980, DOI 10.1109/TSMCB.2007.896999
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Li GQ, 2015, I W BIOMETRIC FORENS
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Nanni L, 2008, PATTERN RECOGN, V41, P3461, DOI 10.1016/j.patcog.2008.05.013
   NIST, NIST mobility package used for network simulator NS-2.29
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Prasad MVNK, 2014, EXPERT SYST APPL, V41, P6114, DOI 10.1016/j.eswa.2014.04.020
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C., 2015, 3rd Intrl. Wrks on biometrics and forensics, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Tams B., 2013, BIOSIG'13, P75
   Tams B, 2015, IEEE T INF FOREN SEC, V10, P985, DOI 10.1109/TIFS.2015.2392559
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Tulyakov S, 2007, PATTERN RECOGN LETT, V28, P2427, DOI 10.1016/j.patrec.2007.08.008
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
   Yang GH, 2010, INT CONF SMART GRID, P1, DOI 10.1109/SMARTGRID.2010.5622001
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
NR 45
TC 9
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15113
EP 15137
DI 10.1007/s11042-017-5095-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200031
DA 2024-07-18
ER

PT J
AU Veeraputhiran, A
   Sankararajan, R
AF Veeraputhiran, Angayarkanni
   Sankararajan, Radha
TI Quantization and security enabled compressive video CODEC for WSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PH encoding; Scrambling; Optimized Quantization; Wireless Sensor
   Networks
ID ORTHOGONAL MATCHING PURSUIT; FRAMEWORK
AB Real time image and video transmission in surveillance applications need efficient video coding and security. Recent advances in computer vision have enabled the development of highly secured compressive video codec framework based on compressed sensing (CS) for video surveillance. This paper presents an efficient quantization and security enabled compressive video codec (QSCVC) framework compatible for wireless multimedia sensor networks. QSCVC focuses on secured transmission of the quantized CS measurements using scrambling. The security is ensured by the key controlled scrambler and descrambler algorithm used at the encoder and decoder respectively. On an average saving percentage of the QSCVC framework with quantization exceeds 13.19% without quantization and it is also observed that an average data rate of 736 Kbps is achieved. It is also proved that there is a 97.54% reduction in transmission energy when compared with raw frame transmission.
C1 [Veeraputhiran, Angayarkanni; Sankararajan, Radha] SSN Coll Engn, Dept Elect & Commun Engn, Chennai 603110, Tamil Nadu, India.
C3 SSN College of Engineering
RP Veeraputhiran, A (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Chennai 603110, Tamil Nadu, India.
EM angayarkanniv@ssn.edu.in; radhas@ssn.edu.in
RI V, ANGAYARKANNI/ITV-9978-2023
OI V, ANGAYARKANNI/0009-0007-6926-9736
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Angayarkanni V, 2016, WIRELESS PERS COMMUN, V88, P553, DOI 10.1007/s11277-016-3176-1
   Aruna N., 2015, IEEE INT C COMP POW
   Baig Y, 2010, IEEE 17 INT C TEL IC
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Bhanu B., 2011, Distributed Video Sensor Networks
   Boufounos PT, 2015, APPL NUMER HARMON AN, P193, DOI 10.1007/978-3-319-16042-9_7
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Dai Y, 2016, J COMPUTER COMMUNICA, V04, P16, DOI DOI 10.4236/JCC.2016.45003
   Feng JM, 2014, IEEE SIGNAL PROC LET, V21, P1351, DOI 10.1109/LSP.2014.2336700
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Karahanoglu NB, 2012, DIGIT SIGNAL PROCESS, V22, P555, DOI 10.1016/j.dsp.2012.03.003
   Neggazi M, 2014, IEEE INT SYMP CIRC S, P2401, DOI 10.1109/ISCAS.2014.6865656
   Pudlewski S, 2012, IEEE T MOBILE COMPUT, V11, P1060, DOI 10.1109/TMC.2011.175
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Shirazinia A, 2014, ARXIV14047651
   Sukumaran AN, 2015, COMPUT ELECTR ENG, V44, P51, DOI 10.1016/j.compeleceng.2015.02.008
   Tong L, 2011, VISUAL COMMUNICATION
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yunus F, 2013, INT J ENG TECHNOL, V5, P4501
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
NR 23
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15677
EP 15694
DI 10.1007/s11042-017-5140-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200054
DA 2024-07-18
ER

PT J
AU Alqhtani, SM
   Luo, SH
   Regan, B
AF Alqhtani, Samar M.
   Luo, Suhuai
   Regan, Brian
TI A multiple kernel learning based fusion for earthquake detection from
   multimedia twitter data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data fusion; Data mining; Event detection; Kernel method; Multimedia
   data
ID EVENT DETECTION
AB An efficient way of extracting useful information from multiple sources of data is to use data fusion technology. This paper introduces a data fusion approach in multimedia data for earthquake detection in twitter by using kernel fusion. The fusion method applies to fuse two types of data. The first type is features extracted from text by using bag-of-words method which is based on the calculation of the term frequency-inverse document frequency. The second type is the visual features extracted from images by applying scale-invariant feature transform. A multiple kernel fusion is applied in order to fuse the information from these two sources. Our experiments have indicated that comparing to the approaches using single data source, the proposed approach of using multiple kernel learning algorithm as early fusion increased the accuracy for earthquake detection. Experimental results for the proposed method achieved a high accuracy of 0.94, comparing to accuracy of 0.89 with texts only, and accuracy of 0.83 with images only.
C1 [Alqhtani, Samar M.; Luo, Suhuai; Regan, Brian] Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
C3 University of Newcastle
RP Alqhtani, SM (corresponding author), Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
EM Samar.alqhtani@uon.edu.au
RI Alqhtani, Samar Medawi/ABH-3456-2021
OI Alqhtani, Samar Medawi/0000-0002-8664-8953; Luo,
   Suhuai/0000-0002-6185-6035
FU Najran University in Saudi Arabia
FX The corresponding author and related research is sponsored by Najran
   University in Saudi Arabia.
CR [Anonymous], 2010, MULTIMEDIA DATA MINI
   [Anonymous], SCI CHANG WORLD
   [Anonymous], SOCIAL NETWORK MININ
   [Anonymous], P INT C MULT
   [Anonymous], WORK NOT P MEDIAEVAL
   [Anonymous], 2007, MIR
   [Anonymous], 2014, 10 US NAT C EARTHQ E
   [Anonymous], MULTIMODAL DATA FUSI
   [Anonymous], IJCSI INT J COMPUTER
   [Anonymous], ARXIV150303920
   [Anonymous], VIS WORKSH COMP DIS
   [Anonymous], ARXIV14052102
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Brocher TM, 2015, SEISMOL RES LETT, V86, P309, DOI 10.1785/0220150004
   Castillo C., 2010, P 1 WORKSH SOC MED A, P71, DOI DOI 10.1145/1964858.1964869
   Crooks A, 2013, T GIS, V17, P124, DOI 10.1111/j.1467-9671.2012.01359.x
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Earle PS, 2011, ANN GEOPHYS-ITALY, V54, P708, DOI 10.4401/ag-5364
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   He MX, 2010, PATTERN RECOGN, V43, P1789, DOI 10.1016/j.patcog.2009.11.018
   Isson J.-P., 2012, WIN ADV BUSINESS ANA
   Iwanaga I. S. M., 2011, 2011 IEEE International Conference on Granular Computing, P306, DOI 10.1109/GRC.2011.6122613
   Kirsch S, 2010, DIALECT ANTHROPOL, V34, P87, DOI 10.1007/s10624-009-9113-x
   Klein L. A., 2019, SENSOR DATA FUSION I
   Kompatsiaris Y., 2008, SEMANTIC MULTIMEDIA
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muhammad K, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3171-8
   Ozdikis O, 2012, P VLDB 2012 WORKSH O
   Petkos G, 2014, P ACM ICMR 2014 WORK
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie ZB, 2013, INT J MULTIMED DATA, V4, P1, DOI 10.4018/ijmdem.2013100101
   Xu Z, 2020, IEEE T CLOUD COMPUT, V8, P387, DOI 10.1109/TCC.2016.2517638
   Yardi S., 2010, Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media, V4, P194
   Zafarani R, 2014, SOCIAL MEDIA MINING, DOI DOI 10.1017/CBO9781139088510
   Zhang XM, 2015, NEUROCOMPUTING, V149, P1469, DOI 10.1016/j.neucom.2014.08.045
   Zhou SB, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/586259
NR 42
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12519
EP 12532
DI 10.1007/s11042-017-4901-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100038
DA 2024-07-18
ER

PT J
AU Courtemanche, F
   Léger, PM
   Dufresne, A
   Fredette, M
   Labonté-LeMoyne, É
   Sénécal, S
AF Courtemanche, Francois
   Leger, Pierre-Majorique
   Dufresne, Aude
   Fredette, Marc
   Labonte-LeMoyne, Elise
   Senecal, Sylvain
TI Physiological heatmaps: a tool for visualizing users' emotional
   reactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physiological computing; Eyetracking; Affective computing; Heatmap; User
   experience
ID EYE-MOVEMENTS; EEG; MODELS; PUPIL; OVERT
AB Practitioners in many fields of human-computer interaction are now using physiological data to measure different aspects of user experience. The dynamic nature of physiological data offers a continuous window to the users and allows a better understanding of their experience while interacting with a system. However, in order to be truly informative, physiological signals need to be closely linked to users' behaviors and interaction states. This paper presents an analysis method that provides a direct visual interpretation of users' physiological signals when interacting with an interface. The proposed physiological heatmap tool uses eyetracking data along with physiological signals to identify regions where users are experiencing different emotional and cognitive states with a higher frequency. The method was evaluated in an experiment with 44 participants. Results show that physiological heatmaps are able to identify emotionally significant regions within an interface better than standard gaze heatmaps. Applications of the method to different fields of HCI research are also discussed.
C1 [Courtemanche, Francois; Labonte-LeMoyne, Elise] HEC Montreal, Tech3lab, 3000 Cote St Catherine, Montreal, PQ H3T 2A7, Canada.
   [Leger, Pierre-Majorique] HEC Montreal, Dept Informat Sci, 3000 Cote St Catherine, Montreal, PQ H3T 2A7, Canada.
   [Dufresne, Aude] Univ Montreal, Dept Commun, 2900 Edouard Montpetit, Montreal, PQ H3T 1J4, Canada.
   [Fredette, Marc] HEC Montreal, Dept Stat, 3000 Cote St Catherine, Montreal, PQ H3T 2A7, Canada.
   [Senecal, Sylvain] HEC Montreal, Dept Mkt, 3000 Cote St Catherine, Montreal, PQ H3T 2A7, Canada.
C3 Universite de Montreal; HEC Montreal; Universite de Montreal; HEC
   Montreal; Universite de Montreal; Universite de Montreal; HEC Montreal;
   Universite de Montreal; HEC Montreal
RP Courtemanche, F (corresponding author), HEC Montreal, Tech3lab, 3000 Cote St Catherine, Montreal, PQ H3T 2A7, Canada.
EM francois.courtemanche@hec.ca
FU SSHRC (Social Sciences and Humanities Research Council); FRQNT (Fonds de
   recherche du Quebec - Nature et technologies)
FX Authors want to thank Vanessa Georges for manuscript revision and
   artwork editing and Emma Campbell for the experiment preparation. The
   authors also want to thank the research assistants who administered the
   experiment. This work is supported by the SSHRC (Social Sciences and
   Humanities Research Council) and the FRQNT (Fonds de recherche du Quebec
   - Nature et technologies).
CR Aboyoun DC, 1998, SOC BEHAV PERSONAL, V26, P415, DOI 10.2224/sbp.1998.26.4.415
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], P 4 NORD C HUM COMP
   [Anonymous], 2000, HDB PSYCHOPHYSIOLOGY
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   Bailey BP, 2008, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1314683.1314689
   Birmingham E, 2009, VISION RES, V49, P2992, DOI 10.1016/j.visres.2009.09.014
   Blignaut P, 2010, P 2010 S EYE TRACK R
   Bojko A, 2009, LECT NOTES COMPUT SC, V5610, P30, DOI 10.1007/978-3-642-02574-7_4
   Borji A, 2014, J VISION, V14, DOI 10.1167/14.3.29
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Bourke P, 1996, COLOUR RAMPING DATA
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Breslow LA, 2009, HUM FACTORS, V51, P321, DOI 10.1177/0018720809338286
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.1017/CBO9780511546396.001
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.2277/ 0521844711
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Conati C, 2011, NEW PERSPECTIVES ON AFFECT AND LEARNING TECHNOLOGIES, P71, DOI 10.1007/978-1-4419-9625-1_6
   Courtemanche F, 2014, LECT NOTES COMPUT SC, V8908, P43, DOI 10.1007/978-3-662-45686-6_3
   Coy AL, 2012, VIS COGN, V20, P883, DOI 10.1080/13506285.2012.712556
   DAVIDSON RJ, 1988, INT J NEUROSCI, V39, P71, DOI 10.3109/00207458808985694
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   Dimigen O, 2011, J EXP PSYCHOL GEN, V140, P552, DOI 10.1037/a0023885
   Duchowski AT, 2012, P S EYE TRACK RES AP
   Dufresne A., 2010, Measuring Behavior, P218
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Ganglbauer E, 2009, US EXP EV METH PROD
   Georges V, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4850, DOI 10.1145/2858036.2858271
   Giakoumis D, 2011, IEEE T AFFECT COMPUT, V2, P119, DOI 10.1109/T-AFFC.2011.4
   Hairston W.D., 2012, ACCOUNTING TIMING DR
   Healey JA, 2010, 1 INT WORKSH BIOINSP
   Humphrey K, 2012, J VISION, V12, DOI 10.1167/12.1.22
   Irwin D.E., 1992, Eye movements and visual cognition: Scene perception and reading, P146, DOI [10.1007/978-1-4612-2852-3_9, DOI 10.1007/978-1-4612-2852-3_9]
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jennings JR, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P812, DOI 10.1017/CBO9780511546396.034
   JENNINGS JR, 1992, PSYCHOPHYSIOLOGY, V29, P742, DOI 10.1111/j.1469-8986.1992.tb02052.x
   Jung TP, 2000, CLIN NEUROPHYSIOL, V111, P1745, DOI 10.1016/S1388-2457(00)00386-2
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Kivikangas JM, 2011, ENTERTAIN COMPUT, V2, P11, DOI 10.1016/j.entcom.2011.03.006
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Laeng B, 2012, PERSPECT PSYCHOL SCI, V7, P18, DOI 10.1177/1745691611427305
   Lang PJ, 2008, B3 U FLOR
   Leger P-M, J ASS INFORM SYSTEMS
   McQuiggan SW, 2007, LECT NOTES COMPUT SC, V4738, P698
   Mills M, 2011, J VISION, V11, DOI 10.1167/11.8.17
   Nacke LE, 2010, INTERACT COMPUT, V22, P336, DOI 10.1016/j.intcom.2010.04.005
   Nielsen J., 2012, Eyetracking Web Usability
   Niu YQ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2325722.2325726
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   Pomplun M, 1996, PERCEPTION, V25, P931, DOI 10.1068/p250931
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salvucci DD, 2000, P 2000 S EYE TRACK R
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Senecal S, 2013, INT C INF SYST ICIS, P8
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   STANNERS R F, 1979, Motivation and Emotion, V3, P319, DOI 10.1007/BF00994048
   Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5
   Torniainen J, 2014, NEUROIMAGE
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   WILDER J, 1958, AM J PSYCHOTHER, V12, P199, DOI 10.1176/appi.psychotherapy.1958.12.2.199
   Wooding D. S., 2002, P 2002 S EYE TRACK R
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P518, DOI 10.3758/BF03195481
NR 69
TC 27
Z9 29
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11547
EP 11574
DI 10.1007/s11042-017-5091-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900063
OA hybrid
DA 2024-07-18
ER

PT J
AU Fan, Q
   Zhang, LF
AF Fan, Qian
   Zhang, Lifeng
TI A novel patch matching algorithm for exemplar-based image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Adaptive patch; Rotation invariant patch
ID RESTORATION
AB In the existing exemplar-based image inpainting algorithms, the Sum of Squared Differences (SSD) method is employed to measure the similarities between patches in a fixed size, and then using the most similar one to inpaint the destroyed region. However, sometimes only calculating the SSD difference would produce a discontinuous structure and blur the texture. To solve this problem, we firstly optimize the inpainting priority function and proposed an adaptive patch method to obtain more significant patches. The adaptive patch method changes the size of the patch by computing the patch sparsity. Secondly the proposed method calculates the maximum similarity between patches in different rotation angles so that it obtains the most similar rotation invariant matching patch. From the experimental results, the proposed method can improve the accuracy of the patch selection process compared with the traditional methods, and the proposed method can keep a better global visual appearance, especially for the image which contains more structure contents and the images whose destroyed region has a large width.
C1 [Fan, Qian; Zhang, Lifeng] Kyushu Inst Technol, Dept Elect Engn & Elect, Tobata Ku, Sensui Cho 1-1, Kitakyushu, Fukuoka 8040015, Japan.
C3 Kyushu Institute of Technology
RP Fan, Q (corresponding author), Kyushu Inst Technol, Dept Elect Engn & Elect, Tobata Ku, Sensui Cho 1-1, Kitakyushu, Fukuoka 8040015, Japan.
EM cnzshakka@gmail.com
CR Andris S., 2016, P 8 ADV SAT MULT SYS, P1
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Hu HT, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 3, P1167, DOI 10.1109/ICEMI.2015.7494460
   Hui-Yu Huang, 2010, 2010 International Computer Symposium (ICS 2010), P165, DOI 10.1109/COMPSYM.2010.5685527
   Lu HM, 2017, IEEE ACCESS, V5, P7115, DOI 10.1109/ACCESS.2017.2690455
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Munawar A, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P41, DOI 10.1109/MVA.2015.7153128
   OU JS, 2016, COMPUTATIONAL INTELL, P152, DOI DOI 10.1109/CIS.2016.42
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Ram I, 2013, IEEE T IMAGE PROCESS, V22, P2764, DOI 10.1109/TIP.2013.2257813
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Ullo SL, 2011, INT GEOSCI REMOTE SE, P3602, DOI 10.1109/IGARSS.2011.6050003
   Umarani AT, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P233, DOI 10.1109/ICACCCT.2016.7831637
   Wang H, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P737, DOI 10.1109/BMEI.2015.7401600
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang Yan-xi, 2009, Journal of Xi'an University of Technology, V25, P129
NR 20
TC 26
Z9 31
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10807
EP 10821
DI 10.1007/s11042-017-5077-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900025
DA 2024-07-18
ER

PT J
AU Furuta, R
   Ikehata, S
   Yamaskai, T
   Aizawa, K
AF Furuta, Ryosuke
   Ikehata, Satoshi
   Yamaskai, Toshihiko
   Aizawa, Kiyoharu
TI Efficiency-enhanced cost-volume filtering featuring coarse-to-fine
   strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cost-volume filtering; Markov random field; Multi-labeling problems;
   Coarse-to-fine
ID ENERGY MINIMIZATION
AB Cost-volume filtering (CVF) is one of the most widely used techniques for solving general multi-labeling problems based on a Markov random field (MRF). However it is inefficient when the label space size (i.e., the number of labels) is large. This paper presents a coarse-to-fine strategy for cost-volume filtering that efficiently and accurately addresses multi-labeling problems with a large label space size. Based on the observation that true labels at the same coordinates in images of different scales are highly correlated, we truncate unimportant labels for cost-volume filtering by leveraging the labeling output of lower scales. Experimental results show that our algorithm achieves much higher efficiency than the original CVF method while maintaining a comparable level of accuracy. Although we performed experiments that deal with only stereo matching and optical flow estimation, the proposed method can be employed in many other applications because of the applicability of CVF to general discrete pixel-labeling problems based on an MRF.
C1 [Furuta, Ryosuke; Yamaskai, Toshihiko; Aizawa, Kiyoharu] Univ Tokyo, Dept Informat Commun & Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
   [Ikehata, Satoshi] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo, Japan.
C3 University of Tokyo; Research Organization of Information & Systems
   (ROIS); National Institute of Informatics (NII) - Japan
RP Furuta, R (corresponding author), Univ Tokyo, Dept Informat Commun & Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM furuta@hal.t.u-tokyo.ac.jp; sikehata@seas.wustl.edu;
   yamasaki@hal.t.u-tokyo.ac.jp; aizawa@hal.t.u-tokyo.ac.jp
FU Grants-in-Aid for Scientific Research [16J07267, 26700008, 17H07324]
   Funding Source: KAKEN
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2004, ECCV
   [Anonymous], 2015, ICCV
   [Anonymous], 1998, BILATERAL FILTERING
   [Anonymous], 2015, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 2014, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2010, P CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2016, J MACH LEARN RES
   Bai X, 2014, ICIP
   Bames C, 2010, ECCV
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2359374
   Barnes C, 2009, ACM SIGGRAGH
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Brunton A, 2012, 3 DIMPVT
   Cho J, 2013, IVMSP WORKSH
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Furuta R, 2014, ICIP
   Helala MA, 2014, ACCV
   Hosni A, 2011, LECT NOTES COMPUT SC, V7087, P165, DOI 10.1007/978-3-642-25367-6_15
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Kramarev V, 2013, ACCV
   Lu J., 2012, CVPR
   Lu J., 2013, P CVPR
   Min D., 2011, ICCV
   Min DB, 2013, IEEE T PATTERN ANAL, V35, P2539, DOI 10.1109/TPAMI.2013.15
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Richardt C., 2010, ECCV
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Tan X, 2014, ECCV
   Tao M, 2012, COMPUT GRAPH FORUM, V31, P345, DOI 10.1111/j.1467-8659.2012.03013.x
   Tappen M., 2003, ICCV
   Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938
   Wang Y., 2014, CVPR
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Yang Q., 2012, CVPR
   YANG Q., 2010, CVPR
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yang R., 2003, CVPR
   Yoon K.J., 2005, CVPR
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhan YL, 2016, IEEE T CIRC SYST VID, V26, P1632, DOI 10.1109/TCSVT.2015.2473375
   Zhang K., 2014, CVPR
   Zhao Y, 2011, IMAGE VISION COMPUT, V29, P420, DOI 10.1016/j.imavis.2011.01.007
NR 48
TC 1
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12469
EP 12491
DI 10.1007/s11042-017-4897-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100036
OA hybrid
DA 2024-07-18
ER

PT J
AU Verma, M
   Raman, B
AF Verma, Manisha
   Raman, Balasubramanian
TI Local neighborhood difference pattern: A new feature descriptor for
   natural and texture image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Feature descriptor; Texture; Local binary
   pattern; Local neighborhood difference pattern
ID BINARY PATTERNS; COOCCURRENCE PATTERN; CLASSIFICATION; COLOR; EXTREMA;
   FACE; RECOGNITION
AB A new image retrieval technique using local neighborhood difference pattern (LNDP) has been proposed for local features. The conventional local binary pattern (LBP) transforms every pixel of image into a binary pattern based on their relationship with neighboring pixels. The proposed feature descriptor differs from local binary pattern as it transforms the mutual relationship of all neighboring pixels in a binary pattern. Both LBP and LNDP are complementary to each other as they extract different information using local pixel intensity. In the proposed work, both LBP and LNDP features are combined to extract the most of the information that can be captured using local intensity differences. To prove the excellence of the proposed method, experiments have been conducted on four different databases of texture images and natural images. The performance has been observed using well-known evaluation measures, precision and recall and compared with some state-of-art local patterns. Comparison shows a significant improvement in the proposed method over existing methods.
C1 [Verma, Manisha] Indian Inst Technol Gandhinagar, Elect Engn Dept, Gandhinagar 382355, Gujrat, India.
   [Raman, Balasubramanian] Indian Inst Technol Roorkee, Comp Sci & Engn Dept, Roorkee, Uttrakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Verma, M (corresponding author), Indian Inst Technol Gandhinagar, Elect Engn Dept, Gandhinagar 382355, Gujrat, India.
EM manisha.verma89@gmail.com; balarfma@iitr.ac.in
RI verma, manisha/KIB-5458-2024
OI Verma, Manisha/0000-0002-5202-4325
FU Ministry of Human Resource and Development (MHRD) grant, India
   [MHRD-02-23-200-304]
FX This work was supported by the Ministry of Human Resource and
   Development (MHRD) grant, India under grant MHRD-02-23-200-304. The
   authors would like to thank the editor and anonymous reviewers for
   thoughtful comments and valuable suggestions to improve the quality,
   which have been incorporated in this paper.
CR Abdelmounaime Safia, 2013, ISRN Machine Vision, DOI 10.1155/2013/876386
   Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], URB NAT SCEN CAT
   [Anonymous], 2002, P 5 NORD SIGN PROC S
   Baber Junaid, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P513, DOI 10.1007/978-3-642-34778-8_48
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Celik T, 2009, PATTERN RECOGN LETT, V30, P331, DOI 10.1016/j.patrec.2008.10.006
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He YG, 2013, PATTERN ANAL APPL, V16, P595, DOI 10.1007/s10044-011-0264-4
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Houam L, 2014, PATTERN ANAL APPL, V17, P179, DOI 10.1007/s10044-012-0288-4
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Kim DH., 2011, INT J COMPUT TECHNOL, V1, P1
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kwitt R., 2012, SALZBURG TEXTURE IMA
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Loupias E, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P518, DOI 10.1109/ICIP.2000.899469
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Ma WY, 1996, MULTIMED TOOLS APPL, V2, P35
   Mahood L, 2016, PATTERN RECOGN, V55, P87, DOI 10.1016/j.patcog.2016.01.021
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nian F, 2015, MULTIMED TOOLS APPL, P1
   Nigam S, 2014, MULTIMED TOOLS APPL, V74, P1
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Nosaka Ryusuke, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P15, DOI 10.1007/978-3-642-37410-4_2
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Wang XJ, 2006, INT C PATT RECOG, P503
   Xia Y, 2014, P 3 INT C MULT TECHN, P143
   Xia Y, 2014, PROC SPIE, V9069, DOI 10.1117/12.2049916
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 62
TC 107
Z9 112
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11843
EP 11866
DI 10.1007/s11042-017-4834-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100011
DA 2024-07-18
ER

PT J
AU Yu, ZM
   Gu, CS
   Jing, ZJ
   Cai, QR
   Luo, Y
   Wang, Y
AF Yu, Zhimin
   Gu, Chunsheng
   Jing, Zhengjun
   Cai, Qiuru
   Luo, Ye
   Wang, Yao
TI Cryptanalysis of an asymmetric cipher protocol using a matrix
   decomposition problem: revisited
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matrix decomposion; Linear equations; Cryptanalysis of an asymmetric
   cipher protocol; Equivalent secret key
ID HOMOMORPHIC ENCRYPTION; KEY
AB With the development of quantum computing technology, quantum computers pose a serious threat to the widely used public key cryptography. This is because there are effective quantum algorithms to solve many difficult problems based on commutative algebra structures such as factorization or discrete logarithms. It is generally believed that many public key crytosystems based on non-commutative cryptosystem algebraic structures have the potential to resist quantum computing attacks. Since multiplication of matrices has non-commutative properties, the cryptography based on matrix-based has the potential to resist quantum computing attacks. The security of matrix-based cryptography is closely related to the difficulty of matrix decomposition. An asymmetric cipher protocol based on matrix decomposition problem has been proposed by Raulynaitis et al. to meet the requirements of public key cryptography in the post quantum era. Liu et al. identified some weak keys in this scheme, through which an attacker can solve the equivalent secret key and crack the scheme by solving simultaneous linear equations. Liu et al. proposed an improved scheme to avoid weak keys. However, Raulynaitis and Liu schemes are not fully secured because a special structure of matrix is used to make some matrics commutative. The analysis presented in this paper demostrates that regardless of whether the private key is weak key or not, the equivalent keys from an associated public key can be solved in a reasonable time by a linear algebra attack. For this purpose, the linear equations with coefficients n(2) x n(2) are needed to solve. The equation coefficients are much less than the coefficients 5n(2) x 2n(2) in the attack methods of Liu et al. Thus, the proposed attack method is not only more general and but also more efficient.
C1 [Yu, Zhimin; Gu, Chunsheng; Jing, Zhengjun; Cai, Qiuru; Luo, Ye; Wang, Yao] Jiangsu Univ Technol, Key Lab Cloud Comp & Intelligent Informat Proc Ch, Sch Comp Engn, Changzhou 213001, Jiangsu, Peoples R China.
C3 Jiangsu University of Technology
RP Jing, ZJ (corresponding author), Jiangsu Univ Technol, Key Lab Cloud Comp & Intelligent Informat Proc Ch, Sch Comp Engn, Changzhou 213001, Jiangsu, Peoples R China.
EM jzjing@jsut.edu.cn
RI Jing, Zhengjun/JAO-1695-2023; Jing, Zhengjun/GWC-9082-2022
OI Jing, Zhengjun/0009-0004-5734-6544; 
CR [Anonymous], P INF RES APPL VARN
   [Anonymous], 1978, DSN Prog. Rep
   Applebaum B, 2009, LECT NOTES COMPUT SC, V5677, P595, DOI 10.1007/978-3-642-03356-8_35
   Boneh D., 2003, CONT MATH, V324, P71, DOI DOI 10.1090/CONM/324/05731
   Brakerski Z, 2011, ANN IEEE SYMP FOUND, P97, DOI 10.1109/FOCS.2011.12
   Braun J, 2014, DESIGN CODE CRYPTOGR, V71, P459, DOI 10.1007/s10623-012-9747-6
   Cabarcas D, 2014, J ACM, DOI [10.1145/2600694.2600695, DOI 10.1145/2600694.2600695]
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Gupta BB, 2016, HANDBOOK OF RESEARCH
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jiao Luyao, 2013, J ELECT CHINA, V30, P198
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Liu J, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5526-8
   Peikert C, 2014, LECT NOTES COMPUT SC, V8772, P197, DOI 10.1007/978-3-319-11659-4_12
   Raulynaitis A, 2010, INFORMATICA-LITHUAN, V21, P215
   Regev Oded, 2005, P 37 ACM STOC, P84, DOI [DOI 10.1145/1568318.1568324, 10.1145/1060590.1060603, DOI 10.1145/1060590.1060603, 10.1145/1568318.1568324]
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shor PW, 1997, SIAM J COMPUT, V26, P1484, DOI 10.1137/S0036144598347011
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 32
TC 1
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11307
EP 11320
DI 10.1007/s11042-017-5535-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900051
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Guo, JC
   Li, CY
AF Zhang, Yan
   Guo, Jichang
   Li, Chongyi
TI Image compressed sensing based on non-convex low-rank approximation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compressed sensing; Low-rank approximation; Weighted Schatten
   p-norm; Non-convex optimization
ID SCHATTEN P-NORM; THRESHOLDING ALGORITHM; MATRIX COMPLETION;
   RECONSTRUCTION; SPARSITY; RECOVERY
AB Nonlocal sparsity and structured sparsity have been evidenced to improve the reconstruction of image details in various compressed sensing (CS) studies. The nonlocal processing is achieved by grouping similar patches of the image into the groups. To exploit these nonlocal self-similarities in natural images, a non-convex low-rank approximation is proposed to regularize the CS recovery in this paper. The nuclear norm minimization, as a convex relaxation of rank function minimization, ignores the prior knowledge of the matrix singular values. This greatly restricts its capability and flexibility in dealing with many practical problems. In order to make a better approximation of the rank function, the non-convex low-rank regularization namely weighted Schatten p-norm minimization (WSNM) is proposed. In this way, both the local sparsity and nonlocal sparsity are integrated into a recovery framework. The experimental results show that our method outperforms the state-of-the-art CS recovery algorithms not only in PSNR index, but also in local structure preservation.
C1 [Zhang, Yan; Guo, Jichang; Li, Chongyi] Tianjin Univ, Sch Elect Informat Engn, 92 Weijin Rd, Tianjin 300072, Peoples R China.
   [Zhang, Yan] Tianjin Chengjian Univ, Sch Comp & Informat Engn, 26 Jinjing Rd, Tianjin 300384, Peoples R China.
C3 Tianjin University; Tianjin Chengjian University
RP Guo, JC (corresponding author), Tianjin Univ, Sch Elect Informat Engn, 92 Weijin Rd, Tianjin 300072, Peoples R China.
EM zhangyantju@tju.edu.cn; jchguotju@163.com; lichongyi@tju.edu.cn
RI Guo, Jichang/GQY-5798-2022
OI Guo, Jichang/0000-0003-3130-1685
FU Natural Science Foundation of Tianjin [15JCYBJC15500]
FX The authors would like to give thanks to the anonymous reviewers for
   their valuable comments that were useful to improve the quality of the
   paper. This work was supported by Natural Science Foundation of Tianjin
   (Grant No. 15JCYBJC15500).
CR Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès E, 2005, PROC SPIE, V5674, P76, DOI 10.1117/12.600722
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Egiazarian K, 2007, IEEE IMAGE PROC, P549
   Foucart S, 2009, APPL COMPUT HARMON A, V26, P395, DOI 10.1016/j.acha.2008.09.001
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Lin Z., 2009, AUGMENTED LAGRANGE M
   Liu L, 2014, J COMPUT APPL MATH, V267, P218, DOI 10.1016/j.cam.2014.02.015
   Liu RS, 2012, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2012.6247726
   Lu T, 2016, INT CONF ACOUST SPEE, P1746, DOI 10.1109/ICASSP.2016.7471976
   Lu YM, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2007.914999
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Massa A, 2015, IEEE ANTENN PROPAG M, V57, P224, DOI 10.1109/MAP.2015.2397092
   MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Tropp J.A., 2005, SIGNAL RECOVERY PART
   Wang B, 2016, 2016 INT C PATT REC
   Wang Y, 2014, SIGNAL PROCESS, V104, P188, DOI 10.1016/j.sigpro.2014.03.040
   Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016
   Wu XL, 2012, IEEE T IMAGE PROCESS, V21, P451, DOI 10.1109/TIP.2011.2163520
   Xie Y., 2015, ARXIV151201003
   Xu BH, 2016, MULTIMED TOOLS APPL, V75, P2681, DOI 10.1007/s11042-015-2545-1
   Zhang DB, 2012, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR.2012.6247927
   Zuo WM, 2013, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2013.34
NR 42
TC 5
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12853
EP 12869
DI 10.1007/s11042-017-4919-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100053
DA 2024-07-18
ER

PT J
AU Chen, YY
   Chen, WS
AF Chen, Yung-Yao
   Chen, Wei-Sheng
TI High-quality blind watermarking in halftones using random toggle
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital halftoning; Digital watermarking; Image/document security;
   Printer application; Direct binary search (DBS); Data hiding
ID DIRECT BINARY SEARCH; VISIBILITY; MODULATION
AB This paper presents a blind watermarking method for embedding large data into halftone images. Watermarking in ready-to-print halftones is desirable in printer applications such as authentication and document/image security. It is challenging to embed large information into halftones, while maintaining high image quality. In this paper, we first review a series of halftone watermarking methods that embed data by using Embedding Toggle (ET) in the selected positions. We find that such ET-based methods have two shortcomings: 1) the image quality is limited because of the unknown input data and randomly selected embedding positions, and 2) the selected embedding positions must be recorded to retrieve the hidden data. To tackle the above disadvantages, this study makes two improvements. First, we propose a random toggle approach, in which the embedding positions are movable. Therefore, after the data are embedded, each dot can still be shifted to the most appropriate position to improve the image quality. Second, a self-decodable even/odd parity checking scheme is proposed to embed one bit information in each image block. We also propose a new search strategy, called Swap-Only Block-Based (SOBB) search. By integrating SOBB search with the direct binary search method, the image quality can be greatly improved without damaging the hidden data. From experimental results, the proposed method demonstrated sufficient robustness and excellent image quality.
C1 [Chen, Yung-Yao; Chen, Wei-Sheng] Natl Taipei Univ Technol, Grad Inst Automat Technol, 1,Sect 3,Zhongxiao E Rd, Taipei 106, Taiwan.
C3 National Taipei University of Technology
RP Chen, YY (corresponding author), Natl Taipei Univ Technol, Grad Inst Automat Technol, 1,Sect 3,Zhongxiao E Rd, Taipei 106, Taiwan.
EM yungyaochen@ntut.edu.tw
RI Chen, Yung-Yao/IQU-8095-2023; xu, chen/JNE-5010-2023; fang,
   yu/KCK-2014-2024
OI Chen, Yung-Yao/0000-0001-6852-8862; Chen, Wei-Sheng/0000-0001-8672-180X
FU Ministry of Science and Technology [104-2221-E-027-032]
FX This work was supported in part by the Ministry of Science and
   Technology (104-2221-E-027-032).
CR ANALOUI M, 1992, P SOC PHOTO-OPT INS, V1666, P96, DOI 10.1117/12.135959
   [Anonymous], RANDOMIZED TRIAL EFF
   [Anonymous], 2014, AM J ENG TECHNOLOGY
   Baqai FA, 2005, IEEE SIGNAL PROC MAG, V22, P87, DOI 10.1109/MSP.2005.1407718
   Bulan O, 2010, IEEE T IMAGE PROCESS, V19, P2070, DOI 10.1109/TIP.2010.2046795
   Fu MS, 2002, IEEE T IMAGE PROCESS, V11, P477, DOI 10.1109/TIP.2002.999680
   Fu MS, 2000, PROC SPIE, V3971, P228, DOI 10.1117/12.384977
   Fu MS, 2000, INT CONF ACOUST SPEE, P2318, DOI 10.1109/ICASSP.2000.859304
   Fu WS, 2001, INT CONF ACOUST SPEE, P1965, DOI 10.1109/ICASSP.2001.941332
   Guo Jing-Ming, 2015, IEEE Trans Image Process, V24, P2009, DOI 10.1109/TIP.2014.2387417
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4117, DOI 10.1109/TIP.2012.2198221
   Guo JM, 2011, SIGNAL PROCESS, V91, P126, DOI 10.1016/j.sigpro.2010.06.017
   Guo Y, 2011, P AS PAC SIGN INF PR, P18
   Guo Y, 2014, HIDING SECRET PATTER, P465
   Guo YF, 2016, SIGNAL PROCESS-IMAGE, V41, P85, DOI 10.1016/j.image.2015.12.002
   Guo YF, 2013, IEEE INT SYMP CIRC S, P2996, DOI 10.1109/ISCAS.2013.6572509
   Kacker D, 2003, IEEE T SIGNAL PROCES, V51, P1054, DOI 10.1109/TSP.2003.809369
   Kim HY, 2004, INT J IMAG SYST TECH, V14, P147, DOI 10.1002/ima.20018
   Kim J, 2011, P ICASSP, P1733
   Li PS, 2004, IEEE T IMAGE PROCESS, V13, P201, DOI 10.1109/tip.2003.819232
   Lieberman DJ, 2000, IEEE T IMAGE PROCESS, V9, P1950, DOI 10.1109/83.877215
   Lien BK, 2011, MULTIMED TOOLS APPL, V52, P499, DOI 10.1007/s11042-010-0497-z
   Liu J, 2011, OPT ENG, V50, P1
   NASANEN R, 1984, IEEE T SYST MAN CYB, V14, P920, DOI 10.1109/TSMC.1984.6313320
   Nguyen TS, 2016, MULTIMED TOOLS APPL, V75, P8513, DOI 10.1007/s11042-015-2768-1
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Parah SA, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS, P57, DOI 10.1109/iNIS.2015.41
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Sharma G, 2004, P SOC PHOTO-OPT INS, V5306, P670, DOI 10.1117/12.525550
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Ulichney R, 2000, P SOC PHOTO-OPT INS, V3963, P378
   Ulichney R., 2010, NIP Digital Fabrication Conference, V2010, P602
   Ulichney R., 1987, DIGITAL HALFTONING
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu X, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.9.095005
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
NR 40
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8019
EP 8041
DI 10.1007/s11042-017-4697-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800012
DA 2024-07-18
ER

PT J
AU Kottari, K
   Delibasis, K
   Plagianakos, V
AF Kottari, K.
   Delibasis, K.
   Plagianakos, V.
TI Real time vision-based measurements for quality control of industrial
   rods on a moving conveyor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Online signal processing; Real-time measurement;
   Quality control; Manufacturing; Metal rod
ID NEURAL-NETWORKS; SYSTEM; INSPECTION; IMAGES
AB This work proposes a fully automated approach for vision-based quality control of manufactured metal rods. The proposed approach is able to detect the main axis of the rod and calculate its curvature, versus specifications. The proposed algorithm utilizes video acquired in real time by a single mono-ocular USB camera. A signal processing module identifies in real time the video frame that images the rod at the appropriate position on the conveyor. Initialization of the algorithm can take place either manually, or by utilizing the calibration of the camera. Concurrently, the image processing module estimates the curvature of the rod using its medial axis, to classify the rod as normal or defect. Initial results show that the proposed algorithm can operate in real time with very high accuracy under controlled illumination conditions and backgrounds. This methodology is capable of processing video at 30 frames per second, using a general purpose laptop.
C1 [Kottari, K.; Delibasis, K.; Plagianakos, V.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
RP Kottari, K (corresponding author), Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM kottarikonstantina@gmail.com; kdelibasis@gmail.com; vpp@dib.uth.gr
OI Kottari, Konstantina/0000-0001-7224-5961; Delibasis,
   Konstantinos/0000-0003-1055-3007
CR Bahlmann C, 1999, PATTERN RECOGN, V32, P1049, DOI 10.1016/S0031-3203(98)00128-9
   Bosché F, 2010, ADV ENG INFORM, V24, P107, DOI 10.1016/j.aei.2009.08.006
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Fraser C., 1997, Photogrammetric Record, V15, P901, DOI [DOI 10.1111/0031-868X.00099, 10.1111/0031-868X.00099]
   Gonzalez R.C., 1992, DIGITAL IMAGE PROCES, V5, P11
   Jamshidi J, 2010, P I MECH ENG B-J ENG, V224, P25, DOI 10.1243/09544054JEM1280
   Jiménez AR, 2000, MACH VISION APPL, V11, P321, DOI 10.1007/s001380050117
   Jurca MC, 1993, U. S. patent, Patent No. [5,272,312, 5272312]
   Kottari K, 2016, IEEE CONF IMAGING SY, P423, DOI 10.1109/IST.2016.7738263
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Malamas EN, 2003, IMAGE VISION COMPUT, V21, P171, DOI 10.1016/S0262-8856(02)00152-X
   Oppenheim A, 2013, Discrete-Time Signal Processing
   Packianather MS, 2000, INT J ADV MANUF TECH, V16, P424, DOI 10.1007/s001700050174
   Park C, 2010, OPT ENG, V49, DOI 10.1117/1.3284779
   SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918
   Stojanovic R, 2001, REAL-TIME IMAGING, V7, P507, DOI 10.1006/rtim.2001.0231
   SURESH BR, 1983, IEEE T PATTERN ANAL, V5, P563, DOI 10.1109/TPAMI.1983.4767445
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wulf O., 2003, International conference on control systems and computer science (CSCS14), P2
   Yun JP, 2008, OPT ENG, V47, DOI 10.1117/1.2957958
   Yung-Chun Liu, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P1667, DOI 10.1109/ICIEA.2010.5515197
NR 21
TC 3
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9307
EP 9324
DI 10.1007/s11042-017-4891-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200008
DA 2024-07-18
ER

PT J
AU Singh, D
   Kumar, V
AF Singh, Dilbag
   Kumar, Vijay
TI Comprehensive survey on haze removal techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Dark channel prior; Filtering; Supervised learning;
   Meta-heuristic techniques
ID FAST SINGLE IMAGE; ALGORITHM; FOG; ENHANCEMENT; DEPTH
AB Image haze removal techniques are extensively used in several outdoor applications. Lack of sufficient knowledge that is required to restore hazy images, the existing techniques usually use various attributes and assign constant values to these attributes. Unsuitable assignment to these attributes does not provide desired dehazing results. The primary objective of this review paper is to provide a structured outline of some well-known haze removal techniques. This paper also focuses on the methods which can assign optimal values to image dehazing attributes. The review has revealed that the meta-heuristic techniques can attain the optimistic haze removal parameters and also concurrently develops an optimistic objective function to estimate the depth map efficiently. Finally, this paper describes the various issues and challenges of image dehazing techniques, which are required to be further studied.
C1 [Singh, Dilbag; Kumar, Vijay] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, D (corresponding author), Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM dggill2@gmail.com; vijaykumarchahar@gmail.com
RI Singh, Dilbag/AAQ-6339-2020; Chahar, Vijay Kumar/A-2782-2015
OI Singh, Dilbag/0000-0001-6475-4491; Chahar, Vijay
   Kumar/0000-0002-3460-6989
CR Amintoosi M, 2011, IMAGING SCI J, V59, P238, DOI 10.1179/1743131X10Y.0000000014
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2017, J MOD OPT
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2016, J DISP TECHNOL, V12, P753, DOI 10.1109/JDT.2016.2518646
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Cheng FC, 2015, ENG APPL ARTIF INTEL, V43, P27, DOI 10.1016/j.engappai.2015.03.011
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Ding M, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4566-y
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Faming Fang, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P219, DOI 10.1109/IASP.2010.5476126
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu ZZ, 2015, J SYST ENG ELECTRON, V26, P1070, DOI 10.1109/JSEE.2015.00116
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Galdran A, 2015, SIAM J IMAGING SCI, V8, P1519, DOI 10.1137/15M1008889
   Ge GY, 2015, OPTIK, V126, P3245, DOI 10.1016/j.ijleo.2015.07.138
   Guo F, 2016, INFORM PROCESS LETT, V116, P595, DOI 10.1016/j.ipl.2016.04.013
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Huang SC, 2014, IEEE T INTELL TRANSP, V15, P2321, DOI 10.1109/TITS.2014.2314696
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Kaufman YJ, 1997, J GEOPHYS RES-ATMOS, V102, P16815, DOI 10.1029/97JD01496
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kumari A, 2015, AEU-INT J ELECTRON C, V69, P43, DOI 10.1016/j.aeue.2015.09.001
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li JF, 2015, NEUROCOMPUTING, V156, P1, DOI 10.1016/j.neucom.2015.01.026
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu SL, 2017, COMPUT ELECTR ENG, V62, P345, DOI 10.1016/j.compeleceng.2016.11.021
   Ma ZL, 2016, NEUROCOMPUTING, V173, P1257, DOI 10.1016/j.neucom.2015.08.084
   Meng D, 2015, OPTIK, V126, P3522, DOI 10.1016/j.ijleo.2015.08.220
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Pan XX, 2015, IEEE SIGNAL PROC LET, V22, P1806, DOI 10.1109/LSP.2015.2432466
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Sun W, 2015, COMPUT ELECTR ENG, V46, P371, DOI 10.1016/j.compeleceng.2015.02.009
   Sun W, 2013, OPTIK, V124, P4770, DOI 10.1016/j.ijleo.2013.01.097
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Valls JM, 2005, LECT NOTES COMPUT SC, V3512, P257
   Wang LQ, 2015, IET COMPUT VIS, V9, P903, DOI 10.1049/iet-cvi.2014.0324
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wang Z, 2014, COMPUT ELECTR ENG, V40, P785, DOI 10.1016/j.compeleceng.2013.06.009
   Xie C, 2016, ADV MATH PHYS, V2016, DOI 10.1155/2016/1297832
   Yang YJ, 2013, INT CONF COMPUTAT, P275, DOI [10.1109/ICCPS.2013.6893493, 10.1007/978-3-319-02726-5_20]
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 56
TC 41
Z9 43
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9595
EP 9620
DI 10.1007/s11042-017-5321-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200021
DA 2024-07-18
ER

PT J
AU Singh, N
   Arya, R
   Agrawal, RK
AF Singh, Navjot
   Arya, Rinki
   Agrawal, R. K.
TI Performance enhancement of salient object detection using superpixel
   based Gaussian mixture model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Superpixels; Gaussian mixture model;
   Expectation maximization; Spatial variance; Saliency map
ID VISUAL-ATTENTION; EXTRACTION
AB Humans possess an intelligent system which effortlessly detect salient objects with high accuracy in real-time. It is a challenge to develop a computational model which can mimic human behavior such that the model achieves better detection accuracy and takes less computation time. So far the research community have suggested models which achieve better detection accuracy but at the cost of computation time and vice versa. In this paper, we attempted to realize a model that takes less computational time and simultaneously achieves higher detection accuracy. In the proposed model the original image is divided into m superpixels using SLIC superpixels algorithm and then these superpixels are clustered into k regions using k-means algorithm. Thereafter the result of the k-means clustering is used to build Gaussian mixture model whose parameters are refined using Expectation-Maximization algorithm. Finally the spatial variance of the clusters is computed and a center-weighted saliency map is computed. The performance of the proposed model and seventeen related models is evaluated both qualitatively and quantitatively on seven publicly available datasets. Experimental results show that the proposed model outperforms the existing models in terms of precision, recall and F -measure on all the seven datasets and in terms of area under curve on four datasets. Also, the proposed model takes less computation time in comparison to many methods.
C1 [Singh, Navjot] Natl Inst Technol Uttarakhand, Srinagar 246174, Uttarakhand, India.
   [Arya, Rinki; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; Jawaharlal Nehru University, New Delhi
RP Singh, N (corresponding author), Natl Inst Technol Uttarakhand, Srinagar 246174, Uttarakhand, India.
EM navjot.singh.09@gmail.com
RI AGRAWAL, RAMESH/AAR-8896-2020; Singh, Navjot/I-5444-2017
OI Agrawal, Ramesh kumar/0000-0003-3122-5096; Singh,
   Navjot/0000-0003-0409-8482
CR Achanta  R., 2010, SLIC SUPERPIXELS, P149
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Fu H, 2013, IEEE T IMAGE PROCESS
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Peng P, 2015, NEUROCOMPUTING, V166, P337, DOI 10.1016/j.neucom.2015.03.067
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Singh N, 2015, SIGNAL IMAGE VIDEO P, V9, P427, DOI 10.1007/s11760-013-0457-y
   Snowden RJ, 2012, P PSYCHOL SCI, V13, P180
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yu J, 2014, INT WORKS EARTH OB
   Yu ZW, 2007, IEEE T MULTIMEDIA, V9, P766, DOI 10.1109/TMM.2007.893351
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
NR 34
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8511
EP 8529
DI 10.1007/s11042-017-4748-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800033
DA 2024-07-18
ER

PT J
AU Ramanauskaite, S
   Cenys, A
   Radvile, E
   Ramanauskas, N
AF Ramanauskaite, Simona
   Cenys, Antanas
   Radvile, Egle
   Ramanauskas, Nerijus
TI Gaze point estimation on curved display by using session level
   calibration for flat screen displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flat screen; Curved screen; Gaze point; Eye tracking
ID TRACKING
AB The advantages of curved screen displays find their place in populations everyday life, therefore it is important to adapt the existing eye tracking systems for estimating the gaze point on a curved screen. In this paper we present a curved screen based gaze point estimation model. This model provides methods for estimating the gaze point position by eye rotation angles, and also transforms flat screen based relative coordinates into curved screen based relative coordinates. The model was validated by using a flat screen based eye tracking system for a gaze point estimation on a curved screen. The eye rotation angle, distance to the screen and gaze point location's influence were modelled in this paper as well. The results of these experiments prove the up to 4% increase of gaze point estimation accuracy by using the proposed model, by comparing the flat screen mode with the curved screen. However the results found are significant only if the distance to the screen is less than 0.5 of curved screen radius.
C1 [Ramanauskaite, Simona] Vilnius Gediminas Tech Univ, Dept Informat Technol, Vilnius, Lithuania.
   [Cenys, Antanas; Radvile, Egle] Vilnius Gediminas Tech Univ, Dept Informat Syst, Vilnius, Lithuania.
   [Ramanauskas, Nerijus] Siauliai Univ, Dept Engn, Shiauliai, Lithuania.
C3 Vilnius Gediminas Technical University; Vilnius Gediminas Technical
   University; Siauliai University
RP Ramanauskaite, S (corresponding author), Vilnius Gediminas Tech Univ, Dept Informat Technol, Vilnius, Lithuania.
EM simona.ramanauskaite@vgtu.lt
RI Ramanauskaitė, Simona/A-8594-2016; Čenys, Antanas/ABC-1904-2021
OI Ramanauskaitė, Simona/0000-0003-3195-4280; Cenys,
   Antanas/0000-0002-0208-7176
CR [Anonymous], 1999, ELECTROENCEPHALOGR C
   Beymer David, 2003, COMP VIS PATT REC 20, V2
   EyeTech, 2015, CES 2015 1 MULT EYE
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jen CL, 2016, IEEE ICCE
   Kao WC, 2016, IEEE ICCE
   Kar A, 2016, IEEE ICCE
   KUMAR A, 1992, LARYNGOSCOPE, V102, P367, DOI 10.1288/00005537-199204000-00002
   Mazo G, 2012, USE SMART STAY GALAX
   Mohns R, 2016, WHATS BEST FONT SIZE
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Morimoto CH, 2002, PATT REC 2002 P 16 I, V4
   Newman R, 2000, AUT FAC GEST REC 200, P69
   Ramanauskas N., 2015, Elec- tronics and Electrical Engineering, V72, P65
   REMMEL RS, 1984, IEEE T BIO-MED ENG, V31, P388, DOI 10.1109/TBME.1984.325352
   The Eye Tribe, 2016, EYE TRIB TRACK PRO
   Tobii Tech, 2016, CHANG GAM TOB EYE TR
   Victor TW, 2005, TRANSPORT RES F-TRAF, V8, P167, DOI 10.1016/j.trf.2005.04.014
   Xia L, 2016, MULTIMED TOOLS APPL, V75, P221, DOI 10.1007/s11042-014-2288-4
   Yoo DH, 2002, AUT FAC GEST REC 200
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhefan Y, 2012, P 2012 ACM C UB COMP
NR 24
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6969
EP 6985
DI 10.1007/s11042-017-4616-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700025
DA 2024-07-18
ER

PT J
AU Thap, T
   Chung, H
   Jeong, C
   Ryu, J
   Nam, Y
   Yoon, KH
   Lee, J
AF Thap, Tharoeun
   Chung, Heewon
   Jeong, Changwon
   Ryu, Jonghyun
   Nam, Yunyoung
   Yoon, Kwon-Ha
   Lee, Jinseok
TI Real-time heart activity monitoring with optical illusion using a
   smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Holographic projection; Heart rate; Smartphone; Photoplethysmogram
ID ATRIAL-FIBRILLATION; HEALTH-CARE; PHOTOPLETHYSMOGRAPHY; SURGERY
AB In this study, we obtained a pulsatile photoplethysmogram (PPG) signal from a fingertip using the built-in camera of an iPhone 6 s and displayed a real-time heart activity images with holographic projection on a smartphone screen. Our proposed heart activity hologram is simple and can be easily realized with only a smartphone and overhead projector (OHP) film. A square pyramid-shaped OHP film was positioned on a smartphone screen. The actual cardiac cycle on the smartphone screen was projected onto the film while measuring the pulsatile signal from a fingertip placed on the smartphone's camera. The heart's beat-to-beat time interval was then recorded. This approach enables observation of one's own virtual heart activity in real time, rather than seeing a pulsatile signal graphically on a smartphone. To investigate the feasibility of this heart activity monitoring based on holographic projection, we tested it under different conditions in terms of environmental light, smartphone screen light intensity, and film color, and quantified the contrast-to-noise ratio for comparison.
C1 [Thap, Tharoeun; Chung, Heewon; Lee, Jinseok] Wonkwang Univ, Sch Med, Biomed Engn, Iksan, South Korea.
   [Jeong, Changwon; Ryu, Jonghyun] Wonkwang Univ, Imaging Sci Based Lung & Bone Dis Res Ctr, Iksan, South Korea.
   [Nam, Yunyoung] Soonchunhyang Univ, Comp Sci & Engn, Asan, South Korea.
   [Yoon, Kwon-Ha] Wonkwang Univ, Sch Med, Radiol, Iksan, South Korea.
C3 Wonkwang University; Wonkwang University; Soonchunhyang University;
   Wonkwang University
RP Lee, J (corresponding author), Wonkwang Univ, Sch Med, Biomed Engn, Iksan, South Korea.
EM wec.tharoeun@gmail.com; heewon1001@gmail.com; mediblue@wku.ac.kr;
   jhryu@wku.ac.kr; ynam@sch.ac.kr; khy1646@wku.ac.kr; gonasago@wku.ac.kr
RI Lee, Jinseok/AAV-7182-2021; Lee, Jinseok/GRR-6086-2022; Lee,
   Jinseok/ACF-1247-2022; Nam, Yunyoung/AAI-4536-2020
OI Lee, Jinseok/0000-0002-8580-490X; Lee, Jinseok/0000-0002-8580-490X; Lee,
   Jinseok/0000-0002-8580-490X; Nam, Yunyoung/0000-0002-3318-9394
FU Korean Health Technology R&D Project, Ministry of Health and Welfare,
   Republic of Korea [HI12C0110]; Basic Science Research Program through
   the National Research Foundation of Korea (NRF) - Ministry of Science,
   ICT & Future Planning [NRF-2013R1A1A1005775, NRF-2015M3A9D7067215]
FX This study was partially supported by a grant from the Korean Health
   Technology R&D Project, Ministry of Health and Welfare, Republic of
   Korea (HI12C0110), and partially supported by a Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Science, ICT & Future Planning: NRF-2013R1A1A1005775
   and NRF-2015M3A9D7067215.
CR Aboy M, 2005, IEEE T BIO-MED ENG, V52, P1662, DOI 10.1109/TBME.2005.855725
   Allen J, 2007, PHYSIOL MEAS, V28, pR1, DOI 10.1088/0967-3334/28/3/R01
   Alqassim S., 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P443, DOI 10.1109/HealthCom.2012.6379457
   [Anonymous], 2009, NEW SCI, V204, DOI [10.1016/S0262-4079(09)63056-6, DOI 10.1016/S0262-4079(09)63056-6]
   Banitsas K., 2009, P 9 INT C INF TECH A, P1
   Boulos MNK, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-24
   Bourdillon P, 1980, J MOD OPTIC, V27, P731
   Burgner J, 2013, INT J MED ROBOT COMP, V9, P190, DOI 10.1002/rcs.1446
   Che UK, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P605, DOI 10.1109/TSP.2012.6256368
   Gregoski MJ, 2012, INT J TELEMED APPL, V2012, DOI 10.1155/2012/696324
   Hackett M, 2013, 12 INT IND TRAIN SIM
   Han M, 2004, OPT EXPRESS, V12, P4275, DOI 10.1364/OPEX.12.004275
   Jimenez Luis Felipe, 2013, COMPUTER SCI
   Karlen W, 2013, IEEE ENG MED BIO, P2263, DOI 10.1109/EMBC.2013.6609988
   Kyriacou EC, 2009, IEEE ENG MED BIO, P1246, DOI 10.1109/IEMBS.2009.5333913
   Lee J, 2013, IEEE ENG MED BIO, P1724, DOI 10.1109/EMBC.2013.6609852
   Lee J, 2012, IEEE ENG MED BIO, P1177, DOI 10.1109/EMBC.2012.6346146
   Lee J, 2013, IEEE T BIO-MED ENG, V60, P203, DOI 10.1109/TBME.2012.2208112
   LENSKIYARTEM, 2013, Journal of Information and Communication Convergence Engineering, V11, P216
   Li H, 2013, INT CONF BIOMED, P260, DOI 10.1109/BMEI.2013.6746945
   Luxton DD, 2011, PROF PSYCHOL-RES PR, V42, P505, DOI 10.1037/a0024485
   Marieb Elaine Nicpon, 2007, Human Anatomy Physiology
   Matsumura K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091205
   McManus DD, 2013, HEART RHYTHM, V10, P315, DOI 10.1016/j.hrthm.2012.12.001
   Nam Y, 2014, ANN BIOMED ENG, V42, P885, DOI 10.1007/s10439-013-0944-x
   Ozdalga E, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1994
   Pechprasarn Thanakij, 2013, 2013 10th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, P750
   Pelegris P, 2010, IEEE ENG MED BIO, P5488, DOI 10.1109/IEMBS.2010.5626580
   SANTANGELO PJ, 1993, PROG ENERG COMBUST, V19, P587, DOI 10.1016/0360-1285(93)90004-X
   Schäfer A, 2013, INT J CARDIOL, V166, P15, DOI 10.1016/j.ijcard.2012.03.119
   Scully CG, 2012, IEEE T BIO-MED ENG, V59, P303, DOI 10.1109/TBME.2011.2163157
   Siddiqui SA, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0485-6
   Tamura T, 2014, ELECTRONICS-SWITZ, V3, P282, DOI 10.3390/electronics3020282
   Ventola C Lee, 2014, P T, V39, P356
   Vizbara V, 2013, BIOMED ENG, V2015, P17
   Wac K, 2013, ARXIV13107965
NR 36
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6209
EP 6224
DI 10.1007/s11042-017-4530-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800050
DA 2024-07-18
ER

PT J
AU Zhao, MH
   Yuan, YQ
   Zhang, X
   Shi, ZH
   Wang, YH
AF Zhao, Minghua
   Yuan, Yongqin
   Zhang, Xin
   Shi, Zhenghao
   Wang, Yinghui
TI A novel key frames matching approach for human locomotion interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical motion capture; Locomotion interpolation; Feature extraction;
   Key frames matching; Locomotion segmentation
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; HUMAN MOTION; HEVC
AB A novel key frames matching approach for human locomotion interpolation is proposed in this paper. Firstly, locomotion data is transformed from body coordinate system to world coordinate system based on recursive algorithm; secondly, features of two feet and step distance are extracted; thirdly, key frames are extracted based on feature curve and the locomotion sequence is segmented; fourthly, a new approach for key frames matching is put forward; finally, transition frames are interpolated between the matched key frames using quaternion Slerp (Spherical linear interpolation) algorithm and linear interpolation algorithm. The main contributions of this paper are: i) different locomotion sequences can be synthesized in a controllable manner with good effect; ii) to extract locomotion features conveniently, locomotion data in body coordinate system is transformed to world coordinate system; iii) to analyze locomotion sequences intuitively and accurately, key frames are extracted and locomotion sequences are segmented based on feature curve analysis; iv) to avoid illogical jump of traditional interpolation between key frames, a new key frames matching strategy is put forward and only the key frames between two continuous segments can be chosen as matching frames. Experimental results based on the CMU MoCap database show that the proposed method can confirm the logical correctness and naturalness in the junction of two locomotion sequences.
C1 [Zhao, Minghua; Yuan, Yongqin; Zhang, Xin; Shi, Zhenghao; Wang, Yinghui] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, MH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
EM mh_zhao@126.com
RI wang, yinghui/GWV-7334-2022
FU National Natural Science Foundation of China [61401355, 61472319,
   61502382]; Key Laboratory Foundation of Shaanxi Education Department,
   China [14JS072]; Science and Technology Project Foundation of Beilin
   District, Xi'an City, China [GX1621]; Fok Ying Tung Education Foundation
   [141119]
FX This work was partially supported by a grant from the National Natural
   Science Foundation of China (No. 61401355, No. 61472319 and No.
   61502382), a grant from the Key Laboratory Foundation of Shaanxi
   Education Department, China (No. 14JS072), a grant from Science and
   Technology Project Foundation of Beilin District, Xi'an City, China
   (No.GX1621) and a grant from Fok Ying Tung Education Foundation (No.
   141119). The authors also thank anonymous reviewers for their valuable
   comments.
CR [Anonymous], 1998, QUATERNIONS INTERPOL
   Ashraf G, 2000, PROC GRAPH INTERF, P45
   Cardle M, 2004, TECHNICAL REPORT
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Gleicher M, 2008, ACM SIGGRAPH 2008 CL, V52
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kron Taesoo., 2005, EUROGRAPHICSACM SIGG, P29, DOI DOI 10.1145/1073368.1073373
   LaViers A, 2012, P AMER CONTR CONF, P4327
   Mahmudi M, 2013, IEEE T VIS COMPUT GR, V19, P774, DOI 10.1109/TVCG.2012.149
   Nopparit Suthasinee, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P13, DOI 10.1109/ICITEED.2013.6676203
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Rose C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P147, DOI 10.1145/237170.237229
   Ruijiao Tian, 2012, 2012 Fourth International Conference on Computational and Information Sciences (ICCIS), P530, DOI 10.1109/ICCIS.2012.115
   Xia SH, 2009, SCI CHINA SER F, V52, P741, DOI 10.1007/s11432-009-0088-7
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Tao, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P1691
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
   Zaman L, 2013, P 2013 IE INT C COMP, V11, P585
   Zhao LM, 2009, GRAPH MODELS, V71, P139, DOI 10.1016/j.gmod.2009.04.001
NR 24
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7779
EP 7794
DI 10.1007/s11042-017-4677-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700061
DA 2024-07-18
ER

PT J
AU Chang, J
   Ryoo, S
AF Chang, JaeKhun
   Ryoo, SeungTaek
TI Implementation of an improved facial emotion retrieval method in
   multimedia system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion retrieval; Facial features; Machine learning; Fisherface
AB The interaction between machine and human with the development of information technology is growing, and therefore human friendly system is more increasing in actual circumstances. The most important thing in communication between human and machine is the understanding of each other's thought and the knowing of each other's emotion. This paper proposes a new method of grasping human emotion with the emotion recognition through the human's facial image. This new approach consists of two categories, which include the combination of principal component analysis, linear discriminant analysis for pattern recognition problem, and support vector machine for the emotion retrieval from the images.
C1 [Chang, JaeKhun; Ryoo, SeungTaek] Hanshin Univ, Sch Comp Engn, Osan, South Korea.
C3 Hanshin University
RP Chang, J (corresponding author), Hanshin Univ, Sch Comp Engn, Osan, South Korea.
EM jchang@hs.ac.kr; stryoo@hs.ac.kr
FU Hanshin University
FX This work was supported by Hanshin University Research Grant.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Ekman P, 1972, EMOTION HUMAN FACE P
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   황인학, 2014, [Journal of The Korean Society for Computer Game, 한국컴퓨터게임학회논문지], V27, P113
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
NR 7
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 5059
EP 5065
DI 10.1007/s11042-017-5241-5
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500054
DA 2024-07-18
ER

PT J
AU Farhan, M
   Aslam, M
   Jabbar, S
   Khalid, S
AF Farhan, Muhammad
   Aslam, Muhammad
   Jabbar, Sohail
   Khalid, Shehzad
TI Multimedia based qualitative assessment methodology in eLearning:
   student teacher engagement analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Electronic assessment; Visual engagement; Assessment;
   Qualitative multimedia research
ID VISUAL-ATTENTION; TOOLS; TECHNOLOGIES; CHILDREN
AB Multimedia-based Electronic learning (eLearning) is an effective method of knowledge transfer. Multimedia-based eLearning provides the opportunity to the students that they can use once delivered and recorded video lecture any time. Multimedia tools and its applications if used in eLearning enable the students and teachers to take such kind of advantages. Multimedia applications provide the advantages to students and teacher in eLearning but challenges are also striking features. One of the challenges is to measure and analyze visual engagement and visual attention for teachers and students respectively. Visual engagement of the video lecture is measured and analyzed to verify the effectiveness of the teachers' lectures. In the same way, the visual attention for the students is also be measured and analyzed. We have presented a qualitative assessment methodology and an algorithm for both of the measures and their correlation. Covariance and relationship between the two measures are the key technique of this paper. Multimedia-based software tools have been developed for this purpose. Results of both the tools are very interesting and promising. They are interpreted using descriptive and graphical statistics.
C1 [Farhan, Muhammad; Aslam, Muhammad] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Farhan, Muhammad; Jabbar, Sohail] COMSATS Inst Informat Technol, Dept Comp Sci, GT Rd,COMSATS Rd, Sahiwal 54000, Punjab, Pakistan.
   [Jabbar, Sohail] Kyungpook Natl Univ, Sch Comp Sci & Engn, Network Lab, Daegu, South Korea.
   [Khalid, Shehzad] Bahria Univ, Dept Comp Engn, Islamabad, Pakistan.
C3 University of Engineering & Technology Lahore; COMSATS University
   Islamabad (CUI); Kyungpook National University
RP Farhan, M (corresponding author), Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.; Farhan, M (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, GT Rd,COMSATS Rd, Sahiwal 54000, Punjab, Pakistan.
EM farhansajid@gmail.com; maslam@uet.edu.pk; sjabbar.research@gmail.com;
   shehzad_khalid@hotmail.com
RI ASLAM, MUHAMMAD/AAB-9831-2020; Farhan, Muhammad/F-8071-2011; Jabbar,
   Sohail/E-3052-2012
OI Farhan, Muhammad/0000-0002-3649-5717; Jabbar, Sohail/0000-0002-2127-1235
CR Ali  N., 2016, ADV HLTH PROFESSIONS, V1, P70
   Gómez-Aguilar DA, 2015, COMPUT HUM BEHAV, V47, P60, DOI 10.1016/j.chb.2014.11.001
   [Anonymous], 2004, INT J INSTR TECHNOL
   [Anonymous], 2002, ANN C ASS INF TECHN
   Baumgartner H, 2014, UNDERSTANDING ROLE N
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bostan CG, 2015, PROCD SOC BEHV, V180, P1444, DOI 10.1016/j.sbspro.2015.02.291
   Cheon J, 2012, COMPUT EDUC, V59, P1054, DOI 10.1016/j.compedu.2012.04.015
   Clark R. C., 2016, E LEARNING SCI INSTR, DOI [10.1002/9781119239086, DOI 10.1002/9781119239086]
   Feldmann-Wüstefeld T, 2015, PSYCHOPHYSIOLOGY, V52, P1483, DOI 10.1111/psyp.12514
   Ferreira C, 2013, J BALT SCI EDUC, V12, P509
   Fisher AV, 2014, PSYCHOL SCI, V25, P1362, DOI 10.1177/0956797614533801
   George PP, 2014, J GLOB HEALTH, V4, DOI 10.7189/jogh.04.010406
   Han JW, 2014, MACH VISION APPL, V25, P1671, DOI 10.1007/s00138-013-0558-1
   Jabbar S, 2016, J SUPERCOMPUT, V72, P58, DOI 10.1007/s11227-015-1488-7
   Jeong HY, 2014, MULTIMED TOOLS APPL, V73, P887, DOI 10.1007/s11042-013-1445-5
   Jeong YS, 2015, MULTIMED TOOLS APPL, V74, P3413, DOI 10.1007/s11042-015-2586-5
   Johnson AM, 2015, J COMPUT ASSIST LEAR, V31, P97, DOI 10.1111/jcal.12078
   Khalid S, 2017, J REAL-TIME IMAGE PR, V13, P449, DOI 10.1007/s11554-015-0545-z
   Kimura A, 2013, IEICE T INF SYST, VE96D, P562, DOI 10.1587/transinf.E96.D.562
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   LaBerge D., 2014, Learning and Cognitive Processes, V4, P237
   Laurillard D., 2002, Rethinking University Teaching: A Conversational Framework for the Effective Use of Learning Technologies, DOI [10.4324/9781315012940, DOI 10.4324/9781315012940]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leow F. -T., 2014, TURK ONLINE J EDUC T, V13, P99
   Lim H, 2007, INT J INFORM MANAGE, V27, P22, DOI 10.1016/j.ijinfomgt.2006.08.002
   Lin CF, 2013, COMPUT EDUC, V68, P199, DOI 10.1016/j.compedu.2013.05.009
   Malik KR, 2015, MULTIMED TOOLS APPL, V75, P1
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Naseer MK, 2014, 2014 WORLD SYMPOSIUM ON COMPUTER APPLICATIONS & RESEARCH (WSCAR)
   Nation ISP, 2013, TEACH LEARN VOC
   Renkl A, 2017, EDUC PSYCHOL REV, V29, P599, DOI 10.1007/s10648-015-9340-4
   Renninger A., 2014, The role of interest in learning and development
   Sasson NJ, 2014, J AUTISM DEV DISORD, V44, P584, DOI 10.1007/s10803-013-1910-z
   Spampinato C, 2014, MULTIMED TOOLS APPL, V70, P409, DOI 10.1007/s11042-014-1853-1
   Stanisavljevic Z, 2015, MULTIMED TOOLS APPL, V74, P3843, DOI 10.1007/s11042-013-1802-4
   Tsai MJ, 2012, COMPUT EDUC, V58, P375, DOI 10.1016/j.compedu.2011.07.012
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yeo SS, 2015, MULTIMED TOOLS APPL, V74, P179, DOI 10.1007/s11042-014-2113-0
   Yousafzai A, 2016, INT J INFORM MANAGE, V36, P784, DOI 10.1016/j.ijinfomgt.2016.05.010
NR 41
TC 11
Z9 12
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4909
EP 4923
DI 10.1007/s11042-016-4212-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500046
DA 2024-07-18
ER

PT J
AU Hu, Y
   Duan, K
   Zhang, Y
   Hossain, MS
   Rahman, SMM
   Alelaiwi, A
AF Hu, Ying
   Duan, Kui
   Zhang, Yin
   Hossain, M. Shamim
   Rahman, Sk Md Mizanur
   Alelaiwi, Abdulhameed
TI Simultaneously aided diagnosis model for outpatient departments via
   healthcare big data analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Aided diagnosis; SVM; Spatio-temporal evolution
ID MEDICINE; VECTOR; CLASSIFICATION; SERVICES
AB Recent real medical datasets show that the number of outpatients in China has sharply increased since 2013, when the Chinese health insurance reform started. This situation leads to increased waiting time for the outpatients; in particular, the normal operation of a hospital will be congested at rush hour. The existence of this problem in outpatient departments causes a reduction in doctors' diagnostic time, and a high working strength is required to address this issue. In this paper, a simultaneous model based on machine learning is proposed for aiding outpatient doctors in performing diagnoses. We use Support Vector Machine (SVM) and Neural Networks (NN) to classify hyperlipemia using the clinical features extracted from a real medical dataset. The results, with an accuracy of 90 %, indicate that our Simultaneously Aided Diagnosis Model (SADM) applied to aid diagnosis for outpatient doctors and achieves the objective of increasing efficiency and reducing working strength.
C1 [Hu, Ying] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Duan, Kui] Huazhong Univ Sci & Technol, Sch Hosp, Wuhan 430074, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430074, Peoples R China.
   [Hossain, M. Shamim; Alelaiwi, Abdulhameed] King Saud Univ, Software Engn Dept, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Rahman, Sk Md Mizanur] King Saud Univ, Dept Informat Syst, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Zhongnan University of Economics & Law; King Saud
   University; King Saud University
RP Duan, K (corresponding author), Huazhong Univ Sci & Technol, Sch Hosp, Wuhan 430074, Peoples R China.
EM kuiduan.hust@gmail.com; yin.zhang.cn@ieee.org; mshossain@ksu.edu.sa;
   mizan@ksu.edu.sa; aalelaiwi@ksu.edu.sa
RI Li, Wang/M-1612-2019; Zhang, Yin/K-2414-2019; Alelaiwi, Abdulhameed
   A/D-8729-2015; Rahman, Sk Md Mizanur/AAN-7841-2020; Hossain, M.
   Shamim/K-1362-2014; Zhang, Yin/O-2149-2015; Guizani,
   Mohsen/AAX-4534-2021
OI Zhang, Yin/0000-0002-8103-8937; Rahman, Sk Md
   Mizanur/0000-0002-9166-6830; Hossain, M. Shamim/0000-0001-5906-9422;
   Zhang, Yin/0000-0002-1772-0763; Guizani, Mohsen/0000-0002-8972-8094
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia through the Profile Research Group project [PRG-1436-17]
FX The authors would like to extend their sincere appreciations to the
   Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia for its funding of this research through the Profile Research
   Group project (PRG-1436-17).
CR [Anonymous], IEEE SYSTEMS J
   [Anonymous], IEEE T CIRCUITS SYST
   Bates DW, 2014, HEALTH AFFAIR, V33, P1123, DOI 10.1377/hlthaff.2014.0041
   Bellazzi R, 2008, INT J MED INFORM, V77, P81, DOI 10.1016/j.ijmedinf.2006.11.006
   Bron EE, 2015, IEEE J BIOMED HEALTH, V19, P1617, DOI 10.1109/JBHI.2015.2432832
   Chang CD, 2011, EXPERT SYST APPL, V38, P5507, DOI 10.1016/j.eswa.2010.10.086
   Chen M, 2016, MOBILE NETW APPL, V21, P825, DOI 10.1007/s11036-016-0745-1
   Chen M, 2014, INFORM SCIENCES, V284, P142, DOI 10.1016/j.ins.2014.06.023
   Chen M, 2014, IEEE COMMUN SURV TUT, V16, P98, DOI 10.1109/SURV.2013.110113.00249
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chen Min, 2014, Big Data: Related Technologies, Challenges and Future Prospects
   Chu SM, 2015, J ETHNOPHARMACOL, V168, P129, DOI 10.1016/j.jep.2015.03.047
   Cinar M, 2009, EXPERT SYST APPL, V36, P6357, DOI 10.1016/j.eswa.2008.08.010
   Dogan Sengul, 2008, Mathematical & Computational Applications, V13, P193
   Esfandiari N, 2014, EXPERT SYST APPL, V41, P4434, DOI 10.1016/j.eswa.2014.01.011
   Ge XH, 2015, IEEE T COMMUN, V63, P1019, DOI 10.1109/TCOMM.2015.2394386
   Ge XH, 2015, IET NETW, V4, P158, DOI 10.1049/iet-net.2014.0081
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Lin K, 2016, IEEE T AUTOMATION SC
   Liu C.H., 2017, IEEE SYST J, V11, P1435, DOI [DOI 10.5772/61836, DOI 10.1109/JSYST.2015.2430362]
   Liu CZ, 2011, PROC SPIE, V8201, DOI [10.1117/12.904710, 10.1109/SAHCN.2011.5984882]
   Liu CH, 2015, IEEE T VEH TECHNOL, V64, P4684, DOI 10.1109/TVT.2014.2367029
   Liu CH, 2014, IEEE T EMERG TOP COM, V2, P473, DOI 10.1109/TETC.2014.2364915
   Liu CH, 2014, AD HOC NETW, V18, P85, DOI 10.1016/j.adhoc.2013.02.008
   Liu CH, 2014, IEEE T WIREL COMMUN, V13, P604, DOI 10.1109/TWC.2013.010214.121856
   Liu CH, 2013, IEEE NETWORK, V27, P33, DOI 10.1109/MNET.2013.6574663
   Liu CY, 2016, SCI REP-UK, V6, DOI 10.1038/srep23375
   Nori N, 2015, SSACM SIGKDD C KNOWL, P13
   Premarathne US, 2013, 35 ANN INT C IEEE EN, P3
   Shamim Hossain M, 2016, AUDIO VISUAL EMOTION
   Sheng ZG, 2015, IEEE T VEH TECHNOL, V64, P1156, DOI 10.1109/TVT.2014.2322653
   Yurur O, 2014, IEEE COMMUN MAG, V52, P24, DOI 10.1109/MCOM.2014.6829941
   Zhang B, 2016, COMPUT NETW, V101, P29, DOI 10.1016/j.comnet.2015.12.022
   Zhang B, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2630074
   Zhang Y, 2014, IEEE NETWORK, V28, P52, DOI 10.1109/MNET.2014.6863132
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
NR 38
TC 30
Z9 31
U1 2
U2 121
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3729
EP 3743
DI 10.1007/s11042-016-3719-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600046
DA 2024-07-18
ER

PT J
AU Jiang, WH
   Zhao, ZC
   Su, F
AF Jiang, Wenhui
   Zhao, Zhicheng
   Su, Fei
TI Weakly supervised detection with decoupled attention-based deep
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weak supervision; Object detection; Deep learning; Attention model
ID OBJECT LOCALIZATION
AB Training object detectors with only image-level annotations is an important problem with a variety of applications. However, due to the deformable nature of objects, a target object delineated by a bounding box always includes irrelevant context and occlusions, which causes large intra-class object variations and ambiguity in object-background distinction. For this reason, identifying the object of interest from a substantial amount of cluttered backgrounds is very challenging. In this paper, we propose a decoupled attention-based deep model to optimize region-based object representation. Different from existing approaches posing object representation in a single-tower model, our proposed network decouples object representation into two separate modules, i.e., image representation and attention localization. The image representation module captures content-based semantic representation, while the attention localization module regresses an attention map which simultaneously highlights the locations of the discriminative object parts and down weights the irrelevant backgrounds presented in the image. The combined representation alleviates the impact from the noisy context and occlusions inside an object bounding box. As a result, object-background ambiguity can be largely reduced and background regions can be suppressed effectively. In addition, the proposed object representation model can be seamlessly integrated into a state-of-the-art weakly supervised detection framework, and the entire model can be trained end-to-end. We extensively evaluate the detection performance on the PASCAL VOC 2007, VOC 2010 and VOC2012 datasets. Experimental results demonstrate that our approach effectively improves weakly supervised object detection.
C1 [Jiang, Wenhui; Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
   [Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Jiang, WH (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
EM jiang1st@bupt.edu.cn; zhaozc@bupt.edu.cn; sufei@bupt.edu.cn
RI jiang, wen/GYI-9662-2022
FU Chinese National Natural Science Foundation [61471049, 61372169,
   61532018]
FX This work is supported by Chinese National Natural Science Foundation
   under Grants 61471049, 61372169 and 61532018.
CR Bency AJ, 2016, EUR C COMP VIS
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711
   Chang JY, 2016, IEEE T PATTERN ANAL, V38, P1612, DOI 10.1109/TPAMI.2016.2519021
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen L, 2015, RSC SMART MATER, P1
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang WH, 2016, MULTIMED TOOLS APPL, V75, P9095, DOI 10.1007/s11042-015-2939-0
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karthikeyan S, 2015, P IEEE C COMP VIS PA, DOI [10.1109/CVPR.2015.7298944, DOI 10.1109/CVPR.2015.7298944]
   Kavukcuoglu K.., 2015, P INT C LEARNING REP, P1, DOI [10.48550/arXiv.1412.7755, DOI 10.48550/ARXIV.1412.7755]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Mnih V, 2014, ADV NEUR IN, V27
   Oquab M., 2015, PROC CVPR IEEE, P685
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Papadopoulos Dim P., 2014, ECCV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma S, 2016, ACTION RECOGNITION U
   Shi M, 2016, EUR C COMP VIS
   Shih KevinJ., 2016, Where to Look: Focus Regions for Visual Question Answering
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HO, 2014, P ICML 14 P 31 INT C, V32
   Song HO, 2014, P NIPS 14 P 27 INT C
   Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Uijlings JRR, 2016, IEEE C COMP VIS PATT
   Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You Q, 2016, IEEE C COMP VIS PATT, P10
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang HW, 2016, COMPUT FRAUD SECUR, P16, DOI 10.1016/S1361-3723(16)30027-6
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 59
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3261
EP 3277
DI 10.1007/s11042-017-5087-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600019
DA 2024-07-18
ER

PT J
AU Tutubalina, E
   Nikolenko, S
AF Tutubalina, Elena
   Nikolenko, Sergey
TI Exploring convolutional neural networks and topic models for user
   profiling from drug reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text mining; Natural language processing; Topic modeling; Deep learning;
   Convolutional neural networks; Multi-task learning; Single-task
   learning; User reviews; Demographic prediction; Demographic attributes;
   Social media; Mental health
ID SENTIMENT ANALYSIS; AGE; TOOL
AB Pharmacovigilance, and generally applications of natural language processing models to healthcare, have attracted growing attention over the recent years. In particular, drug reactions can be extracted from user reviews posted on the Web, and automated processing of this information represents a novel and exciting approach to personalized medicine and wide-scale drug tests. In medical applications, demographic information regarding the authors of these reviews such as age and gender is of primary importance; however, existing studies usually either assume that this information is available or overlook the issue entirely. In this work, we propose and compare several approaches to automated mining of demographic information from user-generated texts. We compare modern natural language processing techniques, including extensions of topic models and convolutional neural networks (CNN). We apply single-task and multi-task learning approaches to this problem. Based on a real-world dataset mined from a health-related web site, we conclude that while CNNs perform best in terms of predicting demographic information by jointly learning different user attributes, topic models provide additional information and reflect gender-specific and age-specific symptom profiles that may be of interest for a researcher.
C1 [Tutubalina, Elena; Nikolenko, Sergey] Kazan Volga Reg Fed Univ, Kazan, Russia.
   [Nikolenko, Sergey] Steklov Inst Math, St Petersburg, Russia.
C3 Kazan Federal University; Russian Academy of Sciences; Steklov
   Mathematical Institute of the Russian Academy of Sciences; St.
   Petersburg Department of the Steklov Mathematical Institute of the
   Russian Academy of Sciences
RP Tutubalina, E (corresponding author), Kazan Volga Reg Fed Univ, Kazan, Russia.
EM elvtutubalina@kpfu.ru; sergey@logic.pdmi.ras.ru
RI Nikolenko, Sergey/AAU-3615-2020; Tutubalina, Elena/E-3752-2017
OI Nikolenko, Sergey/0000-0001-7787-2251; Tutubalina,
   Elena/0000-0001-7936-0284
FU Russian Science Foundation [15-11-10019]; Russian Science Foundation
   [15-11-10019] Funding Source: Russian Science Foundation
FX This work was supported by the Russian Science Foundation grant no.
   15-11-10019. The authors are grateful to Prof. Valery Solovyev for his
   continuous support. The authors also thank Ilseyar Alimova for her
   suggestions on related work.
CR Adams DZ, 2017, INT J MED INFORM, V100, P108, DOI 10.1016/j.ijmedinf.2017.01.005
   Alekseev A, 2017, COMPUT SIST, V21, P203, DOI [10.13053/CyS-21-2-2734, 10.13053/cys-21-2-2734]
   Alekseev A, 2016, PROCEEDINGS OF THE 2016 IEEE ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE CONFERENCE (AINL FRUCT 2016), P3
   Alimova I, 2017, P INT C AN IM SOC NE
   [Anonymous], 2011, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing
   [Anonymous], 2017, KOMPJUT LINGVISTIKA
   Arnett JJ, 2000, AM PSYCHOL, V55, P469
   Bardel A, 2009, BMC PUBLIC HEALTH, V9, DOI 10.1186/1471-2458-9-37
   Benton A, 2017, PROCEEDINGS OF THE 1, P152, DOI [DOI 10.18653/V1/E17-1015, 10.18653/v1/e17-1015]
   Biyani Prakhar, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P413
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bui Nicola., 2011, Proceedings of the 4th International Symposium on Applied Sciences in Biomedical and Communication Technologies - ISABEL'11, P1
   Buzzi MC, 2017, MULTIMED TOOLS APPL, V76, P10677, DOI 10.1007/s11042-015-3190-4
   Cambria E, 2012, EXPERT SYST APPL, V39, P10533, DOI 10.1016/j.eswa.2012.02.120
   Choi S- P, 2014, MULTIMEDIA TOOLS APP, V71
   Chou WYS, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1249
   Coates J., 2015, Women, men and language: A sociolinguistic account of gender differences in language, DOI DOI 10.4324/9781315835778
   Conway M, 2016, CURR OPIN PSYCHOL, V9, P77, DOI 10.1016/j.copsyc.2016.01.004
   Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]
   Correa T, 2010, COMPUT HUM BEHAV, V26, P247, DOI 10.1016/j.chb.2009.09.003
   Coulter A., 2006, The quality enhancing interventions project: patient-focused interventions
   Salas-Zárate MD, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/5140631
   Deng Y, 2014, MEDIR SIGIR, P12
   Deriu J, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1045, DOI 10.1145/3038912.3052611
   FISCHER JL, 1958, WORD, V14, P47, DOI 10.1080/00437956.1958.11659655
   Fisher C R, 1980, Health Care Financ Rev, V1, P65
   Gao Z, 2017, MULTIMED TOOLS APPL, V76, P20125, DOI 10.1007/s11042-017-4384-8
   Garera Nikesh., 2009, P JOINT C 47 ANN M A, V2, P710
   GLENN F, 1981, ANN SURG, V193, P56, DOI 10.1097/00000658-198101000-00009
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Helmert U, 2001, SOZ PRAVENTIV MED, V46, P320, DOI 10.1007/BF01321083
   Hossain MS, 2015, MULTIMED TOOLS APPL, V74, P5205, DOI 10.1007/s11042-014-2202-0
   Jin-Cheon Na, 2012, The Outreach of Digital Libraries: A Globalized Resource Network. 14th International Conference on Asia-Pacific Digital Libraries. (ICADL 2012). Proceedings, P189, DOI 10.1007/978-3-642-34752-8_25
   Karger A, 2014, BUNDESGESUNDHEITSBLA, V57, P1092, DOI 10.1007/s00103-014-2019-z
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Kotov A, 2015, SOCIAL MEDIA ANAL HE, P309, DOI [10.1201/b18588-11, DOI 10.1201/B18588-11]
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu MF, 2017, MULTIMED TOOLS APPL, V76, P10541, DOI 10.1007/s11042-015-3094-3
   McClellan C, 2016, J AM MED INFORM ASSN
   McCracken JP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055670
   Miftakhutdinov Z, 2017, CLEF
   Nikolenko SI, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1029, DOI 10.1145/2911451.2914720
   Ofek N, 2013, 2013 INTERNATIONAL CONFERENCE ON SOCIAL INTELLIGENCE AND TECHNOLOGY (SOCIETY), P109, DOI 10.1109/SOCIETY.2013.20
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Preoiuc-Pietro D., 2015, P 2 WORKSH COMP LING, P21, DOI [DOI 10.3115/V1/W15-1203, 10.3115/v1/W15-1203]
   Pyysalo S, 2013, P LBM, P39
   Ramage Daniel, 2011, P 17 ACM SIGKDD INT, P457, DOI DOI 10.1145/2020408.2020481
   Ramtekkar UP, 2010, J AM ACAD CHILD PSY, V49, P217, DOI 10.1016/j.jaac.2009.11.011
   Ranzato M, 2015, INT J COMPUT VISION, V113, P1, DOI 10.1007/s11263-015-0813-1
   Rao D., 2010, P 2 INT WORKSHOP SEA, P37, DOI DOI 10.1145/1871985.1871993
   Rodrigues RG, 2016, INT J MED INFORM, V85, P80, DOI 10.1016/j.ijmedinf.2015.09.007
   Rose C., 2011, Proceedings of the 5th ACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, LaTeCH@ACL 2011, 24 June, 2011, Portland, Oregon, USA, P115
   [Саркисян А.З. Sarkisian A.Z.], 2011, [Проблемы репродукции, Problemy reproduktsii], P105
   Sharma H., 2014, P 6 ASE INT C SOC CO, P1, DOI [DOI 10.1109/NCC.2014.6811357, 10.1109/NCC.2014.6811357]
   Sidana S, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P849, DOI 10.1145/2911451.2914697
   Slutske WS, 2003, J ABNORM PSYCHOL, V112, P263, DOI 10.1037/0021-843X.112.2.263
   Snyder PJ, 1999, J CLIN ENDOCR METAB, V84, P2647, DOI 10.1210/jc.84.8.2647
   Sogaard A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P231
   Solovyev V, 2016, COMPUT INTEL NEUROSC, V2016, P16
   Nguyen T, 2017, MULTIMED TOOLS APPL, V76, P10653, DOI 10.1007/s11042-015-3128-x
   Dang TT, 2016, LECT NOTES ARTIF INT, V9799, P255, DOI 10.1007/978-3-319-42007-3_22
   Turney P., 2003, MEASURING PRAISE CRI
   Tutubalina E, 2017, J HEALTHC ENG, P2017
   Tutubalina E, 2016, P 5 INT C AN IM SOC, P208
   Tutubalina E, 2017, COMPUT SIST, V21, P227, DOI [10.13053/cys-21-2-2736, 10.13053/CyS-21-2-2736]
   Tutubalina E, 2017, LECT NOTES ARTIF INT, V10089, P174, DOI 10.1007/978-3-319-58130-9_17
   Tutubalina E, 2015, LECT NOTES ARTIF INT, V9414, P92, DOI 10.1007/978-3-319-27101-9_7
   Volkova S, 2014, P ASS COMP LING ACL
   Xia L, 2009, LECT NOTES ARTIF INT, V5729, P70
   Yalamanchi D, 2011, THESIS
   Yang ZH, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P413, DOI 10.1145/2766462.2767758
NR 74
TC 13
Z9 14
U1 0
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4791
EP 4809
DI 10.1007/s11042-017-5336-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500040
DA 2024-07-18
ER

PT J
AU Wang, Z
   Hahn, K
   Kim, Y
   Song, S
   Seo, JM
AF Wang, Zihuan
   Hahn, Kyusup
   Kim, Youngsam
   Song, Sanghyup
   Seo, Jong-Mo
TI A news-topic recommender system based on keywords extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet news; Recommender system; Keywords extraction; Topic extraction
ID TRACKING
AB In recent years, internet news has become one of the most important channels for information acquisition, as more and more people read news through internet connected computers, tablets, and smart phones, etc. Owing to the constantly reproduced news, the number of online media increases dramatically and the volume of news also expands rapidly. Consequently, obtaining primary information from the internet is of great interest. This paper presents a news-topic recommender system based on keywords extraction. It is shown that the proposed system is very effective in acquiring specific topics within any specific period of time.
C1 [Wang, Zihuan; Seo, Jong-Mo] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
   [Hahn, Kyusup] Seoul Natl Univ, Dept Commun, Seoul, South Korea.
   [Kim, Youngsam] Seoul Natl Univ, Dept Linguist, Seoul, South Korea.
   [Song, Sanghyup] Seoul Natl Univ, Big Data Inst, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University (SNU)
RP Seo, JM (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
EM keith228@snu.ac.kr; kyuhahn@snu.ac.kr; youngsamy@gmail.com;
   willsong@snu.ac.kr; callme@snu.ac.kr
FU Seoul National University Big Data Institute through the Data Science
   Research Project
FX This work was supported by Seoul National University Big Data Institute
   through the Data Science Research Project 2015.
CR Allan J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P37, DOI 10.1145/290941.290954
   [Anonymous], 2003, P 26 ANN INT ACM SIG, DOI DOI 10.1145/860435.860495
   [Anonymous], 2004, P 2004 C EMP METH NA
   Bruno P, 2004, P 20 INT C COMP LING
   Chen KY, 2007, IEEE T KNOWL DATA EN, V19, P1016, DOI 10.1109/TKDE.2007.1040
   [洪宇 HONG Yu], 2007, [中文信息学报, Journal of Chinese Information Processing], V21, P71
   Hsu WH, 2006, IEEE IMAGE PROC, P141, DOI 10.1109/ICIP.2006.312379
   Iwata T, 2009, IJCAI, V9
   James A, 2012, TOPIC DETECTION TRAC, V12
   Jin Zhu, 2005, Journal of the China Society for Scientific and Technical Information, V24, P555
   Lee Sungjick, 2009, [The Journal of Society for e-Business Studies, 한국전자거래학회지], V14, P59
   Lee S, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P554, DOI 10.1109/NCM.2008.199
   Li H., 2009, MICROCOMPUTER APPL, V30, pl
   Mikel R, 2009, 2009 IEEE 12 INT C C
   Mori M, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P338, DOI 10.1109/WI.2006.171
   Rose S., 2010, TEXT MINING APPL THE, V1, P10, DOI DOI 10.1002/9780470689646.CH1
   Shengdong Li, 2010, Proceedings of the 2nd International Conference on Software Engineering and Data Mining (SEDM 2010), P384
   Wang J, 2017, IEEE T SIGNAL PROCES, V65, P2049, DOI 10.1109/TSP.2016.2639467
   Wang J, 2015, IEEE T SIGNAL PROCES, V63, P5868, DOI 10.1109/TSP.2015.2468676
   Weng J., 2021, Proc. Int. AAAI Conf. Web Soc. Media, V5, P401, DOI [10.1609/icwsm.v5i1.14102, DOI 10.1609/ICWSM.V5I1.14102]
   Xiang-Ying Dai, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P3341, DOI 10.1109/ICMLC.2010.5580677
   Yang Y., 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953
   Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083
   Zheng W, 2008, AS INF RETR S
   Zi-Yan J, 2004, J COMP RES DEV, V7
NR 25
TC 15
Z9 15
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4339
EP 4353
DI 10.1007/s11042-017-5513-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500017
DA 2024-07-18
ER

PT J
AU Wu, XY
   Yang, JQ
   Wang, SH
AF Wu, Xueyan
   Yang, Jiquan
   Wang, Shuihua
TI Tea category identification based on optimal wavelet entropy and
   weighted k-Nearest Neighbors algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimal wavelet entropy; Weighted k-Nearest Neighbors; Tea category
   identification; Pattern recognition
ID SUPPORT VECTOR MACHINE; PROTEIN SUBCELLULAR-LOCALIZATION; PATHOLOGICAL
   BRAIN DETECTION; CLASSIFICATION; PREDICTION; DIAGNOSIS; DIRECTION;
   ELECTRON; SHANNON; IMAGES
AB Tea category classification is of vital importance to industrial applications. We developed a tea-category identification system based on machine learning and computer vision with the aim of classifying different tea types automatically and accurately. 75 photos of three categories of tea were obtained with 3-CCD digital camera, they are green, black, and oolong. After preprocessing, we obtained 7 coefficient subbands using 2-level wavelet transform, and extracted the entropies from the coefficient subbands as the features. Finally, a weighted k-Nearest Neighbors algorithm was trained for the classification. The experiment results over 5 x 5-fold cross validation showed that the proposed approach achieved sensitivities of 95.2 %, 90.4 %, and 98.4 %, for green, oolong, and black tea, respectively. We obtained an overall accuracy of 94.7 %. The average time to identify a new image was merely 0.0491 s. Our method is accurate and efficient in identifying tea categories.
C1 [Wu, Xueyan; Yang, Jiquan] Jiangsu Key Lab 3D Printing Equipment & Mfg, Nanjing 210042, Jiangsu, Peoples R China.
   [Wu, Xueyan; Yang, Jiquan] Hunan Policy Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Wang, Shuihua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Wang, Shuihua] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Jiangsu, Peoples R China.
C3 Nanjing Normal University; Nanjing University
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Jiangsu, Peoples R China.
EM 412341827@qq.com; jiquany@126.com; wangshuihua@njnu.edu.cn
RI Wang, shuihua/G-7326-2016
OI Wang, shuihua/0000-0003-4713-2791
FU NSFC [61602250]; Natural Science Foundation of Jiangsu Province
   [BK20150983]; Open Project Program of the State Key Lab of CADAMP;CG,
   Zhejiang University [A1616]; Open Research Fund of Hunan Provincial Key
   Laboratory of Network Investigational Technology [2016WLZC013]; Open
   Fund of Fujian Provincial Key Laboratory of Data Intensive Computing
   [BD201607]
FX This paper was supported by NSFC (61602250), Natural Science Foundation
   of Jiangsu Province (BK20150983), Open Project Program of the State Key
   Lab of CAD&CG, Zhejiang University (A1616), Open Research Fund of Hunan
   Provincial Key Laboratory of Network Investigational Technology
   (2016WLZC013), Open Fund of Fujian Provincial Key Laboratory of Data
   Intensive Computing (BD201607).
CR Adewole AC, 2016, APPL SOFT COMPUT, V46, P296, DOI 10.1016/j.asoc.2016.05.013
   Aguiar V, 2015, PHYSICA A, V423, P72, DOI 10.1016/j.physa.2014.12.031
   Alshatwi AA, 2016, CHEM-BIOL INTERACT, V247, P1, DOI 10.1016/j.cbi.2016.01.012
   [Anonymous], ENTROPY
   Boros K, 2016, PHARMACOGN MAG, V12, P75, DOI 10.4103/0973-1296.176061
   Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9
   Chen QS, 2015, TRENDS FOOD SCI TECH, V43, P63, DOI 10.1016/j.tifs.2015.01.009
   Chen QS, 2013, J PHARMACEUT BIOMED, V84, P77, DOI 10.1016/j.jpba.2013.05.046
   Dai YW, 2015, CHEMOMETR INTELL LAB, V144, P63, DOI 10.1016/j.chemolab.2015.03.010
   Gao YL, 2010, NEUROCOMPUTING, V73, P3079, DOI 10.1016/j.neucom.2010.06.024
   Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057
   Diniz PHGD, 2015, J FOOD COMPOS ANAL, V39, P103, DOI 10.1016/j.jfca.2014.11.012
   Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721
   Korkmaz SA, 2016, SPECTROCHIM ACTA A, V160, P39, DOI 10.1016/j.saa.2016.02.004
   Kumar A, 2015, J MED IMAG HEALTH IN, V5, P138, DOI 10.1166/jmihi.2015.1369
   Lee MJ, 2016, GEOINFORMATICA, V20, P471, DOI 10.1007/s10707-016-0245-2
   Ma L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149591
   Mangalova E, 2016, INT J FORECASTING, V32, P1067, DOI 10.1016/j.ijforecast.2015.11.007
   Milani RF, 2016, LWT-FOOD SCI TECHNOL, V68, P491, DOI 10.1016/j.lwt.2015.12.041
   Plawiak P, 2014, SENSOR ACTUAT B-CHEM, V192, P117, DOI 10.1016/j.snb.2013.10.065
   Plimley B, 2016, NUCL INSTRUM METH A, V827, P18, DOI 10.1016/j.nima.2016.04.092
   Schumann A, 2015, IEEE ENG MED BIO, P6154, DOI 10.1109/EMBC.2015.7319797
   Shahabi M, 2014, FOOD SCI TECHNOL INT, V20, P465, DOI 10.1177/1082013213492524
   Su MY, 2011, EXPERT SYST APPL, V38, P3492, DOI 10.1016/j.eswa.2010.08.137
   Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023
   Tang Z, 2015, NEUROCOMPUTING, V168, P1011, DOI 10.1016/j.neucom.2015.05.024
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Xiao P, 2015, J FOOD SCI TECH MYS, V52, P6727, DOI 10.1007/s13197-015-1803-6
   Xie JY, 2016, INFORM SCIENCES, V354, P19, DOI 10.1016/j.ins.2016.03.011
   Xu YT, 2016, NEUROCOMPUTING, V205, P430, DOI 10.1016/j.neucom.2016.04.024
   Yaroshenko TY, 2015, COMMUN NONLINEAR SCI, V26, P265, DOI 10.1016/j.cnsns.2015.02.013
   Yu XJ, 2011, KEY ENG MATER, V460-461, P774, DOI 10.4028/www.scientific.net/KEM.460-461.724
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030077
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
   Zhou XX, 2016, LECT NOTES COMPUT SC, V9576, P48, DOI 10.1007/978-3-319-32557-6_5
NR 43
TC 32
Z9 34
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3745
EP 3759
DI 10.1007/s11042-016-3931-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600047
DA 2024-07-18
ER

PT J
AU Bellini, P
   Mesiti, M
   Nesi, P
   Perlasca, P
AF Bellini, Pierfrancesco
   Mesiti, Marco
   Nesi, Paolo
   Perlasca, Paolo
TI Protection and composition of crossmedia content in collaborative
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital resource composition; Digital Licenses; MPEG-21; AXMEDIS
ID LOGIC
AB A large range of new applications are appearing nowadays on the Web in which content and data produced by single users or groups are going to be adapted, composed and aggregated and then redistributed in other forms to other users and/or groups. In this context, the management of intellectual property rights (IPR) of the users collaborating in authoring and composition activities have to be preserved. In this paper we adopt an MPEG-21 representation of digital contents and propose a system that supports the users in their composition that takes into account the permissions of access/composition/modification that each single user or group can exercise on them. In our environment, users can retrieve digital content and data, check the authoring privileges that can be executed on the component resources to generate composite and aggregated contents, and verify the situations in which the composition can hide some privileges that exist in the original contents. When the user holds the privileges for the composition, a license can be automatically generated for the composite content that preserves the rights the user/group holds on the components. This environment supports collaboration among users belonging to different organizations that would like to work together in the realization of non trivial content/data aggregation processes.
C1 [Bellini, Pierfrancesco; Nesi, Paolo] Univ Florence, Dipartimento Ingn Informaz, Via S Marta 3, I-50139 Florence, Italy.
   [Mesiti, Marco; Perlasca, Paolo] Univ Milan, Dipartimento Informat, Via Comelico 39-41, I-20135 Milan, Italy.
C3 University of Florence; University of Milan
RP Mesiti, M (corresponding author), Univ Milan, Dipartimento Informat, Via Comelico 39-41, I-20135 Milan, Italy.
EM pierfrancesco.bellini@unifi.it; mesiti@di.unimi.it; paolo.nesi@unifi.it;
   perlasca@di.unimi.it
RI Bellini, Pierfrancesco/D-5923-2015
OI PERLASCA, PAOLO/0000-0001-6674-2822
CR Abelson H, 2008, ccREL: The Creative Commons Rights Expression Language
   [Anonymous], 2006, MPEG21
   [Anonymous], 2005, MPEG21
   Bellini P, 2007, P INT C DISTR MULT S, P106
   Bellini P, 2015, INT J SOFTWARE ENG K
   Bellini P, 2007, P INT C DISTR MULT S, P112
   Bellini P, 2014, MULTIMED TOOLS APPL, V72, P1611, DOI 10.1007/s11042-013-1468-y
   Bellini P, 2011, INT J SOFTW ENG KNOW, V21, P3, DOI 10.1142/S0218194011005141
   Cabrio Elena, 2014, The Semantic Web: Trends and Challenges. 11th International Conference (ESWC 2014). Proceedings: LNCS 8465, P255, DOI 10.1007/978-3-319-07443-6_18
   Cardellino C., 2014, INT SEM WEB C POST D, P277
   Cuomo A, 2013, J GRID COMPUT, V11, P1, DOI 10.1007/s10723-012-9241-4
   Delgado J., 2003, P C LEG KNOWL INF SY
   Delgado J, 2006, AXMEDIS 2006: SECOND INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P136
   Fung B, 2011, T SERVICES COMPUTING
   Gangadharan G, 2007, P INT WORKSH TECHN E, P73
   Gangadharan GR, 2007, LECT NOTES COMPUT SC, V4749, P257
   Gangadharan GR, 2011, SERV ORIENTED COMPUT, V5, P37, DOI 10.1007/s11761-011-0079-6
   Gangadharan GR, 2008, SEVENTH INTERNATIONAL CONFERENCE ON COMPOSITION-BASED SOFTWARE SYSTEMS, PROCEEDINGS, P194, DOI 10.1109/ICCBSS.2008.29
   García R, 2005, FRONT ARTIF INTEL AP, V134, P137
   Governatori G, 2013, LECT NOTES COMPUT SC, V8218, P151, DOI 10.1007/978-3-642-41335-3_10
   Governatori G, 2009, LOG J IGPL, V17, P227, DOI 10.1093/jigpal/jzp006
   Greengrass J, 2009, IEEE INTERNET COMPUT, V13, P70, DOI 10.1109/MIC.2009.14
   Hong-Linh Truong, 2011, Proceedings of the 2011 IEEE Asia-Pacific Services Computing Conference (APSCC), P174, DOI 10.1109/APSCC.2011.65
   Iannella R, 2001, WORKSH DIG RIGHTS MA
   Iannella R, 2005, ODRL CREATIVE COMMON
   Iannella Renato., 2002, OPEN DIGITAL RIGHTS
   ISO base media file format, 2005, ISOIEC1449612
   Kodama M, 2008, CISIS 2008: THE SECOND INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, PROCEEDINGS, P249, DOI 10.1109/CISIS.2008.70
   Mesiti M, 2013, P INT C DEXA
   MPEG-21, 2004, MPEG21
   Nadah N., 2007, P 11 INT C ART INT L, P65, DOI DOI 10.1145/1276318.1276330
   Nesi P, 2009, AXMEDIS FOR DUMMIES
   Nesi P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1357, DOI 10.1109/ICME.2006.262790
   Pucella R, 2002, P IEEE CSFW, P282, DOI 10.1109/CSFW.2002.1021822
   RealNetworks, 2013, WIND MED DIG RIGHTS
   RealNetworks, 2013, IBM EL MED MAN SYST
   RealNetworks, 2013, HEL FDN GREAT MULT A
   Rotolo A., 2013, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law, P111
   SCORM, 2003, SHAR CONT OBJ REF MO
   Serrao C., 2003, P INT ASS DEV INF SO
   Villata S, 2012, P INT WORKSH CONS LI
   Wu L., 2011, Performance and Dependability in Service Computing: Concepts, Techniques and Research Directions
   Yang JC, 2017, FUTURE GENER COMP SY, V70, P94, DOI 10.1016/j.future.2016.06.015
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
NR 44
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2083
EP 2114
DI 10.1007/s11042-017-4382-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400028
DA 2024-07-18
ER

PT J
AU Yang, X
   He, L
   Qu, D
   Zhang, WQ
AF Yang, Xu -Kui
   He, Liang
   Qu, Dan
   Zhang, Wei-Qiang
TI Semi-supervised minimum redundancy maximum relevance feature selection
   for audio classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio classification; Semi-supervised feature selection; Minimal
   redundancy; Maximal relevance; Locality preserving; Constraint
   information; Bhattacharyya distance
ID CONSTRAINT; MAX
AB It is still a changing problem of choosing the most relevant ones from multiple features for their specific machine learning tasks. However, feature selection provides an effective solution to it, which aims to choose the most relevant and least redundant features for data analysis. In this paper, we present a feature selection algorithm termed as semi-supervised minimum redundancy maximum relevance. The relevance is measured by a semi-supervised filter score named constraint compensated Laplacian score, which takes advantage of the local geometrical structures of unlabeled data and constraint information from labeled data. The redundancy is measured by a semi-supervised Gaussian mixture model-based Bhattacharyya distance. The optimal feature subset is selected by maximizing feature relevance and minimizing feature redundancy simultaneously. We apply our algorithm in audio classification task and compare it with other known feature selection methods. Experimental results further prove that our algorithm can lead to promising improvements.
C1 [Yang, Xu -Kui; Qu, Dan] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [He, Liang; Zhang, Wei-Qiang] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
C3 PLA Information Engineering University; Tsinghua University
RP Yang, X (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM gzyangxk@gmail.com; qudanqudan@sina.com
RI Zhang, Wei-Qiang/A-7088-2008
FU National Natural Science Foundation of China [61673395, 61403415,
   61302107, 61403224]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61673395, No. 61403415, No. 61302107, and No.
   61403224).
CR [Anonymous], 2014, INTRO AUDIO ANAL
   Bartsch MA, 2005, IEEE T MULTIMEDIA, V7, P96, DOI 10.1109/TMM.2004.840597
   Benabdeslem K, 2014, IEEE T KNOWL DATA EN, V26, P1131, DOI 10.1109/TKDE.2013.86
   Bhalerao A, 2003, P BMVC
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Chao YH, 2005, INT CONF ACOUST SPEE, P649
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Chung F. R. K., 1997, Spectral graph theory
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Geiger J., 2013, 2013 IEEE WORKSHOP A, P1, DOI [DOI 10.1109/WASPAA.2013.6701857, 10.1109/WASPAA.2013.6701857]
   Giannakopoulos T, 2008, P ICASSP
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   He X. F., 2005, P NIPS, P1
   Janett WW, 2009, P ROUGH SETS KNOWL T
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Liu H., 2012, Spectral feature selection for data mining
   Misra H, 2004, P ICASSP
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Ramalingam Thiruvengatanadhan, 2014, Journal of Computer Science, V10, P34, DOI 10.3844/jcssp.2014.34.44
   Reyes-Aldasoro CC, 2006, PATTERN RECOGN, V39, P812, DOI 10.1016/j.patcog.2005.12.003
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Ross BC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087357
   Scheirer E, 1997, P ICASSP
   Song L, 2012, J MACH LEARN RES, V13, P1393
   Suzuki T, 2009, P IEEE INT S INF THE
   Wang R. P, 2011, THESIS
   Xu Z., 2009, P 21 INT JOINT C ART
   Yang XK, 2016, EURASIP J AUDIO SPEE, P1, DOI 10.1186/s13636-016-0086-9
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   Zhang DQ, 2008, PATTERN RECOGN, V41, P1440, DOI 10.1016/j.patcog.2007.10.009
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
   Zhao Z, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P641
   Zubair S, 2013, DIGIT SIGNAL PROCESS, V23, P960, DOI 10.1016/j.dsp.2013.01.004
NR 39
TC 13
Z9 14
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 713
EP 739
DI 10.1007/s11042-016-4287-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400030
DA 2024-07-18
ER

PT J
AU Yazici, A
   Koyuncu, M
   Yilmaz, T
   Sattari, S
   Sert, M
   Gulen, E
AF Yazici, Adnan
   Koyuncu, Murat
   Yilmaz, Turgay
   Sattari, Saeid
   Sert, Mustafa
   Gulen, Elvan
TI An intelligent multimedia information system for multimodal content
   extraction and querying
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia applications; Prototype multimedia system; Multimedia
   platform; Video data; Semantic content extraction; Multimedia databases;
   Multimedia data fusion; Multimedia querying; Multimedia information
   retrieval
ID IMAGE RETRIEVAL; SEARCH; CLASSIFICATION; FRAMEWORK; FUSION; TEXT
AB This paper introduces an intelligent multimedia information system, which exploits machine learning and database technologies. The system extracts semantic contents of videos automatically by using the visual, auditory and textual modalities, then, stores the extracted contents in an appropriate format to retrieve them efficiently in subsequent requests for information. The semantic contents are extracted from these three modalities of data separately. Afterwards, the outputs from these modalities are fused to increase the accuracy of the object extraction process. The semantic contents that are extracted using the information fusion are stored in an intelligent and fuzzy object-oriented database system. In order to answer user queries efficiently, a multidimensional indexing mechanism that combines the extracted high-level semantic information with the low-level video features is developed. The proposed multimedia information system is implemented as a prototype and its performance is evaluated using news video datasets for answering content and concept-based queries considering all these modalities and their fused data. The performance results show that the developed multimedia information system is robust and scalable for large scale multimedia applications.
C1 [Yazici, Adnan; Sattari, Saeid] Middle East Tech Univ, Comp Engn, Ankara, Turkey.
   [Koyuncu, Murat] Atilim Univ, Informat Syst Engn, Ankara, Turkey.
   [Yilmaz, Turgay] Havelsan Inc, Command Control & Combat Syst, Ankara, Turkey.
   [Sert, Mustafa] Baskent Univ, Comp Engn, Ankara, Turkey.
   [Gulen, Elvan] Microsoft Corp, CE Management, Redmond, WA 98052 USA.
C3 Middle East Technical University; Atilim University; Havelsan AS;
   Baskent University; Microsoft
RP Koyuncu, M (corresponding author), Atilim Univ, Informat Syst Engn, Ankara, Turkey.
EM mkoyuncu@atilim.edu.tr
RI Koyuncu, Murat/ABI-5498-2020; Koyuncu, Murat/C-9407-2017; Sattari,
   Saeid/AAV-4801-2021; SERT, Mustafa/AAB-8673-2019; Sert,
   Mustafa/D-3080-2015
OI Koyuncu, Murat/0000-0003-1958-5945; Koyuncu, Murat/0000-0003-1958-5945;
   Sattari, Saeid/0000-0002-6367-3224; SERT, Mustafa/0000-0002-7056-4245;
   Sert, Mustafa/0000-0002-7056-4245; YAZICI, Adnan/0000-0001-9404-9494
FU TUBITAK [MFAG-114R082]
FX This work is supported by the research grants from TUBITAK with the
   grant numbers "MFAG-114R082". We thank to all of previous researchers of
   Multimedia DB Lab. at METU and Ahmet Cosar, who have contributed to this
   research.
CR Agün RS, 2004, MULTIMED TOOLS APPL, V24, P29, DOI 10.1023/B:MTAP.0000033982.50288.14
   [Anonymous], 2003, CSDTR0302 U LOND
   [Anonymous], P ACM ICMR
   [Anonymous], COMPUTER INFORM SCI
   [Anonymous], 108 M PLANCK I
   [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], ADV INTELLIGENT SYST
   Bastan M, 2010, IEEE MULTIMEDIA, V17, P62, DOI 10.1109/MMUL.2010.5692184
   Benavent X, 2013, IEEE T MULTIMEDIA, V15, P2009, DOI 10.1109/TMM.2013.2267726
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Bertini M., 2005, 13th Annual ACM International Conference on Multimedia, P395, DOI 10.1145/1101149.1101235
   Bu SH, 2014, IEEE MULTIMEDIA, V21, P38, DOI 10.1109/MMUL.2014.52
   Calistru C, 2006, LECT NOTES COMPUT SC, V4071, P401
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   Gonçalves B, 2007, I C DATA ENGIN WORKS, P95, DOI 10.1109/ICDEW.2007.4400978
   Gulen E, 2012, INT J MULTIMED DATA, V3, P52, DOI 10.4018/jmdem.2012100103
   Hacid MS, 2000, IEEE T KNOWL DATA EN, V12, P729, DOI 10.1109/69.877505
   Hjelsvold R, 2012, P 20 INT C VER LARG, P686
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jiang Y. -G., 2011, P 1 ACM INT C MULT R, P29
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Kücük D, 2012, EXPERT SYST APPL, V39, P2733, DOI 10.1016/j.eswa.2011.08.131
   Küçük D, 2009, INT J UNCERTAIN FUZZ, V17, P135, DOI 10.1142/S0218488509006066
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li Hongzhi., 2013, Proceedings of the 21st ACM international conference on Multimedia, P357, DOI DOI 10.1145/2502081.2508118
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu ZB, 2016, IEEE T NEUR NET LEAR, V27, P1150, DOI 10.1109/TNNLS.2015.2495148
   Ma ZM, 2010, J INF SCI ENG, V26, P427
   Marques O, 2002, MULTIMED TOOLS APPL, V17, P21, DOI 10.1023/A:1014679605305
   Meng T, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P144, DOI 10.1109/IRI.2012.6303003
   Montagnuolo M, 2009, MULTIMED TOOLS APPL, V41, P125, DOI 10.1007/s11042-008-0222-3
   Okuyucu Ç, 2013, IEEE INT SYM MULTIM, P125, DOI 10.1109/ISM.2013.29
   OVER P, 2007, TRECVID 2007
   Ozgur NB, 2009, FUZZY SET SYST, V160, P2253, DOI 10.1016/j.fss.2009.02.017
   Petkovic M, 2000, INT C ADV INFR E BUS
   Rho S, 2004, LECT NOTES COMPUT SC, V3046, P859
   Safadi Bahjat, 2014, ICMR 2014 P ACM INT, P265
   Saggion H, 2004, DATA KNOWL ENG, V48, P247, DOI 10.1016/S0169-023X(03)00108-3
   Shao J, 2008, PROC VLDB ENDOW, V1, P1598, DOI 10.14778/1454159.1454232
   Smith J., 2013, Revitalising Grasslands to Sustain our Communities: Proceedings, 22nd International Grassland Congress, 15-19 September, 2013, Sydney, Australia, P1
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Tao Meng, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P860, DOI 10.1109/ICME.2012.134
   Tusch R., 2000, Proceedings ACM Multimedia 2000, P448, DOI 10.1145/354384.376360
   Wang G., 2006, CVPR, P1597
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Yazici A, 2008, IEEE T FUZZY SYST, V16, P942, DOI 10.1109/TFUZZ.2008.917304
   Yazici Y, 2016, LNCS, V9516, P354
   Yilmaz T, 2014, MULTIMEDIA SYST, V20, P389, DOI 10.1007/s00530-014-0360-6
   Yilmaz T, 2011, LECT NOTES ARTIF INT, V7022, P149, DOI 10.1007/978-3-642-24764-4_14
   2006, DTO CHALL WORKSH LAR
NR 57
TC 11
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2225
EP 2260
DI 10.1007/s11042-017-4378-6
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400033
DA 2024-07-18
ER

PT J
AU Liu, ZK
   Wang, ZL
AF Liu, Zhikang
   Wang, Zilei
TI Action recognition with low observational latency via part movement
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Observational latency; Feature extraction; Action
   representation
ID LOCALIZATION
AB In this paper, we address the issue of recognizing human actions with low observational latency, which is vital for many applications such as virtual reality and interactive entertainment. Then our purpose is to achieve competitive action recognition performance from very short video clips. Such a task essentially is challenging because only very limited information is provided. To this end, we first develop a feature extraction method to exploit both motion (local flow) and appearance (local shape) features such that the information insufficiency can be effectively mitigated. Then we propose an action representation method named Part Movement Model (PMM), which explicitly captures the spatial-temporal structure of human actions and divides the actions into discriminative part movements. Consequently, the actions can be better represented and the competitive performance can be achieved although only short clips are used. Finally, we experimentally verify the effectiveness of the proposed method on three benchmark datasets. The results show that short clips of 6-7 frames (0.2-0.3 second video) are enough to achieve the recognition performance comparable to the baselines with high latency.
C1 [Liu, Zhikang; Wang, Zilei] Univ Sci & Technol China, Dept Automat, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Wang, ZL (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Anhui, Peoples R China.
EM zlwang@ustc.edu.cn
FU National Natural Science Foundation of China [61673362, 61233003];
   Fundamental Research Funds for the Central Universities
FX This work is supported partially by the National Natural Science
   Foundation of China under Grant 61673362 and 61233003, and the
   Fundamental Research Funds for the Central Universities.
CR [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2007, PROC IEEE C COMPUT V
   [Anonymous], 2007, IEEE INT C COMP VIS
   [Anonymous], P ECCV
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Casile A, 2005, J VISION, V5, P348, DOI 10.1167/5.4.6
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gong J, 2011, ADV ENG INFORM, V25, P771, DOI 10.1016/j.aei.2011.06.002
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hongjuan Wang, 2015, 2015 International Symposium on VLSI Technology, Systems and Applications (VLSI-TSA), P1, DOI 10.1109/VLSI-TSA.2015.7117563
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Li GD, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379797
   Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Tu H, 2014, SCI WORLD J
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang HW, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING MANAGEMENT, P124
   Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Weilong Yang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P482, DOI 10.1109/ICCVW.2009.5457663
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang JG, 2010, COMPUT VIS IMAGE UND, V114, P857, DOI 10.1016/j.cviu.2010.04.006
   Zhang Z, 2015, PATTERN ANAL APPL, V18, P157, DOI 10.1007/s10044-013-0349-3
NR 43
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26675
EP 26693
DI 10.1007/s11042-016-4193-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500051
DA 2024-07-18
ER

PT J
AU Rui, T
   Zou, JH
   Zhou, Y
   Fang, HS
   Gao, QY
AF Rui, Ting
   Zou, Junhua
   Zhou, You
   Fang, Husheng
   Gao, Qiyu
TI Pedestrian detection based on multi-convolutional features by feature
   maps pruning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Convolutional neural network; Feature maps
   pruning; Histogram of oriented gradient
AB Convolutional neural network (CNN) has developed such a large network size in last few years, so reducing the storage requirement without hurting its accuracy becomes necessary. In this paper, in order to reduce the number of high dimensional feature maps in shallow layers, we propose a feature map selection method, which cuts the feature map number by correlation coefficient between kernels and finishes detection by HOG+SVM method. Firstly, we extract feature maps of shallow layers from trained CNN. Then, we merge strongly relevant feature maps and choose all maps among weakly relevant feature maps by analyzing correlation coefficient of kernels. Finally, we extract HOG features of the chosen feature maps and use SVM to complete the training and classification. The experimental results show that the proposed method can effectively prune high dimensional feature maps and stabilize or even advance the performance in pedestrian detection.
C1 [Rui, Ting; Zou, Junhua; Fang, Husheng; Gao, Qiyu] PLA Univ Sci & Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Rui, Ting] Nanjing Univ, State Key Lab Novel Software Technol, 22 Hankou Rd, Nanjing, Jiangsu, Peoples R China.
   [Zhou, You] Jiangsu Inst Commerce, Coll Mach Engn, Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
   [Rui, Ting] PLA Univ Sci & Technol, Informat Technol Dept, Nanjing, Jiangsu, Peoples R China.
C3 Army Engineering University of PLA; Nanjing University; Army Engineering
   University of PLA
RP Zou, JH (corresponding author), PLA Univ Sci & Technol, 1 Haifu Lane,Guanghua Rd, Nanjing, Jiangsu, Peoples R China.
EM rtinguu@sohu.com; 278287847@qq.com; 354442511@qq.com; zoujhzz@gmail.com;
   540473772@qq.com
OI Zou, Junhua/0000-0003-4655-7173
FU National Natural Science Foundation of China [61472444, 61472392]
FX This work was supported in part by National Natural Science Foundation
   of China: 61472444, 61472392.
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   [Anonymous], 2016, IEEE TPAMI
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Bertozzi M., 2007, 2007 IEEE Intelligent Transportation Systems Conference, P143, DOI 10.1109/ITSC.2007.4357692
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gong Y., 2014, INT C LEARN REPR ICL
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia HX, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P683, DOI 10.1109/ICIG.2007.53
   John V, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P246, DOI 10.1109/MVA.2015.7153177
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Ouyang, 2014, ARXIV14093505, DOI [10.1016/j.patcog.2018.02.004, DOI 10.1016/J.PATCOG.2018.02.004]
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang T, 2012, INT C PATT RECOG, P3304
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 22
TC 6
Z9 7
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25079
EP 25089
DI 10.1007/s11042-017-4837-0
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300028
DA 2024-07-18
ER

PT J
AU Wang, CP
   Wang, XY
   Chen, XJ
   Zhang, C
AF Wang, Chun-peng
   Wang, Xing-yuan
   Chen, Xing-jun
   Zhang, Chuan
TI Robust zero-watermarking algorithm based on polar complex exponential
   transform and logistic mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accurate coefficient selection; Geometric attack; Logistic mapping;
   Polar complex exponential transform; Zero-watermarking
ID COLOR IMAGE WATERMARKING; ORTHOGONAL MOMENTS; FOURIER-TRANSFORM; RING
   PARTITION; SCHEME; PROTECTION; ATTACKS; DOMAIN
AB This paper introduces a new zero-watermarking algorithm based on polar complex exponential transform (PCET) and logistic mapping. This algorithm takes advantage of the geometric invariance of PCET to improve the robustness of the algorithm against geometric attacks, and the logistic mapping's sensitivity to initial values to improve the security of the algorithm. First, the algorithm computes the PCET of the original grayscale image. Then it randomly selects PCET coefficients based on logistic mapping, and computes their magnitudes to obtain a binary feature image. Finally, it performs an exclusive-or operation between the binary feature image and the scrambled logo image to obtain the zero-watermark image. At the stage of copyright verification, the image copyright can be determined by performing the exclusive-or operation between the feature image and the verification image and comparing the resulting image to the original logo image. Experimental results show that this algorithm has excellent robustness against geometric attacks and common image processing attacks and better performance compared to other zero-watermarking algorithms.
C1 [Wang, Chun-peng; Wang, Xing-yuan; Zhang, Chuan] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116023, Peoples R China.
   [Chen, Xing-jun] Dalian Navy Acad, Operat Software & Simulat Inst, Dalian 116018, Peoples R China.
C3 Dalian University of Technology; Dalian Naval Academy
RP Wang, XY (corresponding author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116023, Peoples R China.
EM mpeng1122@163.com; wangxy@dlut.edu.cn
RI Wang, Xing-yuan/I-6353-2015; Zhang, Chuan/A-6503-2018
FU National Natural Science Foundation of China [61672124, 61370145,
   61173183]; Program for Liaoning Excellent Talents in University
   [LR2012003]
FX This work was supported by the National Natural Science Foundation of
   China (Nos: 61672124, 61370145 and 61173183), Program for Liaoning
   Excellent Talents in University (No: LR2012003).
CR [Anonymous], 1992, RFC1321
   Boyer JP, 2007, IEEE T INF FOREN SEC, V2, P283, DOI 10.1109/TIFS.2007.897279
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Hu HT, 2014, PATTERN RECOGN, V47, P2596, DOI 10.1016/j.patcog.2014.02.014
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Qi M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013004
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Sang J, 2006, OPT ENG, V45, DOI 10.1117/1.2354076
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Sun L., 2015, MathSJ, V9, P2023, DOI DOI 10.12785/AMIS/090442
   Suryanto Y, 2016, J INFORM HIDING MULT, V7, P697
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2013, J SYST SOFTWARE, V86, P335, DOI 10.1016/j.jss.2012.08.040
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang XY, 2016, AEU-INT J ELECTRON C, V70, P416, DOI 10.1016/j.aeue.2016.01.002
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wang XY, 2014, MULTIMED TOOLS APPL, V72, P1933, DOI 10.1007/s11042-013-1483-z
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wo Y, 2013, INT C WAVEL ANAL PAT, P158, DOI 10.1109/ICWAPR.2013.6599309
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Zhang Qiu- Yu, 2016, J INF HIDING MULTIME, V7, P1126
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 40
TC 59
Z9 61
U1 2
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26355
EP 26376
DI 10.1007/s11042-016-4130-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500038
DA 2024-07-18
ER

PT J
AU Ellahyani, A
   El Ansari, M
AF Ellahyani, Ayoub
   El Ansari, Mohamed
TI Mean shift and log-polar transform for road sign detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road sign detection; Mean shift clustering; Log-polar transform; Random
   forests
ID RECOGNITION; FEATURES
AB Road sign detection is an important function for driver assistance systems. Although it has been studied for many years, it still has some performance limitations. This paper proposes a new method for road sign detection by employing both color and shape cues. The proposed method consists of three steps. First, the initial image is pre-processed using mean shift clustering algorithm. The clustering is carried out based on color information. Second, a random forest classifier is used to segment the clustered image. In the final step, a shape based classification is performed using a log-polar transform and cross correlation technique. The proposed detection method has been tested on both the German traffic sign detection benchmark (GTSDB) and the Swedish traffic signs (STS) datasets, and yields to 93.50 % and 94.22 % on the GTSDB dataset in terms of F-measure and area under curve(AUC), respectively. These results are satisfactory when compared to recent state-of-the-art methods.
C1 [Ellahyani, Ayoub; El Ansari, Mohamed] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Ellahyani, A (corresponding author), Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
EM ayoub.ellahyani@gmail.com; m.elansari@uiz.ac.ma
RI Ellahyani, Ayoub/ABA-8951-2021; El Ansari, Mohamed/L-9738-2016
OI Ellahyani, Ayoub/0000-0001-5881-3328; El Ansari,
   Mohamed/0000-0001-5394-9066
CR [Anonymous], 2016, MULTIMED TOOLS APPL
   [Anonymous], 2016, NEUROCOMPUTING
   Becker LP, 2014, US Patent, Patent No. [8,643,721, 8]
   Chang KC, 2015, IEEE ICCE, P43, DOI 10.1109/ICCE-TW.2015.7216981
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Fan YJ, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P1335, DOI 10.1109/FSKD.2015.7382137
   Gómez-Moreno H, 2010, IEEE T INTELL TRANSP, V11, P917, DOI 10.1109/TITS.2010.2054084
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   Gudigar A, 2016, MULTIMED TOOLS APPL, V75, P333, DOI 10.1007/s11042-014-2293-7
   Houben S, 2013, GERMAN TRAFFIC SIGN
   Houben S, 2011, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2011.5940429
   Jaafari I E, 2016, SIGNAL IMAGE VIDEO P, V11, P1
   Kuo WJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1427
   Larsson F, 2011, SWEDISH TRAFFIC SIGN
   Larsson F, 2011, LECT NOTES COMPUT SC, V6688, P238, DOI 10.1007/978-3-642-21227-7_23
   Lee J, 2013, IEEE INT C INTELL TR, P1131, DOI 10.1109/ITSC.2013.6728384
   Lillo-Castellano JM, 2015, NEUROCOMPUTING, V153, P286, DOI 10.1016/j.neucom.2014.11.026
   Lopez LD, 2007, LECT NOTES COMPUT SC, V4633, P1138
   Bascón SM, 2010, COMPUT VIS IMAGE UND, V114, P373, DOI 10.1016/j.cviu.2009.12.002
   Mercedes-Benz, 2014, TRAFF SIGN ASS
   Opel-International, 2014, OP INN YOUR SAF
   Overett G, 2009, IEEE INT VEH SYM, P584, DOI 10.1109/IVS.2009.5164343
   Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018
   Stein GP, 2011, US Patent, Patent No. [8,064,643, 8]
   Takarli F, 2016, SIGNAL IMAGE VIDEO P, V10, P93, DOI 10.1007/s11760-014-0706-8
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Traver VJ, 2010, ROBOT AUTON SYST, V58, P378, DOI 10.1016/j.robot.2009.10.002
   Wang GY, 2014, VISUAL COMPUT, V30, P539, DOI 10.1007/s00371-013-0879-0
   Xia YJ, 2015, NEUROCOMPUTING, V151, P700, DOI 10.1016/j.neucom.2014.05.091
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yuan X, 2015, IEEE T SYST MAN CY-S, V45, P1509, DOI 10.1109/TSMC.2015.2427771
   Zaklouta F, 2011, IEEE INT VEH SYM, P1019, DOI 10.1109/IVS.2011.5940454
   Zang D, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P201, DOI 10.1109/SNPD.2016.7515901
   Zhang Kui, 2015, Journal of Shanghai Jiaotong University (Science), V20, P61, DOI 10.1007/s12204-015-1589-8
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 36
TC 23
Z9 24
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24495
EP 24513
DI 10.1007/s11042-016-4207-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700061
DA 2024-07-18
ER

PT J
AU Feng, YC
   Shen, XJ
   Chen, HP
   Zhang, XL
AF Feng, Yuncong
   Shen, Xuanjing
   Chen, Haipeng
   Zhang, Xiaoli
TI Segmentation fusion based on neighboring information for MR brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Fusion; Multilevel thresholding; Discrete curve
   evolution; Local Laplacian filtering
ID PSO ALGORITHM; ENTROPY
AB In this paper, we study on how to boost image segmentation algorithms. First of all, a novel fusion scheme is proposed to combine different segmentations with mutual information to reduce misclassified pixels and obtain an accurate segmentation. As the class label of each pixel depends on the pixel's gray level and neighbors' labels, the fusion scheme takes both spatial and intensity information of pixels into account. Then, a detail thresholding segmentation case is designed using the proposed fusion scheme. In the case, the local Laplacian filter is used to get the smoothed version of original image. To accelerate segmentation, a discrete curve evolution based Otsu method is employed to segment the original image and its smoothed version to get two different segmentation maps. The fusion scheme is used to fuse the two maps to get the final segmentation result. Experiments on medical MR-T2 brain images are conducted to demonstrate the effectiveness of the proposed segmentation fusion method. The experimental results indicate that the proposed algorithm can improve segmentation accuracy and it is superior to other multilevel thresholding methods.
C1 [Feng, Yuncong; Shen, Xuanjing; Chen, Haipeng; Zhang, Xiaoli] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Feng, Yuncong; Shen, Xuanjing; Chen, Haipeng; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Chen, HP (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.; Chen, HP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM chenhp@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
FU National Natural Science Foundation of China for Youths [61305046];
   Jilin Province Science Foundation for Youths [20130522117JH]; Natural
   Science Foundation of Jilin Province [20140101193JC]
FX This research is supported by the National Natural Science Foundation of
   China for Youths (No. 61305046), Jilin Province Science Foundation for
   Youths (No. 20130522117JH), and the Natural Science Foundation of Jilin
   Province (No. 20140101193JC).
CR Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Ayech MW, 2016, NEUROCOMPUTING, V175, P243, DOI 10.1016/j.neucom.2015.10.056
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Bai XF, 2014, NEUROCOMPUTING, V136, P243, DOI 10.1016/j.neucom.2014.01.008
   Banerjee S, 2016, INFORM SCIENCES, V330, P88, DOI 10.1016/j.ins.2015.10.018
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Chae S.-H., 2014, MULTIMED TOOLS APPL, P1
   Chander A, 2011, EXPERT SYST APPL, V38, P4998, DOI 10.1016/j.eswa.2010.09.151
   Chang HL, 2015, NEUROCOMPUTING, V151, P632, DOI 10.1016/j.neucom.2014.05.092
   Delon J, 2007, IEEE T IMAGE PROCESS, V16, P253, DOI 10.1109/TIP.2006.884951
   Dirami A, 2013, SIGNAL PROCESS, V93, P139, DOI 10.1016/j.sigpro.2012.07.010
   Durand F., 2014, ACM T GRAPHIC, V33, P1935
   Gloger O, 2015, IEEE T BIO-MED ENG, V62, P2338, DOI 10.1109/TBME.2015.2425935
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Kang Y, 2011, IEEE T INTELL TRANSP, V12, P1423, DOI 10.1109/TITS.2011.2160539
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khan S, 2010, IEEE T BIO-MED ENG, V57, P2587, DOI 10.1109/TBME.2010.2060196
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Ledig C, 2014, PROC CVPR IEEE, P3065, DOI 10.1109/CVPR.2014.392
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li YF, 2016, PATTERN RECOGN, V52, P332, DOI 10.1016/j.patcog.2015.10.004
   Ma J, 2013, COMPUT VIS IMAGE UND, V117, P1072, DOI 10.1016/j.cviu.2012.11.016
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Sathya PD, 2011, MEASUREMENT, V44, P1828, DOI 10.1016/j.measurement.2011.09.005
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sathya PD, 2011, NEUROCOMPUTING, V74, P2299, DOI 10.1016/j.neucom.2011.03.010
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012
   Wang XY, 2016, NEURAL NETWORKS, V74, P1, DOI 10.1016/j.neunet.2015.10.012
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang HG, 2014, PATTERN RECOGN, V47, P2266, DOI 10.1016/j.patcog.2013.11.004
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2582, DOI 10.1109/TIP.2011.2121080
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
NR 39
TC 13
Z9 13
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23139
EP 23161
DI 10.1007/s11042-016-4098-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700001
DA 2024-07-18
ER

PT J
AU Jian, CX
   Gao, J
   Ao, YH
AF Jian, Chuanxia
   Gao, Jian
   Ao, Yinhui
TI Imbalanced defect classification for mobile phone screen glass using
   multifractal features and a new sampling method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile phone screen glass; Defect classification; Imbalanced datasets;
   Multifractal features; Sampling
ID FEATURE-EXTRACTION; FRACTAL DIMENSION; INSPECTION; IMAGE; SMOTE
AB Defect classification has drawn significant attention in the mobile phone screen glass (MPSG) manufacturing field because it helps to determine problems in the manufacturing process. Two problems exist in MPSG defect classification: (1) the high dimensionality of the defect feature; (2) imbalanced defect example classification. The first problem tends to yield low accuracy for classifying overall defect examples, and the second problem has a low accuracy for minority ones. To address these two problems, an imbalanced MPSG defect classification scheme is presented. First, based on the multifractal spectrum, defect features are extracted to reduce the feature dimensionality. Defect features are distinguishably characterized by two multifractal metrics to promote the performance of classifying defects. Second, considering example contributions to determine the classification boundary, a new sampling method is proposed to address the imbalanced defect example classification. This method improves the classification accuracy of the minority class through implementation of different sampling strategies to SVs (support vectors) and NSVs (non support vectors) in the majority and minority classes. Experiments are conducted on real MPSG defect examples, and the experimental results show that the imbalanced MPSG defect classification scheme achieves a 96.61% overall accuracy and a 93.27% geometric mean of the classification accuracies of four-type defects; these results are superior to the results achieved by other methods used in the experiment.
C1 [Jian, Chuanxia; Gao, Jian] Guangdong Univ Technol, Key Lab Mech Equipment Mfg & Control Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Ao, Yinhui] Guangdong Univ Technol, Guangdong Prov Key Lab Comp Integrated Mfg, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Technology; Guangdong University of Technology
RP Jian, CX (corresponding author), Guangdong Univ Technol, Key Lab Mech Equipment Mfg & Control Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
EM jianchxia@gdut.edu.cn; gaojian@gdut.edu.cn; aoyinhui@gdut.edu.cn
FU National Natural Science Foundation of China [51675106, 51275093];
   Guangdong Provincial Natural Science Foundation [2015A030312008];
   Guangdong Provincial RD Key Projects [2015B010104008, 2016A030308016]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant no. 51675106, no. 51275093), Guangdong
   Provincial Natural Science Foundation (Grant no. 2015A030312008), and in
   part by the Guangdong Provincial R&D Key Projects (Grant no.
   2015B010104008, no. 2016A030308016).
CR Alaie HF, 2016, SPEECH COMMUN, V77, P28, DOI 10.1016/j.specom.2015.12.001
   Alibeigi M, 2012, DATA KNOWL ENG, V81-82, P67, DOI 10.1016/j.datak.2012.08.001
   [Anonymous], ADDRESSING CURSE IMB
   [Anonymous], 2006, COMPUT SCI ENG
   [Anonymous], 1983, FRACTAL GEOMETRY NAT
   Barua S, 2014, IEEE T KNOWL DATA EN, V26, P405, DOI 10.1109/TKDE.2012.232
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen ZY, 2015, OPT EXPRESS, V23, P23634, DOI 10.1364/OE.23.023634
   Cheng X, 2004, T ASAE, V47, P1313, DOI 10.13031/2013.16565
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Du JX, 2013, NEUROCOMPUTING, V116, P150, DOI 10.1016/j.neucom.2012.03.028
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gokmen G, 2014, J VIBROENG, V16, P1434
   HALSEY TC, 1986, PHYS REV A, V33, P1141, DOI 10.1103/PhysRevA.33.1141
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Hu HJ, 2016, NEUROCOMPUTING, V181, P86, DOI 10.1016/j.neucom.2015.05.134
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Jian CX, 2017, APPL SOFT COMPUT, V52, P348, DOI 10.1016/j.asoc.2016.10.030
   Jian CX, 2016, NEUROCOMPUTING, V193, P115, DOI 10.1016/j.neucom.2016.02.006
   Li D, 2014, INT J ADV MANUF TECH, V73, P1605, DOI 10.1007/s00170-014-5871-y
   Li WC, 2012, PATTERN RECOGN, V45, P742, DOI 10.1016/j.patcog.2011.07.025
   Li XC, 2008, ENG APPL ARTIF INTEL, V21, P785, DOI 10.1016/j.engappai.2007.07.001
   Liang LQ, 2016, MULTIMED TOOLS APPL, V75, P2655, DOI 10.1007/s11042-015-2559-8
   Lin ZY, 2009, LECT NOTES COMPUT SC, V5678, P536
   Liu HG, 2011, INT J ADV MANUF TECH, V56, P1079, DOI 10.1007/s00170-011-3248-z
   Liu MF, 2016, J VIS COMMUN IMAGE R, V37, P70, DOI 10.1016/j.jvcir.2015.04.005
   Liu YH, 2008, MEAS SCI TECHNOL, V19, DOI 10.1088/0957-0233/19/9/095501
   Lopes R, 2009, MED IMAGE ANAL, V13, P634, DOI 10.1016/j.media.2009.05.003
   Nasira G, 2013, INT J COMPUT INT INF, V3, P61
   Peng XQ, 2008, INT J ADV MANUF TECH, V39, P1180, DOI 10.1007/s00170-007-1302-7
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Serdaroglu A, 2006, S MACH PERC, V16, P61
   Sophian A, 2003, NDT&E INT, V36, P37, DOI 10.1016/S0963-8695(02)00069-5
   Tian GY, 2005, IEE P-SCI MEAS TECH, V152, P141, DOI 10.1049/ip-smt:20045011
   Tsai DM, 2009, MACH VISION APPL, V20, P423, DOI 10.1007/s00138-008-0136-0
   Valavanis I, 2010, EXPERT SYST APPL, V37, P7606, DOI 10.1016/j.eswa.2010.04.082
   Veropoulos K., 1999, P INT JOINT C ART IN, P55
   Xu K, 2013, INT J MIN MET MATER, V20, P37, DOI 10.1007/s12613-013-0690-y
   Yi-Hung Liu, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1863, DOI 10.1109/IJCNN.2009.5179024
   [No title captured]
NR 41
TC 14
Z9 15
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24413
EP 24434
DI 10.1007/s11042-016-4199-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700057
DA 2024-07-18
ER

PT J
AU Kim, BG
   Hong, GS
   Psannis, KE
AF Kim, Byung-Gyu
   Hong, Gwang-Soo
   Psannis, Kostas E.
TI Design of efficient shape feature for object-based watermarking
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape descriptor; Image retrieval; Keypoint matching; Feature
   extraction; Object detection
ID IMAGE
AB The accelerated development of IT technologies on the Internet for fast provision of commercial multimedia services has stimulated an urgent demand for reliable and secure copyright protection for digital multimedia. Also, information retrieval is required to search valuable information from wide range of image data for various applications such as biometrics, crime prevention, health informatics, and image search. We proposes the shape representation method using angles, orientations, and locations which is called as Oriented Angular Keypoints (OAK) to make help for shape-based watermarking scheme. First, the contour is extracted from input image and is divided into contour blocks. Then, angles and directions from the divided contour blocks are computed to make unique feature. To evaluate the proposed image retrieval algorithm, commonly employed datasets of Gorelick and MPEG-7 are also used in this paper. The performance of the similarity measure that proposed image retrieval algorithm achieves improvement of about 10 % compared with Shape Context in terms of Bull's eye score.
C1 [Kim, Byung-Gyu; Hong, Gwang-Soo] Sookmyung Womens Univ, Dept IT Engn, Seoul, South Korea.
   [Psannis, Kostas E.] Univ Macedonia, Dept Appl Informat, Thessaloniki, Greece.
C3 Sookmyung Women's University; University of Macedonia
RP Kim, BG (corresponding author), Sookmyung Womens Univ, Dept IT Engn, Seoul, South Korea.
EM bg.kim@sookmyung.ac.kr; gs.hong@vicl.sookmyuing.ac.kr;
   kpsannis@uom.edu.gr
RI Psannis, Kostas/AHA-8462-2022; Psannis, Konstantinos/C-8760-2017
OI Psannis, Kostas/0000-0003-0020-6394; Psannis,
   Konstantinos/0000-0003-0020-6394; Kim, Byung-Gyu/0000-0001-6555-3464
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2016R1D1A1B04934750]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (NRF-2016R1D1A1B04934750).
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Barghout L, 2013, J VIS, P709
   Batenburg KJ, 2009, PATTERN RECOGN, V42, P2297, DOI 10.1016/j.patcog.2008.11.027
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2014, COMP VIS PATT REC WO, P178
   Forouzanfar M, 2010, ENG APPL ARTIF INTEL, V23, P160, DOI 10.1016/j.engappai.2009.10.002
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Ho YK, 2004, PATTERN RECOGN LETT, V25, P1673, DOI 10.1016/j.patrec.2004.06.011
   Jeon Y, 2014, I SYMP CONSUM ELECTR, P99
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kato T, 1992, P SPIE
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Kosch H., 2004, DISTRIBUTED MULTIMED
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Ling HB, 2005, IEEE I CONF COMP VIS, P1466
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rui Y., 1998, STORAGE RETRIEVAL IM, P25
   Rusinol M., 2010, P 8 IAPR INT WORKSHO, P215
   Sebastian TB, 2002, LECT NOTES COMPUT SC, V2352, P731
   Shelke NA, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1068, DOI 10.1109/WiSPNET.2016.7566301
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Zhan TS, 2014, INTERNATIONAL CONFERENCE ON COMPUTATIONAL AND INFORMATION SCIENCES (ICCIS 2014), P1
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
NR 36
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22741
EP 22759
DI 10.1007/s11042-017-4344-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200043
DA 2024-07-18
ER

PT J
AU Mokni, R
   Drira, H
   Kherallah, M
AF Mokni, Raouia
   Drira, Hassen
   Kherallah, Monji
TI Combining shape analysis and texture pattern for palmprint
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint identification; Riemannian geometry; Shape analysis;
   Intra-Modal features; Texture pattern; Random forest
ID 3D FACE RECOGNITION; DESIGN
AB We propose an efficient method for principal line extraction from the palmprint and geometric framework for analyzing their shapes. This representation, along with the elastic Riemannian metric, seems natural for measuring principal line deformations and is robust to challenges such as orientation variation and re-parameterization due to pose variation and missing part, respectively. The palmprint texture is investigated using the fractal analysis; thus the resulting features are fused with the principal line features. This framework is shown to be promising from both - empirical and theoretical - perspectives. In terms of empirical evaluation, our results match or improve the state-of-the-art methods on three prominent palmprint datasets: PolyU, CASIA, and IIT-Delhi, each posing a different type of challenge. From a theoretical perspective, this framework allows fusing texture analysis and shape analysis.
C1 [Mokni, Raouia] Univ Sfax, Fac Econ & Management Sfax FSEGS, Sfax, Tunisia.
   [Drira, Hassen] Inst Mines Telecom Telecom Lille, CRIStAL, CNRS, UMR 9189, Villeneuve Dascq, France.
   [Kherallah, Monji] Univ Sfax, Fac Sci Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Universite de Lille; Centrale Lille; Centre National
   de la Recherche Scientifique (CNRS); Universite de Sfax; Faculty of
   Sciences Sfax
RP Mokni, R (corresponding author), Univ Sfax, Fac Econ & Management Sfax FSEGS, Sfax, Tunisia.
EM raouia.mokni@gmail.com; hassen.drira@telecom-lille.fr;
   Monji.kheralllah@enis.rnu.tn
RI Drira, Hassen/AAG-9736-2020; Mokni, Raouia/S-6378-2016
OI Drira, Hassen/0000-0003-1052-4353; KHERALLAH, Monji/0000-0002-4549-1005;
   Mokni, Raouia/0000-0002-6652-5251
CR [Anonymous], INT J IMAGE GRAPHICS
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Ben Amor B, 2009, ANN TELECOMMUN, V64, P369, DOI 10.1007/s12243-008-0077-7
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bruno A, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P50, DOI 10.1109/BIOMS.2014.6951535
   Burlacu C, 2005, ISSCS 2005: International Symposium on Signals, Circuits and Systems, Vols 1 and 2, Proceedings, P347
   Chaabouni Aymen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3793, DOI 10.1109/ICPR.2010.924
   Chaabouni A, 2014, INT ARAB J INF TECHN, V11, P416
   Charfi N, 2014, IEEE SYS MAN CYBERN, P4141, DOI 10.1109/SMC.2014.6974586
   Chen J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P234, DOI 10.1109/ICIP.2001.958094
   Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Drira H, 2009, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2009.5459451
   Drira Hassen., 2010, BMVC, P1
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Fractals MBLO, 1975, FORM HAS DIM
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gonzalez Serrano G., 2011, ROTATIONAL FEATURES
   Guesmi H, 2015, MULTIMED TOOLS APPL, V74, P3253, DOI 10.1007/s11042-013-1785-1
   Hammami M, 2014, MULTIMED TOOLS APPL, V68, P1023, DOI 10.1007/s11042-012-1109-x
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   IIT Delhi I. I. o. T. D, 2014, IIT DELH TOUCHL PALM
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Jaswal G, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P344, DOI 10.1109/ISPCC.2015.7375053
   Jose A, 2013, IEEE IMAGE PROC, P3059, DOI 10.1109/ICIP.2013.6738630
   Junlin Hu, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1449, DOI 10.1109/ICOSP.2008.4697405
   Khan ZN, 2016, ARXIV160201927
   Krishneswari K., 2012, ICTACT J IMAGE VIDEO, V2, P435
   Kumar A, 2005, PATTERN RECOGN, V38, P1695, DOI 10.1016/j.patcog.2005.03.012
   Kumar A, 2010, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2010.5653214
   Leqing Zhu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P15, DOI 10.1109/FSKD.2009.43
   Liu YN, 2015, J BIONIC ENG, V12, P504, DOI 10.1016/S1672-6529(14)60141-4
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Mokni R, 2015, PREPROCESSING EXTRAC
   Mokni R, 2016, LECT NOTES COMPUT SC, V9887, P259, DOI 10.1007/978-3-319-44781-0_31
   Mokni R, 2016, J INF ASSUR SECUR, V11, P77
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Rashid RA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P898, DOI 10.1109/ICCCE.2008.4580735
   Shanmugavadivu P, 2012, PROCEDIA ENGINEER, V38, P2981, DOI 10.1016/j.proeng.2012.06.348
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tunkpien P., 2010, P 2 INT C KNOWL SMAR
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Wang X, 2012, KNOWL-BASED SYST, V27, P451, DOI 10.1016/j.knosys.2011.10.008
   Wu Xiang-Qian, 2004, Journal of Software, V15, P869
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Zouari R., 2014, INT IM PROC APPL SYS, P1, DOI 10.1109/IPAS.2014.7043305
NR 50
TC 15
Z9 15
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23981
EP 24008
DI 10.1007/s11042-016-4088-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700039
DA 2024-07-18
ER

PT J
AU Venkitasubramanian, AN
   Tuytelaars, T
   Moens, MF
AF Venkitasubramanian, Aparna Nurani
   Tuytelaars, Tinne
   Moens, Marie-Francine
TI Entity linking across vision and language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entity linking; Animal labeling; Multimedia indexing; Language-vision
   alignment
ID RECOGNITION; MODELS
AB We propose a novel weakly supervised framework that jointly tackles entity analysis tasks in vision and language. Given a video with subtitles, we jointly address the questions: a) What do the textual entity mentions refer to? and b) What/ who are in the video key frames? We use a Markov Random Field (MRF) to encode the dependencies within and across the two modalities. This MRF model incorporates beliefs using independent methods for the textual and visual entities. These beliefs are propagated across the modalities to jointly derive the entity labels. We apply the framework to a challenging dataset of wildlife documentaries with subtitles and show that this integrated modeling yields significantly better performance over text-based and vision-based approaches. We show that textual mentions that cannot be resolved using text-only methods are resolved correctly using our method. The approaches described here bring us closer to automated multimedia indexing.
C1 [Venkitasubramanian, Aparna Nurani; Moens, Marie-Francine] Katholieke Univ Leuven, Comp Sci Dept, Celestijnenlaan 200A, B-3001 Leuven, Belgium.
   [Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT PSI, Kasteelpk Arenberg 10, B-3001 Leuven, Belgium.
C3 KU Leuven; KU Leuven
RP Venkitasubramanian, AN (corresponding author), Katholieke Univ Leuven, Comp Sci Dept, Celestijnenlaan 200A, B-3001 Leuven, Belgium.
EM aparna.venkit@gmail.com; tinne.tuytelaars@kuleuven.be;
   sien.moens@kuleuven.be
RI Tuytelaars, Tinne/B-4319-2015
OI Tuytelaars, Tinne/0000-0003-3307-9723
CR Afkham HM, 2008, INT C PATT RECOG, P2019
   Alfonseca E., 2002, Proceedings of the 1st international conference on general WordNet, P34
   [Anonymous], P 10 ED LANG RES EV
   [Anonymous], 2011, PROC CVPR WORKSHOP F
   [Anonymous], 2002, P 19 INT C COMPUTATI
   [Anonymous], 2014, EMNLP
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], ARXIV14114952
   [Anonymous], 2014, ARXIV14122306
   [Anonymous], 2016, CORR
   [Anonymous], 2012, UGM MATLAB CODE UNDI
   Bagga A., 1998, PROC 1 LANGUAGE RESO, P563
   Berg TamaraL., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.57
   COATESSTEPHENS S, 1992, COMPUT HUMANITIES, V26, P441, DOI 10.1007/BF00136985
   Coughlan JM, 2002, LECT NOTES COMPUT SC, V2352, P453
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Durrett Greg., 2014, Trans- actions of the Association for Computational Linguistics (TACL)
   Durrett Greg, 2013, P C EMP METH NAT LAN
   Dusart T, 2013, P 2 ACM INT WORKSH M, P9
   GOMEZ A, 2016, ARXIV160306169
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Guillaumin M., 2008, Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, P1
   Hellier P, 2012, IEEE IMAGE PROC, P3085, DOI 10.1109/ICIP.2012.6467552
   Joly A, 2015, LECT NOTES COMPUT SC, V9283, P462, DOI 10.1007/978-3-319-24027-5_46
   Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455
   Lee H, 2013, COMPUT LINGUIST, V39, P885, DOI 10.1162/COLI_a_00152
   Leser U, 2005, BRIEF BIOINFORM, V6, P357, DOI 10.1093/bib/6.4.357
   Liu X., 2013, Long Papers, V1, P1304
   Luo X, 2005, P HUM LANG TECHN C C, P25
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Pearl J., 2014, PROBABILISTIC REASON
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Pham PT, 2011, IEEE MULTIMEDIA, V18, P44, DOI 10.1109/MMUL.2011.22
   Pradhan Sameer., 2011, Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, P1
   Pradhan Sameer, 2014, SCORING COREFERENCE
   Ramanan D, 2006, IEEE T PATTERN ANAL, V28, P1319, DOI 10.1109/TPAMI.2006.155
   Ramanathan V, 2014, LECT NOTES COMPUT SC, V8689, P95, DOI 10.1007/978-3-319-10590-1_7
   Schmid C, 2001, PROC CVPR IEEE, P39
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Venkitasubramanian AN, 2016, PATTERN RECOGN LETT
   Vilain M, 1995, P 6 C MESS UND ASS C, P45, DOI DOI 10.3115/1072399.1072405
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Williams C.K.I., PASCAL VISUAL OBJECT
NR 44
TC 7
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22599
EP 22622
DI 10.1007/s11042-017-4732-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200036
DA 2024-07-18
ER

PT J
AU Zhuang, Y
   Jiang, N
   Hu, H
   Chiu, DKW
   Li, Q
AF Zhuang, Yi
   Jiang, Nan
   Hu, Hua
   Chiu, Dickson K. W.
   Li, Qing
TI Interactive transmission processing for large images in a
   resource-constraint mobile wireless network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive transmission; Multi-resolution; Mobile network; User anxiety
   degree
AB In the state-of-the-art methods for (large) image transmission, no user interaction behaviors (e. g., user tapping) can be actively involved to affect the transmission performance (e. g., higher image transmission efficiency with relatively poor image quality). So, to effectively and efficiently reduce the large image transmission costs in resource-constraint mobile wireless networks (MWN), we design a content-based and bandwidth-aware Interactive large Image Transmission method inMWN, called the IIT. To the best of our knowledge, this is the first study on the interactive image transmission. The whole transmission processing of the IIT works as follows: before transmission, a preprocessing step computes the optimal and initial image block (IB) replicas based on the image content and the current network bandwidth at the sender node. During transmission, in case of unsatisfied transmission efficiency, the user's anxiety to preview the image can be implicitly indicated by the frequency of tapping the screen. In response, the transmission resolutions of the candidate IB replicas can be dynamically adjusted based on the user anxiety degree (UAD). Finally, the candidate IB replicas are transmitted with different priorities to the receiver for reconstruction and display. The experimental results show that the performance of our approach is both efficient and effective, minimizing the response time by decreasing the network transmission cost while improving user experiences.
C1 [Zhuang, Yi] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
   [Jiang, Nan] Hangzhou First Peoples Hosp, Hangzhou, Zhejiang, Peoples R China.
   [Hu, Hua] Hangzhou Dianzi Univ, Sch Comp, Hangzhou, Zhejiang, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, Hong Kong, Hong Kong, Peoples R China.
   [Li, Qing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Zhejiang Gongshang University; Hangzhou Dianzi University; University of
   Hong Kong; City University of Hong Kong
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
EM zhuang@mail.zjgsu.edu.cn
RI Li, Qing/JMH-1365-2023; Chiu, Dickson K. W./B-9630-2017; JIANG,
   NAN/AHB-1945-2022
OI Li, Qing/0000-0003-3370-471X; Chiu, Dickson K. W./0000-0002-7926-9568; 
FU Program of National Natural Science Foundation of China [61272188,
   61379075, 61540064, 71571162]; National Science & Technology Pillar
   Program of the Ministry of Science and Technology [2014BAK14B01];
   Program of Natural Science Foundation of Zhejiang Province
   [LY13F020008]; Ministry of Education of Humanities and Social Sciences
   Project [14YJCZH235]; "Qianjiang Talent" Project of Zhejiang Province
   [QJD1402017]
FX The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by the Program
   of National Natural Science Foundation of China under grant No.
   61272188, 61379075, 61540064, 71571162; the project in National Science
   & Technology Pillar Program of the Ministry of Science and Technology
   under grant No. 2014BAK14B01; the Program of Natural Science Foundation
   of Zhejiang Province under grant No. LY13F020008; the Ministry of
   Education of Humanities and Social Sciences Project under grant No.
   14YJCZH235; the "Qianjiang Talent" Project of Zhejiang Province under
   grant No. QJD1402017.
CR Allcock B, 2002, PARALLEL COMPUT, V28, P749, DOI 10.1016/S0167-8191(02)00094-7
   Arslan SS, 2012, IEEE T IMAGE PROCESS, V21, P3586, DOI 10.1109/TIP.2012.2195668
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Boluk PS, 2011, MOBILE NETW APPL, V16, P149, DOI 10.1007/s11036-010-0282-2
   Chang C.C., 2002, VISUAL COMPUT, P341
   Chang CC, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1774
   Chang RC, 2008, J INF SCI ENG, V24, P691
   Chin-Chen Chang, 1999, Fifth Asia-Pacific Conference on Communications and Fourth Optoelectronics and Communications Conference. APCC/OECC'99. Proceedings. Conference - Vitality to the New Century (IEEE Cat. No.99EX379), P892, DOI 10.1109/APCC.1999.820406
   Gao DH, 2010, LECT NOTES ARTIF INT, V6216, P334
   Gelogo Y. E., 2013, INT J COMPUT GRAPH, V5, P1
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Hu YS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1079
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang Dingde., 2016, Multi-media Tools and Applications, P1
   John M. D., 1995, ACM INT C MULT
   Kim JH, 1996, IEE VISION IMAGE SIG, P132
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Maani R, 2012, J DIGIT IMAGING, V25, P101, DOI 10.1007/s10278-011-9387-9
   Raman S, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P209, DOI 10.1109/ICNP.2000.896305
   Ruiz V., 2001, P 19 IASTED INT C AP, P519
   Sun Y, 2006, IEEE T MOBILE COMPUT, V5, P1016, DOI 10.1109/TMC.2006.120
   Turner C. J., 1992, Computer Communication Review, V22, P258, DOI 10.1145/144191.144296
   TZOU KH, 1987, OPT ENG, V26, P581, DOI 10.1117/12.7974121
   Victor S, 2010, IEEE T MED IMAGING, V10, P1808
   Wu HM, 2004, IEEE SYMP COMP COMMU, P202
   Xu HS, 2015, DIGIT COMMUN NETW, V1, P213, DOI 10.1016/j.dcan.2015.05.002
   Zhuang Y, 2014, INFORM SCI
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23539
EP 23565
DI 10.1007/s11042-016-3965-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700019
DA 2024-07-18
ER

PT J
AU Katarya, R
   Verma, OP
AF Katarya, Rahul
   Verma, Om Prakash
TI An effective web page recommender system with fuzzy c-mean clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web recommender system; Clustering; Fuzzy c-mean; Accuracy
ID SOCIAL MEDIA; MODEL; USAGE; IMPLEMENTATION; RECOGNITION
AB With the exponential development of the number of users browsing the internet, an important factor that now the developer community is focussing on is the user experience. Recommender systems are the platforms that make personalized recommendations for a particular user by predicting the ratings for various items. Recommender systems majorly ignore the sequential information and rather focus on content information, but sequential information also provides much information about the behavior of the user. In this research work, we have presented a novel web-based recommender system which is based on sequential information of user's navigation on web pages. We received top-N clusters when Fuzzy C-mean (FCM) clustering is employed. We determined the similar users for the target user and also evaluated the weight for each web page. We have tried to solve that problem of recommender systems as we offered a system to forecast a user's next Web page visit. In our work, we proposed a system which generates recommendations to the users, by considering the sequential information that exists in their usage patterns of Web pages. We employed fuzzy clustering to give recommender system a sequential approach. We calculated weights for each page category considered in our system and predict top page recommendation for the target user. The real-world dataset of MNSBC is used in the experiments. The dataset consists of 5000 user entries with 6, entries per user. When we performed a comparison between the existing model with our proposed model, then it clearly showed that the accuracy of the proposed model is almost three times better than some existing systems. The accuracy of our proposed model is nearly 33 %.
C1 [Katarya, Rahul; Verma, Om Prakash] Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University
RP Katarya, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, Delhi 110042, India.
EM rahulkatarya@dtu.ac.in
RI Katarya, Dr. Rahul/AAH-9233-2020
OI Katarya, Dr. Rahul/0000-0001-7763-291X
CR Ahila SS, 2016, WIRELESS PERS COMMUN, V87, P499, DOI 10.1007/s11277-015-3082-y
   [Anonymous], 2014, ELECT J DIFFERENTIAL, DOI DOI 10.18280/EESRJ.010104
   [Anonymous], 2014, P INT C MULT RETR
   Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032
   Barragáns-Martínez B, 2015, EXPERT SYST APPL, V42, P4216, DOI 10.1016/j.eswa.2015.01.052
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bilge A, 2014, EXPERT SYST APPL, V41, P3671, DOI 10.1016/j.eswa.2013.11.039
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Boratto L, 2015, J INTELL INF SYST, V45, P221, DOI 10.1007/s10844-014-0346-z
   Bouadjenek MR, 2016, INFORM SCIENCES, V369, P614, DOI 10.1016/j.ins.2016.07.046
   Bouras C, 2017, INT J MACH LEARN CYB, V8, P223, DOI 10.1007/s13042-014-0316-3
   Calzarossa MC, 2014, I C COMP SYST APPLIC, P699, DOI 10.1109/AICCSA.2014.7073268
   CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778
   Cao J, 2016, INT J PARALLEL PROG, V44, P163, DOI 10.1007/s10766-014-0330-9
   Cobo M., 2015, KNOWLEDGE BASED SYST
   Conforti R, 2015, DECIS SUPPORT SYST, V69, P1, DOI 10.1016/j.dss.2014.10.006
   Dixit VS, 2015, INT J SYST ASSUR ENG, V6, P373, DOI 10.1007/s13198-014-0266-x
   Dooms S, 2014, J INTELL INF SYST, V42, P645, DOI 10.1007/s10844-013-0276-1
   Forsati R, 2015, INFORM RETRIEVAL J, V18, P167, DOI 10.1007/s10791-015-9252-4
   Guo ZC, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1305, DOI 10.1145/2567948.2579705
   Hasija H, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P175, DOI 10.1109/ICACCI.2014.6968499
   Hoic-Bozic N, 2015, IEEE T ED IN PRESS, P39
   Hu X, 2016, EUR PHYS J B, V89, DOI 10.1140/epjb/e2016-60509-9
   Jalali M, 2010, EXPERT SYST APPL, V37, P6201, DOI 10.1016/j.eswa.2010.02.105
   Javari A, 2015, KNOWL INF SYST, V44, P609, DOI 10.1007/s10115-014-0779-2
   Ji K, 2015, KNOWL-BASED SYST, V88, P134, DOI 10.1016/j.knosys.2015.07.039
   Jiménez P, 2016, INFORM SYST, V62, P74, DOI 10.1016/j.is.2016.05.003
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Katarya R, 2016, PHYSICA A, V461, P182, DOI 10.1016/j.physa.2016.05.046
   Katarya R, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P907, DOI 10.1109/ICGCIoT.2015.7380592
   Katarya R, 2013, 2013 4TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT), P222, DOI 10.1109/ICCCT.2013.6749631
   Koohi H, 2016, MEASUREMENT, V91, P134, DOI 10.1016/j.measurement.2016.05.058
   Krishnaraju V, 2016, INFORM SYST FRONT, V18, P579, DOI 10.1007/s10796-015-9550-9
   Laclau C, 2016, NEUROCOMPUTING, V193, P133, DOI 10.1016/j.neucom.2016.02.003
   Liu DW, 2017, NEURAL COMPUT APPL, V28, pS641, DOI 10.1007/s00521-016-2410-9
   Lorentzen DG, 2014, SCIENTOMETRICS, V99, P409, DOI 10.1007/s11192-013-1227-x
   Lotfy HMS, 2016, J ADV RES, V7, P285, DOI 10.1016/j.jare.2015.06.005
   Malarvizhi SP, 2016, CLUSTER COMPUT, V19, P269, DOI 10.1007/s10586-015-0507-z
   Mishra R, 2015, DECIS SUPPORT SYST, V75, P1, DOI 10.1016/j.dss.2015.04.004
   Moreno MN, 2016, NEUROCOMPUTING, V176, P72, DOI 10.1016/j.neucom.2014.10.097
   Pàmies-Estrems D, 2016, EXPERT SYST APPL, V64, P523, DOI 10.1016/j.eswa.2016.08.033
   Poornalatha G, 2011, COMM COM INF SC, V191, P243
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ristoski P, 2016, J WEB SEMANT, V36, P1, DOI 10.1016/j.websem.2016.01.001
   García MDR, 2016, EXPERT SYST APPL, V63, P20, DOI 10.1016/j.eswa.2016.06.034
   Santoro M, 2016, ENVIRON MODELL SOFTW, V84, P18, DOI 10.1016/j.envsoft.2016.06.010
   Schmachtenberg M, 2014, 4TH INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, MINING AND SEMANTICS, DOI 10.1145/2611040.2611080
   Shivaprasad G, 2015, PROCEDIA COMPUT SCI, V54, P327, DOI 10.1016/j.procs.2015.06.038
   Nguyen TTS, 2014, IEEE T KNOWL DATA EN, V26, P2574, DOI 10.1109/TKDE.2013.78
   Thiyagarajan R, 2014, INT J COMPUT APPL, V86, P44
   Treerattanapitak K, 2012, J COMPUT SCI TECH-CH, V27, P567, DOI 10.1007/s11390-012-1244-x
   Verma O. P., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P190, DOI 10.1109/ICECTECH.2011.5941983
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Xie XF, 2018, NEURAL COMPUT APPL, V29, P235, DOI 10.1007/s00521-016-2444-z
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yera R, 2016, APPL SOFT COMPUT, V40, P187, DOI 10.1016/j.asoc.2015.10.060
   Yu CY, 2017, SERV ORIENTED COMPUT, V11, P33, DOI 10.1007/s11761-016-0191-8
   Yu XH, 2012, IEEE T KNOWL DATA EN, V24, P720, DOI 10.1109/TKDE.2010.269
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhang HR, 2016, KNOWL-BASED SYST, V91, P275, DOI 10.1016/j.knosys.2015.06.019
   Zhang ZY, 2016, IEEE ACCESS, V4, P2272, DOI 10.1109/ACCESS.2016.2569074
   Zhao WNX, 2016, IEEE T KNOWL DATA EN, V28, P1147, DOI 10.1109/TKDE.2015.2508816
   Zhu K, 2014, MACH LEARN, V97, P177, DOI 10.1007/s10994-014-5454-z
NR 65
TC 29
Z9 30
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21481
EP 21496
DI 10.1007/s11042-016-4078-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400051
DA 2024-07-18
ER

PT J
AU Kim, YM
   Park, J
   Lim, J
   Yoo, J
AF Kim, Yong-Min
   Park, Junho
   Lim, Jongtae
   Yoo, Jaesoo
TI An energy-efficient compression scheme for wireless multimedia sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Compression; Pre-processing;
   Chinese Remainder Theorem; Energy-efficiency
AB In this paper, we propose an energy-efficient compression scheme for wireless multimedia sensor networks. To do this, we analyze the characteristics of multimedia data under the environment of wireless multimedia sensor networks. First, this paper proposes a multimedia sensor data compression scheme based on the Chinese Remainder Theorem by considering the limited resources and restriction of the sensor networks. The proposed scheme utilizes the Chinese Remainder Theorem that is performed based on the modular operation in a category of basic arithmetic operations for data compression. Moreover, for the maximization of compression efficiency, it uses a pre-processing algorithm that consists of dynamic area extraction and bit-plane deletion before conducting the compression scheme. To show the superiority of our scheme, we compare the existing multimedia data compression scheme with our compression scheme. Our experimental results show that our proposed scheme increases compression ratio while reducing the number of compression operations compared to the existing compression scheme.
C1 [Kim, Yong-Min] Chonnam Natl Univ, Dept Elect Commerce, Yeosu, South Korea.
   [Park, Junho] Agcy Def Dev, Daejeon, South Korea.
   [Lim, Jongtae; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju, South Korea.
   [Yoo, Jaesoo] Chungbuk Natl Univ, Dept Informat & Commun Engn, Cheongju, South Korea.
C3 Chonnam National University; Agency of Defense Development (ADD),
   Republic of Korea; Chungbuk National University; Chungbuk National
   University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Cheongju, South Korea.; Yoo, J (corresponding author), Chungbuk Natl Univ, Dept Informat & Commun Engn, Cheongju, South Korea.
EM ymkim@chonnam.ac.kr; junhopark@add.re.kr; jtlim@chungbuk.ac.kr;
   yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) support program
   [IITP-2015-H8501-15-1013]; ICT R&D program of MSIP/IITP [B0101-15-0266];
   "Human Resources Program in Energy Technology" of the Korea Institute of
   Energy Technology Evaluation and Planning (KETEP) from the Ministry of
   Trade, Industry & Energy, Republic of Korea [20144030200450]
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2015-H8501-15-1013) supervised by the
   IITP(Institute for Information & communication Technology Promotion), by
   the ICT R&D program of MSIP/IITP. [B0101-15-0266, Development of High
   Performance Visual BigData Discovery Platform for Large-Scale Realtime
   Data Analysis], and by "Human Resources Program in Energy Technology" of
   the Korea Institute of Energy Technology Evaluation and Planning
   (KETEP), granted financial resource from the Ministry of Trade, Industry
   & Energy, Republic of Korea. (No. 20144030200450)
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], FIRE OCCURRENCE BUSA
   [Anonymous], P SPIE APPL DIG IM P
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen YS, 2007, IEEE ICC, P3576, DOI 10.1109/ICC.2007.590
   Chew L. W., 2008, PROC INT S INF TECHN, P1
   Ghouti L, 2005, IEEE INT SYMP CIRC S, P2313, DOI 10.1109/ISCAS.2005.1465087
   IKONOMOPOULOS A, 1985, SIGNAL PROCESS, V8, P179, DOI 10.1016/0165-1684(85)90073-8
   Ma T, 2013, IEEE COMMUN SURV TUT, V15, P963, DOI 10.1109/SURV.2012.060912.00149
   MCLEAN GF, 1993, IEEE T SYST MAN CYB, V23, P637, DOI 10.1109/21.256539
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Wang P, 2013, IEEE T MULTIMEDIA, V15, P684, DOI 10.1109/TMM.2012.2236304
NR 15
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19707
EP 19722
DI 10.1007/s11042-016-3440-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500023
DA 2024-07-18
ER

PT J
AU Biswas, A
   Biswas, B
AF Biswas, Anupam
   Biswas, Bhaskar
TI Community-based link prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Link prediction; Community detection; Social network analysis
ID MISSING LINKS; NETWORKS; ORGANIZATION
AB This work proposes a community-based link prediction approach for identifying missing links or the links that are likely to appear in near future. Earlier works on link prediction consider only connectivity pattern or node attributes. We incorporate the notion of community structure in link prediction. An algorithm is designed to account the influence of communities on link prediction. We have considered recently developed edge centrality measures to compute likelihood scores of missing links. The performance of proposed algorithm is analyzed in terms of three metrics and execution time on both real-world networks and synthetic networks, where ground truth communities are already defined. The time complexity of proposed algorithm is also analyzed.
C1 [Biswas, Anupam; Biswas, Bhaskar] Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Biswas, A (corresponding author), Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM abanumail@gmail.com; bhaskar.cse@iitbhu.ac.in
RI Biswas, Anupam/AAU-7440-2020
OI Biswas, Anupam/0000-0003-0756-6026
CR Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   Airoldi E.M., 2006, P INT BIOMETRICS SOC, P1
   Akcora CG, 2013, SOC NETW ANAL MIN, V3, P475, DOI 10.1007/s13278-012-0090-8
   Akcora CG, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P292, DOI 10.1109/IRI.2011.6009562
   Al Hasan M, 2011, SOCIAL NETWORK DATA ANALYTICS, P243
   Alahakoon T., 2011, P 4 WORKSH SOC NETW, P1, DOI [DOI 10.1145/1989656.1989657, 10.1145/1989656.1989657]
   Almansoori W, 2012, NETW MODEL ANAL HLTH, V1, P27, DOI 10.1007/s13721-012-0005-7
   Anderson Ashton., 2012, Proceedings of the 5th ACM Symposium on Web Search and Data Mining WSDM 2012, P703
   [Anonymous], COMMUNITY BASED LINK
   [Anonymous], SCI REPORTS
   [Anonymous], SCI PROGRAMMING
   [Anonymous], 2006, SDM06
   [Anonymous], SCI REPORTS
   [Anonymous], ETUDE COMP DISTRIBUT
   [Anonymous], KNOWL BASED SYST, DOI DOI 10.1016/J.KN0SYS.2016.01.034
   [Anonymous], ARXIV11065053
   [Anonymous], 2016, IJCAI
   [Anonymous], COMMUNITY BASED LINK
   Backstrom L., 2011, P 4 ACM INT C WEB SE, P635, DOI DOI 10.1145/1935826.1935914
   Bhattacharyya P, 2011, SOC NETW ANAL MIN, V1, P143, DOI 10.1007/s13278-010-0006-4
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Bringmann B, 2010, IEEE INTELL SYST, V25, P26, DOI 10.1109/MIS.2010.91
   Chen BL, 2014, APPL INTELL, V41, P694, DOI 10.1007/s10489-014-0558-5
   Chen H.H., 2012, P 27 ANN ACM S APPL, P138
   Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830
   De Meo P, 2012, KNOWL-BASED SYST, V30, P136, DOI 10.1016/j.knosys.2012.01.007
   de Sá HR, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2281, DOI 10.1109/IJCNN.2011.6033513
   Ding JY, 2015, PHYSICA A, V417, P76, DOI 10.1016/j.physa.2014.09.005
   Fazel-Zarandi Maryam., 2011, Proceedings of the Second International Workshop on Information Heterogeneity and Fusion in Recommender Systems, HetRec'11, P41, DOI DOI 10.1145/2039320.2039326
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Friedman N, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1300
   Geisser S., 1993, PREDICTIVE INFERENCE
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Guimerà R, 2009, P NATL ACAD SCI USA, V106, P22073, DOI 10.1073/pnas.0908366106
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Heckerman D., 2004, Proceedings of the ICML-2004 Workshop on Statistical Relational Learning and its Connections to Other Fields, P55
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Huang Z, 2009, INFORMS J COMPUT, V21, P286, DOI 10.1287/ijoc.1080.0292
   Jeh G., 2002, PROC 8 ACM SIGKDD IN, P538
   Jeong H, 2000, NATURE, V407, P651, DOI 10.1038/35036627
   Juszczyszyn K., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P27, DOI 10.1109/PASSAT/SocialCom.2011.15
   Katz L., 1953, Psychometrika, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026]
   Kim Myunghwan, 2011, P 11 SIAM INT C DAT, P47, DOI DOI 10.1137/1.9781611972818.5
   Kiousis S., 2007, J PUBLIC RELAT RES, V19, P147, DOI DOI 10.1080/10627260701290661
   Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lichtenwalter Ryan N, 2010, P 16 ACM SIGKDD INT, P243, DOI [10.1145/1835804.1835837, DOI 10.1145/1835804.1835837]
   Lin D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P296
   Liu R, 2016, LECT NOTES COMPUT SC, V9790, P453, DOI 10.1007/978-3-319-42092-9_35
   Liu WP, 2010, EPL-EUROPHYS LETT, V89, DOI 10.1209/0295-5075/89/58007
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Lü LY, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046122
   Lusseau D, 2003, BEHAV ECOL SOCIOBIOL, V54, P396, DOI 10.1007/s00265-003-0651-y
   Marchette DJ, 2008, COMPUT STAT DATA AN, V52, P1373, DOI 10.1016/j.csda.2007.03.016
   Mavroforakis C, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P732, DOI 10.1145/2736277.2741125
   Maxson C.L., 2003, Factors that influence public opinion of the police
   Michael JH, 1997, FOREST PROD J, V47, P41
   Moore HT, 1921, AM J PSYCHOL, V32, P16, DOI 10.2307/1413472
   Mori J, 2012, EXPERT SYST APPL, V39, P10402, DOI 10.1016/j.eswa.2012.01.202
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Oh HS, 2004, ACAD MANAGE J, V47, P860, DOI 10.5465/20159627
   Oshagan H, 1996, INT J PUBLIC OPIN R, V8, P335
   Qi XQ, 2015, PATTERN RECOGN LETT, V58, P51, DOI 10.1016/j.patrec.2015.02.007
   Raeder T, 2011, SOC NETWORKS, V33, P245, DOI 10.1016/j.socnet.2011.07.002
   Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374
   Raymond R, 2010, LECT NOTES ARTIF INT, V6323, P131, DOI 10.1007/978-3-642-15939-8_9
   Salton G, 1986, Introduction to Modern Information Retrieval
   Schmutte IM, 2015, J LABOR ECON, V33, P1, DOI 10.1086/677389
   Sie RLL, 2012, INT J TECHNOL ENHANC, V4, P121, DOI 10.1504/IJTEL.2012.048314
   Sorensen T.A., 1948, BIOL SKRIFTER, V5, P1
   Sparrowe RT, 2001, ACAD MANAGE J, V44, P316, DOI 10.5465/3069458
   Sun D, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.017101
   Teixeira A.S., 2013, WORKSHOP MINING LEAR, V24, P27
   Wang P, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5237-y
   Watts DJ, 2007, J CONSUM RES, V34, P441, DOI 10.1086/518527
   Wu Sen., 2013, Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,WSDM '13, P43, DOI [10.1145/2433396.2433404, DOI 10.1145/2433396.2433404]
   Yu HY, 2008, SCIENCE, V322, P104, DOI 10.1126/science.1158684
   Yu K., 2006, Advances in Neural Information Processing Systems, P1553, DOI DOI 10.7551/MITPRESS/7503.003.0199
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zhu J., 2002, P 13 ACM C HYP HYP, P169, DOI [DOI 10.1145/513338.513381, 10.1145/513338.513381]
NR 80
TC 29
Z9 34
U1 8
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18619
EP 18639
DI 10.1007/s11042-016-4270-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800023
DA 2024-07-18
ER

PT J
AU Chen, WH
   Paik, I
   Yen, NY
AF Chen, Wuhui
   Paik, Incheon
   Yen, Neil Y.
TI Discovering internal social relationship for influence-aware service
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social link; Global social service network; Recommend-as-you-go; Social
   influence; Service recommendation
ID WEB; NETWORKS
AB Existing approaches, such as semantic content-based or Collaborative Filtering-based recommendations, fail to exploit social aspects of services because services lack social relationships and do not consider social influence. In this paper, we propose a methodology for connecting distributed services in a global social service network (GSSN) to facilitate discovering internal social relationship for social influence-aware service recommendation. First, we propose a novel platform for constructing a GSSN by linking distributed services with social links based on quality of social link. We then propose a flexible model of the effective awareness of social influence, which provides a quantitative measure of the strength of influence between services. Next, a novel social influence-aware service recommendation approach is proposed based on GSSN using internal social relationship among services. The experimental results demonstrated that our new approach can solve the service recommendation problem with a low usage threshold and high accuracy, where the user preferences are exploited by a recommend-as-you-go method.
C1 [Chen, Wuhui; Paik, Incheon; Yen, Neil Y.] Univ Aizu, Sch Comp Sci & Engn, Fukushima, Japan.
C3 University of Aizu
RP Chen, WH (corresponding author), Univ Aizu, Sch Comp Sci & Engn, Fukushima, Japan.
EM chenwuhui21@gmail.com; paikic@u-aizu.ac.jp; neilyyen@u-aizu.ac.jp
FU Grants-in-Aid for Scientific Research [14J07114] Funding Source: KAKEN
CR Albert R, 2000, PHYS REV LETT, V85, P5234, DOI 10.1103/PhysRevLett.85.5234
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Bianconi G, 2001, EUROPHYS LETT, V54, P436, DOI 10.1209/epl/i2001-00260-6
   Bianconi G, 2001, PHYS REV LETT, V86, P5632, DOI 10.1103/PhysRevLett.86.5632
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Chen WH, 2015, IEEE T SERV COMPUT, V8, P284, DOI 10.1109/TSC.2013.20
   Chen XF, 2010, PROCEEDINGS OF 2010 CROSS-STRAIT CONFERENCE ON INFORMATION SCIENCE AND TECHNOLOGY, P9, DOI 10.1145/1952222.1952226
   Christakis NA, 2007, NEW ENGL J MED, V357, P370, DOI 10.1056/NEJMsa066082
   Dong YX, 2012, IEEE DATA MINING, P181, DOI 10.1109/ICDM.2012.140
   Klusch M., 2006, Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems, P915
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Lécué F, 2010, IEEE INT C SEMANT CO, P200, DOI 10.1109/ICSC.2010.37
   Lécué F, 2011, IEEE T KNOWL DATA EN, V23, P942, DOI 10.1109/TKDE.2010.237
   Lee YJ, 2009, P 7 INT C WEB SERV I
   Maamar Z, 2011, 11 ANN INT C NEW TEC, P9
   Maamar Z, 2011, IEEE INTERNET COMPUT, V15, P48, DOI 10.1109/MIC.2011.27
   Maamar Z, 2011, IEEE INTERNET COMPUT, V15, P90, DOI 10.1109/MIC.2011.49
   Paliwal AV, 2012, IEEE T SERV COMPUT, V5, P260, DOI 10.1109/TSC.2011.19
   Paolucci M, 2002, LECT NOTES COMPUT SC, V2342, P333
   Pedrinaci C, 2010, J UNIVERS COMPUT SCI, V16, P1694
   Shao LS, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P439
   Tan Wei, 2011, IEEE INT C SERV COMP
   Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807
   Wang FY, 2007, IEEE INTELL SYST, V22, P79, DOI 10.1109/MIS.2007.41
   Wang G, 2008, P 4 INT C NEXT GEN W
   Wu J, 2013, IEEE T SYST MAN CY-S, V43, P428, DOI 10.1109/TSMCA.2012.2210409
   XIA H., 2007, Proceedings of the Second International Conference on Innovative Computing, P412
   Yechun Jiang, 2011, Proceedings of the 2011 IEEE International Conference on Web Services (ICWS 2011), P211, DOI 10.1109/ICWS.2011.38
   Zhang Jia, 2011, IEEE INT C SERV COMP
   Zheng ZB, 2013, IEEE T SERV COMPUT, V6, P289, DOI 10.1109/TSC.2011.59
   Zheng ZB, 2011, IEEE T SERV COMPUT, V4, P140, DOI 10.1109/TSC.2010.52
NR 31
TC 4
Z9 4
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18193
EP 18220
DI 10.1007/s11042-016-3437-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800002
DA 2024-07-18
ER

PT J
AU Jung, KD
   Moon, SJ
   Lee, JY
AF Jung, Kye-dong
   Moon, Seok-Jae
   Lee, Jong-Yong
TI XMDR-DAI-based USN multimedia MetaData management agent for sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE USN multimedia metadata; XMDR-Dai; SensorML; Data interoperability;
   Ubiquitous; Agent
ID MIDDLEWARE
AB In a ubiquitous sensor network (USN) environment, it is necessary to define and manage a single metadata between the multimedia sensor and multimedia sensor node for interoperability purposes. One method to resolve this issue is the SensorML (Sensor Model Language), which is standard language that can be applied to sensor modeling. SensorML describes the model for data processing between multimedia sensors and provides a framework that can describe the information of each sensor. In this paper, an XMDR-DAI-based USN multimedia metadata is defined to describe the application of sensor devices, sensor nodes and sensor network information. And then an agent technology is used for effective storing and search of XMDR-DAI-based USN multimedia metadata. Sensor multimedia metadata can maintain interoperability in a USN multimedia environment based on SensorML, and the metadata management system can be directly used for metadata management in USN multimedia middleware or applications.
C1 [Jung, Kye-dong; Lee, Jong-Yong] Kwangwoon Univ, Dept Culture, 20 Kwangwoon Ro, Seoul 139701, South Korea.
   [Moon, Seok-Jae] Kwangwoon Univ, Dept Comp Sci, 20 Kwangwoon Ro, Seoul 139701, South Korea.
C3 Kwangwoon University; Kwangwoon University
RP Moon, SJ (corresponding author), Kwangwoon Univ, Dept Comp Sci, 20 Kwangwoon Ro, Seoul 139701, South Korea.
EM gdchung@kw.ac.kr; msj8086@kw.ac.kr; jyonglee@kw.ac.kr
CR [Anonymous], 2010, EXT MET REG CONS
   Botts M., 2004, SENSOR MODEL LANGUAG
   Botts M., 2007, OpenGIS Sensor Model Language (SensorML) Implementation Specification
   Botts M, 2014, OGC R SENSORML MODEL
   Chen H, 2006, 7 INT C IEEE
   Jeong YS, 2010, IEEE INTELL SYST, V25, P48, DOI 10.1109/MIS.2010.52
   Jung E, 2012, 14 INT C
   KECK KD, 2005, XMDR PROPOSED PROTOT
   Kim C-S, 2008, 10 INT C IEEE 3
   Moon SJ, 2010, INT J GRID DISTRIB, V3, P1
   Moon S, 2010, COMM COM INF SC, V74, P72
   OGC Sensor Model Language, 2007, OPENGIS STAND
   Park JH, 2011, ARTIF INTELL REV, V35, P37, DOI 10.1007/s10462-010-9182-x
   Robin A., 2006, CREATION SPECIFIC SE
   Telecommunications Technology Association. TTAS, 2000, KO060025R1 TTAS
   USN Metadata Model, 2009, TTAKKO060168R1 USN M
NR 16
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18067
EP 18081
DI 10.1007/s11042-016-3721-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800027
DA 2024-07-18
ER

PT J
AU Zhu, YH
   Zhang, XJ
   Wen, GQ
   He, W
   Cheng, DB
AF Zhu, Yonghua
   Zhang, Xuejun
   Wen, Guoqiu
   He, Wei
   Cheng, Debo
TI Double sparse-representation feature selection algorithm for
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Joint sparse learning; Self-representation
ID REGRESSION; RELEVANCE
AB since amount of unlabeled and high-dimensional datasets need to be preprocessed, unsupervised learning plays a more and more important role in machine learning field. This paper proposed a novel unsupervised feature selection algorithm that can select informative features from dataset without label, by mixing two sparse representation and self-representation loss function into a unified framework. That is, we use self-representation loss function to represent every feature with remainder features and achieve minimum reconstruction mirror, and then utilize l (2 , 1)-norm regularization term and l (1)-norm regularization term simultaneously to enforce coefficient matrix to be sparse, such that filter redundant and irrelative features in order to conduct feature selection, where l (2 , 1)-norm regularization can enforce group sparsity while l (1)-norm regularization enforce element sparsity. By this way that utilize both of sparse representation terms, we can choose representative features more accurately. At final, we feed reduced data into support vector machine (SVM) to conduct classification accuracy, which is main assessment criteria to validate performance of algorithm. Extensive experiments on synthetic datasets and real-world datasets have exhibited that our proposed method outperform most of common-used methods, such as PCA, LPP and so on.
C1 [Zhu, Yonghua; Zhang, Xuejun] Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Guangxi, Peoples R China.
   [Zhang, Xuejun] Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techn, Nanning 530004, Guangxi, Peoples R China.
   [Wen, Guoqiu; He, Wei; Cheng, Debo] Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Guangxi, Peoples R China.
   [Wen, Guoqiu; He, Wei; Cheng, Debo] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi University; Guangxi University; Guangxi Normal University;
   Guangxi Normal University
RP Zhang, XJ (corresponding author), Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Guangxi, Peoples R China.; Zhang, XJ (corresponding author), Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techn, Nanning 530004, Guangxi, Peoples R China.
EM 1293234987@qq.com; xjzhang@gxu.edu.cn; 2107360652@qq.com;
   risehnhew@163.com; 15676209686@163.com
RI Cheng, Debo/Y-5226-2019
OI Cheng, Debo/0000-0002-0383-1462
FU China "1000-Plan" National Distinguished Professorship; Nation Natural
   Science Foundation of China [61263035, 61573270, 61672177]; China 973
   Program [2013CB329404]; China Key Research Program [2016YFB1000905];
   Guangxi Natural Science Foundation [2015GXNSFCB139011]; Innovation
   Project of Guangxi Graduate Education [YCSZ2016046]; Guangxi High
   Institutions' Program of Introducing 100 High-Level Overseas Talents;
   Guangxi Collaborative Innovation Center of Multi-Source Information
   Integration and Intelligent Processing; Guangxi "Bagui" Teams for
   Innovation and Research
FX This work was supported in part by the China "1000-Plan" National
   Distinguished Professorship; the Nation Natural Science Foundation of
   China (Grants No: 61263035, 61573270 and 61672177), the China 973
   Program (Grant No: 2013CB329404); the China Key Research Program (Grant
   No: 2016YFB1000905); the Guangxi Natural Science Foundation (Grant No:
   2015GXNSFCB139011); the Innovation Project of Guangxi Graduate Education
   under grant YCSZ2016046; the Guangxi High Institutions' Program of
   Introducing 100 High-Level Overseas Talents; and the Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing; and the Guangxi "Bagui" Teams for Innovation
   and Research.
CR [Anonymous], 2007, P AAAI C ART INT
   [Anonymous], COMPUT VIS ECCV
   Cheng B, 2013, NEUROINFORMATICS, V11, P339, DOI 10.1007/s12021-013-9180-7
   Dong Chen, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7412967
   Feng Y., 2012, P 11 ASIAN C COMPUTE, P343
   Hai TN, 2011, GEN DEFINITION L1 NO, V1, P279
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lai HJ, 2013, IEEE T COMPUT, V62, P1221, DOI 10.1109/TC.2012.62
   Laporte L, 2014, IEEE T NEUR NET LEAR, V25, P1118, DOI 10.1109/TNNLS.2013.2286696
   Leordeanu M, 2009, INT J COMPUT VISION, V96, P28
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qian M., 2013, P 23 INT JOINT C ART, P1621
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Ryali S., 2009, NEUROIMAGE, V47, pS57, DOI [10.1016/S1053-8119(09)70217-4, DOI 10.1016/S1053-8119(09)70217-4]
   Shakhnarovich G., 2004, HDB FACE RECOGNITION, P141
   Shang RH, 2016, NEUROCOMPUTING, V171, P1242, DOI 10.1016/j.neucom.2015.07.068
   Stonnington CM, 2010, NEUROIMAGE, V51, P1405, DOI 10.1016/j.neuroimage.2010.03.051
   Tomar D., 2014, Int. J. Bio-Sci. Bio-Technol, V6, P69, DOI 10.14257/ijbsbt.2014.6.2.07
   Wang JJY, 2014, NEURAL NETWORKS, V51, P9, DOI 10.1016/j.neunet.2013.11.009
   Wang S, 2016, PATTERN RECOGN, V57, P179, DOI 10.1016/j.patcog.2016.02.019
   Weston J, 2001, ADV NEUR IN, V13, P668
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Xu YM, 2016, PATTERN RECOGN, V53, P25, DOI 10.1016/j.patcog.2015.12.007
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yuan G.-X., 2011, Proceedings of the Seventeenth ACM SIGKDD International Con- ference on Knowledge Discovery and Data Mining, P33, DOI DOI 10.1145/2020408.2020421
   Zhang C, 2006, CLUSTERING BASED MIS, P1081
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu X, 2015, NEUROIMAGE, V100, P91
   Zhu X., 2016, IEEE T CYBERNETICS, V46, P1
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2013, IEEE T MULTIMEDIA, V15, P633, DOI 10.1109/TMM.2012.2233723
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu Y., 2013, IEEE T PATTERN ANAL, V37, P529
   Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650
   Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200
NR 42
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17525
EP 17539
DI 10.1007/s11042-016-4121-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500036
DA 2024-07-18
ER

PT J
AU Chiu, MC
   Ko, LW
AF Chiu, Ming-Chuan
   Ko, Li-Wei
TI Develop a personalized intelligent music selection system based on heart
   rate variability and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Personalized music system; Machine learning; Heart
   rate variability (HRV); Wearable device
ID EXPRESSION; VOICE
AB Music often plays an important role in people's daily lives. Because it has the power to affect human emotion, music has gained a place in work environments and in sports training as a way to enhance the performance of particular tasks. Studies have shown that office workers perform certain jobs better and joggers run longer distances when listening to music. However, a personalized music system which can automatically recommend songs according to user's physiological response remains absent. Therefore, this study aims to establish an intelligent music selection system for individual users to enhance their learning performance. We first created an emotional music database using data analytics classifications. During testing, innovative wearable sensing devices were used to detect heart rate variability (HRV) in experiments, which subsequently guided music selection. User emotions were then analyzed and appropriate songs were selected by using the proposed application software (App). Machine learning was used to record user preference, ensuring accurate and precise classification. Significant results generated through experimental validation indicate that this system generates high satisfaction levels, does not increase mental workload, and improves users' performance. Under the trend of the Internet of Things (IoT) and the continuing development of wearable devices, the proposed system could stimulate innovative applications for smart factory, home, and health care.
C1 [Chiu, Ming-Chuan; Ko, Li-Wei] Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
C3 National Tsing Hua University
RP Chiu, MC (corresponding author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
EM mcchiu@ie.nthu.edu.tw
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 103 -2221-E-007-051-MY3]; Advanced Manufacturing and Service
   Management Research Center (AMSMRC), National Tsing Hua University
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for partially financially supporting
   this research under contract number MOST 103 -2221-E-007-051-MY3. This
   work was also supported by the Advanced Manufacturing and Service
   Management Research Center (AMSMRC), National Tsing Hua University.
CR [Anonymous], 2012, ACM T INTEL SYST TEC, DOI DOI 10.1145/2168752.2168754
   BAILEY JE, 1983, MANAGE SCI, V29, P530, DOI 10.1287/mnsc.29.5.530
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bassellier G, 2004, MIS QUART, V28, P673
   Biehl J.T., 2006, CHI 06 EXTENDED ABST, P556
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cheng WY, 2014, INT J IND ENG-THEORY, V21, P304
   Dalla Bella S, 2001, COGNITION, V80, pB1, DOI 10.1016/S0010-0277(00)00136-0
   Davitz JR, 1964, COMMUNICATION EMOTIO, DOI [10.1016/B978-1-4832-3041-2.50008-7, DOI 10.1016/B978-1-4832-3041-2.50008-7]
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Eysenck H. J., 1985, PERSONALITY INDIVIDU
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   Fairbanks G, 1941, SPEECH MONOGR, V8, P85, DOI 10.1080/03637754109374888
   Feng Y., 2003, P 26 ANN INT ACM SIG, P375, DOI [DOI 10.1145/860500.860508, 10.1145/860435, DOI 10.1145/860435]
   Fonagy I., 1963, Z F R PHONETIK, V16, P293, DOI DOI 10.1524/STUF.1963.16.14.293
   FORNELL C, 1981, J MARKETING RES, V18, P382, DOI 10.2307/3150980
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gabrielsson A., 2001, Music And Emotion, P223, DOI DOI 10.1525/MP.2004.21.4.561
   Gray E, 2013, PERSPECT PUBLIC HEAL, V133, P14, DOI 10.1177/1757913912468642
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hand DavidJ., 1981, Discrimination and classification
   HART S G, 1988, P139
   Hsu Y-W, 2014, P 21 ISPE INC INT C
   IVES B, 1983, COMMUN ACM, V26, P785, DOI 10.1145/358413.358430
   Jiawei Han., 2001, Data mining: concepts and techniques, P5
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kenny D.T., 2004, Music Forum
   Khalfa S, 2005, NEUROREPORT, V16, P1981, DOI 10.1097/00001756-200512190-00002
   Kim KJ, 2006, INT J IND ENG-THEORY, V13, P177
   Kinoshita Yuichiro, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P94, DOI 10.1109/ISCE.2009.5157047
   Kohavi R., 1998, Machine Learning, V30, P271
   Levenson RW, 2003, ANN NY ACAD SCI, V1000, P348, DOI 10.1196/annals.1280.016
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Malik M, 2008, DYNAMIC ELECTROCARDI, P13, DOI 10.1002/9780470987483.ch2
   Medicore, 2015, SA 3000P CLIN MAN VE
   Michalski R.S., 2013, Machine Learning: An Artificial Intelligence Approach
   Mindlab, 2014, DOES PLAYING WORK IN
   Newman K., 2001, INT J BANK MARK, V19, P126, DOI 10.1108/02652320110388559
   Niitsuma M., 2008, Proceedings of International Society for Music Information Retrieval Conference, P193
   Nirjon Shahriar, 2012, P 10 ACM C EMB NETW, P43, DOI DOI 10.1145/2426656.2426662
   Oliver N, 2006, ISMIR, V2006, P7
   PARASURAMAN A, 1985, J MARKETING, V49, P41, DOI 10.2307/1251430
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell S.J., 2010, Artificial Intelligence a Modern Approach, DOI [10.1016/0925-2312(95)90020-9, DOI 10.1016/0925-2312(95)90020-9]
   Satoh M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095230
   Schellenberg EG, 2000, MUSIC PERCEPT, V18, P155
   Serrà J, 2008, IEEE T AUDIO SPEECH, V16, P1138, DOI 10.1109/TASL.2008.924595
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Tseng Y. E., 2010, THESIS
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P1863, DOI 10.1007/s11042-013-1722-3
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Watson KB, 1942, PSYCHOL MONOGR, V54, P1
   Weiss Sholom M, 1991, COMPUTER SYSTEMS LEA
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yeh CH, 2014, MULTIMED TOOLS APPL, V73, P2103, DOI 10.1007/s11042-013-1687-2
NR 55
TC 31
Z9 32
U1 5
U2 98
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15607
EP 15639
DI 10.1007/s11042-016-3860-x
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900018
DA 2024-07-18
ER

PT J
AU Thakkar, FN
   Srivastava, VK
AF Thakkar, Falgun N.
   Srivastava, Vinay Kumar
TI A fast watermarking algorithm with enhanced security using compressive
   sensing and principle components and its performance analysis against a
   set of standard attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Principle Component Analysis (PCA); Compressive Sensing (CS); Orthogonal
   Matching Pursuit (OMP); Fast watermarking; Orthogonal and biorthogonal
   wavelet analysis; Checkmark attacks; Watermarking execution time
ID DIGITAL-IMAGE WATERMARKING; WAVELET TRANSFORM; SCHEME
AB An algorithm for watermarking of digital images is proposed in this paper which utilizes Compressive Sensing (CS) with Principle Components (PCs) to achieve robustness, speed and security. CS is applied on PCs of watermark image to get the CS measurements. The singular values of these CS measurements are embedded with a scale factor into the HL subband of the cover image. The generated watermarked image contains three-layer security: one from PCs and other two from CS measurements. To recover PCs from CS measurements, a convex optimization tool, namely, the Orthogonal Matching Pursuit (OMP) is employed. Experiments are performed on both types of cover images; one with more low frequency components and another with more high frequency components. The algorithm offers state-ofthe art values of robustness and security in presence of different checkmark attacks like geometrical, non-geometrical and JPEG compression. A comparison of robustness of proposed algorithm with existing algorithms reveals that the proposed algorithm outperforms for most of the noise attacks. The performance of proposed algorithm with different wavelet families (e.g., orthogonal, biorthogonal, symmetric and asymmetric) are compared in terms of robustness and execution time. Such comparison may be helpful in selecting a suitable wavelet for a class of cover images in presence of checkmark attacks. The Haar wavelet performs better for geometric noise attack whereas Bior6.8 and Sym8 for non-geometric and JPEG compression type of noise attacks. The execution time of proposed algorithm with Haar wavelet is found to be minimum for all checkmark attacks. Moreover, it is quite less as compared to Optimization based methods and close to the other watermarking technique used for H.264 video standard.
C1 [Thakkar, Falgun N.; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Allahabad 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Thakkar, FN (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Allahabad 211004, Uttar Pradesh, India.
EM falgungcet@gmail.com; vinay@mannit.ac.in
RI Thakkar, Falgun/AAR-1995-2020; Srivastava, Vinay Kumar/AAL-2501-2021
OI Srivastava, Vinay Kumar/0000-0002-7993-0993
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], J INF COMPUT SCI
   Baraniuk R G, 2007, IEEE SIGNAL PROCESSI, V24
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Brannock E, 2009, J COMPUT, V4, P554, DOI 10.4304/jcp.4.6.554-566
   Fan T, 2013, INT J AUTOMATION CON, V2, P56
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Goyal Sachin, 2009, INT J COMPUTER SCI E, V1, P239
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hammouri A. I., 2013, INT J COMPUTER SCI I, V10, P330
   Jain C, 2008, ARXIV08080309V1
   Lai CC, 2013, 2013 14TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD 2013), P581, DOI 10.1109/SNPD.2013.21
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu X, 2014, J COMPUT INF SYST, V10, P5113
   Lu CS, 2005, PROC SPIE, V5681, P147, DOI 10.1117/12.586637
   Nguyen CV, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P81
   Orovic Irena, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P41
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Rao VSV, 2012, 2012 STUD C ENG SYST, P1
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Surekha P, 2012, APPL ARTIF INTELL, V26, P615, DOI 10.1080/08839514.2012.687670
   Thanki R., 2013, INT J ELECT COMM COM, V4, P1133
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Valenzise G, 2009, IEEE IMAGE PROC, P1265, DOI 10.1109/ICIP.2009.5413615
   Veena VK, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P105, DOI 10.1109/MVIP.2012.6428771
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Wang ZQ, 2007, LECT NOTES COMPUT SC, V4688, P307
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu J, 2016, SECUR COMMUN NETW, V9, P371, DOI 10.1002/sec.670
   Xiong CZ, 2008, IEEE IMAGE PROC, P437, DOI 10.1109/ICIP.2008.4711785
   Yamashita M.M., 2013, Proc. SIGGRAPH2013 Posters. Anaheim, P1
   Yang ZY, 2015, IEEE T EMERG TOP COM, V3, P363, DOI 10.1109/TETC.2014.2372151
   Zhang ML, 2011, LECT NOTES ARTIF INT, V7003, P75, DOI 10.1007/978-3-642-23887-1_10
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 39
TC 15
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15191
EP 15219
DI 10.1007/s11042-016-3744-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900001
DA 2024-07-18
ER

PT J
AU Wang, JH
   Wang, WQ
   Li, B
   Xu, GM
   Zhang, RZ
   Zhang, JZ
AF Wang, Jinhua
   Wang, Weiqiang
   Li, Bing
   Xu, Guangmei
   Zhang, Ruizhe
   Zhang, Jingzun
TI Exposure fusion via sparse representation and shiftable complex
   directional pyramid transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exposure fusion; PDTDFB; Sparse representation; Fusion rule
ID IMAGES
AB Sparse code theory with the sliding window technique can be used for the efficient fusion of multi-exposure images. However, when the size of the source images is large, this process requires a significant amount of time. To solve this problem, we propose a method that uses low-frequency sub-images of the source images as the input to the sparse code fusion framework. These low-frequency sub-images (which are far smaller than the entire image) provide a coarse representation of the original image. Regarding multi-scale decomposition, the high redundancy ratio of some methods limits their applicability to image fusion, especially multi-exposure image fusion (usually more than two source images). In this paper, we propose a method that employs a novel shiftable complex directional pyramid with shift-invariance and a low redundancy ratio to obtain the low-and high-frequency sub-images. For the high-frequency sub-image, we introduce a novel fusion rule based on the entropy of the segmented block, allowing more details of the source images to be preserved. Experiments show that our method attains results that are comparable to or better than existing methods.
C1 [Wang, Jinhua; Wang, Weiqiang] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.
   [Wang, Jinhua; Xu, Guangmei; Zhang, Ruizhe; Zhang, Jingzun] Beijing Union Univ, Coll Informat Technol, Beijing 100101, Peoples R China.
   [Li, Bing] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Beijing Union University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Wang, JH (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.; Wang, JH (corresponding author), Beijing Union Univ, Coll Informat Technol, Beijing 100101, Peoples R China.
EM xxtwangjinhua@buu.edu.cn
FU National Natural Science Foundation of China [61202245, 61271370,
   61271369, 61372148, 91420202, 61370138]; Project of Construction of
   Innovative Teams and Teacher Career Development for Universities and
   Colleges under Beijing Municipality [CITTCD20130513]; importation and
   development of High-Caliber Talents Project of Beijing Municipal
   Institutions [CITTCD20130320]; Beijing Education Commission Science and
   Technology Project; Research on Image Recognition of Seal in Chinese
   Painting and Calligraphy on Multi-features Fusion [KM201311417015]
FX This work is partly supported by the National Natural Science Foundation
   of China (Nos. 61202245, 61271370, 61271369, 61372148, 91420202, and
   61370138), the Project of Construction of Innovative Teams and Teacher
   Career Development for Universities and Colleges under Beijing
   Municipality (CIT&TCD20130513), the importation and development of
   High-Caliber Talents Project of Beijing Municipal Institutions
   (CIT&TCD20130320), the Beijing Education Commission Science and
   Technology Project, and Research on Image Recognition of Seal in Chinese
   Painting and Calligraphy on Multi-features Fusion (KM201311417015).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2008, TECHNION
   Ashikhmin M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P145
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Burt P., 1993, P 4 INT C IEEE, V4, P173, DOI DOI 10.1109/ICCV.1993.378222
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Gu B, 2012, J VIS COMMUN IMAGE R, V23, P604, DOI 10.1016/j.jvcir.2012.02.009
   Hu J, 2012, P ECCV, P499
   Krawczyk G, 2006, P IS T SPIES HUMAN V
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Mertens T., 2007, P PAC GRAPH MAUI HAW
   Nguyen TT, 2008, IEEE T SIGNAL PROCES, V56, P4661, DOI 10.1109/TSP.2008.927461
   Nguyen TT, 2008, IEEE T SIGNAL PROCES, V56, P4651, DOI 10.1109/TSP.2007.912897
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Wang JH, 2014, NEUROCOMPUTING, V135, P145, DOI 10.1016/j.neucom.2013.12.042
   Wang JH, 2009, OPT ENG, V48, DOI 10.1117/1.3265712
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
NR 28
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15755
EP 15775
DI 10.1007/s11042-016-3868-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900024
DA 2024-07-18
ER

PT J
AU Jenadeleh, M
   Moghaddam, ME
AF Jenadeleh, Mohsen
   Moghaddam, Mohsen Ebrahimi
TI BIQWS: efficient Wakeby modeling of natural scene statistics for blind
   image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image quality assessment; Natural scene statistics; Wake by
   distribution model; Support vector machine
ID INFORMATION
AB In this paper, a universal blind image quality assessment (IQA) algorithm is proposed that works in presence of various distortions. The proposed algorithm is a Blind Image Quality metric based on Wakeby Statistics (BIQWS) which extracts local mean subtraction and contrast normalization (MSCN) coefficients in spatial domain from input image. The MSCN coefficients are used for generating a Wakeby distribution statistical model to extract quality-aware features. The statistical studies indicate that the MSCN coefficients histogram is altered in the presence of various distortions with different severities. These changes are regular and can be used to estimate the type of the distortion and its severity. We extended our previous studies to extract efficient Wakeby distribution model parameters which are more sensitive to changes in MSCN coefficients. These parameters are used to form a quality-aware feature vector. This feature vector is then fed to an SVM (support vector machine) regression model with a nonlinear Kernel to predict the quality score of the input image without any information about the distortion type or reference image. Experimental results show that the image quality index obtained by the proposed method has higher correlation with respect to human perceptual opinions and it is superior in some distortions when compared to some full-reference and other state-of-the-art blind image quality assessment methods.
C1 [Jenadeleh, Mohsen; Moghaddam, Mohsen Ebrahimi] Shahid Beheshti Univ, Fac Comp Sci & Engn, GC, Tehran, Iran.
C3 Shahid Beheshti University
RP Jenadeleh, M (corresponding author), Shahid Beheshti Univ, Fac Comp Sci & Engn, GC, Tehran, Iran.
EM m_jenadeleh@sbu.ac.ir; m_moghadam@sbu.ac.ir
OI Jenadeleh, Mohsen/0000-0002-7567-7388; Jenadeleh,
   Mohsen/0000-0002-8216-1195
CR Altous S, 2011, ELMAR PROC, P97
   [Anonymous], 2011, MICT Image Quality Evaluation Database
   Aydin TO, 2015, IEEE T VIS COMPUT GR, V21, P31, DOI 10.1109/TVCG.2014.2325047
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZY, 2014, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2014.384
   Chou HH, 2012, IEEE T SYST MAN CY B, V43, P296
   Ding Y, 2015, ELECTRON LETT, V51, P338, DOI 10.1049/el.2014.2781
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Hosking JR, 1998, ENCYCL STAT SCI
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jenadeleh M, 2015, LECT NOTES COMPUT SC, V9164, P14, DOI 10.1007/978-3-319-20801-5_2
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Liu DL, 2014, SIGNAL PROCESS-IMAGE, V29, P844, DOI 10.1016/j.image.2014.06.007
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lu FF, 2015, NEURAL COMPUT APPL, V26, P77, DOI 10.1007/s00521-014-1699-5
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, INT CONF ACOUST SPEE, P962, DOI 10.1109/ICASSP.2010.5495298
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Nuutinen M, 2016, MULTIMED TOOLS APPL, V75, P2367, DOI 10.1007/s11042-014-2410-7
   Oh T, 2014, IEEE T IMAGE PROCESS, V23, P5428, DOI 10.1109/TIP.2014.2364925
   Omari M, 2015, MULTIMED TOOLS APPL, V74, P8685, DOI 10.1007/s11042-014-2353-z
   Phi BN, 2010, LECT NOTES COMPUT SC, V6297, P685, DOI 10.1007/978-3-642-15702-8_63
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rohaly A.M., 2000, ITU T STANDARDS CONT, P9
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Seshadrinathan K, 2011, MULTIMED TOOLS APPL, V51, P163, DOI 10.1007/s11042-010-0625-9
   Shao F, 2016, IEEE T CYBERNETICS, V46, P730, DOI 10.1109/TCYB.2015.2414479
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shen J, 2011, IEEE T IMAGE PROCESS, V20, P2089, DOI 10.1109/TIP.2011.2108661
   Shuhong J, 2014, INF TECHN J, V13
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Tao DC, 2009, IEEE T SYST MAN CY B, V39, P1623, DOI 10.1109/TSMCB.2009.2021951
   Traoré A, 2014, IEEE IMAGE PROC, P526, DOI 10.1109/ICIP.2014.7025105
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Yang JC, 2015, NEURAL NETWORKS, V71, P45, DOI 10.1016/j.neunet.2015.07.011
   Yang J, 2016, MOL CELL PROTEOMICS, V15, P1, DOI 10.1074/mcp.O115.056051
   Zaric A, 2010, ELMAR PROC, P113
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao B, 2015, P ELM 2014, V4, P223
   Zhao S, 2014, P 22 ACM INT C MULT
NR 57
TC 12
Z9 12
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13859
EP 13880
DI 10.1007/s11042-016-3785-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800008
DA 2024-07-18
ER

PT J
AU Duch, MM
   Morros, JR
   Ruiz-Hidalgo, J
AF Maceira Duch, Marc
   Morros, Josep-Ramon
   Ruiz-Hidalgo, Javier
TI Depth map compression via 3D region-based representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map coding; 3D representation; Image segmentation; Data
   compression
ID MULTIVIEW VIDEO; PARALLEL FRAMEWORK; DECISION; MOTION; TREE; VIEW
AB In 3D video, view synthesis is used to create new virtual views between encoded camera views. Errors in the coding of the depth maps introduce geometry inconsistencies in synthesized views. In this paper, a new 3D plane representation of the scene is presented which improves the performance of current standard video codecs in the view synthesis domain. Two image segmentation algorithms are proposed for generating a color and depth segmentation. Using both partitions, depth maps are segmented into regions without sharp discontinuities without having to explicitly signal all depth edges. The resulting regions are represented using a planar model in the 3D world scene. This 3D representation allows an efficient encoding while preserving the 3D characteristics of the scene. The 3D planes open up the possibility to code multiview images with a unique representation.
C1 [Maceira Duch, Marc; Ruiz-Hidalgo, Javier] Univ Politecn Cataluna, Image Proc Grp, Barcelona, Spain.
   [Morros, Josep-Ramon] Univ Politecn Cataluna, Teaching Telecommun, Barcelona, Spain.
   [Morros, Josep-Ramon] Univ Politecn Cataluna, Area Digital Image Proc, Barcelona, Spain.
   [Morros, Josep-Ramon] Univ Politecn Cataluna, Area Comp Vis, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya; Universitat Politecnica de
   Catalunya; Universitat Politecnica de Catalunya; Universitat Politecnica
   de Catalunya
RP Duch, MM (corresponding author), Univ Politecn Cataluna, Image Proc Grp, Barcelona, Spain.
EM marc.maceira@upc.edu; ramon.morros@upc.edu; j.ruiz@upc.edu
RI Morros, Josep Ramon/F-8227-2013; Ruiz-Hidalgo, Javier/F-8137-2013
OI Morros, Josep Ramon/0000-0002-1395-487X; Ruiz-Hidalgo,
   Javier/0000-0001-6774-685X; Maceira, Marc/0000-0002-8634-4888
FU Spanish Ministerio de Economia y Competitividad
   [BIGGRAPH-TEC2013-43935-R]; European Regional Development Fund (ERDF)
FX This work has been developed in the framework of the project
   BIGGRAPH-TEC2013-43935-R, financed by the Spanish Ministerio de Economia
   y Competitividad and the European Regional Development Fund (ERDF).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 3DTV C TRUE VIS TRAN
   [Anonymous], 2011, VISUAL COMMUN-US, DOI DOI 10.1109/VCIP.2011.6115989
   [Anonymous], P 2011 IEEE 13 INT W, DOI DOI 10.1109/MMSP.2011.6093810
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Ataer-Cansizoglu E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P51, DOI 10.1109/ICCVW.2013.14
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Farid MS, 2015, IEEE T IMAGE PROCESS, V24, P205, DOI 10.1109/TIP.2014.2374533
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Kim WS, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2447737
   Kowdle A, 2012, LECT NOTES COMPUT SC, V7576, P789, DOI 10.1007/978-3-642-33715-4_57
   Lei JJ, 2015, IEEE T CIRC SYST VID, V25, P275, DOI 10.1109/TCSVT.2014.2335471
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Maugey T, 2015, IEEE T IMAGE PROCESS, V24, P1573, DOI 10.1109/TIP.2015.2400817
   Merkle P., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P245, DOI 10.1109/3DTV.2008.4547854
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Milani S, 2011, IEEE INT CON MULTI
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Özkalayci BO, 2014, IEEE T IMAGE PROCESS, V23, P5222, DOI 10.1109/TIP.2014.2360452
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   RABBANI T., 2006, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P248
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shah S. K., 2014, INT C DIG IM COMP TE, P1, DOI DOI 10.1109/DICTA.2014.7008105
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Vilaplana V, 2008, IEEE T IMAGE PROCESS, V17, P2201, DOI 10.1109/TIP.2008.2002841
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 44
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13761
EP 13784
DI 10.1007/s11042-016-3727-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Thanh, TM
   Tanaka, K
AF Ta Minh Thanh
   Tanaka, Keisuke
TI An image zero-watermarking algorithm based on the encryption of visual
   map feature with watermark information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual map feature (VMF); Permuted visual map feature (PVMF); 1D-DCT; QR
   decomposition; Image zero-watermarking
ID QR DECOMPOSITION; CRYPTOGRAPHY; SCHEME
AB We propose a new image zero-watermarking scheme based on the encryption of visual map feature (VMF) and permuted visual map feature (PVMF) of the original image with watermark information. To resist strong attacks, we employ the robust feature extracted from the host image by using the combination of QR decomposition and 1D-DCT. Since the feature extracted from the host image presents the coarse part of the host image, we call it VMF. For enhancing the security of VMF, we apply the permutation method on VMF based on the Torus permutation to obtain PVMF. We construct a new method of image zero-watermarking by the encryption of VMF and PVMF with copyright data, and then generate the master share and the ownership share. The master share is generated by comparison of two consecutive DC coefficients after the QR decomposition is applied. The ownership share is generated by encryption of the master share with copyright data. Experimental results show that the proposed method is robust against common processing and geometric attacks with low consuming time.
C1 [Ta Minh Thanh; Tanaka, Keisuke] Tokyo Inst Technol, Meguro Ku, 2-12-2 Ookayama, Tokyo 1528552, Japan.
   [Ta Minh Thanh] Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
C3 Tokyo Institute of Technology; Le Quy Don Technical University
RP Thanh, TM (corresponding author), Tokyo Inst Technol, Meguro Ku, 2-12-2 Ookayama, Tokyo 1528552, Japan.; Thanh, TM (corresponding author), Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
EM thanhtm@mta.edu.vn; keisuke@is.titech.ac.jp
RI Thanh, Ta Minh/ABH-2076-2021
OI Thanh, Ta Minh/0000-0002-4776-4265
FU Ministry of Education, Science, Sports and Culture [24240001]; I-System
   Co. Ltd.; NTT Secure Platform Laboratories; CREST, JST; Grants-in-Aid
   for Scientific Research [16H01705, 17H01695] Funding Source: KAKEN
FX This work is supported by the Ministry of Education, Science, Sports and
   Culture, Grant-in-Aid for Scientific Research (A) No. 24240001, a grant
   of I-System Co. Ltd., NTT Secure Platform Laboratories and CREST, JST.
CR Barni M, 2004, WATERMARKING SYSTEMS, P6
   Ferguson N, 2008, CRYPTOGRAPHY ENG DES
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hernandez-Avalos PA, 2010, MIDWEST SYMP CIRCUIT, P628, DOI 10.1109/MWSCAS.2010.5548906
   Li D, 2016, INT J SECUR APPL, V10, P203, DOI 10.14257/ijsia.2016.10.1.19
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Rani A, 2014, MULTIMED TOOLS APPL, P1
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Shih F.Y., 2008, Digital Watermarking and Steganography: Fundamentals and Techniques
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Thanh TM, 2014, P IEEE 25 INT S PERS
   Thanh TM, 2014, AEU INT J ELECT COMM
   Thanh TM, 2015, INT J MULTI IN PRESS
   Thanh TM, 2015, P 10 INT JOINT C COM
   Voyatzis G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P237, DOI 10.1109/ICIP.1996.560753
   Wanhong N, 2009, APPL COMPUT SYST, V12, P66
   Yaxun Zhou, 2011, 2011 International Conference on Multimedia Technology, P2873
   Zhou L, 2015, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND COGNITIVE INFORMATICS, P34
   [周支元 Zhou Zhiyuan], 2010, [微计算机信息, Microcomputer Information.], V26, P82
NR 23
TC 37
Z9 40
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13455
EP 13471
DI 10.1007/s11042-016-3750-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900024
DA 2024-07-18
ER

PT J
AU Yu, S
   Cheng, Y
   Su, SZ
   Cai, GR
   Li, SZ
AF Yu, Sheng
   Cheng, Yun
   Su, Songzhi
   Cai, Guorong
   Li, Shaozi
TI Stratified pooling based deep convolutional neural networks for human
   action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Convolutional neural networks (CNN);
   Stratified pooling (SP); Support vector machines (SVM)
ID IMAGE; DESCRIPTORS; MODEL
AB Video based human action recognition is an active and challenging topic in computer vision. Over the last few years, deep convolutional neural networks (CNN) has become the most popular method and achieved the state-of-the-art performance on several datasets, such as HMDB-51 and UCF-101. Since each video has a various number of frame-level features, how to combine these features to acquire good video-level feature becomes a challenging task. Therefore, this paper proposed a novel action recognition method named stratified pooling, which is based on deep convolutional neural networks (SP-CNN). The process is mainly composed of five parts: (i) fine-tuning a pre-trained CNN on the target dataset, (ii) frame-level features extraction; (iii) the principal component analysis (PCA) method for feature dimensionality reduction; (iv) stratified pooling frame-level features to get video-level feature; and (v) SVM for multiclass classification. Finally, the experimental results conducted on HMDB-51 and UCF-101 datasets show that the proposed method outperforms the state-of-the-art.
C1 [Yu, Sheng; Su, Songzhi; Li, Shaozi] Xiamen Univ, Cognit Sci Dept, Xiamen 361005, Peoples R China.
   [Yu, Sheng; Cheng, Yun] Hunan Univ Humanities Sci & Technol, Sch Informat, Loudi 417000, Peoples R China.
   [Yu, Sheng; Su, Songzhi; Li, Shaozi] Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China.
   [Cai, Guorong] Jimei Univ, Comp Engn Coll, Xiamen 361005, Peoples R China.
C3 Xiamen University; Hunan University Of Humanities, Science & Technology;
   Jimei University
RP Li, SZ (corresponding author), Xiamen Univ, Cognit Sci Dept, Xiamen 361005, Peoples R China.; Li, SZ (corresponding author), Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China.
EM yushengxmu@stu.xmu.edu.cn; szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU Nature Science Foundation of China [61202143, 61572409, 61571188];
   Natural Science Foundation of Fujian Province [2013J05100]; Research
   Foundation of Education Bureau of Hunan Province [15C0726]
FX This work is supported by the Nature Science Foundation of China (No.
   61202143, No. 61572409, No. 61571188), the Natural Science Foundation of
   Fujian Province (No. 2013J05100), the Research Foundation of Education
   Bureau of Hunan Province(No. 15C0726).
CR [Anonymous], 1988, SIMULATED ANNEALING
   [Anonymous], ARXIV150504868
   [Anonymous], ARXIV14054506
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], ARXIV150301224
   [Anonymous], 2013, ARXIV PREPRINT ARXIV, DOI [DOI 10.48550/ARXIV.1312.6229, 10.48550/arXiv.1312.6229]
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chen QQ, 2016, NEUROCOMPUTING, V173, P364, DOI 10.1016/j.neucom.2015.03.124
   Coates A., 2011, P 28 INT C MACH LEAR, V28, P921
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Iosifidis A, 2014, CLASS SPECIFIC REFER
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jhuang H., 2011, P IEEE INT C COMP VI
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Leng B, 2015, NEUROCOMPUTING, V151, P593, DOI 10.1016/j.neucom.2014.06.084
   Liu L, 2014, ARXIV14117466
   Liu Ruijun, 2015, MULTIMED TOOLS APPL, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng XJ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.59
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perronnin F., 2007, P IEEE CVPR, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Sharma S., 2015, NEURAL INFORM PROCES
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K., 2012, ARXIV12120402CS
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xu H, 2015, MULTIMED TOOLS APPL, P1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
NR 52
TC 30
Z9 30
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13367
EP 13382
DI 10.1007/s11042-016-3768-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900020
DA 2024-07-18
ER

PT J
AU An, L
   Chen, XJ
   Liu, S
   Lei, YJ
   Yang, SF
AF An, Le
   Chen, Xiaojing
   Liu, Shuang
   Lei, Yinjie
   Yang, Songfan
TI Integrating appearance features and soft biometrics for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Appearance features; Soft biometrics;
   Multimodal fusion; Graph learning
ID 3-D OBJECT RETRIEVAL
AB Matching people in different camera views, commonly referred to as person re-identification, is an inherently challenging task due to the appearance disparity caused by view change.Other factors such as low image resolution and occlusion further compound this problem. As a highly demanded technique, person re-identification has been actively studied in recent years. Most of the existing approaches either focus on feature design or distance metric learning, based on appearance features. However, due to the view change, the appearance features may significantly vary for the same subject, resulting in matching difficulties. Instead of using features from a single modality, i.e, appearance, we propose to use multimodal features to improve the re-identification accuracy. Specifically, in this work, we leverage both appearance features and soft biometrics, i.e, human characteristics such as gender, to match individuals across cameras. We build multiple graphs, each of which represent one feature modality, and the graphs are then combined and optimized to derive the similarities between a probe and the gallery subjects. The proposed method is evaluated on the VIPeR dataset with annotated soft biometric labels. The results suggest that using multimodal features, e.g, appearance and soft biometrics, can improve the matching accuracy as compared to using appearance features only, and superior performance is obtained as compared to other state-of-the-art approaches.
C1 [An, Le] Huazhong Univ Sci & Technol, Sch Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Peoples R China.
   [Chen, Xiaojing] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
   [Liu, Shuang] Dongbei Univ Finance & Econ, Sch Int Business Commun, Dalian 116025, Peoples R China.
   [Lei, Yinjie; Yang, Songfan] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
C3 Huazhong University of Science & Technology; University of California
   System; University of California Riverside; Dongbei University of
   Finance & Economics; Sichuan University
RP Chen, XJ (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
EM xchen010@ucr.edu
RI liu, shuang/HPD-8666-2023
FU Natural Science Foundation of China [61602193, 61501312, 61403265];
   Fundamental Research Funds for the Central Universities [HUST:
   2016YXMS063]; Science and Technology Plan of Sichuan Province
   [2015SZ0226]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant Numbers 61602193, 61501312, 61403265, and in part by
   the Fundamental Research Funds for the Central Universities (HUST:
   2016YXMS063). This work was also supported in part by the Science and
   Technology Plan of Sichuan Province under Grant Number 2015SZ0226.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], 2013, 2013 7 INT C DISTR S
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Dandan Xu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P477, DOI 10.1109/ICIG.2013.100
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kuo CH, 2013, IEEE WORK APP COMP, P281, DOI 10.1109/WACV.2013.6475030
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu MX, 2016, IEEE T CYBERNETICS, V46, P298, DOI 10.1109/TCYB.2015.2401733
   Liu MX, 2016, IEEE T PATTERN ANAL, V38, P2335, DOI 10.1109/TPAMI.2015.2430325
   Liu MX, 2014, NEUROCOMPUTING, V139, P34, DOI 10.1016/j.neucom.2013.09.056
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wei HJ, 2013, IEEE T MED IMAGING, V32, P1928, DOI 10.1109/TMI.2013.2269195
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhang J, 2013, COMPUT VIS IMAGE UND, V117, P56, DOI 10.1016/j.cviu.2012.10.004
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
NR 46
TC 14
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12117
EP 12131
DI 10.1007/s11042-016-4070-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000054
DA 2024-07-18
ER

PT J
AU Huang, SY
   Yu, JP
   Wang, YK
   Liu, JW
AF Huang, Shih-Yu
   Yu, Jen-Perng
   Wang, Yuan-Kai
   Liu, Jia-Wei
TI Designing an exergaming system for exercise bikes using kinect sensors
   and Google Earth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exergaming; Kinect; Google Earth; Exercise bike
ID HUMAN MOTION ANALYSIS; OBJECT RETRIEVAL
AB This paper proposes an Exergaming system for exercise bikes. With the assistance of a Kinect device and the proposed body-movement-detection algorithm, exercise bike users are required to perform correct neck and shoulder movements to control the airplane trajectory in Google Earth. They can take a flying tour in the virtual reality provided by Google Earth while riding an exercise bike. According to the experimental results, 95 % of the users in the experiment considered the proposed Exergaming system to be very entertaining; more than 85 % of the users affirmed that the assigned neck and shoulder movements effectively help stretch the muscles in these body parts; the detection rate of the proposed body-movement algorithm was over 90 %. Therefore, the proposed Exergaming system is a good assisting system for exercise bikes.
C1 [Huang, Shih-Yu; Liu, Jia-Wei] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Huang, Shih-Yu] 5 Ming Rd, Gui Shan District 333, Taoyuan County, Taiwan.
   [Yu, Jen-Perng] Ming Chuan Univ, Dept Informat Management, Taipei, Taiwan.
   [Wang, Yuan-Kai] Fu Jen Catholic Univ, Dept Elect Engn, Taipei, Taiwan.
C3 Ming Chuan University; Ming Chuan University; Fu Jen Catholic University
RP Huang, SY (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.; Huang, SY (corresponding author), 5 Ming Rd, Gui Shan District 333, Taoyuan County, Taiwan.
EM syhuang@mail.mcu.edu.tw
RI Wang, Yuan-Kai/N-4086-2015
OI Wang, Yuan-Kai/0000-0002-0676-5886
FU Ministry of Science and Technology, Taiwan [MOST 103-2221-E-130-018]
FX This research is supported in part by the Ministry of Science and
   Technology, Taiwan under the grant of MOST 103-2221-E-130-018.
CR Adams RJ, 2015, IEEE T
   [Anonymous], 2012, LOADING
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Dowling AV, 2014, IEEE J
   Sucar LE, 2008, COMM COM INF SC, V25, P531
   EVETT L, 2011, 2011 IEEE 1 INT C SE, P1, DOI DOI 10.1109/SEGAH.2011.6165460
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Garrido JE, 2013, PERV COMP TECHN HEAL
   Girshick R, 2011, COMP VIS PATT REC CV
   Han J, 2013, IEEE T CYBERN, V43
   Hossein Mousavi H, 2014, J MED ENG, V2014
   Jun S-k, 2013, AUT SCI ENG CASE IEE
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Lee J-d, 2014, CONS EL ICCE IEEE IN
   Lin T-Y, 2013, MOD S AMS 7 AS
   Obdrzálek S, 2012, IEEE ENG MED BIO, P1188, DOI 10.1109/EMBC.2012.6346149
   Padma T, 2011, APPL SOFT COMPUT, V11, P1762, DOI 10.1016/j.asoc.2010.05.019
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Shotton J., 2011, COMP VIS PATT REC CV
   Sinclair J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P289
   Tang Y, 2012, INT J DIGIT CONTENT, V6, P385, DOI DOI 10.4156/JDCTA.V0L6.ISSUE19.47
   van Diest M, 2014, J BIOMECH, V47, P2925, DOI 10.1016/j.jbiomech.2014.07.017
   Wang YK, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/761460
   Wu CH, 2011, IEEE T MOBILE COMPUT, V10, P1459, DOI 10.1109/TMC.2010.264
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 27
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12281
EP 12314
DI 10.1007/s11042-016-3641-6
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200006
DA 2024-07-18
ER

PT J
AU Yang, HC
   Chang, WC
AF Yang, Hsuan-Che
   Chang, Wen-Chih
TI Ubiquitous smartphone platform for K-7 students learning geography in
   Taiwan
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous learning; Geography learning; Smartphone; Android
ID MOBILE; SYSTEM; GAMES
AB With the rapid development of handheld devices, Ubiquitous Learning becomes more and more popular and has attracted many researchers in the field of E-Learning. Geography learning can be further adapted into smartphone platform with its mobility and GPS capability to be a useful learning system. In Taiwan, Junior high school students are conducted an experiment to assess the smartphone to study Geography. With simple test items, the proposed system generates individual learning profile and test analysis report for each student. After the experiment in one semester, the final-term examination for experiment and control groups was counted and compared. The experimental result shows that the students, which learned with proposed system, in the experimental group achieved better leaning efficiency by learning with ubiquitous Geography learning system assistance.
C1 [Yang, Hsuan-Che] Tungnan Univ, Dept Business Adm, 152,Sec 3,BeiShen Rd, New Taipei 222, Peoples R China.
   [Chang, Wen-Chih] Chung Hua Univ, Dept Informat Management, 707,Sec 2,WuFu Rd, Hsinchu 30012, Taiwan.
C3 Chung Hua University
RP Yang, HC (corresponding author), Tungnan Univ, Dept Business Adm, 152,Sec 3,BeiShen Rd, New Taipei 222, Peoples R China.
EM hsuanche.yang@mail.tnu.edu.tw; yilan.earnest@gmail.com
CR [Anonymous], 2010, DESIGNING EFFECTIVE
   Cavus N, 2009, BRIT J EDUC TECHNOL, V40, P78, DOI 10.1111/j.1467-8535.2007.00801.x
   Chang WC, 2009, IEEE INTERNET COMPUT, V13, P26, DOI 10.1109/MIC.2009.81
   Chen CC, 2012, COMPUT ED
   Chen Y M, 2006, STUDY INTEGRATING GL
   Chiu P, 2007, STUDY LEARNERS BEHAV
   Churchill D, 2008, COMPUT EDUC, V50, P1439, DOI 10.1016/j.compedu.2007.01.002
   Eschenbrenner B, 2007, P 6 ANN WORKSH HCI R
   Fang L, 2013, ED MED ICEM 2013 IEE, P1
   FitzGerald E, 2012, J COMPUT ASSIST LEAR, V28, P195, DOI 10.1111/j.1365-2729.2012.00481.x
   Garyfallidou DM, 2014, 2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL), P57, DOI 10.1109/IMCTL.2014.7011104
   Gu X, 2011, J COMPUT ASSIST LEAR, V27, P204, DOI [10.1111/j.1365-2729.2010.00391.x, 10.1111/J.1365-2729.2010.00391.x]
   Hsuan-Che Yang, 2011, 2011 International Conference on Electrical and Control Engineering, P6254, DOI 10.1109/ICECENG.2011.6056772
   Hsuan-Che Yang, 2011, Proceedings of the 2011 4th International Conference on Ubi-Media Computing (U-Media 2011), P191, DOI 10.1109/U-MEDIA.2011.29
   Hwang GJ, 1998, IEEE T EDUC, V41, P343
   Hwang GJ, 2011, BRIT J EDUC TECHNOL, V42, pE65, DOI 10.1111/j.1467-8535.2011.01183.x
   Klopfer E, 2012, J COMPUT ASSIST LEAR, V28, P465, DOI 10.1111/j.1365-2729.2011.00456.x
   Lin T-C, 2007, STUDY INSTRUCTIONAL
   Manjoo F., 2015, MURKY ROAD AHEAD AND
   McDonald DS, 2004, COMPUT EDUC, V42, P195, DOI 10.1016/j.compedu.2003.07.003
   Merrill D.M., 1996, Educational Technology, V36, P5
   Özdemir S, 2010, BRIT J EDUC TECHNOL, V41, pE135, DOI 10.1111/j.1467-8535.2010.01071.x
   Peng H, 2009, INNOV EDUC TEACH INT, V46, P171, DOI 10.1080/14703290902843828
   Sarker S, 2003, COMMUN ACM, V46, P35, DOI 10.1145/953460.953484
   Shih YC, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P352, DOI 10.1109/ICALT.2003.1215119
   Shih YC, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P943, DOI 10.1109/CIE.2002.1186120
   Tüzün H, 2009, COMPUT EDUC, V52, P68, DOI 10.1016/j.compedu.2008.06.008
   Wang MJ, 2009, BRIT J EDUC TECHNOL, V40, P673, DOI 10.1111/j.1467-8535.2008.00846.x
   Williams Storm, IDC SMART CONNECTED
NR 29
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11651
EP 11668
DI 10.1007/s11042-016-3325-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000030
DA 2024-07-18
ER

PT J
AU Chai, XL
   Yang, K
   Gan, ZH
AF Chai, Xiuli
   Yang, Kang
   Gan, Zhihua
TI A new chaos-based image encryption algorithm with dynamic key selection
   mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic keystream sequence group selection mechanism (DKSGSM); Dynamic
   keystream selection mechanism (DKSM); Image encryption; Chaos;
   Permutation; Diffusion
ID SCHEME; IMPROVEMENT; STANDARD; CRYPTANALYSIS; PERMUTATION; MAP
AB In recent years, a wide variety of cryptographic algorithms based on chaos have been put forward and most of them have been proved to be successful by adopting the traditional permutation-diffusion architecture. However, one drawback these methods mostly hold is that they have little connection with the plaintext or, properly speaking, the relationship between them is rather less. The drawback makes the encryption algorithms vulnerable to the known-plaintext and chosen-plaintext attack. In addition, the secret keys are stationary at most times, and they can't be selected dynamically by the corresponding plain image pixels. In order to overcome these disadvantages mentioned above, we introduce a new chaos-based image encryption algorithm with dynamic key selection mechanisms in this paper, and present a dynamic keystream sequence group selection mechanism (DKSGSM) and a dynamic keystream selection mechanism (DKSM). They strongly enhance the relationship between the plaintext and the encryption scheme. In particular, the DKSGSM and DKSM expand the selection range of the keys and allow us to select the keys dynamically by the corresponding plaintext pixels. What's more, by adopting the bidirectional encryption, we can spread the influence to the whole image once a tiny change in plain image and this can greatly increase the security level of our encryption method. Simulation results and numerical analyses indicate that our encryption scheme is safe and efficient.
C1 [Chai, Xiuli; Yang, Kang] Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
   [Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
C3 Henan University; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); University of Pittsburgh; Henan University
RP Chai, XL (corresponding author), Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.; Chai, XL (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
EM chaixiuli@henu.edu.cn
FU National Natural Science Foundation of China [61203094, 61305042];
   Science and Technology Foundation of Henan Province of China
   [152102210048]; Foundation and Frontier Project of Henan Province of
   China [162300410196]; Natural Science Foundation of Educational
   Committee of Henan Province of China [14A413015]; Ministry of Education
   of China [SBGJ090603]; Research Foundation of Henan University
   [xxjc20140006]; Henan Provincial Government
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61203094 and 61305042), Science and Technology
   Foundation of Henan Province of China (Grant No. 152102210048),
   Foundation and Frontier Project of Henan Province of China (Grant No.
   162300410196), Natural Science Foundation of Educational Committee of
   Henan Province of China (Grant No. 14A413015), the joint funds between
   Henan Provincial Government and Ministry of Education of China (Grant
   No. SBGJ090603), the Research Foundation of Henan University (Grant No.
   xxjc20140006).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Li CQ, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500752
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Mannai O, 2015, NONLINEAR DYNAM, V82, P107, DOI 10.1007/s11071-015-2142-x
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2013, NONLINEAR DYNAM, V73, P795, DOI 10.1007/s11071-013-0832-9
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 40
TC 77
Z9 79
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9907
EP 9927
DI 10.1007/s11042-016-3585-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300036
DA 2024-07-18
ER

PT J
AU Cheng, TF
   Chang, CC
   Liu, L
AF Cheng, Ting-Fang
   Chang, Ching-Chun
   Liu, Li
TI Secret sharing: using meaningful image shadows based on Gray code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Absolute moment block truncation coding; Gray code; Low bit rate; Low
   complexity; Meaningful shadows; Secret sharing
ID STEGANOGRAPHY; SCHEME; AUTHENTICATION; QUALITY
AB Steganography, such as secret sharing, is an important technique to use for protecting transmitted confidential data from the attention of any adversaries. Gray code is a commonly encountered binary labeling that was proposed by Frank Gray of Bell Laboratories in 1940 to prevent errors when using pulse-code modulation to transmit signals. The main features of Gray code are its recursive construction method and the fact that any two adjacent codes change only one bit. According to our observations, the image pixel correction based on these features is suitable for application secret sharing without making significant changes to the pixel value. We designed a reversible secret sharing method using meaningful image shadows based on Gray code. Our design applies absolute moment block truncation coding (AMBTC) compression to reduce the transmission bit rate. The experimental results show that our scheme can achieve the adequate visual quality of shadow images with lower communication overhead, thus proving it practical for numerous applications.
C1 [Cheng, Ting-Fang] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   [Liu, Li] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Peoples R China.
C3 Feng Chia University; University of Warwick; Taiyuan University of
   Science & Technology
RP Cheng, TF (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM nthu.tiffany@gmail.com
RI Chang, Ching-Chun/AGG-3857-2022; Chang, Ching-Chun/JAN-6210-2023; Cheng,
   Ting-Fang/GLR-9279-2022
CR Aho AV., 1974, DESIGN ANAL COMPUTER
   [Anonymous], J VISUAL COMMUNICATI
   [Anonymous], 1979, P AFIPS NAT COMP C N
   Cai K.Y., 2011, P 5 INT C UB INF MAN, P129
   Chang CC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1305, DOI 10.1109/IIH-MSP.2008.140
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P485, DOI 10.1109/IIH-MSP.2014.127
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Gray F., 1953, United States Patent
   Le THN, 2011, DIGIT SIGNAL PROCESS, V21, P734, DOI 10.1016/j.dsp.2011.07.004
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P302, DOI 10.1109/ISDA.2008.207
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Ou DH, 2014, J VIS COMMUN IMAGE R, V25, P1222, DOI 10.1016/j.jvcir.2013.12.018
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang C., 2010, PROC IEEE INT C COMP, P15
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
NR 23
TC 13
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9337
EP 9362
DI 10.1007/s11042-016-3535-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300010
DA 2024-07-18
ER

PT J
AU Wu, JX
   Zhong, SH
   Jiang, JM
   Yang, YY
AF Wu, Jiaxin
   Zhong, Sheng-hua
   Jiang, Jianmin
   Yang, Yunyun
TI A novel clustering method for static video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Static video summarization; Clustering method; Video representation
ID FEATURES; SEARCH; MODEL; BAG
AB Static video summarization is recognized as an effective way for users to quickly browse and comprehend large numbers of videos. In this paper, we formulate static video summarization as a clustering problem. Inspired by the idea from high density peaks search clustering algorithm, we propose an effective clustering algorithm by integrating important properties of video to gather similar frames into clusters. Finally, all clusters' center will be collected as static video summarization. Compared with existing clustering-based video summarization approaches, our work can detect frames which are highly relevant and generate representative clusters automatically. We evaluate our proposed work by comparing it with several state-of-the-art clustering-based video summarization methods and some classical clustering algorithms. The experimental results evidence that our proposed method has better performance and efficiency.
C1 [Wu, Jiaxin; Zhong, Sheng-hua; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Guang Dong, Peoples R China.
   [Yang, Yunyun] Harbin Inst Technol, Sch Nat Sci & Humanities, Shenzhen Grad Sch, Shenzhen, Guang Dong, Peoples R China.
C3 Shenzhen University; Harbin Institute of Technology
RP Zhong, SH (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Guang Dong, Peoples R China.
EM csshzhong@szu.edu.cn
RI Wu, Jiaxin/GVT-3486-2022
FU National Natural Science Foundation of China [61502311]; Natural Science
   Foundation of Guangdong Province [2016A030310053]; Special Program for
   Applied Research on Super Computation of the NSFC-Guangdong Joint Fund;
   Science and Technology Innovation Commission of Shenzhen
   [JCYJ20150324141711640]; Shenzhen University [201535]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61502311), Natural Science Foundation of Guangdong Province
   (No. 2016A030310053), Special Program for Applied Research on Super
   Computation of the NSFC-Guangdong Joint Fund (the second phase), the
   Science and Technology Innovation Commission of Shenzhen under Grant
   (No. JCYJ20150324141711640), and the Shenzhen University research
   funding (201535).
CR Almageed A, 2008, ICIP08, P3200
   [Anonymous], 2007, 2007 INT C CONS EL
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chen L, 2015, ACM T MULTIM COMPUT, V23, P1163
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P485, DOI 10.1109/TMM.2015.2405343
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gong Y, 2011, P IEEE INT C IM PROC, P362
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Hanjalic A, 1998, P IM DAT MULT SEARCH
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu JK, 2015, IEEE NETWORK, V29, P46, DOI 10.1109/MNET.2015.7064902
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mei S, 2015, PATTERN RECOGN, V48, P289
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ren TW, 2015, MULTIMEDIA SYST, V21, P189, DOI 10.1007/s00530-014-0384-y
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Zhou YP, 2015, IEEE ACM T NETWORK, V23, P1163, DOI 10.1109/TNET.2014.2321422
   Zhou YP, 2015, IEEE T MULTIMEDIA, V17, P1273, DOI 10.1109/TMM.2015.2447277
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 27
TC 58
Z9 62
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9625
EP 9641
DI 10.1007/s11042-016-3569-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300023
DA 2024-07-18
ER

PT J
AU Yu, WS
   Hou, ZQ
   Hu, D
   Wang, P
AF Yu, Wangsheng
   Hou, Zhiqiang
   Hu, Dan
   Wang, Peng
TI Robust mean shift tracking based on refined appearance model and online
   update
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Mean shift tracking; Appearance model; Model update
ID VISUAL TRACKING; OBJECT TRACKING
AB In this paper, a robust mean shift tracking algorithm based on refined appearance model (RAM) and online update strategy is proposed. The main idea of the proposed algorithm is to construct a more accurate appearance model to improve tracking precision and design an online update strategy to adjust to the appearance variation. At the beginning of the tracking, the simple mean shift tracking algorithm is applied on the first few frames to collect a set of target templates, which contains both foreground and background of the target. During the model construction, simple linear iterative clustering (SLIC) algorithm is exploited to obtain the superpixels of the target templates, and the superpixels are further clustered to distinguish the foreground from background. A weighted vector is then obtained based on the classified foreground from background, which is utilized to modify the kernel histogram appearance model. The following frames are processed based on the mean shift tracking algorithm with the modified appearance model, and the stable tracking results with no occlusion will be selected to update the appearance model. The concrete operation of model update is the same as model construction. Experiment results on some challenging test sequences indicate that the proposed algorithm can well cope with both appearance variation and background change to obtain a robust tracking performance. A further comprehensive experiment on OTB2013 demonstrates that the proposed tracking algorithm outperforms the state-of-the-art works in most cases.
C1 [Yu, Wangsheng; Hou, Zhiqiang; Hu, Dan; Wang, Peng] Air Force Engn Univ, Informat & Nav Coll, Xian 710077, Peoples R China.
C3 Air Force Engineering University
RP Yu, WS (corresponding author), Air Force Engn Univ, Informat & Nav Coll, Xian 710077, Peoples R China.
EM xing_fu_yu@sina.com
RI Wang, Peng/N-2475-2017
OI Wang, Peng/0000-0002-0610-4754
FU National Natural Science Foundation of China [61473309, 61403414];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2016JM6050]
FX This research was supported by National Natural Science Foundation of
   China (No. 61473309 and 61403414) and Natural Science Basic Research
   Plan in Shaanxi Province of China (No. 2016JM6050).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Collins R, 2003, MEAN SHIFT BLOB TRAC
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
   Zivkovic Z, 2004, PROC CVPR IEEE, P798
NR 28
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10973
EP 10990
DI 10.1007/s11042-016-3472-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400037
DA 2024-07-18
ER

PT J
AU López, GL
   Negrón, APP
   Jiménez, AD
   Rodríguez, JR
   Paredes, RI
AF Lara Lopez, Graciela
   Perez Negron, Adriana Pena
   De Antonio Jimenez, Angelica
   Ramirez Rodriguez, Jaime
   Imbert Paredes, Ricardo
TI Comparative analysis of shape descriptors for 3D objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape descriptors; Matching and similarity; Voxelization; Pose
   normalization and visual salience
ID MODEL RETRIEVAL; SIMILARITY; CLASSIFICATION; REPRESENTATION;
   RECOGNITION; TRANSFORM; SEARCH; SYSTEM; IMAGES
AB One of the basic characteristics of an object is its shape. Several research areas in mathematics and computer science have taken an interest in object representation in both 2D images and 3D models, where shape descriptors are a powerful mechanism enabling the processes of classification, retrieval and comparison for object matching. In this paper, we present a literature survey of this broad field, including a comparative analysis based on the above shape descriptor processes. In view of their significance, we identified the shape descriptors implemented using the concept of visual salience. This paper gives an overview of this topic.
C1 [Lara Lopez, Graciela; Perez Negron, Adriana Pena] Univ Guadalajara, CUCEI, Modulo O Div Elect & Comp, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [De Antonio Jimenez, Angelica; Ramirez Rodriguez, Jaime; Imbert Paredes, Ricardo] Univ Politecn Madrid, Escuela Tecn Super Ingn Informat, Madrid, Spain.
C3 Universidad de Guadalajara; Universidad Politecnica de Madrid
RP López, GL (corresponding author), Univ Guadalajara, CUCEI, Modulo O Div Elect & Comp, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM graciela.lara@red.cucei.udg.mx; adriana.pena@cucei.udg.mx;
   angelica@fi.upm.es; jramirez@fi.upm.es; rimbert@fi.upm.es
RI Peña Pérez Negrón, Adriana/AFK-8243-2022; de Antonio,
   Angélica/B-2584-2009; Imbert, Ricardo/M-1268-2014
OI Peña Pérez Negrón, Adriana/0000-0001-6823-2367; de Antonio,
   Angélica/0000-0002-8936-9095; Imbert, Ricardo/0000-0002-7738-4941
FU UDG, Mexico [UDG-685]; PROMEP scholarship
FX Graciela Lara holds a PROMEP scholarship in partnership with the UDG
   (UDG-685), Mexico.
CR AKGUL CB, 2006, 14 EUR SIGN PROC C E
   Akgul CB, 2007, THESIS
   Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   Ankerst M, 1999, P 6 INT S SP DAT, V1651
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   [Anonymous], 2007, THESIS
   [Anonymous], THESIS
   Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Bakhadyrov I., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P904, DOI 10.1109/ICSMC.1999.825382
   Barrios JM, 2011, P 4 INT C SIMILARITY, P61
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Behley J, 2012, IEEE INT CONF ROBOT, P4391, DOI 10.1109/ICRA.2012.6225003
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bespalov D, 2006, COMPUT AIDED DESIGN, V38, P1020, DOI 10.1016/j.cad.2006.07.005
   Biasotti S, 2006, EUR S GEOM PROC, P239
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Bu SH, 2015, COMPUT GRAPH-UK, V46, P117, DOI 10.1016/j.cag.2014.09.007
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Cerri A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P795, DOI 10.1109/ICIAP.2007.4362873
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen LB, 2009, PROC CVPR IEEE, P365, DOI 10.1109/CVPRW.2009.5206792
   Chung F.R.K, 1997, AM MATH SOC
   Dadi E, 2012, INT J FUTUR GENER CO, V5, P29
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1139, DOI 10.1109/34.625116
   Dutagaci H, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P188, DOI 10.1109/3DIM.2005.79
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P83, DOI 10.1016/S0010-4485(01)00177-4
   ElNaghy Hanan, 2013, International Journal of Research and Reviews in Applied Sciences, V14, P412
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Godil A, 2011, IS T SPIE ELECT IMAG
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Healy DM, 2003, J FOURIER ANAL APPL, V9, P341, DOI 10.1007/s00041-003-0018-9
   Heczko M., 2002, DATENBANK SPEKTRUM, V2, P54
   Heider P, 2012, VISUAL COMPUT, V28, P919, DOI 10.1007/s00371-012-0725-9
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hoffmann C.M., 1989, Geometric and solid modeling : an introduction edition, P338
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Huang P, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P408
   Icke I, 2004, CONTENT BASED 3D SHA
   Ikeuchi Katsushi., 1981, IJCAI Conference, P595
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   KANG SB, 1993, IEEE T PATTERN ANAL, V15, P707, DOI 10.1109/34.221171
   Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5
   Kazhdan M., 2003, ROTATION INVARIANT S, P156
   Keim DA, 1999, P INT C MAN DAT SIGM, V28, P419
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kortgen M, 2003, P 7 CENTR EUR SEM CO, P34
   Laga H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P75
   LAMDAN Y, 1988, INT C COMP VIS, P238
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z
   Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu Wei, 2006, Journal of Zhejiang University (Science), V7, P1500, DOI 10.1631/jzus.2006.A1500
   Liu Y., 2006, Computer Vision and Pattern Recognition, P2025, DOI DOI 10.1109/CVPR.2006.278
   Liu Y, 2006, IEEE P INT C SHAP MO
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   Mortara M., 2002, INT J SHAPE MODELING, V8, P139
   Novotni M, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P167, DOI 10.1109/SMA.2001.923387
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   O'Hara S, 2010, INTRO BAG FEATURES P
   Ohbuchi R, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P265, DOI 10.1109/PCCGA.2002.1167870
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Paquet E, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P375, DOI 10.1109/MMCS.1999.779233
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Paquet E., 1998, Multimedia Information Analysis and Retrieval. IAPR International Workshop, MINAR'98. Proceedings, P20, DOI 10.1007/BFb0016486
   Paquet E, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P345, DOI 10.1109/IM.1997.603886
   Passalis G, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P374
   PELEG S, 1989, IEEE T PATTERN ANAL, V11, P739, DOI 10.1109/34.192468
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Ricard J, 2005, PATTERN RECOGN LETT, V26, P2174, DOI 10.1016/j.patrec.2005.03.030
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Schmitt W, 2015, SIBGRAPI, P226, DOI 10.1109/SIBGRAPI.2015.51
   Shamir A., 2003, International Journal of Shape Modeling, V9, P203, DOI 10.1142/S0218654303000127
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Suzuki MT, 2000, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2000.884448
   Taimouri V, 2014, GRAPH MODELS, V76, P57, DOI 10.1016/j.gmod.2013.12.001
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tangelder JWH, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P119
   Tung T, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P157, DOI 10.1109/SMI.2004.1314503
   Undurraga C, 2011, LECT NOTES COMPUT SC, V7042, P141, DOI 10.1007/978-3-642-25085-9_16
   Vandeborre J-P, 2002, IEEE 1 INT S 3D DAT, P19
   Vaxman A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778858
   Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389
   Vrani D.V., 2001, P ECMCS 2001 3 EURAS, P271
   Vranic DV, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P177, DOI 10.1109/ICME.2002.1035747
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   Vranic DV, 2004, THESIS
   Yu M, 2003, PROC CVPR IEEE, P656
   Zaharia T, 2001, PROC SPIE, V4476, P175, DOI 10.1117/12.447283
   Zaharia T, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P437, DOI 10.1109/ICME.2002.1035812
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang L., 2004, Proceedings of the IMAC-XXII, A Conf. on Structural Dynamics, Dearborn, P1, DOI [10.1016/j.ultsonch.2010.03.006, DOI 10.1016/J.ULTSONCH.2010.03.006]
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhao X, 2013, J SOFTW, V8, P963
   Zhu ZT, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P279, DOI 10.1109/SPAC.2014.6982699
NR 110
TC 21
Z9 23
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6993
EP 7040
DI 10.1007/s11042-016-3330-5
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400040
DA 2024-07-18
ER

PT J
AU Li, HG
AF Li, Honggui
TI 1D representation of locally linear embedding for image prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Locally linear embedding; Nonlinear dimensionality reduction; Embedding
   and reconstruction; Machine learning; Dictionary learning; Image
   prediction; Image coding; Video coding
ID NONLINEAR DIMENSIONALITY REDUCTION; PARALLEL FRAMEWORK;
   INTRA-PREDICTION; VIDEO
AB Image prediction is a very important step in image and video coding. LLE (locally linear embedding) is a famous algorithm of NLDR (nonlinear dimensionality reduction), and it is capable of projecting high dimensional image blocks into a low dimensional space of embedding. This paper is concerned with the image prediction by 1D representation of LLE algorithm. Two LLE algorithms have been studied. One is the general LLE algorithm, the other is the proposed distance-keeping based LLE algorithm, which has the merit of preserving the distance property in low dimensional space. 1D representation of LLE algorithms can hugely improve the CR (compression ratio). The training input and output of LLE algorithms are employed as training pair for ERA (embedding and reconstruction algorithm) of testing samples, and the training pair is as large as possible to overcome the inherent disadvantage of classical algorithms for image prediction, which only utilize the adjacent image blocks. Three stable ERAs have been proposed. The first is general ERA, the second is nearest neighbor based ERA, and the third is machine learning based ERA. The nearest neighbor based ERA has the best performance if the training samples are sufficient, while the machine learning based ERA has the best performance if the training samples are insufficient. Three DLAs (dictionary learning algorithms) for selecting training samples are presented. The first is exemplars based DLA, the second is K-means clustering based DLA, and the third is sparse representation based DLA. The K-means clustering based DLA has the best performance. A unified framework for intra-frame, inter-frame, multi-view, 3D and multi-view 3D image prediction, has been built according to the proposed algorithms. The performance of proposed algorithms for image prediction has been evaluated by simulation experimentations. The results of simulation experiments indicate that proposed algorithms are able to gain very high PSNR (peak signal to noise ratio). The results of simulation experiments also reveal that 1D representation of distance-keeping based LLE algorithm, machine learning based ERA, and K-means clustering based DLA are very effective and efficient for image prediction.
C1 [Li, Honggui] Yangzhou Univ, Phys Coll Sci & Technol, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Li, HG (corresponding author), Yangzhou Univ, Phys Coll Sci & Technol, Yangzhou, Jiangsu, Peoples R China.
EM hgli@yzu.edu.cn
RI Li, Hong-Ye/AAX-2736-2020
OI Li, Hong-Ye/0000-0001-7427-0706
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Agarwal A, 2008, INT J COMPUT VISION, V78, P15, DOI 10.1007/s11263-007-0072-x
   [Anonymous], 2015, IEEE T SERV COMPUT
   [Anonymous], 2001, ADV NEUR IN
   Blasi SG, 2015, IEEE T CIRC SYST VID, V25, P798, DOI 10.1109/TCSVT.2014.2359097
   Chen JZ, 2013, SIGNAL PROCESS-IMAGE, V28, P1202, DOI 10.1016/j.image.2013.08.001
   Cherigui S, 2013, IEEE T IMAGE PROCESS, V22, P1161, DOI 10.1109/TIP.2012.2227772
   Daza-Santacoloma G, 2012, NEUROCOMPUTING, V80, P19, DOI 10.1016/j.neucom.2011.09.015
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   Dey B, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445631
   Dickscheid T, 2011, INT J COMPUT VISION, V94, P154, DOI 10.1007/s11263-010-0340-z
   Farid MS, 2015, IEEE T IMAGE PROCESS, V24, P205, DOI 10.1109/TIP.2014.2374533
   Goulermas JY, 2007, IEEE T NEURAL NETWOR, V18, P1683, DOI 10.1109/TNN.2007.902730
   Gudivada VN, 2015, COMPUTER, V48, P20, DOI 10.1109/MC.2015.62
   Guillemot C, 2013, INT CONF ACOUST SPEE, P2006, DOI 10.1109/ICASSP.2013.6638005
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu W, 2015, IEEE SIGNAL PROC LET, V22, P1913, DOI 10.1109/LSP.2015.2446683
   Kamisli F, 2015, IEEE T IMAGE PROCESS, V24, P1247, DOI 10.1109/TIP.2015.2400818
   Kouropteva O, 2005, PATTERN RECOGN, V38, P1764, DOI 10.1016/j.patcog.2005.04.006
   Martin Aurelie, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1255
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Monnig ND, 2014, APPL COMPUT HARMON A, V37, P162, DOI 10.1016/j.acha.2013.10.004
   Nichols JM, 2011, EXPERT SYST APPL, V38, P13472, DOI 10.1016/j.eswa.2011.04.146
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Puri A, 2015, INT C 3D IM IC3D LIE, P1
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shan RF, 2014, CHEMOMETR INTELL LAB, V131, P31, DOI 10.1016/j.chemolab.2013.12.002
   Song X, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/298356
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Tao H, 2002, INT J COMPUT VISION, V50, P111, DOI 10.1023/A:1020389714861
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Trocan M, 2014, MULTIMED TOOLS APPL, V72, P95, DOI 10.1007/s11042-012-1330-7
   Türkan M, 2012, IEEE T IMAGE PROCESS, V21, P1885, DOI 10.1109/TIP.2011.2170700
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yeh CH, 2015, IEEE T MULTIMEDIA, V17, P1508, DOI 10.1109/TMM.2015.2449659
   Yeo C, 2011, INT J COMPUT VISION, V94, P267, DOI 10.1007/s11263-011-0427-1
   Yong R, 2014, IEEE MULTIMEDIA, V21, P2
   Zhang CS, 2004, PATTERN RECOGN, V37, P325, DOI 10.1016/j.patcog.2003.07.005
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao XM, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-20
   Zhou Y, 2013, IEEE SIGNAL PROC LET, V20, P335, DOI 10.1109/LSP.2013.2246513
NR 44
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8651
EP 8676
DI 10.1007/s11042-016-3491-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800045
DA 2024-07-18
ER

PT J
AU Rahman, MA
AF Rahman, Md. Abdur
TI Web-based multimedia hand-therapy framework for measuring forward and
   inverse kinematic data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia for hand-therapy; Kinematic data; LEAP; Hand gesture tracking
ID MOTION; REHABILITATION; ACCURACY; VISION; JOINT
AB Recognizing rotational and angular hand movements using a non-invasive way is a challenging task. In this paper, we present a web-based multimedia hand-Therapy framework that can dynamically provide therapy services to a patient having Hemiplegia disability. Using off the shelf 3D motion control sensor called LEAP, the framework can detect, recognize and track different high-level therapeutic movements, both rotational as well as angular, originated from different joints of a Hemiplegic patient's hand and deduce live kinematic data from these movements. The obtained kinematic data consists of a wide span of hand joint and therapy parameters that is assumed to help medical professionals in their clinical decision making. The multimedia environment uses forward kinematics to receive the live sensory data from the 3D motion tracking sensors and uses inverse kinematics to analyze the sensory data streams in real-time. A subject performs a rehabilitation therapy prescribed by the physician and using both forward and inverse kinematics, the system validates the angular and rotational motion of the joints with respect to the correct therapeutic posture and provides live feedback to the subject. The proposed method is non-invasive as the patient does not need to wear any external devices in the hand and hence can perform therapy exercises even at home. The system uses serious game interfaces to provide immersive and engaging perspective to the therapy domain. To the best of our knowledge, this study is the first of its kind to propose a non-invasive way of tracking live forward and inverse kinematic data in the context of hand therapy. We share the implementation details and our initial test results. Finally, our experiment shows that LEAP has the potential to be used for obtaining kinematic data from primitive and complex hand therapies.
C1 [Rahman, Md. Abdur] Umm Al Qura Univ, Dept Comp Sci, Coll Comp & Informat Syst, Adv Media Lab, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Rahman, MA (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Coll Comp & Informat Syst, Adv Media Lab, Mecca, Saudi Arabia.
EM rahman@mcrlab.uottawa.ca
RI Guizani, Mohsen/AAX-4534-2021; Rahman, Abdur/AAG-9302-2019
OI Guizani, Mohsen/0000-0002-8972-8094; Rahman, Abdur/0000-0002-4105-0368
CR Alamri A, 2012, INT J COMP SCI SPORT, V9, P2
   Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Anderson S. A., 1993, ANATOMY OF MOVEMENT
   [Anonymous], 2009, Biomechanics and motor control of human movement
   [Anonymous], 2005, P 2005 ACM SIGGRAPHE, DOI DOI 10.1145/1073368.1073414
   Aziz O, 2007, SURG INNOV, V14, P83, DOI 10.1177/1553350607302326
   Baran M, 2011, IEEE ENG MED BIO, P7602, DOI 10.1109/IEMBS.2011.6091874
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Cubero Sam., 2006, Industrial-Robotics-Theory-Modelling-Control, P964
   DOLPHIN JA, 1965, J BONE JOINT SURG AM, VA 47, P161, DOI 10.2106/00004623-196547010-00011
   Erdemir A, 2007, CLIN BIOMECH, V22, P131, DOI 10.1016/j.clinbiomech.2006.09.005
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gabel Moshe, 2012, Annu Int Conf IEEE Eng Med Biol Soc, V2012, P1964, DOI 10.1109/EMBC.2012.6346340
   Gips J., 2007, DISABILITY REHABILIT, V2, P189
   Goto A, 2014, CLIN ORTHOP RELAT R, V472, P1106, DOI 10.1007/s11999-013-3066-8
   Gustus A, 2012, BIOL CYBERN, V106, P741, DOI 10.1007/s00422-012-0532-4
   Hanna SE, 2008, PHYS THER, V88, P596, DOI 10.2522/ptj.20070314
   Harley L, 2011, LECT NOTES COMPUT SC, V6764, P167, DOI 10.1007/978-3-642-21619-0_22
   Herman I., 2007, PHYS HUMAN BODY
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Hondori HM, 2013, P 2013 C MED MEETS V
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79, DOI DOI 10.1145/2159616.2159630.6,17
   HUME MC, 1990, J HAND SURG-AM, V15A, P240, DOI 10.1016/0363-5023(90)90102-W
   Jenkins M, 1998, J HAND SURG-BRIT EUR, V23B, P796, DOI 10.1016/S0266-7681(98)80100-9
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kim D, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Lange B, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P170
   Ma M, P IEEE INT C MAN CYB, P1872
   MALLON WJ, 1991, J HAND SURG-AM, V16A, P882, DOI 10.1016/S0363-5023(10)80155-8
   Memh F., 2011, P 19 ACM INT C MULT, P807, DOI DOI 10.1145/2072298.2072469
   MINEAR WL, 1956, PEDIATRICS, V18, P841
   Rahman MA, 2013, INT C MULT RETR DALL, P16
   Rahman MA, 2013, IEEE HEALTHCOM, P9
   Rahman MdA, 2013, HDB INNOVATIVE MED T
   Saini S., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P55, DOI 10.1109/ICCISci.2012.6297212
   Skarilova B, 1996, ACTA CHIR PLAST, V38
   Smahel Z, 2004, ACTA CHIR PLAST, V46
   Stanley F., 2000, CLIN DEV MED
   Stone EE, 2011, IEEE ENG MED BIO, P6491, DOI 10.1109/IEMBS.2011.6091602
   Sueda S., 2008, ACM T GRAPH SIGGRAPH, V27, P3
   Wang FF, 2009, IEEE I SYMP SUST SYS, P271
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
   [No title captured]
NR 44
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8227
EP 8255
DI 10.1007/s11042-016-3447-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800028
DA 2024-07-18
ER

PT J
AU Syarif, MA
   Ong, TS
   Teoh, ABJ
   Tee, C
AF Syarif, Munalih Ahmad
   Ong, Thian Song
   Teoh, Andrew B. J.
   Tee, Connie
TI Enhanced maximum curvature descriptors for finger vein verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Finger vein; Support vector machine; Histogram of oriented
   gradient; Maximum curvature
AB Maximum Curvature Method (MCM) is one of the promising methods for finger vein verification. MCM scans the curvature of the vein image profiles within a finger for feature extraction. However, the quality of the image can be poor due to variations in illumination and sensor conditions. Furthermore, traditional MCM matching of the vein pattern requires extensive processing time. To address these limitations, we propose an integrated Enhanced Maximum Curvature (EMC) method with Histogram of Oriented Gradient (HOG) descriptor for finger vein verification. Unlike MCM, EMC incorporates an enhancement mechanism to extract small vein delineation that is hardly visible in the extracted vein patterns. Next, HOG is applied instead of image binarization to convert a two-dimensional vein image into a one-dimensional feature vector for efficient matching. The HOG descriptor is able to characterize the local spatial representation of a finger vein by capturing the gradient information effectively. The proposed method is evaluated based on two datasets namely the PKU Finger Vein Database (V4) and SDUMLA-HMT finger vein database. Experiments show promising verification results with equal error rates as low as 0.33 % for DB1 and 0.14 % for DB2 respectively, when EMC+HOG+SVM is applied.
C1 [Syarif, Munalih Ahmad; Ong, Thian Song; Tee, Connie] Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
   [Teoh, Andrew B. J.] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Multimedia University; Yonsei University
RP Ong, TS (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
EM tsong@mmu.edu.my
RI Teoh, Andrew Beng Jin/F-4422-2010; Ong, Thian Song/Q-6932-2018
OI Ong, Thian Song/0000-0002-5867-9517; Tee, Connie/0000-0002-0901-3831
FU Science Fund MOSTI Malaysia [MMUE/130153]
FX This research uses two finger vein databases, PKU Finger Vein Database
   and SDUMLA, provided by Artificial Intelligence Lab of Peking University
   and Shandong University, respectively. This research was supported by
   Science Fund MOSTI Malaysia under grants MMUE/130153.
CR Aziz W. N., 2013, AUST J BASIC APPL SC, V7, P751
   Bertozzi M, 2007, P 2007 IEEE WA
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dong S, 2015, KSII T INTERNET INF, V9, P4126, DOI 10.3837/tiis.2015.10.020
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Hartung D, 2013, INT CONF BIOMETR
   Hsu W, 2010, PRACTICAL GUIDE SUPP
   Huang B, 2010, 2010 INT C PATT REC
   Joon HC, 2009, P SOC PHOTO-OPT INS, P2009
   Juang CF, BLOCK HISTOGRAM BASE
   장영균, 2008, [KIPS Transactions on Software and Data Engineering, 정보처리학회논문지. 소프트웨어 및 데이터 공학], V15, P275
   Kang WX, 2012, PATTERN RECOGN LETT, V33, P1916, DOI 10.1016/j.patrec.2012.02.020
   Kohler T, 2013, 2013 IEEE 26 INT S P
   Lee EC, 2009, FINGER VEIN RECOGNIT, P179
   Lian Z, 2008, 2 INT C BION BIM ENG
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2005, IAPR C MACH VIS APPL, V2005
   Ong TS, 2013, 2013 6 INT C IM SIGN
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang K, 2010, P 8 WORLD C INT CONT
   Wen X, 2010, 2010 AS PAC C POW EL
   Xi X, 2013, SENS
   Yanagawa T., 2007, HUMAN FINGER VEIN IM
   Yang GP, 2012, SENSORS-BASEL, V12, P1738, DOI 10.3390/s120201738
   Yang J., 2010, Finger-Vein Recognition Based on a Bank Gabor Filters
NR 28
TC 49
Z9 51
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6859
EP 6887
DI 10.1007/s11042-016-3315-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400035
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Wang, F
   Zhang, XQ
AF Tang, Zhenjun
   Wang, Fei
   Zhang, Xianquan
TI Image encryption based on random projection partition and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image content protection; Projection partition; Arnold
   transform; Chaotic system; Skew tent map
ID SCHEME; COMPRESSION; TRANSFORM; ALGORITHM; ROBUST
AB Image encryption is a useful technique of multimedia security and has been widely used in content protection, image authentication, data hiding, and so on. In this paper, we investigate the use of projection partition in image encryption, and then design an efficient image encryption algorithm based on random projection partition and chaotic system. Specifically, our algorithm randomly divides the input image into overlapping blocks. For each block, our algorithm further divides it into a set of projection lines. And then, chaotic system is exploited to generate a secret data pool. Finally, data encryption is done by random projection line swapping and XOR operation between projection line and secret sequence selected from the secret data pool. Many experiments are conducted to validate efficiency of our algorithm. Comparisons are also done and the results show that our algorithm is better than some popular algorithms.
C1 [Tang, Zhenjun; Wang, Fei; Zhang, Xianquan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Tang, Zhenjun; Wang, Fei; Zhang, Xianquan] Guangxi Normal Univ, Dept Comp Sci, 15 Yucai Rd, Guilin 541004, Peoples R China.
C3 Guangxi Normal University; Guangxi Normal University
RP Tang, ZJ (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Tang, ZJ (corresponding author), Guangxi Normal Univ, Dept Comp Sci, 15 Yucai Rd, Guilin 541004, Peoples R China.
EM tangzj230@163.com; 935663538@qq.com; zxq6622@163.com
FU National Natural Science Foundation of China [61562007, 61300109,
   61363034]; Guangxi Natural Science Foundation [2015GXNSFDA139040];
   Guangxi "Bagui Scholar" Teams for Innovation and Research; Scientific
   and Technological Research Projects in Guangxi Higher Education
   Institutions [YB2014048]; Project of the Guangxi Key Lab of Multi-source
   Information Mining Security [15-A-02-02, 14-A-02-02, 13-A-03-01];
   Guangxi Collaborative Innovation Center of Multi-source Information
   Integration and Intelligent Processing
FX The authors would like to thank the anonymous referees for their
   valuable comments and suggestions. This work is partially supported by
   the National Natural Science Foundation of China (61562007, 61300109,
   61363034), the Guangxi Natural Science Foundation (2015GXNSFDA139040),
   Guangxi "Bagui Scholar" Teams for Innovation and Research, the
   Scientific and Technological Research Projects in Guangxi Higher
   Education Institutions (YB2014048), the Project of the Guangxi Key Lab
   of Multi-source Information Mining & Security (15-A-02-02, 14-A-02-02,
   13-A-03-01), and Guangxi Collaborative Innovation Center of Multi-source
   Information Integration and Intelligent Processing.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Ginesu G, 2006, P INT C AC SPEECH SI, P313
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Naeem EA, 2014, J SYST SOFTWARE, V97, P118, DOI 10.1016/j.jss.2014.07.026
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Qi Dongxu, 1999, J NO POLYTECHNIC U, V11, P24
   Qin C, 2012, FUND INFORM, V120, P59, DOI 10.3233/FI-2012-749
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   TANG Z, 2011, ICIC EXPRESS LETT B, V2, P1297
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang ZJ, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P183, DOI 10.1109/MUE.2009.42
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Van de Ville D, 2004, IEEE T CIRC SYST VID, V14, P892, DOI 10.1109/TCSVT.2004.828325
   Wang Q, 2012, OPT COMMUN, V285, P4317, DOI 10.1016/j.optcom.2012.07.033
   Wang Y, 2014, OPT COMMUN, V330, P91, DOI 10.1016/j.optcom.2014.05.032
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe O, 2004, IEEE IMAGE PROC, P3435
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang XP, 2014, MULTIMED TOOLS APPL, V72, P489, DOI 10.1007/s11042-013-1392-1
   Zhenjun Tang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P237, DOI 10.1007/978-3-642-35236-2_24
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
   Zuras D., 2008, 7542008 IEEE, V754-2008, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2008.5976968]
NR 33
TC 27
Z9 28
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8257
EP 8283
DI 10.1007/s11042-016-3476-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800029
DA 2024-07-18
ER

PT J
AU Wuttidittachotti, P
   Daengsi, T
AF Wuttidittachotti, Pongpisit
   Daengsi, Therdpong
TI VoIP-quality of experience modeling: E-model and simplified E-model
   enhancement using bias factor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; QoE modeling; E-model; Subjective tests; MOS; Thai
ID SPEECH; NETWORKS; PREDICTION
AB The E-model is a non-intrusive measurement method that many researchers have applied to the study of VoIP quality measurement. While the Simplified E-model is a modified version from the original, it can still be used as an alternative solution. Nevertheless, it has been found that the E-model and the Simplified E-model still require further improvement. Therefore, to enhance the original E-model, this paper proposes a new factor. Moreover, the Simplified E-model has also been enhanced by the same approach. Based-on the Thai environment, the new factor called Thai Bias factor, can be computed by subtracting the subjective test results using conversation tests with native Thai users from the objective test results using an E-model tool and the Simplified E-model calculation. Of course, both E-mode tests and conversation tests were conducted with the same VoIP system and test scenarios. The Enhanced E-model and the Simplified E-model using the Thai Bias factor were then evaluated by comparing the test set from other groups of native Thai users. After evaluation of the improved models, it has been found that the Enhanced E-model and the enhanced Simplified E-model can gain higher confidence. The Enhanced E-model delivers improved accuracy and reliability at approximately more than 20 % when compared to an available E-model tool, while the Enhanced Simplified E-model delivers improved performance at approximately more than 46 % when compared to Simplified E-model calculation.
C1 [Wuttidittachotti, Pongpisit] King Mongkuts Univ Technol North Bangkok, Fac Informat Technol, Dept Data Commun & Networking, Bangkok, Thailand.
   [Daengsi, Therdpong] JADS Comm Ltd, Dept Enterprise Serv, Bangkok, Thailand.
C3 King Mongkuts University of Technology North Bangkok
RP Daengsi, T (corresponding author), JADS Comm Ltd, Dept Enterprise Serv, Bangkok, Thailand.
EM pongpisitw@kmutnb.ac.th; therdpong1@yahoo.com
RI Daengsi, Therdpong/AAH-9231-2019
OI Daengsi, Therdpong/0000-0002-7569-8197
FU Graduate College and the Faculty of Information Technology, KMUTNB
FX Thank you to the Graduate College and the Faculty of Information
   Technology, KMUTNB for part of funding support. Thank you to SCP Systems
   Company Ltd. for providing E-model tools for experiments. Thanks all
   participants and staff/lecturers in KMUTNB, who were involved,
   particularly Assoc. Prof. Dr. Saowanit Suparungsee the old advisor of
   the second author and Mr. Gary Sherriff (for his English editing
   support). Finally, to express the deepest gratitude to the old advisor
   of the second author who sadly passed away in 2010, the contribution of
   this paper is especially dedicated to Dr. Gareth Clayton.
CR Al-Akhras M, 2009, NEUROCOMPUTING, V72, P2595, DOI 10.1016/j.neucom.2008.10.019
   Altbach P., 2004, ASIAN U HIST PERSPEC, P13
   [Anonymous], P GLOBECOM
   [Anonymous], SONGKLANAKARIN J SCI
   Assem H., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P927, DOI 10.1109/ICCNC.2013.6504214
   Batteram H, 2010, BELL LABS TECH J, V15, P175, DOI 10.1002/bltj.20431
   Boutremans C, 2002, P 12 INT WORKSH NETW, P63
   Chunlei Jiang, 2011, Proceedings of the 2011 International Conference on Internet Computing and Information Services (ICICIS 2011), P499, DOI 10.1109/ICICIS.2011.130
   Côté N, 2011, T-LAB SER TELECOMMUN, P1, DOI 10.1007/978-3-642-18463-5
   Daengsi T, 2010, P O COCOSDA2010 KATH
   Daengsi T., 2012, IJCIM, V20, P21
   Daengsi T., 2012, THESIS
   Daengsi T, 2015, INT CONF UBIQ FUTUR, P386, DOI 10.1109/ICUFN.2015.7182571
   Daengsi T, 2013, IEEE GLOB COMM CONF, P1329, DOI 10.1109/GLOCOM.2013.6831258
   De Pessemier T, 2015, MULTIMED TOOLS APPL, V74, P5873, DOI 10.1007/s11042-014-1895-4
   De Rango F, 2006, INT J COMPUT SCI NET, V6, P140
   Ding LJ, 2007, SPEECH COMMUN, V49, P477, DOI 10.1016/j.specom.2007.04.003
   Ding LJ, 2003, GLOB TELECOMM CONF, P3974, DOI 10.1109/GLOCOM.2003.1258975
   Fluke Corporation, 2005, QUAL MAN TROUBL TECH
   Gandour J, 1998, NEUROREPORT, V9, P2115, DOI 10.1097/00001756-199806220-00038
   Goudarzi M, 2008, THESIS
   Hiwasaki Y, 2009, IEEE COMMUN MAG, V47, P110, DOI 10.1109/MCOM.2009.5273817
   Huang YT, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/478202
   ITU-T, 2009, QUEST 7 12 METH TOOL
   ITU-T, 2011, ITU T REC G 107 E MO
   ITU-T, 2007, ITU T REC P 805 SUBJ
   ITU-T, 2001, ITU REC P 862 PERC E
   ITU- T, 2003, ITU T REC G 114 ON W
   ITU-T, 1996, ITU T REC P 800 METH
   ITU-T, 2009, ITU T REC G 107 E MO
   ITU-T, 2015, ACC STAND
   ITU-T Test Signals for Telecommunication Systems, 2015, ITU T TEST SIGNALS T
   Jiuchun Ren, 2010, 2010 3rd International Conference on Information Sciences and Interaction Sciences (ICIS), P256, DOI 10.1109/ICICIS.2010.5534748
   Johannesson NO, 1997, IEEE COMMUN MAG, V35, P70, DOI 10.1109/35.568213
   Karapantazis S, 2009, COMPUT NETW, V53, P2050, DOI 10.1016/j.comnet.2009.03.010
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Laghari KUR, 2013, J UNIVERS COMPUT SCI, V19, P1718
   Mahdi AE, 2009, DIGIT SIGNAL PROCESS, V19, P79, DOI 10.1016/j.dsp.2007.11.006
   Markopoulou A, 2004, IEEE INFOCOM SER, P2307
   Markopoulou A, 2006, COMPUT COMMUN, V29, P1590, DOI 10.1016/j.comcom.2005.07.011
   MathWorks, 2013, CURV FITT TOOLB
   Narbutt M, 2005, P MESAQIN 2005 PRAG
   Ong HC, 2011, INT PROC COMPUT SCI, V7, P56
   Psytechnics, 2003, COMP SUBJ LIST QUAL
   Radonjic V, 2012, ELEKTRON ELEKTROTECH, V18, P113, DOI 10.5755/j01.eee.18.8.2640
   Ren JC, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1624, DOI 10.1109/ICALIP.2008.4590151
   Sodanil M, 2010, INT J COMPUT SCI NET, V10, P103
   Soontayatron S., 2010, THESIS
   Sun L., 2013, GUIDE VOICE VIDEO IP
   Takahashi A, 2006, IEEE T AUDIO SPEECH, V14, P1984, DOI 10.1109/TASL.2006.883261
   Thanasankit T., 2002, ASIAN ACAD MANAGEMEN, V7, P103
   Triyason T, 2015, ELEKTRON ELEKTROTECH, V21, P82, DOI 10.5755/j01.eee.21.1.7612
   Vatanasakdakul S, 2006, P ECIS 2006 GOT
   Voznak M., 2011, INT J MATH MOD MET S, V6, P1301
   Wutiwiwatchsi C, 2007, SPEECH COMMUN, V49, P8, DOI 10.1016/j.specom.2006.10.004
   Wuttidittachotti P, 2013, INT CONF UBIQ FUTUR, P401, DOI 10.1109/ICUFN.2013.6614850
   Zhang HB, 2005, SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERNG, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING AND FIRST AICS INTERNATIONAL WORKSHOP ON SELF-ASSEMBLING WIRELESS NETWORKS, PROCEEDINGS, P214
   Zhou X, 2006, P IPS MOME 2006 SALZ
NR 59
TC 10
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8329
EP 8354
DI 10.1007/s11042-016-3389-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800032
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Sun, Z
   Jiang, P
   Huang, Y
   Peng, JL
AF Zhang, Yan
   Sun, Zheng
   Jiang, Peng
   Huang, Yan
   Peng, Jingliang
TI Hybrid image retargeting using optimized seam carving and scaling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid image retargeting; Bi-directional seam carving; Seam carving;
   Scaling; Importance map
AB We present a novel hybrid scheme for content-aware image retargeting that allows retargeting images into arbitrary dimensions while preserving visually prominent features and minimizing global information loss. One of the novelties in our scheme is an optimized importance map incorporating the impacts of the gradient map, context-aware saliency map, skin map and Canny edge map. Another novelty is a systematic utilization of both seam carving and scaling for a good balance between information loss and image stretching, where the number of seam operations along each dimension is adaptively determined by a non-linear optimization process. Furthermore, a switching factor is added to the optimization for interactive user control of the switching point between information loss and image stretching. In addition, we propose an optional step to accelerate seam carving by restricting the optimal seam search to a down-sampled thumbnail and the local regions of the input image.
C1 [Zhang, Yan] Shandong Jianzhu Univ, Sch Sci, Jinan, Peoples R China.
   [Zhang, Yan; Jiang, Peng; Huang, Yan; Peng, Jingliang] Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Sun, Zheng] Univ Southern Mississippi, Sch Comp, Hattiesburg, MS 39402 USA.
   [Sun, Zheng] Shandong Univ Technol, Sch Comp Sci & Technol, Zibo, Peoples R China.
C3 Shandong Jianzhu University; Shandong University; University of Southern
   Mississippi; Shandong University of Technology
RP Zhang, Y (corresponding author), Shandong Jianzhu Univ, Sch Sci, Jinan, Peoples R China.; Zhang, Y; Huang, Y (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM zhangyanxx@hotmail.com; yan.h@sdu.edu.cn
RI Zhang, Yan/HZL-5184-2023
OI Zhang, Yan/0000-0002-1282-4520
FU National Natural Science Foundation of China [61303083, 61472223]
FX Authors thank three anonymous reviewers for their valuable suggestions
   to improve the presentation of this paper. This work is supported by the
   National Natural Science Foundation of China (Grants No.s 61303083,
   61472223).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, P 17 ACM S VIRTUAL R
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], ERA INTERACTIVE MEDI
   [Anonymous], GM6010 GM6015 PROGR
   [Anonymous], TRENDS TOPICS COMPUT
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Chen R.C., 2010, 2010 IEEE International Conference on Fuzzy Systems, P1
   Domingues D, 2010, IEEE IMAGE PROC, P901, DOI 10.1109/ICIP.2010.5653984
   Dong WM, 2012, J COMPUT SCI TECH-CH, V27, P121, DOI 10.1007/s11390-012-1211-6
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hwang DS, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1029, DOI 10.1109/ICME.2008.4607613
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Liang Y, 2012, SIGNAL PROCESS, V92, P1243, DOI 10.1016/j.sigpro.2011.11.018
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Mansfield A, 2010, LECT NOTES COMPUT SC, V6311, P143, DOI 10.1007/978-3-642-15549-9_11
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Simakov D, 2008, PROC CVPR IEEE, P3887
   Subramanian Sushil, 2008, 2008 IEEE Conference on Soft Computing in Industrial Applications. SMCia/08, P78, DOI 10.1109/SMCIA.2008.5045939
   Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Thilagam K., 2012, International Journal of Computer Applications, P24
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Yang J., 1997, Skin-color modeling and adaptation, P687
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
NR 40
TC 13
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8067
EP 8085
DI 10.1007/s11042-016-3318-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800021
DA 2024-07-18
ER

PT J
AU Ke, CH
   Yang, CY
   Chen, JL
AF Ke, Chih-Heng
   Yang, Chong-Yi
   Chen, Jiann-Liang
TI A novel mapping mechanism for MPEG-4 video delivery over IEEE 802.11e
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 802.11e; Quality of video delivery; Wireless local area network; MPEG-4
AB IEEE 802.11e has been introduced to support quality of service (QoS) in WLANs by allocating different traffics to four access categories. Cross-layer design is a method to improve the transmission quality of multimedia over wireless networks. However, when the fragmented packets of a single frame are allocated to different AC queues, out-of-order delivery may occur. Then the receiving node requires more buffer space to absorb the out-of-order packets. Therefore, even with a significance classification mechanism, the quality of the video transmission may still be limited due to the occurrence of out-of-order delivery and the transmission of information that becomes useless to the receiver. Therefore, this work developed a novel mapping mechanism (NMM) to improving the quality of MPEG-4 video delivery over IEEE 802.11e networks. The NMM considers the action that was taken on packet of the video frame that had been previously transmitted to resolve the out-of-order delivery by allocating them to the same AC queue as the previously process if possible. Furthermore, the proposed mechanism NMM takes more aggressive scheme to protect more important frame packets from being dropped. In order to evaluate the quality of MPEG-4 video delivery over IEEE 802.11e networks by the proposed mechanism, this work adopted two evaluation metrics, which is called Peak to Signal Noise Ratio (PSNR) and the ratio of frames loss. The simulation results demonstrate that, in terms of both PSNR and the ratio of frames loss, the proposed scheme outperforms exiting schemes such as EDCA (Enhanced Distributed Channel Access) and adaptive mapping.
C1 [Ke, Chih-Heng] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Jinning, Taiwan.
   [Yang, Chong-Yi; Chen, Jiann-Liang] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CY (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM smallko@gmail.com; chongyi.yang@gmail.com; lchen@mail.ntust.edu.tw
FU National Project of Taiwan [MOST 103-2221-E507-001]; Ministry of Science
   and Technology, Government of Taiwan
FX Foundation item: The National Project of Taiwan (No.: MOST
   103-2221-E507-001). Authors are grateful to Ministry of Science and
   Technology, Government of Taiwan for financial support to carry out this
   work.
CR Foh CH, 2007, IEEE T CIRC SYST VID, V17, P1665, DOI 10.1109/TCSVT.2007.903808
   Hsing-Lung Chen, 2008, Fourth International Conference on Wireless and Mobile Communications. ICWMC 2008, P241, DOI 10.1109/ICWMC.2008.35
   Kim JO, 2005, GLOB TEL C 2005 GLOB, V6
   Lai WP, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-59
   Lin CH, 2009, TELECOMMUN SYST, V42, P223, DOI 10.1007/s11235-009-9182-9
   Majkowski J., 2006, VEH TECHN C VTC 2006, P1
   Majkowski J, 2006, SOFTCOM 2006: INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND COMPUTER NETWORKS, P66
   Mangold S, 2003, IEEE WIREL COMMUN, V10, P40, DOI 10.1109/MWC.2003.1265851
   Siris V. A., 2006, P 2006 INT S WORLD W, P419
   Takeuchi S., 2005, P 5 INT C INF COMM S, P659
   Xiao X, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P186, DOI 10.1109/IMSNA.2013.6743247
   Yan W, 2004, WRKS LOC METRO AREA, P51, DOI 10.1109/LANMAN.2004.1338399
   Zheng Wan, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P180, DOI 10.1109/INFCOMW.2011.5928803
NR 13
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5937
EP 5949
DI 10.1007/s11042-015-2791-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500057
DA 2024-07-18
ER

PT J
AU Darabi, K
   Ghinea, G
AF Darabi, Kaveh
   Ghinea, Gheorghita
TI User-centred personalised video abstraction approach adopting SIFT
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; SIFT; Personalization; Saliency score; Relevancy
   level
AB The rapid growth of digital video content in recent years has imposed the need for the development of technologies with the capability to produce condensed but semantically rich versions of original input video. Consequently, the topic of Video Summarisation is becoming increasingly popular in the multimedia community and numerous video abstraction approaches have been proposed. Creating personalised video summaries remains a challenge, though. Accordingly, in this paper we propose a methodology for generating user-tailored video abstracts. First, video frames are scored by a group of video experts (operators) according to audio, visual and textual content of the video. Later, SIFT visual features are adopted in our proposed approach to identify the video scenes' semantic categories. Fusing this retrieved data with pre-built users' profiles will provide a metric to update the previously averaged saliency scores assigned by video experts to each frame in accordance to users' priorities. In the next stage, the initial averaged scores of the frames are updated based on the end-users' generated profiles. Eventually, the highest scored video frames alongside the auditory and textual content are inserted into final digest Experimental results showed the effectiveness of this method in delivering superior outcomes comparing to our previously recommended algorithm and the three other automatic summarisation techniques.
C1 [Darabi, Kaveh; Ghinea, Gheorghita] Brunel Univ, Dept Comp Sci, Kingston Lane, London, England.
C3 Brunel University
RP Ghinea, G (corresponding author), Brunel Univ, Dept Comp Sci, Kingston Lane, London, England.
EM kaveh.darabi@brunel.ac.uk; george.ghinea@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580
CR Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2014, 2014 IEEE INT C MULT
   [Anonymous], 2014, 2014 IEEE INT C MULT
   Bhatt Rajen B., 2009, Proceedings 2009 7th International Conference on ICT and Knowledge Engineering (ICT & Knowledge Engineering 2009), P63, DOI 10.1109/ICTKE.2009.5397324
   Carvajal J, 2014, IEEE WINT CONF APPL, P769, DOI 10.1109/WACV.2014.6836025
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Darabi K, 2014, INT CONF MULTIMED, P112, DOI 10.1109/ICMCS.2014.6911240
   Darabi K, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P310, DOI 10.1109/ChinaSIP.2014.6889254
   Darabkh K. A., 2014, P 2014 IEEE INT MULT, P1
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fukumura S, 2003, 2003 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS, AND SIGNAL PROCESSING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P605
   Guo Y, 2012, IEEE MULTIMEDIA, V12, P717
   Han B., 2011, 2011 IEEE WORKSH APP, P51
   Han JW, 2014, INFORM SCIENCES, V281, P781, DOI 10.1016/j.ins.2013.12.039
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hari R, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P245, DOI 10.1109/RAICS.2013.6745481
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Hopfgartner F, 2010, MULTIMEDIA SYST, V16, P255, DOI 10.1007/s00530-010-0189-6
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li X., 2006, MULTIMEDIA 06, P607, DOI DOI 10.1145/1180639.1180764
   Liu Yang, 2014, ScientificWorldJournal, V2014, P476219, DOI 10.1155/2014/476219
   Liu YL, 2014, IEEE IJCNN, P3909, DOI 10.1109/IJCNN.2014.6889581
   Lu S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1959, DOI 10.1109/ICME.2004.1394645
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Mahmoud KM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P811, DOI 10.1109/ICCVW.2013.111
   Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Money AG, 2009, DISPLAYS, V30, P59, DOI 10.1016/j.displa.2008.12.003
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Park HS, 2011, INFORM SYST, V36, P1124, DOI 10.1016/j.is.2011.04.005
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Takahashi Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1171
   Takahashi Y., 2005, Advances in Multimedia Information Processing - PCM 2004, V3332, P272
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   이원범, 2013, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V18, P185, DOI 10.5909/JBE.2013.18.2.185
   Wu S.-Y., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, P1531
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   You JY, 2009, EUROCON 2009: INTERNATIONAL IEEE CONFERENCE DEVOTED TO THE 150 ANNIVERSARY OF ALEXANDER S. POPOV, VOLS 1- 4, PROCEEDINGS, P1358, DOI 10.1109/EURCON.2009.5167816
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
   Zimmerman DW, 1997, J EDUC BEHAV STAT, V22, P349, DOI 10.3102/10769986022003349
NR 43
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2353
EP 2378
DI 10.1007/s11042-015-3210-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000034
DA 2024-07-18
ER

PT J
AU Guo, M
   Hou, XH
   Ma, YT
   Wu, XJ
AF Guo, Min
   Hou, Xiaohong
   Ma, Yuting
   Wu, Xiaojun
TI Facial expression recognition using ELBP based on covariance matrix
   transform in KLT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Extended local binary pattern; Covariance
   matrix transform; KLT; Machine learning
ID INVARIANT TEXTURE CLASSIFICATION; FEATURE-SELECTION
AB According to the deficiencies of Local Binary Pattern (LBP), the dimension of extraction is large, and it is not conducive to describe all characteristics of image texture, this paper proposes a novel facial expression recognition algorithm "K-ELBP" which uses uniform patterns of Extended Local Binary Pattern (ELBP), and combines with the covariance matrix transform in K-L transform (KLT). In this paper, ELBP is used for the first step to extract the feature matrix of expression images, then covariance matrix transform is applied to the ELBP matrix for reducing the dimension, which aims at extracting the main feature vectors. And the best recognition performance is obtained by using SVM for classification. A series of experiments by using different divided methods are designed to evaluate the effects of characteristics which are extracted by K-ELBP algorithm. According to the results of the experiments, the proposed K-ELBP algorithm can extract facial expression features effectively, and the rates of recognition are satisfying.
C1 [Guo, Min; Hou, Xiaohong; Ma, Yuting; Wu, Xiaojun] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   [Guo, Min; Hou, Xiaohong; Ma, Yuting; Wu, Xiaojun] Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
C3 Shaanxi Normal University
RP Guo, M (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.; Guo, M (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
EM guomin@snnu.edu.cn
FU National Natural Science Foundation of China [11172342, 11372167];
   Fundamental Research Funds for the Central Universities [GK201405007];
   Interdisciplinary Incubation Project of Learning Science of Shaanxi
   Normal University; Program of Key Science and Technology Innovation Team
   in Shaanxi Province [2014KTC-18]
FX This work was supported by the National Natural Science Foundation of
   China (No. 11172342, 11372167), the Fundamental Research Funds for the
   Central Universities (No. GK201405007), Interdisciplinary Incubation
   Project of Learning Science of Shaanxi Normal University, the Program of
   Key Science and Technology Innovation Team in Shaanxi Province (No.
   2014KTC-18).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2006, IEEE C COMP VIS PATT
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010
   Gao T, 2013, OPTIK, V124, P6286, DOI 10.1016/j.ijleo.2013.05.007
   Guo GD, 2003, PROC CVPR IEEE, P346
   Hadid A, 2004, PROC CVPR IEEE, P797
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Kai-Biao Ge, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P40, DOI 10.1109/ICWAPR.2011.6014477
   Kumbhar M., 2012, INT J COMPUT COMMUN, V1, P117, DOI [10.7763/IJCCE.2012.V1.33, DOI 10.7763/IJCCE.2012.V1.33]
   Londhe R., 2012, International Journal of Computer Science Issues (IJCSI), V9, P388
   Maenpaa T., 2005, Handbook of Pattern Recognition and Computer Vision, V3rd, P197
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Topi M, 2000, 3951 ICPR, P3951
   Turtinen M, 2006, IEICE T INF SYST, VE89D, P2076, DOI 10.1093/ietisy/e89-d.7.2076
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang J, 2002, PATTERN RECOGN, V35, P295, DOI 10.1016/S0031-3203(01)00152-2
   Zhang SQ, 2011, COMM COM INF SC, V214, P443
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 23
TC 12
Z9 12
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2995
EP 3010
DI 10.1007/s11042-016-3282-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000062
DA 2024-07-18
ER

PT J
AU Kitanovski, I
   Strezoski, G
   Dimitrovski, I
   Madjarov, G
   Loskovska, S
AF Kitanovski, Ivan
   Strezoski, Gjorgji
   Dimitrovski, Ivica
   Madjarov, Gjorgji
   Loskovska, Suzana
TI Multimodal medical image retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image retrieval; Retrieval in medical texts; Image modality
   classification; Visual image descriptors
ID SEARCH ENGINE; CLASSIFICATION; INFORMATION; FEATURES
AB In this paper we depict an implemented system for medical image retrieval. Our system performs retrieval based on both textual and visual content, separately and combined, using advanced encoding and quantization techniques. The text-based retrieval subsystem uses textual data acquired from an image's corresponding article to generate a suitable representation. Using a vector space model, the generated representations structure is altered to increase performance. Query expansion with pseudo-relevance feedback is applied to fine-tune the results. The content-based retrieval subsystem performs retrieval based on visual features extracted from the images. A Gaussian Mixture Model is constructed from the extracted visual features, in our case - RGB histograms, and is used in encoding the same features into Fisher Vectors. With scalability and speed in mind, we utilized a product quantization technique over the generated vectors, which provides fast response times over large image collections. Product quantization drastically reduces the size of the image representation at almost no cost to accuracy, thus improving the scalability factor of our system. Our system uses modality classification to further improve retrieval results. This subsystem labels the image modality based on their visual content. The images are described using state-of-the-art opponentSIFT visual features. Classification was performed using Support Vector Machines (SVMs). The predictions from the SVMs are used for re-ranking the resulting images based on their modality and the modality of the query. The system was evaluated against the standardized ImageCLEF 2013, 2012 and 2011 medical datasets and it reported state-of-the-art performance for all datasets.
C1 [Kitanovski, Ivan; Strezoski, Gjorgji; Dimitrovski, Ivica; Madjarov, Gjorgji; Loskovska, Suzana] Univ Ss Cyril & Methodius, Fac Comp Sci & Engn, Skopje, North Macedonia.
C3 Saints Cyril & Methodius University of Skopje
RP Kitanovski, I (corresponding author), Univ Ss Cyril & Methodius, Fac Comp Sci & Engn, Skopje, North Macedonia.
EM ivan.kitanovski@finki.ukim.mk; strezoski.g@gmail.com;
   ivica.dimitrovski@finki.ukim.mk; gjorgji.madjarov@finki.ukim.mk;
   suzana.loskovska@finki.ukim.mk
OI Madjarov, Gjorgji/0000-0002-1530-0642; Dimitrovski,
   Ivica/0000-0002-2877-3430
FU European Commission through the project MAESTRA - Learning from Massive,
   Incompletely annotated, and Structured Data [ICT-2013-612944]
FX We would like to acknowledge the support of the European Commission
   through the project MAESTRA - Learning from Massive, Incompletely
   annotated, and Structured Data (Grant number ICT-2013-612944).
CR Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   [Anonymous], 2011, 2011 24 INT S COMPUT, DOI DOI 10.1109/CBMS.2011.5999142
   [Anonymous], 2012, IMAGECLEF
   [Anonymous], 2013, WHO
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Brazier H, 1996, J ADV NURS, V24, P868, DOI 10.1046/j.1365-2648.1996.26426.x
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatfield Ken., The devil is in the details: an evaluation of recent feature encoding methods
   Clough P, 2004, LECT NOTES COMPUT SC, V3115, P243
   de Herrera AGS, 2013, WORKSH NOT CLEF 2013
   de Herrera AGS, 2012, CLEF ONL WORK NOT LA
   Dimitrovski I, 2015, COMPUT MED IMAG GRAP, V39, P14, DOI 10.1016/j.compmedimag.2014.06.005
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Gonalves N, DOCUMENT MINING COMB
   Guld MO, 2002, SPIE, V4685, P280
   Hearst MA, 2007, BIOINFORMATICS, V23, P2196, DOI 10.1093/bioinformatics/btm301
   Ide NC, 2007, J AM MED INFORM ASSN, V14, P253, DOI 10.1197/jamia.M2233
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kahn CE, 2007, AM J ROENTGENOL, V188, P1475, DOI 10.2214/AJR.06.1740
   Kalpathy-Cramer J., 2011, CLEF NOTEBOOK PAPERS, P97
   Kalpathy-Cramer J, 2008, PATTERN RECOGN LETT, V29, P2032, DOI 10.1016/j.patrec.2008.05.013
   Kitanovski I, 2013, P 10 C OP RES AR INF, P25
   Kitanovski I, 2013, CLEF ONL WORK NOT LA
   Kitanovski I, 2013, ADV INTELLIGENT SYST, P81
   Kitanovski I, 2014, LECT NOTES ARTIF INT, V8777, P144, DOI 10.1007/978-3-319-11812-3_13
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Lehmann TM, 2000, P SOC PHOTO-OPT INS, V3972, P312, DOI 10.1117/12.390591
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Macdonald C, 2006, LECT NOTES COMPUT SC, V4022, P898
   Mazin B., 2012, 2012 21st International Conference on Pattern Recognition (ICPR 2012), P2667
   Montague M., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P427, DOI 10.1145/502585.502657
   Muller H, 2009, SPIE MED IMAGING
   Névéol A, 2009, J AM SOC INF SCI TEC, V60, P123, DOI 10.1002/asi.20955
   Okan Ozturkmenoglu NMC, 2013, CLEF ONL WORK NOT LA
   Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517
   Rahman MM, 2013, INT J MULTIMED INF R, V2, P159, DOI 10.1007/s13735-013-0038-4
   Simonyan K, 2012, MICCAI INT WORKSH CO
   Spyridon Stathopoulos AK, 2013, CLEF ONL WORK NOT LA
   Tornmasi T, 2008, PATTERN RECOGN LETT, V29, P1996, DOI 10.1016/j.patrec.2008.03.009
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Gemert JC, IEEE T PATTERN ANAL, V99
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xu SH, 2008, BIOINFORMATICS, V24, P1968, DOI 10.1093/bioinformatics/btn340
   Zheng L, 2003, IEEE T INF TECHNOL B, V7, P249, DOI 10.1109/TITB.2003.822952
NR 47
TC 16
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2955
EP 2978
DI 10.1007/s11042-016-3261-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000060
DA 2024-07-18
ER

PT J
AU Nóbrega, R
   Correia, N
AF Nobrega, Rui
   Correia, Nuno
TI Interactive 3D content insertion in images for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed and augmented reality; Multimedia; Computer vision; Computer
   graphics; Human-computer interaction
ID TRACKING
AB This article addresses the problem of creating interactive mixed reality applications where virtual objects interact in images of real world scenarios. This is relevant to create games and architectural or space planning applications that interact with visual elements in the images such as walls, floors and empty spaces. These scenarios are intended to be captured by the users with regular cameras or using previously taken photographs. Introducing virtual objects in photographs presents several challenges, such as pose estimation and the creation of a visually correct interaction between virtual objects and the boundaries of the scene. The two main research questions addressed in this article include, the study of the feasibility of creating interactive augmented reality (AR) applications where virtual objects interact in a real world scenario using the image detected high-level features and, also, verifying if untrained users are capable and motivated enough to perform AR initialization steps. The proposed system detects the scene automatically from an image with additional features obtained using basic annotations from the user. This operation is significantly simple to accommodate the needs of non-expert users. The system analyzes one or more photos captured by the user and detects high-level features such as vanishing points, floor and scene orientation. Using these features it will be possible to create mixed and augmented reality applications where the user interactively introduces virtual objects that blend with the picture in real time and respond to the physical environment. To validate the solution several system tests are described and compared using available external image datasets.
C1 [Nobrega, Rui; Correia, Nuno] UNL, FCT, CITI, NOVA LINCS, P-2829516 Caparica, Portugal.
   [Nobrega, Rui] Univ Porto, DEI FEUP INESC TEC, Oporto, Portugal.
C3 Universidade Nova de Lisboa; Universidade do Porto; INESC TEC
RP Nóbrega, R (corresponding author), UNL, FCT, CITI, NOVA LINCS, P-2829516 Caparica, Portugal.; Nóbrega, R (corresponding author), Univ Porto, DEI FEUP INESC TEC, Oporto, Portugal.
EM rui.nobrega@gmail.com; nmc@fct.unl.pt
RI Correia, Natália T. T./D-6699-2013; Correia, Nuno/D-2298-2010
OI Nobrega, Rui/0000-0002-3620-7279; Correia, Nuno/0000-0002-8704-6698
FU Portuguese Science and Technology Foundation, FCT/MEC
   [SFRH/BD/47511/2008, PEst-OE/EEI/UI0527/2011]; North Portugal Regional
   Operational Programme (ON.2 O Novo Norte), under the National Strategic
   Reference Framework (NSRF), through the European Regional Development
   Fund (ERDF) [NORTE-07-0124-FEDER-000061]; Portuguese funding agency,
   Fundao para a Cincia e a Tecnologia (FCT); Fundação para a Ciência e a
   Tecnologia [PEst-OE/EEI/UI0527/2011, SFRH/BD/47511/2008] Funding Source:
   FCT
FX The authors would like to thank the support from everyone at IMG and
   CITI. This work was funded by the Portuguese Science and Technology
   Foundation, FCT/MEC, through grants SFRH/BD/47511/2008,
   PEst-OE/EEI/UI0527/2011 (CITI/FCT/UNL now NOVA-LINCS) and to the MAT
   Project. The Media Arts and Technologies project (MAT),
   NORTE-07-0124-FEDER-000061, is financed by the North Portugal Regional
   Operational Programme (ON.2 O Novo Norte), under the National Strategic
   Reference Framework (NSRF), through the European Regional Development
   Fund (ERDF), and by national funds, through the Portuguese funding
   agency, Fundao para a Cincia e a Tecnologia (FCT). The authors also
   thank the Project I-City for Future Mobility:
   NORTE-07-0124-FEDER-000064, and European Project FP7 Future Cities:
   FP7-REGPOT-2012-2013-1.
CR [Anonymous], 2004, ACM T GRAPHICS TOG
   [Anonymous], 2010, IEEE C EVOLUTIONARY, DOI DOI 10.1109/CEC.2010.5585957
   [Anonymous], 2008, P 16 ACM INT C MULT, DOI DOI 10.1145/1459359.1459410
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bunnun P, 2012, INT SYM MIX AUGMENT, P273, DOI 10.1109/ISMAR.2012.6402570
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Coughlan JM, 1999, P INT C COMP VIS ICC, V2, P1
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Del Pero L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2009, DOI 10.1109/CVPR.2011.5995737
   Delong A, 2009, IEEE I CONF COMP VIS, P285, DOI 10.1109/ICCV.2009.5459263
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fite-Georgel P., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P201, DOI 10.1109/ISMAR.2011.6092387
   Forsyth D, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2436256.2436275
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Gioi R.G. V., 2008, Journal of Mathematical Imaging and Vision, V32, P1
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Hedau V, 2012, PROC CVPR IEEE, P2807
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Karst KL, 2011, SUPREME COURT REV, P1
   Klein George, 2007, P1
   Lee D. C., 2010, NIPS FDN, P1
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   Li B, 2012, PATTERN RECOGN LETT, V33, P1, DOI 10.1016/j.patrec.2011.09.027
   Lima JP, 2012, INT SYM MIX AUGMENT, P297, DOI 10.1109/ISMAR.2012.6402582
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mulloni A, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P212, DOI 10.1145/2254556.2254595
   Nguyen V., 2012, Proceedings of the Third Symposium on Information and Communication Technology (SoICT '12), P97
   Nobrega R., 2013, Proceedings of International Conference on Computer Graphics Theory and Applications (GRAPP'13), P298
   Nobrega R, 2014, INT J CREATIVE INTER, V4, P22
   Nóbrega R, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P332, DOI 10.1145/2254556.2254620
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Simon G, 2002, IEEE COMPUT GRAPH, V22, P46, DOI 10.1109/MCG.2002.1046628
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Simon G., 2006, Proceedings IEEE International Symposium On Mixed and Augmented Reality (ISMAR'06), P4
   Tillon A. B., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P41, DOI 10.1109/ISMAR-AMH.2011.6093655
   Uchiyama H., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P17, DOI 10.1109/ISMAR.2011.6092366
   Vallino J.R., 1998, INTERACTIVE AUGMENTE
   von Gioi R., 2007, Proceedings of the IEEE International Conference on Image Processing(ICIP'07), P1
   Wagner D, 2009, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2009.5336497
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Xiong XH, 2011, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2011.5980125
NR 44
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 163
EP 197
DI 10.1007/s11042-015-3031-5
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000009
DA 2024-07-18
ER

PT J
AU Choi, HH
   Lim, SA
   Jeong, CS
AF Choi, Hak-Hyun
   Lim, Seung-Ae
   Jeong, Chang-Sung
TI New promotional video technique utilizing augmented reality and popcode
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Popcode; Motion tracking; Augmented reality; Promotional video
AB We are living in the middle of media era's turning point. Old media may change largely. Recently the growth of Tablet PC and Smartphone has brought the digital media, New media, expand. Companies are likely to use the Augmented reality applied marketing, based on mobile display. This research proposes augmented reality based techniques to enhance promotional videos for cultural arts organizations. Specifically, it aims to propose editing techniques based on augmented reality and the Popcode mobile application. Currently, Popcode is not widely utilized; however, it has potential value for promotional videos by working in concert with augmented reality systems. To achieve this goal, we enhanced Popcode's features and capabilities, applied them to promotional videos, and concluded that these techniques would create a synergistic effect for marketing campaigns. Based on related Popcode research conducted by the University of Cambridge, we implemented Popcode technology into a video, focusing on a motion tracking technique that incorporates the Adobe After Effects program. Augmented reality and Popcode aren't just a technology. Now we are going to find out the meaning of augmented reality as a means of media. As well as analyze the interactive effect as a role of advertising.
C1 [Choi, Hak-Hyun; Lim, Seung-Ae] Seoul Womens Univ, Dept Contents Design, 621 Hwarang Ro, Seoul 139774, South Korea.
   [Jeong, Chang-Sung] Korea Univ, Dept Visual Informat Proc, 145 Anam Ro, Seoul 136701, South Korea.
C3 Seoul Women's University; Korea University
RP Choi, HH (corresponding author), Seoul Womens Univ, Dept Contents Design, 621 Hwarang Ro, Seoul 139774, South Korea.
EM choiidea@naver.com; lsaictdesigner@gmail.com; csjeong44@gmail.com
FU Seoul Women's University
FX This work was supported by a special research grant from Seoul Women's
   University (2014).
CR Akkapeddi Prasad R, 1983, P ART AD OPT SYST TE, V3762
   Azuma Ronald T, 1997, TELOEPERATORS VIRTUA
   Coates G., 1992, Program from Invisible Site - a virtual sho
   Fow J, 2009, SURVIVAL GUIDE SOCIA
   Frederick P, 1999, WHATS REAL VIRTUAL R
   Gobbetti E., 1998, VIRTUAL REALITY PAST
   Huang WenDa, 2013, SCI COLDE ARID REGIO
   Information Society Development Institute, 2011, INF SOC DEV I GEN RE, P284
   Jupiter Reasearch, 2011, FOR STRAT AN
   Matijasevic Maja, 2008, J COMMUNICATIONS SOF
   Michael B, 1992, VIRTUAL REALITY ABST
   Mun Changhyeon, 2012, INTERACTIVITY AUGMEN
   Steuer J., 1993, J COMMUNICATION
   Stony J, 2010, MARKET TRENDS SEMICO
   Zappar, 2010, WHAT IS POPCODE
NR 15
TC 6
Z9 6
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15311
EP 15326
DI 10.1007/s11042-014-2272-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700012
DA 2024-07-18
ER

PT J
AU Choi, J
   Kim, C
AF Choi, Jiwon
   Kim, Changick
TI Object-aware image thumbnailing using image classification and enhanced
   detection of ROI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image thumbnailing; Thumbnail cropping; Image classification; Saliency
   detection
AB Thumbnail images are used to display a large collection of photos in various digital devices. It aims for people to browse and search the image collection effectively. The provided thumbnail images are expressed in a much lower resolution compared to the resolution of the original image. Thus, it faces a significant problem of how to represent the content of a given image effectively in a tiny thumbnail image. Many image thumbnailing methods have been presented in literature for this purpose. However, the existing thumbnailing methods are designed to use a single method to all kinds of images, regardless of image contents. On the other hand, the proposed method employs two different thumbnail generation methods either of which is applied according to corresponding image context. To achieve this, we first classify images into two groups by detecting the object existence. Then, an ROI cropping method using a saliency map is presented for images with objects, in order to represent the important region of images in the thumbnail. Images without any interesting objects, such as landscape images, are considered to be resized by using a simple scaling method to maintain the whole image context. Experimental results show that the proposed method yields comparable performance on a variety of datasets.
C1 [Choi, Jiwon; Kim, Changick] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, C (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 305701, South Korea.
EM g1choi@kaist.ac.kr; changick@kaist.ac.kr
RI Kim, Changick/C-1779-2011
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], P 2 INT C INT SCI
   [Anonymous], 2007, ACM T GRAPH
   Choi J, 2014, IEEE SIGNAL PROC LET, V21, P957, DOI 10.1109/LSP.2014.2321751
   Ciocca G, 2010, P IS T SPIE EL IM IN
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Kennedy L, 2011, P ACM INT C MULT RET, P30
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Kim W, 2012, OPT LETT, V37, P1550, DOI 10.1364/OL.37.001550
   Li X, 2009, IEEE INT CON MULTI, P558, DOI 10.1109/ICME.2009.5202557
   Lin SS, 2013, IEEE T VIS COMPUT GR, V19, P1677, DOI 10.1109/TVCG.2013.75
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma M, 2004, CCNC 2004: 1ST IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, PROCEEDINGS, P710, DOI 10.1109/CCNC.2004.1286964
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Mellina A, 2012, CONSUM COMM NETWORK, P472, DOI 10.1109/CCNC.2012.6181003
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Samadani Ramin, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P193
   Scharfenberger C, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P75, DOI 10.1109/CRV.2013.25
   Sentinelli A, 2013, IEEE INT CONF MULTI
   Stentiford F, 2007, P INT COMP VIS SYST
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Wu YC, 2013, IEEE T VIS COMPUT GR, V19, P278, DOI 10.1109/TVCG.2012.114
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Yang Yang, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P337, DOI 10.1007/978-3-319-03731-8_32
   Yen TC, 2011, IEEE T IMAGE PROCESS, V20, P2339, DOI 10.1109/TIP.2011.2114357
   Zhan Qu, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P445, DOI 10.1007/978-3-642-37447-0_34
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang M, 2005, P IEEE INT C MULT EX
NR 37
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16191
EP 16207
DI 10.1007/s11042-015-2926-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700060
DA 2024-07-18
ER

PT J
AU Cui, YF
   Liu, W
   Dong, S
AF Cui, Yongfeng
   Liu, Wei
   Dong, Shi
TI A time-slice optimization based weak feature association algorithm for
   video condensation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grid background model; Weak feature association; Time-slice
   optimization; Video condensation
AB There are a lot of complex environments in real scene, such as illumination variation, shadow variation, object occlusion, which will directly affect the performance of video synopsis. In this paper, we adopt Grid Background Model as object detection algorithm, proposing algorithm based on weak feature to solve the object occlusion problem, at last we propose to use time-slice optimization algorithm to solve the visualization problem of video condensation. Specifically, Grid Background Model is adopted to segment the foreground from the background, then we use current frame to update background frame, and then binarize the foreground frame to perform Neighborhood illumination invariant shadow elimination. A clear foreground can be obtained by doing the procedure above as well as Gaussian noise elimination and morphological operation such as inflation and corrosion to remove cavities. Meanwhile, the outline of the object is extracted by using the canny edge detector. In the object tracking section, we will introduce how to use the weak features, such as color, speed and direction on the basis of location prediction based on tracking algorithm to perform object association, and the extraction of accurate information of abstract and outline of the object at the same time. Finally, in the video condensation section, we will describe how to use optical time-slice based minimum energy model to perform video condensation according to frame sequence. The experimental result shows that, the method mentioned above can provide a new approach for solving the occlusion problems of video condensation, and have better visualization of abstract video, and achieve up to 6 times concentration to the original video.
C1 [Cui, Yongfeng; Liu, Wei; Dong, Shi] Zhoukou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466001, Henan, Peoples R China.
   [Dong, Shi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Zhoukou Normal University; Huazhong University of Science & Technology
RP Cui, YF (corresponding author), Zhoukou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466001, Henan, Peoples R China.
EM cuiyf@zknu.edu.cn; liuwei@zknu.edu.cn; njbsok@gmail.com
RI Dong, Shi/P-7294-2014; Dong, Shi/ITT-3871-2023
OI Dong, Shi/0000-0003-4616-6519
FU National Natural Science Foundation of China [U1504602]; Postdoctoral
   Science Foundation of China [2015M572141]; Science and Technology Plan
   Projects of Henan Province [162102310147, 132300410485, 142300410463];
   Key Research Projects of Universities in Henan Province [15A520035,
   15A520124]
FX This study was supported by the National Natural Science Foundation of
   China(Grant no. U1504602), Postdoctoral Science Foundation of China
   (2015M572141). The authors wish to thank the Science and Technology Plan
   Projects of Henan Province for contract 162102310147, 132300410485 and
   142300410463, the Key Research Projects of Universities in Henan
   Province for contract 15A520035 and 15A520124, under which the present
   work was possible.
CR [Anonymous], ARXIV150406359
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P 2006 IEEE COMP SOC
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Leo C, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530285
   Eshel R, 2010, INT J COMPUT VISION, V88, P129, DOI 10.1007/s11263-009-0307-0
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Gu W, 2015, MULTIMEDIA TOOLS APP
   Hanjalic A, 2001, PROC SPIE, V4315, P301, DOI 10.1117/12.410940
   Jiang D., 2015, TELECOMMUN SYST, P1
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Park D, 2013, PATTERN RECOGN, V46, P1985, DOI 10.1016/j.patcog.2012.12.013
   Pritch Y, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P195, DOI 10.1109/AVSS.2009.53
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Sundaram H, 2002, THESIS
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
   Yang J., 2015, MULTIMEDIA TOOLS APP
   Yoshitaka A, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P661, DOI 10.1109/SITIS.2012.100
NR 27
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17515
EP 17530
DI 10.1007/s11042-016-3473-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600036
DA 2024-07-18
ER

PT J
AU Qian, ZX
   Zhang, XP
   Ren, YL
   Feng, GR
AF Qian, Zhenxing
   Zhang, Xinpeng
   Ren, Yanli
   Feng, Guorui
TI Block cipher based separable reversible data hiding in encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Block cipher; Image recovery
ID WATERMARKING
AB While most reversible data hiding in encrypted images (RDH-EI) are based on stream cipher, this paper aims to present an alternative method feasible for block-enciphered images. Before uploading data to a remote server, the content owner encrypts the original image with a block cipher algorithm using an encryption key. Then, the server embeds additional bits into the encrypted image with an embedding key to generate the marked encrypted image. On the recipient side, the additional bits can be extracted if the receiver has the embedding key. In case the receiver has only the encryption key, the marked encrypted image can be directly deciphered to a plaintext image with good quality. When both the embedding and encryption keys are available for the receiver, he can recover the original image without any errors. Compared with the existing block cipher based RDH-EI method, drawbacks of the encryption and the recovery are avoided, and good embedding payloads are achieved.
C1 [Qian, Zhenxing; Zhang, Xinpeng; Ren, Yanli; Feng, Guorui] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Zhang, Xinpeng; Ren, Yanli; Feng, Guorui] Shanghai Key Lab Intelligent Informat Proc, Shanghai, Peoples R China.
C3 Shanghai University
RP Qian, ZX (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM zxqian@shu.edu.cn; xzhang@shu.edu.cn; grfeng@shu.edu.cn;
   renyanli@shu.edu.cn
RI Qian, Zhenxing/AHC-9176-2022
FU Shanghai Rising-Star Program [14QA1401900]; Natural Science Foundation
   of China [61232016, U1405254, 61472235]; Shanghai Key Laboratory of
   Intelligent Information Processing [IIPL-2014-006]; Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning; Shanghai Pujiang Program [13PJ1403200];
   PAPD fund
FX This work was supported by Shanghai Rising-Star Program under Grant
   14QA1401900, Natural Science Foundation of China under Grant 61232016,
   U1405254, and 61472235, Shanghai Key Laboratory of Intelligent
   Information Processing under Grant IIPL-2014-006, Program for Professor
   of Special Appointment (Eastern Scholar) at Shanghai Institutions of
   Higher Learning, Shanghai Pujiang Program under Grant 13PJ1403200, and
   the PAPD fund.
CR Deng MN, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P9
   Erkin Z, 2008, EURASIP J INF SECUR
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qian ZX, 2013, ADV INTEL SYS RES, V84, P869
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 22
TC 34
Z9 36
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13749
EP 13763
DI 10.1007/s11042-015-2760-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800039
DA 2024-07-18
ER

PT J
AU Ozcinar, C
   Ekmekcioglu, E
   Calic, J
   Kondoz, A
AF Ozcinar, Cagri
   Ekmekcioglu, Erhan
   Calic, Janko
   Kondoz, Ahmet
TI Adaptive delivery of immersive 3D multi-view video over the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D; Multi-view video; Multi-view video coding; Video coding; Video
   streaming; Video adaptation; Adaptive streaming; MPEG-DASH
ID ALGORITHM; IMAGE; ERROR; TRANSMISSION; OPTIMIZATION; 3-D
AB The increase in Internet bandwidth and the developments in 3D video technology have paved the way for the delivery of 3D Multi-View Video (MVV) over the Internet. However, large amounts of data and dynamic network conditions result in frequent network congestion, which may prevent video packets from being delivered on time. As a consequence, the 3D video experience may well be degraded unless content-aware precautionary mechanisms and adaptation methods are deployed. In this work, a novel adaptive MVV streaming method is introduced which addresses the future generation 3D immersive MVV experiences with multi-view displays. When the user experiences network congestion, making it necessary to perform adaptation, the rate-distortion optimum set of views that are pre-determined by the server, are truncated from the delivered MVV streams. In order to maintain high Quality of Experience (QoE) service during the frequent network congestion, the proposed method involves the calculation of low-overhead additional metadata that is delivered to the client. The proposed adaptive 3D MVV streaming solution is tested using the MPEG Dynamic Adaptive Streaming over HTTP (MPEG-DASH) standard. Both extensive objective and subjective evaluations are presented, showing that the proposed method provides significant quality enhancement under the adverse network conditions.
C1 [Ozcinar, Cagri] Univ Paris Saclay, LTCI, CNRS, Telecom ParisTech, F-75013 Paris, France.
   [Ozcinar, Cagri; Calic, Janko] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England.
   [Ekmekcioglu, Erhan; Kondoz, Ahmet] Loughborough Univ London, Inst Digital Technol, London, England.
C3 Universite Paris Cite; Universite Paris Saclay; Centre National de la
   Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; University of Surrey;
   Loughborough University
RP Ozcinar, C (corresponding author), Univ Paris Saclay, LTCI, CNRS, Telecom ParisTech, F-75013 Paris, France.; Ozcinar, C (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England.
EM cagri.ozcinar@telecom-paristech.fr; e.ekmekcioglu@lboro.ac.uk;
   j.calic@surrey.ac.uk; a.kondoz@lboro.ac.uk
OI Ozcinar, Cagri/0000-0003-4915-2251
FU ROMEO project [287896]; EC FP7 ICT collaborative research programme
FX This work was supported by the ROMEO project (grant number: 287896),
   which was funded by the EC FP7 ICT collaborative research programme.
   This paper is an extended version of the original paper [49] which
   appeared in the Proceedings of the 2013 ACM International Workshop on
   Immersive Media Experiences [7]. Special thanks to the anonymous
   reviewers and program chairs in the workshop and the journal for their
   constructive comments and suggestions that assisted in enhancing the
   paper.
CR [Anonymous], 1999, document P.910, DOI 11.1002/1000/4751
   [Anonymous], 2003, P WORKSH EC PEER PEE
   [Anonymous], 2005, P 16 ANN WORKSH CIRC
   [Anonymous], MPEG2008M15419
   [Anonymous], P 2013 ACM INT WORKS
   [Anonymous], 1988, ACM SIGCOMM COMP COM
   [Anonymous], 2016, AL GLASS FREE 3D DIS
   [Anonymous], 2004, Digital Speech: Coding for Low Bit Rate Communication Systems
   [Anonymous], MATH PROBL ENG
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   Bjotegaard G, 2001, VCEG M AUST TEX US
   Carballeira P, 2010, P 3DTV C TRUE VIS CA, P1
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Chambel T, 2013, P 2013 ACM INT WORKS
   Cheng CM, 2011, IEEE T BROADCAST, V57, P523, DOI 10.1109/TBC.2011.2139090
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P3179, DOI 10.1109/TIP.2011.2158230
   Cheung NM, 2012, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2012.6467536
   Christensen E., 2016, WEB SERVICES DESCRIP
   Dempsey BJ, 1996, COMPUT NETWORKS ISDN, V28, P719, DOI 10.1016/0169-7552(95)00051-8
   Detti A, 2015, COMPUT NETW, V81, P272, DOI 10.1016/j.comnet.2015.02.018
   Domanski M, 2013, IEEE T IMAGE PROCESS, V22, P3517, DOI 10.1109/TIP.2013.2266580
   Dufaux F., 2013, Emerging_Technologies_for_3D_Video:_ Creation,_Coding,_Transmission_and_Rendering
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Feldmann I. I., 2008, MPEG2008M15413
   GIST Electronics and telecommunications research institute and gwangju institute of science and technology, 2016, 3DV SEQ ETRI DS
   Gürler CG, 2010, IEEE IMAGE PROC, P2409, DOI 10.1109/ICIP.2010.5651035
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   HHI Fraunhofer, 2016, 3DV SEQ HHI FRAUNH H
   Hur JH, 2007, IEEE T CIRC SYST VID, V17, P1496, DOI 10.1109/TCSVT.2007.903774
   ISO/IEC JTC1/SC29/WG11, 2016, JTC1SC29WG11 ISOIEC
   ISO/IEC JTC1/SC29/WG11, 2015, JTC1SC29WG11 ISOIEC
   ISO/IEC JTC1/SC29/WG11, 2005, JTC1SC29WG11 ISOIEC
   ISO/IEC JTC1/SC29/WG11, 2011, Tech. Rep
   Kang YS, 2009, MPEG2009M16949
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kim WS, 2009, IEEE IMAGE PROC, P721, DOI 10.1109/ICIP.2009.5414304
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Kondoz A, 2014, 3D FUTURE INTERNET M
   Lederer S., 2012, P 3 MULT SYST C, P89
   Lewandowski F, 2012, 2012 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS (ICSES), DOI 10.1109/ICSES.2012.6382237
   Lightstone M, 1997, J VLSI SIG PROCESS S, V17, P215, DOI 10.1023/A:1007959007434
   Liu YN, 2013, IEEE ICC, P3629, DOI 10.1109/ICC.2013.6655116
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Nagoya University, 2016, 3DV SEQ NAG U
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Onural L, 2007, P IEEE, V95, P1143, DOI 10.1109/JPROC.2007.896490
   Ozcinar C, 2014, IEEE IMAGE PROC, P2462, DOI 10.1109/ICIP.2014.7025498
   Oztas B, 2014, INT CONF COMPUT NETW, P1006, DOI 10.1109/ICCNC.2014.6785475
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Pulipaka A, 2013, IEEE T BROADCAST, V59, P382, DOI 10.1109/TBC.2013.2244792
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Savas SS, 2012, IEEE IMAGE PROC, P2273, DOI 10.1109/ICIP.2012.6467349
   Savas SS, 2012, SIGNAL PROCESS-IMAGE, V27, P522, DOI 10.1016/j.image.2012.02.013
   Seeling P, 2005, IEEE T BROADCAST, V51, P473, DOI 10.1109/TBC.2005.851121
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sripanidkulchai K., 2004, Proceedings of the 4th ACM SIGCOMM conference on Internet measurement, P41
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   SUGIYAMA Y, 1986, IEEE T INFORM THEORY, V32, P394, DOI 10.1109/TIT.1986.1057178
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030
   Sun W., 2013, P IEEE ICME SAN JOS, P1
   Tanimoto M, 2008, MPEG2008M15377
   Tanimoto M, 2009, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2009.5202803
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   The official Microsoft IIS site, 2016, MICR SMOOTH STREAM
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wegner K, 2010, M17913 MPEG
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang C., 2009, Proc. IEEE International Workshop on Multimedia Signal Processing, P1
   Zhao Y, 2010, P SOC PHOTO-OPT INS, V7744
NR 80
TC 18
Z9 18
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12431
EP 12461
DI 10.1007/s11042-016-3475-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700008
DA 2024-07-18
ER

PT J
AU Ghimire, D
   Lee, J
AF Ghimire, Deepak
   Lee, Joonwhoan
TI Online sequential extreme learning machine-based co-training for dynamic
   moving cast shadow detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground segmentation; Cast shadow detection; Co-training; Online
   sequential extreme learningmachine
ID OBJECT DETECTION; TEXTURE
AB Cast shadow detection and removal is one of the key problems in vision-based systems for accurate and robust segmentation of moving objects. This paper proposes a co-training-based adaptive method for detecting moving shadows in video sequences. Shadow detection based on static methods cannot adapt to changing environment such as gradual illumination changes. In order to solve this problem, we have proposed an online sequential extreme learning machine(OS-ELM)-based semi-supervised technique for moving cast shadow detection. Online learning of OS-ELM is much faster and provides better generalization performance compared to other popular online learning algorithms. First, we extracted color, texture, gradient, and image patch similarity features using a backgroundmodel and input video frame, which are useful for discriminating moving shadows and objects. Co-training scheme is used for online updating of the OS-ELM classifier in order to adapt to the dynamic environment. Experimental results on different benchmark video sequences shows that the proposed method performs better shadow detection and discrimination compared with other methods.
C1 [Ghimire, Deepak] Korea Elect Technol Inst, Jeonju Si 561844, Jeollabuk Do, South Korea.
   [Lee, Joonwhoan] Chonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
C3 Jeonbuk National University
RP Lee, J (corresponding author), Chonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
EM deepak@keti.re.kr; chlee@jbnu.ac.kr
RI Ghimire, Deepak/W-2826-2019
OI Ghimire, Deepak/0000-0001-8940-8739
CR Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cavallaro A, 2005, IEE P-VIS IMAGE SIGN, V152, P398, DOI 10.1049/ip-vis:20045108
   Chao Yuan, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P188, DOI 10.1109/MMIT.2010.96
   Chia-Chih Chen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2407, DOI 10.1109/ICPR.2010.589
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   El-Zahhar M. M., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P348, DOI 10.1109/ICSIPA.2011.6144084
   Grest D, 2003, VISION, MODELING, AND VISUALIZATION 2003, P253
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Jalal AS, 2014, MULTIMED TOOLS APPL, V73, P779, DOI 10.1007/s11042-012-1326-3
   Jarraya SK, 2012, LECT NOTES COMPUT SC, V7324, P19, DOI 10.1007/978-3-642-31295-3_3
   Jia Y, 2012, P 3 SIN FOR INT C IN, P115
   Jiang K, 2013, IET COMPUT VIS, V7, P115, DOI 10.1049/iet-cvi.2012.0106
   Joshi AJ, 2008, IEEE T PATTERN ANAL, V30, P2055, DOI 10.1109/TPAMI.2008.150
   Joshi AJ, 2007, IEEE INT CONF ROBOT, P4827, DOI 10.1109/ROBOT.2007.364223
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Li L. Qin, 2013, Era of Interactive Media, P399, DOI [10.1007/978-1-4614-3501-333.23M., DOI 10.1007/978-1-4614-3501-333.23M]
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Ling ZG, 2013, CHINESE J ELECTRON, V22, P757
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Song KT, 2007, P IEEE, V95, P413, DOI 10.1109/JPROC.2006.888403
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Yang MT, 2008, IET IMAGE PROCESS, V2, P95, DOI 10.1049/iet-ipr:20070113
   Yu Yang, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P358, DOI 10.1109/ICINIS.2009.98
NR 29
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11181
EP 11197
DI 10.1007/s11042-015-2839-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900016
DA 2024-07-18
ER

PT J
AU Kotus, J
   Lopatka, K
   Czyzewski, A
   Bogdanis, G
AF Kotus, J.
   Lopatka, K.
   Czyzewski, A.
   Bogdanis, G.
TI Processing of acoustical data in a multimodal bank operating room
   surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sound event detection; Sound source localization; Audio surveillance;
   Acoustic vector sensor
ID EVENT DETECTION; RECOGNITION
AB An automatic surveillance system capable of detecting, classifying and localizing acoustic events in a bank operating room is presented. Algorithms for detection and classification of abnormal acoustic events, such as screams or gunshots are introduced. Two types of detectors are employed to detect impulsive sounds and vocal activity. A Support Vector Machine (SVM) classifier is used to discern between the different classes of acoustic events. The methods for calculating the direction of coming sound employing an acoustic vector sensor are presented. The localization is achieved by calculating the DOA (Direction of Arrival) histogram. The evaluation of the system based on experiments conducted in a real bank operating room is presented. The results of sound event detection, classification and localization are provided and discussed. The practical usability of the engineered methods is underlined by presenting the results of analyzing a staged robbery situation.
C1 [Kotus, J.; Lopatka, K.; Czyzewski, A.] Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
   [Bogdanis, G.] Informat Syst Designing & Applicat Agcy Microsyst, Sopot, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Kotus, J (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
EM joseph@sound.eti.pg.gda.pl; klopatka@multimed.org; andcz@multimed.org
RI Czyzewski, Andrzej/JXN-0946-2024; Bogdanis, Gregory C./B-1705-2018
OI Czyzewski, Andrzej/0000-0001-9159-8658; Bogdanis, Gregory
   C./0000-0003-3382-0438
FU European Commission [218086]; European Regional Development Fund under
   the Innovative Economy Operational Programme, INSIGMA project
   [POIG.01.01.02-00-062/09]
FX Research is subsidized by the European Commission within FP7 project
   "INDECT" (Grant Agreement No. 218086). The presented work has been also
   co-financed by the European Regional Development Fund under the
   Innovative Economy Operational Programme, INSIGMA project no.
   POIG.01.01.02-00-062/09.
CR Basten T., 2009, Multiple Incoherent Sound Source Localization Using a Single Vector Sensor
   Cowling M, 2003, PATTERN RECOGN LETT, V24, P2895, DOI 10.1016/S0167-8655(03)00147-8
   Kotus J, 2013, SIG P ALGO ARCH ARR, P100
   Kotus J., 2010, INFORM TECHNOLOGIES, V18, P111
   Kotus J, 2012, MULTIMED TOOLS APPL, V07
   Kotus J, 2013, MULTIMEDIA TOOLS APP
   Kotus J, 2013, COMM COM INF SC, V368, P107
   Lopatka K, 2011, ARCH ACOUST, V36, P851, DOI 10.2478/v10168-011-0056-2
   Lopatka K, 2010, ADV INTEL SOFT COMPU, V80, P49, DOI 10.1007/978-3-642-14989-4_5
   Peeters G., 2004, DUIDADO IST PROJ REP, V54, P1
   Raangs R., 2002, SOUND SOURCE LOCALIZ
   Rabaoui A., 2008, INT S COMM CONTR SIG
   Temko A, 2009, PATTERN RECOGN LETT, V30, P1281, DOI 10.1016/j.patrec.2009.06.009
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Weyna S., 2003, Archives of Acoustics, V28, P191
   Wind J.W., 2009, THESIS
   Wind J.W., 2009, SOURCE LOCALIZATION
   Yoo IC, 2009, ETRI J, V31, P451, DOI 10.4218/etrij.09.0209.0104
   Zhuang XD, 2010, PATTERN RECOGN LETT, V31, P1543, DOI 10.1016/j.patrec.2010.02.005
   Zwan P., 2010, J DIGITAL FORENSIC P, V3, P33
NR 20
TC 7
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10787
EP 10805
DI 10.1007/s11042-014-2264-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800034
OA hybrid
DA 2024-07-18
ER

PT J
AU Hamadi, A
   Mulhem, P
   Quénot, G
AF Hamadi, Abdelkader
   Mulhem, Philippe
   Quenot, Georges
TI A comparative study for multiple visual concepts detection in images and
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic indexing; Multimedia; Fusion; Multiple concepts; Multi-concept;
   Concept pairs; Triplet of concepts; Bi-concept; Tri-concept; Image;
   Video; Pascal VOC; TRECVid
AB Automatic indexing of images and videos is a highly relevant and important research area in multimedia information retrieval. The difficulty of this task is no longer something to prove. Most efforts of the research community have been focusing, in the past, on the detection of single concepts in images/videos, which is already a hard task. With the evolution of information retrieval systems, users' needs become more abstract, and lead to a larger number of words composing the queries. It is important to think about indexing multimedia documents with more than just individual concepts, to help retrieval systems to answer such complex queries. Few studies addressed specifically the problem of detecting multiple concepts (multi-concept) in images and videos. Most of them concern the detection of concept pairs. These studies showed that such challenge is even greater than the one of single concept detection. In this work, we address the problem of multi-concept detection in images/videos by making a comparative and detailed study. Three types of approaches are considered: 1) building detectors for multi-concept, 2) fusing single concepts detectors and 3) exploiting detectors of a set of single concepts in a stacking scheme. We conducted our evaluations on PASCAL VOC' 12 collection regarding the detection of pairs and triplets of concepts. We extended the evaluation process on TRECVid 2013 dataset for infrequent concept pairs' detection. Our results show that the three types of approaches give globally comparable results for images, but they differ for specific kinds of pairs/triplets. In the case of videos, late fusion of detectors seems to be more effective and efficient when single concept detectors have good performances. Otherwise, directly building bi-concept detectors remains the best alternative, especially if a well-annotated dataset is available. The third approach did not bring additional gain or efficiency.
C1 [Hamadi, Abdelkader] Univ Lorraine, F-54052 Nancy, France.
   [Mulhem, Philippe; Quenot, Georges] Univ Grenoble Alpes, CNRS, LIG, F-38000 Grenoble, France.
C3 Universite de Lorraine; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS)
RP Hamadi, A (corresponding author), Univ Lorraine, F-54052 Nancy, France.
EM Abdelkader.Hamadi@imag.fr; Philippe.Mulhem@imag.fr;
   Georges.Quenot@imag.fr
RI Hamadi, Abdelkader/AAU-8111-2020
OI Hamadi, Abdelkader/0000-0001-9990-332X
FU OSEO, French State agency for innovation; French project VideoSense of
   the ANR [ANR-09-CORD-026]; CNRS; RENATER
FX This work was partly realized as part of the Quaero Program funded by
   OSEO, French State agency for innovation. This work was supported in
   part by the French project VideoSense ANR-09-CORD-026 of the ANR.
   Experiments presented in this paper were carried out using the Grid'5000
   experimental test bed, being developed under the INRIA ALADDIN
   development action with support from CNRS, RENATER and several
   Universities as well as other funding bodies (see
   https://www.grid5000.fr). The authors wish to thanks the participants of
   the IRIM (Indexation et Recherche d'Information Multimedia) group of the
   GDR-ISIS research network from CNRS for providing the descriptors used
   in these experiments.
CR [Anonymous], ADAPTIVITY PERSONALI
   [Anonymous], P TRECVID WORKSH GAI
   [Anonymous], P TRECVID WORKSH GAI
   [Anonymous], P TRECVID WORKSH GAI
   [Anonymous], 7 ACM INT C CONT BAS
   [Anonymous], P TRECVID WORKSH GAI
   [Anonymous], 2007, P CIVR
   [Anonymous], P TRECVID WORKSH
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Hamadi A, 2014, MULTIMED TOOLS APPL, P1
   Hamadi A, 2013, INT WORK CONTENT MUL, P53, DOI 10.1109/CBMI.2013.6576552
   Jiang W., 2010, THESIS
   Li XR, 2012, IEEE T MULTIMEDIA, V14, P1091, DOI 10.1109/TMM.2012.2191943
   Platt JC, 2000, ADV NEUR IN, P61
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Safadi B, 2013, CBMI 2013 11 INT WOR
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   Shu-Ching Chen, 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P80, DOI 10.1109/ICSC.2008.72
   Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Wang G, 2009, IEEE I CONF COMP VIS, P537, DOI 10.1109/ICCV.2009.5459194
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Weng M.F., 2008, PROC ACM INT C MULTI, P71, DOI DOI 10.1145/1459359.1459370
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xie LX, 2008, IEEE IMAGE PROC, P2148, DOI 10.1109/ICIP.2008.4712213
   Yan R., 2003, P 11 ACM INT C MULT, V3, P339, DOI DOI 10.1145/957013.957086
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 27
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8973
EP 8997
DI 10.1007/s11042-015-2730-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500010
DA 2024-07-18
ER

PT J
AU Li, PA
   Li, YF
   Tan, LX
AF Li, Ping'an
   Li, Yufeng
   Tan, Lixin
TI Transfer useful knowledge for headpose estimation from low resolution
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Headpose estimation; Low resolution images; Transfer learning
AB The knowledge of where a person is looking is useful in human computer interaction as well as human behavior analysis. Headpose estimation from low resolution images is still a challenge problem due to noisy feature representation for low resolution images. In this paper, we investigate transfer learning technique to conquer the weakness of the apperance-based feature of humans head-pose when their relative locations to far-field cameras are different. We evaluate our methods on public datasets which prove the efficiency of our proposed method.
C1 [Li, Ping'an; Li, Yufeng; Tan, Lixin] Hunan Coll Informat, Sch Elect Engn, Changsha, Hunan, Peoples R China.
RP Li, PA (corresponding author), Hunan Coll Informat, Sch Elect Engn, Changsha, Hunan, Peoples R China.
EM pingan.li.76@gmail.com
CR [Anonymous], 2007, ICML
   [Anonymous], P ASS COMP LING
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ICPR
   [Anonymous], NIPS
   APerez Cordoba M, 2003, P INT C COMP GRAPH V
   Ba O, 2011, IEEE T PATTERN ANAL
   Ba O, 2005, P INT C MULT EXP
   Bonilla EV., 2008, ADV NEURAL INFORM PR, P153, DOI DOI 10.5555/2981562.2981582
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chutorian E.Murphy., 2009, IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI)
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Evgeniou T, 2002, COMPUT STAT DATA AN, V38, P421, DOI 10.1016/S0167-9473(01)00069-X
   Evgeniou T, 2004, PROC 10TH ACM SIGKDD
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gee A, 1994, DETERMINING GAZE FAC, V12
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Jiang W, 2008, P IEEE INT C IM PROC
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meagher M, 2007, IEEE INT CONF INF VI, P601
   Mihalkova L, 2007, P ADV ART INT AAAI C
   Orozco Javier, 2009, BRIT MACH VIS C
   Pan SJ, 2008, P ASS ADV ART INT
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   RAKOTOMAMONJY A, 2008, J MACHINE LEARNING R
   Robertson N, 2006, P EUR C COMP VIS
   Smith K, 2008, IEEE T PATTERN ANAL
   Sugiyama Masashi, 2008, Advances in Neural Information Processing Systems, P1433
   Tosato D, 2010, P EUR C COMP VIS
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu Pengcheng., 2004, ICML
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang J, 2007, P ACM INT C MULT
   Yao Y, 2010, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2010.5539857
   Zheng VW, 2008, P ASS ADV ART INT
NR 40
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9395
EP 9408
DI 10.1007/s11042-016-3297-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500030
DA 2024-07-18
ER

PT J
AU Su, CH
AF Su, Chung-Ho
TI Developing and evaluating effectiveness of 3D game-based rehabilitation
   system for Total Knee Replacement Rehabilitation patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total knee replacement; 3D game-based rehabilitation; Motivation;
   Physical rehabilitation system
ID VIRTUAL-REALITY; TECHNOLOGY; EQUALITY; INJURY
AB With the development and popularization of virtual reality and motion capture technology, physical therapists have had a new option to improve patient rehabilitation effectiveness. However, there were few studies in the past focusing on total knee replacement (TKR) rehabilitation solutions and many restrictions on the assistance devices. This paper aims to explore how users' motivation and perception of system usability affect rehabilitation performance in a 3D game-based rehabilitation environment. Further, we examine the feasibility of applying Kinect-based method in rehabilitation activities to improve performance. A system called the Physical Rehabilitation System (PRS) was developed and deployed in a one-week TKR rehabilitation process. 27 TKR rehabilitants were divided into a control group (N = 11), and an experimental group, which was rehabilitated with a PRS (N = 16), and had, also, to fill out a questionnaire. The group with higher performances generally had stronger motivation and a better evaluation on a PRS (p < .05). The experimental group showed greater improvement with an average knee-bending angle of 109.38. This study shows that motivation influences the effectiveness of rehabilitation, and that PRS acceptance by rehabilitants was indeed able to strengthen their motivation and improve their rehabilitation outcomes.
C1 [Su, Chung-Ho] Shu Te Univ Taiwan, Dept Animat & Game Design, Kaohsiung, Taiwan.
C3 Shu-Te University
RP Su, CH (corresponding author), Shu Te Univ Taiwan, Dept Animat & Game Design, Kaohsiung, Taiwan.
EM mic6033@stu.edu.tw
CR Alankus G, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P219
   Betker AL, 2007, PHYS THER, V87, P1389, DOI 10.2522/ptj.20060229
   Chan DKC, 2011, PSYCHOL SPORT EXERC, V12, P83, DOI 10.1016/j.psychsport.2010.08.005
   Chang YJ, 2011, RES DEV DISABIL, V32, P2064, DOI 10.1016/j.ridd.2011.08.010
   Chen YP, 2007, PHYS THER, V87, P1441, DOI 10.2522/ptj.20060062
   Delaney HD, 2002, PSYCHOL METHODS, V7, P485, DOI 10.1037//1082-989X.7.4.485
   Deutsch JE, 2008, PHYS THER, V88, P1196, DOI 10.2522/ptj.20080062
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Keller J., 1983, INSTRUCTIONAL DESIGN, P383
   Kubeck JE, 1996, PSYCHOL AGING, V11, P92, DOI 10.1037/0882-7974.11.1.92
   Levac D, 2010, HUM MOVEMENT SCI, V29, P1023, DOI 10.1016/j.humov.2010.06.006
   Lotan M, 2010, RES DEV DISABIL, V31, P869, DOI 10.1016/j.ridd.2010.01.010
   O'Connor TJ, 2000, NEUROREHAB NEURAL RE, V14, P21, DOI 10.1177/154596830001400103
   Reinen IJ, 1997, COMPUT EDUC, V28, P65, DOI 10.1016/S0360-1315(97)00005-5
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Rizzo AA, 1997, J HEAD TRAUMA REHAB, V12, P1, DOI 10.1097/00001199-199712000-00002
   Rose FD, 1999, DISABIL REHABIL, V21, P548
   Ryan R. M., 1985, INTRINSIC MOTIVATION
   Sayenko DG, 2011, MED ENG PHYS, V33, P249, DOI 10.1016/j.medengphy.2010.10.010
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Shaughnessy M, 2006, REHABIL NURS, V31, P15, DOI 10.1002/j.2048-7940.2006.tb00005.x
   Siegel Sidney, 1988, Nonparametric statistics for the behavioral sciences
   Tondeur J, 2008, J COMPUT ASSIST LEAR, V24, P494, DOI 10.1111/j.1365-2729.2008.00285.x
   Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101
   Wood Susie R, 2003, Top Stroke Rehabil, V10, P134
   [No title captured]
NR 27
TC 11
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 10037
EP 10057
DI 10.1007/s11042-015-2820-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500028
DA 2024-07-18
ER

EF