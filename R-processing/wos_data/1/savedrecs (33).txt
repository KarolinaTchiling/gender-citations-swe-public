FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Lu, YF
   Qiao, H
   Li, Y
   Jia, LH
AF Lu, Yan-Feng
   Qiao, Hong
   Li, Yi
   Jia, Li-Hao
TI Image recommendation based on a novel biologically inspired hierarchical
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recommendation; Classification; Biologically inspired model; Image
   retrieval; Feature representation
ID OBJECT RECOGNITION; RECEPTIVE FIELDS; FEATURES; SCENE
AB Image recommendation has become an increasingly relevant problem recently, since strong demand to quickly find interested images from vast amounts of image library. We describe a biologically inspired hierarchical model for image recommendation. The biologically inspired model (BIM) for invariant feature representation has attracted widespread attention, which approximately follows the organization of cortex visuel. BIM is a computation architecture with four layers. With the image data size increases, the four-layer framework is prone to be overfitting, which limits its application. To address this issue, we propose a biologically inspired hierarchical model (BIHM) for feature representation, which adds two more discriminative layers upon the conventional four-layer framework. In contrast to the conventional BIM that mimics the inferior temporal cortex, which corresponds to the low level feature, the proposed BIHM adds two more layers upon the conventional framework to simulate inferotemporal cortex, exploring higher level feature invariance and selectivity. Furthermore, we firstly utilize the BIHM in the image recommendation. To demonstrate the effectiveness of proposed model, we use it to image classification and retrieval tasks and perform experiments on CalTech5, Imagenet and CalTech256 datasets. The experiment results show that BIHM exhibits better performance than the conventional model in the tasks and is very comparable to existing architectures.
C1 [Lu, Yan-Feng; Jia, Li-Hao] Chinese Acad Sci, Inst Automat, Res Ctr Brain Inspired Intelligence, Beijing, Peoples R China.
   [Qiao, Hong] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.
   [Qiao, Hong] CAS Ctr Excellence Brain Sci & Intelligence Techn, Shanghai, Peoples R China.
   [Li, Yi] Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS; Chinese Academy of
   Sciences; Center for Excellence in Brain Science and Intelligence
   Technology, CAS; Nanchang University
RP Lu, YF (corresponding author), Chinese Acad Sci, Inst Automat, Res Ctr Brain Inspired Intelligence, Beijing, Peoples R China.
EM yanfeng.lv@ia.ac.cn; hong.qiao@ia.ac.cn; littlepear@ncu.edu.cn;
   lihao.jia@ia.ac.cn
RI Li, Yi/HHY-7693-2022
FU National Science Foundation of China [61603389]; National Natural
   Science Foundation of China [61502494, 61210009]; Strategic Priority
   Research Program of the CAS [XDB02080003]; Development of Science and
   Technology of Guangdong Province Special Fund Project [2016B090910001]
FX The authors would like to thank the edtors and anonymous reviewers for
   their constructive comments. This work was supported by the National
   Science Foundation of China (Grant 61603389) and partially supported by
   National Natural Science Foundation of China (Grants 61502494, 61210009)
   and also by the Strategic Priority Research Program of the CAS (Grant
   XDB02080003) and the Development of Science and Technology of Guangdong
   Province Special Fund Project(Grant 2016B090910001).
CR [Anonymous], 2014 INT C COMP COMM
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2015 IE INT C COMP I
   [Anonymous], 2012 IE INT C AC SPE
   [Anonymous], 2014, P 22 ACM INT C MULT
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], P 3 ACM C INT C MULT
   [Anonymous], 2004, Realistic modeling of simple and complex cell tuning in the hmaxmodel, and implications for invariant object recognition in cortex'
   [Anonymous], 2015, P IEEE C COMPUTER VI
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], ACM SIGGRAPH
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], P CLEF EHEALTH
   [Anonymous], 2006 IE COMP SOC C C
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Dharani T, 2013, 2013 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, INFORMATICS AND MEDICAL ENGINEERING (PRIME)
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Huang KQ, 2011, IEEE T SYST MAN CY B, V41, P307, DOI 10.1109/TSMCB.2009.2037923
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Kim M, 2013, MULTIMED TOOLS APPL, V64, P505, DOI 10.1007/s11042-011-0897-8
   Kobatake E, 1998, J NEUROPHYSIOL, V80, P324, DOI 10.1152/jn.1998.80.1.324
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Long FH, 2003, SIG COM TEC, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YF, 2017, LECT NOTES COMPUT SC, V10262, P583, DOI 10.1007/978-3-319-59081-3_68
   Lu YF, 2016, NEUROCOMPUTING, V193, P155, DOI 10.1016/j.neucom.2016.01.069
   Lu YF, 2015, IET COMPUT VIS, V9, P663, DOI 10.1049/iet-cvi.2014.0249
   Lu YF, 2014, NEUROCOMPUTING, V139, P189, DOI 10.1016/j.neucom.2014.02.046
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mutch J., 2006, 2006 IEEE COMP SOC C, V1, P11, DOI DOI 10.1109/CVPR.2006.200
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Plant W, 2013, MULTIMED TOOLS APPL, V64, P695, DOI 10.1007/s11042-011-0951-6
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   Qiao H, 2014, IEEE T CYBERNETICS, V44, P1485, DOI 10.1109/TCYB.2013.2287014
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Serre T., 2006, Learning a dictionary of shape-components in visual cortex: Comparison with neurons, humans and machines
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tam KP, 2013, J ENVIRON PSYCHOL, V34, P64, DOI 10.1016/j.jenvp.2013.01.004
   Viana W, 2014, IEEE MULTIMEDIA, V21, P24, DOI 10.1109/MMUL.2013.47
   Wang J, 2015, IEEE T SIGNAL PROCES, V63, P5868, DOI 10.1109/TSP.2015.2468676
   Wang J, 2012, IEEE T SIGNAL PROCES, V60, P6202, DOI 10.1109/TSP.2012.2218810
   Wang J, 2012, IEEE T SIGNAL PROCES, V60, P4973, DOI 10.1109/TSP.2012.2203124
   Wang YS, 2016, J BIOMED INFORM, V63, P379, DOI 10.1016/j.jbi.2016.08.026
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Zhang HZ, 2016, NEUROCOMPUTING, V218, P242, DOI 10.1016/j.neucom.2016.08.051
NR 52
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4323
EP 4337
DI 10.1007/s11042-017-5514-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500016
DA 2024-07-18
ER

PT J
AU Xu, PF
   Guo, ST
   Miao, QG
   Li, BG
   Chen, XJ
   Fang, DY
AF Xu, Pengfei
   Guo, Songtao
   Miao, Qiguang
   Li, Baoguo
   Chen, Xiaojiang
   Fang, Dingyi
TI Face detection of golden monkeys via regional color quantization and
   incremental self-paced curriculum learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE golden monkey; face detection; regional color quantization; incremental
   self-paced curriculum learning
AB Animal detection plays a very vital role in wildlife protection and many other real life applications. In this paper, we focus on face detection of Golden monkeys who live in Qinling Mountains, Shaanxi province, China, and present a relatively complete face detection algorithm to detect these monkeys' faces, which mainly includes three parts: the location of the monkeys' bodies, the detection of th+e suspicious facial skin and the accurate detection of the true faces. Firstly, regional color quantization is proposed to quantize the HSV color space for the nature images with different sizes, and we can get the areas of the monkeys' bodies according to the color distribution of the monkeys' hair in the histogram of the quantized color space. Then the areas of suspicious facial skin can be extracted from these areas of the monkeys' bodies. Further, we propose incremental self-paced curriculum learning (ISPCL) to detect the true monkeys' faces accurately. In our method, regional color quantization can increase the color differences between the background and the monkeys' hair, so that the segmented results have fewer background pixels. Besides, the basic idea of the incremental learning is introduced into the training process of SPCL, which is to simulate the process in which human learn something from easy samples to hard ones, this idea is able to improve the performances of face detection. The experimental results demonstrate that the proposed algorithm can locate the monkeys' bodies in the images with different sizes, and can detect their faces effectively. This research lays a foundation for face recognition and behavior analysis of golden monkeys.
C1 [Xu, Pengfei; Chen, Xiaojiang; Fang, Dingyi] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Guo, Songtao; Li, Baoguo] Northwest Univ, Shaanxi Key Lab Anim Conservat, Xian, Shaanxi, Peoples R China.
   [Miao, Qiguang] Xidian Univ, Sch Comp, Xian 710071, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Northwest University Xi'an; Xidian
   University
RP Guo, ST (corresponding author), Northwest Univ, Shaanxi Key Lab Anim Conservat, Xian, Shaanxi, Peoples R China.
EM pfxu@nwu.edu.cn; songtaoguo@nwu.edu.cn; qgmiao@126.com;
   baoguoli@nwu.edu.cn; xjchen@nwu.edu.cn; dyf@nwu.edu.cn
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundations of China [61502387, 41601353];
   Natural Science Foundation of Shaanxi Province [2016JQ6029]; 59th
   China's Post-doctoral Science Fund [2016 M592832]
FX The work was jointly supported by the National Natural Science
   Foundations of China under grant No. 61502387 and 41601353; Natural
   Science Foundation of Shaanxi Province, under grant No. 2016JQ6029; The
   59th China's Post-doctoral Science Fund No. 2016 M592832.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.376
   [Anonymous], 2015, AAAI C ARTIF INTELL, DOI DOI 10.1109/IJCNN.2015.7280498
   Baratchi M, 2013, SENSORS-BASEL, V13, P6054, DOI 10.3390/s130506054
   Burghardt T, 2006, IEE P-VIS IMAGE SIGN, V153, P305, DOI 10.1049/ip-vis:20050052
   Burghardt T, 2004, EUR WORKSH INT KNOWL, P1
   Cao JP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077922
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Du X., 2011, LAB ANIM COMP MED, V31, P166
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Karlsson J., 2010, Proceedings of the 2010 IEEE/ACM Int'l Conference on Green Computing and Communications (GreenCom) and Int'l Conference on Cyber, Physical and Social Computing (CPSCom), P510, DOI 10.1109/GreenCom-CPSCom.2010.69
   Koik BT, 2012, J ANIM VET ADV, V11, P3557, DOI 10.3923/javaa.2012.3557.3560
   Lahiri M., 2011, P 1 ACM INT C MULT R, V6, P1, DOI [10.1145/1991996.1992002, DOI 10.1145/1991996.1992002]
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   RAKESH R, 2012, RES J APPL SCI ENG T, V4, P5344
   Rousselet GA, 2003, J VISION, V3, P440, DOI 10.1167/3.6.5
   Royle JA, 2003, ECOLOGY, V84, P777, DOI 10.1890/0012-9658(2003)084[0777:EAFRPA]2.0.CO;2
   Sharma S., 2013, SIGNAL IMAGE PROCESS, V4, P77, DOI DOI 10.5121/SIPIJ.2013.4307
   Tie J, 2013, PLANT FLORA CHARACTE
   Tweed D, 2002, INT C PATT RECOG, P24, DOI 10.1109/ICPR.2002.1048227
   Wei PL, 2011, SCI CULT, V3, P12
   Wichmann FA, 2010, J VISION, V10, DOI 10.1167/10.4.6
   Yang B, 2013, CHINESE B BIOL, V48, P8
   Zeppelzauer M, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-46
   ZHANG CJ, 2010, TECHN REP MSR TR, V1, P1
   Zhang DY, 2007, INT AC SEM EM HLTH D, P289
   Zhang WW, 2011, IEEE T IMAGE PROCESS, V20, P1696, DOI 10.1109/TIP.2010.2099126
NR 31
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3143
EP 3170
DI 10.1007/s11042-017-4984-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600013
DA 2024-07-18
ER

PT J
AU Kang, ZH
   Kim, K
AF Kang, Ziho
   Kim, Kwangtaek
TI Multimodal perception study on virtual 3D curved textures with vision
   and touch for interactive multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Multi-sensory perception; Tactile feedback; Human
   computer interface; Human factors and engineering; 3D touch interaction
ID HAPTIC PERCEPTION; 3-D SHAPE; CURVATURE; DISCRIMINATION; INFORMATION;
   DISPLAY; OBJECTS
AB Understanding the multimodal rendering of 3D shapes is becoming an important research topic as multimedia and virtual reality technologies are rapidly advancing. This study is aimed to investigate human perceptibility on the curvature and texture changes of 3D virtual surfaces across modalities, vision and touch. Our interest is to obtain perception data that can be used for 3D watermarking or data compression under a virtual reality environment providing multimodal interactions. For this study, we designed two psychophysical experiments to estimate curvature discrimination and texture detection thresholds on curvature surfaces over three conditions: vision only, touch only, and both vision and touch. The results show that touch is dominant at both discriminating curvature surfaces and detecting surface texture changes on a curved surface. In addition, the sensitivity of the both senses to detect texture changes linearly increases as a curvature value increases. Finally, the vision and touch senses compensate each other when both modalities are available at the same time. The thresholds from the present study can potentially be used as the upper limit for selecting watermark strengths or compression in order to ensure imperceptibility in a 3D visuohaptic multimedia systems.
C1 [Kang, Ziho] Univ Oklahoma, Sch Ind & Syst Engn, Norman, OK 73019 USA.
   [Kim, Kwangtaek] Incheon Natl Univ, Dept Informat & Telecommun Engn, Incheon, South Korea.
C3 University of Oklahoma System; University of Oklahoma - Norman; Incheon
   National University
RP Kim, K (corresponding author), Incheon Natl Univ, Dept Informat & Telecommun Engn, Incheon, South Korea.
EM ktkim@inu.ac.kr
RI Kang, Ziho/V-6929-2019
OI Kang, Ziho/0000-0003-4058-4584
FU Incheon National University [2015]
FX This work was supported by Incheon National University (International
   Cooperative) Research Grant in 2015 (grant no. 2015).
CR Dostmohamed H, 2005, EXP BRAIN RES, V164, P387, DOI 10.1007/s00221-005-2262-5
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Frisoli A, 2008, PRESENCE-TELEOP VIRT, V17, P550, DOI 10.1162/pres.17.6.550
   Frizoli A., 2004, S MULTIPOINT INTERAC, P177
   Gibson J. J, 2014, ECOLOGICAL APPROACH, DOI DOI 10.4324/9781315740218
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   GORDON IE, 1982, PERCEPT PSYCHOPHYS, V31, P446, DOI 10.3758/BF03204854
   Helbig HB, 2007, EXP BRAIN RES, V179, P595, DOI 10.1007/s00221-006-0814-y
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Huffman DA, 1977, MACH INTELL, V8, P2
   Jansson G, 2002, TECH REP
   Kang ZH, 2015, IEEE T HUM-MACH SYST, V45, P13, DOI 10.1109/THMS.2014.2363121
   Kim K, 2016, SKIN RES TECHNOL, V22, P334, DOI 10.1111/srt.12270
   Kim K, 2012, SEEING PERCEIVING, V25, P351, DOI 10.1163/187847612X629937
   KLATZKY RL, 1985, PERCEPT PSYCHOPHYS, V37, P299, DOI 10.3758/BF03211351
   KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321
   Lederman SJ, 2004, PERCEPT PSYCHOPHYS, V66, P618, DOI 10.3758/BF03194906
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527
   Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Pont SC, 1999, PERCEPT PSYCHOPHYS, V61, P874, DOI 10.3758/BF03206903
   Provancher WR, 2005, INT J ROBOT RES, V24, P691, DOI 10.1177/0278364905057121
   Reed CL, 2004, HUM BRAIN MAPP, V21, P236, DOI 10.1002/hbm.10162
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P943, DOI 10.3758/BF03206908
   Todd JT, 2003, PERCEPT PSYCHOPHYS, V65, P31, DOI 10.3758/BF03194781
   Tse PU, 2002, PSYCHOL REV, V109, P91, DOI 10.1037//0033-295X.109.1.91
   VANDAMME WJM, 1994, PERCEPT PSYCHOPHYS, V55, P340, DOI 10.3758/BF03207604
   Vogels IMLC, 1999, ACTA PSYCHOL, V100, P267, DOI 10.1016/S0001-6918(98)00041-9
   Wijntjes MWA, 2008, LECT NOTES COMPUT SC, V5024, P361, DOI 10.1007/978-3-540-69057-3_46
   Wijntjes MWA, 2009, IEEE T HAPTICS, V2, P94, DOI [10.1109/TOH.2009.1, 10.1109/ToH.2009.1]
   Zangaladze A, 1999, NATURE, V401, P587, DOI 10.1038/44139
NR 34
TC 8
Z9 8
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2209
EP 2223
DI 10.1007/s11042-017-4392-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400032
DA 2024-07-18
ER

PT J
AU Katarya, R
   Verma, OP
AF Katarya, Rahul
   Verma, Om Prakash
TI Efficient music recommender system using context graph and particle
   swarm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Collaborative filtering; Hybrid; Particle swarm
   optimization; Music
ID MATRIX FACTORIZATION; ALGORITHMS; IMPLICIT
AB Music recommender systems is an important field of research because of easy availability and use of online music. The most existing models only focus on explicit data like ratings and other user-item dimensions. A challenging problem in music recommendation is to model a variety of contextual information, such as feedback, time and location. In this article, we proposed a competent hybrid music recommender system (HMRS), which works on context and collaborative approaches. The timestamp is extracted from users listening log to construct a decision context behavior that extracted various temporal features like a week, sessions(as morning, evening or night). We used depth-first-search (DFS) algorithm which traverses the whole graph through the paths in different contexts. Bellman-Ford algorithm provides ranked list of recommended items with multi-layer context graph. We enhanced the process using particle swarm optimization (PSO) which produced highly optimized results. The dataset is used from Last.fm which contains 19,150,868 music listening logs of 992 users (till May, 4th 2009). We extract the properties of music from user's listening history and evaluate the efficient system to recommend music based on user's contextual preferences. Our system noticeably delivers the best recommendations regarding recall results when compared to existing methods.
C1 [Katarya, Rahul; Verma, Om Prakash] Delhi Technol Univ, Delhi Coll Engn, Dept Comp Sci & Engn, Main Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University
RP Katarya, R (corresponding author), Delhi Technol Univ, Delhi Coll Engn, Dept Comp Sci & Engn, Main Bawana Rd, Delhi 110042, India.
EM rahulkatarya@dtu.ac.in
RI Katarya, Dr. Rahul/AAH-9233-2020
OI Katarya, Dr. Rahul/0000-0001-7763-291X
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Alqadah F, 2015, KNOWL INF SYST, V44, P475, DOI 10.1007/s10115-014-0771-x
   AWERBUCH B, 1994, IEEE T COMMUN, V42, P2515, DOI 10.1109/26.310604
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Chen H, 2016, J SUPERCOMPUT, V72, P2565, DOI 10.1007/s11227-015-1518-5
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Chen SH, 2015, INFORM SCIENCES, V318, P123, DOI 10.1016/j.ins.2014.09.058
   Christensen I, 2013, MEX INT CONF ARTIF I, P10, DOI 10.1109/MICAI.2013.7
   Cormen T. H., 2009, INTRO ALGORITHMS, DOI [10.1163/9789004256064_hao_introduction, DOI 10.1163/9789004256064_HAO_INTRODUCTION]
   Diaz-Aviles E., 2009, P 11 ANN C GEN EV CO, P9, DOI DOI 10.1145/1569901.1569904
   Elmisery AM, 2016, J SUPERCOMPUT, V72, P247, DOI 10.1007/s11227-015-1574-x
   GOLDBERG AV, 1993, APPL MATH LETT, V6, P3, DOI 10.1016/0893-9659(93)90022-F
   Gong YJ, 2015, APPL SOFT COMPUT, V34, P286, DOI 10.1016/j.asoc.2015.04.061
   Guo L, 2015, SOFT COMPUT, V19, P1351, DOI 10.1007/s00500-014-1347-0
   Huang Z, 2007, IEEE INTELL SYST, V22, P68, DOI 10.1109/MIS.2007.4338497
   Hwang WS, 2016, INFORM FUSION, V28, P75, DOI 10.1016/j.inffus.2015.07.005
   Jiang M, 2014, IEEE T KNOWL DATA EN, V26, P2789, DOI 10.1109/TKDE.2014.2300487
   Katarya R, 2018, NEURAL COMPUT APPL, V30, P1679, DOI 10.1007/s00521-016-2817-3
   Katarya R, 2017, EGYPT INFORM J, V18, P105, DOI 10.1016/j.eij.2016.10.002
   Katarya R, 2017, MULTIMED TOOLS APPL, V76, P21481, DOI 10.1007/s11042-016-4078-7
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Katarya R, 2016, PHYSICA A, V461, P182, DOI 10.1016/j.physa.2016.05.046
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kim HN, 2013, MULTIMEDIA SYST, V19, P509, DOI 10.1007/s00530-012-0298-5
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lee WP, 2016, KNOWL-BASED SYST, V106, P125, DOI 10.1016/j.knosys.2016.05.037
   Mao K, 2016, SIGNAL PROCESS, V120, P806, DOI 10.1016/j.sigpro.2015.03.026
   Maurus S, 2016, KNOWL INF SYST, V46, P1, DOI 10.1007/s10115-015-0838-3
   Najafabadi MK, 2016, ARTIF INTELL REV, V45, P167, DOI 10.1007/s10462-015-9443-9
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pirasteh P, 2015, KNOWL-BASED SYST, V83, P51, DOI 10.1016/j.knosys.2015.03.006
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Systems C, 2013, 2013 5 INT C INT NET, DOI [10.1109/INCoS.2013.27, DOI 10.1109/INCOS.2013.27]
   Thakkar S, 2015, INT J APPL INNOVATIO, V4, P161
   Tkalcic M, 2010, USER MODEL USER-ADAP, V20, P279, DOI 10.1007/s11257-010-9079-z
   Ujjin S, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P124, DOI 10.1109/SIS.2003.1202257
   Vanattenhoven J, 2015, PERS UBIQUIT COMPUT, V19, P761, DOI 10.1007/s00779-015-0861-0
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Xu YS, 2015, ENG APPL ARTIF INTEL, V45, P281, DOI 10.1016/j.engappai.2015.07.012
   Yao WL, 2015, WORLD WIDE WEB, V18, P1351, DOI 10.1007/s11280-014-0307-z
   Yin HZ, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2663356
   Yuan T, 2015, KNOWL-BASED SYST, V88, P70, DOI 10.1016/j.knosys.2015.08.005
   Zhao DZ, 2016, PROCEDIA COMPUT SCI, V91, P959, DOI 10.1016/j.procs.2016.07.121
   ZHAO SC, 2014, IEEE INT CON MULTI, pNI255
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao W, 2015, NEUROCOMPUTING, V148, P521, DOI 10.1016/j.neucom.2014.07.011
   Zhou W, 2014, DECIS SUPPORT SYST, V68, P89, DOI 10.1016/j.dss.2014.09.006
   Zhu TQ, 2014, FUTURE GENER COMP SY, V36, P142, DOI 10.1016/j.future.2013.07.019
NR 52
TC 42
Z9 43
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2673
EP 2687
DI 10.1007/s11042-017-4447-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400051
DA 2024-07-18
ER

PT J
AU de Andrade, DOS
   Maia, LF
   de Figueiredo, HF
   Viana, W
   Trinta, F
   Baptista, CD
AF Serrano de Andrade, Davi Oliveira
   Maia, Luis Fernando
   de Figueiredo, Hugo Feitosa
   Viana, Windson
   Trinta, Fernando
   Baptista, Claudio de Souza
TI Photo annotation: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo annotation; Event annotation; Location annotation; People
   annotation
ID FACE RECOGNITION; INFORMATION; RETRIEVAL
AB Due to the large number of photos that are currently being generated, it is very important to have techniques to organize, search for, and retrieve such images. Photo annotation plays a key role in these mechanisms because it can link raw data (photos) to specific information that is essential for human beings to handle large amounts of content. However, the generation of photo annotation is still a difficult problem to solve as part of a well-known challenge called the semantic gap. In this paper, a literature review was conducted with the aim of investigating the most popular methods employed to produce photo annotations. Based on the papers surveyed, we identified that People ("Who?"), Location ("Where?"), and Event ("Where? When?") are the most important features of photo annotation. We also established comparisons between similar photo annotation methods, highlighting key aspects of the most commonly used approaches. Moreover, we provide an overview of a general photo annotation process and present the main aspects of photo annotation representation comprising formats, context of usage, advantages and disadvantages. Finally, we discuss ways to improve photo annotation methods and present some future research guidelines.
C1 [Serrano de Andrade, Davi Oliveira; Baptista, Claudio de Souza] Univ Campina Grande, Informat Syst Lab, Campina Grande, Brazil.
   [Maia, Luis Fernando] Fed Inst Educ Sci & Technol Maranhao, Sao Luis, Brazil.
   [de Figueiredo, Hugo Feitosa] Fed Inst Educ Sci & Technol Paraiba, Esperanca, Brazil.
   [Viana, Windson; Trinta, Fernando] Univ Fed Ceara, Fortaleza, Ceara, Brazil.
C3 Instituto Federal do Maranhao; Instituto Federal da Paraiba (IFPB);
   Universidade Federal do Ceara
RP de Andrade, DOS (corresponding author), Univ Campina Grande, Informat Syst Lab, Campina Grande, Brazil.
EM davi@copin.ufcg.edu.br; luis.maia@ifma.edu.br;
   hugo.figueiredo@ifpb.edu.br; windson@great.ufc.br;
   fernandotrinta@great.ufc.br; baptista@computacao.ufcg.edu.br
RI DE CARVALHO, WINDSON VIANA/E-8998-2015
OI DE CARVALHO, WINDSON VIANA/0000-0002-8627-0823
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Ahern S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P357
   Anguelov D., 2007, Computer Vision and Pattern Recognition, P1
   [Anonymous], VIGTA 2013 P INT WOR
   [Anonymous], ICWSM 2011 P 5 INT A
   [Anonymous], VIE 2006 P IET INT C
   [Anonymous], P NOKIAMOB DAT CHALL
   [Anonymous], 2009, MM 09 P 2009 ACM MUL, DOI DOI 10.1145/1631272.1631456
   [Anonymous], GEOPROCESSING 2013 P
   [Anonymous], P MULT SEC
   [Anonymous], GEORICH 2014 P WORK
   [Anonymous], ICMR 2013 P 3 ACM C
   [Anonymous], P WORK SUPP HUM MEM
   [Anonymous], 2014, MULT SYST C 2014
   [Anonymous], MM 2013 P 21 ACM INT
   [Anonymous], WEBMEDIA 2008 P 14 B
   [Anonymous], ICMR 2012 P 2 ACM IN
   [Anonymous], ICMR 2013 P 3 ACM C
   [Anonymous], P MED 2015 WORK WURZ
   [Anonymous], 2014, P 1 INT WORKSH GAM I
   [Anonymous], P 4 INT SEM WEB C
   [Anonymous], 2013, MEDIAEVAL
   [Anonymous], SAAW 2006 P 1 SEM WE
   [Anonymous], J COGN NEUROSCI
   [Anonymous], P IS T SPIE 18 ANN S
   [Anonymous], P MEDIAEVAL 2013 MUL
   [Anonymous], ISWC 2002 P 1 INT SE
   [Anonymous], WWW 2012 P 21 INT C
   [Anonymous], PERMIS 2010 P 10 PER
   [Anonymous], 2013, 2013 INT C IT CONV S, DOI DOI 10.1109/ICITCS.2013.6717813
   [Anonymous], P 1 1 INT WORK SEM W
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], 2011, P 19 ACM INT C MULT, DOI [DOI 10.1145/2072298.2072345, 10.1145/2072298.2072345]
   [Anonymous], 2011, 2011 IEEE 73 VEHICUL
   Baltieri D., 2013, Proceedings of the 21st ACM International Conference on Multimedia, MM'13, P557
   Becker Hila., 2012, Proceedings of the fifth ACM international conference on Web search and data mining, P533, DOI [DOI 10.1145/2124295.2124360, 10.1145/2124295.212436017, DOI 10.1145/2124295.212436017]
   Caprani N, 2014, INT J MOB HUM COMPUT, V6, P15, DOI 10.4018/ijmhci.2014010102
   Chai YM, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P38, DOI 10.1109/CIMSA.2009.5069914
   Choi J, 2009, PROC 16 INT C DIGIT, P1
   Choi J.Y., 2008, MIR 08, P44
   Choi JY, 2011, IEEE T MULTIMEDIA, V13, P14, DOI 10.1109/TMM.2010.2087320
   Choi JY, 2010, IEEE T CIRC SYST VID, V20, P1292, DOI 10.1109/TCSVT.2010.2058470
   Cooray SH, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P251, DOI 10.1109/DEXA.2009.41
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   De Choudhury Munmun, 2012, ACM 2012 Conference on Computer Supported Cooperative Work, P241, DOI DOI 10.1145/2145204.2145242
   de Figueirêdo HF, 2012, MULTIMED TOOLS APPL, V59, P279, DOI 10.1007/s11042-011-0745-x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng KY, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P63, DOI 10.1145/2588555.2612173
   Gallagher A., 2008, P 16 ACM INT C MULTI, P681
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   Gallagher AndrewC., 2009, IPSJ Transactions on Computer Vision and Applications, V1, P115
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hollenstein L, 2010, J SPAT INT SCI, P21, DOI 10.5311/JOSIS.2010.1.3
   Hulsebosch RJ, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P397, DOI 10.1109/ARES.2008.45
   Ilina Elena, 2012, Web Engineering. Proceedings 12th International Conference, ICWE 2012, P169, DOI 10.1007/978-3-642-31753-8_12
   Ivanov I, 2012, MULTIMED TOOLS APPL, V56, P155, DOI 10.1007/s11042-010-0570-7
   Izquierdo E, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P131, DOI 10.1109/ICIAPW.2007.32
   Joshi D, 2012, MULTIMED TOOLS APPL, V56, P131, DOI 10.1007/s11042-010-0553-8
   Kim HN, 2012, EXPERT SYST APPL, V39, P6955, DOI 10.1016/j.eswa.2012.01.022
   Lacerda YA, 2008, IEEE INT SYM MULTIM, P258, DOI 10.1109/ISM.2008.81
   Lee YJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.36
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Lin DH, 2010, LECT NOTES COMPUT SC, V6311, P243
   Malpas JE., 2007, Place and Experience: A Philosophical Topography
   Martins Bruno, 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P1, DOI 10.1109/ICSC.2008.86
   Medvet E., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P47, DOI 10.1109/WI-IAT.2011.101
   Mezaris V, 2014, MULTIMED TOOLS APPL, V70, P1, DOI 10.1007/s11042-013-1426-8
   Monaghan F, 2007, LECT NOTES COMPUT SC, V4816, P252
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   Naaman M., 2004, P 12 ANN ACM INT C M, P196
   Nakaji Y, 2012, IEEE INT CONF MULTI, P272, DOI 10.1109/ICMEW.2012.53
   Nita B, 2013, I C CONTR SYS COMP S, P255, DOI 10.1109/CSCS.2013.13
   O'Hare N, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P880, DOI 10.1145/1244002.1244195
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599
   Oliveira Serrano de Andrade Davi, 2014, 16th International Conference on Enterprise Information Systems (ICEIS 2014). Proceedings, P92
   Ou Wu, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P648, DOI 10.1109/WIIAT.2008.48
   Petridis K, 2006, LECT NOTES ARTIF INT, V4253, P633
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Psallidas F., 2013, IEEE Data Eng. Bull, V36, P42
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sadlier David A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P215, DOI 10.1109/WIAMIS.2008.16
   Sandhaus P, 2011, MULTIMED TOOLS APPL, V51, P5, DOI 10.1007/s11042-010-0673-1
   Schreiber AT, 2001, IEEE INTELL SYST APP, V16, P66, DOI 10.1109/5254.940028
   de Andrade DOS, 2014, LECT NOTES ARTIF INT, V8864, P742, DOI 10.1007/978-3-319-12027-0_60
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JR, 2011, IEEE MULTIMEDIA, V18, P2, DOI 10.1109/MMUL.2011.47
   Spyrou E, 2016, NEUROCOMPUTING, V172, P114, DOI 10.1016/j.neucom.2014.12.104
   Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551
   Suh B, 2007, INTERACT COMPUT, V19, P524, DOI 10.1016/j.intcom.2007.02.002
   Verborgh R, 2012, MULTIMED TOOLS APPL, V61, P105, DOI 10.1007/s11042-010-0709-6
   Viana W, 2011, MULTIMED TOOLS APPL, V53, P391, DOI 10.1007/s11042-010-0502-6
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Vyas D, 2013, LECT NOTES COMPUT SC, V8120, P55
   WAGENAAR WA, 1986, COGNITIVE PSYCHOL, V18, P225, DOI 10.1016/0010-0285(86)90013-7
   Wang G, 2010, LECT NOTES COMPUT SC, V6315, P169, DOI 10.1007/978-3-642-15555-0_13
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang Xianwang., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P1353
   Wells Liz., 2015, PHOTOGRAPHY CRITICAL, V5th
   Wilhelm A., 2004, Proc. CHI Extended Abstracts, P1403
   Yagnik J., 2007, International Workshop on Multimedia Information Retrieval, P285
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang W, 2010, IEEE IMAGE PROC, P4593, DOI 10.1109/ICIP.2010.5651704
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu SH, 2015, PATTERN RECOGN LETT, V65, P103, DOI 10.1016/j.patrec.2015.07.037
   Zigkolis C, 2014, MULTIMED TOOLS APPL, V70, P89, DOI 10.1007/s11042-012-1154-5
NR 113
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 423
EP 457
DI 10.1007/s11042-016-4281-6
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400018
DA 2024-07-18
ER

PT J
AU Shakoor, MH
   Boostani, R
AF Shakoor, Mohammad Hossein
   Boostani, Reza
TI A novel advanced local binary pattern for image-based coral reef
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coral reef classification; Local binary patterns; Texture feature
   extraction
ID INVARIANT TEXTURE CLASSIFICATION; GRAY-SCALE; ROTATION; FEATURES;
   RECOGNITION
AB High computational burden and low accuracy in non-uniform textures are the two main challenges of coral reef classification frameworks. To overcome these drawbacks, two novel forms of mapping approaches are proposed to enable Local Binary Patterns (LBP) scheme to extract discriminative features from textures. The mapping approach is away to map the extracted features into a histogram (features vector) efficiently. In other words, the mapping method can merge some features into a feature and provides lower number of features efficiently. The proposed mapping techniques can be used for various types of LBPs; consequently, the extended LBPs can be applied to all types of textures. Benthic texture datasets are employed to assess the proposed method compared to the traditional ones. Regarding the multimodal distribution of the elicited features, K-Nearest Neighbor (KNN) is employed for classifying the extracted features. Here, the proposed mapping methods are tested on a special form of completed local binary patterns (CLBP). From the accuracy point of view, the extended CLBPs demonstrate higher accuracy compared to CLBP and also other state-of-the-art LBPs. Moreover, the proposed mapping approaches enhance the accuracy of rotation invariant LBPs, especially for large neighborhood. The proposed methods improve the classification accuracy for both noisy and noise-free images. From the computational complexity point of view, the extended CLBPs provide lower number of features compared to the others which leads to a faster recall time in KNN classifier.
C1 [Shakoor, Mohammad Hossein] Islamic Azad Univ, Shiraz Branch, Dept Comp Engn, Shiraz, Iran.
   [Boostani, Reza] Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
C3 Islamic Azad University; Shiraz University
RP Shakoor, MH (corresponding author), Islamic Azad Univ, Shiraz Branch, Dept Comp Engn, Shiraz, Iran.
EM mhshakoor@google.com
RI Boostani, Reza/ABC-5999-2021
OI Boostani, Reza/0000-0003-0055-4452
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beijbom O, 2012, P IEEE C COMP VIS PA, P16
   Bianconi F, 2011, J MATH IMAGING VIS, V40, P259, DOI 10.1007/s10851-011-0261-7
   Campisi P, 2004, IEEE T IMAGE PROCESS, V13, P782, DOI 10.1109/TIP.2003.822607
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   Clement R, 2005, AUSTR C ROB AUT AUST
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   EICHMANN G, 1988, COMPUT VISION GRAPH, V41, P267, DOI 10.1016/0734-189X(88)90102-8
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Fukunaga K, 1990, INTRO STAT PATTERN R, p[3, 97]
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Goodman JA, 2007, J APPL REMOTE SENS, V1, DOI 10.1117/1.2815907
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haralick RM, 1979, IEEE T SYSTEMS MAN C
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Kim ND, 2000, IEEE T SYST MAN CY A, V30, P847, DOI 10.1109/3468.895915
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Lam WK, 1997, IEE P-VIS IMAGE SIGN, V144, P171, DOI 10.1049/ip-vis:19971198
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leutenegger Stefan., 2011, BRISK BINARY ROBUST
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loya Y, 2004, CORAL HEALTH AND DISEASE, P1
   Marcos MSA, 2008, ENVIRON MONIT ASSESS, V145, P177, DOI 10.1007/s10661-007-0027-2
   Mehta A, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P302
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mir AH, 1995, ENG MED BIOL MAGAZIN, V14
   Nanni L, 2012, PATTERN RECOGN, V45, P3844, DOI 10.1016/j.patcog.2012.04.007
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1997, ACTA UNIVERSIT IS C, V105
   Padmavathi G., 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P983, DOI 10.1109/CISP.2010.5646932
   Pican N, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P424, DOI 10.1109/OCEANS.1998.725781
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pizarro O, 2013, REMOTE SENS, V5, P1834
   Roelfsema C, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3430107
   Shakoor M. H., 2015, IRANIAN J ELECT ELEC, V11, P195
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Soriano M, 2001, OCEANS 2001 MTS/IEEE: AN OCEAN ODYSSEY, VOLS 1-4, CONFERENCE PROCEEDINGS, P1008, DOI 10.1109/OCEANS.2001.968254
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Turner W, 2003, TRENDS ECOL EVOL, V18, P306, DOI 10.1016/S0169-5347(03)00070-3
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   VARMA M, 2003, PROC CVPR IEEE, P691, DOI DOI 10.1109/CVPR.2003.1211534
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 60
TC 21
Z9 21
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2561
EP 2591
DI 10.1007/s11042-017-4394-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400046
DA 2024-07-18
ER

PT J
AU Sujatha, K
   Punithavathani, DS
AF Sujatha, K.
   Punithavathani, D. Shalini
TI Optimized ensemble decision-based multi-focus imagefusion using binary
   genetic Grey-Wolf optimizer in camera sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Grey wolf optimizer; Noisy feature validation;
   Camera sensor network
ID IMAGE FUSION; WAVELETS
AB Modern developments in image technology enabled easy access to an innovative type of sensor-based networks, Camera or Visual Sensor Networks (VSN). Nevertheless, more sensor data sources bring about the problem of overload information. To solve this problem, some researchers have been carried out on the techniques to counteract the data overload caused by sensors without losing useful data. The aim of fusion in each application is to combine images from several sensors, which leads to the decreased amount of input image data, producing an image with more accurate data. This paper proposes a noisy feature removal scheme for multi-focus image fusion combining the decision information of optimized individual features. The proposed scheme is developed in two main steps. In the first step, the diverse types of features are extracted from each block of input blurred images. The useful information of these individual features indicates which image block is more focused among corresponding blocks in source images. After that, noisy features are removed using binary Genetic Grey wolf optimizer (GGWO) algorithm. The ensemble decision based on individual features is employed to fuse blurred images in the second step. The experimentation is evaluated on different multi-focus images and it reveals that GGWO based proposed method performs better visual quality than other methods.
C1 [Sujatha, K.] Anna Univ, Govt Coll Engn, Tirunelveli, India.
   [Punithavathani, D. Shalini] Govt Coll Engn, Tirunelveli, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Sujatha, K (corresponding author), Anna Univ, Govt Coll Engn, Tirunelveli, India.
EM sujathassps@gcetly.ac.in; shalini329@gmail.com
OI krishnamoorthy, sujatha/0000-0002-0122-6357
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Anish A, 2012, INT J ADV RES COMPUT, V1, P2012
   [Anonymous], IEEE INT ZUR SEM COM
   [Anonymous], IRE T MILITARY ELECT
   [Anonymous], INT C TEL CHENGD CHI
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Chen TH, 2004, IEEE INT C IM PROC
   Dargie W., 2010, FUNDAMENTALS WIRELES, DOI DOI 10.1002/9780470666388
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fleck S, 2008, P IEEE, V96, P1698, DOI 10.1109/JPROC.2008.928765
   Ghoggali N., 2008, P IEEE IGARSS BOST M, V4, P538
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Han XH, 2013, INFORM SCIENCES, V218, P103, DOI 10.1016/j.ins.2012.06.033
   Jiwu H, 1999, J IMAGE GRAPH, V4, P400
   Kausar N, 2016, COMPUTERS ELECT ENG, P1
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kong J, 2008, INT J COMPUT SCI NET, V8, P220
   Li YF, 2015, OPTIK, V126, P107, DOI 10.1016/j.ijleo.2014.08.136
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nooshyar M, 2014, COMM COM INF SC, V427, P23, DOI 10.1007/978-3-319-10849-0_3
   Schreer O, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P1, DOI 10.1002/0470022736
   Shah P, 2013, SIGNAL IMAGE VIDEO P, V7, P95, DOI 10.1007/s11760-011-0219-7
   Sheen DM, 2001, IEEE T MICROW THEORY, V49, P1581, DOI 10.1109/22.942570
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Skolnik M, 2001, IEEE T AERO ELEC SYS, V37, P1163, DOI 10.1109/7.976957
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Tang JS, 2004, DIGIT SIGNAL PROCESS, V14, P218, DOI 10.1016/j.dsp.2003.06.001
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Vinu S, INT J INTELLIGENT EN, V9, P117
   Wan T, 2009, IEEE T MULTIMEDIA, V11, P624, DOI 10.1109/TMM.2009.2017640
   Wang ZS, 2015, OPTIK, V126, P4184, DOI 10.1016/j.ijleo.2015.08.118
   Zhang P., 2015, MATH PROBL ENG, V2015
   Zhang Y, 2009, DIGIT SIGNAL PROCESS, V19, P86
   Zhao HJ, 2013, PATTERN RECOGN, V46, P1002, DOI 10.1016/j.patcog.2012.09.012
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 39
TC 27
Z9 29
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1735
EP 1759
DI 10.1007/s11042-016-4312-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400012
DA 2024-07-18
ER

PT J
AU Thanh, TM
   Tanaka, K
   Dung, LH
   Tai, NT
   Nam, HN
AF Ta Minh Thanh
   Tanaka, Keisuke
   Luu Hong Dung
   Nguyen Tuan Tai
   Hai Nguyen Nam
TI Performance analysis of robust watermarking using linear and nonlinear
   feature matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear feature; Nonlinear feature; Feature point matching; Accelerated
   KAZE (AKAZE) feature; KAZE feature; SIFT feature; SURF;
   Rotation-Scaling-Translation (RST) attack; Image watermarking
AB Recently, the feature point matching based watermarking techniques have been paying attention for resisting the geometric attacks. We present a performance analysis of robust watermarking using the linear and nonlinear features. In particular, we consider the geometric attacks and the signal processing attacks for the image watermarking. In order to analyze the efficiency of linear and nonlinear features, we employ the linear and the nonlinear feature matching technique in the image watermarking. The extracted feature points can survive against several attacks, therefore, those can be used as reference points for restoration before the extraction of the watermark information. For blindness and robustness, we embed the watermark into the low-band of the discrete cosine transform (DCT) domain. Experimental results show our performance analysis of watermarking methods using the linear and nonlinear feature matching, against the geometric attacks and the signal processing attacks. These include the JPEG compression, the filtering attacks, and so on.
C1 [Ta Minh Thanh; Luu Hong Dung] Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
   [Tanaka, Keisuke] Tokyo Inst Technol, Meguro Ku, 2-12-2 Ookayama, Tokyo 1528552, Japan.
   [Nguyen Tuan Tai] MMD, Ha Noi City, Vietnam.
   [Hai Nguyen Nam] Acad Cryptog Tech, Ha Noi City, Vietnam.
C3 Le Quy Don Technical University; Tokyo Institute of Technology
RP Thanh, TM (corresponding author), Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
EM thanhtm@mta.edu.vn; keisuke@is.titech.ac.jp; luuhongdung@gmail.com;
   tainguyen.dlvn@gmail.com; nnhai61@gmail.com
RI Dung, Luu Hong/ABH-1990-2021; Thanh, Ta Minh/ABH-2076-2021
OI Dung, Luu Hong/0000-0002-3961-3774; Thanh, Ta Minh/0000-0002-4776-4265
FU Grants-in-Aid for Scientific Research [17H01695, 16H01705] Funding
   Source: KAKEN
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Hernández MC, 2009, IEEE INT CON MULTI, P1744
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Hernandez-Avalos PA, 2010, MIDWEST SYMP CIRCUIT, P628, DOI 10.1109/MWSCAS.2010.5548906
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nikolaidis A, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-97
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Pham VQ, 2008, IEICE T INF SYST, VE91D, P2027, DOI 10.1093/ietisy/e91-d.7.2027
   Qi X, 2004, IEEE INT C AC SPEECH, P495
   Shih F.Y., 2008, Digital Watermarking and Steganography: Fundamentals and Techniques
   Steinebach M, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P49, DOI 10.1109/ITCC.2001.918764
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Thanh TM, 2014, AEU INT J ELECT COMM
   Voyatzis G., 1996, Proceedings of the European Conference on Multimedia Applications, Services and Techniques, P687
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang XJ, 2013, FRONT COMPUT SCI-CHI, V7, P145, DOI 10.1007/s11704-013-2174-7
   Zheng D, 2003, IEEE T CIRC SYST VID, V13, P753, DOI 10.1109/TCSVT.2003.815959
NR 23
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2901
EP 2920
DI 10.1007/s11042-017-4435-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400060
DA 2024-07-18
ER

PT J
AU Ali, T
   Jhandhir, Z
   Ahmad, A
   Khan, M
   Khan, AA
   Choi, GS
AF Ali, Tenvir
   Jhandhir, Zeeshan
   Ahmad, Awais
   Khan, Murad
   Khan, Arif Ali
   Choi, Gyu Sang
TI Detecting fraudulent labeling of rice samples using computer vision and
   fuzzy knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Fuzzy knowledge; Possibility theory; Neural network;
   Classification
ID BIG DATA ANALYTICS; CLASSIFICATION; INSPECTION
AB Pakistan's climate allows growing several types of crops, among them is rice. Basmati is one of the most harvested and most profitable varieties of rice because of its unique fragrance. Rice varieties are difficult to differentiate accurately by visual inspection. Therefore, dishonest dealers could easily mislabel or adulterate basmati rice with less valuable assortments that look similar. We need a way to guard the interests of our trade partners. Many different approaches have been proposed to detect adulteration or fraud labeling of rice, in particular, to detect mixtures of authentic basmati and non-basmati varieties. These techniques employ characteristics such as morphological parameters, physicochemical properties, DNA, protein, or metabolites and are expensive and time-consuming. In this paper, we propose a novel and inexpensive technique to detect fraudulent labeling. We use computer vision and a fuzzy classification database for detecting fault labels. For classification, we employ a neural network based approach, and for detecting fraudulent labels, we create a fuzzy classification knowledge database to label rice samples accurately. Our proposed approach is novel and achieves a precision of more than 90% (for 10 gram sample) in identifying fraudulent labels of rice. We conclude that our approach can help in identifying the rice varieties with a higher accuracy.
C1 [Ali, Tenvir; Jhandhir, Zeeshan; Choi, Gyu Sang] Yeungnam Univ, Dept Informat & Commun Engn, Gyeongbukdo, South Korea.
   [Ahmad, Awais; Khan, Murad] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Khan, Arif Ali] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Yeungnam University; Kyungpook National University; City University of
   Hong Kong
RP Choi, GS (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyeongbukdo, South Korea.
EM tenvirali@ynu.ac.kr; zeeshanjhandir@ynu.ac.kr; awais.ahmad@live.com;
   muradkhan23@gmail.com; aliakhan2-c@my.cityu.edu.hk; castchoi@ynu.ac.kr
RI Ahmad, Awais/AAA-4504-2019; Khan, Arif Ali/ABG-2862-2020; Khan,
   Murad/AAB-6060-2019; khan, Arif/HMV-3165-2023
OI Khan, Arif Ali/0000-0002-8479-1481; Khan, Murad/0000-0001-9905-8904; 
FU Ministry of Trade, Industry & Energy (MOTIE, Korea) under Industrial
   Technology Innovation Program [10063130]; Basic Science Research Program
   through National Research Foundation of Korea (NRF) - Ministry of
   Education [2016R1A2B4007498]; MSIP (Ministry of Science, ICT and Future
   Planning), Korea under ITRC (Information Technology Research Center)
   support program [IITP-2016-R2718-16-0035]
FX This research is supported by the Ministry of Trade, Industry & Energy
   (MOTIE, Korea) under the Industrial Technology Innovation Program, No.
   10063130, by the Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Education
   (2016R1A2B4007498), and the MSIP (Ministry of Science, ICT and Future
   Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2016-R2718-16-0035) supervised by the IITP
   (Institute for Information & communications Technology Promotion).
CR Ahmad A, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2834118
   Ahmad A, 2016, NEUROCOMPUTING, V174, P439, DOI 10.1016/j.neucom.2015.04.109
   [Anonymous], MODERN TECHNIQUES FO
   [Anonymous], 2016, WORLD RICE PRODUCTIO
   [Anonymous], 2016, 15492004 EC
   [Anonymous], 2016, LEADERS RICE PRODUCT
   Aulakh JS, 2012, INT C TRENDS EL EL P, P15
   Ballard DH, 1982, COMPUTER VISION ARTI, P4
   Beerh O. P., 1991, Oryza, V28, P399
   BROGAN WL, 1974, PATTERN RECOGN, V6, P97, DOI 10.1016/0031-3203(74)90012-0
   Carter RM, 2006, MEAS SCI TECHNOL, V17, P235, DOI 10.1088/0957-0233/17/2/002
   Carter RM, 2005, J PHYS CONF SER, V15, P177, DOI 10.1088/1742-6596/15/1/030
   CASADY WW, 1989, T ASAE, V32, P1821, DOI 10.13031/2013.31229
   CASADY WW, 1992, T ASAE, V35, P2027, DOI 10.13031/2013.28831
   CASTLEMAN KR, 1979, DIGITAL IMAGE PROCES, P429
   Choi YW, 2016, CONSUMERS VALUATION
   Findlay I, 1997, NATURE, V389, P555, DOI 10.1038/39225
   Fridez F, 2016, CHIMIA, V70, P354, DOI 10.2533/chimia.2016.354
   GERSHON R, 1989, COLOR RES APPL, V14, P325, DOI 10.1002/col.5080140610
   Gonzalez R.C., 1992, Digital Image Processing, P716
   GONZALEZ RC, 1982, COMPUTER, V15, P17, DOI 10.1109/MC.1982.1653913
   Guzman J.D., 2008, WORLD C AGR INF IT T
   Haralick RM., 1992, Computer and robot uision, uolume, P672
   Hetzroni A, 1994, AM SOC AGR ENG M US
   Hobson DM, 2007, 2007 IE INSTR MEAS T
   Kim SS, 1997, CEREAL CHEM, V74, P212, DOI 10.1094/CCHEM.1997.74.3.212
   KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2
   Kranzler GA, 1985, APPL DIGITAL IMAGE P
   Li Z, 2000, THEOR APPL GENET, V101, P379, DOI 10.1007/s001220051494
   Lilhare SF, 2012, INT J ENG RES TECHNO, V1
   Metzler V, 1999, ASAIO J, V45, P264, DOI 10.1097/00002480-199907000-00004
   Novini AR, 1985, FUNDAMENTALS MACHINE
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Primrose S, 2010, TRENDS FOOD SCI TECH, V21, P582, DOI 10.1016/j.tifs.2010.09.006
   SAPIRSTEIN HD, 1987, J CEREAL SCI, V6, P3, DOI 10.1016/S0733-5210(87)80035-8
   Schäfer M, 2002, PART PART SYST CHAR, V19, P158, DOI 10.1002/1521-4117(200207)19:3<158::AID-PPSC158>3.0.CO;2-8
   Shapiro L., 1992, Computer and robot vision, P8
   Shaw WE, 1990, FOOD PROC AUT P 1990
   Silva CS, 2013, P TECHNICAL SESSIONS, V29
   Sommer HJ, 1990, C P 2 FUEL COMB S
   Thind GK, 2005, FOOD CHEM, V91, P227, DOI 10.1016/j.foodchem.2003.10.015
   Wan YN, 2002, T ASAE, V45, P379
   Yao Q, 2009, 2009 WRI GLOB C INT, V4
NR 43
TC 7
Z9 8
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24675
EP 24704
DI 10.1007/s11042-017-4472-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300006
DA 2024-07-18
ER

PT J
AU Choi, B
   Kang, S
   Jun, K
   Cho, J
AF Choi, Byoungjo
   Kang, Seokhoon
   Jun, Kyungkoo
   Cho, Joonghwee
TI Rule-based soft computing for edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image edge detection; Fuzzy rule-based decision; Soft computing; Sobel
   mask
ID IMAGE COMPRESSION
AB In this paper, we present a robust rule-based edge detection method. Although generalized edge detection approaches are effective for most images they often fail in others. Thus the goal of our method is to provide more reliable edge detection results that are effective in most images. We implement the proposed method as follows: (1) transform RGB images to YCbCr format, (2) apply Sobel mask in four edge directions (horizontal, vertical, diagonal, anti-diagonal), (3) apply a bi-directional mask in four edge directions (horizontal-diagonal, vertical-diagonal, horizontal-anti-diagonal, vertical-anti-diagonal), and (4) detect rule-based edges by calculating membership degrees. Simulation results demonstrate that the proposed method is effective in most given images. We used three benchmarks approaches (Canny edge mask, high-pass filter, and Sobel mask) to compare the subjective performance quality.
C1 [Choi, Byoungjo; Kang, Seokhoon; Jun, Kyungkoo; Cho, Joonghwee] Incheon Natl Univ, Dept Embedded Syst Engn, Coll Informat & Technol, 119 Acad Ro, Incheon 22012, South Korea.
C3 Incheon National University
RP Jun, K (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Coll Informat & Technol, 119 Acad Ro, Incheon 22012, South Korea.
EM kjun@inu.ac.kr
FU Converging Research Program through Incheon National University,
   Republic of Korea [CRP-20141311]
FX This authors acknowledge the financial support of Converging Research
   Program (CRP-20141311) through Incheon National University, Republic of
   Korea.
CR [Anonymous], P ICPADS 2015 MELB A
   [Anonymous], 2015, SPACECRAFT ADAPTIVE, DOI DOI 10.2514/6.2015-1780
   [Anonymous], SCTV
   [Anonymous], P IJCV
   [Anonymous], 2003, STAT EDGE DETECTION
   [Anonymous], P IEEE SITIS2015 BAN
   Canny John, 1986, A computational approach to edge detection
   Feng XL, 2015, OPTIK, V126, P3823, DOI 10.1016/j.ijleo.2015.08.175
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Jeon G, 2016, INFORM SCIENCES, V354, P112, DOI 10.1016/j.ins.2016.03.016
   Liu SH, 2015, J SUPERCOMPUT, V71, P3353, DOI 10.1007/s11227-015-1413-0
   Long YF, 2015, OPT COMMUN, V355, P406, DOI 10.1016/j.optcom.2015.07.001
   Long YF, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.7.073109
   Paul A, 2011, IET IMAGE PROCESS, V5, P323, DOI 10.1049/iet-ipr.2009.0256
   Shi J, 2016, J REAL TIME IMAGE PR, P1
   SHI J, 2014, MATH PROBL ENG, V2014, P15
   Shin MC, 2001, COMPUT VIS IMAGE UND, V84, P160, DOI 10.1006/cviu.2001.0932
   Wang L, 2015, SIGNAL PROCESS-IMAGE, V36, P63, DOI 10.1016/j.image.2015.06.002
   Wu JJ, 2013, SIGNAL PROCESS-IMAGE, V28, P727, DOI 10.1016/j.image.2013.04.004
NR 19
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24819
EP 24831
DI 10.1007/s11042-016-4329-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300013
DA 2024-07-18
ER

PT J
AU Hsu, CH
   Cheng, WH
   Wu, YL
   Huang, WS
   Mei, T
   Hua, KL
AF Hsu, Che-Hao
   Cheng, Wen-Huang
   Wu, Yi-Leh
   Huang, Wen-Shiung
   Mei, Tao
   Hua, Kai-Lung
TI CrossbowCam: a handheld adjustable multi-camera system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera array alignment; Bullet time visual effect; Autostereoscopic 3D
   display
ID VIDEO
AB This paper presents a novel multi-functional, low-cost handheld multi-camera system (one dimensional camera array)-"CrossbowCam". The CrossbowCam is suitable for multi-viewpoint image acquisition, smooth switching, alignment and seamless stitching applications. The proposed system differs from the traditional fixed image acquisition systems which are large-sized, high-priced, single functional, and can only captured images at specific locations. With the proposed system, the users can push one single button to change the configuration of the camera array rapidly to divergence (convex arc), parallel (linear), or convergence (concave arc). The three camera configurations can each be suitable for applications such as panorama image stitching, autostereoscopic 3D display, bullet-time (time-freeze) visual effect, 3D scene reconstruction, etc. To rapidly acquire the relationship among cameras after configuration change, we propose a two-stage calibration method to compensate the mechanical misalignment. The first stage adopts the traditional checkerboard calibration method to get the intrinsic parameters (focal length, principal point) and the lens distortion for each camera. The second stage requires no auxiliary tool but utilizes a large number of common feature points from multiple viewpoint images to acquire the extrinsic parameters (translation and rotation matrix) and to compensate the vertical misalignment and the horizontal uneven angle distribution due to the mechanical structure. The proposed system can then insert virtual viewpoint images between actual viewpoint images to allow the viewpoint switching more smoothly. The proposed system has eight cameras with maximum viewing angle of 90. in divergence mode, 38 mm spacing in parallel mode, and imaging radius of 10 m similar to 0.5 m in convergence mode. We believe that the proposed system can potentially change the consumer habits and becomes the new type of home-use handheld camcorder system in the future.
C1 [Hsu, Che-Hao; Wu, Yi-Leh; Huang, Wen-Shiung; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Cheng, Wen-Huang] Acad Sinica, Res Ctr Informat Technol Innovat CITI, Taipei, Taiwan.
   [Mei, Tao] Microsoft Res Asia, Beijing, Peoples R China.
C3 National Taiwan University of Science & Technology; Academia Sinica -
   Taiwan; Microsoft; Microsoft Research Asia
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM hua@mail.ntust.edu.tw
RI Cheng, Wen-Huang/AAK-2774-2020; Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307; Hua, Kai-Lung/0000-0002-7735-243X
FU Ministry of Science and Technology, Taiwan [MOST104-2221-E-011-091-MY2,
   MOST103-2221-E-011-105]
FX This work was supported in part by Ministry of Science and Technology,
   Taiwan via MOST104-2221-E-011-091-MY2 and MOST103-2221-E-011-105.
CR Akechi N, 2014, SIGGRAPH ASIA POSTER
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Breeze-System, 2015, DSLR REM PROM CAM
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chen D, 2014, ACM SIGGRAPH POSTERS
   Debevec P, 2012, SIGGRAPH ASIA TECHNI
   Dickie Connor., 2012, Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts-CHI EA '12, P1051, DOI [10.1145/2212776.2212383, DOI 10.1145/2212776.2212383]
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Ikeya K, 2014, P EUR C VIS MED PROD
   Kang YS, 2011, IEEE T CONSUM ELECTR, V57, P1041, DOI 10.1109/TCE.2011.6018853
   Kang YS, 2008, LECT NOTES COMPUT SC, V5353, P543, DOI 10.1007/978-3-540-89796-5_56
   Lee D, 2015, BULLET TIME MATRIX
   Lipski C, 2010, COMPUT GRAPH FORUM, V29, P2555, DOI 10.1111/j.1467-8659.2010.01824.x
   Loop C, 1999, IEEE COMP SOC C COMP, V1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lytro, 2015, ILL
   Nomura Yoshikuni., 2007, P 18 EUROGRAPHICS C, P127
   Nozick V, 2013, ANN TELECOMMUN, V68, P581, DOI 10.1007/s12243-013-0382-7
   Nozick V, 2008, INT J AUTOM COMPUT, V5, P257, DOI 10.1007/s11633-008-0257-y
   Replay-Technology, 2015, FREED FREE DIM VID
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Venkataraman K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508390
   Wang Y, 2015, ARXIV150701147
   Wang Y., 2015, ARXIV150701148
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Yang JC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033001
   Yun-Siik Kang, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P61
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 28
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24961
EP 24981
DI 10.1007/s11042-017-4852-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300022
DA 2024-07-18
ER

PT J
AU Li, A
   Miao, ZJ
   Cen, YG
   Cen, Y
AF Li, Ang
   Miao, Zhenjiang
   Cen, Yigang
   Cen, Yi
TI Anomaly detection using sparse reconstruction in crowded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HMOFP; Online dictionary learning; Sparse representation; Abnormal
   events; Crowded scenes
ID BEHAVIOR DETECTION; REPRESENTATION
AB In this paper, we propose an algorithm of anomaly detection in crowded scenes by using sparse representation over the normal bases. First, the histogram of maximal optical flow projection (HMOFP) features are extracted from a set of normal training data. Then, the online dictionary learning algorithm is used to train an optimal dictionary with proper redundancy, which is better than the dictionary simply composed by the HMOFP features of the whole training data. In order to detect the normalness of a frame, the l (1)-norm of the sparse reconstruction coefficients is used as the Reconstruction Coefficient Sparsity (RCS). Our algorithm is effective for both global abnormal events (GAE) and local abnormal events (LAE). We evaluate our method on three benchmark datasets-the UMN dataset, the PETS2009 dataset and the UCSD Ped1 dataset. Compared with the most popular methods, experimental results show that our algorithm achieves good results especially for the pixel-level local abnormal event localization.
C1 [Li, Ang; Miao, Zhenjiang; Cen, Yigang] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Li, Ang; Miao, Zhenjiang; Cen, Yigang] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Cen, Yi] Minzu Univ China, Sch Informat Engn, Beijing 100081, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Minzu
   University of China
RP Li, A (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.; Li, A (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM lianghit@126.com; zjmiao@bjtu.edu.cn; ygcen@bjtu.edu.cn;
   630491958@qq.com
RI Cen, Yigang/AAC-1999-2019
FU 973 Program [2011CB302203]; NSFC [61572067, 61272028, 61273274,
   61672089, 61602538, 61572064]; National Key Technology R&D Program of
   China [2012BAH01F03]; NSFB [4123104]; Beijing Municipal Natural Science
   Foundation [4162050]; Natural Science Foundation of Guangdong Province
   [2016A030313708];  [PXM2016_014219_000025]
FX This work is supported by the 973 Program (no. 2011CB302203), NSFC (nos.
   61572067, 61272028, 61273274, 61672089, 61602538, and 61572064),
   PXM2016_014219_000025, National Key Technology R&D Program of China (no.
   2012BAH01F03), NSFB (no. 4123104), Beijing Municipal Natural Science
   Foundation (no. 4162050), and Natural Science Foundation of Guangdong
   Province (no. 2016A030313708).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], PERF EV TRACK SURV P
   [Anonymous], P INT C IT CONV SEC
   Bi CJ, 2014, INT CONF CLOUD COMPU, P327, DOI 10.1109/CCIS.2014.7175753
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Haque M, 2010, IEEE INT CON MULTI, P173, DOI 10.1109/ICME.2010.5583057
   Hung TY, 2013, IEEE INT SYMP CIRC S, P2844, DOI 10.1109/ISCAS.2013.6572471
   Kosmopoulos D, 2010, IEEE SIGNAL PROC MAG, V27, P34, DOI 10.1109/MSP.2010.937392
   Lee C. P., 2010, Proceedings of the 2010 IEEE Student Conference on Research and Development (SCOReD 2010). Engineering: Innovation & Beyond, P192, DOI 10.1109/SCORED.2010.5704000
   Li A, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/406941
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Quan Q, 2009, IEEE 15TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING, PROCEEDINGS, P189, DOI 10.1109/PRDC.2009.38
   Ren HM, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P125, DOI 10.1109/AVSS.2014.6918655
   Rodriguez M, 2009, IEEE I CONF COMP VIS, P1389, DOI 10.1109/ICCV.2009.5459301
   Sandhan T, 2013, INT CONF IMAG VIS, P494, DOI 10.1109/IVCNZ.2013.6727064
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Sjarif N. N. A., 2011, INT J ADV SOFT COMPU, V3, P1
   Thida M., 2013, Intelligent multimedia surveillance, P17, DOI DOI 10.1007/978-3-642-41512-8_2
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   Tziakos I., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P519, DOI 10.1109/AVSS.2010.70
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Xie M, 2015, IEEE T PARALL DISTR, V26, P574, DOI 10.1109/TPDS.2014.2308198
   Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 32
TC 8
Z9 9
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26249
EP 26271
DI 10.1007/s11042-016-4115-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500034
DA 2024-07-18
ER

PT J
AU Ryu, S
   Kim, J
   Lee, YS
AF Ryu, Seokhoon
   Kim, Jeakwan
   Lee, Young-Sup
TI Active sound profiling of narrowband signals for improving sound quality
   in an enclosed space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active sound profiling; Narrowband signals; Sound quality; Target
   signals
AB In this paper, an active sound profiling (ASP) system based on the command-FxLMS algorithm was implemented in an enclosed space for improving sound quality. This ASP system was designed to track a pre-defined target signal against rpm in order to actively reduce and enhance the disturbance signal from a rotating machine. The control system consists of an error microphone at a control point, a midrange loudspeaker and a subwoofer in the enclosed space with a digital signal processing board. The real-time control experiment with the ASP system was carried out in the enclosed space to track the target signal of 9 orders from C2 to C6 which was defined because the disturbance signal before control had poor sound quality. Sound pressure levels (SPLs) of the 9 orders were attenuated or enhanced over rpm. The root mean square values of the deviations between the SPLs after control and the target SPLs of the orders became about 1.62-5.23 dB, which were dramatically reduced compared to the deviations before control. This result showed that the ASP algorithm in the control experiment improved sound quality greatly.
C1 [Ryu, Seokhoon; Kim, Jeakwan; Lee, Young-Sup] Incheon Natl Univ, Dept Embedded Syst Engn, 119 Acad Ro Songdo Dong, Incheon 22012, South Korea.
C3 Incheon National University
RP Lee, YS (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, 119 Acad Ro Songdo Dong, Incheon 22012, South Korea.
EM ysl@inu.ac.kr
FU Incheon National University
FX This work was supported by the Incheon National University Research
   Grant in 2014.
CR [Anonymous], 2001, SIGNAL PROCESSING AC
   Carme C, 2006, P 2006 INT S ACT CON
   Cerrato G, 2009, SOUND VIB, V43, P16
   Couche J., 1999, P 1999 INT S ACTIVE, P2
   Das D.P., 2006, P IEEE INT C AC SPEE, P289
   de Oliveira LPR, 2010, MECH SYST SIGNAL PR, V24, P1727, DOI 10.1016/j.ymssp.2010.01.004
   Duan J, 2015, J DYN SYST-T ASME, V137, DOI 10.1115/1.4028183
   Elliott SJ, 1993, IEEE SIGNAL PROC MAG, V10, P12, DOI 10.1109/79.248551
   Elliott S.J., 1988, Proceedings of the 1988 International Congress and Exposition on Noise Control Engineering, P987
   Kim J, 2015, P KOR SOC NOIS VIBR, P280
   Kuo S.M., 1996, Active Noise Control Systems: Algorithms and DSP Implementations
   KUO SM, 1993, NOISE CONTROL ENG, V41, P281, DOI 10.3397/1.2827842
   Rees LE, 2006, IEEE T AUDIO SPEECH, V14, P711, DOI 10.1109/TSA.2005.855828
   Ryu S, 2015, P KOR SOC NOIS VIBR, P280
   Ryu Seokhoon, 2015, [Transactions of the Korean Society for Noise and Vibration Engineering, 한국소음진동공학회논문집], V25, P628, DOI 10.5050/KSNVE.2015.25.9.628
   Schirmacher R, 2002, ACT DES AUT ENG SOUN
NR 16
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24595
EP 24607
DI 10.1007/s11042-017-4648-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300002
DA 2024-07-18
ER

PT J
AU Tan, WM
   Yan, B
AF Tan, Weimin
   Yan, Bo
TI Salient object detection via multiple saliency weights
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Visual cues; Multiple saliency weights;
   Saliency smoothing
ID MODEL; ATTENTION
AB Salient object detection aims to emulate the extraordinary capability of human visual system, which has the ability to find the most visually attractive objects in a complex visual scene. The human visual attention is often complicated and affected by many factors. In this paper, we present a novel bottom-up approach to automatically detect salient objects of an image via multiple visual cues. The key idea of our approach is to represent a saliency map of an image as an integration of multiple visual cues (saliency weights), which have been proven to be effective and useful. Specifically, we propose four saliency weights, i.e., local contrast weight, superpixel clarity weight, background probability weight, and central bias weight, to effectively represent each visual cue. To obtain our saliency map, the four resulting saliency weights are integrated in a principled way via multiplication and summation based fusion. Furthermore, we propose a new superpixel-level saliency smoothing approach to optimize the integrated results for producing clean and consistent saliency maps. Our experimental results on three standard benchmark datasets demonstrate that the proposed approach outperforms other saliency detection approaches in terms of the subjective observations and objective evaluations.
C1 [Tan, Weimin; Yan, Bo] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 201203, Peoples R China.
C3 Fudan University
RP Yan, B (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 201203, Peoples R China.
EM wmtan14@fudan.edu.cn; byan@fudan.edu.cn
RI Yan, Bo/AFQ-7025-2022
OI Yan, Bo/0000-0002-7775-1270
FU NSFC [61370158, 61522202]
FX This work was supported in part by NSFC (Grant No.: 61370158; 61522202).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   ALFANO PL, 1990, PERCEPT MOTOR SKILL, V70, P35, DOI 10.2466/PMS.70.1.35-45
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], THESIS
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 1956, ROUTING PROBLEM
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruce NDB, 2007, LECT NOTES ARTIF INT, V4840, P171
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cline D., 1997, DICT VISUAL SCI
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2
   Li Z., 2014, Understanding vision: theory, models, and data
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma K, 2016, WIRELESS COMMUNICATI, P1
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Panozzo D, 2012, COMPUT GRAPH FORUM, V31, P229, DOI 10.1111/j.1467-8659.2012.03001.x
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Schmidt R.F., 1981, FUNDAMENTALS SENSORY
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Strasburger H, 2011, J VISION, V11, DOI 10.1167/11.5.13
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Yan B, 2015, IEEE T CIRC SYST VID, V25, P15, DOI 10.1109/TCSVT.2014.2329374
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhaoping L, 2006, NETWORK-COMP NEURAL, V17, P301, DOI 10.1080/09548980600931995
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 41
TC 1
Z9 1
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25091
EP 25107
DI 10.1007/s11042-017-4725-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300029
DA 2024-07-18
ER

PT J
AU Wang, J
   Li, LG
   Zhi, GM
   Zhang, ZP
   Zhang, H
AF Wang, Jie
   Li, Linge
   Zhi, Guoming
   Zhang, Zuping
   Zhang, Hao
TI Efficient algorithms for HEVC bitrate transcoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Transcoding; Bit-rate
ID VIDEO; ARCHITECTURES; H.264/AVC
AB HEVC, which is the latest video coding standard, resulting in much higher compression efficiency than any previous standards. It is expected to take the place of the widely deployed standard H.264. The final version of HEVC has been published by ISO/IEC and ITU-T at January 2013. To speed up its adoption and application, highly efficient transcoding techniques among current deployed video standards and various versions of HEVC bitstreams are needed. Hence, an accelerated HEVC bit-rate transcoder, based on the cascaded pixel-domain framework, is proposed in this paper. Based on thorough statistical analysis, the proposed algorithm mainly utilizes information from the input video stream such as Code Unit (CU) depths, Prediction Unit PU) partitions as well as the image complexity to speedup the transcoding procedure. Experimental results demonstrate the superior performance of the proposed algorithm and its suitability for a wide range of bit-rate reduction tasks.
C1 [Wang, Jie] Cent S Univ, Informat & Commun Engn, Changsha, Hunan, Peoples R China.
   [Li, Linge] Cent S Univ, Software Engn, Changsha, Hunan, Peoples R China.
   [Zhi, Guoming] Cent S Univ, Comp Sci, Changsha, Hunan, Peoples R China.
   [Zhang, Zuping; Zhang, Hao] Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
C3 Central South University; Central South University; Central South
   University; Central South University
RP Zhang, H (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM wangjiecsu@csu.edu.cn; hao@csu.edu.cn
CR [Anonymous], 2014, 18 IEEE INT S CONS E
   [Anonymous], 2012, document JCTVC-H1100 of JCT-VC
   Bjotegaard G, 2001, CALCULATION AVERAGE
   Chang CI, 2006, IEE P-VIS IMAGE SIGN, V153, P837, DOI 10.1049/ip-vis:20050032
   Chen ZY, 2013, 3 INT C MULTIMEDIA T
   Haralick R.M., 2010, SYSTEMS MAN CYBERNET, V3, P610
   Hur JH, 2005, TENCON 2005 IEEE REG, V10, p1C6
   Lefol D, 2006, IEEE IMAGE PROC, P845, DOI 10.1109/ICIP.2006.312534
   Liu X, 2005, IEEE INT S CIRC SYST
   McCann K, 2014, JCTVCQ1002 HEVC
   Nakajima J, 2001, 2001 P WORKSH EXH MP, p87C90
   Peixoto E, 2013, 20 IEEE INT C ICIP
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Purnachand N, 2012, 2012 IEEE INT C CONS, p34C37
   Purnachand N, 2002, INT C INF TECHN COD
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Teng S.-W., 2011, VISUAL COMMUNICATION, P1
   Ternigan M, 1984, IEEE T PATTERN ANAL, V6
   Van LP, 2015, IEEE T MULTIMEDIA, P1
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang SS, 2013, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2013.6738413
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Ying Zhang, 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P520, DOI 10.1109/ICSIPA.2011.6144158
   Zheng FY, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P765, DOI 10.1109/ICALIP.2014.7009898
NR 30
TC 4
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26581
EP 26601
DI 10.1007/s11042-016-4182-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500047
DA 2024-07-18
ER

PT J
AU Alsmirat, MA
   Obaidat, I
   Jararweh, Y
   Al-Saleh, M
AF Alsmirat, Mohammad A.
   Obaidat, Islam
   Jararweh, Yaser
   Al-Saleh, Mohammed
TI A security framework for cloud-based video surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Encryption; Big multimedia data; Cloud computing;
   SRTP
AB Utilizing cloud services in running large-scale video surveillance systems is not uncommon. However, special attention should be given to data security and privacy because, typically, data travels over insecure public networks. In this work, we propose an end-to-end security framework for a cloud-based video surveillance system that supports a large number of cameras. Our framework provides mutual authentication, session key management, data confidentiality, and data integrity. Consequently, encrypted video frames can only be sourced from authenticated cameras and only destined to authenticated cloud devices where the integrity of such frames can also be verified against potential change. As video streaming is a very delay-sensitive application, we study different variations of the proposed framework to find security options that achieve the best trade-off between the added delay and the security of the system.
C1 [Alsmirat, Mohammad A.; Obaidat, Islam; Jararweh, Yaser; Al-Saleh, Mohammed] Jordan Univ Sci & Technol, Comp Sci Dept, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Alsmirat, MA (corresponding author), Jordan Univ Sci & Technol, Comp Sci Dept, Irbid 22110, Jordan.
EM masmirat@just.edu.jo; yijararweh@just.edu.jo; misaleh@just.edu.jo
RI Jararweh, Yaser/JCO-2836-2023; Jararweh, Yaser/ABE-6543-2021; Obaidat,
   Islam/JUF-2484-2023
OI Obaidat, Islam/0000-0002-2258-0785; Alsmirat,
   Mohammad/0000-0002-1071-7713; Jararweh, Yaser/0000-0002-4403-3846;
   Al-Saleh, Mohammed/0000-0001-6950-8337
FU Jordan University of Science and Technology Deanship of Scientific
   Research [20150348]
FX This work was funded in parts by the Jordan University of Science and
   Technology Deanship of Scientific Research grant number 20150348.
CR Abd-Elrahman E., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P33, DOI 10.1109/ISM.2010.15
   Alamri A, 2016, MULTIMED TOOLS APPL, V75, P13333, DOI 10.1007/s11042-015-3074-7
   Alsmirat M.A., 2012, Proceedings of the 21st International Conference on Computer Communications and Networks (ICCCN), Munich, Germany, P1
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 2000, Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], 2004, 3711 RFC
   Chang YT, 2016, MULTIMED TOOLS APPL, V75, P9837, DOI 10.1007/s11042-015-2784-1
   Daemen J., 1999, AES proposal: Rijndael
   Delp EJ, 2005, ADV SCI TECH SEC APP, P135
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   Fehér G, 2008, MULTIMEDIA SYST, V14, P167, DOI 10.1007/s00530-008-0122-4
   Forouzan B.A., 2008, Cryptography and Network Security, V1st
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta BB, 2017, NEURAL COMPUT APPL, V28, P3655, DOI 10.1007/s00521-016-2317-5
   Hyncica O., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P277, DOI 10.1109/IDAACS.2011.6072756
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Lee H.Y., 2009, IJCSIS INT J COMPUT, V6, P70
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Lin YN, 2014, IMPROVEMENT VIDEO ST, P355, DOI [10.1007/978-3-319-05503-935, DOI 10.1007/978-3-319-05503-935]
   Obaidat I, 2016, INT CONF INFORM COMM, P190, DOI 10.1109/IACS.2016.7476109
   Rajan MA, 2016, IEEE 30TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA 2016), P373, DOI 10.1109/WAINA.2016.101
   Reza TA, 2013, QOS AWARE ADAPTIVE S, P324, DOI [10.1007/978-3-642-37119-621, DOI 10.1007/978-3-642-37119-621]
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schulzrinne H., 2003, TECH REP
   Seedorf J, 2009, SECURITY ISSUES P2P, P95, DOI [10.1007/978-3-642-05437-210, DOI 10.1007/978-3-642-05437-210]
   Shirani S, 1997, IEEE T COMMUNI UNPUB
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Sun Z, 2016, SHOCK VIB, V2016, DOI 10.1155/2016/8454567
   Tawalbeh L, 2012, INT ARAB J INF TECHN, V9, P284
   Turner S., 2011, Updated Security Considerations for the MD5 Message-Digest and the HMAC-MD5 Algorithms
   Venugopalan R., 2003, P 2003 INT C COMP AR, P188, DOI DOI 10.1145/951710.951737
   Wang CH, 2014, MULTIMED TOOLS APPL, V73, P737, DOI 10.1007/s11042-012-1186-x
   Wei X, 2015, LECT NOTES COMPUT SC, V9532, P551, DOI 10.1007/978-3-319-27161-3_50
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Yang X, 2016, MULTIRESOURCE ALLOCA, P544, DOI [10.1007/978-3-319-31854-749, DOI 10.1007/978-3-319-31854-749]
   Yi S, 2012, MODEL FACE RECOGNITI, P105, DOI [10.1007/978-3-642-30126-118, DOI 10.1007/978-3-642-30126-118]
NR 38
TC 17
Z9 17
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22787
EP 22802
DI 10.1007/s11042-017-4488-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200046
DA 2024-07-18
ER

PT J
AU Chandra, A
   Mondal, S
AF Chandra, Abhijit
   Mondal, Sumita
TI Amalgamation of iterative double automated thresholding and
   morphological filtering: a new proposition in the early detection of
   cerebral aneurysm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cerebral aneurysm (CA); Digital subtraction angiography (DSA); Iterative
   double automated thresholding (IDAT) algorithm; Morphological filtering
ID UNRUPTURED INTRACRANIAL ANEURYSMS; DIGITAL SUBTRACTION; RUPTURE;
   HEMODYNAMICS; PATIENT; RATIO; SIZE
AB Cerebral aneurysm (CA) has been emerging as one of the life threatening diseases in adults which results due to the pathological distension of cerebral arteries. Rupture of cerebral aneurysms causes subarachnoid hemorrhage (SAH) which is having a miserable prognosis. SAH is one of the cerebrovascular diseases with the highest mortality. With the rapid improvement in the field of medical image processing, prior detection of cerebral (intracranial) aneurysms before rupture is on a high rise. In this communication, we have made one novel attempt to detect CA from medical images through efficient amalgamation of automated thresholding and morphological filtering. In regard to this, an iterative double automated thresholding (IDAT) algorithm has been proposed which exhibits superiority over other existing thresholding techniques like Sauvola, Niblack and Otsu's threshold. Efficiency of the proposed algorithm has been validated over a number of digital subtraction angiography (DSA) images in terms of accuracy, sensitivity and specificity. The performance of the proposed method has also been compared with other existing methods for CA detection and finally its supremacy has been substantiated.
C1 [Chandra, Abhijit] Jadavpur Univ, Dept Instrumentat & Elect Engn, Sect 3,Block LB,Plot 8, Kolkata 700098, W Bengal, India.
   [Mondal, Sumita] Indian Inst Technol, Sch Med Sci & Technol, Kharagpur, W Bengal, India.
C3 Jadavpur University; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Kharagpur
RP Chandra, A (corresponding author), Jadavpur Univ, Dept Instrumentat & Elect Engn, Sect 3,Block LB,Plot 8, Kolkata 700098, W Bengal, India.
EM abhijit922@yahoo.co.in; sumitam95@gmail.com
CR Basak K, 2012, PROC INT CONF EMERG, P110, DOI 10.1109/EAIT.2012.6407874
   Bhadri P. R., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1924
   Bisbal Jesus, 2011, Database and Expert Systems Applications. Proceedings 22nd International Conference, DEXA 2011, P59, DOI 10.1007/978-3-642-23091-2_6
   Bradley A., 2002, MODEL PTX PROPERTIES, P1
   Brain aneurysms foundations, 2013, CER AN RES
   Cárdenes R, 2011, IEEE T MED IMAGING, V30, P1863, DOI 10.1109/TMI.2011.2157698
   Cebral JR, 2005, IEEE T MED IMAGING, V24, P457, DOI 10.1109/TMI.2005.844159
   Farnoush A, 2012, IEEE ENG MED BIO, P6677, DOI 10.1109/EMBC.2012.6347526
   Hentschke CM, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P800, DOI 10.1109/ISBI.2012.6235669
   Hentschke CM, 2011, IEEE NUCL SCI CONF R, P3116, DOI 10.1109/NSSMIC.2011.6152566
   Kroon M, 2011, MOD SIMUL ENG, V2011, DOI 10.1155/2011/289523
   Li MH, 2009, STROKE, V40, P3127, DOI 10.1161/STROKEAHA.109.553800
   Loong TW, 2003, BMJ-BRIT MED J, V327, P716, DOI 10.1136/bmj.327.7417.716
   McKinney AM, 2008, AM J NEURORADIOL, V29, P594, DOI 10.3174/ajnr.A0848
   Meng H, 2007, STROKE, V38, P1924, DOI 10.1161/STROKEAHA.106.481234
   Mikhal J, 2010, EUR C COMP FLUID DYN
   Mitra J., 2013, ELCVIA Electronic Letters on Computer Vision and Image Analysis, V12, P57
   Mitra J, 2013, ADV INTELL SYST, V177, P915
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Nikravanshalmani A., 2010, P 10 IEEE INT C INF, P1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Piccinelli M, 2009, IEEE T MED IMAGING, V28, P1141, DOI 10.1109/TMI.2009.2021652
   Rahman M, 2010, STROKE, V41, P916, DOI 10.1161/STROKEAHA.109.574244
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shimogonya Y, 2010, WORKING TIME MEASURE, P1
   Uchiyama Y, 2006, 28 ANN INT C IEEE EN, P4865, DOI [10.1109/IEMBS.2006.260438, DOI 10.1109/IEMBS.2006.260438]
   Ujiie H, 2001, NEUROSURGERY, V48, P495, DOI 10.1097/00006123-200103000-00007
   Utami N., 2011, 2011 2nd International Conference on Instrumentation, Communications, Information Technology, and Biomedical Engineering, P310, DOI 10.1109/ICICI-BME.2011.6108629
   Valencia C, 2010, IEEE ENG MED BIO, P6046, DOI 10.1109/IEMBS.2010.5627610
   Villablanca JP, 2002, AM J NEURORADIOL, V23, P1187
   Wang YH, 2011, MICROB CELL FACT, V10, DOI [10.1155/2011/672369, 10.1186/1475-2859-10-98]
   Wardlaw JM, 2000, BRAIN, V123, P205, DOI 10.1093/brain/123.2.205
   Wermer MJH, 2007, STROKE, V38, P1404, DOI 10.1161/01.STR.0000260955.51401.cd
   Wiebers D, 2003, LANCET, V362, P103, DOI 10.1016/S0140-6736(03)13860-3
   Wu J, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P58
   Zakaria H, 2011, P 2011 INT C EL ENG, P1, DOI [10.1109/ICEEI.2011.6021503., DOI 10.1109/ICEEI.2011.6021503]
   ZUBILLAGA AF, 1994, AM J NEURORADIOL, V15, P815
NR 37
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23957
EP 23979
DI 10.1007/s11042-016-4149-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700038
DA 2024-07-18
ER

PT J
AU Orsolic, I
   Pevec, D
   Suznjevic, M
   Skorin-Kapov, L
AF Orsolic, Irena
   Pevec, Dario
   Suznjevic, Mirko
   Skorin-Kapov, Lea
TI A machine learning approach to classifying YouTube QoE based on
   encrypted network traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of Experience; Video streaming; HTTP adaptive streaming;
   YouTube; Network measurements; Passive monitoring; Machine learning
AB Due to the widespread use of encryption in Over-The-Top video streaming traffic, network operators generally lack insight into application-level quality indicators (e.g., video quality levels, buffer underruns, stalling duration). They are thus faced with the challenge of finding solutions for monitoring service performance and estimating customer Quality of Experience (QoE) degradations based solely on passive monitoring solutions deployed within their network. We address this challenge by considering the concrete case of YouTube, whereby we present a methodology for the classification of end users' QoE when watching YouTube videos, based only on statistical properties of encrypted network traffic. We have developed a system called YouQ which includes tools for monitoring and analysis of application-level quality indicators and corresponding traffic traces. Collected data is then used for the development of machine learning models for QoE classification based on computed traffic features per video session. To test the YouQ system and methodology, we collected a dataset corresponding to 1060 different YouTube videos streamed across 39 different bandwidth scenarios, and tested various classification models. Classification accuracy was found to be up to 84% when using three QoE classes ("low", "medium" or "high") and up to 91% when using binary classification (classes "low" and "high"). To improve the models in the future, we discuss why and when prediction errors occur. Moreover, we have analysed YouTube's adaptation algorithm, thus providing valuable insight into the logic behind the quality level selection strategy, which may also be of interest in improving future QoE estimation algorithms.
C1 [Orsolic, Irena; Pevec, Dario; Suznjevic, Mirko; Skorin-Kapov, Lea] Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
C3 University of Zagreb
RP Orsolic, I (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
EM irena.orsolic@fer.hr; dario.pevec@fer.hr; mirko.suznjevic@fer.hr;
   lea.skorin-kapov@fer.hr
RI Skorin-Kapov, Lea/AAJ-4737-2021; Orsolic, Irena/AAC-4983-2021; Pevec,
   Dario/S-6811-2019
OI Orsolic, Irena/0000-0002-5707-3679; 
FU Ericsson Nikola Tesla, Croatia; Croatian Science Foundation
   [UIP-2014-09-5605]
FX This work has been conducted in the scope of the project "Survey and
   analysis of monitoring solutions for YouTube network traffic and
   application layer KPIs" funded by Ericsson Nikola Tesla, Croatia. This
   work has also been supported in part by the Croatian Science Foundation
   under the project UIP-2014-09-5605 (Q-MANIC).
CR Aggarwal Vaneet., 2014, P 15 WORKSHOP MOBILE, P18
   [Anonymous], QUIC UDP BA IN PRESS
   [Anonymous], P ACM SIGCOMM WORKSH
   [Anonymous], 2015, Cisco Fog Computing Solutions: Unleash the Power of the Internet of Things
   [Anonymous], 2016, document ITU-T, P1203
   [Anonymous], 2015, QOMEX
   Archibald R, 2011, INT WIREL COMMUN, P1808, DOI 10.1109/IWCMC.2011.5982809
   Aroussi S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P200, DOI 10.1109/ComManTel.2014.6825604
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Callado A, 2009, IEEE COMMUN SURV TUT, V11, P37, DOI 10.1109/SURV.2009.090304
   Casas Pedro, 2013, Performance Evaluation Review, V41, P44
   Casas P, 2014, P EUR C NETW COMM, P1
   Casas P, 2016, IEEE T NETW SERV MAN, V13, P181, DOI 10.1109/TNSM.2016.2537645
   Casas P, 2014, IEEE T NETW SERV MAN, V11, P441, DOI 10.1109/TNSM.2014.2377691
   Chen QA, 2014, PROCEEDINGS OF THE 2014 ACM INTERNET MEASUREMENT CONFERENCE (IMC'14), P151, DOI 10.1145/2663716.2663726
   Dimopoulos G., 2016, P 2016 INT MEAS C SA, P513, DOI DOI 10.1145/2987443.2987459
   Eckert M, 2012, INT C MOB NETW MAN, P57
   Finamore A., 2011, ACM IMC, P345, DOI DOI 10.1145/2068816.2068849
   Ghadiyaram D, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P989, DOI 10.1109/GlobalSIP.2014.7032269
   Han YT, 2010, ETRI J, V32, P22, DOI 10.4218/etrij.10.0109.0236
   Hofeld Tobias, 2015, INT C QUAL MULT EXP, P1
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932
   Hoque MA, 2015, PERVASIVE MOB COMPUT, V16, P96, DOI 10.1016/j.pmcj.2014.05.004
   Horvat Goran, 2015, 2015 38th International Conference on Telecommunications and Signal Processing (TSP), P1, DOI 10.1109/TSP.2015.7296435
   Hossfeld Tobias, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P111, DOI 10.1109/QoMEX.2014.6982305
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Keogh E., 2015, Naive Bayes Classifier
   Li W, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P11, DOI 10.1109/SIPROCESS.2016.7888214
   Mansy A., 2014, Proceedings of Workshop on Mobile Video Delivery, P8
   Moore A., 2005, Discriminators for Use in Flow-Based Classification
   Moore A. W., 2005, Performance Evaluation Review, V33, P50, DOI 10.1145/1071690.1064220
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Nam H, 2014, ACM SIGCOMM COMP COM, V44, P111, DOI 10.1145/2740070.2631433
   Nguyen TTT, 2008, IEEE COMMUN SURV TUT, V10, P56, DOI 10.1109/SURV.2008.080406
   Orsolic I, 2016, IEEE GLOBE WORK
   Plakia M., 2016, 2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2016.7498962, 10.1109/QoMEX.2016, DOI 10.1109/QOMEX.2016]
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Qian L., 2015, INT CONF WIRE COMMUN, P1
   Ramos-Munoz JJ, 2014, IEEE WIREL COMMUN, V21, P18, DOI 10.1109/MWC.2014.6757893
   Reichl P, 2015, INT WORK QUAL MULTIM, DOI 10.1109/QoMEX.2015.7148138
   Roughan M., 2004, P 4 ACM SIGCOMM C IN, P135, DOI DOI 10.1145/1028788.1028805
   Schatz R., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P358, DOI 10.1109/IMIS.2012.12
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shafiq M. Zubair, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P367, DOI 10.1145/2591971.2591975
   Shafiq MZ, 2015, TRACKING MOBILE VIDE, P3
   Sieber C, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P1261, DOI 10.1109/INM.2015.7140478
   Testolin Alberto, 2014, 2014 13th Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), P31, DOI 10.1109/MedHocNet.2014.6849102
   Wamser F, 2016, COMPUT NETW, V109, P211, DOI 10.1016/j.comnet.2016.03.020
   Wamser F, 2015, 2015 EUROPEAN CONFERENCE ON NETWORKS AND COMMUNICATIONS (EUCNC), P239, DOI 10.1109/EuCNC.2015.7194076
   Wu TY, 2015, 2015 IEEE 23RD INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), P95, DOI 10.1109/IWQoS.2015.7404719
   Zec M, 2004, WORKSH OP SYST ARCH, P1
   Zhang JG, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON MECHANICS AND MECHATRONICS (ICMM 2015), P3
NR 53
TC 59
Z9 64
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22267
EP 22301
DI 10.1007/s11042-017-4728-4
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200022
DA 2024-07-18
ER

PT J
AU Qian, Y
   Li, L
   Yang, ZZ
   Zhou, FF
AF Qian, Yang
   Li, Lei
   Yang, Zhenzhen
   Zhou, Feifei
TI An AK-BRP dictionary learning algorithm for video frame sparse
   representation in compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bilateral random projections (BRP); Adaptive K-BRP algorithm; Dictionary
   learning; Sparse representation; K-SVD algorithm
ID K-SVD; MINIMIZATION; RECOVERY
AB Sparsifying transform is an important prerequisite in compressed sensing. And it is practically significant to research the fast and efficient signal sparse representation methods. In this paper, we propose an adaptive K-BRP (AK-BRP) dictionary learning algorithm. The bilateral random projection (BRP), a method of low rank approximation, is used to update the dictionary atoms. Furthermore, in the sparse coding stage, an adaptive sparsity constraint is utilized to obtain sparse representation coefficient and helps to improve the efficiency of the dictionary update stage further. Finally, for video frame sparse representation, our adaptive dictionary learning algorithm achieves better performance than K-SVD dictionary learning algorithm in terms of computation cost. And our method produces smaller reconstruction error as well.
C1 [Qian, Yang; Zhou, Feifei] Nanjing Univ Posts & Telecommun, Sch Sci, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Lei; Yang, Zhenzhen] Nanjing Univ Posts & Telecommun, Ctr Visual Cognit Computat & Its Applicat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Qian, Y (corresponding author), Nanjing Univ Posts & Telecommun, Sch Sci, Nanjing 210023, Jiangsu, Peoples R China.
EM 739086359@qq.com
RI Yang, Zhenzhen/X-3839-2019
FU National Natural Science Foundation of China [61070234, 61071167,
   61373137, 61501251]; university graduate student research innovation
   project of Jiangsu province [KYZZ_0233, KYZZ15_0235]; NUPTSF [NY214191]
FX This work was supported in part by National Natural Science Foundation
   of China (Granted No. 61070234, 61071167, 61373137, 61501251),
   university graduate student research innovation project of Jiangsu
   province in 2014 (Granted NO. KYZZ_0233) and in 2015 (Granted NO.
   KYZZ15_0235) and the NUPTSF (Granted No. NY214191).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Anaraki FP, 2013, INT CONF ACOUST SPEE, P5469, DOI 10.1109/ICASSP.2013.6638709
   [Anonymous], 2011, P 28 INT C MACHINE L
   [Anonymous], 2015, MATH PROBL ENG
   Bahrampour S., 2015, ARXIV150201094
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Liu XM, 2013, IEEE DATA COMPR CONF, P93, DOI 10.1109/DCC.2013.17
   Mailhé B, 2012, INT CONF ACOUST SPEE, P3573, DOI 10.1109/ICASSP.2012.6288688
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Roweis S, 1998, ADV NEUR IN, V10, P626
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Tianyi Zhou, 2012, Proceedings of the 2012 IEEE International Symposium on Information Theory - ISIT, P1286, DOI 10.1109/ISIT.2012.6283064
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang LJ, 2012, IEEE T IMAGE PROCESS, V21, P2379, DOI 10.1109/TIP.2012.2183879
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zheng H, 2015, NEUROCOMPUTING, V162, P9, DOI 10.1016/j.neucom.2015.03.071
   Zhou FF, 2015, J COMPUTATIONAL INFO, V11, P1
NR 26
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23739
EP 23755
DI 10.1007/s11042-016-4134-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700029
DA 2024-07-18
ER

PT J
AU Shahriari, M
   Bergevin, R
AF Shahriari, Mana
   Bergevin, Robert
TI Land-use scene classification: a comparative study on bag of visual word
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Land-use scene classification; Bag of visual words;
   Spatial pyramid; SIFT; Encoding; Clustering
ID IMAGE CLASSIFICATION; REPRESENTATION
AB With successful launch of high spatial resolution (HSR) sensors, highly detailed spatial information is provided for remote sensing research. This improvement has allowed researchers to monitor environmental changes on a small spatial scale. However traditional pixel-based classification approaches are not able to interpret high spatial resolution remote sensing imagery effectively. Bag of visual words (BoVW) framework, on the other hand, is becoming one of the most popular approaches to validate the performance of remote sensing image datasets. While pixel-based approaches may not fully describe very high-resolution remote sensing images, BoVW model is narrowing the gap between low-level features and high-level semantic features by generating an intermediate description of image features. This paper presents a comparative study to evaluate the potential of using different coding approaches of BoVW model to solve the land-use scene classification problem. Initially, this work summarizes different configurations of BoVW framework in coding and clustering. Later, we perform an extensive evaluation of BoVW on land-use scene classification and retrieval. Finally we draw several conclusions regarding different coding strategies of BoVW, codebook size and number of training images. The approach is validated on two commonly used datasets in remote sensing, UC Merced a 21-class land-use dataset and RSDataset a 19-class satellite scene dataset.
C1 [Shahriari, Mana; Bergevin, Robert] Laval Univ, Comp Vis & Syst Lab, Quebec City, PQ, Canada.
C3 Laval University
RP Shahriari, M (corresponding author), Laval Univ, Comp Vis & Syst Lab, Quebec City, PQ, Canada.
EM mana.shahriari.1@ulaval.ca; robert.bergevin@gel.ulaval.ca
OI Bergevin, Robert/0000-0002-1115-7471
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work is partially supported by a Discovery Grant to Professor
   Robert Bergevin from the Natural Sciences and Engineering Research
   Council of Canada (NSERC).
CR Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2009, VISAPP
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen C, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P324, DOI 10.1109/BigMM.2015.23
   Chen SZ, 2015, IEEE T GEOSCI REMOTE, V53, P1947, DOI 10.1109/TGRS.2014.2351395
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P173, DOI 10.1109/LGRS.2010.2055033
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dos Santos Jefersson Alex, 2013, 2013 26th Conference on Graphics, Patterns and Images - Tutorials (SIBGRAPI-T), P23, DOI 10.1109/SIBGRAPI-T.2013.11
   dos Santos JA, 2012, INT C PATT RECOG, P3090
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Hu JW, 2015, INT GEOSCI REMOTE SE, P2389, DOI 10.1109/IGARSS.2015.7326290
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   McLachlan G., 2004, FINITE MIXTURE MODEL
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Qi KL, 2015, IEEE GEOSCI REMOTE S, V12, P2403, DOI 10.1109/LGRS.2015.2478966
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Shaw G. A., 2003, Lincoln Laboratory Journal, V14, P3
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911
   Xia GS, 2010, INT ARCH PHOTOGRAMM, V38, P298
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yu Q, 2006, PHOTOGRAMM ENG REM S, V72, P799, DOI 10.14358/PERS.72.7.799
   Zhang JP, 2016, IEEE J-STARS, V9, P2343, DOI 10.1109/JSTARS.2016.2536943
   Zhang JP, 2015, INT GEOSCI REMOTE SE, P1012, DOI 10.1109/IGARSS.2015.7325940
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhao LJ, 2014, INT J REMOTE SENS, V35, P2296, DOI 10.1080/01431161.2014.890762
   Zhao YD, 2007, IEEE T GEOSCI REMOTE, V45, P1458, DOI 10.1109/TGRS.2007.892602
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   Zhu QQ, 2016, IEEE GEOSCI REMOTE S, V13, P747, DOI 10.1109/LGRS.2015.2513443
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 48
TC 17
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 23059
EP 23075
DI 10.1007/s11042-016-4316-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200060
DA 2024-07-18
ER

PT J
AU Vega, MT
   Mocanu, DC
   Liotta, A
AF Vega, Maria Torres
   Mocanu, Decebal Constantin
   Liotta, Antonio
TI Unsupervised deep learning for real-time assessment of video streaming
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience; No-reference video quality assessment;
   Unsupervised machine learning; Deep learning
ID QUALITY ASSESSMENT; IMAGE
AB Evaluating quality of experience in video streaming services requires a quality metric that works in real time and for a broad range of video types and network conditions. This means that, subjective video quality assessment studies, or complex objective video quality assessment metrics, which would be best suited from the accuracy perspective, cannot be used for this tasks (due to their high requirements in terms of time and complexity, in addition to their lack of scalability). In this paper we propose a light-weight No Reference (NR) method that, by means of unsupervised machine learning techniques and measurements on the client side is able to assess quality in real-time, accurately and in an adaptable and scalable manner. Our method makes use of the excellent density estimation capabilities of the unsupervised deep learning techniques, the restricted Boltzmann machines, and light-weight video features computed just on the impaired video to provide a delta of quality degradation. We have tested our approach in two network impaired video sets, the LIMP and the ReTRiEVED video quality databases, benchmarking the results of our method against the well-known full reference metric VQM. We have obtained levels of accuracy of at least 85% in both datasets using all possible cases.
C1 [Vega, Maria Torres; Mocanu, Decebal Constantin; Liotta, Antonio] Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Vega, MT (corresponding author), Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM m.torres.vega@tue.nl; d.c.mocanu@tue.nl; a.liotta@tue.nl
RI Vega, Maria Torres/AAL-1171-2020; Liotta, Antonio/G-9532-2014
OI Vega, Maria Torres/0000-0002-5656-6607; Liotta,
   Antonio/0000-0002-2773-4421; Mocanu, Decebal
   Constantin/0000-0002-5636-7683
FU European Research Council [291632]; European Research Council (ERC)
   [291632] Funding Source: European Research Council (ERC)
FX This work has been carried out in the context of the European Research
   Council project BROWSE (Beam-steered Reconfigurable Optical-Wireless
   System for Energy-efficient communication - Grant 291632) and the ICT
   COST Action 3D-ConTourNet (IC1105).
CR Agboma F, 2012, TELECOMMUN SYST, V49, P85, DOI 10.1007/s11235-010-9355-6
   [Anonymous], 2016, Deep learning
   [Anonymous], 2015, INT WORKSHOP QUALITY
   [Anonymous], 2014, PORC IEEE NETW OPER
   [Anonymous], 2012, NEURAL NETWORKS TRIC
   Atzori L, 2014, J VIS COMMUN IMAGE R, V25, P586, DOI 10.1016/j.jvcir.2013.08.013
   Atzori L, 2012, IEEE COMMUN MAG, V50, P18, DOI 10.1109/MCOM.2012.6178829
   Battisti F, PAUDYAL P RETRIEVED
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Borer S., 2010, Quality of Multimedia Experience (QoMEX), 2010 Second International Workshop on, P218, DOI DOI 10.1109/QOMEX.2010.5516155
   Brandao T., 2010, IMAGE PROCESSING ALG, V20, P1437
   Cagnetta Luciana, 2013, P INT C ADV MOB COMP, P525, DOI [10.1145/2536853.2536903, DOI 10.1145/2536853.2536903]
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Choi M. G., 2009, INT J ELECT COMPUT E, V3, P184
   Desjardins G., 2010, P 13 INT C ARTIFICIA, ppp 145
   Exarchakos G, 2011, J MOBILE MULTIMEDIA, V7, P151
   Ferzli R, 2006, IEEE IMAGE PROC, P2949, DOI 10.1109/ICIP.2006.312925
   Gescheider G. A., 2013, Psychophysics: the fundamentals
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hu J, 2009, INT WORK QUAL MULTIM, P216, DOI 10.1109/QOMEX.2009.5246950
   Huynh-Thu Q, 2009, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP.2009.5413894
   Kendall M. G., 1987, Kendall's Advanced Theory of Statistics
   Kordelas A, 2016, MULTIMED TOOLS APPL, V75, P5619, DOI 10.1007/s11042-015-2530-8
   Ma L, 2012, IEEE T CIRC SYST VID, V22, P1441, DOI 10.1109/TCSVT.2012.2202049
   Mocanu DC, 2016, MACH LEARN, V104, P243, DOI 10.1007/s10994-016-5570-z
   Mocanu DC, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P1278, DOI 10.1109/INM.2015.7140481
   Mocanu DC, 2014, IEEE IMAGE PROC, P758, DOI 10.1109/ICIP.2014.7025152
   Oelbaum T, 2008, SYST CYBERN INF, V6
   Paudyal P., 2014, P 5 EUR WORKSH VIS I
   Paudyal P, 2016, MULTIMED TOOLS APPL, V75, P16461, DOI 10.1007/s11042-015-3214-0
   Perra C, 2014, IEEE 22 TELECOMMUNIC, DOI [10.1109/TELFOR.2014.7034606, DOI 10.1109/TELFOR.2014.7034606]
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Shanableh T, 2015, SIGNAL PROCESS-IMAGE, V34, P22, DOI 10.1016/j.image.2015.02.008
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Suárez FJ, 2016, J NETW SYST MANAG, V24, P116, DOI 10.1007/s10922-015-9343-y
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   Tieleman T., 2009, P 26 ANN INT C MACH, P1033
   Vega M. T., LIMP VIDEO QUALITY D
   Vega MT, 2016, INT J PERVASIVE COMP, V12, P66, DOI 10.1108/IJPCC-01-2016-0008
   Vink JP, 2011, IEEE J-STSP, V5, P297, DOI 10.1109/JSTSP.2010.2055832
   Wolf S., 2005, P INT WORKSH VID PRO
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Xue Y, 2014, ARXIVABS14111705 COR
   Yang S, 2011, ELECTRON LETT, V47, P382, DOI 10.1049/el.2010.3620
   Zeng K, 2010, IEEE IMAGE PROC, P3229, DOI 10.1109/ICIP.2010.5651106
   Zeng K, 2010, INT CONF ACOUST SPEE, P1010, DOI 10.1109/ICASSP.2010.5495316
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
NR 49
TC 10
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22303
EP 22327
DI 10.1007/s11042-017-4831-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200023
OA Green Submitted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Cha, HJ
   Kim, JM
   Moon, JK
AF Cha, Hyun-Jong
   Kim, Jin-Mook
   Moon, Jeong-Kyung
TI A study on mobile ad-hoc network for reliable multimedia streaming
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MANET; Mobility; Reliable; Multimedia streaming services
AB With innovative developments made in the research of wireless communication network technologies, many different types of cutting-edge wireless systems are being developed and used today. This paper focuses on the development of a MANET(Mobile Ad-hoc network) scheme intended to be used for delivery of wireless multimedia streaming services. MANET don't use a fixed infrastructure network but mobile devices form the network themselves autonomously. But owing to un-stability in the state of the wireless channel formed in this way, there will be frequent transmission delays and data losses. In ordinary routing schemes available for data transmission, the greater the amount of data transmitted by the devices, the more severe the quality degradation. Therefore, these schemes are not suitable for streaming multimedia data. This paper suggests a stable protocol that takes into account mobility of nodes, in order to provide an efficient scheme for streaming video content in a MANET. The suggested protocol handles movements of nodes particularly well compared to the existing MP-AOMDV(Mobility Prediction Ad-hoc on-demand Multipath Distance Vector) scheme. The test results show the performance of the suggested protocol. In a large network, it has a short response time and a high transmission success rate. Use of the suggested protocol increases the reliability of the transmission paths, thereby resulting in more organic or flexible handling of changes to the network topology. Furthermore, multimedia streaming services can be delivered more stably compared to when existing systems or schemes are used.
C1 [Cha, Hyun-Jong] Kwangwoon Univ, Dept Def Acquisit Program, 447-1 Wolgye Dong, Seoul 139701, South Korea.
   [Kim, Jin-Mook; Moon, Jeong-Kyung] Sunmoon Univ, Div IT Educ, 221 Sunmoon Ro, Asan 336708, Chungnam, South Korea.
C3 Kwangwoon University; Sun Moon University
RP Moon, JK (corresponding author), Sunmoon Univ, Div IT Educ, 221 Sunmoon Ro, Asan 336708, Chungnam, South Korea.
EM Chj826@kw.ac.kr; calf0425@sunmoon.ac.kr; moonjk@sunmoon.ac.kr
RI Cha, HyunJong/T-9784-2017
CR [Anonymous], WIRELESS COMMUNICATI
   [Anonymous], INT J INNOVATIVE TEC
   Cha HJ, 2008, ACM INT SYM MOB MAN, P53
   Johnson D., 2004, RFC 3775
   Kumar G.V., 2010, International Journal on Computer Science and Engineering, V2, P706
   Kumar M., 2012, Indian J. Comput. Sci. Eng, V3, P121
   Raja L, 2013, INT J ENG COMPUT SCI, V2, P707
   Seema S., 2012, INT J INNOV ENG TECH, V1, P28
   Xu SG, 2001, IEEE COMMUN MAG, V39, P130, DOI 10.1109/35.925681
   Zhu J, 2003, IEEE COMMUN MAG, V41, P60, DOI 10.1109/MCOM.2003.1252800
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 16
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19861
EP 19879
DI 10.1007/s11042-016-3765-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500032
DA 2024-07-18
ER

PT J
AU Huang, SC
   Chang, HY
AF Huang, Shih-Chang
   Chang, Hong-Yi
TI A farmland multimedia data collection method using mobile sink for
   wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data gathering; Virtual-grid; Redundant locations
   elimination; Cross-edge adjusting trajectory scheduling; Wireless
   multimedia sensor networks
AB Wireless sensor networks are applied to collect the information about farmland required to achieve unmanned agriculture. The major purpose of the deployed sensors is to collect data. However, if the data collected by the sensors are too large, such as an image, sensors quickly become unavailable. In this paper, a novel method for collecting image data from deployed sensors by using a mobile sink is proposed. Unlike the existing data gathering methods, in which sensors deliver data to a sink via long distance transmission, in the proposed method the mobile sink walks within the region of interest (ROI) to harvest the data. A virtual-grid method is proposed to determine the visiting locations of the mobile sink. An algorithm to eliminate redundant locations that uses set-conjunction operations is also proposed for reducing the number of unnecessary visiting locations. In addition, a cross-edge adjusting trajectory scheduling (CATS) algorithm is proposed to reduce the moving distance of the mobile sink. Simulation results show that the proposed virtual-grid method can effectively reduce the number of visiting locations by about 15-20 % as compared to the cluster-centroid method. The CATS algorithm can also shorten the moving distance of the mobile sink by about 25 % as compared to that of a heuristic minimum spanning tree method.
C1 [Huang, Shih-Chang] Natl Formosa Univ, Dept Comp Sci & Informat Engn, Huwei Township, Yunlin, Taiwan.
   [Chang, Hong-Yi] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
C3 National Formosa University; National Chiayi University
RP Chang, HY (corresponding author), Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
EM schuang@nfu.edu.tw; alanc68@gmail.com
RI Huang, Shih-Chang/F-1469-2011
OI Huang, Shih-Chang/0000-0003-4058-9465
FU Ministry of Science and Technology (MOST) project of Taiwan [MOST
   103-2221-E-150-054, MOST 103-2218-E-150 -003, MOST 104-2218-E-150 -003,
   MOST 103-2218-E-415-001-, MOST 104-2221-E-415-003-]
FX This work was supported by Ministry of Science and Technology (MOST)
   project of Taiwan [MOST 103-2221-E-150-054], [MOST 103-2218-E-150 -003],
   [MOST 104-2218-E-150 -003], [MOST 103-2218-E-415-001-] and [MOST
   104-2221-E-415-003-].
CR [Anonymous], 2006, INTELLIGENT PRODUCTI, DOI DOI 10.1016/B978-008045157-2/50081-X
   [Anonymous], 2009, P 4 INT S WIR PERV C, DOI DOI 10.1109/ISWPC.2009.4800585
   BELLMORE M, 1968, OPER RES, V16, P538, DOI 10.1287/opre.16.3.538
   Chang SH, 2007, P INT C 21 ADV INF N, V1, P46
   Du K, 2003, P INT PAR DISTR PROC, P22, DOI DOI 10.1109/IPDPS.2003.1213472
   Englert M, 2014, ALGORITHMICA, V68, P190, DOI 10.1007/s00453-013-9801-4
   Erman AT, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-17
   Gu YY, 2005, 2005 SECOND ANNUAL IEEE COMMUNICATIONS SOCIETY CONFERENCE ON SENSOR AND AD HOC COMMUNICATIONS AND NETWORKS, P386
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   HUANG SC, 2006, INT J SENS NETW, V1, P190
   Lindsey S, 2002, AEROSP CONF PROC, P1125, DOI 10.1109/aero.2002.1035242
   Lindsey S, 2002, IEEE T PARALL DISTR, V13, P924, DOI 10.1109/TPDS.2002.1036066
   Liu JS, 2003, IEEE IPCCC, P129, DOI 10.1109/PCCC.2003.1203692
   Liu WJ, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P857, DOI 10.1109/HPCC.and.EUC.2013.123
   Lu KH, 2012, WIRELESS PERS COMMUN, V64, P347, DOI 10.1007/s11277-010-0202-6
   Luo HY, 2005, WIREL NETW, V11, P161, DOI 10.1007/s11276-004-4753-x
   Luo J, 2005, IEEE INFOCOM SER, P1735
   Ma M, 2013, IEEE T VEH TECHNOL, V62, P1472, DOI 10.1109/TVT.2012.2229309
   Manjeshwar A., 2001, P 1 INT WORKSHOP PAR, P2009, DOI DOI 10.1109/IPDPS.2001.925197
   Nakayama H, 2007, COMPUT COMMUN, V30, P2375, DOI 10.1016/j.comcom.2007.04.023
   Nazir B., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P624, DOI 10.1109/ICCAIE.2010.5735010
   Saad E. M., 2008, Fourth International Conference on Wireless and Mobile Communications. ICWMC 2008, P207, DOI 10.1109/ICWMC.2008.38
   Sasaki Y., 2008, IEEE GLOBECOM, P1
   Shon M., 2009, INFORM NETWORKING, P1
   Younis M, 2002, MASCOTS 2002: 10TH IEEE INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS, AND SIMULATION OF COMPUTER AND TELECOMMUNICATIONS SYSTEMS, PROCEEDINGS, P129, DOI 10.1109/MASCOT.2002.1167069
   Yuan X. X., 2011, WIR COMM NETW MOB CO, P1, DOI DOI 10.1109/WICOM.2011.6040374
NR 26
TC 6
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19463
EP 19478
DI 10.1007/s11042-015-3175-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500008
DA 2024-07-18
ER

PT J
AU Kanmani, M
   Narasimhan, V
AF Kanmani, Madheswari
   Narasimhan, Venkateswaran
TI An optimal weighted averaging fusion strategy for thermal and visible
   images using dual tree discrete wavelet transform and self tunning
   particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal image; Visible image; Image fusion; Dual tree discretewavelet
   transform; Weighted averaging; Entropy; Rootmeansquare error;
   Particleswarm optimization; self tunning particle swarm optimization
ID FACE RECOGNITION; ALGORITHM; MODEL
AB Image fusion plays a vital role in providing better visualization of image data. In this paper, we propose a new algorithm that optimally combines information from thermal images with a visual image of the same scene to create a single comprehensive fused image. In this work, an improved version of particle swarm optimization alogithm is proposed to optimally combine the thermal and visible images. The proposed algorithm is named self tunning particle swarm optimization (STPSO). Because of the importance of the fusion rule, a weighted averaging fusion rule is formulated that uses optimal weights resulting from STPSO for the fusion of both high frequency and low frequency coefficients obtained by applying Dual Tree Discrete Wavelet Transform (DT-DWT). The objective function in STPSO is formulated with the twin objectives of maximizing the Entropy and minimizing the Root Mean Square Error (RMSE), which differentiates our work from existing fusion techniques. The efficiency of our fusion algorithm is also evaluated by adding Gaussian white noise to the source images. The fusion results are compared with existing multi-resolution based fusion techniques, such as Laplacian Pyramid (LAP), Discrete Wavelet Transform (DWT) and Non Sub-Sampled Contourlet Transform (NSCT). The simulation results indicate that the proposed fusion framework results in better quality fused images when evaluated with subjective and objective metrics. Comparision of these results with those from PSO shows that our algorithm outperforms generic PSO.
C1 [Kanmani, Madheswari] SSN Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Narasimhan, Venkateswaran] SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Kanmani, M (corresponding author), SSN Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM madheswarik@ssn.edu.in; venkateswarann@ssn.edu.in
RI N, Venkateswaran/AGR-2157-2022
OI N, Venkateswaran/0000-0002-6789-4112
CR ALEjaily AM, 2008, INNOVATIONS AND ADVANCED TECHNIQUES IN SYSTEMS, COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P213, DOI 10.1007/978-1-4020-8735-6_40
   [Anonymous], INT J IND ELECT ELEC
   Arivazhagan S, 2009, SIGNAL IMAGE VIDEO P, V3, P137, DOI 10.1007/s11760-008-0065-4
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bhuvaneswari C, 2014, EGYPT INFORM J, V15, P69, DOI 10.1016/j.eij.2014.05.001
   Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009
   Chen HY, 2012, MULTIMED TOOLS APPL, V60, P495, DOI 10.1007/s11042-011-0820-3
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Dey T, 2013, INT J ELECT COMMUN C, V4
   Duan HB, 2013, IEEE COMPUT INTELL M, V8, P16, DOI 10.1109/MCI.2013.2264577
   El-Maadi A, 2007, QIRT J, V4, P25, DOI DOI 10.3166/QIRT.4.25-40
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Farokhi S, 2014, DIGIT SIGNAL PROCESS, V31, P13, DOI 10.1016/j.dsp.2014.04.008
   Jedrasiak K, 2012, LECT NOTES COMPUT SC, V7594, P423, DOI 10.1007/978-3-642-33564-8_51
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Jian MW, 2011, MULTIMED TOOLS APPL, V53, P237, DOI 10.1007/s11042-010-0509-z
   Jin HY, 2014, INFRARED PHYS TECHN, V64, P134, DOI 10.1016/j.infrared.2014.02.013
   Keller W., 2004, Wavelets in Geodesy and Geodynamics
   Kingsbury N, 2003, IEEE IMAGE PROC, P1013
   Kludas J, 2010, THESIS
   Kludas J, 2009, MULTIMED TOOLS APPL, V42, P57, DOI 10.1007/s11042-008-0251-y
   Kong WW, 2010, SCI CHINA INFORM SCI, V53, P2429, DOI 10.1007/s11432-010-4118-2
   Lacewell CW, 2010, PROC NAECON IEEE NAT, P116, DOI 10.1109/NAECON.2010.5712933
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li X, 2010, IET IMAGE PROCESS, V4, P283, DOI 10.1049/iet-ipr.2008.0259
   Liu LL, 2008, LECT NOTES COMPUT SC, V4974, P616
   Liu XB, 2016, SIGNAL IMAGE VIDEO P, V10, P959, DOI 10.1007/s11760-015-0846-5
   Liu X, 2014, AEU-INT J ELECTRON C, V68, P471, DOI 10.1016/j.aeue.2013.12.003
   Liu Z, 2012, IEEE TRANS PATTERN A, V34
   Luo B, 2011, MULTIMED TOOLS APPL, V52, P235, DOI 10.1007/s11042-010-0468-4
   Malviya P, 2014, INT J COMPUT APPL, V101
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Miao D, 2014, 22 INT C PATT REC
   Muhammad A, 2014, SIG PROCESS COMMUN, P1351, DOI 10.1109/SIU.2014.6830488
   Nickabadi A, 2011, APPL SOFT COMPUT, V11, P3658, DOI 10.1016/j.asoc.2011.01.037
   Ou F, 2012, MULTIMED TOOLS APPL, V57, P549, DOI 10.1007/s11042-010-0658-0
   Palsson F, 2015, IEEE T GEOSCI REMOTE, V53, P2652, DOI 10.1109/TGRS.2014.2363477
   Petrovic V, 2007, INFORM FUSION, V8, P2018
   Pu HB, 2014, FOOD BIOPROCESS TECH, V7, P3088, DOI 10.1007/s11947-014-1330-x
   Rahman SMM, 2010, IET IMAGE PROCESS, V4, P374, DOI 10.1049/iet-ipr.2009.0163
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Shamsafar F, 2014, MACH VISION APPL, V25, P881, DOI 10.1007/s00138-013-0572-3
   Sharma Prabhat Kumar, 2012, International Journal of Information Technology and Computer Science, V4, P42, DOI 10.5815/ijitcs.2012.11.06
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Suraj A.Anoop., 2014, J ELECTR SYST INF TE, V1, P72
   Tan H., 2013, J COMPUT INFORM SYST, V9, P327
   Tao JL, 2010, COMM COM INF SC, V93, P296
   Teo TA, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-4
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Tong Y, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-150
   Uniyal N., 2014, INT J COMPUT APPL, V95, P34
   Wang HH, 2004, J MATH IMAGING VIS, V21, P177, DOI 10.1023/B:JMIV.0000035181.00093.e3
   Wang SF, 2014, FRONT COMPUT SCI-CHI, V8, P232, DOI 10.1007/s11704-014-2345-1
   Wang ST, 2015, J MECH DESIGN, V137, DOI 10.1115/1.4030433
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yin M, 2014, OPTIK, V125, P2274, DOI 10.1016/j.ijleo.2013.10.064
   Zhao J, 2014, MULTIMED TOOLS APPL, V73, P61, DOI 10.1007/s11042-012-1299-2
   Zhou DW, 2011, EXPERT SYST APPL, V38, P15356, DOI 10.1016/j.eswa.2011.06.029
NR 62
TC 12
Z9 12
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20989
EP 21010
DI 10.1007/s11042-016-4030-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400030
DA 2024-07-18
ER

PT J
AU Molnar, A
AF Molnar, Andreea
TI Content type and perceived multimedia quality in mobile learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content category; Mobile learning; Perceived video quality; Quality of
   experience; Screen size; Video based learning
ID VIDEO QUALITY
AB The increased usage of mobile devices for learning purposes raises several concerns regarding how this adaptation affects learning and perceived quality of educational content across different screen resolutions. This research looks into how educational content type and video adaptation affect the perceived quality of multimedia educational content on two different mobile devices. We consider seven different categories of educational content: slideshow, screencast, presentation, lab demo, interview, documentary, and animation. The results show that the participants could learn regardless of the video content type and the adapted version of the video. We found no statistical significant difference between the perceived quality of the highest quality video and the lower quality video for two of the categories (lab demo and interview) and statistical significant difference on the remaining ones. The implications of this study are also discussed.
C1 [Molnar, Andreea] Univ Portsmouth, Winston Churchill Ave, Portsmouth PO1 2UP, Hants, England.
C3 University of Portsmouth
RP Molnar, A (corresponding author), Univ Portsmouth, Winston Churchill Ave, Portsmouth PO1 2UP, Hants, England.
EM andreea.molnar@port.ac.uk
CR Al Ghamdi E, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0381-5
   [Anonymous], YOUTUBE RANKING FACT
   [Anonymous], STATE UNION BLOG MOB
   [Anonymous], ELEARN MAG
   [Anonymous], AM ASTR SOC M
   [Anonymous], P ACM MOMM
   [Anonymous], P 800 1 MEAN OP SCOR
   [Anonymous], YOUTUBE T MOBILE IS
   [Anonymous], 2010, Contemporary Issues in Technology and Teacher Education
   [Anonymous], NETFLIX HAS BANDWIDT
   [Anonymous], ECLO 15 INT C BUD
   [Anonymous], MULTIMEDIA LEARNING
   [Anonymous], IS YOUTUBE NEXT GOOG
   [Anonymous], 2013, AM C INF SYST
   [Anonymous], SER P TEL TRANSM QUA
   [Anonymous], IEEE INT S BROADB MU
   [Anonymous], LEARNING ORIENTED TE
   [Anonymous], 2012, METHODOLOGY SUBJECTI
   [Anonymous], CANADIAN J LEARNING
   Backåberg S, 2015, NORD J DIGIT LIT, V10, P246
   Bradley C, 2009, ISS ONLINE EDUC, P157
   Campbell D.T., 2015, EXPT QUASIEXPERIMENT
   Chang YL, 2015, EDUC TECHNOL SOC, V18, P166
   Charness G, 2012, J ECON BEHAV ORGAN, V81, P1, DOI 10.1016/j.jebo.2011.08.009
   Deb S., 2011, International Journal of Multimedia and Ubiquitous Engineering, V6, P33
   Ghinea G, 2006, MULTIMEDIA SYST, V11, P271, DOI 10.1007/s00530-005-0007-8
   Giannakos MN, 2013, BRIT J EDUC TECHNOL, V44, pE191, DOI 10.1111/bjet.12070
   Granda JC, 2011, IEEE INT CON MULTI
   Gregson J, 2009, ISS ONLINE EDUC, P215
   Hwang G. J., 2015, Interactive Learning Environments, P1
   Hwang GJ, 2015, J COMPUT EDUC, V2, P449, DOI 10.1007/s40692-015-0043-0
   Jumisko-Pyykko S., 2005, 13th Annual ACM International Conference on Multimedia, P535, DOI 10.1145/1101149.1101270
   Karadimce A, 2014, ADV INTELL SYST, V231, P57, DOI 10.1007/978-3-319-01466-1_5
   Kim D, 2012, BRIT J EDUC TECHNOL, V43, P62, DOI 10.1111/j.1467-8535.2010.01145.x
   Kong SC, 2015, COMPUT EDUC, V88, P227, DOI 10.1016/j.compedu.2015.06.003
   Maniar Nipan, 2008, Journal of Software, V3, P51, DOI 10.4304/jsw.3.4.51-61
   Milutinovic M, 2015, MULTIMED TOOLS APPL, V74, P903, DOI 10.1007/s11042-013-1704-5
   Moldovan A.-N., 2014, Proceedings of Society for Information Technology Teacher Education International Conference, P1687
   Moldovan AN, 2014, IEEE COMMUN SURV TUT, V16, P234, DOI 10.1109/SURV.2013.071913.00194
   Molnar A., 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P871, DOI 10.1109/ISDA.2010.5687153
   Molnar A., 2015, Journal of Interactive Learning Research, V26, P209
   Molnar A, 2014, BULL TECH COMM LEARN, V16, P18
   Molnar A, 2015, J UNIVERS COMPUT SCI, V21, P959
   Molnar A, 2013, IEEE T BROADCAST, V59, P484, DOI 10.1109/TBC.2013.2244786
   Molnar A, 2012, CONSUM COMM NETWORK, P265, DOI 10.1109/CCNC.2012.6181099
   MOLNAR Andreea., 2012, Intelligent and Adaptive Learning Systems: Technology Enhanced Support for Learners and Teachers, P311, DOI DOI 10.4018/978-1-60960-842-2.CH020
   Newhouse C.P., 2015, Journal of Digital Learning in Teacher Education, V31, P64
   Nur G, 2014, MULTIMED TOOLS APPL, V70, P689, DOI 10.1007/s11042-012-1120-2
   Pozueco L, 2017, NEW REV HYPERMEDIA M, V23, P1, DOI 10.1080/13614568.2016.1152310
   Preece J., 2000, Online communities. Designing usability, DOI DOI 10.1108/IMDS.2000.100.9.459.3
   Rekkedal Torstein., 2007, INT REV RES OPEN DIS, V8
   Sanchez CA, 2010, COMPUT EDUC, V55, P1056, DOI 10.1016/j.compedu.2010.05.001
   Satgunam PN, 2013, IEEE T IMAGE PROCESS, V22, P5146, DOI 10.1109/TIP.2013.2282120
   Scott MJ, 2016, IEEE T MULTIMEDIA, V18, P1796, DOI 10.1109/TMM.2016.2574623
   Shen RM, 2009, IEEE T EDUC, V52, P538, DOI 10.1109/TE.2008.930794
   Song Wei., 2011, Proceedings_of_the_19th_ACM international_conference_on_Multimedia, P403
   Teall E., 2014, International Journal on E-Learning, V13, P79
   Teng YT., 2009, Create motivating YouTube videos: using dual coding theory and multimedia learning theory to investigate viewer perceptions
   Trestian I, 2012, IEEE ACM T NETWORK, V20, P1010, DOI 10.1109/TNET.2011.2172952
   Trestian I, 2011, IEEE INFOCOM SER, P2840, DOI 10.1109/INFCOM.2011.5935121
   Trifonova A., 2003, E-Learn, P1794
   Ullrich C, 2010, IEEE T LEARN TECHNOL, V3, P6, DOI 10.1109/TLT.2009.54
   Wang MJ, 2012, BRIT J EDUC TECHNOL, V43, P561, DOI 10.1111/j.1467-8535.2011.01214.x
   Wang MJ, 2009, BRIT J EDUC TECHNOL, V40, P673, DOI 10.1111/j.1467-8535.2008.00846.x
   Wennersten M, 2015, INT REV EDUC, V61, P503, DOI 10.1007/s11159-015-9504-y
   ZIMMERMAN DW, 1987, J EXP EDUC, V55, P171, DOI 10.1080/00220973.1987.10806451
NR 66
TC 16
Z9 18
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21613
EP 21627
DI 10.1007/s11042-016-4062-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400057
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, BP
   Qu, YY
   Peng, JY
   Fan, JP
AF Zhang, Baopeng
   Qu, Yanyun
   Peng, Jinye
   Fan, Jianping
TI An automatic image-text alignment method for large-scale web image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel image clustering; Automatic image-text alignment; Relevance
   re-ranking; Uncertainty reduction
ID ANNOTATION
AB For reducing huge uncertainty on the relatedness between the web images and their auxiliary text terms, an automatic image-text alignment algorithm is developed to achieve more accurate indexing and retrieval of large-scale web images by assigning the web images into their most relevant visual text terms precisely. First, large-scale web pages are crawled, where the informative images and their most relevant auxiliary text blocks are extracted. Second, parallel image clustering is performed to partition large-scale informative web images into a large number of clusters. By grouping the visually-similar web images into the same cluster, our parallel image clustering algorithm can significantly reduce the huge uncertainty on the relatedness between the web images and their auxiliary text terms, which can provide a good starting point for supporting automatic image-text alignment. Finally, a relevance re-ranking algorithm is developed to identify the most relevant text terms for characterizing the semantics of the visually-similar web images in the same cluster, e.g., assigning the web images into their most relevant visual text terms. Our experiments on large-scale web images have obtained very positive results.
C1 [Zhang, Baopeng] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Qu, Yanyun] Xiamen Univ, Dept Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Peng, Jinye] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
   [Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC USA.
C3 Beijing Jiaotong University; Xiamen University; Northwest University
   Xi'an; University of North Carolina; University of North Carolina
   Charlotte
RP Zhang, BP (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM bpzhang@bjtu.edu.cn; yyqu@xmu.edu.cn; pjy@nwu.edu.cn; jfan@uncc.edu
RI Peng, Jin/HZH-6965-2023
OI zhang, baopeng/0000-0003-2592-2354
FU National Science Foundation of China [61272285, 61373077]; National
   High-Technology Program of China [2014AA012301]; National Key Technology
   Support Program of China [2014BAH24F02]; Program for Changjiang Scholars
   and Innovative Research Team in University [IRT13090]; Program of
   Shaanxi Province Innovative Research Team [2014KCT-17]
FX This research is partly supported by National Science Foundation of
   China under (Grant No. 61272285 and No. 61373077), National
   High-Technology Program of China (No. 2014AA012301), National Key
   Technology Support Program of China (No. 2014BAH24F02), Program for
   Changjiang Scholars and Innovative Research Team in University (No.
   IRT13090), and Program of Shaanxi Province Innovative Research Team (No.
   2014KCT-17).
CR [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383173
   [Anonymous], ACM INT C MULT
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 2004, ADV NEURAL INFORM PR
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei D.M., 2003, P 26 ANN INT ACM SIG
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cal D., 2004, P 12 ANN ACM INT C M
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Fujiwara Y, 2011, P 22 INT JOINT C ART, VThree
   Gao B., 2005, P 13 ANN ACM INT C M
   Givoni I., 2012, HIERARCHICAL AFFINIT
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1665, DOI 10.1109/TMM.2014.2321530
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hofmann T, 1999, P 22 ANN INT ACM SIG, V99, P50
   Hsu W. H., 2007, P 15 ACM INT C MULT
   Hsu WH, 2006, P 14 ACM INT C MULT
   Jamieson M, 2010, IEEE T PATTERN ANAL, V32, P148, DOI 10.1109/TPAMI.2008.283
   JEON J, 2003, P 26 ANN INT ACM SIG
   Jia Y., 2008, ACM INT C MULT
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Jing YS, 2013, IEEE T MULTIMEDIA, V15, P2022, DOI 10.1109/TMM.2013.2279663
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Kim G, 2015, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2015.7298927
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li ZX, 2009, IEEE INT CON MULTI, P366, DOI 10.1109/ICME.2009.5202510
   Liu D, 2009, MADRID
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Mori Y, 1999, MANAGEMENT, P1999
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Qu YY, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P451, DOI 10.1145/2671188.2749294
   Rose DM, 2014, PARALLEL HIERARCHICA
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Tan Hung-Khoon, 2008, P 16 ACM INT C MULT
   Victor L, 2004, MODEL LEARNING SEMAN
   Wang C, 2006, P 14 ACM INT C MULT
   Wang X.-J., 2004, P 12 ANN ACM INT C M
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P810, DOI 10.1109/TPAMI.2013.214
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Wu L, 2012, IEEE T PATTERN ANAL, V34, P863, DOI 10.1109/TPAMI.2011.195
   Yeh JB, 2011, IEEE T MULTIMEDIA, V13, P206, DOI 10.1109/TMM.2010.2095412
NR 60
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21401
EP 21421
DI 10.1007/s11042-016-4059-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400048
DA 2024-07-18
ER

PT J
AU Hwang, BN
   Pai, NY
   Wu, CH
AF Hwang, Bang-Ning
   Pai, Nai-Yuan
   Wu, Chih-Hung
TI Fuzzy AHP for determining the key features and cognitive differences of
   mobile game development among designer and game player
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game design feature; Game system quality; Games motivation; Fuzzy AHP;
   Mobile game development
ID ONLINE GAME; SERVICE QUALITY; SATISFACTION; MOTIVATIONS; EXPERIENCE;
   ANTECEDENTS; COMMUNITIES; PERSPECTIVE; INTENTION; SELECTION
AB Previous studies have assessed the elements of a game design from game players' viewpoints. Scant research has been conducted from the perspectives of both game players and game developers. This study explored the cognitive difference among game players and game developers in the importance of online game designs by employing the fuzzy analytic hierarchy process (FAHP) to analyze the importance of puzzle game designs. The online game design hierarchical framework comprising 3 systems, 9 components, and 29 factors was established. The research findings are summarized as follows: 1) System quality is the most crucial design component. 2) Game development should primarily focus on technology followed by aesthetics. 3) A gap exists in the perception of game players and game developers on the design component "service quality." Finally, researchers can adopt the multiple criteria decision-making model used in this current study to rank the importance of design contents for cultural and creative industries.
C1 [Hwang, Bang-Ning] Natl Yunlin Univ Sci & Technol, Dept Business Adm, Touliu, Yunlin, Taiwan.
   [Pai, Nai-Yuan] Sun Yat Sen Univ, Nanfang Coll, Dept Art Design & Creat Ind, Guangzhou, Guangdong, Peoples R China.
   [Wu, Chih-Hung] Natl Taichung Univ Educ, Dept Digital Content & Technol, 140 Min Shen Rd, Taichung 403, Taiwan.
C3 National Yunlin University Science & Technology; Sun Yat Sen University;
   Nanfang College, Guangzhou; National Taichung University of Education
RP Wu, CH (corresponding author), Natl Taichung Univ Educ, Dept Digital Content & Technol, 140 Min Shen Rd, Taichung 403, Taiwan.
EM bnhuang@yuntech.edu.tw; billy_pai@hotmail.com; chwu@mail.ntcu.edu.tw
RI Wu, Chih-Hung/GZM-8190-2022
OI Wu, Chih-Hung/0000-0003-3804-0852
FU Ministry of Science and Technology (MOST), Taiwan [MOST
   103-2410-H-142-006, MOST 104-2410-H-142-017-MY2]
FX Funding of this research work was partly supported by Ministry of
   Science and Technology (MOST), Taiwan, under Grant numbers: MOST
   103-2410-H-142-006 and MOST 104-2410-H-142-017-MY2.
CR [Anonymous], FUZZY SETS SYSTEMS
   [Anonymous], 1992, J MARKETING
   Armitage GJ, 2004, EMPIRICALLY MEASURIN
   Billieux J, 2013, COMPUT HUM BEHAV, V29, P103, DOI 10.1016/j.chb.2012.07.021
   Bishop L, 1998, IEEE COMPUT GRAPH, V18, P46, DOI 10.1109/38.637270
   BUCKLEY JJ, 1985, FUZZY SET SYST, V17, P233, DOI 10.1016/0165-0114(85)90090-9
   Burns CG, 2015, INT J HUM-COMPUT ST, V73, P107, DOI 10.1016/j.ijhcs.2014.09.002
   Chang TS, 2013, TECHNOL FORECAST SOC, V80, P175, DOI 10.1016/j.techfore.2012.06.009
   Chen KT, 2006, COMMUN ACM, V49, P34, DOI 10.1145/1167838.1167859
   Chittaro L, 2014, INT J HUM-COMPUT ST, V72, P663, DOI 10.1016/j.ijhcs.2014.01.007
   Collins E, 2014, INT J HUM-COMPUT ST, V72, P654, DOI 10.1016/j.ijhcs.2013.12.006
   Cortinas M., 2004, Int. Rev. Retail Distrib. Consum. Res., V14, P407
   Crawford G, 2015, GAMES CULT, V10, P571, DOI 10.1177/1555412014566235
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   Devaraj S, 2002, INFORM SYST RES, V13, P316, DOI 10.1287/isre.13.3.316.77
   Hainey T, 2011, COMPUT EDUC, V57, P2197, DOI 10.1016/j.compedu.2011.06.001
   Hsiao CC, 2012, ELECTRON COMMER R A, V11, P75, DOI 10.1016/j.elerap.2011.10.001
   Hsu CL, 2007, COMPUT HUM BEHAV, V23, P1642, DOI 10.1016/j.chb.2005.09.001
   Hsu CL, 2015, ELECTRON COMMER R A, V14, P46, DOI 10.1016/j.elerap.2014.11.003
   Hsu CL, 2004, INFORM MANAGE-AMSTER, V41, P853, DOI 10.1016/j.im.2003.08.014
   Hsu SH, 2005, CYBERPSYCHOL BEHAV, V8, P585
   Jacobs G, 2005, DESIGN STUD, V26, P243, DOI 10.1016/j.destud.2004.06.006
   Kleinsmith A, 2013, INT J HUM-COMPUT ST, V71, P775, DOI 10.1016/j.ijhcs.2013.03.005
   Koo DM, 2009, COMPUT HUM BEHAV, V25, P466, DOI 10.1016/j.chb.2008.10.010
   Kosmadoudi Z, 2013, COMPUT AIDED DESIGN, V45, P777, DOI 10.1016/j.cad.2012.08.001
   Kwon C, 2016, GAMES CULT, V11, P390, DOI 10.1177/1555412014568789
   Lipscomb Scott D, 2004, J Physiol Anthropol Appl Human Sci, V23, P337, DOI 10.2114/jpa.23.337
   Lo YF, 2010, EXPERT SYST APPL, V37, P8685, DOI 10.1016/j.eswa.2010.06.059
   Luo L, 2006, IBM SYST J, V45, P145, DOI 10.1147/sj.451.0145
   Malone TW, 1987, APTITUDE LEARN INSTR
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Murray J.H., 1997, Hamlet on the Holodeck
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Norman Don, 2013, The design of everyday things
   Oliver RL, 1999, J MARKETING, V63, P33, DOI 10.2307/1252099
   Park BW, 2011, COMPUT HUM BEHAV, V27, P2178, DOI 10.1016/j.chb.2011.06.013
   Pitt F.L., 1995, MIS Quarterly, V19, P173
   Reichheld F., 2000, EUR BUS J, V12, P173
   Rezaei S, 2014, COMPUT HUM BEHAV, V35, P252, DOI 10.1016/j.chb.2014.03.002
   Rodgers W, 2005, PSYCHOL MARKET, V22, P313, DOI 10.1002/mar.20061
   Rohm AJ, 2004, J BUS RES, V57, P748, DOI 10.1016/S0148-2963(02)00351-X
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   Schell J, 2008, ART GAME DESIGNA BOO
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Seok S, 2015, GAMES CULT, V10, P481, DOI 10.1177/1555412014565640
   SKOGLAND I, 2004, CORNELL HOTEL REST A, V46, P221
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Teng JY, 1998, FUZZY SET SYST, V96, P259, DOI 10.1016/S0165-0114(96)00330-2
   Tsai HT, 2006, PSYCHOL MARKET, V23, P447, DOI 10.1002/mar.20121
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Wang RM, 2014, MULTIMED TOOLS APPL, V71, P395, DOI 10.1007/s11042-013-1519-4
   Wu JH, 2010, COMPUT HUM BEHAV, V26, P1862, DOI 10.1016/j.chb.2010.07.033
   Yang HE, 2009, EXPERT SYST APPL, V36, P1816, DOI 10.1016/j.eswa.2007.12.005
NR 53
TC 2
Z9 2
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18265
EP 18290
DI 10.1007/s11042-016-3792-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800005
DA 2024-07-18
ER

PT J
AU Lim, MS
   Choi, SB
AF Lim, Myung Suh
   Choi, Suk Bong
TI Stress caused by social media network applications and user responses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Media Network; SNS related stress; Psychological response
ID EMOTIONAL EXHAUSTION; JOB-PERFORMANCE; STRATEGIES; RESISTANCE; OPTIMISM
AB This study investigated the effects of stress caused by social media network applications on the psychological and behavioral reactions of users: these included emotional exhaustion, the intention to switch applications, and resistance. We also examined the mediating role played by coping behaviors in these relationships. We analyzed a data from 446 users of Korean Social Network Services (SNSs) including Facebook, Twitter, and Kakao Talk, using a structural equation modeling (SEM) approach. Our findings showed that SNS-related stress increased users' emotional exhaustion, intention to switch, and resistance of user. While both approach coping and avoidance coping reduced emotional exhaustion and resistance, avoidance coping had no significant impact on switching intention. Our results also found that approach coping partially mediated the relationships between SNS-related stress, emotional exhaustion, switching intention, and resistance.
C1 [Lim, Myung Suh] Sangji Univ, Coll Econ & Business Adm, 83 Sangjidae Gil, Wonju, Ganwondo, South Korea.
   [Choi, Suk Bong] Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong City 339700, South Korea.
C3 Sangji University; Korea University
RP Choi, SB (corresponding author), Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong City 339700, South Korea.
EM mslim@sangji.ac.kr; sukchoi@korea.ac.kr
CR Anshel MH, 2000, CRIM JUSTICE BEHAV, V27, P375, DOI 10.1177/0093854800027003006
   Ayyagari R, 2011, MIS QUART, V35, P831
   Bagozzi RP, 1998, Journal of the academy of marketing science, V16, P76
   Bhattacherjee A, 2001, MIS QUART, V25, P351, DOI 10.2307/3250921
   Bovey W.H., 2001, Journal of Managerial Psychology, V16, P534, DOI [DOI 10.1108/EUM0000000006166, 10.1108/EUM0000000006166]
   Brissette I, 2002, J PERS SOC PSYCHOL, V82, P102, DOI 10.1037//0022-3514.82.1.102
   Butler E., 2011, HUMAN COMMUNICATION, V14, P39
   CARVER CS, 1994, J PERS SOC PSYCHOL, V66, P184, DOI 10.1037/0022-3514.66.1.184
   CARVER CS, 1993, J PERS SOC PSYCHOL, V65, P375, DOI 10.1037/0022-3514.65.2.375
   CARVER CS, 1989, J PERS SOC PSYCHOL, V56, P267, DOI 10.1037/0022-3514.56.2.267
   Choi CR, 2015, MULTIMED TOOLS APPL, V74, P5041, DOI 10.1007/s11042-013-1713-4
   Compas BE, 2001, PSYCHOL BULL, V127, P87, DOI 10.1037//0033-2909.127.1.87
   Cropanzano R, 2003, J APPL PSYCHOL, V88, P160, DOI 10.1037/0021-9010.88.1.160
   Duhachek A, 2005, J CONSUM RES, V32, P41, DOI 10.1086/426612
   ENDLER NS, 1990, J PERS SOC PSYCHOL, V58, P844, DOI 10.1037/0022-3514.58.5.844
   Endler NS., 2000, Coping with Health Injuries and Problems (CHIP)
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gartner, 2011, GARTN SURV HIGHL CON
   Gibbs JL, 2006, COMMUN RES, V33, P152, DOI 10.1177/0093650205285368
   Hair JF, 2010, Multivariate data analysis
   Harman H. H., 1967, Modern Factor Analysis
   Holland KD, 2003, PSYCHOL HEALTH, V18, P15, DOI 10.1080/0887044031000080656
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Hung AW, 2006, J AM ACAD BUSINESS, V9, P75
   Jang YJ, 2015, MULTIMED TOOLS APPL, V74, P5029, DOI 10.1007/s11042-014-2061-8
   Jeong OR, 2015, MULTIMED TOOLS APPL, V74, P2433, DOI 10.1007/s11042-014-1884-7
   Kim G, 2006, INFORM MANAGE-AMSTER, V43, P884, DOI 10.1016/j.im.2006.08.004
   Kim HW, 2009, MIS QUART, V33, P567
   Kim Hyoung-Jee, 2012, [Korean Journal of Journalism & Communication Studies, 한국언론학보], V56, P439
   Kleijnen M, 2009, J ECON PSYCHOL, V30, P344, DOI 10.1016/j.joep.2009.02.004
   Krasnova H., 2013, Wirtschaftsinformatik, V11, P1, DOI DOI 10.7892/BORIS.47080
   Lazarus RS, 1984, Stress, appraisal, and coping
   Lodge J, 2007, BRIT J DEV PSYCHOL, V25, P633, DOI 10.1348/026151007X185310
   Maier C, 2012, P 33 INT C INF SYST, P16
   Maier C, 2012, P 12 EUR C INF SYST, P10
   MASLACH C, 1981, J OCCUP BEHAV, V2, P99, DOI 10.1002/job.4030020205
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   O'Keeffe GS, 2011, PEDIATRICS, V127, P800, DOI 10.1542/peds.2011-0054
   PEACOCK EJ, 1993, CAN J BEHAV SCI, V25, P64, DOI 10.1037/h0078787
   Phelps JosephE., 2001, J INTERACT MARK, V15, P2, DOI [DOI 10.1002/DIR.1019, 10.1002/dir.1019]
   Podsakoff PM, 2003, J APPL PSYCHOL, V88, P879, DOI 10.1037/0021-9010.88.5.879
   RAM S, 1989, J PROD INNOVAT MANAG, V6, P20, DOI 10.1111/1540-5885.610020
   Rosen L. D, 2012, I DISORDER UNDERSTAN
   ROTH S, 1986, AM PSYCHOL, V41, P813, DOI 10.1037/0003-066X.41.7.813
   RUDOLPH KD, 1995, PSYCHOL BULL, V118, P328, DOI 10.1037/0033-2909.118.3.328
   Sacks MA, 2012, BUS PROF COMMUN Q, V75, P80, DOI 10.1177/1080569911433326
   Samuelson W., 1988, Journal of Risk and Uncertainty, V1, P7, DOI [10.1007/BF00055564, DOI 10.1007/BF00055564]
   Sheth J., 1981, RES MARKETING, V4, P273
   Simoni PS, 1997, J PROF NURS, V13, P178, DOI 10.1016/S8755-7223(97)80069-5
   Sobel M.E., 1982, SOCIOL METHODOL, V13, P290, DOI [10.2307/270723, DOI 10.2307/270723]
   Spreitzer GM, 1997, J MANAGE, V23, P679, DOI 10.1177/014920639702300504
   Tufekci Zeynep, 2008, Information Communication & Society, V11, P544, DOI 10.1080/13691180801999050
   Weil M.M., 1997, Technostress: Coping with Technology @Work @Home @Play
   Weiten W., 2011, PSYCHOL APPL MODERN
   Wright TA, 1998, J APPL PSYCHOL, V83, P486, DOI 10.1037/0021-9010.83.3.486
   Ye C, 2011, COMMUN ASSOC INF SYS, V28, P585
   Zaltman G., 1983, CONSUMER BEHAV
   Zengyan C., 2009, Proceedings of the 42nd Hawaii International Conference on System Sciences, P1, DOI DOI 10.1109/HICSS.2009.140
   Zhang KZK, 2012, J ELECTRON COMMER RE, V13, P184
NR 59
TC 32
Z9 33
U1 7
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17685
EP 17698
DI 10.1007/s11042-015-2891-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800005
DA 2024-07-18
ER

PT J
AU Chen, J
   Wang, N
   Xue, F
   Gao, YT
AF Chen, Jian
   Wang, Ning
   Xue, Fei
   Gao, Yatian
TI Distributed compressed video sensing based on the optimization of
   hypothesis set update technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Distributed compressed video sensing;
   Multihypothesis reconstruction; Second reconstruction
ID RECONSTRUCTION
AB Compressed Sensing (CS) breakthroughs the limitation of Nyquist sampling rate and realizes the sampling and compression of data simultaneous. Hence, it is widely used in image processing and video compression. However, it remains a challenge to obtain the high quality reconstructed image and video. To this end, we focus on the reconstruction algorithm of CS and the melioration of the existing distributed compressed video sensing (DCVS). In the perspectives of hypothesis set design and reference frames selection, we give detailed analyses for existing schemes and propose hypothesis set updating (HSU) and dynamic reference frames selection (DRS) algorithms to polish up the reconstruction performance. Then the superiorities in performance for these schemes are illustrated. Finally, the simulation results indicate that at a low sampling rate, the block based DCVS with the proposed HSU and DRS (HD-BDCVS) ameliorates the quality of non-key frames and key frames simultaneously without increasing the complexity of the coding.
C1 [Chen, Jian; Wang, Ning; Xue, Fei; Gao, Yatian] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Chen, J (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM jianchen@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61540046]; "111" project
   [B08038]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61540046) and the "111" project (Grant No. B08038).
CR Asif MS, 2013, CONF REC ASILOMAR C, P579, DOI 10.1109/ACSSC.2013.6810345
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen C, 2014, IEEE T GEOSCI REMOTE, V52, P365, DOI 10.1109/TGRS.2013.2240307
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen J, 2015, MULTIMED TOOLS APPL, V74, P2085, DOI 10.1007/s11042-013-1743-y
   Chen ScottShaobing., 2001, SIAM Journal on Scientific Computing, V20, P33
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Flierl M, 1998, IEEE DATA COMPR CONF, P239, DOI 10.1109/DCC.1998.672152
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Kuo YH, 2013, ELECTRON LETT, V49, P991, DOI 10.1049/el.2013.0345
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mun S, 2009, P 16 IEEE INT C IM P, P547
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031
NR 24
TC 18
Z9 22
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15735
EP 15754
DI 10.1007/s11042-016-3866-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900023
DA 2024-07-18
ER

PT J
AU Hou, J
   Gao, T
   Wang, P
AF Hou, Jie
   Gao, Tao
   Wang, Ping
TI Flow feature analysis and extraction for classifying axisymmetric vector
   field patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector fields classification; Vector flow pattern; Vector feature
   analysis; HSL; PCA
ID VORTEX DETECTION; IDENTIFICATION; CYCLONES
AB A relatively fixed structure vector field which includes clockwise vortex, anticlockwise vortex, convergence, divergence, and saddle is defined as axisymmetric vector fields (AVF) in this study. A method for characterizing and classifying the type of flow patterns in 2-dimension actual vector field for the meteorology application is proposed. First of all, the collected AVF samples are transformed to a directional pseudo-color image by means of mapping them to the hue component space in the HSL color model. Secondly, the directional hue difference and similarity degree to the normal AVF are respectively extracted as two features by the technique of image processing. Thirdly, two improved physical properties (vorticity and divergence) of AVF are introduced and improved for this study. Finally, in the experiment, the probability density distribution for every type of AVF samples is employed to analyze the four features advantages and disadvantages on the five AVF patterns classification. The correlation of the features is discussed by the PCA method. The statistics results show that the features are effective to describe the AVF patterns. By training a classifier based on constructing a decision tree, the classification ability of the features is proved on processing different scale and resolution AVF samples by comparing with traditional methods.
C1 [Hou, Jie; Wang, Ping] Tianjin Univ, Sch Elect & Automat Engn, Tianjin 300072, Peoples R China.
   [Gao, Tao] North China Elect Power Univ, Dept Automat, Baoding 071003, Peoples R China.
C3 Tianjin University; North China Electric Power University
RP Gao, T (corresponding author), North China Elect Power Univ, Dept Automat, Baoding 071003, Peoples R China.
EM gaotao863@163.com
RI Wang, Ping/GPP-2471-2022
FU Special Found for Meteorology Scientific Research in the Public
   Interest; National Natural Science Foundation of China [71102174,
   51306058]; Fundamental Research Funds for the Central Universities
   [2014QN46]; Hebei Science and Technology Support Project [15212204D];
   Tianjin Science and Technology Support Project [15ZCZDNC00130]; State
   Scholarship Fund for Visiting Scholar by the China Scholarship Council
   [201406735004]
FX The author would like to thank the Special Found for Meteorology
   Scientific Research in the Public Interest for financial support and to
   Tianjin Meteorological Station for the provision of wind fields data of
   European Centre for Medium Range Weather Forecasts and China
   Meteorological Center. This work is supported by National Natural
   Science Foundation of China (No. 71102174 and No. 51306058), the
   Fundamental Research Funds for the Central Universities (No. 2014QN46),
   the Hebei Science and Technology Support Project (No. 15212204D), the
   Tianjin Science and Technology Support Project (No. 15ZCZDNC00130), and
   State Scholarship Fund for Visiting Scholar by the China Scholarship
   Council (No. 201406735004).
CR [Anonymous], 2011, Statistical Pattern Recognition
   Ausoni CO, 2014, GEOMETRIC ALGEBRA VE
   Corpetti T, 2003, J MATH IMAGING VIS, V19, P175, DOI 10.1023/A:1026352203836
   Dudas D, 2013, THESIS, P8
   Dudas D, 2008, THESIS
   Ebling J., 2003, P 14 IEEE VIS SEATTL, P26
   Hanley J, 2012, Q J ROY METEOR SOC, V138, P612, DOI 10.1002/qj.948
   Ho S-S, 2012, 21 INT C PATT REC
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Ketelaar J, 2015, THESIS
   Letouzey A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.46
   Marsland S, 2009, CH CRC MACH LEARN PA, P1
   McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2
   Nascimento R., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P103, DOI 10.1109/SIBGRAPI.2010.22
   Nguyen LT, 2014, MON WEATHER REV, V142, P4326, DOI 10.1175/MWR-D-14-00044.1
   Petz C, 2012, COMPUT GRAPH FORUM, V31, P1045, DOI 10.1111/j.1467-8659.2012.03097.x
   Pollock S, 2014, ADV APPL CLIFFORD AL, V24, P423, DOI 10.1007/s00006-013-0434-0
   Polthier K, 2003, VISUALIZATION AND MATHEMATICS III, P113
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   Potvin CK, 2013, MON WEATHER REV, V141, P3102, DOI 10.1175/MWR-D-13-00015.1
   Schuchert T, 2010, IEEE T PATTERN ANAL, V32, P1646, DOI 10.1109/TPAMI.2009.162
   Tu EM, 2015, NEUROCOMPUTING, V157, P173, DOI 10.1016/j.neucom.2015.01.020
   Varun AV, 2008, EXP FLUIDS, V45, P857, DOI 10.1007/s00348-008-0505-5
   Wernli H, 2006, J ATMOS SCI, V63, P2486, DOI 10.1175/JAS3766.1
   Wong KY, 2009, PATTERN RECOGN, V42, P1371, DOI 10.1016/j.patcog.2008.11.037
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu J.Z., 2006, Vorticity and Vortex Dynamics, P776, DOI DOI 10.1007/978-3-540-29028-5
   Xu H, 2011, THESIS, P33
   Xu HX, 2011, VISUAL COMPUT, V27, P441, DOI 10.1007/s00371-011-0577-8
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Zhang L, 2013, ED TEACHING FORUM, P32
NR 32
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14617
EP 14634
DI 10.1007/s11042-016-3812-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400005
DA 2024-07-18
ER

PT J
AU Lugmayr, A
   Sutinen, E
   Suhonen, J
   Sedano, CI
   Hlavacs, H
   Montero, CS
AF Lugmayr, Artur
   Sutinen, Erkki
   Suhonen, Jarkko
   Sedano, Carolina Islas
   Hlavacs, Helmut
   Montero, Calkin Suero
TI Serious storytelling - a first definition and review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Serious storytelling; Digital narratives; E-learning;
   Persuasive messages; Digital interactive media; Ubiquitous computation;
   E-health; Forensics; Human-computer interaction; User-experience;
   Storytelling, digital storytelling; Virtual reality; Design science;
   Education; E-leadership; Ubiqutious media; Ambient media; Smart media;
   Journalism
AB In human culture, storytelling is a long-established tradition. The reasons people tell stories are manifold: to entertain, to transfer knowledge between generations, to maintain cultural heritage, or to warn others of dangers. With the emergence of the digitisation of media, many new possibilities to tell stories in serious and non-entertainment contexts emerged. A very simple example is the idea of serious gaming, as in, digital games without the primary purpose of entertainment. In this paper, we introduce the term serious storytelling as a new potential media genre - defining serious storytelling as storytelling with a purpose beyond entertainment. We also put forward a review of existing potential application areas, and develop a framework for serious storytelling. We foresee several application areas for this fundamental concept, including wellbeing and health, medicine, psychology, education, ethical problem solving, e-leadership and management, qualitative journalism, serious digital games, simulations and virtual training, user experience studies, and online communication.
C1 [Lugmayr, Artur] Curtin Univ Technol, Perth, WA, Australia.
   [Sutinen, Erkki] Univ Turku, Comp Sci, Turku, Finland.
   [Suhonen, Jarkko] Univ Eastern Finland, Sch Comp, Joensuu, Finland.
   [Sedano, Carolina Islas] Univ Eastern Finland, Educ Technol Res Grp, Joensuu, Finland.
   [Montero, Calkin Suero] Univ Eastern Finland, Joensuu, Finland.
   [Hlavacs, Helmut] Univ Vienna, Inst Comp Sci & Business Informat, Vienna, Austria.
C3 Curtin University; University of Turku; University of Eastern Finland;
   University of Eastern Finland; University of Eastern Finland; University
   of Vienna
RP Lugmayr, A (corresponding author), Curtin Univ Technol, Perth, WA, Australia.
EM lartur@acm.org; erkki.sutinen@utu.fi; jarkko.suhonen@uef.fi;
   carolina.islas@uef.fi; helmut.hlavacs@univie.ac.at; calkins@uef.fi
RI Suhonen, Jarkko/X-6575-2019; Lugmayr, Artur/AAY-7738-2020; Lugmayr,
   Artur/G-4357-2014
OI Suhonen, Jarkko/0000-0002-3501-6286; Suero Montero,
   Calkin/0000-0001-5686-7285; Lugmayr, Artur/0000-0001-6994-4470
CR Alexander B., 2011, The new digital storytelling: Creating narratives with new media
   Alighieri D., 1321, DIVINE COMEDY
   [Anonymous], 2008, Computers in Entertainment
   [Anonymous], 1868, Proceedings of the American Academy of Arts and Sciences, DOI DOI 10.2307/20179567
   Bachmayer S, 2010, INT J WEB INF SYST, V6, P74, DOI 10.1108/17440081011034493
   Bernard S.C., 2011, Documentary storytelling: Creative nonfiction on screen, V3rd
   Bordwell D., 1997, FILM ART INTRO
   Campbell Joseph., 1990, The Hero's Journey: Joseph Campbell on His Life and Work
   Coats E, 22 STORY BASICS HAVE
   Cook David., 2004, HIST NARRATIVE FILM, V3rd
   Day D, 2015, MODEL VIEW CULTURE T
   Debra Malina P, EONLINE, P2160
   Denning S, 2011
   Duveskog Marcus, 2013, Journal of Educational Multimedia and Hypermedia, V22, P383
   Duveskog M., 2015, Digital storytelling for HIV and AIDS education in Africa
   Eco Umberto., 2014, The name of the rose
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   Gagne R.M., 1985, The conditions of learning and theory of instruction Robert Gagn
   Johanneson P, 2014, INTRO DESIGN SCI
   Kayali F, 2016, ENTERTAIN COMPUT, V15, P57, DOI 10.1016/j.entcom.2016.04.002
   Kolog E.A., 2014, International Journal of Education and Development using Information and Communication Technology, V10, P32
   Lamminen H, 2003, TELEMEDICINE JOURNAT, V8
   Lawrence R., 2016, New Directions for Adult and Continuing Education, V149, P63, DOI DOI 10.1002/ACE.20177
   Lothe J., 2000, Narrative in fiction and film: An introduction, vol, V20
   Lugmayr A, 2006, P SPIE, V6074
   Lugmayr A, 2006, 14 EUROMICRO INT C P, P348
   Lugmayr A, 2008, HIGH PERFORMANCE MUL, P7
   Lugmayr A, 2006, SIGGRAPH 2006
   Lugmayr A, 2007, INTERACTIVE TV SHARE, V35
   Lugmayr A., 2004, SIG COM TEC
   Lugmayr A, 2008, INTERACTIVE DIGITAL, P112
   Lugmayr A, 2000, P 7 UK VRSIG C UKVRS, P173
   Lugmayr A, 2008, ARTISTIC FILM MAKING
   Lugmayr A, P 15 INT ACAD MINDTR, P332
   Lugmayr A, 2013, MULTIMED TOOLS APPL, V66, P1, DOI 10.1007/s11042-012-1239-1
   Lugmayr A, 2013, MULTIMED TOOLS APPL, V66, P33, DOI 10.1007/s11042-012-1143-8
   Lugmayr A, 2012, IEEE INT CONF MULTI, P358, DOI 10.1109/ICMEW.2012.68
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P289, DOI 10.1007/s11042-011-0899-6
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P385, DOI 10.1007/s11042-010-0671-3
   Lugmayr A, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, P516, DOI 10.1109/ISPA.2008.141
   Manfred J., 2005, NARRATOLOGY GUIDE TH
   Manovich Lev, 2001, The Language of new media
   March J, 2004, AM J FOREN MED PATH, V25, P60, DOI 10.1097/01.paf.0000113863.69360.42
   McLeod S.A., 2009, Jean Piaget
   McLuhan M., 1994, Understanding media: the extensions of man 1964
   McQuail D., 2010, McQuail's mass communication theory
   Meadows M.S., 2002, Pause effect: the art of interactive narrative
   Mor Y, 2013, HANDBOOK OF DESIGN IN EDUCATIONAL TECHNOLOGY, P189
   Munezero M, 2013, P 13 KOLI CALLING IN, P142
   Nuutinen J, 2009, BR J ED TECHNOL, V5, P753
   Peng C, 2002, DIGITAL TELEVISION N, V17, P121
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Rakkolainen IsmoK., 2007, ACE '07, P95
   Ryan M- L, 2001, NARRATIVE VIRTUAL RE, P399
   Sadik A, 2008, ETR&D-EDUC TECH RES, V56, P487, DOI 10.1007/s11423-008-9091-8
   Samsel J, 1998, WRITING INTERACTIVE, P305
   Schanek R, 2007, ELEARN MAGAZINE
   Smeda N, 2014, SMART LEARN ENVIRON, V6
   Sutinen E, BIG DATA INTERFAITH
   Svahn M, 2015, CONVERGENT DIVERGENC
   Uhlmann S, 2011, MEDIA UBIQUITOUS ERA, P66
   Uhlmann S, 2008, P 12 INT C ENTERTAIN
   van Doorn M, 2006, CONTACT Q, V31
   Wells H.G., 1997, The War of the Worlds
NR 64
TC 82
Z9 94
U1 9
U2 134
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15707
EP 15733
DI 10.1007/s11042-016-3865-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900022
DA 2024-07-18
ER

PT J
AU Zhang, AZ
   Sun, GY
   Liu, SH
   Wang, ZJ
   Wang, P
   Ma, JS
AF Zhang, Ai Zhu
   Sun, Gen Yun
   Liu, Si Han
   Wang, Zhen Jie
   Wang, Peng
   Ma, Jing Sheng
TI Multi-scale segmentation of very high resolution remote sensing image
   based on gravitational field and optimized region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Gravitational field; Region merging; High
   resolution; Remote sensing
ID CLASSIFICATION; INFORMATION; ALGORITHM; AGGREGATION; WATERSHEDS;
   FEATURES; EDGE
AB This paper proposes a multi-scale segmentation approach for high resolution remote sensing image (HRRSI) based on the gravitational field and region merging. In this approach, the HRRSI is firstly transformed into a gravitational field by incorporating the spatial and spectral information. Based on which, the attraction among neighboring pixels will cause travelling of each pixel. During the travelling, pixels with similar spectral information which are at the nearby location get grouped, which define an initial segmentation for the HRRSI which is often over-segmented in places. Then, an improved graph based region merging method is adopted to merge the over-segmented regions which yield the multi-scale segmentation results. To evaluate the proposed approach, we conduct extensive experiments on three HRRSIs from different sensors and the obtained results are compared with those of eCognition's multi-resolution segmentation method. The experimental results show that the proposed approach reduces much more over-segmentation problem and produces more accurate image segmentation.
C1 [Zhang, Ai Zhu; Sun, Gen Yun; Wang, Zhen Jie; Wang, Peng] China Univ Petr East China, Sch Geosci, Qingdao 266580, Shandong, Peoples R China.
   [Zhang, Ai Zhu; Sun, Gen Yun; Wang, Zhen Jie; Wang, Peng] Qingdao Natl Lab Marine Sci & Technol, Lab Marine Mineral Resources, Qingdao 266071, Shandong, Peoples R China.
   [Liu, Si Han] Minist Environm Protect China, Satellite Environm Ctr, Beijing 100094, Peoples R China.
   [Ma, Jing Sheng] Heriot Watt Univ, Inst Petr Engn, Edinburgh EH14 2AD, Midlothian, Scotland.
C3 China University of Petroleum; Laoshan Laboratory; Heriot Watt
   University
RP Sun, GY (corresponding author), China Univ Petr East China, Sch Geosci, Qingdao 266580, Shandong, Peoples R China.; Sun, GY (corresponding author), Qingdao Natl Lab Marine Sci & Technol, Lab Marine Mineral Resources, Qingdao 266071, Shandong, Peoples R China.; Liu, SH (corresponding author), Minist Environm Protect China, Satellite Environm Ctr, Beijing 100094, Peoples R China.
EM genyunsun@163.com; liusihan1200@163.com
RI Aizhu, Zhang/AAS-8305-2021
OI Ma, Jingsheng/0000-0003-4054-6668
FU Chinese Natural Science Foundation Projects [41471353]
FX This work is funded by Chinese Natural Science Foundation Projects
   (41471353).
CR Akçay HG, 2008, IEEE T GEOSCI REMOTE, V46, P2097, DOI 10.1109/TGRS.2008.916644
   [Anonymous], P ACM C EMB NETW SEN
   [Anonymous], 2000, PROCESS ENHANCING SP
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Banerjee B, 2014, IEEE J-STARS, V7, P888, DOI 10.1109/JSTARS.2013.2266572
   BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P2587, DOI 10.1109/TGRS.2006.875360
   Carleer AP, 2006, INT J REMOTE SENS, V27, P1035, DOI 10.1080/01431160500297956
   Chabrier S, 2006, EURASIP J APPL SIG P, P217
   De Wit AJW, 2004, INT J REMOTE SENS, V25, P4091, DOI 10.1080/01431160310001619580
   Gaetano R, 2009, IEEE T GEOSCI REMOTE, V47, P2129, DOI 10.1109/TGRS.2008.2010708
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Hay GJ, 2003, ISPRS J PHOTOGRAMM, V57, P327, DOI 10.1016/S0924-2716(02)00162-4
   Huang ZJ, 2014, OPTIK, V125, P870, DOI 10.1016/j.ijleo.2013.07.092
   Ilc N, 2012, NEUROCOMPUTING, V96, P47, DOI 10.1016/j.neucom.2011.10.043
   Johnson B, 2011, ISPRS J PHOTOGRAMM, V66, P473, DOI 10.1016/j.isprsjprs.2011.02.006
   Karl JW, 2010, LANDSCAPE ECOL, V25, P591, DOI 10.1007/s10980-009-9439-4
   Liu J, 2015, ISPRS J PHOTOGRAMM, V101, P145, DOI 10.1016/j.isprsjprs.2014.11.009
   Moreno R., 2014, RECENT ADV KNOWLEDGE, P103
   NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Rashedi E, 2013, ENG APPL ARTIF INTEL, V26, P1322, DOI 10.1016/j.engappai.2012.10.002
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rezvanifar A, 2014, IEEE T IMAGE PROCESS, V23, P635, DOI 10.1109/TIP.2013.2289984
   Sen D, 2012, INFORM SCIENCES, V191, P169, DOI 10.1016/j.ins.2011.12.029
   Sun GY, 2007, PATTERN RECOGN, V40, P2766, DOI 10.1016/j.patcog.2007.01.006
   Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922
   Tilton JC, 2012, IEEE T GEOSCI REMOTE, V50, P4454, DOI 10.1109/TGRS.2012.2190079
   Tzotsos A., 2006, P ASPRS 2006 ANN C R
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   WRIGHT WE, 1977, PATTERN RECOGN, V9, P151, DOI 10.1016/0031-3203(77)90013-9
   Wu T, 2014, OPT LASER TECHNOL, V62, P1, DOI 10.1016/j.optlastec.2014.02.004
   Yuan JY, 2014, IEEE T GEOSCI REMOTE, V52, P16, DOI 10.1109/TGRS.2012.2234755
   Zhang XL, 2014, ISPRS J PHOTOGRAMM, V98, P19, DOI 10.1016/j.isprsjprs.2014.09.011
   Zhao JN, 2015, OPTIK, V126, P4330, DOI 10.1016/j.ijleo.2015.08.037
NR 37
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15105
EP 15122
DI 10.1007/s11042-017-4558-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400031
DA 2024-07-18
ER

PT J
AU Liu, QG
   Xiong, JJ
   Zhu, L
   Zhang, MH
   Wang, YH
AF Liu, Qiegen
   Xiong, Jiaojiao
   Zhu, Li
   Zhang, Minghui
   Wang, Yuhao
TI Extended RGB2Gray conversion model for efficient contrast preserving
   decolorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color-to-gray conversion; extended RGB2GRAY conversion model; gradient
   correlation similarity; the linear parametric model; discrete searching
ID COLOR-TO-GRAY; GRADIENT; IMAGES
AB The RGB2GRAY conversion model is the classical and most popularly used tool for image decolorization. Recent researches have validated that optimally selecting the three weighting parameters in this first-order linear model has great potential to improve its conversion ability. A question is naturally raised that extending the parameter range will count for further improvement? In this paper, we present a simple yet efficient strategy to extend the parameter range for achieving such goal. In the extended model, the parameter range is extended to be [-1, 1] and the sum of three parameters is still constrained to be 1. A discrete searching solver is proposed by determining the solution with the minimum function value from the linear parametric model induced candidate images. Among the solving procedure, the newly presented vector p-norm of gradient correlation similarity measure is utilized. Extensive experiments under a variety of test images and a comprehensive evaluation against the state-of-the-art methods consistently demonstrate the potential of the proposed model and algorithm.
C1 [Liu, Qiegen; Xiong, Jiaojiao; Zhu, Li; Zhang, Minghui; Wang, Yuhao] Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Liu, Qiegen] Univ Illinois, Beckman Inst, 405 N Mathews Ave, Urbana, IL 61801 USA.
C3 Nanchang University; University of Illinois System; University of
   Illinois Urbana-Champaign
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.; Liu, QG (corresponding author), Univ Illinois, Beckman Inst, 405 N Mathews Ave, Urbana, IL 61801 USA.
EM liuqiegen@ncu.edu.cn; 1368824644@qq.com; 237833977@qq.com;
   zhangmh3529@163.com; wangyuhao@ncu.edu.cn
RI WANG, Yuhao/O-9322-2019; Li, Yuanyuan/J-3539-2014
OI WANG, Yuhao/0000-0002-8445-0361; Li, Yuanyuan/0000-0001-6151-9306
FU National Natural Science Foundation of China [61362001, 61503176,
   61261010, 51165033]; Natural Science Foundation of Jiangxi Province
   [20151BAB207008, 20151BAB207007]; Jiangxi Advanced Projects for
   Post-doctoral Research Funds [2014KY02]; international postdoctoral
   exchange fellowship program
FX The authors sincerely thank the anonymous reviewers for their valuable
   comments and constructive suggestions that are very helpful in the
   improvement of this paper. This work was partly supported by the
   National Natural Science Foundation of China under 61362001, 61503176,
   61261010, 51165033, the Natural Science Foundation of Jiangxi Province
   under 20151BAB207008, 20151BAB207007, Jiangxi Advanced Projects for
   Post-doctoral Research Funds under 2014KY02 and the international
   postdoctoral exchange fellowship program.
CR Ancuti CO, 2011, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2011.5995414
   [Anonymous], 2007, PROC 3 EUR C COMPUTA
   [Anonymous], 2010, P AS C COMP VIS
   [Anonymous], ACM SIGGRAPH ASIA TE
   Bala R, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P82
   Cadík M, 2008, COMPUT GRAPH FORUM, V27, P1745
   Du H, 2015, IEEE T IMAGE PROCESS, V24, P434, DOI 10.1109/TIP.2014.2380172
   Eynard D, 2014, COMPUT GRAPH FORUM, V33, P215, DOI 10.1111/cgf.12295
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Grundland M, 2007, PATTERN RECOGN, V40, P2891, DOI 10.1016/j.patcog.2006.11.003
   Ji Z., 2015, VISUAL COMPUT, P1
   Jin ZM, 2014, SIAM J IMAGING SCI, V7, P944, DOI 10.1137/130935197
   Kim Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618507
   Lee B, 2015, IEEE IMAGE PROC, P3170, DOI 10.1109/ICIP.2015.7351388
   Liu QG, 2015, IEEE T IMAGE PROCESS, V24, P2889, DOI 10.1109/TIP.2015.2423615
   Liu QG, 2013, IEEE I CONF COMP VIS, P1081, DOI 10.1109/ICCV.2013.138
   Lu C., 2012, ACM SIGGRAPH ASIA TE
   Lu CW, 2014, INT J COMPUT VISION, V110, P222, DOI 10.1007/s11263-014-0732-6
   Qin L, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P1, DOI [10.1109/ICACI.2012.6463111, 10.1109/ICCH.2012.6724460]
   Rasche K, 2005, COMPUT GRAPH FORUM, V24, P423, DOI 10.1111/j.1467-8659.2005.00867.x
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Song ML, 2013, NEUROCOMPUTING, V119, P222, DOI 10.1016/j.neucom.2013.03.037
   Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74
   Song YB, 2014, IEEE WINT CONF APPL, P159, DOI 10.1109/WACV.2014.6836106
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
NR 25
TC 14
Z9 15
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14055
EP 14074
DI 10.1007/s11042-016-3748-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800018
DA 2024-07-18
ER

PT J
AU He, W
   Zhu, XF
   Cheng, DB
   Hu, RY
   Zhang, SC
AF He, Wei
   Zhu, Xiaofeng
   Cheng, Debo
   Hu, Rongyao
   Zhang, Shichao
TI Low-rank unsupervised graph feature selection via feature
   self-representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-rank; Unsupervised feature selection; Self-representation; Sparse
   learning; Graph embedding
ID IMAGE; CLASSIFICATION; INFORMATION; PATTERN
AB Feature selection and subspace learning are two popular approaches of dimensionality reduction for solving the issue of 'curse of dimensionality' in high-dimensional data. However, most of previous methods of feature selection and subspace learning ignore the fact that there exist noise and outliers in high-dimensional data, which increase the rank of the data matrix so that decreasing the stability of learning models. In this paper, we integrate a feature-level self-representation loss function, a low-rank constraint, a graph Laplacian regularizer, and a sparsity regularizer into a unified framework to conduct unsupervised feature selection for solving mentioned issues. Specifically, we first propose a new feature-level self-representation loss function plus a sparsity regularizer (a"" (2,1)-norm regularizer) to select representative features, and then push a low-rank constraint on the coefficient matrix which considers the response variables as a whole group to avoid the impact of noise and outliers, and a graph regularizer to preserve the local structures of the data to conduct subspace learning in the framework of feature selection. Experimental results on real databases implied that the proposed method effectively selected the most representative features and removed the adverse effect of irrelevant features, compared to the state-of-the-art methods.
C1 [He, Wei; Zhu, Xiaofeng; Cheng, Debo; Hu, Rongyao; Zhang, Shichao] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Zhu, XF; Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM risehnhew@163.com; seanzhuxf@gmail.com; 15676209686@163.com;
   hu_No1@126.com; zhangsc@maibox.gxnu.edu.cn
RI Hu, Rongyao/AAH-3834-2020; Zhang, Shichao/AAA-7608-2020; Cheng,
   Debo/Y-5226-2019; Zhang, Shichao/JXW-9650-2024; Zhu,
   Xiaofeng/HII-5291-2022
OI Hu, Rongyao/0000-0001-9989-1103; Cheng, Debo/0000-0002-0383-1462; Zhu,
   Xiaofeng/0000-0001-6840-0578
FU National Natural Science Foundation of China [61263035, 61573270,
   61450001, 61363009]; China 973 Program [2013CB329404]; Guangxi Natural
   Science Foundation [2015GXNSFCB139011]; Guangxi Higher Institutions'
   Program of Introducing 100 High-Level Over-seas Talents; Guangxi
   Collaborative Innovation Center of Multi-Source Information Integration
   and Intelligent Processing; Innovation Project of Guangxi Graduate
   Education [YCSZ2016046]; project "Application and Research of Big Data
   Fusion in Inter-City Traffic Integration of The Xijiang River - Pearl
   River Economic Belt(da shu jv rong he zai xijiang zhujiang jing ji dai
   cheng ji jiao tong yi ti hua zhong de ying yong yu yan jiu)"
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No: 61263035, 61573270, 61450001 and
   61363009), the China 973 Program (Grant No: 2013CB329404), the Guangxi
   Natural Science Foundation (Grant No: 2015GXNSFCB139011), the Guangxi
   Higher Institutions' Program of Introducing 100 High-Level Over-seas
   Talents, the Guangxi Collaborative Innovation Center of Multi-Source
   Information Integration and Intelligent Processing, Innovation Project
   of Guangxi Graduate Education under grant YCSZ2016046 and the project
   "Application and Research of Big Data Fusion in Inter-City Traffic
   Integration of The Xijiang River - Pearl River Economic Belt(da shu jv
   rong he zai xijiang zhujiang jing ji dai cheng ji jiao tong yi ti hua
   zhong de ying yong yu yan jiu)".
CR [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], JOINT DIAGNOSIS CONV
   [Anonymous], 2007, P AAAI C ART INT
   [Anonymous], VISUAL CODING SEMANT
   [Anonymous], KDD
   [Anonymous], 2015, BRAIN STRUCT FUNCT
   [Anonymous], P 19 ACM SIGKDD C KN
   Cao J, 2014, INFORM SCIENCES, V266, P31, DOI 10.1016/j.ins.2013.12.062
   Cao J, 2013, WORLD WIDE WEB, V16, P729, DOI 10.1007/s11280-012-0164-6
   Cao J, 2013, KNOWL INF SYST, V36, P607, DOI 10.1007/s10115-012-0562-1
   Cao J, 2013, SIGNAL PROCESS, V93, P2026, DOI 10.1016/j.sigpro.2012.07.030
   Cao J, 2013, IEEE T CYBERNETICS, V43, P570, DOI 10.1109/TSMCB.2012.2212430
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Leung Y, 2010, IEEE ACM T COMPUT BI, V7, P108, DOI 10.1109/TCBB.2008.46
   Lewandowski M, 2014, IEEE T CYBERNETICS, V44, P936, DOI 10.1109/TCYB.2013.2277664
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu RY, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS, P65, DOI 10.1109/IITA.2009.390
   Lv SZ, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P664, DOI 10.1109/FSKD.2013.6816279
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Tabakhi S, 2014, ENG APPL ARTIF INTEL, V32, P112, DOI 10.1016/j.engappai.2014.03.007
   Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033
   Thung KH, 2012, PATTERN RECOGN, V45, P2193, DOI 10.1016/j.patcog.2011.12.001
   Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037
   Wang JJY, 2014, IEEE IJCNN, P1942, DOI 10.1109/IJCNN.2014.6889591
   Xu Y, 2010, EXPERT SYST APPL, V37, P6718, DOI 10.1016/j.eswa.2010.02.107
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Zhang J, 2014, BIOMED OPT EXPRESS, V5, P1861, DOI 10.1364/BOE.5.001861
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhang Q, 2015, IEEE T GEOSCI REMOTE, V53, P261, DOI 10.1109/TGRS.2014.2321405
   Zheng ZW, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P810
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, LECT NOTES COMPUT SC, V8674, P162, DOI 10.1007/978-3-319-10470-6_21
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
NR 42
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12149
EP 12164
DI 10.1007/s11042-016-3937-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000056
DA 2024-07-18
ER

PT J
AU Ji, XY
   Bai, S
   Zhu, GB
   Yan, B
AF Ji Xiaoyong
   Bai Sen
   Zhu Guibin
   Yan Bing
TI Image encryption and compression based on the generalized knight's tour,
   discrete cosine transform and chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption and compression; The generalized knight's tour;
   Discrete cosine transform; Chaotic maps
ID CRYPTANALYSIS; ALGORITHM
AB An efficient and simple encryption and compression scheme for digital image is reported in this paper. This scheme is based on the algorithm of the generalized knight's tour, discrete cosine transform and non-linear chaotic maps. In this scheme, according to the structure of compression, confusion and diffusion are attained by methods of the generalized knight's tour and chaotic maps. Firstly, the generalized knight's tour algorithm is utilized to scramble the pixels while the data correlation preserved. Then, the chaotic system is used to generate a pseudorandom permutation to encrypt the part of coefficients from discrete cosine transform for diffusion. Experimental results show that the proposed scheme can gain robust security and a high compression ratio, which indicates that the proposed scheme is practicable.
C1 [Ji Xiaoyong; Bai Sen; Zhu Guibin; Yan Bing] Chongqing Commun Inst, Chongqing 400035, Peoples R China.
   [Ji Xiaoyong; Bai Sen; Zhu Guibin; Yan Bing] Chongqing Key Lab Emergency Commun, Chongqing 400035, Peoples R China.
RP Bai, S (corresponding author), Chongqing Commun Inst, Chongqing 400035, Peoples R China.; Bai, S (corresponding author), Chongqing Key Lab Emergency Commun, Chongqing 400035, Peoples R China.
EM baisencq@126.com
FU National Natural Science Foundation of China [61272043]; Basic and
   Frontier Project of Chongqing [cstc2013jjB40009]; Program for Innovative
   Research Team in University of Chongqing [KJTD201343]; innovation
   project of graduate students [CYS14203]
FX The work on this paper is supported by National Natural Science
   Foundation of China (Grant No. 61272043), Basic and Frontier Project of
   Chongqing (Project No. cstc2013jjB40009), Program for Innovative
   Research Team in University of Chongqing (No. KJTD201343) and innovation
   project of graduate students (CYS14203).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bai S, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P570, DOI 10.1109/ICCIAS.2006.294200
   Bai S, 2010, DISCRETE APPL MATH, V158, P1727, DOI 10.1016/j.dam.2010.07.009
   Chen JY, 2011, IEEE T CIRCUITS-II, V58, P110, DOI 10.1109/TCSII.2011.2106316
   Gordon VS, 2004, IEEE C EVOL COMPUTAT, P1435, DOI 10.1109/CEC.2004.1331065
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Jiang Delei, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P251, DOI 10.1109/CSSE.2008.1142
   Kim H, 2007, IEEE T SIGNAL PROCES, V55, P2263, DOI 10.1109/TSP.2007.892710
   Li CQ, 2014, SIGNAL PROCESS-IMAGE, V29, P914, DOI 10.1016/j.image.2014.06.011
   Li SJ, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2360697
   Li SJ, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6011939
   Nivasch G, 2003, TECHNICAL REPORT, P1
   Philip A, 2013, IEEE POTENTIALS, V32, P10, DOI 10.1109/MPOT.2012.2219651
   Sen B, 2002, INT CONTR AUT 2002 P, V2, P1333
   Thanikaiselvan V, 2012, PROCEDIA ENGINEER, V30, P36, DOI 10.1016/j.proeng.2012.01.831
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wong KW, 2008, IEEE T CIRCUITS-II, V55, P1193, DOI 10.1109/TCSII.2008.2002565
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yuen CH, 2011, APPL SOFT COMPUT, V11, P5092, DOI 10.1016/j.asoc.2011.05.050
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P1366, DOI 10.1016/j.cnsns.2013.09.019
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
   Zhou JT, 2008, IEEE T CIRCUITS-I, V55, P3368, DOI 10.1109/TCSI.2008.924117
   Zhou JT, 2009, IEEE T SIGNAL PROCES, V57, P1825, DOI 10.1109/TSP.2009.2013901
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
   Zhu ZL, 2009, 2009 INTERNATIONAL WORKSHOP ON CHAOS-FRACTALS THEORIES AND APPLICATIONS (IWCFTA 2009), P260, DOI 10.1109/IWCFTA.2009.61
NR 30
TC 11
Z9 11
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12965
EP 12979
DI 10.1007/s11042-016-3684-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200035
DA 2024-07-18
ER

PT J
AU Li, WM
   Ye, ZB
   Xin, MJ
   Jin, Q
AF Li, Weimin
   Ye, Zhengbo
   Xin, Minjun
   Jin, Qun
TI Social recommendation based on trust and influence in SNS environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation algorithm; Similarity; Trust; Social influence
AB The development of social media provides convenience to people's lives. People's social relationship and influence on each other is an important factor in a variety of social activities. It is obviously important for the recommendation, while social relationship and user influence are rarely taken into account in traditional recommendation algorithms. In this paper, we propose a new approach to personalized recommendation on social media in order to make use of such a kind of information, and introduce and define a set of new measures to evaluate trust and influence based on users' social relationship and rating information. We develop a social recommendation algorithm based on modeling of users' social trust and influence combined with collaborative filtering. The optimal linear relation between them will be reached by the proposed method, because the importance of users' social trust and influence varies with the data. Our experimental results show that the proposed algorithm outperforms traditional recommendation in terms of recommendation accuracy and stability.
C1 [Li, Weimin; Ye, Zhengbo; Xin, Minjun] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Jin, Qun] China Jiliang Univ, Coll Informat Engn, Hangzhou, Zhejiang, Peoples R China.
   [Jin, Qun] Waseda Univ, Fac Human Sci, Tokorozawa, Saitama, Japan.
C3 Shanghai University; China Jiliang University; Waseda University
RP Jin, Q (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou, Zhejiang, Peoples R China.; Jin, Q (corresponding author), Waseda Univ, Fac Human Sci, Tokorozawa, Saitama, Japan.
EM wmli@shu.edu.cn; yezb@shu.edu.cn; xinmj@shu.edu.cn; jin@waseda.jp
RI Li, Weimin/ADE-4854-2022
FU National Natural Science Foundation [61074315, 71061005/G0112]; Natural
   Science Foundation of Ningxia [NZ12212]
FX This work was partly supported by National Natural Science Foundation
   under Grant No. 61074315 and No. 71061005/G0112, and Natural Science
   Foundation of Ningxia under Grant No. NZ12212.
CR [Anonymous], 2007, KDD CUP WORKSH
   [Anonymous], 2014, Association for Computing Machinery SIGKDD Explorations Newsletter, DOI [DOI 10.1145/2641190.2641195, 10.1145/2641190.2641195]
   Bonhard P, 2006, BT TECHNOL J, V24, P84, DOI 10.1007/s10550-006-0080-3
   Cha  M., 2010, ICWSM, P10
   Gayo-Avello D., 2010, SPAN C INF RETR CERI
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Guha R., 2004, P 13 INT C WORLD WID, P403, DOI [DOI 10.1145/988672.988727, 10.1145/988672.988727]
   Guy I., 2009, Proceedings of the 14th international conference on Intelligent user interfaces, P77
   He J., 2010, SOCIAL NETWORK BASED
   Huang J., 2012, P 5 ACM INT C WEB SE
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397
   Jebrin AS, P 2 ACM RECSYS 10 WO, P1
   Josang A., 2011, IFIP International Conference on Trust Management, P312
   Kempe D, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kim HW, 2012, ELECTRON COMMER R A, V11, P241, DOI 10.1016/j.elerap.2011.06.003
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Lathia N, 2008, INT FED INFO PROC, V263, P119
   Li F, 2011, DECIS SUPPORT SYST, V51, P190, DOI 10.1016/j.dss.2010.12.007
   Liu DR, 2011, INT J HUM-COMPUT ST, V69, P587, DOI 10.1016/j.ijhcs.2011.06.001
   Lü LY, 2012, PHYS REP, V519, P1, DOI 10.1016/j.physrep.2012.02.006
   Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   Nykl M, 2014, J INFORMETR, V8, P683, DOI 10.1016/j.joi.2014.06.005
   ODonovan John, 2005, P 10 INT C INTELLIGE, P167, DOI [10.1145/1040830.1040870, DOI 10.1145/1040830.1040870]
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Qiao Xiu-Quan, 2011, Chinese Journal of Computers, V34, P2403, DOI 10.3724/SP.J.1016.2011.02403
   Sarabjot S.A., 2011, Proceedings of the fifth ACM conference on Recommender systems, RecSys '11, P205
   Sarwar B, 2000, APPL DIMENSIONALITY
   Singla P., 2008, Proceedings of the 17th international conference on World Wide Web, WWW '08, P655, DOI DOI 10.1145/1367497.1367586
   Song Xiaodan., 2006, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, P509, DOI [10.1145/1148170.1148258, DOI 10.1145/1148170.1148258>(2006)]
   Victor P, 2011, IEEE INTELL SYST, V26, P48, DOI 10.1109/MIS.2011.22
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Yang B, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P195, DOI 10.1109/CIS.2012.51
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
   Yuan Q., 2009, Proceedings of Workshop on Recommender Systems and the Social Web, P49
   Ziegler CN, 2004, LECT NOTES COMPUT SC, V2995, P251
NR 40
TC 11
Z9 13
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11585
EP 11602
DI 10.1007/s11042-015-2732-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000027
DA 2024-07-18
ER

PT J
AU Yin, CJ
   Yau, JYK
   Hwang, GJ
   Ogata, H
AF Yin, Chengjiu
   Yau, Jane Yin-Kim
   Hwang, Gwo-Jen
   Ogata, Hiroaki
TI An SNS-based model for finding collaborative partners
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networking; Personal relationship; Collaboration; Search engine
ID SOCIAL NETWORK SITES; TRUST
AB This paper proposes a model, Recommendation of Appropriate Partners (RAP), used on a Social Networking Service (SNS) for locating appropriate "helpers" for users based on individual users' Chain of Friends (CoF) relationships. Using the RAP model, individual users can participate in a collaborative online community in remote locations, whereby helpers are willing to help other users solve their tasks/problems, and it is intended that both the users and helpers gain knowledge from these interactive online sessions. An example of the RAP-based system was implemented to invite Program Committee members to an international conference. The system was evaluated and the experimental results show that our model is very effective for discovering collaboration partners and finding users with similar interests in order to create communities for providing future and longer-term helping exchange.
C1 [Yin, Chengjiu] Kyushu Univ, Fac Arts & Sci, Nishi Ku, 744 Motooa, Fukuoka 8190395, Japan.
   [Yau, Jane Yin-Kim] Malmo Univ, Dept Comp Sci, Malmo, Sweden.
   [Hwang, Gwo-Jen] Natl Taiwan Univ Sci & Technol, Grad Inst Digital Learning & Educ, Taipei, Taiwan.
   [Ogata, Hiroaki] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fac Arts & Sci, Fukuoka, Japan.
C3 Kyushu University; Malmo University; National Taiwan University of
   Science & Technology; Kyushu University
RP Yin, CJ (corresponding author), Kyushu Univ, Fac Arts & Sci, Nishi Ku, 744 Motooa, Fukuoka 8190395, Japan.
EM yinchengjiu@gmail.com
RI Hwang, Gwo-Jen/G-6454-2012; Ogata, Hiroaki/ABF-6023-2020; Yin,
   Chengjiu/J-4663-2018; Yin, Chengjiu/E-9570-2018
OI Ogata, Hiroaki/0000-0001-5216-1576; Yin, Chengjiu/0000-0003-1492-5250;
   Yau, Jane Yin-Kim/0000-0001-6688-7079
FU JSPS KAKENHI [25750084]; Grants-in-Aid for Scientific Research
   [25750084, 16H03078] Funding Source: KAKEN
FX This work was supported in part by JSPS KAKENHI Grant Number 25750084.
CR BAIER A, 1986, ETHICS, V96, P231, DOI 10.1086/292745
   Barile AL, 2002, COMPUT HUM BEHAV, V18, P173, DOI 10.1016/S0747-5632(01)00040-1
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Brown B.B., 1989, Peer relationships in child development, P188
   Chang WL, 2013, COMPUT EDUC, V62, P320, DOI 10.1016/j.compedu.2012.11.007
   Chen YJ, 2012, ACTA HORTIC, V938, P137, DOI 10.1109/WMUTE.2012.32
   Colquitt JA, 2007, J APPL PSYCHOL, V92, P909, DOI 10.1037/0021-9010.92.4.909
   De Guzman Edward S., 2007, Proceedings Graphics Interface 2007, P143, DOI 10.1145/1268517.1268542
   Dinet J, 2012, BRIT J EDUC TECHNOL, V43, P439, DOI 10.1111/j.1467-8535.2011.01199.x
   El-Bishouty MM, 2010, EDUC TECHNOL SOC, V13, P27
   Eveland J. D., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P265, DOI 10.1145/192844.193025
   Heo GM, 2013, EDUC TECHNOL SOC, V16, P133
   Howes C., 2008, Encyclopedia of Infant and Early Chilhood Development, V1, P552
   Hsu MH, 2007, INT J HUM-COMPUT ST, V65, P153, DOI 10.1016/j.ijhcs.2006.09.003
   Joinson AN, 2008, SOCIAL NETWORKS, V5
   Kelley PG, 2011, LECT NOTES COMPUT SC, V6948, P216, DOI 10.1007/978-3-642-23765-2_15
   Lampe C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P435
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   Ozenc FK, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P561
   Qing Tan, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P16, DOI 10.1109/ICALT.2010.11
   Raento M, 2005, IEEE PERVAS COMPUT, V4, P51, DOI 10.1109/MPRV.2005.29
   Rollett H, 2007, INT J LEARN TECHNOL, V3, P87, DOI 10.1504/IJLT.2007.012368
   Stecher Kristin, 2008, P 2 INT C WEBL SOC M, P127
   Yin C., 2004, The Journal of Information and Systems in Education, V3, P33
NR 24
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11531
EP 11545
DI 10.1007/s11042-015-2480-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000024
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, XX
   Nie, WZ
   Su, YT
AF Zhang, Jing
   Li, Xiaoxue
   Nie, Weizhi
   Su, Yuting
TI Automatic report generation based on multi-modal information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News event detection; Multi-modal; Report generation
ID FUSION; VIEW
AB In this paper, we propose a new framework which can utilize multi-modal social media information to automatically generate related reports for users or government. First, we utilize DBSCAN (Density Based Spatial Clustering of Applications with Noise) to detect events in official news websites. Then, some unofficial information details are extracted from social network platforms (Foursquare, Twitter, YouTube), which will be leveraged to enhance the official report in order to excavate some latent and useful information. In this process, we applied some classic textual processing methods and computer vision technologies to reduce the noise information uploaded by user generated contents (UGCs). Then, we applied LSTM-CNN model to generate the related image caption and successfully convert visual information to textual information. Finally, we extracted some latent topics using graph cluster method to generate the final report. To demonstrate the effectiveness of our framework, we got a large of multi-source event dataset from official news websites and Twitter. Finally, the user study demonstrates the practicability of our approach.
C1 [Zhang, Jing; Li, Xiaoxue; Nie, Weizhi; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61502337, 61472275];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [15JCYBJC16200]; Elite Scholar Program of Tianjin University
   [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61502337, 61472275), the Tianjin Research Program
   of Application Foundation and Advanced Technology (15JCYBJC16200), the
   grant of Elite Scholar Program of Tianjin University (2014XRG-0046).
CR Abel F, 2011, LECT NOTES COMPUT SC, V6787, P1, DOI 10.1007/978-3-642-22362-4_1
   Aggarwal C., 2012, A Survey of Text Clustering Algorithms
   [Anonymous], IEEE C VIS AN SCI TE
   [Anonymous], 2010, WWW
   [Anonymous], 2009, P 17 ACM SIGSPATIAL, DOI DOI 10.1145/1653771.1653781
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], ANOMALY DETECTION ST
   [Anonymous], PRIVACY PRESERVING D
   [Anonymous], ICWSM
   [Anonymous], INTRO TOPIC DETECTIO
   [Anonymous], THESIS
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baucom E., 2013, International Workshop on Mining Unstructured Big Data Using Natural Language Processing, P61
   Gao DH, 2014, IEEE-ACM T AUDIO SPE, V22, P293, DOI 10.1109/TASL.2013.2282191
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Hua T, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1466
   Kuo YH, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P201, DOI 10.1145/2647868.2656406
   Larivière B, 2013, J SERV MANAGE, V24, P268, DOI 10.1108/09564231311326996
   Lee CH, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P254, DOI 10.1109/ASONAM.2011.74
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2012, IEEE T MED IMAGING, V31, P359, DOI 10.1109/TMI.2011.2169495
   Liu PL, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P111
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Wang YH, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1231, DOI 10.1145/2736277.2741634
   Weizhi Nie, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P574, DOI 10.1007/978-3-319-03731-8_53
   Weng J., 2011, P 5 INT C WEBLOGS SO
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Xie W, 2013, IEEE DATA MINING, P837, DOI 10.1109/ICDM.2013.86
   Zhang YJ, 2013, INT CONF SERVICE SCI, P64, DOI 10.1109/ICSS.2013.38
NR 32
TC 3
Z9 4
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12005
EP 12015
DI 10.1007/s11042-016-3936-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000047
DA 2024-07-18
ER

PT J
AU To, HT
   Sohn, BS
AF Hai Thien To
   Sohn, Bong-Soo
TI Bas-relief generation from face photograph based on facial feature
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer graphics; Bas-relief; 3D printing
AB This paper describes a novel method for generating a bas-relief surface from the photographic image of a human face. One of the simplest methods is to take each pixel brightness as a depth value and use it to elevate the resulting surface. Although this approach can generate a bas-relief surface with realistic textures, it has the disadvantage of generating erroneous 3D depth. This problem is especially serious in the areas of facial features, such as hair, eyes, eyebrows, nose, and lips, because they are often composed of dark pixel values, and hence make the corresponding area sunken on the resulting surface. Our main contribution is to resolve this problem by detecting the facial features and making them protrude by adjusting the brightness values of the areas. The experimental results show that our method generates realistic and natural looking bas-relief surfaces that represent more accurate 3D depth, especially in the areas of facial features.
C1 [Hai Thien To; Sohn, Bong-Soo] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Sohn, BS (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM bongbong@cau.ac.kr
OI To, Hai Thien/0000-0002-2099-1863
CR Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   Furferi R, 2014, GRAPH MODELS, V76, P706, DOI 10.1016/j.gmod.2014.10.001
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Kerber J, 2007, P 23 SPRING C COMP G, P101
   Kerber J, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P148, DOI 10.1109/SMI.2009.5170176
   Li ZW, 2012, IEEE T VIS COMPUT GR, V18, P177, DOI 10.1109/TVCG.2011.26
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Patil CS, 2013, INT J COMPUT APPL, V62
   Reichinger A., 2011, J. Comput. Cult. Herit, V4, P108, DOI DOI 10.1145/2037820.2037822
   Song WH, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P211, DOI 10.1109/SMI.2007.9
   Sun XF, 2009, IEEE T VIS COMPUT GR, V15, P642, DOI 10.1109/TVCG.2009.21
   Tanaka M, 2014, FACE PARTS DETECTION
   To HT, 2016, HCI KOR C
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Zeng Q, 2014, GRAPH MODELS, V76, P140, DOI 10.1016/j.gmod.2013.10.001
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang YW, 2013, GRAPH MODELS, V75, P2, DOI 10.1016/j.gmod.2012.10.003
NR 19
TC 12
Z9 14
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10407
EP 10423
DI 10.1007/s11042-016-3924-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400006
DA 2024-07-18
ER

PT J
AU Jung, JE
   Lee, OJ
   You, ES
   Nam, MH
AF Jung, Jai E.
   Lee, O-Joun
   You, Eun-Soon
   Nam, Myoung-Hee
TI A computational model of transmedia ecosystem for story-based contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transmedia; Storytelling; Multimedia analysis; Digital contents;
   Computational ecosystem
AB Story-based contents (e.g., novel, movies, and computer games) have been dynamically transformed into various media. In this environment, the contents are not complete in themselves, but closely connected with each other. Also, they are not simply transformed form a medium to other media, but expanding their stories. It is called as a transmedia storytelling, and a group of contents following it is called as a transmedia ecosystem. Since the contents are highly connected in terms of the story in the transmedia ecosystem, the existing content analysis methods are hard to extract relationships between the contents. Therefore, a proper content analysis method is needed with considering expansions of the story. The aim of this work is to understand how (and why) such contents are transformed by i) defining the main features of the transmedia storytelling and ii) building the taxonomy among the transmedia patterns. More importantly, computational transmedia ecosystem is designed to process a large number of the contents, and to support high understandability of the complex transmedia patterns.
C1 [Jung, Jai E.; Lee, O-Joun] Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
   [You, Eun-Soon] Inha Univ, Dept French Civilizat, Incheon 22212, South Korea.
   [Nam, Myoung-Hee] Inha Univ, Dept Theater & Film Studies, Incheon 22212, South Korea.
C3 Chung Ang University; Inha University; Inha University
RP Lee, OJ (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
EM concerto34@cau.ac.kr
RI Jung, Jason J./B-9622-2012; Lee, O-Joun/A-3607-2015; You,
   Eun-Soon/E-7686-2015
OI Jung, Jason J./0000-0003-0050-7445; Lee, O-Joun/0000-0001-8921-5443;
   You, Eun-Soon/0000-0001-8827-1232
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of Korea [NRF-2015S1A5B6037297]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2015S1A5B6037297).
CR Aarseth E, 2006, POP COMMUN, V4, P203, DOI 10.1207/s15405710pc0403_4
   Scolari CA, 2009, INT J COMMUN-US, V3, P586
   [Anonymous], 2007, THESIS
   Boutemedjet S, 2008, IEEE T MULTIMEDIA, V10, P52, DOI 10.1109/TMM.2007.911226
   Brooker W, 2009, POP COMMUN, V7, P79, DOI 10.1080/15405700802659056
   Chunwijitra S, 2013, IEICE T INF SYST, VE96D, P1754, DOI 10.1587/transinf.E96.D.1754
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Fienberg SE, 2010, STAT METHODOL, V7, P175
   Harvey CB, 2015, HOBBITS HULKS ADAPTA, P63
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Jung JJ, 2013, MULTIMED TOOLS APPL, V65, P29, DOI 10.1007/s11042-012-1133-x
   Krizanovich K, 2010, THESIS
   Manning S., 2005, International Journal of Project Management, V23, P410, DOI [10.1016/j.ijproman.2005.03.006, DOI 10.1016/J.IJPROMAN.2005.03.006]
   McKee R., 1997, SUBSTANCE STRUCTURE
   Meixner B, 2014, MULTIMED TOOLS APPL, V70, P1251, DOI 10.1007/s11042-012-1218-6
   Menard D, 2015, THESIS
   Mestyán M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071226
   Moon S, 2010, J MARKETING, V74, P108, DOI 10.1509/jmkg.74.1.108
   Phillips Andrea., 2012, A Creator's Guide To Transmedia Storytelling: How to Captivate and Engage Audiences Across Multiple Platforms
   Pratten R., 2011, GETTING STARTED TRAN
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Shmueli Erez., 2012, P 21 INT C WORLD WID, P429
   Tryon C, 2013, CONVERGENCE INT J RE, V19
   Xia F, 2013, IEEE ACCESS, V1, P606, DOI 10.1109/ACCESS.2013.2281156
NR 24
TC 10
Z9 10
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10371
EP 10388
DI 10.1007/s11042-016-3626-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400004
DA 2024-07-18
ER

PT J
AU Li, ZL
   Zhu, SA
   Hong, HW
   Li, YY
   El Saddik, A
AF Li, Zhongli
   Zhu, Shiai
   Hong, Huiwen
   Li, Yuanyuan
   El Saddik, Abdulmotaleb
TI City digital pulse: a cloud based heterogeneous data analysis platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; Cloud-based system; Social media; Data analytics; Data
   visualization
AB In recent years, increasing attention has been paid to developing exceptional technologies for efficiently processing massive collection of data. This is essential in the research on smart city, which involves various types of data generated by different kinds of sensors (hard and soft). In this paper, we propose a cloud-based platform named City Digital Pulse (CDP), where a unified mechanism and extensible architecture are provided to facilitate the various aspects in big data analysis, ranging from data acquisition to data visualization. We instantiate the proposed system using multi-model data collected from two social networks, namely Twitter and Instagram, which can provide instant geo-tagged data. Data analysis is performed to detect human affections from user uploaded content. The information revealed from the collected social data can be visualized at multiple dimensions through a well-designed Web application. This allows users to easily sense changes in human affective status and identify the underlying reasons. This offers priceless opportunities to improve the decision making in many critical tasks using the detected attitudes in the social messages, such as promotion strategy for companies or new policy making for the government. Our experiment results confirm the effectiveness of the proposed architecture and algorithms.
C1 [Li, Zhongli; Zhu, Shiai; Hong, Huiwen; Li, Yuanyuan; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Comp Res Labs MCRLab, Ottawa, ON, Canada.
C3 University of Ottawa
RP Zhu, SA (corresponding author), Univ Ottawa, Multimedia Comp Res Labs MCRLab, Ottawa, ON, Canada.
EM lzl19920403@gmail.com; zshiai@gmail.com; huiwen.hong@gmail.com;
   yuanyuanli199@gmail.com; elsaddik@uottawa.ca
RI li, yuanyuan/GZA-4435-2022; /D-4159-2009
OI /0000-0002-7690-8547
CR Agrawal R, 2015, P 7 INT C MAN COMP C, P169, DOI DOI 10.1145/2857218.2857256
   Tuán AL, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P196, DOI 10.1109/UIC-ATC.2012.165
   [Anonymous], 2014, AAAI
   [Anonymous], AAAI
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Buzzi M, 2016, MULTIMED TOOLS APPL, P1
   Castro M, 2013, INT C ADV INF NETW A
   Chen HC, 2012, MIS QUART, V36, P1165
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chen T, 2013, ACM MM
   Costa C, 2015, P WORLD C ENG
   Dave K, 2003, WWW
   Dey S, 2012, IEEE 37 C LOC COMP N
   Fan MY, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0416-y
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Hossain MS, 2015, IEEE T CIRC SYST VID, V25, P2105, DOI 10.1109/TCSVT.2015.2444731
   Hossain MS, 2016, MOBILE NETWORKS APPL
   Hromic H, 2015, ICC
   Hsu CY, 2015, INT J PROD ECON, V164, P454, DOI 10.1016/j.ijpe.2014.08.014
   Hu X., 2013, WSDM
   Hwang D, 2014, COMPUT INFORM, V33, P591
   Khan Z, 2013, INT C UT CLOUD COMP
   Lombardi P, 2012, INNOVATION-ABINGDON, V25, P137, DOI 10.1080/13511610.2012.660325
   Ma S, 2015, INT C INT SYST KNOWL
   Mell P, 2010, COMMUN ACM, V53, P50
   Mukkamala RR, 2015, IEEE INT CONGR BIG, P745, DOI 10.1109/BigDataCongress.2015.123
   Mullen T, 2004, EMNLP
   Niu T., 2016, MULTIMEDIA MODELING, P15, DOI [DOI 10.1007/978-3-319-27674-82, 10.1007/978-3-319-27674-8_2]
   Nuaimi EA, 2015, J INTERNET SERV APPL, P6
   Palmieri F, 2016, COMPUT ELECT ENG
   Pang B., 2007, INFORM RETRIEVAL, V2, P1, DOI DOI 10.1561/1500000011
   Pang Bo, 2002, EMNLP
   Plotnikova N, 2015, SEMEVAL 2015 WORKSH
   Rosenthal S, 2015, SEMEVAL 2015 WORKSH
   Saif H, 2013, ESSEM WORKSH
   Saini M, 2017, MULTIMED TOOLS APPL, V76, P11621, DOI 10.1007/s11042-015-3158-4
   Scholl HJ, 2016, SOC SCI INFORM, V55, P255, DOI 10.1177/0539018416629230
   Su K, 2011, ICECC
   Sudhof M, 2014, SIGKDD
   Taherkordi A., 2016, 2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops), P1
   Tedeschi A, 2014, 2014 INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD), P541, DOI 10.1109/FiCloud.2014.94
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   Yamamoto S, 2012, INT C CLOUD COMP TEC
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
   Zhao Yan-guo, 2014, Modular Machine Tool & Automatic Manufacturing Technique, P1, DOI 10.13462/j.cnki.mmtamt.2014.12.001
NR 48
TC 10
Z9 10
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10893
EP 10916
DI 10.1007/s11042-016-4038-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400033
DA 2024-07-18
ER

PT J
AU Pakdaman, F
   Hashemi, MR
   Ghanbari, M
AF Pakdaman, Farhad
   Hashemi, Mahmoud-Reza
   Ghanbari, Mohammad
TI Fast and efficient intra mode decision for HEVC, based on dual-tree
   complex wavelet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Complexity reduction; Intra coding; Mode decision; Complex wavelet
ID PREDICTION; REDUCTION; ALGORITHM
AB The new video coding standard, High Efficiency Video Coding (HEVC) uses up to 33 angular intra modes to achieve better coding efficiency in intra coding. While larger number of modes results in a significant increase in coding efficiency than its predecessor H.264/AVC, it leads to much more complexity. To reduce this complexity, this paper proposes a novel method based on the dual-tree complex wavelet Transform (CWT). As CWT is effectively capable of representing edges in various directions, it is used to estimate the best intra angular mode in each coding block. The encoder then only analyzes a few modes around the best estimated mode. The experimental results show that searching only six modes around the estimated mode (estimated mode +/- 3) plus DC and planar can predict the best mode in almost 80 % of the times. In fact the remaining unpredicted blocks have such unspecified behavior that even their random selections do not have any side effects. With all-intra configuration, searching with this method among the estimated mode +/- 3 and DC and planar can improve the intra frame coding time by up to 4-10 times faster and can save the total encoding time over 32 %, while causing less than 0.4 % increase in bitrate and preserving the quality.
C1 [Pakdaman, Farhad; Hashemi, Mahmoud-Reza; Ghanbari, Mohammad] Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 University of Tehran; University of Essex
RP Pakdaman, F (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
EM farhad.pakdaman@ut.ac.ir
RI Ghanbari, Mohammad/L-4053-2019; Pakdaman, Farhad/L-1457-2019; Hashemi,
   Mahmoud Reza/H-2172-2011
OI Ghanbari, Mohammad/0000-0002-5482-8378; Pakdaman,
   Farhad/0000-0001-6526-3811; Hashemi, Mahmoud Reza/0000-0002-3518-9195
CR [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Ding WP, 2014, INT C DIGITAL HOME, P70, DOI 10.1109/ICDH.2014.21
   Kang D, 2014, ELECTRON LETT, V50, P1345, DOI 10.1049/el.2014.1493
   Khan MUK, 2014, IEEE IMAGE PROC, P3681, DOI 10.1109/ICIP.2014.7025747
   Khan MUK, 2013, DES AUT TEST EUROPE, P125
   Kim I-K, 2014, JCTVCP1002 ITUTISOIE
   Kingsbury N. G., 1998, IEEE DIG SIGN PROC W, P319
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li F, 2011, IEEE IMAGE PROC, P373
   Lian CJ, 2007, IEEE CIRC SYST MAG, V7, P26, DOI 10.1109/MCAS.2007.4299440
   Moiron S, 2009, IEEE T CONSUM ELECTR, V55, P606, DOI 10.1109/TCE.2009.5174429
   Ozcan E, 2014, IEEE T CONSUM ELECTR, V60, P745, DOI 10.1109/TCE.2014.7027351
   Romberg JK, 2001, IEEE IMAGE PROC, P614, DOI 10.1109/ICIP.2001.959120
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
NR 19
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9891
EP 9906
DI 10.1007/s11042-016-3584-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300035
DA 2024-07-18
ER

PT J
AU Hua, W
   Liao, XF
AF Hua, Wei
   Liao, Xiaofeng
TI A secret image sharing scheme based on piecewise linear chaotic map and
   Chinese remainder theorem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Piecewise linear map; Chinese remainder theorem (CRT); Compression
   coding scheme; Sharing scheme
ID ENCRYPTION
AB In this paper, a secret image sharing scheme, by combining arithmetic compression coding and Chinese remainder theorem (CRT) is proposed. It is well known that arithmetic compression coding method for image has a good compressibility, and it can reduce the size of the shadow image, which consists of sharing values. Usually, a smaller shadow image is convenient to store and transmit. The piecewise linear map is applied to design compression coding scheme, which has the same properties as the conventional arithmetic compression coding. The CRT is used to construct the sharing scheme for compression codes. Meanwhile, it also has encryption effects in the process of sharing. Finally, the security and the effectiveness of the secret image sharing scheme are confirmed by some computer simulation results.
C1 [Hua, Wei; Liao, Xiaofeng] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM xfliao@swu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Natural Science Foundation of China [61472331]; Talents of
   Science and Technology Promote Plan; Chongqing Science & Technology
   Commission
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61472331, in part by the Talents of
   Science and Technology Promote Plan, Chongqing Science & Technology
   Commission.
CR Bao L, 2014, IEEE SYS MAN CYBERN, P3209, DOI 10.1109/SMC.2014.6974422
   Bose R, 2006, IEEE T CIRCUITS-I, V53, P848, DOI 10.1109/TCSI.2005.859617
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chien MC, 2012, IEEE INT C IM SIGN P
   Duan LL, 2011, COMMUN NONLINEAR SCI, V16, P2554, DOI 10.1016/j.cnsns.2010.09.012
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Harn L, 2010, INFORM SCIENCES, V180, P3059, DOI 10.1016/j.ins.2010.04.016
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Iftene S., 2005, Sci. Ann. Cuza Univ, V15, P161
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Lin QZ, 2013, J SYST SOFTWARE, V86, P1384, DOI 10.1016/j.jss.2013.01.012
   Luca MB, 2004, P IEEE COMM C BUCH R
   Mi B, 2008, CHAOS SOLITON FRACT, V38, P1523, DOI 10.1016/j.chaos.2007.01.133
   Nagaraj N, 2009, COMMUN NONLINEAR SCI, V14, P1013, DOI 10.1016/j.cnsns.2007.12.001
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Rao G. R., 2012, INT J NETWORK SECURI, V4, P111, DOI 10.5121/ijnsa.2012.4307
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sharma S, 2013, INT J COMPUTER SCI M, V2, P263
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Shyu SJ, 2008, IEEE AS PAC SERV COM
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wong KW, 2010, IEEE T CIRCUITS-II, V57, P146, DOI 10.1109/TCSII.2010.2040315
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
NR 28
TC 12
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7087
EP 7103
DI 10.1007/s11042-016-3364-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400043
DA 2024-07-18
ER

PT J
AU Lacheheb, H
   Aouat, S
AF Lacheheb, Hadjer
   Aouat, Saliha
TI SIMIR: New mean SIFT color multi-clustering image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; SIFT; Mean SIFT; HSV; Multi-clustering
ID FEATURES
AB Content based image retrieval systems (CBIR) are used to search images on the basis of their visual content in a huge image database. This approach uses a multiclustering technique with a multi-searching process. In addition it integrate, Mean SIFT (Scale Invariant Feature Transform) descriptor as local feature and HSV(hue, saturation, value) histogram as global feature. Our proposition aims to a maximum separation of the execution to gain time and keep the performance of each descriptor. Local and global features are combined for more relevant results. Getting several views to relevant results to cover the subjectivity in displaying results. This article, detailed our proposed method with a comparison with the FIRE (Flexible Image Retrieval) Engine and LIRE (Lucene Image Retrieval). The results demonstrate the feasibility and relevance of our proposition.
C1 [Lacheheb, Hadjer; Aouat, Saliha] USTHB Univ, Dept Comp Sci, LRIA Lab, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Lacheheb, H (corresponding author), USTHB Univ, Dept Comp Sci, LRIA Lab, Algiers, Algeria.
EM hlacheheb@usthb.dz; saouat@usthb.dz
OI LACHEHEB, Hadjer/0000-0001-9723-1910; AOUAT, Saliha/0000-0002-4022-9075
CR [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 260 SWISS FED I TECH
   [Anonymous], 2011, P 19 ACM INT C MULT
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Borde S., 2012, INT J COMPUT APPL, V60, P20
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   Deselaers T, 2004, LECT NOTES COMPUT SC, V3175, P228
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dorko G, 2006, THESIS
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jagadish H. V., 1991, SIGMOD Record, V20, P208, DOI 10.1145/119995.115821
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mller H, 2000, PERFORMANCE EVALUATI
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Nguyen DA, 2010, LECT NOTES ARTIF INT, V5990, P294
   Niblack W, 1998, RETRIEVAL IMAGE VI 4, P150
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Subramanya SR, 2002, FIRST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, PROCEEDINGS, P168, DOI 10.1109/CW.2002.1180876
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan P. N., 2016, INTRO DATA MINING
   Torres RDS, REV INFORM TERICA AP, V13, P161
   Veltkamp R. C., 1999, TECH REP
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   YANG L, 1994, INT C PATT RECOG, P201, DOI 10.1109/ICPR.1994.576257
   Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang Dengsheng., 2004, Review of shape representation and description techniques
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
NR 42
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6333
EP 6354
DI 10.1007/s11042-015-3167-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400013
DA 2024-07-18
ER

PT J
AU Sirin, Y
   Demirci, MF
AF Sirin, Yahya
   Demirci, M. Fatih
TI 2D and 3D shape retrieval using skeleton filling rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape recognition; Shape retrieval; Earth mover's distance; 2D and 3D
   skeleton
ID RECOGNITION; CLASSIFICATION; REPRESENTATION; INVARIANT; DESCRIPTOR;
   SCALE; DISTANCE; FEATURES
AB As an increasing number of digital images are generated, a demand for an efficient and effective image retrieval mechanisms grows. In this work, we present a new skeleton-based algorithm for 2D and 3D shape retrieval. The algorithm starts by drawing circles (spheres for 3D) of increasing radius around skeletons. Since each skeleton corresponds to the center of a maximally inscribed circle (sphere), this process results in circles (spheres) that are partially inside the shape. Computing the ratio between pixels that lie within the shape and the total number of pixels allows us to distinguish shapes with similar skeletons. Experimental evaluation of the proposed approach including a comprehensive comparison with the previous techniques demonstrates both effectiveness and robustness of our algorithm for shape retrieval using several 2D and 3D datasets.
C1 [Sirin, Yahya; Demirci, M. Fatih] TOBB Univ Econ & Technol, Dept Comp Engn, TR-06560 Ankara, Turkey.
C3 TOBB Ekonomi ve Teknoloji University
RP Demirci, MF (corresponding author), TOBB Univ Econ & Technol, Dept Comp Engn, TR-06560 Ankara, Turkey.
EM ysirin@etu.edu.tr; mfdemirci@etu.edu.tr
OI , Fatih/0000-0003-1552-0087
CR Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   Akimaliev M, 2015, PATTERN RECOGN, V48, P3504, DOI 10.1016/j.patcog.2015.05.010
   An Guocheng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P507, DOI 10.1109/ICPR.2010.129
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], COMPUTATIONAL IMAGIN
   [Anonymous], 2013, ICCV
   [Anonymous], P SCCG BRAT SLOV
   [Anonymous], 2009, P ACM INT C IM VID R, DOI DOI 10.1145/1646396.1646430
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Axenopoulos A, 2011, ICMR, P41, DOI [10.1145/1991996.1992037, DOI 10.1145/1991996.1992037]
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Ben-Chen M., 2008, Proceedings of the 1st Eurographics Conference on 3D Object Retrieval, P1
   Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4
   Bustos B, 2012, MULTIMED TOOLS APPL, V58, P81, DOI 10.1007/s11042-010-0689-6
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   CHELLAPPA R, 1984, IEEE T PATTERN ANAL, V6, P102, DOI 10.1109/TPAMI.1984.4767482
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Demirci MF, 2011, COMPUT VIS IMAGE UND, V115, P976, DOI 10.1016/j.cviu.2010.12.012
   Demirci MF, 2009, J MATH IMAGING VIS, V35, P103, DOI 10.1007/s10851-009-0157-y
   Demirci MF, 2003, LECT NOTES COMPUT SC, V2695, P17
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Ebrahim Y, 2009, PATTERN RECOGN LETT, V30, P348, DOI 10.1016/j.patrec.2008.09.013
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Frejlichowski D, 2011, LECT NOTES COMPUT SC, V6688, P457, DOI 10.1007/978-3-642-21227-7_43
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Hu RX, 2012, PATTERN RECOGN, V45, P3222, DOI 10.1016/j.patcog.2012.02.020
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Iyer N., 2003, ASME 2003 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, P89
   Kang S. B., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P580, DOI 10.1109/CVPR.1991.139757
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Kawamura S., 2012, 5 EUR WORKSH 3D OBJ, P55
   Kazhdan M.M., 2003, S GEOM PROC, V6
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Kuang ZZ, 2015, COMPUT AIDED DESIGN, V58, P13, DOI 10.1016/j.cad.2014.08.004
   Laiche N, 2014, SIGNAL PROCESS-IMAGE, V29, P556, DOI 10.1016/j.image.2014.01.009
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li SS, 2013, INT C WAVEL ANAL PAT, P62, DOI 10.1109/ICWAPR.2013.6599293
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Lian ZH, 2010, INT J COMPUT VISION, V89, P130, DOI 10.1007/s11263-009-0295-0
   LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2005, PROC CVPR IEEE, P719
   Lou K., 2003, ASME 2003 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, P169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Nanni L, 2012, PATTERN RECOGN LETT, V33, P2254, DOI 10.1016/j.patrec.2012.07.007
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Ohishi Y, 2013, 2013 14 INT WORKSH I, P1
   Ohkita Y, 2012, IEEE INT CONF MULTI, P593, DOI 10.1109/ICMEW.2012.109
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Papadakis P, 2008, EUR WORKSH 3 OBJ RET
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Pedrosa GV, 2013, NEUROCOMPUTING, V120, P156, DOI 10.1016/j.neucom.2012.07.055
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   RAUBER TW, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P466, DOI 10.1109/ICPR.1992.201819
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Ruggeri MR, 2010, INT J COMPUT VISION, V89, P248, DOI 10.1007/s11263-009-0250-0
   Schreck T., 2012, P 3 ACM MULT SYST C, P23
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496
   Shekar BH, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P46, DOI 10.1145/2708463.2709062
   Shekar BH, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P218, DOI 10.1109/ICSIP.2014.41
   Shen W, 2011, PATTERN RECOGN, V44, P196, DOI 10.1016/j.patcog.2010.08.021
   Shen Y-T, 2003, EUROGRAPHICS
   Shih JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI 10.1007/s11042-008-0256-6
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Sipiran I, 2013, COMPUT GRAPH-UK, V37, P460, DOI 10.1016/j.cag.2013.04.002
   Sirin Y, 2014, INT C PATT RECOG, P4005, DOI 10.1109/ICPR.2014.686
   Soderkvist O., 2001, COMPUTER VISION CLAS
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tyng-Luh Liu, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P456, DOI 10.1109/ICCV.1999.791256
   van der Zwan Matthew, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P285
   Van Otterloo P. J., 1991, CONTOUR ORIENTED APP
   Vranic DV, 2005, IEEE INT C MULT EXP, P4
   Wang F, 2012, LECT NOTES COMPUT SC, V7572, P442, DOI 10.1007/978-3-642-33718-5_32
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wu JN, 2008, PROC CVPR IEEE, P2221
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Xu J, 2012, VLDB J, V21, P535, DOI 10.1007/s00778-011-0258-2
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 101
TC 10
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7823
EP 7848
DI 10.1007/s11042-016-3422-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800011
DA 2024-07-18
ER

PT J
AU Lam, V
   Phan, S
   Le, DD
   Duong, DA
   Satoh, S
AF Vu Lam
   Phan, Sang
   Le, Duy-Dinh
   Duc Anh Duong
   Satoh, Shin'ichi
TI Evaluation of multiple features for violent scenes detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Violent scenes detection; Video retrieval; Multi-modal fusion; Multiple
   features
ID EVENT; FUSION
AB Violent scenes detection (VSD) is a challenging problem because of the heterogeneous content, large variations in video quality, and complex semantic meanings of the concepts involved. In the last few years, combining multiple features from multi-modalities has proven to be an effective strategy for general multimedia event detection (MED), but the specific event detection like VSD has been comparatively less studied. Here, we evaluated the use of multiple features and their combination in a violent scenes detection system. We rigorously analyzed a set of low-level features and a deep learning feature that captures the appearance, color, texture, motion and audio in video. We also evaluated the utility of mid-level visual information obtained from detecting related violent concepts. Experiments were performed on the publicly available MediaEval VSD 2014 dataset. The results showed that visual and motion features are better than audio features. Moreover, the performance of the mid-level features was nearly as good as that of the low-level visual features. Experiments with a number of fusion methods showed that all single features are complementary and help to improve overall performance. This study also provides an empirical foundation for selecting feature sets that are capable of dealing with heterogeneous content comprising violent scenes in movies.
C1 [Vu Lam] Univ Sci, VNU HCMC, 227 Nguyen Van Cu,Dist 5, Ho Chi Minh, Vietnam.
   [Phan, Sang; Le, Duy-Dinh; Satoh, Shin'ichi] Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
   [Duc Anh Duong] Univ Informat Technol, VNU HCMC, Linh Trung Ward, Quarter 6, Thu Duc Dist, Ho Chi Minh, Vietnam.
C3 Vietnam National University Hochiminh City; Research Organization of
   Information & Systems (ROIS); National Institute of Informatics (NII) -
   Japan; Vietnam National University Hochiminh City
RP Lam, V (corresponding author), Univ Sci, VNU HCMC, 227 Nguyen Van Cu,Dist 5, Ho Chi Minh, Vietnam.
EM lqvu@fit.hcmus.edu.vn; plsang@nii.ac.jp; ledduy@nii.ac.jp;
   ducda@uit.edu.vn; satoh@nii.ac.jp
FU Vietnam National University Ho Chi Minh City (VNUHCM) [B2013-26-01];
   Grants-in-Aid for Scientific Research [26240016] Funding Source: KAKEN
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNUHCM) under grant number B2013-26-01.
CR Acar E, 2014, TUB IRML MEDIAEVAL 2
   Aly Robin., 2013, The axes submissions at trecvid 2013
   [Anonymous], MEDIAEVAL 2013 WORKI
   [Anonymous], FUDAN NJUST MEDIAEVA
   [Anonymous], 2015, J INF HIDING MULTIME
   [Anonymous], 2013, MEDIAEVAL
   [Anonymous], J INFORM HIDING MULT
   [Anonymous], TRECVID
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2013, P 3 ACM C INT C MULT, DOI DOI 10.1145/2461466.2461502
   [Anonymous], 2010, WHY WATCHING IT IS H
   Avila S, 2014, RECOD MEDIAEVAL 2014
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Castan D, 2014, VIVOLAB CVLAB MEDIAE
   Cdric P, 2011, MEDIAEVAL MULT BENCH
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155
   Clarin C., 2005, PCSC, V6, P150
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dai Q., 2013, MediaEval
   de Magalhaes C.V. C., 2014, International Conference on Evaluation and Assessment in Software Engineering, P1, DOI 10.1109/CBMI.2014.6849827
   Demarty CH, 2014, MULTIMED TOOLS APPL, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   do Nascimento Teixeira B, 2014, MTM MEDIAEVAL 2014 V
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Gong Y, 2008, LECT NOTES COMPUT SC, V5353, P317, DOI 10.1007/978-3-540-89796-5_33
   Harris Z.S., 1954, WORD
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai PS, 2005, LECT NOTES ARTIF INT, V3682, P1238
   Lam V, 2014, NII UIT MEDIAEVAL 20
   Lam V, 2012, MEDIAEVAL CITESEER
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li L.-j., 2010, NIPS
   Liang-Hua Chen, 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P119, DOI 10.1109/CGIV.2011.14
   Lin JA, 2009, LECT NOTES COMPUT SC, V5879, P930
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Myers GK, 2014, MACH VISION APPL, V25, P17, DOI 10.1007/s00138-013-0527-8
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Oh S, 2014, MACH VISION APPL, V25, P49, DOI 10.1007/s00138-013-0525-x
   Oneata D., 2014, The lear submission at thumos
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Sjoberg M, 2013, MEDIAEVAL
   Sjoberg M, 2014, FAR MEDIAEVAL 2014 V
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Sun C, 2013, IEEE WORK APP COMP, P15, DOI 10.1109/WACV.2013.6474994
   Tan ChunChet., 2013, MediaEval
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Zhang B, 2014, MIC TJU MEDIAEVAL VI
NR 63
TC 12
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7041
EP 7065
DI 10.1007/s11042-016-3331-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400041
DA 2024-07-18
ER

PT J
AU Chriskos, P
   Zoidi, O
   Tefas, A
   Pitas, I
AF Chriskos, P.
   Zoidi, O.
   Tefas, A.
   Pitas, I.
TI De-identifying facial images using singular value decomposition and
   projections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face de-idenification; Privacy protection; Singular value decomposition;
   Projections on hyperspheres
AB In this paper, two methods are presented that manipulate images to hinder automatic face identification. They partly degrade image quality, so that humans can identify the persons in a scene, while face identification algorithms fail to do so. The approaches used involve: a) singular value decomposition (SVD) and b) image projections on hyperspheres. Simulation experiments verify that these methods reduce the percentage of correct face identification rate by over 90 %. Additionally, the final image is not degraded beyond recognition by humans, in contrast with the majority of other de-identification methods.
C1 [Chriskos, P.; Zoidi, O.; Tefas, A.; Pitas, I.] Aristotle Univ Thessloniki, Dept Informat, Thessaloniki 54124, Greece.
   [Pitas, I.] Univ Bristol, Dept Elect & Elect Engn, Bristol, Avon, England.
C3 Aristotle University of Thessaloniki; University of Bristol
RP Chriskos, P (corresponding author), Aristotle Univ Thessloniki, Dept Informat, Thessaloniki 54124, Greece.
EM pchriskos@gmail.com
RI Chriskos, Panteleimon/AAQ-9275-2020; Tefas, Anastasios/ABA-2328-2020;
   Tefas, Anastasios/F-1899-2010
OI Chriskos, Panteleimon/0000-0003-1002-2417; Tefas,
   Anastasios/0000-0003-1288-3667
FU COST, Action [IC1206]; European Union [287674, 316564]
FX The research leading to these results has received funding from COST,
   Action IC1206, and the European Union Seventh Framework Programme
   (FP7/20072013) under grant agreement numbers 287674 (3DTVS) and 316564
   (IMPART). This publication reflects only the authors views. The European
   Union is not liable for any use that may be made of the information
   contained therein.
CR Agrawal PR, 2005, IEEE T CIRCUITS SYST, V21, P299
   [Anonymous], 2002, IEEE INT C AUT FAC G
   [Anonymous], 2008, P 2008 IEEE C COMP V
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Boyd S, 2004, CONVEX OPTIMIZATION, V244
   Driessen B, 2013, CRYPTOLOGY EPRINT AR
   Du L., 2014, P IEEE INT JOINT C B, P1
   Georghiades A, 2001, PAMI
   Golub GH, 2012, MATRIX COMPUTATIONS, P76
   Gross R., 2009, Protecting privacy in video surveillance, P129
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Iosifidis A, 2013, IEEE INT WORKSH BIOM
   Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096
   Letournel G, 2015, IEEE INT C IM PROC I
   Meng L, 2014, 37 INT C INF COMM TE
   Messer K., 1999, P 2 C AUD VID BAS BI
   Mosaddegh S, P AS C COMP VIS, P1
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Phillips PJ, 2013, AUDIO VIDEO BASED BI, P869
   Pitas I., 2000, DIGITAL IMAGE PROCES
   Singular Value Decomposition (SVD) Department of Computer Science & Engineering University of Nevada, CS4791Y DEP COMP SCI
   Sommerville DMY, 1958, INTR GEOM DIM
   Stamou G, 2005, P VIS COMM IM PROC V, P12
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Tansuriyavong S., 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, P1, DOI DOI 10.1145/971478.971519
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Theodoridis S, 2011, IEEE SIGNAL PROC MAG, V28, P97, DOI 10.1109/MSP.2010.938752
   Weisstein EW, 2014, HYPERSPHERE MATHWORL
   Zoidi O, 2013, IEEE S SER COMP INT, P16
   Zongji S, 2015, 11 IEEE INT C WORKSH, V4
NR 30
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3435
EP 3468
DI 10.1007/s11042-016-4069-8
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200014
DA 2024-07-18
ER

PT J
AU De Marsico, M
   Marchionni, L
   Novelli, A
   Oertel, M
AF De Marsico, Maria
   Marchionni, Luca
   Novelli, Andrea
   Oertel, Michael
TI FATCHA: biometrics lends tools for CAPTCHAs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Interactive Proofs; CAPTCHA; BOT; Usability; Accessibility;
   Multimodal interaction; Denial of service; Human face detection
ID RECOGNITION
AB This paper presents a novel strategy to implement a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart). The aim of these tests is to easily and reliably distinguish between real human users and (malicious) bots. The approach underlying FATCHA is to exploit real time capture of human actions instead of human ability to recognize visual or auditory items. The latter approach explicitly requires proposing a challenge difficult for an automatic responder but easy for a human. However, it is often the case that pursuing the first feature takes to lose the second one. Moreover the user task may be hindered by specific disabilities. According to FATCHA approach the system rather asks the user to carry out some trivial gesture, e.g., rotating or moving the head. The webcam, which is available in almost all computers or mobile devices, captures the user gesture, and the server (hosting the service to protect) matches it with the requested one. It is possible to extend the service with a second module that allows the user to authenticate himself by face recognition instead of using a password. On the contrary, FATCHA gesture challenge can be used as a liveliness test to avoid biometric spoofing. Multimodal interaction is the base for both an advanced Human Interactive Proof (HIP) test and for robust/comfortable authentication.
C1 [De Marsico, Maria; Marchionni, Luca; Novelli, Andrea; Oertel, Michael] Sapienza Univ Rome, Via Salaria 113, I-00198 Rome, Italy.
C3 Sapienza University Rome
RP De Marsico, M (corresponding author), Sapienza Univ Rome, Via Salaria 113, I-00198 Rome, Italy.
EM demarsico@di.uniroma1.it; luca.marchionni89@gmail.com;
   andreanovelli91@gmail.com; oertel.michael90@gmail.com
RI De Marsico, Maria/K-6684-2015
OI De Marsico, Maria/0000-0002-1391-8502
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Almazyad A.S., 2011, P ICISA 11 INT C INF, P1, DOI DOI 10.1109/ICISA.2011.5772421
   [Anonymous], 2010, GOOD ARE HUMANS SOLV
   [Anonymous], 2009, UNIVERSAL ACCESS HDB
   [Anonymous], INACCESSIBI IN PRESS
   [Anonymous], WEB ACC IN CAPTCH AL
   [Anonymous], 2015, 11 BIANN C IT SIGCHI
   Bianchini C. S., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P526, DOI 10.1109/ICALT.2012.235
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Bushell D., 2011, In Search Of The Perfect CAPTCHA: Smashing Coding
   Datta R., 2005, 13th Annual ACM International Conference on Multimedia, P331, DOI 10.1145/1101149.1101218
   Freire Andre, 2012, CHI 12, P433, DOI DOI 10.1145/2207676.2207736
   Gossweiler R., 2009, P 18 INT C WORLD WID, P841, DOI DOI 10.1145/1526709.1526822
   Goswami G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P412, DOI 10.1109/BTAS.2012.6374608
   Hernandez- Castro CJ, 2010, P 2010 INT C SECURIT, P1
   Misra D., 2006, P AICT ICIW 06 ADV I, P122
   Mori G, 2003, PROC CVPR IEEE, P134
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Poh N, 2016, IET BIOMETRICS, V5, P20, DOI 10.1049/iet-bmt.2015.0016
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Roshanbin N, 2013, J WEB ENG, V12, P1
   Rui Y, 2004, MULTIMEDIA SYST, V9, P493, DOI 10.1007/s00530-003-0122-3
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Shirali-Shahreza M., 2008, 2008 Conference on Human System Interactions, P1042, DOI 10.1109/HSI.2008.4581589
   Shirali-Shahreza Mohammad, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P995, DOI 10.1109/ISSPIT.2007.4458048
   Shirali-Shahreza MH, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P675
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
NR 29
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5117
EP 5140
DI 10.1007/s11042-016-3518-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500020
DA 2024-07-18
ER

PT J
AU Fei, MJ
   Ju, ZJ
   Zhen, XT
   Li, J
AF Fei, Mengjuan
   Ju, Zhaojie
   Zhen, Xiantong
   Li, Jing
TI Real-time visual tracking based on improved perceptual hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Perceptual hashing; AHash; PHash; DHash
ID INTELLIGENT SUPERVISION; TARGET TRACKING; NAVIGATION; FEATURES
AB Video object tracking represents a very important computer vision domain. In this paper, a perceptual hashing based template-matching method for object tracking is proposed to efficiently track objects in challenging video sequences. In the tracking process, we first apply three existing basic perceptual hashing techniques to visual tracking, namely average hash (aHash), perceptive hash (pHash) and difference hash (dHash). Compared with previous tracking methods such as mean-shift or compressive tracking (CT), perceptual hashing-based tracking outperforms in terms of efficiency and accuracy. In order to further improve the accuracy of object localization and the robustness of tracking, we propose Laplace-based Hash (LHash) and Laplace-based Difference Hash (LDHash). By qualitative and quantitative comparison with some representative tracking algorithms, experimental results show that our improved perceptual hashing-based tracking algorithms perform favorably against the state-of-the-art algorithms under various challenging environments in terms of time cost, accuracy and robustness. Since our improved perceptual hashing can be a compact and efficient representation of objects, it can be further applied to fusing with depth information for more robust RGB-D video tracking.
C1 [Fei, Mengjuan] Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Peoples R China.
   [Ju, Zhaojie] Univ Portsmouth, Sch Comp, Intelligent Syst & Biomed Robot Grp, Portsmouth PO1 3HE, Hants, England.
   [Zhen, Xiantong] Univ Western Ontario, London, ON, Canada.
   [Li, Jing] Nanchang Univ, Sch Informat Engn, Lab Ubiquitous Vis Percept & Intelligent Comp, Nanchang 330031, Jiangxi, Peoples R China.
C3 Zhejiang University; University of Portsmouth; Western University
   (University of Western Ontario); Nanchang University
RP Li, J (corresponding author), Nanchang Univ, Sch Informat Engn, Lab Ubiquitous Vis Percept & Intelligent Comp, Nanchang 330031, Jiangxi, Peoples R China.
EM jingli@ncu.edu.cn
RI Ju, Zhaojie/AAA-5872-2019
OI Ju, Zhaojie/0000-0002-9524-7609
FU National Natural Science Foundation of China [61463032, 61563035,
   81501560]; Scientific Research Foundation for Returned Scholars,
   Ministry of Education of China
FX This work is supported by National Natural Science Foundation of China
   (61463032, 61563035, and 81501560) and Scientific Research Foundation
   for Returned Scholars, Ministry of Education of China.
CR Altinok A., 2006, COMPUTER VISION PATT, V2, P1662
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 1994, Mathematica Journal, DOI DOI 10.1016/0165-1684(90
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bhattacharjee S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P435, DOI 10.1109/ICIP.1998.723518
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bradski G., 2008, LEARNING OPENCV
   Bulling A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI 10.1109/TPAMI.2010.86
   Bulling A, 2010, IEEE PERVAS COMPUT, V9, P8, DOI 10.1109/MPRV.2010.86
   Cesetti A, 2010, J INTELL ROBOT SYST, V57, P233, DOI 10.1007/s10846-009-9373-3
   Chen JYC, 2010, ERGONOMICS, V53, P940, DOI 10.1080/00140139.2010.500404
   Chen N, 2011, IET INFORM SECUR, V5, P19, DOI 10.1049/iet-ifs.2010.0097
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Coskun B, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P292, DOI 10.1109/SIU.2004.1338317
   Jia Z, 2008, ALGORITHMS, V1, P153, DOI 10.3390/a1020153
   Jie Z, 2013, ARXIV13064079
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Karavasilis V, 2011, IMAGE VISION COMPUT, V29, P295, DOI 10.1016/j.imavis.2010.12.002
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Laradji IH, 2013, IEEE IMAGE PROC, P4402, DOI 10.1109/ICIP.2013.6738907
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313
   Liu L., 2013, 23 INT JOINT C ART I
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Micalizio R, 2011, LECT NOTES ARTIF INT, V6934, P151, DOI 10.1007/978-3-642-23954-0_16
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   NARASIMHA MJ, 1978, IEEE T COMMUN, V26, P934, DOI 10.1109/TCOM.1978.1094144
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   PERNG MH, 1993, IEE PROC-D, V140, P405, DOI 10.1049/ip-d.1993.0053
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang PK, 2012, INT SOC OPTICS PHOTO
   Weng L, 2009, IEEE INT CON MULTI, P1074, DOI 10.1109/ICME.2009.5202684
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoon Y, 2014, INT C PATT RECOG, P2227, DOI 10.1109/ICPR.2014.387
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Zhang B, 2016, IEEE TCSVT
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang P., 2005, J ASS INFORM SYSTEMS, V6, P227
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 48
TC 13
Z9 13
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4617
EP 4634
DI 10.1007/s11042-016-3723-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200069
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kwon, HS
   Hahn, CH
   Kim, DY
   Hur, J
AF Kwon, Hyunsoo
   Hahn, Changhee
   Kim, Daeyoung
   Hur, Junbeom
TI Secure deduplication for multimedia data with user revocation in cloud
   storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Deduplication; User revocation; Cloud computing;
   Access control
AB Increment of multimedia data motivates users to utilize cloud storage (CS) to exploit its massive size. For this extensible storage system, there are two desirable requirements: (1) the users should be able to ensure that their outsourced data is securely protected and (2) the cloud service provider should be able to eliminate redundant copies of data for improvement of storage utilization. Conventional encryption scheme does not satisfy the deduplication on ciphertext as it destroys message equality. Recent study, DupLESS, has enhanced Convergent Encryption (CE) and provided strong privacy. However, CE-based scheme allows the users to possibly decrypt cloud data even if the user loses his ownership to the data. In order to solve this problem, we propose a secure deduplication scheme with user revocation. Our scheme leveages oblivious pseudo-random function to generate encryption key. The CS enforces data access policy using privilege-based encryption to provide user revocation. The security analysis proves that the proposed scheme is secure against unauthorized decryption by revoked users or the cloud server, and brute-force attack on predictable set of data.
C1 [Kwon, Hyunsoo; Hahn, Changhee; Kim, Daeyoung] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Hur, Junbeom] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University; Korea University
RP Hur, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM khs910504@cau.ac.kr; Mckinsey@cau.ac.kr; rlaeod@cau.ac.kr;
   jbhur@korea.ac.kr
RI Hahn, Changhee/HTR-0677-2023
OI Hahn, Changhee/0000-0003-4334-0411
FU National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [2013R1A2A2A01005559]; Chung-Ang University
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP) (No.
   2013R1A2A2A01005559). This research was also supported by the Chung-Ang
   University Excellent Student Scholarship.
CR Abadi M, 2013, LECT NOTES COMPUT SC, V8042, P374, DOI 10.1007/978-3-642-40041-4_21
   Bellare M, 2003, J CRYPTOL, V16, P185, DOI 10.1007/s00145-002-0120-1
   Bellare M, 2013, 22 USENIX SEC S USEN, P179
   Bellare M, 2013, LECT NOTES COMPUT SC, V7881, P296, DOI 10.1007/978-3-642-38348-9_18
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Bolosky WJ, 2000, PERF E R SI, V28, P34, DOI 10.1145/345063.339345
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Clements A.T., 2009, P 2009 C USENIX ANN, P8
   De Santis A, 1999, IEEE T INFORM THEORY, V45, P1720, DOI 10.1109/18.771255
   Douceur JR, 2002, INT CON DISTR COMP S, P617, DOI 10.1109/ICDCS.2002.1022312
   Fiat A., 1993, LECT NOTES COMPUTER, P480, DOI DOI 10.1007/3-540-48329-2
   Goyal V., 2006, P 2006 INT C PRIVACY, P1
   Halevi S, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P491, DOI 10.1145/2046707.2046765
   Intel IT Center, 2014, PLANN GUID GETT STAR
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Russell A, 2002, LECT NOTES COMPUT SC, V2332, P133
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
NR 18
TC 17
Z9 17
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5889
EP 5903
DI 10.1007/s11042-015-2595-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500054
DA 2024-07-18
ER

PT J
AU Marra, F
   Poggi, G
   Sansone, C
   Verdoliva, L
AF Marra, Francesco
   Poggi, Giovanni
   Sansone, Carlo
   Verdoliva, Luisa
TI A study of co-occurrence based local features for camera model
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera model identification; Local features; Residuals; Co-occurrences
ID STEGANALYSIS
AB Camera model identification has great relevance for many forensic applications, and is receiving growing attention in the literature. Virtually all techniques rely on the traces left in the image by the long sequence of in-camera processes which are specific of each model. They differ in the prior assumptions, if any, and in how such evidence is gathered in expressive features. In this work we study a class of blind features, based on the analysis of the image residuals of all color bands. They are extracted locally, based on co-occurrence matrices of selected neighbors, and then used to train a classifier. A number of experiments are carried out on the well-known Dresden Image Database. Besides the full-knowledge case, where all models of interest are known in advance, other scenarios with more limited knowledge and partially corrupted images are also investigated. Experimental results show these features to provide a state-of-the-art performance.
C1 [Marra, Francesco] Univ Naples Federico II, Informat Technol & Elect Engn, Naples, Italy.
   [Poggi, Giovanni; Verdoliva, Luisa] Univ Naples Federico II, Telecommun, Dept Elect Engn & Informat Technol, Naples, Italy.
   [Sansone, Carlo] Univ Naples Federico II, Comp Sci, Dept Elect Engn & Informat Technol, Naples, Italy.
C3 University of Naples Federico II; University of Naples Federico II;
   University of Naples Federico II
RP Poggi, G (corresponding author), Univ Naples Federico II, Telecommun, Dept Elect Engn & Informat Technol, Naples, Italy.
EM poggi@unina.it
RI Marra, Francesco/KUF-2496-2024; Sansone, Carlo/AGZ-8858-2022
OI Marra, Francesco/0000-0002-7863-2230
FU Italian Ministry of Education, University and Research (MIUR)
   [PAC02L1_00050 AETERNUUM]
FX This work was partially funded by the Italian Ministry of Education,
   University and Research (MIUR) within the framework of the project
   PAC02L1_00050 AETERNUUM.
CR Amerini I, 2015, IET IMAGE PROCESS, V9, P329, DOI 10.1049/iet-ipr.2014.0316
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], SPIE
   [Anonymous], INT C POW CONTR EMB
   [Anonymous], 2010, J DIGITAL FORENSIC P
   [Anonymous], SPIE
   [Anonymous], 6 IEEE INT WORKSH IN
   [Anonymous], INT WORKSH DIG FOR W
   [Anonymous], MULTI TOOLS APPL
   [Anonymous], HDB DIGITAL FORENSIC
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Bayram S., 2006, ADV DIGITAL FORENSIC, P289
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Çeliktutan O, 2008, IEEE T INF FOREN SEC, V3, P553, DOI 10.1109/TIFS.2008.926993
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cheng CQ, 2015, INT ARCH PHOTOGRAMM, V47, P1, DOI 10.5194/isprsarchives-XL-7-W4-1-2015
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Chierchia Giovanni., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security, and intelligence, MiFor '10, P117, DOI DOI 10.1145/1877972.1878002
   Cogranne R, 2015, IEEE T INF FOREN SEC, V10, P2627, DOI 10.1109/TIFS.2015.2470220
   Costa FD, 2014, PATTERN RECOGN LETT, V39, P92, DOI 10.1016/j.patrec.2013.09.006
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fan N, 2006, TENCON, P1
   Filler Tomas, 2008, 2008 15th IEEE International Conference on Image Processing - ICIP 2008, P1296, DOI 10.1109/ICIP.2008.4712000
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gloe Thomas, 2012, Transactions on Data Hiding and Multimedia Security VIII. Pattern Recognition for IT Security, P42, DOI 10.1007/978-3-642-31971-6_3
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Guanshuo Xu, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P392, DOI 10.1109/ICME.2012.87
   Huang YG, 2015, IEEE T INF FOREN SEC, V10, P2692, DOI 10.1109/TIFS.2015.2474836
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Marra F, 2015, LECT NOTES COMPUT SC, V9281, P11, DOI 10.1007/978-3-319-23222-5_2
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Razzazi F, 2014, IEEE INT SYMP SIGNAL, P462, DOI 10.1109/ISSPIT.2014.7300633
   Shi YQ, 2008, LECT NOTES COMPUT SC, V5041, P158
   Swaminathan A, 2007, IEEE T INF FOREN SEC, V2, P91, DOI 10.1109/TIFS.2006.890307
   Thai TH, 2015, DIGIT SIGNAL PROCESS, V40, P88, DOI 10.1016/j.dsp.2015.01.002
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P250, DOI 10.1109/TIP.2013.2290596
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Xu GS, 2009, LECT NOTES COMPUT SC, V5703, P294, DOI 10.1007/978-3-642-03688-0_26
NR 49
TC 26
Z9 28
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4765
EP 4781
DI 10.1007/s11042-016-3663-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500006
DA 2024-07-18
ER

PT J
AU Marti, P
   Iacono, I
AF Marti, Patrizia
   Iacono, Iolanda
TI Experience over time: evaluating the experience of use of a squeezable
   interface in the medium term
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Squeezable interface; Tangible interaction; User experience evaluation;
   Interaction design; Input/output devices; Longitudinal study; Short-term
   evaluation
AB The paper presents the user experience evaluation of Squeeze Me, an interactive cover for tablet and smartphone that enables continuous and expressive interaction with electronic devices. The cover has been used to implement "Squeeze to zoom", a mobile application to zoom in and out while taking a photograph from a tablet. The experience of use was evaluated in the short and medium term, comparing the Squeeze Me interaction modality with classic modalities for zooming in and out commonly available on tablets and smartphones. The evaluation process was conducted using AttrakDiff [3] a questionnaire that measures hedonic stimulation and identity, as well as pragmatic qualities and attractiveness of software products. Participants were asked to try out different interaction modalities for comparison in the short-term (67 people) and over 4 weeks (8 people). Results obtained in the short-term evaluation reveal that "Squeeze to zoom" was awarded higher values than the classic "Slide to zoom" in the hedonic quality-stimulation and attractiveness dimensions, whilst it obtained lower values in the pragmatic quality and hedonic quality-identity. However, the experience of use changed over time. During the longitudinal study, the usability of "Squeeze to zoom" improved whilst the attractiveness of "Slide to zoom" decreases significantly. Furthermore results reveal that "Squeeze to zoom" is significantly more appreciated for its hedonic qualities and the effect is maintained over time. This study highlights the importance of evaluating the experience of use over time, a practice that is almost ignored in the literature on Experience Design.
C1 [Marti, Patrizia] Eindhoven Univ Technol, Via Roma 56, I-53100 Siena, Italy.
   [Marti, Patrizia; Iacono, Iolanda] Univ Siena, Via Roma 56, I-53100 Siena, Italy.
C3 University of Siena
RP Marti, P (corresponding author), Eindhoven Univ Technol, Via Roma 56, I-53100 Siena, Italy.; Marti, P (corresponding author), Univ Siena, Via Roma 56, I-53100 Siena, Italy.
EM patrizia.marti@unisi.it
RI Marti, Patrizia/J-4102-2012
OI Marti, Patrizia/0000-0002-2448-8747
CR Alonso MB., 2008, TEI'08 - Second International Conference on Tangible and Embedded Interaction - Conference Proceedings, P105
   [Anonymous], 2006, WORKSHOP 4 NORDIC C
   [Anonymous], P 23 ANN INT C DES C
   Harrison BL, 1998, P CHI 98, P18
   Hassenzahl M, 2004, HUM-COMPUT INTERACT, V19, P319, DOI 10.1207/s15327051hci1904_2
   Hassenzahl M, 2004, CHI 04 HUM FACT COMP, P1283
   Hassenzahl M, 2007, INTERACT COMPUT, V19, P429, DOI 10.1016/j.intcom.2007.05.001
   Karapanos E., 2008, P CHI 2008, P3561
   Karapanos E, 2012, INT J HUM-COMPUT ST, V70, P849, DOI 10.1016/j.ijhcs.2012.06.004
   Karapanos E, 2010, INTERACT COMPUT, V22, P328, DOI 10.1016/j.intcom.2010.04.003
   Kelley GA, 2010, J HYPERTENS, V28, P411, DOI 10.1097/HJH.0b013e3283357d16
   Kildal J., 2012, Proc. CHI EA, P1871
   Kujala Sari., 2011, Proceedings of the 2011 Conference on Designing Pleasurable Products and Interfaces - DPPI'11, P1, DOI [10.1145/2347504.2347523, DOI 10.1145/2347504.2347523]
   Marti P., 2015, Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter, CHItaly '15, P42, DOI [10.1145/2808435.2808461, DOI 10.1145/2808435.2808461]
   Marti P, 2014, P IEEE RAS-EMBS INT, P536, DOI 10.1109/BIOROB.2014.6913833
   Norman D A., 2009, Interactions, V16, P24
   Stienstra JT, 2013, P ANN CHI C HUM FACT, P595
   Weinberg G, 2001, COMPUT MUSIC J, V25, P37, DOI 10.1162/014892601750302570
NR 18
TC 7
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5095
EP 5116
DI 10.1007/s11042-016-3595-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500019
OA Green Published
DA 2024-07-18
ER

PT J
AU Niu, PP
   Wang, XY
   Liu, YN
   Yang, HY
AF Niu Pan-Pan
   Wang Xiang-Yang
   Liu Yu-Nan
   Yang Hong-Ying
TI A robust color image watermarking using local invariant significant
   bitplane histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Desynchronization attacks; Speeded-up robust
   features detector; Color invariance model; Probability density;
   Significant bitplane histogram
ID SPREAD-SPECTRUM WATERMARKING; DETECTORS; SECURITY
AB Desynchronization attacks that cause displacement between embedding and detection are usually difficult for watermark to survive. It is a challenging work to design a robust image watermarking scheme against desynchronization attacks, especially for color images. In this paper, we propose a robust color image watermarking approach based on local invariant significant bitplane histogram. The novelty of the proposed approach includes: 1) A fast and effective color image feature points detector is constructed, in which probability density and color invariance model are used; 2) The fully affine invariant local feature regions are built based on probability density Hessian matrix; and 3) The invariant significant bitplane histograms are introduced to embed digital watermark. The extensive experimental works are carried out on a color image set collected from Internet, and the preliminary results show that the proposed watermarking approach can survive numerous kinds of distortions, including common image processing operations and desynchronization attacks.
C1 [Niu Pan-Pan; Wang Xiang-Yang; Liu Yu-Nan; Yang Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Niu, PP; Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM niupanpan3333@163.com; wxy37@126.com
RI Yang, Jing/JFK-4046-2023; Liu, Yunan/JGM-3801-2023; Liu,
   Yunan/GXH-9776-2022
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61272416, 61472171];
   Foundation of Science and Technology Plan for Higher Education of
   Liaoning Province of China [L2015289]; Youth Foundation of Liaoning
   Normal University of China [LS2014L016]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61272416, & 61472171, the Foundation of Science
   and Technology Plan for Higher Education of Liaoning Province of China
   under Grant No. L2015289, and Youth Foundation of Liaoning Normal
   University of China under Grant No. LS2014L016.
CR Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Deng Cheng, 2010, Acta Automatica Sinica, V36, P221, DOI 10.3724/SP.J.1004.2010.00221
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Golabi S, 2014, INFORM SCIENCES, V269, P94, DOI 10.1016/j.ins.2013.11.020
   Guijun Nian, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P43, DOI 10.1109/MMIT.2010.93
   Ji F, 2013, NEUROCOMPUTING, V106, P42, DOI 10.1016/j.neucom.2012.09.032
   Kaur M, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY, PROCEEDINGS, P296, DOI 10.1109/ICIMT.2009.81
   Li M, 2013, IEEE T INF FOREN SEC, V8, P1201, DOI 10.1109/TIFS.2013.2264462
   Li X, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2372473
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Mathon B, 2014, IEEE T IMAGE PROCESS, V23, P1694, DOI 10.1109/TIP.2014.2305873
   Minamoto T, 2014, APPL MATH COMPUT, V226, P306, DOI 10.1016/j.amc.2013.10.028
   Moghaddam ME, 2013, FORENSIC SCI INT, V233, P193, DOI 10.1016/j.forsciint.2013.09.005
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Naskar R, 2013, IET IMAGE PROCESS, V7, P99, DOI 10.1049/iet-ipr.2012.0232
   [綦科 Qi Ke], 2012, [自动化学报, Acta Automatica Sinica], V38, P1646
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Sun D, 2009, RES DENSITY BASED IM
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wang XY, 2012, J VIS COMMUN IMAGE R, V23, P892, DOI 10.1016/j.jvcir.2012.05.008
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Yang SL, 2011, RES DIGITAL IMAGE WA
   Yu YN, 2012, IEEE T IMAGE PROCESS, V21, P229, DOI 10.1109/TIP.2011.2160271
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang Z., 2011, INT J DIGIT CONTENT, V5, P255, DOI DOI 10.4156/JDCTA.VOL5.ISSUE3.26
   Zhang Z. Y., 2012, INT J DIGIT CONTENT, V6, P245, DOI DOI 10.4156/JDCTA.V0L6.ISSUE9.31
NR 43
TC 18
Z9 19
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3403
EP 3433
DI 10.1007/s11042-016-3935-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200013
DA 2024-07-18
ER

PT J
AU Huang, YZ
   Guan, YP
AF Huang, Yizhen
   Guan, Yepeng
TI Learning and intelligence can happen everywhere, a case study: learning
   via Non-uniform 1D rulers with applications in image classification and
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parameter learning; Image classification; Recognition
AB In this paper, we presented a non-uniform 1D ruler model and applied it in various image classification and image recognition scenarios, and some are for military technology usage. Our model is very simple, elegant and original, which is solved by convex quadratic programming. It has wide applications in pattern recognition and intelligent multimedia data analysis. We believe that a new research topic, namely, numeric calibration, has started, which is parallel to dimensionality reduction, feature selection, or metric learning etc. Our methods can be used as a pre-processing step for metric learning methods, in which, our learned calibrated feature space is used as input for them. The various combinations of our methods and metric learning methods, may lead to new interesting research problems.
C1 [Huang, Yizhen; Guan, Yepeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Guan, Yepeng] Minist Educ, Key Lab Adv Displays & Syst Applicat, Shanghai, Peoples R China.
C3 Shanghai University
RP Guan, YP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.; Guan, YP (corresponding author), Minist Educ, Key Lab Adv Displays & Syst Applicat, Shanghai, Peoples R China.
EM ypguan@shu.edu.cn
RI Moureng, Huang/AAH-8485-2020
FU Natural Science Foundation of China [11176016, 60872117]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20123108110014]
FX This research work is funded by Natural Science Foundation of China
   (Grant No. 11176016, 60872117), and Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20123108110014).
CR [Anonymous], 2004, NIPS
   [Anonymous], 1981, Introduction to multidimensional scaling
   [Anonymous], 2007, ICCV
   [Anonymous], 2006, TECHNICAL REPORT
   [Anonymous], RC23612W0505104 IBM
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Fan N, 2011, IEEE I CONF COMP VIS, P249, DOI 10.1109/ICCV.2011.6126249
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Guana YP, 2015, ENG APPL ARTIF INTEL, V37, P181, DOI 10.1016/j.engappai.2014.08.004
   Huang YZ, 2006, J COMPUT ELECTRON, V5, P275, DOI 10.1007/s10825-006-0145-z
   Ji S., 2008, P 14 ACM SIGKDD INT, P381, DOI [DOI 10.1145/1401890.1401939, 10.1145/1401890.1401939]
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
   Sun FM, 2014, IEEE T IMAGE PROCESS, V23, P1028, DOI 10.1109/TIP.2014.2298978
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Weinberger Kilian., 2006, NIPS, V18, P1475
   Xiao B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P451
   Yu K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P258, DOI 10.1145/1076034.1076080
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 25
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 913
EP 929
DI 10.1007/s11042-015-3043-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000039
DA 2024-07-18
ER

PT J
AU Kapsouras, I
   Tefas, A
   Nikolaidis, N
   Peeters, G
   Benaroya, L
   Pitas, I
AF Kapsouras, I.
   Tefas, A.
   Nikolaidis, N.
   Peeters, G.
   Benaroya, L.
   Pitas, I.
TI Multimodal speaker clustering in full length movies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Diarization; Clustering; Movies; Actor presence
ID DIARIZATION; TRACKING
AB Multimodal clustering/diarization tries to answer the question "who spoke when" by using audio and visual information. Diarizationconsists of two steps, at first segmentation of the audio information and detection of the speech segments and then clustering of the speech segments to group the speakers. This task has been mainly studied on audiovisual data from meetings, news broadcasts or talk shows. In this paper, we use visual information to aid speaker clustering and we introduce a new video-based feature, called actor presence that can be used to enhance audio-based speaker clustering. We tested the proposed method in three full length stereoscopic movies, i.e. a scenario much more difficult than the ones used so far, where there is no certainty that speech segments and video appearances of actors will always overlap. The results proved that the visual information can improve the speaker clustering accuracy and hence the diarization process.
C1 [Kapsouras, I.; Tefas, A.; Nikolaidis, N.; Pitas, I.] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
   [Peeters, G.; Benaroya, L.] STMS IRCAM CNRS UPMC, Sound Anal Synth Team, 1 Pl Igor Stravinsky, F-75004 Paris, France.
C3 Aristotle University of Thessaloniki; Sorbonne Universite; Centre
   National de la Recherche Scientifique (CNRS)
RP Kapsouras, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM jkapsouras@aiia.csd.auth.gr
RI Tefas, Anastasios/ABA-2328-2020; Nikolaidis, Nikos/F-1819-2010; Tefas,
   Anastasios/F-1899-2010
OI Nikolaidis, Nikos/0000-0003-1515-7986; Tefas,
   Anastasios/0000-0003-1288-3667
FU European Union [287674 (3DTVS)]
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme (FP7/2007-2013) under grant
   agreement number 287674 (3DTVS). This publication reflects only the
   authors views. The European Union is not liable for any use that may be
   made of the information contained therein.
CR Alameda-Pineda X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P5, DOI 10.1145/2733373.2806238
   [Anonymous], 2006, ELRA Newslett
   [Anonymous], 1998, P BROADC NEWS TRANSC
   [Anonymous], P MLMI
   [Anonymous], P IEEE C COMP VIS PA
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Baltzakis H, 2008, LECT NOTES COMPUT SC, V5008, P33
   Calic J, 2005, EUROCON 2005: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOL 1 AND 2 , PROCEEDINGS, P135
   El Khoury E, 2014, MULTIMED TOOLS APPL, V68, P747, DOI 10.1007/s11042-012-1080-6
   Elmansori M. M., 2011, EUR J SCI RES, V55, P80
   Feng W, 2009, J VISUAL LANG COMPUT, V20, P188, DOI 10.1016/j.jvlc.2009.01.009
   Friedland G, 2009, P 17 ACM INT C MULT, P195
   Friedland G, 2009, INT CONF ACOUST SPEE, P4069, DOI 10.1109/ICASSP.2009.4960522
   Garau G, 2010, INT CONF ACOUST SPEE, P4942, DOI 10.1109/ICASSP.2010.5495101
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Jaimes A, 2005, LECT NOTES COMPUT SC, V3766, P1, DOI 10.1007/11573425_1
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Noulas A, 2012, IEEE T PATTERN ANAL, V34, P79, DOI 10.1109/TPAMI.2011.47
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Orfanidis G, 2014, IEEE S SERIES COMPUT
   Orfanidis G, 2015, SIGNAL PROCESS-IMAGE, V33, P86, DOI 10.1016/j.image.2015.01.009
   Patrona F, 2015, IEEE INT C IM PROC I
   Sargin ME, 2009, INT CONF ACOUST SPEE, P1977, DOI 10.1109/ICASSP.2009.4959999
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Stamou GN, 2007, J MULTIMODAL USER IN, V1, P31, DOI 10.1007/BF02910057
   SUBRAMANIAN R, 2013, ICM P 2013 ACM INT, P3, DOI DOI 10.1145/2522848.2522862
   Uricar Michal, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P547
   Vallet F, 2013, IEEE T MULTIMEDIA, V15, P509, DOI 10.1109/TMM.2012.2233724
   Wang H., 2009, BMVC 2009 BRIT MACH
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Zoidi O, 2014, SIGNAL PROCESS-IMAGE, V29, P573, DOI 10.1016/j.image.2014.03.004
   Zoidi O, 2013, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2013.6638092
NR 33
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2223
EP 2242
DI 10.1007/s11042-015-3181-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000028
DA 2024-07-18
ER

PT J
AU Khlif, A
   Mignotte, M
AF Khlif, Ayman
   Mignotte, Max
TI Segmentation data visualizing and clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Berkeley dataset; Clustering algorithm; Entropy; Database browsing and
   retrieving images; Hierarchical clustering; K-means; Multidimensional
   visualization; Query-by-drawing; Segmentation data clustering;
   Descriptive content based image classification; Variation of
   information; Visualization of image databases
ID IMAGE; MODEL; FUSION
AB Browsing, searching and retrieving images from large databases based on low level color or texture visual features have been widely studied in recent years but are also often limited in terms of usefulness. In this paper, we propose a new framework that allows users to effectively browse and search in large image database based on their segmentation-based descriptive content and, more precisely, based on the geometrical layout and shapes of the different objects detected and segmented in the scene. This descriptive information, provided at a higher level of abstraction, can be a significant and complementary information which helps the user to browse through the collection in an intuitive and efficient manner. In addition, we study and discuss various ways and tools for efficiently clustering or for retrieving a specific subset or class of images in terms of segmentation-based descriptive content which can also be used to efficiently summarize the content of the image database. Experiments conducted on the Berkeley Segmentation Datasets show that this new framework can be effective in supporting image browsing and retrieval tasks.
C1 [Khlif, Ayman; Mignotte, Max] Univ Montreal, DIRO, Fac Arts & Sci, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal
RP Mignotte, M (corresponding author), Univ Montreal, DIRO, Fac Arts & Sci, Montreal, PQ H3C 3J7, Canada.
EM mignotte@iro.umontreal.ca
RI Mignotte, Max/F-7014-2015
CR Alvarez C., 2004, Multilingual Information Access for Text, Speech and Images. 5th Workshop of the Cross-Language Evaluation Forum, CLEF 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3491), P676
   [Anonymous], 1952, Psychometrika
   [Anonymous], 2009, 2009 WORKSHOP APPL C, DOI DOI 10.1109/WACV.2009.5403029
   Banks S.P., 1990, SIGNAL PROCESSING IM
   Bartolini I, 2006, MULTIMED TOOLS APPL, V31, P269, DOI 10.1007/s11042-006-0044-0
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   Cayton L., 2006, P 23 INT C MACHINE L, P169, DOI [10.1145/1143844.1143866, DOI 10.1145/1143844.1143866]
   Hedjam R, 2009, IEEE IMAGE PROC, P1365, DOI 10.1109/ICIP.2009.5413555
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Jiang Y, 2004, NEURAL PROCESS LETT, V20, P171, DOI 10.1007/s11063-004-2022-8
   Keuchel J, 2006, LECT NOTES COMPUT SC, V4174, P41
   Leelanupab T, 2009, LECT NOTES COMPUT SC, V5887, P3, DOI 10.1007/978-3-642-10543-2_3
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013
   Mignotte M, 2004, IEEE T PATTERN ANAL, V26, P184, DOI 10.1109/TPAMI.2004.1262180
   Mignotte M, 2014, FUSION INFORM
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Mignotte M, 2014, PATTERN ANAL APPL, V17, P129, DOI 10.1007/s10044-012-0272-z
   Mignotte M, 2011, IEEE T NEURAL NETWOR, V22, P447, DOI 10.1109/TNN.2010.2101614
   Mignotte M, 2011, PATTERN RECOGN LETT, V32, P359, DOI 10.1016/j.patrec.2010.09.016
   Mignotte M, 2010, IEEE T GEOSCI REMOTE, V48, P4236, DOI 10.1109/TGRS.2010.2051553
   Mignotte M, 2010, IEEE T IMAGE PROCESS, V19, P1610, DOI 10.1109/TIP.2010.2044965
   Oumohmed AI, 2005, LECT NOTES COMPUT SC, V3687, P414
   Schaefer G, 2012, LECT NOTES COMPUT SC, V7594, P236, DOI 10.1007/978-3-642-33564-8_29
   Schaefer G, 2010, MULTIMED TOOLS APPL, V47, P105, DOI 10.1007/s11042-009-0409-2
   Urban J, 2006, MULTIMED TOOLS APPL, V31, P1, DOI 10.1007/s11042-006-0035-1
   Vega-Pons S, 2011, INT J PATTERN RECOGN, V25, P337, DOI 10.1142/S0218001411008683
   Wattuya P, 2008, INT C PATT RECOG, P1550
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Young G, 1938, PSYCHOMETRIKA, V3, P19, DOI 10.1007/BF02287916
NR 33
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1531
EP 1552
DI 10.1007/s11042-015-3148-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000067
DA 2024-07-18
ER

PT J
AU Sadek, MM
   Khalifa, AS
   Mostafa, MGM
AF Sadek, Mennatallah M.
   Khalifa, Amal S.
   Mostafa, Mostafa G. M.
TI Robust video steganography algorithm using adaptive skin-tone detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Adaptive; Video; Skin detection; Wavelet transform;
   Quantization
ID WATERMARKING; SCHEME
AB Human skin regions have recently drawn attention in the literature of data hiding due to its promising robustness characteristics. In this paper, we propose a blind adaptive data hiding algorithm for video files where human skin regions are regarded as the Regions Of Interest (ROI) hosting the embedding process. A skin map is created for each frame using an adaptive skin detection algorithm with reduced number of false positives. Then the skin map is converted to a skin-block-map in order to eliminate the error-prone skin pixels that can result in inefficient retrieval of the hidden data. Moreover, the embedding process is done using a wavelet quantization technique over the red and blue channels of the host frames for increased robustness. Experimental results showed the high imperceptibility of the proposed method as well as its robustness against MPEG-4 compression.
C1 [Sadek, Mennatallah M.; Khalifa, Amal S.; Mostafa, Mostafa G. M.] Ain Shams Univ, Fac Comp & Informat Sci, Abassiacairo, Egypt.
   [Khalifa, Amal S.] Princess Nora Bint Abdulrahman Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; Princess Nourah
   bint Abdulrahman University
RP Sadek, MM (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Abassiacairo, Egypt.
EM menna.sadek@cis.asu.edu.eg; askhalifa@pnu.edu.sa;
   mgmostafa@cis.asu.edu.eg
RI Mostafa, Mostafa G. M./HGP-0396-2022; Khalifa, Amal/AAN-9725-2020
OI Mostafa, Mostafa G. M./0000-0002-3555-4148; Khalifa,
   Amal/0000-0002-2054-7869
CR Basilio JAM, 2011, APPL MATH COMPUT ENG
   Bei-bei Liu, 2008, 2008 Fourth International Conference on Semantics, Knowledge and Grid (SKG), P487, DOI 10.1109/SKG.2008.48
   CHANNALLI S, 2009, INT J COMPUTER SCI E, V1, P137, DOI DOI 10.3923/itj.2004.245.269
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chen WY, 2007, APPL MATH COMPUT, V185, P432, DOI 10.1016/j.amc.2006.07.041
   Elgammal A, 2009, ENCY BIOMETRICS, P1218
   Eltahir ME, 2009, INTERNATIONAL CONFERENCE ON FUTURE COMPUTER AND COMMUNICATIONS, PROCEEDINGS, P672, DOI 10.1109/ICFCC.2009.44
   Farag H, 2014, INT REFEREED J ENG S, V3
   Fleck M. M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P593
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Hamad SH, 2013, EGYPT COMPUT SCI J
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Khan R., 2008, P 1 ACM WORKSH AN RE, P89, DOI 10.1145/1463542.1463557
   Kumravat S, 2013, INT J COMPUT SCI ENG, V4
   Lakshmi HCV, 2011, INT J COMPUT SCI COM, V3
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Ma X., 2010, IEEE T CIRCUITS SYST, V20
   Mansouri J, 2009, INT J IMAG SYST TECH, V19, P306, DOI 10.1002/ima.20207
   Ming Yang, 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P935
   Mulcahy C., 1997, SPELMAN SCI MATH J, V1, P22
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Rumyantsev O, 2012, IMAGE PROCESS
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Shang YY, 2007, ICNC 2007: Third International Conference on Natural Computation, Vol 5, Proceedings, P576
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Sherly AP, 2010, INT J DATABASE MANAG, V2, DOI [10.5121/ijdms.2010.230767, DOI 10.5121/IJDMS.2010.230767]
   Shirali-Shahreza M, 2006, 8 INT C SIGN PROC
   Sur A, 2006, LECT NOTES COMPUT SC, V4338, P738
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
NR 31
TC 34
Z9 36
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3065
EP 3085
DI 10.1007/s11042-015-3170-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000066
DA 2024-07-18
ER

PT J
AU Shojanazeri, H
   Adnan, WAW
   Ahmad, SMS
   Rahimipour, S
AF Shojanazeri, Hamid
   Adnan, Wan Azizun Wan
   Ahmad, Sharifah Mumtadzah Syed
   Rahimipour, Somayeh
TI Authentication of images using Zernike moment watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Image authentication; Authentication; Copyright
   protection; Multimedia security; Image watermarking
ID SCHEME; ROTATION; SCALE
AB The rapid development of the Internet and digital image modification software has invited the illegal access to and use of digital images. In response, digital watermarking has emerged as a unique tool for protecting the authenticity of digital images. This technique involves the insertion of an imperceptible message within the media. This paper proposes a semi-fragile watermarking system using content-based techniques that address the challenge of image authentication. The proposed algorithm exploits the Zernike moments to authenticate an image and the Sobel edge map to perform tamper detection. The main contributions of this work are the establishment of an authentication algorithm that is robust against scaling, translation, noise pollution, rotation and JPEG compression, which are considered to be non-malicious modifications, while significantly decreasing the computational complexity using optimum orders of Zernike moments. In addition, this work addresses the challenge of capacity in terms of watermark insertion while preserving the visual quality of the image, where the capacity is increased almost three fold, as shown in the results. This process can successfully distinguish malicious attacks and reject modifications to watermarked images made through additions, replacements, and image cropping.
C1 [Shojanazeri, Hamid] Univ Putra Malaysia, Dept Comp & Commun Syst Engn, Serdang 43300, Selangor, Malaysia.
   [Adnan, Wan Azizun Wan; Ahmad, Sharifah Mumtadzah Syed; Rahimipour, Somayeh] Univ Putra Malaysia, Serdang, Malaysia.
C3 Universiti Putra Malaysia; Universiti Putra Malaysia
RP Shojanazeri, H (corresponding author), Univ Putra Malaysia, Dept Comp & Commun Syst Engn, Serdang 43300, Selangor, Malaysia.
EM hamid.nazeri2010@gmail.com
RI AHMAD, SHARIFAH/JJC-4353-2023
CR [Anonymous], 2004, DIGITAL IMAGE PROCES
   [Anonymous], MOL BIOL INT
   Chan PW, 2005, IEEE T CIRC SYST VID, V15, P1638, DOI 10.1109/TCSVT.2005.856932
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Gong ZQ, 2012, ADV INTEL SOFT COMPU, V125, P773
   Hao Z, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL I, P519, DOI 10.1109/ICMTMA.2009.110
   Hongmei L, 2010, EURASIP J ADV SIGNAL, V2010
   Hsieh SL, 2011, MULTIMED TOOLS APPL, V52, P597, DOI 10.1007/s11042-010-0520-4
   Hu YP, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5484
   Jayanthi VE, 2011, INT J ELECTRON, V98, P1565, DOI 10.1080/00207217.2011.601444
   Kang H., 2003, Proc. of STEG, P127
   Kao C, 2009, P APSIPA ASC 2009 AP
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Li C. Y., 2014, ELECT J DIFFERENTIAL, V2014, P1, DOI DOI 10.1016/J.RSE.2014.04.020
   Li GB, 2009, INT C COMP SUPP COOP, P107, DOI 10.1109/CSCWD.2009.4968043
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Liu HM, 2005, IEEE INT SYMP CIRC S, P4014
   Liu HM, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P229, DOI 10.1109/ICME.2008.4607413
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Min-Jen Tsai, 2000, IEEE Transactions on Consumer Electronics, V46, DOI 10.1109/30.826405
   Misiti M., 1996, Wavelet toolbox
   Ouyang B, 2010, THESIS
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Shojanazeri Hamid, 2013, International Journal of Computer Information Systems and Industrial Management Applications, V5, P652
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis E, 2012, J SYSTEMS SOFTWARE
   WALLIN A, 1995, IEEE T PATTERN ANAL, V17, P1106, DOI 10.1109/34.473239
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Zhou X, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P374
NR 39
TC 13
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 577
EP 606
DI 10.1007/s11042-015-3018-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000026
DA 2024-07-18
ER

PT J
AU Vella, F
   Infantino, I
   Scardino, G
AF Vella, Filippo
   Infantino, Ignazio
   Scardino, Giuseppe
TI Person identification through entropy oriented mean shift clustering of
   human gaze patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Identification; Gaze detection; Depth sensors; Mean shift;
   Entropy
AB The paper describes a system aimed at improving the human machine interaction that is able to identify users according how she looks at the monitor. The proposed system does not need invasive measurements that could limit the naturalness of her actions. The approach, here described, detects the gaze movements on the monitor and clusters the sequences of user gaze fixation points on the screen characterizing the user according the particular patterns her gaze follows. The recognition of the user is performed through a clustering process employing the Mean-Shift algorithm and it can open new perspective in human-machine interaction. In particular, the parameters of the clustering process are tuned optimizing an entropy oriented cost function that allows an automatic selection of the best parameters setting.
C1 [Vella, Filippo; Infantino, Ignazio; Scardino, Giuseppe] Natl Res Council Italy CNR, High Performance Comp & Networking Inst ICAR, Viale Sci Ed 11, Palermo, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR)
RP Vella, F (corresponding author), Natl Res Council Italy CNR, High Performance Comp & Networking Inst ICAR, Viale Sci Ed 11, Palermo, Italy.
EM filippo.vella@pa.icar.cnr.it
RI Infantino, Ignazio/JAC-8531-2023; Infantino, Ignazio/P-8450-2019; Vella,
   Filippo/B-7279-2013
OI Vella, Filippo/0000-0002-2502-0062; INFANTINO,
   IGNAZIO/0000-0002-0980-7391
CR Aggarwal JK, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P640
   [Anonymous], 2013, P 2013 INT C BIOM IC, DOI DOI 10.1109/ICB.2013.6612953
   [Anonymous], 2010, P 2010 S EYE TRACK R, P187
   [Anonymous], PATTERN RECOGNITION
   Ardizzone E, 2008, P INT C IM PROC WORK
   Ardizzone E, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3274617
   Ben-Yacoub S, 1999, IEEE T NEURAL NETWOR, V10, P1065, DOI 10.1109/72.788647
   Bergadano F., 2003, Intelligent Data Analysis, V7, P469
   Bezdek James C., 1981, PATTERN RECOGN
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deravi F, 2011, BIOSIGNALS 2011, P335
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kelley R, 2010, UNDERSTANDING ACTIVI
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Orr R. J., 2000, CHI 00 EXTENDED ABST, P275, DOI [DOI 10.1145/633292.633453, 10.1145/633451.633453]
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Rigas I, 2012, PATTERN RECOGN LETT, V33, P786, DOI 10.1016/j.patrec.2012.01.003
   Scardino Giuseppe, 2013, Human Aspects of Information Security, Privacy, and Trust. First International Conference, HAS 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8030, P49, DOI 10.1007/978-3-642-39345-7_6
   Steichen B, 2014, LECT NOTES COMPUT SC, V8538, P183
   Toker Dereck., 2013, proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P295
   Turk M, 2004, COMMUN ACM, V47, P61, DOI 10.1145/962081.962107
   Wu KL, 2005, PATTERN RECOGN LETT, V26, P1275, DOI 10.1016/j.patrec.2004.11.022
   Yampolskiy RV, 2008, INT J BIOMETRICS, V1, P81, DOI 10.1504/IJBM.2008.018665
NR 23
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2289
EP 2313
DI 10.1007/s11042-015-3153-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000031
DA 2024-07-18
ER

PT J
AU Ruso, T
   Chellappan, C
   Sivasankar, P
AF Ruso, T.
   Chellappan, C.
   Sivasankar, P.
TI Ppssm: push/pull smooth video streaming multicast protocol design and
   implementation for an overlay network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Application layer multicast; Buffer management; Network coding; Load
   balancing
AB IP multicast is one of the best techniques for video streaming on the Internet. It faces issues with respect to address allocation, routing, authorization, group management, security, and scalability. By default, local Internet Service Providers did not enable IP multicast services, because of the cost incurred in using multicast-enabled routers. To solve these issues some of the IP layer functionalities have been shifted to the Application Layer, thus leading to Application Layer Multicast (ALM) protocols. However, ALM protocols face issues related to synchronous data delivery, scalability, link stress, link stretch and node failures. Some of the existing protocols are CoolStreaming, and mTreebone. A novel ALM protocol based Push/Pull Smooth video Streaming Multicast (PPSSM) protocol is proposed in this paper, to increase the throughput and reduce the packet loss rate. The PPSSM protocol involves three stages, such as tree-mesh construction, dynamic buffer management and network coding techniques. In the tree-mesh construction, a tree consists of stable nodes and a mesh consists of unstable nodes. The proposed PPSSM optimizes the stable nodes in the tree, which minimizes or eliminates the pull operations from the unstable mesh overlay nodes, by exploring the potential of the stable nodes. Dynamic buffer management is achieved by setting the optimal buffer threshold value, using the optimization of the sensitivity parameters, such as packet loss and packet workload/delay by the Infinitesimal Perturbation Analysis and Stochastic Approximation algorithms. In addition to the tree-mesh construction and buffer management, the introduction of the network coding technique will enhance the throughput and minimize the packet loss and delay. Finally, the performance of the proposed PPSSM protocol is compared with those of CoolStreaming, and mTreebone, and it shows improvement in respect of throughput, packet loss, and average decoding time.
C1 [Ruso, T.] Saveetha Univ, Saveetha Sch Engn, Dept Comp Sci & Engn, Madras 77, Tamil Nadu, India.
   [Chellappan, C.] GKM Coll Engn & Technol, Madras, Tamil Nadu, India.
   [Sivasankar, P.] NITTTR, Dept Elect Engn, Madras 113, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science
RP Ruso, T (corresponding author), Saveetha Univ, Saveetha Sch Engn, Dept Comp Sci & Engn, Madras 77, Tamil Nadu, India.
EM racingruso@gmail.com; drcc@annauniv.edu; siva_sankar123p@yahoo.com
RI P, Sivasankar/ABE-4259-2021
OI P, Sivasankar/0000-0003-4797-522X
CR Adams A., 2005, 3973 RFC
   Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   [Anonymous], 2008, Network Coding: An Introduction
   BANERJEE S, 2002, P ACM SIGC
   Besharati R, 2010, P CCNC
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Cheng HJ, 2012, AD HOC NETW, V10, P760, DOI 10.1016/j.adhoc.2011.02.004
   Deering S, 2002, 3376 RFC
   DEERING SE, 1990, ACM T COMPUT SYST, V8, P85, DOI 10.1145/78952.78953
   Demestichas PP, 2004, IEEE T SYST MAN CY C, V34, P69, DOI 10.1109/TSMCC.2003.818500
   Fenner B., 2006, Protocol Independent Multicast - Sparse Mode (PIM-SM): Protocol Specification (Revised)
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   Lee JJ, DYNAMIC SETTING OPTI
   Li P, 2012, IEEE INFOCOM SER, P100, DOI 10.1109/INFCOM.2012.6195456
   Liu L, 2015, IEEE T COMPUT, V64, P819, DOI 10.1109/TC.2013.229
   Markou NM, 2005, IEEE VTS VEH TECHNOL, P2162
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Song YM, 2014, IEEE T NETW SERV MAN, V11, P417, DOI 10.1109/TNSM.2014.2346080
   Thomos N, 2010, IEEE T CIRC SYST VID, V20, P1834, DOI 10.1109/TCSVT.2010.2087830
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Venkataraman V, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P2, DOI 10.1109/ICNP.2006.320193
   Vlavianos A., 2006, P IEEE INFOCOM, P1
   Wang F, 2010, IEEE T PARALL DISTR, V21, P379, DOI 10.1109/TPDS.2009.77
   Youssef M, 2014, IEEE COMMUN SURV TUT, V16, P92, DOI 10.1109/SURV.2013.082713.00184
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
   Zhou LA, 2011, IEEE T VEH TECHNOL, V60, P692, DOI 10.1109/TVT.2010.2102782
NR 28
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17097
EP 17119
DI 10.1007/s11042-015-2979-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600018
DA 2024-07-18
ER

PT J
AU Ji, QB
   Zheng, EZ
   Yue, XQ
   Xie, Y
   Lin, Y
AF Ji Qingbo
   Zheng Enze
   Yue Xinqi
   Xie Yu
   Lin Yun
TI Face recognition method based on HOG and DMMA from single training
   sample
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; DMMA; Statistics manifold learning; Single training
   sample; HOG
ID DIMENSIONALITY REDUCTION; IMAGE; EIGENFACES
AB Single training sample for face recognition technology has become one of the important topics in the field of computer vision, and presents various challenges and opportunities. In this paper, an improved method based on discriminative multi-manifold analysis (DMMA) algorithm is proposed for the single training sample problem in face recognition. The major contributions of the paper are that a novel method by fusing Histogram of the Oriented Gradient (HOG) features and DMMA algorithm is proposed, and a new adaptive method is applied to calculate similarity between patches of the face image. First, each face image is partitioned into several non-overlapping patches to form an image set for each sample per person. Then HOG operator is used to extract image histogram of each an image set, and the histogram of each an image set forms a statistics manifold. Finally, DMMA algorithm is applied to obtain the low-dimensional face image features, and the reconstruction-based manifold-manifold distance is used to identify the unlabeled faces. The performance of the proposed method is verified on the FERET and AR face databases. Experimental results indicate that the proposed method is superior to the general DMMA recognition algorithms under illumination variation and geometry transformation.
C1 [Ji Qingbo; Zheng Enze; Xie Yu; Lin Yun] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
   [Yue Xinqi] Chinese Aeronaut Radio Elect Res Inst, Shanghai, Peoples R China.
   [Lin Yun] Wright State Univ, Dept Elect Engn, Dayton, OH 45435 USA.
C3 Harbin Engineering University; University System of Ohio; Wright State
   University Dayton
RP Yue, XQ (corresponding author), Chinese Aeronaut Radio Elect Res Inst, Shanghai, Peoples R China.
EM yuexinqi@hrbeu.edu.cn
RI Yun, Lin/C-4759-2019
OI Yun, Lin/0000-0003-1379-9301
FU Science Foundation of Heilongjiang Province of China [F201407]
FX This work is supported by the Science Foundation of Heilongjiang
   Province of China (Grant No. F201407).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Do T-T, AC SPEECH SIGN PROC, P1301
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu CH, 2015, MULTIMED TOOLS APPL, V74, P10313, DOI 10.1007/s11042-014-2168-y
   Jebara T., 2009, P 26 ANN INT C MACH, P441
   Kanan HR, 2008, PATTERN RECOGN, V41, P3799, DOI 10.1016/j.patcog.2008.05.024
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Luh G-C, 2011, P 2011 INT C MACH LE, P10
   Martinez A., 1998, AR FACE DATABASE
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shu Chang, 2011, Tsinghua Science and Technology, V16, P216, DOI 10.1016/S1007-0214(11)70032-3
   Tan XY, 2004, LECT NOTES COMPUT SC, V3173, P858
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J, 2013, PLOS ONE, V8
   Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zang F, 2012, PATTERN RECOGN, V45, P3866, DOI 10.1016/j.patcog.2012.04.022
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
NR 24
TC 6
Z9 6
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13163
EP 13177
DI 10.1007/s11042-015-3005-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800012
DA 2024-07-18
ER

PT J
AU Xiao, YL
   Xia, LM
AF Xiao, Yongliang
   Xia, Limin
TI Human action recognition using modified slow feature analysis and
   multiple kernel learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Slow feature analysis; Multiple kernel
   learning; Powell method
ID OPTIMIZATION; MODELS
AB A novel human action recognition method is proposed, which includes two periods of action feature extraction and action recognition. Firstly, we use a modified slow feature analysis (SFA) to extract video local feature. Unlike slow feature analysis, we redefine the objective function with supervised information, which make the modified SFA more suitable to preserve the slow feature and label information. Meanwhile, in effort to cope with the dimension explosion in SFA, locality preserving projections (LPP) is used to reduce the quadratic expansion dimension. Secondly, we use a multiple kernel learning method (MKL) to classify human action, in which the weights of different kernels are optimized by combining Bacterial Chemotaxis method and Powell method. The results of experiments indicate the efficiency of our method.
C1 [Xiao, Yongliang; Xia, Limin] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Peoples R China.
   [Xiao, Yongliang] Hunan Univ Finance & Econ, Dept Informat Management, Changsha 410205, Peoples R China.
C3 Central South University; Hunan University of Finance & Economics
RP Xia, LM (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Peoples R China.
EM xylroc@163.com; xlm@mail.csu.edu.cn
FU Postdoctoral Science Foundation of Central South University; Construct
   Program of the Key Discipline in Hunan Province; Hunan Province
   Education and Science Issue "Performance Evaluation for College Teacher
   Based on Adaptive Learning" [XJK013CGD083]; Teaching Reform Research
   Foundation of Hunan Province Ordinary College [[2014] 247-612]; Research
   Foundation of Science & Technology Office of Hunan Province [2014FJ3057]
FX This work is supported by the Postdoctoral Science Foundation of Central
   South University, the Construct Program of the Key Discipline in Hunan
   Province, Hunan Province Education and Science Issue "Performance
   Evaluation for College Teacher Based on Adaptive Learning" (no.
   XJK013CGD083), the Teaching Reform Research Foundation of Hunan Province
   Ordinary College under Grant (no. [2014] 247-612), and the Research
   Foundation of Science & Technology Office of Hunan Province under Grant
   (no. 2014FJ3057).
CR [Anonymous], 2014, J. Converg. Inf. Technol.
   Ben Aoun N, 2014, J VIS COMMUN IMAGE R, V25, P329, DOI 10.1016/j.jvcir.2013.11.003
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boser B, 1992, P 5 ACM WORKSH COMP
   Christodoulou CA, 2010, ENERGY, V35, P3375, DOI 10.1016/j.energy.2010.04.023
   Ding H, 2009, ACTA PHOTOMICA SINIC, V38, P46
   Guo P, 2014, MULTIMED TOOLS APPL, V68, P827, DOI 10.1007/s11042-012-1084-2
   He X., 2003, P NEUR INF PROC SYST
   Kalinin YV, 2009, BIOPHYS J, V96, P2439, DOI 10.1016/j.bpj.2008.10.027
   Kim H, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0009-7
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Moghaddam Z, 2014, IEEE T AUTOM SCI ENG, V11, P394, DOI 10.1109/TASE.2013.2262940
   Müller SD, 2002, IEEE T EVOLUT COMPUT, V6, P16, DOI 10.1109/4235.985689
   Narang N, 2012, ENERGY, V47, P237, DOI 10.1016/j.energy.2012.09.004
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Sadek S., 2010, Precipitation Patterns in Reaction-Diffusion Systems, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shen B.F., 2006, PRECAMBRIAN MINERALI, P1
   Shon JG, 2014, J INF PROCESS SYST, V10, P543, DOI 10.3745/JIPS.04.0010
   Tan Lunzheng, 2013, Journal of National University of Defense Technology, V35, P102
   Thériault C, 2014, IEEE J-STSP, V8, P428, DOI 10.1109/JSTSP.2014.2315742
   Tonaru T, 2009, INT J HYBRID INFORM, V2, P13
   TU H, 2014, SCI WORLD J, DOI DOI 10.1155/2014/495071
   Tu HB, 2013, J APPL MATH, DOI 10.1155/2013/506752
   Thi TH, 2012, IMAGE VISION COMPUT, V30, P1, DOI 10.1016/j.imavis.2011.12.006
   Tuia D, 2010, IEEE T GEOSCI REMOTE, V48, P3780, DOI 10.1109/TGRS.2010.2049496
   Wang Y, 2007, LECT NOTES COMPUT SC, V4814, P240
   Wang YY, 2014, INT J HUMANOID ROB, V11, P329
   Yang GL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/398583
   Zhang Y, 2009, P 5 INT C NAT COMP, P388
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhou W, 2011, INT J ADV MANUF TECH, V52, P715, DOI 10.1007/s00170-010-2738-8
NR 34
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13041
EP 13056
DI 10.1007/s11042-015-2569-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800004
DA 2024-07-18
ER

PT J
AU Xie, YX
   He, YG
   Cheng, AB
   Zhang, JW
AF Xie, Yuxi
   He, Yonggui
   Cheng, Aibin
   Zhang, Junwei
TI Study on medical image enhancement based on IFOA improved grayscale
   image adaptive enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos theory; Fruit fly optimization algorithm; Adaptive enhancement;
   Image processing; Image quality evaluation
ID SEGMENTATION
AB In allusion to deficiencies of traditional medical image enhancement algorithms such as poor applicability, large calculated amount and manual parameter setting and local optimum problem of FOA algorithm, this paper introduces chaos theory into FOA algorithm for improvement based on good global optimum searching performance of fruit fly optimization algorithm and optimizes normalized incomplete Beta function with IFOA for medical image enhancement. The experimental result shows that the improved FOA algorithm can highlight image features effectively, improve visual effect of images and efficiency, avoid invariability of manual parameter adjustment, configure best parameters of normalized incomplete Beta function automatically while guaranteeing best image quality and achieve adaptive enhancement of medical images.
C1 [Xie, Yuxi; He, Yonggui; Cheng, Aibin; Zhang, Junwei] North China Univ Sci & Technol, Affiliated Hosp, Tangshan 063000, Peoples R China.
C3 North China University of Science & Technology
RP Xie, YX (corresponding author), North China Univ Sci & Technol, Affiliated Hosp, Tangshan 063000, Peoples R China.
EM xieyuxincust@163.com
CR [Anonymous], MULTIMED TOOLS APPL
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Li H, 2011, IEEE T SYST MAN CYB, V19, P1276
   Li XJ, 1998, ICSP '98: 1998 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P1017, DOI 10.1109/ICOSP.1998.770787
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Peng DL, 2012, P 1 INT C MACH LEARN, P820
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tizhoosh HR, 2007, P 6 IEEE INT C FUZZ, V3, P1398
   TUBBS JD, 1987, PATTERN RECOGN, V20, P617, DOI 10.1016/0031-3203(87)90031-8
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
NR 17
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14367
EP 14379
DI 10.1007/s11042-016-3358-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500021
DA 2024-07-18
ER

PT J
AU Yang, JJ
   Zhang, X
   Peng, W
   Liu, ZB
AF Yang, Jingjing
   Zhang, Xiao
   Peng, Wei
   Liu, Zhanbiao
TI A novel regularized K-SVD dictionary learning based medical image
   super-resolution algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image super-resolution; K-SVD dictionary learning; RMOP; Sparse
   presentation; Mathematical optimization
ID ORTHOGONAL MATCHING PURSUIT; SPARSE; RECOVERY
AB Recently sparse representations over learned dictionaries have been proven to be a very successful representation method for many image processing applications. In the medical image processing community, image super-resolution has been playing a vital role to make the computer based diagnosis more efficient and accurate. Resolution enhancement through conventional interpolation methods strongly affects the precision of consequent processing steps such as segmentation and registration. In this paper, we propose a novel regularized KSVD dictionary learning based medical image super-resolution algorithm. First, the dictionary is trained using the modified version of the K-SVD dictionary learning procedure. The sparse coding phase of the K-SVD dictionary learning scheme is then enhanced incorporating a simple and an efficient regularized version of orthogonal matching pursuit. In addition, the dictionary update stage allows for an arbitrary number of atoms at the same time and sparse coefficient vector. In the SR reconstruction procedure, ROMP is adopted to find out for the vector of sparse representation coefficients for the underlying patch. In the final part, mathematical optimization finalizes the SR work effectively. The numerical analysis and experimental simulation prove the feasibility and robustness of our proposed methodology compared with other state-of-the-art algorithms.
C1 [Yang, Jingjing; Zhang, Xiao; Peng, Wei] Hebei North Univ, Sch Informat Sci & Engn, Zhangjiakou 075000, Hebei, Peoples R China.
   [Liu, Zhanbiao] 251ST Hosp PLA, Zhangjiakou 075000, Hebei, Peoples R China.
C3 Hebei North University
RP Zhang, X (corresponding author), Hebei North Univ, Sch Informat Sci & Engn, Zhangjiakou 075000, Hebei, Peoples R China.
EM r78z@foxmail.com; r78z-yang@126.com; Pengwei_hnu@126.com;
   lzb0251@tom.com
FU Hebei North University [ZD201301, ZD201302]; Youth Foundation of the
   Education Department of Hebei Province [QN2015225]; Engineering Research
   Center of Population Health Information, Hebei Province; Hebei North
   University
FX The Major Programs of Hebei North University (No. ZD201301 and No.
   ZD201302), The Youth Foundation of the Education Department of Hebei
   Province (No.QN2015225) and Engineering Research Center of Population
   Health Information, Hebei Province. Authors are grateful to the Hebei
   North University for financial support to carry out this work.
CR [Anonymous], INT J DISTRIB SENS N
   [Anonymous], WHOLE BRAIN ATLAS
   [Anonymous], MATH PROBL ENG
   [Anonymous], SIGNAL IMAGE VIDEO P
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Dai W, 2012, IEEE T SIGNAL PROCES, V60, P6340, DOI 10.1109/TSP.2012.2215026
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653
   Dong WS, 2010, PROC SPIE, V7744, DOI 10.1117/12.863368
   Fu CH, 2014, INT CONF DIGIT SIG, P449, DOI 10.1109/ICDSP.2014.6900704
   Gill PR, 2011, IEEE T SIGNAL PROCES, V59, P4595, DOI 10.1109/TSP.2011.2161292
   He B, 2014, COGN COMPUT, V6, P264, DOI 10.1007/s12559-013-9224-1
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Needell D, 2010, IEEE J-STSP, V4, P310, DOI 10.1109/JSTSP.2010.2042412
   Needell D, 2009, FOUND COMPUT MATH, V9, P317, DOI 10.1007/s10208-008-9031-3
   Ren J, 2013, IEEE T IMAGE PROCESS, V22, P1454, DOI 10.1109/TIP.2012.2231690
   Rueda A, 2013, MED IMAGE ANAL, V17, P113, DOI 10.1016/j.media.2012.09.003
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Sajjad M, 2014, SENSORS-BASEL, V14, P3652, DOI 10.3390/s140203652
   Sun J., 2008, IEEE C COMPUTER VISI, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang T, 2011, IEEE T INFORM THEORY, V57, P6215, DOI 10.1109/TIT.2011.2162263
   Zhu QP, 2014, TEXT RES J, V84, P1634, DOI 10.1177/0040517514525880
NR 26
TC 8
Z9 9
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13107
EP 13120
DI 10.1007/s11042-015-2744-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800008
DA 2024-07-18
ER

PT J
AU Zheng, SL
   Li, DD
   Hu, DH
   Ye, DP
   Wang, LN
   Wang, JW
AF Zheng, Shuli
   Li, Dandan
   Hu, Donghui
   Ye, Dengpan
   Wang, Lina
   Wang, Jinwei
TI Lossless data hiding algorithm for encrypted images with high capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Reversible data hiding; Image encryption; Lossless
   compression
AB In this paper, a novel reversible data hiding algorithm for encrypted images is proposed. In encryption phase, chaotic sequence is applied to encrypt the original image. Then the least significant bits (LSBs) of pixels in encrypted image are losslessly compressed to leave place for secret data. With auxiliary bit stream, the lossless compression is realized by the Hamming distance calculation between the LSB stream and auxiliary stream. At receiving terminal, the operation is flexible, that is, it meets the requirement of separation. With the decryption key, a receiver can get access to the marked decrypted image which is similar to the original one. With data-hiding key, the receiver can successfully extract secret data from the marked encrypted image. With both keys, the receiver can get secret data and the exactly original image. Compared with existing methods, experiments show the feasibility and efficiency of the proposed method, especially in aspect of embedding capacity, embedding quality and error-free recovery with increasing payload.
C1 [Zheng, Shuli; Li, Dandan; Hu, Donghui] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Ye, Dengpan; Wang, Lina] Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Jiangsu Network Monitoring Engn Ctr, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hefei University of Technology; Wuhan University; Nanjing University of
   Information Science & Technology
RP Zheng, SL (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM ZSL251@163.com; lidandan110506@126.com; hudh@hfut.edu.cn;
   yedp2001@163.com; lnawang@163.com; wjwei_2004@163.com
RI Wang, Li-Na/T-7047-2018
FU National Natural Science Foundation of China [61272540, 61272453,
   61232016]; Anhui Provincial Natural Science Foundation [1508085MF115];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD)
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61272540,61272453 and 61232016), the Anhui Provincial
   Natural Science Foundation(Grant No. 1508085MF115) and the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD).
CR [Anonymous], 2008, REVERSIBLE DATA HIDI
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen G, 2011, J SOFTW, V16, P1975
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   [顾勤龙 Gu Qinlong], 2003, [计算机工程与应用, Computer Engineering and Application], V39, P114
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 20
TC 35
Z9 36
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13765
EP 13778
DI 10.1007/s11042-015-2920-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800040
DA 2024-07-18
ER

PT J
AU Zhu, J
   Jiang, DD
   Yuan, YH
   Li, FW
AF Zhu, Jiang
   Jiang, Dingde
   Yuan, Ying-hui
   Li, Fang-wei
TI An evolutionary game theory-based channel access mechanism for wireless
   multimedia sensor network with rate-adaptive applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor network; Channel access mechanism;
   Evolutionary game theory; Dynamic equation; Nash equilibrium
ID POTENTIAL GAMES; SYSTEM
AB Wireless multimedia sensor networks are involved with rate-adaptive applications, such as video, audio and image, therefore, high bandwidth or throughput is demanded. To maximize the system throughput of the network, a channel access mechanism based on evolutionary game is proposed. Under the mechanism, users are assumed to be bounded rationality, in order to coordinate users' behavior in distributed manner, a new reward function is deduced. On the basis of the reward function, a dynamic channel access algorithm and corresponding dynamic equation are designed for the mechanism, which converge to Nash Equilibrium with faster speed. Theoretical analysis and simulation results show that the reward function proposed can realize the maximization of system throughput and higher normalized utilities of users under the framework of evolutionary game, and the corresponding dynamic equation is globally asymptotically stable, besides, when user deviates because of bounded rationality, the dynamic equation is still able to guarantee faster convergence and smaller performance deviation.
C1 [Zhu, Jiang; Yuan, Ying-hui; Li, Fang-wei] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Mobile Commun Technol, Chongqing, Peoples R China.
   [Jiang, Dingde] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Northeastern
   University - China
RP Zhu, J (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Mobile Commun Technol, Chongqing, Peoples R China.
EM zhujiang@cqupt.edu.cn
FU National Nature Science Foundation of China [61102062, 61271260,
   61571104]; Key Project of Chinese Ministry of Education [212145]; Nature
   Science Foundation of Chongqing Science and Technology Commission
   [cstc2015jcyjA40050]; Science and Technology Research Project of
   Chongqing Education Commission [KJ120530]
FX This work is supported by National Nature Science Foundation of China
   (No. 61102062, 61271260, 61571104) and Key Project of Chinese Ministry
   of Education (No.212145), the Nature Science Foundation of Chongqing
   Science and Technology Commission (No.cstc2015jcyjA40050), the Science
   and Technology Research Project of Chongqing Education Commission
   (No.KJ120530).
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Barth D, 2009, 3 INT WORKSH GAM THE, DOI [10.4108/ICST.VALUETOOLS2009.7775, DOI 10.4108/ICST.VALUETOOLS2009.7775]
   Neto JXC, 2013, J CONVEX ANAL, V20, P395
   Evans C, 2006, 2006 1ST INTERNATIONAL SYMPOSIUM ON PERVASIVE COMPUTING AND APPLICATIONS, PROCEEDINGS, P427, DOI 10.1109/SPCA.2006.297612
   Fang H, 2013, 2013 IEEE NINTH INTERNATIONAL CONFERENCE ON MOBILE AD-HOC AND SENSOR NETWORKS (MSN 2013), P127, DOI 10.1109/MSN.2013.48
   Goldsmith D, 2008, IEEE INT CONF INF VI, P539, DOI 10.1109/IV.2008.72
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Guo C, 2015, SOLITONS FRACTALS
   He B, 2014, J APPL MATH, DOI 10.1155/2014/294591
   Hu T, 2015, AD HOC NETW, V35, P127, DOI 10.1016/j.adhoc.2015.07.004
   Hwang J, 2010, SENSORS-BASEL, V10, P11189, DOI 10.3390/s101211189
   Jaramillo JJ, 2010, AD HOC NETW, V8, P416, DOI 10.1016/j.adhoc.2009.10.002
   Jiang CX, 2013, IEEE T WIREL COMMUN, V12, P2470, DOI 10.1109/TWC.2013.031813.121135
   Jiang D, 2015, J COMMUN NETW
   Jiang DD, 2016, TELECOMMUN SYST, V62, P771, DOI 10.1007/s11235-015-0111-9
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Khaday B, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P405, DOI 10.1109/ICARA.2015.7081182
   Li TL, 2015, IEEE INT C CL COMP, P516, DOI 10.1109/CLUSTER.2015.90
   Li X, 2017, MULTIMED TOOLS APPL, V76, P17801, DOI 10.1007/s11042-015-3095-2
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Messier GG, 2007, IEEE COMMUN LETT, V11, P13, DOI 10.1109/LCOMM.2007.061291
   Othman MF, 2012, PROCEDIA ENGINEER, V41, P1204, DOI 10.1016/j.proeng.2012.07.302
   Sandholm WH, 2001, J ECON THEORY, V97, P81, DOI 10.1006/jeth.2000.2696
   Sandholm WH, 2008, ENCY COMPLEXITY SYST
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   SHENKER S, 1995, IEEE J SEL AREA COMM, V13, P1176, DOI 10.1109/49.414637
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Sun Y, 2011, ADV MATER RES-SWITZ, V314-316, P2486, DOI 10.4028/www.scientific.net/AMR.314-316.2486
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Tomassini M, 2013, P 15 ANN C COMP GEN, P765, DOI [10.1145/2464576.2480808, DOI 10.1145/2464576.2480808]
   Wang JJY, 2015, ENG APPL ARTIF INTEL, V37, P1, DOI 10.1016/j.engappai.2014.08.009
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
   Wang K, 2015, IEEE INT C CL COMP, P236, DOI 10.1109/CLUSTER.2015.42
   Wang Y, 2014, P 26 INT C SCI STAT, P9
   Weibull J.W., 1997, Evolutionary Game Theory
   Wu DP, 2007, WIREL NETW, V13, P299, DOI 10.1007/s11276-006-7526-x
   Xie S. Y., 2001, J. Shanghai Univ. Finance Econ, V3, P3
   Xu YH, 2012, IEEE J-STSP, V6, P180, DOI 10.1109/JSTSP.2011.2176916
   Xu YH, 2012, CHINESE SCI BULL, V57, P125, DOI 10.1007/s11434-011-4775-6
   Yaacoub E, 2012, PROCEEDINGS OF THE 8TH ACM SYMPOSIUM ON QOS AND SECURITY FOR WIRELESS AND MOBILE NETWORKS, P79
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Yang L, 2013, IEEE ACM T NETWORK, V21, P522, DOI 10.1109/TNET.2012.2203827
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
   Zhao DF, 2014, IEEE INT CONF BIG DA, P61, DOI 10.1109/BigData.2014.7004214
   Zhao SS, 2012, J COMPUTATIONAL INFO, V8, P4225
NR 50
TC 3
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14329
EP 14349
DI 10.1007/s11042-016-3403-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500019
DA 2024-07-18
ER

PT J
AU Arab, F
   Abdullah, SM
   Hashim, SZM
   Manaf, AA
   Zamani, M
AF Arab, Farnaz
   Abdullah, Shahidan M.
   Hashim, Siti Zaiton Mohd
   Manaf, Azizah Abdul
   Zamani, Mazdak
TI A robust video watermarking technique for the tamper detection of
   surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Tamper detection; Surveillance systems
ID AUTHENTICATION
AB A digital watermark embeds an imperceptible signal into data such as audio, video and images, for different purposes including authentication and tamper detection. A real-time video surveillance application requires a large quantity of sequences to be processed, which makes computational efficiency an additional constraint on video watermarking for surveillance systems. As a result, spatial domain schemes are a more efficient than frequency domain schemes. This paper focuses on video watermarking, particularly with respect to the Audio Video Interleaved (AVI) form of video file format. It proposes two new watermarking schemes which seem to offer a high degree of imperceptibility and efficient tamper detection. Both schemes were subjected to nine different types of common attack, which revealed one scheme, VW8F, to be superior, particularly in terms of imperceptibility. VW8F was then compared with a range of similar schemes by other authors. The results show thatVW8F offers both improved imperceptibility (average PSNR of 47.87 dB) and proven efficiency at detecting a wider range of tampering compared to the other similar schemes.
C1 [Arab, Farnaz; Abdullah, Shahidan M.; Manaf, Azizah Abdul; Zamani, Mazdak] Univ Teknol Malaysia, Adv Informat Sch, Kuala Lumpur, Malaysia.
   [Arab, Farnaz; Hashim, Siti Zaiton Mohd] Univ Teknol Malaysia, Fac Comp, Skudai, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia
RP Arab, F (corresponding author), Univ Teknol Malaysia, Adv Informat Sch, Kuala Lumpur, Malaysia.; Arab, F (corresponding author), Univ Teknol Malaysia, Fac Comp, Skudai, Malaysia.
EM arab.farnaz@gmail.com; mshahidan@utm.my; sitizaiton@utm.my;
   azizaham.kl@utm.my; zamani.mazdak@gmail.com
RI Hashim, Siti Zaiton Mohd/AAE-5401-2020; shahidan, abdullah
   mohd/A-2719-2014; Manaf, Azizah Abdul/Q-4838-2019; Zamani,
   Mazdak/A-1687-2013
OI Zamani, Mazdak/0000-0002-6421-0053
CR Agarwal H, 2012, INT J IMAGE GRAPHICS, V4
   Amira H, 2010, INT MULT SYST SIGN D, P1
   [Anonymous], 2011, International Journal of Wisdom Based Computing
   Chaluvadi Surya Bhagavan, 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P993, DOI 10.1109/NABIC.2009.5393888
   Chimanna MA, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P613, DOI 10.1109/ICICES.2013.6508357
   DO H, 2008, SIGN PROC INF TECHN, P330
   Duanquan Xu, 2010, Proceedings 2010 International Conference on Computational Intelligence and Security (CIS 2010), P654, DOI 10.1109/CIS.2010.147
   Garibotto G, 2013, LECT NOTES COMPUT SC, V8157, P721, DOI 10.1007/978-3-642-41184-7_73
   Giovanni B, 2009, 3 ACM IEEE INT C DIS
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hasnaoui M, 2012, EUR SIGNAL PR CONF, P1782
   He HJ, 2011, MULTIMED TOOLS APPL, V52, P307, DOI 10.1007/s11042-010-0474-6
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Ishtiaq M, 2009, COMM COM INF SC, V61, P177
   Jin XM, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1, DOI 10.1109/ITNG.2009.10
   Luo T, 2014, MULTIMED TOOLS APPL, V73, P1077, DOI 10.1007/s11042-013-1435-7
   Min Liu, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P77, DOI 10.1109/ICCSEE.2012.391
   Nithyanandam S, 2011, PROC AUT CONTR COMP, P1
   Po-Chyi Su, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P742, DOI 10.1109/MMSP.2008.4665173
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Tokar T, 2009, 2009 19 INT C RAD IC, P319
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   van Schyndel Ron, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P343, DOI 10.1109/DICTA.2010.65
   Xing Chang, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P61, DOI 10.1109/ICNC.2011.6022111
   Xue JX, 2011, PROCEDIA ENGINEER, V24, P90, DOI 10.1016/j.proeng.2011.11.2607
   Yu PF, 2014, APPL MECH MATER, V457-458, P893, DOI 10.4028/www.scientific.net/AMM.457-458.893
   Zhaoqing Liu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P382, DOI 10.1109/IIH-MSP.2009.273
NR 27
TC 26
Z9 26
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10855
EP 10885
DI 10.1007/s11042-015-2800-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900003
DA 2024-07-18
ER

PT J
AU Chen, HP
   Shen, XJ
   Long, JW
AF Chen, Hai-peng
   Shen, Xuan-Jing
   Long, Jian-Wu
TI Histogram-based colour image fuzzy clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colour image segmentation; Histogram; Clustering; FCM algorithm
ID SEGMENTATION
AB In this work, a histogram-based colour image fuzzy clustering algorithm is proposed for addressing the problem of low efficiency due to computational complexity and poor clustering performance. Firstly, the presented scheme constructs the red, green and blue (short for RGB) component histograms of a given colour image, each of which is pre-processed to preserve their smoothness. Secondly, the proposed algorithm multi-thresholds each component histogram, using some dominant valleys identified from a fast peak-valley location scheme in each global histogram. Thirdly, a new histogram is reconstructed by applying a histogram merging scheme to the RGB three-component histograms, and multi-thresholding this new histogram again using some dominant valleys obtained from the fast peak-valley location scheme. Thus, the proposed approach can easily identify the initialisation condition of cluster centroids and centroid number. Finally, we construct a new dataset composed of some pre-segmented small regions using the WaterShed algorithm, and the FCM (Fuzzy C-Means) algorithm is executed on this dataset, instead of on pixels, in combination with the initial cluster centroids. Experimental results have demonstrated that the proposed algorithm is more efficient than the DSRPCL (Distance Sensitive Rival Penalised Competitive Learning) algorithm and the HTFCM (Histogram Thresholding Fuzzy C-Means) algorithm with respect to run times and PRI (Probability Rand Index) values.
C1 [Chen, Hai-peng; Shen, Xuan-Jing] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Chen, Hai-peng; Shen, Xuan-Jing] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Long, Jian-Wu] Chongqing Univ Technol, Coll Comp Sci & Engn, Chongqing 400045, Peoples R China.
C3 Jilin University; Jilin University; Chongqing University of Technology
RP Chen, HP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Chen, HP (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM chenhp@jlu.edu.cn
CR CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   [龙建武 Long Jianwu], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P1420
   [龙建武 Long Jianwu], 2012, [自动化学报, Acta Automatica Sinica], V38, P1134
   Ma JW, 2006, IEEE T SYST MAN CY B, V36, P722, DOI 10.1109/TSMCB.2006.870633
   Mok PY, 2012, PATTERN RECOGN, V45, P3017, DOI 10.1016/j.patcog.2012.02.003
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Peng B, 2011, PATTERN RECOGN, V44, P2527, DOI 10.1016/j.patcog.2011.03.024
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Shen Xuan-jing, 2011, Acta Electronica Sinica, V39, P1108
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Vantaram SR, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040901
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wei Wei, 2011, Acta Automatica Sinica, V37, P944, DOI 10.3724/SP.J.1004.2011.00944
   Yu ZD, 2010, PATTERN RECOGN, V43, P1889, DOI 10.1016/j.patcog.2009.11.015
NR 18
TC 12
Z9 12
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11417
EP 11432
DI 10.1007/s11042-015-2860-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900027
DA 2024-07-18
ER

PT J
AU Chmiel, W
   Danda, J
   Dziech, A
   Ernst, S
   Kadluczka, P
   Mikrut, Z
   Pawlik, P
   Szwed, P
   Wojnicki, I
AF Chmiel, Wojciech
   Danda, Jacek
   Dziech, Andrzej
   Ernst, Sebastian
   Kadluczka, Piotr
   Mikrut, Zbigniew
   Pawlik, Piotr
   Szwed, Piotr
   Wojnicki, Igor
TI INSIGMA: an intelligent transportation system for urban mobility
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportation systems; Video detector; GPS; Architecture;
   Route planning; Traffic control
ID RISK-ASSESSMENT; MAP
AB Intelligent Transportation Systems (ITS) aim to improve safety, mobility and environmental performance of road transport. The INSIGMA project provides a fresh look at the possible innovations in this field, by enhancing the functionality and accuracy of ITS in urban environments. This paper describes the architecture, sensors, processing algorithms, output modules and advantages of the developed system. A comparison of existing ITS systems has been provided as background. Special attention has been given to performance and privacy issues, as the system includes social aspects such as location monitoring.
C1 [Chmiel, Wojciech; Danda, Jacek; Dziech, Andrzej; Ernst, Sebastian; Kadluczka, Piotr; Mikrut, Zbigniew; Pawlik, Piotr; Szwed, Piotr; Wojnicki, Igor] AGH Univ Sci & Technol, Krakow, Poland.
C3 AGH University of Krakow
RP Ernst, S (corresponding author), AGH Univ Sci & Technol, Krakow, Poland.
EM wch@agh.edu.pl; danda@agh.edu.pl; adzie@kt.agh.edu.pl; ernst@agh.edu.pl;
   pkad@agh.edu.pl; zibi@agh.edu.pl; piotrus@agh.edu.pl; pszwed@agh.edu.pl;
   wojnicki@agh.edu.pl
RI Danda, Jacek/A-1191-2013; Chmiel, Wojciech/K-1011-2019; Szwed,
   Piotr/C-8474-2013; Wojnicki, Igor/ABI-2085-2020; Ernst,
   Sebastian/A-3705-2015
OI Chmiel, Wojciech/0000-0002-4773-9123; Szwed, Piotr/0000-0003-1231-3867;
   Wojnicki, Igor/0000-0002-4406-4992; Ernst, Sebastian/0000-0001-8983-480X
FU European Regional Development Fund under the Innovative Economy
   Operational Programme, INSIGMA project [POIG.01.01.02-00-062/09]
FX Work has been co-financed by the European Regional Development Fund
   under the Innovative Economy Operational Programme, INSIGMA project no.
   POIG.01.01.02-00-062/09.
CR Adamski A, 2014, INTELLIGENT RECOGNIT
   Administration NHTS, 2004, TECH REP, P2004
   [Anonymous], 1999, INTELLIGENT TRANSPOR
   [Anonymous], TECH REP
   [Anonymous], 1959, LMSD285875
   [Anonymous], ADV SAFETY VEHICLE P
   [Anonymous], 2009, MARKOV DECISION PROC
   Baran R, 2015, MULTIMED TOOLS APPL, V74, P4269, DOI 10.1007/s11042-013-1545-2
   Baran R, 2014, COMM COM INF SC, V429, P1
   Brewczynski L, 2014, THESIS
   Chan Eric, 2012, COOPERATIVE CONTROL
   Chmiel W, 2015, COMM COM INF SC, V566, P195, DOI 10.1007/978-3-319-26404-2_16
   Chmiel W, 2014, COMM COM INF SC, V429, P58
   Chmiel W, 2011, COMM COM INF SC, V149, P174
   Deloitte Research, 2003, COMB GRIDL PRIC ROAD
   Dziech A, 2013, IEEE CPS
   Dziech A., 2012, Patent App, Patent No. [13/524,609, 13524609]
   Fabiano B, 2005, DANGEROUS GOOD TRANS, V18
   Ference JJ, P PERF METR INT SYST, P23
   Gaborski R.S., 2007, J APPL SCI ENG TECHN, V1, P51
   Gleba K, 2013, MIL COMM INF SYST C, P1
   Glowacz A, 2008, EUROGR TECH REP SER, P76, DOI 10.1109/HSI.2008.4581412
   Glowacz A, 2012, COMM COM INF SC, V287, P118
   Janowski L, 2014, MULTIMED TOOLS APPL, V68, P23, DOI 10.1007/s11042-012-1199-5
   Kasera S, 2004, TATA MCGRAW HILL PRO
   Krajzewicz D., 2012, Int. J. Adv. Syst. Meas., V5, P128
   Li QJ, 2011, COMM COM INF SC, V202, P24
   McQueen B., 1999, AR HO IN TR SYST LIB
   Modsching Marko, 2006, P 3 WORKSH POS NAV C, V2006, P209
   Mohan P, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P323
   Montemanni R, 2002, TECH REP
   Naja Rola., 2013, WIRELESS VEHICULAR N
   Nathanail EG, 2010, TRANSP RES RECORD, P98, DOI 10.3141/2162-12
   Qi Y, 2009, TECH REP
   Quddus MA, 2007, TRANSPORT RES C-EMER, V15, P312, DOI 10.1016/j.trc.2007.05.002
   Ronchi E, 2012, TUNN UNDERGR SP TECH, V30, P74, DOI 10.1016/j.tust.2012.02.008
   Sheng-hai An, 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P332, DOI 10.1109/CICSyN.2011.76
   Sliwa J, 2011, LECT NOTES ARTIF INT, V6922, P602, DOI 10.1007/978-3-642-23935-9_59
   Szwed P, 2012, FED CONF COMPUT SCI, P9
   Szwed P, 2016, MULTIMED TOOLS APPL, V75, P10667, DOI 10.1007/s11042-014-2047-6
   Szwed P, 2013, COMM COM INF SC, V368, P248
   Szwed P, 2014, COMM COM INF SC, V424, P425
   Szwed P, 2014, LECT NOTES ARTIF INT, V8468, P579, DOI 10.1007/978-3-319-07176-3_51
   Szwed P, 2014, INT J AP MAT COM-POL, V24, P213, DOI 10.2478/amcs-2014-0016
   Tadeusiewicz R, 2011, INNOVATIONS INTELLIG, V339, P5
   Thiagarajan A, 2009, SENSYS 09: PROCEEDINGS OF THE 7TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P85
   U. S. Department of Transportation, 2014, VEH SAF COMM APPL VS
   U. S. Department of Transportation, 2015, VEH INFR INT VII
   U. S. Department of Transportation, 2014, INT VEH BAS SAF SYST
   van Diggelen F., 2007, GPS WORLD, V18, P26
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Volker L., 2008, Route Planning in Road Networks with Turn Costs
   Wang YY, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS, P222, DOI 10.1109/HIS.2009.51
   Wani K, 2006, P 13 ITS WORLD C
   Ward's Automotive Group, 2010, VEH OP COUNTR
   Wojnicki I, 2012, COMM COM INF SC, V287, P380
NR 56
TC 20
Z9 20
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10529
EP 10560
DI 10.1007/s11042-016-3367-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800021
OA hybrid
DA 2024-07-18
ER

PT J
AU Leszczuk, M
   Hanusiak, M
   Farias, MCQ
   Wyckens, E
   Heston, G
AF Leszczuk, Mikolaj
   Hanusiak, Mateusz
   Farias, Mylene C. Q.
   Wyckens, Emmanuel
   Heston, George
TI Recent developments in visual quality monitoring by key performance
   indicators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Quality; Metrics; Artifacts; VQEG; Video quality; Key performance
   indicators; KPI
ID ARTIFACTS
AB In addition to traditional Quality of Service (QoS), Quality of Experience (QoE) poses a real challenge for Internet service providers, audio-visual services, broadcasters and new Over-The-Top (OTT) services. Therefore, objective audio-visual metrics are frequently being dedicated in order to monitor, troubleshoot, investigate and set benchmarks of content applications working in real-time or off-line. The concept proposed here, Monitoring of Audio Visual Quality by Key Performance Indicators (MOAVI), is able to isolate and focus investigation, set-up algorithms, increase the monitoring period and guarantee better prediction of perceptual quality. MOAVI artefacts Key Performance Indicators (KPI) are classified into four categories, based on their origin: capturing, processing, transmission, and display. In the paper, we present experiments carried out over several steps with four experimental set-ups for concept verification. The methodology takes into the account annoyance visibility threshold. The experimental methodology is adapted from International Telecommunication Union - Telecommunication Standardization Sector (ITU-T) Recommendations: P.800, P.910 and P.930. We also present the results of KPI verification tests. Finally, we also describe the first implementation of MOAVI KPI in a commercial product: the NET-MOZAIC probe. Net Research, LLC, currently offers the probe as a part of NET-xTVMS Internet Protocol Television (IPTV) and Cable Television (CATV) monitoring system.
C1 [Leszczuk, Mikolaj; Hanusiak, Mateusz] AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
   [Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, Brasilia, DF, Brazil.
   [Wyckens, Emmanuel] Orange Labs, Rennes, France.
   [Heston, George] Net Res, 8201 Greensboro Dr,Suite 300, Mclean, VA 22102 USA.
C3 AGH University of Krakow; Universidade de Brasilia; Orange SA
RP Leszczuk, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM leszczuk@agh.edu.pl; mateusz.hanusiak@gmail.com; mylene@ieee.org;
   emmanuel.wyckens@orange.com; geohes@netrsr.com
RI Leszczuk, Mikołaj I/C-4857-2011; Farias, Mylene/C-4900-2015
OI Leszczuk, Mikołaj I/0000-0001-9123-1039; Farias,
   Mylene/0000-0002-1957-9943
FU European Regional Development Fund under the Innovative Economy
   Operational Program, INSIGMA project [POIG 01.01.02-00-062/09-00]
FX The research leading to these results has received funding from the
   European Regional Development Fund under the Innovative Economy
   Operational Program, INSIGMA project No POIG 01.01.02-00-062/09-00.
CR [Anonymous], 2011, OBJ PERC MULT VID QU
   [Anonymous], 2011, IEEE INT C MULT EXP
   [Anonymous], OBJ PERC MULT VID QU
   Cerqueira E, 2009, LECT NOTES COMPUT SC, V5630, P242, DOI 10.1007/978-3-642-02472-6_26
   Farias M. C. Q, 2013, 7 INT WORKSH VID PRO, V1
   Farias MCQ, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.043013
   Gustafsson J, 2008, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2008.4711777
   International Telecommunication Union, 1996, METH SUBJ DET TRASM
   International Telecommunication Union, 2008, PERC IS QUAL MEAS TE
   International Telecommunication Union, 2009, METH SUBJ ASS QUAL T
   International Telecommunication Union, 1996, PRINC REF IMP SYST V
   International Telecommunication Union, 2004, OBJ PERC VID QUAL ME
   International TelecommunicationUnion, 2011, OBJ MULT VID QUAL ME
   International TelecommunicationUnion, 2010, PERC VID QUAL MEAS T
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   Leszczuk M., 2013, MUSCLE INT WORKSH CO, P6
   P ITU-T RECOMMENDATION, 1999, SUBJ VID QUAL ASS ME
   Punchihewa A, 2002, IMAGE VISION COMPUTI
   Rohaly A. M, 2000, VIDEO QUALITY EXPERT
   Romaniak P, 2012, CONSUM COMM NETWORK, P597, DOI 10.1109/CCNC.2012.6181021
   Takahashi A., 2008, NTT TECHNICAL REV, V6, P1
   Takahashi A, 2010, TECH REP
   van Kester S, 2011, PROC SPIE, V7865, DOI 10.1117/12.873390
   Wyckens E, 2011, HILLSB M OR LABS VID
NR 24
TC 19
Z9 19
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10745
EP 10767
DI 10.1007/s11042-014-2229-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800032
OA hybrid
DA 2024-07-18
ER

PT J
AU Lin, TL
   Chen, WC
   Fan, CY
   Lee, HC
   Ding, TL
   Wang, CJ
   Chen, SL
   Hsia, CH
AF Lin, Ting-Lan
   Chen, Wen-Chih
   Fan, Chang-Yi
   Lee, Hsin-Chin
   Ding, Tsai-Ling
   Wang, Chuan-Jia
   Chen, Shih-Lun
   Hsia, Chih-Hsien
TI Switching error concealment algorithm based on optimal decisions for
   performance and complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion vector recovery; H.264; Video packet loss; Error concealment
ID VECTOR RECOVERY ALGORITHM; EFFICIENT
AB The proposed paper discusses two switching error concealment algorithms: SECA (Switching Error Concealment Algorithm) and OSECA (Optimal Switching Error Concealment Algorithm) to efficiently switch among three existing error concealment methods for optimal performance and complexity tradeoff. SECA uses the motion vector statistics in the neighborhood of the lost MB (Macro Block) to make the switching decision. SECA is better than the best-PSNR method by 0.14 dB in PSNR and better than the best-win-rate method by 1.49 % in win rate, with 63 % time complexity reduction. OSECA further considers the correlation between surrounding pixels of the lost MB and the pixels in the reference frame. An optimization problem is formulated to derive the optimal decision thresholds. For OSECA, the PSNR performance is further improved by 0.24 dB from SECA and the time complexity reduction from the existing work can increase to 69 %. On different testing sets of the lost MBs, the proposed SECA and OSECA perform consistently against existing methods. Compared to SECA in the testing sets, OSECA has larger PSNR improvement (by up to 0.23 dB) against the best-PSNR method, and has larger time complexity reduction (by up to 71 %) against existing method.
C1 [Lin, Ting-Lan; Chen, Wen-Chih; Fan, Chang-Yi; Lee, Hsin-Chin; Ding, Tsai-Ling; Wang, Chuan-Jia; Chen, Shih-Lun] Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
   [Hsia, Chih-Hsien] Chinese Culture Univ, Dept Elect Engn, 325 Da Yi Bldg,55,Hua Kang Rd, Taipei 11114, Taiwan.
C3 Chung Yuan Christian University; Chinese Culture University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
EM tinglan@cycu.edu.tw; g10076032@cycu.edu.tw; g10076027@cycu.edu.tw;
   g10176023@cycu.edu.tw; g10376001@cycu.edu.tw; g10376014@cycu.edu.tw;
   chrischen@cycu.edu.tw; chhsia625@gmail.com
RI Chen, Shih-Lun/AFF-8659-2022
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU National Science Council, Taiwan [NSC 100-2218-E-033-004, NSC
   101-2221-E-033-036, NSC 102-2221-E-033-018]; Ministry of Science and
   Technology, Taiwan [MOST 103-2221-E-033-020, MOST 103-2221-E-033-070,
   MOST-103-2221-E-034-010]
FX The authors would like to thank the anonymous reviewers of their paper
   for the many helpful suggestions. This research is supported by the
   National Science Council, Taiwan under Grant NSC 100-2218-E-033-004, NSC
   101-2221-E-033-036, NSC 102-2221-E-033-018, and by the Ministry of
   Science and Technology, Taiwan under Grant MOST 103-2221-E-033-020, MOST
   103-2221-E-033-070 and MOST-103-2221-E-034-010.
CR Chen C, 2008, IEEE T CONSUM ELECTR, V54, P1422, DOI 10.1109/TCE.2008.4637636
   Chen WC, 2013, I SYMP CONSUM ELECTR, P47
   Chen XM, 2010, IEEE T CONSUM ELECTR, V56, P2694, DOI 10.1109/TCE.2010.5681158
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chien JT, 2010, IEEE T CONSUM ELECTR, V56, P1689, DOI 10.1109/TCE.2010.5606314
   Hsia SC, 2004, IEEE SIGNAL PROC LET, V11, P577, DOI 10.1109/LSP.2004.827916
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1811, DOI 10.1109/TCE.2008.4711239
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Persson D, 2008, IEEE T IMAGE PROCESS, V17, P145, DOI 10.1109/TIP.2007.914151
   Persson D, 2009, IEEE T IMAGE PROCESS, V18, P1048, DOI 10.1109/TIP.2009.2014261
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Seth K, 2010, IEEE T BROADCAST, V56, P467, DOI 10.1109/TBC.2010.2058030
   Tröger T, 2011, IEEE T BROADCAST, V57, P777, DOI 10.1109/TBC.2011.2173813
   Valente S, 2001, IEEE T CONSUM ELECTR, V47, P568, DOI 10.1109/30.964147
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Xu YL, 2008, IEEE T CONSUM ELECTR, V54, P1846, DOI 10.1109/TCE.2008.4711244
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhang YB, 2012, IEEE T CIRC SYST VID, V22, P12, DOI 10.1109/TCSVT.2011.2130450
   Zheng JH, 2005, IEEE T MULTIMEDIA, V7, P507, DOI 10.1109/TMM.2005.843343
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
NR 21
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11199
EP 11219
DI 10.1007/s11042-015-2841-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900017
DA 2024-07-18
ER

PT J
AU Pan, LL
   Yan, WD
   Zheng, HC
AF Pan, Lulu
   Yan, Weidong
   Zheng, Hongchan
TI Super-resolution from a single image based on local self-similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Local self-similarity; Learning-based
ID LIMITS
AB Super-resolution from a single image plays an important role in many areas. However, it is still a challenging work, especially in the high-resolution image's quality and the algorithm's efficiency. To obtain high-resolution images, a new single image super-resolution technique that extends existing learning-based super-resolution frameworks is presented in this paper. We don't use any external example database or image pyramid to learn the missing details, and propose a single image SR method by learning local self-similarities from the original image itself. To synthesize the missing details, we design new filters which based on principles that model the super-resolution process, and use the new filters to establish the HR-LR patch pairs using the original image and its downsampled version. To obtain the SR image, we adopt a gradual magnification scheme to upscale the original image to the desired size step by step. In addition, to control the iterative error, we use the original image to guide the details added. Experimental results demonstrate that the proposed method is very flexible and give good empirical results.
C1 [Pan, Lulu; Yan, Weidong; Zheng, Hongchan] Northwestern Polytech Univ, Sch Sci, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Pan, LL (corresponding author), Northwestern Polytech Univ, Sch Sci, Xian 710072, Peoples R China.
EM panlulu@nwpu.edu.cn
OI Yan, Weidong/0000-0003-1226-8621; Pan, Lulu/0000-0001-7203-4291
FU National Natural Science Foundation of China [61070233, 61201323];
   Natural Science Foundation projects of Shaanxi Province [2014JQ5189]
FX This work was supported by the National Natural Science Foundation of
   China(No. 61070233,61201323), and Natural Science Foundation projects of
   Shaanxi Province(No. 2014JQ5189).
CR Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852
   Ben-Ezra M, 2007, ICCV
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai S., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383028
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Jamed DF, 1990, COMPUTER GRAPHICS PR
   Kim KI, 2008, LECT NOTES COMPUT SC, V5096, P456
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lane RO, 2010, IET RADAR SONAR NAV, V4, P639, DOI 10.1049/iet-rsn.2009.0094
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Morse BS, 2001, PROC CVPR IEEE, P333
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Tipping M. E., 2003, ADV NEURAL INFORM PR, P1303
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
NR 28
TC 7
Z9 7
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11037
EP 11057
DI 10.1007/s11042-015-2834-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900011
DA 2024-07-18
ER

PT J
AU Yan, SF
   Tang, GM
   Chen, YL
AF Yan, Shufan
   Tang, Guangming
   Chen, Yanling
TI Incorporating data hiding into G.729 speech codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE G.729 codec; Low bit-rate speech; Steganography; Fixed codebook search
ID STEGANOGRAPHY; VOICE
AB The rapid development of speech communication technology has made it possible for low bit-rate speech to become appropriate steganographic cover media. To incorporate data hiding into the low bit-rate speech codec, a novel steganography algorithm is proposed in this paper. By analyzing the encoding rule of fixed codebook vector, the way of transposing encoding locations of adjacent pulses is found to be suitable for data embedding with good imperceptibility. Based on encoding location transposition of adjacent pulses, the relationship between adjacent pulse locations is used to embed secret data while the fixed codebook search is being conducted during the encoding process of G.729 codec, which can maintain synchronization between data embedding and speech encoding. The experimental results demonstrate that the proposed steganography algorithm performs well in imperceptibility with a hiding capacity of 550 bits/s. Furthermore, the real-time and anti-detection performances are also satisfactory.
C1 [Yan, Shufan; Chen, Yanling] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
   [Tang, Guangming] Zhengzhou Informat Sci & Technol Inst, Dept Informat Secur, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Yan, SF (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM yansfluk@163.com
RI chen, yanling/GRE-8287-2022; TANG, Guang-Ming/E-5315-2013
CR [Anonymous], INT J ADV COMPUTING
   [Anonymous], 1991, AN4 DATABASE
   [Anonymous], 2009, IEEE INT C COMM 2009
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   ITU-T, 2002, E MOD COMP MOD US TR
   ITU-T Recommendation P, 2001, REC P 862 PERC EV SP
   Jin Liu, 2012, IEEE International Conference on Communications (ICC 2012), P1133, DOI 10.1109/ICC.2012.6363997
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Mazurczyk W, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543587
   Su YM, 2006, 2006 IMACS: Multiconference on Computational Engineering in Systems Applications, Vols 1 and 2, P11
   Tang SY, 2016, SECUR COMMUN NETW, V9, P747, DOI 10.1002/sec.1183
   Tian H, 2014, MULTIMEDIA SYST, V20, P143, DOI 10.1007/s00530-013-0302-8
   Tian H, 2011, COMPUT COMMUN, V34, P2236, DOI 10.1016/j.comcom.2011.07.003
   Tian H, 2010, J CENT SOUTH UNIV T, V17, P1285, DOI 10.1007/s11771-010-0633-y
   Wei ZL, 2014, J AMB INTEL HUM COMP, V5, P601, DOI 10.1007/s12652-013-0212-9
   Wu ZJ, 2015, CHINESE J ELECTRON, V24, P157, DOI 10.1049/cje.2015.01.026
   Yan S, 2014, MATH PROBL ENG, V2014, P1, DOI DOI 10.1007/S11042-014-2265-Y
NR 17
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11493
EP 11512
DI 10.1007/s11042-015-2865-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900031
DA 2024-07-18
ER

PT J
AU Wang, JC
   Xu, H
   Cai, S
   Guo, J
AF Wang, Jiachun
   Xu, Hao
   Cai, Shen
   Guo, Juan
TI A rapid method for detecting objects with rectangular structures based
   on line correspondences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Rectangle detection; Homography with unknown
   parameter; Line correspondences; Rotated cuboid bound of camera centre
AB Rectangles commonly appear in man-made environments. This paper presents an approach for rapid detection of objects with rectangular structures. Considering that the object to be detected may have different textures, colors or other characteristics, only geometric structure information can be used for identification. Therefore, the key task in detecting rectangles is to acquire correct line correspondences. We analyze the reason why a basic frame of 2D homography computation and verification cannot meet the practical requirement for detection speed and then propose a two-step algorithm to solve the problem. First, we utilize a unified expression of homography between an unknown size rectangle and a quadrangle on the image to simplify the homography computation. Second, we propose a rotated cuboid bound constraint of the camera centre to rapidly remove incorrect homographies with unknown size parameters. Experiments with simulated and real data verify the correctness of our method.
C1 [Wang, Jiachun; Xu, Hao; Cai, Shen; Guo, Juan] Donghua Univ, Sch Comp Sci & Technol, 2999 Renmin North Load, Shanghai 201620, Peoples R China.
   [Xu, Hao] Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Peoples R China.
   [Guo, Juan] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai, Peoples R China.
C3 Donghua University; Xiamen University; East China Normal University
RP Cai, S (corresponding author), Donghua Univ, Sch Comp Sci & Technol, 2999 Renmin North Load, Shanghai 201620, Peoples R China.
EM Jiachun_Aeg@163.com; Johiten@gmail.com; hammer_cai@163.com;
   joann_g@163.com
RI Zhou, Jing/IVH-8073-2023; Liu, Chang/ISV-3950-2023; Liu,
   Kai/IST-6808-2023
FU China NSFC Program [61472075]; Fundamental Research Funds for the
   Central Universities [2232014D3-02, 15D110924]
FX This work was partially supported by China NSFC Program 61472075, the
   Fundamental Research Funds for the Central Universities 2232014D3-02 and
   15D110924.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Alemán-Flores M, 2014, PATTERN RECOGN, V47, P89, DOI 10.1016/j.patcog.2013.05.011
   Bhat K. K. Srikrishna, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P155, DOI 10.1109/3DV.2014.27
   Bu J, 2011, IEEE INT CON MULTI
   Cai S, 2012, APPL OPTICS, V51, P5369, DOI 10.1364/AO.51.005369
   Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gurdjos P, 2002, LECT NOTES COMPUT SC, V2353, P252
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Kim K, 2010, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2010.5540128
   Kosecká J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Proença H, 2014, MACH VISION APPL, V25, P763, DOI 10.1007/s00138-014-0593-6
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Woo J, 2008, INT C PATT RECOG, P156
   Zhang LL, 2013, J VIS COMMUN IMAGE R, V24, P794, DOI 10.1016/j.jvcir.2013.05.006
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 19
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9409
EP 9426
DI 10.1007/s11042-016-3345-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500031
DA 2024-07-18
ER

PT J
AU Fan, H
   Xiang, JH
   Zhao, L
AF Fan, Heng
   Xiang, Jinhai
   Zhao, Liang
TI Robust visual tracking via bag of superpixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Bag of superpixels (BoS); Appearance model; K-means
   algorithm
AB The Bag of Words (BoW) model is one of the most popular and effective image representation methods and has been drawn increasing interest in computer vision filed. However, little attention is paid on it in visual tracking. In this paper, a visual tracking method based on Bag of Superpixels (BoS) is proposed. In BoS, the training samples are oversegmented to generate enough superpixel patches. Then K-means algorithm is performed on the collected patches to form visual words of the target and a superpixel codebook is constructed. Finally the tracking is accomplished via searching for the highest likelihood between candidates and codebooks within Bayesian inference framework. In this process, an effective updating scheme is adopted to help our tracker resist occlusions and deformations. Experimental results demonstrate that the proposed method outperforms several state-of-the-art trackers.
C1 [Fan, Heng] Huazhong Agr Univ, Coll Engn, Wuhan 430070, Peoples R China.
   [Xiang, Jinhai; Zhao, Liang] Huazhong Agr Univ, Coll Informat, Wuhan 430070, Peoples R China.
C3 Huazhong Agricultural University; Huazhong Agricultural University
RP Xiang, JH (corresponding author), Huazhong Agr Univ, Coll Informat, Wuhan 430070, Peoples R China.
EM hfan@webmail.hzau.edu.cn; jimmy_xiang@mail.hzau.edu.cn;
   zhaoliang323@mail.hzau.edu.cn
OI Xiang, Jinhai/0000-0002-8923-5302
FU Fundamental Research Funds for the Central Universities [2014BQ083];
   Fundamental Research Funds for Central Universities [2014QC008]
FX Jinhai Xiang is supported by the Fundamental Research Funds for the
   Central Universities (Program No.2014BQ083). Liang Zhao is supported by
   the Fundamental Research Funds for Central Universities (Program
   No.2014QC008).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bolovinou A, 2013, PATTERN RECOGN, V46, P1039, DOI 10.1016/j.patcog.2012.07.024
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan H, 2015, J VIS COMMUN IMAGE R, V31, P54, DOI 10.1016/j.jvcir.2015.05.011
   Fan H, 2014, SCI WORLD J, DOI 10.1155/2014/402185
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Iosifidis A, 2014, PATTERN RECOGN LETT, V49, P224
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kumar P, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P694, DOI 10.1109/ICARCV.2008.4795602
   Li X., 2013, ACM T INTEL SYST TEC, V4, P2411
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tsagkatakis G, 2011, IEEE T CIRC SYST VID, V21, P1810, DOI 10.1109/TCSVT.2011.2133970
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Yang F, 2012, IET IMAGE PROCESS, V6, P115, DOI 10.1049/iet-ipr.2010.0127
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
NR 29
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8781
EP 8798
DI 10.1007/s11042-015-2790-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300029
DA 2024-07-18
ER

PT J
AU Shu, YC
   Wang, TJ
   Shao, GP
   Hu, CL
AF Shu, Yucheng
   Wang, Tianjiang
   Shao, Guangpu
   Hu, Chunlong
TI Discriminative transform of receptive field patterns for feature
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Receptive field; Discrete cosine transform; Feature representation;
   Image descriptor
ID TEXTURE; CLASSIFICATION
AB As reported by many neurophysiological researches, the receptive field is a basic and significant component in the human visual system. It has various kinds of properties such as orientation-selectivity, correlativity, etc. Motivated by these structural and functional properties, we propose in this paper a novel local image descriptor namely the Discriminative Transform of Receptive Field (DTRF). Specifically, around each sample pixel in the interest region, we define a low-level feature structure called Receptive Field Patterns (RFP) which is further divided into two components: the RFP-Center and RFP-Surround. Then, the local features are extracted based on Local Annular Discrete Cosine Transform (LADCT). At the descriptor construction stage, these features are pooled spatially to mimic the correlative property of receptive field. Image matching and classification experiments on four standard data set demonstrate that the proposed descriptor outperforms the state-of-the-art methods under various types of image transformations such as rotation and scaling changes, viewpoint changes, image blurring, JPEG compression, illumination changes, and image noise.
C1 [Shu, Yucheng; Wang, Tianjiang; Shao, Guangpu] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Hu, Chunlong] JiangSu Univ Sci & Technogly, 2 Mengxi Rd, Zhenjiang 212003, Jiangsu, Peoples R China.
C3 Huazhong University of Science & Technology
RP Shu, YC (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM shuyucheng@hust.edu.cn; huchunlong@just.edu.cn
FU National Natural Science Foundation of China [61073094, U1233119]
FX This work is partially supported by the National Natural Science
   Foundation of China(Grant 61073094 and U1233119).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2004, P 2004WORKSHOP STAT
   Balasubramanian V, 2009, J PHYSIOL-LONDON, V587, P2753, DOI 10.1113/jphysiol.2009.170704
   Chen Y, 2009, J VISION, V9, DOI 10.1167/9.9.12
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   HUBEL DAVID H., 1963, SCI AMER, V209, P54
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malone BJ, 2007, J NEUROPHYSIOL, V97, P407, DOI 10.1152/jn.00830.2006
   McGugin RW, 2012, P NATL ACAD SCI USA, V109, P17063, DOI 10.1073/pnas.1116333109
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nister David, 2006, CVPR
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140
   Saha S., 2000, ACM Cross Words Students Magazine, V6, P12
   Shadlen MN, 1998, J NEUROSCI, V18, P3870
   Shu Y, 2014, P IEEE, P5601
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tsao DY, 2006, SCIENCE, V311, P670, DOI 10.1126/science.1119983
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Winder S.A. J., 2007, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1
   Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
NR 35
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7495
EP 7517
DI 10.1007/s11042-015-2673-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600002
DA 2024-07-18
ER

PT J
AU Chen, CC
   Wu, WJ
   Chen, JL
AF Chen, Chien-Chang
   Wu, Wei-Jie
   Chen, Jun-Long
TI Highly efficient and secure multi-secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-secret image sharing; Symmetric; Secure; Boolean operation
ID VISUAL CRYPTOGRAPHY
AB This paper presents a novel highly efficient secret image sharing scheme that is symmetric, Boolean-based, secure, and enables multi-secret image sharing. The proposed (n, n) scheme involves sharing n secret images among n shared images and recovers all n secret images from n shared images, and losing any shared image prevents recovering any secret image. We propose a novel symmetric sharing-recovery function (SSRF) for performing sharing and recovery. The scheme is based on Boolean operations to attain low computational complexity and is more secure than previous Boolean-based schemes; it exhibits more randomness in each shared image, more randomness between two or more shared images, and higher shared image sensitivity. The experimental results showed that a similar CPU computation time is required for both generating shared images from secret images, and recovering secret images from shared images. Furthermore, the computation time of the SSRF is proportional to the number of secret images.
C1 [Chen, Chien-Chang; Wu, Wei-Jie; Chen, Jun-Long] Tamkang Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 Tamkang University
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI chen, junlong/KJL-8942-2024; Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
FU National Science Council of the Republic of China [MOST
   103-2221-E-032-051]
FX This paper was partially supported by the National Science Council of
   the Republic of China under contract MOST 103-2221-E-032-051.
CR Chen CC, 2014, INT J ELECTRON COMM, V5, P219
   Chen CC, 2008, J INF SCI ENG, V24, P1567
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen J, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993627
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Cheng CF, 2013, EVID-BASED COMPL ALT, V2013, DOI [10.1155/2013/613950, 10.1155/2013/958025]
   Dhara BC, 2012, J VIS COMMUN IMAGE R, V23, P313, DOI 10.1016/j.jvcir.2011.11.005
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Hsu HC, 2007, IMAGING SCI J, V55, P175, DOI 10.1179/174313107X176289
   Huang CP, 2010, J SYST SOFTWARE, V83, P517, DOI 10.1016/j.jss.2009.10.012
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Lima JB, 2013, SIGNAL PROCESS-IMAGE, V28, P1537, DOI 10.1016/j.image.2013.05.008
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1332, DOI 10.1109/APSCC.2008.223
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 25
TC 20
Z9 20
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7113
EP 7128
DI 10.1007/s11042-015-2634-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400021
DA 2024-07-18
ER

PT J
AU Chen, ST
   Huang, HN
   Kung, WM
   Hsu, CY
AF Chen, Shuo-Tsung
   Huang, Huang-Nan
   Kung, Woon-Man
   Hsu, Chih-Yu
TI Optimization-based image watermarking with integrated quantization
   embedding in the wavelet-domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Integrated; Quantization; DWT; Optimization
ID SINGULAR-VALUE DECOMPOSITION; SCHEME
AB This study presents an optimization-based image watermarking scheme with integrated quantization embedding. First, peak signal to noise ratio (PSNR) is rewritten as a performance index in matrix form. In order to guarantee the robustness, this study embeds a watermark into the low-frequency coefficients of discrete wavelet transform (DWT). Unlike traditional way of single-coefficient quantization, this study applies amplitude quantization to embed the watermark and then rewrite this amplitude quantization as a constraint with embedding state. Then, an optimization-based equation connecting the performance index and amplitude-quantization constraint is obtained. Second, Lagrange Principle is used to solve the equation and then the optimal results are applied to embed the watermark. In detection, the hidden watermark can be extracted without original image. Finally, the performance of the proposed scheme is evaluated by PSNR and BER.
C1 [Chen, Shuo-Tsung; Huang, Huang-Nan] Tunghai Univ, Dept Appl Math, Taichung 407, Taiwan.
   [Kung, Woon-Man] CCU, Coll Educ, Dept Exercise & Hlth Promot, Taipei, Taiwan.
   [Kung, Woon-Man] Lotung Poh Ai Hosp, Lo Hsu Fdn, Dept Neurosurg, Yilan 265, Taiwan.
   [Hsu, Chih-Yu] Chaoyang Univ Technol, Dept Informat & Commun Engn, Chaoyang 413, Taichung Cty, Taiwan.
   [Chen, Shuo-Tsung] Natl Formosa Univ, Dept Elect Engn, Huwei Township 632, Yunlin, Taiwan.
C3 Tunghai University; Chaoyang University of Technology; National Formosa
   University
RP Hsu, CY (corresponding author), Chaoyang Univ Technol, Dept Informat & Commun Engn, Chaoyang 413, Taichung Cty, Taiwan.
EM shough34@yahoo.com.tw; nhuang@thu.edu.tw; nskungwm@yahoo.com.tw;
   tccnchsu@gmail.com
RI Kung, Woon-Man/Q-3012-2019; Hsu, Chih-Yu/U-6407-2019
OI Kung, Woon-Man/0000-0001-8311-2902; Hsu, Chih-Yu/0000-0003-1074-8170;
   Huang, Huang-Nan/0000-0001-7387-0427
CR Alghoniemy M, 2000, PROC SPIE, V3971, P82, DOI 10.1117/12.385011
   Alghoniemy M, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P295, DOI 10.1145/319463.319629
   Anderson B., 1990, OPTIMAL CONTROL LINE
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Chae J., 1998, P SPIE INT SOC OPT E, VVI, P308
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P720, DOI 10.1049/iet-spr.2009.0187
   Chen ST, 2013, ADAPTIVE AUDIO WATER, P971
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Gaurav B, 2009, NEW ROBUST REFERENCE, P1
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lewis F.L., 1986, OPTIMAL CONTROL
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Z, 2012, BIOINFORMATICS, V28, P914, DOI 10.1093/bioinformatics/bts078
   Malay SP, 2004, IEEE IMAGE PROC, P2633
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Rao R.M., 2000, WAVELET TRANSFORMS I
   Ruanaidh J. J. K. O., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P207, DOI 10.1109/CVPR.1999.786940
   Sharkas M, 2006, 23 NAT RAD SCI C, P14
   [宿富林 Su Fulin], 2003, [电子与信息学报, Journal of electronics & information technology], V25, P295
   Xiao Liang, 2003, Journal of Computer Aided Design & Computer Graphics, V15, P200
   Yingkun H, 8 ACIS INT C SOFTW E
NR 26
TC 18
Z9 20
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5493
EP 5511
DI 10.1007/s11042-015-2522-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600007
DA 2024-07-18
ER

PT J
AU Jain, A
   Rajpal, N
AF Jain, Anchal
   Rajpal, Navin
TI A robust image encryption algorithm resistant to attacks using DNA and
   chaotic logistic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; DNA operation; Statistical attack;
   Differential attack
AB An image encryption technique using DNA (Deoxyribonucleic acid) operations and chaotic maps has been proposed in this paper. Firstly, the input image is DNA encoded and a mask is generated by using 1D chaotic map. This mask is added with the DNA encoded image using DNA addition. Intermediate result is DNA complemented with the help of a complement matrix produced by two 1D chaotic maps. Finally, the resultant matrix is permuted using 2D chaotic map followed by DNA decoding to get the cipher image. Proposed technique is totally invertible and it can resist known plain text attack, statistical attacks and differential attacks.
C1 [Jain, Anchal] Inderprastha Engn Coll, Dept Comp Sci & Engn, Ghaziabad, India.
   [Rajpal, Navin] GGSIP Univ, Univ Sch Informat & Commun Technol, Delhi, India.
C3 Inderprastha Engineering College; GGS Indraprastha University
RP Jain, A (corresponding author), Inderprastha Engn Coll, Dept Comp Sci & Engn, Ghaziabad, India.
EM anchalresearch10@gmail.com; navin_rajpal@yahoo.com
CR [Anonymous], 2002, IEEE CIRCUITS SYSTEM
   [Anonymous], 2000, DIMACS SERIES DISCRE
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Enzeng D, 2008, INT C INF MAN INN MA
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Jain A, 2012, IEEE NAT C COMP COMM
   Jain A, 2013, IEEE INT C MACH INT
   Liu HJ, 2008, IEEE INT C YOUNG COM
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Zhang Q, 2012, SCI WORLD J, DOI 10.1100/2012/286741
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
NR 24
TC 98
Z9 100
U1 1
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5455
EP 5472
DI 10.1007/s11042-015-2515-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600005
DA 2024-07-18
ER

PT J
AU Liu, Y
   Wang, J
   Fan, JH
   Gong, LH
AF Liu, Ye
   Wang, Jun
   Fan, Jinghui
   Gong, Lihua
TI Image encryption algorithm based on chaotic system and dynamic S-boxes
   composed of DNA sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; S-box; DNA sequence; Chaotic system
ID FRACTIONAL FOURIER-TRANSFORM; OPERATION; SCHEME; MAP
AB A new image encryption scheme based on dynamic S-boxes combined with chaotic system is proposed. Different from traditional diffusion methods based on DNA operations, dynamic S-boxes composed of DNA sequences are used to diffuse the pixel values of the image. Simulation results and security analysis show that the proposed algorithm has good performance and ability to resist common attacks.
C1 [Liu, Ye; Wang, Jun; Fan, Jinghui; Gong, Lihua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
C3 Nanchang University
RP Liu, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
EM liuye@ncu.edu.cn; wjncdx@163.com; jinghuifan@163.com; lhgong@ncu.edu.cn
FU National Natural Science Foundation of China [61262084, 61462061];
   Foundation for Young Scientists of Jiangxi Province (Jinggang Star)
   [20122BCB23002]; Opening Project of Key Laboratory of Image Processing
   and Pattern Recognition (Nanchang Hangkong University), Jiangxi Province
   [TX201204002]
FX This work was supported by the National Natural Science Foundation of
   China [grant number 61262084], [grant number 61462061]; the Foundation
   for Young Scientists of Jiangxi Province (Jinggang Star) [grant number
   20122BCB23002]; the Opening Project of Key Laboratory of Image
   Processing and Pattern Recognition (Nanchang Hangkong University),
   Jiangxi Province [grant number TX201204002].
CR Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Chen JX, 2014, NANO RES, P1
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Hermassi H., 2013, MULTIMED TOOLS APPL, P1
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Liu ZJ, 2013, OPT LASER TECHNOL, V47, P152, DOI 10.1016/j.optlastec.2012.09.007
   Liu ZJ, 2012, OPT LASER ENG, V50, P1352, DOI 10.1016/j.optlaseng.2012.05.021
   Liu ZJ, 2012, OPTIK, V123, P428, DOI 10.1016/j.ijleo.2011.04.022
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Rehm A., 1914, MULTIMED TOOLS APPL, VI, P1
   Shan MG, 2012, OPT COMMUN, V285, P4227, DOI 10.1016/j.optcom.2012.06.023
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tang Z, 2014, MULTIMED TOOLS APPL, P1, DOI 10.1007/s11042-014-1861-1
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2012, NONLINEAR DYNAM, V67, P365, DOI 10.1007/s11071-011-9984-7
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
NR 30
TC 81
Z9 87
U1 1
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4363
EP 4382
DI 10.1007/s11042-015-2479-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700010
DA 2024-07-18
ER

PT J
AU Moustakas, K
AF Moustakas, Konstantinos
TI 6DoF haptic rendering using distance maps over implicit representations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic rendering; Collision detection; Implicit representation; Support
   plane mapping
AB This paper presents a haptic rendering scheme based on distance maps over implicit surfaces. Using the successful concept of support planes and mappings, a support plane mapping formulation is used so as to generate a convex representation and efficiently perform collision detection. The proposed scheme enables, under specific assumptions, the analytical reconstruction of the rigid 3D object's surface, using the equations of the support planes and their respective distance map. As a direct consequence, the problem of calculating the force feedback can be analytically solved using only information about the 3D object's spatial transformation and position of the haptic interaction point. Moreover, several haptic effects are derived by the proposed mesh-free haptic rendering formulation. Experimental evaluation and computational complexity analysis demonstrates that the proposed approach can reduce significantly the computational cost when compared to existing methods.
C1 [Moustakas, Konstantinos] Univ Patras, Dept Elect & Comp Engn, Rion, Greece.
C3 University of Patras
RP Moustakas, K (corresponding author), Univ Patras, Dept Elect & Comp Engn, Rion, Greece.
EM moustakas@upatras.gr
OI Moustakas, Konstantinos/0000-0001-7617-227X
CR [Anonymous], P EUR BIRM UK
   [Anonymous], 2002, SURFACES
   [Anonymous], ACM S VIRT REAL SOFT
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   [Anonymous], 2008, HAPTIC RENDERING FDN
   Barbic Jernej, 2009, 2009 World Haptics Conference (WHC 2009), P393, DOI 10.1109/WHC.2009.4810910
   Barlit A, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P589
   Burdea G. C., 2003, Virtual reality technology
   Coming DS, 2008, IEEE T VIS COMPUT GR, V14, P1, DOI 10.1109/TVCG.2007.70405
   Conti F., 2005, IEEE World Haptics
   DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0
   Ericson C., 2005, Real-time collision detection
   Fuhrmann A., 2003, P GRAPHICON 2003, P58
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Laycock S. D., 2007, Computer Graphics Forum, V26, P50, DOI 10.1111/j.1467-8659.2007.00945.x
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Moustakas K, 2007, IEEE MULTIMEDIA, V14, P62, DOI 10.1109/MMUL.2007.10
   Moustakas K, 2007, IEEE T VIS COMPUT GR, V13, P80, DOI 10.1109/TVCG.2007.20
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Palmerius KL, 2008, IEEE T VIS COMPUT GR, V14, P263, DOI 10.1109/TVCG.2007.70409
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Sethian J., 1999, LEVEL SET METHODS FA
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Teschner M., 2004, Eurographics State-of-the-Art Report, P119
   Van Den Bergen G., 2003, Collision Detection in Interactive 3D Environments
   Vogiannou A, 2010, COMPUT GRAPH FORUM, V29, P1595, DOI 10.1111/j.1467-8659.2010.01768.x
NR 28
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4543
EP 4557
DI 10.1007/s11042-015-2490-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700018
DA 2024-07-18
ER

PT J
AU Rizzi, A
   Berolo, AJ
   Bonanomi, C
   Gadia, D
AF Rizzi, Alessandro
   Berolo, Anna Jerry
   Bonanomi, Cristian
   Gadia, Davide
TI Unsupervised digital movie restoration with spatial models of color
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital movie restoration; Color restoration; Spatial color algorithms;
   Color appearance; Unsupervised restoration; Restoration kickoff
ID RETINEX; ALGORITHM
AB In this paper, we present an efficient approach to digital color restoration, based on the idea of recovering the appearance of color rather than the original color signal, since, in most of the cases, for old films the original reference is missing, and new films or digital coding can be subject to severe gamut transformations. This approach is based on the application of algorithms inspired by the capabilities of the Human Vision System of automatically adjust to the variation of color and lightness in the scene. The proposed method allows more unsupervised restoration. We present an overview of the approach, characteristics of this family of algorithms, and restoration examples.
C1 [Rizzi, Alessandro; Berolo, Anna Jerry; Bonanomi, Cristian; Gadia, Davide] Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
C3 University of Milan
RP Gadia, D (corresponding author), Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
EM alessandro.rizzi@unimi.it; beroloanna@gmail.com;
   cristian.bonanomi@unimi.it; gadia@di.unimi.it
RI Gadia, Davide/P-6309-2016
OI Gadia, Davide/0000-0003-4491-9150; Bonanomi,
   Cristian/0000-0003-4515-9122
FU SMART-K project from Lombardy Region [30223187]; Italian Ministry of
   University and Research
FX The authors would like to thank Ferruccio and Rodolfo Musitelli, mentors
   and friends, for their longlasting support; Majed Chambah, Desiree
   Sabatini, Simone Brivio, Alice DeMauro, Sergio Toffetti, the National
   Industry Film Archive of Ivrea and Luigi Micheletti Foundation for their
   collaboration. This work has been partly funded by SMART-K project,
   grant n. 30223187 from Lombardy Region and Italian Ministry of
   University and Research.
CR [Anonymous], 2000, BUT CON MUS
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chambah M, 2006, P SOC PHOTO-OPT INS, V6059, pS590, DOI 10.1117/12.642414
   Chambah M., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4663, P98, DOI 10.1117/12.452979
   Chambah M., 2002, Machine Graphics & Vision, V11, P363
   European Brodcasting Union, 2001, PRES REUS FILM MAT T
   FERNANDO WAC, 2000, IEEE INT S CIRC SYST, V4, P709
   Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761
   Gatta C, 2006, IEE P-VIS IMAGE SIGN, V153, P357, DOI 10.1049/ip-vis:20050279
   Gavioli R., 1960, LA LUNGA CALZA VERDE
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   Gombrich Ernst H. J., 1960, ART ILLUSION STUDY P
   HAN S, 2000, P 12 WORKSH IM PROC
   HANJALIC A, 1996, P 1 INT WORKSH IM DA
   Harrison Helen P., 1997, Audiovisual Archives: A Practical Reader
   Kolas O., 2011, J IMAGING SCI TECHNO
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Marini D, 2000, IMAGE VISION COMPUT, V18, P1005, DOI 10.1016/S0262-8856(00)00037-8
   McCann J, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P1
   McCann J.J., 2011, ART SCI HDR IMAGING
   MCCANN JJ, 1976, VISION RES, V16, P445, DOI 10.1016/0042-6989(76)90020-1
   Musitelli F., 1961, CIUDAD PLAYA
   Olmi E., 1955, RACCONTO STURA
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Provenzi E, 2008, IEEE T PATTERN ANAL, V30, P1757, DOI 10.1109/TPAMI.2007.70827
   Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946
   Reilly J. M., 1998, STORAGE GUIDE COLOR
   Rizzi A, 2006, LECT NOTES COMPUT SC, V3736, P1
   Rizzi A, 2004, P SOC PHOTO-OPT INS, V5308, P1286, DOI 10.1117/12.525789
   Rizzi A, 2004, J ELECTRON IMAGING, V13, P75, DOI 10.1117/1.1635366
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Rizzi A., 2007, COLOR IMAGING
   Rizzi A., 2013, UNSUPERVISED DIGITAL
   Rizzi A, 2010, SMPTE MOTION IMAG J, V119, P33, DOI 10.5594/J17295
   Rui Y, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P237, DOI 10.1109/MMCS.1998.693648
   Ueda H., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P343, DOI 10.1145/108844.108939
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
   2004, J ELECT IMAGING, V13, P6
NR 39
TC 10
Z9 10
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3747
EP 3765
DI 10.1007/s11042-014-2064-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200010
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, J
   Cai, CH
   Li, L
   Li, CH
AF Chen, Jing
   Cai, Canhui
   Li, Li
   Li, Cuihua
TI Layered multiple description video coding using dual-tree discrete
   wavelet transform and H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description coding; Video coding; Layered coding; Dual-tree
   discrete wavelet transform; H.264/AVC
ID ALLOCATION
AB A novel hybrid layered multiple description video coding (HLMDVC) algorithm is proposed to provide a robust and flexible video transmission via unreliable networks, like Internet or the wireless network. First, the input video sequence is encoded by a standard H.264/AVC encoder in low bit rate to form the base layer, which is then duplicated to each description. Second, the 3D dual-tree discrete wavelet transform is performed on the difference between the reconstructed base layer and the input sequence to produce four wavelet coefficient trees. Then the noise shaping is used to reduce the redundancy of these coefficient trees. After that, the four sparse wavelet coefficient trees are separately encoded by 3D-SPIHT encoders. The resulted four bitstreams are partitioned into two groups, separately forming enhancement layers of two descriptions. The redundancy of the proposed multiple description video coding scheme can be easily adjusted by changing the bitrate of the base layer to fit for different transmission channels. The directional selectivity feature of 3D dual-tree discrete wavelet transform frees the enhancement layer coding from the time consuming motion estimation, such that no mismatch happens and the coding efficiency is improved. Simulation results have shown that the quality of the reconstructed video of the proposed HLMDVC algorithm is superior to that by the state-of-the-art multiple description video coding methods.
C1 [Chen, Jing; Li, Cuihua] Xiamen Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Chen, Jing; Cai, Canhui; Li, Li] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
C3 Xiamen University; Huaqiao University
RP Chen, J (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM chenjing8005@gmail.com; chcai@hqu.edu.cn; hababy@hqu.edu.cn;
   chli@xmu.edu.cn
FU National Natural Science Foundation of China [61372107, 61373077];
   Xiamen Key Science and Technology Project Foundation [3502Z20133024];
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China [20110121110020]; Class A Project of Fujian Province Department
   of Education [JA14300]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant No. 61372107 and 61373077), the Xiamen Key
   Science and Technology Project Foundation (Grant No. 3502Z20133024, the
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China (Grant No. 20110121110020), and the Class A Project of Fujian
   Province Department of Education (Grant No. JA14300).
CR [Anonymous], 1998, DUAL TREE COMPLEX WA
   Bernardini R, 2004, IEEE IMAGE PROC, P3213
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Dong M, 2013, IEEE IMAGE PROC, P1928, DOI 10.1109/ICIP.2013.6738397
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Hsiao CW, 2010, IEEE T CIRC SYST VID, V20, P76, DOI 10.1109/TCSVT.2009.2026973
   Jing Chen, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1296, DOI 10.1109/ICOSP.2008.4697369
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Radulovic I, 2010, IEEE T CIRC SYST VID, V20, P144, DOI 10.1109/TCSVT.2009.2026815
   Reeves TH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P597, DOI 10.1109/ICIP.2002.1039041
   Reibman AR, 2002, IEEE T CIRC SYST VID, V12, P193, DOI 10.1109/76.993440
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sun YC, 2014, MULTIMED TOOLS APPL, V72, P1411, DOI 10.1007/s11042-013-1434-8
   Tillier C, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/31319
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Vaishampayan V. A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P812, DOI 10.1109/ICIP.1999.817235
   Wang BB, 2004, IEEE IMAGE PROC, P1317
   Wang BB, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/42761
   Wei Z, 2006, IEEE IMAGE PROC, P3253, DOI 10.1109/ICIP.2006.312917
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
NR 21
TC 6
Z9 6
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2801
EP 2814
DI 10.1007/s11042-015-2546-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000025
DA 2024-07-18
ER

PT J
AU Kobayashi, G
   Hatakeyama, H
   Ota, K
   Nakada, Y
   Kaburagi, T
   Matsumoto, T
AF Kobayashi, Go
   Hatakeyama, Hiroki
   Ota, Kosuke
   Nakada, Yohei
   Kaburagi, Takashi
   Matsumoto, Takashi
TI Predicting viewer-perceived activity/dominance in soccer games with
   stick-breaking HMM using data from a fixed set of cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hidden Markov model; Sports movie analysis; Non-parametric Bayesian
   learning; Soccer game analysis; Time series modeling
ID HIDDEN MARKOV-MODELS; VIDEO; REGULARIZATION
AB We attempted to predict activity/dominance for soccer games, where activity is defined as the degree of activity of the game as perceived by the viewer, whereas dominance is the degree at which the viewer perceives a particular team to dominate over the other team. Such activity/dominance information would help a layman viewer understand the game. It would also enable construction of an automatic digest creation system that extracts scenes having high activity/dominance. There are two facets of this study: 1. The main part of the underlying prediction model consists of a Stick-Breaking Hidden Markov Model, where the data automatically estimates the number of states of the Markov process behind the data. 2. The data used in this paper is vector time-series data consisting of player, referee, and ball positions, together with team information, acquired by a set of fixed cameras. The problem was approached with a Bayesian framework where learning and prediction were implemented by three different methods: Markov Chain Monte Carlo, Expectation Maximization, and Variational Bayes. The proposed method was tested using a dataset consisting of 10 professional soccer games and was compared against standard regression methods.
C1 [Kobayashi, Go; Hatakeyama, Hiroki; Ota, Kosuke; Matsumoto, Takashi] Waseda Univ, Shinjuku Ku, 3-4-1 Ohkubo, Tokyo, Japan.
   [Nakada, Yohei] Meiji Univ, Nakano Ku, 4-21-1 Nakano, Tokyo 101, Japan.
   [Kaburagi, Takashi] Aoyama Gakuin Univ, Chuo Ku, 5-10-1 Fuchinobe, Sagamihara, Kanagawa, Japan.
C3 Waseda University; Meiji University; Aoyama Gakuin University
RP Kaburagi, T (corresponding author), Aoyama Gakuin Univ, Chuo Ku, 5-10-1 Fuchinobe, Sagamihara, Kanagawa, Japan.
EM y_nakada@meiji.ac.jp; kaburagi@ise.aoyama.ac.jp;
   takashi@matsumoto.elec.waseda.ac.jp
CR [Anonymous], P EUR S TIM SER PRED
   [Anonymous], ANN STAT, DOI DOI 10.1214/A0S/1176342360
   [Anonymous], INF MEDIA TECHNOL
   [Anonymous], IEIC TECHNICAL REPOR
   [Anonymous], 2 INT S INF THEOR
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], PATTERN ANAL APPL
   [Anonymous], NEUR NETW SIGN PROC
   [Anonymous], 1998, Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids
   [Anonymous], I ELECT INFORM COMUN
   [Anonymous], 2004, THESIS U COLL LONDON
   [Anonymous], CONTENT BASED REPRES
   [Anonymous], ACM SIGCHI C H UNPUB
   [Anonymous], INT C BROADC AS BROA
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Ding Y, 2007, COMPUTER VISION PATT, P1
   Duan L.Y., 2003, Proc. ACM Int. Conf. Multimedia, P33
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Goldwater S., 2007, P 45 ANN M ASS COMP, P744
   Green P.J., 1995, ANN STAT, V82, P711, DOI DOI 10.1093/BI0MET/82.4.711
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758
   Johnson M., 2007, P EMNLP CONLL
   Kimura T, 2013, PATTERN ANAL APPL, V16, P55, DOI 10.1007/s10044-011-0256-4
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Kupiec J., 1992, Computer Speech and Language, V6, P225, DOI 10.1016/0885-2308(92)90019-Z
   Mannens E, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P61, DOI 10.1109/WIAMIS.2009.5031432
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Paisley J, 2009, IEEE T SIGNAL PROCES, V57, P3905, DOI 10.1109/TSP.2009.2024987
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Schliep A, 2003, BIOINFORMATICS, V19, pi255, DOI 10.1093/bioinformatics/btg1036
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Scott SL, 2002, J AM STAT ASSOC, V97, P337, DOI 10.1198/016214502753479464
   Shih HC, 2005, IEEE T BROADCAST, V51, P449, DOI 10.1109/TBC.2005.854169
   Yasuda H, 2000, INT J PATTERN RECOGN, V14, P675, DOI 10.1142/S021800140000043X
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 41
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3081
EP 3119
DI 10.1007/s11042-014-2425-0
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600008
DA 2024-07-18
ER

PT J
AU Ou, DH
   Sun, W
AF Ou, Duanhao
   Sun, Wei
TI Meaningful (2, <i>i</i> <i>n</i> <i>f</i> <i>i</i> <i>n</i> <i>i</i>
   <i>t</i> <i>y</i>) secret image sharing scheme based on flipping
   operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; XOR operation; Flipping operation; Meaningful
   shares; (2, infinity)
ID ENCRYPTION; STEGANOGRAPHY
AB In this paper, a new method to construct a secret image sharing (SIS) scheme is proposed, where a secret image is shared into several shares by a perfect secure way without any knowledge of cryptography. A basic algorithm implemented by flipping operations with probability for constructing a meaningful (2, 2) SIS scheme is first proposed. Neither codebook tailor-made requirement nor pixel expansion is required in the proposed scheme. Additionally, the meaningful shares by the proposed scheme can be directly generated without any extra data hiding process. During the decrypting procedure, the secret image is visually revealed by performing XOR operations on two meaningful shares. In the following stage, a meaningful (2, i n f i n i t y) SIS scheme is extended underlying the basic algorithm, where the number of shares can be extended anytime. Further, no matter how large the number of the extended shares is, the visual qualities of both the meaningful share and revealed secret image remain unchanged. Finally, sufficient number of formal proofs are provided to validate the correctness of the proposed schemes, whose superiority is also demonstrated by the experimental results.
C1 [Ou, Duanhao] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Ou, DH (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.; Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM ouduanhao@163.com; sunwei@mail.sysu.edu.cn
FU 973 Program [2011CB302400]; Natural Science Foundation of Guangdong
   Province, China [S2013010013728]
FX This work was in part supported by 973 Program (Grant No. 2011CB302400)
   and Natural Science Foundation of Guangdong Province, China (Grant No.
   S2013010013728).
CR Ababneh S, 2009, J VIS COMMUN IMAGE R, V20, P303, DOI 10.1016/j.jvcir.2009.03.010
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chen SK, 2012, J VIS COMMUN IMAGE R, V23, P677, DOI 10.1016/j.jvcir.2012.03.004
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Koga H, 2006, DESIGN CODE CRYPTOGR, V40, P81, DOI 10.1007/s10623-005-6700-y
   Li HJ, 2009, OPT LASER ENG, V47, P45, DOI 10.1016/j.optlaseng.2008.08.001
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu F., 2010, OPTIMAL XOR BASED 2, V545
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Yan X., 2014, MULTIMED TOOLS APPL, P1
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 33
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3517
EP 3536
DI 10.1007/s11042-015-2462-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600028
DA 2024-07-18
ER

PT J
AU Shim, JY
   Kim, SW
AF Shim, Jae Youn
   Kim, Seong-Whan
TI LaserShoot: a natural shooting interface for FPS gaming using laser
   recognizable display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative space; Laser; Large screen; Computer games
AB In this paper, we present a new game interface design "LaserShoot" for collaborative First Person Shooters (FPS) games. Previously, gamers play FPS on computer using keyboard/mouse or joystick along with PC display. Currently, we should resort to CRT display technology for a realistic gun interface, because CRT display can detect gun shooting position by checking the beam direction. However, CRT technology cannot support large screen display due to its manufacturing limitation. To facilitate a collaborative and realistic environment for multi-players, we design a new natural input interface including a laser gun and a large screen display with laser spot detection capability (laser recognizable display). Our interface can create a real life-like collaborative space for gamers. Results suggest that the laser-based interface creates a natural user interface environments which helps beginners to enjoy playing a FPS immediately, and also gives experienced players a new gaming experience.
C1 [Shim, Jae Youn; Kim, Seong-Whan] Univ Seoul, Sch Comp Sci, 13 Siripdae Gil, Seoul 130743, South Korea.
C3 University of Seoul
RP Kim, SW (corresponding author), Univ Seoul, Sch Comp Sci, 13 Siripdae Gil, Seoul 130743, South Korea.
EM simpo@uos.ac.kr; swkim7@uos.ac.kr
CR [Anonymous], 2006, INTRO KALMAN FILTER
   Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308
   Beckhaus S, 2005, NEW GAMING DEVICE IN
   Cheok AD, 2004, PERS UBIQUIT COMPUT, V8, P71, DOI 10.1007/s00779-004-0267-x
   Cox JF, 2001, FUNDAMENTALS LINEAR, P91
   CTA Digital Inc, 2012, ASS RIFL CONTR PLAYS
   Dardas NH, 2014, MULTIMED TOOLS APPL, V70, P2211, DOI 10.1007/s11042-012-1236-4
   Gower J. C., 1969, APPL STAT, V18, DOI [10.2307/2346439, DOI 10.2307/2346439]
   Intersence Inc, 2006, INERTIACUBE2
   Jong-Won Yoon, 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P69, DOI 10.1109/ITW.2010.5593369
   Kasugai K., 2010, Proceedings of CREATE, V10, P62
   Luque A., 2011, Handbook of Photovoltaic Science and Engineering, P5
   MarcoDi N, 2012, UNDERSTANDING USING, P1
   Olivas A, 2012, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON INTERACCION PERSONA-ORDENADOR (INTERACCION'12), DOI 10.1145/2379636.2379687
   Opara FK, 2012, ACAD RES INT, V2
   RAJLICH P, CAVE QUAKE 2
   Shin JP, 2002, PATTERN RECOGN LETT, V23, P601, DOI 10.1016/S0167-8655(01)00136-2
   SHOCKLEY W, 1949, AT&T TECH J, V28, P435, DOI 10.1002/j.1538-7305.1949.tb03645.x
   Stellanet Inc, 2013, SPECTRAWIZ SPECTR
   Svelto O, 2010, PRINCIPLES LASERS, V2010, P407
   Tedjokusumo J, 2010, IEEE T SYST MAN CY A, V40, P147, DOI 10.1109/TSMCA.2009.2028432
   Yu F.T. S., 2002, FIBER OPTIC SENSORS
NR 22
TC 0
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3409
EP 3423
DI 10.1007/s11042-014-2442-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600023
DA 2024-07-18
ER

PT J
AU Zhou, YH
   Cheng, ZX
   Jing, L
AF Zhou, Yinghui
   Cheng, Zixue
   Jing, Lei
TI Threshold selection and adjustment for online segmentation of one-stroke
   finger gestures using single tri-axial accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable computing; Gesture recognition; Online segmentation; Adaptive
   threshold; One-stroke gestures
ID RECOGNITION
AB Online segmentation of continuous gestures is a key issue in accelerometer-based gesture recognition. The challenge is to segment short-duration, ambiguous, and individually different gestures by an accurate method for online applications. In this paper, we propose a threshold-based method for the online segmentation of one-stroke gestures using a single tri-axial accelerometer on a finger. The method first obtains a proper initial threshold based on Bayes decision theory to ensure accurate initial segmentation, and then an adaptation mechanism is designed to automatically adjust the threshold to improve user-dependent accuracy. A dataset of over 1,200 samples from 12 gestures and 25 subjects is created for evaluation. The results show that our method achieves high segmentation precision/recall and high user-dependent adaptability with low computational complexity.
C1 [Zhou, Yinghui] Univ Aizu, Grad Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
   [Cheng, Zixue; Jing, Lei] Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 University of Aizu; University of Aizu
RP Zhou, YH (corresponding author), Univ Aizu, Grad Sch Comp Sci & Engn, Ikki Machi, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM shueikei@gmail.com; z-cheng@u-aizu.ac.jp; leijing@u-aizu.ac.jp
FU Grants-in-Aid for Scientific Research [13J09319, 26730094] Funding
   Source: KAKEN
CR Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Benbasat AriY., 2001, International Gesture Workshop, P9
   Bulling A., 2013, ACM COMPUTING SURVEY
   Burch_eld T.R., 2007, P 1 ACM SIGMOBILE IN, P67
   Choe B, 2010, LECT NOTES COMPUT SC, V6444, P650, DOI 10.1007/978-3-642-17534-3_80
   DeVaul R., 2001, REAL TIME MOTION CLA
   Guo T., 2012, Proceedings of the Eleventh ACM International Workshop on Data Engineering for Wireless and Mobile Access, P7
   Helmi N, 2009, P 2009 IE INT S COMP
   Hoai M., 2012, P 25 IEEE C COMP VIS
   Jing L., 2011, 11 IEEE IPSJ INT S A
   Jing L, 2011, IEICE T INF SYST, VE94D, P1062, DOI 10.1587/transinf.E94.D.1062
   Junker H, 2008, PATTERN RECOGN, V41, P2010, DOI 10.1016/j.patcog.2007.11.016
   Kahol K, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P105
   Kasteren TV, 2008, P UB COMP 2008 SEOUL
   Kela J, 2006, PERS UBIQUIT COMPUT, V10, P285, DOI 10.1007/s00779-005-0033-8
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   Lester J, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P225
   Logan B, 2007, LECT NOTES COMPUT SC, V4717, P483
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Spriggs EH, 2009, P 1 WORKSH EG VIS MI
   Stikic M, 2008, 2008 2ND INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING TECHNOLOGIES FOR HEALTHCARE, P245
   Vahdatpour A, 2012, PERVASIVE MOB COMPUT, V7, P746
   Wu JH, 2009, LECT NOTES COMPUT SC, V5585, P25
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
   Zhou Y, 2012, P 5 IET INT C UB MED
NR 25
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9387
EP 9406
DI 10.1007/s11042-014-2111-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200015
DA 2024-07-18
ER

PT J
AU Abawajy, JH
   Fudzee, F
   Deris, MM
AF Abawajy, J. H.
   Fudzee, F.
   Deris, M. M.
TI Multimedia content adaptation service discovery mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service-oriented content adaptation; Distributed systems; QoS;
   Adaptation task; Service discovery; SLA
AB Electronic information is becoming increasingly rich in content and varied in format and style while at the same time client devices are getting increasingly varied in their capabilities. This mismatch between rich contents and the end devices capability presents a challenge in providing seamless and ubiquitous access to electronic documents to interested users. Service-oriented content adaptation has emerged as a potential solution to the content-device mismatch problem. Since an adaptation task can potentially be performed by multiple content adaptation services (CAS), an approach for CAS discovery is a fundamental component of service-oriented content adaptation environment. In this paper, we propose a service discovery approach that considers the client device capability and the service's attributes to discover appropriate CAS while optimizing performance and functionality. The efficiency of the proposed CAS discovery protocol is studied experimentally. The results show that the proposed discovery approach is effective in terms of discovering appropriate content adaptation services.
C1 [Abawajy, J. H.] Deakin Univ, Sch Informat Technol, Parallel & Distributed Comp Lab, Geelong, Vic 3217, Australia.
   [Fudzee, F.; Deris, M. M.] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Batu Pahat, Malaysia.
C3 Deakin University; University of Tun Hussein Onn Malaysia
RP Abawajy, JH (corresponding author), Deakin Univ, Sch Informat Technol, Parallel & Distributed Comp Lab, Geelong, Vic 3217, Australia.
EM jemal@deakin.edu.au
RI Deris, Mustafa Mat/D-4662-2013
OI Md Fudzee, Mohd Farhan/0000-0002-6801-2660
CR Azhan N.N., 2007, INT C MOB TECHN APPL, P552
   Ben Mokhtar S, 2008, J SYST SOFTWARE, V81, P785, DOI 10.1016/j.jss.2007.07.030
   Eder H., 2009, P IDEAS IT 16 18 SEP, P334
   Fawaz Y, 2008, INT J DIGIT MULTIMED, V2008, DOI 10.1155/2008/851628
   Fudzee Mohd Farhan Md, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P721, DOI 10.1109/CCGRID.2010.128
   Fudzee MFM, 2011, LECT NOTES COMPUT SC, V7017, P235, DOI 10.1007/978-3-642-24669-2_23
   Fudzee MFM, 2011, FUTURE GENER COMP SY, V27, P256, DOI 10.1016/j.future.2010.09.005
   Javadi B, 2008, CONCURR COMP-PRACT E, V20, P75, DOI 10.1002/cpe.1222
   Kritikos K, 2009, IEEE T SERV COMPUT, V2, P320, DOI 10.1109/TSC.2009.26
   Kritikos K, 2009, IEEE T SERV COMPUT, V2, P122, DOI 10.1109/TSC.2009.10
   Lai YC, 2007, COMPUT NETW, V51, P3220, DOI 10.1016/j.comnet.2007.01.018
   Lemma S, 2006, ADVANCES IN SYSTEMS, COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P25
   Md Fudzee M-F, 2010, DEV ADV WEB SERVICES
   Meditskos G, 2010, IEEE T KNOWL DATA EN, V22, P278, DOI 10.1109/TKDE.2009.89
   Merat S, 2008, ERPAS 10 INT C INF I, P626
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Plebani P, 2009, IEEE T KNOWL DATA EN, V21, P1629, DOI 10.1109/TKDE.2009.35
   Rosario Sidney, 2008, IEEE Transactions on Services Computing, V1, P187, DOI 10.1109/TSC.2008.17
   Song X, WORKFLOW FRAMEWORK I, DOI [10.1016/j.future.2010.06.008, DOI 10.1016/J.FUTURE.2010.06.008]
NR 19
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8365
EP 8378
DI 10.1007/s11042-013-1696-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600008
DA 2024-07-18
ER

PT J
AU Jung, SD
   Kim, JS
   Park, JW
   Won, JH
   Kim, MK
AF Jung, Sam Dong
   Kim, Jeong Soo
   Park, Jung Won
   Won, Jong Hwa
   Kim, Moon Kyum
TI Distinct element method analysis of a retaining wall using a steel frame
   and fill materials
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retaining wall; Cellular structure; Shear resistance; Fill materials;
   DEM
AB A technique is developed to clearly establish the shear resistance of a cellular structure, retaining wall composed of a steel frame and fill materials with both continuous and discontinuous characteristics. To overcome the limitation of the existing analysis approach based on continuum mechanics, in which the shear behavior and interaction between the frames and fill material of this type of structure are difficult to describe, this paper introduces displacement incremental analysis into the distinct element method. The results obtained by using the proposed approach are compared with experimental results to verify its accuracy. The results show an internal friction angle of fill materials and overburdening load are major factor determining the shear resistance of a retaining wall with a cellular structure type. From the results of the parametric study on the shear behavior of this type of structure, this paper also proposes a shear resistance moment-shear displacement formula for designing a retaining wall with a cellular structure type.
C1 [Jung, Sam Dong; Kim, Jeong Soo; Park, Jung Won; Won, Jong Hwa; Kim, Moon Kyum] Yonsei Univ, Dept Civil & Environm Engn, Seoul 120749, South Korea.
   [Jung, Sam Dong] Korea Inst Construct & Transportat Technol Evalua, R&D Planning Div, Anyang, South Korea.
   [Park, Jung Won] Korea Inst Construct & Transportat Technol Evalua, SOC, Anyang, South Korea.
   [Park, Jung Won] Korea Inst Construct & Transportat Technol Evalua, Plant Div, Anyang, South Korea.
   [Won, Jong Hwa] DSME R&D Inst, Subsea R&D Grp, Seoul, South Korea.
C3 Yonsei University
RP Kim, JS (corresponding author), Yonsei Univ, Dept Civil & Environm Engn, 50 Yonsei Ro, Seoul 120749, South Korea.
EM coffee1210@yonsei.ac.kr
FU National Research Foundation of Korea [2010-0026196]
FX This work was financially supported by the National Research Foundation
   of Korea (No. 2010-0026196).
CR Cummings EM, 1960, ASCE, V125, P13
   Hansen J.B., 1953, EARTH PRESSURE CALCU
   Jung SD, 2012, LNEE, V215, P1133
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Ovensen NK, 1962, CALCULATION METHOD M
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Terzahi K, 1945, ASCE, V71, P980
NR 9
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9017
EP 9029
DI 10.1007/s11042-013-1534-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600023
DA 2024-07-18
ER

PT J
AU Nasridinov, A
   Ihm, SY
   Park, YH
AF Nasridinov, Aziz
   Ihm, Sun-Young
   Park, Young-Ho
TI A hybrid construction of a decision tree for multimedia contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia contents; GPU computing; CUDA; Decision tree
AB The growing availability of large amounts of multimedia contents in science and industry have made data mining applications such as data classification highly demanding. The contribution of this paper is two-fold. First, we propose an approach for constructing a decision tree based classification model for multimedia contents. Second, in order to speed up the performance of the proposed model, we propose a hybrid CPU-GPU approach for construction of decision tree on Graphic Processing Unit (GPU). Our approach not only accelerates the construction of decision tree via GPU computing, but also does so by considering the power and energy consumption of the GPU. Through the experiments, we demonstrate that the proposed hybrid CPU-GPU approach outperforms CPU-based sequential implementation by several times.
C1 [Nasridinov, Aziz; Ihm, Sun-Young; Park, Young-Ho] Sookmyung Womens Univ, Dept Multimedia Sci, Seoul 140742, South Korea.
C3 Sookmyung Women's University
RP Park, YH (corresponding author), Sookmyung Womens Univ, Dept Multimedia Sci, Cheongpa Ro 47 Gil 100, Seoul 140742, South Korea.
EM aziz@sm.ac.kr; sunnyihm@sm.ac.kr; yhpark@sm.ac.kr
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education, Science and Technology [2012003797]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2012003797).
CR Basak J, 2005, IEEE T KNOWL DATA EN, V17, P121, DOI 10.1109/TKDE.2005.11
   Chui FCF, 2009, J SIGNAL PROCESS IMA, V2, P1
   Hong T.H., 2013, International Journal of Multimedia Ubiquitous Engineering, V8, P151
   Jin RM, 2005, IEEE T KNOWL DATA EN, V17, P71, DOI 10.1109/TKDE.2005.18
   Kuo HC, 2009, 2009 IEEE/ACM/IFIP 7TH WORKSHOP ON EMBEDDED SYSTEMS FOR REAL-TIME MULTIMEDIA, P1, DOI 10.1109/ESTMED.2009.5336823
   Lee YC, 2009, J INF PROCESS SYST, V5, P175, DOI 10.3745/JIPS.2009.5.4.175
   Lim N., 2007, CLASSIFICATION ENSEM
   Liu M., 2002, Soft Computing, V6, P357, DOI 10.1007/s00500-002-0189-3
   Ma A, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P606, DOI 10.1109/ISM.2009.87
   Nguyen Hubert, 2007, GPU GEMS, V3
   Park YH, 2006, J SYST SOFTWARE, V79, P180, DOI 10.1016/j.jss.2005.05.009
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544
   Teng ZX, 2007, LECT NOTES COMPUT SC, V4426, P296
   van der Laan WJ, 2011, IEEE T PARALL DISTR, V22, P132, DOI 10.1109/TPDS.2010.143
   Zhou ZH, 2003, ARTIF INTELL, V143, P139, DOI 10.1016/S0004-3702(02)00357-0
NR 16
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8455
EP 8465
DI 10.1007/s11042-013-1614-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600013
DA 2024-07-18
ER

PT J
AU Kalra, GS
   Talwar, R
   Sadawarti, H
AF Kalra, G. S.
   Talwar, R.
   Sadawarti, H.
TI Adaptive digital image watermarking for color images in frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Error correcting codes; DCT; DWT; Frequency domain
ID ROBUST
AB We have presented an algorithm of digital image watermarking for color images which we implemented in frequency domain. Before inserting the watermark, we added the Hamming codes row wise as well column wise in the intensity component of color image. Two encryption techniques were implemented on the ECC inserted watermark for its security. The pixel position for inserting the watermark was calculated using starting row and column number for that 8 x 8 block. Pixel embedding strength is calculated using criteria that low frequency is robust in general signal processing attacks, thus choosing less value to be embedded and vice-versa. Results show that the watermarking algorithm is robust against common signal processing attacks. The algorithm is tested against multiple attacks also.
C1 [Kalra, G. S.] Lovely Profess Univ, Sch Elect Engn, Jalandhar, Punjab, India.
   [Talwar, R.] Punjab Tech Univ, CGC Coll Engn, Kapurthala, Punjab, India.
   [Sadawarti, H.] Punjab Tech Univ, RIMTIET, Kapurthala, Punjab, India.
C3 Lovely Professional University; I. K. Gujral Punjab Technical
   University; I. K. Gujral Punjab Technical University
RP Kalra, GS (corresponding author), Lovely Profess Univ, Sch Elect Engn, Jalandhar, Punjab, India.
EM gursharanjeetkalra@yahoo.com; rajneesh_talwar@yahoo.com;
   harshsada@yahoo.com
RI Talwar, Rajneesh/GPK-5841-2022; Sadawarti, Harsh/T-7615-2019; Talwar,
   Rajneesh/AAC-3117-2021; Sadawarti, Harsh/T-7664-2019
OI Talwar, Rajneesh/0000-0002-2109-8858; Sadawarti, Dr.
   Harsh/0000-0003-4179-142X
CR Abdul W, 2009, IEEE IMAGE PROC, P3637, DOI 10.1109/ICIP.2009.5414271
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Business Software Alliances, 2007, PIR STUD 4 ANN BSA I
   Cika P., 2009, 16 INT C SYST SIGN I, P1
   Domingo-Ferrer J, 2000, ELECTRON LETT, V36, P1697, DOI 10.1049/el:20001231
   Ge HT, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1584, DOI 10.1109/ICOSP.2002.1180100
   Gu LM, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P798
   Guyeux Christophe, 2010, Proceedings of the Second International Conference on Evolving Internet (INTERNET 2010). First International Conferences on Access Networks, Services and Technologies (ACCESS 2010), P119, DOI 10.1109/INTERNET.2010.29
   Jayalakshmi M, 2008, IET INFORM SECUR, V2, P119, DOI 10.1049/iet-ifs:20070106
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   KUNG CY, 2006, CYB INT SYS IEEE C, P1
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Nayak J, 2004, Proceedings of the IEEE INDICON 2004, P147, DOI 10.1109/INDICO.2004.1497726
   Rahmani H, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/428183
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Terzija N, 2002, P VIS IMAG IMAG PROC
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Xin YQ, 2008, INT J AP MAT COM-POL, V18, P93, DOI 10.2478/v10006-008-0009-8
   Xuan M, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P126, DOI 10.1109/MINES.2009.58
   Zhang Y, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P213, DOI 10.1109/ISECS.2009.207
NR 22
TC 47
Z9 48
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6849
EP 6869
DI 10.1007/s11042-014-1932-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800013
DA 2024-07-18
ER

PT J
AU Su, LC
   Huang, TQ
   Yang, JM
AF Su, Lichao
   Huang, Tianqiang
   Yang, Jianmei
TI A video forgery detection algorithm based on compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video Forgery; K-SVD; Compressive Sensing; Passive Forensics
ID RECOVERY
AB Video processing software is often used to delete moving objects and modify the forged regions with the information provided by the areas around them. However, few algorithms have been suggested for detecting this form of tampering. In this paper, a novel algorithm based on compressive sensing is proposed for the detection in which the moving foreground was removed from background. Firstly, the features of the difference between frames are obtained through K-SVD (k-Singular Value Decomposition), and then random projection is used to project the features into the lower-dimensional subspace which is clustered by k-means, and finally the detection results are combined to output. The experimental results show that our algorithm has higher detection accuracy and better robustness than that of the previous algorithms.
C1 [Su, Lichao; Huang, Tianqiang; Yang, Jianmei] Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou, Peoples R China.
C3 Fujian Normal University
RP Su, LC (corresponding author), Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou, Peoples R China.
EM 651424071@qq.com
FU National Science Foundation of China [61070062]; Industry-university
   Cooperation Major Projects in Fujian Province [2012H6006]; Program for
   New Century Excellent Talents in University in Fujian Province
   [JAI1038]; University Services HaiXi Major Project in Fujian Province
   [2008HX200941-4-5]; Science and Technology Department of Fujian province
   K-class Foundation Project [JA10064]; Education Department of Fujian
   province A-class Foundation Project [JA10064]
FX This work was supported by the National Science Foundation of China
   (Grant No.61070062), Industry-university Cooperation Major Projects in
   Fujian Province (Grant No.2012H6006), Program for New Century Excellent
   Talents in University in Fujian Province (Grant No.JAI1038), the
   University Services HaiXi Major Project in Fujian Province (Grant
   No.2008HX200941-4-5), Science and Technology Department of Fujian
   province K-class Foundation Project (Grant No.JA10064), The Education
   Department of Fujian province A-class Foundation Project (Grant
   No.JA10064).
CR AHARON M, 2005, K SVD DESIGN DICT SP
   [Anonymous], [No title captured]
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Bo L., 2011, Neural Information Processing Systems, P2115
   Burger W., 2002, Meas. Sci. Technol, V13, P1503
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Delp E, 2009, IEEE SIGNAL PROC MAG, V26, P14, DOI 10.1109/MSP.2008.931089
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Feng JZ, 2009, IEEE IMAGE PROC, P2149, DOI 10.1109/ICIP.2009.5414328
   Figueiredo MA, 2007, IEEE J SEL TOP SIGN, V1
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Iwen MA, 2008, PROCEEDINGS OF THE NINETEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P20
   Kobayashi M, 2009, LECT NOTES COMPUT SC, V5414, P306, DOI 10.1007/978-3-540-92957-4_27
   Mohimani H, 2008, ARXIV08092508
   Sarvotham S., 2006, PREPRINT
   Shih TK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1471
   Song Y, 2011, DIGITAL VIDEO FORENS
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y., 2004, Extensions of compressed sensing
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Young I.T., 1998, FUNDAMENTALS IMAGE P
   Zhang J, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P49, DOI 10.1109/ETCS.2009.273
NR 30
TC 30
Z9 34
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6641
EP 6656
DI 10.1007/s11042-014-1915-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800003
DA 2024-07-18
ER

PT J
AU Vafadar, M
   Behrad, A
AF Vafadar, Maryam
   Behrad, Alireza
TI A vision based system for communicating in virtual reality environments
   by recognizing human hand gestures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision based communicating; Eigen space; Hand gesture recognition;
   Motion history image; Spatio-temporal volume; Virtual reality
ID MOTION
AB Nowadays, with the emerging of the new applications like virtual reality using image processing and machine vision algorithms, it is necessary to have more modern interfaces for interaction with robots and computers. To cope with this problem, vision based gesture recognition systems play a significant role. This paper implements a vision based system for human hand gesture recognition. We propose three different methods for human hand gesture recognition, including, 1-a new method based on spatio-temporal volumes, 2-hand gesture recognition based on Motion History Image (MHI) and 3-method based on eigen space features. In these algorithms, after applying necessary pre-processing on video frames, some features are extracted for each gesture. These features are then analyzed and finally, a classification algorithm is applied for the hand gesture recognition. We tested the proposed three algorithms with the collected dataset and the results showed that proposed method based on the spatio-temporal volumes results in the correct recognition rate of 99.58 % for noiseless and 97.92 % for noisy data. Comparing the results of the proposed method based on the spatio-temporal volumes with two other methods shows that the recognition rate is improved up to 5.83 % and 8.75 % respectively.
C1 [Vafadar, Maryam; Behrad, Alireza] Shahed Univ, Fac Engn, Dept Elect & Elect Engn, Tehran, Iran.
C3 Shahed University
RP Vafadar, M (corresponding author), Shahed Univ, Fac Engn, Dept Elect & Elect Engn, Tehran, Iran.
EM vafadar.mar@gmail.com; behrad@shahed.ac.ir
RI Vafadar, Maryam/K-7996-2019; Behrad, Alireza/F-8795-2018
OI Vafadar, Maryam/0000-0003-2285-5854; Behrad, Alireza/0000-0002-1990-6668
CR Allard J, 2010, PRESENCE-TELEOP VIRT, V19, P142, DOI 10.1162/pres.19.2.142
   [Anonymous], 2010, P IAEA S INT SAFEGUA
   [Anonymous], MSC INFORM RES REV
   [Anonymous], 1995, IEEE INT WORKSH AUT
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Basso V, 2012, INT S ART INT ROB AU
   Bolduc MM, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P236, DOI 10.1109/CRV.2005.26
   Dionisio C. R. P., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), DOI 10.1109/SIBGRA.2000.895833
   Harding PRG, 2004, INT C PATT RECOG, P286, DOI 10.1109/ICPR.2004.1334523
   Ho-Sub Yoon, 1999, Proceedings 10th International Conference on Image Analysis and Processing, P969, DOI 10.1109/ICIAP.1999.797721
   Kovalik V., 2012, WSCG POST P, P15, DOI [10.3390/ijgi6120407, DOI 10.3390/ijgi6120407]
   Kumar S, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P299
   Lamar M. V., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P57, DOI 10.1109/ICSMC.1999.812376
   Liu N, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P648
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moghaddam B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1131, DOI 10.1109/ICCV.1999.790407
   Nyamse Victor, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P66, DOI 10.1007/978-3-642-39420-1_8
   Ohara Y., 2004, Proceedings of 5th Workshop on Omnidirectional Vision, Camera Networks and Non-classical Cameras, P79
   Pedersoli F., 2012, Proceedings of the 20th ACM international conference on Multimedia - MM '12, P1465, DOI DOI 10.1145/2393347.2396521
   Preston S., 2005, CS051500 U CAP TOWN
   Ristivojevic M, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P9
   Shalbaf R, 2007, 13 IR C BIOM ENG ICB
   Shan CF, 2004, INT C PATT RECOG, P954, DOI 10.1109/ICPR.2004.1334687
   Swaminathan R, 2002, LECT NOTES COMPUT SC, V2350, P508
   Vafadar M, 2007, INT C INF KNOWL TECH
   Vafadar M, 2008, LECT NOTES COMPUT SC, V5099, P378, DOI 10.1007/978-3-540-69905-7_43
   Zhang J, 2013, EMERGING TECHNOLOGIE, P971
NR 27
TC 9
Z9 10
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7515
EP 7535
DI 10.1007/s11042-014-1989-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200005
DA 2024-07-18
ER

PT J
AU Kang, S
   Kim, H
   Kang, S
AF Kang, Sunyoung
   Kim, Hyuncheol
   Kang, Seungae
TI Virtual private network for wellness sports information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports information; Information network; Virtual private network
AB To this day, active discussions and attempts were made to develop the IT foundation in order to ensure growth and advancement of the sports related industry and to ensure individual companies marketability and enhancement. In particular, development of the system in the current high-speed network in Korea that enables effective linkage and sharing of sports related information, and the system effective management and operation are certainly important issues. In order for the developed IT infra in Korea to act as a growth driver for the sports industry, it is important to develop structured and user-friend information network to make an effort to connect these information networks in an integrated manner. Development and linkage of effective information network in the sports field are expected to become an important medium for satisfying diverse demands for the sports. This research propose a virtual private network for the development of large capacity for the sports related information based on the nation technological capability.
C1 [Kang, Sunyoung] Korea Univ, Dept Phys Sci, Seoul, South Korea.
   [Kim, Hyuncheol] Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
   [Kang, Seungae] Namseoul Univ, Dept Hlth & Exercise Sci, Cheonan, South Korea.
C3 Korea University; Namseoul University; Namseoul University
RP Kang, S (corresponding author), Namseoul Univ, Dept Hlth & Exercise Sci, Cheonan, South Korea.
EM 1010kang@hanmail.net; hckim@nsu.ac.kr; sahome@nsu.ac.kr
CR [Anonymous], STAT TRENDS LEB ENV
   [Anonymous], 2008, CONSTR SERV SPORT IN
   Hyunseob L., 2004, KOREAN SOC SPORT LEI, V22, P845
   Jimyung C., 2009, SPORT SCI, V109, P91
   Jinkyung P, 2009, P KWAND U, V25
   Jinkyung P., 2001, KOREAN ALLIANCE HLTH, V40, P97
   Ministry of Culture and Tourism, 2006, SPORTS WHIT PAP, P201
   Sang K, 2000, KOREAN ALLIANCE HLTH, V40, P311
   Yong K., 2000, KOREAN SOC SPORT LEI, V14, P779
NR 9
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6497
EP 6507
DI 10.1007/s11042-014-2096-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700026
DA 2024-07-18
ER

PT J
AU Yang, HS
   Lee, DH
   Yoo, SJ
AF Yang, Hwan-Seok
   Lee, Dong-Hwi
   Yoo, Seung-Jae
TI A study on stable web server system using virtualization technology
   against attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtualization; Computer security; DoS attack; Honeypot
AB Computing environment has greatly changed by development of computing technology and distribution of extensive network. But the damage is taken seriously while attack techniques are diverse and attack target also is increasing. Thus, the normal network service should be done coping with these attacks actively. In this study, we propose new technique that can provide collection of attack information using virtualization technology and stable web service. The collection of attack information is done dynamically in honey system and managed by HSC. The continuous service of web server is performed by LBC. The superior performance of proposed method is confirmed through experiment.
C1 [Yang, Hwan-Seok; Yoo, Seung-Jae] Joongbu Univ, Dept Informat Secur Engn, Chungnam, South Korea.
   [Lee, Dong-Hwi] Kyonggi Univ, Dept Ind Secur, Suwon, South Korea.
C3 Joongbu University; Kyonggi University
RP Yoo, SJ (corresponding author), Joongbu Univ, Dept Informat Secur Engn, 101 Majeon Ri, Chungnam, South Korea.
EM yanghs@joongbu.ac.kr; sjyoo@joongbu.ac.kr
CR [Anonymous], 2012, INT J NETWORK SECURI
   Chen CL, 2009, J UNIVERS COMPUT SCI, V15, P488
   Dobrilovic D, 2006, INT J SOC SCI    SPR
   François J, 2012, IEEE ACM T NETWORK, V20, P1828, DOI 10.1109/TNET.2012.2194508
   Fuertes W. M., 2007, P 14 HP SOFTW U ASS, P8
   Ikinci A., 2008, Sicherheit, V8, P407
   Keller J., 2006, P 2 IEEE INT C E SCI, P126
   Kumar PAR, 2011, COMPUT COMMUN, V34, P1328, DOI 10.1016/j.comcom.2011.01.012
   Li M, 2009, P 2 INT C IM SIGN PR, P1, DOI DOI 10.1109/CISP.2009.5300903
   PAUL O, 2006, P IEEE IST WORKSH MO
   Pizzonia M., 2008, P TRIDENTCOM 2008 IN
   Provos N, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P1
NR 12
TC 3
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6381
EP 6390
DI 10.1007/s11042-014-2109-9
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700018
DA 2024-07-18
ER

PT J
AU Hsu, JL
   Huang, CC
AF Hsu, Jia-Lien
   Huang, Chien-Chang
TI Designing a graph-based framework to support a multi-modal approach for
   music information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Multi-modal approach
ID GENRE CLASSIFICATION; EVALUATION EXCHANGE
AB In this paper, we propose a graph-based framework to organize low-level and high-level features of music objects in a unified way. The featured graph, called the power graph, is associated with operators to support a variety of music information retrieval applications, such as auto-tagging, link analysis, similarity measurement, and clustering. Among these operators, we have identified the node ranking by computing prestige value as one of the essential fundamental link analysis operators. For this particular operator, we propose two methods of computing prestige; they are the power method and the algebraic method. Although the algebraic method is originated from the symmetric graph, the algebraic method can be applied as an approximate but efficient alternative to the power method. To demonstrate the feasibility of our framework, we have carried out an auto-tagging experiment and a music object clustering experiment. According to the auto-tagging experimental results, we have observed that the algebraic method has achieved almost the same results as the power method with only a one-fifth elapsed time. In the experiments we have conducted, we have achieved accuracy levels up to 75 %.
C1 [Hsu, Jia-Lien; Huang, Chien-Chang] Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei City, Taiwan.
C3 Fu Jen Catholic University
RP Hsu, JL (corresponding author), Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei City, Taiwan.
EM alien@csie.fju.edu.tw
RI Hsu, Jia-Lien/K-7271-2015
OI Hsu, Jia-Lien/0000-0002-4818-3198
FU Fu Jen Catholic University [410031044042]; National Science Council
   [NSC-100-2221-E-030-021, NSC-101-2221-E-030-008]
FX This research was supported by Fu Jen Catholic University with Project
   No. 410031044042 and sponsored by the National Science Council under
   Contract No. NSC-100-2221-E-030-021 and NSC-101-2221-E-030-008.
CR [Anonymous], P 2 ACM INT C WEB SE
   [Anonymous], PATTERN RECOGNITION
   Barbedo JGA, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/64960
   Bailloeul T., 2008, Proc. Multimedia Information Retrieval, P75, DOI DOI 10.1145/1460096.1460110
   Berenzweig A, 2004, P 5 INT C MUS INF RE
   Bertin-Mahieux T., 2011, ISMIR, P591
   Breyer L, 2002, TECHNICAL REPORT
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Bryan NicholasJ., 2011, Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR), P329
   Cano P, 2006, CHAOS INTERDISCIP J, V16
   Cano P., 2004, P 5 INT S MUS INF RE, P466
   Coscia Michele, 2011, Statistical Analysis and Data Mining, V4, P514, DOI 10.1002/sam.10133
   Downie JS, 2010, STUD COMPUT INTELL, V274, P93
   Downie JS, 2008, ACOUST SCI TECHNOL, V29, P247, DOI 10.1250/ast.29.247
   Easley D., 2010, Networks, crowds, and markets: Reasoning about a highly connected world
   Fallows D, 2013, GROVE MUSIC ONLINE
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gersho A., 2003, Vector Quantization and Signal Compression
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Gouyon F, 2004, P 25 INT AES C LOND
   Graphviz, GRAPH VIS SOFTW
   Hsu JL, 2012, MULTIMED TOOLS APPL, V58, P521, DOI 10.1007/s11042-011-0729-x
   Jang R, 2011, DCPR TOOLBOX
   Lartillot O, 2011, MIRTOOLBOX
   Levy M, 2009, IEEE T MULTIMEDIA, V11, P383, DOI 10.1109/TMM.2009.2012913
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li Q, 2007, INFORM PROCESS MANAG, V43, P473, DOI 10.1016/j.ipm.2006.07.005
   Lidy T, 2005, P 6 INT C MUS INF RE, P34
   Liu B, 2011, DATA CENTRIC SYST AP, P1, DOI 10.1007/978-3-642-19460-3
   Manning C. D., 2008, INTRO INFORM RETRIEV, P496
   Marcus S., 2007, MINING GRAPH DATA, P443
   McFee B, 2012, P 4 INT WORKSH ADV M
   McKay C, 2008, P INT C MUS INF RETR
   McKay C, 2010, P 11 INT C MUS INF R
   Miotto R., 2010, PROC 11 INT SOC MUSI, P15
   Miotto R, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180870
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Pan J-Y, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135
   Pohle T., 2005, P 4 INT WORKSH CONT
   Sayood K., 2012, INTRO DATA COMPRESSI, V4, P768
   Scaringella N, 2006, IEEE SIGNAL PROC MAG, V23, P133, DOI 10.1109/MSP.2006.1598089
   Song Y., 2012, P 13 INT C MUS INF R
   Stober S, 2013, MULTIMED TOOLS APPL, V65, P467, DOI 10.1007/s11042-012-1042-z
   Tan SL, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037679
   Tong HH, 2008, KNOWL INF SYST, V14, P327, DOI 10.1007/s10115-007-0094-2
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Zsuzsanna M., 2011, 2011 IEEE International Conference on Intelligent Computer Communication and Processing, P137, DOI 10.1109/ICCP.2011.6047857
NR 48
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5401
EP 5427
DI 10.1007/s11042-014-1860-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100002
DA 2024-07-18
ER

PT J
AU Rahman, MA
AF Rahman, Md Abdur
TI Multimedia environment toward analyzing and visualizing live kinematic
   data for children with Hemiplegia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia for e-Health; Kinematic data; Second Life; Hemiplegia
ID REHABILITATION; MOTION; SYSTEM
AB In this paper we propose a multimedia environment that can capture kinematic data from live gestures of a child having Hemiplegia disability and generate live analytical results as part of decision making system of a therapist. The kinematic data is obtained from clinically suggested therapy modules that are used to monitor quality of improvement of a disabled child, which includes exercises involving the affected joints and muscles. The methodology proposed is non-invasive as the child does not need to wear any external devices in the body. The multimedia environment incorporates Second Life serious game environment coupled with Microsoft Kinect where the live therapeutic movement of child, and therapist is synchronized between physical and virtual world. Our preliminary test results are validated by the therapists from three different disability hospitals that treat children with Hemiplegia, which is presented in this paper.
C1 Umm Al Qura Univ, Dept Comp Sci, Adv Media Lab, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Rahman, MA (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Adv Media Lab, Mecca, Saudi Arabia.
EM rahman@mcrlab.uottawa.ca
RI Guizani, Mohsen/AAX-4534-2021; Rahman, Abdur/AAG-9302-2019
OI Guizani, Mohsen/0000-0002-8972-8094; Rahman, Abdur/0000-0002-4105-0368
FU NSTIP strategic technologies program in the Kingdom of Saudi Arabia
   [11-INF1703-10]
FX The author would like to thank Dr. Saleh Basalamah, Dr. Mohamed Ahmed,
   Ahmad Muaz Qamar and Delwar Hossain for assisting in data collection.
   This project was supported by the NSTIP strategic technologies program
   (11-INF1703-10) in the Kingdom of Saudi Arabia.
CR Alamri A, 2010, INT J COMP SCI SPORT, V9
   Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Anderson S. A., 1993, ANATOMY OF MOVEMENT
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   [Anonymous], THESIS NOTRE DAME
   [Anonymous], 2005, P 2005 ACM SIGGRAPHE, DOI DOI 10.1145/1073368.1073414
   Baran M, 2011, IEEE ENG MED BIO, P7602, DOI 10.1109/IEMBS.2011.6091874
   Berjano P, EUROP SPINE J, P1
   Chang C., 2012, INT C PERV COMP TECH
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Cho S, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P283, DOI 10.1109/VR.2009.4811056
   Da Gama A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2012.6184203
   Gabel Moshe, 2012, Annu Int Conf IEEE Eng Med Biol Soc, V2012, P1964, DOI 10.1109/EMBC.2012.6346340
   Gips J., 2007, DISABILITY REHABILIT, V2, P189
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Hanna SE, 2008, PHYS THER, V88, P596, DOI 10.2522/ptj.20070314
   Hardy S, 2011, IIEEE MED MEAS AN
   Harley L, 2001, HCII 11 P 14 INT C H, P167
   Harley L, 2011, LECT NOTES COMPUT SC, V6764, P167, DOI 10.1007/978-3-642-21619-0_22
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Huber Meghan, 2008, 2008 Virtual Rehabilitation, P105, DOI 10.1109/ICVR.2008.4625145
   Huber M, 2010, IEEE T INF TECHNOL B, V14, P526, DOI 10.1109/TITB.2009.2038995
   Lakany H, 2008, PATTERN RECOGN, V41, P1627, DOI 10.1016/j.patcog.2007.11.004
   Lange B, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P170
   Liu CK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531365
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Ma M, 2008, MAN CYB IEEE INT C S, P1872
   Ma MH, 2007, LECT NOTES COMPUT SC, V4555, P681
   MINEAR WL, 1956, PEDIATRICS, V18, P841
   Norris J, 2009, 3D VIRTUAL WORLDS HL, V2, P2
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Rahman MA, 2010, IEEE T INSTRUM MEAS, V59, P1327, DOI 10.1109/TIM.2009.2038307
   ROAAS A, 1982, ACTA ORTHOP SCAND, V53, P205, DOI 10.3109/17453678208992202
   Saini S., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P55, DOI 10.1109/ICCISci.2012.6297212
   Sakzewski L, 2009, PEDIATRICS, V123, pE1111, DOI 10.1542/peds.2008-3335
   Schonauer C, 2011, P INT C VIRT REH ZUR
   Shaughnessy M, 2006, REHABIL NURS, V31, P15, DOI 10.1002/j.2048-7940.2006.tb00005.x
   Stanley F., 2000, CLIN DEV MED
   Sueda S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360682
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Tong XL, 2012, INT SYM COMPUT INTEL, P347, DOI 10.1109/ISCID.2012.238
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 45
TC 12
Z9 12
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5463
EP 5487
DI 10.1007/s11042-014-1864-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100005
DA 2024-07-18
ER

PT J
AU Wu, B
   Zhou, XK
   Jin, Q
AF Wu, Bo
   Zhou, Xiaokang
   Jin, Qun
TI Participatory information search and recommendation based on social
   roles and networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Participatory systems; Social roles; Information search; Information
   recommendation; SNS
AB With the increasing popularity of social network services, a tremendous amount of information has been produced. And with more and more users involving in the SNS environment, their network relationships have become as complex as in the real world. In order to find out the useful information more efficiently, in this study, we propose a participatory search and recommendation system based on users' social roles and their relationships in the SNS environment. The proposed system is used to filter users and their messages in a participatory way by analyzing their social roles and connection networks between each user, which can further contribute to personalized information search and recommendation. We describe the design and implementation issues of a prototype system, and discuss how to use the social roles and connection networks to support and empower information search and recommendation.
C1 [Wu, Bo; Zhou, Xiaokang; Jin, Qun] Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
C3 Waseda University
RP Jin, Q (corresponding author), Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
EM wubo@ruri.waseda.jp; xkzhou@ruri.waseda.jp; jin@waseda.jp
RI Bennis, Mehdi/ABE-5838-2020
OI Bennis, Mehdi/0000-0003-0261-0171
FU Waseda University [2012B-215, 2013B-207]; National Natural Science
   Foundation of China [71061005/G0112]
FX The work has been partly supported by 2012 and 2013 Waseda University
   Grants for Special Research Project under No. 2012B-215 and No.
   2013B-207. The work of the third author has been partly supported by
   National Natural Science Foundation of China under No. 71061005/G0112.
CR Borgatti SP, 2003, MANAGE SCI, V49, P432, DOI 10.1287/mnsc.49.4.432.14428
   Chen J, 2009, INT J ADV INTELL SYS, V2, P192
   Elmisery AM, 2011, J CONVERGENCE, V2, P33
   Fukazawa Y., 2006, P 14 INT SEM WEB C
   Gallego D., 2012, J CONVERGENCE, V3, P41
   Jeong WH, 2013, J INF PROCESS SYST, V9, P157, DOI 10.3745/JIPS.2013.9.1.157
   Junquero-Trabado V., 2012, Proc. the 21st Int. Conf. companion on World Wide Web, P1051
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Liu D, 2008, P 3 COMM POL RES S C
   Mcleod S., SOCIAL ROLES
   Nolker RD, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P87
   Nomura K., SOCIOLOGICAL SENSE
   Pan R., 2012, J CONVERGENCE, V3, P13
   Roda C, 2004, P INT C COGN EXPL LE, P366
   Shtykh RY, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-2
   Walter FE, 2008, AUTON AGENT MULTI-AG, V16, P57, DOI 10.1007/s10458-007-9021-x
   Watts DJ, 2002, SCIENCE, V296, P1302, DOI 10.1126/science.1070120
   Xiaokang Zhou, 2011, Advances in Web-Based Learning - ICWL 2011. Proceedings 10th International Conference, P219, DOI 10.1007/978-3-642-25813-8_23
   Zhou XK, 2011, P 5 INT C UB INF MAN, P21
NR 19
TC 5
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5173
EP 5188
DI 10.1007/s11042-013-1849-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900012
DA 2024-07-18
ER

PT J
AU Liu, YN
   Wang, YW
   Zhu, XD
AF Liu, Yuanning
   Wang, Youwei
   Zhu, Xiaodong
TI Novel robust multiple watermarking against regional attacks of digital
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple watermarking; Regional attacks; Arnold transform; Human Visual
   System; Particle Swarm Optimization; Accidental attacks; Joint attacks
ID PARTICLE SWARM OPTIMIZATION; ALGORITHM; SYSTEM
AB This paper presents a novel robust multiple watermarking method for regional attacks of digital images. The core idea of the proposed method is to divide the host image into 4 x 4 non-overlapping regions and embed the watermark image into these regions repeatedly. First, the binary watermark image is scrambled by Arnold transform and divided into four equal parts. Then, the variance and mean value information of each 8 x 8 size block in the host image is used as side information, and each part of the scrambled watermark is embedded in the particular four regions of the host image. In the watermark extraction process, each part of the scrambled watermark image is divided into four equal sub-parts further. The similarity between the sub-part of the scrambled watermark and each extracted watermark segment corresponding to this sub-part is used as side information to search the final extracted watermark segment. For ensuring the visual quality of the watermarked image, the watermark embedding quantization steps are selected by combining Human Visual System (HVS) and Particle Swarm Optimization (PSO). Moreover, a novel watermark quality evaluating measurement, called Weighted Normalized Correlation (WNC), is proposed. Experimental results demonstrate good visual imperceptibility and robustness of the proposed method against traditional regional attacks, accidental attacks and joint attacks, which are performed by Stirmark or Adobe Photoshop CS5.
C1 [Liu, Yuanning; Wang, Youwei; Zhu, Xiaodong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin Province, Peoples R China.
C3 Jilin University
RP Zhu, XD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, 2699 Qianjin St, Changchun 130012, Jilin Province, Peoples R China.
EM 1036569449@qq.com
FU National Natural Science Foundation of China [60971089]; National
   Electronic Development Foundation of China [2009537]
FX This research is supported by National Natural Science Foundation of
   China under Grant No. 60971089 and National Electronic Development
   Foundation of China under Grant No. 2009537.
CR Ahmed N, 2007, IEEE INT C SIGN PROC
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   [Anonymous], 2013, J INF HIDING MULTIM
   [Anonymous], IEEE SIGNAL PROCESSI
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Banitalebi A, 2012, INT ARAB J INF UNPUB
   Benhocine A., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P9
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen X., 2012, J COMPUTER RES DEV S, P287
   Chua K.K., 2011, DEV ANAL SPATIAL DOM
   Cong Jin, 2010, Proceedings of the 2010 International Conference of Information Science and Management Engineering. ISME 2010, P64, DOI 10.1109/ISME.2010.62
   Cox I. J., 2002, Digital Watermarking
   Dehkordi, 2011, EL ENG ICEE 2011 19, P1
   Gonzalez RC, 1998, TELECOMMUNICATIONS T
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Jutta H, 2011, 18 IEEE INT C IM PRO, P265
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Latif A, 2013, J INFORM HIDING MULT, V4, P250
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Liu YN, 2011, J BIONIC ENG, V8, P191, DOI 10.1016/S1672-6529(11)60020-6
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Lu W, 2009, COMPUT ELECTR ENG, V35, P183, DOI 10.1016/j.compeleceng.2008.09.004
   Lubin J, 2003, P SOC PHOTO-OPT INS, V5020, P536, DOI 10.1117/12.477336
   Mintzer F, 1999, INT CONF ACOUST SPEE, P2067, DOI 10.1109/ICASSP.1999.758338
   Na Xu, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P3058, DOI 10.1109/EMEIT.2011.6023734
   Namazi F, 2012, INT J COMPUTER APPL, V41, P41
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1408, DOI 10.1016/j.dsp.2009.10.015
   Sheppard N., 2001, WORKSHOP SECURITY MU, P3
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Shieh CS, 2003, J INF SCI ENG, V19, P381
   Unler A, 2010, EUR J OPER RES, V206, P528, DOI 10.1016/j.ejor.2010.02.032
   Wang XY, 2011, MULTIMED TOOLS APPL, V54, P341, DOI 10.1007/s11042-010-0534-y
   Wang YL, 2011, SENSOR REV, V31, P349, DOI 10.1108/02602281111169767
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen-Chuan Wu, 2011, 2011 Proceedings of the 3rd International Conference on Data Mining and Intelligent Information Technology Applications (ICMIA 2011), P122
   Xi ML, 2008, APPL MATH COMPUT, V205, P751, DOI 10.1016/j.amc.2008.05.135
   Yi-lin Bei, 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P305, DOI 10.1109/CSAE.2011.5952856
   Zhan ZH, 2009, IEEE T SYST MAN CY B, V39, P1362, DOI 10.1109/TSMCB.2009.2015956
   Zhu SM, 2009, LECT NOTES COMPUT SC, V5451, P136
NR 46
TC 5
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4765
EP 4787
DI 10.1007/s11042-013-1838-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400015
DA 2024-07-18
ER

PT J
AU Rehman, AU
   Liao, XF
   Kulsoom, A
   Abbas, SA
AF Rehman, Aqeel Ur
   Liao, Xiaofeng
   Kulsoom, Ayesha
   Abbas, Syed Ali
TI Selective encryption for gray images based on chaos and DNA
   complementary rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block image encryption; Logistic; PWLCM; Chaos; Complementary DNA rules
AB A new block cipher for gray images is proposed in this paper which fully utilizes whole set of DNA complementary rules dynamically for encoding and decoding each pixel of a block. The most significant (MSB) part of each block is added under DNA addition operation with least significant (LSB) while LSB part itself get encrypted by chaotically selecting different DNA rules for each pixel. The initial condition is calculated from 128-bits external input key and then the said key is modified for each subsequent block of an image. An image is permuted by Piecewise Linear Chaotic Map (PWLCM) while logistic sequence is used for the selection of encoding and decoding rules for each pixel of a block. The simulated experimental results and the security analysis in terms of quantitative and qualitative way show that our cipher can not only achieve good encryption effect to resist the exhaustive and statistical attacks but also is a good candidate for encrypting large sized uncompressed gray images.
C1 [Rehman, Aqeel Ur; Liao, Xiaofeng; Kulsoom, Ayesha; Abbas, Syed Ali] Chongqing Univ, Dept Comp Sci & Engn, Chongqing 630044, Peoples R China.
C3 Chongqing University
RP Rehman, AU (corresponding author), Chongqing Univ, Dept Comp Sci & Engn, Chongqing 630044, Peoples R China.
EM rehmancqu@gmail.com
RI Rehman, Aqeel ur/R-4559-2018; Liao, Xiaofeng/HPD-6655-2023
OI Rehman, Aqeel ur/0000-0002-3083-6066; 
FU National Natural Science Foundation of China [61003247, 61170249];
   Computer Science and Engineering Department, ChongQing University,
   People Republic of China
FX Financial support for the work described here was provided by National
   Natural Science Foundation of China Grant Nos. (61003247 and 61170249),
   Computer Science and Engineering Department, ChongQing University,
   People Republic of China
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Biham E, 1991, P 10 ANN INT CRYPT C
   Biham E, 1993, P 12 ANN INT CRYPT C
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hermassi H, 2010, COMMUN NONLINEAR SCI, V15, P2987, DOI 10.1016/j.cnsns.2009.11.022
   Hui CG, 2012, IPCSIT 52
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Socek D., 2007, EURASIP J INF SECUR, V2007, P1, DOI DOI 10.1155/2007/52965
   Stallings W., 1999, CRYPTOGRAPHY NETWORK, Vsecond
   Stinson DR, 2002, CRTOGRAPHY THEORY PR
   Wang X., 2008, Electromagnetic compatibility, P1
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2011, CORR
   Xiao GZ, 2006, CHINESE SCI B, V51
   Zhang Q, 2009, 4 INT C BIOINSP COMP
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2012, OPT COMMUN, V285, P2343, DOI 10.1016/j.optcom.2012.01.029
NR 31
TC 101
Z9 101
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4655
EP 4677
DI 10.1007/s11042-013-1828-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400010
DA 2024-07-18
ER

PT J
AU Yus, R
   Mena, E
   Ilarri, S
   Illarramendi, A
   Bernad, J
AF Yus, Roberto
   Mena, Eduardo
   Ilarri, Sergio
   Illarramendi, Arantza
   Bernad, Jorge
TI MultiCAMBA: a system for selecting camera views in live broadcasting of
   sport events using a dynamic 3D model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content selection in run-time; Mobile multi-camera management;
   Location-aware systems
ID VIDEO; ABSTRACTION; EXTRACTION
AB For a Technical Director (TD) in charge of a live broadcasting, selecting the best camera shots among the available video sources is a challenging task, even more now that the number of cameras (some of them mobile, or attached to moving objects) in the broadcasting of sport events is increasing. So, the TD needs to manage a great amount of continuously changing information to quickly select the camera whose view should be broadcasted. Besides, the better the decisions made by the TD, the more interesting the content for the audience. Therefore, the development of systems that could help the TD with the selection of camera views is demanded by broadcasting organizations.
   In this paper, we present the system MultiCAMBA that helps TDs in the live broadcasting task by allowing them to indicate in run-time their interest in certain kind of shots, and the system will show the cameras that are able to provide them. To achieve this task, the system manages location-dependent queries generated according to the interests of the TD. Moreover, to avoid the use of costly on line real-image processing techniques over the camera views, such real camera views are recreated in a 3D engine by using the information contained in a 3D model of the scenario. This model is updated continuously with real-time data retrieved from the real objects and cameras in the scenario. In this way, the system extracts high-level semantic features of 2D projections of the 3D reconstruction of the camera views. We present a prototype of the system and experimental results that show the feasibility of our proposal.
C1 [Yus, Roberto; Mena, Eduardo; Ilarri, Sergio; Bernad, Jorge] Univ Zaragoza, IIS Dept, Zaragoza 50018, Spain.
   [Illarramendi, Arantza] Univ Basque Country, LSI Dept, San Sebastian 20080, Spain.
C3 University of Zaragoza; University of Basque Country
RP Yus, R (corresponding author), Univ Zaragoza, IIS Dept, Maria de Luna 1, Zaragoza 50018, Spain.
EM ryus@unizar.es
RI Yus, Roberto/AAO-4477-2020; Bernad, Jorge/G-2782-2016; ILARRI,
   SERGIO/L-6311-2014; ILLARRAMENDI, ARANTZA/E-3466-2016; Mena Nieto,
   Eduardo/F-7459-2016
OI Yus, Roberto/0000-0002-9311-954X; ILARRI, SERGIO/0000-0002-7073-219X;
   ILLARRAMENDI, ARANTZA/0000-0001-9567-6326; Mena Nieto,
   Eduardo/0000-0002-7462-0080
FU CICYT [TIN2010-21387-C02]; DGA-FSE
FX This work has been supported by the CICYT project TIN2010-21387-C02 and
   DGA-FSE. We thank David Anton and Francisco J. Seron for their help with
   the implementation of our prototype and technical support, respectively.
CR Aliaga D.G., 2006, J VIRTUAL REALITY BR, V3
   [Anonymous], 2002, P 10 ACM INT C MULTI
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Bianchi M., 2004, MUM 04, P117
   Cha J, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596993
   Chen F, 2011, IEEE T MULTIMEDIA, V13, P1381, DOI 10.1109/TMM.2011.2166379
   Chen F, 2010, COMPUT VIS IMAGE UND, V114, P667, DOI 10.1016/j.cviu.2010.01.005
   Chen Y, 2012, IEEE T KNOWL DATA EN, V9, P2257
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Choi K, 2009, INT WORKSH ADV IM TE
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Heck R, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198306
   Hendawi Abdeltawab M., 2012, P 1 ACM SIGSPATIAL I, P97
   Ilarri S, 2012, MOB INF SYST, V8, P17, DOI 10.1155/2012/386472
   Ilarri S, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1670679.1670682
   Kolekar MH, 2011, MULTIMED TOOLS APPL, V54, P27, DOI 10.1007/s11042-010-0544-9
   Nitta N, 2009, MULTIMED TOOLS APPL, V41, P1, DOI 10.1007/s11042-008-0217-0
   Park HS, 2009, MULTISENSOR FUSION I, V35, P45
   Rui Y., 2001, P 9 ACM INT C MULTIM, P2, DOI DOI 10.1145/500141.500145
   SERR K., 2006, URISA Journal, V18, P19
   Tao Y., 2004, PROC ACM MANAGEMENT, P611
   Terry D, 1992, Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, V21, P321
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   Yildirim Y, 2013, IEEE T KNOWL DATA EN, V25, P47, DOI 10.1109/TKDE.2011.189
   Yus R, 2011, 19 ACM INT C MULT MM, P1005
   Yus R, 2011, 8 ANN INT C MOB UB S, P238
   Yus R, 2015, MULTIMED TOOLS APPL, V74, P2659, DOI 10.1007/s11042-013-1550-5
   Zhang C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324293
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 34
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4059
EP 4090
DI 10.1007/s11042-013-1810-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800021
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lin, WY
   Tsai, CF
   Wu, PC
   Chen, BR
AF Lin, Wei-Yang
   Tsai, Chih-Fong
   Wu, Pei-Chen
   Chen, Bo-Rong
TI Image retargeting using RGB-D camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-aware image resizing; Depth information; Discontinuous seam
   carving
ID INTEGRATION; FREQUENCY; ATTENTION; SHIFT
AB Forimage retargeting, most approaches only use color information to tackle this problem. In this paper, we analyze both color and depth information captured by a RGB-D camera to maintain the structure and preserve important regions. Particularly, we present a content-aware image retargeting algorithm based on depth information. In addition, we introduce a depth-based importance map, such that deformation of the image is guided by this map. This depth-based importance map is produced automatically by combining gradient, salience, and depth-based measures. More specifically, the depth-based measure is a weight map, in which we analyze depth information and use the mean shift procedure to find the local peak as the central of the important objects, and apply Gaussian distribution to determine the weight. Consequently, this depth-based importance map is used as the input of the discontinuous seam carving algorithm, and the seam is processed by the dynamic programming method. Our experimental results demonstrate the effectiveness of using the depth-based importance map in the discontinuous seam carving algorithm that it can visually behave better in maintaining the structure and preserving important regions. The proposed method produces much better results than other approaches, that are the state-of-the-art in content-aware image resizing.
C1 [Lin, Wei-Yang; Wu, Pei-Chen; Chen, Bo-Rong] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
   [Tsai, Chih-Fong] Natl Cent Univ, Dept Informat Management, Zhongli 32001, Taoyuan County, Taiwan.
C3 National Chung Cheng University; National Central University
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wylin@cs.ccu.edu.tw; cftsai@mgt.ncu.edu.tw
CR [Anonymous], TRENDS TOPICS COMPUT
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   ERIKSEN CW, 1973, PERCEPT PSYCHOPHYS, V14, P155, DOI 10.3758/BF03198630
   Fox E, 1998, PERCEPT PSYCHOPHYS, V60, P1004, DOI 10.3758/BF03211935
   Frankovich M, 2011, IEEE SIGNAL PROC LET, V18, P375, DOI 10.1109/LSP.2011.2140396
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   JUOLA JF, 1991, J EXP PSYCHOL HUMAN, V17, P125, DOI 10.1037/0096-1523.17.1.125
   KAHNEMAN D, 1992, COGNITIVE PSYCHOL, V24, P175, DOI 10.1016/0010-0285(92)90007-O
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P615, DOI 10.1109/TCE.2011.5955199
   Kim W, 2011, IEEE SIGNAL PROC LET, V18, P631, DOI 10.1109/LSP.2011.2165337
   Lamb MR, 2000, PERCEPT PSYCHOPHYS, V62, P753, DOI 10.3758/BF03206921
   Li J-H, 2004, RES APPL PSYCHOL, V21, P165
   Mansfield A, 2010, LECT NOTES COMPUT SC, V6311, P143, DOI 10.1007/978-3-642-15549-9_11
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Sung Y-H, 2013, ADV INTELLIGENT SYST, P339
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
NR 22
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3155
EP 3170
DI 10.1007/s11042-013-1776-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800015
DA 2024-07-18
ER

PT J
AU Oldfield, R
   Shirley, B
   Spille, J
AF Oldfield, Robert
   Shirley, Ben
   Spille, Jens
TI Object-based audio for interactive football broadcast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object-based audio; Interactive broadcast; Audio objects; Audio feature
   extraction; 3D audio; Football; Salient audio events; Spatial audio;
   Audio extraction
AB An end-to-end AV broadcast system providing an immersive, interactive experience for live events is the development aim for the EU FP7 funded project, FascinatE. The project has developed real time audio object event detection and localisation, scene modelling and processing methods for multimedia data, which will allow users to navigate the event by creating their own unique user-defined scene. As part of the first implementation of the system a test shoot was carried out capturing a live Premier League football game and methods have been developed to detect, analyse, extract and localise salient audio events from a range of sensors and represent them within an audio scene in order to allow free navigation within the scene. Within this context, this paper describes a procedure for the detection, extraction and localisation of ball-kicks and whistle-blows from the pitch-side microphones used in the broadcast of football and describes a potential audio streaming format for an object-based broadcast.
C1 [Oldfield, Robert; Shirley, Ben] Univ Salford, Salford M5 4WT, Lancs, England.
   [Spille, Jens] Technicolor, Hannover, Germany.
C3 University of Salford; Technicolor SA
RP Oldfield, R (corresponding author), Univ Salford, Salford M5 4WT, Lancs, England.
EM r.g.oldfield@salford.ac.uk
OI Shirley, Ben/0000-0001-9634-4489
FU European Union [248138]
FX This research project work is part of the FascinatE project which has
   received funding from the European Union's Seventh Framework Programme
   (FP7/2007-2013) under grant agreement no: 248138.
CR Andrews P, 2011, IOA REPR SOUND
   Barsanti RJ, 2003, IEEE C SIGN SYST COM
   Benesty J, 2000, J ACOUST SOC AM, V107, P384, DOI 10.1121/1.428310
   BERKHOUT AJ, 1993, J ACOUST SOC AM, V93, P2764, DOI 10.1121/1.405852
   Bove VM, 1995, SMPTE J, V104, P803, DOI 10.5594/J09591
   Bove VM, 1996, IBM SYST J, V35, P337, DOI 10.1147/sj.353.0337
   Carey Rikk., 1997, The Annotated VRML 97 Reference Manual
   Carter G.C., 1993, Ed. Coherence and Time Delay Estimation: An Applied Tutorial 72 for Research, Development, Test
   Cengarle G, 2001, 128 CONV AUD ENG SOC
   Chen S.-C., 2003, Proceedings of the 4th International Workshop on Multimedia Data Mining, P36
   Cheng Z, 2003, IEEE T SIGNAL PROCES, V51, P1859, DOI 10.1109/TSP.2003.812735
   Choi Seungjin, 2005, Neural Information Processing-Letters and Reviews, V6, P1
   Do H., 2007, IEEE INT C AC SPEECH
   Geier M, 2010, ORGAN SOUND, V15, P219, DOI 10.1017/S1355771810000324
   GERZON MA, 1985, J AUDIO ENG SOC, V33, P859
   GERZON MA, 1973, J AUDIO ENG SOC, V21, P2
   GRENNBERG A, 1994, IEEE T ULTRASON FERR, V41, P588, DOI 10.1109/58.308493
   Hoffmann H, 2003, 2003 INT C AUD DISPL
   Jakobsson A, 1998, IEEE T SIGNAL PROCES, V46, P2472, DOI 10.1109/78.709535
   Kim H.G., 2006, MPEG 7 AUDIO AUDIO C
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830
   Kyriakakis C, 1998, P IEEE, V86, P941, DOI 10.1109/5.664281
   Lindsay AT, 2001, J AUDIO ENG SOC, V49, P589
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   MPEG, 1998, W2203 MPEG
   Peters N, 2008, 2008 INT COMP MUS C
   Pihkala K, 2003, 2003 INT C AUD DISPL
   Scheirer ED, 1999, IEEE T MULTIMEDIA, V1, P237, DOI 10.1109/6046.784463
   Schreer O, 2013, P IEEE, V101, P99, DOI 10.1109/JPROC.2012.2193850
   Shirley B., 2006, Technology and Disability, V18, P31, DOI DOI 10.3233/TAD-2006-18105
   Silverman HF, 2005, IEEE T SPEECH AUDI P, V13, P593, DOI 10.1109/TSA.2005.848875
   Torkkola K, 1999, WORKSH IND COMP AN B
   Vincent E, 2005, C4DMTR0501
   Wang JJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P599, DOI 10.1109/ICME.2004.1394263
   Watlington JA, 1997, PARALLEL COMPUT, V23, P1793, DOI 10.1016/S0167-8191(97)00088-4
   Westner AG, 1998, OBJECT BASED AUDIO C
   Zongchuang L, 2002, 6 IEEE INT C SIGN PR
NR 37
TC 11
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2717
EP 2741
DI 10.1007/s11042-013-1472-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300008
DA 2024-07-18
ER

PT J
AU Chen, M
   Gong, LY
   Wang, TJ
   Feng, Q
AF Chen, Meng
   Gong, Liyu
   Wang, Tianjiang
   Feng, Qi
TI Action recognition using lie algebrized gaussians over dense local
   spatio-temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Dense sampling; Local spatio-temporal feature;
   Gaussian mixture model; Lie algebrized gaussians
AB This paper presents a novel framework for human action recognition based on a newly proposed mid-level feature representation method named Lie Algebrized Guassians (LAG). As an action sequence can be treated as a 3D object in space-time space, we address the action recognition problem by recognizing 3D objects and characterize 3D objects by the probability distributions of local spatio-temporal features. First, for each video, we densely sample local spatio-temporal features (e.g. HOG3D) at multiple scales confined in bounding boxes of human body. Moreover, normalized spatial coordinates are appended to local descriptor in order to capture spatial position information. Then the distribution of local features in each video is modeled by a Gaussian Mixture Model (GMM). To estimate the parameters of video-specific GMMs, a global GMM is trained using all training data and video-specific GMMs are adapted from the global GMM. Then the LAG is adopted to vectorize those video-specific GMMs. Finally, linear SVM is employed for classification. Experimental results on the KTH and UCF Sports dataset show that our method achieves state-of-the-art performance.
C1 [Chen, Meng; Wang, Tianjiang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Gong, Liyu] Eedoo Inc, Beijing 100085, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM tjwang@hust.edu.cn
FU National Natural Science Foundation of China [61073094, U1233119]
FX This work is supported by National Natural Science Foundation of China
   (No. 61073094 and No. U1233119).
CR [Anonymous], 2011, P CVPR 2011 PROV RI
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT C COMP VIS
   [Anonymous], ACM INT C MULT
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2008, IEEE C COMP VIS PATT
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gilbert A, 2009, IEEE I CONF COMP VIS, P925, DOI 10.1109/ICCV.2009.5459335
   Gong L, 2013, ARXIV13040823V1
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   O'Hara S, 2012, IEEE C COMP VIS PATT
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang H., 2009, BMVC
   Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong SF, 2007, IEEE I CONF COMP VIS, P746
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zhou X., 2008, ACM INT C MULT
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
NR 30
TC 6
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2127
EP 2142
DI 10.1007/s11042-013-1746-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500020
DA 2024-07-18
ER

PT J
AU Hamadi, A
   Mulhem, P
   Quénot, G
AF Hamadi, Abdelkader
   Mulhem, Philippe
   Quenot, Georges
TI Extended conceptual feedback for semantic multimedia indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic indexing; Multimedia; Fusion; Conceptual feedback;
   Inter-concepts relationships; Ontology; Temporal context; Semantic
   context; TRECVid
ID VIDEO
AB In this paper, we consider the problem of automatically detecting a large number of visual concepts in images or video shots. State of the art systems generally involve feature (descriptor) extraction, classification (supervised learning) and fusion when several descriptors and/or classifiers are used. Though direct multi-label approaches are considered in some works, detection scores are often computed independently for each target concept. We propose a method that we call "conceptual feedback" which implicitly takes into account the relations between concepts to improve the overall concepts detection performance. A conceptual descriptor is built from the system's output scores and fed back by adding it to the pool of already available descriptors. Our proposal can be iterated several times. Moreover, we propose three extensions of our method. Firstly, a weighting of the conceptual dimensions is performed to give more importance to concepts which are more correlated to the target concept. Secondly, an explicit selection of a set of concepts that are semantically or statically related to the target concept is introduced. For video indexing, we propose a third extension which integrates the temporal dimension in the feedback process by taking into account simultaneously the conceptual and the temporal dimensions to build the high-level descriptor. Our proposals have been evaluated in the context of the TRECVid 2012 semantic indexing task involving the detection of 346 visual or multi-modal concepts. Overall, combined with temporal re-scoring, the proposed method increased the global system performance (MAP) from 0.2613 to 0.3082 ( + 17.9 % of relative improvement) while the temporal re-scoring alone increased it only from 0.2613 to 0.2691 ( + 3.0 %).
C1 [Hamadi, Abdelkader; Mulhem, Philippe; Quenot, Georges] CNRS, LIG UMR 5217, Grenoble INP, UJF Grenoble 1 UPMF Grenoble 2, F-38041 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Quénot, G (corresponding author), CNRS, LIG UMR 5217, Grenoble INP, UJF Grenoble 1 UPMF Grenoble 2, F-38041 Grenoble, France.
EM abdelkader.hamadi@imag.fr; philippe.mulhem@imag.fr;
   georges.quenot@imag.fr
RI Hamadi, Abdelkader/AAU-8111-2020
OI Hamadi, Abdelkader/0000-0001-9990-332X
FU OSEO, French State agency for innovation; French project VideoSense of
   the ANR [ANR-09-CORD-026]; CNRS; RENATER
FX This work was partly realized as part of the Quaero Program funded by
   OSEO, French State agency for innovation. This work was supported in
   part by the French project VideoSense ANR-09-CORD-026 of the ANR.
   Experiments presented in this paper were carried out using the Grid'5000
   experimental test bed, being developed under the INRIA ALADDIN
   development action with support from CNRS, RENATER and several
   Universities as well as other funding bodies (see
   https://www.grid5000.fr). The authors wish to thanks the participants of
   the IRIM (Indexation et Recherche d'Information Multimedia) group of the
   GDR-ISIS research network from CNRS for providing the descriptors used
   in these experiments.
CR [Anonymous], 2007, ACM MULTIMEDIA, DOI DOI 10.1145/1291233.1291379
   [Anonymous], 2012, P TRECVID 2012 NIST
   [Anonymous], P 10 INT WORKSH CONT
   [Anonymous], P TRECVID WORKSH GAI
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Hradis M, 2012, LECT NOTES COMPUT SC, V7517, P155, DOI 10.1007/978-3-642-33140-4_14
   Inoue N, 2012, TRECVID 2012 US GAIT
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Platt JC, 2000, ADV NEUR IN, P61
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Qi GJ, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404883
   Safadi B., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P2081
   Safadi B, 2013, P CONT BAS MULT ING
   Safadi B, 2011, LECT NOTES COMPUT SC, V6611, P708, DOI 10.1007/978-3-642-20161-5_76
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   Snoek CG, 2005, P ACM MULT
   Tao Meng, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P860, DOI 10.1109/ICME.2012.134
   Tiberius Strat S, 2012, ECCV 2012 WORKSH INF
   Wang F, 2009, TREC2009 NOTEBOOK
   WANG F, 2009, TREC, V2009, P2009
   Yilmaz Emine, 2006, Proceedings of the 2006 ACM CIKM International Conference on Information and Knowledge Management, Arlington, Virginia, USA, November 6-11, 2006, P102, DOI [10.1145/1183614.1183633 (cit. on p. 34, DOI 10.1145/1183614.1183633(CIT.ONP.34]
   Zhu Q, 2012, TRECVID 2012 US GAIT
NR 28
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1225
EP 1248
DI 10.1007/s11042-014-1937-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300005
DA 2024-07-18
ER

PT J
AU Yuan, J
   Wei, BG
   Liu, YH
   Zhang, Y
   Wang, LD
AF Yuan, Jie
   Wei, Baogang
   Liu, Yonghuai
   Zhang, Yin
   Wang, Lidong
TI A method for text line detection in natural images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; Text line; Maximal stable extremal regions; Sparse
   classifier
ID READING TEXT; VIDEO; SEGMENTATION; EXTRACTION
AB Text information in natural images is very important to cross-media retrieval, index and understanding. However, its detection is challenging due to varying backgrounds, low contrast between text and non-text regions, perspective distortion and other disturbing factors. In this paper, we propose a novel text line detection method which can detect text line aligned with a straight line in any direction. It is mainly composed of three steps. In the first step, we use the maximal stable extremal region detector with dam line constraint to detect candidate text regions, we then define a similarity measurement between two regions which combines sizes, absolute distance, relative distance, contextual information and color histograms. In the second step, we propose a text line identification algorithm based on the defined similarity measurement. The algorithm firstly searches three regions as the seeds of a line, and then expands to obtain all regions in the line. In the last step, we develop a filter to remove non-text lines. The filter uses a sparse classifier based on two dictionaries which are learned from feature vectors extracted from morphological skeletons of those candidate text lines. A comparative study using two datasets shows the excellent performance of the proposed method for accurate text line detection with horizontal or arbitrary consistent orientation.
C1 [Yuan, Jie] Jiangsu Elect Power Informat Technol Co Ltd, Nanjing 210029, Jiangsu, Peoples R China.
   [Wei, Baogang; Zhang, Yin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Liu, Yonghuai] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
   [Wang, Lidong] Hangzhou Normal Univ, Qianjiang Coll, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Aberystwyth University; Hangzhou Normal University
RP Yuan, J (corresponding author), Jiangsu Elect Power Informat Technol Co Ltd, Nanjing 210029, Jiangsu, Peoples R China.
EM java_mc@163.com; wbg@zju.edu.cn; yyl@aber.ac.uk; yinzh@zju.edu.cn;
   violet_wld@163.com
RI Yuan, Jie/AAH-6158-2021; Liu, Yonghuai/ABF-3794-2020
OI Yuan, Jie/0000-0002-3604-6874; Wang, Lidong/0000-0003-4699-7937
FU National Natural Science Foundation of China [60673088]
FX This work is supported by the National Natural Science Foundation of
   China (No. 60673088).
CR [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   Chen XR, 2004, PROC CVPR IEEE, P366
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Grana C, 2011, MULTIMED TOOLS APPL, V55, P483, DOI 10.1007/s11042-010-0561-8
   Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355
   Karatzas D, 2004, INT C PATT RECOG, P634, DOI 10.1109/ICPR.2004.1334328
   Kim W, 2009, IEEE T IMAGE PROCESS, V18, P401, DOI 10.1109/TIP.2008.2008225
   Kimmel R, 2011, IEEE T PATTERN ANAL, V33, P2316, DOI 10.1109/TPAMI.2011.133
   Li Z, 2010, PROC 11 PAC RIM C AD, P284
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006
   Liu XQ, 2012, IEEE T MULTIMEDIA, V14, P482, DOI 10.1109/TMM.2011.2177646
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Minetto R, 2010, IEEE IMAGE PROC, P3861, DOI 10.1109/ICIP.2010.5651761
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shivakumara P., 2008, Pattern recognition, P1
   Shivakumara P., 2010, P 9 IAPR INT WORKSH, P279
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Shivakumara P, 2010, IEEE T CIRC SYST VID, V20, P1520, DOI 10.1109/TCSVT.2010.2077772
   Shivakumara P, 2010, PATTERN RECOGN, V43, P2165, DOI 10.1016/j.patcog.2010.01.009
   Tianding Chen, 2008, 2008 11th IEEE International Conference on Communication Technology (ICCT 2008), P722, DOI 10.1109/ICCT.2008.4716220
   Wang F, 2008, PATTERN RECOGN, V41, P3257, DOI 10.1016/j.patcog.2008.03.024
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yao Cong, 2012, P IEEE C COMP VIS PA
   Ye QX, 2007, J VIS COMMUN IMAGE R, V18, P504, DOI 10.1016/j.jvcir.2007.07.003
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yi J., 2007, MULTIMEDIA 07, P847, DOI DOI 10.1145/1291233.1291426
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhao M, 2010, IMAGE VISION COMPUT, V28, P1590, DOI 10.1016/j.imavis.2010.04.002
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P790, DOI 10.1109/TIP.2010.2068553
NR 34
TC 10
Z9 11
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 859
EP 884
DI 10.1007/s11042-013-1702-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400010
DA 2024-07-18
ER

PT J
AU Li, J
   Qian, XM
   Li, Q
   Zhao, YS
   Wang, LJ
   Tang, YY
AF Li, Jing
   Qian, Xueming
   Li, Qing
   Zhao, Yisi
   Wang, Liejun
   Tang, Yuan Yan
TI Mining near duplicate image groups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near duplicate image group; Social media; Image retrieval
AB Most recently the social media sharing websites such as Flickr, Facebook, and Picasa have allowed users to share their personal photos with friends. Moreover, people like to follow, forward their favorite images, which is one of the main source of near duplicate images. And also, the worldwide place of interests such as Roma, Statue of Liberty and London Tower Bridge etc., attract world-wide visitors. For these places, travelers take photos, write travelogues and share them with their social friends. The photos taken from the same place with or without viewpoint variations are near duplicate images. How to detect them is an ad-hoc problem in the area of image analysis and multimedia processing. The existing near duplicate image processing approaches mainly focused on finding the near duplicate images for a given input image, where a query image is needed. However, how to find the near duplicate image groups (NDIG) automatically from the web-scale social images is very challenging. So, in this paper, instead of searching near duplicates image for certain input image, we proposed an automatic NDIG mining approach by utilizing adaptive global feature clustering and local feature refinement. The proposed NDIG mining approach is achieved by utilizing a hierarchical model. It is a two-layer hierarchical structure by first utilizing adaptive global feature clustering based candidate NDIG detection and then using local feature refinement based NDIG verification. The global clustering is mainly for reducing computational cost for processing the large scale image set. The local refinement is for improving NDIG detection performances. Experiments on four datasets show the effectiveness of our approach.
C1 [Li, Jing; Qian, Xueming; Li, Qing; Zhao, Yisi] Xi An Jiao Tong Univ, SMILES LAB, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Wang, Liejun] Xinjiang Univ, Urumqi, Peoples R China.
   [Tang, Yuan Yan] Macau Univ, Macau, Peoples R China.
C3 Xi'an Jiaotong University; Xinjiang University; University of Macau
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, SMILES LAB, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qianxm@mail.xjtu.edu.cn; wljxju@xju.edu.cn
RI Li, Jing/X-3424-2019; Qian, Xueming/E-9867-2015
OI Li, Jing/0000-0003-4007-7697; 
FU National Natural Science Foundation of China (NSFC) [61173109, 60903121,
   61261036]; Microsoft Research Asia
FX This work is supported in part by National Natural Science Foundation of
   China (NSFC) Project No.61173109 and No.60903121, No.61261036, and
   Microsoft Research Asia.
CR [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Battiato S, 2010, MIFOR 10 OCT 29 2010
   Chum J, 2007, COMPUT VIS PATTERN R
   Gao Y., 2011, IEEE T MULTIMED, V13
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22
   Han Y, 2013, SIG PROCESS, V93
   Han Y, 2014, IEEE T MULTIMED
   Hu Y, 2009, IEEE T MULTIMED, V11
   Kennedy L, 2008, GENERATING DIVERSE R
   Lee J, IEEE MULTIMED
   Li J, 2013, GPS ESTIMATION USERS
   Li J, 2014, IEEE T MULTIMED
   Li X, 2011, ICMR 11 APR 17 20 TR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Philbin J, 2010, INT J COMPUT VIS
   Qian X., 2012, Multimedia Tools and Applications, P1
   Sayad IE, 2011, SEMANTICALLY SIGNIFI, V978-1-61284-350-6/11/$26.00
   Song J, 2011, MM 11 NOV 28 DEC 1 2
   Wang B, 2006, LARGE SCALE DUPLICAT
   Wang M, 2010, IEEE T MULTIMED, V12
   Wang X, DUPLICATE SEARCH BAS, DOI [10.1109/JPROC.2012.2193109, DOI 10.1109/JPROC.2012.2193109]
   Wang Y, 2011, LECT NOTES COMPUT SC, V6523, P328
   Wu P, 2011, WSDM 11 FEBR 9 12 20
   Xu D, NEAR DUPLICATE IMAGE
   Xu D, 2010, IEEE T CIRC SYST VID
   Zhou W, 2010, MM 10 OCT 25 29 2010
NR 26
TC 17
Z9 17
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 655
EP 669
DI 10.1007/s11042-014-2008-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300019
DA 2024-07-18
ER

PT J
AU Liu, LW
   Wang, LH
   Zhang, M
AF Liu, Li-Wei
   Wang, Liang-Hao
   Zhang, Ming
TI Depth map Super-Resolution based on joint dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map; Super-resolution; Joint dictionary learning; Sparse
   expression
ID IMAGE SUPERRESOLUTION
AB Although Time-of-Flight (ToF) camera can provide real-time depth information from a real scene, the resolution of depth map captured by ToF camera is rather limited compared to HD color cameras, and thus it cannot be directly used in 3D reconstruction. In order to handle this problem, this paper proposes a novel compressive sensing (CS) and dictionary learning based depth map super-resolution (SR) method, which transforms a low resolution depth map to a high resolution depth map. Different from previous depth map SR methods, this algorithm uses a joint dictionary learning method with both low and high resolution depth maps, and this method also builds a sparse vector classification method which is used in depth map SR. Experimental results show that the proposed method outperforms state-of-the-art methods for depth map super-resolution.
C1 [Liu, Li-Wei; Wang, Liang-Hao; Zhang, Ming] Zhejiang Univ, Inst Informat & Commun Engn, Hangzhou 31002738, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, LH (corresponding author), Zhejiang Univ, Inst Informat & Commun Engn, Zheda Rd, Hangzhou 31002738, Zhejiang, Peoples R China.
EM smartrain123@163.com; wang_sunsky@163.com; zhangm@zju.edu.cn
FU National Natural Science Foundation of China [61271338]; National High
   Technology Research and Development Program (863) of China
   [2012AA011505]; Zhejiang Provincial Natural Science Foundation of China
   [Q14F010020]; Open Projects Program of National Laboratory of Pattern
   Recognition of China [201306308]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61271338), the National High Technology
   Research and Development Program (863) of China (Grant No.
   2012AA011505), the Zhejiang Provincial Natural Science Foundation of
   China (Grant No. Q14F010020), and the Open Projects Program of National
   Laboratory of Pattern Recognition of China (Grant No. 201306308).
CR [Anonymous], 2006, CAN EL PERC DEV KIT
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scharstein Daniel., 2002, MIDDLEBURY STEREO EV
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0
   Wang JJ, 2010, PATTERN RECOGN LETT, V31, P1, DOI 10.1016/j.patrec.2009.09.004
   Wu F., 2013, P ACM INT C MULT, P877
   Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214
   Xu Z, 1998, M2VIP 1998 INT C MEC, P259
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 25
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 467
EP 477
DI 10.1007/s11042-014-2002-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300009
DA 2024-07-18
ER

PT J
AU Wan, Z
   Xiong, NX
   Yang, LT
AF Wan, Zheng
   Xiong, Naixue
   Yang, Laurence T.
TI Cross-layer video transmission over IEEE 802.11e multihop networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transmission; Cross-layer; Wireless multihop networks; Integrated
   routing metric; Adaptive scheduling
ID DESIGN; MECHANISM; PATH
AB With the development of electronics and computer industry, powerful wireless terminals came to facilitate human life. In the last decade, both customers and researchers paid attention to wireless video applications because they contain abundant and visual information. To ensure wireless video transmission, many cross-layer schemes which combined routing and scheduling mechanisms have been proposed. However, characteristics of wireless networks such as limited resource and fluctuated link quality degrade video transmission quality. In this paper, several mechanisms are designed to improve wireless video transmission performance: (1) an integrated routing metric is proposed to evaluate path quality, taking hop count, congestion bottleneck and other parameters of a path into account; (2) traffic assignment and traffic adjustment modules are designed to make routing scheme be flexible to the changing environments; (3) an enhanced link layer scheduling algorithm based on our previous work is proposed. Simulation results show that compared to commonly used schemes, the proposed network layer scheme always provides better performance with various traffic modes. Combined with link layer scheduling algorithm, the performance could be further improved.
C1 [Wan, Zheng; Xiong, Naixue] Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
   [Yang, Laurence T.] St Francis Xavier Univ, Antigonish, NS B2G 1C0, Canada.
C3 Jiangxi University of Finance & Economics; Saint Francis Xavier
   University - Canada
RP Wan, Z (corresponding author), Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
EM cloudcity66@yahoo.com.cn
RI Laurence T. Yang, FCAE/AAA-1898-2019; xiong, naixue/M-4277-2019
OI Laurence T. Yang, FCAE/0000-0002-7986-4244; xiong,
   naixue/0000-0002-0394-4635
FU National Natural Science Foundation of China [61162009, 60963011];
   Science and Technology Project of Jiangxi Education Department
   [GJJ12273]
FX This work was supported by National Natural Science Foundation of China
   (No. 61162009, No. 60963011), and Science and Technology Project of
   Jiangxi Education Department (No. GJJ12273).
CR Cranley N, 2007, GLOB TELECOMM CONF, P2075
   Foh CH, 2007, IEEE T CIRC SYST VID, V17, P1665, DOI 10.1109/TCSVT.2007.903808
   Frias VCarrascal., 2006, 14 IEEE INT C NETWOR, V1, P1
   Hsieh MY, 2007, MULTIMED TOOLS APPL, V34, P155, DOI 10.1007/s11042-006-0086-3
   Hsu JL, 2009, IEEE SIGNAL PROC LET, V16, P268, DOI 10.1109/LSP.2008.2010821
   IEEE, 2005, 80211E2005 IEEE
   Jansang A, 2011, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2011-158
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Kompella S, 2009, IEEE ACM T NETWORK, V17, P212, DOI 10.1109/TNET.2008.925942
   Lai WP, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-59
   Li MD, 2011, J VIS COMMUN IMAGE R, V22, P284, DOI 10.1016/j.jvcir.2011.01.002
   Liao YT, 2011, IEEE T MULTIMEDIA, V13, P132, DOI 10.1109/TMM.2010.2089504
   Lin CH, 2012, COMPUT NETW, V56, P2590, DOI 10.1016/j.comnet.2012.04.004
   Niculescu D, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P339
   Politis I, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.30
   Rong B, 2009, IEEE WIREL COMMUN, V16, P24, DOI 10.1109/MWC.2009.5281252
   Shiang HP, 2007, IEEE J SEL AREA COMM, V25, P770, DOI 10.1109/JSAC.2007.070513
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Wan Z, 2014, MULTIMED TOOLS APPL, V72, P541, DOI 10.1007/s11042-013-1378-z
   Wang H, 2012, PHYS LETT B, V707, P11, DOI 10.1016/j.physletb.2011.12.016
   Wei W, 2009, IEEE T CIRC SYST VID, V19, P165, DOI 10.1109/TCSVT.2008.2009242
   Zhang Y, 2007, IEEE COMMUN LETT, V11, P498, DOI 10.1109/LCOMM.2007.062030
   Zhou L, 2009, IEEE T BROADCAST, V55, P731, DOI 10.1109/TBC.2009.2032795
NR 24
TC 10
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 5
EP 23
DI 10.1007/s11042-013-1447-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300002
DA 2024-07-18
ER

PT J
AU Li, LT
   Pedronette, DCG
   Almeida, J
   Penatti, OAB
   Calumby, RT
   Torres, RD
AF Li, Lin Tzy
   Guimaraes Pedronette, Daniel Carlos
   Almeida, Jurandy
   Penatti, Otavio A. B.
   Calumby, Rodrigo Tripodi
   Torres, Ricardo da Silva
TI A rank aggregation framework for video multimodal geocoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video geotagging; Multimodal retrieval; Rank aggregation; Effectiveness
   measure
ID INFORMATION FUSION; RETRIEVAL
AB This paper proposes a rank aggregation framework for video multimodal geocoding. Textual and visual descriptions associated with videos are used to define ranked lists. These ranked lists are later combined, and the resulting ranked list is used to define appropriate locations for videos. An architecture that implements the proposed framework is designed. In this architecture, there are specific modules for each modality (e. g, textual and visual) that can be developed and evolved independently. Another component is a data fusion module responsible for combining seamlessly the ranked lists defined for each modality. We have validated the proposed framework in the context of the MediaEval 2012 Placing Task, whose objective is to automatically assign geographical coordinates to videos. Obtained results show how our multimodal approach improves the geocoding results when compared to methods that rely on a single modality (either textual or visual descriptors). We also show that the proposed multimodal approach yields comparable results to the best submissions to the Placing Task in 2012 using no extra information besides the available development/training data. Another contribution of this work is related to the proposal of a new effectiveness evaluation measure. The proposed measure is based on distance scores that summarize how effective a designed/tested approach is, considering its overall result for a test dataset.
C1 [Li, Lin Tzy; Guimaraes Pedronette, Daniel Carlos; Almeida, Jurandy; Penatti, Otavio A. B.; Calumby, Rodrigo Tripodi; Torres, Ricardo da Silva] Univ Campinas UNICAMP, Inst Comp, RECOD Lab, BR-13083852 Campinas, SP, Brazil.
   [Li, Lin Tzy] CPqD Fdn, Telecommun Res & Dev Ctr, BR-13086902 Campinas, SP, Brazil.
   [Guimaraes Pedronette, Daniel Carlos] Univ Estadual Paulista UNESP, Dept Stat Appl Math & Comp, BR-13506900 Rio Claro, SP, Brazil.
   [Calumby, Rodrigo Tripodi] Univ Feira Santana UEFS, Dept Exact Sci, BR-44036900 Feira De Santana, BA, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual Paulista
RP Li, LT (corresponding author), Univ Campinas UNICAMP, Inst Comp, RECOD Lab, BR-13083852 Campinas, SP, Brazil.
EM lintzyli@ic.unicamp.br; dcarlos@ic.unicamp.br;
   jurandy.almeida@ic.unicamp.br; penatti@ic.unicamp.br;
   tripodi@ic.unicamp.br; rtorres@ic.unicamp.br
RI Calumby, Rodrigo/ABB-5699-2020; Pedronette, Daniel C. G./E-7817-2015;
   Pedronette, Daniel/X-9057-2019; Almeida, Jurandy/I-2177-2012; Torres,
   Ricardo da S./C-4526-2012
OI Calumby, Rodrigo/0000-0001-8515-265X; Pedronette, Daniel C.
   G./0000-0002-2867-4838; Pedronette, Daniel/0000-0002-2867-4838; Almeida,
   Jurandy/0000-0002-4998-6996; Torres, Ricardo/0000-0001-9772-263X
FU CAPES (Brazilian Federal Agency for Support and Evaluation of Graduate
   Education); FAPESP (Sao Paulo Research Foundation) [2011/11171-5,
   2009/10554-8]; CNPq (National Council for Scientific and Technological
   Development) [306580/2012-8, 484254/2012-0]; CPqD Foundation
   (Telecommunications Research and Development Center); Fundacao de Amparo
   a Pesquisa do Estado de Sao Paulo (FAPESP) [11/11171-5] Funding Source:
   FAPESP
FX The authors thank CAPES (Brazilian Federal Agency for Support and
   Evaluation of Graduate Education), FAPESP (Sao Paulo Research
   Foundation) grants 2011/11171-5 and 2009/10554-8, and CNPq (National
   Council for Scientific and Technological Development) grants
   306580/2012-8 and 484254/2012-0, as well as CPqD Foundation
   (Telecommunications Research and Development Center) for their support.
   Additionally we would like to thank for the suggestions and questions
   arisen by the anonymous reviewers that gave us the chance to improve our
   paper.
CR Almeida Jurandy, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3673, DOI 10.1109/ICIP.2011.6116516
   Andrade Felipe S. P., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P845, DOI 10.1007/978-3-642-33275-3_104
   [Anonymous], P ACM SIGIR C SIGIR
   [Anonymous], TERR COGN 2011 WORKS
   [Anonymous], 1998, P 11 WORKSH ALG ENG
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], P MEDIAEVAL WORKSH
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], INT C MULT RETR
   [Anonymous], WORKING NOTES P MED
   [Anonymous], THESIS UNICAMP CAMPI
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 1999 ESRI US C
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], ICMR
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], INT C MULT RETR
   [Anonymous], INT C MULT RETR
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], INT C MULT RETR
   [Anonymous], P MEDIAEVAL WORKSH
   [Anonymous], 2012, LBSN 12 P 5 ACM SIGS, DOI DOI 10.1145/2442796.2442805
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], INT C MULT RETR
   [Anonymous], P 6 ACM INT C IM VID
   [Anonymous], P MEDIAEVAL WORKSH
   [Anonymous], P 2011 ACM WORKSH SO
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Coppersmith D, 2010, ACM T ALGORITHMS, V6, DOI 10.1145/1798596.1798608
   Cormack GV, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P758, DOI 10.1145/1571941.1572114
   Croft W. B., 2002, ADV INFORM RETRIEVAL, V7, P1
   Faria F.F., 2010, Proceedings of the International Conference on Multimedia information retrieval, P285, DOI DOI 10.1145/1743384.1743434
   Fishburn Peter C, 1988, Nonlinear preference and utility theory
   Fox E. A., 1994, Second Text REtrieval Conference (TREC-2) (NIST-SP 500-215), P243
   Friendly M, 2002, AM STAT, V56, P316, DOI 10.1198/000313002533
   Pedronette DCG, 2014, MULTIMED TOOLS APPL, V69, P689, DOI 10.1007/s11042-012-1115-z
   Pedronette DCG, 2011, J VISUAL LANG COMPUT, V22, P453, DOI 10.1016/j.jvlc.2011.08.001
   Jones CB, 2008, INT J GEOGR INF SCI, V22, P219, DOI 10.1080/13658810701626343
   Kalantidis Y, 2011, MULTIMED TOOLS APPL, V51, P555, DOI 10.1007/s11042-010-0651-7
   Kludas J, 2008, LECT NOTES COMPUT SC, V4918, P147, DOI 10.1007/978-3-540-79860-6_12
   Kokar M. M., 2004, Information Fusion, V5, P189, DOI 10.1016/j.inffus.2003.11.001
   Kozorovitsky AK, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P893
   Larson RR, 2009, LECT NOTES COMPUT SC, V5714, P461, DOI 10.1007/978-3-642-04346-8_59
   Li L.T., 2012, P 20 INT C ADV GEOGR, P474
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Montague M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P538, DOI 10.1145/584792.584881
   Poh N, 2005, IEEE T SIGNAL PROCES, V53, P4384, DOI 10.1109/TSP.2005.857006
   Sculley D, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P587
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   YOUNG HP, 1974, J ECON THEORY, V9, P43, DOI 10.1016/0022-0531(74)90073-8
   Zhang H., 2005, Proceedings of the 22nd International Conference on Machine Learning, P1020
   Zhou X, 2010, LECT NOTES COMPUT SC, V6388, P129, DOI 10.1007/978-3-642-17711-8_14
NR 56
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1323
EP 1359
DI 10.1007/s11042-013-1588-4
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200012
DA 2024-07-18
ER

PT J
AU Kim, D
   Kim, D
   Jun, S
   Rho, S
   Hwang, E
AF Kim, Daehoon
   Kim, Daeyong
   Jun, Sanghoon
   Rho, Seungmin
   Hwang, Eenjun
TI TrendsSummary: a platform for retrieving and summarizing trendy
   multimedia contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Trends; Multimedia contents recommendation; Summarization;
   Naive Bayes classifier; TreeMap
AB With the flood and popularity of various multimedia contents on the Internet, searching for appropriate contents and representing them effectively has become an essential part for user satisfaction. So far, many contents recommendation systems have been proposed for this purpose. A popular approach is to select hot or popular contents for recommendation using some popularity metric. Recently, various social network services (SNSs) such as Facebook and Twitter have become a widespread social phenomenon owing to the smartphone boom. Considering the popularity and user participation, SNS can be a good source for finding social interests or trends. In this study, we propose a platform called TrendsSummary for retrieving trendy multimedia contents and summarizing them. To identify trendy multimedia contents, we select candidate keywords from raw data collected from Twitter using a syntactic feature-based filtering method. Then, we merge various keyword variants based on several heuristics. Next, we select trend keywords and their related keywords from the merged candidate keywords based on term frequency and expand them semantically by referencing portal sites such as Wikipedia and Google. Based on the expanded trend keywords, we collect four types of relevant multimedia contents-TV programs, videos, news articles, and images-from various websites. The most appropriate media type for the trend keywords is determined based on a naive Bayes classifier. After classification, appropriate contents are selected from among the contents of the selected media type. Finally, both trend keywords and their related multimedia contents are displayed for effective browsing. We implemented a prototype system and experimentally demonstrated that our scheme provides satisfactory results.
C1 [Kim, Daehoon; Kim, Daeyong; Jun, Sanghoon; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
C3 Korea University; Sungkyul University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM kdh812@korea.ac.kr; ritgd05@korea.ac.kr; ysbhjun@korea.ac.kr;
   smrho@sungkyul.edu; ehwang04@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU National Research Foundation of Korea(NRF) - Ministry of Education
   [NRF-2013R1A1A2012627]; MSIP(Ministry of Science, ICT&Future Planning),
   Korea, under the C-ITRC(Convergence Information Technology Research
   Center) [NIPA-2013-H0301-13-3006]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (NRF-2013R1A1A2012627) and the MSIP(Ministry of Science,
   ICT&Future Planning), Korea, under the C-ITRC(Convergence Information
   Technology Research Center) support program (NIPA-2013-H0301-13-3006)
   supervised by the NIPA(National IT Industry Promotion Agency)
CR Alvanaki F., 2011, P 2011 ACM SIGMOD IN, P1271
   Alvanaki Foteini., 2012, P 15 INT C EXTENDING, P336, DOI DOI 10.1145/2247596.2247636
   [Anonymous], 2007, IJCAI
   Barzilay R, 2005, COMPUT LINGUIST, V31, P297, DOI 10.1162/089120105774321091
   Cano P., 2005, 13th Annual ACM International Conference on Multimedia, P211, DOI 10.1145/1101149.1101181
   Chen HC, 2005, J INTELL INF SYST, V24, P113, DOI 10.1007/s10844-005-0319-3
   DeFrancisciMorales G, 2012, P 5 ACM INT C WEB SE, P153, DOI DOI 10.1145/2124295.2124315
   Eck D, 2007, NEUR INF PROC SYST C, V20, pM70
   Fang F., 2011, P 21 ANN WORKSH INF, P49
   Kim D, 2013, INT J SMART HOME, V7, P209
   Kim D, 2014, SECUR COMMUN NETW, V7, P1517, DOI 10.1002/sec.735
   Kim D, 2012, ENG APPL ARTIF INTEL, V25, P1373, DOI 10.1016/j.engappai.2012.03.005
   Kleinberg J., 2002, P 8 ACM SIGKDD INT C
   Kuo Byron YL, 2007, P 16 INT C WORLD WID, P1203, DOI [DOI 10.1145/1242572.1242766, 10.1145/1242572.1242766]
   Lai CF, 2011, FUTURE GENER COMP SY, V27, P823, DOI 10.1016/j.future.2010.10.002
   Liu J, 2010, IUI 2010, P31
   Mathioudakis M., 2010, P 2010 ACM SIGMOD IN, P1155
   Otterbacher J, 2008, INFORM PROCESS MANAG, V44, P931, DOI 10.1016/j.ipm.2007.06.002
   Phelan O, 2011, LECT NOTES COMPUT SC, V6611, P448, DOI 10.1007/978-3-642-20161-5_44
   Quercia D, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P247
   Shin C, 2009, IEEE T CONSUM ELECTR, V55, P927, DOI 10.1109/TCE.2009.5174476
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Si Xiance., 2009, Journal of Computational Information Systems, V6, P23
   Yihong Gong, 2001, SIGIR Forum, P19
   Yokomoto Daisuke, 2012, Web Technologies and Applications. Proceedings of the APWeb 2012 International Workshops: SenDe, IDP, IEKB, MBC, P114, DOI 10.1007/978-3-642-29426-6_15
NR 25
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 857
EP 872
DI 10.1007/s11042-013-1547-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700014
DA 2024-07-18
ER

PT J
AU Sun, ZZ
   Tan, YA
   Li, YZ
AF Sun Zhizhuo
   Tan Yu-An
   Li Yuanzhang
TI An energy-efficient storage for video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Energy saving; Storage; RAID
AB With the rapid growth of the video surveillance applications, the storage energy consumption of video surveillance is more noticeable, but existed energy-saving methods for massive storage system most concentrate on the data centers mainly with random accesses. The storage of video surveillance has inherent access pattern, and requires special energy-saving approach to save more energy. An energy-efficient data layout for video surveillance, Semi-RAID is proposed. It adopts partial-parallelism strategy, which partitions disk data into different groups, and implements parallel accesses in each group. Grouping benefits to realize only partial disks working and the rest ones idle, and inner-group parallelism provides the performance guarantee. In addition, greedy strategy for address allocation is adopted to effectively prolong the idle period of the disks; particular Cache strategies are used to filter the small amount of random accesses. The energy-saving efficiency of Semi-RAID is verified by a simulated video surveillance consisting of 32 cameras with D1 resolution. The experiment shows: Semi-RAID can save 45 % energy than Hibernator; 80 % energy than PARAID; 33 % energy than MAID; 79 % energy than eRAID-5, while providing single disk fault tolerance and meeting the performance requirement, such as throughput.
C1 [Sun Zhizhuo; Tan Yu-An; Li Yuanzhang] Beijing Inst Technol, Sch Comp, Beijing 100081, Peoples R China.
   [Sun Zhizhuo] Dezhou Univ, Dept Comp, Dezhou, Shandong, Peoples R China.
C3 Beijing Institute of Technology; Dezhou University
RP Sun, ZZ (corresponding author), Beijing Inst Technol, Sch Comp, Beijing 100081, Peoples R China.
EM sunzhizhuo@126.com
CR [Anonymous], 1988, A case for redundant arrays of inexpensive disks RAID, DOI DOI 10.1145/50202.50214
   Atrey PK, 2011, MULTIMED TOOLS APPL, V51, P697, DOI 10.1007/s11042-010-0649-1
   Bisson T, 2007, IEEE IPCCC, P236, DOI 10.1109/PCCC.2007.358900
   Carrera E.V., 2003, Proceedings of the 17th annual international conference on Supercomputing, ICS '03, P86
   Colarelli Dennis., 2002, SUPERCOMPUTING 02, P1, DOI DOI 10.1109/SC.2002.10058
   Deng YH, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922660
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Guerra J., 2011, P 9ST USENIX C FAST, P20
   Gurumurthi S, 2003, CONF PROC INT SYMP C, P169, DOI 10.1109/ISCA.2003.1206998
   Li X, 2011, 2011 SECOND ETP/IITA CONFERENCE ON TELECOMMUNICATION AND INFORMATION (TEIN 2011), VOL 1, P1, DOI 10.1109/ICCSN.2011.6014661
   Narayanan D, 2008, PROCEEDINGS OF THE 6TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '08), P253
   Otoo E, 2010, LECT NOTES COMPUT SC, V6187, P322, DOI 10.1007/978-3-642-13818-8_24
   Pinheiro E., 2004, INT C SUPERCOMPUTING, P68, DOI DOI 10.1145/1006209.1006220
   ROSENBLUM M, 1992, ACM T COMPUT SYST, V10, P26, DOI 10.1145/146941.146943
   Saini M, 2012, IEEE T MULTIMEDIA, VPP, P1
   Schroeder B, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 5TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES ( FAST '07), P1
   Son S.W., 2005, ICS 05 P 19 ANN INT, P274
   Storer MW, 2008, PROCEEDINGS OF THE 6TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '08), P1, DOI 10.1145/1456469.1456471
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Wang J, 2008, IEEE T COMPUT, V57, P359, DOI 10.1109/TC.2007.70821
   Weddle C, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 5TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES ( FAST '07), P245
   Xie T, 2008, LECT NOTES COMPUT SC, V5374, P529
   Zedlewski J, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 2ND USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST'03), P217
   Zhu Q, 2007, THESIS U ILLINOIS UR
   Zhu Q, 2005, P 20 ACM S OP SYST P, P177, DOI DOI 10.1145/1095809.1095828
NR 25
TC 6
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 151
EP 167
DI 10.1007/s11042-012-1262-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700008
DA 2024-07-18
ER

PT J
AU Wang, CH
   Liu, HS
   Hsieh, CC
AF Wang, Chia-Hui
   Liu, Hsing-Shao
   Hsieh, Ching-Chia
TI Rate-sensitive leverage of QoS and QoP for ubiquitous video streaming
   via buffer-aware feedback control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure VoD; Quality of service; Quality of protection; Playback buffer
   occupancy; Feedback control
ID ENCRYPTION; CRYPTANALYSIS; IPTV
AB Providing real-time Internet video streaming anytime, anywhere and using any devices from different access networks preserves more challenges to equilibrate the quality of service (QoS) and security protection (QoP). Because encryption/decryption for video packets are time-consuming processes to protect real-time video streaming services from eavesdropping, our observation is that the playback buffer occupancy (PBO) can simply indicate time availability to adjust security level to affect the packet sending rate. In this paper, we present an end-to-end buffer-aware feedback control from client PBO for effectively securing media streaming for heterogeneous clients over ubiquitous Internet. That is, security-level adjustments can be applied further to keep PBO running away from overflow and underflow to pursue an effective leverage between QoS and QoP. To further boost the protection, we also apply the Diffie-Hellman key negotiation method to provide the dynamic key changes. Moreover, since the running PBO will vary on the dynamics of Internet from access time, client devices and access networks, the different applied security levels and key changes during the video streaming session will make eavesdropper more difficult to recover all the encrypted videos delivered in public networks. We demonstrate the leverage performance in preserving both QoS and QoP for ubiquitous video streaming in our proposed schemes by comprehensive experiments on a true VoD system. The experimental results show our secure VoD scheme can achieve cost-effective leverage of QoS and QoP from different inserted network dynamics, even if client buffer size is limited to 256 KB only.
C1 [Wang, Chia-Hui] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Guei Shan Dist 333, Taoyuan County, Taiwan.
   [Liu, Hsing-Shao] YES Information Inc, Multimedia Commun Business Div, Taipei 110, Taiwan.
   [Hsieh, Ching-Chia] Natl Taiwan Univ, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University
RP Wang, CH (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 De Ming Rd, Guei Shan Dist 333, Taoyuan County, Taiwan.
EM wangch@mail.mcu.edu.tw; sidney.liu@yesinfo.com.tw; cchsieh@im.ntu.edu.tw
OI Wang, Chia-Hui/0000-0002-3125-8632
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   Alattar A, 1999, P IEEE INT C IM PROC
   Aly SA, 2003, CTI S C NOV
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Biham E., 1993, DIFFERENTIAL CRYPTAN
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Choo E, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P60
   Courtois NT, 2007, LECT NOTES COMPUT SC, V4887, P152
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Data Encryption Algorithm (DEA), X3921981 ANSI
   Diffie W., 1976, NEW DIRECTIONS CRYPT
   Furht B, 2004, SURVEY MULTIMEDIA SE
   Huang YS, 2009, IEEE T MULTIMEDIA, V11, P1072, DOI 10.1109/TMM.2009.2026085
   Kankanhalli MS, 2002, IEEE T CONSUM ELECTR, V48, P356, DOI 10.1109/TCE.2002.1010142
   Lai Jen-Chieh, 2006, IEEE PAC RIM S IM VI
   Lei Tang, 1996, Proceedings ACM Multimedia 96, P219, DOI 10.1145/244130.244209
   Liu FW, 2005, LECT NOTES COMPUT SC, V3677, P88
   Liu J, 2006, NAS: 2006 INTERNATIONAL WORKSHOP ON NETWORKING, ARCHITECTURE, AND STORAGES, PROCEEDINGS, P183
   Liu ZY, 2005, IEEE INT SYM MULTIM, P69
   Marshall KP, 1999, J BUS ETHICS, V19, P81, DOI 10.1023/A:1006154023743
   Matsui M, 1993, P EUROCRYPT 93
   Meyer J., 1995, SECURITY MECH MULTIM
   Ong CS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P137
   Pfeffer P, 2006, FIBER INTEGRATED OPT, V25, P325, DOI 10.1080/01468030600816979
   Qiao L, 1998, COMPUT GRAPH, V22, P437, DOI 10.1016/S0097-8493(98)00033-8
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Shi C, 1999, P INT C PAR DIST PRO
   Shi CG, 1998, SYM REL DIST SYST, P381, DOI 10.1109/RELDIS.1998.740527
   Spanos G. A., 1995, Proceedings Fourth International Conference on Computer Communications and Networks (ICCCN'95) (Cat. No.95TB8110), P2, DOI 10.1109/ICCCN.1995.540095
   Sun YS, 1998, IEICE T COMMUN B, VE81-B
   Tosun AS, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P157, DOI 10.1109/ITCC.2001.918783
   Tosun AS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P119, DOI 10.1109/ICME.2000.869559
   Wang CH, 2001, MILT INT VID TECHN 2
   Wang CH, 2003, IEEE GLOB TEL C
   Wang CH, 2011, J NETW COMPUT APPL, V34, P1545, DOI 10.1016/j.jnca.2010.10.011
   Wiener M, 1994, LNCS, V773
   WIENER MJ, 1990, IEEE T INFORM THEORY, V36, P553, DOI 10.1109/18.54902
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Xiao Y, 2007, IEEE COMMUN MAG, V45, P126, DOI 10.1109/MCOM.2007.4378332
   Yang C.H., 2001, P 2001 S CRYPT INF S, P727
   Yang M, 2004, IEEE POTENTIALS, V23, P28
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zeng WJ, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P285, DOI 10.1145/319463.319627
   ZHANG H, 1994, J HIGH SPEED NETWORK, V3
   Zhu BB, 2005, IEEE T MULTIMEDIA, V7, P222, DOI 10.1109/TMM.2005.843340
   Zhu BB, 2006, MULTIMEDIA SECURITY
NR 46
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 737
EP 761
DI 10.1007/s11042-012-1186-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700007
DA 2024-07-18
ER

PT J
AU Gao, SB
   Yang, J
   Yan, YY
AF Gao, Shangbing
   Yang, Jian
   Yan, Yunyang
TI A novel multiphase active contour model for inhomogeneous image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary fitting (LBF) model; Intensity inhomogeneity; Active
   contour model; Chan-Vese (CV) model; Natural image
ID INTENSITY NONUNIFORMITY; AUTOMATIC CORRECTION; EVOLUTION; MUMFORD
AB The problem of image segmentation has been investigated with a focus on inhomogeneous multiphase image segmentation. Intensity inhomogeneity is an undesired phenomenon that represents the main obstacle for magnetic resonance (MR) and natural images segmentation. The complex images usually contain an arbitrary number of objects. This paper presents a new multiphase active contour model method for simultaneous regions classification of MR images and natural images without bias field correction. In this model, a simple and effective initialization method is taken to speed up the curve evolution toward final results; a new multiphase level set method is proposed to segment the multiple regions. This model not only extracts multiple objects simultaneously, but also provides smooth and accurate boundaries of the objects. The results for experiments on several synthetic and real images demonstrate the effectiveness and accuracy of our model.
C1 [Gao, Shangbing; Yang, Jian; Yan, Yunyang] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
   [Gao, Shangbing; Yan, Yunyang] Huaiyin Inst Technol, Fac Comp Engn, Huaian 223003, Peoples R China.
C3 Nanjing University of Science & Technology; Huaiyin Institute of
   Technology
RP Gao, SB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
EM luxiaofen_2002@126.com; csjyang@njust.edu.cn
FU Qing Lan project of Jiang Su; Major Program of the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [11KJA460001]; Jiangsu 333 Project; Huai'an 533 Project; Major Program
   for scientific and technological research in University of China
   [311024]
FX This work was supported by the Qing Lan project of Jiang Su, the Major
   Program of the Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China (11KJA460001), Jiangsu 333 Project,
   Huai'an 533 Project and supported in part by the Major Program for
   scientific and technological research in University of China under the
   Grant No. 311024.
CR [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   Boesen K, 2004, NEUROIMAGE, V22, P1255, DOI 10.1016/j.neuroimage.2004.03.010
   Butina D, 1999, J CHEM INF COMP SCI, V39, P747, DOI 10.1021/ci9803381
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen WJ, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1307
   Chen Zhi-bin, 2008, Acta Electronica Sinica, V36, P1733
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   Li CM, 2005, PROC CVPR IEEE, P430
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P885, DOI 10.1109/42.811268
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vokurka EA, 1999, JMRI-J MAGN RESON IM, V10, P550, DOI 10.1002/(SICI)1522-2586(199910)10:4<550::AID-JMRI8>3.0.CO;2-Q
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
NR 19
TC 5
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2321
EP 2337
DI 10.1007/s11042-013-1553-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300013
DA 2024-07-18
ER

PT J
AU Akrami, F
   Zargari, F
AF Akrami, Farahnaz
   Zargari, Farzad
TI An efficient compressed domain video indexing method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video indexing; Video retrieval; Compressed domain; H.264/AVC standard
AB Video indexing is employed to represent the features of video sequences. Motion vectors derived from compressed video are preferred for video indexing because they can be accessed by partial decoding; thus, they are used extensively in various video analysis and indexing applications. In this study, we introduce an efficient compressed domain video indexing method and implement it on the H.264/AVC coded videos. The video retrieval experimental evaluations indicate that the video retrieval based on the proposed indexing method outperforms motion vector based video retrieval in 74 % of queries with little increase in computation time. Furthermore, we compared our method with a pixel level video indexing method which employs both temporal and spatial features. Experimental evaluation results indicate that our method outperforms the pixel level method both in performance and speed. Hence considering the speed and precision characteristics of indexing methods, the proposed method is an efficient indexing method which can be used in various video indexing and retrieval applications.
C1 [Akrami, Farahnaz] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Zargari, Farzad] Res Inst ICT, Dept Informat Technol, Tehran, Iran.
C3 Islamic Azad University
RP Zargari, F (corresponding author), Res Inst ICT, Dept Informat Technol, Tehran, Iran.
EM f.akrami@srbiau.ac.ir; zargari@itrc.ac.ir
RI Akrami, Farahnaz/ABE-5418-2020
CR Amir Arnon., 2003, NIST TRECVID-2003
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], JOINT MOD REF SOFTW
   Ardizzone E, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P725, DOI 10.1109/MMCS.1999.778574
   Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   Babu RV, 2002, PATTERN RECOGN LETT, V23, P1203, DOI 10.1016/S0167-8655(02)00067-3
   Barla A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P513
   Benois-Pineau J., 2010, INT C IMAGE PROCESSI, P3
   Campbell M, 2006, P TREC VI RETR EV TR
   Gao L, 2009, IEEE T CIRC SYST VID, V19, P1566, DOI 10.1109/TCSVT.2009.2026813
   Lie WN, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P237
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Manjunath B.S., 2002, Introduction to MPEG-7: multimedia content description interface, V1
   Mehrabi M, 2010, IEEE T CONSUM ELECTR, V56, P1801, DOI 10.1109/TCE.2010.5606329
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   Natsev A, 2010, P TRECVID 2010 WORKS
   Pan XF, 2007, IEEE T CONSUM ELECTR, V53, P769, DOI 10.1109/TCE.2007.381758
   Sun XD, 2001, LECT NOTES COMPUT SC, V2195, P450
   Takaya K, 2006, I S INTELL SIG PROC, P414
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Yao-Hui Qin, 2010, 2010 International Conference on Computational Problem-Solving (ICCP 2010), P323
   Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112
   Yi HR, 2005, PATTERN RECOGN LETT, V26, P1221, DOI 10.1016/j.patrec.2004.11.011
   Zampoglou Markos, 2007, 2007 IEEE Workshop on Machine Learning for Signal Processing, P176, DOI 10.1109/MLSP.2007.4414302
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
   Zhao JH, 2011, COMPUT SCI INF SYST, V8, P821, DOI 10.2298/CSIS101012030Z
NR 27
TC 6
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 705
EP 721
DI 10.1007/s11042-013-1403-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800032
DA 2024-07-18
ER

PT J
AU Wang, YH
   Zhang, ZX
   Wang, KY
   Deng, HR
   Ma, B
AF Wang, Yunhong
   Zhang, Zhaoxiang
   Wang, Kaiyue
   Deng, Haoran
   Ma, Bin
TI On-line signature verification based on spatio-temporal correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE On-line signature; Biometrics; Spatio-temporal correlation; Texture
   representation; Multiple templates
AB We address the problem of on-line signature representation and verification. A novel strategy is proposed in this paper by combining texture based image analysis and spatio-temporal representation. Firstly, a correlation based method is proposed to describe spatio-temporal information between sampling points, which is then converted to traditional 2D intensity images. Secondly, abundant texture analysis methods are adopted to construct effective features for high accuracy verification. Furthermore, a template selection strategy based on intra-class variations is presented to further enhance the performance of signature verification. Extensive experiments are conducted on the SVC2004 database and experimental results demonstrate the inspiring performance of our proposed methods.
C1 [Wang, Yunhong; Zhang, Zhaoxiang; Wang, Kaiyue; Deng, Haoran; Ma, Bin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, ZX (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM zxzhang@buaa.edu.cn
FU National Basic Research Program of China [2010CB327902]; National
   Natural Science Foundation of China [60873158, 61005016, 61061130560];
   Open Projects Program of National Laboratory of Pattern Recognition
FX This work is funded by the National Basic Research Program of China (No.
   2010CB327902), the National Natural Science Foundation of China (No.
   60873158, No. 61005016, No. 61061130560) and the Open Projects Program
   of National Laboratory of Pattern Recognition.
CR Chen Y, 2002, P SOC PHOTO-OPT INS, V4875, P744, DOI 10.1117/12.477063
   Deng HR, 2009, LECT NOTES COMPUT SC, V5754, P75, DOI 10.1007/978-3-642-04070-2_9
   Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012
   Fuentes M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P253, DOI 10.1109/IWFHR.2002.1030918
   Gruber C, 2010, IEEE T SYST MAN CY B, V40, P1088, DOI 10.1109/TSMCB.2009.2034382
   Hu L, 2007, P INT C WAV AN PATT
   Igarza JJ, 2003, P CIARP
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Jain AK, 2002, PATTERN RECOGN, V35, P2963, DOI 10.1016/S0031-3203(01)00240-0
   Jain AK, 2003, P 4 AUD VID BAS BIOM, P1061
   Ji HW, 2005, P INT C INT COMP
   Kashi RS, 1997, PROC INT CONF DOC, P253, DOI 10.1109/ICDAR.1997.619851
   Khalil MI, 2009, IEEE IMAGE PROC, P2713, DOI 10.1109/ICIP.2009.5414166
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Kovari B., 2010, WSEAS Latest Trends on Computers, P473
   Lejtman DZ, 2001, PROC INT CONF DOC, P992, DOI 10.1109/ICDAR.2001.953934
   Li B, 2004, P ICBA
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   MOHANKRISHNAN N, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P2303, DOI 10.1109/ISCAS.1993.394223
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Osman T. A., 2007, IEEE WORKSH SIGN PRO
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Quan ZH, 2007, INT J COMPUT SCI NET, V7, P313
   Richiardi J, 2005, PROC INT CONF DOC, P625, DOI 10.1109/ICDAR.2005.152
   Tian Y, 2003, PATTERN RECOGN, V36, P649, DOI 10.1016/S0031-3203(02)00105-X
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
NR 26
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 879
EP 904
DI 10.1007/s11042-013-1408-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800040
DA 2024-07-18
ER

PT J
AU Amato, G
   Gennaro, C
   Savino, P
AF Amato, Giuseppe
   Gennaro, Claudio
   Savino, Pasquale
TI MI-File: using inverted files for scalable approximate similarity search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity searching; Access methods; Multimedia information retrieval
ID NEAREST-NEIGHBOR; PROXIMITY; RETRIEVAL
AB We propose a new efficient and accurate technique for generic approximate similarity searching, based on the use of inverted files. We represent each object of a dataset by the ordering of a number of reference objects according to their distance from the object itself. In order to compare two objects in the dataset, we compare the two corresponding orderings of the reference objects. We show that this representation enables us to use inverted files to obtain very efficiently a very small set of good candidates for the query result. The candidate set is then reordered using the original similarity function to obtain the approximate similarity search result. The proposed technique performs several orders of magnitude better than exact similarity searches, still guaranteeing high accuracy. To also demonstrate the scalability of the proposed approach, tests were executed with various dataset sizes, ranging from 200,000 to 100 million objects.
C1 [Amato, Giuseppe; Gennaro, Claudio; Savino, Pasquale] ISTI CNR, I-56124 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Amato, G (corresponding author), ISTI CNR, Via G Moruzzi 1, I-56124 Pisa, Italy.
EM giuseppe.amato@isti.cnr.it; claudio.gennaro@isti.cnr.it;
   pasquale.savino@isti.cnr.it
RI Savino, Pasquale/AAY-7287-2020; Amato, Giuseppe/F-2227-2013; Gennaro,
   Claudio/AAH-5171-2019
OI Amato, Giuseppe/0000-0003-0171-4315; Gennaro,
   Claudio/0000-0002-3715-149X; Savino, Pasquale/0000-0002-8841-5440
CR Amato G, 2003, ACM T INFORM SYST, V21, P192, DOI 10.1145/763693.763696
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2008, P 3 INT C SCALABLE I
   [Anonymous], 1954, THESIS MIT
   [Anonymous], 2009, P 2 WORKSH VER LARG
   [Anonymous], 1983, INTRO MODERN INFORM
   Bawa M, 2005, Proceedings of the 14th International Conference on World Wide Web-WWW'05, P651, DOI [DOI 10.1145/1060745.1060840, 10.1145/1060745.1060840]
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Bozkaya T., 1997, SIGMOD Record, V26, P357, DOI 10.1145/253262.253345
   Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574
   Chavez E, 2008, IEEE T PATTERN ANAL, V30, P1647, DOI 10.1109/TPAMI.2007.70815
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P244, DOI 10.1109/ICDE.2000.839417
   Diaconis P, 1988, SER IMS LECT NOTES M, V11
   Egecioglu O., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P219, DOI 10.1145/354756.354822
   Esuli A, 2012, INFORM PROCESS MANAG, V48, P889, DOI 10.1016/j.ipm.2010.11.011
   Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812
   Ferhatosmanoglu H, 2001, PROC INT CONF DATA, P503, DOI 10.1109/ICDE.2001.914864
   Gennaro C, 2010, LECT NOTES COMPUT SC, V6273, P55, DOI 10.1007/978-3-642-15464-5_8
   Hjaltason GR, 2003, ACM T DATABASE SYST, V28, P517, DOI 10.1145/958942.958948
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ogras U.Y., 2003, Proceedings of the twelfth international conference on Information and knowledge management, New York, NY, P99
   Patella M, 2009, J DISCRET ALGORITHMS, V7, P36, DOI 10.1016/j.jda.2008.09.014
   SAPIR, 2009, SEARCH AUD VIS CONT
   SHAPIRO M, 1977, COMMUN ACM, V20, P339, DOI 10.1145/359581.359599
   Skala M, 2009, J DISCRET ALGORITHMS, V7, P49, DOI 10.1016/j.jda.2008.09.011
   UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weber R, 2000, LECT NOTES COMPUT SC, V1777, P21
   Weiss A., 2008, NIPS, P1753
   Witten IH, 1999, BELL MANAGING GIGABY
   Xiong Wan, 2000, Knowledge and Information Systems, V2, P161, DOI 10.1007/s101150050009
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
   Zezula P, 1998, VLDB J, V7, P275, DOI 10.1007/s007780050069
   Zezula P, 2006, SER ADV DATABASE SYS, V32
NR 36
TC 37
Z9 38
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1333
EP 1362
DI 10.1007/s11042-012-1271-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000017
DA 2024-07-18
ER

PT J
AU Chen, LW
   Cong, M
   Huang, J
   Li, L
   Liu, HW
   Qian, C
AF Chen, Liwei
   Cong, Ming
   Huang, Jing
   Li, Ling
   Liu, Hongwei
   Qian, Cheng
TI A novel hardware/software partitioning for SIMD-based real-time AVS
   video decoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hardware/software partitioning; SIMD; AVS; Video decoder
ID PROCESSOR; ARCHITECTURE
AB Decoding high-quality videos in real-time is becoming more and more difficult with the increasing resolution. In this paper, a novel hardware/software (HW/SW) partitioning is proposed with powerful SIMD (single instruction multiple data) instructions for the real-time AVS video decoder. Since most key functions that need large amounts of computations are optimized by SIMD instead of hardware, the distribution of workload between hardware and software is balanceable, and the performance of the video decoder is improved. Besides, the generality and programmability are also maintained. The proposed method is implemented on a 32-bit dual-issue RISC processor with 256-bit vector extension. The experimental results of conformation AVS test sequences show that the video decoder system can support the real-time decoding of AVS 1080p videos at 30 fps, and improve performance over 100 times compared to the original processor without the proposed method. Moreover, this approach could be easily applied to other video decoders, such as H.264 and VC-1.
C1 [Chen, Liwei; Cong, Ming; Huang, Jing; Li, Ling; Liu, Hongwei; Qian, Cheng] Chinese Acad Sci, Key Lab Comp Syst & Architecture, Beijing, Peoples R China.
   [Chen, Liwei; Cong, Ming; Huang, Jing; Li, Ling; Liu, Hongwei; Qian, Cheng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Chen, Liwei; Huang, Jing; Liu, Hongwei] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
   [Chen, Liwei; Cong, Ming; Huang, Jing; Li, Ling; Liu, Hongwei; Qian, Cheng] Loongson Technol Corp Ltd, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Chen, LW (corresponding author), Chinese Acad Sci, Key Lab Comp Syst & Architecture, Beijing, Peoples R China.
EM chenliwei@ict.ac.cn; congming@ict.ac.cn; huangjing@ict.ac.cn;
   liling@ict.ac.cn; liuhongwei@ict.ac.cn; qiancheng@ict.ac.cn
OI Li, Ling/0000-0001-8877-9052
FU National Sci&Tech Major Project [2009ZX01028-002-003,
   2009ZX01029-001-003, 2010ZX01036-001-002]; National Natural Science
   Foundation of China [60921002, 61003064, 61050002, 61070025, 61100163,
   61133004, 61173001, 61222204]; National High Technology Development 863
   Program of China [2012AA010901, 2012AA011002]; Strategic Priority
   Research Program of the Chinese Academy of Sciences [XDA06010401-02]
FX This work is partially supported by the National Sci&Tech Major Project
   (No. 2009ZX01028-002-003, 2009ZX01029-001-003, 2010ZX01036-001-002),
   National Natural Science Foundation (No. 60921002, 61003064, 61050002,
   61070025, 61100163, 61133004, 61173001, 61222204) of China, the National
   High Technology Development 863 Program of China (2012AA010901,
   2012AA011002), and the Strategic Priority Research Program of the
   Chinese Academy of Sciences (under Grant XDA06010401-02).
CR Cheung NM, 2010, IEEE SIGNAL PROC MAG, V27, P79, DOI 10.1109/MSP.2009.935416
   Gschwind M, 2006, IEEE MICRO, V26, P10, DOI 10.1109/MM.2006.41
   Hu WW, 2009, IEEE MICRO, V29, P17, DOI 10.1109/MM.2009.30
   Hu Weiwu, 2010, PROC S HIGH PERFORMA, P22
   Iwata K, 2010, IEEE J SOLID-ST CIRC, V45, P59, DOI 10.1109/JSSC.2009.2031797
   Jia HZ, 2006, IEEE T CONSUM ELECTR, V52, P1447, DOI 10.1109/TCE.2006.273169
   Jian GA, 2009, IEEE INT SYMP CIRC S, P2237, DOI 10.1109/ISCAS.2009.5118243
   Jian GA, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1313, DOI 10.1109/ITNG.2009.225
   Joint Video Team (JVT) of ISO/IEC MPEG and ITU-T VCEG, 2004, INF TECHN COD AUD 10
   Krommydas K, 2010, IEEE INT CON MULTI, P896, DOI 10.1109/ICME.2010.5582558
   Lappalainen V, 2002, IEEE T CIRC SYST VID, V12, P660, DOI 10.1109/TCSVT.2002.800865
   Lee J, 2004, P IEEE AS PAC C CIRC, V2, P1149
   Lee JY, 2010, IET CIRC DEVICE SYST, V4, P147, DOI 10.1049/iet-cds.2009.0038
   Liu F, 2006, EMB SYST REAL TIME M, P87
   Liu W, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P648, DOI 10.1109/WKDD.2009.128
   Liwei Chen, 2012, 2012 IEEE 7th International Conference on Networking, Architecture, and Storage (NAS), P273, DOI 10.1109/NAS.2012.38
   Mori T, 2009, IEEE J SOLID-ST CIRC, V44, P2957, DOI 10.1109/JSSC.2009.2028936
   MPTE Standard, 2006, 421M2006 SMPTE
   Peng C, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P306, DOI 10.1109/ISIMP.2004.1434061
   Sheng B, 2006, IEEE T CONSUM ELECTR, V52, P696, DOI 10.1109/TCE.2006.1649699
   Tachikake K, 2003, ASP-DAC 2003: PROCEEDINGS OF THE ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, P135, DOI 10.1109/ASPDAC.2003.1195006
   Togawa N, 2000, IEICE T FUND ELECTR, VE83A, P442
   Woh M, 2010, IEEE MICRO, V30, P81, DOI 10.1109/MM.2010.8
NR 23
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1651
EP 1671
DI 10.1007/s11042-012-1296-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000031
DA 2024-07-18
ER

PT J
AU Rahman, MA
   Kim, HN
   El Saddik, A
   Gueaieb, W
AF Rahman, Md. Abdur
   Kim, Heung-Nam
   El Saddik, Abdulmotaleb
   Gueaieb, Wail
TI A context-aware multimedia framework toward personal social network
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia systems; Context aware multimedia systems; Social media; Web
   services
ID SECURE
AB People use various Internet-based services including social networks to conduct tasks of diversified categories such as informational, professional, educational, hobbies, health, recreational, academic, and news. Many people not only maintain association with a number of different services but also share information with their social ties in their daily life. However, a person only consumes a subset of services and needs to communicate with a subset of social ties at any given context. In this paper, we present a framework called SenseFace that leverages sensory data coming from one's body sensor network and multimedia information contained within Internet-based services to recommend context-aware services and community of interest. We present the detailed design and implementation of the framework and share our preliminary test results.
C1 [Rahman, Md. Abdur] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Kim, Heung-Nam; El Saddik, Abdulmotaleb] Univ Ottawa, SITE, Multimedia Commun Res Lab MCRLab, Ottawa, ON K1N 6N5, Canada.
   [Gueaieb, Wail] Univ Ottawa, SITE, Ottawa, ON K1N 6N5, Canada.
C3 Umm Al Qura University; University of Ottawa; University of Ottawa
RP Rahman, MA (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
EM marahman@uqu.edu.sa; hnkim@mcrlab.uottawa.ca; abed@mcrlab.uottawa.ca;
   wgueaieb@site.uottawa.ca
RI Rahman, Abdur/AAG-9302-2019; Guizani, Mohsen/AAX-4534-2021; /D-4159-2009
OI Rahman, Abdur/0000-0002-4105-0368; Guizani, Mohsen/0000-0002-8972-8094;
   /0000-0002-7690-8547; Gueaieb, Wail/0000-0001-6490-4648
CR An J, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P554
   Bardram JE, 2005, PERS UBIQUIT COMPUT, V9, P312, DOI 10.1007/s00779-004-0335-2
   Bhardwaj S., 2008, Sensors Transducers Journal, V90, P87
   Bottazzi D, 2006, IEEE COMMUN MAG, V44, P82, DOI 10.1109/MCOM.2006.1632653
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Eisenman SB, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P87
   El Helou S., 2009, Proc. of the 3rd ACM Conf. on Recommender Systems, New York, USA, P373
   Ganti RK, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P563, DOI 10.1109/IPSN.2008.48
   GAO T, 2005, P INT C INF COMM TEC
   Gaonkar S, 2008, MOBISYS'08: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P174
   Gartrell CM, THESIS
   Jagtap P, 2011, IEEE INT C SEMANT CO, P149, DOI 10.1109/ICSC.2011.87
   Joly A., 2009, Int. Journal of Computer Science and Applications, V6, P50
   Kawahara Y., 2007, 2007 IEEE International Conference on Portable Information Devices, P1, DOI DOI 10.1109/PORTABLE/2007.12
   KILLWORTH PD, 1990, SOC NETWORKS, V12, P289, DOI 10.1016/0378-8733(90)90012-X
   Koolwaaij J, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P61, DOI 10.1109/VS-GAMES.2009.21
   Leimeister J. M., 2002, P TOK MOB BUS ROUNDT
   Liang XH, 2012, COMPUT COMMUN, V35, P1910, DOI 10.1016/j.comcom.2012.01.009
   Nurmi P, BETELGUESE TOOL BLUE
   Ocampo R., 2008, 2nd Int. Conf. on Communications and Networking in China, P98
   Phung D., 2009, P IEEE INT C PERV CO, P1
   Rahman Md A, 2010, P IEEE INT INSTR MEA
   Rahman MA, 2011, IEEE T INSTRUM MEAS, V60, P345, DOI 10.1109/TIM.2010.2084190
   Rahman MA, 2010, IEEE T INSTRUM MEAS, V59, P1327, DOI 10.1109/TIM.2009.2038307
   Raji F., 2011, 2011 CSI International Symposium on Computer Science and Software Engineering (CSSE 2011), P135, DOI 10.1109/CSICSSE.2011.5963982
   Ryu H, 2007, LECT NOTES COMPUT SC, V4761, P20
   Santana P.C., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems, P2099, DOI DOI 10.1145/1056808
   Shtykh Roman Y., 2008, 2008 3rd International Conference on Systems and Networks Communications, P365, DOI 10.1109/ICSNC.2008.55
   Sun F, 2007, SCHAT GROUP COMMUNIC, P543
   Upendra R., 2008, Proc. of the 5th Annual Int. Conf. on Mobile and Ubiquitous Systems, P1
   Wu WH, 2008, ARTIF INTELL MED, V42, P137, DOI 10.1016/j.artmed.2007.11.006
   Wyatt D., 2008, PROC UBICOMP, P168
   Zhan J, 2010, IEEE T SYST MAN CY C, V40, P682, DOI 10.1109/TSMCC.2010.2050879
NR 33
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1717
EP 1747
DI 10.1007/s11042-012-1302-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000034
DA 2024-07-18
ER

PT J
AU Xu, PF
   Miao, QG
   Tang, X
   Zhang, JY
AF Xu, Pengfei
   Miao, Qiguang
   Tang, Xing
   Zhang, Junying
TI A denoising algorithm via wiener filtering in the shearlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Shearlets; Shearlet domain; Wiener filtering;
   Minimizing the mean square error criteria; Shrinkage factor
ID CONTOURLET TRANSFORM; IMAGE
AB An image denoising algorithm via wiener filtering in the shearlet domain is proposed in this paper, it makes full use of the advantages of them. Shearlets have the features of directionality, localization, anisotropy and multiscale, the image can be decomposed more accurately, and the noise information locates at the high frequency contents in the frequency spectrum, which can help the removal of noise. The wiener filtering is based on minimizing the mean square error criteria; and it has a good performance on removing the Gaussian white noise. So the combination between them can remove noise more effectively. The noisy image is decomposed by the shearlet transform at any scales and in any directions firstly, the high and low frequency coefficients are thus acquired. And then, in the shearlet domain, the high frequency parts are filtered by wiener filtering. Finally, the inverse shearlet transform is adopted to obtain the denoised image. At the end of paper, the experiments show that the proposed algorithm could get better results than others.
C1 [Xu, Pengfei; Miao, Qiguang; Tang, Xing; Zhang, Junying] Xidian Univ, Sch Comp, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Miao, QG (corresponding author), Xidian Univ, Sch Comp, Xian 710071, Shaanxi, Peoples R China.
EM qgmiao@126.com
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundations of China [61072109, 61272280,
   41271447]; Fundamental Research Funds for the Central Universities
   [K5051203020, K5051203001]; Creative Project of the Science and
   Technology State of xi'an [CXY1133(1), CXY1119(6)]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments and advices which contributed much to the improvement
   of this paper. The work was jointly supported by the National Natural
   Science Foundations of China under grant No. 61072109, 61272280,
   41271447, the Fundamental Research Funds for the Central Universities
   under grant No. K5051203020 and K5051203001, the Creative Project of the
   Science and Technology State of xi'an under grant No. CXY1133(1) and
   CXY1119(6).
CR Aboshosha A, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P245, DOI 10.1109/ICCES.2009.5384036
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Deng Na, 2012, 2012 9 INT C FUZZ SY
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Eslami R, 2006, IEEE T IMAGE PROCESS, V15, P3362, DOI 10.1109/TIP.2006.881992
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Hu Hai-zhi, 2010, Journal of Computer Applications, V30, P1562, DOI 10.3724/SP.J.1087.2010.01562
   Jiao L., 2008, Image Multiscale Geometric Analysis: Theory andApplications-Beyond Wavelets
   Kazubek M, 2003, IEEE SIGNAL PROC LET, V10, P324, DOI 10.1109/LSP.2003.818225
   Kim D, 2011, IET IMAGE PROCESS, V5, P684, DOI 10.1049/iet-ipr.2010.0231
   Kutyniok G, 2009, T AM MATH SOC, V361, P2719
   Lee Y., 1960, STAT THEORY COMMUNIC
   Liu G, 2012, IET SIGNAL PROCESS, V6, P148, DOI 10.1049/iet-spr.2010.0265
   Liu Sheng-peng, 2008, Computer Engineering, V34, P210
   Liu YX, 2007, SCI CHINA SER F, V50, P212, DOI [10.1007/s11432-007-0013-x, 10.1007/s11432-007-0013-X]
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Patel VM, 2009, IEEE T IMAGE PROCESS, V18, P2673, DOI 10.1109/TIP.2009.2029594
   Shao-Wei D, 2007, WAV AN PATT REC 2007, V4, P1742
   Shui PL, 2007, IET IMAGE PROCESS, V1, P311, DOI [10.1049/iet-ipr:20060222, 10.1049/ict-ipr:20060222]
   Shui PL, 2005, IEEE SIGNAL PROC LET, V12, P681, DOI 10.1109/LSP.2005.855555
   Tian P, 2008, J IMAGE GRAPHICS, V13, P395
   [谢杰成 Xie Jiecheng], 2002, [中国图象图形学报. A, Journal of image and graphics], V7, P209
   Xuesen Q, 1981, ENG CYBERNETICS
   Zhang Xiaohua, IMAGE DENOISING NONL
   Zhou ZF, 2007, ELECTRON LETT, V43, P92, DOI 10.1049/el:20073166
NR 26
TC 17
Z9 18
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1529
EP 1558
DI 10.1007/s11042-012-1290-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000025
DA 2024-07-18
ER

PT J
AU Chung, KY
AF Chung, Kyung-Yong
TI Effect of facial makeup style recommendation on visual sensibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Makeup styles; Collaborative filtering; Cosmetic; Sensibility
ID ALGORITHM; MODEL
AB As ubiquitous commerce using IT convergence technologies is coming, it is important for the strategy of cosmetic sales to investigate the sensibility and the degree of preference in the environment for which the makeup style has changed focusing on being consumer centric. The users caused the diversification of the facial makeup styles, because they seek makeup and individuality to satisfy their needs. In this paper, we proposed the effect of the facial makeup style recommendation on visual sensibility. Development of the facial makeup style recommendation system used a user interface, sensibility analysis, weather forecast, and collaborative filtering for the facial makeup styles to satisfy the user's needs in the cosmetic industry. Collaborative filtering was adopted to recommend facial makeup style of interest for users based on the predictive relationship discovered between the current user and other previous users. We used makeup styles in the survey questionnaire. The pictures of makeup style details, such as foundation, color lens, eye shadow, blusher, eyelash, lipstick, hairstyle, hairpin, necklace, earring, and hair length were evaluated in terms of sensibility. The data were analyzed by SPSS using ANOVA and factor analysis to discover the most effective types of details from the consumer's sensibility viewpoint. Sensibility was composed of three concepts: contemporary, mature, and individual. The details of facial makeup styles were positioned in 3D-concept space to relate each type of detail to the makeup concept regarding a woman's cosmetics. Ultimately, this paper suggests empirical applications to verify the adequacy and the validity of this system.
C1 Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
EM dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023; Kiriakova, Glafira/JQI-7709-2023
FU Sangji University
FX This research was supported by Sangji University that allowed Prof. K.
   Y. Chung to have the sabbatical year, 2012. Sincere thanks go to Prof.
   Y. J. Na who provided the idea for 3D-concept space.
CR Behrens R, 2000, LECT NOTES COMPUT SC, V1832, P172
   Chung K. Y., 2011, P INT C INF SCI APPL, P712
   Chung KY, 2011, LNEE, V120, P445
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jalali M, 2010, EXPERT SYST APPL, V37, P6201, DOI 10.1016/j.eswa.2010.02.105
   Jung K. Y., 2004, J TEXT I, V94, P207
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   Jung KY, 2005, J KOREAN SOC CLOTHIN, V7, P162
   Jung kyung-Yong, 2010, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V10, P23
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Kim HS, 2001, J KOREAN HOME EC ASS, V39, P65
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim TH, 2005, LECT NOTES ARTIF INT, V3809, P1150
   Kim TH, 2005, IEICE T INF SYST, VE88D, P1072, DOI 10.1093/ietisy/e88-d.5.1072
   Kohrs A, 2001, INTERACT COMPUT, V13, P695, DOI 10.1016/S0953-5438(01)00038-8
   Lee M, 2009, HUM FACTORS ERGONOM, V19, P168, DOI 10.1002/hfm.20144
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   MICHAEL T, 1997, MACHING LEARNING, P154
   Na Y, 2009, HUM FACTORS ERGONOM, V19, P158, DOI 10.1002/hfm.20143
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Wang J, 2006, LECT NOTES COMPUT SC, V3936, P37
   이경희, 2010, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V10, P233
NR 25
TC 30
Z9 35
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 843
EP 853
DI 10.1007/s11042-013-1355-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400028
DA 2024-07-18
ER

PT J
AU Lee, IH
   Mahmood, MT
   Shim, SO
   Choi, TS
AF Lee, Ik-Hyun
   Mahmood, Muhammad Tariq
   Shim, Seong-O
   Choi, Tae-Sun
TI Optimizing image focus for 3D shape recovery through genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape; Shape from focus; Genetic algorithm; Optimization
ID RESTORATION
AB Three-dimensional information of objects is advantageous and widely used in multimedia systems and applications. Shape form focus (SFF) is a passive optical technique that reconstructs 3D shape of an object using a sequence of images with varying focus settings. In this paper, we propose an optimization of the focus measure. First, Wiener filter is applied for noise reduction from the image sequence. At the second stage, genetic algorithm (GA) is applied for focus measure optimization. GA finds the maximum focus measurement under a fitness criterion. Finally, 3D shape of the object is determined by maximizing focus measure along the optical direction. The proposed method is tested with image sequences of simulated and real objects. The performance of the proposed technique is analyzed through statistical criteria such as root mean square error (RMSE) and correlation. Comparative analysis shows the effectiveness of the proposed method.
C1 [Lee, Ik-Hyun; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Sch Informat & Mechatron, Kwangju 500712, South Korea.
   [Mahmood, Muhammad Tariq] Korea Univ Technol & Educ, Sch Comp Sci & Engn, Cheonan 330708, Chungnam, South Korea.
   [Shim, Seong-O] Plus Fountain Co Ltd, R&D Ctr, Seoul 137890, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Korea University of
   Technology & Education
RP Choi, TS (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Mechatron, 123 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM ihlee@gist.ac.kr; tariq@kut.ac.kr; seongo@gmail.com; tschoi@gist.ac.kr
RI Shim, Seong-O/AAZ-8674-2020; Mahmood, Muhammad Tariq/F-8534-2012
OI Shim, Seong-O/0000-0002-1842-4624; Mahmood, Muhammad
   Tariq/0000-0001-6814-3137; Choi, Tae-Sun/0000-0001-7496-2438
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education, Science and Technology
   [2012-0001344]; Mid-career Researcher Program through a National
   Research Foundation (NRF) grant - Ministry of Education, Science and
   Technology (MEST), Korea
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology(2012-0001344). This work
   (2012-0005542) was supported by the Mid-career Researcher Program
   through a National Research Foundation (NRF) grant funded by the
   Ministry of Education, Science and Technology (MEST), Korea.
CR Ahmad MB, 2005, IEEE T CIRC SYST VID, V15, P566, DOI 10.1109/TCSVT.2005.844450
   Alberts B., 2007, Molecular Biology of the Cell in Cell, V5th
   Calumby RT, 2014, MULTIMED TOOLS APPL, V69, P991, DOI 10.1007/s11042-012-1152-7
   Helmli FS, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P188, DOI 10.1109/ISPA.2001.938626
   Jin F, 2003, P INT C IM PROC ICIP, V3
   KONDO K, 1977, APPL OPTICS, V16, P2554, DOI 10.1364/AO.16.002554
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Malik AS, 2007, IEEE T CONSUM ELECTR, V53, P258, DOI 10.1109/TCE.2007.381683
   Nayar S. K., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P218, DOI 10.1109/ROBOT.1990.125976
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Pham TD, 2001, PATTERN RECOGN, V34, P2403, DOI 10.1016/S0031-3203(00)00164-3
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tenenbaum JayMartin., 1971, Accommodation in computer vision
   Vincent L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P633, DOI 10.1109/CVPR.1992.223122
   Vincent L., 1993, SHAPE PICTURE MATH D, P196
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Xie H, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P229, DOI 10.1109/IROS.2006.282641
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
   Zou KS, 2014, MULTIMED TOOLS APPL, V69, P799, DOI 10.1007/s11042-012-1130-0
NR 21
TC 11
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 247
EP 262
DI 10.1007/s11042-013-1433-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700014
DA 2024-07-18
ER

PT J
AU Wang, Y
   Luo, ZX
   Liu, JC
   Fan, X
   Li, HJ
   Wu, YZ
AF Wang, Yi
   Luo, ZhongXuan
   Liu, JunCheng
   Fan, Xin
   Li, HaoJie
   Wu, Yunzhen
TI Real-time estimation of hand gestures based on manifold learning from
   monocular videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manifold learning; Locality preserving projections; Gesture recognition
ID DIMENSIONALITY REDUCTION; RECOGNITION; TRACKING; POSE
AB Object pose estimation by manifold learning has become a hot research area recently. In this paper, we propose an efficient method that can recover pose and viewpoints for numerous hand gestures from monocular videos based on Locality Preserving Projections. We first select some hand dynamic gestures as primitive hand motions and set a 3D-2D mapping table to relate 3D joint angles of sampling static pose with their projective silhouettes from arbitrary viewpoints. Then the embedding space and explicit mapping function are learnt for every primitive motion. In order to make classification and prediction among those embedding spaces, a Subspace Filtering Algorithm is also proposed which can recognize and recover numerous hand dynamic gestures by the combination of primitive gestures. At last, by using skin color cues and oriented k-Dops, multi-hands can be labeled and tracked separately and accurately. Extensive experimental results demonstrate qualitatively and quantitatively that 3D pose recovery of hands can be achieved by our method robustly and efficiently.
C1 [Wang, Yi; Luo, ZhongXuan; Fan, Xin; Li, HaoJie; Wu, Yunzhen] Dalian Univ Technol, Sch Software, Dalian 116620, Peoples R China.
   [Liu, JunCheng] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100000, Peoples R China.
C3 Dalian University of Technology; Peking University
RP Fan, X (corresponding author), Dalian Univ Technol, Sch Software, Dalian 116620, Peoples R China.
EM dlutwangyi@dlut.edu.cn; zxluo@dlut.edu.cn; ljc91122@yahoo.cn;
   xin.fan@ieee.org; lihaojieyt@gmail.com; yunzhen.eric@gmail.com
FU Doctor Startup Fund of Liaoning Province, China [20111023]; National
   Natural Science Funds of China [61033012, 61003177, 61272371, 11171052,
   61173104]; program for New Century Excellent Talents [NCET-11-0048];
   Specialized Research Fund for the Doctoral Program of Higher Education
   [20120041120050]
FX The research activities as described in this paper were funded by Doctor
   Startup Fund of Liaoning Province, China (20111023), the National
   Natural Science Funds of China (61033012, 61003177, 61272371, 11171052
   and 61173104), and the program for New Century Excellent Talents
   (NCET-11-0048) and Specialized Research Fund for the Doctoral Program of
   Higher Education (20120041120050).
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Alvarez-Alvarez A, 2012, IEEE T FUZZY SYST, V20, P205, DOI 10.1109/TFUZZ.2011.2171973
   [Anonymous], TR200209 U CHIC DEP
   [Anonymous], PATTERN RECOG
   [Anonymous], P 2001 IEEE COMP SOC
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Athitsos V, 2003, PROC CVPR IEEE, P432
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cobos Guzman S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2246, DOI 10.1109/IROS.2008.4651053
   Dadgostar F., 2005, Research letters in the information and mathematical sciences, V7, P127
   Elmezain M, 2008, INT C PATT RECOG, P424
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   He XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P385, DOI 10.1109/ICCV.2003.1238370
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Ibraheem N.A., 2012, International Journal of human Computer Interaction (IJHCI)), V3, P1
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Li WS, 2012, J COMPUT, V7, P1163, DOI 10.4304/jcp.7.5.1163-1168
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mugavin ME, 2008, NURS RES, V57, P64, DOI 10.1097/01.NNR.0000280659.88760.7c
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Romero Javier, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P87, DOI 10.1109/ICHR.2009.5379596
   Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Song Y, 2012, MULTIMED TOOLS APPL, V58, P663, DOI 10.1007/s11042-011-0748-7
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang XY, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/986134
   Yen SH, 2012, LECT NOTES ARTIF INT, V7197, P253, DOI 10.1007/978-3-642-28490-8_27
   Zachmann G, 1998, P IEEE VIRT REAL ANN, P90, DOI 10.1109/VRAIS.1998.658428
   Zhang ZY, 2012, IEEE T PATTERN ANAL, V34, P253, DOI 10.1109/TPAMI.2011.115
NR 38
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 555
EP 574
DI 10.1007/s11042-013-1524-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400011
DA 2024-07-18
ER

PT J
AU Jing, GD
   Shi, YH
   Kong, DH
   Ding, WP
   Yin, BC
AF Jing, Guodong
   Shi, Yunhui
   Kong, Dehui
   Ding, Wenpeng
   Yin, Baocai
TI Image super-resolution based on multi-space sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Sparse representation; Total variation; Over-complete
   bases
ID INTERPOLATION; RESOLUTION
AB Sparse representation provides a new method of generating a super-resolution image from a single low resolution input image. An over-complete base for sparse representation is an essential part of such methods. However, discovering the over-complete base with efficient representation from a large amount of image patches is a difficult problem. In this paper, we propose a super-resolution construction based on multi-space sparse representation to efficiently solve the problem. In the representation, image patches are decomposed into a structure component and a texture component represented by the over-complete bases of their own spaces so that their high-level features can be captured by the bases. In the implementation, a prior knowledge about low resolution images generation is combined to the typical base construction for high construction quality. Experiment results demonstrate that the proposed method significantly improves the PSNR, SSIM and visual quality of reconstructed high-resolution image.
C1 [Jing, Guodong; Shi, Yunhui; Kong, Dehui; Ding, Wenpeng; Yin, Baocai] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Shi, YH (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM jingguodong@gmail.com; syhzm@bjut.edu.cn
FU 973 Program [2011CB302703]; NSFC [61033004, 60825203, 60973056,
   61170103, U0935004, 61003182]; BJNSF [4102009, 4112007]
FX This paper is supported by 973 Program (2011CB302703), NSFC (No.
   61033004, 60825203, 60973056, 61170103, U0935004, 61003182), BJNSF
   (4102009, 4112007).
CR Alfonso S, 2008, IEEE T IMAGE PROCESS, V17, P1817
   [Anonymous], 2006, P INT C MATH
   [Anonymous], 2006, NIPS
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cai J.-F., 2009, P IEEE C COMP VIS PA
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Capel D, 2001, PROC CVPR IEEE, P627
   Dong W., 2011, IEEE T PATTERN ANAL, P1
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Herman MA, 2009, IEEE T SIGNAL PROCES, V57, P2275, DOI 10.1109/TSP.2009.2014277
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Landgrebe TCW, 2008, IEEE T PATTERN ANAL, V30, P810, DOI 10.1109/TPAMI.2007.70740
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Sun J, 2003, PROC CVPR IEEE, P729
   Yang J., 2009, TR0937 CAAM RIC U
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang J, 2008, PROCEEDINGS OF 2008 INTERNATIONAL SEMINAR ON EDUCATION MANAGEMENT AND ENGINEERING, P333
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 22
TC 13
Z9 13
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 741
EP 755
DI 10.1007/s11042-011-0953-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900008
DA 2024-07-18
ER

PT J
AU Porebski, A
   Vandenbroucke, N
   Macaire, L
   Hamad, D
AF Porebski, A.
   Vandenbroucke, N.
   Macaire, L.
   Hamad, D.
TI A new benchmark image test suite for evaluating colour texture
   classification schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Benchmark colour texture test suite; Supervised classification; OuTex;
   VisTex
AB Several image test suites are available in the literature to evaluate the performance of classification schemes. In the framework of colour texture classification, OuTex-TC-00013 (OuTex) and Contrib-TC-00006 (VisTex) are often used. These colour texture image sets have allowed the accuracies reached by many classification schemes to be compared. However, by analysing the classification results obtained with these two sets of colour texture images, we have noticed that the use of colour histogram yields a higher rate of well-classified images compared to colour texture features. It does not take into account any texture information in the image, this incoherence leads us to question the relevance of these two benchmark colour texture sets for measuring the performances of colour texture classification algorithms. Indeed, the partitioning used to build these two sets consists of extracting training and validating sub-images of an original image. We show that such partitioning leads to biased classification results when it is combined with a classifier such as the nearest neighbour. In this paper a new relevant image test suite is proposed for evaluating colour texture classification schemes. The training and the validating sub-images come from different original images in order to ensure that the correlation of the colour texture images is minimized.
C1 [Porebski, A.; Vandenbroucke, N.; Hamad, D.] Univ Littoral Cote dOpale, Lab LISIC, EA 4491, F-62228 Calais, France.
   [Macaire, L.] Univ Lille 1, Lab LAGIS, UMR CNRS 8219, F-59655 Villeneuve Dascq, France.
C3 Universite du Littoral-Cote-d'Opale; Universite de Lille
RP Porebski, A (corresponding author), Univ Littoral Cote dOpale, Lab LISIC, EA 4491, 50 Rue Ferdinand Buisson,BP 719, F-62228 Calais, France.
EM porebski@lisic.univ-littoral.fr
RI Macaire, Ludovic/GLS-5693-2022
OI Macaire, Ludovic/0000-0002-4375-5169; Vandenbroucke,
   Nicolas/0000-0002-7766-4898; POREBSKI, Alice/0000-0002-1482-5447
CR [Anonymous], 2010, 2010 2 INT C IM PROC
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   Hable R, 2013, J MACH LEARN RES, V14, P153
   Hernandez OJ, 2005, J COMPUT SCI TECHNOL, V5, P150
   Hiremath PS, 2006, INT J COMPUT SCI NET, V6, P124
   Iakovidis D, 2005, IWSSIP 2005: PROCEEDINGS OF THE 12TH INTERNATIONAL WORSHOP ON SYSTEMS, SIGNALS & IMAGE PROCESSING, P203
   Khotanzad A., 2006, Mathematical & Computational Applications, V11, P111
   Lakmann R., 1998, BARKTEX BENCHMARK DA
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Münzenmayer C, 2005, LECT NOTES COMPUT SC, V3663, P17
   Munzenmayer C., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P42
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Palm C., 2002, Machine Graphics & Vision, V11, P195
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pietikainen M., 2002, Workshop on Texture Analysis in Machine Vision, P109
   Porebski A, 2007, IEEE IMAGE PROC, P1637
   Porebski A, 2013, PATTERN ANAL APPL, V16, P1, DOI 10.1007/s10044-012-0291-9
   Qazi IUH, 2011, PATTERN RECOGN, V44, P16, DOI 10.1016/j.patcog.2010.07.007
   Van de Wouwer G, 1999, PATTERN RECOGN, V32, P443, DOI 10.1016/S0031-3203(98)00035-1
   van den Broek E. L., 2004, 16 BELG NETH ART INT, P35
   Vandenbroucke N, 2012, COLOR TEXTURE ATTRIB
   Xu Q, 2005, PATTERN RECOGN LETT, V26, P1710, DOI 10.1016/j.patrec.2005.01.013
NR 25
TC 29
Z9 30
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 543
EP 556
DI 10.1007/s11042-013-1418-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300025
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, C
AF Kim, Cheonshik
TI Data hiding by an improved exploiting modification direction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Data hiding; EMD; CIE; Steganalysis
ID IMAGES
AB This paper represents an improved data hiding scheme, CIE, which uses a codebook to improve the Exploiting Modification Direction (EMD) embedding scheme. In our scheme, one secret (2 (n + x) -aEuro parts per thousand 1)-ary digit is hidden in a group of pixels in an image as a modified secret digit. Our proposed scheme has an embedding rate , which is greater than the rate of the EMD scheme, which is R = log(2)(2n + 1)/n for n a parts per thousand yenaEuro parts per thousand 2 . Embedding rate R is the number of secret bits embedded in each cover pixel. Our experimental results demonstrate that our scheme is able to embed 3 times as many secret bits in an image compared to the original EMD embedding scheme when n = 2 and x = 5. Our scheme has low time complexity and achieves this higher embedding performance while retaining reasonable perceptual quality for the image. An experiment verifies these features of our proposed data hiding scheme.
C1 Sejong Univ, Comp Sci & Engn Fac, Seoul 143747, South Korea.
C3 Sejong University
RP Kim, C (corresponding author), Sejong Univ, Comp Sci & Engn Fac, 98 Gunja Dong, Seoul 143747, South Korea.
EM mipsan@sejong.ac.kr
CR [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Byun JY, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P264, DOI 10.1109/UMC.2008.63
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Fridrich J, 2003, PROC SPIE, V5020, P178, DOI 10.1117/12.473140
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kim C, 2011, COMM COM INF SC, V186, P130
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Li XL, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P133
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Spaulding J, 2002, PATTERN RECOGN LETT, V23, P1579, DOI 10.1016/S0167-8655(02)00122-8
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang ZH, 2010, J INFORM HIDING MULT, V1, P1, DOI DOI 10.1007/978-3-642-35473-114
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 24
TC 35
Z9 36
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 569
EP 584
DI 10.1007/s11042-012-1114-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300001
DA 2024-07-18
ER

PT J
AU Doudpota, SM
AF Doudpota, Sher Muhammad
TI Mining movie archives for song sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie mining; Video indexing; Scene detection; Song extraction; Content
   characterization
ID AUDIO CLASSIFICATION; SEGMENTATION
AB Music and songs are integral parts of Bollywood movies. Every movie of two to three hours, contains three to ten songs, each song is 3-10 min long. Music lovers like to listen music and songs of a movie, however it is time consuming and error prone to search manually all the songs in a movie. Moreover, the task becomes much harder when songs are to be extracted from a huge archived movies' database containing hundreds of movies. This paper presents an approach to automatically extract music and songs from archived musical movies. We used song grammar to construct Markov Chain Model that differentiates song scenes from dialogue and action scenes in a movie. We tested our system on Bollywood, Hollywood, Pakistani, Bengali, and Tamil movies. A total of 20 movies from different industries were selected for the experiments. On Bollywood movies, we achieved 97.22% recall in song extraction, whereas the recall on Hollywood musical movies is 80%. The test result on Pakistani, Tamil and Bengali movies is 87.09%.
C1 Asian Inst Technol, Bangkok 10501, Thailand.
C3 Asian Institute of Technology
RP Doudpota, SM (corresponding author), Asian Inst Technol, Bangkok 10501, Thailand.
EM sherkhalil2003@hotmail.com
RI Daudpota, Sher Muhammad/AAN-2438-2020
CR Aisopos F, 2011, ACM MULT 2011 ACM MM
   [Anonymous], SEARCH LATA MANGESHK
   [Anonymous], 1995, PROC ICJAI, DOI DOI 10.1145/217279.215068
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Becchetti C., 1999, Speech Recognition, Theory and C++ Implementation
   Berenzweig AL, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P119, DOI 10.1109/ASPAA.2001.969557
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cesa-Bianchi N., 2006, PREDICTION LEARNING
   Chowdhry Prem., 2000, COLONIAL INDIA MAKIN
   Doulamis AD, 2000, IEEE T NEURAL NETWOR, V11, P137, DOI 10.1109/72.822517
   El-Maleh K, 2000, INT C AC SPEECH SIGN
   Gokulsing K.M., 1998, INDIAN POPULAR CINEM
   Gulzar G.N., 2003, Encyclopedia of Hindi cinema: an enchanting close-up of India's Hindi cinema (Britannica)
   Han J., 2006, DATA MINING CONCEPTS
   Hirji Faiza., 2005, Global Media Journal, V4, P1
   Huang T.-M., 2006, Kernel Based Algorithms for Mining Huge Data Sets, V17, P11, DOI DOI 10.1007/3-540-31689-2
   Imai T, 2007, IEICE T INF SYST, VE90D, P1286, DOI 10.1093/ietisy/e90-d.8.1286
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   Kim YE, 2002, INT S C MUS INF RETR
   Lehane B, 2004, C IM VID RETR
   Lehane B, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/14615
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Mesaros A, 2007, INT S C MUS INF RETR
   Nwe TL, 2004, INT S C MUS INF RETR
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Saunders J, 1996, INT C AC SPEECH SIGN
   Scheirer E., 1997, INT C AC SPEECH SIGN
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Sundaram H., 2000, Proceedings ACM Multimedia 2000, P95, DOI 10.1145/354384.354440
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
NR 33
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 359
EP 382
DI 10.1007/s11042-012-1021-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400007
DA 2024-07-18
ER

PT J
AU Lalos, C
   Voulodimos, A
   Doulamis, A
   Varvarigou, T
AF Lalos, Constantinos
   Voulodimos, Athanasios
   Doulamis, Anastasios
   Varvarigou, Theodora
TI Efficient tracking using a robust motion estimation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Temporal inference; Motion estimation
ID VISION SYSTEM; CLASSIFICATION; SELECTION
AB Camera based supervision is a critical part of event detection and analysis applications. However, visual tracking still remains one of the biggest challenges in the area of computer vision, although it has been extensively discussed during in the previous years. In this paper we propose a robust tracking approach based on object flow, which is a motion model for estimating both the displacement and the direction of an object of interest. In addition, an observation model that utilizes a generative prior is adopted to tackle the pitfalls that derive from the appearance changes of the object under study. The efficiency of our technique is demonstrated using sequences captured in a complex industrial environment. The experimental results show that the proposed algorithm is sound, yielding improved performance in comparison with other tracking approaches.
C1 [Lalos, Constantinos; Voulodimos, Athanasios; Doulamis, Anastasios; Varvarigou, Theodora] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
C3 National Technical University of Athens
RP Lalos, C (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Iroon Polytechniou St, Athens 15780, Greece.
EM lalosc@mail.ntua.gr
RI Doulamis, Anastasios/AAL-5972-2021; Voulodimos, Athanasios/ABC-1836-2021
FU European Community [FP7-ICT-216465 SCOVIS]
FX This research was supported by the European Community Seventh Framework
   Programme under grant agreement no FP7-ICT-216465 SCOVIS.
CR [Anonymous], 2004, ECCV
   [Anonymous], 2008, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 2009, ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2009, CVPR
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Balestrino A., 2006, IEEE INT C CONTR APP, P626
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Doulamis A, 2010, MULTIMED TOOLS APPL, V50, P49, DOI 10.1007/s11042-009-0368-7
   Gao T, 2012, MULTIMED TOOLS APPL, V58, P1, DOI 10.1007/s11042-010-0676-y
   Geiger Andreas., 2009, CVPR
   Gong Z, 2006, 32 ANN C IEEE IND EL, P5468
   Grabner H, 2006, CVPR
   Heleno P, 2002, EURASIP J APPL SIG P, V2002, P728, DOI 10.1155/S1110865702204114
   Lalos C, 2010, P 10 INT WORKSH VIS
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Lawrence ND, 2006, P 23 INT C MACH LEAR
   Leibe B., 2007, ICCV
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Li Yuan., 2007, CVPR
   Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008
   Morzinger R., 2010, P 1 ACM INT WORKSH A, P81
   Odobez JM, 2006, IEEE T IMAGE PROCESS, V15, P3514, DOI 10.1109/TIP.2006.877497
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Peña M, 2006, ELECT ROBOT AUTO MEC, P30
   Phung SL, 2002, IEEE IMAGE PROC, P289
   SANTOSVICTOR JA, 1993, IEEE T IND APPL, V29, P470, DOI 10.1109/28.222414
   Tan J. T. C., 2011, 2011 IEEE INT S ASS, P1
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Usamentiaga R, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P105, DOI 10.1109/ICMV.2009.14
   Veres G, 2010, AS C COMP VIS ACCV
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Voulodimos A, 2011, IEEE IMAGE PROC
   Voulodimos A, 2011, NEURAL NETWORKS, V24, P852, DOI 10.1016/j.neunet.2011.06.001
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Woodley Thomas, 2007, BMVC
   Yang M., 2009, ICCV
NR 39
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 277
EP 292
DI 10.1007/s11042-012-0994-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400003
DA 2024-07-18
ER

PT J
AU Jee, HK
   Lim, S
   Youn, J
   Lee, J
AF Jee, Hyung-Keun
   Lim, Sukhyun
   Youn, Jinyoung
   Lee, Junsuk
TI An augmented reality-based authoring tool for E-learning applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; E-learning application; Authoring tool; Multimedia
   tool
ID EXPERIENCE
AB In recent years, augmented reality technologies have been a subject of great interest among the scientific community. However, most studies have focused on hardware and software development without particular emphasis on the authoring phase. As a consequence, the authoring process of augmented reality applications is accomplished today through hard-coding of a specific application. This approach, however, requires operators. In the education applications, the hard-coding methods tend to be retained, despite remarkable technological developments in the industrial area. Textbooks are mainly used in educational systems and many educators are very passive about applying new materials. In this paper, we present an immersive authoring tool for education using augmented reality, where applications authorized by our tool interact with the user in order to increase the learner's interest and reflect various desires of dynamic environment. Our authoring tool consists of a composing tool that can be used to create educational contents, a viewer that plays the content, and an engine to power the tool and viewer.
C1 [Jee, Hyung-Keun; Lim, Sukhyun; Youn, Jinyoung; Lee, Junsuk] ETRI, Knowledge E Learning Team, Taejon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Lim, S (corresponding author), ETRI, Knowledge E Learning Team, 138 Kajeongno, Taejon, South Korea.
EM cgwizard@hotmail.com; younjy@etri.re.kr; leejs@etri.re.kr
RI Youn, Jinyoung/ABD-4588-2020
FU IT R&D program of MKE/MCST/IITA, [Development of learner-participational
   and interactive 3D Virtual learning contents technology]
FX This work was supported by the IT R&D program of MKE/MCST/IITA,
   [Development of learner-participational and interactive 3D Virtual
   learning contents technology].
CR Bauer M, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P45, DOI 10.1109/ISAR.2001.970514
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Grimm P, 2003, P AUGM REAL TOOLK, P2
   HAMPSHIRE A, 2006, P 18 AUSTR C COMP HU, P409
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Lee GA, 2005, COMMUN ACM, V48, P76, DOI 10.1145/1070838.1070840
   LEE GA, 2002, P ACM S VIRT REAL SO, P41
   MacIntyre Blair., 2004, Presence: Teleoperators and Virtual Environments, V6, P197
   Mine MR, 1995, TR95020 UNC
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   SCHMALSTIEG D, 2002, PRESENCE TELEOPE FEB, P33
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Wang Y, 2009, P NZCSRSC 2009
NR 14
TC 41
Z9 45
U1 0
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 225
EP 235
DI 10.1007/s11042-011-0880-4
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400002
DA 2024-07-18
ER

PT J
AU Elmisery, AM
   Botvich, D
AF Elmisery, Ahmed M.
   Botvich, Dmitri
TI Multi-agent based middleware for protecting privacy in IPTV content
   recommender services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Clustering; IPTV networks; Recommender System; Multi-agent
AB This work presents our efforts to design an agent based middleware that enables the end-users to use IPTV content recommender services without revealing their sensitive preference data to the service provider or any third party involved in this process. The proposed middleware (called AMPR) preserves users' privacy when using the recommender service and permits private sharing of data among different users in the network. The proposed solution relies on a distributed multi-agent architecture involving local agents running on the end-user set up box to implement a two stage concealment process based on user role in order to conceal the local preference data of end-users when they decide to participate in recommendation process. Moreover, AMPR allows the end-users to use P3P policies exchange language (APPEL) for specifying their privacy preferences for the data extracted from their profiles, while the recommender service uses platform for privacy preferences (P3P) policies for specifying their data usage practices. AMPR executes the first stage locally at the end user side but the second stage is done at remote nodes that can be donated by multiple non-colluding end users that we will call super-peers Elmisery and Botvich (2011a, b, c); or third parties mash-up service Elmisery A, Botvich (2011a, b). Participants submit their locally obfuscated profiles anonymously to their local super-peer who collect and mix these preference data from multiple participants. The super-peer invokes AMPR to perform global perturbation process on the aggregated preference data to ensure a complete concealment of user's profiles. Then, it anonymously submits these aggregated profiles to a third party content recommender service to generate referrals without breaching participants' privacy. In this paper, we also provide an IPTV network scenario and experimentation results. Our results and analysis shows that our two-stage concealment process not only protect the users' privacy, but also can maintain the recommendation accuracy.
C1 [Elmisery, Ahmed M.; Botvich, Dmitri] Waterford Inst Technol, Telecommun Software & Syst Grp, Waterford, Ireland.
C3 South East Technological University (SETU)
RP Elmisery, AM (corresponding author), Waterford Inst Technol, Telecommun Software & Syst Grp, Waterford, Ireland.
EM ahmedmohmed2001@gmail.com
RI Elmisery, Ahmed/C-3309-2011; Botvich, Dmitri/AAS-9512-2021; Elmisery,
   Ahmed M./I-9357-2017
OI Botvich, Dmitri/0000-0002-3260-1404; Elmisery, Ahmed
   M./0000-0003-1077-4790
FU Higher Education Authority in Ireland under the PRTLI Cycle 4 programme,
   in the FutureComm project (Serving Society: Management of Future
   Communications Networks and Services)
FX This work has received support from the Higher Education Authority in
   Ireland under the PRTLI Cycle 4 programme, in the FutureComm project
   (Serving Society: Management of Future Communications Networks and
   Services).
CR [Anonymous], 2011, J CONVERG
   [Anonymous], 2009, P 15 ACM SIGKDD INT
   [Anonymous], INFORM THEORY NOTES
   [Anonymous], 1998, STOC
   [Anonymous], P 16 INT C WORLD WID
   [Anonymous], 2010, J CONVERGENCE SECURI
   CANNY J, 2002, P 25 ANN INT ACM SIG
   Canny J, 2002, P 2002 IEEE S SEC PR, P45
   Carbo J, 2003, INT J COOP INF SYST, V12, P135, DOI 10.1142/S0218843003000681
   Dingledine R, 2004, P 13 C USENIX SEC S
   Elmisery A., 2011, 12 IFIP IEEE INT S I
   Elmisery A., 2011, 11 IFIP C E BUS E SE
   Elmisery A, 2010, 34 IEEE ANN INT COMP
   Elmisery A., 2011, 5 FTRA IEEE INT C MU
   Elmisery A, 2011, 3 INT ICST C SEC PRI
   Elmisery A, 2011, 3 INT C INT DEC TECH
   Elmisery A., 2011, 16 IEEE INT WORKSH C
   Elmisery A. M., 2011, INTELLIGENT DECISION, P821, DOI [10.1007/978-3-642-22194-1_81, DOI 10.1007/978-3-642-22194-1_81]
   Esma A., 2008, EXPT DEMONSTRATION H, P161
   Fellows MR, 2009, P 15 ANN INT C COMP
   Gemmis M., 2009, EUR C MACH LEARN PRI
   Gupta D., 1999, P 22 ANN INT ACM SIG
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Huang Z., 2005, P 2005 ACM SIGMOD IN
   JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640
   Kargupta H., 2003, P 3 IEEE INT C DAT M
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Liu K, 2006, LECT NOTES ARTIF INT, V4213, P297
   Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618
   NEJDL W, 2003, P 12 INT C WORLD WID
   Pingley A, 2009, P 2009 29 IEEE INT C
   POLAT H, 2005, P 2005 ACM S APPL CO
   POLAT H, 2003, P 3 IEEE INT C DAT M
   Pyshkin E, 2010, J CONVERG, V1, P1
   Reaz A, 2010, SCALABLE PEER TO PEE
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Ye Y, 2010, INT J INF TECHNOL CO, V1, P206
NR 39
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 249
EP 275
DI 10.1007/s11042-012-1067-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200003
DA 2024-07-18
ER

PT J
AU Hammami, M
   Jarraya, SK
   Ben-Abdallah, H
AF Hammami, Mohamed
   Jarraya, Salma Kammoun
   Ben-Abdallah, Hanene
TI On line background modeling for moving object segmentation in dynamic
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background modeling; Cast shadow detection and removal; Moving object
   detection
ID MOTION DETECTION; OPTICAL-FLOW; SHADOW; SUBTRACTION
AB Fast and accurate moving object segmentation in dynamic scenes is the first step in many computer vision applications. In this paper, we propose a new background modeling method for moving object segmentation based on dynamic matrix and spatio-temporal analyses of scenes. Our method copes with some challenges related to this field. A new algorithm is proposed to detect and remove cast shadow. A comparative study by quantitative evaluations shows that the proposed approach can detect foreground robustly and accurately from videos recorded by a static camera and which include several constraints. A Highway Control and Management System called RoadGuard is proposed to show the robustness of our method. In fact, our system has the ability to control highway by detecting strange events that can happen like vehicles suddenly stopped in roads, parked vehicles in emergency zones or even illegal conduct such as going out from the road. Moreover, RoadGuard is capable of managing highways by saving information about the date and time of overloaded roads.
C1 [Hammami, Mohamed] Sfax Univ, MIRACL FS, Sfax 3018, Tunisia.
   [Jarraya, Salma Kammoun; Ben-Abdallah, Hanene] Sfax Univ, MIRACL FSEG, Sfax 3018, Tunisia.
C3 Universite de Sfax; Multimedia, InfoRmation Systems & Advancing
   Computing Laboratory (MIRACL); Multimedia, InfoRmation Systems &
   Advancing Computing Laboratory (MIRACL); Universite de Sfax
RP Jarraya, SK (corresponding author), Sfax Univ, MIRACL FS, Rte Soukra Km 3 BP 802, Sfax 3018, Tunisia.
EM Mohamed.Hammami@fss.rnu.tn; Salma.Kammoun@fsegs.rnu.tn;
   Hanene.Benabdallah@fsegs.rnu.tn
RI Kammoun, Salma/N-9090-2014; Ben-Abdallah, Hanene/L-1239-2014
OI Kammoun, Salma/0000-0003-1086-6599; Ben-Abdallah,
   Hanene/0000-0001-9215-4661; Hammami, Mohamed/0000-0003-3580-0473
CR [Anonymous], 2010, Handbook of pattern recognition and computer vision
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], MIR 2008
   [Anonymous], 2010, 2010 6 INT C SIGN PR
   [Anonymous], INT WORKSH PATT REC
   [Anonymous], IEEE INT WORKSH HAPT
   Biswas S., 2011, JICGST GVIP, V11, P29
   Boult TE, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P48
   Cavallaro A, 2003, P WORKSH IM AN MULT, P9
   Chang MC, 2007, IEEE INT SYMP CIRC S, P3667, DOI 10.1109/ISCAS.2007.378638
   Cheung S-C, P EL IM VIS COMM IM, V5308, P881
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Choi Yeon-sung, 2006, INT C ICHIT HYBR INF, V1, P263
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Cucchiara R, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P145
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34
   Ho MAT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P170, DOI 10.1109/AFGR.2002.1004150
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jacques JCS, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P189
   Jarraya S. K., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P52, DOI 10.1109/DICTA.2010.18
   Jarraya SK, 2010, SIGNAL IMAGE PROCESS, V23-25
   Jing G, 2004, TENCON IEEE REGION, pA379
   Joshi AJ, 2007, IEEE INT CONF ROBOT, P4827, DOI 10.1109/ROBOT.2007.364223
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kilger M., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P11, DOI 10.1109/ACV.1992.240332
   Kinoshita K., 2007, 9 INT C CONTR AUT RO, P1
   Lim S, 2005, IEEE T IMAGE PROCESS, V14, P1074, DOI 10.1109/TIP.2005.851688
   Lu N., 2008, IAENG INT J COMPUTER, V35, P1
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MA YF, 2001, P 2001 IEEE INT C MU, P381
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Pathirana PN, 2007, IEEE INT C NETW SENS, P634, DOI 10.1109/ICNSC.2007.372853
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Prati A., 2003, IEEE Trans. Pattern Analysis And Machine Intillegence
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Radke RJ, IEEE T, V14, P294
   Roth S, 2005, IEEE I CONF COMP VIS, P42
   Soumya T, 2008, LECT NOTES ENG COMP, P1161
   Spagnolo P, 2005, LECT NOTES COMPUT SC, V3691, P398
   Stocker AA, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P332
   Thongkamwitoon T, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1459, DOI 10.1109/ICME.2004.1394510
   Tsai D, 2008, IEEE T IMAGE PROCESS
   Vladimir N, 2008, TECHNICAL REPORT
   Xiao M, 2007, INT J AUTOM COMPUT, V4, P38, DOI 10.1007/s11633-007-0038-z
   Yang T., 2004, P ACM 2 INT WORKSH V, P136, DOI [10.1145/1026799.1026822, DOI 10.1145/1026799.1026822]
   Yu Z, 2009, ASIA CONTROL CONF AS, P1594
   Zhou DX, 2005, IEEE SYS MAN CYBERN, P2224
NR 54
TC 8
Z9 9
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 899
EP 926
DI 10.1007/s11042-011-0935-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000014
DA 2024-07-18
ER

PT J
AU Incarbone, G
   Lombardo, A
   Reforgiato, D
   Schembra, G
AF Incarbone, Giuseppe
   Lombardo, Alfio
   Reforgiato, Diego
   Schembra, Giovanni
TI A comprehensive platform to manage peer churn and bandwidth fluctuations
   in real-time multimedia P2P networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; P2P; Peer churn; Bandwidth fluctuation; Revenue model
AB In the last few years, new service providers are growing in the Internet scenario to create new multimedia services. The most common approach to this end is based on peer-to-peer (P2P) networks. The new service providers are manifesting great interest not only for classical multimedia applications, like video streaming and video on demand, but also for multi-party games, private video-chat rooms, videoconference and real-time video teaching, usually containing a small number of high-interactive group members. The target of this paper is to define a multipoint multimedia communication platform for such kind of applications, accounting both peer set variation (peer arrivals and departures) and peer bandwidth modifications. In addition, a revenue model for providers of this kind of services is proposed to allow them to design their networks in order to maximize their revenue while satisfying user requirements in terms of both admission rejection probability and perceived quality on the received video stream.
C1 [Incarbone, Giuseppe; Lombardo, Alfio; Reforgiato, Diego; Schembra, Giovanni] Univ Catania, DIEEI, Catania, Italy.
   [Lombardo, Alfio] Univ Catania, OpenLab, Catania, Italy.
C3 University of Catania; University of Catania
RP Reforgiato, D (corresponding author), Univ Catania, DIEEI, Catania, Italy.
EM giuseppe.incarbone@diit.unict.it; lombardo@diit.unict.it;
   diegoref@diit.unict.it; schembra@diit.unict.it
RI Schembra, Giovanni/AAA-3947-2021
OI Schembra, Giovanni/0000-0002-7432-8389; Lombardo,
   Alfio/0000-0003-3617-7732; Reforgiato Recupero,
   Diego/0000-0001-8646-6183
FU Italian MIUR PRIN project "Sorpasso"; European Community
   [PIRG03-GA-2008-231021]
FX This work is partially supported by the Italian MIUR PRIN 2007 project
   "Sorpasso". Moreover, the work leading to this invention has benefited
   from a fellowship of the Seventh Framework Programme of the European
   Community [7o PQ/2007-2013] regarding the Grant Agreement n.
   PIRG03-GA-2008-231021.
CR [Anonymous], P IEEE INF 98 SAN FR
   BANERJEE S, 2002, P ACM SIGC 2002 PITT
   Bindal R., 2006, Operating Systems Review, V40, P22, DOI 10.1145/1151374.1151382
   Bonald T, 2008, PERF E R SI, V36, P325, DOI 10.1145/1384529.1375494
   CASTRO M, 2003, LNCS, V2735
   Chu Y., 2000, P ACM SIGMETRICS
   da Silva Couto, 2008, P IEEE P2P 08 AACH D
   Deshpande H, 2001, CS200131 STANF U DAT
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Hauske G., 2003, MOMUC 2003, P5
   Incarbone G, 2007, GLOBECOM
   Incarbone G, 2007, PEER ADMISSION CONTR
   Jannotti J, 2000, P OP SYST DES IMPL O, P292
   Kim Y-H, 2009, ICACT
   KUNG HT, 2003, P WORKSH EC PEER TO
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lombardo A, 2009, INT J DIGIT MULTIMED, V2009, DOI 10.1155/2009/453471
   Marfia G, 2007, 3 STMICROELECTRONICS
   Noh J, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.470
   Padmanabhan VN, 2002, LECT NOTES COMPUT SC, V2429, P178
   RAGHUVEER A., 2007, P MMCN SAN JOS CA JA
   Sentinelli A, 2009, TOWARDS THE FUTURE INTERNET: A EUROPEAN RESEARCH PERSPECTIVE, P273, DOI 10.3233/978-1-60750-007-0-273
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   VENKATARAMAN V, 2006, ICNP
   Venkatraman V, 2005, P 2 S NETW SYST DES
   WANG F, 2008, P IEEE INFOCOM 2008
   Wang M, P 18 INT WORKSH NETW
   Wang M, 2007, IEEE JSAC
   Wang YK, 2006, Patent No. [PCT/IB2006/000631, 2006000631]
   Xu D., 2002, P IEEE ICDCS AUSTR J
   ZHANG J, 2007, J NETWORK COMPUTER A
   Zhang M, 2008, P GLOBECOM 2008, P1741
   ZHANG M, 2005, P ACM MULT 2005 NOV
   ZHANG X, 2005, INFOCOM
NR 34
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 851
EP 873
DI 10.1007/s11042-011-0943-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000012
DA 2024-07-18
ER

PT J
AU Minovic, M
   Milovanovic, M
   Starcevic, D
AF Minovic, Miroslav
   Milovanovic, Milos
   Starcevic, Dusan
TI Learning object repurposing for various multimedia platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia repurposing; Learning objects; Educational games; MDA
ID EDUCATIONAL GAMES; MODEL
AB The major question addressed in this paper is finding a way to use existing Learning Objects in different forms of multimedia. There is evident need of using Learning Objects in various multimedia settings. With new shift in technology and the grasp of learning methods, multimedia is gaining on importance as a standard tool for education. Since Learning Objects consist of content and presentation, the presentation part creates a reusability issue with every new multimedia environment. Systems that are based on multimedia can reach high levels of presentational complexity. Integrating existing Learning Objects in to different presentational multimedia forms can prove very difficult. This is emphasized when it comes to games, since they are one of the most complex multimedia platforms. For that reason our proof of concept will use educational games as a subject, by honoring that if the concept is applicable in complex setting, it can be successfully applied in simple ones as well.
C1 [Minovic, Miroslav; Milovanovic, Milos; Starcevic, Dusan] Univ Belgrade, Sch Business Adm, Belgrade, Serbia.
C3 University of Belgrade
RP Minovic, M (corresponding author), Univ Belgrade, Sch Business Adm, Jove Ilica 154, Belgrade, Serbia.
EM mminovic@fon.bg.ac.rs; milovanovicm@fon.bg.ac.rs; starcev@fon.bg.ac.rs
FU Serbian Ministry of Science and Technology Development [32013]
FX This research is part of the project Multimodal biometry in identity
   management, grant no. 32013 funded by Serbian Ministry of Science and
   Technology Development.
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   [Anonymous], 2009, FIELD GUIDE LEARNING
   Brajnik G, 2007, P UN ACC HUM COMP IN, P501
   Egenfeldt-Nielsen S., 2007, Beyond Edutainment: The Educational Potential of Computer Games
   El Saddik A, 2000, P AUSTR C COMP ED, P87
   *FED AM SCI, 2006, R D CHALL GAM LEARN
   Fiaidhi J, 2006, P 5 WSEAS INT C TEL, P13
   Fiaidhi J, 2006, IJCSNS INT J COMPUT, V6
   Gasevic D, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P714, DOI 10.1109/ICALT.2004.1357633
   Jovanovic J, 2007, IEEE INTERNET COMPUT, V11, P45, DOI 10.1109/MIC.2007.116
   Kickmeier-Rust MD, 2008, LECT NOTES COMPUT SC, V4823, P78, DOI 10.1007/978-3-540-78139-4_8
   Merrick K., 2006, ACM SIGCHI INT C ADV
   Minovic M, 2009, LECT NOTES ARTIF INT, V5736, P156, DOI 10.1007/978-3-642-04754-1_17
   Minovic M, 2008, 2ND EUROPEAN CONFERENCE ON GAMES BASED LEARNING, P307
   Obrenovic Z, 2004, IEEE MULTIMEDIA, V11, P62, DOI 10.1109/MMUL.2004.1261109
   Oliveira EW, 2008, P 14 BRAZ S MULT WEB, P226
   RADA R, 1995, DEV ED HYPERMEDIA CO
   Ram A, 1999, IEEE MULTIMEDIA, V6, P40, DOI 10.1109/93.771372
   Sicilia M, 2003, INT REV RES OPEN DIS, V4
   Singh G, 1999, IEEE MULTIMEDIA, V6, P18
   Steinacker A., 2001, IEEE Multimedia, V8, P70, DOI 10.1109/93.923956
   Teixeira JSF, 2009, P INT STUD COMP SCI, P44
   The Belle Project, 2002, BEST PRACT MET GUID
   Torrente J, 2009, EDUC TECHNOL SOC, V12, P359
   Verbert K., 2006, International Journal on E-Learning, V5, P67
   Wang C, 2007, LECT NOTES COMPUT SC, V4753, P378
NR 26
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 927
EP 946
DI 10.1007/s11042-011-0964-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000015
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Zhao, XM
AF Zhang, Shiqing
   Zhao, Xiaoming
TI Dimensionality reduction-based spoken emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Dimensionality reduction; Manifold learning
ID VOICE QUALITY; SPEECH; CLASSIFICATION; FEATURES; MANIFOLD; PROSODY;
   CHOICE
AB To improve effectively the performance on spoken emotion recognition, it is needed to perform nonlinear dimensionality reduction for speech data lying on a nonlinear manifold embedded in a high-dimensional acoustic space. In this paper, a new supervised manifold learning algorithm for nonlinear dimensionality reduction, called modified supervised locally linear embedding algorithm (MSLLE) is proposed for spoken emotion recognition. MSLLE aims at enlarging the interclass distance while shrinking the intraclass distance in an effort to promote the discriminating power and generalization ability of low-dimensional embedded data representations. To compare the performance of MSLLE, not only three unsupervised dimensionality reduction methods, i.e., principal component analysis (PCA), locally linear embedding (LLE) and isometric mapping (Isomap), but also five supervised dimensionality reduction methods, i.e., linear discriminant analysis (LDA), supervised locally linear embedding (SLLE), local Fisher discriminant analysis (LFDA), neighborhood component analysis (NCA) and maximally collapsing metric learning (MCML), are used to perform dimensionality reduction on spoken emotion recognition tasks. Experimental results on two emotional speech databases, i.e. the spontaneous Chinese database and the acted Berlin database, confirm the validity and promising performance of the proposed method.
C1 [Zhang, Shiqing] Taizhou Univ, Sch Phys & Elect Engn, Taizhou 318000, Peoples R China.
   [Zhao, Xiaoming] Taizhou Univ, Dept Comp Sci, Taizhou 318000, Peoples R China.
C3 Taizhou University; Taizhou University
RP Zhang, SQ (corresponding author), Taizhou Univ, Sch Phys & Elect Engn, Taizhou 318000, Peoples R China.
EM tzczsq@163.com
FU Zhejiang Provincial Natural Science Foundation of China [Z1101048,
   Y1111058]
FX The authors would like to thank all the anonymous reviewers and editors
   for their helpful comments and suggestions about the improvement of this
   paper. This work is supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant No. Z1101048 and No. Y1111058.
CR Ang J., 2002, Proceeings of International Conference on Spoken Language Pro- cessing, P2037
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Batliner A, 2000, ART INTEL, P106
   Batliner A, 2011, COMPUT SPEECH LANG, V25, P4, DOI 10.1016/j.csl.2009.12.003
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Boersma P., 2009, Praat: Doing Phonetics by Computer
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Daza-Santacoloma G, 2010, NEUROCOMPUTING, V73, P1595, DOI 10.1016/j.neucom.2009.11.038
   de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333
   De Ridder D., 2002, PH200201 DELFT U TEC, P1
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Errity A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2506
   Fernandez R, 2003, SPEECH COMMUN, V40, P145, DOI 10.1016/S0167-6393(02)00080-8
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Globerson A., 2006, ADV NEURAL INFORM PR, P451
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goddard J, 2009, BIOMED SIGNAL PROCES, V4, P194, DOI 10.1016/j.bspc.2009.01.001
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hozjan V., 2003, EUROSPEECH 2003 GEN, P133
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Iliev Alexander I., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P495, DOI 10.1109/IWSSIP.2007.4381149
   Iliev AI, 2010, COMPUT SPEECH LANG, V24, P445, DOI 10.1016/j.csl.2009.02.005
   Jain V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P984
   Jansen A., 2005, GEOMETRIC PERSPECTIV
   Jansen A, 2006, INT CONF ACOUST SPEE, P241
   Johnstone T., 1999, P 14 INT C PHONETIC, P2029
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kayo O, 2006, Locally Linear Embedding Algorithm-Extensions and Applications
   Kim J, 2010, INT CONF ACOUST SPEE, P5142, DOI 10.1109/ICASSP.2010.5495032
   Kouropteva O., 2003, PROC 11 EUROPEAN S A, P229
   Kwon O.-W., 2003, Interspeech, P125
   Lamarche A., 2007, International Congress of Phonetic Sciences, P2081
   Lee C., 2004, P INTERSPEECH, P889
   Lee C.M., 2002, P ICSLP
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee CM, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P240, DOI 10.1109/ASRU.2001.1034632
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   Liang D, 2005, PATTERN RECOGN LETT, V26, P2374, DOI 10.1016/j.patrec.2005.04.011
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Nicholson J, 2000, NEURAL COMPUT APPL, V9, P290, DOI 10.1007/s005210070006
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Osgood CE, 1975, Cross-Cultural Universals of Affective Meaning
   Pao TL, 2005, LECT NOTES COMPUT SC, V3784, P279
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Petrushin V., 1999, Proc. Artif. Neural Netw. Eng., V710, P22
   Petrushin ValeryA., 2000, PROC ICSLP 2000, P222
   Picard R, 2001, AFFECTIVE MED TECHNO, P69
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Picard RW, 2002, INTERACT COMPUT, V14, P141, DOI 10.1016/S0953-5438(01)00055-8
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer S, 2009, ADVANCED INTELLIGENT ENVIRONMENTS, P95, DOI 10.1007/978-0-387-76485-6_5
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Schuller B, 2007, INT CONF ACOUST SPEE, P941
   Schuller B, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P881
   Shami M, 2007, SPEECH COMMUN, V49, P201, DOI 10.1016/j.specom.2007.01.006
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Valencia-Aguirre J, 2009, LECT NOTES COMPUT SC, V5856, P77, DOI 10.1007/978-3-642-10268-4_9
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Ververidis D, 2005, IEEE INT SYMP CIRC S, P2871, DOI 10.1109/ISCAS.2005.1465226
   Ververidis D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P593
   Ververidis D, 2008, SIGNAL PROCESS, V88, P2956, DOI 10.1016/j.sigpro.2008.07.001
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023
   Wang YJ, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P15
   Xiao ZZ, 2010, MULTIMED TOOLS APPL, V46, P119, DOI 10.1007/s11042-009-0319-3
   Yildirim S, 2011, COMPUT SPEECH LANG, V25, P29, DOI 10.1016/j.csl.2009.12.004
   You M., 2007, Computational Linguistics and Chinese Language Processing, V12, P49
   You MY, 2006, INT C PATT RECOG, P91
   Zhang SQ, 2008, LECT NOTES COMPUT SC, V5264, P457
   Zhao LX, 2009, COMPUT MATH APPL, V57, P919, DOI 10.1016/j.camwa.2008.10.055
NR 84
TC 26
Z9 27
U1 8
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 615
EP 646
DI 10.1007/s11042-011-0887-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000002
DA 2024-07-18
ER

PT J
AU Masood, S
   Hussain, A
   Jaffar, MA
   Choi, TS
AF Masood, Sohail
   Hussain, Ayyaz
   Jaffar, M. Arfan
   Choi, Tae-Sun
TI Intelligent noise detection and filtering using neuro-fuzzy system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Mixed impulse noise; Fuzzy filter; Fuzzy logic
   control; Random-valued impulse noise System control
AB In this paper, we propose a neuro-fuzzy based blind image restoration to remove impulse noise from low as well as highly corrupted images. Main components of the proposed technique include noise detection, histogram estimation and noise filtering process. Proposed technique constructs the fuzzy sets using fuzzy number construction algorithm. These fuzzy sets are used in noise filtering process to remove impulse noise from the noisy pixels using neuro-fuzzy inference system and fuzzy decider. Experimental results are based on global and local error measures, which prove that the proposed technique gives superior results than the present well known impulse noise filtering methods.
C1 [Masood, Sohail; Jaffar, M. Arfan] Natl Univ Comp & Emerging Sci, NU FAST, Islamabad, Pakistan.
   [Hussain, Ayyaz] Int Islamic Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Jaffar, M. Arfan; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Dept Mechatron, Kwangju, South Korea.
C3 International Islamic University, Pakistan; Gwangju Institute of Science
   & Technology (GIST)
RP Jaffar, MA (corresponding author), Natl Univ Comp & Emerging Sci, NU FAST, Islamabad, Pakistan.
EM rsmbhatti@gmail.com; ayyaz.hussain@iiu.edu.pk; arfanjaffar@gist.ac.kr;
   tschoi@gist.ac.kr
RI Jaffar, Arfan/GQB-2768-2022; Bhatti, Sohail Masood/GPK-8682-2022
OI Bhatti, Sohail Masood/0000-0002-8210-2785; Choi,
   Tae-Sun/0000-0001-7496-2438
FU National Research Foundation of Korea (NRF); Korean government (MEST)
   [2011-0006644]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MEST) (No. 2011-0006644).
CR Arakawa K, 1996, FUZZY SET SYST, V77, P3, DOI 10.1016/0165-0114(95)00122-0
   Castillo O, 2008, INT J INNOV COMPUT I, V4, P771
   Chaudhry A, 2006, INT J IMAGING SYSTEM
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hussain A, 2009, INT J INNOVATIVE COM, V5
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   Lee CS, 2005, IEEE T SYST MAN CY B, V35, P694, DOI 10.1109/TSMCB.2005.845397
   Lee CS, 2004, LECT NOTES COMPUT SC, V3174, P375
   Mockor J, 2008, INT J INNOV COMPUT I, V4, P1063
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Ponomarchuk Y., 2010, Journal of Convergence, V1, P35
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Wang JH, 2002, IEEE T SYST MAN CY B, V32, P230, DOI 10.1109/3477.990880
NR 15
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 93
EP 105
DI 10.1007/s11042-012-1015-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400007
DA 2024-07-18
ER

PT J
AU Hernández-Gracidas, CA
   Sucar, LE
   Montes-y-Gómez, M
AF Arturo Hernandez-Gracidas, Carlos
   Enrique Sucar, Luis
   Montes-y-Gomez, Manuel
TI Improving image retrieval by using spatial relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Spatial relations; Conceptual graphs
AB In this paper we proposed the use of spatial relations as a way of improving annotation-based image retrieval. We analyzed different types of spatial relations and selected the most adequate ones for image retrieval. We developed an image comparison and retrieval method based on conceptual graphs, which incorporates spatial relations. Additionally, we proposed an alternative term-weighting scheme and explored the use of more than one sample image for retrieval using several late fusion techniques. Our methods were evaluated with a rich and complex image dataset, based on the 39 topics developed for the ImageCLEF 2008 photo retrieval task. Results show that: (i) incorporating spatial relations produces a significant increase in performance, (ii) the label weighting scheme we proposed obtains better results than other traditional schemes, and (iii) the combination of several sample images using late fusion produces an additional improvement in retrieval according to several metrics.
C1 [Arturo Hernandez-Gracidas, Carlos; Montes-y-Gomez, Manuel] Natl Inst Astrophys Opt & Elect, Dept Computat Sci, Puebla, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica
RP Hernández-Gracidas, CA (corresponding author), Natl Inst Astrophys Opt & Elect, Dept Computat Sci, Luis Enrique Erro 1, Puebla, Mexico.
EM carloshg@ccc.inaoep.mx; esucar@inaoep.mx; mmontesg@inaoep.mx
RI Hernández-Gracidas, Carlos Arturo/J-2939-2019
OI Hernández-Gracidas, Carlos Arturo/0000-0003-0267-6306; Sucar, Luis
   Enrique/0000-0002-3685-5567
FU CONACyT [CB-2008-01-103878, 10216]
FX This research was partially supported by CONACyT under project grant
   CB-2008-01-103878 and postdoctoral fellowship 10216. Thanks to Dr.
   Antonio Juarez who kindly processed our lists with his fusion methods to
   obtain results for fuzzy Borda count and combMNZ.
CR [Anonymous], 2007, ACM MULTIMEDIA, DOI DOI 10.1145/1291233.1291379
   [Anonymous], 1984, Conceptual Structures: Information Processing in Mind and Machine
   Arni T, 2008, OVERVIEW IMAGECLEF 2
   Aslam J. A., 2001, SIGIR Forum, P276
   Belkhatir M, 2005, ACM-IEEE J CONF DIG, P368, DOI 10.1145/1065385.1065471
   Berretti S, 2003, IEEE T MULTIMEDIA, V5, P52, DOI 10.1109/TMM.2002.802833
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P2007
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   Chen J., 1998, INT ARCH PHOTOGRAMM, V32, P99
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Egenhofer M.J., 1993, Data Engineering Bulletin, V16, P40
   EGENHOFER MJ, 1991, INT J GEOGR INF SYST, V5, P161, DOI 10.1080/02693799108927841
   EGENHOFER MJ, 1989, LNCS, V367, P457
   Fox E. A., 1994, Second Text REtrieval Conference (TREC-2) (NIST-SP 500-215), P243
   Frank A. U., 1992, Journal of Visual Languages and Computing, V3, P343, DOI 10.1016/1045-926X(92)90007-9
   Goodrum A., 2000, INFORM SCI, V3, P2000
   Goyal RK, 2000, IEEE T KNOW IN PRESS
   Grubinger M., 2007, THESIS VICTORIA U ME
   Hernandez-Gracidas C, 2009, P 1 CHIL WORKSH PATT
   Hernandez-Gracidas C, 2010, P 9 INT C AD PERS FU
   Hernández-Gracidas C, 2007, LECT NOTES COMPUT SC, V4872, P879
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Kanji G.K., 1993, 100 STAT TESTS
   Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587
   Mechkour M., 1995, Multimedia Modeling. Towards Information Superhighway, P127
   Millard D.E., 2005, HYPERTEXT 05 P 16 AC, P54
   Montes M, 2000, P MEX INT C ART INT
   Paul K, 1995, P 3 TEXT RETR C TREC
   Picard RW, 1995, MULTIMEDIA SYSTEMS
   Rathi V, 2002, P IND C COMP VIS GRA
   Ren W., 2002, 9 INT WORKSHOP SYSTE, V2, P44
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sistla A. P., 1994, P 20 INT C VER LARG, P570
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Vogt C. C., 1999, Information Retrieval, V1, P151, DOI 10.1023/A:1009980820262
   Wu SL, 2006, INFORM PROCESS MANAG, V42, P899, DOI 10.1016/j.ipm.2005.08.004
   Zhang Q, 2004, COMMUNICATIONS INFOR, V4, P181
   Zhou X, 2005, P ISPRS HANGZH WORKS
NR 41
TC 8
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 479
EP 505
DI 10.1007/s11042-011-0911-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900009
DA 2024-07-18
ER

PT J
AU Trocan, M
   Mikovicova, B
   Zhanguzin, D
AF Trocan, Maria
   Mikovicova, Beata
   Zhanguzin, Daulet
TI An adaptive motion-compensated approach for video deinterlacing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video deinterlacing; Motion-based interpolation; Edge detection
ID ALGORITHM; EFFICIENT; INTERPOLATION; TELEVISION
AB Deinterlacing, defined as the process of converting a stream of interlaced frames into a sequence of progressive frames, represents a key feature in video processing. The interlaced video format, introduced by the old analog television transmission systems as a trade-off between framerate and bandwidth capacity, has become obsolete nowadays, when all transmissions are digital. Moreover, almost all recent displays-whether LCD or plasma-require progressive video input, whereas much of the available video content is in interlaced format. In this paper an adaptive, edge-preserving motion-compensated approach for video deinterlacing is proposed. The algorithm preserves strong edges and interpolates the missing pixels along the contours depending on the motion-degree of the region to which they belong. Our proposal is optimized to lower heavy computation, which is the main drawback of motion-compensated deinterlacing algorithms. Therefore it provides complexity scalability as a trade-off tool between performance and computation time. Experiments demonstrate a significant gain in reconstruction quality as compared to other deinterlacing implementations.
C1 [Trocan, Maria; Mikovicova, Beata] Inst Super Elect Paris, F-75006 Paris, France.
   [Zhanguzin, Daulet] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University
RP Trocan, M (corresponding author), Inst Super Elect Paris, 28 Rue Notre Dame Champs, F-75006 Paris, France.
EM maria.trocan@isep.fr; beata.mikovicova@isep.fr; daul0001@e.ntu.edu.sg
CR Bellers E. B., 2006, 2006 Digest of Technical Papers. International Conference on Consumer Electronics, P181, DOI 10.1109/ICCE.2006.1598370
   Biswas M, 2006, IEEE T IMAGE PROCESS, V15, P2596, DOI 10.1109/TIP.2006.877405
   Brox P, 2009, IEEE T INSTRUM MEAS, V58, P2952, DOI 10.1109/TIM.2009.2016791
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang J, 2009, IEEE T CIRC SYST VID, V19, P1214, DOI 10.1109/TCSVT.2009.2020341
   Chen MJ, 2004, IEEE T CONSUM ELECTR, V50, P1202
   Chen T, 2000, OPT ENG, V39, P2101, DOI 10.1117/1.1305262
   Chen YR, 2009, IEEE T CIRC SYST VID, V19, P1489, DOI 10.1109/TCSVT.2009.2022782
   Choi YJ, 2009, IEEE IMAGE PROC, P393, DOI 10.1109/ICIP.2009.5414461
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P956, DOI 10.1109/TIP.2009.2012906
   De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528
   deHaan G, 1997, IEEE T CONSUM ELECTR, V43, P819, DOI 10.1109/30.628721
   Doyle T., 1989, P 3 INT WORKSH HDTV, P711
   DUBOIS E, 1994, SIGNAL PROCESS-IMAGE, V6, P189
   El-Qawasmeh E, 2003, INFORMATICA-LITHUAN, V14, P19
   Engstrom EW, 1935, P IRE, V23, P295, DOI 10.1109/JRPROC.1935.227972
   Fan YC, 2008, J DISP TECHNOL, V4, P218, DOI 10.1109/JDT.2007.909372
   Fan YC, 2009, IEEE T CIRC SYST VID, V19, P932, DOI 10.1109/TCSVT.2009.2020327
   Ghodstinat M, 2009, LECT NOTES COMPUT SC, V5604, P91, DOI 10.1007/978-3-642-03061-1_5
   Hong S-H, 2006, EDGE PRESERVING SPAT
   Huang Q, 2006, IEEE T CONSUM ELECTR, V52, P888
   Huang Q, 2010, IEEE T CIRC SYST VID, V20, P673, DOI 10.1109/TCSVT.2010.2045807
   Jeon G, 2009, IEEE T CIRC SYST VID, V19, P842, DOI 10.1109/TCSVT.2009.2017309
   Jeon G, 2009, IMAGE VISION COMPUT, V27, P425, DOI 10.1016/j.imavis.2008.06.001
   Ji G, 2010, INT CONF SIGN PROCES, P771, DOI 10.1109/ICOSP.2010.5655916
   Kim W, 2007, IEEE T CONSUM ELECTR, V53, P1036, DOI 10.1109/TCE.2007.4341583
   Kwon H, 2003, IEEE T CONSUM ELECTR, V49, P198, DOI 10.1109/TCE.2003.1205477
   Lee GG, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/741290
   Lee K, 2010, IEEE T CONSUM ELECTR, V56, P2469, DOI 10.1109/TCE.2010.5681129
   Lee K, 2009, IEEE T CONSUM ELECTR, V55, P636, DOI 10.1109/TCE.2009.5174433
   Li M, 2007, IEEE T IMAGE PROCESS, V16, P2633, DOI 10.1109/TIP.2007.904967
   Lin CC, 2007, IEICE T FUND ELECTR, VE90A, P2575, DOI 10.1093/ietfec/e90-a.11.2575
   Lin SF, 2003, IEEE T CONSUM ELECTR, V49, P1256, DOI 10.1109/TCE.2003.1261227
   Mohanimadi HM, 2007, IEEE T CONSUM ELECTR, V53, P1117, DOI 10.1109/TCE.2007.4341594
   Park MK, 2003, IEEE T CONSUM ELECTR, V49, P1508, DOI 10.1109/TCE.2003.1261260
   PIGEON S, 1995, SPECIFICATION GENERI
   Shen YF, 2006, IEEE T CONSUM ELECTR, V52, P1403, DOI 10.1109/TCE.2006.273163
   Sze KW, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P1017
   Tu SF, 2009, IEEE INT CON MULTI, P77, DOI 10.1109/ICME.2009.5202440
   Usama S, 2005, ACTA POLYTECH, V45, P29
   Wang DM, 2005, IEEE T CIRC SYST VID, V15, P1019, DOI 10.1109/TCSVT.2005.852414
   Yang S, 2009, IEEE T CONSUM ELECTR, V55, P1654, DOI 10.1109/TCE.2009.5278039
   Yu LJ, 2006, IEEE T CONSUM ELECTR, V52, P712, DOI 10.1109/TCE.2006.1649702
   Zhanguzin D., 2010, IEEE IET BCS 3 INT W
NR 44
TC 10
Z9 11
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 819
EP 837
DI 10.1007/s11042-011-0845-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700015
DA 2024-07-18
ER

PT J
AU de Figueirêdo, HF
   Lacerda, YA
   de Paiva, AC
   Casanova, MA
   Baptista, CD
AF de Figueiredo, Hugo Feitosa
   Lacerda, Yuri Almeida
   de Paiva, Anselmo Cardoso
   Casanova, Marco Antonio
   Baptista, Claudio de Souza
TI PhotoGeo: a photo digital library with spatial-temporal support and
   self-annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal photo collections; Geo-referenced photos; Automatic photo
   organization; Metadata; Geo-tags
ID CONTEXT
AB The recent popularity of digital cameras has posed a new problem: how to efficiently store and retrieve the very large number of digital photos captured and chaotically stored in multiple locations without any annotation. This paper proposes an infrastructure, called PhotoGeo, which aims at helping users with the people photo annotation, event photo annotation, storage and retrieval of personal digital photos. To achieve the desired objective, PhotoGeo uses new algorithms that make it possible to annotate photos with the key metadata to facilitate their retrieval, such as: the people who were shown in the photo (who); where it was captured (where); the date and time of capture (when); and the event that was captured. The paper concludes with a detailed evaluation of these algorithms.
C1 [de Figueiredo, Hugo Feitosa; Lacerda, Yuri Almeida; Baptista, Claudio de Souza] Univ Campina Grande, Dept Comp Sci, BR-58109900 Bodocongo Campina Grande, Paraiba, Brazil.
   [de Paiva, Anselmo Cardoso] Univ Fed Maranhao, Appl Comp Grp NCA, BR-58109900 Sn Sao Luis, Maranhao, Brazil.
   [Casanova, Marco Antonio] Pontifical Catholic Univ Rio de Janeiro, BR-22451900 Rio De Janeiro, Brazil.
C3 Universidade Federal do Maranhao; Pontificia Universidade Catolica do
   Rio de Janeiro
RP de Figueirêdo, HF (corresponding author), Univ Campina Grande, Dept Comp Sci, Av Aprigio Veloso 882, BR-58109900 Bodocongo Campina Grande, Paraiba, Brazil.
EM hugoff@dsc.ufcg.edu.br; yuri@dsc.ufcg.edu.br; paiva@deinf.ufma.br;
   casanova@inf.puc-rio.br; baptista@dsc.ufcg.edu.br
RI Paiva, Anselmo/L-2358-2013; Lacerda, Yuri Almeida/ABB-3479-2020;
   Casanova, Marco Antonio/M-9054-2014
OI Paiva, Anselmo/0000-0003-4921-0626; Lacerda, Yuri
   Almeida/0000-0001-6842-4553; Casanova, Marco Antonio/0000-0003-0765-9636
CR Ames M, 2010, PERS UBIQUIT COMPUT, V14, P95, DOI 10.1007/s00779-009-0237-4
   [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   [Anonymous], EXCH IM FIL FORM DIG
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], HDB RES MOBILITY COM
   Baptista CS, 2000, IEEE ADVANCES IN DIGITAL LIBRARIES 2000, PROCEEDINGS, P151, DOI 10.1109/ADL.2000.848378
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Goodchild MF, 2008, INT J GEOGR INF SCI, V22, P1039, DOI 10.1080/13658810701850497
   Graham A., 2002, Proceedings of the second ACM/IEEE-CS joint conference on Digital libraries, P326
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   Naaman M., 2004, P 12 ANN ACM INT C M, P196
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Viana W, 2010, MULTIMED TOOLS APPL, P1
NR 18
TC 7
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 279
EP 305
DI 10.1007/s11042-011-0745-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800014
DA 2024-07-18
ER

PT J
AU Schandl, B
   Haslhofer, B
   Bürger, T
   Langegger, A
   Halb, W
AF Schandl, Bernhard
   Haslhofer, Bernhard
   Buerger, Tobias
   Langegger, Andreas
   Halb, Wolfgang
TI Linked Data and multimedia: the state of affairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linked Data; Semantic Web; Multimedia semantics; Multimedia metadata
ID ANNOTATION; ONTOLOGY
AB Linked Data is a way of exposing and sharing data as resources on the Web and interlinking them with semantically related resources. In the last three years significant amounts of data have been generated, increasingly forming a globally connected, distributed data space. For multimedia content, metadata are a key factor for efficient management, organization, and retrieval. However, the relationship between multimedia and Linked Data has been rarely studied, leading to a lack of mutual awareness and, as a consequence thereof, technological deficiencies. This article introduces the basic concepts of Linked Data in the context of multimedia metadata, and discusses techniques to generate, expose, discover, and consume Linked Data. It shows that a large amount of data sources exist, which are ready to be exploited by multimedia applications. The benefit of Linked Data in two multimedia-related applications is discussed and open research issues are outlined with the goal of bringing the research fields of multimedia and Linked Data closer together in order to facilitate mutual benefit.
C1 [Schandl, Bernhard; Haslhofer, Bernhard] Univ Vienna, Dept Distributed & Multimedia Syst, A-1010 Vienna, Austria.
   [Buerger, Tobias] Salzburg Res Forsch Gesell mbH, A-5020 Salzburg, Austria.
   [Langegger, Andreas] Johann Kepler Univ Linz, Inst Applicat Oriented Knowledge Proc, A-4040 Linz, Austria.
   [Halb, Wolfgang] JOANNEUM RES Forsch Gesell mbH, DIGITAL Inst Informat & Commun Technol, A-8010 Graz, Austria.
C3 University of Vienna; Johannes Kepler University Linz
RP Schandl, B (corresponding author), Univ Vienna, Dept Distributed & Multimedia Syst, Liebiggasse 4-3-4, A-1010 Vienna, Austria.
EM bernhard.schandl@univie.ac.at; bernhard.haslhofer@univie.ac.at;
   tobias.buerger@salzburgresearch.at; al@jku.at; wolfgang.halb@joanneum.at
FU Austrian Federal Ministry of Transport, Innovation, and Technology
   [815133]; EU
FX Parts of this work have been funded by FIT-IT grant 815133 from the
   Austrian Federal Ministry of Transport, Innovation, and Technology, and
   the EU eContentPlus project EuropeanaConnect.
CR Adida B, 2008, RDFA XHTML SYNT PROC
   Agosti M, 2004, LECT NOTES COMPUT SC, V3232, P244
   Alexander K, 2009, P 2 INT WORKSH LINK
   Anderson O, 2008, SCALABLE VECTOR GRAP
   [Anonymous], 2004, Architecture of the World Wide Web
   [Anonymous], 2006, LINKED DATA
   [Anonymous], 2000, Dissertation
   [Anonymous], SPARQL QUER LANG RDF
   [Anonymous], WORKSH SOC DAT WEB S, V405
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Auer S, 2009, P 7 INT SEM WEB C IS
   Auer S, 2009, P 18 INT WORLD WID W
   Becker C, 2008, LINK DAT WEB WORKSH, V369
   Beckett D., 2008, Turtle - Terse RDF Triple Language
   Berners-Lee T., 2006, P 3 INT SEM WEB US I
   Berruta D, 2008, BEST PRACTICE RECIPE
   Bizer C., 2006, 5 INT SEM WEB C, V26
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bizer Christian., 2007, How to Publish Linked Data on the Web
   Boardman R., 2003, Proceedings of HCI International, V2003, P616
   Brickley D., 2004, RDF VOCABULARY DESCR
   Burger T, 2008, 1 INT WORKSH INT MUL
   Burger T, 2010, HDB METADAT IN PRESS
   BUSH V, 1945, The Atlantic Monthly, DOI DOI 10.1145/227181.227186
   CARROLL JJ, 2004, P 13 INT WORLD WID W
   Cheng G, 2008, P 17 INT C WORLD WID
   Corlosquet S, 2009, P 8 INT SEM WEB C IS
   CYGANIAK R, 2009, LINKING OPEN DATA DA
   d'Aquin M, 2007, P 5 INT EON WORKSH E
   Erling O., 2007, Proceedings of the 1st Conference on Social Semantic Web (CSSW), P59
   Frisse ME, 1987, HYPERTEXT 87 P ACM C, P57
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Han L, 2008, 7 INT SEM WEB C ISWC
   Harth A, 2007, SEM WEB CHALL 6 INT
   HARTIG O., 2009, P 8 INT SEM WEB C IS
   Haslhofer B, 2010, LINKED DATA TRIPLIFI
   Haslhofer B, 2008, INT WORKSH LINK DAT
   Haslhofer B, 2009, INT J DIGIT LIBRARIE, V10, P15, DOI 10.1007/s00799-009-0050-8
   Hassanzadeh O, 2009, P 2 INT WORKSH LINK
   Hausenblas M, 2007, P SAMT 2007 DEC 4 7
   Hausenblas M, 2009, P 2 INT WORKSH LINK
   Hunter J, 2009, ANNU REV INFORM SCI, V43
   ISO/IEC, 2006, MULT FRAM MPEG 21 17
   Kahan J., 2001, P INT WORLD WIDE WEB, P623, DOI DOI 10.1145/371920.372166
   Kobilarov G, 2009, LECT NOTES COMPUT SC, V5554, P723, DOI 10.1007/978-3-642-02121-3_53
   Langegger A, 2008, P EUR SEM WEB C 2008
   Langegger A, 2009, P 8 INT SEM WEB C IS
   Lee W, 2009, ONTOLOGY MEDIA RESOU
   Marshall CC, 2004, ACM-IEEE J CONF DIG, P349, DOI 10.1145/996350.996432
   Marshall CC, 2000, CL LIB APPL, P97
   Network Working Group (NVVG), 2005, RFC3986 NWG
   Ovsiannikov IA, 1999, INT J HUM-COMPUT ST, V50, P329, DOI 10.1006/ijhc.1999.0247
   Raimond Y., 2008, Proceedings of the International Conference on Music Information Retrieval, P263
   Richardson L., 2008, RESTFUL WEB SERVICES
   Rodriguez JB, 2004, P 2 WORKSH SEM WEB D
   Saathoff C, 2009, P WORKSH SEM MULT DA
   Sack H, 2009, P 9 INT C INN COMM S
   Sauermann L, 2005, P 1 SEM DESKT WORKSH, V175
   Sauermann Leo., 2008, COOL URIS SEMANTIC W
   Schandl B, 2010, P 3 INT WORKSH LINK
   Scharffe F, 2009, ALIGNMENTS DATA INTE
   Schroeter R, 2007, P 4 EUR SEM WEB C ES
   Sheth A., 1998, Multimedia data management: using metadata to integrate and apply digital media
   Simon R, 2010, WORKSH LINK SPAT DAT
   Stegmaier F, 2009, P WORKSH SEM MULT DA
   Tummarello G, 2007, P 6 INT SEM WEB 2 AS
   Volz J, 2009, P 2 INT WORKSH LINK
   W3C, 2009, OWL 2WEB ONT LANG W3
   W3C, 2004, RES DESCR FRAM RDF W
   W3C, 2004, RDF/XML syntax specification (revised), W3C recommendation
   W3C, 2003, XPOINTER FRAM
   W3C Media Fragments Working Group, 2009, MED FRAGM URI 1 0 W3
   W3C Semantic Web Deployment Group, 2009, SKOS SIMPL KNOWL ORG
NR 74
TC 11
Z9 11
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 523
EP 556
DI 10.1007/s11042-011-0762-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000006
DA 2024-07-18
ER

PT J
AU Zhao, Z
   Cui, B
   Cong, G
   Huang, Z
   Shen, HT
AF Zhao, Zhe
   Cui, Bin
   Cong, Gao
   Huang, Zi
   Shen, Heng Tao
TI Extracting representative motion flows for effective video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Content feature; Motion flow; Trajectory matching
ID MOVING-OBJECTS; MODELS
AB In this paper, we propose a novel motion-based video retrieval approach to find desired videos from video databases through trajectory matching. The main component of our approach is to extract representative motion features from the video, which could be broken down to the following three steps. First, we extract the motion vectors from each frame of videos and utilize Harris corner points to compensate the effect of the camera motion. Second, we find interesting motion flows from frames using sliding window mechanism and a clustering algorithm. Third, we merge the generated motion flows and select representative ones to capture the motion features of videos. Furthermore, we design a symbolic based trajectory matching method for effective video retrieval. The experimental results show that our algorithm is capable to effectively extract motion flows with high accuracy and outperforms existing approaches for video retrieval.
C1 [Zhao, Zhe; Cui, Bin] Peking Univ, State Key Lab Software Dev Environm, Beijing 100871, Peoples R China.
   [Zhao, Zhe; Cui, Bin] Peking Univ, Dept Comp Sci, Beijing 100871, Peoples R China.
   [Cong, Gao] Nanyang Technol Univ, Nanyang, Singapore.
   [Huang, Zi; Shen, Heng Tao] Univ Queensland, Brisbane, Qld 4072, Australia.
C3 Peking University; Peking University; Nanyang Technological University;
   University of Queensland
RP Cui, B (corresponding author), Peking Univ, State Key Lab Software Dev Environm, Beijing 100871, Peoples R China.
EM zpegt@pku.edu.cn; bin.cui@pku.edu.cn; gaocong@ntu.edu.sg;
   huang@itee.uq.edu.au; shenht@itee.uq.edu.au
RI Cong, Gao/A-3726-2011; Cui, Bin/A-4554-2012; Shen, Heng
   Tao/ABD-5331-2021
OI HUANG, ZI/0000-0002-9738-4949; CUI, Bin/0000-0003-1681-4677; Cong,
   Gao/0000-0002-4430-6373
FU National Natural Science foundation of China [60933004, 60811120098,
   61073019];  [SKLSDE-2010KF-03]
FX This research was supported by the National Natural Science foundation
   of China under Grant No. 60933004, 60811120098 and 61073019, and Grant
   SKLSDE-2010KF-03.
CR [Anonymous], P 16 ACM INT C MULT
   [Anonymous], 2005, P INT C IMAGE PROCES
   Avrithis YS, 1999, COMPUT VIS IMAGE UND, V75, P3, DOI 10.1006/cviu.1999.0761
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Bashir FI, 2007, IEEE T IMAGE PROCESS, V16, P1912, DOI 10.1109/TIP.2007.898960
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chen L., 2005, P 2005 ACM SIGMOD IN, P491
   Chen LCL, 2004, PACLIC 18: Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation, P227, DOI 10.1145/1026711.1026749
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601
   Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508
   Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   KEOGH E, 2004, DATA MINING TIME SER
   Le TL, 2007, LECT NOTES COMPUT SC, V4351, P418
   Lertrusdachakul T, 2005, P ICCIMA C
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YF, 2002, INT C PATT RECOG, P548, DOI 10.1109/ICPR.2002.1048361
   Manjunath BS, 2002, P ICPR C, P548
   Rath GB, 1999, IEEE T CIRC SYST VID, V9, P1075, DOI 10.1109/76.795060
   Sivic J, 2004, LECT NOTES COMPUT SC, V3022, P85
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   Tomasi C, 1991, DETECTION TRACKING P, P864
   Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 31
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 687
EP 711
DI 10.1007/s11042-011-0763-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900011
DA 2024-07-18
ER

PT J
AU Kolekar, MH
AF Kolekar, Maheshkumar H.
TI Bayesian belief network based broadcast sports video indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Bayesian belief network; Soccer video annotation;
   Cricket video analysis; Semantic concept mining; Sports video indexing
ID SEMANTIC ANNOTATION; EVENT DETECTION; FRAMEWORK; RETRIEVAL; INFORMATION;
   EXTRACTION
AB This paper presents a probabilistic Bayesian belief network (BBN) method for automatic indexing of excitement clips of sports video sequences. The excitement clips from sports video sequences are extracted using audio features. The excitement clips are comprised of multiple subclips corresponding to the events such as replay, field-view, close-ups of players, close-ups of referees/umpires, spectators, players' gathering. The events are detected and classified using a hierarchical classification scheme. The BBN based on observed events is used to assign semantic concept-labels to the excitement clips, such as goals, saves, and card in soccer video, wicket and hit in cricket video sequences. The BBN based indexing results are compared with our previously proposed event-association based approach and found BBN is better than the event-association based approach. The proposed scheme provides a generalizable method for linking low-level video features with high-level semantic concepts. The generic nature of the proposed approach in the sports domain is validated by demonstrating successful indexing of soccer and cricket video excitement clips. The proposed scheme offers a general approach to the automatic tagging of large scale multimedia content with rich semantics. The collection of labeled excitement clips provide a video summary for highlight browsing, video skimming, indexing and retrieval.
C1 Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Kolekar, MH (corresponding author), Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
EM mahesh@iitp.ac.in
RI Kolekar, Maheshkumar/ABF-8942-2020
OI Kolekar, Maheshkumar/0000-0002-4272-3528
CR AGARWAL R, 1994, INT C VER LARG DAT B, P487
   Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   ANCONA N, 2001, INT JOINT C NEUR NET, V1, P611
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Baillie M, 2003, LECT NOTES COMPUT SC, V2728, P300
   Barnard M, 2003, 2003 IEEE XIII WORKSHOP ON NEURAL NETWORKS FOR SIGNAL PROCESSING - NNSP'03, P469, DOI 10.1109/NNSP.2003.1318046
   Bertini M, 2005, MULTIMED TOOLS APPL, V26, P345, DOI 10.1007/s11042-005-0893-y
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   CHRISTEL M, 1995, INT J MULTIMED TOOLS, V2, P501
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   DING Y, 2007, IEEE INT C COMP VIS
   DUAN L, 2003, ACM INT C MULT
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Hanjalic A, 2003, IEEE IMAGE PROC, P1
   HAUPTMANN AG, 1995, IJCAI WORKSH INT MUL, P17
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310
   Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026
   Jung C, 2009, IEEE T BROADCAST, V55, P79, DOI 10.1109/TBC.2008.2010377
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Kolekar MH, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P382, DOI 10.1109/ICVGIP.2008.102
   Kolekar MH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1617, DOI 10.1109/ICME.2006.262856
   Kolekar Maheshkumar H, 2009, J Multimed, V4, P298, DOI 10.4304/jmm.4.5.298-312
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Kolekar MH, 2006, LECT NOTES COMPUT SC, V3852, P633
   KOPPARAPU SK, 2001, KLUWER INT SER ENG C, V616, pR13
   LEFEVRE S, 2002, INT C DIG SIGN PROC, V2, P975
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li BX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   LI Y, 2005, IEEE INT C ADV VID S
   Mei T, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P107
   NARAYANA M, 2007, IEEE INT C COMP VIS, P1
   NILLIUS P, 2006, IEEE INF C COMP VIS, V2
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   SANKAR KP, 2006, INT C PATT REC, V4338, P433
   Shih HC, 2005, IEEE T BROADCAST, V51, P449, DOI 10.1109/TBC.2005.854169
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   SUN X, 2003, MULTISPECTRAL IMAGE
   Tsin Y, 2001, PROC CVPR IEEE, P1132
   WAN K, 2004, IEEE INT C MULT EXP, V1, P591
   Wang JJ, 2007, IEEE T MULTIMEDIA, V9, P576, DOI 10.1109/TMM.2006.888013
   Wang P, 2004, LECT NOTES COMPUT SC, V3331, P49
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   XIONG Z, 2003, IEEE INT C AC SPEECH, V5, P632
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   XU H, 2004, ACM SIGMM INT MULT W, P127
   Xu M, 2004, IEEE IMAGE PROC, P2909
   Yu TL, 2001, ELECTRON LETT, V37, P893, DOI 10.1049/el:20010597
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 54
TC 42
Z9 44
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 27
EP 54
DI 10.1007/s11042-010-0544-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100003
DA 2024-07-18
ER

PT J
AU Chen, DY
AF Chen, Duan-Yu
TI Modelling salient visual dynamics in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Spatiotemporal analysis
ID ATTENTION
AB Automatic video annotation is a critical step for content-based video retrieval and browsing. Detecting the focus of interest in video frames automatically can benefit the tedious manual labeling process. However, producing an appropriate extent of visually salient regions in video sequences is a challenging task. Therefore, in this work, we propose a novel approach for modeling dynamic visual attention based on spatiotemporal analysis. Our model first detects salient points in three-dimensional video volumes, and then uses the points as seeds to search the extent of salient regions in a novel motion attention map. To determine the extent of attended regions, we use the maximum entropy in the spatial domain to analyze the dynamics derived by spatiotemporal analysis. Our experiment results show that the proposed dynamic visual attention model achieves high precision value of 70% and reveals its robustness in successive video volumes.
C1 Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
EM dychen@saturn.yzu.edu.tw
CR BOLLMANN M, 1997, P DAGM S, P483
   COURTY N, 2003, P INT C IM PROC BARC
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HO CC, 2003, P PAC RIM C MULT SIN, V3, P1315
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   James W., 1980, PRINCIPLES PSYCHOL
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Li S, 2007, IEEE T CIRC SYST VID, V17, P1383, DOI 10.1109/TCSVT.2007.903798
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Navalpakkam V., 2006, P IEEE C COMPUTER VI, P2049
   PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079
   Shic F, 2007, INT J COMPUT VISION, V73, P159, DOI 10.1007/s11263-006-9784-6
   Shih CC, 2001, LECT NOTES COMPUT SC, V2195, P819
   Su CW, 2005, IEEE T MULTIMEDIA, V7, P1106, DOI 10.1109/TMM.2005.858394
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 17
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 271
EP 284
DI 10.1007/s11042-010-0511-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700012
DA 2024-07-18
ER

PT J
AU Hsieh, SL
   Tsai, IJ
   Yeh, CP
   Chang, CM
AF Hsieh, Shang-Lin
   Tsai, I-Ju
   Yeh, Chung-Ping
   Chang, Chia-Ming
TI An image authentication scheme based on digital watermarking and image
   secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Origin verification; Tamper detection; Digital
   watermarking; Image secret sharing
AB This paper presents an image authentication scheme that can verify the origin of the received image and, moreover, detect if the image has been tampered with. The underlying technologies of the scheme are digital watermarking and image secret sharing. Different from other schemes that use one piece of watermark information for one purpose and a different piece for another, the watermark information used for original verification is also utilized for tamper detection. Moreover, unlike other schemes that employ a fixed strength value for embedding watermarks, the scheme automatically utilizes two different strength values, one for flat regions and the other for complex regions. The experimental results prove that using different strength values increases the robustness of the watermark with little sacrifice in image quality. The results also demonstrate the effectiveness of the scheme for the origin verification as well as the tamper detection.
C1 [Hsieh, Shang-Lin; Tsai, I-Ju; Yeh, Chung-Ping; Chang, Chia-Ming] Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.
C3 Tatung University
RP Hsieh, SL (corresponding author), Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Zhongshan N Rd, Taipei 104, Taiwan.
EM slhsieh@ttu.edu.tw; tsayir@seed.net.tw; y12971@ms55.hinet.net;
   cmchang@ttu.edu.tw
FU Tatung University, Taipei, Taiwan [B97-I12-053]
FX Financial support of this study by Tatung University, Taipei, Taiwan,
   under grant B97-I12-053 is gratefully acknowledged.
CR ADIL H, 2008, SPRINGER MULTIMEDIA, V39, P1
   [Anonymous], P INT C IM PROC
   Bhatnagar G, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P526, DOI 10.1109/ICADIWT.2008.4664404
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   CHINCHEN C, 2002, 1 INT S CYB WORLDS, P217
   CONGXU Z, 2008, INT S EL COMM SEC, P930
   Fan MQ, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P19, DOI 10.1109/DMAMH.2007.34
   FAN Z, 2004, ICCCAS 2004, V2, P796
   Guzmán VVH, 2004, INT CONF ELECTR COMM, P283, DOI 10.1109/ICECC.2004.1269587
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   HONGMEI L, 2002, IEEE INT S CIRC SYST, V2, P672
   HUAJIAN L, 2006, IEEE INT C IM PROC, P1973
   IKUAN K, 2008, C IM SIGN PROC, V1, P504
   JUN X, 2008, INT C COMP INT SEC, V1, P285
   KWANGFU L, 2001, IEEE PAC RIM C COMM, V1, P164
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   SAFABAKHSH R, 2004, IEEE INT C INF TECHN, V1, P671
   SANGHEUN O, 2002, INT C CONS EL 2002, P192
   Shang-Lin Hsieh, 2008, Journal of Multimedia, V3, P42
   SHINFENG DL, 2006, 1 INT C INN COMP INF, V3, P74
   TUNGSHOU C, 2004, IEEE INT C NETW SENS, V2, P1235
   XIANHAI Z, 2006, 1 INT MULT COMP COMP, V2, P69
   YAZHOU L, 2004, INT S CIRC SYST, V2, P177
   2008, INT C SYST SIGN IM P, P173
NR 25
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 597
EP 619
DI 10.1007/s11042-010-0520-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000020
DA 2024-07-18
ER

PT J
AU Dantcheva, A
   Velardo, C
   D'Angelo, A
   Dugelay, JL
AF Dantcheva, Antitza
   Velardo, Carmelo
   D'Angelo, Angela
   Dugelay, Jean-Luc
TI Bag of soft biometrics for person identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft biometrics; Weight; Clothes color; Bag of soft biometrics; Human
   identification; Multibiometrics; Biometrics
ID GAIT RECOGNITION; WEIGHT; HEIGHT; LENGTH
AB In this work we seek to provide insight on the general topic of soft biometrics. We firstly present a new refined definition of soft biometrics, emphasizing on the aspect of human compliance, and then proceed to identify candidate traits that accept this novel definition. We then address relations between traits and discuss associated benefits and limitations of these traits. We also consider two novel soft biometric traits, namely weight and color of clothes and we analyze their reliability. Related promising results on the performance are provided. Finally, we consider a new application, namely human identification solely carried out by a bag of facial, body and accessory soft biometric traits, and as an evidence of its practicality, we provide preliminary promising results.
C1 [Dantcheva, Antitza; D'Angelo, Angela; Dugelay, Jean-Luc] EURECOM, Multimedia Commun Dept, Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Dantcheva, A (corresponding author), EURECOM, Multimedia Commun Dept, Sophia Antipolis, France.
EM dantchev@eurecom.fr; velardo@eurecom.fr; dangelo@eurecom.fr;
   dugelay@eurecom.fr
RI DUGELAY, Jean-Luc/ABE-7096-2021
OI DUGELAY, jean-luc/0000-0003-3151-4330
FU European project
FX This work was partly funded by the European project ACTIBIO, and the
   French national projects VIDEOID and BIORAFALE. Part of this work is
   presented in [12, 63] and [16].
CR ADJEROH D, 2010, P WIFS
   Ailisto H, 2006, PATTERN RECOGN LETT, V27, P325, DOI 10.1016/j.patrec.2005.08.018
   [Anonymous], P WACV
   [Anonymous], 1999, National Health and Nutrition Examination Survey
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   BenAbdelkader C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P499
   Berlin B., 1993, BASIC COLOR TERMS TH
   CAIFENG S, 2007, P AVSS, P505
   Carnicky J., 2006, Measurement Science Review, V6, P1
   CHIRAZ BA, 2002, P ICBA, V2359, P155
   Coe TR, 1999, ANAESTHESIA, V54, P582, DOI 10.1046/j.1365-2044.1999.00838.x
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Dangelo A, 2010, P VPQM
   DANGELO A, 2011, P ELECT IMAGING
   DANTCHEVA A, 2010, P MMSP
   DANTCHEVA A, 2010, P BTAS
   De Mendonca MC, 2000, AM J PHYS ANTHROPOL, V112, P39, DOI 10.1002/(SICI)1096-8644(200005)112:1<39::AID-AJPA5>3.0.CO;2-#
   Denman S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P196, DOI 10.1109/DICTA.2009.38
   Dugelay J.L, 2011, P WACV
   Duyar I, 2003, AM J PHYS ANTHROPOL, V122, P23, DOI 10.1002/ajpa.10257
   GIVENS G, 2003, P CVPR
   GRAY D, 2007, SOC POLICY J N Z MAR, pR4
   Gutta S., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P4084, DOI 10.1109/IJCNN.1999.830815
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Hadid A, 2002, INT C PATT RECOG, P196, DOI 10.1109/ICPR.2002.1047431
   Heo J., 2004, Computer Vision and Pattern Recognition Workshop, page, P122, DOI DOI 10.1109/CVPR.2004.35
   Hong L., 1999, P AUTOID 99, P59
   Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530
   Indovina M., 2003, Workshop on Multimodal User Authentication, P99
   Jain A., 2004, P 37 HAW INT C SYST, V3, P93, DOI [10.1115/HT-FED2004-56226, DOI 10.1115/HTFED2004-56226]
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Jeges Erno, 2008, 2008 Conference on Human System Interactions, P755, DOI 10.1109/HSI.2008.4581536
   Jiang X, 2000, PATTERN ANAL APPL, V3, P9, DOI 10.1007/s100440050002
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   JOHANSSON G, 1973, VISUAL PERCEPTION BI, V3
   KAKUMANUA P, 2007, P ICPR, V40
   KAUSHIK N, 2006, P INDICON
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   KEYS A, 1972, J CHRON DIS, V25, P329, DOI 10.1016/0021-9681(72)90027-6
   LAZEBNIK S, 2006, P ICPR, V2
   LEE JE, 2008, P BCC
   LIN H, 2006, P 6 WORLD C INT CONT, V2, P9988
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   MADDEN C, 2005, P IM VIS COMP NEW ZE
   Matta Federico, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P785, DOI 10.1109/MMSP.2008.4665181
   Menon Shyaman, 2005, Emerg Med Australas, V17, P113, DOI 10.1111/j.1742-6723.2005.00701.x
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Moustakas K, 2010, IEEE SIGNAL PROC LET, V17, P367, DOI 10.1109/LSP.2010.2040927
   Newham E., 1995, BIOMETRIC REPORT
   NIXON M, 1985, SPIE P, V575, P279
   Nkengne A, 2008, J EUR ACAD DERMATOL, V22, P982, DOI 10.1111/j.1468-3083.2008.02698.x
   OTOOLE AJ, 1994, MEM COGNITION, V22, P208, DOI 10.3758/BF03208892
   PATTERSON E, 2007, P BTAS
   POH N, 2006, P ICASSP, P5
   Puhan NB, 2008, C IND ELECT APPL, P1886, DOI 10.1109/ICIEA.2008.4582847
   RHODES HTF, 1956, A BERTILLON FATHER S, P27
   Saatci Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P393
   SAMANGOOEI S, 2008, P BTAS
   SUN D, 2008, P WCICA, P7773
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   VELARDO C, 2010, P BTAS
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wayman J., 1997, P CARD TECH SEC TECH, P732
   WEDA H, 2007, P ICME
   WOLF F, 2006, BAG WORDS
   WU H, 2002, P ICPR, V16, P346
   XIAO Y, 2004, EXTRACTION GLASSES H, P1
   ZEWAIL R, 2004, P MWSCAS
   2004, J EMERG MED, V27, P219
NR 71
TC 141
Z9 168
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 739
EP 777
DI 10.1007/s11042-010-0635-7
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300014
DA 2024-07-18
ER

PT J
AU Krausz, B
   Herpers, R
AF Krausz, Barbara
   Herpers, Rainer
TI MetroSurv: detecting events in subway stations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Foreground segmentation; Shadow detection; Tracking;
   Event detection; Expert system
ID MOTION
AB Video surveillance has become a hot research topic due to the recently increased importance of safety and security issues. Usually, security personnel has to monitor a surveillance area and often they have to do this for 24 h a day. Thus, it would be desirable to develop intelligent surveillance systems that support this task automatically. The system described in this contribution is thought of such an automatic surveillance system that has been developed to detect several dangerous situations in subway stations. The workflow and the most important steps from foreground segmentation, shadow detection, tracking and classification to event detection are described, discussed and evaluated in detail. The developed surveillance system yields satisfying results, as dangerous situations that need to be recognized are detected in most cases.
C1 [Krausz, Barbara] Fraunhofer IAIS, D-53754 St Augustin, Germany.
   [Herpers, Rainer] Bonn Rhein Sieg Univ Appl Sci, D-53757 St Augustin, Germany.
C3 Hochschule Bonn Rhein Sieg
RP Krausz, B (corresponding author), Fraunhofer IAIS, D-53754 St Augustin, Germany.
EM barbara.krausz@iais.fraunhofer.de; rainer.herpers@h-brs.de
OI Herpers, Rainer/0000-0002-9712-598X
CR [Anonymous], AM NUCL SOC 8 INT TO
   [Anonymous], THESIS S FRASER U
   [Anonymous], 1999, IEEE C COMP VIS PATT
   BARTH A, 2005, ANN M GERM ASS PATT
   Bevilacqua A, 2003, WSCG'2003, VOL 11, NO 1, CONFERENCE PROCEEDINGS, P57
   BHATTACHARYYA J, 2004, THESIS MCGILL U MONT
   BREMOND F, 1998, P DARPA IM UND WORKS
   *CLIPS, 2006, CLIPS REF MAN BAS PR, V1
   Comaniciu D., 1999, P INT C COMP VIS, V2
   *CREDS, 2005, CALL REAL TIM EV DET
   Cucchiara R., 2004, P INT C PATT REC
   CUCCHIARA R, 2001, P INT C IM AN PROC
   CUPILLARD F, 2004, P INT C NETW SENS CO
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   FERNANDEZ C, 2007, INT C ADV ART INT
   FRAHM JM, 2003, INT S IM SIGN PROC A
   Ghanem N., 2004, C COMP VIS PATT REC
   Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838
   Gryn JM, 2009, COMPUT VIS IMAGE UND, V113, P291, DOI 10.1016/j.cviu.2008.10.006
   Haritaoglu I., 1998, P INT C FAC GEST REC
   Hongeng S, 2000, INT C PATT RECOG, P164, DOI 10.1109/ICPR.2000.905296
   HORPRASERT T, 1999, INT C COMP VIS 99 FR
   Hsieh JW, 2004, INT C PATT RECOG, P372
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Jackson P, 1998, INTRO EXPERT SYSTEMS
   KAZAROV A, 1998, 108 ATLAS DAQ
   KRAUSZ B, 2007, THESIS FH BONN RHEIN
   Liao SH, 2005, EXPERT SYST APPL, V28, P93, DOI 10.1016/j.eswa.2004.08.003
   LIPTON A, 1998, INT WORKSH APPL COMP
   Lo KH, 2006, INT C PATT RECOG, P743
   McCahill M., 2002, CCTV LONDON
   Muncaster Justin, 2007, J MULTIMEDIA, V2, P66
   Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232
   NEVATIA R, 2003, WORKSH EV MIN
   SALVADOR E, 2004, THESIS LAUSANNE
   SENIOR A, 2001, INT WORKSH PERF EV T
   SENIOR A, 2002, INT WORKSH PERF EV T
   Shet V. D., 2005, IEEE C ADV VID SIGN
   SHET VD, 2006, EUR C COMP VIS
   STARNER T, 1995, INT S COMP VIS
   SUBRAMANYA SR, 2005, IEEE WORKSH APPL COM
   VU VT, 2002, INT C COMP GRAPH VIS
   VU VT, 2003, INT JOINT C ART INT
   Wilson A. D., 1998, INT C COMP VIS
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZANG Q, 2003, P COMP AN IM PATT
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, IEEE T PATTERN ANAL, V26, P651, DOI 10.1109/TPAMI.2004.1273970
NR 50
TC 16
Z9 17
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 123
EP 147
DI 10.1007/s11042-009-0367-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ren, K
   Sarvas, R
   Calic, J
AF Ren, Kan
   Sarvas, Risto
   Calic, Janko
TI Interactive search and browsing interface for large-scale visual
   repositories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image and video browsing; Interactive interfaces; Unsupervised
   clustering; Video search
AB Due to the rapid proliferation of both user-generated and broadcasted content, the interfaces for search and browsing of visual media have become increasingly important. This paper presents a novel intuitive interactive interface for browsing of large-scale image and video collections. It visualises underlying structure of the dataset by the size and spatial relations of displayed images. In order to achieve this, images or video key-frames are initially clustered using an unsupervised graph-based clustering algorithm. By selecting images that are hierarchically laid out on the screen, user can intuitively navigate through the collection or search for specific content. The extensive experimental results based on user evaluation of photo search, browsing and selection as well as interactive video search demonstrate good usability of the presented system and improvement when compared to the standard methods for interaction with large-scale image and video collections.
C1 [Ren, Kan; Calic, Janko] Univ Surrey, I Lab, Guildford GU2 7XH, Surrey, England.
   [Sarvas, Risto] Helsinki Inst Informat Technol, Helsinki 02015, Finland.
C3 University of Surrey; University of Helsinki
RP Ren, K (corresponding author), Univ Surrey, I Lab, Guildford GU2 7XH, Surrey, England.
EM k.ren@surrey.ac.uk; risto.sarvas@hiit.fi; j.calic@surrey.ac.uk
RI Calic, Janko/K-7420-2012
OI Calic, Janko/0000-0001-7209-0584
CR [Anonymous], 1971, Psychological Types
   *APPL LTD, 2009, IPHOTO09
   Bederson BenjaminB., 2001, P ACM S USER INTERFA, P71
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Calic J, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/19496
   COOPER M, 2003, P 11 ACM INT C MULT, P364
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ferman AM, 1997, P SOC PHOTO-OPT INS, V3229, P23, DOI 10.1117/12.290352
   GRAHAM A, 2002, P 2 ACM IEEE CS JOIN
   Huynh DavidF., 2005, CHI 05, P1937
   LOUI A, 2000, IEEE INT C MULT EXP
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   REN K, 2009, P ACM MULT
   REN K, 2009, P ACM MULT MULT GRAN
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 17
TC 6
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 513
EP 528
DI 10.1007/s11042-009-0445-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kovacevic, A
   Milosavljevic, B
   Konjovic, Z
   Vidakovic, M
AF Kovacevic, Aleksandar
   Milosavljevic, Branko
   Konjovic, Zora
   Vidakovic, Milan
TI Adaptive content-based music retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based music retrieval; Feature space tuning; Genetic algorithms;
   Information retrieval
AB This paper presents a tunable content-based music retrieval (CBMR) system suitable the for retrieval of music audio clips. The audio clips are represented as extracted feature vectors. The CBMR system is expert-tunable by altering the feature space. The feature space is tuned according to the expert-specified similarity criteria expressed in terms of clusters of similar audio clips. The main goal of tuning the feature space is to improve retrieval performance, since some features may have more impact on perceived similarity than others. The tuning process utilizes our genetic algorithm. The R-tree index for efficient retrieval of audio clips is based on the clustering of feature vectors. For each cluster a minimal bounding rectangle (MBR) is formed, thus providing objects for indexing. Inserting new nodes into the R-tree is efficiently performed because of the chosen Quadratic Split algorithm. Our CBMR system implements the point query and the n-nearest neighbors query with the O(logn) time complexity. Different objective functions based on cluster similarity and dissimilarity measures are used for the genetic algorithm. We have found that all of them have similar impact on the retrieval performance in terms of precision and recall. The paper includes experimental results in measuring retrieval performance, reporting significant improvement over the untuned feature space.
C1 [Kovacevic, Aleksandar; Milosavljevic, Branko; Konjovic, Zora; Vidakovic, Milan] Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
C3 University of Novi Sad
RP Kovacevic, A (corresponding author), Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
EM kocha78@uns.ac.rs; mbranko@uns.ac.rs; ftn_zora@uns.ac.rs;
   minja@uns.ac.rs
OI Kovacevic, Aleksandar/0000-0002-8342-9333; Milosavljevic,
   Branko/0000-0003-4551-9802
CR Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   BROCHU E, 2002, NEURAL INFORM PROCES
   Casey MichaelA., 2006, ISMIR, P144
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   GHIAS A, 1995, ACM INT MULT C
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   HABICH D, 2005, P 5 OP WORKSH MUS IN
   HAITSMA J, 2002, 3 INT S MUS INF RETR
   HOOS H, 2001, INT S MUS INF RETR I, P4150
   HU N, 2002, ACM JOINT C DIG LIB
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   JANG J, 2001, IEEE PAC RIM C MULT
   KARYDIS I, 2005, P 11 IEEE INT MULT M
   King Lum Cheung, 1998, SIGMOD Record, V27, P16, DOI 10.1145/290593.290596
   KOVACEVIC A, 2006, P 3 START AI RES S S, P62
   KUO FF, 2004, 4 ACM IEEE CS JOINT
   Kurth F., 2002, 112 CONV AUD ENG SOC
   Lampropoulos AS, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P136, DOI 10.1109/WI.2005.8
   Li T, 2006, IEEE DATA MINING, P372
   LIU Z, 1997, IEEE SIGN PROC SOC W
   Lo YL, 2002, 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOP, PROCEEDINGS, P258, DOI 10.1109/ICDCSW.2002.1030779
   MILOSAVLJEVIC B, 2004, IEEE MULTIMEDIA SOFT, P218
   MILOSAVLJEVIC B, 2002, IEEE MULTIMEDIA SOFT, P114
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   Pickens J., 2001, SURVEY FEATURE SELEC
   PICKENS J, 2002, ACM INT C INF KNOWL
   Rho S, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P739
   RUI Y, 1999, 7 ACM INT C MULT 2, P67
   SHALEVSHWARTZ S, 2002, ACM SIGIR C RES DEV
   TOKUI N, 2000, 3 INT C GEN ART MIL
   TYPKE R, 2004, SURVEY MUSIC INFORM
   Typke Rainer., 2003, ISMIR 2003: Proceedings of the Fourth International Conference on Music Information Retrieval, P107
   UNEHARA M, 2003, J ASIAN DES INT C
NR 34
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 525
EP 544
DI 10.1007/s11042-009-0336-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200009
DA 2024-07-18
ER

PT J
AU Poullot, S
   Buisson, O
   Crucianu, M
AF Poullot, Sebastien
   Buisson, Olivier
   Crucianu, Michel
TI Scaling content-based video copy detection to very large databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video copy detection; Video retrieval; Scalability;
   Multidimensional index structure; Video indexing
AB Video copy detection is mainly required for protecting owners against unauthorized use of their content. Content-based copy detection methods rely on the evaluation of the similarity between potential copies and the original videos. Scalability is the key issue in making these methods practical for very large video databases. To address this challenge, we put forward here an optimized similarity-based search method that takes into account the local characteristics of the space of content signatures. First, refined models of the distortions undergone by the signatures during the copy creation process allow to search in a more appropriately defined area of the description space, increasing query selectivity and improving detection quality. Second, by identifying in the description space those regions where the local density of content signatures is high, a significant additional reduction of the computation cost is obtained. An evaluation on ground truth databases shows that the proposed solution is reliable. Scalability is then demonstrated on larger databases of up to 280,000 h of video.
C1 [Poullot, Sebastien; Crucianu, Michel] CNAM, Vertigo CEDRIC, F-75141 Paris 03, France.
   [Poullot, Sebastien; Buisson, Olivier] Inst Natl Audiovisuel, F-94366 Bry Sur Marne, France.
C3 heSam Universite; Conservatoire National Arts & Metiers (CNAM)
RP Poullot, S (corresponding author), CNAM, Vertigo CEDRIC, 292 Rue St Martin, F-75141 Paris 03, France.
EM spoullot@ina.fr; obuisson@ina.fr; michel.crucianu@cnam.fr
FU French National Research Agency (ANR)
FX This work was partly supported by the French National Research Agency
   (ANR) within the Sigmund project.
CR [Anonymous], P 7 ACM SIGMM MIR
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BERRANI SA, 2003, P ACM INT WORKSH MUL, P70
   Chang EY, 1998, P SOC PHOTO-OPT INS, V3527, P58, DOI 10.1117/12.325852
   CHUM O, 2007, P 6 ACM INT C IM VID, P549
   Eickeler S, 1999, INT CONF ACOUST SPEE, P2997, DOI 10.1109/ICASSP.1999.757471
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FOO JJ, 2007, P 6 ACM INT C IM VID, P557
   FOO JJ, 2007, THESIS SCH COMP SCI
   GENGEMBRE N, 2008, P ACM INT C CONT BAS, P211
   Hampapur A, 2002, P SOC PHOTO-OPT INS, V4676, P194
   Henrich A, 1998, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.1998.655799
   JAIMES A, 2003, 4 PAC RIM C MULT, V1, P16
   Joly A, 2003, LECT NOTES COMPUT SC, V2728, P414
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Ke Y, 2004, PROC CVPR IEEE, P506
   Ke Y., 2004, ACM MULTIMEDIA 04, P869
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Law-To J., 2006, P ACM INT C MULTIMED, P835
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Lin ET, 2005, P IEEE, V93, P171, DOI 10.1109/JPROC.2004.839623
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARCO B, 2006, P ACM INT C IM VID R, P133
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Poullot S., 2007, Proceedings of the ACM International Conference on Image and Video Retrieval, P348
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
NR 33
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 279
EP 306
DI 10.1007/s11042-009-0323-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000004
DA 2024-07-18
ER

PT J
AU Chou, YF
   Shih, ZC
AF Chou, Yun-Feng
   Shih, Zen-Chung
TI A nonparametric regression model for virtual humans generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deformation; Nonparametric regression; Elliptic radial basis
   functions; Functional approximation; Locally weighted regression
ID IMAGE; SPEECH; MOTION
AB In this paper, we propose a novel nonparametric regression model to generate virtual humans from still images for the applications of next generation environments (NG). This model automatically synthesizes deformed shapes of characters by using kernel regression with elliptic radial basis functions (ERBFs) and locally weighted regression (LOESS). Kernel regression with ERBFs is used for representing the deformed character shapes and creating lively animated talking faces. For preserving patterns within the shapes, LOESS is applied to fit the details with local control. The results show that our method effectively simulates plausible movements for character animation, including body movement simulation, novel views synthesis, and expressive facial animation synchronized with input speech. Therefore, the proposed model is especially suitable for intelligent multimedia applications in virtual humans generation.
C1 [Chou, Yun-Feng; Shih, Zen-Chung] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Shih, ZC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM yfchou@cs.nctu.edu.tw; zcshih@cs.nctu.edu.tw
FU National Science Council, Republic of China [NSC 98-2221-E-009-123-MY3]
FX This work is supported partially by the National Science Council,
   Republic of China, under grant NSC 98-2221-E-009-123-MY3. We would like
   to thank Prof. Sang-Soo Yeo and reviewers for their helpful suggestions.
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   [Anonymous], 2012, INTRO LINEAR REGRESS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2002, LEARNING KERNEL CLASSIFIERS. THEORY AND ALGORITHMS
   [Anonymous], ICCV, DOI DOI 10.1109/ICCV.2007.4408903
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   BRUCE HT, 1995, 8 ACM S US INT SOFTW, P3
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P2331, DOI 10.1109/TASL.2007.905145
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   CHEN SE, 1993, SIGGRAPH 93, P279
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Deng Z., 2006, Proc. of ACM SIGGGRAPH/Eurographics Symposium on Computer Animation, P251
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Forstmann S, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P141
   Fu T, 2004, IEEE IMAGE PROC, P3519
   GLOCKER B, 2008, IEEE C COMP VIS PATT
   GOLDSTEIN E, 1995, GRAPH INTER, P247
   Hornung A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186645
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jang Y, 2006, COMPUT GRAPH FORUM, V25, P587, DOI 10.1111/j.1467-8659.2006.00978.x
   LEMPITSKY L, 2008, IEEE C COMP VIS PATT
   LI Y, 2008, 10 EUR C COMP VIS, V2, P379
   LITWINOWICZ P, 1994, SIGGRAPH 94, P409, DOI DOI 10.1145/192161.192270
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Ngo T, 2000, COMP GRAPH, P403, DOI 10.1145/344779.344964
   PARK J, 1993, 32 C DEC CONTR, P3700
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ranjan V, 1996, COMPUT GRAPH FORUM, V15, pC129, DOI 10.1111/1467-8659.1530129
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   RUPRECHT D, 1995, IEEE COMPUT GRAPH, V15, P37, DOI 10.1109/38.365004
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001
   SEITZ SM, 1996, SIGGRAPH, P21
   Sethian J., 1999, LEVEL SET METHODS FA
   SETHIAN J., 1996, LEVEL SET METHODS
   SUN D, 2008, 10 EUR C COMP VIS, V3, P83
   TROBIN W, 2008, 10 EUR C COMP VIS, V4, P677
   Vedula S, 2005, ACM T GRAPHIC, V24, P240, DOI 10.1145/1061347.1061351
   Vorobyov SA, 2001, DIGIT SIGNAL PROCESS, V11, P204, DOI 10.1006/dspr.2001.0398
   Wang YZ, 2008, COMPUT ANIMAT VIRT W, V19, P411, DOI 10.1002/cav.251
   Weber O, 2009, COMPUT GRAPH FORUM, V28, P587, DOI 10.1111/j.1467-8659.2009.01399.x
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   XU L, 2008, 10 EUR C COMP VIS, V1, P671
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   YOTSUKURA T, 2003, 11 ACM INT C MULT, P351
NR 51
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 163
EP 187
DI 10.1007/s11042-009-0412-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400010
DA 2024-07-18
ER

PT J
AU Shih, JL
   Chen, HY
AF Shih, Jau-Ling
   Chen, Hong-Yu
TI A 3D model retrieval approach using the interior and exterior 3D shape
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; ART-based elevation descriptor; Shell grid
   descriptor
AB In this paper, we will propose a new exterior shape feature, ART-based elevation descriptor (ART-ED), and a new interior shape feature, shell grid descriptor (SGD), for 3D model retrieval. ART-ED describes the elevation information of a 3D model from six different angles. Since ART-ED represents only the exterior contour of a 3D model, SGD is proposed for extracting the interior shape information. Finally, these two proposed features as well as other features are combined in an attempt to improve retrieval. Experimental results show that the proposed methods are superior to other descriptors.
C1 [Shih, Jau-Ling; Chen, Hong-Yu] Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
C3 Chung Hua University
RP Shih, JL (corresponding author), Chung Hua Univ, Dept Comp Sci & Informat Engn, 707 Sec 2 WuFu Rd, Hsinchu, Taiwan.
EM sjl@chu.edu.tw
FU National Science Council, Taiwan [NSC 96-2221-E-216-041-MY2]
FX This research was supported in part by the National Science Council,
   Taiwan under Contract NSC 96-2221-E-216-041-MY2.
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], P S GEOM PROC
   Assfalg J, 2006, MULTIMED TOOLS APPL, V31, P29, DOI 10.1007/s11042-006-0034-2
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Ip C.Y., 2003, Proc. of the 8th ACM Symposium on Solid Modeling and Applications, Seattle, Washington, USA, P322
   Kuo CT, 2007, PATTERN RECOGN, V40, P742, DOI 10.1016/j.patcog.2006.06.006
   Löffler J, 2000, IEEE INFOR VIS, P82, DOI 10.1109/IV.2000.859741
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Ohbuchi R, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P293, DOI 10.1109/PCCGA.2003.1238271
   Ohbuchi R, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P97, DOI 10.1109/TPCG.2003.1206936
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Reisert M, 2006, COMPUT GRAPH-UK, V30, P197, DOI 10.1016/j.cag.2006.01.025
   Shih J. L., 2005, ELECTRON LETT, V41, P23, DOI DOI 10.1049/EL:20056916
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Super BJ, 2003, PATTERN RECOGN, V36, P69, DOI 10.1016/S0031-3203(02)00023-7
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   YAMADA A, 2001, ISOIECJTC1SC29WG11N4
   Yu M, 2003, PROC CVPR IEEE, P656
NR 21
TC 7
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 45
EP 62
DI 10.1007/s11042-008-0256-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 425HF
UT WOS:000264626900003
DA 2024-07-18
ER

PT J
AU Jeong, SD
   Kim, SW
   Choi, BU
AF Jeong, Seungdo
   Kim, Sang-Wook
   Choi, Byung-Uk
TI Dimensionality reduction for similarity search with the Euclidean
   distance in high-dimensional applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia information retrieval; High-dimensional indexing;
   Dimensionality reduction; Similarity search
ID QUERIES; INDEX
AB In multimedia information retrieval, multimedia data are represented as vectors in high-dimensional space. To search these vectors efficiently, a variety of indexing methods have been proposed. However, the performance of these indexing methods degrades dramatically with increasing dimensionality, which is known as the dimensionality curse. To resolve the dimensionality curse, dimensionality reduction methods have been proposed. They map feature vectors in high-dimensional space into vectors in low-dimensional space before the data are indexed. This paper proposes a novel method for dimensionality reduction based on a function that approximates the Euclidean distance based on the norm and angle components of a vector. First, we identify the causes of, and discuss basic solutions to, errors in angle approximation during the approximation of the Euclidean distance. Then, this paper propose a new method for dimensionality reduction that extracts a set of subvectors from a feature vector and maintains only the norm and the approximated angle for every subvector. The selection of a good reference vector is crucial for accurate approximation of the angle component. We present criteria for being a good reference vector, and propose a method that chooses a good reference vector. Also, we define a novel distance function using the norm and angle components, and formally prove that the distance function consistently lower-bounds the Euclidean distance. This implies information retrieval with this function does not incur any false dismissals. Finally, the superiority of the proposed approach is verified via extensive experiments with synthetic and real-life data sets.
C1 [Kim, Sang-Wook] Hanyang Univ, Dept Elect & Comp Engn, Sch Informat & Commun, Seoul 133791, South Korea.
C3 Hanyang University
RP Kim, SW (corresponding author), Hanyang Univ, Dept Elect & Comp Engn, Sch Informat & Commun, Seoul 133791, South Korea.
EM sdjeong@hanyang.ac.kr; wook@hanyang.ac.kr; buchoi@hanyang.ac.kr
OI Jeong, Seungdo/0000-0002-6059-1266
FU Korean Government(MOEHRD) [KRF-2005-041-D00651, KRF-2007-314-D00221];
   MKE(Ministry of Knowledge Economy), Korea [IITA-2008-C1090-0801-0040]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government(MOEHRD) (Grant: KRF-2005-041-D00651), the Korea
   Research Foundation Grant funded by the Korean Government (MOEHRD, Basic
   Research Promotion Fund)(Grant: KRF-2007-314-D00221), and the
   MKE(Ministry of Knowledge Economy), Korea, under the ITRC(Information
   Technology Research Center) support program supervised by the
   IITA(Institute of Information Technology Advancement)(Grant:
   IITA-2008-C1090-0801-0040). And, all correspondences of this work should
   be addressed to S.-W. Kim.
CR Aggarwal C.C., 2001, P ACM SIGACT SIGMOD, P256
   Agrawal R., 1993, Proceedings of the International Conference on Foundations of Data Organization and Algorithms, Chicago, IL, P69
   [Anonymous], 1994, The VLDB Journal, DOI DOI 10.1007/BF01231606
   [Anonymous], P ACM SIGMOD
   [Anonymous], 2002, Numerical Recipes in C++: The Art of Scientific Computing
   [Anonymous], P ACM INT C MAN DAT
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BERCHTOLD S, 1997, P ACM SIGMOD INT C M, P1
   Beyer K., 1999, Proceedings of the 7th International Conference on Database Theory, ICDT'99, DOI [10.1007/3-540-49257-7_15, DOI 10.1007/3-540-49257-7_15]
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Egecioglu Ö, 2004, IEEE T KNOWL DATA EN, V16, P714, DOI 10.1109/TKDE.2004.9
   EGECIOGLU O, 2001, P C PRINC PRACT KNOW, P79
   EIDENBERGER H, 2004, P SPIE STOR RETR MET, P145
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   JEONG S, 2006, P INT C DAT EXP SYST, P863
   Katayama N., 1997, P ACM SIGMOD, P369
   KRISHNAMACHARI S, 1999, P SOC PHOTO-OPT INS, P427
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   Lin T, 2006, LECT NOTES COMPUT SC, V3951, P44
   MERTINS A, 2000, SIGNAL ANAL
   Moon T.K., 2000, Mathematical Methods and Algorithms for Signal Processing
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   OGRAS UY, 2003, P 12 INT C INF KNOWL, P99
   Pagel B.-U., 1995, Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1995, P86, DOI 10.1145/212433.212458
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Seidl T, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P506
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thomasian A, 2008, MULTIMED TOOLS APPL, V38, P253, DOI 10.1007/s11042-007-0179-7
   Thomasian A, 2008, MULTIMED TOOLS APPL, V40, P241, DOI 10.1007/s11042-008-0206-3
   *U CAL, 1999, COR IM FEAT
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   XIAO L, 2006, INT C MACH LEARN, P1041
NR 34
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 251
EP 271
DI 10.1007/s11042-008-0243-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300006
DA 2024-07-18
ER

PT J
AU Asteriadis, S
   Tzouveli, P
   Karpouzis, K
   Kollias, S
AF Asteriadis, Stylianos
   Tzouveli, Paraskevi
   Karpouzis, Kostas
   Kollias, Stefanos
TI Estimation of behavioral user state based on eye gaze and head
   pose-application in an e-learning environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User attention estimation; Head pose; Eye gaze; Facial feature detection
   and tracking
ID RECOGNITION; TRACKING; PLAY
AB Most e-learning environments which utilize user feedback or profiles, collect such information based on questionnaires, resulting very often in incomplete answers, and sometimes deliberate misleading input. In this work, we present a mechanism which compiles feedback related to the behavioral state of the user (e.g. level of interest) in the context of reading an electronic document; this is achieved using a non-intrusive scheme, which uses a simple web camera to detect and track the head, eye and hand movements and provides an estimation of the level of interest and engagement with the use of a neuro-fuzzy network initialized from evidence from the idea of Theory of Mind and trained from expert-annotated data. The user does not need to interact with the proposed system, and can act as if she was not monitored at all. The proposed scheme is tested in an e-learning environment, in order to adapt the presentation of the content to the user profile and current behavioral state. Experiments show that the proposed system detects reading- and attention-related user states very effectively, in a testbed where children's reading performance is tracked.
C1 [Asteriadis, Stylianos; Tzouveli, Paraskevi; Karpouzis, Kostas; Kollias, Stefanos] Natl Tech Univ Athens, Sch Elect & Comp Engn, Image Video & Multimedia Syst Lab, Athens 15780, Greece.
C3 National Technical University of Athens
RP Asteriadis, S (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Image Video & Multimedia Syst Lab, Athens 15780, Greece.
EM stiast@image.ntua.gr; tpar@image.ntua.gr; kkarpou@image.ntua.gr;
   stefanos@cs.ntua.gr
RI Kollias, Stefanos/ACY-7285-2022; Karpouzis, Kostas/A-1792-2008;
   Karpouzis, Kostas/AAQ-8018-2020; Asteriadis, Stylianos/O-2140-2016
OI Karpouzis, Kostas/0000-0002-4615-6751; Tzouveli,
   Paraskevi/0000-0002-2061-9607; Kollias, Stefanos/0000-0003-2899-0598;
   Asteriadis, Stylianos/0000-0002-4298-6870
FU FP6 IP Callas (Conveying Affectiveness in Leading-edge Living Adaptive
   Systems) [IST-034800, IST-034549]
FX This work has been funded by the FP6 IP Callas (Conveying Affectiveness
   in Leading-edge Living Adaptive Systems), Contract Number IST-34800 and
   the FP6 STREP Agent-Dysl (Accommodative Intelligent Educational
   Environments for Dyslexic learners) Contract Number IST-034549.
CR [Anonymous], 1995, MINDBLINDNESS
   [Anonymous], 2006, P S EYE TRACK RES AP, DOI DOI 10.1145/1117309.1117349
   [Anonymous], PROCEEDINGS OF 2000
   [Anonymous], 2001, Danish yearbook for philosophy
   [Anonymous], P C BRIT MACH VIS MU
   ASTERIADIS S, 2007, P 2 INT C COMP VIS T, V2, P247
   BEYMER D., 2003, P IEEE C COMP VIS PA, V2, pII, DOI [10.1109/CVPR.2003.1211502, DOI 10.1109/CVPR.2003.1211502]
   Bosse T., 2007, Proceedings of the AISB 2007 Workshop on Mindful Environments, P335
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Caridakis G, 2008, NEUROCOMPUTING, V71, P2553, DOI 10.1016/j.neucom.2007.11.043
   Chiu S. L., 1994, J INTELL FUZZY SYST, V2, P267, DOI [10.3233/IFS-1994-2306, DOI 10.3233/IFS-1994-2306]
   CHRISTIE JF, 1983, REV EDUC RES, V53, P93, DOI 10.2307/1170328
   D'Orazio T, 2007, PATTERN RECOGN, V40, P2341, DOI 10.1016/j.patcog.2007.01.018
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deng JY, 1997, PATTERN RECOGN, V30, P403, DOI 10.1016/S0031-3203(96)00086-6
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Gee C.A., 1994, IEEE PROC MECHATRONI, P112
   Gourier N., 2004, P POINT ICPR INT WOR
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   JESORSKY O, 2001, P 3 INT C AUD VID BA, P90
   LILLARD AS, 1993, CHILD DEV, V64, P348, DOI 10.2307/1131255
   Marsella SC, 2004, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON COGNITIVE MODELING, P243
   Meyer A, 2006, LECT NOTES ARTIF INT, V4021, P208
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Stiefelhagen R., 2001, P WORKSH PERC US INT
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Tzouveli P, 2008, P 8 IEEE INT C ADV L
   Tzouveli P, 2008, COMPUT EDUC, V51, P224, DOI 10.1016/j.compedu.2007.05.005
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Voit M, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P347, DOI 10.1109/CRV.2005.55
   Ward R, 2004, INTERACT COMPUT, V16, P879, DOI 10.1016/j.intcom.2004.08.002
   Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 53
TC 94
Z9 113
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2009
VL 41
IS 3
SI SI
BP 469
EP 493
DI 10.1007/s11042-008-0240-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 395EL
UT WOS:000262506300006
DA 2024-07-18
ER

PT J
AU Ding, GG
AF Ding, Guiguang
TI Distributed video coding based on part intracoding and soft side
   information estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed source coding; Video coding; Side information; Intracoding
   mode
AB Recently, distributed source coding (DSC) has been proposed to implement source compression by exploiting source statistics at the decoder only, which enables low-complexity video coding. However, to date, the video codecs based on DSC have been unable to compress as efficiently as traditional predictive video codecs, such as H.264. So, new techniques have to be investigated to improve the performance of the distributed video coding scheme for practical applications. In this paper, I propose a novel distributed video coding scheme based on part intracoding and soft side information estimation. Firstly, at the encoder side, to improve the compression performance of distributed video coding system, we divide the video data into strongly correlative data encoded by Slepian-Wolf codec and weakly correlative data encoded by Intracoding codec. Secondly, at the decoder side, to improve the accuracy of side information estimation, a soft side information estimation method is proposed, which is more suitable for video coding due to the non-stationary feature of video data. Our experimental results show that the performance of our coding system is better than that of the traditional distributed video coding system while keeping the simple encoding property. Also the concept of soft side information is a new idea in distributed video coding and will significantly influence the side information estimation method.
C1 Tsinghua Univ, Sch Software, Minist Educ, Tsinghua Natl Lab Informat Sci & Technol,Key Lab, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Ding, GG (corresponding author), Tsinghua Univ, Sch Software, Minist Educ, Tsinghua Natl Lab Informat Sci & Technol,Key Lab, Beijing 100084, Peoples R China.
EM dinggg@tsinghua.edu.cn
RI Ding, Guiguang/KIL-3528-2024
FU National Natural Science Foundation of China [60502014]
FX The authors acknowledge the support received from the National Natural
   Science Foundation of China (Project 60502014). Useful comments made by
   the anonymous reviewers are acknowledged with gratitude.
CR Aaron A, 2002, CONF REC ASILOMAR C, P240
   Aaron A, 2002, IEEE DATA COMPR CONF, P252, DOI 10.1109/DCC.2002.999963
   AARON A, 2004, IEEE INT C IM PROC S
   Aaron A., 2004, P SPIE VIS COMM IM P
   AARON A, 2006, PICT COD S PCS 2006
   AVUDAINAYAGAM A, 2005, P IEEE GLOB 2005 STL, V3, P1
   Bajcsy J, 2001, GLOB TELECOMM CONF, P1400, DOI 10.1109/GLOCOM.2001.965721
   BAJCSY J, 2002, P BIENN S COMM KINGT
   Cheng S, 2005, IEEE T SIGNAL PROCES, V53, P3269, DOI 10.1109/TSP.2005.851138
   DING GG, 2007, WYNER ZIV VIDEO CODI, P230
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P440, DOI 10.1109/LCOMM.2002.804244
   LIVERIS AD, 2002, P MULT SIGN PROC WOR
   Pradhan SS, 1999, IEEE DATA COMPR CONF, P158, DOI 10.1109/DCC.1999.755665
   PURI R, 2003, P IEEE INT C IM PROC
   SEHGAL A, 2003, P IEEE INT C IM PROC
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   VARODAYAN D, 2005, P AS C SIGN SYST PAC
   WANG X, 2001, P IEEE DAT COMPR C S, P417
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xu Q, 2006, IEEE T IMAGE PROCESS, V15, P3791, DOI 10.1109/TIP.2006.884925
   ZHAO Y, 2001, P ALL C COMM CONTR C
NR 22
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 183
EP 195
DI 10.1007/s11042-008-0224-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500001
DA 2024-07-18
ER

PT J
AU Kim, H
   Yeom, HY
AF Kim, Hyunjoo
   Yeom, Heon Y.
TI P-chaining: a practical VoD service scheme autonomically handling
   interactive operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE streaming; P2P; VoD; VCR operations
AB Providing scalable VoD streaming services has recently become a hot issue, and many approaches have been proposed. Because video streaming services through the Internet are widely used, the need to support VCR operations also increases. However, there are few approaches to supporting VCR operations on the Internet. We propose a service scheme based on chaining, in which clients as well as the server provide streaming services. In the proposed scheme, services are provided by unicast and managed locally using node lists. In addition, our scheme can support frequent VCR operations without incurring significant overhead in the server workload. We have evaluated our scheme through simulation with real traces from a content distribution network (CDN) company and with various parameters. The results show that the proposed scheme reduces server workload significantly. The results also verify that frequent VCR operations can be served smoothly without causing too much overhead.
C1 [Kim, Hyunjoo; Yeom, Heon Y.] Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Kim, H (corresponding author), Seoul Natl Univ, Sch Engn & Comp Sci, San 56-1, Seoul 151742, South Korea.
EM hjkim@dcslab.snu.ac.kr; yeom@dcslab.snu.ac.kr
CR Acharya A., 1996, CSTR3736 U MAR
   [Anonymous], P ACM WWW 04
   Chen JK, 1999, IEEE T BROADCAST, V45, P215, DOI 10.1109/11.796263
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   FOULIRAS P, 2004, ACM S APPL COMP MARC, P14
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Hua KA, 2004, P IEEE, V92, P1439, DOI 10.1109/JPROC.2004.832954
   Jannotti J, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P197
   Kalapriya K, 2005, AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2, P229
   LEE GJ, 2005, P 6 INT C COMP INT M, P272, DOI DOI 10.1109/ICCIMA.2005.42
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   ROCHA M, 2005, P ACM MULT NOV, P966
   Schultz JJ, 2003, PROC ANNU SIMUL SYMP, P31, DOI 10.1109/SIMSYM.2003.1192795
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Su TC, 2005, IEEE T MULTIMEDIA, V7, P972, DOI 10.1109/TMM.2005.854390
   TRAN DA, 2002, P ACM MULT C SIGMM 2, P247
   Yang XD, 2005, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND MECHANICS 2005, VOLS 1 AND 2, P322
NR 17
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2008
VL 39
IS 1
BP 117
EP 142
DI 10.1007/s11042-007-0160-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 311TE
UT WOS:000256622500005
DA 2024-07-18
ER

PT J
AU Wang, ZH
   Ji, XG
   Gao, W
   Huang, QM
   Zhao, DB
AF Wang, Zhihang
   Ji, Xiangyang
   Gao, Wen
   Huang, Qingming
   Zhao, Debin
TI Effective algorithms for fast transcoding of AVS to H.264/AVC in the
   spatial domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AVS; H.264/AVC; transcoding; mode mapping; mode reuse; AVS to H.264/AVC
ID INTEGER-TRANSFORM; MOTION-ESTIMATION; VIDEO; MPEG
AB This paper proposes a transcoding scheme from AVS to H.264/AVC. As high-compression video coding standards, H.264/AVC jointly developed by MPEG and ITU and AVS developed by the Audio Video Coding Standard Working Group of China will co-exist in the future market. Therefore, it is worthy to transcode the AVS format to the H.264/AVC format or vice versa. After an insight into the inter transcoding from AVS to H.264/AVC, a simple and effective method is proposed by reusing the mode and motion vectors to achieve high-efficient and fast transcoding. The problem in reusing the skip mode is studied and an effective method to eliminate the artifacts is proposed. Furthermore, a fast intra transcoding algorithm based on the distribution of the DCT coefficients is proposed to speed up the transcoding process. Detailed experiment results demonstrate that the proposed algorithm can effectively reduce the transcoding complexity.
C1 Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   Peking Univ, Beijing 100871, Peoples R China.
   Chinese Acad Sci, Grad Sch, Res Ctr Digital Media, Beijing, Peoples R China.
   Harbin Inst Technol, Dept Comp Sci, Harbin 150006, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Peking University; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Harbin Institute of Technology
RP Wang, ZH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM zhihangwang@jdl.ac.cn; xyji@jdl.ac.cn; wgao@jdl.ac.cn;
   qmhuang@jdl.ac.cn; dbzhao@jdl.ac.cn
RI Huang, Qingming/GLR-3473-2022; Zhao, Debin/JEP-0204-2023
OI Huang, Qingming/0000-0002-3025-7099; 
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   BIALKOWSKI J, 2006, INT C MULT EXP
   CHEN G, 2004, P 12 ANN ACM INT C M, P300
   Chen MJ, 2002, IEEE T CIRC SYST VID, V12, P269, DOI 10.1109/76.999204
   Eleftheriadis A, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC396
   FERNANDEZESCRIB.G, 2006, INT C MULT EXP, P309
   Fung KT, 2002, IEEE T IMAGE PROCESS, V11, P886, DOI 10.1109/TIP.2002.800890
   HU B, 2005, IEEE PAC RIM C MULT, P830
   *ISO IEC, 2001, 144962 ISO IEC
   *ISO IEC, 2000, 138182 ISOIEC
   *ITUT, 2003, IN PRESS DRAFT TEXT
   JI X, 2004, IEEE INT C MULT EXP, V1, P101
   Ji XY, 2004, IEEE IMAGE PROC, P469
   Kalvi H, 2004, CCNC 2004: 1ST IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, PROCEEDINGS, P657, DOI 10.1109/CCNC.2004.1286946
   KEESMAN G, 1996, IMAGE COMMUN, V8, P481
   Lee JB, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P53, DOI 10.1109/ICME.2006.262548
   Lee YK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P57, DOI 10.1109/ICME.2006.262549
   Liang F., 2004, IEEE INT C MULT EXP, V1, P423
   Lu X, 2005, IEEE INT SYMP CIRC S, P1246
   Ma SW, 2006, J COMPUT SCI TECH-CH, V21, P354, DOI 10.1007/s11390-006-0354-8
   MARPE D, 2005, IEEE INT C IM PROC
   Meng JH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P474, DOI 10.1109/ICIP.1998.723534
   Nakajima Y, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC408
   Panusopone K, 2001, INT CONF ACOUST SPEE, P981, DOI 10.1109/ICASSP.2001.941081
   Roma N, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P125, DOI 10.1109/ICDSP.2002.1027848
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   Shen B, 2004, IEEE IMAGE PROC, P115
   Shen B, 1999, IEEE T CIRC SYST VID, V9, P929, DOI 10.1109/76.785730
   SHEN B, 2006, INT C MULT EXP, P317
   Song J, 1999, IEEE T CIRC SYST VID, V9, P1100, DOI 10.1109/76.795061
   Srinivasan S, 2004, SIGNAL PROCESS-IMAGE, V19, P851, DOI 10.1016/j.image.2004.06.005
   Su YP, 2005, IEEE INT SYMP CIRC S, P1234
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   Wang Q, 2006, J COMPUT SCI TECHNOL, V21, P315, DOI 10.1007/s11390-006-0315-2
   Wang QA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P89, DOI 10.1109/ICME.2004.1394132
   Wang QM, 2004, LETT ORG CHEM, V1, P93, DOI 10.2174/1570178043488770
   Wang XF, 2006, J COMPUT SCI TECH-CH, V21, P310, DOI 10.1007/s11390-006-0310-7
   Wang ZH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P61, DOI 10.1109/ICME.2006.262550
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   XIN J, 2006, INT C MULT EXP, P313
   XIN J, 2004, PAC C MULT PCM, P939
   Yang JY, 2005, PROC SPIE, V5960, P1995, DOI 10.1117/12.633372
   Yin P, 2002, IEEE T CIRC SYST VID, V12, P1009, DOI 10.1109/TCSVT.2002.805509
   Yu L, 2005, P SOC PHOTO-OPT INS, V5960, P679, DOI 10.1117/12.632515
   Zhang CX, 2005, IEEE INT SYMP CIRC S, P316
   Zhou Z, 2005, IEEE INT SYMP CIRC S, P1230
NR 47
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2007
VL 35
IS 2
BP 175
EP 202
DI 10.1007/s11042-007-0121-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 212XA
UT WOS:000249629100005
DA 2024-07-18
ER

PT J
AU Yu, XD
   Xue, P
   Duan, LY
   Tian, Q
AF Yu, Xiaodong
   Xue, Ping
   Duan, Lingyu
   Tian, Qi
TI An algorithm to estimate mean vehicle speed from MPEG Skycam video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG; motion vectors; mean vehicle speed; Skycam
ID MOTION
AB With low computation cost, motion vectors can be readily extracted from MPEG video streams and processed to estimate vehicle motion speed. A statistical model is proposed to model vehicle speed and noise. In order to achieve high estimation accuracy and also study the limitations of the proposed algorithm, we quantitatively evaluated four parameters used in our algorithm: temporal filter window size T, video resolution R-v (CIF/QCIF), motion vector frame distance m, and video bit-rates. Our experiments showed that the mean vehicle speed can be estimated with high accuracy, up to 85 to 92% by proper spatial and temporal processing. The proposed algorithm is especially suitable for Skycam-based application, where the traditional tracking-based or virtual-loop-based approaches perform poorly because of their requirements of high-resolution images. Although extensive work has been done in extracting motion information directly from MPEG video data in compressed domain, to our best knowledge, this paper is the very first work in which stationary motion (speed) of moving objects can be estimated with high accuracy directly from MPEG motion vectors. Furthermore the proposed method is not limited to vehicle speed estimation by nature and it can be applied to other applications where the stationary motion assumption is satisfied.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 119613, Singapore.
C3 Nanyang Technological University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Yu, XD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM exdyu.assoc@ntu.edu.sg; epxue@ntu.edu.sg; lingyu@i2r.a-star.edu.sg;
   tian@i2r.a-star.edu.sg
RI Xue, Ping/A-5155-2011
CR [Anonymous], ACTIVE VISION
   BARTOLINI F, 1993, P 4 INT WORKSH TIM V, P359
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   DIMITROVA N, 1995, ACM T INFORM SYST, V13, P408, DOI 10.1145/211430.211433
   Duda R., 2000, Pattern Classification, P26
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Garcia C, 2002, IMAGE VISION COMPUT, V20, P793, DOI 10.1016/S0262-8856(02)00088-4
   Gonzales CA, 1999, IBM J RES DEV, V43, P453, DOI 10.1147/rd.434.0453
   *ISO IEC, 1993, 111722 ISOIEC
   Jin J. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P32, DOI 10.1109/6979.869019
   Lai A. H. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P86, DOI 10.1109/6979.880965
   Li HZ, 1999, J VISUAL LANG COMPUT, V10, P607, DOI 10.1006/jvlc.1999.0149
   Malik J., 1997, Traffic Surveillance and Detection Technology Development: New Traffic Sensor Technology
   MARIJA J, 1992, SPSS WINDOWS BASE SY, P183
   MENG J, 1996, P ACM MULT BOST MA N, V96, P43
   MICHALOPOULOS PG, 1991, IEEE T VEH TECHNOL, V40, P21, DOI 10.1109/25.69968
   MILANESE R, 1997, P SPIE C MULT STOR A, V2
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   PILU M, 1998, SPIE VISUAL COMMUNIC
   Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934
   Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615, DOI 10.1109/76.611173
   Yeo BL, 1999, MULTIMEDIA SYST, V7, P269, DOI 10.1007/s005300050129
   YOON K, 2000, INT C PATT RECOG, V1, P1819
   Yu XD, 2002, IEEE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P37, DOI 10.1109/ITSC.2002.1041185
NR 24
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2007
VL 34
IS 1
BP 85
EP 105
DI 10.1007/s11042-006-0073-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 169VE
UT WOS:000246619400004
DA 2024-07-18
ER

PT J
AU Dong, YF
   Zhang, ZL
   Du, DHC
AF Dong, Yingfei
   Zhang, Zhi-Li
   Du, David Hung-Chang
TI Full-sharing: efficient bandwidth scheduling for video streaming over
   broadband cable networks (BCNs)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video streaming; broadband cable networks; bandwidth scheduling;
   multimedia networks
ID SCHEME
AB Broadband Cable Networks (BCNs) bring high-speed Internet access to home and make emerging multimedia streaming applications feasible. However, bandwidth contention is still a challenging problem in providing efficient IP-based Video-On-Demand (VOD) service on BCNs, due to the lack of effective approaches to exploit the unique characteristics of BCNs. To address the bandwidth contention issue, we propose an efficient video scheduling technique, called full-sharing scheduling in this paper. This technique fully exploits the unique characteristics of BCNs to reduce the bandwidth consumption of video sessions sharing a cable channel of fixed capacity, thereby maximizing the number of simultaneous video sessions on the single channel. Furthermore, we analyze the expected bandwidth and the session blocking probability of a video under the full-sharing scheduling. Based on this analysis, we design an efficient video assignment mechanism for maximizing the profit of a VOD system in scheduling videos on BCNs. Through both analysis and simulation, we show that our approach minimizes the bandwidth consumption of video sessions compared with the previous approaches and has significant advantages on BCNs. The proposed approach is also directly applicable on other broadcast/multicast networks in which clients have sufficient buffer and downstream bandwidth, e.g., satellite broadband networks.
C1 Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA.
   Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
C3 University of Hawaii System; University of Minnesota System; University
   of Minnesota Twin Cities
RP Dong, YF (corresponding author), Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA.
EM yingfei@hawaii.edu; zhzhang@cs.umn.edu; du@cs.umn.edu
CR Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P118, DOI 10.1109/MMCS.1996.534963
   Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P253, DOI 10.1109/MMCS.1996.534983
   *CABL TEL LAB INC, 2004, DOCSIS OV
   Chan SHG, 2002, IEEE T BROADCAST, V48, P19, DOI 10.1109/11.992850
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   DONG Y, 2003, P IEEE PACK VID 03 N
   DONG Y, 2003, 02028 U MINN DEP COM
   EAGER D, 1998, LECT NOTES COMPUTER, V1058, P18
   EAGER D, 2000, P MMCN 00 SAN JOS CA
   EAGER D, 1999, P 5 INT WORKSH MULT, P21
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   Griwodz C, 2000, PERF E R SI, V27, P20, DOI 10.1145/346000.346006
   GUO Y, 2002, P INT PACK VID WORKS
   HOGAN M, 2001, CABLES BIG DILEMMA M
   HU A, 2001, P INFOCOM 01 ANCH AZ
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua K. A., 1997, Computer Communication Review, V27, P89, DOI 10.1145/263109.263144
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Paris J.-F., 1999, Proceedings Eight International Conference on Computer Communications and Networks (Cat. No.99EX370), P118, DOI 10.1109/ICCCN.1999.805505
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   SAPARILLA D, 1999, P INFOCOM 99 NEW YOR
   SEN S, 2001, IEEE INT PERF COMP C
   SEN S, 1999, P IEEE NOSSDAV 99 BA
   *TIVO INC, TIVO BOX
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Yan EM, 2003, PROC SPIE, V5019, P200, DOI 10.1117/12.483908
   DOCSIS 1 1 RADIO FRE
NR 28
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 131
EP 156
DI 10.1007/s11042-006-0069-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000002
DA 2024-07-18
ER

PT J
AU Cesar, P
   Vierinen, J
   Vuorimaa, P
AF Cesar, P.
   Vierinen, J.
   Vuorimaa, P.
TI Open graphical framework for interactive TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 5th IEEE International Symposium on Multimedia Software Engineeting
CY DEC 10-12, 2003
CL Tai Chung, TAIWAN
SP IEEE Comp Soc, Taichung Healthcare & Management Univ, Natl Tsing Hua Univ, Natl Cent Univ, Bioinformat Soc Taiwan, Univ Calif Irvine
DE digital television; graphics architecture; DVB-MHP; XML
AB Multimedia end-user terminals are expected to perform advanced user interface related tasks. These tasks are carried out by user interface runtime tools and include, among others, the visualization of complex graphics and the efficient handling of user input. In addition, the terminal's graphical system is expected, for example, to be able to synchronize audio and video, and control different contexts on the same screen. Finally, the availability of high-level tools to simplify the user interface implementation and the adaptiveness of the user interfaces for a diversity of configurations are, as well, desirable features. This paper presents a layered model that meets the just mentioned requirements. The architecture is divided into five different layers: hardware abstraction layer, multimedia cross platform libraries, graphical environment, GUI toolkit and high-level languages. Moreover, this paper presents the experiences of developing a prototype system based on the architecture, targeted to digital television receivers. In order to evaluate the prototype, some already developed DVB-MHP compliant digital television applications were tested. Finally, the prototype was extended with a high-level profile (i.e., SMIL support) and a low-level one (i.e., access to the framebuffer memory).
C1 Helsinki Univ Technol, Telecommun Software & Multimedia Lab, FIN-02015 Helsinki, Finland.
   CWI, NL-1090 GB Amsterdam, Netherlands.
C3 Aalto University
RP Cesar, P (corresponding author), Helsinki Univ Technol, Telecommun Software & Multimedia Lab, POB 5400, FIN-02015 Helsinki, Finland.
EM pcesar@tml.hut.fi; jvierine@tml.hut.fi; pv@tml.hut.fi
RI Vierinen, Juha/M-9726-2015; Akalugwu, Kenneth/F-4815-2014; Vuorimaa,
   Petri/G-6303-2011
OI Cesar, Pablo/0000-0003-1752-6837; Vuorimaa, Petri/0009-0007-6198-6650
CR CESAR P, 2002, P 10 INT C CENTR EUR, P1
   DUBINKO M, 2003, XFORMS 1 0 W3C RECOM
   EVANS JP, 1998, EBU TECHNICAL RE SPR, P4
   Goldberg A., 1983, Smalltalk 80: The Language and Its Implementation
   LAMADON JL, 2003, P 7 INT C INT MULT S, P578
   Milenkovic M, 1998, IEEE MULTIMEDIA, V5, P34, DOI 10.1109/93.735867
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   MYERS BA, 1995, ACM T COMPUT-HUM INT, V2, P65
   OLSEN DR, 1998, DEV USER INTERFACES
   Peng C., 2002, THESIS HELSINKI U TE
   PIESING J, 1999, IEEE C INT TEL, V2, P1
   Pihkala K, 2002, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMMUNICATIONS, INTERNET, AND INFORMATION TECHNOLOGY, P48
   Williams C., 2002, LINUX SCHEDULER LATE
NR 13
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2006
VL 30
IS 2
BP 189
EP 203
DI 10.1007/s11042-006-0019-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 082CG
UT WOS:000240363500005
DA 2024-07-18
ER

PT J
AU Andric, A
   Haus, G
AF Andric, Andreja
   Haus, Goffredo
TI Automatic playlist generation based on tracking user's listening habits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE adaptive behavior; listening habits; personal taste; media player;
   playlist
ID MUSIC
AB Algorithms for automatic playlist generation solve the problem of tedious and time consuming manual selection of musical playlists. These algorithms generate playlists according to the user's music preferences of the moment. The user describes his preferences either by manually inputting a couple of example songs, or by defining constraints for the choice of music. The approaches to automatic playlist generation up to now were based on examining the metadata attached to the music pieces. Some of them took also the listening history into account. But anyway, a heavy accent has been put on the metadata, while the listening history, if it was used at all, had a minor role. Missings and errors in metadata frequently appear, especially when the music is acquired from the Internet. When the metadata is missing or wrong, the approaches proposed so far cannot work. Besides, entering constraints for the playlist generation can be a difficult activity. In our approach we ignored the metadata and focused on examining the listening habits. We developed two simple algorithms that track the listening habits and form a listener model-a profile of listening habits. The listener model is then used for automatic playlist generation. We developed a simple media player which tracks the listening habits and generates playlists according to the listener model. We tried the solution with a group of users. The experiment was not a successful one, but it threw some new light on the relationship between the listening habits and playlist generation.
C1 State Univ Milan, Dept Informat & Commun, I-20135 Milan, Italy.
C3 University of Milan
RP Andric, A (corresponding author), State Univ Milan, Dept Informat & Commun, I-20135 Milan, Italy.
EM aandreja@dico.unimi.it; haus@dico.unimi.it
RI Haus, Goffredo/H-1839-2015
OI Haus, Goffredo/0000-0002-3477-4042
CR [Anonymous], 1993, Modern Heuristics Technics for Combinatorial Problems: Tabu Search pp
   [Anonymous], 1998, P 14 C UNC ART INT M
   AUCOUTURIER JJ, 2002, 3 CIRP INT SEM INT C
   Blaukopf K., 1992, MUSICAL LIFE CHANGIN
   Hargreaves D.J., 1997, SOCIAL PSYCHOL MUSIC
   Konecni V., 1982, PSYCHOL MUSIC
   Pauws S., P 2 INT SOC MUS INF, P222
   Peynircioglu ZF, 1998, MEM COGNITION, V26, P1131, DOI 10.3758/BF03201190
   Platt JC, 2002, ADV NEUR IN, V14, P1425
   SINHA R, 2002, P ACM CHI 2002 C HUM
   WANG C, 2002, P 3 INT C MUS INF RE
   WILLIAMS CKI, 1996, NEURAL INFORM PROCES, V8, P514
NR 12
TC 17
Z9 21
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 127
EP 151
DI 10.1007/s11042-006-0003-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300003
DA 2024-07-18
ER

PT J
AU Wang, L
   Khan, L
AF Wang, Lei
   Khan, Latifur
TI Automatic image annotation and retrieval using weighted feature
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Workshop on Multimedia and Web Design
CY DEC 13, 2004
CL Miami, FL
DE automatic image annotation; subspace clustering algorithm
AB The development of technology generates huge amounts of non-textual information, such as images. An efficient image annotation and retrieval system is highly desired. Clustering algorithms make it possible to represent visual features of images with finite symbols. Based on this, many statistical models, which analyze correspondence between visual features and words and discover hidden semantics, have been published. These models improve the annotation and retrieval of large image databases. However, image data usually have a large number of dimensions. Traditional clustering algorithms assign equal weights to these dimensions, and become confounded in the process of dealing with these dimensions. In this paper, we propose weighted feature selection algorithm as a solution to this problem. For a given cluster, we determine relevant features based on histogram analysis and assign greater weight to relevant features as compared to less relevant features. We have implemented various different models to link visual tokens with keywords based on the clustering results of K-means algorithm with weighted feature selection and without feature selection, and evaluated performance using precision, recall and correspondence accuracy using benchmark dataset. The results show that weighted feature selection is better than traditional ones for automatic image annotation and retrieval.
C1 Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Dallas
RP Khan, L (corresponding author), Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
EM leiwang@utdallas.edu; lkhan@utdallas.edu
OI Khan, Latifur/0000-0002-9300-1576; Wu, Weili lily/0000-0001-8747-6340
CR Aggarwal CC, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P61, DOI 10.1145/304181.304188
   [Anonymous], 1999, 1 INT WORKSHOP MULTI
   [Anonymous], IEEE C COMP VIS PATT
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM., 2003, 26 ANN INT ACM SIGIR
   CHENG CH, 1909, P 5 ACM SIGKDD INT C, P84
   Deprettere F., 1988, SVD and Signal Processing
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   FORST CO, 2000, INF RETR, V1, P287
   JEON J, 2003, 26 ANN INT ACM SIGIR
   KANG F, 2004, CIKM 04, P350
   KHAN L, 2002, P 8 INT WORKSH MULT, P56
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Markkula M., 2000, Information Retrieval, V1, P259, DOI 10.1023/A:1009995816485
   NAGESH HS, 1999, THESIS NW U
   PAN JY, 2004, P 2004 IEEE INT C MU
   Prabhakar S, 1998, PROC INT CONF DATA, P94, DOI 10.1109/ICDE.1998.655763
   WANG L, 2004, P ACM MMDB ARL VIRG
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 19
TC 28
Z9 33
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2006
VL 29
IS 1
BP 55
EP 71
DI 10.1007/s11042-006-7813-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 061AH
UT WOS:000238843100004
DA 2024-07-18
ER

PT J
AU Fernando, WAC
AF Fernando, WAC
TI Sudden scene change detection in compressed video using interpolated
   macroblocks in B-frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video indexing; video segmentations; MPEG; video retrieval
ID SELECTION; MPEG-7
AB This paper addresses an important area in video processing, namely compressed domain processing. For video indexing, video scene transition detection is an essential step to segment the video. Current techniques for scene change detection tend to suffer from a major limitation as most of them cannot identify scene transitions in the compressed domain. Since most video is expected to be stored in the compressed domain, scene transition detection in this domain is highly desirable. In this paper an algorithm for video scene change detection is proposed to overcome this limitation. In this scheme, properties of the B-frames are used as it is capable of measuring the correlation between two adjacent reference frames. The results show that this scheme performs better than schemes based on P-frames. Proposed scheme can be directly applied with compressed data with minimum decompression and hence it is computationally efficient and makes real time implementations possible. Results show that video scene transitions can be identified satisfactorily with the proposed scheme.
C1 Brunel Univ, Dept Elect & Comp Engn, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Fernando, WAC (corresponding author), Brunel Univ, Dept Elect & Comp Engn, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
EM Anil.Fernando@brunel.ac.uk
CR [Anonymous], IEEE COMPUT
   *AOE GROUP, 1995, JTC1SC29WG11N0998 IS
   Arman F., 1993, Proceedings ACM Multimedia 93, P267, DOI 10.1145/166266.166297
   Benitez AB, 2000, SIGNAL PROCESS-IMAGE, V16, P235, DOI 10.1016/S0923-5965(00)00030-8
   Campisi P, 1999, PROC SPIE, V3813, P861, DOI 10.1117/12.366844
   DAWOOD AM, 1999, C PUBLICATIONS, V465, P285
   ENSER PGB, 1995, J DOC, V51, P126, DOI 10.1108/eb026946
   FERNANDO WAC, 1999, P INT S CIRC SYST, V4, P520
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   GUPTA A, 1996, SPIE, V2670, P76
   Hunter J, 2000, SIGNAL PROCESS-IMAGE, V16, P271, DOI 10.1016/S0923-5965(00)00027-8
   *ISO IEC, 2000, JTC1SC29WG11N3445 IS
   MENG J, 1995, SPIE, V2419
   SHIN T, 1998, IEEE INT S CIRCUITS, V4, P253
   Sikora T, 1997, IEEE SIGNAL PROC MAG, V14, P82, DOI 10.1109/79.618010
   Toklu C, 2000, PROC SPIE, V3972, P554
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   YEO BL, 1996, THESIS
   YEO BL, 1995, P 2 INT C MULT COMP
   ZHANG HJ, 1994, SPIE S EL IM SCI TEC, V2, P142
NR 21
TC 1
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 301
EP 320
DI 10.1007/s11042-006-7716-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000003
DA 2024-07-18
ER

PT J
AU Yuen, J
   Chan, E
   Lam, KY
AF Yuen, Joe
   Chan, Edward
   Lam, Kam-Yiu
TI A buffered-bandwidth approach for supporting real-time video streaming
   over cellular networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE wireless multimedia; cellular network; bandwidth allocation; admission
   control
ID CALL ADMISSION CONTROL; PERFORMANCE ANALYSIS; RESOURCE-ALLOCATION;
   WIRELESS NETWORKS; RESERVATION; SCHEME; MANAGEMENT
AB In this paper, we Study the admission and bandwidth allocation problems in real-time video streaming in a cellular network. Admission control in a cellular network is a complex issue due to the mobility of the clients, and the additional workload imposed by incoming clients could exceed the network capacity of a cell and seriously degrade the quality of services provided to the resident clients. To minimize the number of forced terminations of real-time video playback, we incorporate the notion of buffered bandwidth in the admission test for handoff client. Using this approach, we can balance the video workload among adjacent cells to minimize the impact of overloading as the result of handoff operations. We also examine techniques to maintain fairness in services especially under overload situations even though the requested videos from various types of clients could generate very different workload. Simulation experiments confirm the effectiveness of our approach compared to widely used schemes.
C1 City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Lam, KY (corresponding author), City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM csjyuen@cityu.edu.hk; csedward@cityu.edu.hk; cskylam@cityu.edu.hk
RI Lam, Kam Yiu/W-3711-2018
OI Lam, Kam-Yiu/0000-0003-0673-3566
CR AGARWAL R, 1999, P IEEE INT C MULT CO
   Ahn CW, 2004, IEEE T VEH TECHNOL, V53, P106, DOI 10.1109/TVT.2003.822000
   Chen H, 2002, IEEE WCNC, P114, DOI 10.1109/WCNC.2002.993474
   CHIU MH, 2003, IEEE J SEL AREA COMM, V18, P510
   Choi S, 2000, WIREL NETW, V6, P289, DOI 10.1023/A:1019154001580
   CHOI S, 1998, P ACM SIGCOMM 98 VAN, P155
   Choi SH, 2002, IEEE T PARALL DISTR, V13, P882, DOI 10.1109/TPDS.2002.1036063
   Chou CT, 2004, IEEE T MOBILE COMPUT, V3, P5, DOI 10.1109/TMC.2004.1261813
   DAVID K, 1997, IEEE ACM T NETWORKIN, V5
   Ei-Kadi M., 2002, IEEE Transactions on Parallel and Distributed Systems, V13, P156, DOI 10.1109/71.983943
   Epstein BM, 2000, IEEE J SEL AREA COMM, V18, P523, DOI 10.1109/49.840209
   HONG D, 1986, IEEE T VEH TECHNOL, V35, P77, DOI 10.1109/T-VT.1986.24076
   Hou JK, 2002, IEEE T PARALL DISTR, V13, P898, DOI 10.1109/TPDS.2002.1036064
   Huang L, 2004, IEEE T VEH TECHNOL, V53, P547, DOI 10.1109/TVT.2003.823290
   Huang Q, 2004, IEEE COMMUN LETT, V8, P195, DOI 10.1109/LCOMM.2004.825731
   Jeon WS, 2001, IEEE T VEH TECHNOL, V50, P59, DOI 10.1109/25.917873
   Kim S, 2004, IEEE T VEH TECHNOL, V53, P835, DOI 10.1109/TVT.2004.825704
   Lee J, 2004, ENGLISH, V53, P1
   Levine DA, 1997, IEEE ACM T NETWORK, V5, P1, DOI 10.1109/90.554717
   Luo XY, 2002, IEEE T WIREL COMMUN, V1, P521, DOI 10.1109/TWC.2002.800550
   Malla A, 2003, IEEE T PARALL DISTR, V14, P63, DOI 10.1109/TPDS.2003.1167371
   Naghshineh M, 1996, IEEE J SEL AREA COMM, V14, P711, DOI 10.1109/49.490422
   OLIVEIRA C, 1998, IEEE J SELECTED AREA, V16
   Perros HG, 1996, IEEE COMMUN MAG, V34, P82, DOI 10.1109/35.544197
   Wang JG, 2003, IEEE T MOBILE COMPUT, V2, P65, DOI 10.1109/TMC.2003.1195152
   Zhang Y, 2001, GLOB TELECOMM CONF, P3628, DOI 10.1109/GLOCOM.2001.966358
NR 26
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 141
EP 155
DI 10.1007/s11042-006-6139-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600003
DA 2024-07-18
ER

PT J
AU Guo, HP
   Georganas, ND
AF Guo, HP
   Georganas, ND
TI Jointly verifying ownership of an image using digital watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital watermarking; cryptography; secret sharing; wavelet transform
ID QUANTIZATION INDEX MODULATION
AB The current image watermarking schemes only involve one key, thus can not resolve the problem of joint ownership. This paper proposes two totally new algorithms that make use of a secret sharing scheme in cryptography to address this problem. The first one applies Shamir's (2,2) threshold scheme to the watermarking algorithm. A watermark, which is a gaussian distributed random vector determined by two keys, is embedded to selected coefficients in all middle bands in the wavelet domain of an image, so that only when the two keys are put together can the ownership be verified. The second algorithm is a modification of the first one. Three random watermarks are embedded to middle bands in the wavelet domain of an image. For the watermark detection, two thresholds are set, so the watermark detector can verify partial ownership as well as full ownership. Experimental results show that both algorithms have the desired properties such as invisibility, reliable detection and robustness against a wide range of imaging processing operations.
C1 Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.
C3 University of Ottawa
RP Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.
EM ghping@mcrlab.uottawa.ca; georganas@mcrlab.uottawa.ca
CR [Anonymous], 1979, COMMUNICATIONS ACM
   Bender W., 1996, IBM SYST J, V35, DOI DOI 10.1147/SJ.353.0313
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   CHENG Q, 2001, P ACM MULT
   COSTA M, 1983, IEEE T INFORMATION T, V29
   Cox I., 2001, Digital Watermarking
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   DUGAD R, 1998, IEEE INT C IM PROC
   EGGERS J, 1999, SIGNAL PROCESS, V81, P239
   FRIDRICH J, 1999, P INT C IM SCI SYST
   GUO H, 2002, P ACM MULT
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu CT, 1998, IEEE T CIRCUITS-II, V45, P1097, DOI 10.1109/82.718818
   JACKSON WA, 1995, LECT NOTES COMPUTER, P183
   LICKS V, 2000, P INT C IM PROC
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Mintzer F, 1998, COMMUN ACM, V41, P56
   PIVA A, 1997, P IEEE INT C IM PROC
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Puate J, 1996, P SPIE PHOT E S
   Stinson D. R., 2018, Cryptography Theory and Practice
   SWANSON MD, 1997, IEEE J SEL AREA COMM, V16, P540
   Voloshynovskiy S, 2000, 10 EUR SIGN PROC C
   WU M, 1999, SPIE PHOTONICS E
   ZHENG YL, 1994, COMPUT J, V37, P199, DOI 10.1093/comjnl/37.3.199
   ZHU W, 1999, IEEE T CIRCUITS SYST, V9
NR 30
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 323
EP 349
DI 10.1007/s11042-005-3812-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300002
DA 2024-07-18
ER

PT J
AU Hermes, T
   Miene, A
   Herzog, O
AF Hermes, T
   Miene, A
   Herzog, O
TI Graphical search for images by <i>PictureFinder</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image retrieval; color matching; similarity search; query by example
ID RETRIEVAL
AB The text searching paradigm still prevails even when users are looking for image data for example in the Internet. Searching for images mostly means searching on basis of annotations that have been made manually. When annotations are left empty, which is usually the case, searches on image file names are performed. This may lead to surprising retrieval results. The graphical search paradigm, searching image data by querying graphically, either with an image or with a sketch, currently seems not to be the preferred method partly because of the complexity in designing the query.
   In this paper we present our PictureFinder system, which currently supports "full image retrieval" in analogy to full text retrieval. PictureFinder allows graphical queries for the image the user has in his mind by sketching colored and/or textured regions or by whole images (query by example). By adjusting the search tolerances for each region and image feature (i.e. hue, saturation, lightness, texture pattern and coverage) the user can tune his query either to find images matching his sketch or images which differing from the specified colors and/or textures to a certain degree. To compare colors we propose a color distance measure that takes into account the fact that different colors spread differently in the color space, and which take into account that the position of a region in an image may be important.
   Furthermore, we show our query by example approach. Based on the example image chosen by the user, a graphical query is generated automatically and presented to the user. One major advantage of this approach is the possibility to change and adjust a query by example in the same way as a query which was sketched by the user. By deleting unimportant regions and by adjusting the tolerances of the remaining regions the user may focus on image details which are important to him.
C1 Univ Bremen, TZI Ctr Comp Technol Digital Media Image Proc, D-28359 Bremen, Germany.
C3 University of Bremen
RP Hermes, T (corresponding author), Univ Bremen, TZI Ctr Comp Technol Digital Media Image Proc, Univ Allee 21-23, D-28359 Bremen, Germany.
EM hermes@tzi.de; andrea@tzi.de; herzog@tzi.de
RI Herzog, Otthein/ABD-1774-2020
OI Herzog, Otthein/0000-0003-4781-2551
CR ALSHUTH P, 1998, IS T SPIE S EL IM SC, V3312, P236
   [Anonymous], IEEE COMPUT
   [Anonymous], INT J DIGITAL LIB
   BARNARD K, 2001, P 1 ACM IEEE CS JOIN, P469
   BERK T, 1982, IEEE COMPUT GRAPH, V2, P37
   BRADSHAW B, 2000, P 8 ACM INT C MULT T, P157
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   CHANG E, 2001, P ACM MULT OCT, P611
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cinque L, 2001, IMAGE VISION COMPUT, V19, P979, DOI 10.1016/S0262-8856(01)00060-9
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Herman CR, 2002, J OROFAC PAIN, V16, P64
   HERMES T, 1995, P 3 SPIE C STOR RETR, P394
   HERMES T, 1999, HDB COMPUTER VISION, V3, P517
   Hofmann T., 1998, P WORKSH LEARN TEXT
   Holmes AS, 2002, IMAGE VISION COMPUT, V20, P331, DOI 10.1016/S0262-8856(02)90005-3
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KOUBAROULIS D, 2000, P 15 ICPR, V3, P379
   KREYSS J, 1997, IS T SPIE S EL IM SC, P236
   Matas J, 2000, LECT NOTES COMPUT SC, V1842, P48
   MELZER B, 2002, P 8 WORKSH FARBB FAR
   Mukherjea S., 1999, World Wide Web, V2, P115, DOI 10.1023/A:1019248722478
   Natsev A, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P395, DOI 10.1145/304181.304217
   Nikolaou N, 2002, ENG APPL ARTIF INTEL, V15, P81, DOI 10.1016/S0952-1976(02)00028-3
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Rubner L. J., 1997, P ARPA IM UND WORKSH, P661
   SKARBEK W, 1994, 9432 TU BERL
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Stevens S., 1994, Interactions, V1, P67, DOI 10.1145/194283.194311
   TANGELDER J, 2002, UUCS2002019
   Wang H., 1998, Proceedings ACM Multimedia 98, P229, DOI 10.1145/290747.290775
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 34
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2005
VL 27
IS 2
BP 229
EP 250
DI 10.1007/s11042-005-2576-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 961OP
UT WOS:000231672000004
DA 2024-07-18
ER

PT J
AU Candan, KS
   Yamuna, P
AF Candan, KS
   Yamuna, P
TI Similarity-based retrieval of temporal specifications and its
   application to the retrieval of multimedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE similarity-based retrieval; temporal information; multimedia retrieval
ID EDITING DISTANCE; FAST ALGORITHMS; MODELS
AB In this paper, we describe a similarity-based retrieval framework for temporal information, such as multimedia presentations. We develop techniques that allow users to query and retrieve multimedia documents, based on their temporal content. For this purpose, we describe different temporal data models and a set of similarity metrics applicable for different retrieval tasks. We develop algorithms that efficiently compute these metrics and report on experiment results. We also develop algorithms that efficiently index temporal structures based on these measures and show that the proposed variant of multi dimensional scaling is efficient and provides high quality retrieval of temporal specifications.
C1 Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
EM candan@asu.edu; prakash.yamuna@asu.edu
CR Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   ADALI S, 1999, SIGMOD 99, P121
   ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 1952, Psychometrika
   [Anonymous], P ACM SIGMOD INT C M
   ASPAVALL B, 1980, SIAM J COMPUT, V9, P827
   Buchanan M. C., 1993, Network and Operating Systems Support for Digital Audio and Video. Third International Workshop Proceedings, P237
   Candan K. S., 2001, Knowledge and Information Systems, V3, P30, DOI 10.1007/PL00011658
   Candan KS, 1998, MULTIMEDIA SYST, V6, P232, DOI 10.1007/s005300050091
   Candan KS, 1998, IEEE T KNOWL DATA EN, V10, P433, DOI 10.1109/69.687977
   Candan KS, 2000, VLDB J, V9, P131, DOI 10.1007/PL00010673
   Candan KS, 2000, DATA KNOWL ENG, V35, P259, DOI 10.1016/S0169-023X(00)00025-2
   CANDAN KS, INT J INTELLIGENT SY
   CANDAN KS, 1998, 4 INT WORKSH MULT IN
   CANDAN KS, 1998, INT J INTELLIGENT SY, V13
   CANDAN KS, IEEE INT C MULT COMP, P279
   CANDAN KS, THESIS U MARYLAND CO
   CANDAN KS, MULTIMEDIA AUTHORING
   CANDAN KS, IN PRESS ACM SPRINGE
   CANDAN KS, 1997, CSTR3746 UMCPCSD
   *CECI MIT, 1992, ATHENAMUSE 2 FUNCT S
   CHAWATHE S, 1999, IN PRESS P 25 INT C
   CLAUDIO S, 1997, CHI 1997, P287
   CLAUDIO S, 1998, UNPUB AAAI 98
   de Lima RM, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P929, DOI 10.1109/MMCS.1999.778613
   DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6
   DELBIMBO A, 1995, IEEE T KNOWL DATA EN, V7, P609, DOI 10.1109/69.404033
   ESCOBARMOLANO ML, 2001, WORKSH MULT INF SYST, P7
   Fagin R, 1998, INT J COMPUT VISION, V30, P219, DOI 10.1023/A:1008023416823
   Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163
   Farach M, 1997, SIAM J COMPUT, V26, P210, DOI 10.1137/S0097539794262422
   Hakkoymaz V, 1997, MULTIMED TOOLS APPL, V4, P171, DOI 10.1023/A:1009666332261
   HAKKOYMAZ V, 1998, IN PRESS ACM MULTIME
   HAMAKAWA R, 1993, ACM MULTIMEDIA 93, P273
   *ISO, 135225 ISO
   *ISO, 1986, 8879 ISO
   *ISO IEC, 10744 ISOIEC
   KIM MY, 1995, ACM MULT C 95
   KIM MY, 1993, RC1927783726 IBM COM
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kruskal JB, 1978, MULTIDIMENSIONAL SCA
   LI L, 1994, J MULTIMEDIA SYSTEMS, V1, P143
   Li WS, 2001, VLDB J, V9, P312, DOI 10.1007/s007780100040
   Li WS, 1998, DATA KNOWL ENG, V27, P139, DOI 10.1016/S0169-023X(97)00058-X
   LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017
   LITTLE TDC, 1993, IEEE T KNOWL DATA EN, V5, P551, DOI 10.1109/69.234768
   LUCCIO F, 1995, INFORM COMPUT, V123, P111, DOI 10.1006/inco.1995.1160
   Mirbel I, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P867, DOI 10.1109/MMCS.1999.778601
   Myers EW, 1986, ALGORITHMICA, V1, P251, DOI 10.1007/BF01840446
   Nestorov S, 1997, PROC INT CONF DATA, P79, DOI 10.1109/ICDE.1997.581741
   Ozsoyoglu G, 1996, PROC INT CONF DATA, P593, DOI 10.1109/ICDE.1996.492210
   PRABHAKARAN B, 1994, ACM MULTIMEDIA SYSTE, V2, P53
   SELKOW SM, 1977, INFORM PROCESS LETT, V6, P184, DOI 10.1016/0020-0190(77)90064-3
   SHASHA D, 1990, J ALGORITHM, V11, P581, DOI 10.1016/0196-6774(90)90011-3
   SONG J, 1995, MODELING TIMED USER
   Song YQ, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P585, DOI 10.1109/MMCS.1999.778550
   SUCIU D, 1998, P 5 INT C FDN DAT OR
   TAI KC, 1979, J ACM, V26, P422, DOI 10.1145/322139.322143
   VANBEEK P, 1989, P 11 INT JOINT C ART, P1291
   VAZIRGIANNIS M, 1997, IEEE INT C MULT COMP
   Vilain M., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P377
   Wirag S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P307, DOI 10.1109/MMCS.1999.778403
   *WORLD WID WEB CON, 1998, EXT MARK LANG 1 0 RE
   *WORLD WID WEB CON, 1998, SYNCHR MULT INT LANG
   YAMAN F, PLAN DATABASES MODEL
   YAMUNA P, 2001, S APPL INT JAN
   YAMUNA P, 2000, INT WORKSH MULT INF
   Zhang C, 1996, CHINESE CHEM LETT, V7, P1
   ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 74
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 143
EP 180
DI 10.1007/s11042-005-2717-5
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800006
DA 2024-07-18
ER

PT J
AU Jha, SK
   Fry, M
AF Jha, SK
   Fry, M
TI Video decompression estimation and playout scheme over the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video playout; multimedia; Internet; Quality of Service
AB This paper examines problems associated with display of live continuous media. Under the assumption that the network cannot guarantee the required bounds on delay and jitter and the operating system scheduling is non-realtime, there is a need to accommodate the delay and jitter in the end systems in order to maintain a desirable Quality of Service (QoS). We propose a method of video playback which requires accurate estimation of display cycle time of video frames and the delay suffered by frames in the packet network. We apply various deterministic forecasting methods used in time series analysis on experimental data collected from video transmission. Suitable methods are recommended for display cycle time and delay estimation.
C1 Univ New S Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
   Univ Sydney, Sydney, NSW 2006, Australia.
C3 University of New South Wales Sydney; University of Sydney
RP Univ New S Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
EM sjha@cse.unsw.edu.au
OI Jha, Sanjay/0000-0002-1844-1520
CR [Anonymous], 1988, ACM SIGCOMM COMPUTER
   [Anonymous], 1981, RFC793 IETF
   BASU S, 1996, P INT C PATT REC, P611
   Bolot J.-C., 1993, Journal of High Speed Networks, V2, P305
   Campbell A., 1996, Protocols for High-Speed Networks V. TC6 WG6.1/6.4 Fifth International Workshop on Protocols for High-Speed Networks (PfHSN '96), P201
   Cen S., 1995, Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, P151
   GALL DL, 1991, COMMUN ACM, V34, P47
   JHA SK, 1996, P IEEE C MULT SYST H
   JHA SK, 1997, P 5 INT WORKSH QUAL, P145
   KOUVELAS I, 1996, P IEEE C GLOB COMM G
   Makridakis S.G., 1983, Forecasting, methods and applications
   MCCANNE S, 1995, P ACM MULT 95 SAN FR, P511
   Moon SB, 1998, MULTIMEDIA SYST, V6, P17, DOI 10.1007/s005300050073
   PANCHA P, 1992, P C COMP COMM IEEE I, V1
   RAMJEE R, 1994, IEEE INFOCOM SER, P680, DOI 10.1109/INFCOM.1994.337672
   ROWE LA, 1992, 3 INT WORKSH NETW OP, P334
   SINGH S, 1996, 996 LATR U SCH COMP
   Yuang MC, 1998, MULTIMED TOOLS APPL, V6, P47, DOI 10.1023/A:1009638628952
NR 18
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 305
EP 321
DI 10.1007/s11042-005-5609-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000006
DA 2024-07-18
ER

PT J
AU Fan, JP
   Zhu, XQ
   Najarian, K
   Wu, LD
AF Fan, JP
   Zhu, XQ
   Najarian, K
   Wu, LD
TI Accessing video contents through key objects over IP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE semantic object extraction; key object; key VOP; scalable coding
ID IMAGE SEGMENTATION; MOVING-OBJECTS; MOTION; EXTRACTION; REGION;
   IMPLEMENTATION; RETRIEVAL; SYSTEM
AB In order to support content-based video database access over the Internet Protocol (IP), achieving the following objectives are important: (i) video query by a representative object (key object) or some statistical characterization of the target contents, (ii) bandwidth-efficient browsing over IP, and (iii) scalable and user-centric video transmission over a heterogeneous and variable-bandwidth network. We present a video object extraction and scalable coding system designed to meet the above objectives. In our system, key objects of meaning to video database users are generated via a human-computer-interaction procedure, and are tracked across frames. Given a key object, an algorithm classifies a subset of its VOPs as key VOPs. This subset forms the basis of a highly bandwidth-efficient base layer for supporting activities such as browsing and refining queries. Over the base layer, a number of enhancement layers can be defined to progressively increase the spatial and temporal resolutions of retrieved video. It is expected that heterogeneous users can subscribe to different numbers of the enhancement layers according to their own conditions, such as access authorization, available connection bandwidth, and quality preference.
C1 Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.
C3 University of North Carolina; University of North Carolina Charlotte;
   Purdue University System; Purdue University; University of North
   Carolina; University of North Carolina Charlotte; Fudan University
RP Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM jfan@uncc.edu; xingquan.zhu@uvm.edu; knajaria@uncc.edu;
   ldwu@srcap.stc.sh.cn
RI Najarian, Kayvan/B-2303-2010; ZOU, Fengcai/ABE-4598-2021
OI ZOU, Fengcai/0000-0002-9613-3734; Zhu, Xingquan/0000-0003-4129-9611
CR ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   Alatan AA, 1998, IEEE T CIRC SYST VID, V8, P802, DOI 10.1109/76.735378
   BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   CASTAGNO R, 1998, IEEE T CIRCUITS SYST, V8, P572
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   Chen JY, 1999, PROC SPIE, V3846, P148, DOI 10.1117/12.368470
   Courtney JD, 1997, PATTERN RECOGN, V30, P607, DOI 10.1016/S0031-3203(96)00107-0
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DELBIMBO A, 1995, IEEE T KNOWL DATA EN, V7, P609, DOI 10.1109/69.404033
   Deng YN, 1998, IEEE T CIRC SYST VID, V8, P616, DOI 10.1109/76.718508
   DUBUISSON MP, 1995, INT J COMPUT VISION, V14, P83, DOI 10.1007/BF01421490
   Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163
   FAN J, 2002, SEEDED IMAGE SEGMENT
   FAN J, 2000, J ELECT IMAGING, V9
   Fan JP, 1997, IEEE T IMAGE PROCESS, V6, P1584, DOI 10.1109/83.641418
   Fan JP, 1997, OPT ENG, V36, P2845, DOI 10.1117/1.601512
   Fan JP, 1996, PATTERN RECOGN LETT, V17, P1101, DOI 10.1016/0167-8655(96)00056-6
   Fan JP, 2000, OPT ENG, V39, P438, DOI 10.1117/1.602382
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   FORSYTH D, 1997, P ICIP SANT BARB US
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   Günsel B, 1998, J ELECTRON IMAGING, V7, P592, DOI 10.1117/1.482613
   GUO J, 1999, SIVOG SMART INTERACT, P13
   HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867
   HOTTER M, 1988, SIGNAL PROCESS, V15, P315, DOI 10.1016/0165-1684(88)90021-7
   HUMRAPUR A, 1997, SPIE P STOR RETR IM, P188
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Ishikawa Y., 1998, P 24 VLDB C
   JAIMES A, 1999, P SPIE STOR RETR IM
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Kwon YM, 1999, DATA KNOWL ENG, V30, P217, DOI 10.1016/S0169-023X(99)00012-9
   LUO H, ACM MULT 99, P265
   Meier T, 1998, IEEE T CIRC SYST VID, V8, P525, DOI 10.1109/76.718500
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   PAL NR, 1989, SIGNAL PROCESS, V16, P97, DOI 10.1016/0165-1684(89)90090-X
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PICARD RW, 1995, MULTIMEDIA SYST, V3, P3, DOI 10.1007/BF01236575
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P237, DOI 10.1109/MMCS.1998.693648
   RUI Y, ACM MULT 99, P67
   Rui Yong, 1996, P 1 INT WORKSH IM DA
   SALEMBIER P, 1994, IEEE T IMAGE PROCESS, V3, P639, DOI 10.1109/83.334980
   SATOH S, 1997, P COMP VIS PATT REC
   SHEIKHOLESLAMI G, ACM MULT 99 BRIST UK, P3
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Vailaya A., 1999, P 1999 SPIE C STORAG, P415
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Wei G, 1999, PATTERN RECOGN LETT, V20, P1313, DOI 10.1016/S0167-8655(99)00100-2
   Xu Y, 1997, IMAGE VISION COMPUT, V15, P47, DOI 10.1016/S0262-8856(96)01105-5
   Yeo BL, 1997, P SOC PHOTO-OPT INS, V3312, P60, DOI 10.1117/12.298470
   YEUNG MM, 1996, P 3 IEEE INT C MULT
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhao DM, 1997, PATTERN RECOGN, V30, P895, DOI 10.1016/S0031-3203(96)00126-4
   ZHONG D, 1996, P SPIE
   [No title captured]
NR 61
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2003
VL 21
IS 1
BP 75
EP 96
DI 10.1023/A:1025086200838
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709HD
UT WOS:000184619000005
DA 2024-07-18
ER

PT J
AU Lee, BS
   Yeo, CK
   Soon, IY
   Lee, KK
   Sun, W
AF Lee, BS
   Yeo, CK
   Soon, IY
   Lee, KK
   Sun, W
TI Design and implementation of a Java-based meeting space over Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE computer supported cooperative work; Java; multimedia application
   collaborative framework
AB This paper describes the implementation of Java Meeting Space (JMS), a generic, extensible framework and environment for developing synchronous collaborative applications. The JMS framework is based on a fully object-oriented replicated architecture where the application instances and management services are all replicated at each site. JMS provides basic CSCW coordination services: session management and dynamic floor control services. As a framework, it provides a set of programming interfaces that allow an application developer to take advantage of coordination services in the runtime environment.
C1 Nanyang Technol Univ, Singapore 2263, Singapore.
C3 Nanyang Technological University
RP Lee, BS (corresponding author), Nanyang Technol Univ, Singapore 2263, Singapore.
RI Yeo, Chai Kiat/A-3683-2011; Lee, Francis BS/G-9323-2014; Soon, Ing
   Yann/A-5173-2011
OI Yeo, Chai Kiat/0000-0002-7618-1472; Lee, Francis BS/0000-0001-7828-7900;
   
CR ABDELWAHAB H, 1997, 5 IEEE COMP SOC WORK
   Begole J., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P55, DOI 10.1145/263407.263509
   Chabert A, 1998, COMMUN ACM, V41, P69, DOI 10.1145/276609.276622
   Dommel HP, 1997, MULTIMEDIA SYST, V5, P23, DOI 10.1007/s005300050040
   GREENBERG S, 1999, COMPUTER SUPPORT COO, P201
   Schooler EM, 1996, MULTIMEDIA SYST, V4, P210, DOI 10.1007/s005300050025
   Shirmohammadi S, 1998, IEEE MULTIMEDIA, V5, P64, DOI 10.1109/93.682527
   WEI S, 1999, IEEE INT WORKSH 99 I
   WEI S, 2000, J ORG COMPUTING ELEC, V10
NR 9
TC 0
Z9 0
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2003
VL 20
IS 2
BP 179
EP 195
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 675WP
UT WOS:000182720800004
DA 2024-07-18
ER

PT J
AU Akbacak, E
AF Akbacak, Enver
TI An efficient and robust supervised video hashing scheme based on a
   timedistributed CNN-BLSTM model and principal component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video hashing; Timedistributed; Spatio-temporal; PCA; Reranking
ID ARTIFICIAL-INTELLIGENCE; BIT SELECTION; FUTURE
AB Efficient and fast content-based video retrieval is an increasing demand and necessity area. Studies that initially ignored the motion type in videos have now begun to be replaced by those considering spatiotemporal features. However, there are two critical issues that all retrieval approaches must provide: speed and efficiency. Deep hashing-based video retrieval methods are the most prominent approaches that offer speed and efficiency. Among them, supervised methods are more efficient than those unsupervised and semisupervised. However, two critical points are missing in most supervised video hashing approaches. First, they did not achieve possible higher scores due to the lack of a reranking mechanism. Second, a bottleneck occurs when the hash layer size is smaller than the number of classes. This reduces the efficiency of hash codes, that is, the retrieval performance. Moreover, the network should be trained from scratch when extracting hash codes of various sizes and when the size of an already running hash code database must be changed, which is time-consuming. This study addresses both drawbacks. A time distributed CNN-LSTM-based supervised hashing framework has been proposed. The proposed method sets the hash layer size to an optimum level without a bottleneck. Training is performed in one go, and PCA is utilized to extract various efficient hash code sizes without sacrificing efficiency. Finally, a feature reranking mechanism has been utilized to improve retrieval efficiency further. Experiments performed on two public benchmark video datasets have shown that the proposed video hashing method is superior to the most recent video hashing methods.
C1 [Akbacak, Enver] Hal Univ, Fac Engn, Dept Comp Engn, Istanbul, Turkiye.
C3 Halic University
RP Akbacak, E (corresponding author), Hal Univ, Fac Engn, Dept Comp Engn, Istanbul, Turkiye.
EM enverakbacak@halic.edu.tr
RI AKBACAK, ENVER/AAA-7122-2021
OI AKBACAK, ENVER/0000-0002-6753-7887
CR Alkadi R, 2019, LECT NOTES COMPUT SC, V11132, P734, DOI 10.1007/978-3-030-11018-5_66
   Anuranji R, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102729
   Baduge SK, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104440
   Barros B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165486
   Bian XM, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5845094
   Cengil E, 2022, INT J IMAG SYST TECH, V32, P26, DOI 10.1002/ima.22659
   Chen HQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093094
   Chen ZX, 2018, IEEE T CIRC SYST VID, V28, P1421, DOI 10.1109/TCSVT.2017.2669095
   Elhoseny M, 2020, CIRC SYST SIGNAL PR, V39, P611, DOI 10.1007/s00034-019-01234-7
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   Helm JM, 2020, CURR REV MUSCULOSKE, V13, P69, DOI 10.1007/s12178-020-09600-8
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jain S, 2022, EVOL INTELL, V15, P609, DOI 10.1007/s12065-020-00536-z
   Jaouedi N, 2020, J KING SAUD UNIV-COM, V32, P447, DOI 10.1016/j.jksuci.2019.09.004
   Jing LL, 2021, IEEE WINT CONF APPL, P1109, DOI [10.1109/WACV48630.2021.00115, 10.1109/ICCSE51940.2021.9569374]
   Joly A, 2011, PROC CVPR IEEE, P873, DOI 10.1109/CVPR.2011.5995709
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Kiziltepe RS, 2023, NEURAL COMPUT APPL, V35, P24513, DOI 10.1007/s00521-021-06322-x
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Li JY, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114490
   Li SY, 2022, IEEE T CIRC SYST VID, V32, P2441, DOI 10.1109/TCSVT.2021.3093258
   Li SY, 2021, PROC CVPR IEEE, P13544, DOI 10.1109/CVPR46437.2021.01334
   Li SY, 2020, IEEE T MULTIMEDIA, V22, P1542, DOI 10.1109/TMM.2019.2946096
   Liang SY, 2020, LECT NOTES COMPUT SC, V11961, P752, DOI 10.1007/978-3-030-37731-1_61
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1209, DOI 10.1109/TMM.2016.2645404
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu HW, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3263195
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5367, DOI 10.1109/TIP.2017.2695895
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Ma C, 2018, NEURAL PROCESS LETT, V47, P877, DOI 10.1007/s11063-018-9812-x
   Minh D, 2022, ARTIF INTELL REV, V55, P3503, DOI 10.1007/s10462-021-10088-y
   Montaha S, 2022, IEEE ACCESS, V10, P60039, DOI 10.1109/ACCESS.2022.3179577
   Nguyen Long D., 2023, Journal of Ambient Intelligence and Humanized Computing, P15455, DOI 10.1007/s12652-019-01276-4
   Nie XS, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107467
   Noh SH, 2021, INFORMATION, V12, DOI 10.3390/info12110442
   Ogawa T, 2018, IEEE ACCESS, V6, P61401, DOI 10.1109/ACCESS.2018.2876710
   Patel MFS, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P279, DOI 10.1109/ICIMIA.2017.7975619
   Qiao SS, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107754
   Qiao SS, 2020, IEEE T IMAGE PROCESS, V29, P1299, DOI 10.1109/TIP.2019.2940683
   Saad W, 2022, J AMB INTEL HUM COMP, V13, P2025, DOI 10.1007/s12652-021-02967-7
   Saeed N, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3178155
   Salim MZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010136
   Schwalbe N, 2020, LANCET, V395, P1579, DOI 10.1016/S0140-6736(20)30226-9
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen L, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8229-7
   Singh A, 2022, KNOWL INF SYST, V64, P2565, DOI 10.1007/s10115-022-01734-0
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Soomro K., 2012, CoRR, V2
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Tang ZJ, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103209
   Tian L, 2017, MULTIMED TOOLS APPL, V76, P13271, DOI 10.1007/s11042-016-3708-4
   Togaçar M, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107459
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang Y, 2023, Contrastive masked autoencoders for self-supervised video hashing, DOI [10.1609/aaai.v37i3.25373, DOI 10.1609/AAAI.V37I3.25373]
   Wang YX, 2021, IEEE T COGN DEV SYST, V13, P491, DOI 10.1109/TCDS.2019.2963339
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Wu KX, 2023, IEEE ACCESS, V11, P47956, DOI 10.1109/ACCESS.2023.3276321
   Xing YJ, 2019, IEEE IMAGE PROC, P1410, DOI 10.1109/icip.2019.8803757
   Yan HY, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106782
   Yao X, 2023, IEEE T MULTIMEDIA, V25, P6678, DOI 10.1109/TMM.2022.3213476
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yuxiang Xie, 2021, 2021 7th International Conference on Big Data and Information Analytics (BigDIA), P261, DOI 10.1109/BigDIA53151.2021.9619706
   Zhang CY, 2019, PATTERN RECOGN LETT, V123, P82, DOI 10.1016/j.patrec.2019.03.015
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
NR 73
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17810-8
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200002
DA 2024-07-18
ER

PT J
AU Eragi, SM
   Bensaid, F
   Alimi, AM
AF Eragi, Saddam M.
   Bensaid, Fatma
   Alimi, Adel M.
TI Efficient human face recognition in real-life applications using the
   discrete wavelet transformation (HFRDWT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human face recognition; Discrete Wavelet Transformation; Approximation
   coefficient; Convolutional Neural Network; Face recognition time
ID DEEP; CASCADE; DWT
AB Human Face receives major attention and acquires most of the efforts of the research and studies of Machine Learning in detection and recognition. In real-life applications, the problem of quick and rapid recognition of the Human Face is always challenging researchers to come out with powerful and reliable techniques. In this paper, we proposed a new human face recognition system using the Discrete Wavelet Transformation named HFRDWT. The proposed system showed that the use of Wavelet Transformation along with the Convolutional Neural Network to represent the features of an image had significantly reduced the face recognition time, which makes it useful in real-life areas, especially in public and crowded places. The Approximation coefficient of the Discrete Wavelet Transformation played the dominant role in our system by reducing the raw image resolution to a quarter while maintaining the high level of accuracy rate that the raw image had. Results on ORL, Japanese Female Facial Expression, extended Cohn-Kanade, Labeled Faces in the Wild datasets, and our new Sudanese Labeled Faces in the Wild dataset showed that our system obtained the least recognition timing (average of 24 milliseconds for training and 8 milliseconds for testing) and acceptable high recognition rate (average of 98%) compared to the other systems.
C1 [Eragi, Saddam M.] Sudan Univ Sci & Technol, Coll Comp Sci & Informat Technol, Khartoum, Sudan.
   [Bensaid, Fatma; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, Res Grp Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University of Johannesburg
RP Eragi, SM (corresponding author), Sudan Univ Sci & Technol, Coll Comp Sci & Informat Technol, Khartoum, Sudan.
EM saddam.m.eragi@regim.usf.tn; fatma.bensaid@enis.usf.tn;
   adel.alimi@regim.usf.tn
FU Tunisian Ministry of Higher Education and Scientific Research; 
   [LR11ES48]
FX The research leading to these results has received funding from the
   Tunisian Ministry of Higher Education and Scientific Research under
   grant agreement number LR11ES48. Appreciation sound also goes to Mrs.
   Rawaa Wadie, without her help SuLFiW faces dataset would not see the
   light.
CR Abid A, 2019, PR MACH LEARN RES, V97
   Adjabi I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030728
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   [Anonymous], 2021, arXiv
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Arya K. V., 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P645, DOI 10.1007/978-981-13-1135-2_49
   Aslam W, 2016, INT J ADV COMPUT SC, V7, P294
   Ben Fredj H, 2021, VISUAL COMPUT, V37, P217, DOI 10.1007/s00371-020-01794-9
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Choudhary Pushpa, 2021, Advances in Computational Intelligence and Communication Technology. Proceedings of CICT 2019. Advances in Intelligent Systems and Computing (AISC 1086), P549, DOI 10.1007/978-981-15-1275-9_45
   Cuculo V, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010146
   Dashtdar M., 2019, J Electr Comput Eng, V3, P30
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deokar SA, 2014, INT J ELEC POWER, V61, P594, DOI 10.1016/j.ijepes.2014.04.015
   Divya A, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P150, DOI [10.1109/icispc.2019.8935675, 10.1109/ICISPC.2019.8935675]
   Dumitrescu CM, 2019, I C CONTR SYS COMP S, P216, DOI 10.1109/CSCS.2019.00043
   Ghazal MT., 2020, TELKOMNIKA Indones. J. Electr. Eng, V18, P733, DOI [10.12928/telkomnika.v18i2.14106, DOI 10.12928/TELKOMNIKA.V18I2.14106]
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   Hosseini-Fard E, 2022, J PETROL SCI ENG, V209, DOI 10.1016/j.petrol.2021.109971
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Jarraya I, 2023, MULTIMED TOOLS APPL, V82, P91, DOI 10.1007/s11042-022-12610-y
   Karolin M, 2022, P INT C PAR COMM COM, P735
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Khalajzadeh H, 2013, INT J COMPUT INTELL, V12, DOI 10.1142/S1469026813500181
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Kherif F., 2020, Machine Learning: Methods and Applications to Brain Disorders, P209, DOI DOI 10.1016/B978-0-12-815739-8.00012-2
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Lahaw ZB, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P413
   Lal PV, 2022, J Theor Appl Inf Technol, V100
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114, DOI 10.1109/72.554196
   Liu X, 2017, FRONT COMPUT SCI-CHI, V11, P208, DOI 10.1007/s11704-016-6076-3
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mady H, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMPUTING AND ELECTRONIC ENTERPRISE (ICSCEE)
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Melaugh R, 2019, INT SYMP IMAGE SIG, P193, DOI 10.1109/ISPA.2019.8868630
   Mulyono I.U.W., 2019, 2019 INT SEM APPL TE, P1
   Nath S, 2021, SIGNAL IMAGE VIDEO P, V15, P1601, DOI 10.1007/s11760-021-01895-5
   Palma TA, 2021, BASIC APPL SOC PSYCH, V43, P90, DOI 10.1080/01973533.2020.1843462
   Pei Z, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101088
   Peng CL, 2019, IEEE T IMAGE PROCESS, V28, P4553, DOI 10.1109/TIP.2019.2912360
   Qusay AK, 2020, Journal of Physics: Conference Series, V1530
   Ranjan R, 2018, IEEE SIGNAL PROC MAG, V35, P66, DOI 10.1109/MSP.2017.2764116
   Raveendra K., 2021, Int. J. Comput. Netw. Inf. Secur., V13, P47
   Sam Yin Yee, 2020, Advances in Electronics Engineering. Proceedings of the ICCEE 2019. Lecture Notes in Electrical Engineering (LNEE 619), P315, DOI 10.1007/978-981-15-1289-6_29
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Senthilkumar R, 2020, J SUPERCOMPUT, V76, P4476, DOI 10.1007/s11227-018-2408-4
   Sun JD, 2020, IEEE ACCESS, V8, P35777, DOI 10.1109/ACCESS.2020.2975312
   Sun Y, 2015, Arxiv, DOI arXiv:1502.00873
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Tenllado C., 2004, High Performance Computing for Computational Science - VECPAR 2004. 6th International Conference. Revised Selected and Invited Papers (Lecture Notes in Computer Science Vol.3402), P556
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang R, 2019, PATTERN RECOGN LETT, V127, P11, DOI 10.1016/j.patrec.2018.11.001
   Wood E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3661, DOI 10.1109/ICCV48922.2021.00366
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Xu BR, 2019, IEEE T NEUR NET LEAR, V30, P151, DOI 10.1109/TNNLS.2018.2836933
   Yaman MA, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110651
   Zeng D, 2019, PATTERN RECOGN LETT, V119, P180, DOI 10.1016/j.patrec.2018.05.024
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang YH, 2018, IET IMAGE PROCESS, V12, P819, DOI 10.1049/iet-ipr.2017.1085
NR 66
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17232-6
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Singh, H
   Sinha, A
AF Singh, Harikesh
   Sinha, Amit
TI A Blockchain Framework for E-Voting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Voting; Framework; Blocks; Decentralized; EVM
AB An electronic democratic framework can also fulfill all the rules and regulations of any governing body. The election is one of the important events for a robust democratic system in a country, but still, many people are not thinking of it as major concern for democracy. There are several issues of vote fraud, hacking of EVM (Electronic Voting Machine), election manipulation, and booth capturing within the current electoral system. In this paper, we proposed a framework for E-voting (Electronic Voting) which might resolve these issues. This framework uses Blockchain technology as a service along with an E-Voting system that addresses all restrictions. Blockchain advancements proposed a wide scope of different applications to reduce the sharing of monetary economies. The proposed framework uses proof of voter's identity (PoVI) consensus algorithm that makes the proposed system more secure and differentiates this model from other models of E-voting systems. The objective of this paper is to clarify the utilization of Blockchain innovation as assistance for an authentic electronic democratic framework. The proposed framework evaluates the capability of distributed record advances with the assistance of illustrative contextual analysis, specifically the cycle of a political decision that improves security and minimizes the expense of facilitating a cross-country casting a ballot framework.
C1 [Singh, Harikesh] JSS Acad Tech Educ, Noida, UP, India.
   [Sinha, Amit] ABES Engn Coll, Ghaziabad, UP, India.
RP Singh, H (corresponding author), JSS Acad Tech Educ, Noida, UP, India.
EM harikeshsingh@yahoo.co.in; amit.sinha@abes.ac.in
RI Singh, Harikesh/ABB-9826-2020
OI Singh, Harikesh/0000-0003-2203-0828
CR Adida Ben, 2008, USENIX SECURITY S, V17, P335
   Alvi Syada Tasmia, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P228, DOI 10.1109/ICSSIT48917.2020.9214250
   Bell Susan, 2013, 2013 EL VOT TECHN WO
   Chaithra S., 2020, Int Res J Eng Technol (IRJET), V7, P323
   Chaum D, 2005, LECT NOTES COMPUT SC, V3679, P118
   Chaum D, 2008, IEEE SECUR PRIV, V6, P40, DOI 10.1109/MSP.2008.70
   Dagher GG, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P96, DOI 10.5220/0006609700960107
   Ge L., 2022, Security Comm Net, V2022, P1
   Hardwick FS, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1561, DOI 10.1109/Cybermatics_2018.2018.00262
   Jafar U, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175874
   Khader D., 2012, LECT NOTES INFORMAT, V205, P285
   Khan KM, 2018, INT J ELECTRON GOV R, V14, P53, DOI 10.4018/IJEGR.2018010103
   Li KJ, 2020, FRONT BLOCKCHAIN, V3, DOI 10.3389/fbloc.2020.00011
   Li WC, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25091320
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Malsa N, 2022, INT C ADV COMMUNICAT, P682
   Mohammedali Noor, 2019, International Journal of Computer Science & Information Technology, V11, P13, DOI 10.5121/ijcsit.2019.11502
   Pandey A, 2019, 2019 GLOB C ADV TECH, P1
   Pathak S, 2022, ADV COMPUTING INTELL, P369
   Prasetyadi GC, 2020, INT J ADV COMPUT SC, V11, P164
   Rawat SS, 2023, Computers, Materials & Continua, V76
   Sahni U, 2022, INT C ADV COMMUNICAT, P431
   Sekar S., 2020, Int Res J Eng Technology (IRJET), V7, P312
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Yi HB, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1473-6
   Zheng WeiC C., 2018, Int J Informatics Visualization, V2, P336, DOI DOI 10.30630/JOIV.2.4-2.174
NR 27
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17837-x
EA DEC 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ3E1
UT WOS:001131620700002
DA 2024-07-18
ER

PT J
AU Alarab, I
   Prakoonwit, S
AF Alarab, Ismail
   Prakoonwit, Simant
TI Robust recurrent graph convolutional network approach based sequential
   prediction of illicit transactions in cryptocurrencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Graph neural network; Long short-term memory; Bitcoin blockchain;
   Anti-money laundering
AB Money laundering has urged the need for machine learning algorithms for combating illicit services in the blockchain of cryptocurrencies due to its increasing complexity. Recent studies have revealed promising results using supervised learning methods in classifying illicit Bitcoin transactions of Elliptic data, one of the largest labelled data of Bitcoin transaction graphs. Nonetheless, all learning algorithms have failed to capture the dark market shutdown event that occurred in this data using its original features. This paper proposes a novel method named recurrent graph neural network model that extracts the temporal and graph topology of Bitcoin data to perform node classification as licit/illicit transactions. The proposed model performs sequential predictions that rely on recent labelled transactions designated by antecedent neighbouring features. Our main finding is that the proposed model against various models on Elliptic data has achieved state-of-the-art with accuracy and f(1)-score of 98.99% and 91.75%, respectively. Moreover, we visualise a snapshot of a Bitcoin transaction graph of Elliptic data to perform a case study using a backward reasoning process. The latter highlights the effectiveness of the proposed model from the explainability perspective. Sequential prediction leverages the dynamicity of the graph network in Elliptic data.
C1 [Alarab, Ismail; Prakoonwit, Simant] Bournemouth Univ, Creat Technol, Talbot Campus, Poole, England.
C3 Bournemouth University
RP Alarab, I (corresponding author), Bournemouth Univ, Creat Technol, Talbot Campus, Poole, England.
EM ialarab@bournemouth.ac.uk; sprakoonwit@bournemouth.ac.uk
RI Alarab, Ismail/AAU-1011-2021
OI Alarab, Ismail/0000-0001-8320-6423
CR Alarab I, 2020, P 2020 5 INT C MACHI, P23, DOI DOI 10.1145/3409073.3409080
   Alarab I, 2020, P 2020 5 INT C MACH, P11, DOI DOI 10.1145/3409073.3409078
   Alarab I, 2021, Neural Process Lett, P1
   Alarab I, 2021, NEURAL PROCESS LETT, V53, P1001, DOI 10.1007/s11063-021-10424-x
   Baumann Annika, 2014, 10th International Conference on Web Information Systems and Technologies (WEBIST 2014). Proceedings, P369
   Brenig C, 2015, ECIS 2015 Completed Research Papers, V20
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Di Battista G, 2015, IEEE SYM VIS CYB SEC
   Eloul S, 2021, 37TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2021, P761, DOI 10.1145/3485832.3485913
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, DOI 10.48550/ARXIV.1903.02428]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Harlev MA, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P3497
   Liu XF, 2021, IEEE ACCESS, V9, P37229, DOI 10.1109/ACCESS.2021.3062652
   Meiklejohn S., 2013, P 2013 C INT MEAS C, P127, DOI 10.1145/2504730.2504747.10.1145
   Morris C, 2019, AAAI CONF ARTIF INTE, P4602
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nicholls J, 2021, IEEE ACCESS, V9, P163965, DOI 10.1109/ACCESS.2021.3134076
   Ober M, 2013, FUTURE INTERNET, V5, P237, DOI 10.3390/fi5020237
   Oliveira C, 2021, Arxiv, DOI arXiv:2102.05373
   Pareja A, 2020, AAAI CONF ARTIF INTE, V34, P5363
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pham T, 2017, Arxiv, DOI arXiv:1611.03942
   Reid F., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1318, DOI 10.1109/PASSAT/SocialCom.2011.79
   Ron D., 2013, P INT C FIN CRYPT DA, P6
   Sheu GY, 2022, J MONEY LAUND CONTRO, V25, P594, DOI 10.1108/JMLC-07-2021-0076
   Spagnuolo M, 2014, LECT NOTES COMPUT SC, V8437, P457, DOI 10.1007/978-3-662-45472-5_29
   Vassallo Dylan, 2021, SN Comput. Sci, V2, P1, DOI DOI 10.1007/S42979-021-00558-Z
   Weber Mark, 2019, Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics
   Xia PF, 2022, ARAB J SCI ENG, V47, P1921, DOI 10.1007/s13369-021-06116-2
   Xu K., 2018, arXiv, DOI DOI 10.48550/ARXIV.1810.00826
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
AR s11042-023-17323-4
DI 10.1007/s11042-023-17323-4
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Sheng, B
   Chen, XH
   Zhang, YX
   Tao, J
   Sun, YL
AF Sheng, Bo
   Chen, Xiaohui
   Zhang, Yanxin
   Tao, Jing
   Sun, Yueli
TI Structural topic model-based comparative review of human pose estimation
   research in the United States and China
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Human pose estimation; Structural topic model; Comparative review; Deep
   learning; Computer vision
AB Human pose estimation, a key area in computer vision, benefits various fields. The comparative study of research approaches in the United States and China, both leaders in this domain, is vital for understanding and influencing global trends in this technology. This review collected 191 influential papers from 2014 to 2022, sourced from Google Scholar. The Structural Topic Model (STM) was utilized to analyze research content, preferences, and trends in research topics. Specifically, 10 topics were summarized, and topic proportions, preferences, intensities, and word clouds were displayed via visualization methods. The findings revealed: 1) research on feature extraction and depth image constituted the largest proportion, approximately 12.2%, while data training research accounted for the lowest proportion, around 7.9%; 2) the United States and China exhibited distinct research preferences: the United States focused more on model and data research, while China emphasized deep learning and neural networks; 3) both countries exhibited similar research trends within the same topics, and research on deep learning technologies has experienced a slowdown in recent years. By comparative study, this review offers valuable insights and guidance for future investigations and applications in human pose estimation, such as improving the quality and diversity of data sets.
C1 [Sheng, Bo; Chen, Xiaohui; Tao, Jing] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai 200444, Peoples R China.
   [Sheng, Bo] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 99 Shangda Rd, Shanghai, Peoples R China.
   [Zhang, Yanxin] Univ Auckland, Dept Exercise Sci, 4703906 Newmarket, Auckland, New Zealand.
   [Sun, Yueli] Shanghai Univ TCM, Longhua Hosp, 725 South Wanping Rd, Shanghai 200032, Peoples R China.
C3 Shanghai University; Shanghai University; University of Auckland;
   Shanghai University of Traditional Chinese Medicine
RP Tao, J (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai 200444, Peoples R China.; Sun, YL (corresponding author), Shanghai Univ TCM, Longhua Hosp, 725 South Wanping Rd, Shanghai 200032, Peoples R China.
EM taojing1016@shu.edu.cn; Yueli_sun@foxmail.com
RI chen, xiaohui/AAX-2600-2021
OI chen, xiaohui/0000-0001-7672-0432
FU National Natural Science Foundation of China [21PJ1404000]; Shanghai
   Pujiang Program [62103252]; National Natural Science Foundation of China
   [22Q003]; Shanghai Sports Science and Technology's "National Fitness
   Plan" project [22QC1401300]; Shanghai Tech Rising Stars Program
FX This research was supported by the Shanghai Pujiang Program under Grant
   21PJ1404000, the National Natural Science Foundation of China under
   Grant 62103252, the Shanghai Sports Science and Technology's "National
   Fitness Plan" project(22Q003), and the Shanghai Tech Rising Stars
   Program(22QC1401300). The authors would like to thank Jennifer (Yujiao)
   Qiao for the English improvement.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2014, Adv Neural Inf Process Syst
   [Anonymous], Google Fit
   Artacho B, 2020, PROC CVPR IEEE, P7033, DOI 10.1109/CVPR42600.2020.00706
   Bai XW, 2021, TRANSPORT POLICY, V102, P11, DOI 10.1016/j.tranpol.2020.12.013
   Baziyad H, 2020, P C 4 INT C EL COMP
   Baziyad H, 2019, J Biostat Epidemiol
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cai Y., 2020, COMPUTER VISION ECCV, P455
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen H, 2022, Multimed Syst, P1
   Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58
   Chen XJ, 2015, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2015.7299020
   Chen X, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103855
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Choi H, 2022, APPL ENERG, V313, DOI 10.1016/j.apenergy.2022.118898
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   COCO, COCO Keypoints Challenge
   Colyer SL, 2018, SPORTS MED-OPEN, V4, DOI 10.1186/s40798-018-0139-y
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Drover D, 2019, LECT NOTES COMPUT SC, V11132, P78, DOI 10.1007/978-3-030-11018-5_7
   Dubey S, 2023, MULTIMEDIA SYST, V29, P167, DOI 10.1007/s00530-022-00980-0
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodrick D., 2014, COMP CASE STUDIES ME
   Guangqing T., 2022, Mod Intell, V42, P58
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Habibie I, 2019, PROC CVPR IEEE, P10897, DOI 10.1109/CVPR.2019.01116
   Haifeng L., 2020, Intell Mag, V39, P9
   Hang YAN., 2021, Comput Eng, V47, P12
   Hanyue Tu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P197, DOI 10.1007/978-3-030-58452-8_12
   He Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P541, DOI 10.1007/978-3-030-58580-8_32
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He YS, 2021, PROC CVPR IEEE, P3002, DOI 10.1109/CVPR46437.2021.00302
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Hosseini S, 2021, SCIENTOMETRICS, V126, P2667, DOI 10.1007/s11192-020-03840-8
   Huang FY, 2020, IEEE WINT CONF APPL, P418, DOI [10.1109/wacv45572.2020.9093526, 10.1109/WACV45572.2020.9093526]
   Huang XF, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9666956
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   L. Calorie Technology Co. Keep, ABOUT US
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li Wenhao, 2022, IEEE Trans. Multimed.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lingteng Qiu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P488, DOI 10.1007/978-3-030-58529-7_29
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, DOI 10.48550/ARXIV.1906.08172]
   Luo ZX, 2021, Arxiv, DOI arXiv:2107.10477
   Luo ZX, 2021, PROC CVPR IEEE, P13259, DOI 10.1109/CVPR46437.2021.01306
   Mao WA, 2022, LECT NOTES COMPUT SC, V13666, P72, DOI 10.1007/978-3-031-20068-7_5
   Mao Weian, 2021, arXiv, DOI DOI 10.48550/ARXIV.2103.15320
   Munea TL, 2020, IEEE ACCESS, V8, P133330, DOI 10.1109/ACCESS.2020.3010248
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pourhatami A, 2021, SCIENTOMETRICS, V126, P6625, DOI 10.1007/s11192-021-04038-2
   Qi CR, 2017, ADV NEUR IN, V30
   Reddy ND, 2021, PROC CVPR IEEE, P15185, DOI 10.1109/CVPR46437.2021.01494
   Rempe D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11468, DOI 10.1109/ICCV48922.2021.01129
   Roberts ME, 2019, J STAT SOFTW, V91, P1, DOI 10.18637/jss.v091.i02
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Stanford Institute for Human-Centered Artificial Intelligence, Artificial Intelligence Index Report 2022
   Stenum J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217315
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tan MX, 2019, PR MACH LEARN RES, V97
   The State Council of China, Development Plan for New Generation Artificial Intelligence
   The White House Office of Science and Technology Policy, The National Artificial Intelligence Research and Development Strategic Plan: 2019 Update
   Tome D, 2019, IEEE I CONF COMP VIS, P7727, DOI 10.1109/ICCV.2019.00782
   Tompson J, 2014, ADV NEUR IN, V27
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tremblay J, 2018, Arxiv, DOI arXiv:1809.10790
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang R, 2022, NEURAL PROCESS LETT, V54, P3941, DOI 10.1007/s11063-022-10794-w
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wenjun Z., 2018, Comput Syst Appl, V27, P109
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xuemei C, 2018, Action Evaluation System Based on 3D Human Pose
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Yen-Chen L, 2021, IEEE INT C INT ROBOT, P1323, DOI 10.1109/IROS51168.2021.9636708
   Yong L., 2021, Comput Eng, V47, P16
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Zeng W, 2020, PROC CVPR IEEE, P7052, DOI 10.1109/CVPR42600.2020.00708
   Zhang F, 2021, arXiv
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang YF, 2023, IEEE T PATTERN ANAL, V45, P2613, DOI 10.1109/TPAMI.2022.3163709
   Zhang Z, 2020, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR42600.2020.00227
   Zhao L, 2021, IEEE T IMAGE PROCESS, V30, P6785, DOI 10.1109/TIP.2021.3097836
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zheng C, 2022, Arxiv, DOI [arXiv:2012.13392, DOI 10.48550/ARXIV.2012.13392]
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zou ZM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11457, DOI 10.1109/ICCV48922.2021.01128
NR 111
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17923-0
EA DEC 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000010
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhou, XD
   Wang, K
   Wang, N
   Li, ZH
AF Zhang, Yan
   Zhou, Xudong
   Wang, Ke
   Wang, Nian
   Li, Zenghui
TI A multi-scale hierarchical node graph neural network for few-shot
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Few-shot learning; Graph neural network; Multi-scale hierarchical node;
   Block alignment; Aggregation module
AB The graph neural network model has shown strong classification performance in few-shot learning (FSL) tasks in recent years. However, the existing methods have mainly participated in model training by extracting the single features of the samples as nodes. This method of constructing nodes ignores the multi-scale information contained in the samples to a certain extent and limits the expressiveness of node features. Therefore, we propose a multi-scale hierarchical node graph neural network (MsHN-GNN), which constructs hierarchical nodes bearing multi-scale information by deeply extracting structural features, global features, and local features of samples and enhances the representation ability of node features. At the same time, MsHN-GNN sorts the hierarchical relationship among sub-nodes through the block alignment module so that sub-nodes correspond one-to-one according to their own content attributes, which lays a foundation for updating multi-scale hierarchical nodes. In addition, we design a unique graph network update method according to the characteristics of hierarchical nodes. Through the multi-scale hierarchical node aggregation and edge aggregation modules, we realize the hierarchical information interaction among multiple sub-nodes so that the updated nodes and edge features have stronger information expression ability. Finally, to verify the effectiveness of the model, we conduct extensive experiments on miniImageNet, TiredImageNet, and CUB-200-2011 datasets. The experimental results show that MsHN-GNN outperforms other advanced few-shot learning methods with a graph structure in classification performance. In the above three datasets, the 5-way 1-shot experimental results achieved 68.32%, 72.56%, and 76.21%, respectively.
C1 [Zhang, Yan; Zhou, Xudong; Wang, Nian; Li, Zenghui] Anhui Univ, Sch Elect & Informat Engn, Hefei 230001, Anhui, Peoples R China.
   [Wang, Ke] Anhui Univ, Sch Internet, Hefei 230001, Anhui, Peoples R China.
C3 Anhui University; Anhui University
RP Wang, N (corresponding author), Anhui Univ, Sch Elect & Informat Engn, Hefei 230001, Anhui, Peoples R China.
EM zhangyan@ahu.edu.cn; P23101001@stu.ahu.edu.cn; wangke4747@126.com;
   wn_xlb@ahu.edu.cn; p21201077@stu.ahu.edu.cn
RI li, zenghui/GPX-9431-2022
FU Anhui Provincial Key Research and Development Plan [2022k07020006,
   K120636001]; Anhui Province Key Research and Development Program
   [GXXT-2022-038]; University Synergy Innovation Program of Anhui Province
FX This work was supported by Anhui Province Key Research and Development
   Program (2022k07020006), the central government guides local funds of
   Anhui provincial in 2021 (K120636001) and the University Synergy
   Innovation Program of Anhui Province(GXXT-2022-038).
CR Al-Sabri R, 2023, IEEE ACM T COMPUT BI, V20, P1221, DOI 10.1109/TCBB.2022.3205113
   Cen Chen, 2022, IEEE Transactions on Circuits and Systems for Video Technology, V32, P240, DOI 10.1109/TCSVT.2021.3058098
   Di ZC, 2022, PROC SPIE, V12083, DOI 10.1117/12.2623385
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Finn C, 2017, PR MACH LEARN RES, V70
   Gan Tao, 2021, 2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP), P234, DOI 10.1109/ICCWAMTIP53232.2021.9674120
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Garcia V., 2017, arXiv
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Kaur A, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P142, DOI [10.1109/icct46177.2019.8969054, 10.1109/ICCT46177.2019.8969054]
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Lin GF, 2020, Arxiv, DOI arXiv:2005.14415
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Liu Z, 2020, CHIN CONTR CONF, P7328, DOI [10.23919/ccc50068.2020.9188567, 10.23919/CCC50068.2020.9188567]
   Mane S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1809, DOI 10.1109/ICCONS.2018.8662921
   Mishra N, 2018, Arxiv, DOI arXiv:1707.03141
   Nichol A, 2018, Arxiv, DOI [arXiv:1803.02999, DOI 10.48550/ARXIV.1803.02999]
   Ravi S., 2016, INT C LEARNING REPRE
   Ren MY, 2018, Arxiv, DOI arXiv:1803.00676
   Rudenko A, 2020, INT J ROBOT RES, V39, P895, DOI 10.1177/0278364920917446
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tang JX, 2019, INT GEOSCI REMOTE SE, P1212, DOI [10.1109/igarss.2019.8898180, 10.1109/IGARSS.2019.8898180]
   Tao T, 2015, IEEE access
   Tyukin IY, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534395
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wei T, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207213
   Xiao J, 2023, MEASUREMENT, V214, DOI 10.1016/j.measurement.2023.112764
   Xiong C, 2021, IEEE SIGNAL PROC LET, V28, P573, DOI 10.1109/LSP.2021.3061978
   Yang YX, 2020, IEEE ACCESS, V8, P137966, DOI 10.1109/ACCESS.2020.3012720
   Ye H., 2018, arXiv
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Zhang Y, 2021, NEUROCOMPUTING, V449, P1, DOI 10.1016/j.neucom.2021.03.114
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu L, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2276318
NR 39
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17059-1
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600005
DA 2024-07-18
ER

PT J
AU Jun, C
   Lei, C
   Wei, L
   Yang, Y
AF Jun, Chen
   Lei, Cai
   Wei, Liu
   Yang, Yu
TI Infrared and visible image fusion via gradientlet filter and
   salience-combined map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image fusion; Infrared; Target-enhanced; Salience
ID MULTISCALE DECOMPOSITION; CONTOURLET TRANSFORM; FRAMEWORK
AB In this study, we innovatively propose salience-combined map and gradientlet filter for infrared and visible image fusion. It can enhance the infrared image of the target and also retain more detailed textures. First, our method is based on a multi-scale decomposition framework and gradientlet filter to decompose the source graph into approximate layers and residual layers. The approximate layers preserve smooth areas of the source images without edge blurring. The residual layers reflect the small gradients and noise of the source image. Since the texture part of the residual layer is weak, we introduce a Gamma-enhanced gradient map to complement the texture. The initial fusion image can be obtained by fusing the approximate layers and the residual layers. The salience-combined map directly extracts salient objects from infrared images according to pixel threshold segmentation, and extracts background information other than objects from visible images. Then the salience-combined map is used to guide the initial fusion image to get the final image. In our qualitative analysis, we compared our method against 5 traditional methods and deep learning-based methods. In the quantitative assessment, utilizing 29 pairs of randomly selected source images, our algorithm distinctly showcased absolute superiority across various metrics, including EN, SF, AG, and FD. The aforementioned results affirm that our method ensures the generation of fused images with clear targets and rich details.
C1 [Jun, Chen; Lei, Cai; Wei, Liu] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Jun, Chen; Lei, Cai; Wei, Liu] Hubei Key Lab Adv Control & Intelligent Automation, Wuhan, Peoples R China.
   [Jun, Chen; Lei, Cai; Wei, Liu] Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Peoples R China.
   [Yang, Yu] Chinese Acad Sci, Shanghai Inst Tech Phys, Shanghai 200083, Peoples R China.
   [Yang, Yu] Chinese Acad Sci, Key Lab Infrared Syst Detecting & Imaging Technol, Shanghai 200083, Peoples R China.
C3 China University of Geosciences; Chinese Academy of Sciences; Shanghai
   Institute of Technical Physics, CAS; Chinese Academy of Sciences
RP Jun, C (corresponding author), China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.; Jun, C (corresponding author), Hubei Key Lab Adv Control & Intelligent Automation, Wuhan, Peoples R China.; Jun, C (corresponding author), Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Peoples R China.
EM chenjun71983@163.com
OI Chen, Jun/0000-0001-9005-6849
FU National Natural Science Foundation of China [62073304, 62373338];
   National Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China nos. 62073304 and 62373338.
CR Bhatnagar G, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691311004444
   Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Chipman L. J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P248, DOI 10.1109/ICIP.1995.537627
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fernandez-Beltran R, 2018, IEEE J-STARS, V11, P4982, DOI 10.1109/JSTARS.2018.2881342
   Geng P, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.6.067005
   Gupta M, 2022, SOFT COMPUT, V26, P8025, DOI 10.1007/s00500-022-07047-2
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Li H, 2016, INFRARED PHYS TECHN, V74, P28, DOI 10.1016/j.infrared.2015.11.002
   Li HF, 2016, INFORM SCIENCES, V349, P25, DOI 10.1016/j.ins.2016.02.030
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038013
   Ma JY, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103016
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Naidu V., 2013, International Journal of Computer Science and Business Informatics, V5, P1
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Song YJ, 2016, PROC SPIE, V10157, DOI 10.1117/12.2246341
   Tang LF, 2022, INFORM FUSION, V82, P28, DOI 10.1016/j.inffus.2021.12.004
   Toet Alexander, 2014, Figshare
   Wesley RJ, 2008, J Appl Remote Sens, V2, P1
   Xi C, 2010, INT CONF SIGN PROCES, P845, DOI 10.1109/ICOSP.2010.5655945
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu L, 2015, IET IMAGE PROCESS, V9, P318, DOI 10.1049/iet-ipr.2014.0245
   Yan X, 2015, J OPT SOC AM A, V32, P1643, DOI 10.1364/JOSAA.32.001643
   Zhang H, 2021, INT J COMPUT VISION, V129, P2761, DOI 10.1007/s11263-021-01501-8
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zou Y., 2013, INDONESIAN J ELECT E, V11, P6290, DOI DOI 10.11591/TELKOMNIKA.V11I11.2898
NR 43
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 16
PY 2023
DI 10.1007/s11042-023-17778-5
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE1R9
UT WOS:001130268000003
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Wang, CL
AF Tsai, Tsung-Han
   Wang, Chiao-Li
TI GMM-Based Speaker Verification System with Hardware MFCC in SoC Design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speaker verification; Mel-frequency cepstral coefficients; Gaussian
   Mixture Model; Hidden Markov Model; FPGA
AB In recent years, speaker verification has been extensively explored and has significantly improved its effectiveness. It analyzes the voiceprint characteristics of speakers and finds out the differences in voiceprint characteristics between speakers for verification. In this paper, we propose a text-dependent speaker verification system and its hardware implementation of the feature extraction. The proposed speaker verification system includes two phases: enrollment and verification. In the enrollment phase, the speaker has to provide appropriate speech, such as continuous number strings, sentences, or phrases for building the speakers' models in the system. In the verification phase, the verified speech is substituted into the enrolled speaker models, and the similarity between the speech and the models is used to discriminate. We further design the whole system in a system-on-a-chip (SoC). We focus on the Mel-frequency cepstral coefficients (MFCCs) pre-processing module on FPGA and implement the lightweight the post-processing models such as Gaussian Mixture Model (GMM) and Hidden Markov Model (HMM) in software. A piece of speech data can be processed in 53.6ms to meet the real-time way. The proposed speaker verification system has a 93.3% accuracy rate. The overall architecture consumes only 4.26W on Xilinx ZCU104. Moreover, the proposed MFCC chip was implemented in TSMC 90nm, and the gate count is 276k at 1 volt while power consumption is 41.15 mW with a 200 MHz operating frequency.
C1 [Tsai, Tsung-Han; Wang, Chiao-Li] Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jhong Li City 320, Taiwan.
C3 National Central University
RP Tsai, TH (corresponding author), Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jhong Li City 320, Taiwan.
EM han@ee.ncu.edu.tw; ccindyleotw@dsp.ee.ncu.edu.tw
CR Allili M.S., 2010, A Short Tutorial on Gaussian Mixture Models
   Anshu A, 2022, 2022 2 AS C INN TECH, P1, DOI [10.1109/ASIANCON55314.2022.9908692, DOI 10.1109/ASIANCON55314.2022.9908692]
   Babu SP, 2015, International Journal of Engineering Research and Technology (IJERT), V04, P1398
   Babu SP, 2015, International Journal of Engineering Research & Technology (IJERT), V4
   Boujelben O, 2018, J SYST ARCHITECT, V88, P54, DOI 10.1016/j.sysarc.2018.05.010
   Chakroun R, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P693, DOI 10.1109/ATSIP.2016.7523169
   Chauhan N, 2019, IEEE 4 INT C COMP CO
   Chen CP, 2019, INT CONF ACOUST SPEE, P6211, DOI [10.1109/ICASSP.2019.8683185, 10.1109/icassp.2019.8683185]
   Cheng NN, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2929562
   Chougala M, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P510, DOI 10.1109/ICEEOT.2016.7755666
   Chowdhury A, 2020, IEEE T INF FOREN SEC, V15, P1616, DOI 10.1109/TIFS.2019.2941773
   Chung JS, 2018, INTERSPEECH, P1086
   Dalmiya CP, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1263
   Das R, 2017, IETE Technical Review, P1
   Dave N., 2013, INT J ADV RES ENG TE, V1, P1
   Thu DDT, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P196, DOI 10.1109/SOCPAR.2013.7054126
   EhKan P, 2011, INT J RECONFIGURABLE, V2011, DOI 10.1155/2011/420369
   Furui S, 1997, PATTERN RECOGN LETT, V18, P859, DOI 10.1016/S0167-8655(97)00073-1
   Islam Md, 2019, Bangla Dataset and MMFCC in Text-dependent Speaker Identification, DOI [10.14456/easr.2019.7, DOI 10.14456/EASR.2019.7]
   Jo J, 2016, IEEE T VLSI SYST, V24, P754, DOI 10.1109/TVLSI.2015.2413454
   Khadkevich M, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-15
   Larcher A, 2014, SPEECH COMMUN, V60, P56, DOI 10.1016/j.specom.2014.03.001
   Lévy C, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/806186
   Mahboob T., 2015, INT J COMPUTER SCI I, V12, P126
   Manning Christopher D., 2001, Foundations of Statistical Natural Language Processing
   Mao SY, 2019, INT CONF ACOUST SPEE, P6715, DOI 10.1109/ICASSP.2019.8683172
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Muhammad A, 2018, IEEE 8 INT C SYST EN
   Nithya K, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P25, DOI 10.1109/iSES47678.2019.00019
   Povey D., 2011, P IEEE ASRU
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ramos-Lara R, 2013, J SIGNAL PROCESS SYS, V71, P89, DOI 10.1007/s11265-012-0683-5
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Sarkar AK, 2016, INTERSPEECH, P425, DOI 10.21437/Interspeech.2016-362
   Sharma R, 2018, SPEECH COMMUN, V96, P207, DOI 10.1016/j.specom.2017.12.001
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   Toruk MM, 2019, INT MULTICONF SYST, P383, DOI [10.1109/SSD.2019.8893188, 10.1109/ssd.2019.8893188]
   Dao VL, 2017, ADV INTELL SYST COMP, V538, P248, DOI 10.1007/978-3-319-49073-1_27
   von Zeddelmann D, 2010, INT CONF ACOUST SPEE, P257, DOI 10.1109/ICASSP.2010.5495974
   Vu NV, 2010, IEEE INT SYMP CIRC S, P2334, DOI 10.1109/ISCAS.2010.5537242
   Zeinali H, 2017, IEEE-ACM T AUDIO SPE, V25, P1421, DOI 10.1109/TASLP.2017.2694708
   Zhang YD, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P398, DOI 10.1109/ASRU.2009.5372931
NR 42
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17561-6
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY3H0
UT WOS:001142451400001
DA 2024-07-18
ER

PT J
AU Liu, H
   Dong, ZY
AF Liu, Hui
   Dong, Zhenyang
TI ESA-SSD: single-stage object detection network using deep hierarchical
   feature learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; 3D point cloud; Object detection; Enhanced feature
   expression; Semantic aware sampling; Attention mechanism
AB Object detection, localization and identification based on 3D point cloud data are widely applied in autonomous driving, robotics, augmented reality and other fields. We propose a raw point cloud-based, lightweight and single-stage 3D object detector ESA-SSD, which aggregate contextual features to key points using multi-set abstraction modules. At first, an enhanced feature expression module is utilize to encode the geometric information and feature content of points within the neighborhood for strengthening the feature expression of each point. And then, semantic aware sampling method performs down-sampling for making more foreground points included in the key points and reducing the ineffective learning of the network. To focus the network more on the key features of the object, the spatial attention mechanism is introduced to weight the features at each point. Finally, the center of the instance is estimated with the contextual instance centroid perception module in order to making the context features of the detection object extracted adequately. We performed experimental validation on the publicly available KITTI and DAIR-V2X datasets. On the KITTI dataset, ESA-SSD achieves detection accuracies of 88.58%, 80.26% and 76.80% for the car categories with easy, medium and difficult detection difficulties; on the DAIR-V2X dataset, the detection accuracies for the car categories with three detection difficulties reach 73.21%, 61.62% and 56.99%.
C1 [Liu, Hui; Dong, Zhenyang] Beijing Univ Civil Engn & Architecture, Sch Elect & Informat Engn, Beijing 102616, Peoples R China.
   [Liu, Hui] Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 102616, Peoples R China.
C3 Beijing University of Civil Engineering & Architecture; Beijing
   University of Civil Engineering & Architecture
RP Liu, H (corresponding author), Beijing Univ Civil Engn & Architecture, Sch Elect & Informat Engn, Beijing 102616, Peoples R China.; Liu, H (corresponding author), Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 102616, Peoples R China.
EM liuhui@bucea.edu.cn; dzy07062023@163.com
FU National Natural Science Foundation of China
FX No Statement Available
CR Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng JJ, 2021, AAAI CONF ARTIF INTE, V35, P1201
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta S., 2020, Int. J. Comput. Sci. Trends Technol. IJCST, V8, P26
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Laroca R., 2018, P INT JOINT C NEUR N, P1
   Li JJ, 2020, IEEE COMPUT SOC CONF, P1894, DOI 10.1109/CVPRW50498.2020.00239
   Liang Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13326, DOI 10.1109/CVPR42600.2020.01334
   Liu H, 2024, VISUAL COMPUT, V40, P971, DOI 10.1007/s00371-023-02826-w
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Noh J, 2021, PROC CVPR IEEE, P14600, DOI 10.1109/CVPR46437.2021.01437
   Pan XR, 2021, PROC CVPR IEEE, P7459, DOI 10.1109/CVPR46437.2021.00738
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi D., 2022, EUR C COMPUT VIS, P228
   Qiu S, 2023, IEEE T PATTERN ANAL, V45, P1312, DOI 10.1109/TPAMI.2021.3137794
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi GS, 2022, LECT NOTES COMPUT SC, V13670, P35, DOI 10.1007/978-3-031-20080-9_3
   Shi SS, 2023, INT J COMPUT VISION, V131, P531, DOI 10.1007/s11263-022-01710-9
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Yu HB, 2022, PROC CVPR IEEE, P21329, DOI 10.1109/CVPR52688.2022.02067
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhang YF, 2022, PROC CVPR IEEE, P18931, DOI 10.1109/CVPR52688.2022.01838
   Zheng W, 2021, PROC CVPR IEEE, P14489, DOI 10.1109/CVPR46437.2021.01426
   Zheng W, 2021, AAAI CONF ARTIF INTE, V35, P3555
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 41
TC 0
Z9 0
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17754-z
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300004
DA 2024-07-18
ER

PT J
AU Nagajyothi, CN
   Oommen, L
   Chebrolu, S
AF Nagajyothi, Chiluka Nikhila
   Oommen, Lintu
   Chebrolu, Srilatha
TI Classification of imbalanced multi-label leaf diseases using CaRiT:
   class attention enabled RegionViT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-label classification; Vision transformers; RegionViT; Imbalanced
   data; Plant leaf diseases
AB Plant diseases, particularly leaf diseases, are one of the factors contributing to crop loss, accounting for approximately 15-40% of the total loss in crop production. Early identification of these diseases is crucial in maximizing crop yield. However, existing models struggle to accurately identify leaf diseases as they manifest in images as irregularly shaped spots, and a single leaf can exhibit multiple disease symptoms, making it a multi-label classification problem. To address this issue, a novel variant of the Region Vision Transformer architecture called Class attention enabled RegionViT (CaRiT) has been proposed for plant leaf disease classification. CaRiT incorporates a class attention mechanism that allows the model to capture the spatial relationships between patches, enabling accurate multi-label disease classification. CaRiT model performance was evaluated on imbalanced datasets, namely Dataset-I1 and Dataset-I2, as well as a balanced dataset called Dataset-B. The CaRiT model achieved the average ROC-AUC values of 0.946 for Dataset-I1, 0.936 for Dataset-I2, and 0.953 for Dataset-B. The CaRiT model is compared with DenseNet, ResNeSt, ResNeXt, and RegionViT. These models achieved average ROC-AUC values ranging from 0.810 to 0.931, 0.811 to 0.930, and 0.650 to 0.940 for Dataset-I1, Dataset-I2, and Dataset-B respectively. These results demonstrate the consistent outperformance of the CaRiT model when compared to the other models on all three datasets.
C1 [Nagajyothi, Chiluka Nikhila; Oommen, Lintu; Chebrolu, Srilatha] Natl Inst Technol Andhra Pradesh, Dept Comp Sci & Engn, Tadepalligudem 534101, Andhra Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Andhra Pradesh
RP Nagajyothi, CN (corresponding author), Natl Inst Technol Andhra Pradesh, Dept Comp Sci & Engn, Tadepalligudem 534101, Andhra Prades, India.
EM chilukanikki509@gmail.com; oomensusan@gmail.com;
   srilatha.chebrolu@nitandhra.ac.in
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cap QH, 2022, IEEE T AUTOM SCI ENG, V19, P1258, DOI 10.1109/TASE.2020.3041499
   Chen C.F., 2021, arXiv, DOI 10.48550/ARXIV.2106.02689
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Choudhury RA, 2021, PLANT PATHOL, V70, P676, DOI 10.1111/ppa.13314
   Christine KaeserChen M, 2020, Plant Pathology 2020 FGVC7
   Debnath O, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104631
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   ErnestMwebaze JM, 2020, Kaggle
   Fan XJ, 2022, COMPUT ELECTRON AGR, V196, DOI 10.1016/j.compag.2022.106892
   Feng Jingze, 2022, ScienceDB, DOI 10.11922/sciencedb.01627
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Phan TH, 2020, Arxiv, DOI [arXiv:2006.01413, 10.48550/arXiv.2006.01413]
   Jin HB, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107055
   Kaur P, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105210
   Khan AI, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107093
   Li X, 2022, J King Saud Univ-Comput Inf Sci
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Oyewola DO, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.352
   Hughes DP, 2016, Arxiv, DOI [arXiv:1511.08060, DOI 10.48550/ARXIV.1511.08060]
   Pathology F, 2021, Plant pathology 2021 FGVC8
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma P., 2011, Int J Sci Eng Res, V2, P262
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Thai HT, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107518
   Thakur PS, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118117
   Tian YN, 2019, J SENSORS, V2019, DOI 10.1155/2019/7630926
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P32, DOI 10.1109/ICCV48922.2021.00010
   Wahjuni S, 2023, J AGR FOOD RES, V11, DOI 10.1016/j.jafr.2023.100514
   [王东方 Wang Dongfang], 2021, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V37, P199
   Wang JH, 2023, COMPUT ELECTRON AGR, V206, DOI 10.1016/j.compag.2023.107682
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xing S, 2022, COMPUT ELECTRON AGR, V199, DOI 10.1016/j.compag.2022.107144
   Yu XH, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109131
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang SW, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107511
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Y, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106644
   Zhou CJ, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106020
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SS, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107539
NR 50
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17678-8
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800003
DA 2024-07-18
ER

PT J
AU Wang, MH
   Xu, JJ
   Ke, FH
   Liao, L
AF Wang, Meihua
   Xu, Jiajie
   Ke, Fanhui
   Liao, Lei
TI A encoder-decoder deblurring network combined with high-frequency a
   priori
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image deblurring; High-frequency a priori; Bilateral redistribution
AB Convolutional neural network based methods have been proposed to address blind deblurring. Aiming at the difficulty of reconstructing high-frequency features of images with existing network models, this paper proposes a two-stage convolution-based encoder-decoder for fusing high-frequency a prior. In the first stage, both blurred and high-frequency images are input, and the image features extracted by the network and the high-frequency features are fused. In the second stage, the fused features are further refined and recovered as potentially clear images, and the reconstruction ability of the model for high-frequency features is enhanced. In addition, this paper proposes a deep feature reorganization module that integrates multi-layer semantic information in the encoder-decoder and targets the encoder semantics to further enhance the feature characterization capability of the model. Comprehensive experimental results show that our method achieves 0.9085 structural similarity index (SSIM) and 30.66db peak signal-to-noise ratio (PSNR) on the GoPro dataset. Meanwhile, our method achieves 0.8514 SSIM and 27.39db PSNR on the Lai dataset.
C1 [Wang, Meihua; Xu, Jiajie; Ke, Fanhui; Liao, Lei] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Peoples R China.
C3 South China Agricultural University
RP Wang, MH (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Peoples R China.
EM wangmeihua@scau.edu.cn; xjj1212@stu.scau.edu.cn; weian@stu.scau.edu.cn;
   ll1423543604@stu.scau.edu.cn
FU Basic and Applied Basic Research Foundation of Guangdong Province;
   College of Mathematics and Informatics, South China Agricultural
   University
FX Particular thanks are due to Pengtao Li and Anbang Wang of the College
   of Mathematics and Informatics, South China Agricultural University, for
   their special contributions in critically reviewing the study proposal,
   writing the manuscript, and language editing and proofreading.
CR Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P6885, DOI 10.1109/TIP.2020.2995048
   Chen L, 2021, INFORM SCIENCES, V546, P368, DOI 10.1016/j.ins.2020.08.105
   Dong XY, 2022, PROC CVPR IEEE, P12114, DOI 10.1109/CVPR52688.2022.01181
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Dou ZY, 2019, IEEE ACCESS, V7, P90904, DOI 10.1109/ACCESS.2019.2927158
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Franke U, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P273, DOI 10.1109/IVS.2000.898354
   Gong GL, 2019, IEEE I C SIGNAL IMAG, P231, DOI [10.1109/ICSIPA45851.2019.8977761, 10.1109/icsipa45851.2019.8977761]
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Khetkeeree S, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P1015, DOI [10.1109/SIPROCESS.2019.8868907, 10.1109/siprocess.2019.8868907]
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu RW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1348, DOI 10.1109/ICASSP.2018.8461857
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Thorpe C, 2013, IEEE T PATTERN ANAL, V35, P3066, DOI 10.1109/TPAMI.2013.161
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yuchen Li, 2019, 2019 2nd International Conference on Information Systems and Computer Aided Education (ICISCAE), P288, DOI 10.1109/ICISCAE48440.2019.221637
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
NR 31
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17771-y
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, B
   Lu, WW
AF Li, Bo
   Lu, Weiwei
TI Application of image processing technology in the digital media era in
   the design of integrated materials painting in installation art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital media age; Image processing technology; Installation art;
   Comprehensive material painting
AB In response to the problems of lack of intelligence, low recognition, loss of brightness, and unclear design objects in the comprehensive material painting of installation art, when materials enter the field of artistic creation, they can assist in artistic creation, but constantly updating materials is also a challenge for artists. This article utilized image processing technology in the digital media era to develop a comprehensive material painting design system for installation art. The aim was to use image processing technology to intelligently restore brightness balance, enhance restoration, and denoise paintings in integrated material painting, thereby improving the problems in installation art integrated material painting. In order to demonstrate the effectiveness of the designed installation art comprehensive material painting design system based on image processing technology, this article conducted relevant tests on the design system. The test results showed that the brightness of the 5 sample paintings without image processing technology was relatively dim. The brightness of character painting was the brightest compared to the 5 sample paintings, at 47.13%; the landscape painting had the lowest brightness, at 36.61%. The brightness of the five sample paintings processed by image processing technology significantly improved, and the brightness of all sample paintings reached over 70%. From this, it can be seen that the design system can effectively improve the quality of integrated material painting in installation art, and can also enhance the brightness of integrated material painting in installation art. Moreover, it can ensure a certain degree of recognition and clarity, and the design system has a high level of intelligence. This article hoped that the application of image processing technology in the digital media era in the comprehensive material painting design of installation art can effectively promote the improvement and upgrading of installation art comprehensive material painting design, and inject technological strength into the application of installation art in the comprehensive material painting design. This article can provide reference value for the design and development of installation art and comprehensive material painting.
C1 [Li, Bo] Hebei Acad Fine Arts, Sch Plast Arts, Shijiazhuang 050700, Hebei, Peoples R China.
   [Lu, Weiwei] NingboTech Univ, Sch Design, Ningbo 315100, Peoples R China.
C3 NingboTech University
RP Lu, WW (corresponding author), NingboTech Univ, Sch Design, Ningbo 315100, Peoples R China.
EM libo@hbafa.edu.cn; luww@nbt.edu.cn
CR Akdeniz D, 2019, Gastroia J Gastron Travel Res, V3, P346
   Avia D., 2019, Art Hist Critic, V15, P37, DOI [10.2478/mik-2019-0003, DOI 10.2478/MIK-2019-0003]
   Castellano G, 2021, NEURAL COMPUT APPL, V33, P12263, DOI 10.1007/s00521-021-05893-z
   Dandolo CLK, 2018, OPT EXPRESS, V26, P5358, DOI 10.1364/OE.26.005358
   Degano I, 2018, ANGEW CHEM INT EDIT, V57, P7313, DOI 10.1002/anie.201713404
   Deng X., 2021, Art Perform Lett, V2, P37
   Feltrin F, 2020, LEUKOS, V16, P25, DOI 10.1080/15502724.2018.1522261
   Fruhstuck A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322993
   Gahlot M., 2020, Int J Curr Microbiol App Sci, V9, P803, DOI [10.20546/ijcmas.2020.908.086, DOI 10.20546/IJCMAS.2020.908.086]
   Hagendijk T, 2019, EARLY SCI MED, V24, P248, DOI 10.1163/15733823-00243P02
   Hassan E, 2022, Nile Journal of Communication and Computer Science Internet, V3, P17, DOI [10.21608/njccs.2022.280047, DOI 10.21608/NJCCS.2022.280047]
   Kholmuratovich MK., 2020, INT J PSYCHOSOCIAL R, V24, P285, DOI [10.37200/IJPR/V24I5/PR201880, DOI 10.37200/IJPR/V24I5/PR201880]
   Lv C., 2018, Angewandte Chemie, V130, P9574, DOI DOI 10.1002/ANGE.201805212
   Mackie M, 2018, ANGEW CHEM INT EDIT, V57, P7369, DOI 10.1002/anie.201713020
   Purtle J, 2020, J CONTEMP PAINTING, V6, P11, DOI 10.1386/jcp_00011_1
   Sarwari AQ., 2020, Shanlax Intl J Arts Sci Human, V8, P16, DOI [10.34293/sijash.v8i2.3422, DOI 10.34293/SIJASH.V8I2.3422]
   Thomson J, 2020, DEPART CRIT QUAL RES, V9, P28, DOI 10.1525/dcqr.2020.9.3.28
NR 17
TC 0
Z9 0
U1 11
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17713-8
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100003
DA 2024-07-18
ER

PT J
AU Yusuf, AA
   Feng, C
   Mao, XL
   Duma, RA
   Abood, MS
   Chukkol, AHA
AF Yusuf, Abdulganiyu Abdu
   Feng, Chong
   Mao, Xianling
   Ally Duma, Ramadhani
   Abood, Mohammed Salah
   Chukkol, Abdulrahman Hamman Adama
TI Graph neural networks for visual question answering: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Graph neural networks; Visual question answering; Computer vision;
   Natural language processing
ID CONVOLUTIONAL NETWORKS; LANGUAGE; VISION
AB Recently, visual question answering (VQA) has gained considerable interest within the computer vision and natural language processing (NLP) research areas. The VQA task involves answering a question about an image, which requires both language and vision understanding. Effectively extracting visual representations from images, textual embedding from questions, and bridging the semantic disparity between image and question representations pose fundamental challenges in VQA. Lately, an increasing number of studies are focusing on utilizing graph neural networks (GNNs) to enhance the performance of VQA tasks. The ability to handle graph-structured data is a major advantage of GNNs for VQA tasks, which allows better representation of relationships between objects and regions in an image. These relationships include both spatial and semantic relationships. This paper systematically reviews various graph neural networks based studies for image-based VQA. Fifty-four related publications written between 2018-Jan. 2023 were carefully synthesized for this review. The review is structured into three perspectives: the various graph neural network techniques and models that have been applied for VQA, a comparison of the model's performance and existing challenges. After analyzing these papers, 45 different models were identified, grouped into four different GNN techniques. These are Graph Convolution Network (GCN), Graph Attention Network (GAT), Graph Isomorphism Network (GIN) and Graph Neural Network (GNN). Also, the performance of these models is compared based on accuracy, datasets, subtasks, feature representation and fusion techniques. Lastly, the study provided some possible suggestions to mitigate still existing challenges for future research in visual question answering.
C1 [Yusuf, Abdulganiyu Abdu; Feng, Chong; Mao, Xianling; Ally Duma, Ramadhani] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 10008, Peoples R China.
   [Yusuf, Abdulganiyu Abdu] Natl Biotechnol Dev Agcy, Abuja, Nigeria.
   [Feng, Chong] Beijing Inst Technol, South East Informat Technol Inst, Beijing 10008, Peoples R China.
   [Mao, Xianling] Beijing Engn Res Ctr High Volume Language Informat, Beijing, Peoples R China.
   [Abood, Mohammed Salah; Chukkol, Abdulrahman Hamman Adama] Beijing Inst Technol, Sch Informat & Elect, Beijing 10008, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology;
   Beijing Institute of Technology
RP Feng, C (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 10008, Peoples R China.; Feng, C (corresponding author), Beijing Inst Technol, South East Informat Technol Inst, Beijing 10008, Peoples R China.
EM abdulg720@gmail.com; fengchong@bit.edu.cn; maoxl@bit.edu.cn;
   radsiffi@gmail.com; mohammedsalah@bit.edu.cn; ahchukkol@gmail.com
RI Yusuf, Abdulganiyu/ABC-1247-2021
OI Salah Abood, Mohammed/0009-0008-5360-9326; ABDU YUSUF,
   ABDULGANIYU/0000-0002-3137-2398; Chukkol,
   Abdulrahman/0000-0003-2279-3606; Duma, Ramadhani
   Ally/0000-0002-9195-4920; Feng, Chong/0000-0002-1691-1584
FU We thank the anonymous reviewers for their valuable comments and
   suggestions.
FX We thank the anonymous reviewers for their valuable comments and
   suggestions.
CR Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Agrawal A, 2017, INT J COMPUT VISION, V123, P4, DOI 10.1007/s11263-016-0966-6
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Asif NA, 2021, IEEE ACCESS, V9, P60588, DOI 10.1109/ACCESS.2021.3071274
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Cao JJ, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3135655
   Cao PP, 2022, NEURAL COMPUT APPL, V34, P13387, DOI 10.1007/s00521-022-07368-1
   Cao WM, 2020, IEEE ACCESS, V8, P35929, DOI 10.1109/ACCESS.2020.2975067
   Cao Y, 2021, 13 INT C WIRELESS CO, V2, P21
   Chae J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892787
   Charikar M, 2002, LECT NOTES COMPUT SC, V2380, P693
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Damodaran V, 2021, Arxiv, DOI arXiv:2101.05479
   Davis E, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00051
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eun-Sol Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14569, DOI 10.1109/CVPR42600.2020.01459
   Feng JF, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102329
   Gao CY, 2022, IEEE T PATTERN ANAL, V44, P9603, DOI 10.1109/TPAMI.2021.3132034
   Gao Difei, 2020, CVPR, P12746
   Gori M, 2005, IEEE IJCNN, P729
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Guo DL, 2023, IEEE T NEUR NET LEAR, V34, P1023, DOI 10.1109/TNNLS.2021.3104937
   Gupta Deepak, 2021, Expert Systems with Applications, V164, P465, DOI 10.1016/j.eswa.2020.113993
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039
   Huang Q., 2020, P 58 ANN M ASS COMP, P7166
   Hudson Drew A, 2019, P IEEE CVF C COMP VI, P6700, DOI DOI 10.1109/CVPR.2019.00686
   Ishida T, 2017, 31 C NEURAL INFORM P, P1
   Jing C, 2022, Maintaining reasoning consistency in compositional visual question answering, P5089, DOI [10.1109/cvpr52688.2022.00504, DOI 10.1109/CVPR52688.2022.00504]
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Khademi M, 2020, P 58 ANN M ASS COMP, P7177, DOI 10.18653/v1/2020.acl-main.643
   Kim JH, 2016, ADV NEUR IN, V29
   Kim JH, 2018, ADV NEUR IN, V31
   Kitchenham B, 2010, INFORM SOFTWARE TECH, V52, P792, DOI 10.1016/j.infsof.2010.03.006
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kv G, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108883
   Li H., 2022, INT J CLIN PRACT, P1, DOI DOI 10.1109/ICME52920.2022.9859766
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li XP, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108455
   Liang W, 2021, NAACL-HLT 2021, V79, DOI [10.18653/v1/2021.maiworkshop-1.12, DOI 10.18653/V1/2021.MAIWORKSHOP-1.12]
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu HY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071404
   Liu LP, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107650
   Liu R, 2022, MULTIMEDIA SYST, V28, P445, DOI 10.1007/s00530-020-00745-7
   Liu XC, 2021, 2021 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING, BIG DATA AND BUSINESS INTELLIGENCE (MLBDBI 2021), P708, DOI 10.1109/MLBDBI54094.2021.00140
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu JS, 2019, ADV NEUR IN, V32
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Mandal D, 2017, PATTERN RECOGN LETT, V98, P110, DOI 10.1016/j.patrec.2017.09.008
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Miao YL, 2022, NEURAL PROCESS LETT, V54, P1435, DOI 10.1007/s11063-021-10689-2
   Mishra A., 2019, 2019 INT C DOC AN RE, P947, DOI DOI 10.1109/ICDAR.2019.00156
   Narasimhan M, 2018, ADV NEUR IN, V31
   Nuthalapati SV, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3353, DOI 10.1145/3459637.3482218
   OpenAI, 2021, Chatgpt
   Pan H, 2022, NEUROCOMPUTING, V492, P62, DOI 10.1016/j.neucom.2022.03.071
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parisot S, 2018, ADV NEUR IN, V2018
   Peng Nanyun, 2017, Transactions of the Association for Computational Linguistics, V5, P101, DOI 10.1162/tacl_a_00049
   Qian Y, 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9859591, DOI 10.1109/ICME52920.2022.9859591]
   Ren HT, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109250
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rk B., 2021, Int Semant Web Conf, V1, P111, DOI [10.1007/978-3-030-88361-4, DOI 10.1007/978-3-030-88361-4]
   Saqur R, 2020, Adv Neural Inf Process Syst, VDecem, P1
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shah S, 2019, AAAI CONF ARTIF INTE, P8876
   Sharma H, 2022, NEURAL PROCESS LETT, V54, P709, DOI 10.1007/s11063-021-10655-y
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Shen X, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0277693
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Soohyeong Lee, 2019, 2019 First International Conference on Graph Computing (GC), P45, DOI 10.1109/GC46384.2019.00015
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344
   Le TM, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P818
   Ting K.M., 2011, Encyclopedia of Machine Learning, DOI DOI 10.1007/978-0-387-30164-8_652
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang YA, 2023, Arxiv, DOI [arXiv:2205.11501, 10.48550/arXiv.2205.11501]
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie JY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4546, DOI 10.1145/3474085.3476969
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu X, 2021, IEEE T NEUR NET LEAR, V32, P1654, DOI 10.1109/TNNLS.2020.2986029
   Xu ZY, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103207
   Yang Zhuoqian., 2018, arXiv, DOI 10.48550/arXiv.1812.09681
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao L., 2019, Proceedings of the AAAI Conference on Artificial Intelligence, V33, P7370
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu J, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107563
   Yu J, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106150
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Yusuf AA, 2022, MULTIMED TOOLS APPL, V81, P40361, DOI 10.1007/s11042-022-13065-x
   Yusuf AA, 2022, ARTIF INTELL REV, V55, P6277, DOI 10.1007/s10462-022-10151-2
   Ze Hu, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P218, DOI 10.1109/DSC50466.2020.00040
   Zhang C., 2020, BMVC, V2019, P1
   Zhang Si, 2019, Comput Soc Netw, V6, P11, DOI 10.1186/s40649-019-0069-y
   Zhang WF, 2021, INFORM FUSION, V72, P70, DOI 10.1016/j.inffus.2021.02.006
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhou Y, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3495161
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
   Zhu ZH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1097
NR 110
TC 0
Z9 0
U1 18
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17594-x
EA NOV 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500003
DA 2024-07-18
ER

PT J
AU Juneja, M
   Minhas, JS
   Singla, N
   Kaur, R
   Jindal, P
AF Juneja, Mamta
   Minhas, Janmejai Singh
   Singla, Naveen
   Kaur, Ravinder
   Jindal, Prashant
TI Denoising techniques for cephalometric x-ray images: A comprehensive
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE X-ray imaging; Deep learning; Denoising filters; Gaussian noise; Poisson
   noise
ID SPARSE
AB Noising in X-ray imaging has been one of the biggest challenges that leads to insufficient and improper diagnosis. Despite the fact that X-rays are one of the most widespread and acceptable imaging techniques among the medical and scientific fraternity, still Gaussian and Poisson noise lead to a lot of image deterioration. Over the past few decades, several denoising techniques have been explored using traditional, hybrid and deep learning techniques which have been reported in this paper. Poisson noise was best removed by the application of bilateral filter with a maximum Peak Signal to Noise Ratio (PSNR) of 36.22 and for the removal of Gaussian noise, median filter proved to be unparalleled with a PSNR of 32.92 for the variance of 0.01, 31.4 for the variance of 0.04, 31.03 for the variance of 0.07, and 30.58 for the variance of 0.1 amongst the conventional filters. The Noise2Noise model employing the deep learning approach has given the best PSNR value of 34.38 amongst all the other alternatives for the images with gaussian noise. This paper serves as a comprehensive review for beginners working in this domain, that would aid them to select the best filter for the image pre-processing and noise removal.
C1 [Juneja, Mamta; Minhas, Janmejai Singh; Singla, Naveen; Kaur, Ravinder; Jindal, Prashant] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Jindal, P (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM mamtajuneja@pu.ac.in; janmejai2002@gmail.com;
   naveensingla532.ns@gmail.com; ravinder.kaur7@yahoo.com; jindalp@pu.ac.in
OI Jindal, Dr. Prashant/0000-0002-3844-3494
FU The authors are grateful to the Ministry of Human Resource Development
   (MHRD), Govt. of India for funding this project under Design Innovation
   Centre (DIC) sub-theme Medical Devices amp; Restorative Technologies.;
   Ministry of Human Resource Development (MHRD); Medical Devices amp;
   Restorative Technologies
FX The authors are grateful to the Ministry of Human Resource Development
   (MHRD), Govt. of India for funding this project under Design Innovation
   Centre (DIC) sub-theme Medical Devices & Restorative Technologies.
CR ALPARONE L, 1995, INT GEOSCI REMOTE SE, P1409, DOI 10.1109/IGARSS.1995.521764
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Chochia PA, 2021, J COMMUN TECHNOL EL+, V66, P769, DOI 10.1134/S1064226921060073
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elbakri IA, 2002, IEEE T MED IMAGING, V21, P89, DOI 10.1109/42.993128
   Freeman WT., 2007, 2007 IEEE C COMP VIS, P1
   Goyal B, 2020, INFORM FUSION, V55, P220, DOI 10.1016/j.inffus.2019.09.003
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Huang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P759, DOI 10.1109/LGRS.2018.2796604
   Ignatov A, 2021, IEEE COMPUT SOC CONF, P2515, DOI 10.1109/CVPRW53098.2021.00285
   Irrera P, 2016, MED IMAGE ANAL, V28, P33, DOI 10.1016/j.media.2015.11.002
   Jin Q., 2021, J Math Imaging and Vision, V17, P1
   Kanwal N, 2011, 2011 5 INT C BIOINF, P1
   Kartsov SK, 2020, Non-local means denoising algorithm based on local binary patterns
   Kaur R, 2018, MULTIMED TOOLS APPL, V77, P22735, DOI 10.1007/s11042-017-5500-5
   Keles O, 2021, PICT COD SYMP, P286, DOI 10.1109/PCS50896.2021.9477470
   Kim HE, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124090
   Lan Xiangyang., 2006, ECCV
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecouat B, 2019, EUR C COMP VIS
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   LEVYMANDEL AD, 1986, COMPUT BIOMED RES, V19, P282, DOI 10.1016/0010-4809(86)90023-6
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkinen Y, 2020, IEEE T IMAGE PROCESS, V29, P8339, DOI 10.1109/TIP.2020.3014721
   Manson E., 2019, Curr. Trends Clin. Med. Imaging, V2, P555620, DOI 10.19080/CTCMI.2019.03.555620
   Mishro PK, 2022, IEEE REV BIOMED ENG, V15, P184, DOI 10.1109/RBME.2021.3055556
   Ning R, 2000, IEEE T MED IMAGING, V19, P949, DOI 10.1109/42.887842
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pugalenthi R, 2020, INT J IMAG SYST TECH, V30, P1119, DOI 10.1002/ima.22453
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sagheer SVM, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102036
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Shuyue C, 2000, 15 WORLD C NOND TEST
   Sidhu K.S., 2012, Int Refereed J Eng Sci, V1, P001
   Singh P, 2018, ENG SCI TECHNOL, V21, P589, DOI 10.1016/j.jestch.2018.05.009
   Smalyuk VA, 1999, REV SCI INSTRUM, V70, P647, DOI 10.1063/1.1149313
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   Wang CW, 2016, MED IMAGE ANAL, V31, P63, DOI 10.1016/j.media.2016.02.004
   Wang T, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012007
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 45
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17495-z
EA NOV 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700008
DA 2024-07-18
ER

PT J
AU Cheng, CH
   Cai, WH
AF Cheng, Ching-Hsue
   Cai, Wen-Hong
TI Double-weight LDA extracting keywords for financial fraud detection
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Latent Dirichlet allocation; Financial fraud detection model; Natural
   language processing; Imbalanced classes; Visual information
   representation
ID TEXT
AB The impact of financial fraud is widespread, from everyday life to the financial industry, and it reduces industry confidence and destabilizes the country's economy. Therefore, it is important to develop an intelligent financial fraud detection system for early warning and prevention. This study proposes a double-weight latent Dirichlet allocation (DW-LDA) to extract the keywords from financial fraud data, and then we use five intelligent classifiers to build an intelligent text fraud detection model. In addition, the financial fraud dataset usually contains more non-fraud cases than fraud cases, which is an imbalanced dataset; hence, this study uses a synthesized minority oversampling technique (SMOTE) and random undersampling to handle imbalanced datasets. In verification, this study collected the Enron email and MD&A datasets to compare the performances of the related topic models and weighted LDA (TFIDF+LDA and PMI + LDA) with the proposed DW-LDA after SMOTE handling. In evaluating model performance, we use accuracy, recall, precision, F-score, and AUC as evaluation metrics, and the results show that the proposed DW-LDA (TFIDF+PMI + LDA) has a better performance than the listing topic models. For visual information representation, we use visual graphs to show the important results, such as the word cloud of the fraudulent email and keywords. The research results and the built intelligent text fraud detection model can be provided to investors and stakeholders for reference.
C1 [Cheng, Ching-Hsue; Cai, Wen-Hong] Natl Yunlin Univ Sci & Technol, Dept Informat Management, Touliu 64002, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Cheng, CH (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Informat Management, Touliu 64002, Yunlin, Taiwan.
EM chcheng@yuntech.edu.tw
OI Cheng, Ching-Hsue/0000-0002-5509-6965
CR Al-Hashedi KG, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100402
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   [Anonymous], 2017, Journal of Computers
   Ballabio D, 2018, CHEMOMETR INTELL LAB, V174, P33, DOI 10.1016/j.chemolab.2017.12.004
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cecchini M, 2010, DECIS SUPPORT SYST, V50, P164, DOI 10.1016/j.dss.2010.07.012
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Craja P, 2020, DECIS SUPPORT SYST, V139, DOI 10.1016/j.dss.2020.113421
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gaber T, 2016, COMPUT ELECTRON AGR, V122, P55, DOI 10.1016/j.compag.2015.12.022
   Goldberg Y, 2016, J ARTIF INTELL RES, V57, P345, DOI 10.1613/jair.4992
   Goode S, 2011, DECIS SUPPORT SYST, V50, P702, DOI 10.1016/j.dss.2010.08.018
   Grootendorst M. R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794
   Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Horwath C., 2011, Putting the Freud in Fraud: Why the Fraud Triangle Is No Longer Enough
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Lauriola I, 2022, NEUROCOMPUTING, V470, P443, DOI 10.1016/j.neucom.2021.05.103
   Lemaitre G, 2016, Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning, P18
   Lin CC, 2015, KNOWL-BASED SYST, V89, P459, DOI 10.1016/j.knosys.2015.08.011
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   NLTK, 2021, NLTK Project
   Pan SW, 2022, J PETROL SCI ENG, V208, DOI 10.1016/j.petrol.2021.109520
   Platt JC, 2000, ADV NEUR IN, P61
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Rezaee Z., 2005, CRIT PERSPECT, V16, P277
   Shearman TM, 2019, ECOL MODEL, V414, DOI 10.1016/j.ecolmodel.2019.108855
   Sun DM, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2021.102210
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769, DOI 10.1109/tsmc.1976.4309452
   Wang X, 2019, PATTERN RECOGN, V86, P236, DOI 10.1016/j.patcog.2018.09.004
   Wang YB, 2018, DECIS SUPPORT SYST, V105, P87, DOI 10.1016/j.dss.2017.11.001
   West J, 2016, COMPUT SECUR, V57, P47, DOI [10.1016/j.cose.2015.09.005, 10.1007/978-3-319-16507-3_4]
   William M, 2015, Enron Email Dataset
   Zhang H, 2021, RES INT BUS FINANC, V58, DOI 10.1016/j.ribaf.2021.101482
   Zhao Y, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0558-4
   Zhou YC, 2022, COMPUT METHOD APPL M, V388, DOI 10.1016/j.cma.2021.114238
NR 43
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17334-1
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600005
DA 2024-07-18
ER

PT J
AU Paturkar, V
   Yadav, R
   Kala, R
AF Paturkar, Varun
   Yadav, Rohit
   Kala, Rahul
TI Sequential visual place recognition using semantically-enhanced features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual place recognition; Semantics; SLAM
AB The problem of visual place recognition enables a vehicle to identify the place that it is currently at; that can be used to localize the vehicle through loop closures when the traditional SLAM algorithms fail due to low resolution of the sensors or extreme lightning conditions. We assume that the vehicle's route is filled with sequential places that the vehicle sees in the same order as it travels a pre-defined route. We handle three distinct challenges for this problem. First, since most places have a very small distinctiveness, we make the feature extraction algorithm conscious of the strong features like building facades and signboards. Second, there may be several dynamic entities that disallow reliable place recognition, and therefore we learn the model so as to eliminate the dynamic objects. Third, to minimize mis-classifications due to the non-distinctiveness of several places, we restrict the model to output smooth trajectories to minimize mis-classifications, attacking the sequential nature of the visual place recognition problem. The test domain may be somewhat different from the domain in which the place dataset is made, and we, therefore, use transfer learning to extract similar features. Experimental results show improved performance as compared to several state-of-the-art approaches.
C1 [Paturkar, Varun; Yadav, Rohit] Navajna Technol Pvt Ltd, Karan Arcade,Patrika Nagar,HITEC City, Hyderabad 500081, Telangana, India.
   [Yadav, Rohit; Kala, Rahul] Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot, Prayagraj 211012, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Yadav, R (corresponding author), Navajna Technol Pvt Ltd, Karan Arcade,Patrika Nagar,HITEC City, Hyderabad 500081, Telangana, India.; Yadav, R (corresponding author), Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot, Prayagraj 211012, Uttar Pradesh, India.
EM paturkarvarun@gmail.com; rsi2019001@iiita.ac.in; rkala@iiita.ac.in
RI yadav, Rohit/KHU-7975-2024
OI yadav, Rohit/0000-0002-2873-0887
FU The datasets generated during and/or analyzed during the current study
   are available from the corresponding author upon reasonable request.
FX This research is supported by NavAjna Technologies Pvt. Ltd., Science
   and Engineering Research Board (SERB) and FICCI under the Prime Minister
   Fellowship for Doctoral Research.r The datasets generated during and/or
   analyzed during the current study are available from the corresponding
   author upon reasonable request.
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic Relja, 2016, P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI P IEEE C COMPUTER VI
   CALC, 2018, Calc github link
   Chancan M, 2020, arXiv
   Chancán M, 2020, IEEE ROBOT AUTOM LET, V5, P993, DOI 10.1109/LRA.2020.2967324
   Chen ZT, 2017, IEEE INT C INT ROBOT, P9, DOI 10.1109/IROS.2017.8202131
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   FABMAP, 2008, Fabmap github link
   Fooladgar F, 2020, MULTIMED TOOLS APPL, V79, P4499, DOI 10.1007/s11042-019-7684-3
   Garg S., 2021, arXiv
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547
   Hausler S, 2019, IEEE ROBOT AUTOM LET, V4, P1924, DOI 10.1109/LRA.2019.2898427
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Magliani F, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC'18), DOI 10.1145/3243394.3243686
   Merrill N., 2018, arXiv
   NetVLAD, 2016, Netvlad github link
   Neuland R, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01375-5
   Sehar U, 2022, MULTIMED TOOLS APPL, V81, P30519, DOI 10.1007/s11042-022-12821-3
   SequentialVPR, 2023, Sequential visual place reconition
   Sünderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986
   Talbot B, 2018, IEEE INT C INT ROBOT, P7758, DOI 10.1109/IROS.2018.8593761
   Tolias G, 2016, Arxiv, DOI [arXiv:1511.05879, DOI 10.48550/ARXIV.1511.05879]
   Tomita MA, 2021, IEEE ACCESS, V9, P118673, DOI 10.1109/ACCESS.2021.3107778
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790
   Vysotska O, 2019, IEEE ROBOT AUTOM LET, V4, P1730, DOI 10.1109/LRA.2019.2897160
   Wei HY, 2021, MULTIMED TOOLS APPL, V80, P31729, DOI 10.1007/s11042-021-11168-5
   Xin Z, 2017, INT CONF IMAG PROC
   Yadav R, 2023, APPL INTELL, V53, P17593, DOI 10.1007/s10489-022-04415-1
   Yadav R, 2022, APPL INTELL, V52, P11928, DOI 10.1007/s10489-021-03050-6
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366
NR 31
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17404-4
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500015
DA 2024-07-18
ER

PT J
AU Hu, RH
   Li, HJ
   Li, JG
   Wang, ZH
   Wang, BJ
AF Hu, Renhao
   Li, Hongjiao
   Li, Jinguo
   Wang, Zhaohui
   Wang, Baojin
TI Continuous release of temporal correlation location statistics with
   local differential privacy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Streaming data; Continuous observation; Location statistics; Temporal
   correlation; Local differential privacy; w-event privacy
ID LEAKAGE
AB The continuous release of location statistics plays a significant role in various real-world applications, such as traffic management and customization of public services. However, existing literature primarily focuses on static scenarios or perturbing locations at a single timestamp, disregarding the consideration of temporal correlation in mobile users. This oversight leaves the data susceptible to privacy attacks, including inference attacks, resulting in extra privacy leakage. To address this challenge, we propose a Local Differential Privacy Budget Distribution and Streaming Data Releasing (LPBD) mechanism for real-world location datasets. Specifically, we investigate the problem of continuously releasing location statistics for infinite streams while protecting user privacy and quantify the impact of temporal correlation on privacy leakage. The LPBD is a novel w-event level privacy-preserving mechanism, which has the capability to provide an adequate privacy budget for each timestamp and effectively mitigate the privacy leakage problem resulting from temporal correlation. Experimental results demonstrate that LPBD enhances data availability with strong privacy guarantees compared to state-of-the-art baseline methods.
C1 [Hu, Renhao; Li, Hongjiao; Li, Jinguo; Wang, Zhaohui; Wang, Baojin] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
C3 Shanghai University of Electric Power
RP Li, HJ (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
EM hjli@shiep.edu.cn
FU This work was supported by the National Natural Science Foundation of
   China (No. 61702321) [61702321]; National Natural Science Foundation of
   China
FX This work was supported by the National Natural Science Foundation of
   China (No. 61702321)
CR Cao Xuyang, 2022, 2022 IEEE International Conference on Big Data (Big Data), P6605, DOI 10.1109/BigData55660.2022.10021116
   Cao Y, 2019, IEEE T KNOWL DATA EN, V31, P1281, DOI 10.1109/TKDE.2018.2824328
   Cao Y, 2018, PROC VLDB ENDOW, V11, P2090, DOI 10.14778/3229863.3236267
   Chan THH, 2011, ACM T INFORM SYST SE, V14, DOI 10.1145/2043621.2043626
   Chen JW, 2021, IEEE T BIG DATA, V7, P784, DOI 10.1109/TBDATA.2017.2777862
   Chen Y, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1375, DOI 10.1145/3133956.3134102
   Cocchia A, 2014, PROGR IS, P13, DOI 10.1007/978-3-319-06160-3_2
   Cunningham T, 2021, arXiv
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Dwork C, 2010, ACM S THEORY COMPUT, P715
   Erlingsson U, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1054, DOI 10.1145/2660267.2660348
   Errounda FZ, 2021, FUTURE GENER COMP SY, V124, P174, DOI 10.1016/j.future.2021.05.020
   Errounda FZ, 2018, IEEE INT CONF BIG DA, P5147, DOI 10.1109/BigData.2018.8621876
   Fan L., 2012, CIKM, P2169, DOI DOI 10.1145/2396761.2398595
   Fan LY, 2014, IEEE T KNOWL DATA EN, V26, P2094, DOI 10.1109/TKDE.2013.96
   He Yuanyuan, 2022, 2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys), P562, DOI 10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00102
   Hemkumar D, 2021, PEER PEER NETW APPL, V14, P1650, DOI 10.1007/s12083-021-01078-6
   Joseph M, 2018, ADV NEUR IN, V31
   Kellaris G, 2014, PROC VLDB ENDOW, V7, P1155, DOI 10.14778/2732977.2732989
   Li YN, 2019, IEEE T INF FOREN SEC, V14, P2342, DOI 10.1109/TIFS.2019.2895970
   Rafiei M, 2022, LECT NOTES COMPUT SC, V13591, P75, DOI 10.1007/978-3-031-17834-4_5
   Ren XB, 2022, INT CONF MANAGE DATA, P1064, DOI 10.1145/3514221.3526190
   Rong Fang, 2021, Collaborative Computing: Networking, Applications and Worksharing. 16th EAI International Conference, CollaborateCom 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 350), P75, DOI 10.1007/978-3-030-67540-0_5
   Schaler C, 2022, Benchmarking the utility of w-event differential privacy mechanisms-when baselines become mighty competitors
   Wang Han, 2022, CCS '22: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, P2809, DOI 10.1145/3548606.3560636
   Wang Q, 2016, IEEE INFOCOM SER
   Wang Q, 2018, IEEE T DEPEND SECURE, V15, P591, DOI 10.1109/TDSC.2016.2599873
   Wang T., 2021, INT C MOB MULT COMM, P432
   Wang ZB, 2020, IEEE INFOCOM SER, P109, DOI [10.1109/infocom41043.2020.9155290, 10.1109/INFOCOM41043.2020.9155290]
   Xiao YH, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1298, DOI 10.1145/2810103.2813640
   Xiong XX, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102633
   Yuan J, 2013, IEEE T KNOWL DATA EN, V25, P220, DOI 10.1109/TKDE.2011.200
   Zhang XK, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23210
NR 33
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17464-6
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200004
DA 2024-07-18
ER

PT J
AU Liu, Z
   Chen, H
   Kong, X
   Wen, CD
   Chen, J
   Liu, SNYY
   Yang, ZK
AF Liu, Zhi
   Chen, Hao
   Kong, Xi
   Wen, Chaodong
   Chen, Jia
   Liu, Sannyuya
   Yang, Zongkai
TI SegRewardGraph: unsupervised teaching video story segmentation method
   based on subtitle length-rewarding strategy and semantic relatedness
   graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Story segmentation; Teaching video segmentation; Subtitle
   length-rewarding strategy; Semantic relatedness graph; Natural language
   processing
ID SEDUCTIVE DETAILS; TEXT
AB Story segmentation plays an important role in helping students quickly locate key knowledge points within massive and fragmented teaching video resources. It also serves as the basis for accurate searching of valuable teaching video clips. While keyframe-based story segmentation has achieved remarkable results in news videos, achieving accurate story segmentation in teaching videos is challenging. Therefore, we propose an unsupervised teaching video story segmentation method called SegRewardGraph, which utilizes a subtitle length-rewarding strategy and semantic relatedness graphs. SegRewardGraph employs subtitle semantic similarity to divide video stories, ensuring semantic integrity and improving the accuracy of story segmentation. Specifically, SegRewardGraph first uses the Bidirectional Encoder Representation from Transformers (BERT) model combined with first-last-avg pooling to encode semantic vectors for sentences within video stories. Then, it computes similarities between all sentence vectors and utilizes the associations to build semantic relatedness graphs. A subtitle length-rewarding strategy is formulated to evaluate the segmentation effect. Additionally, boundary detection and boundary merging algorithms are designed based on the subtitle length-rewarding strategy to generate effective segmentation suggestions. Finally, the selected boundaries are mapped to keyframes, enabling semantic content-based segmentation of teaching videos. This study verifies the effectiveness of the proposed method using massive open online courses (MOOC) teaching video datasets. Experimental results demonstrate that the model proposed in this paper outperforms existing methods and achieves state-of-the-art results for teaching video segmentation tasks.
C1 [Liu, Zhi; Liu, Sannyuya; Yang, Zongkai] Cent China Normal Univ, Natl Engn Res Ctr Elearning, Wuhan 430079, Hubei, Peoples R China.
   [Liu, Zhi; Chen, Hao; Kong, Xi; Wen, Chaodong; Liu, Sannyuya; Yang, Zongkai] Cent China Normal Univ, Natl Engn Lab Educ Big Data, Wuhan 430079, Hubei, Peoples R China.
   [Chen, Jia] Cent China Normal Univ, Fac Artificial Intelligence Educ, Sch Educ Informat Technol, Wuhan 430079, Hubei, Peoples R China.
C3 Central China Normal University; Central China Normal University;
   Central China Normal University
RP Kong, X (corresponding author), Cent China Normal Univ, Natl Engn Lab Educ Big Data, Wuhan 430079, Hubei, Peoples R China.
EM zhiliu@mail.ccnu.edu.cn; zuoyouhr@mails.ccnu.edu.cn;
   kongxicc@mails.ccnu.edu.cn; chaodongwen@mails.ccnu.edu.cn;
   jc@mail.ccnu.edu.cn; LIUsy5918@gmail.com; 13659885363@163.com
RI Liu, Zhi/AAX-5684-2021
OI Liu, Zhi/0000-0001-5024-9056; Wen, Chaodong/0000-0001-9668-8679
FU This work was supported by the National Natural Science Foundation of
   China (Grant Nos.62377016, 62077017, 61977030,61937001), Hubei
   Provincial Natural Science Foundation (NO.2021CFB539), the Fundamental
   Research Funds of the Central Universities (Grant No [62377016,
   62077017, 61977030,61937001]; National Natural Science Foundation of
   China [2021CFB539]; Hubei Provincial Natural Science Foundation
   [CCNU22QN011, CCNU22LJ005]; Fundamental Research Funds of the Central
   Universities [30106230468]; Innovation Funds in Graduate Education of
   Central China Normal University
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos.62377016, 62077017, 61977030,61937001), Hubei
   Provincial Natural Science Foundation (NO.2021CFB539), the Fundamental
   Research Funds of the Central Universities (Grant Nos. CCNU22QN011,
   CCNU22LJ005) and the Innovation Funds in Graduate Education of Central
   China Normal University (30106230468).
CR Abercrombie S, 2013, CONTEMP EDUC PSYCHOL, V38, P149, DOI 10.1016/j.cedpsych.2013.01.002
   Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen HJ, 2017, IEEE-ACM T AUDIO SPE, V25, P112, DOI 10.1109/TASLP.2016.2626965
   Chifu AG, 2016, PROCEDIA COMPUT SCI, V96, P1371, DOI 10.1016/j.procs.2016.08.182
   Choi FY, 2000, arXiv
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Feng W, 2018, NEUROCOMPUTING, V318, P236, DOI 10.1016/j.neucom.2018.08.061
   Glavas G., 2016, P 5 JOINT C LEX COMP, P125
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   Huang Junjie, 2021, arXiv
   Iikura Riku, 2021, Distributed Computing and Artificial Intelligence, 17th International Conference. Advances in Intelligent Systems and Computing (AISC 1237), P21, DOI 10.1007/978-3-030-53036-5_3
   Kalyuga S, 1999, APPL COGNITIVE PSYCH, V13, P351, DOI 10.1002/(SICI)1099-0720(199908)13:4<351::AID-ACP589>3.0.CO;2-6
   Kannao R, 2020, MULTIMED TOOLS APPL, V79, P6191, DOI 10.1007/s11042-019-08445-9
   Kannao R, 2019, MULTIMED TOOLS APPL, V78, P31925, DOI 10.1007/s11042-019-7699-9
   Koshorek O., 2018, NAACL HLT 2018-2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies-Proceedings of the Conference, V2, P469, DOI [10.18653/v1/n18-2075, DOI 10.18653/V1/N18-2075]
   Lattisi T, 2022, COMPUT INFORM, V41, P78, DOI 10.31577/cai_2022_1_78
   Lee J, 2023, arXiv
   Li B., 2020, arXiv
   Lu M, 2011, 12 ANN C INT SPEECH
   Malioutov IIM, 2006, Minimum cut model for spoken lecture segmentation
   Mautone PD, 2007, J EDUC PSYCHOL, V99, P640, DOI 10.1037/0022-0663.99.3.640
   Merz N, 2016, RES POLITICS, V3, DOI 10.1177/2053168016643346
   Naumann J, 2007, J EDUC PSYCHOL, V99, P791, DOI 10.1037/0022-0663.99.4.791
   Ozcelik E, 2010, COMPUT HUM BEHAV, V26, P110, DOI 10.1016/j.chb.2009.09.001
   Park B, 2011, COMPUT HUM BEHAV, V27, P5, DOI 10.1016/j.chb.2010.05.006
   Porter M. F., 1980, An algorithm for suffix stripping
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Sanchez CA, 2006, MEM COGNITION, V34, P344, DOI 10.3758/BF03193412
   Shahbazi Z., 2020, International Journal of Advanced Science and Technology, V29, P5993
   Stokes N, 2004, AI COMMUN, V17, P3
   Xie L, 2011, INFORM SCIENCES, V181, P2873, DOI 10.1016/j.ins.2011.02.013
   Xie L, 2012, IEEE T AUDIO SPEECH, V20, P276, DOI 10.1109/TASL.2011.2160853
   Yu J, 2018, SIGNAL PROCESS, V142, P403, DOI 10.1016/j.sigpro.2017.07.026
   Zhou TF, 2021, PROC CVPR IEEE, P6981, DOI 10.1109/CVPR46437.2021.00691
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhuo BG, 2023, IEICE T INF SYST, VE106D, P58, DOI 10.1587/transinf.2022EDP7083
NR 37
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17523-y
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200017
DA 2024-07-18
ER

PT J
AU Kathania, HK
   Kadyan, V
   Kadiri, SR
   Kurimo, M
AF Kathania, Hemant Kumar
   Kadyan, Virender
   Kadiri, Sudarsana Reddy
   Kurimo, Mikko
TI Spectral warping based data augmentation for low resource children's
   speaker verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speaker verification; Children's speech; Spectral warping; Low resource
   languages; Speed perturbation; Vocal tract length perturbation
ID LINEAR PREDICTION; FORMANT MODIFICATION; SPEECH; DOMAIN
AB In this paper, we present our effort to develop an automatic speaker verification (ASV) system for low resources children's data. For the children's speakers, very limited amount of speech data is available in majority of the languages for training the ASV system. Developing an ASV system under low resource conditions is a very challenging problem. To develop the robust baseline system, we merged out of domain adults' data with children's data to train the ASV system and tested with children's speech. This kind of system leads to acoustic mismatches between training and testing data. To overcome this issue, we have proposed spectral warping based data augmentation. We modified adult speech data using spectral warping method (to simulate like children's speech) and added it to the training data to overcome data scarcity and mismatch between adults' and children's speech. The proposed data augmentation gives 20.46% and 52.52% relative improvement (in equal error rate) for Indian Punjabi and British English speech databases, respectively. We compared our proposed method with well known data augmentation methods: SpecAugment, speed perturbation (SP) and vocal tract length perturbation (VTLP), and found that the proposed method performed best. The proposed spectral warping method is publicly available at https://github.com/kathania/Speaker-Verification-spectral-warping.
C1 [Kathania, Hemant Kumar; Kadiri, Sudarsana Reddy; Kurimo, Mikko] Aalto Univ, Dept Informat & Commun Engn, Espoo 02150, Finland.
   [Kathania, Hemant Kumar] Natl Inst Technol Sikkim, Dept Elect & Commun Engn, Ravangla 737139, India.
   [Kadyan, Virender] Univ Petr & Energy Studies, Speech & Language Res Ctr, Sch Comp Sci, Dehra Dun, India.
C3 Aalto University; National Institute of Technology (NIT System);
   National Institute of Technology Sikkim; University of Petroleum &
   Energy Studies (UPES)
RP Kadiri, SR (corresponding author), Aalto Univ, Dept Informat & Commun Engn, Espoo 02150, Finland.
EM hemant.ece@nitsikkim.ac.in; vkadyan@ddn.upes.ac.in;
   sudarsana.kadiri@aalto.fi; mikko.kurimo@aalto.fi
RI Kadiri, Sudarsana Reddy/T-8597-2019
OI Kadiri, Sudarsana Reddy/0000-0001-5806-3053
FU This work was supported by the Academy of Finland (grants 329267,
   330139). [329267, 330139]; Academy of Finland
FX This work was supported by the Academy of Finland (grants 329267,
   330139).
CR Batliner A, 2005, P INTERSPEECH, ppp2761
   Battenberg E, 2017, Arxiv, DOI arXiv:1707.07413
   Claus F, 2013, INTERSPEECH, P2409
   Du CP, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5844, DOI 10.1109/ICASSP39728.2021.9414438
   Dua M, 2022, APPL ACOUST, V190, DOI 10.1016/j.apacoust.2022.108643
   Eguchi S, 1969, Acta Otolaryngol Suppl, V257, P1
   Fainberg J, 2016, INTERSPEECH, P1598, DOI 10.21437/Interspeech.2016-1348
   Hautamäki RG, 2019, J ACOUST SOC AM, V146, P693, DOI 10.1121/1.5119240
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kanagasundaram A, 2019, A study of x-vector based speaker recognition on short utterances
   Kaseva T., 2021, P 23 NORD C COMP LIN, P86
   Kathania H, 2020, INTERSPEECH, P260, DOI 10.21437/Interspeech.2020-2199
   Kathania HK, 2022, SPEECH COMMUN, V136, P98, DOI 10.1016/j.specom.2021.11.003
   Kathania HK, 2020, INT CONF ACOUST SPEE, P7429, DOI [10.1109/ICASSP40776.2020.9053334, 10.1109/icassp40776.2020.9053334]
   KENT RD, 1976, J SPEECH HEAR RES, V19, P421, DOI 10.1044/jshr.1903.421
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   LAINE UK, 1994, INT CONF ACOUST SPEE, P349
   Laptik R, 2017, P OP C EL EL INF SCI, ppp1
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Povey D, 2015, Arxiv, DOI arXiv:1410.7455
   ROBINSON T, 1995, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1995.479278
   Roccetti DGCLM, 2019, J Big Data
   Safavi S, 2012, PROC INTERSPEECH VOL
   Shahnawazuddin S, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103115
   Shahnawazuddin S, 2020, INT CONF ACOUST SPEE, P7554, DOI 10.1109/ICASSP40776.2020.9053891
   Shahnawazuddin S, 2020, PATTERN RECOGN LETT, V131, P213, DOI 10.1016/j.patrec.2019.12.019
   Smith JO, 1999, IEEE T SPEECH AUDI P, V7, P697, DOI 10.1109/89.799695
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   STRUBE HW, 1980, J ACOUST SOC AM, V68, P1071, DOI 10.1121/1.384992
   Tydlitát B, 2007, INT CONF ACOUST SPEE, P293
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17263-z
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500011
OA hybrid
DA 2024-07-18
ER

PT J
AU Pandey, SK
   Bhandari, AK
AF Pandey, Sanat Kumar
   Bhandari, Ashish Kumar
TI Morphological transfer learning based brain tumor detection using YOLOv5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Transfer learning; Brain tumor; Brain tumor detection;
   YOLOv5
ID COMPUTER-AIDED DIAGNOSIS; NEURAL-NETWORK; CLASSIFICATION; SEGMENTATION;
   MRI; MODEL
AB Medical experts require an efficient tool that provides highly accurate diagnoses of patients for early and precise detection of the severity of brain tumours using brain magnetic resonance imaging (MRI). We propose a deep learning-based transfer learning technique that uses filtering methods on the test dataset to improve accuracy and performance efficiency. In this paper, we propose a morphological approach based on You Only Look Once, i.e., the YOLOv5 automated technique, to achieve accurate brain tumour findings. We also compare the proposed method in this manuscript to a number of well-known deep learning-based object detection frameworks and algorithms, such as AlexNet, ResNet-50, GoogleNet, MobileNet, VGG-16, YOLOv3 Pytorch, YOLOv4 Darknet, and YOLOv4-Tiny, and discover that the YOLOv5 model performs the best among them all. The RSNA-ASNR-MICCAI Brain Tumour Segmentation (BraTS21) Challenge 2021 dataset is used in this study to train the various models using a transfer learning methodology. Following thorough analysis, we discovered that the YOLOv5 model outperforms all other models taken into consideration with a mAP@ 0.5 score of 94.7%. With an MRI test dataset that had been morphologically filtered, it also improved to a mAP@ 0.5 score of 97.2%.
C1 [Pandey, Sanat Kumar; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM sanatp.phd20.ec@nitp.ac.in; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
CR Abdulsalam YS, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14010011
   Al-masni MA, 2017, IEEE ENG MED BIO, P1230, DOI 10.1109/EMBC.2017.8037053
   Ali H., 2017, SCIREA J Comput, V2, P12, DOI DOI 10.5772/INTECHOPEN.72427
   Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   Ananda Resmi S., 2012, 2012 5th International Conference on BioMedical Engineering and Informatics (BMEI), P238, DOI 10.1109/BMEI.2012.6512995
   Avsar E, 2019, TEH GLAS, V13, P337, DOI 10.31803/tg-20190712095507
   Azougaghe A, 2015, INT CONF INTELL SYST, P421, DOI 10.1109/ISDA.2015.7489267
   Bentajer A, 2018, PROCEDIA COMPUT SCI, V141, P559, DOI 10.1016/j.procs.2018.10.126
   Bhanothu Y, 2020, INT CONF ADVAN COMPU, P248, DOI [10.1109/ICACCS48705.2020.9074375, 10.1109/icaccs48705.2020.9074375]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen SN, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106120
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Cherukuri V, 2018, IEEE T BIO-MED ENG, V65, P1871, DOI 10.1109/TBME.2017.2783305
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dipu Nadim Mahmud, 2021, 2021 International Conference on Intelligent Technologies (CONIT), DOI 10.1109/CONIT51480.2021.9498384
   Dipu NM, 2021, 2021 INT C SCI CONT, P1, DOI [10.1109/ICSCT53883.2021.9642649, DOI 10.1109/ICSCT53883.2021.9642649]
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Du J, 2017, IEEE T IMAGE PROCESS, V26, P5855, DOI 10.1109/TIP.2017.2745202
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Fan Xu, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P236, DOI 10.1109/ICIVC47709.2019.8981027
   Futrega M, 2022, LECT NOTES COMPUT SC, V12963, P15, DOI 10.1007/978-3-031-09002-8_2
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Gurbina M, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P505, DOI [10.1109/TSP.2019.8769040, 10.1109/tsp.2019.8769040]
   Hammami M, 2020, INT CONF IMAG PROC, DOI 10.1109/ipta50016.2020.9286712
   Harish P, 2020, WITHDRAWN: MRI based detection and classification of brain tumor using enhanced faster R-CNN and Alex Net model, DOI [10.1016/j.matpr.2020.11.495, DOI 10.1016/J.MATPR.2020.11.495]
   Hedabou M, 2021, LECT NOTES COMPUT SC, V13041, P289, DOI 10.1007/978-3-030-92708-0_18
   Huang ZG, 2020, IEEE ACCESS, V8, P89281, DOI 10.1109/ACCESS.2020.2993618
   Jemimma T. A., 2018, 2018 International Conference on Smart Systems and Inventive Technology (ICSSIT), P155, DOI 10.1109/ICSSIT.2018.8748436
   Jia Z., 2020, IEEE Access, DOI [10.1109/ACCESS.2020.3016319, DOI 10.1109/ACCESS.2020.3016319]
   Jiang SC, 2017, EXPERT SYST APPL, V82, P216, DOI 10.1016/j.eswa.2017.04.017
   Kaluri R, 2021, Arxiv, DOI [arXiv:2102.06026, DOI 10.48550/ARXIV.2102.06026]
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Kapoor L, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P582, DOI 10.1109/CONFLUENCE.2017.7943218
   Khan P, 2021, IEEE ACCESS, V9, P37622, DOI 10.1109/ACCESS.2021.3062484
   Krawczyk Z, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206783
   Krawczyk Z, 2018, PROCEEDINGS OF 19TH INTERNATIONAL CONFERENCE COMPUTATIONAL PROBLEMS OF ELECTRICAL ENGINEERING
   Krishna S., 2019, International Journal of Recent Technology and Engineering (IJRTE), V7, P427
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Kumar N. Suresh, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P578, DOI 10.1109/ICACITE51222.2021.9404656
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Lakshmanna K., 2016, Int. J. Intellig. Eng. Syst, V9, P157, DOI 10.22266/ijies2016.1231.17
   Lakshmanna K, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101604
   Lakshmanna K, 2018, J INTELL SYST, V27, P349, DOI 10.1515/jisys-2016-0111
   Li Meian, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1995/1/012046
   Lu SY, 2020, PATTERN RECOGN LETT, V140, P252, DOI 10.1016/j.patrec.2020.10.017
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Majib MS, 2021, IEEE ACCESS, V9, P116942, DOI 10.1109/ACCESS.2021.3105874
   Montalbo FJP, 2020, KSII T INTERNET INF, V14, P4816, DOI 10.3837/tiis.2020.12.011
   Nie YL, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/ehb47216.2019.8970033
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Ostrom QT, 2022, NEURO-ONCOLOGY, V24, pv1, DOI 10.1093/neuonc/noac202
   Panda B, 2019, Int J Sci Res Sci Technol, V6, P346, DOI [10.32628/IJSRST20717, DOI 10.32628/IJSRST20717, 10.32628/ijsrst20717]
   Papiez BW, 2015, LECT NOTES COMPUT SC, V9351, P427, DOI 10.1007/978-3-319-24574-4_51
   Peiris H, 2022, LECT NOTES COMPUT SC, V12962, P171, DOI 10.1007/978-3-031-08999-2_13
   Pereira Sergio, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P106, DOI 10.1007/978-3-030-02628-8_12
   Qi KH, 2019, LECT NOTES COMPUT SC, V11766, P247, DOI 10.1007/978-3-030-32248-9_28
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   RajMohan K, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P566, DOI 10.1109/ICIIP.2013.6707655
   Ramesh S, 2021, MULTIMED TOOLS APPL, V80, P11789, DOI 10.1007/s11042-020-10351-4
   Rao CS, 2022, MULTIMED TOOLS APPL, V81, P7393, DOI 10.1007/s11042-021-11821-z
   Ravikumar M, 2021, TEH GLAS, V15, P37, DOI 10.31803/tg-20210204162414
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5211949
   Roy Sunita., 2021, Adv Comput Syst Security, V14, P179, DOI [10.1007/978-981-16-4294-4_12, DOI 10.1007/978-981-16-4294-4_12]
   Salama WM, 2022, MULTIMED TOOLS APPL, V81, P16441, DOI 10.1007/s11042-022-12362-9
   Saxena P, 2021, Innovations in Computational Intelligence and Computer Vision, P275, DOI [10.1007/978-981-15-6067-5_30, DOI 10.1007/978-981-15-6067-5_30]
   Sekhar A, 2022, IEEE J BIOMED HEALTH, V26, P983, DOI 10.1109/JBHI.2021.3100758
   Sharif Irfan M, 2019, Int J Eng Res Technol (IJERT), V8, P2278, DOI [10.32628/IJERT81S120190, DOI 10.32628/IJERT81S120190]
   Sharif M, 2020, NEURAL COMPUT APPL, V32, P15975, DOI 10.1007/s00521-019-04679-8
   Shen HC, 2017, IEEE IMAGE PROC, P1727, DOI 10.1109/ICIP.2017.8296577
   Shuteng Niu, 2020, IEEE Transactions on Artificial Intelligence, V1, P151, DOI 10.1109/TAI.2021.3054609
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somasundaram S., 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P217, DOI 10.1109/COMITCon.2019.8862209
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Vivanti R, 2018, MED BIOL ENG COMPUT, V56, P1699, DOI 10.1007/s11517-018-1803-6
   Wang Yu, 2012, About us, P187, DOI [10.1016/j.media.2017.06.014, DOI 10.1016/J.MEDIA.2017.06.014]
   Wozniak M, 2023, NEURAL COMPUT APPL, V35, P14611, DOI 10.1007/s00521-021-05841-x
   Wulandari A, 2018, 2018 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P292, DOI 10.1109/KCIC.2018.8628591
   Xue JH, 2003, PATTERN RECOGN LETT, V24, P2549, DOI 10.1016/S0167-8655(03)00100-4
   Younis A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147282
   Zerhouni K, 2021, IEEE ACCESS, V9, P69426, DOI 10.1109/ACCESS.2021.3078252
NR 85
TC 0
Z9 0
U1 11
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17367-6
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500006
DA 2024-07-18
ER

PT J
AU de la Sotta, T
   Chang, VLT
   Pizarro, B
   Henriquez, H
   Alvear, N
   Saavedra, JM
AF de la Sotta, Tomas
   Chang, Violeta
   Pizarro, Benjamin
   Henriquez, Hector
   Alvear, Nicolas
   Saavedra, Jose M.
TI Impact of attention mechanisms for organ segmentation in chest x-ray
   images over U-Net model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention mechanism; Chest x-ray segmentation; U-Net; Encoder variation
ID RADIOGRAPHS
AB Chest x-ray images are one of the most commonly performed imaging tests, providing crucial clinical information about structures like the heart, lungs, ribs, bones, and blood vessels. In this context, image segmentation is a critical stage as it aims to separate significant parts of an image. However, manual image segmentation presents serious difficulties that can be tackled using deep learning-based methods, such as U-Net. Furthermore, attention mechanisms have attracted the interest of the machine-learning community and can bring improvements in medical image segmentation. This research aims to assess the impact of attention-based mechanisms for segmenting different organs in chest X-ray images, like heart, lungs, clavicles and ribs, over the well-known U-Net architecture as a baseline. We study five U-Net encoder variations, replacing the U-Net encoder with ResNet 18, 34 and 50, Swin Transformer and a simple residual structure comprised of a single ResNet-50 prior to each U-Net encoder layer. In the original U-Net, the skip layers are identity layers connecting each encoder block with its corresponding decoder one. Here, we replace these layers with different attention mechanisms: spatial attention, full spatial attention, double spatial attention, multiple spatial attention, spatial cross-attention and Swin spatial cross-attention. Each encoder variation and attention mechanism was evaluated from scratch and on a pre-trained scenario, independently for lungs, ribs, heart and clavicles. ResNet-UNet-18 achieves up to 0.96 and 0.53 of average overlapping with hand-segmented masks of lungs and clavicles, respectively. The best encoder for rib and heart segmentation was Residual U-Net, with 0.88 and 0.83 overlapping, respectively. Furthermore, for attention mechanisms, the most suitable were selected according to overlapping with hand-segmented masks as Spatial Attention U-Net for lungs (0.96), Three-Head Attention for ribs (0.88), Full Spatial Attention for the heart (0.82) and Spatial Cross-Attention for clavicles (0.54). Encoder variations and attention mechanism have a positive impact over a U-Net for segmentation of lungs, ribs, heart and clavicles from scratch, without transfer learning. Moreover, the encoder and the attention mechanism are not universal for segmenting different organs in chest X-ray images. While organs share the same backbone architecture (lungs and clavicles), the most appropriate attention mechanisms for each organ are all different, achieving up to 0.99 of overlapping in lung segmentation.
C1 [de la Sotta, Tomas; Pizarro, Benjamin; Alvear, Nicolas] RetinaRX, Quimera 231, Valparaiso, Chile.
   [Chang, Violeta] Univ Santiago Chile, Dept Ingn Informat, Ave Victor Jara 3659, Estn Cent, RM, Chile.
   [Pizarro, Benjamin] Univ Chile, Fac Med, Dept Neurociencia, Ave Independencia 1027,Independencia, Santiago 646, RM, Chile.
   [Henriquez, Hector; Saavedra, Jose M.] Univ Andes, Monsenor Alvaro Portillo, Santiago 12455, RM, Chile.
   [Henriquez, Hector] Clin Santa Maria, Serv Radiol, Ave St Maria 0500,Providencia, Santiago 650, RM, Chile.
C3 Universidad de Chile; Universidad de los Andes - Chile
RP Saavedra, JM (corresponding author), Univ Andes, Monsenor Alvaro Portillo, Santiago 12455, RM, Chile.
EM tomas@retinarx.cl; violeta.chang@usach.cl; benjamin@retinarx.cl;
   hhenriquez@miuandes.cl; nicolas@retinarx.cl; jmsaavedrar@miuandes.cl
OI Saavedra Rondo, Jose Manuel/0000-0002-9644-5164
CR Agrawal T, 2023, VISUAL COMPUT, V39, P875, DOI 10.1007/s00371-021-02352-7
   Astley JR, 2022, BRIT J RADIOL, V95, DOI 10.1259/bjr.20201107
   Brady AP., 2022, Insights Imaging, V13, P9167391
   Broder J., 2011, Diagnostic Imaging for the Emergency Physician, P185, DOI [10.1016/B978-1-4160-6113-7.10005-5, DOI 10.1016/B978-1-4160-6113-7.10005-5]
   Cao FD, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050814
   Chavan M, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10050105
   Cheng PM, 2021, RADIOGRAPHICS, V41, P1427, DOI 10.1148/rg.2021200210
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Ganguly D, 2010, Medical Imaging: A review, V78, P504
   Goodman MD, 2010, AM J SURG, V199, P199, DOI 10.1016/j.amjsurg.2009.03.011
   Gunderman R, 2001, ACAD RADIOL, V8, P1252, DOI 10.1016/S1076-6332(03)80708-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong SJ, 2019, J BELG SOC RADIOL, V103, DOI 10.5334/jbsr.1764
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jaeger S, 2014, IEEE T MED IMAGING, V33, P233, DOI 10.1109/TMI.2013.2284099
   Jan J., 2005, Medical Image Processing, Reconstruction and Restoration: Concepts and methods, DOI [10.1201/9781420030679, DOI 10.1201/9781420030679]
   Koffka Kurt, 2013, PRINCIPLES GESTALT P
   Liu WF, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12743-y
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mittal A, 2018, WIRELESS PERS COMMUN, V101, P511, DOI 10.1007/s11277-018-5702-9
   Nguyen H, 2021, P MED IM DEEP LEARN
   Novikov AA, 2018, IEEE T MED IMAGING, V37, P1865, DOI 10.1109/TMI.2018.2806086
   Ou XY, 2021, RESEARCH-CHINA, V2021, DOI 10.34133/2021/9892152
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Palmer S., 1999, VISION SCI PHOTONS P
   Rashid R, 2018, LECT NOTES COMPUT SC, V10882, P71, DOI 10.1007/978-3-319-93000-8_9
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rontgen W C, 1896, Science, V3, P227, DOI 10.1126/science.3.59.227
   ROTE G, 1991, INFORM PROCESS LETT, V38, P123, DOI 10.1016/0020-0190(91)90233-8
   Sander J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77733-4
   Satia I, 2013, CLIN MED, V13, P349, DOI 10.7861/clinmedicine.13-4-349
   Seibert JA, 1997, RADIOGRAPHICS, V17, P1533, DOI 10.1148/radiographics.17.6.9397462
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Sun HF, 2023, QUANT IMAG MED SURG, V13, P394, DOI 10.21037/qims-22-610
   Sussmann AR, 2010, CLIN RADIOL, V65, P155, DOI 10.1016/j.crad.2009.10.005
   Tunguturi M, 2022, Int J Innovations Eng Res & Technol, V9, P37
   Ullah I., 2023, Sci Rep, V13, P2023
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   Vaswani A, 2017, ADV NEUR IN, V30
   Waite S, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00213
   Wang WJ, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/2785464
   Yahyatabar M, 2020, IEEE ENG MED BIO, P1242, DOI [10.1109/EMBC44109.2020.9176033, 10.1109/embc44109.2020.9176033]
   Zdora M., 2021, Principles of X-ray Imaging, P11
   Zhang B, 2021, J APPL CLIN MED PHYS, V22, P45, DOI 10.1002/acm2.13394
   Zhou S. K., 2015, Medical Image Recognition, Segmentation and Parsing: Machine Learning and Multiple Object Approaches
NR 49
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17220-w
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500008
DA 2024-07-18
ER

PT J
AU Nigus, EA
   Taye, GB
   Girmaw, DW
   Salau, AO
AF Nigus, Eyerusalem Assefa
   Taye, Getie Balew
   Girmaw, Dagne Walle
   Salau, Ayodeji Olalekan
TI Development of a Model for Detection and Grading of Stem Rust in Wheat
   Using Deep Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stem rust; Deep learning; CNN; Gabor filter
AB Stem rust is a highly prevalent and damaging fungal disease that affects wheat crops worldwide. It is caused by the Puccinia graminis f. sp. tritici fungus, and can significantly reduce wheat production and quality, by 10% to 50%. In severe cases, it causes up to a 90% decrease in grain yield if left uncontrolled. Manual diagnosis by pathologists and experts which use visual inspection is usually costly, time-consuming, and prone to errors. Moreover, the scarcity of pathologists in rural areas poses a challenge in detecting and grading wheat stem rust. To address these issues, this study presents a system for automated detection and classification of wheat stem rust based on the modified Cobbs scale (CIMMYT) guidelines. The system employs image pre-processing techniques such as adaptive thresholding for segmentation and the Gabor filter for feature extraction which enhances textural features to identify key disease characteristics. For disease classification, a deep learning approach was utilized which employs a 12-way Softmax to assign specific classes: Resistant (tR), Moderately resistant (MR), and Susceptible (S). The proposed model is trained and tested using an image dataset collected in collaboration with pathologists from Haramaya University. The proposed model achieves a training accuracy of 92.02% and a testing accuracy of 92.01% in grading wheat stem rust, outperforming state-of-the-art models such as CNN. The study's main achievements are achieved in the areas of real-time monitoring, and grading precision. Real-time monitoring provides timely updates on disease presence and severity, enabling proactive management and minimizing crop losses. Grading precision offers a quantitative assessment of disease damage, facilitating targeted treatment strategies and resource allocation.
C1 [Nigus, Eyerusalem Assefa] Haramaya Univ, Dept Informat Technol, Haramaya, Ethiopia.
   [Taye, Getie Balew] Univ Gondar, Dept Informat Technol, Gondar, Ethiopia.
   [Girmaw, Dagne Walle] Haramaya Univ, Dept Informat Technol, Dire Dawa, Ethiopia.
   [Salau, Ayodeji Olalekan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Olalekan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
C3 Haramaya University; University of Gondar; Haramaya University; Saveetha
   Institute of Medical & Technical Science; Saveetha School of Engineering
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
EM eyerusalemassefa6@gmail.com; getiebalew00@gmail.com;
   dagnewalle143@gmail.com; ayodejisalau98@gmail.com
RI salau, ayodeji Olalekan/C-1016-2018
OI salau, ayodeji Olalekan/0000-0002-6264-9783; Taye, Getie
   Balew/0009-0008-6993-0712
FU Not applicable
FX Not applicable
CR Abed S, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P297, DOI 10.1109/ISCAIE.2018.8405488
   Abeje BT., 2022, J. Electr. Electron. Eng., V15, P5
   Abeje BT., 2022, 2022 INT C INN INT I, P434, DOI [10.1109/3ICT56508.2022.9990780, DOI 10.1109/3ICT56508.2022.9990780]
   Abrahim A, 2018, Int J Sci Res Publ, V8, DOI [10.29322/IJSRP.8.11.2018.p8328, DOI 10.29322/IJSRP.8.11.2018.P8328]
   Adhikari S., 2018, RESEARCHGATE
   Al-Hiary H, 2011, International Journal of Computer Applications
   Alemu W., 2016, Plant, V4, P14, DOI 10.11648/j.plant.20160403.11
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Belay Abebech Jenber, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.100970
   Bezabih YA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-42843-2
   Dash Arabinda, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101363
   De Wolf E., 2011, Identification and Management of Stem Rust on Wheat and Barley
   Ermon S, 2017, Monitoring Ethiopian Wheat Fungus with satelite imagery and deep feature learning
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gaikwad VP, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P110, DOI 10.1109/ICISIM.2017.8122158
   Islam T, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P62, DOI 10.1109/ICICCT.2018.8473322
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Ma, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P279
   Mandar D., 2015, International Journal of Advanced Technology in Engineering and Science, V2015
   Militante SV, 2019, PROCEEDINGS OF THE 2019 IEEE EURASIA CONFERENCE ON IOT, COMMUNICATION AND ENGINEERING (ECICE), P575, DOI 10.1109/ecice47484.2019.8942690
   MVE Alehegn, 2020, Maize Leaf Diseases Recognition and Classifiaction Based on Imaging and Machine Learning Techniques
   Panchal VC, 2019, 4 INT C COMP SYST IN, P1
   Salau Ayodeji Olalekan, 2023, 2023 INT C CYB MAN E, P344
   Tadesse K., 2009, East African Journal of Sciences, V3, P178
   Wahab AHB, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P57, DOI [10.1109/ICISPC.2019.8935722, 10.1109/icispc.2019.8935722]
   Wallelign S., 2012, ARTIF INTELL
   Wang H, 2012, IFIP Advances in Information and Communication Technology, P163, DOI [10.1007/978-3-642-27275-2_18, DOI 10.1007/978-3-642-27275-2_18]
   Wu G, 2017, INT C INF COMM TECHN
   Xiao DDL, 2017, Evaluation and identification of stem rust resistance genes Sr2, Sr24, Sr25, Sr26, Sr31 and Sr38 in wheat lines from Gansu Pro
   Zhang X, 2019, A Deep Learning-Based Approach for Automated Yellow Rust Disease Detection from High-ResolutionHyperspectral UAV Images
NR 30
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17434-y
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300014
DA 2024-07-18
ER

PT J
AU Gu, Y
   Yu, Q
   Xue, WL
AF Gu, Yue
   Yu, Qiang
   Xue, Wanli
TI Enhanced decoupling graph convolution network for skeleton-based action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Graph convolution networks; Attention mechanism
AB In skeleton-based action recognition, graph convolution networks have been widely applied and very successful. However, because graph convolution is a local operation with a small field of perception, it cannot investigate well for the connections between joints that are far apart in the skeleton graph. In addition, graph convolution makes all channels share the same adjacency matrix, which causes the topology learned to be the same among different channels, which limits the ability of graph convolution to learn topological information. In this paper, we propose an enhanced decoupling graph convolution network that effectively expands the perceptual field of the graph convolution by adding additional graphs, and the decoupled feature fusion mechanism increases its expressive power. In addition, we introduce an attention mechanism in the model to obtain the important elements in the whole feature map from both spatial and temporal dimensions simultaneously, so that the graph convolution can focus on the important elements more precisely and efficiently and suppress the influence of irrelevant elements on the model performance. To validate the effectiveness and advancedness of the proposed model, we conducted extensive experiments on three large datasets: NTU RGB+D 60, NTU RGB+D120 and Northwestern-UCLA. On the NTU RGB+D 60 dataset, the accuracy of our model archieves 91.6% and 96.5% on the two protocols.
C1 [Gu, Yue; Yu, Qiang; Xue, Wanli] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.
   [Gu, Yue; Xue, Wanli] Tianjin Univ Technol, Engn Res Ctr Learning Based Intelligent Syst, Minist Educ, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology
RP Gu, Y; Xue, WL (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.; Gu, Y; Xue, WL (corresponding author), Tianjin Univ Technol, Engn Res Ctr Learning Based Intelligent Syst, Minist Educ, Tianjin 300384, Peoples R China.
EM guyue@email.tjut.edu.cn; yu@stud.tjut.edu.cn; xuewanli@email.tjut.edu.cn
RI Gu, Yue/AAZ-5063-2021
OI Gu, Yue/0000-0002-2425-7551
FU This research was supported by the National Natural Science Foundation
   ofChina (61806145, 62376197, 61906135, 62020106004, 92048301) and the
   Natural Science Foundation of Tianjin City (21JCQNJC01510). [61806145,
   62376197, 61906135, 62020106004, 92048301]; National Natural Science
   Foundation ofChina [21JCQNJC01510]; Natural Science Foundation of
   Tianjin City
FX This research was supported by the National Natural Science Foundation
   ofChina (61806145, 62376197, 61906135, 62020106004, 92048301) and the
   Natural Science Foundation of Tianjin City (21JCQNJC01510).
CR Abu-El-Haifa S, 2019, PR MACH LEARN RES, V97
   Atwood J, 2016, ADV NEUR IN, V29
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen Z, 2021, AAAI CONF ARTIF INTE, V35, P1113, DOI 10.1145/3474085.3475574
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Defferrard M, 2016, ADV NEUR IN, V29
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li C, 2018, Arxiv, DOI arXiv:1804.06055
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13393, DOI 10.1109/ICCV48922.2021.01316
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Xu K., 2018, arXiv, DOI DOI 10.48550/ARXIV.1810.00826
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang JX, 2022, CAAI T INTELL TECHNO, V7, P46, DOI 10.1049/cit2.12012
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
NR 41
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17176-x
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500005
DA 2024-07-18
ER

PT J
AU Elen, A
   Turan, MK
AF Elen, Abdullah
   Turan, M. Kamil
TI Design of a low-cost and fully automated digital microscope system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autofocus; Automated microscope; Medical device design; Optics
ID AUTOFOCUS
AB Microscopes are indispensable devices of laboratories. They are widely used in industry and science, such as medicine, geology, biology, chemistry and so on. Thanks to the developing technology, manual microscopes are leaving their place to automatic systems. However, automatic microscopy systems are difficult to obtain due to their high costs. The best way to circumvent this problem is to reduce device costs as much as possible. Based on this idea, a fully automated digital microscope system (FADMS) has been proposed as a low-cost prototype. The FADMS can scan and autofocus for various microscopic samples. In addition, it can be controlled over the internet thanks to a developed software and can store scanned microscopic images. The total cost of the developed system is around 2500 US dollars. In experimental studies, mechanical motion sensitivity and focusing tests of the FADMS were performed. Five different methods were tested on peripheral blood smear images for autofocus. According to the results obtained based on six different measurement criteria, Brenner's and Geusebroek's method showed the best performance. In positioning tests for the mechanical stage (X and Y axes), the motors in the driving system were moved forward and backward for a distance of 100 mu m. The results obtained showed a deviation of 2.6 mu m for the X-axis and 3.6 mu m for the Y-axis. Experimental results show that micron-sized biological cells can be observed in detail. The FADMS has been designed in a modular structure that allows it to be replaced with lighting, optical system and imaging device alternatives. In terms of performance/cost ratio, the FADMS is attractive for high-throughput microscopy applications ranging from digital pathology to health screening in low-income countries and is considered to be an alternative solution for many industries.
C1 [Elen, Abdullah] Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Dept Software Engn, TR-10200 Balikesir, Turkiye.
   [Turan, M. Kamil] Karabuk Univ, Fac Med, Dept Med Biol, Karabuk, Turkiye.
C3 Bandirma Onyedi Eylul University; Karabuk University
RP Elen, A (corresponding author), Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Dept Software Engn, TR-10200 Balikesir, Turkiye.
EM aelen@bandirma.edu.tr
RI Elen, Abdullah/A-8678-2015
OI Elen, Abdullah/0000-0003-1644-0476
FU Karabuk University [KBU-BAP15/2-DR-003]
FX This work was supported by research fund of the Karabuk University,
   Project Number: KBU-BAP15/2-DR-003.
CR [Anonymous], 2022, Arduino Math Functions
   BRENNER JF, 1976, J HISTOCHEM CYTOCHEM, V24, P100, DOI 10.1177/24.1.1254907
   Campbell RAA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088977
   Chen XD, 2011, ANAL CELL PATHOL, V34, P5, DOI [10.1155/2011/150563, 10.3233/ACP-2011-0006]
   Ciorap M., 2022, IOP Conference Series: Materials Science and Engineering, DOI 10.1088/1757-899X/1254/1/012041
   Das D, 2022, MALARIA J, V21, DOI 10.1186/s12936-022-04146-1
   De NK, 2012, Electric machines and electric drives: problems with solutions, P181
   Elen A, 2019, INT SCI VOC STUD C E, P2
   Elen A., 2019, Uluslar. Muhendis. Arast. Ve Gelistirme Derg, P141
   Elen A, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106855
   Elen A, 2018, INT J ADV APPL SCI, V5, P81, DOI 10.21833/ijaas.2018.01.011
   FIRESTONE L, 1991, CYTOMETRY, V12, P195, DOI 10.1002/cyto.990120302
   Ganesan M, 2022, MICROSC RES TECHNIQ, V85, P3484, DOI 10.1002/jemt.24205
   Geusebroek JM, 2000, CYTOMETRY, V39, P1
   Gulfan CNAM., 2022, Procedia Comput Sci, V197, P309, DOI [10.1016/j.procs.2021.12.145, DOI 10.1016/J.PROCS.2021.12.145]
   Hosseinpour F., 2009, World Academy of Science, Engineering and Technology, V51, P292
   Houwen B., 2001, Lab Hematol, V7, P89, DOI DOI 10.1182/ASHEDUCATION-2012.1.475
   Hunde BR, 2022, RESULTS ENG, V14, DOI 10.1016/j.rineng.2022.100478
   Johansson J, 2011, J MANUF SCI E-T ASME, V133, DOI 10.1115/1.4005355
   Koelemeijer S, 2006, INT FED INFO PROC, V198, P267
   Kunt ED, 2011, TURK J ELECTR ENG CO, V19, P973, DOI 10.3906/elk-1005-566
   Lu Q, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194063
   Mallawaarachchi S, 2015, 2015 8TH BIOMEDICAL ENGINEERING INTERNATIONAL CONFERENCE (BMEICON)
   Mateos-Pérez JM, 2012, CYTOM PART A, V81A, P213, DOI 10.1002/cyto.a.22020
   Masters BR., 2008, Encyclopedia of Life Sciences, P1, DOI [10.1002/9780470015902.a0003082, DOI 10.1002/9780470015902.A0003082]
   Mohan NAP., 2017, Indian J Emerg Electron Comput Commun, V4, P602
   Moreno XC, 2023, HARDWAREX, V13, DOI 10.1016/j.ohx.2023.e00400
   Murali S, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5022549
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Naz SA, 2023, J CHROMATOGR A, V1695, DOI 10.1016/j.chroma.2023.463931
   Nnodim T., 2021, IAES International Journal of Robotics and Automation, V1, P24, DOI [10.11591/ijra.v10i1, DOI 10.11591/IJRA.V10I1]
   Rashed BM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22187065
   Salido J, 2022, MICROSC RES TECHNIQ, V85, P3270, DOI 10.1002/jemt.24200
   Samanta B., 2023, Introduction to Mechatronics: an Integrated Approach, P265, DOI [10.1007/978-3-031-29320-7_10, DOI 10.1007/978-3-031-29320-7_10]
   Santos A, 1997, J MICROSC-OXFORD, V188, P264, DOI 10.1046/j.1365-2818.1997.2630819.x
   Schaefer S, 2012, APPL OPTICS, V51, P2581, DOI 10.1364/AO.51.002581
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Stergar J, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052374
   Tomari R, 2014, PROCEDIA COMPUT SCI, V42, P206, DOI 10.1016/j.procs.2014.11.053
   Vakondios DG, 2020, ADV COMPUT DES, V5, P13, DOI 10.12989/acd.2020.5.1.013
   Vargas C, 2006, EL ROB AUT MECH C ME, P1, DOI [10.1109/cerma.2006.5, DOI 10.1109/CERMA.2006.5]
   VOLLATH D, 1988, J MICROSC-OXFORD, V151, P133, DOI 10.1111/j.1365-2818.1988.tb04620.x
   Walzik MP, 2015, BIOSENS BIOELECTRON, V64, P639, DOI 10.1016/j.bios.2014.09.061
   Yilmaz H, 2017, ENG TECHNOL APPL SCI, V7, P2160
   Zhang J, 2021, J SENSORS, V2021, DOI 10.1155/2021/5643054
   Zheng C., 2014, Procedia CIRP, V21, P282, DOI [10.1016/j.procir.2014.03.176, DOI 10.1016/J.PROCIR.2014.03.176]
   Zheng C, 2017, RES ENG DES, V28, P333, DOI 10.1007/s00163-016-0243-2
NR 47
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17453-9
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700003
DA 2024-07-18
ER

PT J
AU Singh, LK
   Khanna, M
   Thawkar, S
   Singh, R
AF Singh, Law Kumar
   Khanna, Munish
   Thawkar, Shankar
   Singh, Rekha
TI A novel hybridized feature selection strategy for the effective
   prediction of glaucoma in retinal fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Glaucoma prediction; Retinal fundus images; Grey wolf algorithm; Whale
   optimization algorithm; Hybrid approach
ID COMPUTER-AIDED DIAGNOSIS; WAVELET TRANSFORM; CLASSIFICATION; CANCER;
   OPTIMIZATION; SYSTEM; TEXTURE
AB Feature selection (FS) is crucial to transforming high-dimensional data into low-dimensional data. The FS approach selects influential traits and ignores the rest. This approach improves machine learning (ML) classifiers by reducing computational complexity and solution time. This empirical study presents a novel and effective methodology that uses two contemporary state-of-the-art soft-computing algorithms, the Grey Wolf Optimizer (GWO) and the Whale Optimization Algorithm (WOA). We have also created the hybrid version (hGWWO) of these two approaches as our novel, innovative scientific contribution. The baseline algorithms above have been used previously for feature selection across different domains. According to our understanding, these three algorithms are being used for the first time in glaucoma identification, particularly on the publicly available benchmark dataset, ORIGA. The rising global prevalence of glaucoma prompted this proposed methodology's focus on the illness. This illness is second only to cataracts in causing visual loss. Medical imaging professionals are examining retinal scans to diagnose glaucoma. Manual eye screening and retinal fundus imaging for confirmation of this infection require skilled ophthalmologists. The screening analysis method is time-consuming, requires experienced staff, and is subject to observational differences. In order to overcome these issues and to support the medical fraternity, an artificial intelligence-supported computer-aided clinical decision support system (CA-CDSS) is implemented in the present endeavor for confirmation of this disease from retinal fundus images. Nature-inspired computing strategies for feature selection and ML models for classification are employed to classify fundus retinal images under investigation. From the ORIGA dataset, sixty-five features were retrieved. A subset of most influential features is selected from the original dataset using three soft-computing-based FS methods. ML classifiers are trained using this portion of data and evaluated using a 70:30 technique. The suggested method yielded 96.8% accuracy, 0.981 specificity, 0.992 sensitivity, 0.969 precision, and a 0.982 F1-score. This study shows fresh initiatives with positive effects on ophthalmologists, researchers, and the public.
C1 [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
   [Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Informat Technol, Mathura 281122, India.
   [Singh, Rekha] Uttar Pradesh Rajarshi Tandon Open Univ, Dept Phys, Prayagraj 211021, Uttar Pradesh, India.
C3 GLA University
RP Singh, LK (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
EM lawkumarcs@gmail.com; munishkhanna.official@rocketmail.com;
   shankarthawkar@gmail.com; singh.rekha70@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852
CR Abad PF, 2021, MEDRXIV
   Acharya UR, 2015, BIOMED SIGNAL PROCES, V15, P18, DOI 10.1016/j.bspc.2014.09.004
   Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   Agrawal DK, 2019, IET IMAGE PROCESS, V13, P2401, DOI 10.1049/iet-ipr.2019.0036
   Akay MF, 2009, EXPERT SYST APPL, V36, P3240, DOI 10.1016/j.eswa.2008.01.009
   AlAfandy KA, 2019, P 4 INT C BIG DAT IN, P1
   AlAfandy KA., 2020, Advances in Science, Technology and Engineering Systems Journal, V5, P770, DOI [10.25046/aj050594, DOI 10.25046/AJ050594]
   AlAfandy KA, 2022, CMC-COMPUT MATER CON, V72, P739, DOI 10.32604/cmc.2022.022457
   Alweshah M, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107629
   [Anonymous], 2013, Eur J Sci Res
   Arasteh B, 2022, ADV ENG SOFTW, V173, DOI 10.1016/j.advengsoft.2022.103252
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Claro Maíla, 2016, CLEIej, V19, P5
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Dua S, 2012, IEEE T INF TECHNOL B, V16, P80, DOI 10.1109/TITB.2011.2176540
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Elmoufidi A, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500122
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Fu HZ, 2019, ADV COMPUT VIS PATT, P119, DOI 10.1007/978-3-030-13969-8_6
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Ghobaei-Arani M, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.117012
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo F, 2020, MED BIOL ENG COMPUT, V58, P2567, DOI 10.1007/s11517-020-02237-2
   Guo F, 2018, IEEE ACCESS, V6, P77414, DOI 10.1109/ACCESS.2018.2882946
   Haleem MS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0482-9
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Jerith GG, 2020, MULTIMED TOOLS APPL, V79, P10341, DOI 10.1007/s11042-019-7224-1
   Juneja M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108009
   Juneja M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01091-4
   Juneja M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01085-2
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Khanna M, 2023, Multimed Tools Appl, P1
   Koh JEW, 2017, COMPUT BIOL MED, V84, P89, DOI 10.1016/j.compbiomed.2017.03.008
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Lin XK, 2022, COMPUT IND ENG, V171, DOI 10.1016/j.cie.2022.108361
   Liu SP, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103485
   Maheshwari S, 2019, COMPUT BIOL MED, V105, P72, DOI 10.1016/j.compbiomed.2018.11.028
   Maheshwari S, 2017, COMPUT BIOL MED, V88, P142, DOI 10.1016/j.compbiomed.2017.06.017
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Mallika C, 2021, INT J COMPUT INT SYS, V14, DOI 10.1007/s44196-021-00013-0
   Martins J, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105341
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Nadimi-Shahraki MH, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105858
   Noronha KP, 2014, BIOMED SIGNAL PROCES, V10, P174, DOI 10.1016/j.bspc.2013.11.006
   Orlando JI., 2019, Med Image Anal, V2020, P101570
   Prabukumar M, 2019, J AMB INTEL HUM COMP, V10, P267, DOI 10.1007/s12652-017-0655-5
   Purushothaman R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106651
   Raghavendra U, 2018, BIOCYBERN BIOMED ENG, V38, P170, DOI 10.1016/j.bbe.2017.11.002
   Raja C, 2015, J ELECTR ENG TECHNOL, V10, P1899, DOI 10.5370/JEET.2015.10.4.1899
   Raja C, 2015, INT J AUTOM COMPUT, V12, P393, DOI 10.1007/s11633-014-0858-6
   Renukalatha S, 2019, BIOMED ENG-APP BAS C, V31, DOI 10.4015/S101623721950039X
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Selvathi D., 2018, BIOMED PHARMACOL J, V11, P795, DOI [DOI 10.13005/bpj/1434, 10.13005/bpj/1434]
   Septiarini A, 2018, HEALTHC INFORM RES, V24, P53, DOI 10.4258/hir.2018.24.1.53
   Shafipour M, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115620
   Sharma R, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419400116
   Shubhangi DC., 2019, Int J Comput Sci. Mobile Comput, V8, P82
   Singh A, 2016, COMPUT METH PROG BIO, V124, P108, DOI 10.1016/j.cmpb.2015.10.010
   Singh LK, 2024, SOFT COMPUT, V28, P2431, DOI 10.1007/s00500-023-08449-6
   Singh LK, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103468
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   Singh LK, 2022, EVOL SYST-GER, V13, P807, DOI 10.1007/s12530-022-09426-4
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Sreng S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144916
   Thakur N, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102137
   Tulsani A, 2021, Biocybernet Biomed Eng
   Wang LX, 2021, Expert Systems with Appl
   Zareie A, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112971
   Zhou J, 2022, ACTA GEOTECH, V17, P1343, DOI 10.1007/s11440-022-01450-7
NR 74
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17081-3
EA OCT 2023
PG 73
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100007
DA 2024-07-18
ER

PT J
AU Kayani, M
   Riaz, MM
   Ghafoor, A
   Khan, F
AF Kayani, Maemoona
   Riaz, M. Mohsin
   Ghafoor, Abdul
   Khan, Fawad
TI Privacy preserving content based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia security; Privacy; Image retrieval; Chaotic map
AB The rapid and tremendous growth of multimedia content has motivated users and organizations to upload their large scale digital content on the cloud server which makes the security of data an important issue. To overcome the problem of security in content based image retrieval (CBIR), we have proposed a novel privacy preserving image retrieval technique that efficiently retrieves similar images in an encrypted domain. Initially features of all the images in the database are extracted and then encrypted using secret key. In order to enhance the security, images are encrypted using Gauss-Square chaotic (GSC) map prior to outsourcing it to cloud server. Cloud uses modified euclidian distance (for encrypted features) to retrieve images similar to user encrypted query. Simulation results on Corel-1K and GHIM-10K illustrates that proposed technique efficiently retrieves encrypted images without compromising the retrieval accuracy. Moreover, the security analysis demonstrates the high security of proposed image encryption scheme.
C1 [Kayani, Maemoona; Ghafoor, Abdul; Khan, Fawad] Natl Univ Sci & Technol NUST, Mil Coll Signals, Islamabad, Pakistan.
   [Riaz, M. Mohsin] COMSATS, Ctr Adv Studies Telecommun CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), Natl Univ Sci & Technol NUST, Mil Coll Signals, Islamabad, Pakistan.
EM maemoona.kaynai@mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk; fawadkhan@mcs.edu.pk
RI Kayani, Maemoona/GXA-0331-2022; Khan, Fawad/N-4715-2017; Imran,
   Muhammad/AAS-9984-2021
OI Khan, Fawad/0000-0001-6609-5928; Imran, Muhammad/0000-0002-7122-8454;
   Ghafoor, Abdul/0000-0002-6117-3656; Farooq, Maemoona/0009-0002-1177-8654
CR Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2005, ICINCO 395-398
   Arif J, 2022, IEEE ACCESS, V10, P12966, DOI 10.1109/ACCESS.2022.3146792
   Barbu T, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P236, DOI 10.1109/DEXA.2009.61
   Benettin G., 1980, MECCANICA, V15, P9, DOI DOI 10.1007/BF02128236
   Castro JCH, 2005, MATH COMPUT SIMULAT, V68, P1, DOI 10.1016/j.matcom.2004.09.001
   Cheng H, 2016, MULTIMED TOOLS APPL, V75, P13791, DOI 10.1007/s11042-015-2741-z
   Chou JK, 2016, MULTIMED TOOLS APPL, V75, P13805, DOI 10.1007/s11042-015-2917-6
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Fathian M, 2011, P 3 INT C ART INT CO, VIII
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hassan A, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102043
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Kayani M, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501759
   Liang HH, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023032
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Pan WY, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5556634
   Polyakov Y., 2018, PALISADE lattice cryptography library
   Qin JH, 2019, IEEE ACCESS, V7, P24626, DOI 10.1109/ACCESS.2019.2894673
   Rahim N, 2018, COMPUT COMMUN, V127, P75, DOI 10.1016/j.comcom.2018.06.001
   Raj Singh S, 2015, Int J Comput Syst, V2
   Razeghi B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1992, DOI 10.1109/ICASSP.2018.8461862
   Rukhin A, 2010, SP 800-22 Rev. 1A
   Shen M, 2020, FUTURE GENER COMP SY, V109, P621, DOI 10.1016/j.future.2018.04.089
   Srivastava P, 2014, INT CONF CONTR AUTO, P159, DOI 10.1109/ICCAIS.2014.7020550
   Suciati N, 2015, INT CONF INFORM COMM, P99, DOI 10.1109/ICTS.2015.7379879
   Tang WD, 2019, J SYST ARCHITECT, V94, P1, DOI 10.1016/j.sysarc.2019.02.001
   Tsafack N., 2019, J Phys Math, V10, P0902
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wu Y, 2014, P 2013 INT C EL INF, V287, P119
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xia ZH, 2022, IEEE T SERV COMPUT, V15, P202, DOI 10.1109/TSC.2019.2927215
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu WJ, 2018, CMC-COMPUT MATER CON, V55, P285, DOI 10.3970/cmc.2018.01719
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 38
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17168-x
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000001
DA 2024-07-18
ER

PT J
AU Kumari, R
   Gupta, V
   Ashok, N
   Ghosal, T
   Ekbal, A
AF Kumari, Rina
   Gupta, Vipin
   Ashok, Nischal
   Ghosal, Tirthankar
   Ekbal, Asif
TI Emotion aided multi-task framework for video embedded misinformation
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal fake news detection; Video embedded fake news; Supervised
   contrastive learning; Multimodal emotion; Deep learning
AB Online news consumption via social media platforms has accelerated the growth of digital journalism. Adverse to traditional media, digital media has lower entry barriers and allows everyone as a content creator, resulting in numerous fake news productions to attract public attention. As multimedia content is more convenient for users than expressing their feelings through text, images and video-embedded fake news is being circulated rapidly on social media nowadays. Emotional appeal in fake news is also a driving factor in its rapid dissemination. Although prior studies have made a remarkable effort toward fake news detection, they give less emphasis on exploring video modality and emotional appeal in fake news. To bridge this gap, this paper presents the following two contributions: i) It first develops a video-based multimodal fake news detection dataset named FakeClips and ii) It introduces a deep multitask framework dedicated to video-embedded multimodal fake news detection in which fake news detection is the main task and emotion recognition is the auxiliary task. The results reveal that investigating emotion and fake news together in a multitasking framework achieves 9.04% and 5.27% gains in terms of accuracy and f-score, respectively over the state-of-the-art model i.e. Fake Video Detection Model.
C1 [Kumari, Rina] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, India.
   [Gupta, Vipin; Ekbal, Asif] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801106, Bihar, India.
   [Ashok, Nischal] Univ Massachusetts, Dept Comp Sci, Amherst, MA USA.
   [Ghosal, Tirthankar] Oak Ridge Natl Lab, Natl Ctr Computat Sci, Oak Ridge, TN 37831 USA.
C3 Kalinga Institute of Industrial Technology (KIIT); Indian Institute of
   Technology (IIT) - Patna; Indian Institute of Technology System (IIT
   System); University of Massachusetts System; University of Massachusetts
   Amherst; United States Department of Energy (DOE); Oak Ridge National
   Laboratory
RP Kumari, R (corresponding author), Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, India.
EM rinakri08@gmail.com; vipingupta1907@gmail.com;
   nischal.ashok09@gmail.com; ghosalt@ornl.gov; asif.ekbal@gmail.com
RI Ekbal, Asif/JKI-7638-2023
OI Kumari, Rina/0000-0002-1590-4673
CR Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Asha J., 2021, Journal of Mobile Computing, Communications and Mobile Networks, V8, P33
   Boomlive, 2022, Video Of Pakistan Customs Destroying Cellphones Peddled As Afghanistan
   Brady WJ, 2017, P NATL ACAD SCI USA, V114, P7313, DOI 10.1073/pnas.1618923114
   Chakraborty T, 2021, Multi-modal fake news detection, P41, DOI [10.1007/978-3-030-62696-9_3, DOI 10.1007/978-3-030-62696-9_3]
   Choi H, 2022, Pattern Recogn Lett
   Choi H, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2950, DOI 10.1145/3459637.3482212
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Fang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222713
   Ghadiri Z, 2022, Arxiv, DOI arXiv:2201.00083
   Guo C, 2019, Exploiting emotions for fake news detection on social media
   Gupta V., 2022, FINDINGS ASS COMP, P464
   IndiaToday, 2021, Fact Check News
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Jindal S., 2020, CEUR WORKSH P, V2560, P138
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kingma D. P., 2014, arXiv
   Kumari R, 2023, Journal of Intelligent Information Systems, ppp1
   Kumari R, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534218
   Kumari R, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102740
   Kumari R, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115412
   Kumari R, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102631
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Ma J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2561
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Mezaris V, 2016, InVID Verification Plugin-InVID project
   Palod P, 2018, EUR C INF RETR, P140
   Papadopoulou O., 2018, Invid fake video corpus v2. 0 (version 2.0)
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Raffel C, 2020, J MACH LEARN RES, V21
   Rao DN, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3347
   Saikh T, 2020, P 16 INT C NATURAL L, P230
   Saravia E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3687
   Segura-Bedmar I, 2022, INFORMATION, V13, DOI 10.3390/info13060284
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Singh VK, 2021, J ASSOC INF SCI TECH, V72, P3, DOI 10.1002/asi.24359
   Singhal S., 2021, ACM MULTIMEDIA ASIA, P1
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Song CG, 2021, NEUROCOMPUTING, V462, P88, DOI 10.1016/j.neucom.2021.07.077
   Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang JZ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031093
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang W., 2021, P 30 ACM INT C INF K, P3637, DOI 10.1145/3459637.3482196
   Zhang XY, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3465, DOI 10.1145/3442381.3450004
   Zimdars M, 2016, Resource-False-Misleading-Clickbait-y-and-Satirical-"News" -Sources-1.pdf
NR 51
TC 2
Z9 2
U1 10
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17208-6
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000017
DA 2024-07-18
ER

PT J
AU Monika
   Bhat, A
AF Monika
   Bhat, Aruna
TI DAC-BiNet: Twitter crime detection using deep attention convolutional
   bi-directional aquila optimal network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Twitter crime detection; Pre-processing; Feature extraction; Deep
   Attention Convolutional Bi-directional Aquila Optimal Network
   (DAC-BiNet); Aquila optimization
AB Recently, the crime rates in social media are rising rapidly and it produces serious problems to the users. From the past few years, twitter platform has been gaining higher attention due to its effective services. But, the growth of crimes in twitter generates several issues and it redirect users to malicious or phishing websites. Thus, in order to identify various illegal activities on twitter, the proposed study introduces a robust Deep Attention Convolutional Bi-directional Aquila Optimal Network (DAC-BiNet) model. For effectively processing the proposed network, the raw inputs are pre-processed initially to reduce the noises through diverse steps like segmentation of sentences, punctuation removal, tokenization, removal of stop words, acronym and slang correction, lemmatization, lower casing, stemming, removal of hashtag and URLs. From the pre-processed data, the significant features are extracted using ITF-IDF (Improved Term Frequency-Improved Document Frequency), Feature hashing and Glove Modelling methods. Then, the feature dimensionality issue is solved by grouping the features into clusters by Possibilistic Fuzzy LDA (Latent Dirichlet Allocation) based clustering method. Finally, classification stage is initiated to identify the crime tweets in the given inputs through proposed DAC-BiNet model. The proposed study used python platform for simulation and the efficiency of proposed model is measured by evaluating various performance matrices and comparing with other existing techniques. The obtained simulation results proves that proposed model gains enhanced accuracy of 98.23%, precision of 83.86%, recall of 90.05%, specificity of 98.86%, and F1 score of 86.84%.
C1 [Monika; Bhat, Aruna] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Delhi Technological University
RP Bhat, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM monika.siwaliya@gmail.com; aruna.bhat@dtu.ac.in
RI Bhat, Aruna/GSI-4485-2022
OI Bhat, Aruna/0000-0002-5475-8664
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Ahadi A, 2022, EDUC SCI, V12, DOI 10.3390/educsci12030210
   AlGhamdi MA, 2020, ARAB J SCI ENG, V45, P6021, DOI 10.1007/s13369-020-04447-0
   Almadhoor L, 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P2972
   Asaad RR., 2021, Qubahan Acad J, V1, P17, DOI [10.48161/qaj.v1n2a43, DOI 10.48161/QAJ.V1N2A43]
   Benicio DHP, Applying Text Mining and Natural Language Processing to Electronic Medical Records for Extracting and Transforming Texts into Structured Data
   Boukabous M., 2022, INDONES J ELECT ENG, V25, P1131, DOI [10.11591/ijeecs.v25.i2.pp1131-1139, DOI 10.11591/IJEECS.V25.I2.PP1131-1139]
   Chackravarthy S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P399, DOI 10.1109/CIC.2018.00060
   Drew JM, 2021, POLICING, V44, P525, DOI 10.1108/PIJPSM-08-2020-0131
   Dutta HS, 2021, PROCEEDINGS OF THE 32ND ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT '21), P91, DOI 10.1145/3465336.3475108
   He J., 2021, Front Res Metrics Anal, V6, P12
   Hissah AS, 2018, Int J Adv Comput Sci Appl (IJACSA), V9
   Lal S, 2020, PROCEDIA COMPUT SCI, V167, P1911, DOI 10.1016/j.procs.2020.03.211
   Mahor V., 2021, 2021 IEEE 4 INT C CO, P1
   McMullan JL, 2010, J GAMBL ISSUES, P54, DOI 10.4309/jgi.2010.24.5
   Metzger MJ, 2021, MEDIA COMMUN-LISBON, V9, P134, DOI 10.17645/mac.v9i1.3409
   Ojha Divyank, 2021, 2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT), P533, DOI 10.1109/CSNT51715.2021.9509653
   RAJA R.A., 2021, Intelligent Data Analytics for Terror Threat Prediction: Architectures, Methodologies, Techniques and Applications, P119
   Saura JR, 2021, COMPUT COMMUN, V179, P285, DOI 10.1016/j.comcom.2021.08.021
   Razak N.A., 2021, International Journal of Business and Technology Management, V3, P1
   Rigano C., 2019, Natl. Inst. Justice J, V280, P1
   Rouhollahi Z, 2021, Arxiv, DOI arXiv:2105.10866
   Sandagiri Chamith, 2021, International Journal of Systems and Service-Oriented Engineering, V11, P15, DOI 10.4018/IJSSOE.2021010102
   Santhiya K., 2021, Turk J Comput Math Educ (TURCOMAT), V12, P2133
   Thurtell SC, 2021, CRIT ARTS, V35, P85, DOI 10.1080/02560046.2021.1891445
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17250-4
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000008
DA 2024-07-18
ER

PT J
AU Chen, AG
   Zhang, Y
AF Chen, Aiguo
   Zhang, Yong
TI A novel pseudo-random number assisted fast image encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Pseudo-random number assisted encryption; Symmetric
   cryptography; Galois field arithmetic operation; Chaotic system
ID SCHEME; SYSTEM; CHAOS
AB Image information encryption is an essential research direction in symmetric cryptography. A new digital image cryptosystem is proposed in this paper. A 480-bit external key is used to generate an equivalent key by the chaotic map, and a pseudo-random matrix is produced by the computer's pseudo-random number generator to assist the image encryption. The image data processing uses the discrete logarithm-based arithmetic on the Galois field GF(257). The original plain image is transformed into a non-visual image by exponentiation and multiplication operations on the field. Then, the non-visual image is self-scrambled to obtain a cipher image. Since the assisted matrix used for each encryption is a pseudo-random matrix, even for the same plain image and the unchanged secret key, ciphers image produced in multiple encryptions are different for the image encryption system. Simulation experiments show that the cipher images are excellent in statistical characteristics, and the image cryptosystem has the advantages of high processing speed and high security intensity.
C1 [Chen, Aiguo; Zhang, Yong] Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang 330032, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhang, Y (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang 330032, Jiangxi, Peoples R China.
EM zhangyong@jxufe.edu.cn
OI Zhang, Yong/0000-0002-7428-1816
FU This work was fully supported by the National Natural Science Foundation
   of China (No. 61762043), the Jiangxi Provincial Natural Science
   Foundation, China (No. 20232ACB202005), and the Scientific Research
   Foundation of Jiangxi Provincial Education Departme [61762043]; National
   Natural Science Foundation of China [20232ACB202005]; Jiangxi Provincial
   Natural Science Foundation, China [GJJ210507, GJJ2200528]; Scientific
   Research Foundation of Jiangxi Provincial Education Department, China
FX This work was fully supported by the National Natural Science Foundation
   of China (No. 61762043), the Jiangxi Provincial Natural Science
   Foundation, China (No. 20232ACB202005), and the Scientific Research
   Foundation of Jiangxi Provincial Education Department, China (Nos.
   GJJ210507, GJJ2200528).
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Ahmad M, 2022, INFORM SCIENCES, V592, P1, DOI 10.1016/j.ins.2022.01.042
   Bathe B, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03322-7
   Bouteghrine B, 2021, MULTIMED TOOLS APPL, V80, P25583, DOI 10.1007/s11042-021-10773-8
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P8065, DOI 10.1007/s00521-019-04312-8
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   De S, 2022, MULTIMED TOOLS APPL, V81, P5485, DOI 10.1007/s11042-021-11696-0
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Fan HJ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121581
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P505, DOI 10.1007/s11042-021-11384-z
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang HQ, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.1.013031
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu S, 2022, IEEE MULTIMEDIA, V29, P74, DOI 10.1109/MMUL.2021.3114589
   Lu DJ, 2017, OPT LASER ENG, V89, P13, DOI 10.1016/j.optlaseng.2016.04.004
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Mannai O, 2015, NONLINEAR DYNAM, V82, P107, DOI 10.1007/s11071-015-2142-x
   Nardo LG, 2019, CHAOS SOLITON FRACT, V123, P69, DOI 10.1016/j.chaos.2019.03.026
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pourasad Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030341
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Su YN, 2022, PHYSICA A, V587, DOI 10.1016/j.physa.2021.126529
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tewari A, 2020, INT J COMPUT SCI ENG, V21, P298
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang YH, 2018, CHINA COMMUN, V15, P25, DOI 10.1109/CC.2018.8300269
   Wen HP, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020258
   Wu WQ, 2022, INT J THEOR PHYS, V61, DOI 10.1007/s10773-022-04979-1
   Xiong Y, 2022, OPT COMMUN, V517, DOI 10.1016/j.optcom.2022.128272
   Ye GD, 2022, ALEX ENG J, V61, P6785, DOI 10.1016/j.aej.2021.12.023
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Yildirim M, 2021, OPTIK, V237, DOI 10.1016/j.ijleo.2021.166728
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhao MD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250081X
NR 47
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17209-5
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400002
DA 2024-07-18
ER

PT J
AU Han, IL
   Om, CN
   Kim, UI
AF Han, Il
   Om, Chol-Nam
   Kim, Un-Il
TI A gated recurrent unit based robust voice activity detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Voice activity detection; Deep Neural Network; Recurrent Neural Network;
   Gated Recurrent Unit; TDNN
AB Voice activity detection (VAD), which identifies speech and non-speech durations in speech signals, is a challenging task under noisy environment for various speech applications. In this paper, we propose VAD based on TDNN and Gated Recurrent Unit (GRU) under the low signal-to-noise ratios (SNRs) environments. We compare the proposed method with the traditional methods and deep network method based on LSTM by using speech signals smeared with 10 types of noise at low SNRs. Experimental results reveal that the proposed method is superior to traditional method under all the considered noisy environments, indicating that the network based on TDNN and GRU improve the performance of speech detection.
C1 [Han, Il; Om, Chol-Nam; Kim, Un-Il] Kim Il Sung Univ, Inst Informat Technol, Hightech Res & Dev Ctr, Pyongyang, North Korea.
RP Om, CN (corresponding author), Kim Il Sung Univ, Inst Informat Technol, Hightech Res & Dev Ctr, Pyongyang, North Korea.
EM cn.om1011@ryongnamsan.edu.kp
CR Ariav I, 2019, IEEE J-STSP, V13, P265, DOI 10.1109/JSTSP.2019.2901195
   Benyassine A, 1997, IEEE COMMUN MAG, V35, P64, DOI 10.1109/35.620527
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Chang SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5549, DOI 10.1109/ICASSP.2018.8461921
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Dong EQ, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1124, DOI 10.1109/ICOSP.2002.1179987
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Dwijayanti S, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0135-7
   Espi M, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0069-2
   Ferroni G, 2015, IEEE IJCNN
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ishizuka K, 2010, SPEECH COMMUN, V52, P41, DOI 10.1016/j.specom.2009.08.003
   Jo QH, 2009, IET SIGNAL PROCESS, V3, P205, DOI 10.1049/iet-spr.2008.0128
   Kingma D. P., 2014, arXiv
   Kinnunen T., 2007, INT C SPEECH COMPUTE, V2, P556
   Lavechin M, 2020, INTERSPEECH, P3685, DOI 10.21437/Interspeech.2020-2285
   Lei Ba J., 2016, arXiv
   Ma YN, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-21
   Mendelev VS., 2015, Mod Appl Sci, V9, P153
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Myllymaki M, 2008, P 16 EUR SIGN PROC C, P1
   RABINER LR, 1975, AT&T TECH J, V54, P297, DOI 10.1002/j.1538-7305.1975.tb02840.x
   Ramírez J, 2004, SPEECH COMMUN, V42, P271, DOI 10.1016/j.specom.2003.10.002
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sehgal A, 2018, IEEE ACCESS, V6, P9017, DOI 10.1109/ACCESS.2018.2800728
   Sharma S, 2021, Int J Creat Res Thourghts, V9
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Tong SB, 2014, INT CONF SIGN PROCES, P2308, DOI 10.1109/ICOSP.2014.7015406
   Xu TJ, 2020, INTERSPEECH, P3675, DOI 10.21437/Interspeech.2020-1177
   Yang XK, 2016, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-016-0092-y
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P252, DOI 10.1109/TASLP.2015.2505415
   Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986
   Zheng ZP, 2020, INTERSPEECH, P3695, DOI 10.21437/Interspeech.2020-2392
NR 33
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17123-w
EA OCT 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500019
DA 2024-07-18
ER

PT J
AU Ranjbar, FR
   Zamanifar, A
AF Ranjbar, Fatemeh Rashidi
   Zamanifar, Azadeh
TI Autonomous dental treatment planning on panoramic x-ray using deep
   learning based object detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Dental treatment planning; Panoramic x-rays; YOLOv7
ID AGE ESTIMATION; CLASSIFICATION; CARIES
AB The first stage of digestion starts from the mouth. If the teeth are not in good health, they may affect the person's eating and cause a disturbance in the digestive system. In addition, damaged teeth cause a person's self-confidence to decline while laughing and talking. Therefore, diagnosing and treating damaged teeth is of great importance in dentistry. Deep learning has been able to speed up and improve human performance in identifying many dental diseases, diagnosing oral cancer, and diagnosing the treatment stage. In medicine, deep learning applications face challenges due to the need for labeled datasets, and the field of dentistry is no exception. This pilot study used 1025 dental x-ray panoramic images of patients over 14 for dental treatment planning. A dentist with more than 25 years of experience assisted us in conducting this research. The dentist consulted with other dentists in his team to increase the reliability of the treatment plans presented for each panoramic image and then labeled the images. After labeling these images, YOLOv7, which belongs to the family of the You Only Look Once (YOLO), a convolutional neural network model, is used to process the images due to its advantages, especially performing quickly with high accuracy on small datasets. The proposed model identifies damaged teeth by drawing bounding boxes around them, then indicates the proper treatment plan for each damaged tooth state. The released treatment plan concludes an overall of 8 distinct treatments which can be applied in multiple stages to cure the teeth. After training the model, it was tested on the test set, a portion of the dataset that was not used to train the model, to evaluate its performance. The model achieves a precision of 100%, F1 score of 76%, Recall of 96%, and mAP of 81.9%, indicating that this model has excellent potential for clinical use by dentists.
C1 [Ranjbar, Fatemeh Rashidi; Zamanifar, Azadeh] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Sattari Hwy, Tehran 1477893855, Iran.
C3 Islamic Azad University
RP Zamanifar, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Sattari Hwy, Tehran 1477893855, Iran.
EM rashidiranjbarfatemeh@gmail.com; azamanifar@srbiau.ac.ir
RI Zamanifar, Azadeh/O-4436-2017
OI Zamanifar, Azadeh/0000-0002-2629-4794
FU The authors would like to thank Dr. Mohammad Rashidi Ranjbar, Head of
   the Dental Unit of Quds Hospital Polyclinic, for his help in diagnosing
   different treatment plannings and making connections to access the
   images used in the dataset.
FX The authors would like to thank Dr. Mohammad Rashidi Ranjbar, Head of
   the Dental Unit of Quds Hospital Polyclinic, for his help in diagnosing
   different treatment plannings and making connections to access the
   images used in the dataset.
CR Alkaabi S, 2022, J Image Graph, V10, P1
   Almalki YE, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197370
   Balan H, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2073724
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bradley A, 2014, Selection criteria for dental radiography
   Cantu AG, 2020, J DENT, V100, DOI 10.1016/j.jdent.2020.103425
   Casalegno F, 2019, J DENT RES, V98, P1227, DOI 10.1177/0022034519871884
   Chandrashekar G, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105829
   Chang HJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64509-z
   Choi HR, 2022, FOREN SCI RES, V7, P456, DOI 10.1080/20961790.2022.2034714
   De Brabandere B, 2017, Arxiv, DOI [arXiv:1708.02551, 10.48550/arXiv.1708.02551]
   Estai M, 2022, DENTOMAXILLOFAC RAD, V51, DOI 10.1259/dmfr.20210296
   Fan JQ, 2021, STAT SCI, V36, P264, DOI [10.1214/20-sts783, 10.1214/20-STS783]
   Felzenszwalb P, 2013, COMMUN ACM, V56, P97, DOI [10.1145/2500468.2494532, 10.1145/2494532]
   Haghanifar A, 2020, arXiv
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Hossain MS, 2021, NEUROCOMPUTING, V462, P69, DOI 10.1016/j.neucom.2021.07.055
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Jaiswal P, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104708
   Jaiswal P, 2022, INT J ADV COMPUT SC, V13, P239
   Jan AM, 2019, NIGER J CLIN PRACT, V22, P1706, DOI 10.4103/njcp.njcp_206_19
   Jiang, 2021, 2 STAGE DEEP LEARNIN
   Jiang LH, 2022, BMC ORAL HEALTH, V22, DOI 10.1186/s12903-022-02119-z
   Johnson M, 2005, BMVC
   Kim DW, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-018-36760-y, 10.1038/s41598-019-43372-7]
   Kim J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53758-2
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu LZ, 2020, IEEE J BIOMED HEALTH, V24, P898, DOI 10.1109/JBHI.2019.2919916
   Liu Y, 2018, INT SYM COMPUT INTEL, P119, DOI 10.1109/ISCID.2018.10128
   Lyashenko V, 2022, Data augmentation in python: everything you need to know
   Mahdi FP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75887-9
   Manipal S, 2020, Indian J Public Health Res Dev, V11
   Milosevic D, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116038
   Mohamed EG, 2023, COMPUTATION, V11, DOI 10.3390/computation11020018
   Moutselos K, 2019, IEEE ENG MED BIO, P1617, DOI [10.1109/embc.2019.8856553, 10.1109/EMBC.2019.8856553]
   Muresan MP, 2020, INT C INTELL COMP CO, P457, DOI [10.1109/ICCP51029.2020.9266244, 10.1109/iccp51029.2020.9266244]
   Mutasa S, 2020, CLIN IMAG, V65, P96, DOI 10.1016/j.clinimag.2020.04.025
   Nelson J, 2022, Your comprehensive guide to the yolo family of models
   Oktay A.B., 2021, State of the art in neural networks and their applications, P73
   Pinheiro L., 2021, 17 INT S MEDICAL INF, V12088, P95
   Pokhrel S, 2020, Towards Data Science
   Prajapati SA, 2017, 2017 5TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P70, DOI 10.1109/ISCBI.2017.8053547
   Prakash J, 2022, Non maximum suppression: theory and implementation in PyTorch
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Santos C, 2022, ACM COMPUT SURV
   Schwendicke F, 2020, J DENT, V92, DOI 10.1016/j.jdent.2019.103260
   Shokouhi EB, 2018, BIOMED OPT EXPRESS, V9, P3983, DOI 10.1364/BOE.9.003983
   Silva B, 2020, SIBGRAPI, P164, DOI 10.1109/SIBGRAPI51738.2020.00030
   Sukegawa S, 2021, BIOMOLECULES, V11, DOI 10.3390/biom11060815
   Sunnetci KM, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103844
   Szeghalmy S, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042333
   Takahashi T, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81202-x
   Thulaseedharan A, 2022, ANNU IEEE IND CONF, DOI 10.1109/INDICON56171.2022.10040109
   Vila-Blanco N, 2020, P 9 EUR START AI RES, P2655
   Vila-Blanco N, 2020, IEEE T MED IMAGING, V39, P2374, DOI 10.1109/TMI.2020.2968765
   Vinayahalingam S, 2021, The automatic detection of caries in third molars on panoramic radiographs using deep learning: a pilot study
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang W, Adv Neural Inf Process Syst, V35, P12826
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Warin K, 2021, J ORAL PATHOL MED, V50, P911, DOI 10.1111/jop.13227
   Welikala RA, 2020, IEEE ACCESS, V8, P132677, DOI 10.1109/ACCESS.2020.3010180
   Whaites E, 2013, Essentials of Dental Radiography and Radiology, V5th
   Wood NK, 1999, Review of diagnosis, oral medicine, radiology, and treatment, planning
   Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685
   Yang J, 2018, P INT COMP SOFTW APP, P492, DOI 10.1109/COMPSAC.2018.00076
   Yüksel AE, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90386-1
   Zhao Y, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106338
   Zurowietz M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207498
NR 70
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17048-4
EA OCT 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500015
DA 2024-07-18
ER

PT J
AU Bal, A
   Banerjee, M
   Chaki, R
   Sharma, P
AF Bal, Abhishek
   Banerjee, Minakshi
   Chaki, Rituparna
   Sharma, Punit
TI A robust ischemic stroke lesion segmentation technique using two-pathway
   3D deep neural network in MR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep convolution neural network; Two-pathway 3D CNN; Brain stroke lesion
   segmentation; MRI, CT
AB Ischemic stroke is one of the major causes of disability and death of humans. It is a most common disease in aged people which may lead to long-term disability. So, accurate stroke lesion identification and quantification within a short period are the most important tasks in treatment planning. Generally, the supervised and semi-supervised based methods have succeeded in achieving promising performance for the segmentation of acute ischemic stroke lesions, however, few deep learning-based methods have been proposed in recent years successfully. In the present work, a robust deep neural network based on two-pathway 3D convolutional neural network has been proposed to identify the accurate boundary regions of the acute and sub-acute ischemic stroke lesions. The proposed two-pathway 3D CNN not only focuses on segmenting abnormal tissues on individual brain slices but also considers the information from preceding and succeeding slices to establish connectivity among the different slices. This approach allows the model to have a more comprehensive understanding of the brain structures and abnormalities being analyzed. The local pathway can capture fine-grained details and local patterns within each slice, enabling precise segmentation of aberrant tissues. Meanwhile, the contextual pathway considers the spatial dependencies and temporal information between slices, enhancing the model's ability to detect and incorporate the connectivity between different brain regions. Generally, most of the existing deep learning-based methods utilized single MRI modalities (either DWI or FLAIR) to segment the acute ischemic stroke lesions because these two MRI modalities are the most sensitive to find out and quantifying the acute ischemic stroke lesions. In this present work, various MRI modalities have been utilized to improve the performance of the proposed model by accurately identifying the boundary regions of the acute and sub-acute ischemic stroke lesions. The current study explores the potential benefits of incorporating intensity normalization and data augmentation during the pre-processing stage to address the challenges associated with imbalanced stroke labels. The proposed model is tested with the ISLES2015 datasets and obtains promising results as compared to the existing deep learning-based methods depending on various metrics such as dice similarity coefficient (DSC), sensitivity, and positive predictive value (PPV). Furthermore, a significant gain is achieved around the boundaries of the sub-regions of the stroke lesions.
C1 [Bal, Abhishek; Chaki, Rituparna] Univ Calcutta, AK Choudhury Sch Informat Technol, Kolkata, India.
   [Banerjee, Minakshi] RCC Inst Informat Technol, Kolkata, India.
   [Sharma, Punit] Apollo Gleneagles Hosp, Kolkata, India.
C3 University of Calcutta; RCC Institute of Information Technology (RCCIIT)
RP Bal, A (corresponding author), Univ Calcutta, AK Choudhury Sch Informat Technol, Kolkata, India.
EM abhisheknew1991@gmail.com
FU The current work was carried out with inspirational support from the
   Board of Research in Nuclear Sciences (ref no.
   34/14/13/2016-BRNS/34044). The heartiest thanks to Dr. Punit Sharma, for
   providing precious suggestions and validating the results as a neur
   [34/14/13/2016-BRNS/34044]; Board of Research in Nuclear Sciences
FX The current work was carried out with inspirational support from the
   Board of Research in Nuclear Sciences (ref no.
   34/14/13/2016-BRNS/34044). The heartiest thanks to Dr. Punit Sharma, for
   providing precious suggestions and validating the results as a
   neuro-consultant at Apollo Gleneagles Hospital, Kolkata, India.
NR 0
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16689-9
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200011
DA 2024-07-18
ER

PT J
AU Heidari, M
   Mehrdad, V
AF Heidari, Maryam
   Mehrdad, Vahid
TI Segmentation of 3d medical images for detection and classification of
   lung tumor using content-based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D Medical Image; Lung cancer; SVM; K-means
ID CANCER DETECTION; ACTIVE CONTOUR; DIAGNOSIS; NETWORKS; NODULES; MODEL
AB Lung cancer is one of the most fatal types of lung disease, in which early detection of this cancer can prevent its dangerous consequences. This paper presents a method for the detection and classification of lung tumors based on three-dimensional (3D) images of the TCIA dataset. The proposed algorithm has been formed by 2 main steps, segmentation, and classification. In the first level, Histogram Equalization has been chosen to adjust image intensity, then MSER and SURF are applied to select the 2D slices, containing tumors. Besides, the fuzzy system and k-means algorithm are used to segment the selected 2D slices, resulting in a unique 3D segmented model. Finally, SVM is implemented for tumor classification, using the GLCM-HOG features. The most significant item of the method is that, unlike the 2D methods, this scheme provides the depth of tumors based on the capabilities of 3D space. Furthermore, it has less computational complexity and subsequently takes less time than the deep learning-based method. Experimental results demonstrate the superior performance of the proposed method compared to the new algorithms, with DCS = 0.99 +/- 0.008, accuracy = 91.67%, recall = 100%, and precision = 85.71%.
C1 [Heidari, Maryam; Mehrdad, Vahid] Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mehrdad, V (corresponding author), Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Iran.
EM Mehrdad.v@lu.ac.ir
CR Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Azad C, 2022, MULTIMEDIA SYST, V28, P1289, DOI 10.1007/s00530-021-00817-2
   Banerjee S, 2018, INFORM SCIENCES, V424, P337, DOI 10.1016/j.ins.2017.10.011
   Basu A, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116377
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Cao HC, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105934
   Chen W, 2019, IEEE ACCESS, V7, P75591, DOI 10.1109/ACCESS.2019.2921434
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Gaur P, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103076
   Gonzalez R. C., 2009, Using MATLAB®
   Gupta K, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104268
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huret JL, 2003, NUCLEIC ACIDS RES, V31, P272, DOI 10.1093/nar/gkg126
   Jiang J, 2019, IEEE T MED IMAGING, V38, P134, DOI 10.1109/TMI.2018.2857800
   Kalaivani S, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P100, DOI 10.1109/ICECA.2017.8212773
   Kalia R., 2011, An analysis of the effect of different image preprocessing techniques on the performance of SURF: Speeded Up Robust Features, P1, DOI [10.1109/FCV.2011.5739756, DOI 10.1109/FCV.2011.5739756]
   Kamal Uday, 2020, Thoracic Image Analysis. Second International Workshop, TIA 2020. Held in Conjunction with MICCAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12502), P36, DOI 10.1007/978-3-030-62469-9_4
   Kamal U, 2020, Arxiv, DOI [arXiv:1812.01951, 10.48550/arXiv.1812.01951, DOI 10.48550/ARXIV.1812.01951]
   Kasinathan G, 2019, EXPERT SYST APPL, V134, P112, DOI 10.1016/j.eswa.2019.05.041
   Kaur T, 2022, CIRC SYST SIGNAL PR, V41, P3397, DOI 10.1007/s00034-021-01939-8
   Keziah TA., 2018, Int Res J Eng Technol, V4, P3114
   Liu H, 2019, PHYS MEDICA, V63, P112, DOI 10.1016/j.ejmp.2019.06.003
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Lu SY, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11010033
   Makaju S, 2018, PROCEDIA COMPUT SCI, V125, P107, DOI 10.1016/j.procs.2017.12.016
   Masood A, 2018, J BIOMED INFORM, V79, P117, DOI 10.1016/j.jbi.2018.01.005
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   McConnell R. K., 1986, Google Patents
   O'Hea BJ, 1998, J AM COLL SURGEONS, V186, P423, DOI 10.1016/S1072-7515(98)00060-X
   Paing MP, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P302, DOI 10.1109/ECTICon.2017.8096233
   Palanivinayagam A, 2022, INT J E-ADOPT, V14, P1, DOI 10.4018/IJEA.310001
   Pezzano G, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105792
   Rendon-Gonzalez Elmar., 2016, 9th_International_Kharkiv_Symposium on_Physics_and_Engineering_of_Microwaves,_Millimeter_and_Submillimeter_Waves,_MSMW 2016, DOI DOI 10.1109/MSMW.2016.7537995
   Rohmah Luqy Nailur, 2020, 2020 3rd International Conference on Information and Communications Technology (ICOIACT), P105, DOI 10.1109/ICOIACT50329.2020.9332123
   Sangamithraa PB, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2201, DOI 10.1109/WiSPNET.2016.7566533
   Sarker P, 2017, INT CONF ADV ELECTR, P731, DOI 10.1109/ICAEE.2017.8255451
   Sethy PK, 2020, Detection of coronavirus disease (covid-19) based on deep features
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shivhare S. N., Brain Tumor Segmentation Using Random Walks from MRI Images, P29, DOI [10.1007/978-981-33-4299-6_3, DOI 10.1007/978-981-33-4299-6_3]
   Shivhare SN, 2021, MULTIMED TOOLS APPL, V80, P26969, DOI 10.1007/s11042-021-10969-y
   Singh A, 2022, MATH BIOSCI ENG, V19, P12518, DOI 10.3934/mbe.2022584
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Soltani-Nabipour J, 2020, NUCL ENG TECHNOL, V52, P2313, DOI 10.1016/j.net.2020.03.011
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Sun W., 2016, SPIE Medical Imaging, p97850Z, DOI DOI 10.1117/12.2216307
   Swamy SR, 2023, COMPUT SYST SCI ENG, V45, P869, DOI 10.32604/csse.2023.029822
   Tafti AP, 2018, IEEE INT CONF HEALT, P412, DOI 10.1109/ICHI.2018.00078
   Togaçar M, 2020, BIOCYBERN BIOMED ENG, V40, P23, DOI 10.1016/j.bbe.2019.11.004
   Ulutas H, 2023, ALEX ENG J, V74, P345, DOI 10.1016/j.aej.2023.05.036
   Uzelaltinbulat S, 2017, PROCEDIA COMPUT SCI, V120, P140, DOI 10.1016/j.procs.2017.11.221
   Vapnik V., 2013, The nature of statistical learning theory
   Vas M., Lung cancer detection system using lung CT image processing, P1, DOI [10.1109/ICCUBEA.2017.8463851, DOI 10.1109/ICCUBEA.2017.8463851]
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Wu WH, 2020, MED PHYS, V47, P4054, DOI 10.1002/mp.14248
   Xiao ZT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111787
   Xiufeng Zhang, 2020, 2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE), P698, DOI 10.1109/ICISCAE51034.2020.9236798
   Yang JZ, 2021, COMPUT MED IMAG GRAP, V92, DOI 10.1016/j.compmedimag.2021.101957
   Yang XY, 2020, Arxiv, DOI arXiv:2003.13865
   Zhang GB, 2022, MED BIOL ENG COMPUT, V60, P3311, DOI 10.1007/s11517-022-02667-0
   Zhang WH, 2017, COMPUT BIOL MED, V91, P168, DOI 10.1016/j.compbiomed.2017.10.005
   Zhao XM, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/aaf44b
NR 62
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17174-z
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800016
DA 2024-07-18
ER

PT J
AU Wang, LD
   Zhang, Y
   Yuan, J
   Cao, SH
   Zhou, B
AF Wang, Lidong
   Zhang, Yin
   Yuan, Jie
   Cao, Shihua
   Zhou, Bin
TI RLGAT: Retweet prediction in social networks using representation
   learning and GATs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retweet prediction; Social network; Graph Attention Networks;
   Representation learning; XLNet
ID BEHAVIOR PREDICTION; MODEL
AB With the exponential growth of social media platforms, retweet behavior has become a crucial factor in various social network applications like message diffusion, business intelligence, and E-commerce recommendations. The primary objective of this paper is to predict whether a user will retweet a tweet posted by followees. However, the existing prediction methods cannot model the complex interaction between users. Moreover, some complex and implicit features (e.g. content semantic and structural information) are difficult to be represented and fused reasonably and comprehensively. To address the above issues, we propose a novel framework named RLGAT by using Representation Learning and Graph Attention Networks (GATs) for retweet prediction. RLGAT combines content, structure and social attributes to predict retweet behavior. XLNet-CNN and E-SDNE are employed to generate content and structural representations, respectively. Based on the extracted features of content, structure and social attributes, the AE-GATs model for prediction can further incorporate the correlation of nodes into the generation of node representations. The two real-world datasets are extracted from Sina Microblog and Twitter. The results demonstrate the effectiveness of XLNet-CNN, E-SDNE, AE-GATs, and RLGAT. Notably, RLGAT surpasses state-of-the-art methods, achieving an F1 score of 0.8078 and 0.8017 on Sina and Twitter, respectively. RLGAT is not only effective in predicting user's retweet behavior, but also beneficial for predicting information diffusion.
C1 [Wang, Lidong; Cao, Shihua; Zhou, Bin] Hangzhou Normal Univ, Sch Engn, Hangzhou 310018, Peoples R China.
   [Zhang, Yin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310012, Zhejiang, Peoples R China.
   [Yuan, Jie] Zhejiang Wanli Univ, Coll Big Data & Software Engn, Ningbo 315100, Peoples R China.
   [Cao, Shihua] Chinese Univ Hong Kong, Informat Engn Dept, Hong kong 999077, Peoples R China.
C3 Hangzhou Normal University; Zhejiang University; Zhejiang Wanli
   University; Chinese University of Hong Kong
RP Wang, LD (corresponding author), Hangzhou Normal Univ, Sch Engn, Hangzhou 310018, Peoples R China.
EM wld@hznu.edu.cn
OI Wang, Lidong/0000-0003-4699-7937; Cao, Shihua/0000-0002-9391-2345
FU Authors contribution statement
FX This study is supported by Zhejiang Provincial High-Education Teaching
   Reform Project under Grant No.jg20220770, Medical and Health Technology
   Plan of Zhejiang Province (No. 2022507615), China Knowledge Centre for
   Engineering Sciences and Technology(CKCEST), Natural Science Foundation
   of Ningbo (No. 2023J297).r Authors contribution statement
CR Amitani R, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2021, P94, DOI 10.1145/3508230.3508244
   Babic Karlo, 2021, 2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO), P395, DOI 10.23919/MIPRO52101.2021.9596693
   Cai TT, 2022, IEEE T KNOWL DATA EN, V34, P1993, DOI 10.1109/TKDE.2020.3003047
   Cheng J, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P925, DOI 10.1145/2566486.2567997
   Daga I, 2020, PROCEDIA COMPUT SCI, V168, P123, DOI 10.1016/j.procs.2020.02.273
   Dai TJ, 2022, DIGIT COMMUN NETW, V8, P186, DOI 10.1016/j.dcan.2021.07.003
   Firdaus S.N., 2021, ONLINE SOC NETW MEDI, V25
   Firdaus SN, 2019, INT J MACH LEARN CYB, V10, P2071, DOI 10.1007/s13042-018-0798-5
   Guo HH, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/4431416
   Huang S., 2023, 2023 3 INT C NEUR NE, P70, DOI [10.1109/NNICE58320.2023.10105676, DOI 10.1109/NNICE58320.2023.10105676]
   Jain L, 2023, ACM T WEB, V17, DOI 10.1145/3580516
   Jain PK, 2022, MULTIMED TOOLS APPL, V81, P6979, DOI 10.1007/s11042-022-11972-7
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Joshi A, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116846
   Khan PI, 2021, arXiv, DOI [10.48550/arXiv.2106.07344, DOI 10.48550/ARXIV.2106.07344]
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Lahuerta-Otero E, 2018, ONLINE INFORM REV, V42, P562, DOI 10.1108/OIR-04-2017-0135
   Lei K, 2019, IEEE INFOCOM SER, P388, DOI [10.1109/INFOCOM.2019.8737631, 10.1109/infocom.2019.8737631]
   Li Q, 2023, INFORM SCIENCES, V619, P795, DOI 10.1016/j.ins.2022.11.072
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Liu YB, 2018, NEUROCOMPUTING, V275, P733, DOI 10.1016/j.neucom.2017.09.015
   Lymperopoulos IN, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113785
   Ma RF, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P525, DOI 10.1145/3331184.3331236
   Malekzadeh M, 2021, 2021 IEEE 12TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P84, DOI 10.1109/UEMCON53757.2021.9666633
   Ortiz-Ospina E., 2023, The rise of social media
   Pan L, 2023, APPL INTELL, V53, P1855, DOI 10.1007/s10489-022-03413-7
   Saxena N, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103360
   Sharma S, 2022, MULTIMED TOOLS APPL, V81, P27309, DOI 10.1007/s11042-022-12815-1
   Tsugawa S., 2019, P INT AAAI C WEB SOC, P493
   Turenne N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189080
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang J, 2022, NEURAL PROCESS LETT, V54, P523, DOI 10.1007/s11063-021-10642-3
   Wang LD, 2022, NEURAL COMPUT APPL, V34, P13219, DOI 10.1007/s00521-022-07174-9
   Wang LD, 2022, APPL INTELL, V52, P8209, DOI 10.1007/s10489-021-02716-5
   Wang LD, 2019, IEEE ACCESS, V7, P152429, DOI 10.1109/ACCESS.2019.2948073
   Wang SQ, 2020, INFORM SCIENCES, V515, P218, DOI 10.1016/j.ins.2019.12.017
   [王绍卿 Wang Shaoqing], 2019, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V59, P270
   Wu HZ, 2020, AAAI CONF ARTIF INTE, V34, P254
   Xiang TC, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103337
   Xiao YP, 2023, IEEE T KNOWL DATA EN, V35, P4682, DOI 10.1109/TKDE.2022.3144310
   Yan Yizhou., 2021, Comput. Soc. Netw., V8, P1
   Yang ZL, 2019, ADV NEUR IN, V32
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yin H, 2021, WORLD WIDE WEB, V24, P1027, DOI 10.1007/s11280-020-00850-7
   Yu L, 2022, KNOWL-BASED SYST, V255, DOI 10.1016/j.knosys.2022.109740
   Yuan CY, 2021, LECT NOTES ARTIF INT, V12459, P347, DOI 10.1007/978-3-030-67664-3_21
   Zhang J, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700398
   Zhang Q., 2015, In Proc AAAI Conf Artif Intell, V29, P1
   Zhang Q, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P75, DOI 10.1145/2983323.2983809
   Zhang YA, 2023, KNOWL-BASED SYST, V263, DOI 10.1016/j.knosys.2023.110255
   Zhou XK, 2021, IEEE T NETW SCI ENG, V8, P894, DOI 10.1109/TNSE.2021.3064952
NR 52
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16902-9
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T9UR2
UT WOS:001081367600001
DA 2024-07-18
ER

PT J
AU Bhagat, M
   Kumar, D
AF Bhagat, Monu
   Kumar, Dilip
TI Performance enhancement of kernelized SVM with deep learning features
   for tea leaf disease prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; VGG-16; Augmentation; KNN; RF; XGB; Kernel SVM
ID IDENTIFICATION; CLASSIFICATION
AB India is one of the world's leading tea producers, yet more than 70% of the country's tea is consumed domestically. Tea leaf diseases have a significant impact on the quality and yield of tea. So, it is very important to find a more accurate method to identify tea leaf diseases correctly. Due to very limited number of tea leaf images, classification is very difficult. Very frequently overfitting of model occurs. To cope up with this, we applied images augmentation process, that increased dataset nearly fourteen times. But still this number of datasets is not adequate for DL based classification. So, we used here deep learning for feature extraction and machine learning based classifier for classification. In this work, we have proposed a hybrid technique that combines deep learning-based features of augmented dataset with machine learning based classifier for getting better classification result. In proposed work, VGG-16 is used for colour feature extraction from the tea leaf dataset. Based on this feature, model is built and several machine learning-based classifiers like KNN, XGB, Random Forest, and kernelized SVM are employed for classification task. Our proposed model achieved highest classification accuracy with Sigmoid and Linear kernel based SVM and VGG-16 features. The accuracy of proposed model is 96.67%. We compared our proposed work with existing work on tea leaf dataset and found that our model is performing comparatively better.
C1 [Bhagat, Monu; Kumar, Dilip] Natl Inst Technol Jamshedpur, Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Bhagat, M (corresponding author), Natl Inst Technol Jamshedpur, Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM 2018rscs002@nitjsr.ac.in
RI Bhagat, Dr. Monu/GLS-1071-2022
OI Bhagat, Dr. Monu/0000-0001-9074-9653
CR [Anonymous], 2008, US
   Bhagat Monu, 2023, International Journal of Information Technology, P465, DOI 10.1007/s41870-022-01136-z
   Bhagat Monu, 2019, 2019 Devices for Integrated Circuit (DevIC). Proceedings, P141, DOI 10.1109/DEVIC.2019.8783800
   Bhagat M, 2023, MULTIMED TOOLS APPL, V82, P26225, DOI 10.1007/s11042-023-14370-9
   Bhagat M, 2022, MULTIMED TOOLS APPL, V81, P33897, DOI 10.1007/s11042-022-12984-z
   Chaudhary Archana, 2016, Information Processing in Agriculture, V3, P215, DOI 10.1016/j.inpa.2016.08.002
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Han BY, 2002, J CHEM ECOL, V28, P2203, DOI 10.1023/A:1021045231501
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hossain MS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P150, DOI 10.1109/CSPA.2018.8368703
   Hu GS, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100696
   Hu GS, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107984
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Kiani E, 2017, PROCEDIA COMPUT SCI, V120, P893, DOI 10.1016/j.procs.2017.11.323
   Kobayashi T, 2001, PHYTOPATHOLOGY, V91, P316, DOI 10.1094/PHYTO.2001.91.3.316
   Li SL, 2020, NEURAL COMPUT APPL, V32, P1971, DOI 10.1007/s00521-019-04378-4
   Liu F, 2019, IEEE ACCESS, V7, P119209, DOI 10.1109/ACCESS.2019.2935222
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nwankpa C, 2018, Arxiv, DOI arXiv:1811.03378
   Oppenheim D, 2019, PHYTOPATHOLOGY, V109, P1083, DOI 10.1094/PHYTO-08-18-0288-R
   Pani Priyanka, @businessline
   Rakshit Ishita Ayan Dutt, 2019, Business Standard India- via Business Standard
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Römer C, 2011, COMPUT ELECTRON AGR, V79, P180, DOI 10.1016/j.compag.2011.09.011
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tetila EC, 2017, IEEE GEOSCI REMOTE S, V14, P2190, DOI 10.1109/LGRS.2017.2743715
   tocklai, ABOUT US
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Wang T, 2023, INFORM PROCESS AGR, V10, P267, DOI 10.1016/j.inpa.2021.12.004
   Xie CQ, 2017, COMPUT ELECTRON AGR, V135, P154, DOI 10.1016/j.compag.2016.12.015
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang XC, 2023, COMPUT ELECTRON AGR, V206, DOI 10.1016/j.compag.2023.107664
   Zhao XH, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2022.106717
NR 37
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17172-1
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600026
DA 2024-07-18
ER

PT J
AU Bi, ZQ
   Li, HF
   Zhang, WA
   Dong, Z
AF Bi, Zhongqin
   Li, Huanfeng
   Zhang, Weina
   Dong, Zhen
TI Variational bayesian clustering algorithm for unsupervised anomalous
   sound detection incorporating VH-BCL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomalous sound detection; Variational Bayesian clustering method;
   Domain generalization; Hybrid example data augmentation
AB In industrial environments, acoustic detection of equipment can often significantly change the acoustic characteristics between training and testing data due to the absence of anomalous data guidance, as well as changes in machine operating conditions or environmental noise. In addition, during model learning, there are cases where the target data is inaccessible, but an accurate model is still needed for the invisible target domain. To address these challenges, we propose an unsupervised approach for anomalous sound detection applied to unlabeled anomalous sound detection scenarios, which is an optimization algorithm based on joint deep learning and variational Gaussian mixture models, by two jointly training neural networks for feature extraction and using the variational Gaussian mixture model to analyze the obtained embeddings for clustering. We propose a new hybrid example data enhancement method, to generate examples in multiple ways, combining various methods to align the distribution between different domains. The improved sub-cluster AdaCos loss function is used to exclude potential anomalies by learning fewer finite distributions than the standard AdaCos. Experimental results show that the proposed method achieves an average area under curve of 82.70% and an average F1 score of 69.42% on the datasets of seven industrial equipment machine types. The average area under curve for the source domain is 85.49% and for the target domain is 75.63%.
C1 [Bi, Zhongqin; Li, Huanfeng; Zhang, Weina] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
   [Dong, Zhen] State Grid Shanghai Elect Power Co, Elect Power Res Inst, Shanghai 200437, Peoples R China.
C3 Shanghai University of Electric Power; State Grid Corporation of China
RP Zhang, WA (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
EM 277969721@qq.com; mszhangwn@shiep.edu.cn
FU Project of Shanghai Science and Technology Committee [23010501500]
FX This work was supported by the Project of Shanghai Science and
   Technology Committee (No.23010501500)
CR Cho W, 2018, MULTIMED TOOLS APPL, V77, P18563, DOI 10.1007/s11042-017-5210-z
   Cohen O, Unsupervised anomalous detection based on riemannian geometry
   Coletta LFS, 2022, COMPUT ELECTRON AGR, V196, DOI 10.1016/j.compag.2022.106901
   Corduneanu A., 2001, Artificial intelligence and Statistics, P27
   Dai QY, 2023, IEEE T CYBERNETICS, V53, P5094, DOI 10.1109/TCYB.2022.3172790
   Deng Y, 2022, Technical report, DCASE2022 Challenge. Tech Rep
   Dohi K, 2022, Arxiv, DOI arXiv:2206.05876
   Gao J, 2022, IEEE Trans Circ Syst Video Technol
   Gou J, Unsupervised anomalous sound detection using feature extractor and anomaly detector
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kapka S, 2020, Arxiv, DOI arXiv:2007.05314
   Koizumi Y, 2019, IEEE-ACM T AUDIO SPE, V27, P212, DOI 10.1109/TASLP.2018.2877258
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566
   Li X, Anomalous sound detection with ensemble of cnn-based features and autoencoder approaches
   Liu G, Unsupervised anomalous sound detection under domain shift conditions based on mobilefacenets and masked autoregressive flow
   Maas A.L., 2013, P 30 INT C MACH LEAR, V30, P3
   Mei LF, 2022, J SOUND VIB, V540, DOI 10.1016/j.jsv.2022.117277
   Mishra HK, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P183, DOI 10.1109/ICAPR.2009.89
   Naga Srinivasu P, 2023, J Healthc Eng, V2023
   Nasios N, 2006, IEEE T SYST MAN CY B, V36, P849, DOI 10.1109/TSMCB.2006.872273
   Nunes EC, 2021, Arxiv, DOI arXiv:2102.07820
   Park J, 2020, DCASE, P140
   Peng T, Unsupervised abnormal sound detection based on spectral coherence and feature fusion in domain displacement condition
   Primus P, 2020, Arxiv, DOI arXiv:2011.02949
   Purohit H, 2020, Arxiv, DOI arXiv:2009.12042
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Summers C, 2019, IEEE WINT CONF APPL, P1262, DOI 10.1109/WACV.2019.00139
   Tokozume Y, 2018, Arxiv, DOI arXiv:1711.10282
   Wang S, Ensemble of multiple anomaly detectors under domain generalization conditions
   Wei Y., 2022, Tech. Rep.
   Wilkinghoff K, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534290
   Yang FL, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020037
   Zeng Y., 2022, Tech. Rep, Tech. Rep.
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang X, 2019, PROC CVPR IEEE, P10815, DOI 10.1109/CVPR.2019.01108
   Zhu YS, 2022, LECT NOTES COMPUT SC, V13694, P395, DOI 10.1007/978-3-031-19830-4_23
NR 37
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17006-0
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600029
DA 2024-07-18
ER

PT J
AU Iftikhar, H
   Luximon, Y
AF Iftikhar, Hassan
   Luximon, Yan
TI Multiple layer digital wayfinding information: A study of user
   preferences for information content and design in wayfinding
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital wayfinding; Multi-layer information; User preferences; Complex
   environments; Information design
ID MOBILE; SYSTEMS; MODEL; MAPS
AB Wayfinding applications on mobile devices are gradually becoming efficient in delivering environmental information. These applications provide a variety of wayfinding information such as location, orientation, route planning, spatial layout and provided facilities. The information is presented in multiple layers which requires a thoughtful design to effectively deliver the information, especially in complex environments. The objective of the present study is to explore the user preferences for information content and design in wayfinding applications. A wayfinding experiment has been conducted in a complex university setting by using the wayfinding application with a multi-layered information design. Thirty-one participants performed four wayfinding tasks using the purpose-built wayfinding application. Data has been collected by mobile screen recording, pre- and post-experiment interviews. Significant behavioural patterns have been observed for accessing the information content and user preferences have also been explored for the information design. Accurate location pointer, written directions and five to six-layered information design have been preferred for mobile wayfinding information. Information for validation in the real environment has been a significant factor during wayfinding tasks. Significant gender differences have also been recorded. A synthesis of wayfinding information from digital and real-world sources has been suggested to improve the existing wayfinding systems in complex institutional environments.
C1 [Iftikhar, Hassan; Luximon, Yan] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Iftikhar, H (corresponding author), Hong Kong Polytech Univ, Hong Kong, Peoples R China.
EM hassan.iftikhar@connect.polyu.hk
RI Luximon, Yan/A-7946-2010; Iftikhar, Hassan/GSN-5463-2022
OI Iftikhar, Hassan/0000-0003-4187-8082
FU This study was supported by the UGC Funding Scheme (RL6A) from Hong Kong
   Polytechnic University. [RL6A]; Hong Kong Polytechnic University
FX This study was supported by the UGC Funding Scheme (RL6A) from Hong Kong
   Polytechnic University.
CR Adipat B, 2011, MIS QUART, V35, P99
   Allen GL, 1999, PROF GEOGR, V51, P554
   Ayob NZB, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P427, DOI 10.1109/ICIME.2009.99
   Boyd D.R., 1993, Acquisit. Libr., V5, P61, DOI [10.1300/J101v05n09_07, DOI 10.1300/J101V05N09_07]
   Brewster S, 2002, PERS UBIQUIT COMPUT, V6, P188, DOI 10.1007/s007790200019
   Carlson LA, 2010, CURR DIR PSYCHOL SCI, V19, P284, DOI 10.1177/0963721410383243
   Chambers M, 2011, CRIT CARE NURS Q, V34, P317, DOI 10.1097/CNQ.0b013e31822bad05
   Cheung AKL, 2006, LECT NOTES COMPUT SC, V4295, P90
   Devlin AS, 2014, BEHAV SCI-BASEL, V4, P423, DOI 10.3390/bs4040423
   Devlin AS, 1997, J ENVIRON PSYCHOL, V17, P99, DOI 10.1006/jevp.1997.0045
   EVANS GW, 1980, J APPL PSYCHOL, V65, P474, DOI 10.1037/0021-9010.65.4.474
   Gao Q, 2015, HUM FACTOR ERGON MAN, V25, P66, DOI 10.1002/hfm.20523
   GARLING T, 1989, J ENVIRON PSYCHOL, V9, P269, DOI 10.1016/S0272-4944(89)80009-X
   Garrett J. J., 2010, The elements of user experience: user-centered design for the web and beyond
   Gibson David., 2009, The Wayfinding Handbook: Information Design For Public Spaces
   He G., 2014, SPATIAL COGNITION PO, P44
   Iftikhar H, 2023, HERD-HEALTH ENV RES, V16, P250, DOI 10.1177/19375867221134590
   Iftikhar H, 2022, FACILITIES, V40, P452, DOI 10.1108/F-06-2021-0052
   Iftikhar H, 2021, J NAVIGATION, V74, P360, DOI 10.1017/S0373463320000521
   Iftikhar H, 2020, FACILITIES, V38, P871, DOI 10.1108/F-04-2020-0035
   Ishikawa T, 2008, J ENVIRON PSYCHOL, V28, P74, DOI 10.1016/j.jenvp.2007.09.002
   Jeffrey C., 2017, INFORM DESIGN RES PR, P509
   Kaasinen E, 2003, PERS UBIQUIT COMPUT, V7, P70, DOI 10.1007/s00779-002-0214-7
   Kalantari S, 2022, J ENVIRON PSYCHOL, V79, DOI 10.1016/j.jenvp.2021.101744
   Kinsley Kirsten M., 2016, Journal of Access Services, V13, P7, DOI 10.1080/15367967.2016.1154465
   Lawton CA, 2002, SEX ROLES, V47, P389, DOI 10.1023/A:1021668724970
   Legge GE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076783
   Lemoncello R, 2010, BRAIN INJURY, V24, P541, DOI 10.3109/02699051003610425
   [李虹 Li Hong], 2013, [心理学报, Acta Psychologica Sinica], V45, P94
   Li QC, 2020, BEHAV INFORM TECHNOL, V39, P837, DOI 10.1080/0144929X.2019.1622786
   Liao H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082949
   Lingwood J, 2018, J EXP CHILD PSYCHOL, V166, P178, DOI 10.1016/j.jecp.2017.08.012
   Liu L., 2015, Cross-Cultural Commun, V11, P40, DOI [10.3968/7357, DOI 10.3968/7357]
   MACEACHREN AM, 1992, ANN ASSOC AM GEOGR, V82, P245, DOI 10.1111/j.1467-8306.1992.tb01907.x
   McFall R, 2005, ELECTRON LIBR, V23, P72, DOI 10.1108/02640470510582754
   McGrath Paddy T., 2011, Structural Survey, V29, P244, DOI 10.1108/02630801111148211
   Mi N, 2014, UNIVERSAL ACCESS INF, V13, pCP4, DOI 10.1007/s10209-013-0321-4
   Neil T., 2014, Mobile design pattern gallery: UI patterns for smartphone apps
   Oyelola K., 2014, WAYFINDING U SETTING
   Park SY, 2009, EDUC TECHNOL SOC, V12, P150
   Passini R., 1996, DESIGN STUDIES, V17, P319, DOI DOI 10.1016/0142-694X(96)00001-4
   Petrovcic A, 2018, INT J HUM-COMPUT INT, V34, P251, DOI 10.1080/10447318.2017.1345142
   Rechel B, 2009, INT J NURS STUD, V46, P1025, DOI 10.1016/j.ijnurstu.2008.12.008
   Reilly D, 2009, PERS UBIQUIT COMPUT, V13, P321, DOI 10.1007/s00779-008-0207-2
   Richter KF, 2004, LECT NOTES COMPUT SC, V3343, P58
   Rodriguez-Sanchez MC, 2014, EXPERT SYST APPL, V41, P7210, DOI 10.1016/j.eswa.2014.05.031
   Ruddle R, 2006, Presence: Teleoperators and Virtual Environments, P7
   Sadek A.H., 2015, 3 EUR C DESIGN4HEALT, V3, P13
   Schrom-Feiertag H, 2017, SPAT COGN COMPUT, V17, P163, DOI 10.1080/13875868.2016.1228654
   Sykes E R., 2015, Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering, P120
   T?r?k, 2018, INT ARCH PHOTOGRAMME, P4, DOI [10.5194/isprs-archives-XLII-4-631-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-631-2018]
   Tidwell J., 2010, Designing interfaces: Patterns for effective interaction design
   Vainio T, 2011, DIGIT CREAT, V22, P26, DOI 10.1080/14626268.2011.538929
   Vandenberg AE, 2016, J PHYS ACT HEALTH, V13, P189, DOI 10.1123/jpah.2014-0577
   Wagner N, 2014, COMPUT HUM BEHAV, V37, P270, DOI 10.1016/j.chb.2014.05.003
   Weisman G, 1985, P INT C BUILD US SAF, P9
   Wiener JM, 2009, SPAT COGN COMPUT, V9, P152, DOI 10.1080/13875860902906496
   Yi MY, 2003, INT J HUM-COMPUT ST, V59, P431, DOI 10.1016/S1071-5819(03)00114-9
NR 58
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17085-z
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600006
DA 2024-07-18
ER

PT J
AU Kim, H
   Zhao, LL
   Pang, ZQ
   Su, XH
   Lee, JS
AF Kim, Hyeongbok
   Zhao, Lingling
   Pang, Zhiqi
   Su, Xiaohong
   Lee, Jin Suk
TI Joint reconstruction and deidentification for mobile identity
   anonymization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Generative adversarial networks; Image generation;
   Identity anonymization
ID FACE; PRIVACY
AB The growing use of deep learning methods in various applications has raised concerns about privacy, as these methods heavily rely on large-scale datasets. To address this issue, anonymization methods have been proposed that usually use face detection models to remove the original face and regenerate a new one. Although these methods have achieved promising performance, alternative face detection models significantly increase the training cost and inference time. To solve these problems, we propose an end-to-end mobile anonymization method with a joint reconstruction and deidentification (JRD) framework. We introduce deidentification loss into a generative adversarial network to anonymize the original image and add reconstruction loss to reconstruct the background of the original image. By balancing these two losses, we can anonymize the identity without changing the background and no longer rely on additional face detection models. In addition, to ensure the essential difference between the generated and original images, we generated a random code for each original image. Further, we verified the effectiveness and superiority of JRD on the CelebA dataset. The experimental results show that JRD not only outperforms existing one-to-one methods but is also superior to many-to-one methods.
C1 [Kim, Hyeongbok; Zhao, Lingling; Pang, Zhiqi; Su, Xiaohong] Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China.
   [Lee, Jin Suk] Testworks Inc, Seoul, South Korea.
C3 Harbin Institute of Technology
RP Pang, ZQ; Su, XH (corresponding author), Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China.
EM kimhyeongbok@naver.com; zhaoll@hit.edu.cn; zqpang98@gmail.com;
   sxh@hit.edu.cn; jslee@testworks.co.kr
RI ZHAO, lingling/AAM-3755-2020
OI ZHAO, lingling/0000-0003-0315-4569; Pang, Zhiqi/0000-0003-0940-3351
CR Bińkowski M, 2021, Arxiv, DOI [arXiv:1801.01401, DOI 10.48550/ARXIV.1801.01401]
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Cao Y, 2021, MULTIMED TOOLS APPL, V80, P29139, DOI 10.1007/s11042-021-11136-z
   Chen X., 2016, Adv Neural Inf Process Sys, V29
   Desiato D, 2018, SEBD
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo JF, 2021, APPL INTELL, V51, P5953, DOI 10.1007/s10489-020-02121-4
   Harvey A., 2019, Megapixels
   Hensel M, 2017, ADV NEUR IN, V30
   Hukkelås H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kuang ZZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3182, DOI 10.1145/3474085.3475464
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Lee D, 2021, MULTIMED TOOLS APPL, V80, P34517, DOI 10.1007/s11042-020-08776-y
   Li CL, 2023, APPL SOFT COMPUT, V142, DOI 10.1016/j.asoc.2023.110326
   Li X, 2020, MULTIMED TOOLS APPL, V79, P35761, DOI 10.1007/s11042-020-09593-z
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Ma T., 2021, arXiv
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Maximov M, 2020, PROC CVPR IEEE, P5446, DOI 10.1109/CVPR42600.2020.00549
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Pang Z., 2022, IEEE Trans. Multimed.
   Pang ZQ, 2022, IEEE T CIRC SYST VID, V32, P3164, DOI 10.1109/TCSVT.2021.3103753
   Pang ZQ, 2022, APPL INTELL, V52, P2987, DOI 10.1007/s10489-021-02551-8
   Rodríguez-Triana MJ, 2020, IEEE T LEARN TECHNOL, V13, P718, DOI 10.1109/TLT.2020.2995557
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan S, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1589
   Sheng WJ, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107868
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wei K, 2020, IEEE T INF FOREN SEC, V15, P3454, DOI 10.1109/TIFS.2020.2988575
   Wu YF, 2019, J COMPUT SCI TECH-CH, V34, P47, DOI 10.1007/s11390-019-1898-8
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Zhang YP, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3404893
   Zhao C, 2022, A Novel Weakly-supervised approach for RGB-D-based Nuclear Waste Object Detection and Categorization
   Zhao H, 2023, Multimed Tools Appl, P1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17107-w
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900010
DA 2024-07-18
ER

PT J
AU Shrivastava, P
   Alam, B
   Alam, M
AF Shrivastava, Pranav
   Alam, Bashir
   Alam, Mansaf
TI A hybrid lightweight blockchain based encryption scheme for security
   enhancement in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain technology; Hybrid lightweight data encryption; Cloud
   computing; Optimization; Cryptographic hashing; Proof of authority
ID ARCHITECTURE
AB Cloud services provide an optimal form of demand based data outsourcing. The large amount of user data sharing increases the possibility of attacks, and unauthorized users get easy data access to the data. Blockchain technology provides better security in the cloud based on its distributed and highly cohesive nature. In order to enhance the block chain based encryption process, the second work intends to propose a blockchain based hybrid optimized cryptography scheme for secure cloud storage. At first, key generation is performed using the ECC approach in the cloud. In cloud user registration, keys and data are needed, and the cloud will provide the user ID. Then, the optimal key selection is performed by using flamingo search optimization (FSO). The public and the private key is selected by using this optimization approach. Afterwards, data encryption is performed using the Elgamal scheme on the owner side. This hybrid lightweight elliptic Elgamal based encryption (HLEEE) approach in key generation and data encryption process increases data security. After the authentication process, the cloud controller maintains the blockchain to protect the data and signatures of the users by generating the hash in blocks. An optimal hash generation is performed using the SHA-256 approach in the blockchain. The generated hash value, encrypted data and timestamp are stored in each block to provide more security. Finally, blockchain validation is performed using the proof of authority (PoA) approach.
C1 [Shrivastava, Pranav; Alam, Bashir] Jamia Millia Islamia, Dept Comp Engn, New Delhi 110025, India.
   [Alam, Mansaf] Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
C3 Jamia Millia Islamia; Jamia Millia Islamia
RP Shrivastava, P (corresponding author), Jamia Millia Islamia, Dept Comp Engn, New Delhi 110025, India.
EM pranav.paddy@gmail.com
RI Shrivastava, Pranav/AAW-2376-2020; ALAM, BASHIR/KGL-8679-2024
OI Shrivastava, Pranav/0000-0002-6598-734X; ALAM,
   BASHIR/0000-0003-0479-682X
CR Al-Shabi M A., 2019, International Journal of Scientific and Research Publications (IJSRP), V9, P576
   Arunkumar B., 2020, Intelligent Systems, Technologies and Applications. Proceedings of Fifth ISTA 2019, India. Advances in Intelligent Systems and Computing (AISC 1148), P273, DOI 10.1007/978-981-15-3914-5_21
   Attaran M., 2019, Journal of Small Business Entrepreneurship, V31, P495, DOI DOI 10.1080/08276331.2018.1466850
   Bello SA, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103441
   Bermani AK, 2021, J DISCRET MATH SCI C, V24, P1613, DOI 10.1080/09720529.2020.1859799
   Chadwick DW, 2020, FUTURE GENER COMP SY, V102, P710, DOI 10.1016/j.future.2019.06.026
   Chinnasamy P, 2021, INVENTIVE COMMUNICAT, P537, DOI DOI 10.1007/978-981-15-7345-3_46
   Deverajan GG, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4202
   Domingo-Ferrer J, 2019, COMPUT COMMUN, V140, P38, DOI 10.1016/j.comcom.2019.04.011
   El Kafhali S, 2022, ARCH COMPUT METHOD E, V29, P223, DOI 10.1007/s11831-021-09573-y
   Gupta A, 2019, J EMERG TECHNOL INNO, V6, P791
   Heidari A, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.539
   Idrees SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080951
   Indira N, 2021, J AMB INTEL HUM COMP, V12, P4643, DOI 10.1007/s12652-020-01860-z
   Kalia P, 2021, WIRELESS PERS COMMUN, V120, P2847, DOI 10.1007/s11277-021-08588-9
   Kratzke N, 2021, J DEF MODEL SIMUL-AP, V18, P39, DOI 10.1177/1548512919895327
   Maciel Paulo, 2022, Journal of Reliable Intelligent Environments, P227, DOI 10.1007/s40860-021-00154-1
   Meshram C, 2019, SOFT COMPUT, V23, P13127, DOI 10.1007/s00500-019-03855-1
   Murthy CVNUB, 2020, IEEE ACCESS, V8, P205190, DOI 10.1109/ACCESS.2020.3036812
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Qazi R., 2019, International Joutnal of Computing and Communications Networks, V1, P46
   Sharma M, 2020, GLOB BUS REV, V21, P142, DOI 10.1177/0972150917741187
   Kumar AS, 2021, CONCURRENT ENG-RES A, V29, P249, DOI 10.1177/1063293X211008586
   Tahir M, 2021, CLUSTER COMPUT, V24, P739, DOI 10.1007/s10586-020-03157-4
   Wang ZH, 2021, IEEE ACCESS, V9, P88564, DOI 10.1109/ACCESS.2021.3090512
   Wei PC, 2020, FUTURE GENER COMP SY, V102, P902, DOI 10.1016/j.future.2019.09.028
   Xue SM, 2019, AUTOM CONTROL COMPUT, V53, P342, DOI 10.3103/S0146411619040114
   Zhu XB, 2020, PERVASIVE MOB COMPUT, V62, DOI 10.1016/j.pmcj.2020.101113
   Zuo YT, 2021, INT J DISTRIB SENS N, V17, DOI 10.1177/1550147721999616
NR 29
TC 2
Z9 2
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-17040-y
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000004
DA 2024-07-18
ER

PT J
AU Chen, JD
   Chen, WR
   Nanehkaran, YA
   Suzauddola, MD
AF Chen, Junde
   Chen, Weirong
   Nanehkaran, Y. A.
   Suzauddola, M. D.
TI MAM-IncNet: an end-to-end deep learning detector for Camellia pest
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camellia oleifera; Insect pest detection; SSD; M-Inception; Transfer
   learning
ID IDENTIFICATION
AB Camellia oil is one of the most healthy edible oils in the world. It has the effects of lowering blood pressure, reducing blood fat, and softening blood vessels. Whereas, the Camellia oleifera plant is easily infected by various pests and diseases in the process of growing, which limits the yield of Camellia oil. Thereupon, seeking an intelligent information tool to automatically detect Camellia oleifera pests is of great importance. Recent development in deep learning (DL)-based methods has provided promising performance in plant pest detection. However, to date, DL methods have been rarely applied in this field, except that some existing work focuses on it from public datasets. The main reasons behind the limited usage of DL models in Camellia pest detection include: a large number of training samples, which is difficult to collect, the complicated backdrops of experimental materials, which are not easy to train an efficient model, the low recognition accuracy, which is hard to apply in practical scenarios, and others. Therefore, this study proposes a novel network architecture, namely MAM-IncNet, to address these challenges. Referring to the cascaded structure of single shot multibox detector (SSD), we substitute the former convolutional layers of SSD with the optimized Inception modules (M-Inception), and the pre-trained VGG16 is utilized as the backbone network. Further, a hybrid attention mechanism including channel-wise and spatial attention is incorporated into the network to realize the maximum reuse of inter-channel relationships and spatial point characteristics. The proposed method has attained a recall rate of 81.44% for the detection of Camellia oleifera pests in practical field scenarios. Experimental findings demonstrate the efficacy and feasibility of the proposed method for the detection of Camellia oleifera insect pests.
C1 [Chen, Junde] Xiangtan Univ, Dept Elect Commerce, Xiangtan 411100, Peoples R China.
   [Chen, Weirong] Ningde Normal Univ, Dept Informat & Elect Engn, Ningde 352100, Peoples R China.
   [Nanehkaran, Y. A.] Yancheng Teachers Univ, Sch Informat Engn, Yancheng 224000, Peoples R China.
   [Suzauddola, M. D.] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
C3 Xiangtan University; Ningde Normal University; Yancheng Teachers
   University; Xiamen University
RP Chen, JD (corresponding author), Xiangtan Univ, Dept Elect Commerce, Xiangtan 411100, Peoples R China.
EM chen2wo@126.com; cwrndnu@163.com; artavil20@gmail.com;
   suzauddola@stu.xmu.edu.cn
RI Nanehkaran, Yaser Ahangari/AAN-6150-2021
OI Nanehkaran, Yaser Ahangari/0000-0002-8055-3195; Chen,
   Junde/0000-0003-1748-4374
FU Hunan Provincial Natural Science Research Fund
FX The work is partially supported by the Research Funds for the project of
   Automatic identification and diagnosis of plant diseases and pests on
   mobile phones using big data techniques (Hunan Provincial Natural
   Science Research Fund). The authors are very grateful to the editors and
   anonymous reviewers for their constructive suggestions.
CR Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen WR, 2022, MULTIMED TOOLS APPL, V81, P20797, DOI 10.1007/s11042-022-12620-w
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hssayni Eh, 2022, J Ambient Intell Humanized Comput, P1
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Hu J, 2018, ADV NEUR IN, V31
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jia Shijie, 2017, 2017 Chinese Automation Congress (CAC). Proceedings, P3507, DOI 10.1109/CAC.2017.8243388
   Kang SH, 2014, J ASIA-PAC ENTOMOL, V17, P143, DOI 10.1016/j.aspen.2013.12.004
   Kaya Y, 2015, APPL SOFT COMPUT, V28, P132, DOI 10.1016/j.asoc.2014.11.046
   Kingma D. P., 2014, arXiv
   Lee SH, 2020, PLANT PATHOL, V69, P1731, DOI 10.1111/ppa.13251
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZY, 2016, SCI REP-UK, V6, DOI 10.1038/srep20410
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300
   Tsotsos JK, 2011, COMPUTATIONAL PERSPECTIVE ON VISUAL ATTENTION, P1
   Wang JN, 2012, KNOWL-BASED SYST, V33, P102, DOI 10.1016/j.knosys.2012.03.014
   Wang XW, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.634103
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Younis Ayesha, 2020, ICCDE 2020: Proceedings of 2020 the 6th International Conference on Computing and Data Engineering, P44, DOI 10.1145/3379247.3379264
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhao ZB, 2016, IEEE IJCNN, P3187, DOI 10.1109/IJCNN.2016.7727606
NR 41
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31379
EP 31394
DI 10.1007/s11042-023-16680-4
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500003
DA 2024-07-18
ER

PT J
AU Artiaga, K
   Li, Y
   Kuruoglu, EE
   Chan, WK
AF Artiaga, Keren
   Li, Yang
   Kuruoglu, Ercan Engin
   Chan, Wai Kin (Victor)
TI Cross-Sign Language Transfer Learning Using Domain Adaptation with
   Multi-scale Temporal Alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE sign language recognition; domain adaptation; temporal relations;
   optical flow
AB Sign language serves as a vital means of communication for individuals with hearing impairments, yet recognition resources for the over 100 distinct sign languages are severely lacking. In response, we present our work on sign language recognition using transfer learning and the domain adaptation method TA3N, which utilizes the Temporal Relational Network (TRN) module for aligning multi-scale temporal relations. Our findings highlight the superior performance of Domain Adaptation to neural network-based transfer learning, particularly in improving recognition of American Sign Language (ASL). Our research also identifies the effectiveness of aligning shorter-term temporal features between source and target domains. In addition to using RGB, we conducted experiments using Optical Flow mode for the sign language samples, ultimately determining that RGB outperforms Optical Flow in the majority of cases. Our work aims to improve accessibility and communication for individuals who rely on sign language as their primary mode of communication.
C1 [Artiaga, Keren; Li, Yang; Kuruoglu, Ercan Engin; Chan, Wai Kin (Victor)] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University
RP Artiaga, K (corresponding author), Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China.
EM kerenartiaga@outlook.com; yangli@sz.tsinghua.edu.cn;
   kuruoglu@sz.tsinghua.edu.cn; chanw@sz.tsinghua.edu.cn
RI Li, Yang/GWM-7879-2022
OI Artiaga, Keren/0000-0002-1233-5700
FU Shenzhen Science and Technology Innovation Commission
   [JCYJ20210324135011030]; Science and Technology Innovation Committee of
   Shenzhen-Platform and Carrier (International Science and Technology
   Information Center); High-end Foreign Expert Talent Introduction Plan
   [G2021032022L]; Guangdong Pearl River Plan [2019QN01X890]; National
   Natural Science Foundation of China [71971127]
FX This research was funded by the Shenzhen Science and Technology
   Innovation Commission (JCYJ20210324135011030), Science and Technology
   Innovation Committee of Shenzhen-Platform and Carrier (International
   Science and Technology Information Center), High-end Foreign Expert
   Talent Introduction Plan (G2021032022L), Guangdong Pearl River Plan
   (2019QN01X890), and National Natural Science Foundation of China (Grant
   No. 71971127).
CR Abdullayeva GG, 2022, Informatics and Control Problems
   Abner N., 2020, FEAST. Formal and Experimental Advances in Sign Language Theory, V3, P17
   Bird JJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185151
   Bragg D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P16, DOI 10.1145/3308561.3353774
   Cayamcela MEM, 2019, INT CONF COMPUT NETW, P100, DOI [10.1109/iccnc.2019.8685536, 10.1109/ICCNC.2019.8685536]
   Das S, 2022, Expert Syst Appl, V213
   Farhadi A, 2007, PROC CVPR IEEE, P2676
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Halvardsson G., 2021, SN Computer Science, V2, DOI [10.1007/s42979-021-00612-w, DOI 10.1007/S42979-021-00612-W]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang J, 2018, AAAI CONF ARTIF INTE, P2257
   Jamal A, 2018, BMVC, P264
   Jiang XW, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/3291426
   Kocmi T, 2018, Trivial Transfer Learning for Low-Resource Neural Machine Translation
   Kocmi T, 2020, Arxiv, DOI arXiv:2001.01622
   Krishnan R, 2013, IEEE COMPUT SOC CONF, P506, DOI 10.1109/CVPRW.2013.81
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar A, 2016, 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), P422, DOI 10.1109/RAIT.2016.7507939
   Li DX, 2020, IEEE WINT CONF APPL, P1448, DOI [10.1109/WACV45572.2020.9093512, 10.1109/wacv45572.2020.9093512]
   Min-Hung Chen, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P6320, DOI 10.1109/ICCV.2019.00642
   Mocialov B, 2020, Arxiv, DOI arXiv:2006.02144
   Nishat ZK, 2020, P INT JOINT C COMP I, P529, DOI [10.1007/978-981-15-3607-6_42, DOI 10.1007/978-981-15-3607-6_42]
   Pu J., 2016, PAC RIM C MULT, P252
   Rahman MM, 2021, IEEE RAD CONF, DOI 10.1109/RadarConf2147009.2021.9455190
   Rathi D, 2018, Int J Recent Innov Trends Comput Commun, V6, P198
   Ronchetti F., 2016, Congr. Argentine/ Ciencias la Comput
   Sahoo Aadarsh, 2021, Advances in neural information processing systems, V34, P23386
   Sevilla-Lara Laura, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P281, DOI 10.1007/978-3-030-12939-2_20
   Shania S, 2022, Indones J Inf Syst
   Sharma CM, 2021, SSRN Electron J
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro K., 2012, CoRR, V2
   Suharjito, 2021, PROCEDIA COMPUT SCI, V179, P72, DOI 10.1016/j.procs.2021.12.011
   Sultani W, 2014, PROC CVPR IEEE, P764, DOI 10.1109/CVPR.2014.103
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thakar S, 2022, 2022 IEEE 3 GLOB C A, P1
   Vázquez-Enríquez M, 2021, IEEE COMPUT SOC CONF, P3457, DOI 10.1109/CVPRW53098.2021.00385
   Virk JS, 2021, 8 ACM IKDD CODS 26 C
   Wang H, 2009, A Similarity Measure for Vision-Based Sign Recognition
   Wang HJ, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2897735
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Xu TT, 2016, IMAGE VISION COMPUT, V55, P127, DOI 10.1016/j.imavis.2016.01.001
   Yosinski J, 2014, Arxiv, DOI [arXiv:1411.1792, 10.48550/arXiv.1411.1792]
   Zakariah M, 2022, COMPUT INTEL NEUROSC
   Zhang JH, 2016, IEEE INT CON MULTI, DOI 10.1109/ICME.2016.7552950
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 48
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 15
PY 2023
DI 10.1007/s11042-023-16703-0
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R8JK1
UT WOS:001066762000010
DA 2024-07-18
ER

PT J
AU Zibani, R
   Sebbak, F
   Boudaren, ME
   Mataoui, M
   Aissa, RH
   Benaissa, YA
AF Zibani, Rezki
   Sebbak, Faouzi
   Boudaren, Mohamed El Yazid
   Mataoui, M'hamed
   Hadj Aissa, Ridouane
   Benaissa, Yasser Abdeldjalil
TI Multi-attribute fusion-based approach for Algerian automatic license
   plate recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ALPR system; Plate localization; Plate segmentation; Character
   recognition; Dempster-shafer theory
AB Due to the huge rise in the number of vehicles, manual tracking has become a complex task. To deal with this issue, Automatic License Plate Recognition systems have been developed to identify vehicles in real-time situations. This paper proposes a novel automatic license plate recognition approach based on multi-attribute data fusion. The proposed approach's architecture consists of three steps: localization, segmentation, and recognition. For localization, the Yolo object detector is used. The segmentation step is accomplished following two ways: the first method relies on the Yolo object detector, while the second method relies on edge detection. Finally, the recognition step targets the extraction of descriptive attributes from the previously segmented plate images. These attributes are then fused and combined using the mathematical Dempster-Shafer theory and Parzen-Rosenblatt windowing for belief mass building. The proposed system underwent testing and validation using an Algerian license plate dataset, yielding impressive accuracy rates of 98.90% for localization, 98.10% for segmentation, and 97.20% for recognition, outperforming other existing approaches. Furthermore, a comparison is conducted on the OpenALPR-EU, OpenALPR-BR, and SSIG datasets, demonstrating a competitive accuracy rate of 92.23%, 92.45%, and 90.84%, respectively for the proposed approach, comparable to both alternative methods and commercial systems. This good performance can be attributed to the robustness of Yolo in localizing and segmenting characters, as well as the strategic selection and the evidential fusion of significant attributes, leading to better character distinction.
C1 [Zibani, Rezki; Sebbak, Faouzi; Boudaren, Mohamed El Yazid; Mataoui, M'hamed; Hadj Aissa, Ridouane; Benaissa, Yasser Abdeldjalil] Ecole Mil Polytech, POB 17, Algiers 16046, Algeria.
C3 Ecole Military Polytechnic
RP Zibani, R (corresponding author), Ecole Mil Polytech, POB 17, Algiers 16046, Algeria.
EM rezki92halim@gmail.com; faouzi.sebbak@emp.mdn.dz
OI ZIBANI, Rezki/0000-0003-3453-7255
CR Ahmed AM, 2019, ICT OUR LIVES 2019
   Bensouilah M, 2021, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM), P204, DOI 10.5220/0010229202040211
   Bloch I., 1996, Traitement du Signal, V13, P267
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Capar A, 2006, INT C PATT RECOG, P155
   Castanedo F, 2013, SCI WORLD J, DOI 10.1155/2013/704504
   Cavdaroglu GC., 2021, MATH COMPUT SCI, V6, P92, DOI [10.11648/j.mcs.20210606.13, DOI 10.11648/J.MCS.20210606.13]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng Y, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1455
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Cui YT, 1998, MACH VISION APPL, V10, P308, DOI 10.1007/s001380050081
   de Silva C.W., 1995, INTELLIGENT CONTROL, DOI [10.1201/9780203750513, DOI 10.1201/9780203750513]
   DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205
   Eikvil L., 1993, citeseer
   Esteban J, 2005, NEURAL COMPUT APPL, V14, P273, DOI 10.1007/s00521-004-0463-7
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   github, 2019, LIC PLAT ALG DAT
   github, 2022, OPENALPR EU DAT
   github, 2023, OPENALPR BR DAT
   Gonçalves GR, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053034
   Graph workflow, 2022, US
   Gunawan D., 2019, IOP Conference Series: Materials Science and Engineering, V648, DOI 10.1088/1757-899X/648/1/012011
   Guo GD, 2008, PROC CVPR IEEE, P691
   Haider SA, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRICAL ENGINEERING AND COMPUTATIONAL TECHNOLOGIES (ICIEECT)
   Hamache A, 2018, LECT NOTES ARTIF INT, V11069, P103, DOI 10.1007/978-3-319-99383-6_14
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HOMMOS O, 2016, 2016 INT C IND INF C, P1, DOI DOI 10.1109/ICCSII.2016.7462420
   Horn B.K.P, 1986, Robot Vision
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Islam R, 2020, MULTIMED TOOLS APPL, V79, P20107, DOI 10.1007/s11042-020-08629-8
   Laroca R., 2018, 2018 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2018.8489629
   Li WC, 2021, 22ND IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD 2021-FALL), P134, DOI 10.1109/SNPD51163.2021.9704935
   Lin NH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P97, DOI 10.1109/IOTAIS.2018.8600829
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Masood SZ, 2017, ARXIV
   Meng T, 2020, INFORM FUSION, V57, P115, DOI 10.1016/j.inffus.2019.12.001
   MingLei Li, 2018, 2018 IEEE International Conference on Information and Automation (ICIA). Proceedings, P1411, DOI 10.1109/ICInfA.2018.8812381
   Mukhija Pankaj, 2021, 2021 Fourth International Conference on Computational Intelligence and Communication Technologies (CCICT), P255, DOI 10.1109/CCICT53244.2021.00055
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   openalpr, 2022, OPENALPR CLOUD API
   OShea K., 2015, arXiv
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PARHAMI B, 1994, IEEE T RELIAB, V43, P617, DOI 10.1109/24.370218
   Pugalenthy Kuken Raj, 2022, Proceedings of the 6th International Conference on Electrical, Control and Computer Engineering: InECCE2021. Lecture Notes in Electrical Engineering (842), P1011, DOI 10.1007/978-981-16-8690-0_88
   Rattanawong Sasakorn, 2021, 2021 25th International Computer Science and Engineering Conference (ICSEC), P116, DOI 10.1109/ICSEC53205.2021.9684651
   Ravirathinam P, 2019, INT CONF ADV COMPU, P275, DOI [10.1109/ICoAC48765.2019.246853, 10.1109/icoac48765.2019.246853]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Saif N, 2019, TENCON IEEE REGION, P925, DOI [10.1109/tencon.2019.8929280, 10.1109/TENCON.2019.8929280]
   Sarfraz M, 2003, 2003 INTERNATIONAL CONFERENCE ON GEOMETRIC MODELING AND GRAPHICS, PROCEEDINGS, P36, DOI 10.1109/GMAG.2003.1219663
   Sferle RM, 2019, 2019 15TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P57, DOI [10.1109/EMES.2019.8795201, 10.1109/emes.2019.8795201]
   Shafer G., 1976, A mathematical theory of evidence, DOI [10.1515/9780691214696, DOI 10.1515/9780691214696]
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi XF, 2005, LECT NOTES COMPUT SC, V3483, P1159
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Silva SM, 2018, LECT NOTES COMPUT SC, V11216, P593, DOI 10.1007/978-3-030-01258-8_36
   Singh V., 2020, P 4 INT C INT THINGS, P1
   Slimani I, 2019, INT C CONTROL DECISI, P1592, DOI [10.1109/codit.2019.8820446, 10.1109/CoDIT.2019.8820446]
   SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4
   Smets Ph., 1990, Uncertainty in Artificial Intelligence, V5, P29
   Sung J-Y, 2020, P 2020 IEEE INT C CO, P1, DOI DOI 10.1109/ICCE-ASIA49877.2020.9277050
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wu CH, 2018, LECT NOTES COMPUT SC, V11259, P334, DOI 10.1007/978-3-030-03341-5_28
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 68
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30233
EP 30259
DI 10.1007/s11042-023-16789-6
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000008
DA 2024-07-18
ER

PT J
AU Meng, JN
   Zhu, YL
   Sun, SC
   Zhao, DD
AF Meng, Jiana
   Zhu, Yanlin
   Sun, Shichang
   Zhao, Dandan
TI Sarcasm detection based on BERT and attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sarcasm detection; BERT; Convolutional neural network; Attention
   mechanism
ID SKIN; CLASSIFICATION; MELANOMA
AB Sarcasm detection is a challenging task in sentiment analysis and is usually used to detect sarcasm by judging inconsistencies in the individual words of an expression of sentiment; however, detection is less effective for sentences with complex semantic information, especially those with too few sentiment words. To tackle this problem, we propose a sarcasm detection model based on pretraining model and attention mechanism, which works with the context and language environment for sarcasm detection of phrase fragments for semantic feature extraction to attain higher-level semantic features, rather than limiting attention to words. Intrasentence attention mechanism was used to model the semantic information between phrase fragments within sentences, and then further strengthen the key features, which gives higher attention weights to key phrases so as to improving the ability of the model to identify expressions of sarcasm and avoids the lack of semantic incongruity of distant words in most sequential neural networks. Experimental results on a publicly available dataset indicated that the proposed approach outperforms baselines and state-of-the-art models.
C1 [Meng, Jiana; Zhu, Yanlin; Sun, Shichang; Zhao, Dandan] Dalian Minzu Universe, Comp Sci & Engn, Liaohe Rd,Jinpu New Area, Dalian 116600, Liaoning, Peoples R China.
RP Meng, JN (corresponding author), Dalian Minzu Universe, Comp Sci & Engn, Liaohe Rd,Jinpu New Area, Dalian 116600, Liaoning, Peoples R China.
EM mengjn@dlnu.edu.cn; ssc@dlnu.edu.cn
OI meng, jiana/0000-0002-7220-5748
FU National Natural Science Foundation of China [61876031]; Natural Science
   Foundation of Liaoning Province, China [20180550921, 2019-ZD-0175];
   Scientific Research Fund Project of the Education Department of Liaoning
   Province, China [LJYT201906]
FX This research was funded by the National Natural Science Foundation of
   China (No. 61876031), Natural Science Foundation of Liaoning Province,
   China (20180550921, 2019-ZD-0175) and Scientific Research Fund Project
   of the Education Department of Liaoning Province, China (LJYT201906).
CR Abbott R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4445
   Akula R, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23040394
   Amir S, 2016, P 20 SIGNLL C COMP N, P167, DOI DOI 10.18653/V1/K16-1017
   [Anonymous], 2010, P 4 INT C WEBL SOC M
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bharti SK, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1373, DOI 10.1145/2808797.2808910
   Cui J., 2021, Modern Foreign Languages, V44, P284
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Gong X., 2020, Research on sarcasm recognition in chinese text
   Gonzalez-Ibanez R, 2011, Short Papers, ppp581
   Joshi A, 2016, P 2016 C EMP METH NA, ppp1006
   Joshi A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P757
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Lauriola I, 2022, NEUROCOMPUTING, V470, P443, DOI 10.1016/j.neucom.2021.05.103
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Liu P, 2014, LECT NOTES COMPUT SC, V8485, P459, DOI 10.1007/978-3-319-08010-9_49
   Lukin S, 2017, Arxiv, DOI arXiv:1708.08572
   Luo G, 2019, Sarcasm detection in social media
   Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238
   Mishra A, 2016, AAAI CONF ARTIF INTE, P3747
   Moores Bleau, 2022, arXiv
   Mukherjee S, 2017, TECHNOL SOC, V48, P19, DOI 10.1016/j.techsoc.2016.10.003
   Pan H, 2020, EUR C ART INT
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Ren L, 2020, NEUROCOMPUTING, V401, P320, DOI 10.1016/j.neucom.2020.03.081
   Ren YF, 2018, NEUROCOMPUTING, V308, P1, DOI 10.1016/j.neucom.2018.03.047
   Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x
   Riloff E., 2013, P 2013 C EMP METH NA, P704
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tay Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1010
   Torterolo F, 1998, Lecture notes in computer science, Vvol1604, ppp246
   Vaswani A, 2017, ADV NEUR IN, V30
   Veale T, 2010, FRONT ARTIF INTEL AP, V215, P765, DOI 10.3233/978-1-60750-606-5-765
   Walker MA, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P812
   [邢竹天 Xing Zhutian], 2015, [山西大学学报. 自然科学版, Journal of Shanxi University. Natural Science Edition], V38, P385
   Xiong T, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2115, DOI 10.1145/3308558.3313735
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yuan M, 2020, Study on the method of ironic identification based on network text
   Zhang M, 2016, COLING 2016
NR 41
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29159
EP 29178
DI 10.1007/s11042-023-16797-6
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400012
DA 2024-07-18
ER

PT J
AU Tripathi, A
   Prakash, J
AF Tripathi, Abhinandan
   Prakash, Jay
TI A blockchain enabled reversible data hiding based on image smoothing and
   interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDH; Smoothing filter; Blockchain; Data embedding
AB Reversible data hiding has emerged as a crucial and dynamic area of research, driven by the proliferation of online data transfers involving images, videos, and audio files over the internet. As these digital assets traverse various platforms and networks, the need to embed additional data within them while maintaining their integrity becomes paramount. However, the process of embedding data into images is inherently challenging, as it often leads to distortions and quality degradation, impacting the overall user experience. To address this challenge and minimize the distortion caused by data embedding, guided filtering, a powerful image enhancement technique is harnessed to achieve this edge-preserving smoothing. By adopting this approach, the deleterious effects of data embedding on image quality can be successfully mitigated. In addition to the image enhancement aspect, ensuring the security of the embedded data is important. Blockchain technology has been integrated into the proposed system. This incorporation of blockchain adds an extra layer of protection to the encrypted image data, preventing unauthorized access, tampering, or data breaches. The efficacy of the proposed RDH system is rigorously evaluated using a suite of metrics. Peak Signal-to-Noise Ratio and Structural Similarity Image Metrics are employed to measure image quality. Furthermore, the system's performance is assessed in terms of its embedding capacity, which indicates the amount of data that can be seamlessly embedded per unit of image space. The embedding capacity of 1 bit per pixel is easily achieved with PSNR greater than 35 dB. For encryption evaluation, parameters like the Number of Changing Pixel Rate and Unified Averaged Altered Intensity are employed for the assessment the encryption strength and resilience against attacks.
C1 [Tripathi, Abhinandan; Prakash, Jay] Madan Mohan Malaviya Univ Technol, Dept Informat Technol & Comp Applicat, Gorakhpur, India.
C3 Madan Mohan Malaviya University of Technology
RP Tripathi, A (corresponding author), Madan Mohan Malaviya Univ Technol, Dept Informat Technol & Comp Applicat, Gorakhpur, India.
EM abhi.gkrp@gmail.com
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Al-Juaid N., 2018, J INF SECUR CYBERCRI, V1, P8, DOI [10.26735/16587790.2018.006, DOI 10.26735/16587790.2018.006]
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Alanazi N, 2020, J KING SAUD UNIV-COM, V34, P1343, DOI 10.1016/j.jksuci.2020.04.011
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Alattar AM, 2004, ICASSP IEEE INT C AC
   Brabin D, 2022, MULTIMED TOOLS APPL, V81, P24721, DOI 10.1007/s11042-022-12617-5
   Caciula I, 2019, SIGNAL PROCESS-IMAGE, V71, P120, DOI 10.1016/j.image.2018.11.005
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Chen XY, 2019, MULTIMED TOOLS APPL, V78, P7499, DOI 10.1007/s11042-018-6446-y
   Chen XY, 2019, CMC-COMPUT MATER CON, V59, P239, DOI 10.32604/cmc.2019.03572
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hsu FH, 2013, MULTIMED TOOLS APPL, V67, P571, DOI 10.1007/s11042-012-1047-7
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Kim SK, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00537-z
   Kim SK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050763
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P2271, DOI 10.1109/TCSVT.2018.2869935
   Kim S, 2015, IEEE INT WORKS INFOR
   Kuo WC, 2007, LECT NOTES ARTIF INT, V4682, P1152
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liang XK, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540223
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Liu YH, 2021, CLUSTER COMPUT, V24, P1331, DOI 10.1007/s10586-020-03190-3
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P12569, DOI 10.1007/s11042-019-08335-0
   Sen-Ren Jan, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P185, DOI 10.1109/IIHMSP.2011.88
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Srinivasu PN., 2021, Science, V35, P1372
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tripathi A, 2023, P INDIAN NATL SCI AC, V89, P689, DOI 10.1007/s43538-023-00178-6
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wu HZ, 2016, IEEE INT WORKS INFOR
   Wu HT, 2019, IEEE ACCESS, V7, P83332, DOI 10.1109/ACCESS.2019.2921407
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiong LZ, 2019, J INF SECUR APPL, V47, P78, DOI 10.1016/j.jisa.2019.04.005
   Xu DW, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116274
   Xu RH, 2020, SMART CITIES-BASEL, V3, P928, DOI 10.3390/smartcities3030047
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yu CQ, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9103418
   Zhai SP, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/3/032077
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhu K, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540028
NR 70
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29085
EP 29118
DI 10.1007/s11042-023-16695-x
EA SEP 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063374600007
DA 2024-07-18
ER

PT J
AU Roy, M
   Chakraborty, S
   Mali, K
AF Roy, Mousomi
   Chakraborty, Shouvik
   Mali, Kalyani
TI Metaheuristic-supported image encryption framework based on binary
   search tree and DNA encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Binary search tree; Electromagnetism-like
   optimization; DNA encoding; Bitplane decomposition
ID ELECTROMAGNETISM-LIKE MECHANISM; ALGORITHM; SCHEME; MAP
AB Rapid evolution in digital communication increases the risk of unauthorized access to sensitive data. Digital images are one of the most popular types and are frequently used to share various information including many sensitive data. Hence, security of the digital images is one of the major concerns for reliable data communication. This work addresses this issue and proposes a novel image encryption technique in which the concept of the binary search tree is introduced. The structure of the binary search tree is optimized with the help of the electromagnetism-like optimization approach that optimizes the image entropy. The proposed approach also incorporates the concept of DNA (Deoxyribonucleic acid) encoding and based on this concept bitplane decomposition is used to get DNA bit planes. A scrambling approach is also proposed to add an additional layer of security. This approach is a symmetric image encryption scheme and is completely lossless. The performance of this approach is tested in terms of both qualitative and quantitative manner. Experimental results and comparative outcomes with the state-of-the-art approaches are encouraging and prove the efficiency of the proposed approach.
C1 [Roy, Mousomi; Chakraborty, Shouvik; Mali, Kalyani] Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
C3 Kalyani University
RP Chakraborty, S (corresponding author), Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
EM iammouroy@gmail.com; shouvikchakraborty51@gmail.com;
   kalyanimali1992@gmail.com
CR Abdulla A. A., 2015, Ph.D. dissertation
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   [Anonymous], 1999, 463 N FIPS
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Chakraborty S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114142
   Chakraborty S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106800
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Cui GZ, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P37, DOI 10.1109/BICTA.2008.4656701
   Daemen J, 2000, LECT NOTES COMPUT SC, V1820, P277
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Gálvez J, 2018, APPL INTELL, V48, P2580, DOI 10.1007/s10489-017-1090-1
   Gehani A., 2000, DNA Based Computers V. DIMACS Workshop (Series in Discrete Mathematics and Theoretical Computer Science Vol.54), P233
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kamali S. H., 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P141, DOI 10.1109/ICEIE.2010.5559902
   Khan HN, 2020, MICROSYST TECHNOL, V26, P2193, DOI 10.1007/s00542-019-04518-9
   Leong MP, 2000, ANN IEEE SYM FIELD P, P122, DOI 10.1109/FPGA.2000.903399
   Li LL, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105616
   LINDHOLM FA, 1979, IEEE T ELECTRON DEV, V26, P165, DOI 10.1109/T-ED.1979.19400
   Liu S., 2001, PROGR CRYPTOLOGY IND, V2247, P316, DOI [DOI 10.1007/3-540-45311-3_30, 10.1007/3-540-45311-3_30.]
   Mali K, 2015, IJSRD-Int J Sci Res Dev, V3, P2321
   Mali K, 2015, INT J SECUR APPL, V9, P279, DOI 10.14257/ijsia.2015.9.12.26
   Narkhede BE, 2020, INT J ADV MANUF TECH, V108, P3193, DOI 10.1007/s00170-020-05486-5
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Roy Mousomi, 2020, Proceedings of International Ethical Hacking Conference 2019. eHaCON 2019. Advances in Intelligent Systems and Computing (AISC 1065), P239, DOI 10.1007/978-981-15-0361-0_19
   Roy Mousomi, 2020, Proceedings of International Ethical Hacking Conference 2019. eHaCON 2019. Advances in Intelligent Systems and Computing (AISC 1065), P49, DOI 10.1007/978-981-15-0361-0_4
   Roy M, 2021, ADV SMART COMMUNICAT
   ROY M, 2019, 2019 INT C OPTOELECT, P1
   Roy M, 2021, An image security method based on low dimensional chaotic environment and DNA encoding, P267
   Roy M, 2021, MULTIMED TOOLS APPL, V80, P24069, DOI 10.1007/s11042-021-10839-7
   Roy M, 2021, MULTIMED TOOLS APPL, V80, P21261, DOI 10.1007/s11042-021-10761-y
   Roy M, 2021, MICROSYST TECHNOL, V27, P3617, DOI 10.1007/s00542-020-05120-0
   Roy M, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P881, DOI [10.1109/aicai.2019.8701382, 10.1109/AICAI.2019.8701382]
   Seal A, 2017, NEW RESILIENT IMAGE
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Suri S, 2019, J INTELL SYST, V28, P333, DOI 10.1515/jisys-2017-0069
   Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang X, 2009, INT J CONTROL, V82, P1870, DOI 10.1080/00207170902802984
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 56
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25321
EP 25349
DI 10.1007/s11042-023-16471-x
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050733600002
DA 2024-07-18
ER

PT J
AU Sabeti, V
AF Sabeti, Vajiheh
TI Unmistakable information embedding into the integer wavelet transform
   domain of an image using an XOR function and a genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Steganalysis; Discrete Wavelet transform (DWT); Integer
   Wavelet Transform (IWT); Genetic algorithm
ID STEGANOGRAPHY; SECURE; PIXEL; IWT
AB Although wavelet-based steganography techniques are widely used due to their advantages, complete embedding data extraction remains one of the most significant challenges in this field. The Integer Wavelet Transform (IWT) can reduce extraction errors by mapping the image to integers, but it does not fully eliminate them. The proposed method resolves these errors entirely by using an iterative embedding procedure. After determining the image blocks and performing the IWT, this method embeds data in high-frequency sub-bands coefficient pairs. Additionally, it modifies the coefficient pair values such that the XOR of two coefficient LSBs equals two bits of data. The genetic algorithm is used to generate new coefficient values in order to minimize the differences between the stego and cover images. The sender repeats the embedding operation on each block until all extraction errors have been eliminated. If this procedure is unsuccessful in a block, the sender signs it as empty block. The results of the implementation suggest that with each iteration, the errors typically diminish to zero in most of the blocks. Further examination of the test results shows an enhancement in the PSNR and SSIM metrics when contrasted with existing methods. Moreover, the test results also expose the inability of attacks to uncover this method. Key merits of the proposed method include its superior stego image quality, substantial security against attacks, no requirement for lengthy keys, and a zero extraction error rate. These features render this method highly viable for practical applications.
C1 [Sabeti, Vajiheh] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran 1993893973, Iran.
C3 Alzahra University
RP Sabeti, V (corresponding author), Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran 1993893973, Iran.
EM v.sabeti@alzahra.ac.ir
OI sabeti, vajiheh/0000-0002-9985-9143
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atee HA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170329
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   El Safy R. O., 2009, 2009 International Conference on Networking and Media Convergence (ICNM'09), P111, DOI 10.1109/ICNM.2009.4907200
   El-Emam NN, 2015, COMPUT SECUR, V55, P21, DOI 10.1016/j.cose.2015.06.012
   Evsutin O, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107811
   Evsutin O, 2018, MULTIMED TOOLS APPL, V77, P28567, DOI 10.1007/s11042-018-6055-9
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Fridrich J, 2003, PROC SPIE, V5020, P143, DOI 10.1117/12.473142
   Gaurav K, 2018, J INF SECUR APPL, V41, P41, DOI 10.1016/j.jisa.2018.05.001
   Gulve AK, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/684824
   Kadhim IJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107481
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kadhim IJ, 2018, LECT NOTES ARTIF INT, V10956, P544, DOI 10.1007/978-3-319-95957-3_57
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Mandal Pratap Chandra, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P332, DOI 10.1109/ICSCCC51823.2021.9478095
   Mandal PC, 2022, INFORM SCIENCES, V609, P1451, DOI 10.1016/j.ins.2022.07.120
   Mandal PC, 2021, OPTIK, V247, DOI 10.1016/j.ijleo.2021.167804
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Pramanik S, 2020, MULTIMED TOOLS APPL, V79, P17463, DOI 10.1007/s11042-020-08676-1
   Ray B, 2021, MULTIMED TOOLS APPL, V80, P33475, DOI 10.1007/s11042-021-11177-4
   Sabeti V., 2021, ISC INT J INF SECUR, V14, P167, DOI [10.22042/isecure.2022.274305.641, DOI 10.22042/ISECURE.2022.274305.641]
   Sabeti V, 2023, MULTIMED TOOLS APPL, V82, P19323, DOI 10.1007/s11042-022-14166-3
   Sabeti V, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107809
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Shafi I, 2018, SOFT COMPUT, V22, P1555, DOI 10.1007/s00500-017-2944-5
   Shah PD, 2021, ENG SCI TECHNOL, V24, P782, DOI 10.1016/j.jestch.2020.11.008
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tang LL, 2021, SOFT COMPUT, V25, P10987, DOI 10.1007/s00500-021-05825-y
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Wang WJ, 2022, IEEE ACCESS, V10, P107376, DOI 10.1109/ACCESS.2022.3212691
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
NR 40
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16466-8
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600011
DA 2024-07-18
ER

PT J
AU Li, JG
   Liu, Y
   Wang, S
   Wang, LW
   Sun, YM
   Li, X
AF Li, Jinguang
   Liu, Yu
   Wang, Shuai
   Wang, Linwei
   Sun, Yumeng
   Li, Xin
TI Visual perception system design for rock breaking robot based on
   multi-sensor fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Rock breaking; Visual perception; Multi-sensor fusion; 3D point cloud
ID MODEL; SHAPE; LIDAR
AB In recent years, mining automation has received significant attention as a critical focus area. Rock breaking robots are commonly used equipment in the mining industry, and their automation requires an accurate and fast visual perception system. Currently, rock detection and determination of rock breaking surfaces heavily rely on operator experience. To address this, this paper leverages multi-sensor fusion techniques, specifically camera and lidar fusion, as the perception system for the rock breaking robot. The advanced PP-YOLO series algorithm is employed for 2D detection, enabling the generation of specific detection results based on the breaking requirements. Furthermore, 3D reconstruction of rocks detected in the 2D area is performed using point cloud data. The extraction of rock breaking surfaces is achieved through point cloud segmentation and statistical filtering methods. Experimental results demonstrate a rock detection speed of 13.8 ms and the mAP value of 91.2%. The segmentation accuracy for rock breaking surfaces is 75.46%, with an average recall of 91.08%. The segmentation process takes 73.09 ms, thus meeting the real-time detection and segmentation needs within the specified rock breaking range. This study effectively addresses the limitations associated with single sensor information.
C1 [Li, Jinguang; Liu, Yu; Wang, Shuai; Wang, Linwei; Sun, Yumeng; Li, Xin] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Liu, Y (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
EM yuliu@me.neu.edu.cn
RI wang, jin/KHD-7243-2024; Lin, Wei/KFQ-5381-2024; Wang,
   Yifan/KDO-8319-2024; zhang, yingying/KGM-8162-2024; yi,
   cheng/KHC-5004-2024; li, fangyu/KCY-0521-2024; li, qing/KHU-6871-2024;
   WANG, YANAN/KCL-4840-2024; Zhang, Yansong/KHW-4097-2024; Sun,
   Yang/KHY-5117-2024; Chen, Yukun/KGK-4521-2024; wang,
   haoyu/KHY-6295-2024; Wang, zhenhua/KFA-8731-2024; Wang,
   Fei/KEH-6292-2024; li, fang/KDO-8841-2024; Wang, Yibin/KEZ-9645-2024;
   wang, nan/KHW-4897-2024; Yang, Ning/KHD-1133-2024; Wang,
   Yuhan/KGL-5855-2024; wang, shuo/KCL-3379-2024
OI zhang, yingying/0000-0001-7479-3398; li, fangyu/0009-0009-8303-9157;
   wang, haoyu/0009-0001-2467-5331; 
FU National Natural Science Foundation of China [51875094]; Fundamental
   Research Funds for the Central Universities [2020GFYD023]
FX AcknowledgementsThis research was supported by the National Natural
   Science Foundation of China (Grant Nos. 51875094) and the Fundamental
   Research Funds for the Central Universities (Grant Nos.2020GFYD023).
CR Azar ER, 2012, AUTOMAT CONSTR, V24, P194, DOI 10.1016/j.autcon.2012.03.003
   Benet B., 2017, Adv. Anim. Biosci., V8, P583, DOI [10.1017/S2040470017000310, DOI 10.1017/S2040470017000310]
   Bigdeli B, 2016, INT J APPL EARTH OBS, V52, P126, DOI 10.1016/j.jag.2016.06.008
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bonchis A., 2011, IFAC P VOLUMES, V44, P11588, DOI [10.3182/20110828-6-IT-1002.00536, DOI 10.3182/20110828-6-IT-1002.00536]
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Bureau of Labor Statistics, 2015, CENS FAT OCC INJ CFO
   Dai JF, 2017, Arxiv, DOI arXiv:1703.06211
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Di KC, 2013, J EARTH SCI-CHINA, V24, P125, DOI 10.1007/s12583-013-0316-3
   Eraliev OMU, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104428
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ghiasi G, 2018, Arxiv, DOI [arXiv:1810.12890, DOI 10.48550/ARXIV.1810.12890, 10.48550/arXiv.1810.12890]
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang ML, 2022, ALEX ENG J, V61, P10769, DOI 10.1016/j.aej.2022.04.019
   Huang X, 2021, Arxiv, DOI arXiv:2104.10419
   Hurkxkens I., 2020, Impact: Design With All Senses, P69
   Lampinen S, 2021, IEEE ASME INT C ADV, P140, DOI 10.1109/AIM46487.2021.9517695
   Lampinen S, 2021, J FIELD ROBOT, V38, P980, DOI 10.1002/rob.22022
   Liang CJ, 2019, AUTOMAT CONSTR, V104, P80, DOI 10.1016/j.autcon.2019.04.004
   Liu XB, 2020, IEEE ACCESS, V8, P21804, DOI 10.1109/ACCESS.2020.2968515
   Loncomilla P, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116537
   Long X, 2020, Arxiv, DOI [arXiv:2007.12099, DOI 10.48550/ARXIV.2007.12099]
   Maleki-Moghaddam M, 2013, MINER ENG, V46-47, P157, DOI 10.1016/j.mineng.2013.04.013
   McKinnon C, 2014, IEEE T AUTOM SCI ENG, V11, P935, DOI 10.1109/TASE.2014.2308011
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Niu LC, 2019, IEEE INT CON AUTO SC, P1124, DOI [10.1109/COASE.2019.8842859, 10.1109/coase.2019.8842859]
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Sakshi G., 2022, Autonomous and Connected Heavy Vehicle Technology, P375, DOI 10.1016/B978-0-323-90592-3.00021-5
   State Council Information Office of the People's Republic of China, 2003, MIN RES POL CHIN
   Xiao XM, 2017, ADV SPACE RES, V60, P626, DOI 10.1016/j.asr.2017.04.028
   Yuan CJ, 2021, IEEE ROBOT AUTOM LET, V6, P7517, DOI 10.1109/LRA.2021.3098923
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang LJ, 2021, SCI ROBOT, V6, DOI 10.1126/scirobotics.abc3164
NR 36
TC 1
Z9 1
U1 9
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16189-w
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9TM0
UT WOS:001047169200005
DA 2024-07-18
ER

PT J
AU Ballari, SO
AF Ballari, Syed Omar
TI Modelling of heterogeneous traffic using image processing software
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital image; Capturing; Heterogeneous traffic; TRAZER; Trajectories
ID DATA-COLLECTION
AB Image processing software is designed to manipulate the digital images by capturing and converting them into digital form and to accomplish manipulations on traffic data. In this paper the methodology for detecting vehicles on highways is presented. Due to urbanization all over the world, the growth of traffic is shattered since few years and we entered in to the era of big data for transportation. The present study involves the understanding of fundamental elements of traffic, the problems in collecting the data, and their suitable corrections (speed, lateral and longitudinal) to be applied, extraction of error free macroscopic data, modelling and analysis of the macroscopic data. TRAZER is used for trajectory data extraction and the macroscopic relationships investigated by the trajectory data. Problems with TRAZER raw data extraction and corrections to it are discussed. The curves illustrate the basics traffic flow relationships between the three parameters such as density, flow and speed and from the analysis it is observed that the data is fitting Greenshields model.
C1 [Ballari, Syed Omar] Guru Nanak Inst Tech Campus, Dept Civil Engn, Hyderabad, Telangana, India.
C3 Guru Nanak Institutions Technical Campus
RP Ballari, SO (corresponding author), Guru Nanak Inst Tech Campus, Dept Civil Engn, Hyderabad, Telangana, India.
EM ballarisyedomar@gmail.com
RI Ballari, syedomar/AHE-9527-2022
OI Ballari, syedomar/0000-0001-6533-8414
CR Ballari S.O., 2019, INT J INNOV TECHNOL, V8, P1026
   Ballari S. O., 2019, Journal of Advanced Research in Dynamical and Control Systems, VVol. 11, P18
   Ballari S.O., 2020, International Journal of Recent Technology and Engineering (IJRTE), V8, P710, DOI [10.35940/ijrte.D9236.018520, DOI 10.35940/IJRTE.D9236.018520]
   Ballari SO, 2018, TRANSP DEV ECON, V4, DOI 10.1007/s40890-018-0067-z
   Chu C.M., 2005, Journal of the Eastern Asia Society for Transportation Studies, V6, P1496
   Chunchu M, 2010, TRANSPORT-VILNIUS, V25, P262, DOI 10.3846/transport.2010.32
   Ervin R, 2000, REP
   Gunay B, 2007, TRANSPORT RES B-METH, V41, P722, DOI 10.1016/j.trb.2007.02.002
   Gupta AK, 1986, RES TOMORROWS TRANSP, V2, P1521
   Haefner LE, 1998, TRANSPORTATION C P, P12
   Hall F.L., 1993, TRAFFIC ENG CONTROL, V34, P420
   Hoogendoorn SP, 2003, TRANSPORT RES REC, P121
   Koller D., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P189
   Kumar VM, 1994, THESIS INDIAN I TECH
   Mallikarjuna C, 2009, J TRANSP ENG, V135, P174, DOI 10.1061/(ASCE)0733-947X(2009)135:4(174)
   Mallikarjuna C, 2007, THESIS INDIAN I TECH
   Mallikarjuna C, 2006, 22 ARRB C RES PRACT
   Mallikarjuna C, 2011, TRANSPORTMETRICA, V7, P321, DOI 10.1080/18128601003706078
   Masoud O, 2001, IEEE T INTELL TRANSP, V2, P18, DOI 10.1109/6979.911082
   Nagaraj BN, 1990, STUDY LINEAR LATERAL
   Omar BS., 2020, TRANSP RES PROCEDIA, V48, P801, DOI [10.1016/j.trpro.2020.08.085, DOI 10.1016/J.TRPRO.2020.08.085]
   Omar S, 2016, PROCEDIA ENGINEER, V142, P244, DOI 10.1016/j.proeng.2016.02.038
   Raghava Chari S., 1983, HIGHWAY RES B NEW DE, V20, P57
   Sahoo P.K., 1996, INDIAN HIGHWAYS INDI, V24, P11
   Singh B, 1999, THESIS INDIAN I TECH
   Tuladhar SBS, 1987, THESIS BANGALORE U B
   Veeraraghavan H., 2005, DEV TRACKING BASED M
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wei H, 2005, J TRANSP ENG, V131, P496, DOI 10.1061/(ASCE)0733-947X(2005)131:7(496)
   Zhao T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P710, DOI 10.1109/ICCV.2001.937593
NR 30
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16363-0
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O5QZ5
UT WOS:001044367100002
DA 2024-07-18
ER

PT J
AU Sarang, S
   Sonawane, B
   Sharma, P
   Yeradkar, R
AF Sarang, Sushant
   Sonawane, Bhakti
   Sharma, Priyanka
   Yeradkar, Rashmi
TI To study the effect of a newly developed emotion detection and grading
   system software for identifying and grading expressions of patients with
   Parkinson's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial expression recognition; Convolutional neural network; Parkinson's
   disease; Masked face
ID FACIAL EXPRESSIONS; FACES; CAPTURE; VALENCE
AB Parkinson's disease (PD) is the most widespread neurodegenerative disorder after Alzheimer's disease. Masked facial expressions in people with PD may have a substantial impact on their social well-being and quality of life. This study investigated the effectiveness of a newly developed Emotion Detection and Grading System (EDGS) software for identifying and grading expressions of normal as well as patients with PD. EDGS is a deep learning-based emotion detection and grading software for the identification of seven basic emotional expressions and grading the intensities of happy and sad emotional expressivity. It was found that the EDGS software successfully identified happy and surprise emotions in normal subjects and patients with PD. It could categorize two intensities of happy and sad emotions. Additionally, the EDGS software was also found to be able to categorise the patients with PD according to their decrease in emotional expressivity, thereby opening possibilities of detecting the progress of PD.
C1 [Sarang, Sushant] Seth GSMC & KEMH, Occupat Therapy, Mumbai, India.
   [Sonawane, Bhakti] Nirma Univ, Inst Technol, Comp Engn Dept, Ahmadabad, India.
   [Sharma, Priyanka] Fujitsu Res, Ahmadabad, India.
   [Yeradkar, Rashmi] LTMMC & GH, Occupat Therapy Training Sch & Ctr, Mumbai, India.
C3 Seth Gordhandas Sunderdas Medical College & King Edward Memorial
   Hospital; Nirma University
RP Sonawane, B (corresponding author), Nirma Univ, Inst Technol, Comp Engn Dept, Ahmadabad, India.
EM drssushant@gmail.com; 15extphde153@nirmauni.ac.in;
   drpriyankasharma.ai@gmail.com; otrashmi@gmail.com
RI Sonawane, Bhakti/AAH-5333-2020; Sonawane, Bhakti/R-8759-2019; Sonawane,
   Bhakti/KHT-4569-2024; Sonawane, bhakti/T-8756-2019
OI Sonawane, bhakti/0000-0002-2154-9014
CR Abrami A, 2021, J MED INTERNET RES, V23, DOI 10.2196/21037
   Bandini A, 2017, J NEUROSCI METH, V281, P7, DOI 10.1016/j.jneumeth.2017.02.006
   Beaupre M.G., 2000, The Montreal set of facial displays of emotion, P8888
   Bowers D, 2006, J INT NEUROPSYCH SOC, V12, P765, DOI 10.1017/S135561770606111X
   Butt AH, 2020, ANN BIOMED ENG, V48, P2976, DOI 10.1007/s10439-020-02628-4
   Chaudhary S, 2006, PARKINSONISM RELAT D, V12, P239, DOI 10.1016/j.parkreldis.2005.12.004
   Dores AR, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17207420
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Ekman P, 1978, FACIAL ACTION CODING
   Enrici I, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131470
   Goetz CG, 2003, MOVEMENT DISORD, V18, P738, DOI 10.1002/mds.10473
   Goyal J, 2021, INT J DATA SCI ANAL, V11, P69, DOI 10.1007/s41060-020-00234-0
   Gupta R, 2019, PROG BRAIN RES, V247, P23, DOI 10.1016/bs.pbr.2019.02.001
   Gupta R, 2016, EMOTION, V16, P328, DOI 10.1037/emo0000112
   Haaxma CA, 2007, J NEUROL NEUROSUR PS, V78, P819, DOI 10.1136/jnnp.2006.103788
   Jack RE, 2014, CURR BIOL, V24, P187, DOI 10.1016/j.cub.2013.11.064
   Johnson MH, 2015, NEUROSCI BIOBEHAV R, V50, P169, DOI 10.1016/j.neubiorev.2014.10.009
   Johnson MH, 2005, NAT REV NEUROSCI, V6, P766, DOI 10.1038/nrn1766
   Joshi A, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   KATSIKITIS M, 1988, J NEUROL NEUROSUR PS, V51, P362, DOI 10.1136/jnnp.51.3.362
   Khanna K., 2020, J CRIT REV, V7, P1461, DOI [10.31838/jcr.07.18.188, DOI 10.31838/JCR.07.18.188]
   Langevin Raina, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328925
   Lee DH, 2013, PSYCHOL SCI, V24, P957, DOI 10.1177/0956797612464500
   Liu TT, 2021, INFRARED PHYS TECHN, V112, DOI 10.1016/j.infrared.2020.103594
   Lundqvist D, 1998, COGNITION EMOTION, DOI [DOI 10.1037/T27732000, 10.1037/t27732-000, DOI 10.1037/T27732-000]
   Morris JS, 2001, BRAIN, V124, P1241, DOI 10.1093/brain/124.6.1241
   Moshkova A, 2020, PROC CONF OPEN INNOV, P172
   Murugappan M., 2020, 2020 4 INT C COMPUTE, P15, DOI 10.1109/ICCCSP49186.2020.9315234
   Neta M, 2010, PSYCHOL SCI, V21, P901, DOI 10.1177/0956797610373934
   Ramig LO., 1995, LEE SILVERMAN VOICE
   Ricciardi L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169110
   Ricciardi L, 2015, J NEUROL SCI, V358, P125, DOI 10.1016/j.jns.2015.08.1516
   Senturk ZK, 2020, MED HYPOTHESES, V138, DOI 10.1016/j.mehy.2020.109603
   Simons G, 2004, J INT NEUROPSYCH SOC, V10, P521, DOI 10.1017/S135561770410413X
   Smith FW, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197160
   Sonawane B, 2020, PATTERN RECOGN IMAGE, V30, P726, DOI 10.1134/S1054661820040239
   Sonawane B, 2021, VISUAL COMPUT, V37, P1151, DOI 10.1007/s00371-020-01859-9
   Susskind JM, 2008, NAT NEUROSCI, V11, P843, DOI 10.1038/nn.2138
   Tickle-Degnen L., 2010, INTERPERSONAL COMMUN
   Vinokurov N, 2016, COMM COM INF SC, V604, P63, DOI 10.1007/978-3-319-32270-4_7
   Vuilleumier P, 2003, NAT NEUROSCI, V6, P624, DOI 10.1038/nn1057
   Wu P, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/427826
   Xiao HX, 2021, INFRARED PHYS TECHN, V117, DOI 10.1016/j.infrared.2021.103823
   Young A., 2016, Facial expression recognition: The selected works of Andy Young (World library of psychologists)
   Zhang ZL, 2020, NEUROCOMPUTING, V409, P341, DOI 10.1016/j.neucom.2020.05.081
NR 46
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16156-5
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400002
DA 2024-07-18
ER

PT J
AU Bamal, R
   Kasana, SS
AF Bamal, Roopam
   Kasana, Singara Singh
TI Reversible medical image watermarking for tamper detection using ANN and
   SLT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE SLT; PSNR; BPP; PSO; ANN; AES; RS vector
ID CONTRAST ENHANCEMENT; AUTHENTICATION; SCHEME; EXPANSION; RECOVERY;
   REGION
AB Watermarking is exclusively done for ownership authentication and identity integrity. There are various watermarking techniques for hiding crucial patients' data while digital medical image transmission but most lack resistance against many unwanted attacks. The proposed technique focuses on robustness, reversible data hiding with tamper localization, and recovery for medical images. Firstly, ANN is used to create a watermark creation by feature extraction, and the medical image is divided into ROI and RONI. Then, hybrid watermarking uses SLT and RS Vector. SHA-3, AES andLZW are used for reliability and confidentiality. Pre-processing is done to reduce the disordered pixels for minimal visual distortion and contrast enhancement. The tampered data recovery of the ROI from the watermarked image at the receiver's end is located by the difference matrix between the ROI bits after applying ANN and the bits extracted from the background. Experimental results demonstrate that in comparison with < 30 existing articles, the proposed technique achieves high robustness against < 20 attacks along with tamper detection and recovery of ROI, preserving the visual quality of the cover image.
C1 [Bamal, Roopam] Thapar Univ, Comp Sci Engn Dept, Patiala 147004, Punjab, India.
   [Kasana, Singara Singh] Cent Univ Haryana, Comp Sci & Informat Technol, Mahendergarh, Haryana, India.
C3 Thapar Institute of Engineering & Technology; Central University of
   Haryana
RP Bamal, R (corresponding author), Thapar Univ, Comp Sci Engn Dept, Patiala 147004, Punjab, India.
EM roopambamal@gmail.com; singarasingh@cuh.ac.in
CR Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Al-Rakhami M.S., 2021, DIAGNOSIS COVID 19 X, P2020
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], 2009, P INT C MED SYST ENG
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bamal R, 2018, MULTIMED TOOLS APPL, V77, P12493, DOI 10.1007/s11042-017-4898-0
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Cruz RMS., 2011, ARTIFICIAL NEURAL NE, DOI [10.5772/15293, DOI 10.5772/15293]
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Luo YL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114272
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Memon NA, 2010, THESIS GHULAM ISHAQ
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rahman MU, 2020, 2020 IEEE GLOBAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERNET OF THINGS (GCAIOT), P1, DOI 10.1109/GCAIOT51063.2020.9345874
   Selesnick IW, 1998, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P53, DOI 10.1109/TFSA.1998.721359
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Silva PHdaF, 2010, Syst Circ Design Biologically-Inspired Intell Learn, Patent No. 1969067189
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Woo C-S, 2005, MULTIPLE WATERMARK M
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Zain JM, 2007, P ANN INT IEEE EMBS, P5662
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2007, INT J COMPUT SCI NET, V7, P19
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 46
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-14737-y
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700009
DA 2024-07-18
ER

PT J
AU Subramanyam, V
   Kumar, J
   Singh, SN
AF Subramanyam, Vasanth
   Kumar, Jayendra
   Singh, Shiva Nand
TI A hybrid descriptor for low-textural image stitching in real-time
   surface inspection systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; Image stitching; Machine-vision
AB Surface inspection systems in the steel industry use multiple machine-vision (MV) cameras to inspect steel sheets for real-time quality control. Conventional approaches are classified into direct, deep-learning-based, and feature-based methodologies. Direct techniques perform poorly on parallax, while deep-learning-based algorithms require higher execution times and are ineffective for real-time applications. We propose a hybrid descriptor that uses defect detection to effectively stitch low-textural images captured by multiple cameras that are evaluated based on matching accuracy, execution time, and quality of stitched images and compared to popular feature-based image descriptor algorithms. Experimental results show that the proposed hybrid descriptor outperforms existing feature descriptors with 91% matching accuracy and an execution time of 49 milliseconds, producing a seamlessly stitched output.
C1 [Subramanyam, Vasanth] Tata Steel, Automat, Jamshedpur 831005, Jharkhand, India.
   [Subramanyam, Vasanth; Kumar, Jayendra; Singh, Shiva Nand] Natl Inst Technol, Elect & Commun, Jamshedpur 831015, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Subramanyam, V (corresponding author), Tata Steel, Automat, Jamshedpur 831005, Jharkhand, India.; Subramanyam, V (corresponding author), Natl Inst Technol, Elect & Commun, Jamshedpur 831015, Jharkhand, India.
EM v.subramanyam@tatasteel.com; jkumar.ece@nitjsr.ac.in;
   snsingh.ece@nitjsr.ac.in
RI Kumar (SMIEEE), Jayendra/C-4475-2019
OI Kumar (SMIEEE), Jayendra/0000-0002-3381-2764; Subramanyam,
   Vasanth/0000-0002-0804-0221
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alzohairy TA., 2016, INT J COMPUT APPL, V975, P8887
   [Anonymous], 2011, PROC CVPR IEEE
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bonny MZ, 2016, 2016 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE (IWCI), P198, DOI 10.1109/IWCI.2016.7860365
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Chang CH, 2012, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2012.6247786
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao J., 2013, Eurographics (Short Papers), P45, DOI DOI 10.2312/CONF/EG2013/SHORT/045-048
   Ghorai S, 2013, IEEE T INSTRUM MEAS, V62, P612, DOI 10.1109/TIM.2012.2218677
   Jain R, 1995, MACHINE VISION, P249
   Jia JY, 2005, IEEE I CONF COMP VIS, P1651
   Joshi K, 2020, OPEN ACCESS SURVEY R, DOI [10.9790/9622-1005011924, DOI 10.9790/9622-1005011924]
   Kaynig V, 2008, IEEE C COMP VIS PATT, P1
   Kyu-Yul Lee, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8195, DOI 10.1109/CVPR42600.2020.00822
   Lamkin MA, 2019, DISTRIBUTED MULTIAPE
   Le Moigne J, 2002, IEEE T GEOSCI REMOTE, V40, P1849, DOI 10.1109/TGRS.2002.802501
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li J, 2020, IEEE J-STSP, V14, P209, DOI 10.1109/JSTSP.2019.2953950
   Li J, 2020, IEEE T IMAGE PROCESS, V29, P2356, DOI 10.1109/TIP.2019.2949424
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Li Z, 2016, IEEE T MED IMAGING, V35, P63, DOI 10.1109/TMI.2015.2455416
   Liao K, 2020, IEEE T IMAGE PROCESS, V29, P3707, DOI 10.1109/TIP.2020.2964523
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo QW, 2020, IEEE T INSTRUM MEAS, V69, P626, DOI 10.1109/TIM.2019.2963555
   Mistry S, 2016, INT RES J ENG TECHNO, V03, P1363
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   Ono Y, 2018, ADV NEUR IN, V31
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Sanders-Reed, 2010, PROC SPIE, V7692, P1
   Sarnoff, 2015, DISTR AP SYST
   Shen C, 2019, REAL TIME IMAGE STIT, P192
   Shi ZF, 2020, J SIGNAL PROCESS SYS, V92, P435, DOI 10.1007/s11265-019-01477-2
   Silva R., 2016, ACM SIGGRAPH 2016 PO, P1
   Stojanovic R, 2001, REAL-TIME IMAGING, V7, P507, DOI 10.1006/rtim.2001.0231
   Su MS, 2004, IEEE T IMAGE PROCESS, V13, P952, DOI 10.1109/TIP.2004.828416
   Sugimoto T, 1998, IEEE T INSTRUM MEAS, V47, P409, DOI 10.1109/19.744183
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tian L, 2020, IEEE T IMAGE PROCESS, V29, P8429, DOI 10.1109/TIP.2020.3013168
   Hoang VD, 2020, LECT NOTES ARTIF INT, V12034, P141, DOI 10.1007/978-3-030-42058-1_12
   Wang L, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P694, DOI [10.1109/ITNEC48623.2020.9084886, 10.1109/itnec48623.2020.9084886]
   Yan M, 2016, IEEE IJCNN, P4162, DOI 10.1109/IJCNN.2016.7727742
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang F, 2015, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2015.7298811
   Zhang J, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540064
   Zhang ZY, 2018, IEEE T IMAGE PROCESS, V27, P3691, DOI 10.1109/TIP.2018.2821979
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zomet A, 2006, IEEE T IMAGE PROCESS, V15, P969, DOI 10.1109/TIP.2005.863958
NR 57
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20653
EP 20675
DI 10.1007/s11042-023-16357-y
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200013
DA 2024-07-18
ER

PT J
AU Landolsi, MY
   Hlaoua, L
   Ben Romdhane, L
AF Landolsi, Mohamed Yassine
   Hlaoua, Lobna
   Ben Romdhane, Lotfi
TI Extracting and structuring information from the electronic medical text:
   state of the art and trendy directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic medical records; Information extraction; Medical named
   entities recognition; Medical relation extraction; Section detection
ID NAMED ENTITY RECOGNITION; HEALTH RECORDS; IDENTIFICATION; SYSTEM; CARE;
   CLASSIFICATION; DISEASE; CANCER
AB In the medical field, doctors must have comprehensive knowledge by reading and writing narrative documents, and they are responsible for every decision they take for patients. Unfortunately, reading all the necessary information about drugs, diseases, and patients might be time-consuming due to the large number of documents that are increasing every day. Consequently, potential medical errors could be hazardous. Likewise, information extraction can handle this problem using several important tasks to structure the text and extract the relevant and desired information from unstructured text written in natural language. The main principle tasks are named entity recognition and relation extraction. However, to treat the narrative text, we should use natural language processing techniques to extract useful information and features. In our paper, we show and discuss several techniques and useful data used for these tasks. Furthermore, we outline the challenges in information extraction from medical documents. To our knowledge, this is the most comprehensive survey in the literature with a numerical comparison and a suggestion for some uncovered directions.
C1 [Landolsi, Mohamed Yassine; Hlaoua, Lobna; Ben Romdhane, Lotfi] Univ Sousse, MARS Res Lab, SDM Res Grp, ISITCom H Sousse, Hammam Sousse 4011, Tunisia.
C3 Universite de Sousse
RP Landolsi, MY (corresponding author), Univ Sousse, MARS Res Lab, SDM Res Grp, ISITCom H Sousse, Hammam Sousse 4011, Tunisia.
EM medyassine.landolsi@isitc.u-sousse.tn; lobna.hlaoua@essths.u-sousse.tn;
   lotfi.benromdhane@isitc.u-sousse.tn
RI Landolsi, Mohamed Yassine/JGC-8584-2023
OI Landolsi, Mohamed Yassine/0000-0001-8323-8943
CR Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54
   Alex B, 2019, J BIOMED SEMANT, V10, DOI 10.1186/s13326-019-0211-7
   Angeli G, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P344
   [Anonymous], 2004, P 42 ANN M ASS COMPU
   [Anonymous], 2011, J. Biomed. Semant
   Apostolova E, 2009, IEEE ENG MED BIO, P5905, DOI 10.1109/IEMBS.2009.5334831
   Arbabi A, 2019, JMIR MED INF, V7, P191, DOI 10.2196/12596
   Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733
   Aydar M, 2020, ARXIV
   Bart Robert, 2012, P C EMP METH NAT LAN, P523
   Batista D., 2018, NAMED ENTITY EVALUAT
   Beel J, 2010, LECT NOTES COMPUT SC, V6273, P413, DOI 10.1007/978-3-642-15464-5_45
   Ben Abdessalem Karaa W, 2021, MOB INF SYST, P2021
   Ben El Kouni I, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON SOFTWARE TECHNOLOGIES (ICSOFT), P408, DOI 10.5220/0010605904080416
   Bethard S., 2017, P 11 INT WORKSHOP SE, P565
   Bethard S., 2016, P 10 INT WORKSHOP SE, P1052
   Bhatia P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P954
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Bottou L., 1998, ONLINE LEARNING NEUR, V17, P142
   Boudjedir H., 2012, International_Journal_in Foundations_of_Computer_Science_and_Technology, V2, P1, DOI [https://doi.org/10.5121/ijist.2012.2401, DOI 10.5121/IJIST.2012.2401]
   Bramsen Philip, 2006, AMIA Annu Symp Proc, P81
   Carrell DS, 2014, AM J EPIDEMIOL, V179, P749, DOI 10.1093/aje/kwt441
   Chapman W, 2007, Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, BioNLP '07, P81, DOI DOI 10.3115/1572392.1572408
   Chapman WW, 2012, J BIOMED INFORM, V45, P507, DOI 10.1016/j.jbi.2012.01.010
   Chirila OS, 2019, STUD HEALTH TECHNOL, V264, P353, DOI 10.3233/SHTI190242
   Chirila OS, 2019, STUD HEALTH TECHNOL, V262, P284, DOI 10.3233/SHTI190074
   Cohen KB, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1775-9
   Cohen KB., 2017, HDB LINGUISTIC ANNOT, P1379
   Dai HJ, 2015, BIOMED RES INT-UK, P2015
   Dai X, 2020, ARXIV
   de Bruijn B, 2011, J AM MED INFORM ASSN, V18, P557, DOI 10.1136/amiajnl-2011-000150
   Del Corro Luciano, 2013, P 22 INT C WORLD WID, P355, DOI DOI 10.1145/2488388.2488420
   Deleger L, 2014, TALN
   Deng N, 2021, WIREL COMMUN MOB COM, P2021
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006
   Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279
   Edinger Tracy, 2017, AMIA Annu Symp Proc, V2017, P660
   El-allaly ED, 2022, J BIOMED INFORM, V125, DOI 10.1016/j.jbi.2021.103968
   Elhadad N., 2015, P 9 INT WORKSH SEM E, P303, DOI [10.18653/v1/S15-2051, DOI 10.18653/V1/S15-2051]
   Eriksson R, 2013, J AM MED INFORM ASSN, V20, P947, DOI 10.1136/amiajnl-2013-001708
   Fader A., 2011, P C EMP METH NAT LAN, P1535, DOI DOI 10.1234/12345678
   Ford E, 2016, J AM MED INFORM ASSN, V23, P1007, DOI 10.1093/jamia/ocv180
   Fundel K, 2007, BIOINFORMATICS, V23, P365, DOI 10.1093/bioinformatics/btl616
   Garvin JH, 2012, J AM MED INFORM ASSN, V19, P859, DOI 10.1136/amiajnl-2011-000535
   Ghiasvand Omid, 2018, Informatics in Medicine Unlocked, V13, P122, DOI 10.1016/j.imu.2018.10.011
   Goenaga I, 2021, J BIOMED INFORM, V121, DOI 10.1016/j.jbi.2021.103875
   Grishman R., 1996, COLING 1996 VOLUME 1
   Guo FY, 2019, IEEE ACCESS, V7, P169281, DOI 10.1109/ACCESS.2019.2954988
   Hafiene N, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113642
   Hahn Udo, 2020, Yearb Med Inform, V29, P208, DOI 10.1055/s-0040-1702001
   Hallersten A, 2016, REGUL TOXICOL PHARM, V77, P275, DOI 10.1016/j.yrtph.2016.03.021
   Hasan F, 2020, PROC INT C TOOLS ART, P418, DOI 10.1109/ICTAI50040.2020.00072
   Haug Peter J, 2014, AMIA Annu Symp Proc, V2014, P636
   He SF, 2022, MULTIMED TOOLS APPL, V81, P19135, DOI 10.1007/s11042-020-10089-z
   Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166
   Hong WS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201016
   Honnibal M., 2017, IN PRESS, DOI DOI 10.3233/978-1-60750-588-4-1080
   Hsu W, 2016, J AM MED INFORM ASSN, V23, pE152, DOI 10.1093/jamia/ocv161
   Islamaj R, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00875-1
   Jagannatha A, 2019, DRUG SAFETY, V42, P99, DOI 10.1007/s40264-018-0762-z
   Jancsary J., 2008, Proceedings of the 2008 conference on empirical methods in natural language processing, P1
   Jaoul M, 2019, 2019 IEEE BICMOS AND COMPOUND SEMICONDUCTOR INTEGRATED CIRCUITS AND TECHNOLOGY SYMPOSIUM (BCICTS 2019), DOI 10.1109/bcicts45179.2019.8972729
   Jelier R, 2005, BIOINFORMATICS, V21, P2049, DOI 10.1093/bioinformatics/bti268
   Jingli Shi, 2021, Knowledge Management and Acquisition for Intelligent Systems. 17th Pacific Rim Knowledge Acquisition Workshop, PKAW 2020. Proceedings. Lecture Notes in Artificial Intelligence (LNAI 12280), P178, DOI 10.1007/978-3-030-69886-7_15
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Jonnalagadda SR, 2017, J CARDIOVASC TRANSL, V10, P313, DOI 10.1007/s12265-017-9752-2
   Karlsson I, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P356, DOI 10.1109/ICHI.2016.64
   Khan Kainat, 2021, 2021 IEEE 9th Region 10 Humanitarian Technology Conference (R10-HTC), P01, DOI 10.1109/R10-HTC53172.2021.9641515
   Kim Y, 2021, JMIR MED INF, V9, DOI 10.2196/22797
   Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173
   Komninos A., 2016, P 2016 C N AM CHAPT, P1490
   Kreuzthaler M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S2-S4
   Kroll H, 2020, ARXIV
   Kropf S, 2017, METHOD INFORM MED, V56, P230, DOI 10.3414/ME16-01-0073
   Kumar S.K., 2017, ARXIV
   Lai KH, 2015, J BIOMED INFORM, V55, P188, DOI 10.1016/j.jbi.2015.04.008
   Lan M., 2017, P 2017 C EMP METH NA, P1299
   Landolsi MY, 2021, MULTIMED TOOLS APPL, V80, P12009, DOI 10.1007/s11042-020-09730-8
   Laparra E., 2018, P 12 INT WORKSH SEM, P88
   Laparra Egoitz., 2021, P 15 INT WORKSH SEM, P348, DOI DOI 10.18653/V1/2021.SEMEVAL-1.42
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lee W, 2018, HEALTHC INFORM RES, V24, P179, DOI 10.4258/hir.2018.24.3.179
   Lei JB, 2014, J AM MED INFORM ASSN, V21, P808, DOI 10.1136/amiajnl-2013-002381
   Leroy G, 2002, Pac Symp Biocomput, P350
   Li F., 2021, ARXIV
   Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068
   Li Y., 2010, ACM INT HLTH INFORMA, P744
   Liu F., 2016, ARXIV
   Liu Y., 2016, CHINA DIG MED, V11, P53
   Liu Yinhan, 2019, ARXIV190711692
   Lohr Christina, 2018, AMIA Annu Symp Proc, V2018, P770
   Luan Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3036
   Ludwick DA, 2009, INT J MED INFORM, V78, P22, DOI 10.1016/j.ijmedinf.2008.06.005
   Lupșe O. S., 2018, Applied Medical Informatics, V40, P7
   Lupse Oana-Sorina, 2018, Stud Health Technol Inform, V251, P153
   Mabrouk O, 2021, APPL INTELL, V51, P3757, DOI 10.1007/s10489-020-01939-2
   Mahendran D, 2022, P SEM EN BIOM LIT AN
   Mahendran Darshini, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P420
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mehrabi S, 2015, STUD HEALTH TECHNOL, V216, P604, DOI 10.3233/978-1-61499-564-7-604
   Mercorelli L, 2022, AUST HEALTH REV, V46, P289, DOI 10.1071/AH21361
   Meystre S M, 2008, Yearb Med Inform, P128
   Mnasri W, 2021, APPL INTELL, V51, P7365, DOI 10.1007/s10489-021-02203-x
   Nair Namrata, 2022, Proceedings of Sixth International Congress on Information and Communication Technology: ICICT 2021. Lecture Notes in Networks and Systems, P533, DOI 10.1007/978-981-16-2377-6_50
   Nasar Z, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3445965
   Nayel HA, 2019, ARXIV
   Neumann M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P319
   Ni J, 2015, STUD HEALTH TECHNOL, V216, P35, DOI 10.3233/978-1-61499-564-7-35
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Quimbaya AP, 2016, PROCEDIA COMPUT SCI, V100, P55, DOI 10.1016/j.procs.2016.09.123
   Pomares-Quimbaya A, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0792-y
   Popejoy LL, 2015, J AM MED INFORM ASSN, V22, pE93, DOI 10.1136/amiajnl-2014-002702
   Popovski G, 2020, IEEE ACCESS, V8, P31586, DOI 10.1109/ACCESS.2020.2973502
   Pradhan S., 2014, SEMEVAL COLING, P54
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101
   Ramshaw L. A, 1999, TEXT SPEECH LANG TEC, P157
   Roberts RJ, 2001, P NATL ACAD SCI USA, V98, P381, DOI 10.1073/pnas.98.2.381
   Rochefort CM, 2015, IMPLEMENT SCI, V10, DOI 10.1186/s13012-014-0197-6
   Rundo L, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103479
   Sadoughi N, 2018, LECT NOTES ARTIF INT, V11096, P563, DOI 10.1007/978-3-319-99579-3_58
   Sandhya P, 2020, TRENDS APPL TEXT SUM, P125
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Shi JL, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116538
   Sohrab MG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P182
   Song HJ, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0573-6
   Sorgente A., 2013, P 7 INT WORKSH INF F, P37
   Stubbs A, 2015, J BIOMED INFORM, V58, pS67, DOI 10.1016/j.jbi.2015.07.001
   Stubbs A, 2015, J BIOMED INFORM, V58, pS11, DOI 10.1016/j.jbi.2015.06.007
   Sui Y, 2022, TRIGGER GNN TRIGGER
   Sun Q, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3291
   Sun WC, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4302425
   Suominen HJ, 2010, J HEALTHC ENG, V1, P595, DOI 10.1260/2040-2295.1.4.595
   Tang BZ, 2013, BMC MED INFORM DECIS, V13, DOI 10.1186/1472-6947-13-S1-S1
   Tchraktchiev D, 2011, STUD HEALTH TECHNOL, V166, P260, DOI 10.3233/978-1-60750-740-6-260
   Tepper M, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2001
   Tran T, 2019, ARTIF INTELL MED, V98, P18, DOI 10.1016/j.artmed.2019.06.002
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Uzuner Ö, 2010, J AM MED INFORM ASSN, V17, P514, DOI 10.1136/jamia.2010.003947
   Tran V, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P24
   Vunikili R., 2020, IBERLEF SEPLN, V2664, P505
   Wang L, 2021, J BIOMED INFORM
   Wang PW, 2017, J ASSOC INF SCI TECH, V68, P2649, DOI 10.1002/asi.23876
   Wang S, 2018, C IND ELECT APPL, P2725, DOI 10.1109/ICIEA.2018.8398172
   Wang XY, 2009, J AM MED INFORM ASSN, V16, P328, DOI 10.1197/jamia.M3028
   Wang YS, 2020, JMIR MED INF, V8, DOI 10.2196/23375
   Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011
   Wei Qiang, 2019, AMIA Annu Symp Proc, V2019, P1236
   Wei WQ, 2014, CLIN PHARMACOL THER, V95, P331, DOI 10.1038/clpt.2013.202
   Weiskopf NG, 2013, J BIOMED INFORM, V46, P830, DOI 10.1016/j.jbi.2013.06.010
   Wencheng Sun, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210774
   Wu Yonghui, 2017, AMIA Annu Symp Proc, V2017, P1812
   Wusuo Li, 2018, 2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA), P356, DOI 10.1109/ICBDA.2018.8367707
   Xu J, 2018, J HEALTHC ENG, P2018
   Yang J., 2021, arXiv
   Yang X, 2021, ARXIV
   Yang X, 2020, JMIR MED INF, V8, DOI 10.2196/22982
   Yang Z., 2019, Advances in neural information processing systems, P32
   Yang ZH, 2008, COMPUT BIOL CHEM, V32, P287, DOI 10.1016/j.compbiolchem.2008.03.008
   Zhang RT, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15030402
   Zhang SD, 2013, J BIOMED INFORM, V46, P1088, DOI 10.1016/j.jbi.2013.08.004
   Zhang T, 2022, EVID-BASED COMPL ALT
   [张越 Zhang Yue], 2016, [中国全科医学, Chinese General Practice], V19, P2636
   Zhao XY, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3636
   Zheng CY, 2015, CLIN THER, V37, P2048, DOI 10.1016/j.clinthera.2015.07.002
   Zhou J, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2048-y
   Zhou Y., 2021, ARXIV
   Zweigenbaum P., 2013, CLEF
NR 168
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21229
EP 21280
DI 10.1007/s11042-023-15080-y
EA AUG 2023
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400006
DA 2024-07-18
ER

PT J
AU Ahmad, W
   Adnan, SM
   Irtaza, A
AF Ahmad, Wakeel
   Adnan, Syed M.
   Irtaza, Aun
TI Local triangular-ternary pattern: a novel feature descriptor for plant
   leaf disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease; Triangular pattern; Feature descriptor; Tomato leaf
   disease; Precision agriculture
AB Most of the plant diseases severely affect the plant leaves and thus can be identified from infected leaf images using modern computer vision techniques. During the last decade, various machine learning methods have been developed to detect and analyze plant leaf disease accurately. Hence, developing an effective machine learning prediction method for plant disease identification at an early stage arises enormous interest in computer vision research. Diagnosing plant leaf diseases is a challenging area of research, mainly because leaf images exhibit complexity arising from irregular shapes, uneven colors, a mixture of normal and abnormal regions, and are often accompanied by complex backgrounds. In this paper, a new feature descriptor titled as the local triangular-ternary pattern (LTriTP) for plant leaf disease detection is proposed. The proposed method extracts feature vectors using the triangular shape descriptor to enable efficient extraction and representation of features from the leaf images. To apply the ternary pattern, an absolute mean value based dynamic threshold is computed, which supports the sensitive analysis of plant leaf image texture information by producing highly relevant and diverse values. Since plant disease can appear at any orientation on a leaf image, therefore in each triangle, a histogram of the gradient is also computed in four directions (0(0), 45(0), 90(0), and 135(0)) to find the gradient change of infected regions in contrast to healthy areas. This is what we termed as the triangular histogram of gradient (T-HOG), which makes the proposed method orientation invariant. Fusion of T-HOG and LTriTP features has shown better disease detection performance. Multimodal classification is performed using 6 disease classes of tomato leaf images. The performance of the proposed method is compared with renowned methods like Local Binary Pattern, and Local Ternary Pattern using the publicly available PlantVillage dataset of tomato images. The classification accuracy varies from 94.50% to 97.80% with respect to different classifiers, where the error rate varies from 2.03% to 5.03%.
C1 [Ahmad, Wakeel; Adnan, Syed M.; Irtaza, Aun] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
C3 University of Engineering & Technology Taxila
RP Ahmad, W (corresponding author), Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
EM wakeel.ahmad@uettaxila.edu.pk; syed.adnan@uettaxila.edu.pk;
   aun.irtaza@uettaxila.edu.pk
RI Adnan, Syed/JMC-0046-2023
OI , Syed M. Adnan/0000-0002-0254-412X
CR Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Ahmad A, 2023, IEEE ACCESS, V11, P9042, DOI 10.1109/ACCESS.2023.3240100
   Ahmad N, 2021, WIRELESS PERS COMMUN, V121, P1139, DOI 10.1007/s11277-021-09054-2
   Ahmad W, 2020, KSII T INTERNET INF, V14, P3312, DOI 10.3837/tiis.2020.08.009
   Aksoy A, 2021, BULG J AGRIC SCI, V27, P253
   Al-gaashani MSAM, 2022, IET IMAGE PROCESS, V16, P913, DOI 10.1049/ipr2.12397
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2021, CLIM CHANG FANS SPRE
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bensaadi S, 2023, LOW COST CONVOLUTION, V12, P162
   Bhushanamu M., 2020, EUR J MOL CLIN MED, V7, P1088
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Department of Economic and Social Affairs Population Division United Nations, 2022, WORLD POPULATION PRO
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Gadade H, 2021, 2021 5 INT C COMP ME, DOI [10.1109/ICCMC51019.2021.9418263, DOI 10.1109/ICCMC51019.2021.9418263]
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Group TWB, 2021, AGR FOOD
   Guo Y, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/2479172
   Haridasan A, 2023, ENVIRON MONIT ASSESS, V195, DOI 10.1007/s10661-022-10656-x
   Huang XB, 2023, MULTIMED TOOLS APPL, V82, P2121, DOI 10.1007/s11042-021-11790-3
   Huiqun Hong, 2020, 2020 International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), P25, DOI 10.1109/ICBAIE49996.2020.00012
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kaur NJ., 2021, Turkish J. Comput. Math. Educ., V12, P2339
   Khatoon S., 2021, Comput. Mater. Contin, V67, P595, DOI [10.32604/cmc.2021.014580, DOI 10.32604/CMC.2021.014580]
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Li MX, 2022, COMPUT ELECTRON AGR, V194, DOI 10.1016/j.compag.2022.106779
   Li Y, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050178
   Malathi V, 2021, ACTA AGR SCAND B-S P, V71, P552, DOI 10.1080/09064710.2021.1874045
   Mathew A, 2022, MATER TODAY-PROC, V58, P407, DOI 10.1016/j.matpr.2022.02.350
   Mimi TT, 2019, PROCEEDINGS OF THE 2019 8TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2019), P244, DOI [10.1109/smart46866.2019.9117437, 10.1109/SMART46866.2019.9117437]
   Mishra M, 2021, J AMB INTEL HUM COMP, V12, P691, DOI 10.1007/s12652-020-02051-6
   Mohapatra S, 2023, COMP COMM LERN 1 INT, DOI [10.1007/978-3-031-21750-0_20, DOI 10.1007/978-3-031-21750-0_20]
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nikith B. V., 2023, Procedia Computer Science, P291, DOI 10.1016/j.procs.2023.01.011
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Panigrahi K.P., 2020, PROGR COMPUTING ANAL, V1119, P659, DOI [DOI 10.1007/978, 10.1007/978-981-15-2414-1_66, DOI 10.1007/978-981-15-2414-1_66]
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Prabhakar M, 2020, MULTIMED TOOLS APPL, V79, P28773, DOI 10.1007/s11042-020-09461-w
   Rahman SU, 2023, MULTIMED TOOLS APPL, V82, P9431, DOI 10.1007/s11042-022-13715-0
   Rath AK, 2019, ARCH PHYTOPATH PLANT, V52, P1348, DOI 10.1080/03235408.2019.1708546
   Rehman A, 2021, 2021 INT C ART INT I, DOI [10.1109/ICAI52203.2021.9445237, DOI 10.1109/ICAI52203.2021.9445237]
   Shen Weizheng, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P491, DOI 10.1109/CSSE.2008.1649
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Singh Kuldeep, 2019, International Journal of Information Technology, V11, P485, DOI 10.1007/s41870-018-0134-z
   Srivastava D., 2018, INT J COMPUT PHYS SE, V1, P236, DOI [10.29167/A1I1P236-247, DOI 10.29167/A1I1P236-247]
   Sutha P., 2021, ANN ROMANIAN SOC CEL, V25, P9430
   Syed-Ab-Rahman SF, 2022, APPL INTELL, V52, P927, DOI 10.1007/s10489-021-02452-w
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wan H, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P5, DOI 10.1145/3380688.3380697
   Wang YY, 2020, AGR WATER MANAGE, V239, DOI 10.1016/j.agwat.2020.106163
   Wen J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164601
   Yulita IN, 2023, COMPUTATION, V11, DOI 10.3390/computation11020020
   Zafar MZ, 2019, EFFICIENT ALGO UNPUB
   Zafar MZ., 2019, BRAIN TUMOR DETECTIO, V24, P83
   Zhang RF, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074348
   Zhang SW, 2015, J ANIM PLANT SCI, V25, P42
   Zhao SY, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070651
NR 60
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20215
EP 20241
DI 10.1007/s11042-023-16420-8
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900003
DA 2024-07-18
ER

PT J
AU Sharma, H
   Das, S
AF Sharma, Harshad
   Das, Smita
TI A brief study of generative adversarial networks and their applications
   in image synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep generative models; Generative adversarial networks; Image
   synthesis; Computer vision
AB Image Synthesis (IS), an expansion to Artificial Intelligence (AI) and Computer Vision, is the technique of artificially producing images that retains some specific required contents. An adequate procedure to handle IS problem is to tackle it using the Deep Generative Models. Generative Models are broadly utilized in numerous sub fields of AI and have empowered versatile demonstration of perplexing scenarios including image, text and music. In this paper, a particular class of Deep Generative model namely Generative Adversarial Networks (GAN) has been considered to provide a way to acquire deep illustrations derived from backpropagation signals and without the use of wide range of annotated training data. The design of GAN architecture plays a key role in image synthesis and the motive behind this paper is to analyse GAN architecture based on different variants of GANs with respect to Image Synthesis. Furthermore, a compact categorization of GANs along with their key features, pros and cons have been investigated to identify the research challenges in this field.
C1 [Sharma, Harshad; Das, Smita] NIT Agartala, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala
RP Das, S (corresponding author), NIT Agartala, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.
EM smitadas.nita@gmail.com
CR [Anonymous], 2016, Sampling generative networks
   [Anonymous], 2017, arXiv preprint arXiv:1703.06412
   Arjovsky, 2017, ARXIV170104862
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Cha D, 2022, INT CONF ACOUST SPEE, P4883, DOI 10.1109/ICASSP43922.2022.9746659
   Chen J., 2020, INT S INT COMP APPL, P242, DOI DOI 10.1007/978-981-15-5577-0_18
   Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dhariwal P, 2021, ADV NEUR IN, V34
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Fruhstuck Anna., 2022, Insetgan for full-body image generation
   Gharaibeh M, 2016, IEEE CONF COMPUT
   Goodfellow I., 2016, NIPS 2016 TUTORIAL G
   Goodfellow I. J., 2014, ARXIV
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2021, MULTIMODAL CONDITION
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin Yanghua, 2017, ARXIV170805509
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2021, ADV NEUR IN, V34
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kavalerov I, 2019, CGANS MULTIHINGE LOS
   Kingma D. P., 2013, ARXIV13126114
   Kodali N, 2017, ARXIV
   Kwak JG, 2022, LECT NOTES COMPUT SC, V13677, P236, DOI 10.1007/978-3-031-19790-1_15
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee K., 2021, VITGAN TRAINING GANS
   Li B, 2021, ANIGAN STYLE GUIDED
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling Huan, 2021, EDITGAN HIGH PRECISI
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lu Y, 2020, UNIVERSAL APPROXIMAT
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Meng Q., 2021, GNeRF: GAN-based neural radiance field without posedcamera
   Metz L., 2016, ARXIV
   Miyato T., 2018, ARXIV
   Mroueh Y, 2017, ADV NEUR IN, V30
   Muller A, 1997, ADV APPL PROBAB, V29, P429, DOI 10.2307/1428011
   Nichol Alex, 2021, Glide: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
   Nowozin S, 2016, ADV NEUR IN, V29
   Odena A, 2017, PR MACH LEARN RES, V70
   Oord A.V.D., 2017, Neural discrete representation learning
   Park SW, 2019, PROC CVPR IEEE, P4287, DOI 10.1109/CVPR.2019.00442
   Petzka H, 2017, ARXIV
   Pfau David, 2016, CoRR
   Radford A., 2015, ARXIV
   Ramesh Aditya, 2022, Hierarchical text-conditional image generation with clip latents
   Reed S, 2016, PR MACH LEARN RES, V48
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruthotto L, 2021, INTRO DEEP GENERATIV
   Saharia C, 2022, Photorealistic text-to-image diffusion models with deep language understanding
   Salimans T, 2016, ADV NEUR IN, V29
   Sauer A, 2022, STYLEGAN 40 SCALING
   Sauer A, 2023, STYLEGAN T UNLOCKING
   Shee CF, 2022, INT C PATT RECOG, P1478, DOI 10.1109/ICPR56361.2022.9956028
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taigman Y., 2016, INT C LEARN REPR
   Tao M, 2020, DF GAN SIMPLE EFFECT
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Weng L, 2019, ARXIV
   Wu H, 2017, GP GAN REALISTIC HIG
   Yu J., 2018, ARXIV
   Yuan YQ, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE, COMPUTER TECHNOLOGY AND TRANSPORTATION (ISCTT 2020), P392, DOI 10.1109/ISCTT51595.2020.00074
   Zhang B, 2021, STYLESWIN TRANSFORME
   Zhao J, 2016, ARXIV
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zhu J, 2020, IN DOMAIN GAN INVERS
   Zhu JY, 2017, IEEE GLOB COMM CONF
   Zhu Z, 2019, IEEE SIG PROC MED, DOI 10.1109/spmb47826.2019.9037835
NR 78
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21551
EP 21581
DI 10.1007/s11042-023-16175-2
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035725700009
DA 2024-07-18
ER

PT J
AU Yang, P
   Jiang, SM
   Yi, M
   Li, B
   Sun, YK
   Ma, RC
AF Yang, Peng
   Jiang, Siming
   Yi, Meng
   Li, Bing
   Sun, Yuankang
   Ma, Ruochen
TI An optimized environment-adaptive computation offloading strategy for
   real-time cross-camera task in edge computing networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep reinforcement learning; Markov decision process; Edge computing;
   Offloading strategy; Real-time video analytics
ID RESOURCE-ALLOCATION; DELAY
AB With the large-scale establishment of cross-camera networks, edge computing plays an important role in real-time tasks with its abundant edge resources and flexible task offloading strategy. Conventional studies usually utilize cross-camera network topology and real-time task status to generate subtask offloading strategies. However, most existed approaches focus on utilizing static environment information to generate a fixed offloading strategy for single-target optimization, while dynamic environment information and joint optimization objectives are often ignored. In this paper, we model the computing process of cross-camera tasks as a Markov Decision Process (MDP) integrating spatiotemporal correlation, to make full use of the dynamic environment information in the edge computing network. In addition, to achieve multi-objective optimization of cross-camera tasks, this paper develops a joint Q learning equation that integrates multiple utility indicators and proposes a Deep Spatio-Temporal Q Learning (Deep-STQL) algorithm to solve the equation. Based on the camera frame rate and cross-camera task frame rate, a large number of experimental data show that our proposed Deep-STQL algorithm has significantly improved the convergence, hit rate, average processing delay, drop rate of subtask and computing load of real-time cross-camera tasks compared with the baselines.
C1 [Yang, Peng; Yi, Meng; Li, Bing; Sun, Yuankang] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Yang, Peng; Jiang, Siming; Yi, Meng; Li, Bing; Sun, Yuankang; Ma, Ruochen] Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Nanjing, Peoples R China.
   [Jiang, Siming] Southeast Univ, Sch Software Engn, Nanjing, Peoples R China.
   [Ma, Ruochen] Southeast Univ, Sch Cyber Sci & Engn, Nanjing, Peoples R China.
C3 Southeast University - China; Southeast University - China; Southeast
   University - China; Southeast University - China
RP Yang, P (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.; Yang, P (corresponding author), Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Nanjing, Peoples R China.
EM pengyang@seu.edu.cn; jiangsiming@seu.edu.cn; yimeng@seu.edu.cn;
   libing@seu.edu.cn; syk@seu.edu.cn; seu_mrc@seu.edu.cn
RI Sun, Yuankang/JJC-3966-2023
OI Li, Bing/0000-0002-1251-4346
FU National Natural Science Foundation of China [62272100]; Consulting
   Project of Chinese Academy of Engineering [2023-XY-09]; Fundamental
   Research Funds for the Central Universities; Academy-Locality
   Cooperation Project of Chinese Academy of Engineering [JS2021ZT05]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62272100, and in part by the Consulting
   Project of Chinese Academy of Engineering under Grant 2023-XY-09, the
   Fundamental Research Funds for the Central Universities and the
   Academy-Locality Cooperation Project of Chinese Academy of Engineering
   under Grant JS2021ZT05.
CR Aghajan H, 2010, P 18 ACM INT C MULT, P1753, DOI [10.1145/1873951.1874354, DOI 10.1145/1873951.1874354]
   Chen C, 2023, IEEE T INTELL TRANSP, V24, P5186, DOI 10.1109/TITS.2023.3241251
   Chen XF, 2019, IEEE INTERNET THINGS, V6, P4005, DOI 10.1109/JIOT.2018.2876279
   Dehury CK, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS (IEEE EDGE 2022), P33, DOI 10.1109/EDGE55608.2022.00017
   Ding Y, 2020, IEEE T IND INFORM, V16, P4800, DOI 10.1109/TII.2019.2951206
   Donta Praveen Kumar, 2023, Journal of Ambient Intelligence and Humanized Computing, P2951, DOI 10.1007/s12652-023-04534-8
   Dustdar S, 2023, IEEE T KNOWL DATA EN, V35, P4092, DOI 10.1109/TKDE.2022.3142856
   Feng WJ, 2019, IEEE ACCESS, V7, P95970, DOI 10.1109/ACCESS.2019.2928377
   Ge WH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3644, DOI 10.1145/3474085.3475382
   Geist Matthieu, 2019, INT C MACH LEARN, P2160
   Grand View Research, 2021, IP CAM MARK SIZ SHAR
   Gross E, 2016, PHYSICA A, V462, P217, DOI 10.1016/j.physa.2016.06.083
   Hazra A, 2023, IEEE INTERNET THINGS, V10, P3944, DOI 10.1109/JIOT.2022.3150070
   Huang L, 2020, IEEE T MOBILE COMPUT, V19, P2581, DOI 10.1109/TMC.2019.2928811
   Jain S, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P9, DOI 10.1145/3301293.3302366
   Jang SY, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P132, DOI 10.1109/SEC.2018.00017
   Lim J, 2018, 2018 28TH INTERNATIONAL TELECOMMUNICATION NETWORKS AND APPLICATIONS CONFERENCE (ITNAC), P181
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Mnih V, 2013, ARXIV
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mogi R, 2018, 2018 SIXTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2018), P75, DOI 10.1109/CANDARW.2018.00023
   Naveen Soumyalatha, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P61, DOI 10.1109/I-SMAC47947.2019.9032541
   Pasandi HB, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL WORKSHOP ON CHALLENGES IN ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR INTERNET OF THINGS (AICHALLENGEIOT '19), P15, DOI 10.1145/3363347.3363360
   Rajpoot V, 2021, DEEP LEARNING EDGE C, P1, DOI [10.1007/978-3-030-60265-9_1, DOI 10.1007/978-3-030-60265-9_1]
   Ran XK, 2018, IEEE INFOCOM SER, P1421, DOI 10.1109/INFOCOM.2018.8485905
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sallow Amira B., 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P272, DOI 10.1109/CSASE48920.2020.9142048
   Styles O, 2022, IEEE T PATTERN ANAL, V44, P8482, DOI 10.1109/TPAMI.2021.3107958
   Styles O, 2020, IEEE COMPUT SOC CONF, P4379, DOI 10.1109/CVPRW50498.2020.00516
   Sundar S, 2018, IEEE INFOCOM SER, P37, DOI 10.1109/INFOCOM.2018.8486305
   Dinh TQ, 2017, IEEE T COMMUN, V65, P3571, DOI 10.1109/TCOMM.2017.2699660
   Tran TX, 2019, IEEE T VEH TECHNOL, V68, P856, DOI 10.1109/TVT.2018.2881191
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Viola R, 2022, MULTIMED TOOLS APPL, V81, P12387, DOI 10.1007/s11042-022-12537-4
   Wang J, 2017, SMARTIOT 2017 PROC W, DOI DOI 10.1145/3132479.3132490
   Wang QY, 2019, SUSTAIN COMPUT-INFOR, V21, P154, DOI 10.1016/j.suscom.2019.01.007
   Wang SY, 2023, IEEE T WIREL COMMUN, V22, P5800, DOI 10.1109/TWC.2023.3237202
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wu R, 2014, IEEE APP IMG PAT
   Wu ZY, 2021, CHINA COMMUN, V18, P26, DOI 10.23919/JCC.2021.11.003
   Yang KP, 2022, IEEE T EMERG TOP COM, V10, P1142, DOI 10.1109/TETC.2021.3073744
   Yang TT, 2020, IEEE INTERNET THINGS, V7, P5954, DOI 10.1109/JIOT.2019.2958662
   Yaying Wang, 2020, 2020 IEEE 20th International Conference on Communication Technology (ICCT), P1540, DOI 10.1109/ICCT50939.2020.9295920
   Yu G, 2021, PREPRINT
   Zhang P, 2019, INT WIREL COMMUN, P255, DOI 10.1109/IWCMC.2019.8766659
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhang Y, 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9859815, DOI 10.1109/ICME52920.2022.9859815]
   Zhang YT, 2021, IEEE INT CONF COMP V, P252, DOI 10.1109/ICCVW54120.2021.00033
NR 48
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17251
EP 17279
DI 10.1007/s11042-023-16102-5
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300001
DA 2024-07-18
ER

PT J
AU Zhang, CF
   Zhang, ZY
   Li, HY
   He, SD
   Feng, ZL
AF Zhang, Chengfang
   Zhang, Ziyou
   Li, Haoyue
   He, Sidi
   Feng, Ziliang
TI Multi-focus image fusion via online convolutional sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multifocus image fusion; Online convolutional sparse coding;
   Time-consuming; GPU; CBPDN
ID PERFORMANCE; INFORMATION; TRANSFORM; FRAMEWORK; ALGORITHM
AB Efficiently and perfectly eliminate out-of-focus pixels is still a persistent challenge for multi-focus image fusion. Previous approaches tend to focus on high quality fusion results while ignoring running cost. Online Convolutional Sparse Coding (OCSC) is an online version of Convolutional Sparse Coding (CSC) that discards expensive time and space costs associated with batch mode of CSC. In this paper, we use parallel version of OCSC to alleviate time-consuming defects of previous methods. Multi-focus gray and color images, are tested to verify superiority of the proposed method by obtaining excellent visual effects and exciting objective evaluations. The operating cost is roughly reduced by 95% over fusion method using online dictionary learning. A comprehensive analysis of subjectivity, objectivity and time show that our method has characteristics of fast fusion and high reconstruction quality.
C1 [Zhang, Chengfang; Zhang, Ziyou; Feng, Ziliang] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, South 1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
   [Zhang, Chengfang] Sichuan Police Coll, Expt & Equipment Ctr, 186 Longtouguan Rd, Luzhou 646000, Sichuan, Peoples R China.
   [Zhang, Chengfang] 186 longtouguan Rd, Luzhou, Sichuan, Peoples R China.
   [Li, Haoyue; He, Sidi; Feng, Ziliang] Sichuan Univ, Coll Comp Sci, South 1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan Police College; Sichuan University
RP Zhang, CF (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, South 1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.; Zhang, CF (corresponding author), Sichuan Police Coll, Expt & Equipment Ctr, 186 Longtouguan Rd, Luzhou 646000, Sichuan, Peoples R China.; Zhang, CF (corresponding author), 186 longtouguan Rd, Luzhou, Sichuan, Peoples R China.
EM chengfangzhang@scpolicec.edu.cn; 3270564@qq.com; 923479734@qq.com;
   974215646@qq.com; fengziliang@scu.edu.cn
RI Li, Haoyue/HLQ-8005-2023
OI Li, Haoyue/0000-0001-5284-9661
FU Sichuan Science and Technology Program [2023NSFSC0495]; Sichuan
   University and Luzhou Municipal People's Government Strategic
   cooperation projects [2020CDLZ-10]; Colleague Project of Intelligent
   Policing Key Laboratory of Sichuan Province [ZNJW2022ZZMS001,
   ZNJW2023ZZQN004]
FX This work was supported by Sichuan Science and Technology Program
   (2023NSFSC0495), Sichuan University and Luzhou Municipal People's
   Government Strategic cooperation projects(2020CDLZ-10) and Colleague
   Project of Intelligent Policing Key Laboratory of Sichuan
   Province(ZNJW2022ZZMS001,ZNJW2023ZZQN004).
CR Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P5375, DOI 10.1016/j.jksuci.2021.05.006
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Chengfang Zhang, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Algorithms and Applications. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 180), P159, DOI 10.1007/978-981-15-3867-4_19
   Chun IY, 2018, IEEE T IMAGE PROCESS, V27, P1697, DOI 10.1109/TIP.2017.2761545
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537
   Elad M, 2007, INVERSE PROBL, V23, P947, DOI 10.1088/0266-5611/23/3/007
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2021, INT J INF TECH DECIS, V20, P399, DOI 10.1142/S0219622020500522
   Gao R, 2017, IEEE SIGNAL PROC LET, V24, P943, DOI 10.1109/LSP.2017.2696055
   Garcia-Cardona C, 2018, IEEE T COMPUT IMAG, V4, P366, DOI 10.1109/TCI.2018.2840334
   Gebremeskel GB, 2022, SOFT COMPUT, V26, P5209, DOI 10.1007/s00500-022-06998-w
   Guo R, 2020, FRONT INFORM TECH EL, V21, P1019, DOI 10.1631/FITEE.1900336
   He KJ, 2019, SOFT COMPUT, V23, P4685, DOI 10.1007/s00500-018-3118-9
   Heide F, 2015, PROC CVPR IEEE, P5135, DOI 10.1109/CVPR.2015.7299149
   Huang J, 2020, NEURAL COMPUT APPL, V32, P15119, DOI 10.1007/s00521-020-04863-1
   Inik Ö, 2022, SOFT COMPUT, V26, P3329, DOI 10.1007/s00500-021-06711-3
   Iqbal CMM, 2020, MULTIMED TOOLS APPL, V79, P12817, DOI 10.1007/s11042-020-08661-8
   Kaur Swapandeep, 2022, SOFT COMPUT, P1
   Kumari NA, 2022, SILICON-NETH, DOI 10.1007/s12633-022-01695-7
   Lakshmi MachirajuJaya, 2022, SOFT COMPUT, P1
   Li H., 2018, ARXIV
   Li HF, 2013, OPTIK, V124, P40, DOI 10.1016/j.ijleo.2011.11.088
   Li H, 2017, LECT NOTES COMPUT SC, V10666, P675, DOI 10.1007/978-3-319-71607-7_59
   Li J, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103171
   Li LL, 2021, MULTIMED TOOLS APPL, V80, P12389, DOI 10.1007/s11042-020-10462-y
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li XS, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108062
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   [刘羽 Liu Yu], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1435
   Liu YD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010118
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Ma XL, 2019, SIGNAL PROCESS-IMAGE, V78, P125, DOI 10.1016/j.image.2019.06.002
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Peng X, 2015, KNOWL-BASED SYST, V90, P14, DOI 10.1016/j.knosys.2015.10.005
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   SESHADRIRAMANA K, 2022, SOFT COMPUT, P1
   Veshki FG, 2020, INT CONF ACOUST SPEE, P8344, DOI [10.1109/ICASSP40776.2020.9054097, 10.1109/icassp40776.2020.9054097]
   Wang J, 2017, INT CONF SOFTW ENG, P406, DOI 10.1109/ICSESS.2017.8342942
   Wang PW, 2008, INT CONF SIGN PROCES, P965, DOI 10.1109/ICOSP.2008.4697288
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Wang YQ, 2018, IEEE T IMAGE PROCESS, V27, P4850, DOI 10.1109/TIP.2018.2842152
   Wang ZB, 2018, NEURAL COMPUT APPL, V29, P1101, DOI [10.1007/s00521-016-2633-9, 10.1007/s00521-017-3262-7]
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Xiao B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P43, DOI 10.1109/ICCV48922.2021.00011
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2014, OPTIK, V125, P4881, DOI 10.1016/j.ijleo.2014.04.036
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang Y, 2020, IEEE SYST J, V14, P852, DOI [10.1007/s13198-019-00887-6, 10.1109/JSYST.2019.2900336]
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   [尹明 Yin Ming], 2016, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V46, P2052
   Yu JQ, 2013, OPTIK, V124, P3103, DOI 10.1016/j.ijleo.2012.09.033
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang CF, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.5.053016
   Zhang CF, 2021, INT J WAVELETS MULTI, V19, DOI 10.1142/S0219691320500617
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 69
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17327
EP 17356
DI 10.1007/s11042-023-15972-z
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300007
DA 2024-07-18
ER

PT J
AU Manikandan, V
   Amirtharajan, R
AF Manikandan, V
   Amirtharajan, Rengarajan
TI Cartesian coordinated adaptive hiding for payload peaking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible Steganography; Pixel Value Differencing; LSB embedding;
   Hamming Distance; Cartesian product
ID IMAGE STEGANOGRAPHY; HISTOGRAM; ALGORITHM
AB Transferring multimedia content without detection has gained traction over time. Employing steganography for hiding secret data, viz. passwords, medical information, and private messages, has become the norm. This work involves hiding confidential information in the images. It aims to increase the payload capacity by adaptively choosing the embedding pixel location, using hamming distance, and increasing the number of bits embedded per pixel using threshold while retaining the image quality. The secret PHI information was embedded into the medical cover image by choosing the pixels, such that the embedding order was random. The randomness in the embedding order was achieved by generating a random sequence using a Combined Logistical Tent map. (CLT map). The random sequence was used as the key to choose all the pixels, but in a random order for embedding. Two different ways can generate the CLT map. One is by generating the Logistical map sequence and Tent map sequence and performing the XOR operation of both sequences. The other way is to generate the CLT map sequence through governing equations. The algorithm is designed to perform embedding for images of various modalities, viz. effectively., Grayscale, RGB and DICOM. The algorithm was tested for over 100 images across databases. The test results were satisfactory. The resultant stego image has an acceptable range of Peak Signal to Noise Ratio (PSNR) values above 40 dB and Structural Similarity Index (SSIM) values above 0.9. The stego images with visually imperceptible secret information are good quality and could effectively mitigate steganalysis.
C1 [Manikandan, V; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Manikandan, V] Kalasalingam Acad Res & Educ, CSE, Krishnankoil 626126, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Kalasalingam Academy of Research & Education
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Veerappan, Manikandan/HNS-8576-2023; Amirtharajan,
   Rengarajan/C-6471-2011
OI Veerappan, Manikandan/0000-0001-8501-5743; Amirtharajan,
   Rengarajan/0000-0003-1574-3045
FU DST FIST [SR/FST/ET-I/2018/221(C)]
FX DST FIST funding (SR/FST/ET-I/2018/221(C))
CR Ahmad MA, 2022, ALEX ENG J, V61, P10577, DOI 10.1016/j.aej.2022.03.056
   Ansari AS, 2020, IEEE ACCESS, V8, P83926, DOI 10.1109/ACCESS.2020.2991130
   Cao ZK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1818-0
   Chatterjee A, 2020, MULTIMED TOOLS APPL, V79, P11747, DOI 10.1007/s11042-019-08472-6
   Chen JJ, 2020, EDUC MANAG ADM LEAD, V48, P82, DOI 10.1177/1741143218781066
   Chervyakov N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041223
   dicomlibrary, DICOM LIB AN SHAR VI
   Duan XT, 2020, IEEE ACCESS, V8, P195253, DOI 10.1109/ACCESS.2020.3033895
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   El-Khamy SE, 2020, IEEE ACCESS, V8, P148935, DOI 10.1109/ACCESS.2020.3015687
   Elhadad A, 2021, ALEX ENG J, V60, P2471, DOI 10.1016/j.aej.2020.12.050
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Hameed MA, 2019, IEEE ACCESS, V7, P185189, DOI 10.1109/ACCESS.2019.2960254
   Hamzaoui R., 2006, FRACTAL IMAGE COMPRE, P168
   Huang LC, 2021, INFORMATICA-LITHUAN, V32, P69, DOI 10.15388/20-INFOR422
   imageprocessingplace, Image Databases
   Jayapandiyan JR, 2020, IEEE ACCESS, V8, P136537, DOI 10.1109/ACCESS.2020.3009234
   Karakus S, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109691
   Kasapbasi MC, 2019, IEEE ACCESS, V7, P148495, DOI 10.1109/ACCESS.2019.2946807
   Kim PH, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720911006
   Lawnik Marcin, 2018, Journal of Physics: Conference Series, V1141, DOI 10.1088/1742-6596/1141/1/012132
   Lin CC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030281
   Nashat D., 2019, J. Egypt. Math. Soc., V27, P1, DOI [10.1186/s42787-019-0061-6, DOI 10.1186/S42787-019-0061-6]
   pcir, DOWNL AV
   Phadikar A, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3030021
   rubomedical, SAMPL DICOM FIL
   Rustad S, 2022, J KING SAUD UNIV-COM, V34, P3559, DOI 10.1016/j.jksuci.2020.12.017
   Su AT, 2020, IEEE SIGNAL PROC LET, V27, P221, DOI 10.1109/LSP.2020.2964485
   Su GD, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5709513
   Verma V, 2020, MULTIMED TOOLS APPL, V79, P7471, DOI 10.1007/s11042-019-08283-9
   Wazirali R, 2019, IEEE ACCESS, V7, P133496, DOI 10.1109/ACCESS.2019.2941440
   Welstead StephenT., 1999, Fractal and wavelet image compression techniques, P155, DOI DOI 10.1117/3.353798
   Zhang WM, 2008, DESIGN CODE CRYPTOGR, V46, P67, DOI 10.1007/S10623-007-9135-9
   Zhang Y, 2019, IEEE ACCESS, V7, P24282, DOI 10.1109/ACCESS.2019.2900286
NR 34
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17135
EP 17162
DI 10.1007/s11042-023-16208-w
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300006
DA 2024-07-18
ER

PT J
AU Zheng, H
   You, CH
   Wang, TY
   Ju, JP
   Li, X
AF Zheng, Hong
   You, Changhui
   Wang, Tianyu
   Ju, Jianping
   Li, Xi
TI Source camera identification based on an adaptive dual-branch fusion
   residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source camera identification; Deep learning; Dual-branch network;
   Bottleneck residual module; Multiscale feature
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Although deep learning algorithms have addressed the issue of identifying the source camera to a certain extent, developing a straightforward and effective network remains a challenging task. At present, most of the excellent network schemes in source camera identification are deep networks, which heavily rely on the strong feature extraction ability of deep networks. Although deepening network layers has achieved certain results, training a deep convolutional neural network model requires a large dataset, sophisticated hardware and lengthy training time, and there is a waste of resources. To solve the problem of redundant structure and resource waste of deep convolutional neural networks, this paper proposes the SE-BRB module, which we call a new network module based on the residual module and SE module. Based on this, an adaptive dual-branch fusion network (ADF-Net) with a simplified structure is designed to identify the source of digital images. Specifically, the bottleneck residual module can achieve direct backward transfer of shallow features to avoid images being over-compressed and is suitable for capturing weak source features in images; Additionally, the introduction of a channel attention mechanism can increase the weight of effective feature channels in the network and improve network performance. Finally, multiscale camera feature fusion is realized through a dual-branch network structure to further improve the network performance. The accuracy of the model proposed in this paper is 99.33% and 98.78% on the Dresden dataset and the self-built complex dataset, respectively, and the classification accuracy is far ahead of the existing source camera identification methods.
C1 [Zheng, Hong; You, Changhui; Wang, Tianyu] Wuhan Univ, Sch Elect Informat, Wuhan 430000, Peoples R China.
   [You, Changhui] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China.
   [Ju, Jianping] Hubei Business Coll, Sch Artificial Intelligence, Wuhan 430079, Peoples R China.
   [Li, Xi] Nanchang Inst Sci & Technol, Coll Artificial Intelligence, Nanchang 330108, Peoples R China.
C3 Wuhan University; Wuhan University
RP You, CH (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430000, Peoples R China.; You, CH (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China.
EM youchanghui@whu.edu.cn
FU Science and Technology Research Project of Jiangxi Provincial Department
   of Education [GJJ202511]; Hubei Provincial Natural Science Foundation of
   China [2022CFB529]
FX AcknowledgementsThis research is supported by the Science and Technology
   Research Project of Jiangxi Provincial Department of Education under
   Grant No. GJJ202511 and Hubei Provincial Natural Science Foundation of
   China (Grant No.2022CFB529).
CR Amerini I, 2016, ELECT IMAG, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-088
   Baroffio L., 2016, ARXIV160301068, V12, P1603
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bayar B, 2017, IEEE IMAGE PROC, P4098, DOI 10.1109/ICIP.2017.8297053
   Bayram S., 2005, IMAGE PROCESSING
   Bernacki J, 2021, MULTIMED TOOLS APPL, V80, P29657, DOI 10.1007/s11042-021-11129-y
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen Y., 2017, 2017 IEEE INT C IMAG
   Choi KS, 2006, IEEE SYS MAN CYBERN, P3176, DOI 10.1109/ICSMC.2006.384605
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Dirik AE., 2007, IEEE WORKSH SIGN PRO, P243
   [董明利 Dong Mingli], 2013, [仪器仪表学报, Chinese Journal of Scientific Instrument], V34, P2653
   Farid H., 2006, Significance, V3, P162, DOI [DOI 10.1111/J.1740-9713.2006.00197.X, 10.1111/j.1740-9713.2006.00197.x]
   Goljan M., 2008, DIGITAL CAMERA IDENT
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Hui Cai-Tao, 2022, 2022 IEEE 10th Asia-Pacific Conference on Antennas and Propagation (APCAP), P1, DOI 10.1109/APCAP56600.2022.10069240
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Liu YX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144701
   Lukás J, 2005, PROC SPIE, V5685, P249, DOI 10.1117/12.587105
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Satouri B, 2016, INT J ADV COMPUT SC, V7, P77
   Sun XH., 2010, NAT AC C INF HID MUL
   Thai TH, 2015, DIGIT SIGNAL PROCESS, V40, P88, DOI 10.1016/j.dsp.2015.01.002
   Tuama A, 2016, IEEE INT WORKS INFOR
   Wang B., 2009, J OPTOELECTRON LASER, V2009, P96
   Wang B, 2018, SIGNAL PROCESS-IMAGE, V68, P162, DOI 10.1016/j.image.2018.08.001
   Wu G., 2012, IMAGE PROCESSING ICI
   Xiao YH, 2022, MULTIMED TOOLS APPL, V81, P20443, DOI 10.1007/s11042-022-12507-w
   Yang PP, 2019, PATTERN RECOGN LETT, V119, P195, DOI 10.1016/j.patrec.2017.10.016
   You CH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156752
   Zhong K., 2020, RES SOURCE CAMERA ID
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
NR 34
TC 3
Z9 3
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18479
EP 18495
DI 10.1007/s11042-023-16290-0
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032628900001
DA 2024-07-18
ER

PT J
AU Reddy, MI
   Rao, PV
   Kumar, TS
   Reddy, KS
AF Reddy, M. Indrasena
   Rao, P. Venkateswara
   Kumar, Talluri Sunil
   Reddy, K. Srinivasa
TI Encryption with access policy and cloud data selection for secure and
   energy-efficient cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud data centers; Data Security; Energy-efficient distribution;
   Enhanced elliptic curve cryptography; Wiener process-based squirrel
   search algorithm; Shuffled MD5 hashing algorithm
AB With the rapid advancements in technology, cloud computing has emerged as a prominent paradigm for efficient data storage and processing. However, ensuring the security and energy efficiency of cloud computing remains a critical challenge. So, this paper proposed a novel framework that combines encryption with access policy enforcement and cloud data selection to enhance the security and energy efficiency of cloud computing systems. The main objective of this framework is to safeguard user data through encryption and ensure its confidentiality while optimizing resource utilization and energy efficiency by employing intelligent data distribution techniques among suitable cloud data centers. First, the user data are encrypted using enhanced ECC, and then, the important features from the tasks and the cloud server are extracted. The dimensionalities of the extracted features are reduced by using ENT-FLDA. Based on the features, the most optimal Data center is selected by using WP-SSO to process the encrypted data. Finally, shuffled MD5 is utilized to maintain data confidentiality; this allows only the authorized user to access the data. Experimental results show that the proposed architecture effectively distributes the data on the cloud with a minimum energy consumption rate and also withstands higher security rates.
C1 [Reddy, M. Indrasena] BVRIT HYDERABAD Coll Engn Women, Dept Comp Sci Engn, Hyderabed, India.
   [Rao, P. Venkateswara; Kumar, Talluri Sunil] VNR VignanaJyothi Inst Engn & Technol, Dept Comp Sci Engn, Hyderabad, India.
   [Reddy, K. Srinivasa] VIT AP Univ, Sch Comp Sci & Engn, Amaravathi, India.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET); VIT-AP University
RP Reddy, MI (corresponding author), BVRIT HYDERABAD Coll Engn Women, Dept Comp Sci Engn, Hyderabed, India.
EM indrasenareddy.m@bvrithyderabad.edu.in; pvenkat2004@gmail.com;
   suniltallurikumar@gmail.com; srinivasareddy.k@vitap.ac.in
RI P, Venkateswara Rao/ABW-3461-2022; Konda, Srinivasa Reddy/AAY-9808-2021;
   Telagamsetti, Sunil Kumar/C-8765-2019; Reddy, Dr M
   Indrasena/AAJ-5116-2021
OI Konda, Srinivasa Reddy/0000-0002-4371-2169; Telagamsetti, Sunil
   Kumar/0000-0003-0934-7230; P, VENKATESWARA RAO/0000-0002-2765-8318
CR Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Aljunid MF, 2020, CAAI T INTELL TECHNO, V5, P268, DOI 10.1049/trit.2020.0031
   Belgacem A, 2022, J KING SAUD UNIV-COM, V34, P2391, DOI 10.1016/j.jksuci.2022.03.016
   Blanton Marina, 2016, Proceedings on Privacy Enhancing Technologies, V2016, P144, DOI 10.1515/popets-2016-0033
   Cao L, 2022, IEEE ACCESS, V10, P98549, DOI 10.1109/ACCESS.2022.3206021
   Casas I, 2018, J COMPUT SCI-NETH, V26, P318, DOI 10.1016/j.jocs.2016.08.007
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Dubey K, 2022, J KING SAUD UNIV-COM, V34, P3948, DOI 10.1016/j.jksuci.2020.11.001
   Farzaneh SM, 2022, J SUPERCOMPUT, V78, P1288, DOI 10.1007/s11227-021-03863-9
   Georgios C, 2021, SIMUL MODEL PRACT TH, V111, DOI 10.1016/j.simpat.2021.102338
   Ghaffar Z, 2020, IEEE ACCESS, V8, P47144, DOI 10.1109/ACCESS.2020.2977264
   Gharehpasha S, 2021, ARTIF INTELL REV, V54, P2221, DOI 10.1007/s10462-020-09903-9
   Ghetas M, 2021, NEURAL COMPUT APPL, V33, P11011, DOI 10.1007/s00521-020-05559-2
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Hamdy M, 2020, CAAI T INTELL TECHNO, V5, P237, DOI 10.1049/trit.2019.0099
   Iwendi C, 2021, SOFTWARE PRACT EXPER, V51, P2558, DOI 10.1002/spe.2797
   Jararweh Y, 2020, J PARALLEL DISTR COM, V145, P42, DOI 10.1016/j.jpdc.2020.06.014
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Karmakar K, 2022, J SUPERCOMPUT, V78, P3093, DOI 10.1007/s11227-021-03978-z
   Khan AA, 2021, J NETW COMPUT APPL, V173, DOI 10.1016/j.jnca.2020.102869
   Kumar A, 2021, COMPUT COMMUN, V176, P207, DOI 10.1016/j.comcom.2021.06.003
   Mohassel Payman, 2016, Proceedings on Privacy Enhancing Technologies, V2016, P82, DOI 10.1515/popets-2016-0006
   Mukherjee D, 2022, CMC-COMPUT MATER CON, V72, P125, DOI 10.32604/cmc.2022.023611
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra Suyel, 2019, ADV DNA COMPUTING CR
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Raman N, 2021, J SUPERCOMPUT, V77, P9454, DOI 10.1007/s11227-021-03648-0
   Razaque A, 2022, FUTURE GENER COMP SY, V127, P1, DOI 10.1016/j.future.2021.08.024
   Salami HO, 2021, J SUPERCOMPUT, V77, P13330, DOI 10.1007/s11227-021-03807-3
   Saraswathy KS, 2023, MEASUREMENT SENSORS, V27, P1, DOI [10.1016/j.measen.2023.100693, DOI 10.1016/J.MEASEN.2023.100693]
   Sayadnavard MHH, 2022, ENG SCI TECHNOL, V26, DOI 10.1016/j.jestch.2021.04.014
   Singh J, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141912951
   Srivastava DK, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5324202
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Vasko F.J., 2022, Journal of Computational and Cognitive Engineering, V1, P13, DOI DOI 10.47852/BONVIEWJCCE208918205514
   Wu HM, 2021, IEEE INTERNET THINGS, V8, P2163, DOI 10.1109/JIOT.2020.3033521
   Wu YL, 2021, IEEE T DEPEND SECURE, V18, P2820, DOI 10.1109/TDSC.2020.2966632
   Xu J, 2020, IEEE INT CONF AUTOM, P1283, DOI 10.1145/3324884.3415294
   Yadav AK, 2021, BIG DATA RES, V24, DOI 10.1016/j.bdr.2021.100187
   Yuan GJ, 2020, CAAI T INTELL TECHNO, V5, P247, DOI 10.1049/trit.2020.0079
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15649
EP 15675
DI 10.1007/s11042-023-16082-6
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031478800002
DA 2024-07-18
ER

PT J
AU Marougkas, A
   Troussas, C
   Krouska, A
   Sgouropoulou, C
AF Marougkas, Andreas
   Troussas, Christos
   Krouska, Akrivi
   Sgouropoulou, Cleo
TI How personalized and effective is immersive virtual reality in
   education? A systematic literature review for the last decade
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Virtual reality; Personalization; Systematic review; Gamification;
   Education
ID MOBILE; GAME; MODEL
AB During the last decade, there has been a substantial increase of interest in studies related to Virtual Reality (VR) as a learning tool. This paper presents a systematic literature review of personalization strategies utilized in immersive VR for educational objectives in the classroom. For the purposes of this review, 69 studies between 2012 and 2022 were analyzed in terms of their benefits, limitations and development features. The novelty of the study mainly arises from the in-depth analysis and reporting of personalization strategies as well as gamification techniques used in VR applications. The significance of this research lies in the observation that earlier studies' applications did not sufficiently incorporate adaptive learning content, indicating the necessity for more research in this field and revealing a research gap. In conclusion, as it encourages future research of this field, this study may be a beneficial reference for those interested in researching the implementation of Virtual Reality in education, including academics, students, and professionals.
C1 [Marougkas, Andreas; Troussas, Christos; Krouska, Akrivi; Sgouropoulou, Cleo] Univ West Attica, Dept Informat & Comp Engn, Egaleo, Greece.
C3 University of West Attica
RP Marougkas, A (corresponding author), Univ West Attica, Dept Informat & Comp Engn, Egaleo, Greece.
EM amarougkas@uniwa.gr
RI Marougkas, Andreas/JTV-6597-2023
OI Marougkas, Andreas/0000-0002-0996-8849
CR Abuhammad A, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030010
   Adnan AHM., 2020, Advances in Science Technology and Engineering Systems Journal, V5, P373, DOI [10.25046/aj050148, DOI 10.25046/AJ050148]
   Akman E, 2019, INT J EMERG TECHNOL, V14, P121, DOI 10.3991/ijet.v14i15.10576
   Al Kork S., 2018, ADV SCI TECHNOL ENG, V3, P72, DOI [10.25046/aj030409, DOI 10.25046/AJ030409]
   Amin A., 2016, VAMR 2016, DOI [10.1007/978-3-319-39907-2_25, DOI 10.1007/978-3-319-39907-2_25]
   Anamisa D. R., 2020, Journal of Physics: Conference Series, V1569, DOI 10.1088/1742-6596/1569/2/022071
   Asish SM, 2022, COMPUT GRAPH-UK, V109, P75, DOI 10.1016/j.cag.2022.10.007
   Bakar Ika Setiawati A., 2019, Journal of Physics: Conference Series, V1397, DOI 10.1088/1742-6596/1397/1/012040
   Barrett TJ, 2016, COMPUT HUM BEHAV, V65, P220, DOI 10.1016/j.chb.2016.06.026
   Bazargani JS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132313066
   Bennie SJ, 2019, J CHEM EDUC, V96, P2488, DOI 10.1021/acs.jchemed.9b00181
   Bisht B, 2019, ANAT CELL BIOL, V52, P226, DOI 10.5115/acb.18.213
   Boetje J, 2021, J COMPUT ASSIST LEAR, V37, P253, DOI 10.1111/jcal.12484
   Bolkas D, 2020, ISPRS ANN PHOTOGRAMM, P9, DOI [10.5194/isprs-annals-V-5-2020-9-2020, DOI 10.5194/ISPRS-ANNALS-V-5-2020-9-2020]
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brown JR, 2019, FYEE C
   Calvert J, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104005
   Chang CC, 2012, AUSTRALAS J EDUC TEC, V28, P809
   Chang SC, 2020, INTERACT LEARN ENVIR, V28, P915, DOI 10.1080/10494820.2018.1548490
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen CM, 2005, COMPUT EDUC, V44, P237, DOI 10.1016/j.compedu.2004.01.006
   Chen PH, 2020, EDUC SCI, V10, DOI 10.3390/educsci10070172
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   de Back TT, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00228-9
   de Vasconcelos GN, 2019, ECAADE SIGRADI 2019: ARCHITECTURE IN THE AGE OF THE 4TH INDUSTRIAL REVOLUTION, VOLUME 3, P133
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Dorneich MC, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00144
   Gao Y, 2022, VIRTUAL REAL-LONDON, V26, P415, DOI 10.1007/s10055-021-00577-4
   Garcia-Bonete MJ, 2019, BIOCHEM MOL BIOL EDU, V47, P16, DOI 10.1002/bmb.21188
   Gilbert, 2019, INNOV AGING, V3, pS239, DOI [10.1093/geroni/igz038.893, DOI 10.1093/GERONI/IGZ038.893]
   Gong XL, 2015, IEICE T INF SYST, VE98D, P2242, DOI 10.1587/transinf.2015EDP7165
   Guzsvinecz T, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031312
   Hadjipanayi C, 2022, VIRTUAL REAL-LONDON, V26, P343, DOI 10.1007/s10055-021-00568-5
   Häfner P, 2013, PROCEDIA COMPUT SCI, V25, P251, DOI 10.1016/j.procs.2013.11.031
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Haowen J., 2021, VIRT REAL MED STUD E, V11, DOI [10.1136/bmjopen-2020-046986, DOI 10.1136/BMJOPEN-2020-046986]
   Hoover M, 2021, IEEE ACCESS, V9, P138160, DOI 10.1109/ACCESS.2021.3118105
   Huang WH, 2010, COMPUT EDUC, V55, P789, DOI 10.1016/j.compedu.2010.03.011
   Huang Y, 2021, EDARXIV, DOI [10.35542/osf.io/ye6uw, DOI 10.35542/OSF.IO/YE6UW]
   Ikhsan Jaslin, 2020, International Journal of Interactive Mobile Technologies, V14, P183
   Becerra DAI, 2017, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P395, DOI 10.5220/0006328003950401
   Jerald, 2018, VR BOOK HUMAN CENTER, DOI [10.1145/3170427, DOI 10.1145/3170427]
   Jochecová K, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11030180
   Johnson-Glenberg MC, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P24, DOI [10.23919/ilrn47897.2020.9155155, 10.23919/iLRN47897.2020.9155155]
   Johnston APR, 2018, TRAFFIC, V19, P105, DOI 10.1111/tra.12538
   Kaminska D, 2017, OPEN PHYS, V15, P936, DOI 10.1515/phys-2017-0114
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim K, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P143, DOI 10.1109/VR.2012.6180922
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Krajcovic M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13147916
   Krouska Akrivi, 2020, Brain Function Assessment in Learning. Second International Conference, BFAL 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12462), P102, DOI 10.1007/978-3-030-60735-7_11
   Krouska A, 2021, COMPUTERS, V10, DOI 10.3390/computers10110140
   Lanier J., 2017, DAWN NEW EVERYTHING, V1st
   Li YF, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142215359
   Liu Y, 2021, 2021 ANN S COMP HUM, P326, DOI [DOI 10.1145/3450337.3483507, DOI 10.48550/ARXIV.2109.14185, 10.48550/arXiv.2109.14185]
   Loureiro SandraMaria Correia., 2020, Spanish Journal of Marketing - ESIC, DOI [DOI 10.1108/SJME-01-2020-0013, 10.1108/sjme-01-2020-0013]
   Dorado JL, 2017, IEEE SYMP 3D USER, P221, DOI 10.1109/3DUI.2017.7893351
   Luo H, 2021, J COMPUT ASSIST LEAR, V37, P887, DOI 10.1111/jcal.12538
   Madden J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229788
   Maher Y, 2020, IEEE ACCESS, V8, P197597, DOI 10.1109/ACCESS.2020.3034284
   Makransky G, 2022, EDUC PSYCHOL REV, V34, P1771, DOI 10.1007/s10648-022-09675-4
   Manzano-León A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042247
   Mao RDQ, 2021, J SURG RES, V268, P40, DOI 10.1016/j.jss.2021.06.045
   Maresky HS, 2019, CLIN ANAT, V32, P238, DOI 10.1002/ca.23292
   Mariscal G, 2020, EDUC KNOWL SOC, V21, DOI 10.14201/eks.20809
   Marougkas A, 2021, NOVELTIES INTELLIGEN, V338, P95, DOI [10.3233/FAIA210080, DOI 10.3233/FAIA210080]
   Martin N, 2020, INT SYM MIX AUGMENT, P387, DOI 10.1109/ISMAR50242.2020.00065
   Mayor J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199015
   McKimm J, 2009, BRIT J HOSP MED, V70, P348, DOI 10.12968/hmed.2009.70.6.348
   Meacham S, 2020, IEEE ACCESS, V8, P184621, DOI 10.1109/ACCESS.2020.3029888
   Megat Z., 2020, INT J ADV TRENDS COM, V9, P1280, DOI [10.30534/ijatcse/2020/58922020, DOI 10.30534/IJATCSE/2020/58922020]
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Miller J., 2017, Electronic Imaging, V2017, P30, DOI [DOI 10.2352/ISSN.2470-1173.2017.16.CVAS-346, 10.2352/]
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Monita FA, 2020, J PHYS CONF SER, V1440, DOI 10.1088/1742-6596/1440/1/012103
   Montusiewicz J, 2022, ADV SCI TECHNOL-RES, V16, P211, DOI 10.12913/22998624/152822
   Nesenbergs K, 2021, EDUC SCI, V11, DOI 10.3390/educsci11010008
   Nilsson N, 2016, HUM TECHNOL, V12, DOI [10.1016/j.chb.2017.09.012, DOI 10.1016/J.CHB.2017.09.012]
   Ou KL, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13115911
   Oyelere SS, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-020-00142-7
   Page MJ, 2021, INT J SURG, V88, DOI [10.1016/j.ijsu.2021.105906, 10.1016/j.jclinepi.2021.02.003, 10.1186/s13643-021-01626-4]
   Pande P, 2021, RES LEARN TECHNOL, V29, DOI 10.25304/rlt.v29.2482
   Papastergiou M, 2009, COMPUT EDUC, V52, P1, DOI 10.1016/j.compedu.2008.06.004
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   PINTRICH PR, 1993, EDUC PSYCHOL MEAS, V53, P801, DOI 10.1177/0013164493053003024
   Pirker J, 2017, INT J ONLINE ENG, V13, P106, DOI 10.3991/ijoe.v13i08.7371
   Porter CD, 2020, PHYS REV PHYS EDUC R, V16, DOI 10.1103/PhysRevPhysEducRes.16.020119
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ramansyah Wanda, 2021, Journal of Physics: Conference Series, V1842, DOI 10.1088/1742-6596/1842/1/012012
   Ramansyah Wanda, 2020, Journal of Physics: Conference Series, V1511, DOI 10.1088/1742-6596/1511/1/012026
   Remolar I, 2021, COMPUTERS, V10, DOI 10.3390/computers10110146
   Rengganis YA, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012154
   Rychkova A, 2020, J CHEM EDUC, V97, P4184, DOI 10.1021/acs.jchemed.0c00866
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Sanchez-Sepulveda MV, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235161
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Sedlák M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0276267
   Seybold C, 2021, P INT C ENG DES ICED, DOI [10.1017/pds.2021.1, DOI 10.1017/PDS.2021.1]
   Shin DH, 2017, TELEMAT INFORM, V34, P1826, DOI 10.1016/j.tele.2017.05.013
   Sims R, 2022, P 2022 8 INT C IMM L
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Smit ES, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18031088
   Soto Juan, 2020, International Journal of Interactive Mobile Technologies, P4, DOI 10.3991/ijim.v14i07.12181
   Sottilare R, 2018, CEUR WORKSHOP PROC, V2121, P49
   Southgate Erica, 2019, International Journal of Child-Computer Interaction, V19, P19, DOI 10.1016/j.ijcci.2018.10.002
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   Stratos A, 2016, PROC CIRP, V57, P134, DOI 10.1016/j.procir.2016.11.024
   Surer E, 2021, J MULTIMODAL USER IN, V15, P393, DOI 10.1007/s12193-020-00348-6
   Tarng W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030580
   Triviño-Tarradas P, 2022, VIRTUAL REAL-LONDON, V26, P963, DOI 10.1007/s10055-021-00606-2
   Troussas C, 2022, COMPUTERS, V11, DOI 10.3390/computers11020018
   Troussas C, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103698
   Valentine A, 2021, AUSTRALAS J EDUC TEC, V37, P119, DOI 10.14742/ajet.5487
   Varela-Aldás J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226552
   Wang H, 2012, DIGRA C
   Wang ZQ, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132413977
   Wee C, 2022, IEEE ACCESS, V10, P100054, DOI 10.1109/ACCESS.2022.3204392
   Weller M., 2007, Virtual Learning Environments: Using, choosing and developing your VLE, DOI DOI 10.4324/9780203964347
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wizaka Wiyantara, 2020, IOP Conference Series: Earth and Environmental Science, V426, DOI 10.1088/1755-1315/426/1/012080
   Xu XH, 2016, AM J DISTANCE EDUC, V30, P27, DOI 10.1080/08923647.2016.1119621
   Zhang K, 2017, FED CONF COMPUT SCI, P1297, DOI 10.15439/2017F376
   Zhao R, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3341831
NR 126
TC 4
Z9 4
U1 16
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18185
EP 18233
DI 10.1007/s11042-023-15986-7
EA JUL 2023
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100010
OA hybrid
DA 2024-07-18
ER

PT J
AU Hu, YC
   Shuai, Z
   Yang, HC
   Wan, GY
   Zhang, YJ
   Xie, C
   Lu, MQ
   Lu, XB
AF Hu, Yaocong
   Shuai, Zhen
   Yang, Huicheng
   Wan, Guoyang
   Zhang, Yajun
   Xie, Chao
   Lu, Mingqi
   Lu, Xiaobo
TI ESDAR-net: towards high-accuracy and real-time driver action recognition
   for embedded systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driver action; Lightweight; High-accuracy; Real-time
ID DRIVING POSTURES; TRANSFORM; IMAGE
AB Existing driver action recognition approaches suffer from a bottleneck problem which is the trade-off between recognition accuracy and computational efficiency. More specifically, the high-capacity spatial-temporal deep learning model is unable to realize real-time driver action recognition on vehicle-mounted device. To overcome such limitation, this paper puts forward a novel driver action recognition solution suitable for embedded systems. The proposed ESDAR-Net is a multi-branch deep learning framework and directly processes compressed videos. To reduce the computational cost, a lightweight 2D/3D convolutional network is employed for spatial-temporal modeling. Moreover, two strategies are implemented to boost the accuracy performance: (1) cross-layer connection module (CLCM) and spatial-temporal trilinear pooling module (STTPM) are designed to adaptively fuse appearance and motion information; (2) complementary knowledge from the high-capacity spatial-temporal deep learning model is distilled and transferred to the proposed ESDAR-Net. Experimental results show that the proposed ESDAR-Net satisfies both high-accuracy and real-time for driver action recognition. The accuracy on SEU-DAR-V1, SEU-DAR-V2 reaches 98.7%, 96.5%, with learnable parameters of 2.19M, FLOPs of 0.253G, and speed of 27 clips/s on JETSON TX2.
C1 [Hu, Yaocong; Shuai, Zhen; Yang, Huicheng; Wan, Guoyang] Anhui Polytech Univ, Sch Elect Engn, Wuhu 241000, Peoples R China.
   [Hu, Yaocong; Shuai, Zhen; Yang, Huicheng; Wan, Guoyang] Anhui Polytech Univ, Key Lab Adv Percept & Intelligent Control High End, Minist Educ, Wuhu 241000, Peoples R China.
   [Hu, Yaocong; Shuai, Zhen; Yang, Huicheng; Wan, Guoyang] AnHui Polytech Univ, AnHui Key Lab Detect Technol & Energy Saving Devic, Wuhu 241000, Peoples R China.
   [Zhang, Yajun; Xie, Chao] Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Peoples R China.
   [Lu, Mingqi; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Lu, Mingqi; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
C3 Anhui Polytechnic University; Anhui Polytechnic University; Anhui
   Polytechnic University; Nanjing Forestry University; Southeast
   University - China; Southeast University - China
RP Yang, HC (corresponding author), Anhui Polytech Univ, Sch Elect Engn, Wuhu 241000, Peoples R China.; Yang, HC (corresponding author), Anhui Polytech Univ, Key Lab Adv Percept & Intelligent Control High End, Minist Educ, Wuhu 241000, Peoples R China.; Yang, HC (corresponding author), AnHui Polytech Univ, AnHui Key Lab Detect Technol & Energy Saving Devic, Wuhu 241000, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
EM hcyang@ahpu.edu.cn; xblu@seu.edu.cn
FU National Natural Science Foundation of China [62203012, 61871123,
   61901221]; Open Research Fund of AnHui Key Laboratory of Detection
   Technology and Energy Saving Devices [JCKJ2022A07]; Anhui Polytechnic
   University of Technology Introduced Talent Research Startup Fund
   [2022YQQ009]; Youth Foundation of Anhui Polytechnic University
   [Xjky2022039]; Anhui Province Higher Education Quality Engineering
   Project [2022jyxm139, 2022kcsz027]; Anhui University Collaborative
   Innovation Project [GXXT-2020-0069]; Anhui Natural Science Foundation
   [2108085MF220]
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments and constructive suggestions. This work was
   supported in part by the National Natural Science Foundation of China
   (No. 62203012, No. 61871123 and No. 61901221), the Open Research Fund of
   AnHui Key Laboratory of Detection Technology and Energy Saving Devices
   (No. JCKJ2022A07), Anhui Polytechnic University of Technology Introduced
   Talent Research Startup Fund (No. 2022YQQ009) , the Youth Foundation of
   Anhui Polytechnic University (No. Xjky2022039), Anhui Province Higher
   Education Quality Engineering Project (No. 2022jyxm139 and No.
   2022kcsz027), Anhui University Collaborative Innovation Project (No.
   GXXT-2020-0069) and Anhui Natural Science Foundation Project
   (2108085MF220).
CR Abouelnaga Y., 2017, ARXIV
   Ahmed M, 2022, IEEE T INTELL TRANSP, V23, P19743, DOI 10.1109/TITS.2021.3134222
   Ahmed ST, 2023, IEEE INTERNET THINGS
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Basha SM, 2021, 2021 INTERNATIONAL CONFERENCE ON INNOVATIVE TECHNOLOGY CONVERGENCE (CITC 2021), P46, DOI 10.1109/CITC54365.2021.00016
   Boujemaa KS, 2022, IEEE T INTELL TRANSP, V23, P5211, DOI 10.1109/TITS.2021.3052771
   Cao MW, 2021, IEEE T INTELL TRANSP, V22, P3577, DOI 10.1109/TITS.2020.2995768
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen GB, 2017, ADV NEUR IN, V30
   Chen JW, 2022, IEEE WINT CONF APPL, P786, DOI 10.1109/WACV51458.2022.00086
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen L, 2020, IEEE T IND ELECTRON, V67, P10600, DOI [10.1109/TIE.2019.2962413, 10.1109/TITS.2020.3004655]
   Chihang Zhao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P926, DOI 10.1109/ICIG.2011.184
   Dean J., 2015, NIPS DEEP LEARNING R
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feng YC, 2021, IEEE T IMAGE PROCESS, V30, P5363, DOI 10.1109/TIP.2021.3083113
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu YC, 2021, MULTIMEDIA SYST, V27, P483, DOI 10.1007/s00530-020-00724-y
   Hu YC, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115697
   Hu YC, 2019, MACH VISION APPL, V30, P851, DOI 10.1007/s00138-018-0994-z
   Hu YC, 2018, I C CONT AUTOMAT ROB, P1271, DOI 10.1109/ICARCV.2018.8581201
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Köpüklü O, 2019, IEEE INT CONF COMP V, P1910, DOI 10.1109/ICCVW.2019.00240
   Koesdwiady A, 2017, LECT NOTES COMPUT SC, V10317, P11, DOI 10.1007/978-3-319-59876-5_2
   Korbar B, 2019, IEEE I CONF COMP VIS, P6241, DOI 10.1109/ICCV.2019.00633
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Le THN, 2016, IEEE COMPUT SOC CONF, P46, DOI 10.1109/CVPRW.2016.13
   Liu H, 2023, IEEE T MULTIMEDIA, V25, P1390, DOI 10.1109/TMM.2022.3141888
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu MQ, 2020, APPL INTELL, V50, P1100, DOI 10.1007/s10489-019-01603-4
   Lu MQ, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.004
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Maji S., 2011, Computer Vision and Pattern Recognition (CVPR)
   Masood S, 2020, PATTERN RECOGN LETT, V139, P79, DOI 10.1016/j.patrec.2017.12.023
   Mehta S, 2022, INT C LEARNING REPRE
   Moslemi Negar, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P145, DOI 10.1109/PRIA.2019.8786012
   National Bureau of Statistics, 2021, TRAFF ACC REP
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shou Z, 2019, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2019.00136
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tomar S., 2006, LINUX J, V2006, P10
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Yan C, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P680, DOI 10.1109/ICNC.2015.7378072
   Yan C, 2014, ADV MATER RES-SWITZ, V846-847, P1102, DOI 10.4028/www.scientific.net/AMR.846-847.1102
   Yang J, 2023, INT J ENVIRON AN CH, V103, P2168, DOI 10.1080/03067319.2021.1890057
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang CY, 2020, IEEE ACCESS, V8, P191138, DOI 10.1109/ACCESS.2020.3032344
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao CH, 2012, IET INTELL TRANSP SY, V6, P161, DOI 10.1049/iet-its.2011.0116
   Zhao CH, 2012, ENG APPL ARTIF INTEL, V25, P1677, DOI 10.1016/j.engappai.2012.09.018
   Zhao CHH, 2013, NEURAL COMPUT APPL, V22, pS175, DOI 10.1007/s00521-012-1057-4
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 74
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18281
EP 18307
DI 10.1007/s11042-023-15777-0
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200016
DA 2024-07-18
ER

PT J
AU Wang, J
   Liu, JD
   Xu, HQ
AF Wang, Jin
   Liu, Jiandong
   Xu, Haoqiang
TI H.264/AVC video encryption algorithm based on integer dynamic
   cross-coupling tent mapping model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Video Encryption; Dynamic Tent Mapping; Cross Coupled Map
   Lattices
ID IMAGE ENCRYPTION; SELECTIVE ENCRYPTION; SECURITY; SCHEME; CHAOS; CABAC
AB With rapid Internet development and multimedia technologies, video applications are gradually becoming essential to people's lives. However, the data security problems that follow are becoming increasingly prominent. For the problem of excessive video encoding time after encryption of a high-dimensional chaos encryption algorithm, this paper uses chaotic pseudo-random sequences generated by the integer dynamic cross-coupling tent mapping model as the keystream. It then selectively encrypts them with some key syntax elements in video encoding. Several experimental tests were conducted to analyze the proposed algorithm's effectiveness and security, including information entropy, key space analysis, edge detection analysis, and alternative attack analysis. The experimental results show that the entropy value of the test frames is greater than 7.99, and the key space of the proposed algorithm is 2(992). In addition, the encryption algorithm has a low computational cost and the overall encoding time and encryption time consumption of the test video increase by 1.171% on average. The bit stream length increases to 0 after video encryption, which does not affect the video compression ratio. Moreover, the algorithm can resist edge detection attacks and substitution attacks. The algorithm has high timeliness and resistance to attack in terms of real-time and reliability of video encryption transmission.
C1 [Wang, Jin; Liu, Jiandong; Xu, Haoqiang] Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
C3 Beijing Institute of Petrochemical Technology
RP Wang, J (corresponding author), Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
EM zhifeiyu37@gmail.com
CR Bernatin T, 2016, ONL INT C GREEN ENG, P1, DOI [10.1109/GET.2016.7916722, DOI 10.1109/GET.2016.7916722]
   Carral M., 1988, INFORM THEORY DECODI
   Chadha A., 2015, INT J COMPUT APPL, V116, P33, DOI [10.1007/978-81-322-1157-0_6, DOI 10.1007/978-81-322-1157-0_6]
   Chen Z, 2013, IEEE INT C SIGNAL PR, P1, DOI [10.1109/ICSPCC.2013.6663915, DOI 10.1109/ICSPCC.2013.6663915]
   Cheng SL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030332
   [底晓强 Di Xiaoqiang], 2018, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V48, P919
   El-Mowafy MA, 2022, IEEE ACCESS, V10, P124002, DOI 10.1109/ACCESS.2022.3223355
   El-Shafai W, 2022, J INF SECUR APPL, V64, DOI 10.1016/j.jisa.2021.103039
   Farhangkhah N, 2021, WIREL NETW, DOI 10.1007/s11276-021-02821-w
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Hafsa A, 2022, MULTIMED TOOLS APPL, V81, P2275, DOI 10.1007/s11042-021-11668-4
   Hasan MK, 2021, IEEE ACCESS, V9, P47731, DOI 10.1109/ACCESS.2021.3061710
   Hong SS, 2014, MULTIMED TOOLS APPL, V71, P1577, DOI 10.1007/s11042-012-1287-6
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Hou JB, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103535
   Liu JD, 2021, MULTIMED TOOLS APPL, V80, P19219, DOI 10.1007/s11042-021-10668-8
   Khosravi MR, 2021, WIREL NETW, DOI 10.1007/s11276-021-02626-x
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P12837, DOI 10.1007/s11042-017-4916-2
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Liu B, 2020, J ADV COMPUT INTELL, V24, P335, DOI 10.20965/jaciii.2020.p0335
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   [刘建东 Liu Jiandong], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P563
   Ma T., 2017, INT J-TORONTO, V97, P1, DOI [10.1007/s11277-017-4771-5, DOI 10.1007/S11277-017-4771-5]
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Naskar PK, 2015, INT J ELECTRON SECUR, V7, P358
   Notebaert S., 2006, REQUANTIZATION TRANS, P808, DOI [10.1007/11922162_92, DOI 10.1007/11922162_92]
   Ou TS, 2011, IEEE T CIRC SYST VID, V21, P682, DOI 10.1109/TCSVT.2011.2129890
   Peng F, 2017, MULTIMED TOOLS APPL, V76, P3235, DOI 10.1007/s11042-016-3710-x
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Rashmi P, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/9363377
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Singh KN, 2022, SUSTAIN ENERGY TECHN, V53, DOI 10.1016/j.seta.2022.102566
   Song W, 2022, NEURAL COMPUT APPL, V34, P5743, DOI 10.1007/s00521-021-06725-w
   Su PC, 2011, MULTIMED TOOLS APPL, V52, P529, DOI 10.1007/s11042-009-0458-6
   Tabash FK, 2019, J INF SECUR APPL, V45, P20, DOI 10.1016/j.jisa.2019.01.001
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XF, 2010, SIGNAL PROCESS-IMAGE, V25, P427, DOI 10.1016/j.image.2010.03.005
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu H, 2020, MULTIMEDIA SYST, V26, P363, DOI 10.1007/s00530-020-00648-7
   Xu H, 2016, OPTIK, V127, P9305, DOI 10.1016/j.ijleo.2016.07.024
   Zhang J, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P102, DOI 10.1109/IMSCCS.2008.14
   Zhang ZR, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111431
NR 48
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13369
EP 13393
DI 10.1007/s11042-023-15448-0
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800009
DA 2024-07-18
ER

PT J
AU Li, HS
   Lu, YL
AF Li, Hai-Sheng
   Lu, Yan-Ling
TI 3D object detection based on point cloud in automatic driving scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; AI; LiDAR; Point Cloud; 3D object detection
AB In many real-time applications such as autonomous driving and robotics, 3D object detection algorithms represented by PointPillars have great potential to design fast and reliable 3D object detection algorithms by using point cloud columns (Pillars) to represent point clouds. However, this kind of algorithm still has some shortcomings, such as poor detection results for some small objects or distant objects and the existence of wrong detection, missing detection and other problems. In order to solve these problems, we design a three-branch extended convolutional network in the 3D object detection algorithm, which can alleviate the insensitivity of the original network to targets of different sizes, especially small targets. Then, we design an improved hybrid attention mechanism network in 3D object detection algorithm to solve the problem of missing detection and error detection in long-distance vehicle detection. From the experimental verification of KITTI dataset, we draw the following conclusion: Our network has great advantages compared with PointPillars, especially the big improvement in the mAP(mean Average Precision) of vehicle detection and pedestrian and rider detection, in the case that the detection speed is basically equal to PointPillars.
C1 [Li, Hai-Sheng; Lu, Yan-Ling] Guangxi Normal Univ, Coll Elect Engn, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Li, HS (corresponding author), Guangxi Normal Univ, Coll Elect Engn, Guilin 541004, Guangxi, Peoples R China.
EM lhs_ecjtu@126.com
FU Science and Technology Project of Guangxi [2020GXNSFDA238023]; National
   Natural Science Foundation of China [61762012]
FX AcknowledgementsThis work is supported by the Science and Technology
   Project of Guangxi under Grant No. 2020GXNSFDA238023, the National
   Natural Science Foundation of China under Grant no. 61762012.
CR Chen X, 2017, IEEE C COMP VIS PATT, P2980
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen XZ, 2015, ADV NEUR IN, V28
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai JF, 2016, ADV NEUR IN, V29
   Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   González A, 2017, IEEE T CYBERNETICS, V47, P3980, DOI 10.1109/TCYB.2016.2593940
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   He YQ, 2021, NEUROCOMPUTING, V459, P201, DOI 10.1016/j.neucom.2021.06.046
   Jaderberg M, 2015, ADV NEUR IN, V28
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lamas D, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13122332
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Liang Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13326, DOI 10.1109/CVPR42600.2020.01334
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Song SY, 2015, PROC CVPR IEEE, P3734, DOI 10.1109/CVPR.2015.7298997
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang D.Z., 2015, Robotics: Science and Systems, V1
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhang L, 2020, INT ARCH PHOTOGRAMM, V44-4, P167, DOI 10.5194/isprs-archives-XLIV-4-W1-2020-167-2020
   Zheng W, 2021, PROC CVPR IEEE, P14489, DOI 10.1109/CVPR46437.2021.01426
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87
   Zia MZ, 2014, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR.2014.470
NR 39
TC 0
Z9 0
U1 25
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13029
EP 13044
DI 10.1007/s11042-023-15963-0
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001021388000002
DA 2024-07-18
ER

PT J
AU Das Dawn, D
   Khan, A
   Shaikh, SH
   Pal, RK
AF Das Dawn, Debapratim
   Khan, Abhinandan
   Shaikh, Soharab Hossain
   Pal, Rajat Kumar
TI Lexeme connexion measure of cohesive lexical ambiguity revealing factor:
   a robust approach for word sense disambiguation of Bengali text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Word sense disambiguation; WSD of resource scaring languages; WSD of
   Indian languages; Polysemous word; Sense identification
AB Word sense disambiguation (WSD) is the process of finding out the appropriate meaning of a polysemous word based on any given context. The Bengali language inherently comprises a large number of polysemous words. Recently, researchers in the domain of linguistics have been attracted to the problem of WSD in Bengali text due to its numerous interesting applications, viz. machine translation, opinion polarity identification, question-answering systems, etc. In this paper, lexeme connexion measure of cohesive lexical ambiguity revealing factor has been proposed that takes a decision on the disambiguation of senses of a Bengali polysemous word. All the polysemous words have been treated as target words, and a context window of three different sizes, viz. five, seven, and ten are considered based on these target words. This paper has generated lexeme harmony measure for quantifying heuristically of syntactic belongings of a collection of lexemes in Bengali text. The proposed methodology has been extracted a feature vector by considering the cohesive lexical ambiguity revealing factor or CLARF, depending on frame lexeme harmony (FLH), sense lexeme harmony (SLH), polysemy singularity coherence (PSC), polysemy distribution factor (PDF), and relative polysemy singularity coherence (RPSC) factor of a lexeme. This Bengali WSD technique has been applied max-rule of integrated lexeme connexion measure (LCM) of each lexeme of both the testing and training cases score for sense recognition. The proposed algorithm has succeeded in eliminating the drawback of the Bengali WSD approaches, as it can focus on both the lexical and semantic relationships between words. The performance of this algorithm has been evaluated on a dataset that consists of 100 polysemous words of three/four senses. Various evaluation metrics have been used to analyse the results obtained by the proposed algorithm. The obtained results indicate the robustness of the proposed algorithm.
C1 [Das Dawn, Debapratim; Khan, Abhinandan; Pal, Rajat Kumar] Univ Calcutta, Dept Comp Sci & Engn, Acharya Prafulla Chandra Roy Shiksha Prangan, JD-2,Sect 3, Kolkata 700106, India.
   [Khan, Abhinandan] ARP Engn, Prod Dev & Diversificat, 147 Nilgunj Rd, Kolkata 700056, India.
   [Shaikh, Soharab Hossain] BML Munjal Univ, Dept Comp Sci & Engn, Natl Highway 8,67KM Milestone, Gurugram 122413, Haryana, India.
C3 University of Calcutta; BML Munjal University
RP Das Dawn, D (corresponding author), Univ Calcutta, Dept Comp Sci & Engn, Acharya Prafulla Chandra Roy Shiksha Prangan, JD-2,Sect 3, Kolkata 700106, India.
EM debapratimdd@gmail.com; khan.abhinandan@gmail.com; pal.rajatk@gmail.com
RI Hossain Shaikh, Soharab/AAF-6303-2019; PAL, RAJAT KUMAR K/N-5872-2018;
   KHAN, ABHINANDAN/F-9374-2015
OI Hossain Shaikh, Soharab/0000-0003-3409-8467; KHAN,
   ABHINANDAN/0000-0002-0338-8325; Das Dawn, Debapratim/0000-0001-9275-8027
CR Agirre E, 2006, TEXT SPEECH LANG TEC, V33, P1, DOI 10.1007/978-1-4020-4809-8
   Agirre E., 2007, Procs. of the 4th Intl. Workshop on Semantic Evaluations (SemEval-2007), P342
   Anand Kumar M., 2014, INT J APPL ENG RES, V9, P7609
   [Anonymous], 2012, Int. J. Sci. Res. Eng. Technol
   Bala P., 2013, INT J ENG SCI, V2, P36
   Banerjee Somnath, 2014, Text, Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655, P217, DOI 10.1007/978-3-319-10816-2_27
   Biswas M, 2021, INT C MACH LEARN BIG, P22
   Bonami Olivier., 2018, LEXEME DESCRIPTIVE T
   Cohn T, 2003, P AUSTR LANG TECHN W, V2003, P86
   Dang HT, 2002, P 19 INT C COMPUTATI, V1, P1
   Das A, 2013, PROC INT C NATURAL L, V10, P20
   Das A., 2010, INT C COMP PROC OR L, P169
   Das Amitava, 2009, P ICON
   Das D, 2009, P ACL IJCNLP 2009 C, P149
   Das Dawn D, 2022, J AMB INTEL HUM COMP, P1
   Das Dawn D, 2020, ARTIF INTELL REV, V53, P4183, DOI 10.1007/s10462-019-09790-9
   Dey A, 2020, PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P226, DOI 10.1109/ICECE51571.2020.9393107
   Dhungana UR, 2014, INT CONF DIGIT INFO, P46, DOI 10.1109/DICTAP.2014.6821655
   Ekbal A, 2007, P 7 INT S NAT LANG P, P131
   Florian R, 2002, P ACL 02 WORKSH WORD, P67
   Hadni M, 2016, INT ARAB J INF TECHN, V13, P215
   Haque A, 2016, BANGLA WORD SENSE DI
   Hoste V, 2002, P ACL 02 WORKSH WORD, V8, P61
   Islam M, 2021, EMERGING TECHNOLOGIE, P317
   Joachims T., 1997, International conference on machine learning, P143, DOI DOI 10.1016/J.ESWA.2016.09.009
   Korenius T., 2004, P 13 ACM INT C INF K, P625, DOI [DOI 10.1145/1031171.1031285, 10.1145/1031171.1031285]
   LESK Michael, 1986, P 5 ANN INT C SYST D, V5, P24, DOI 10.1145/318723.318728
   Liu HF, 2002, J AM MED INFORM ASSN, V9, P621, DOI 10.1197/jamia.M1101
   Màrquez L, 2006, TEXT SPEECH LANG TEC, V33, P167, DOI 10.1007/1-4020-4809-2_7
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Menai MEB, 2014, INFORMATICA, V38
   Merhbene Laroussi, 2010, Proceedings of the 11th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD 2010), P157, DOI 10.1109/SNPD.2010.32
   Merhbene L, 2013, INT JOINT C NAT LANG, P1027
   Mukaka MM, 2012, MALAWI MED J, V24, P69
   Murata Masaki., 2001, The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems, SENSEVAL '01, P135
   Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Ng HT, 1996, P 34 ANN M ASS COMP, P40, DOI DOI 10.3115/981863.981869
   Pal A. R., 2015, ARXIV
   Pal AR, 2021, INT J SPEECH TECHNOL, V24, P439, DOI 10.1007/s10772-020-09787-8
   Pal AR, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1165-2
   Pal AR, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1149-2
   Pal AR, 2016, ADV INTELL SYST, V435, P423, DOI 10.1007/978-81-322-2757-1_42
   Pal AR, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P342, DOI 10.1109/ReTIS.2015.7232902
   Pal AR., 2017, ADV COMPUTATIONAL SC, V10, P267
   Palanati DP., 2013, INT J ELECT COMMUN C, V4, P176
   Pandit R, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P383, DOI 10.1109/ReTIS.2015.7232909
   Parameswarappa S., 2013, INT J EMERGING TREND, V2, P272
   Parameswarappa S, 2011, INT C COMP COMM SYST, P47
   Pedersen T, 2006, TEXT SPEECH LANG TEC, V33, P133, DOI 10.1007/1-4020-4809-2_6
   Rana P, 2015, ADV INTELLIGENT INFO, P607
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Ritter A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P424
   Roy A., 2014, INT J NATURAL LANGUA, V3, P51, DOI [10.5121/ijnlc.2014.3305, DOI 10.5121/IJNLC.2014.3305]
   Sankar KPS, 2016, PROC TECH, V24, P1507, DOI 10.1016/j.protcy.2016.05.106
   Sarika, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P314, DOI 10.1109/CCAA.2015.7148396
   Sarmah J., 2016, INT J COMPUTER APPL, V141, P42, DOI [10.5120/Ijca2016909488, DOI 10.5120/IJCA2016909488]
   Sengupta S, 2019, J INTELL FUZZY SYST, V36, P4821, DOI 10.3233/JIFS-179030
   Sidorov G, 2001, P TALN, P398
   Singh RL., 2014, ADV COMPUTING, V5, P17, DOI DOI 10.5121/ACIJ.2014.5403
   Singh S, 2013, LECT NOTES COMPUT SC, V8271, P247, DOI 10.1007/978-3-642-44949-9_23
   Sinha M, 2004, INT S MACH TRANSL SU
   Sultana M, 2022, CYBER INTELLIGENCE I, P279
   Tayal D. K., 2015, P 12 INT C NAT LANG, P49
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Yadav P., 2013, INT J EMERGING TECHN, V3, P470
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
   Zouaghi A., 2011, Proceedings of the 2011 International Conference on Artificial Intelligence. ICAI 2011, P561
   Zungre NB, 2016, 2016 WORLD C FUT TRE, P1
NR 69
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12939
EP 12983
DI 10.1007/s11042-023-14676-8
EA JUL 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200005
DA 2024-07-18
ER

PT J
AU Yang, GY
   Wei, WB
   Pan, ZK
AF Yang, Guangyu
   Wei, Weibo
   Pan, Zhenkuan
TI A Variational neural network for image restoration based on coupled
   regularizers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlinear diffusion; Algorithm unfolding networks; Coupling; Proximal
   gradient method; Image restoration
ID MINIMIZATION; DIFFUSION; FRAMEWORK; NORM
AB Variational neural networks based on unrolled optimization algorithms for image restoration have received considerable attentions recently because they inherit the merits of variational methods and deep learning methods in explanation and efficiency. Inspired by coupled regularizers adopted by variational models in vectorial image processing, we propose a novel variational neural network for image restoration making use of algorithm unfolding from isotropic and anisotropic coupled regularizers. The iterative schemes of variational models with coupled regularizers are designed using the proximal gradient descent method, which have exact correspondences with layers of deep neural networks. The diffusion operators are designed as convex combination of DCT(Discrete Cosine Transformation) bases with trainable parameters. The influence functions are designed via combination of Gauss radial basis functions, but they are shared by different channels of the same layer to ensure the simultaneous diffusion of all the channels during training, thanks to the coupled properties of regularizers. Compared with the classic TNRD(Trainable Networks for Reaction-Diffusion) model, the coupled isotropic diffusion terms can reduce training parameters greatly, and the coupled anisotropic diffusion terms have better adaptive properties in texture and edge preserving, which are demonstrated in extensive experiments on image denoising and super-resolution. The proposed variational neural networks via coupled regularizers can be easily extended to other image restoration tasks, such as image deblurring and demosaicking. The similar networks can be designed based on other iterative optimization algorithms, such as HQS and ADMM also.
C1 [Yang, Guangyu; Wei, Weibo; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, 308 Ningxia Rd, Qingdao 266100, Shandong, Peoples R China.
C3 Qingdao University
RP Wei, WB; Pan, ZK (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, 308 Ningxia Rd, Qingdao 266100, Shandong, Peoples R China.
EM lyyangguangyu@126.com; njustwwb@163.com; zkpan@126.com
FU National Natural Science Foundation of China [62172247, 61772294];
   National Statistical Science Research Project [2020LY100]; Natural
   Science Foundation of Shandong Province
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China under Grant (Nos. 62172247, 61772294), the National
   Statistical Science Research Project (No.2020LY100), Natural Science
   Foundation of Shandong Province (No.ZR2019LZH002).
CR AGOSTINELLI F, 2015, 3 INT C LEARN REPR I
   Alexander E., 2020, J MATH IMAGING VIS, V62, P396, DOI DOI 10.1007/S10851-019-00926-8
   Alt T., 2021, SCALE SPACE VARIATIO, P294, DOI DOI 10.1007/978-3-030-75549-2_24
   Alt T, 2022, RES MATH SCI, V9, DOI 10.1007/s40687-022-00339-x
   Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   Aujol JF, 2006, J VIS COMMUN IMAGE R, V17, P916, DOI 10.1016/j.jvcir.2005.02.001
   Beck A, 2009, INT CONF ACOUST SPEE, P693, DOI 10.1109/ICASSP.2009.4959678
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   Brook A, 2003, J MATH IMAGING VIS, V18, P247, DOI 10.1023/A:1022895410391
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Combettes PL, 2020, SET-VALUED VAR ANAL, V28, P491, DOI 10.1007/s11228-019-00526-z
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dang NHT., 2020, SIGNAL PROCESS, V178, P107797
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Feng WS, 2018, IEEE T CYBERNETICS, V48, P1708, DOI 10.1109/TCYB.2017.2713421
   Fu B, 2023, SIGNAL IMAGE VIDEO P, V17, P573, DOI 10.1007/s11760-022-02262-8
   Gavaskar RG, 2021, IEEE T IMAGE PROCESS, V30, P4802, DOI 10.1109/TIP.2021.3075092
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Han J, 2018, P NATL ACAD SCI USA, V115, P8505, DOI 10.1073/pnas.1718942115
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang BX, 2019, IEEE ACCESS, V7, P79825, DOI 10.1109/ACCESS.2019.2923067
   Kongskov RD, 2019, BIT, V59, P903, DOI 10.1007/s10543-019-00755-6
   Lai ZQ, 2022, NEUROCOMPUTING, V481, P281, DOI 10.1016/j.neucom.2022.01.057
   Lei J, 2020, COGN COMPUT, V12, P206, DOI 10.1007/s12559-019-09682-8
   Li M., 2020, PROC 37 INT C MACHIN, P5874, DOI DOI 10.5555/3524938.3525483
   Liu RS, 2019, IEEE T IMAGE PROCESS, V28, P5013, DOI 10.1109/TIP.2019.2913536
   Liu RJ, 2021, MOBILE NETW APPL, V26, P3, DOI 10.1007/s11036-020-01717-x
   Monga V, 2021, IEEE SIGNAL PROC MAG, V38, P18, DOI 10.1109/MSP.2020.3016905
   Hien NN, 2022, IEEE ACCESS, V10, P71584, DOI 10.1109/ACCESS.2022.3188315
   Ono S, 2017, IEEE SIGNAL PROC LET, V24, P1108, DOI 10.1109/LSP.2017.2710233
   Ouala S, 2019, INT CONF ACOUST SPEE, P3622, DOI [10.1109/ICASSP.2019.8683447, 10.13140/rg.2.2.22366.28485]
   Piazza F., 1992, INT JOINT C NEURAL N, V2, P2
   Qiao P, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1847, DOI 10.1145/3123266.3123370
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rousseau F, 2020, J MATH IMAGING VIS, V62, P365, DOI 10.1007/s10851-019-00890-3
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Scherzer O., 2015, Handbook of Mathematical Methods in Imaging
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Thanh DNH, 2020, SIGNAL IMAGE VIDEO P, V14, P1189, DOI 10.1007/s11760-020-01657-9
   Tirer T, 2019, IEEE SIGNAL PROC LET, V26, P1080, DOI 10.1109/LSP.2019.2920250
   Vecci L, 1998, NEURAL NETWORKS, V11, P259, DOI 10.1016/S0893-6080(97)00118-4
   Wang WC, 2022, SIGNAL PROCESS-IMAGE, V106, DOI 10.1016/j.image.2022.116742
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Yang GY, 2023, J MATH IMAGING VIS, V65, P414, DOI 10.1007/s10851-022-01122-x
   Yang Y, 2020, IEEE T PATTERN ANAL, V42, P521, DOI 10.1109/TPAMI.2018.2883941
   Zhai Y, 2021, IEEE ACCESS, V9, P43301, DOI 10.1109/ACCESS.2021.3065662
   Zhang H., 2013, J ENG-NY, V1, P1
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang LN, 2020, J MATH IMAGING VIS, V62, P328, DOI 10.1007/s10851-019-00922-y
   Zhu M, 2019, PROC 7 INT C LEARNIN
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 65
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12379
EP 12401
DI 10.1007/s11042-023-15890-0
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100005
DA 2024-07-18
ER

PT J
AU Barbancho, AM
   Tardón, LJ
   Barbancho, I
AF Barbancho, Ana M.
   Tardon, Lorenzo J.
   Barbancho, Isabel
TI Building music with Lego bricks and Raspberry Pi
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Beatbox; Melody box; Lego; Raspberry Pi; MIDI; Music composition
AB In this paper, a system to build music in an intuitive and accessible way, with Lego bricks, is presented. The system makes use of the new powerful and cheap possibilities that technology offers for making old things in a new way. The Raspberry Pi is used to control the system and run the necessary algorithms, customized Lego bricks are used for building melodies, custom electronic designs, software pieces and 3D printed parts complete the items employed. The system designed is modular, it allows creating melodies with chords and percussion or just melodies or perform as a beatbox or a melody box. The main interaction with the system is made using Lego-type building blocks. Tests have demonstrated its versatility and ease of use, as well as its usefulness in music learning for both children and adults.
C1 [Barbancho, Ana M.; Tardon, Lorenzo J.; Barbancho, Isabel] Univ Malaga, ATIC Res Grp, ETSI Telecomunicac, Campus Teatinos, Malaga 29071, Spain.
C3 Universidad de Malaga
RP Tardón, LJ (corresponding author), Univ Malaga, ATIC Res Grp, ETSI Telecomunicac, Campus Teatinos, Malaga 29071, Spain.
EM abp@uma.es; ltg@uma.es; ibp@uma.es
RI Tardon, Lorenzo J./M-4492-2014
OI Tardon, Lorenzo J./0000-0002-5441-225X
CR Baek Y, 2020, MUSIC EDUC RES, V22, P315, DOI 10.1080/14613808.2020.1767558
   Baratè A, 2017, PROCEDIA COMPUT SCI, V112, P1334, DOI 10.1016/j.procs.2017.08.018
   Bugos JA, 2023, MUSIC SCI, V27, P54, DOI 10.1177/10298649211021463
   Bugos JA, 2017, PSYCHOL MUSIC, V45, P855, DOI 10.1177/0305735617692666
   Cabrera-Tigre P, 2020, P IEEE WORLD C ENG E, P1, DOI [10.1109/EDUNINE48860.2020.9149507, DOI 10.1109/EDUNINE48860.2020.9149507]
   Chih-Fang Huang, 2020, 2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE), P220, DOI 10.1109/ECICE50847.2020.9301934
   Ferreira LDA, THESIS U NOVE LISBOA
   Freescale Semiconductor, 2002, AN991D US SER PER IN
   FYCMA, 2020, TRANSF 2020
   General MIDI Standard, PRINC GEORG COMM COL
   Gold NE, 2022, MULTIDISCIP J EDUC S, V9, P14, DOI 10.4995/muse.2022.16453
   Greenberg DM, 2021, AM PSYCHOL, V76, P1172, DOI 10.1037/amp0000819
   Herrero G, 2015, MULTIMED TOOLS APPL, V74, P10195, DOI 10.1007/s11042-014-2159-z
   Holland Simon., 2013, MUSIC HUMAN COMPUTER, pVIII
   Ilsar A, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3416988
   Jaime J, 2016, MULTIMED TOOLS APPL, V75, P4349, DOI 10.1007/s11042-015-2478-8
   Jakobsen KB, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P46, DOI 10.1145/2930674.2930683
   Johnson-Green E, 2018, VISIONS RES MUSIC ED, V31
   Li HZ, 2020, IEEE ACCESS, V8, P188951, DOI 10.1109/ACCESS.2020.3031155
   Lindsay S, 2017, DISABIL HEALTH J, V10, P173, DOI 10.1016/j.dhjo.2016.10.010
   Ludovico LA, 2017, P 1 ACM SIGCHI INT W, P44
   Microchip Technology Inc, MCP3008 DAT
   MIDI Manufacturers Association, 1996, COMPL MIDI 1 0 DET S
   Mitchell T., 2011, Proceedings of the 11th International Conference on New Interfaces for Musical Expression, P465
   Muller J, 2017, P 19 ACM INT C MULT, P487, DOI DOI 10.1145/3136755.3143018
   Muñoz E, 2016, IEEE T EVOLUT COMPUT, V20, P1, DOI 10.1109/TEVC.2014.2366871
   NXP Semiconductors, 2021, 70 NXP
   Oestermeier U., 2015, PROC 14 INT C INTERA, P283, DOI [10.1145/2771839.2771897, DOI 10.1145/2771839.2771897]
   Perks R, 2023, 21 CENTURY GUITAR
   Philips Semiconductors, 2006, SCC2691 UN AS REC TR
   Raspberry Pi Foundation, RASPB
   Roig C, 2018, KNOWL-BASED SYST, V142, P85, DOI 10.1016/j.knosys.2017.11.027
   Roig C, 2014, KNOWL-BASED SYST, V71, P419, DOI 10.1016/j.knosys.2014.08.018
   Rosa-Pujazón A, 2016, MULTIMED TOOLS APPL, V75, P8137, DOI 10.1007/s11042-015-2729-8
   Shahrbabaki RM, 2023, J PEDIATR NURS, V69, pe7, DOI 10.1016/j.pedn.2022.11.023
   Simpson K, 2011, J AUTISM DEV DISORD, V41, P1507, DOI 10.1007/s10803-010-1172-y
   Stromatolite Sigma-Orionis Ircam-Centre Pompidou Music Technology Group Vienna University of Technology and Fraunhofer IDMT, MUSICBRICKS
   Texas Instruments, SN74LS157 DAT
   Texas Instruments, SN74LS151N DAT
   Torre G, 2016, COMPUT MUSIC J, V40, P22, DOI 10.1162/COMJ_a_00356
   Wiriyachaiporn P, 2018, INT JOINT CONF COMP, P383
NR 41
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10503
EP 10523
DI 10.1007/s11042-023-15902-z
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500004
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Incir, R
   Bozkurt, F
AF Incir, Ramazan
   Bozkurt, Ferhat
TI A study on effective data preprocessing and augmentation method in
   diabetic retinopathy classification using pre-trained deep learning
   approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Diabetic retinopathy; Classification; Data augmentation
AB High glucose levels in the blood not only damage different tissues and organs of the body, but also cause adverse effects on the eye. This condition is called diabetic retinopathy (DR). DR can cause blurred vision, darkening of the field of vision, and severe vision loss. The number of people infected with the disease is increasing in our country and worldwide. The time-consuming physician check-ups and the presence of small lesions indicate the need to develop diagnostic systems. Deep learning-based applications have become the trend for diagnosing and grading diseases from images. This study aims to create a meaningful and sufficient dataset using effective data preprocessing and affine transformation techniques in diabetic retinopathy classification. In this study, classification was performed using seven different pre-trained deep learning architectures. An experimental study of each technique was performed on the EyePACS dataset. An overfitting problem was encountered in the experimental results with the original data set. Thus, data preprocessing and data augmentation processes were carried out in order to eliminate overfitting by considering the imbalance between classes in the dataset. The classification performance obtained from each architecture was observed according to performance metrics of precision, recall, F1 Score, accuracy, and loss. In this study, the best performance was achieved with 97.65% test accuracy with the proposed EfficientNetV2-M network model.
C1 [Incir, Ramazan] Gumushane Univ, Kelkit Aydin Dogan Vocat Sch, Dept Comp Technol, Gumushane, Turkiye.
   [Bozkurt, Ferhat] Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkiye.
C3 Gumushane University; Ataturk University
RP Bozkurt, F (corresponding author), Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkiye.
EM ramazan.incir@gumushane.edu.tr; fbozkurt@atauni.edu.tr
RI Ramazan, incir/KFQ-4164-2024; Bozkurt, Ferhat/GYR-3398-2022
OI Ramazan, incir/0000-0002-7869-9945; Bozkurt, Ferhat/0000-0003-0088-5825
CR Abbood SH, 2022, IEEE ACCESS, V10, P73079, DOI 10.1109/ACCESS.2022.3189374
   AGCA K, 2022, AVRUPA BILIM VE TEKN, P227, DOI [10.31590/ejosat.1112980, DOI 10.31590/EJOSAT.1112980]
   Al-Antary MT, 2021, IEEE ACCESS, V9, P54190, DOI 10.1109/ACCESS.2021.3070685
   Berbar MA, 2022, HEALTH INF SCI SYST, V10, DOI 10.1007/s13755-022-00181-z
   Bilal A, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071427
   Bilal A, 2022, COMP M BIO BIO E-IV, V10, P663, DOI 10.1080/21681163.2021.2021111
   BINGOL H, 2022, FIRAT U MUHENDISLIK, V34, P439, DOI [10.35234/fumbd.1053501, DOI 10.35234/FUMBD.1053501]
   Chetoui M, 2020, IEEE ENG MED BIO, P1966, DOI 10.1109/EMBC44109.2020.9175664
   Chetoui M, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.4.044503
   Deore SP., 2022, Data science, P57, DOI [10.1201/9781003283249-4/hdwr-smartnet-smart-handwrittendevanagari-word-recognition-system-using-deep-resnet-based-scan-profile-method-shalaka-prasad-deore, DOI 10.1201/9781003283249-4/HDWR-SMARTNET-SMART-HANDWRITTENDEVANAGARI-WORD-RECOGNITION-SYSTEM-USING-DEEP-RESNET-BASED-SCAN-PROFILE-METHOD-SHALAKA-PRASAD-DEORE]
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   GARNER A, 1993, EYE, V7, P250, DOI 10.1038/eye.1993.58
   Hastuti E. T., 2021, INHENCE 2021, P1, DOI [DOI 10.1109/INHENCE52833.2021.9537261, 10.1109/InHeNce52833.2021.9537261]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jabbar MK, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12050535
   kaggle, 2019, APTOS BLINDN DET
   kaggle, 2022, KAGGL EYEPACS DAT
   Kajan S, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039850
   Khade AA, 2022, DATA SCI, P119
   Kumar R., 2022, 2022 6 INT C INT COM, P1280
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Leeza M, 2019, IET COMPUT VIS, V13, P523, DOI 10.1049/iet-cvi.2018.5263
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Li C., 2022, 2022 5 INT C ART INT, P427
   Li X, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232127
   Li YJ, 2021, IEEE ACCESS, V9, P140759, DOI 10.1109/ACCESS.2021.3119434
   Malve P, 2022, DATA SCI, P131
   Maqsood S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113865
   Masood S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1183, DOI 10.1109/CCAA.2017.8229977
   mygreatlearning, INTR VGG16 WHAT IS V
   Nirthika R, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103874
   Omar K, 2021, INT J ADV COMPUT SC, V12
   Özbay E, 2023, ARTIF INTELL REV, V56, P3291, DOI 10.1007/s10462-022-10231-3
   Park J, 2022, INT CONF ADV COMMUN, P247, DOI 10.23919/ICACT53585.2022.9728921
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Reguant R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89225-0
   Sakhare P, 2022, DATA SCI, P1
   Saraf V., 2020, ADV COMPUTING TECHNO, P293, DOI [10.1007/978-981- 15- 3242-9_ 28, DOI 10.1007/978-981-15-3242-928]
   Shah Ashita, 2022, Soft Computing and Signal Processing: Proceedings of 3rd ICSCSP 2020. Advances in Intelligent Systems and Computing, P553, DOI 10.1007/978-981-16-1249-7_52
   Shetgaonkar P, 2021, 2021 INT C TECHNOLOG, P133, DOI [10.1109/ICTAI53825.2021.9673345, DOI 10.1109/ICTAI53825.2021.9673345]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan Q., 2021, Efficientnetv2: Smaller models and faster training, P10096, DOI DOI 10.48550/ARXIV.2104.00298
   Taufiqurrahman Shidqie, 2020, 2020 IEEE Region 10 Conference (TENCON), P235, DOI 10.1109/TENCON50793.2020.9293739
   Theckedath D., 2020, SN COMPUT SCI, V1, P1
   Thorat Sumit, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P996, DOI 10.1109/ICICCS51141.2021.9432075
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   What is diabetes, 2022, INT DIABETES FEDERAT
   What is diabetic retinopathy, 2022, AM ACAD OPHTHALMOLOG
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Yaqoob M.K., 2020, 2020 IEEE 23 INT MUL, P1, DOI 10.1109/INMIC50486.2020.9318096
   Yaqoob MK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113883
   Yu MY, 2022, INT J IMAG SYST TECH, V32, P1789, DOI 10.1002/ima.22734
   Zhang CR, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103423
NR 55
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12185
EP 12208
DI 10.1007/s11042-023-15754-7
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200004
DA 2024-07-18
ER

PT J
AU Yang, F
   Ding, XJ
   Liu, YF
   Ma, FM
AF Yang, Fan
   Ding, Xiaojian
   Liu, Yufeng
   Ma, Fumin
TI Inter-reflection compensation for immersive projection display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-projector; Geometric correction; Illuminance compensation; Image
   enhancement; Image warping
ID VIRTUAL-REALITY; LIGHT
AB To ensure high-quality multi-projection display and fast projection scattering compensation processing, we propose a novel inter-reflection compensation algorithm for an immersive multi-projection system. Firstly, manual adjustment of projector image content can be a complex task. Therefore, we propose a multi-projection distortion correction method using color-structured light coding, which establishes a geometric mapping relationship between the projector and the display screen. This mapping relationship is then utilized to correct the distortion of the projection display screen. Secondly, the luminescence scattering between adjacent projection screens can result in color and brightness discrepancies. To address this issue, we propose a luminescence cross-scatter compensation algorithm for immersive multi-projection systems. Furthermore, through experiments, we demonstrate the effectiveness of our approach in compensating for inter-reflection. Our results indicate that our method effectively mitigates light scattering and achieves high levels of visual fidelity and resolution.
C1 [Yang, Fan; Ding, Xiaojian; Liu, Yufeng; Ma, Fumin] Nanjing Univ Finance & Econ, Coll Informat Engn, Nanjing 210023, Peoples R China.
C3 Nanjing University of Finance & Economics
RP Yang, F (corresponding author), Nanjing Univ Finance & Econ, Coll Informat Engn, Nanjing 210023, Peoples R China.
EM nufe_yf@163.com; wjswsl@163.com; yfengliu28@126.com; fmmatj@126.com
RI Yang, Fan/GRJ-6470-2022
OI YANG, FAN/0000-0001-6861-9596
FU National Natural Science Foundation of China [62002156, 61973151,
   62002155]; Natural Science Foundation of Jiangsu Province [BK20191406];
   Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [19KJB520035]; Key Research & Development Plan of Jiangsu
   Province [BE2021001-4]; 'Qing Lan' Project of Jiangsu Province, China
FX The work was supported by the National Natural Science Foundation of
   China (Nos. 62002156, 61973151, 62002155), the Natural Science
   Foundation of Jiangsu Province (BK20191406), the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   (19KJB520035), the Key Research & Development Plan of Jiangsu Province
   (BE2021001-4), and 'Qing Lan' Project of Jiangsu Province, China.
CR Alnagrat A., 2022, J. Hum. Centered Technol, V1, P81, DOI [10.11113/humentech.v1n2.27, DOI 10.11113/HUMENTECH.V1N2.27]
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2470654.2466112
   [Anonymous], 2013, Proc. CHI 2013, DOI DOI 10.1145/2470654.2470688
   Bingyao Huang, 2021, IEEE Transactions on Automation Science and Engineering, V18, P1049, DOI 10.1109/TASE.2020.2994223
   Breitkreutz C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P719, DOI 10.1109/VR51125.2022.00093
   Chukwuani V.N., 2022, Journal of Management, V4, P35
   Drechsler MF, 2022, IEEE T VEH TECHNOL, V71, P3443, DOI 10.1109/TVT.2022.3160353
   Fujimoto Y, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P174, DOI 10.1109/ISMAR.2015.51
   Guimaraes MD, 2022, MULTIMEDIA SYST, V28, P1573, DOI 10.1007/s00530-022-00908-8
   Hatfield HR, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmac016
   Huang BY, 2019, IEEE I CONF COMP VIS, P7164, DOI 10.1109/ICCV.2019.00726
   Huang BY, 2019, PROC CVPR IEEE, P6803, DOI 10.1109/CVPR.2019.00697
   Huang TH, 2017, IEEE T IMAGE PROCESS, V26, P147, DOI 10.1109/TIP.2016.2592799
   Jadhav S, 2023, IEEE T VIS COMPUT GR, V29, P4832, DOI 10.1109/TVCG.2022.3193672
   Jones Brett, 2014, P 27 ANN ACM S US IN, P637, DOI [10.1145/2642918.2647383, DOI 10.1145/2642918.2647383]
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Kurth P, 2022, IEEE T VIS COMPUT GR, V28, P3607, DOI 10.1109/TVCG.2022.3203085
   Lebiedz J, 2021, IEEE T HUM-MACH SYST, V51, P535, DOI 10.1109/THMS.2021.3102520
   Li Y, 2013, P 19 ACM S VIRTUAL R, P201
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Mazikowski A, 2018, OPTO-ELECTRON REV, V26, P116, DOI 10.1016/j.opelre.2018.02.005
   Miyagawa I, 2017, ITE TRANS MEDIA TECH, V5, P96, DOI 10.3169/mta.5.96
   Bernal IFM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020711
   Mukaigawa Y., 2006, P ACM S VIRT REAL SO, P265
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Portalés C, 2019, MULTIMED TOOLS APPL, V78, P1457, DOI 10.1007/s11042-018-6253-5
   Saakes D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P6058, DOI 10.1145/2858036.2858282
   Sheng Y, 2011, COMPUT GRAPH FORUM, V30, P1261, DOI 10.1111/j.1467-8659.2011.01985.x
   Siegl C., 2017, COMPUT VIS MEDIA, V3, P263, DOI [10.1007/s41095-017-0090-8, DOI 10.1007/S41095-017-0090-8]
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Takeda S, 2016, IEEE T VIS COMPUT GR, V22, P1424, DOI 10.1109/TVCG.2016.2518136
   Tehrani MA, 2021, IEEE T VIS COMPUT GR, V27, P2265, DOI 10.1109/TVCG.2019.2950942
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P13115, DOI 10.1007/s11042-017-4934-0
   Ya-ting X, 2020, MULTIMED TOOLS APPL, V79, P4333, DOI 10.1007/s11042-018-6930-4
   Zheng F, 2013, P IEEE VIRT REAL ANN, P47, DOI 10.1109/VR.2013.6549358
   Zhou Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P781, DOI 10.1145/2858036.2858329
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10427
EP 10443
DI 10.1007/s11042-023-15973-y
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200005
DA 2024-07-18
ER

PT J
AU Becerra, A
   de la Rosa, JI
   Velásquez, ED
   Zepeda, G
   Escalante, NI
   Pedroza, AD
AF Becerra, Aldonso
   de la Rosa, J. Ismael
   Velasquez, Emmanuel de Jesus
   Zepeda, Gustavo
   Escalante, N. Iracemi
   Pedroza, A. David
TI Portable student attendance management module for university environment
   by using biometric mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attendance control; Biometric mechanism; Fingerprint; Convolutional
   neural network; Speech spectrogram images
ID SYSTEM
AB Academic performance of students in most places around the world is determined by their presence in the classroom. Lecture attendance control at a university is a traditional process in which student engagement in classes is fostered by means of an institutional policy. In a conventional way, professors have employed different techniques to monitor the influx of students in the classroom, as well as their punctuality and history log. Nevertheless, conventional (paper-based) and modern attendance registration approaches (some using worksheets and computational information systems) often lack either promptness, non-impersonation ability, simplicity, reliability, effectiveness, scalability, acceptance, mobility, or affordability. The aim of this paper is to present a new proposal based on a common fingerprint process and in a new speaker recognition configuration by using a Raspberry system for student attendance administration purposes in order to provide most of these advantages. Thus, the propounded scheme uses ordinary fingerprint verification (a binarized 8-bit grayscale image processing) and speech recognition in the task of text-independent closed-set speaker identification using convolutional neural networks by means of previous enrollment and training process using as input a new approach of spectrograms images configuration. The presented system obtained an accuracy of 97.5% and 97.49% for the fingerprint and speech-based task respectively. These results are comparable with the corresponding state-of-the-art environments. The main findings obtained show a flexible structure with growth capacity, dynamism and prompt response due to the set of user assistance reports and the student control techniques.
C1 [Becerra, Aldonso; de la Rosa, J. Ismael; Velasquez, Emmanuel de Jesus; Zepeda, Gustavo] Univ Autonoma Zacatecas, Unidad Acad Ingn Electr, Av Lopez Velarde 801, Zacatecas 98068, Mexico.
   [Escalante, N. Iracemi] Inst Tecnol Pabellon Arteaga, Dept Basic Sci, Carretera Estn Rincon KM 1, Pabellon De Arteaga 20670, Ags, Mexico.
   [Pedroza, A. David] Tecnol Univ Aguascalientes, Av Siglo XXI 402, Aguascalientes, Ags, Mexico.
C3 Universidad Autonoma de Zacatecas
RP Becerra, A (corresponding author), Univ Autonoma Zacatecas, Unidad Acad Ingn Electr, Av Lopez Velarde 801, Zacatecas 98068, Mexico.
EM a7donso@uaz.edu.mx; ismaelrv@ieee.org; iemmanuelvm@gmail.com;
   gzepeda@uaz.edu.mx; aivinsg_2682@hotmail.com; P.A.D_16@hotmail.com
OI Pedroza, Angel/0000-0003-3568-2745; De la Rosa,
   Ismael/0000-0002-7337-8974
CR Aden A.A., 2013, ACAD RES INT, V4, P409
   Aggarwal S., 2012, INT J ADV RES COMPUT, V1, P699
   Al Sheikh R., 2019, INT RES J ENG TECHNO, V6, P1
   Amri UF, 2017, IOP CONF SER-MAT SCI, V260, DOI 10.1088/1757-899X/260/1/012008
   [Anonymous], 2009, International Journal of Computer Science and Information Security, DOI DOI 10.1109/PROC.1976.10158
   [Anonymous], 2012, PAC J SCI TECHNOL
   [Anonymous], 2016, 1 AFRICA C 1 AFRICA, DOI DOI 10.1109/ISTAFRICA.2016.7530647
   Ansari Aamir Nizam, 2011, 2011 International Conference on Multimedia Technology, P2976
   Arulogun O., 2013, INT J SCI ENG RES, V4, P1
   Basheer KPM, 2012, ANNU IEEE IND CONF, P433
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P27231, DOI 10.1007/s11042-018-5917-5
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P15875, DOI 10.1007/s11042-017-5160-5
   Byalpi AS, 2018, INT C COMM EL SYST I, P121, DOI [10.1109/CESYS.2018.8724006, DOI 10.1109/CESYS.2018.8724006]
   Chandramohan J., 2017, INT J ADV ENG MANAG, V3, P241, DOI DOI 10.24001/IJAEMS.3.3.16
   Charity A, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON ELECTRO-TECHNOLOGY FOR NATIONAL DEVELOPMENT (NIGERCON), P464, DOI 10.1109/NIGERCON.2017.8281916
   Chintalapati S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P541
   Deugo D., 2015, Int'l Congf. Frontiers in Education: Computer Science and Computer Engineering, V(FECS),, P267
   Dey S, 2014, NATL CONF COMMUN
   Dolezel M., 2012, INFLUENCE SKIN DIS F, P275, DOI [10.5772/51992, DOI 10.5772/51992]
   Fahad-Bin-Mazhar, 2015, 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL & ELECTRONIC ENGINEERING (ICEEE), P13, DOI 10.1109/CEEE.2015.7428261
   Gadhave VD, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P2042, DOI 10.1109/RTEICT.2016.7808198
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Gbadamosi OA., 2017, GLOBAL SCI J, V5, P18
   Ghosh S., 2018, 2018 INT C SMART CIT, P1, DOI [10.1109/ICSCET.2018.8537298, DOI 10.1109/ICSCET.2018.8537298]
   Gnanasivam P, 2010, PROCEDIA COMPUT SCI, V2, P133, DOI 10.1016/j.procs.2010.11.017
   Gupta S., 2013, SIGNAL IMAGE PROCESS, V4, P101, DOI [DOI 10.5121/SIPIJ.2013.4408, 10.5121/sipij.2013.4408]
   Hapani S, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Hoo SC, 2019, J SENSORS, V2019, DOI 10.1155/2019/7410478
   Issa T, 2019, BIOMETRIC BASED PHYS, P1
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Jelil S, 2019, INTERSPEECH, P3665
   Jha A., 2007, INT J MATH SCI TECHN, V2, P2007
   Jiang Z, 2016, INT J ADV COMPUT SC, P600
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kar Nirmalya, 2012, INT J COMPUT COMMUN, DOI [10.7763/IJCCE.2012.V1.28, DOI 10.7763/IJCCE.2012.V1.28]
   Kassim M., 2012, Proceedings of the 2012 IEEE Control and System Graduate Research Colloquium (ICSGRC 2012), P213, DOI 10.1109/ICSGRC.2012.6287164
   Kaur G, 2014, Int J Biotech Biosci, V6, P69
   Kawaguchi Y., 2005, FACE RECOGNITION BAS
   Khan MAK, 2018, INT CONF COMPUT INFO
   Khatun A, 2015, INT C EL ENG INF COM, P21, DOI [10.1109/ICEEICT.2015.7307458, DOI 10.1109/ICEEICT.2015.7307458]
   Kingma D. P., 2015, P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR, P1
   Lukas S, 2016, I C INF COMM TECH CO, P1032, DOI 10.1109/ICTC.2016.7763360
   Majekodunmi TO, 2011, P WORLD C ENG, V2, P1681
   Malik Raj, 2016, 2016 International Conference on Information Technology (InCITe): Next-Generation IT Summit on the Theme "Internet of Things: Connect Your Worlds", P40, DOI 10.1109/INCITE.2016.7857586
   Masalha F, 2014, INT J ADV COMPUT SC, V5, P75
   Maurya A.K., 2018, INT J TREND SCI RES, V3, P2, DOI DOI 10.31142/IJTSRD18763
   Mehtre B. M., 1993, Machine Vision and Applications, V6, P124, DOI 10.1007/BF01211936
   Mekala, 2019, International Journal of Innovative Technology and Exploring Engineering (IJITEE), V8, P520, DOI [10.35940/ijitee.L3406.1081219, DOI 10.35940/IJITEE.L3406.1081219]
   Mittal Y, 2015, ANNU IEEE IND CONF
   Mohandes MA, 2017, INTELL AUTOM SOFT CO, V23, P251, DOI 10.1080/10798587.2016.1204749
   Nandhini R., 2019, INT J ENG ADV TECHNO, V8, P574
   Nawaz T, 2009, INT J COMPUT SCI NET, V9, P164
   An NN, 2019, IEEE ACCESS, V7, P85327, DOI 10.1109/ACCESS.2019.2917470
   Okokpujie K, 2016, INT C SEC MAN SAM
   Okokpujie KO, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P563, DOI 10.1109/CSCI.2017.96
   Patil A., 2014, INT J ADV ENG TECHNO, V7, P974
   Purohit A, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P415, DOI 10.1109/ICECA.2017.8203717
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   Reddi S. J., 2018, INT C LEARN REPR
   Saheed YK., 2016, PAC J SCI TECHNOL, V17, P224
   Said MAM, 2014, 2014 1ST INTERNATIONAL SYMPOSIUM ON TECHNOLOGY MANAGEMENT AND EMERGING TECHNOLOGIES (ISTMET 2014), P258, DOI 10.1109/ISTMET.2014.6936516
   Sarker DK, 2016, 2016 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE (IWCI), P91, DOI 10.1109/IWCI.2016.7860345
   Sawhney S, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P522, DOI [10.1109/confluence.2019.8776934, 10.1109/CONFLUENCE.2019.8776934]
   SCARR RWA, 1970, INT J MAN MACH STUD, V2, P41, DOI 10.1016/S0020-7373(70)80020-7
   Shafi Q., 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P555, DOI 10.1109/ICEIE.2010.5559744
   Shehu V., 2010, 2010 32nd International Conference on Information Technology Interfaces (ITI 2010), P397
   Shoewu O., 2011, AFRICAN J COMPUT ICT, V4, P27
   Shoewu O., 2014, AMERICAN J COMPUTING, V2, P8
   Soewito B, 2016, 2016 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA): RECENT TRENDS IN INTELLIGENT COMPUTATIONAL TECHNOLOGIES FOR SUSTAINABLE ENERGY, P175, DOI 10.1109/ISITIA.2016.7828654
   Soniya V, 2017, 2017 INTERNATIONAL CONFERENCE ON POWER AND EMBEDDED DRIVE CONTROL (ICPEDC), P122, DOI 10.1109/ICPEDC.2017.8081072
   Sweetlin JD, 2016, INT CONF RECENT
   Talaviya G., 2013, International Journal of Engineering and Advanced Technology, V2, P201
   Tan ZH, 2020, COMPUT SPEECH LANG, V59, P1, DOI 10.1016/j.csl.2019.06.005
   Tunbunheng Vasutan, 2017, 2017 10th International Conference on Ubi-Media Computing and Workshops (Ubi-Media). Proceedings, DOI 10.1109/UMEDIA.2017.8074119
   Uddin N, 2016, J HUMAN SOCIAL SCI G, V16
   Varadharajan E, 2016, PROCEEDINGS OF 2016 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Verma P., 2013, INT J SCI RES IJSR, V2, P128
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zainal Nur Izzati, 2014, 2014 5th International Conference on Information and Communication Technology for the Muslim World (ICT4M), DOI 10.1109/ICT4M.2014.7020601
   Zhang DD, 2000, AUTOMATED BIOMETRICS, V1
NR 82
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 6
PY 2023
DI 10.1007/s11042-023-15482-y
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I5ZM2
UT WOS:001003562600001
DA 2024-07-18
ER

PT J
AU Aberna, P
   Agilandeeswari, L
AF Aberna, P.
   Agilandeeswari, L.
TI Digital image and video watermarking: methodologies, attacks,
   applications, and future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Social network platform; Tamper detection; Copyright protection; Image
   watermarking; Image authentication; Video watermarking
ID SEMI-FRAGILE WATERMARKING; COPY-MOVE FORGERY; DISCRETE WAVELET
   TRANSFORM; SUPPORT VECTOR MACHINE; CONTENT AUTHENTICATION; TAMPER
   DETECTION; SCHEME; ALGORITHM; LOCALIZATION; RECOVERY
AB In recent years, internet technology has grown in advance, and multimedia data-sharing growth rates have skyrocketed. As a result, protecting multimedia data in digital networks has become a significant problem. Multimedia data such as audio, text, video, and image are highly used as a data-sharing communication system which demands security, particularly in image and video. Digital watermarking is the one solution that has gained widespread recognition over the past two decades for data embedding in image and video, a key tactic in multimedia tamper detection and recovery. The review tells about the growth rate and data breaches on multimedia data across different applications, which raises the issue of multimedia security. Notably, social network platforms are highly targeted due to their rapid growth, which has created opportunities for data breaches and multimedia manipulation. Here, the forensic field comes into play, where some data-hiding strategies are used to look for evidence of tampering. Even though watermarking techniques can attain security in tamper detection, they face some issues and challenges across various applications. This motivated us to analyze the existing work carried out by data hiding watermarking techniques in the field of multimedia tamper detection in detail and the gap analyzed. Overall, dataset availability, watermarking performance quality metrics, and several image-processing attacks are all explicitly mentioned. This review paper discusses a comprehensive study of the existing system in the field of tamper detection (both in Image and Video) in detail. Also, the development of existing watermarking techniques, issues, and challenges are covered in detail in this paper.
C1 [Aberna, P.; Agilandeeswari, L.] VIT, Sch Informat Technol & Engn SITE, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), VIT, Sch Informat Technol & Engn SITE, Vellore 632014, Tamil Nadu, India.
EM agila.l@vit.ac.in
RI L, Agilandeeswari/P-8997-2016
OI L, Agilandeeswari/0000-0001-6147-9535
CR Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   Agarwal H, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102846
   Agilandeeswari L, 2023, MULTIMED TOOLS APPL, V82, P43367, DOI 10.1007/s11042-023-15177-4
   Agilandeeswari L, 2023, MULTIMED TOOLS APPL, V82, P10445, DOI 10.1007/s11042-022-13629-x
   Agilandeeswari L, 2022, MULTIMED TOOLS APPL, V81, P27683, DOI 10.1007/s11042-022-12946-5
   Agilandeeswari L, 2018, MULTIMED TOOLS APPL, V77, P25431, DOI 10.1007/s11042-018-5800-4
   Agilandeeswari L, 2016, J ENG SCI TECHNOL, V11, P327
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P7211, DOI 10.1007/s11042-015-2642-1
   Agilandeeswari L, 2013, INT J ADV RES COMPUT, V3
   Agilandeeswari L, 2013, SECURITY COMPUTING C, P3
   Agilandeeswari L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031670
   Agilandeeswari L, 2013, INT J SECUR APPL, V7, P145
   Al-Otum HM, 2022, OPTIK, V262, DOI 10.1016/j.ijleo.2022.169280
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   [Anonymous], 2016, 2016 IEEE INT WORKSH, DOI DOI 10.1109/WIFS.2016.7823911
   [Anonymous], 2016, IEEE INT C IM PROC I
   [Anonymous], 2014, 2014 10 INT C COMMUN
   Appel G, 2020, J ACAD MARKET SCI, V48, P79, DOI 10.1007/s11747-019-00695-1
   Ariatmanto D, 2022, J KING SAUD UNIV-COM, V34, P605, DOI 10.1016/j.jksuci.2020.02.005
   Asiri S, BRIEF INTRO ARTIFICI
   Azizi S, 2013, IEEE INT CONF MULTI
   Begum M, 2020, ADV MULTIMED, V2020, DOI 10.1155/2020/7912690
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Bhalerao S, 2021, 2021 INT C CONTROL A, P1
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   bin Jeffry MAF, 2017, 2017 IEEE CONFERENCE ON APPLICATION, INFORMATION AND NETWORK SECURITY (AINS), P118, DOI 10.1109/AINS.2017.8270435
   Bolourian Haghighi B, 2018, ARXIV
   Camacho IC, 2021, J IMAGING, V7, DOI 10.3390/jimaging7040069
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Cao H., 2022, OPTIK, V169319, P262
   Cao QF, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9020091
   Castro M, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104864
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chalamala SR, 2015, I C ARTIF INTELL, P159, DOI 10.1109/AIMS.2015.34
   Chang CC, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010013
   Chang YJ, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/846967
   Charkari Nasrollah Moghaddam, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P194, DOI 10.1109/ISSPIT.2007.4458077
   Chaudhary S.V., 2019, 2019 IEEE Indian Conference on Antennas and Propagation (InCAP), Ahmedabad, India, P1
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cruz C, 2019, 2019 7 INT WORKSH BI, P1
   Dobre RA, 2018, INT SYM DES TECH ELE, P255, DOI 10.1109/SIITME.2018.8599235
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   Nguyen DT, 2010, IEEE IMAGE PROC, P4609, DOI 10.1109/ICIP.2010.5651633
   Elshoura SM, 2013, J VIS COMMUN IMAGE R, V24, P567, DOI 10.1016/j.jvcir.2013.03.021
   Eugene B, 2021, DATA BREACHES MOST S
   Fang H, 2019, IEEE T INF FOREN SEC, V14, P1403, DOI 10.1109/TIFS.2018.2878541
   Fita A., 2019, J Math Stat Anal, V127, P964
   Gao H, 2021, OPTIK, V242, DOI 10.1016/j.ijleo.2021.166954
   Coronel SLG, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3460-2
   Gómez-Moreno H, 2014, SCI WORLD J, DOI 10.1155/2014/826405
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Han B, 2021, J HLTH ENG, V2021
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hatami E, 2023, MULTIMED TOOLS APPL, V82, P2021, DOI 10.1007/s11042-022-13197-0
   Hmida A. B., 2018, 2018 4th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P1
   Hongbo B. I., 2013, TELKOMNIKA Indonesian Journal of Electrical Engineering, V11, P7516
   Hoshi A.R., 2021, Indonesian Journal of Electrical Engineering and Computer Science, V22, P842, DOI [10.11591/ijeecs.v22.i2.pp842-856, DOI 10.11591/IJEECS.V22.I2.PP842-856]
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   imageprocessingplace, STAND TEST DAT SIPI
   Issa M, 2018, ADV SOFT COMPUTING M, V730
   Jana M, 2022, J KING SAUD UNIV-COM, V34, P9822, DOI 10.1016/j.jksuci.2021.12.011
   Jayamalar T., 2010, International Journal of Engineering Science and Technology, V2, P6963
   Jie sang, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100052
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Jyothika A, 2018, 2018 2 INT C TRENDS, P676
   kaggle, BOSSB DAT
   kaggle, CASS V2 0 DAT
   Kang HY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199629
   Kessler B, 2002, ADV IMAG ELECT PHYS, V124, P195
   Kim C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199209
   Kim C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083418
   Kim C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031146
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Kourkchi Hossein, 2008, IIT 2008 International Conference on Innovations in Information Technology, P130, DOI 10.1109/INNOVATIONS.2008.4781744
   Lancini R, 2002, PROCEEDINGS VIPROMCOM-2002, P251, DOI 10.1109/VIPROM.2002.1026664
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Laouamer L, 2022, NEW INFORM NONBLIND
   Lee GJ, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P130, DOI 10.1109/UMC.2008.33
   Lefèvre P, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108342
   Li WH, 2010, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2010.5652519
   Lin CH, 2008, MUE: 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P132, DOI 10.1109/MUE.2008.17
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Luo H, 2011, OPTIK, V122, P311, DOI 10.1016/j.ijleo.2009.12.018
   Maheshwari JP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1059, DOI 10.1109/ICCSP.2015.7322663
   Maji Prasenjit, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1272, DOI 10.1109/ICRITO48877.2020.9197780
   Manjunatha S., 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P1278, DOI 10.1109/ICICV50876.2021.9388471
   Mo J., 2012, Advances in Information Sciences and Service Sciences, V4, P221, DOI [10.4156/AISS.VOL4.ISSUE15.27, DOI 10.4156/AISS.VOL4.ISSUE15.27]
   Mobasseri B. G., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P68, DOI 10.1109/ITCC.2000.844185
   Mohanrajan SN, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136387
   Mohidul Islam S. M., 2007, Information and Communication Technology, P246, DOI [10.1109/ICICT.2007.375386, DOI 10.1109/ICICT.2007.375386]
   Moltisanti M, 2015, LECT NOTES COMPUT SC, V9280, P506, DOI 10.1007/978-3-319-23234-8_47
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Munir R., 2020, Digital Forensic Science
   N.R. Neena Raj, 2022, Journal of Visual Communication and Image Representation, DOI 10.1016/j.jvcir.2022.103500
   Ng T, 2004, 4 ADVENT COL U, V4
   Ng Tian-Tsong, 2009, Columbia Image Splicing Detection Evaluation DatasetEB/ OL
   paperswithcode, VID DAT
   paperswithcode, KIN DAT
   Patel M.B., 2013, International J of Scientific and research Publications, V3, P1
   Patil RD, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1661, DOI 10.1109/ICACCI.2015.7275852
   Plata M, 2020, IEEE INT CONF TRUST, P62, DOI 10.1109/TrustCom50675.2020.00022
   Prabukumar M, 2019, J AMB INTEL HUM COMP, V10, P267, DOI 10.1007/s12652-017-0655-5
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Rafigh Majid, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P105, DOI 10.1109/CGIV.2010.24
   Rakhmawati L, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS), P35, DOI 10.1109/ICoIAS.2018.8494080
   Rezaei M, 2022, OPTIK, V264, DOI 10.1016/j.ijleo.2022.169345
   Saini PK., 2021, 2021 9 INT C REL INF, P1
   Sawant Shrutika S., 2021, Arabian Journal of Geosciences, DOI 10.1007/s12517-021-06984-w
   Sawant SS, 2022, INT J REMOTE SENS, V43, P3990, DOI 10.1080/01431161.2022.2105666
   Scheibenreif L, 2022, IEEE COMPUT SOC CONF, P1421, DOI 10.1109/CVPRW56347.2022.00148
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Sharma Vivek, 2019, ICTACT Journal on Image and Video Processing, V10, P2061, DOI 10.21917/ijivp.2019.0293
   Shukla D, 2018, J INTELL SYST, V27, P47, DOI 10.1515/jisys-2017-0039
   Singh B, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106925
   Singh B, 2021, COMPUT IND ENG, V162, DOI 10.1016/j.cie.2021.107733
   Sinhal R, 2020, IEEE ACCESS, V8, P200157, DOI 10.1109/ACCESS.2020.3035428
   SIPI, SIPI DAT ALL WEB 213
   smartinsights, SOC MED GROWTH
   Song C, 2011, 2011 DEV E SYSTEMS E, P215
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Soppari K, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100287
   statcdn, GROWTH RAT FAC
   Sun WW, 2021, IEEE T CIRC SYST VID, V31, P1208, DOI 10.1109/TCSVT.2020.2998476
   Sunny S., 2013, Int. J. Appl. Eng. Res., V8
   Tan LL, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012068
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Tohidi F, 2021, IEEE ACCESS, V9, P57510, DOI 10.1109/ACCESS.2021.3072314
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tsai MJ, 2008, IEEE INT SYMP CIRC S, P3033, DOI 10.1109/ISCAS.2008.4542097
   unisi, VIPP DAT
   Vahedi E, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1383
   Vassaux B, 2002, PROCEEDINGS VIPROMCOM-2002, P239, DOI 10.1109/VIPROM.2002.1026662
   Venu KN, 2021, MAT TODAY P, DOI [10.1016/j.matpr.2021.01.189, DOI 10.1016/J.MATPR.2021.01.189]
   Verma V, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3198, DOI 10.1109/ICEEOT.2016.7755292
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang XQ, 2009, ICMECG: 2009 INTERNATIONAL CONFERENCE ON MANAGEMENT OF E-COMMERCE AND E-GOVERNMENT, PROCEEDINGS, P498, DOI 10.1109/ICMeCG.2009.31
   Wang ZH, 2023, Arxiv, DOI arXiv:2107.09287
   Xu HC, 2019, OPTIK, V183, P401, DOI 10.1016/j.ijleo.2019.02.001
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yeo IK, 2003, MULTIMEDIA SYST, V9, P261, DOI 10.1007/s00530-003-0097-0
   Yu C, 2020, AAAI CONF ARTIF INTE, V34, P1120
   Yu XY, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040056
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang X., 2012, PROCEEDING SENSOR SI, P1
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P272, DOI 10.1109/SIPROCESS.2017.8124547
   Zheng PP, 2014, NEUROCOMPUTING, V142, P520, DOI 10.1016/j.neucom.2014.04.005
   Zhou Guojuan, 2011, 2011 Fourth International Joint Conference on Computational Sciences and Optimization (CSO), P332, DOI 10.1109/CSO.2011.85
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou XY, 2013, 2013 INTERNATIONAL CONFERENCE ON SENSOR NETWORK SECURITY TECHNOLOGY AND PRIVACY COMMUNICATION SYSTEM (SNS & PCS), P197
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zigomitros A., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1381, DOI 10.1109/TrustCom.2012.264
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 162
TC 9
Z9 9
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-15806-y
EA JUN 2023
PG 61
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0SS7
UT WOS:000999967700006
DA 2024-07-18
ER

PT J
AU Saini, JK
   Bansal, D
AF Saini, Jaspal Kaur
   Bansal, Divya
TI Computational techniques to counter terrorism: a systematic survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computational techniques; Data science; Data mining; Machine learning;
   Online social networks; Terrorist network
ID BEHAVIOR
AB Terrorist Network Analysis (TNA) is the field of analyzing and defining the scope of terrorism and researching the countermeasures in order to handle exponentially increasing threats due to ever growing terrorist based activities. This field constitutes several sub-domains such as crawling the data about terrorist attacks/groups, classification, behavioral, and predictive analysis. In this paper we present a systematic review of TNA which includes study of different terrorist groups and attack characteristics, use of online social networks, machine learning techniques and data mining tools in order to counter terrorism. Our survey is divided into three sections of TNA: Data Collection, Analysis Approaches and Future Directions. Each section highlights the major research achievements in order to present active use of research methodology to counter terrorism. Furthermore, the metrics used for TNA analysis have been thoroughly studied and identified. The paper has been written with an intent of providing all the necessary background to the researchers who plan to carry out similar studies in this emerging field of TNA. Our contributions to TNA field are with respect to effective utilization of computational techniques of data mining, machine learning, online social networks, and highlighting the research gaps and challenges in various sub domains.
C1 [Saini, Jaspal Kaur] IIIT Una, Sch Comp, Una, Himachal Prades, India.
   [Bansal, Divya] Deemed Univ, Punjab Engn Coll, CSRC, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Saini, JK (corresponding author), IIIT Una, Sch Comp, Una, Himachal Prades, India.
EM jaspalkaursaini@iiitu.ac.in; divya@pec.edu.in
RI SAINI, JASPAL KAUR/HGC-6731-2022
OI Saini, Jaspal Kaur/0000-0003-1142-1356
FU Cyber Security Research Centre; Punjab Engineering College, Chandigarh,
   India
FX This work was partially supported by Cyber Security Research Centre,
   Punjab Engineering College(Deemed to be University), Chandigarh,
   India.The author Jaspal K Saini is grateful to Visvesvaraya PhD scheme
   for Electronics and IT for funding this research.
CR Abbasi A., 2005, INTELL SYST IEEE, V20, P67, DOI [10.1109/MIS.2005.81, DOI 10.1109/MIS.2005.81]
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Albores P, 2005, PROCEEDINGS OF THE 2005 WINTER SIMULATION CONFERENCE, VOLS 1-4, P886, DOI 10.1109/WSC.2005.1574336
   Allanach J, 2004, AEROSP CONF PROC, P3246, DOI 10.1109/AERO.2004.1368130
   [Anonymous], 2016, INT TERR ATTR TERR E
   [Anonymous], 2016, DYNETMLCASOS
   [Anonymous], 2016, ORA LITE SOFTW CASOS
   [Anonymous], 2012, P 1 INT WORKSH ISS S
   [Anonymous], 2016, DARK WEB FOR
   [Anonymous], 2016, DARK WEB PROJ
   [Anonymous], 2014, SECUR INFORM, DOI DOI 10.1186/S13388-014-0005-5
   [Anonymous], 2016, PROJ CONSTR CASOS
   [Anonymous], 2016, AUTOMAP PROJ CASOS
   [Anonymous], 2016, UCINET SOFTW
   [Anonymous], 2016, CRAWLER4J OP SOURC P
   [Anonymous], 2016, BIOWAR PROJ CASOS
   [Anonymous], 2016, PROJ ORGAHEAD CASOS
   [Anonymous], 2020, AP SOC SENS TOOLK
   [Anonymous], 2016, The R project for statistical computing. Version 3.3.2
   [Anonymous], 2016, PHP HYP PREPR
   [Anonymous], 2016, NPR25 May
   Archetti F, 2014, INT CARN CONF SECU
   Asongu SA, 2019, J GLOB INF TECH MAN, V22, P208, DOI 10.1080/1097198X.2019.1642023
   Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032
   Berzinji A, 2003, 2013 EUR INT SEC INF, P7695
   Best DM, 2015, IT PROF, V17, P66, DOI 10.1109/MITP.2015.57
   Bhattacharyya S, 2011, DECIS SUPPORT SYST, V50, P602, DOI 10.1016/j.dss.2010.08.008
   Brajawidagda U., 2016, ACM International Conference Proceeding Series, P445, DOI DOI 10.1145/2912160.2912193
   Brynielsson J, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P954, DOI 10.1145/2808797.2808810
   Burke Robin, 2006, KDD 06 P 12 ACM SIGK, DOI DOI 10.1145/1150402.1150465
   Cao LB, 2008, IEEE T KNOWL DATA EN, V20, P1053, DOI 10.1109/TKDE.2007.190635
   Chen JH, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P142, DOI 10.1109/GRC.2008.4664739
   Coffman TR, 2004, IEEE AER C P DYN CLA, P1
   David Liben-Nowell JK., 2013, INT REV RES OPEN DIS, V14, P90
   Desmarais B. A., 2011, 2011 European Intelligence and Security Informatics Conference, P171, DOI 10.1109/EISIC.2011.44
   Deylami HA, 2015, P 7 C INF KNOWL TECH, P1, DOI [10.1109/IKT.2015.7288742, DOI 10.1109/IKT.2015.7288742]
   Dhote Y, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1178, DOI 10.1109/ICACCI.2013.6637344
   Dickerson J. P., 2011, 2011 European Intelligence and Security Informatics Conference, P354, DOI 10.1109/EISIC.2011.33
   Duman E, 2011, EXPERT SYST APPL, V38, P13057, DOI 10.1016/j.eswa.2011.04.110
   Engene JO, 2006, DATA SET TERRORISM W
   Fire M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P73, DOI 10.1109/PASSAT/SocialCom.2011.20
   Fu JL, 2012, 2012 FIFTH INTERNATIONAL CONFERENCE ON BUSINESS INTELLIGENCE AND FINANCIAL ENGINEERING (BIFE), P476, DOI 10.1109/BIFE.2012.107
   Goldstein H, 2006, IEEE SPECTRUM, V43, P26, DOI 10.1109/MSPEC.2006.1688255
   Gorecki J., 2011, 2011 International Conference on Computational Aspects of Social Networks (CASoN 2011), P255, DOI 10.1109/CASON.2011.6085954
   Goyal T, 2019, P 2 INT C COMM COMP
   Haglich Peter, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P693, DOI 10.1109/SocialCom.2010.107
   Hogan B, 2011, VISUALIZING INTERPRE
   Hsiao Hw, 2009, P 11 INT C EL COMM, P341
   Huillier GL, 2010, ACM SIGKDD WORKSHOP, P66
   Jayaweera I, 2015, 2015 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON), P277, DOI 10.1109/MERCon.2015.7112359
   JDK, 2016, US
   Jin L, 2013, IEEE COMMUN MAG, V51, P144, DOI 10.1109/MCOM.2013.6588663
   Johnson CW, 2005, P SIGCHI C HUMAN FAC, P651
   Katipally R, 2010, MULTISTAGE ATTACK DE
   Kaur A, 2019, Arxiv, DOI arXiv:1907.12368
   Kengpol A, 2014, COMPUT IND ENG, V75, P55, DOI 10.1016/j.cie.2014.06.003
   Klausen J., 2016, The Role of Social Networks in the Evolution of Al Qaeda-inspired Violent Extremism in the United States, 1990-2015
   Krause L, 2003, FAMILY AGENT BASED M
   Lautenschlager J, 2015, PROCEDIA MANUF, V3, P3933, DOI 10.1016/j.promfg.2015.07.922
   Lee J., 2008, ACM CROSSROADS, V15, P7
   Li GH, 2015, PROCEDIA ENGINEER, V84, P698, DOI 10.1016/j.proeng.2014.10.475
   Mannes A., 2011, 2011 European Intelligence and Security Informatics Conference, P224, DOI 10.1109/EISIC.2011.61
   Mannes A, 2008, SOCIAL COMPUTING, BEHAVIORAL MODELING AND PREDICTION, P37, DOI 10.1007/978-0-387-77672-9_6
   Mason R., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P84, DOI 10.1109/ISI.2012.6284096
   Mathieu B, 2012, IEEE COMMUN MAG, V50, P44, DOI 10.1109/MCOM.2012.6231278
   McKerlich R., 2013, INT REV RES OPEN DIS, V14, P90, DOI [10.1002/asi, DOI 10.1002/ASI]
   Miller RR, 2002, VIEWPOINT INFORM MAN, V45, P31
   Mitchell T. M., 1997, MACHINE LEARNING
   Moon IC, 2007, IEEE INTELL SYST, V22, P40, DOI 10.1109/MIS.2007.4338493
   National Consortium for the Study of Terrorism and Responses to Terrorism, 2020, Global Terrorism Database
   National Consortium for the Study of Terrorism and Responses to Terrorism (START), 2015, GTD GLOB TERR DAT, P63
   Ngai EWT, 2011, DECIS SUPPORT SYST, V50, P559, DOI 10.1016/j.dss.2010.08.006
   Ozgul F, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P468, DOI 10.1109/ASONAM.2011.94
   Ozgul F, 2009, ISI: 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P37, DOI 10.1109/ISI.2009.5137268
   Pagan Jose V., 2010, 2010 2nd International Conference on Software Technology and Engineering (ICSTE 2010), P104, DOI 10.1109/ICSTE.2010.5608902
   R. C. DARPA, 2019, RDWTI RAND
   Rejaie R, 2010, IEEE NETWORK, V24, P32, DOI 10.1109/MNET.2010.5578916
   Sang JT, 2015, IEEE T MULTIMEDIA, V17, P2259, DOI 10.1109/TMM.2015.2486524
   Sardarnia K, 2019, TERROR POLIT VIOLENC, V31, P1266, DOI 10.1080/09546553.2017.1341877
   Schreck T, 2013, COMPUTER, V46, P68, DOI 10.1109/MC.2012.430
   Serra E, 2014, IEEE TRANS COMPUT SO, V1, P66, DOI 10.1109/TCSS.2014.2307454
   Shen HY, 2015, IEEE T COMPUT, V64, P1715, DOI 10.1109/TC.2014.2322598
   Siegrist D., 2000, SIGBIO Newsletter, V20, P2, DOI 10.1145/360262.360264
   Simanjuntak D. A., 2010, 2010 Proceedings of Second International Conference on Advances in Computing, Control and Telecommunication Technologies (ACT 2010), P198, DOI 10.1109/ACT.2010.40
   Skillicorn DB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P61, DOI 10.1109/ISI.2015.7165940
   Skillicorn DB, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P687
   smrfoundation, 2007, NODEXL
   South Asia Terrorism Portal (SATP), 2016, US
   Spezzano Francesca, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P348
   START, 2005, MAROB
   start.umd.edu, 2017, US
   Su P, 2012, DECIS SUPPORT SYST, V54, P142, DOI 10.1016/j.dss.2012.04.013
   Subrahmanian EVS, 2012, HDB COMPUTATIONAL AP
   Suicide Attack Database (SAD), 2016, US
   Sun Duo-Yong, 2011, 2011 IEEE International Conference on Intelligence and Security Informatics (ISI 2011), P373, DOI 10.1109/ISI.2011.5984117
   Taquechel E, 2010, IEEE NETWORK, V24, P30, DOI 10.1109/MNET.2010.5634440
   Thuraisingham B., 2004, Data Mining: Next Generation Challenges and Future Directions, p157,183
   Ugwoke FN, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERSPACE (CYBER-ABUJA), P241, DOI 10.1109/CYBER-Abuja.2015.7360516
   Valenzuela ML, 2010, NONNUMERICAL PREDICT
   Wang J, 2014, NOVEL METHOD CENTRAL, P144
   Wang P, 2014, TALE 3 SOCIAL NETWOR, P10
   Wang T, 2014, INT C MAN E COMM E G, P149
   Weil T, 2015, HAPPENED SONY HAPPEN
   Weinstein C, 2009, AEROSP CONF PROC, P3361
   Wiil UK, 2010, 2010 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2010), P225, DOI 10.1109/ASONAM.2010.29
   Worldwide Incident Tracking System (WITS), 2004, US
   Xiong H, 2009, IEEE T SYST MAN CY B, V39, P318, DOI 10.1109/TSMCB.2008.2004559
   Xu JA, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING ( GRC 2009), P630, DOI 10.1109/GRC.2009.5255041
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Ze L, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P724, DOI 10.1109/ASONAM.2014.6921666
   Zhaohui Huang, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P338, DOI 10.1109/NCM.2009.131
   Zhiliang Liu, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P4007, DOI 10.1109/EMEIT.2011.6023897
   Zhou YL, 2005, ACM-IEEE J CONF DIG, P402, DOI 10.1145/1065385.1065505
NR 113
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-15545-0
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KH3
UT WOS:000999744800001
DA 2024-07-18
ER

PT J
AU Singh, N
   Saini, P
   Shubham, O
   Awasthi, R
   Bharti, A
   Kumar, N
AF Singh, Navjot
   Saini, Paras
   Shubham, Om
   Awasthi, Rituraj
   Bharti, Anurag
   Kumar, Neetesh
TI Improved YOLOv5l for vehicle detection: an application to estimating
   traffic density and identifying over speeding vehicles on highway scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle detection; Vehicle counting; YOLO; Centroid tracking algorithm
ID SELF-DRIVING CARS
AB Vehicle detection and counting are getting progressively significant in highway administration due to the varying sizes of vehicles. This paper proposes a vision-based vehicle detection and counting framework. Initially, the COCO and BDD100K datasets are trained, employing improved YOLOv5l algorithm, using GhostBottleneck, for vehicle detection. Subsequently, the Centroid Tracking Algorithm counts the vehicles in videos uniquely. Later, vehicles are categorized as Light and Heavy vehicles. The model is evaluated over UCSD dataset for traffic estimation. Then, the speed of the recognized vehicle is computed to identify overspeeding. Lastly, number plate identification of the over speeding vehicles is performed. Vehicle detection performed well in precision, recall, F-score, and mAP. The centroid tracking algorithm had the best multiple object tracking accuracy and precision for vehicle tracking. The proposed model performed well in terms of detection rate, false alarm rate, and mean time to traffic detection.
C1 [Singh, Navjot] Indian Inst Informat Technol Allahabad, Prayagraj 211015, India.
   [Saini, Paras; Shubham, Om; Awasthi, Rituraj; Bharti, Anurag] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
   [Kumar, Neetesh] Indian Inst Technol Roorkee, Roorkee 247667, Uttaranchal, India.
C3 Indian Institute of Information Technology Allahabad; National Institute
   of Technology (NIT System); Motilal Nehru National Institute of
   Technology; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Roorkee
RP Singh, N (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj 211015, India.
EM navjot@iiita.ac.in; parassaini16@gmail.com; omshubham99@gmail.com;
   ra972472@gmail.com; anuragbharti936@gmail.com; neetesh@cs.iitr.ac.in
RI Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482
FU Department of Science & Technology (DST), India; DST
   [DST/ICPS/CPS-Individual/2018/678(G)]
FX The authors express their gratitude to Department of Science &
   Technology (DST), India for the obtained financial support in performing
   this research work. This work is one of the outcomes of the project
   entitled "IoT based real time and effective traffic signal scheduling
   for smart city" with sanction no. DST/ICPS/CPS-Individual/2018/678(G)
   dated 03.01.2019, sponsored by DST.
CR Al-Smadi M., 2016, DIGIT IMAGE PROCESS, V5, P435
   [Anonymous], 2016, Int. J. Appl. Eng. Res.
   Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhalla Aman, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P519, DOI 10.1109/ICISS49785.2020.9315968
   Byun S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13204027
   Cai YF, 2015, IET INTELL TRANSP SY, V9, P810, DOI 10.1049/iet-its.2014.0238
   Chan AB, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P771
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chen ST, 2019, IEEE T INTELL VEHICL, V4, P425, DOI 10.1109/TIV.2019.2919470
   Chen SC, 2019, IEEE MULTIMEDIA, V26, P5, DOI 10.1109/MMUL.2019.2935397
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Daily M, 2017, COMPUTER, V50, P18, DOI 10.1109/MC.2017.4451204
   Das TK, 2017, INT CONF COMP COMMUN
   Dongjin Han, 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P285
   Fekri-Ershad S, 2017, COMPUT J, V60, P1633, DOI 10.1093/comjnl/bxx033
   Ferryman J M, 1995, P BRIT MACH VIS C 19, DOI [10.5244/c.9.13, DOI 10.5244/C.9.13]
   García-González J, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107950
   Ghazal B, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER ENGINEERING AND THEIR APPLICATIONS (EECEA), P140, DOI 10.1109/EECEA.2016.7470780
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Greenblatt NA, 2016, IEEE SPECTRUM, V53, P46, DOI 10.1109/MSPEC.2016.7419800
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jing Liu, 2020, 2020 International Conference on Virtual Reality and Intelligent Systems (ICVRIS), P200, DOI 10.1109/ICVRIS51417.2020.00053
   Jocher G., 2020, YOLOv5
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Kim JH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182271
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23017, DOI 10.1007/s11042-016-4211-7
   Li Qiu-lin, 2011, Computer Engineering, V37, P172, DOI 10.3969/j.issn.1000-3428.2011.04.062
   Liang HX, 2022, COMPLEX INTELL SYST, V8, P1389, DOI 10.1007/s40747-021-00602-8
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125619
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P391, DOI 10.1109/CIS.2013.89
   Mou LT, 2020, IET INTELL TRANSP SY, V14, P792, DOI 10.1049/iet-its.2019.0419
   Nepal U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020464
   Park K., 2007, INT C IM PROC COMP V
   pyimagesearch, SIMPL OBJ TRACK OPEN
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yang HH, 2018, IET INTELL TRANSP SY, V12, P75, DOI 10.1049/iet-its.2017.0047
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhang YQ, 2015, NEUROCOMPUTING, V168, P454, DOI 10.1016/j.neucom.2015.05.082
   Zhao ZQ, 2019, Arxiv, DOI arXiv:1807.05511
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhu L, 2019, IEEE T INTELL TRANSP, V20, P383, DOI 10.1109/TITS.2018.2815678
NR 52
TC 0
Z9 0
U1 18
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15520-9
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400007
DA 2024-07-18
ER

PT J
AU Ankalaki, S
   Thippeswamy, MN
AF Ankalaki, Shilpa
   Thippeswamy, M. N.
TI A novel optimized parametric hyperbolic tangent swish activation
   function for 1D-CNN: application of sensor-based human activity
   recognition and anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human Activity Recognition; Anomaly Detection; 1D-Convolutional Neural
   Networks; Non-Linearity; Activation Functions; ReLu; LReLu; PReLu;
   SWISH; MISH; LiSHT; OP-Tanish
AB Human activity recognition (HAR) and abnormal / anomaly detection have significant applications for health monitoring in a smart environment. Abnormal / anomaly prediction during daily activities helps to indicate whether the person is healthy or having behavior issues that need assistance. HAR has been accomplished using deep learning approaches. The activation functions employed in deep learning models have a significant impact on the training model and the reliability of the model. Several activation functions are developed for deep learning models. Nevertheless, most existing activation functions suffer from the dying gradient problem and lack of utilization of large negative input values. This work proposes a novel activation function called Optimized Parametric Hyperbolic Tangent Swish (OP-Tanish), which is non-monotonicity, unbounded in both negative and positive directions, smooth variations, and introduces a higher degree of non-linearity than Relu and other state-of-art activation functions. We test this activation function by training on customized shallow 1D- Convolutional Neural Networks (CS1DCNN) for adequate recognition of human activities and anomaly detection. The contributions are compared to the state-of-the-art activation functions on benchmark datasets (UCI-HAR, PAMPA2, Opportunity, and Daphnet Gait HAR datasets; UP-FALL and Simulated Activities of Daily Living (SIMADL) anomaly datasets), namely: ReLu and its variants, SWISH, MISH, and LiSHT. The proposed OP-Tanish activation function outperforms other state-of-art activation functions with an accuracy of 99.58%, 99.58%, 95.14%, and 97.79%over UCI, Opportunity, PAMPA2, and Daphnet Gait datasets, respectively, and achieved an accuracy of 97.28% and 98% on UP-Fall and SIMADL dataset.
C1 [Ankalaki, Shilpa] Manipal Acad Higher Educ MAHE, Dept Comp Sci & Engn, Manipal Inst Technol Bengaluru, Udupi 576104, India.
   [Thippeswamy, M. N.] Ramaiah Inst Technol, Dept Comp Sci & Engn AI&ML, Bangalore 560054, Karnataka, India.
   [Thippeswamy, M. N.] Ramaiah Inst Technol, Dept Comp Sci & Engn Cyber Secur, Bangalore 560054, Karnataka, India.
C3 Manipal Academy of Higher Education (MAHE); Ramaiah Institute of
   Technology; Ramaiah Institute of Technology
RP Ankalaki, S (corresponding author), Manipal Acad Higher Educ MAHE, Dept Comp Sci & Engn, Manipal Inst Technol Bengaluru, Udupi 576104, India.
EM shilpaa336@gmail.com; mntswamy@gmail.com
RI Ankalaki, Shilpa/ABE-1585-2020
OI Ankalaki, Shilpa/0000-0002-4652-7292
CR Aghdam H. H., 2017, Guide to Convolutional Neural Networks: A Practical Application to Traffic-Sign Detection and Classification, DOI DOI 10.1007/978-3-319-57550-6
   Alaghbari KA, 2022, IEEE ACCESS, V10, P28219, DOI 10.1109/ACCESS.2022.3157726
   Alshammari T, 2018, DATA, V3, DOI 10.3390/data3020011
   Anagun Y, 2022, Arxiv, DOI [arXiv:2210.09083, 10.48550/arXiv.2210.09083, DOI 10.48550/ARXIV.2210.09083]
   Anguita D, 2013, J UNIVERS COMPUT SCI, V19, P1295
   Anguita Davide, 2012, INT WORKSH AMB ASS L, V2012, P216, DOI DOI 10.1007/978-3-642-35395-6_30
   Anh Nguyen, 2021, 2021 International Conference on System Science and Engineering (ICSSE), P215, DOI 10.1109/ICSSE52999.2021.9538437
   Bächlin M, 2010, IEEE T INF TECHNOL B, V14, P436, DOI 10.1109/TITB.2009.2036165
   Bhat G, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358175
   Bhuiyan RA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236990
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Datta L., 2020, ARXIV
   De-La-Hoz-Franco E, 2018, IEEE ACCESS, V6, P59192, DOI 10.1109/ACCESS.2018.2873502
   Fahad LG, 2021, NEUROCOMPUTING, V423, P362, DOI 10.1016/j.neucom.2020.10.102
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grover A, 2019, THESIS SAN JOSE STAT
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Hung YX, 2010, LECT NOTES COMPUT SC, V6159, P186, DOI 10.1007/978-3-642-13778-5_23
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Irvine N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010216
   Ordóñez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kingma D. P., 2017, INT C LEARN REPR SAN, DOI DOI 10.48550/ARXIV.1412.6980
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Le Q, 2012, FUTURE INTERNET, V4, P607, DOI 10.3390/fi4020607
   Liangying Peng, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214277
   Lv TQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071871
   Maas A.L., 2013, INT C MACH LEARN ATL
   Martínez-Villaseñor L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091988
   Masiala S, 2019, Arxiv, DOI arXiv:1909.03428
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nguyen HD, 2019, Arxiv, DOI [arXiv:1905.03809, 10.48550/arXiv.1905.03809]
   Omar S., 2013, Int. J. Comput. Appl., V79, DOI DOI 10.5120/13715-1478
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Palaniappan A., 2012, 2012 International Conference on Recent Trends in Information Technology (ICRTIT), P97, DOI 10.1109/ICRTIT.2012.6206829
   Plotz N. Y., 2011, P INT C ART INT IJCA, V2, P1729
   Qian HW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5614
   Rakitianskaia A, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1423, DOI 10.1109/SSCI.2015.202
   Ramachandran P., 2017, Searching for activation functions
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Reiss A., 2012, P 5 INT C PERV TECHN, P1, DOI [10.1145/2413097.2413148, DOI 10.1145/2413097.2413148]
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Roy Swalpa Kumar, 2023, Computer Vision and Image Processing: 7th International Conference, CVIP 2022, Revised Selected Papers. Communications in Computer and Information Science (1776), P462, DOI 10.1007/978-3-031-31407-0_35
   Sagha H, 2011, IEEE SYS MAN CYBERN, P36, DOI 10.1109/ICSMC.2011.6083628
   Schrader L, 2020, J POPUL AGEING, V13, P139, DOI 10.1007/s12062-020-09260-z
   Shin JH, 2011, IEEE T INF TECHNOL B, V15, P438, DOI 10.1109/TITB.2011.2113352
   Shreyas D. G., 2020, SN Computer Science, V1, P1, DOI DOI 10.1007/S42979-020-00169-0
   Suárez-Paniagua V, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2195-1
   Sun J, 2018, J SENSORS, V2018, DOI 10.1155/2018/8580959
   Suto J, 2020, NEURAL COMPUT APPL, V32, P15673, DOI 10.1007/s00521-018-3437-x
   Wada S., 2021, SN COMPUT SCI, V2, P1, DOI DOI 10.1007/S42979-020-00418-2
   Xu B, 2016, Arxiv, DOI arXiv:1602.05980
   Xu L, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P548, DOI 10.1109/FSKD.2017.8393329
   Yang Z, 2018, IEEE ACCESS, V6, P56750, DOI 10.1109/ACCESS.2018.2873315
   Zeng M, 2018, ARXIV181004038V1CSLG, P1
   Zerkouk M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082359
   Zhang G, 2018, ADV FUNCT MATER, V28, DOI 10.1002/adfm.201706462
   Zhu QY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082950
NR 61
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15766-3
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400007
DA 2024-07-18
ER

PT J
AU Singh, AK
   Acharya, K
   Mukhopadhyay, S
AF Singh, Amit Kumar
   Acharya, Kamalesh
   Mukhopadhyay, Sourav
TI Post-quantum secure recipient revocable broadcast encryption supporting
   anonymity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adaptive security; k-LWE; Chosen plaintext attack; Recipient revocable
   broadcast encryption
ID PRIVACY; CIPHERTEXTS
AB Recipient revocable broadcast encryption (RRevocBE), introduced by Susilo et al. is a cryptographic primitive which allows public revocation of users from encrypted message without decrypting it therefore with the help of RRevocBE we can revoke some users without knowledge of plaintext. We have proposed the first k-LWE based RRevocBE which is secure against post-quantum attack. All the existing similar constructions are bilinear pairing based. Hence, these are not secure in post-quantum cryptographic world. Moreover, our scheme achieves anonymity by concealing the user indices at the time of decryption. Further, it is adaptive secure and does not use random oracles in security proof. More interestingly, the secret key and ciphertext consists of single vector of size m + 1 where m is an integer. We also implemented this post quantum secure RRevocBE construction and achieved reasonable computation time which are given in Table 1. For 128 bit of security we have to select n = 320, log2(p) = 18.85, a = .0001 and m = 681. We computed the running time complexity of RRevocBE in terms of encryption, revoke and decryption time for 128-bit security level. We employed SageMath (version 9.2) for implementation with a workstation comprising an Intel Core i9 1.60 GHz processor with 64-bit Linux Lite (v 5.2) operating system. Results are documented in Table 1.
C1 [Singh, Amit Kumar; Mukhopadhyay, Sourav] IIT Kharagpur, Dept Math, Kharagpur 721302, India.
   [Acharya, Kamalesh] VIT Chennai, Sch Adv Sci, Dept Math, Chennai 600127, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Vellore Institute of Technology (VIT); VIT
   Chennai
RP Singh, AK (corresponding author), IIT Kharagpur, Dept Math, Kharagpur 721302, India.
EM amitmintu01991@gmail.com; kamaleshiitkgp@gmail.com;
   sourav@maths.iitkgp.ac.in
OI Singh, Amit Kumar/0000-0003-0797-7255
CR Acharya K, 2017, INT C INF SEC CRYPT, P191
   Acharya K, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102436
   Acharya K, 2017, LECT NOTES COMPUT SC, V10592, P329, DOI 10.1007/978-3-319-68637-0_20
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Alwen J, 2009, GENERATING SHORTER B
   [Anonymous], 2015, SECURITY LWE BASED C
   Barth A, 2006, LECT NOTES COMPUT SC, V4107, P52
   Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D, 2017, ALGORITHMICA, V79, P1233, DOI 10.1007/s00453-016-0242-8
   Boneh D, 2014, LECT NOTES COMPUT SC, V8616, P206, DOI 10.1007/978-3-662-44371-2_12
   Delerablée C, 2007, LECT NOTES COMPUT SC, V4833, P200
   Do XT, 2020, LECT NOTES COMPUT SC, V12147, P145, DOI 10.1007/978-3-030-57878-7_8
   Fazio N, 2012, LECT NOTES COMPUT SC, V7293, P225, DOI 10.1007/978-3-642-30057-8_14
   Fiat A., 1993, LECT NOTES COMPUTER, P480, DOI DOI 10.1007/3-540-48329-2
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Jianchang Lai, 2016, Information Security and Privacy. 21st Australasian Conference, ACISP 2016. Proceedings: LNCS 9723, P223, DOI 10.1007/978-3-319-40367-0_14
   Lai JC, 2017, COMPUT J, V60, P1809, DOI 10.1093/comjnl/bxx060
   Lai JC, 2017, PERS UBIQUIT COMPUT, V21, P855, DOI 10.1007/s00779-017-1045-x
   Libert B, 2012, LECT NOTES COMPUT SC, V7293, P206, DOI 10.1007/978-3-642-30057-8_13
   Ling S, 2014, LECT NOTES COMPUT SC, V8616, P315, DOI 10.1007/978-3-662-44371-2_18
   Regev Oded, 2005, P 37 ACM STOC, P84, DOI [DOI 10.1145/1568318.1568324, 10.1145/1060590.1060603, DOI 10.1145/1060590.1060603, 10.1145/1568318.1568324]
   SHOR PW, 1994, AN S FDN CO, P124
   Susilo W, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P201, DOI 10.1145/2897845.2897848
   Xingwen Zhao, 2013, Applied Mechanics and Materials, V427-429, P2163, DOI 10.4028/www.scientific.net/AMM.427-429.2163
NR 24
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15435-5
EA MAY 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900004
DA 2024-07-18
ER

PT J
AU Tagore, NK
   Medi, PR
   Chattopadhyay, P
AF Tagore, Nirbhay Kumar
   Medi, Prathistith Raj
   Chattopadhyay, Pratik
TI Deep pixel regeneration for occlusion reconstruction in person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person re-identification; Generative modeling; Occlusion detection and
   reconstruction; Conv-LSTM; DCGAN; Autoencoder; Siamese network
ID TRACKING
AB Person re-identification is very important for monitoring and tracking crowd movement to provide public security. However, re-identification in the presence of occlusion is a challenging area that has not received significant attention yet. In this work, we propose a plausible solution to this problem by developing effective techniques for occlusion detection and reconstruction from RGB images/videos using Deep Neural Networks. Specifically, a CNN-based occlusion detection model is used to detect the occluded frames in an input sequence, following which a Conv-LSTM model or an Autoencoder is employed to reconstruct the pixels corresponding to the occluded regions depending on whether the input frames are sequential or non-sequential. The quality of the reconstructed RGB frames is further refined using a DCGAN. Our method has been evaluated using four public data sets for cumulative rank-based accuracy and Dice score, and the qualitative reconstruction results are indeed appealing. Quantitative evaluation in terms of re-identification accuracy using a Siamese classifier shows a Rank-1 accuracy of over 70% after reconstructing the occlusion present in each of these datasets. A comparative study with popular state-of-the-art approaches also demonstrates the effectiveness of our work for use in real-life surveillance sites.
C1 [Tagore, Nirbhay Kumar] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida 221310, India.
   [Medi, Prathistith Raj] Int Inst Informat Technol, Dept Data Sci & Artificial Intelligence, Naya Raipur 493661, Chhattisgarh, India.
   [Chattopadhyay, Pratik] Indian Inst Technol BHU, Dept Comp Sci & Engn, Pattern Recognit Lab, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Tagore, NK (corresponding author), Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida 221310, India.
EM nirbhaykrtag.rs.cse17@iitbhu.ac.in; prathistith19102@iiitnr.edu.in;
   pratik.cse@iitbhu.ac.in
FU SERB, DST [CRG/2020/005465]
FX AcknowledgementsThe authors would also like to thank SERB, DST for
   partially supporting this work through project grant (CRG/2020/005465)
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2016, Adv. NeuralInf. Process. Syst.
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalvi C, 2021, IEEE ACCESS, V9, P165806, DOI 10.1109/ACCESS.2021.3131733
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge YX, 2018, Arxiv, DOI arXiv:1810.02936
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jiang KZ, 2020, IEEE T IMAGE PROCESS, V29, P8549, DOI 10.1109/TIP.2020.3016869
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lingxiao He, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P357, DOI 10.1007/978-3-030-58604-1_22
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Liu YC, 2019, IEEE IMAGE PROC, P3322, DOI [10.1109/ICIP.2019.8803471, 10.1109/icip.2019.8803471]
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Minetto R, 2019, IEEE T GEOSCI REMOTE, V57, P6530, DOI 10.1109/TGRS.2019.2906883
   Prosser Bryan James, 2008, P BMVC, V8, P74
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shi XJ, 2015, ADV NEUR IN, V28
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tagore NK, 2022, SIGNAL IMAGE VIDEO P, V16, P1071, DOI 10.1007/s11760-021-02056-4
   Tagore NK, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103029
   Tagore NK, 2020, PROCEEDINGS OF THE 17TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS - DCNET, OPTICS, SIGMAP AND WINSYS (ICETE), VOL 2, P103, DOI 10.5220/0009885001030112
   Tagore NK, 2020, MULTIMED TOOLS APPL, V79, P28393, DOI 10.1007/s11042-020-09398-0
   Teyou GKD, 2020, TACKLING CLIMATE CHA
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang Z., 2022, P IEEE CVF C COMP VI, P4754
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu FR, 2022, IEEE T CYBERNETICS, V52, P11014, DOI 10.1109/TCYB.2021.3105970
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11855, DOI 10.1109/ICCV48922.2021.01166
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Ye M, 2021, IEEE T PAMI
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zhou K, 2021, IEEE T PAMI
   Zhou SR, 2020, PATTERN RECOGN LETT, V138, P617, DOI 10.1016/j.patrec.2020.09.009
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhuo JX, 2019, Arxiv, DOI arXiv:1907.03253
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 71
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15322-z
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900005
DA 2024-07-18
ER

PT J
AU Neji, H
   Ben Halima, M
   Nogueras-Iso, J
   Hamdani, TM
   Qahtani, AM
   Almutiry, O
   Dhahri, H
   Alimi, AM
AF Neji, Hala
   Ben Halima, Mohamed
   Nogueras-Iso, Javier
   Hamdani, Tarek M.
   Qahtani, Abdulrahman M.
   Almutiry, Omar
   Dhahri, Habib
   Alimi, Adel M.
TI Deep architecture for super-resolution and deblurring of text images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image super-resolution; Image deblurring; Image enhancement; Deep CNN
ID QUALITY ASSESSMENT; INFORMATION; PIXEL; GAN
AB Image deblurring and super resolution attempts to restore images that have been degraded. We propose a joint technique for super resolution and deblurring to solve the problem of blur and low resolution in text images. This joint technique is based on the use of a Deep Convolutional Neural Network (Deep CNN). Deep CNN has achieved promising performance for single image super-resolution. In particular, the Deep CNN skip Connection and Network in Network (DCSCN) architecture has been successfully applied to natural images super-resolution. In this work we propose a model that jointly performs super-resolution and deblurring of low-resolution blurry text images based on DCSCN. Our model uses subsampled blurry images in the input and original sharp images as ground truth. The proposed architecture consists of a higher number of filters in the input CNN layer to a better analysis of the text details. The experimental results have achieved state-of-the-art performance in the peak-signal-to-noise ratio (PSNR), the structural similarity index measure (SSIM), the information fidelity criterion (IFC) and Visual Information Fidelity (VIF) metrics. Thus, we confirm that DCSCN provides satisfactory results for enhancement tasks on low blurry images. The quantitative and qualitative evaluation on different datasets proves the high performance of our model to reconstruct high-resolution and sharp text images with PSNR= 20.406, SSIM= 0.877, VIF= 0.351, IFC= 2.868 for scale 4 compared to DCSCN with PSNR= 15.553, SSIM= 0.621, VIF= 0.166 IFC= 1.129. In addition, in terms of computational time, our proposed method gives competitive performance compared to state-of-the-art methods.
C1 [Neji, Hala] Univ Gabes, Natl Engn Sch Gabes ENIG, Gabes, Tunisia.
   [Ben Halima, Mohamed; Hamdani, Tarek M.; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Lab, Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
   [Nogueras-Iso, Javier] Univ Zaragoza, Aragon Inst Engn Res I3A, Zaragoza, Spain.
   [Qahtani, Abdulrahman M.] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 11099, Taif 21944, Saudi Arabia.
   [Almutiry, Omar; Dhahri, Habib] King Saud Univ, Coll Appl Comp Sci, Riyadh, Saudi Arabia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Gabes; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS); University of Zaragoza; Taif University; King Saud
   University; University of Johannesburg
RP Neji, H (corresponding author), Univ Gabes, Natl Engn Sch Gabes ENIG, Gabes, Tunisia.
EM hala.neji@enis.tn
RI Hamdani, Tarek M./E-9986-2013; Alimi, Adel M./A-5697-2012; Dhahri,
   Habib/L-7833-2018; BenHalima, Mohamed/AAD-4725-2021
OI Hamdani, Tarek M./0000-0002-8243-6056; Alimi, Adel
   M./0000-0002-0642-3384; BenHalima, Mohamed/0000-0002-3224-2552; NEJI,
   HALA/0000-0003-3595-005X
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]; Spanish Regional Government of Aragon [T5923R]; Spanish
   Ministry of Science and Innovation [PID2020-113353RB-I00]; Taif
   University, Taif, Saudi Arabia [TURSP-2020/327]
FX The research leading to these results has been partially supported by
   the Ministry of Higher Education and Scientific Research of Tunisia
   under the grant agreement number LR11ES48, the Spanish Regional
   Government of Aragon (project T5923R), and the Spanish Ministry of
   Science and Innovation (project PID2020-113353RB-I00). We deeply
   acknowledge Taif University for Supporting this study through Taif
   University Researchers Supporting Project number (TURSP-2020/327), Taif
   University, Taif, Saudi Arabia.
CR Albluwi F, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8903000
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2015, P BMVC, DOI DOI 10.5244/C.29.6
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal S, 2022, INTELLIGENT SUSTAINA, P723
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Du B, 2019, P 2019 8 INT C COMP, P266
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Li Y, 2019, LECT NOTES COMPUT SC, V11542, P395, DOI 10.1007/978-3-030-22514-8_36
   Liang ZW, 2019, IEEE INT CON MULTI, P790, DOI 10.1109/ICME.2019.00141
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu H, 2020, J REAL-TIME IMAGE PR, V17, P1787, DOI 10.1007/s11554-020-00976-x
   Ljubenovic M, 2017, PROC INT CONF DOC, P721, DOI 10.1109/ICDAR.2017.123
   Lumentut JS, 2020, PROC SPIE, V11515, DOI 10.1117/12.2566962
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Neji H, 2021, INT J COMPUT INT SYS, V14, P1315, DOI 10.2991/ijcis.d.210407.001
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Quan YH, 2020, IEEE T COMPUT IMAG, V6, P778, DOI 10.1109/TCI.2020.2981758
   Ren, 2019, P INT C VID SIGN IM, P70
   Shafiei F, 2020, TRAIT SIGNAL, V37, P1029, DOI 10.18280/ts.370615
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tran HTM, 2019, IEEE RIVF INT CONF, P290, DOI 10.1109/rivf.2019.8713657
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36
   Yamanaka J, 2017, LECT NOTES COMPUT SC, V10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Yang CH, 2020, INT CONF ACOUST SPEE, P1623, DOI [10.1109/ICASSP40776.2020.9053784, 10.1109/icassp40776.2020.9053784]
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yun JU, 2020, IEEE ACCESS, V8, P159661, DOI 10.1109/ACCESS.2020.3020729
   Zeng K, 2018, INT C PATT RECOG, P507, DOI 10.1109/ICPR.2018.8545207
   Zhang HC, 2010, LECT NOTES COMPUT SC, V6313, P566
   Zhang X, 2018, BRIT MACHINE VISION
   Zhang XY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1448, DOI 10.1109/ICASSP.2018.8462601
NR 43
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15340-x
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400007
DA 2024-07-18
ER

PT J
AU Jena, B
   Naik, MK
   Panda, R
   Abraham, A
AF Jena, Bibekananda
   Naik, Manoj Kumar
   Panda, Rutuparna
   Abraham, Ajith
TI Exponential entropy-based multilevel thresholding using enhanced
   barnacle mating optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Exponential entropy; Optimal multilevel thresholding; Barnacle mating
   optimization
ID CUCKOO SEARCH ALGORITHM; BIO-INSPIRED OPTIMIZER; FORAGING OPTIMIZATION;
   EVOLUTIONARY ALGORITHMS; DIFFERENTIAL EVOLUTION; IMAGE SEGMENTATION;
   TSALLIS
AB Multilevel Thresholding (MLT) is a prominent image segmentation research field that can effectively handle problems encountered while collecting meaningful information from a digital image. Most of the existing entropy-based Multilevel thresholding approaches use the logarithmic behaviour of Shannon's entropy, which does not exist for all possible points with appropriate bounded value. To evade this problem, an entropy-based on exponential information gain function is introduced as the fitness function in this paper to improve the thresholding accuracy. This research also proposes an enhanced Barnacle Mating optimization algorithm (EBMO) for obtaining appropriate threshold values by maximising the fitness function. The enhancement over basic Barnacle mating optimization is achieved by incorporating an additional Gaussian mutation strategy and a random flow towards the best solution steps with the original algorithm. The involvement of these additional steps helps the algorithm to prevent it to be stagnated at a local minimum by boosting its exploration capability. To validate the proposed optimization algorithm, it has been tested with a set of well-known benchmark functions and the CEC 2014 test suite. The results obtained in various tests are then compared with other standard and state-of-art algorithms with the help of quantitative analysis such as average, median, and standard deviation of the fitness values over several runs, qualitative analysis, such as search history, trajectory, and average fitness history and statistical analysis using Friedman Rank test and found superior to all. A more detailed analysis of the obtained results was also conducted using post hoc Bonferroni-Dunn and Holm test to observe how the proposed EBMO algorithm is significantly different from others. A comparison of the proposed exponential entropy (EE) based multilevel thresholding using EBMO (EBMO-EE) with other optimization algorithms also presented. Various performance measures such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), feature similarity index (FSIM), and Uniformity Measures (UM) obtained from different standard benchmark images of varying dimension are considered. It has been observed that there is an improvement of the thresholding accuracy, using EBMO, about 2% to 4% over others.
C1 [Jena, Bibekananda] Anil Neerukonda Inst Technol & Sci, Dept Elect & Commun Engn, Visakhapatnam 531162, Andhra Prades, India.
   [Naik, Manoj Kumar] Siksha O Anusandhan, Fac Engn & Technol, Bhubaneswar 751030, Odisha, India.
   [Panda, Rutuparna] Veer Surendra Sai Univ Technol, Dept Elect & Telecommun Engn, Burla 768018, Odisha, India.
   [Abraham, Ajith] FLAME Univ, Fac Comp & Data Sci, Pune 412115, Maharashtra, India.
C3 Siksha 'O' Anusandhan University; Veer Surendra Sai University of
   Technology
RP Naik, MK (corresponding author), Siksha O Anusandhan, Fac Engn & Technol, Bhubaneswar 751030, Odisha, India.
EM bibekananda.jena@gmail.com; naik.manoj.kumar@gmail.com;
   r_ppanda@yahoo.co.in; ajith.abraham@ieee.org
RI Panda, Rutuparna/AAA-3214-2021; University, FLAME/HSG-7860-2023;
   Abraham, Ajith/A-1416-2008; Naik, Manoj Kumar/O-2982-2017
OI Panda, Rutuparna/0000-0002-8676-0144; University,
   FLAME/0009-0003-3435-6187; Abraham, Ajith/0000-0002-0169-6738; Naik,
   Manoj Kumar/0000-0002-8077-1811; Jena, Bibekananda/0000-0003-1675-6120
CR Abd Elaziz M, 2021, MULTIMED TOOLS APPL
   Abdel-Basset M, 2021, NEURAL COMPUT APPL, V33, P10685, DOI 10.1007/s00521-020-04820-y
   Agrawal S., 2020, NEW HYBRID ADAPTIVE
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Ameur M, 2019, MULTIMED TOOLS APPL, V78, P34353, DOI 10.1007/s11042-019-08133-8
   [Anonymous], LANDSAT IMAGE GALLER
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bäck T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1
   Bakhshali MA, 2014, J COMPUT SCI-NETH, V5, P251, DOI 10.1016/j.jocs.2013.07.001
   Chouksey M, 2020, MULTIMED TOOLS APPL, V79, P19075, DOI 10.1007/s11042-019-08138-3
   Das S, 2009, STUD COMPUT INTELL, V203, P23, DOI 10.1007/978-3-642-01085-9_2
   de Oliveira PV, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P380, DOI 10.1109/ICDSBA.2018.00078
   Dhieb M, 2016, 2016 IEEE ACS 13 INT, P1
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Feng YC, 2017, DIGIT SIGNAL PROCESS, V60, P186, DOI 10.1016/j.dsp.2016.08.003
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GUO SW, 1992, BIOMETRICS, V48, P361, DOI 10.2307/2532296
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hoang N, 2020, DTU J SCI TECHNOLOGY
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   HOLM S, 1979, SCAND J STAT, V6, P65
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Jain M, 2019, SWARM EVOL COMPUT, V44, P148, DOI 10.1016/j.swevo.2018.02.013
   Jena B, 2019, P 2019 INT C APPL MA
   Jia HM, 2019, IEEE ACCESS, V7, P44097, DOI 10.1109/ACCESS.2019.2908718
   Jizba P, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026128
   Johari Nur Farahlina, 2013, Applied Mechanics and Materials, V421, P512, DOI 10.4028/www.scientific.net/AMM.421.512
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Kumar SN, 2020, COMPUT INTELL-US, P231, DOI [10.1515/9783110671353-014, DOI 10.1515/9783110671353-014]
   Li LG, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/3295769
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Liang HN, 2019, IEEE ACCESS, V7, P11258, DOI 10.1109/ACCESS.2019.2891673
   Lianqing Ji, 2013, 2013 IEEE International Wireless Symposium (IWS), DOI 10.1109/IEEE-IWS.2013.6616806
   Liu SH, 2013, APPL SOFT COMPUT, V13, P3792, DOI 10.1016/j.asoc.2013.05.010
   Liu YY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186343
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Moghdani R, 2018, APPL SOFT COMPUT, V64, P161, DOI 10.1016/j.asoc.2017.11.043
   Naik MK, 2022, J KING SAUD UNIV-COM, V34, P4524, DOI 10.1016/j.jksuci.2020.10.030
   Naik MK, 2021, MULTIMED TOOLS APPL, V80, P35543, DOI 10.1007/s11042-020-10467-7
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   Otsu N., 1979, IEEE T SYST MAN CYB, VC, P62, DOI DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079
   PAL NR, 1989, IEE PROC-E, V136, P284, DOI 10.1049/ip-e.1989.0039
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panda R, 2013, EXPERT SYST APPL, V40, P7617, DOI 10.1016/j.eswa.2013.07.060
   Piotrowski AP, 2018, INFORM SCIENCES, V468, P117, DOI 10.1016/j.ins.2018.08.030
   Raja NSM, 2015, PROCEDIA COMPUT SCI, V48, P524, DOI 10.1016/j.procs.2015.04.130
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Reddy GT, 2022, MULTIMED TOOLS APPL, V81, P41429, DOI 10.1007/s11042-020-09988-y
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sarkar S, 2013, IEEE T IMAGE PROCESS, V22, P4788, DOI 10.1109/TIP.2013.2277832
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Singh S, 2020, NEURAL COMPUT APPL, V32, P16681, DOI 10.1007/s00521-020-04989-2
   Suganthan Ponnuthurai Nagaratnam, 2012, Theory and Practice of Natural Computing. Proceedings of the First International Conference, TPNC 2012, P30, DOI 10.1007/978-3-642-33860-1_4
   Sulaiman MH, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103330
   Sun GY, 2016, APPL SOFT COMPUT, V46, P703, DOI 10.1016/j.asoc.2016.01.054
   Sun M, 2020, MULTIMED TOOLS APPL, V79, P34993, DOI 10.1007/s11042-020-08931-5
   Dang VH, 2019, GENET PROGRAM EVOL M, V20, P479, DOI 10.1007/s10710-019-09357-1
   Wang Z., 2017, CAN J CIVIL ENG, V44, P253, DOI [10.1139/cjce-2016-0381, DOI 10.1139/CJCE-2016-0381]
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wunnava A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103836
   Zar J.H, 2010, Biostatistical Analysis
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
NR 85
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15668-4
EA MAY 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600006
DA 2024-07-18
ER

PT J
AU Prashanti, G
   Bhat, MN
AF Prashanti, Guttikonda
   Bhat, Mundukur Nirupama
TI Cheating identifiable polynomial based secret sharing scheme for audio
   and image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Polynomial; Secret sharing; Polynomial function; Coefficients; Discrete
   logarithms; Security channel; Verification; Dishonest participant; Multi
   secret; Encoding; Decoding
ID PRIVACY; STEGANOGRAPHY
AB Polynomial based secret sharing is the art of protecting information and a tool used in areas where a secret has to be distributed among multiple parties. In this method, secret is encrypted into noisy shares and transferred to participants in the group. Decoding of secret is possible only when sufficient number of authorized members in the group, stack their respective shares. In this article, polynomial based secret sharing for audio is proposed that computes a checksum to identify the dishonest participant and also the audio shares generated are of smaller dimension. To achieve this, a polynomial function is defined by considering amplitude values and random values as coefficients. Inclusion of random value as the coefficient of higher degree term in the polynomial makes the audio shares noisy and does not provide any information about the secret. This reduces the overhead of performing preprocessing on original audio before shares are generated. In addition, our proposed method can be used for multi secret sharing. Proposed scheme also facilitates identification of dishonest participant before reconstruction of secret through a trusted entity called combiner.
C1 [Prashanti, Guttikonda; Bhat, Mundukur Nirupama] Vignans Fdn Sci Technol & Res, Vadlamudi, Andhra Prades, India.
   [Prashanti, Guttikonda] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Koneru
   Lakshmaiah Education Foundation (K L Deemed to be University)
RP Prashanti, G (corresponding author), Vignans Fdn Sci Technol & Res, Vadlamudi, Andhra Prades, India.; Prashanti, G (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
EM prashantiguttikonda77@gmail.com
RI Guttikonda, Prashanti/KIC-5953-2024
CR Abdelfatah RI, 2020, IEEE ACCESS, V8, P69894, DOI 10.1109/ACCESS.2020.2987197
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Bu L, 2019, AD HOC NETW, V92, DOI 10.1016/j.adhoc.2018.09.007
   Cha J, 2021, J INF SECUR APPL, V57, DOI 10.1016/j.jisa.2020.102686
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Guttikonda Prashanti, 2020, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V101, P609, DOI 10.1007/s40031-020-00475-4
   Harn L, 2015, J INF SECUR APPL, V23, P1, DOI 10.1016/j.jisa.2015.07.001
   Hu WT, 2021, MULTIMED TOOLS APPL, V80, P28731, DOI 10.1007/s11042-021-11104-7
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   Kandar S, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102430
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Lakshmi VS, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102869
   Li H, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.507
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, 2003, OPT ENG, V42, P2340, DOI 10.1117/1.1588661
   Ma Z, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00529-z
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Parakh A, 2011, INFORM SCIENCES, V181, P335, DOI 10.1016/j.ins.2010.09.013
   Phiri KK., 2018, INT J APPL ENG RES, V13, P11600
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen J, 2020, FUTURE GENER COMP SY, V109, P450, DOI 10.1016/j.future.2018.10.049
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P11101, DOI [10.1007/s11042-017-5240-6, 10.1007/a11042-017-5240-6]
   Socek D., 2005, 2005 IEEE International Conference on Electro Information Technology (IEEE Cat. No. 05EX1098C)
   Wang N, 2018, INFORM SCIENCES, V444, P105, DOI 10.1016/j.ins.2018.02.064
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Xie D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168674
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yvo D, 1998, AUDIO OPTICAL CRYPTO, V1514, P392
   Zhang E, 2021, INFORM SCIENCES, V546, P166, DOI 10.1016/j.ins.2020.07.032
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 32
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15625-1
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100014
DA 2024-07-18
ER

PT J
AU Adu, K
   Walker, J
   Mensah, PK
   Ayidzoe, MA
   Opoku, M
   Boateng, S
AF Adu, Kwabena
   Walker, Joojo
   Mensah, Patrick Kwabena
   Ayidzoe, Mighty Abra
   Opoku, Michael
   Boateng, Samuel
TI SqueezeCapsNet: enhancing capsule networks with squeezenet for holistic
   medical and complex images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Capsule networks; Image processing; Medical
   images; Squeeze network
AB Early diagnosis of patients' disease is crucial since it helps doctors and patients devise a treatment plan. Therefore, recognizing medical images using Artificial intelligence-based deep learning techniques has recently increased. Capsule Network (CapsNet) has promising methods in visual tasks due to its ability to keep a high relationship of spatial information compared to convolutional neural networks (CNNs). However, CapsNet faces a critical problem with a complex image background that limits its performance. The traditional CapsNet adopts a standalone convolution (SC) as a feature extractor, Softmax function for normalization of coupling coefficient, and dynamic routing procedure to allow active capsules to perform predictions leading to activation of high-level capsules. The SC is not an effective feature extractor, and SoftMax impedes capsules from distributing optimal coupling coefficient during routing. This paper proposes a CapsNet architecture called SqueezeCapsNet that integrates SqueezeNet and CapsNet to achieve effective feature extraction and fewer parameters. A new squash function named parametric squash function (PSF) was proposed to reduce non-informative capsules and promote discriminative capsules. To the best of our knowledge in literature, we are the first to integrate SqueezeNet into CapsNet. We evaluate our framework on two medical image datasets; Brain tumor and Lung & Colon cancer datasets. Additionally, datasets with varied backgrounds; MNIST, fashion-MNIST, CIFAR-10 were used to evaluate the robustness and generalizability of the model. The SqueezeCapsNet produces 94.85%, 99.76%, 99.87%, 93.49%, and 82.45% on Brain tumor, Lung & Colon Cancer, MNIST, fashion-MNIST, and CIFAR-10 datasets, respectively. Experimental results show that the proposed architecture's compression techniques significantly provide fewer parameters while enhancing stability and accuracy across all the evaluation metrics. Our results show that our method improves CapsNet and can be adopted as a computer-aided diagnostic method to support the diagnosis of medical image tasks.
C1 [Adu, Kwabena; Mensah, Patrick Kwabena; Ayidzoe, Mighty Abra; Opoku, Michael; Boateng, Samuel] Univ Energy & Nat Resources, Dept Comp Sci & Informat, Sunyani 00233, Ghana.
   [Walker, Joojo] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Adu, K (corresponding author), Univ Energy & Nat Resources, Dept Comp Sci & Informat, Sunyani 00233, Ghana.
EM kwabena.adu@uenr.edu.gh; joojokojododzi@gmail.com;
   patrick.mensah@uenr.edu.gh; mighy.ayidzoe@uenr.edu.gh;
   michael.opoku@uenr.edu.gh; samuel.boateng@uenr.edu.gh
RI Boateng, Samuel/AAX-5135-2021
OI Boateng, Samuel/0000-0002-0307-3286
CR Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Ahmed Karim., 2019, Advances in Neural Information Processing Systems
   Amer M, 2020, NEURAL PROCESS LETT, V52, P545, DOI 10.1007/s11063-020-10273-0
   [Anonymous], 2017, INT C LEARN REPR
   Bhamidi BS, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P557, DOI [10.1109/UEMCON47517.2019.8993019, 10.1109/uemcon47517.2019.8993019]
   Bing S., 2017, Capsule Network Performance on Complex Data, V10707, P1
   Borkent A, 2019, AM MUS NOVIT, P1
   Chang SW, 2020, IEEE ACCESS, V8, P79876, DOI 10.1109/ACCESS.2020.2990700
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Deborshi R, 2019, APPL CAPSULE NETWORK
   do Rosario VM, 2019, INT SYM COMP ARCHIT, P152, DOI 10.1109/SBAC-PAD.2019.00034
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Hahn T., 2019, ADV NEURAL INFORM PR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2011, LECT NOTES COMPUTER, DOI [10.1007/978-3-642-21735-7_6, DOI 10.1007/978-3-642-21735-7_6]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Nguyen HP, 2019, LECT NOTES COMPUT SC, V11727, P166, DOI 10.1007/978-3-030-30487-4_14
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jia BH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030884
   Karimpour S., 2020, E2 CAPSULE NEURAL NE, V15, P1, DOI 10.30482/jhyd.2020.211670.1425
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2018, LECT NOTES COMPUT SC, V10882, P546, DOI 10.1007/978-3-319-93000-8_62
   Kwabena PM, 2022, J KING SAUD UNIV-COM, V34, P2574, DOI 10.1016/j.jksuci.2020.10.006
   Li HY, 2018, LECT NOTES COMPUT SC, V11215, P266, DOI 10.1007/978-3-030-01252-6_16
   Mandal B., 2019, 2019 2 INT C ADV COM, P1, DOI [10.1109/ICACCP.2019.8883020, DOI 10.1109/ICACCP.2019.8883020]
   Paik I, 2019, ARXIV
   Phaye SSR, 2019, LNCS, V11365
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Rajpurkar Pranav, 2017, ARXIV170701836
   Ren H, 2019, ARXIV
   Sabour S, 2017, ADV NEUR IN, V30
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vimal Kurup R, 2020, P INT C INT COMP COM
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Xiao H., 2017, ARXIV170807747
   XIONG Y, 2019, IEEE IJCNN
   Yang Z, 2019, REDUCING DILUTION AN
   Yao L., 2017, LEARNING DIAGNOSE SC, P1
   Zhao Z, 2019, Arxiv, DOI arXiv:1903.09662
NR 45
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15089-3
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700002
DA 2024-07-18
ER

PT J
AU Grailu, H
AF Grailu, Hadi
TI Compression of high-sampling-rate heart sound signals based on
   downsampling and pattern matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heart Sound Signal; Phonocardiography; Signal Compression; Pattern
   Matching; Downsampling
ID WAVELET
AB Today, auscultation is one of the most effective methods in monitoring heart disease. With the advancement of technology and the facilitation of telecare on the one hand, and the increasing need for high quality and long-term recording of cardiac audio signals on the other hand, the amount of data generated has increased and therefore, the storage and transmission of these signals has become a challenge. This, in turn, demonstrates the importance and necessity of using efficient methods for compression of these signals. These methods should have a high compression ratio and, at the same time, preserve important clinical information as much as possible. In this paper, a lossy compression method is proposed for phonocardiography (PCG) signals recorded at a relatively high sampling rate so that it can control the quality of the compressed signal. This method is based on two techniques: "two-stage downsampling" and "pattern matching (PM)". The proposed two-stage downsampling technique increases the amount of compression ratio and at the same time, reduces the computational complexity. The PM technique is able to reduce the inter-period redundancy and therefore, further increase the compression ratio. The simulation results of the proposed method on two databases of the University of Michigan and the University of Washington showed that the two-stage downsampling and PM techniques have a large contribution in increasing the compression ratio. The performance of the proposed method was evaluated according to the PRD and CR criteria and compared with that of some existing methods. In this evaluation, for the PRD range of <= 5%, the CR value was between 2500 and 3900 for the University of Michigan database and between 2500 and 4125 for the University of Washington database. Also, the results of applying the proposed method on the PASCAL database showed that the efficiency of the proposed method depends to a large extent, on the quality and regularity of the PCG signal.
C1 [Grailu, Hadi] Shahrood Univ Technol, Elect Engn Dept, Elect & Biomed Engn Grp, Shahrood, Iran.
C3 Shahrood University of Technology
RP Grailu, H (corresponding author), Shahrood Univ Technol, Elect Engn Dept, Elect & Biomed Engn Grp, Shahrood, Iran.
EM grailu@shahroodut.ac.ir
CR Aggarwal V, 2022, IETE J RES, V68, P2736, DOI 10.1080/03772063.2020.1725662
   Alajarin JM, 2006, 2006 COMPUTERS CARDI, P17
   [Anonymous], 2011, Classifying heart sounds challenge
   [Anonymous], 2011, P 1 INT C WIRELESS T
   Bendifallah A, 2015, 2015 4 INT C EL ENG
   Boukhennoufa N., 2012, INT J ADV SCI TECHNO, V48, P89
   Burger W., 2009, Principles of Digital Image Processing
   Chien YR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175842
   Chowdhury M, 2018, IEEE SIG PROC MED
   depts.washington, About us
   Kim S, 2016, ELECTRON LETT, V52, P183, DOI 10.1049/el.2015.3449
   Manikandan MS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P164, DOI 10.1109/ADCOM.2007.29
   Martínez-Alajarín J, 2004, ELECTRON LETT, V40, P1040, DOI 10.1049/el:20045476
   Martínez-Alajarín J, 2007, LECT NOTES COMPUT SC, V4527, P508
   medicine.umich, US
   Patidar S, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2193, DOI 10.1109/TENCON.2016.7848416
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SAID A, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P279, DOI 10.1109/ISCAS.1993.393712
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Stark H.G., 2005, WAVELETS SIGNAL PROC
   Stoica P., 2005, Spectral Analysis of Signals
   Subasi A., 2019, Practical Guide for Biomedical Signals Analysis Using Machine Learning Techniques: a MATLAB Based Approach
   Tang H, 2016, COMPUT BIOL MED, V71, P24, DOI 10.1016/j.compbiomed.2016.01.017
   Wei Qin, 2013, 2013 IEEE 4th International Conference on Electronics Information and Emergency Communication (ICEIEC), P109, DOI 10.1109/ICEIEC.2013.6835465
NR 24
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15714-1
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700011
DA 2024-07-18
ER

PT J
AU Kutlugün, MA
   Sirin, Y
AF Kutlugun, Mehmet Ali
   Sirin, Yahya
TI Reducing false positive rate with the help of scene change indicator in
   deep learning based real-time face recognition systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Deep metric learning; Illumination and pose changes;
   Image processing; Real-time face recognition
ID CONVOLUTIONAL NEURAL-NETWORK
AB In face recognition systems, light direction, reflection, and emotional and physical changes on the face are some of the main factors that make recognition difficult. Researchers continue to work on deep learning-based algorithms to overcome these difficulties. It is essential to develop models that will work with high accuracy and reduce the computational cost, especially in real-time face recognition systems. Deep metric learning algorithms called representative learning are frequently preferred in this field. However, in addition to the extraction of outstanding representative features, the appropriate classification of these feature vectors is also an essential factor affecting the performance. The Scene Change Indicator (SCI) in this study is proposed to reduce or eliminate false recognition rates in sliding windows with a deep metric learning model. This model detects the blocks where the scene does not change and tries to identify the comparison threshold value used in the classifier stage with a new value more precisely. Increasing the sensitivity ratio across the unchanging scene blocks allows for fewer comparisons among the samples in the database. The model proposed in the experimental study reached 99.25% accuracy and 99.28% F-1 score values compared to the original deep metric learning model. Experimental results show that even if there are differences in facial images of the same person in unchanging scenes, misrecognition can be minimized because the sample area being compared is narrowed.
C1 [Kutlugun, Mehmet Ali; Sirin, Yahya] Istanbul Sabahattin Zaim Univ, Comp Sci & Engn, Istanbul, Turkiye.
C3 Istanbul Sabahattin Zaim University
RP Kutlugün, MA (corresponding author), Istanbul Sabahattin Zaim Univ, Comp Sci & Engn, Istanbul, Turkiye.
EM mehmet.kutlugun@std.izu.edu.tr; yahya.sirin@izu.edu.tr
OI KUTLUGUN, Mehmet Ali/0000-0003-0720-2142
CR Abu-El-Haija Sami, 2016, arXiv
   Al Machot F, 2019, J REAL-TIME IMAGE PR, V16, P931, DOI 10.1007/s11554-016-0569-z
   Ananthakumar A, 2018, IEEE SW SYMP IMAG, P117, DOI 10.1109/SSIAI.2018.8470351
   Atik ME, 2021, J FAC ENG ARCHIT GAZ, V36, P359, DOI 10.17341/gazimmfd.715450
   Bhattarai S, 2017, 2017 COGNITIVE COMMUNICATIONS FOR AEROSPACE APPLICATIONS WORKSHOP (CCAA)
   Bilgic A, 2017, 2017 25 SIGN PROC CO, P1, DOI [10.1109/SIU.2017.7960368, DOI 10.1109/SIU.2017.7960368]
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chu SL, 2022, MULTIMED TOOLS APPL, V81, P1867, DOI 10.1007/s11042-021-11599-0
   Cuculo V, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010146
   Dabhade R.G., 2017, INT J APPL ENG RES, V12, P12625
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta AK., 2015, FACE DETECTION RECOG, DOI [10.1201/b19349, DOI 10.1201/B19349]
   Davis E.K., 2017, HIGH QUALITY FACE RE
   Elaggoune H, 2022, MULTIMED TOOLS APPL, V81, P9403, DOI 10.1007/s11042-021-11849-1
   Gao Y, 2019, NEURAL COMPUT APPL, V31, P607, DOI 10.1007/s00521-017-3035-3
   Geitgey A, 2017, AGEILGEY FACE RECOGN
   Güllü MK, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P510, DOI 10.1109/SIU.2004.1338577
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Hyun Ah Song, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P466, DOI 10.1007/978-3-642-42054-2_58
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kutlugun MA., 2017, GOZETIMLI MAKINE OGR
   Kutlugün MA, 2023, DIGIT SIGNAL PROCESS, V135, DOI 10.1016/j.dsp.2023.103967
   Kutlugün MA, 2019, FED CONF COMPUT SCI, P929, DOI 10.15439/2019F181
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lee HS, 2022, LUMINANCE LEVEL HIST
   Li YD, 2021, APPL INTELL, V51, P3012, DOI 10.1007/s10489-020-02100-9
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Moghaddam B, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P610, DOI 10.1109/MMCS.1999.778554
   Monaghan TF, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57050503
   Özkaya N, 2008, J FAC ENG ARCHIT GAZ, V23, P785
   Patil H, 2016, APPL INTELL, V44, P913, DOI 10.1007/s10489-015-0735-1
   Qi X., 2018, 2018 IEEE 4 INT C ID, P1
   Saypadith S, 2018, ASIAPAC SIGN INFO PR, P1318, DOI 10.23919/APSIPA.2018.8659751
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seker A., 2017, Gazi Muhendislik Bilimleri Dergisi, V3, P47
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   Wang K, 2019, NEURAL COMPUT APPL, V31, P3805, DOI 10.1007/s00521-017-3316-x
   Zhang Y, 2019, MECH SYST SIGNAL PR, V122, P480, DOI 10.1016/j.ymssp.2018.12.039
   Zhou TF, 2021, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR46437.2021.00572
   Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156
   Zhu XN, 2018, J REAL-TIME IMAGE PR, V15, P617, DOI 10.1007/s11554-017-0743-y
NR 46
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47517
EP 47536
DI 10.1007/s11042-023-15769-0
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000988577200007
PM 37362661
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Singh, HK
   Singh, AK
AF Singh, Himanshu Kumar
   Singh, Amit Kumar
TI Digital image watermarking using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Watermarking; Deep learning; Digital image; Autoencoders
ID NEURAL-NETWORK
AB At present, watermarking techniques play an important role in protecting digital images. To date, many classical watermarking schemes have been developed to protect images based on spatial and transform domains. However, classical watermarking schemes are less resilient to many attacks. Recently, deep learning-based watermarking made a significant contribution to image content security and received attention for various popular applications. In this paper, we use convolutional neural networks (CNNs) to propose an interesting watermarking technique for digital images. Initially, latent features of cover and secret images are extracted using an encoder network and later concatenated to generate a marked image. On the receiver side, a denoising autoencoder network is used to remove noise variations from the received image and later to extract the secret mark image using a CNN. Our technique not only imperceptibly hides an image inside a cover image but also outperforms other state-of-the-art schemes in terms of visual quality and robustness according to simulation results and performance comparisons.
C1 [Singh, Himanshu Kumar; Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM himanshus.ph21.cs@nitp.ac.in; amit.singh@nitp.ac.in
OI Kumar Singh, Himanshu/0000-0003-3731-9878
FU DLRL, Hyderabad, India [DLRL/21CR0003/ SWCCENT/GN/LP]
FX This research was supported by project no. DLRL/21CR0003/ SWCC &
   ENT/GN/LP dt. 29 August, 2020, DLRL, Hyderabad, India.
CR Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Anand A., 2023, MED INFORM PROCESS S, V14, P325, DOI [10.1049/PBHE044E_ch14, DOI 10.1049/PBHE044E_CH14]
   Anand A, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3508365
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2023, KAGGL CATS VS DOGS D
   Bagheri Mahnoosh, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P1067, DOI 10.1109/ICMLA51294.2020.00172
   Chen JK, 2023, IEEE T MED IMAGING, V42, P594, DOI 10.1109/TMI.2022.3213372
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding WP, 2022, IEEE TETCI, V6, P613, DOI 10.1109/TETCI.2021.3055520
   Fkirin A, 2022, MULTIMED TOOLS APPL, V81, P15961, DOI 10.1007/s11042-022-12566-z
   Ge S., 2022, arXiv, DOI [10.1007/s11042-023-15048-y, DOI 10.1007/S11042-023-15048-Y]
   Islam M, 2018, J INTELL FUZZY SYST, V34, P1691, DOI 10.3233/JIFS-169462
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Ziwei, 2018, Largescale celebfaces attributes (celeba) dataset, P11
   Mahapatra D, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.2.021604
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Panchikkil S, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020450
   Singh HK., 2023, J ELECTRON IMAGING, V32, P1
   Wang XC, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102820
   Wei Q, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8869096
   Zheng WB, 2018, C IND ELECT APPL, P1233, DOI 10.1109/ICIEA.2018.8397898
   Zhong X, 2021, IEEE T MULTIMEDIA, V23, P1951, DOI 10.1109/TMM.2020.3006415
NR 25
TC 8
Z9 8
U1 11
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15750-x
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200004
DA 2024-07-18
ER

PT J
AU Liu, H
   Wu, J
   Ma, HK
   Yan, YQ
   He, R
AF Liu, Huan
   Wu, Jian
   Ma, Haokai
   Yan, Yuqi
   He, Rui
TI Skeleton-based multi-stream adaptive-attentional sub-graph convolution
   network for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Adaptive-attentional sub-graph convolution;
   Depth-first tree traversal order; Multi-stream framework
ID 3D; ENSEMBLE; MODEL
AB Recently, graph convolutional networks have achieved remarkable performance with skeleton-based action recognition methods. However, there is potential correlation between different parts of the human body. Many studies have ignored the fact that different actions are the result of the interaction of different human body parts, and that operating on the whole graph provides inadequate information to characterize the action category. In this study, to pay more attention to this problem and further improve the accuracy of action recognition models, sub-graphs based on the depth-first tree traversal order were used to represent the importance and correlation characteristics of joint and bone parts. In addition, beyond the physical structure of the body, joint and bone motion information was also introduced to represent changes in human body parts with movement. To improve the performance of this method, an adaptive-attentional mechanism was added to learn unique topology autonomously for each sample and channel domain. The multi-stream adaptive-attentional sub-graph convolution network was thus proposed for action recognition. The resulting model achieved competitive results on the NTU-RGB + D60 dataset based on 2D or 3D skeleton poses. The experimental results demonstrated the efficacy of our proposed method.
C1 [Liu, Huan; Wu, Jian; Ma, Haokai; Yan, Yuqi; He, Rui] Jilin Univ, State Key Lab Automot Simulat & Control, Changchun, Peoples R China.
C3 Jilin University
RP He, R (corresponding author), Jilin Univ, State Key Lab Automot Simulat & Control, Changchun, Peoples R China.
EM liuhuan19@mails.jlu.edu.cn; wujian@jlu.edu.cn; 903962149@qq.com;
   243129952@qq.com; herui@jlu.edu.cn
FU National Key Research and Development Program of China [2022YFB2503405];
   Natural Science Foundation of Jilin Province [20210101061JC]
FX AcknowledgmentsThe authors thank the anonymous reviewers for valuable
   comments. This work is was supported by the National Key Research and
   Development Program of China 2022YFB2503405, and the Natural Science
   Foundation of Jilin Province Grant No: 20210101061JC.
CR [Anonymous], 2013, IJCAI 13 P 23 INT JO, DOI DOI 10.5555/2540128.2540483
   Atwood J, 2016, ADV NEUR IN, V29
   Cai XY, 2016, IEEE T MULTIMEDIA, V18, P141, DOI 10.1109/TMM.2015.2505089
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YP, 2018, ADV NEUR IN, V31
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Duvenaud D, 2015, Arxiv, DOI arXiv:1509.09292
   Fernando T, 2018, IEEE WINT CONF APPL, P1122, DOI 10.1109/WACV.2018.00128
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussein, 2013, INT JOINT C ART INT
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kipf T, 2018, Arxiv, DOI [arXiv:1802.04687, 10.48550/ARXIV.1802.04687]
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li C, 2017, IEEE INT CONF MULTI
   Li MS, 2019, Arxiv, DOI arXiv:1904.12659
   Li YS, 2019, IEEE INT CON MULTI, P1066, DOI 10.1109/ICME.2019.00187
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Liu SH, 2022, APPL INTELL, V52, P1544, DOI 10.1007/s10489-021-02517-w
   Liu YA, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108146
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Niepert M, 2016, PR MACH LEARN RES, V48
   Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860
   Reddy ND, 2018, PROC CVPR IEEE, P1906, DOI 10.1109/CVPR.2018.00204
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, Arxiv, DOI arXiv:1805.07694
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, Arxiv, DOI arXiv:1406.2199
   Thakkar K, 2018, Arxiv, DOI arXiv:1809.04983
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LM, 2016, Arxiv, DOI [arXiv:1608.00859, DOI 10.48550/ARXIV.1608.00859]
   Wang P, 2018, ARXIV
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Weinzaepfel P, 2021, INT J COMPUT VISION, V129, P1675, DOI 10.1007/s11263-021-01446-y
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xiao FY, 2020, Arxiv, DOI arXiv:2001.08740
   Xu C, 2019, 28 INT JOINT C ART I, DOI [10.24963/ijcai.2019/546, DOI 10.24963/IJCAI.2019/546]
   Yan SJ, 2018, Arxiv, DOI [arXiv:1801.07455, DOI 10.1609/AAAI.V32I1.12328, 10.48550/ARXIV.1801.07455]
   Yang H, 2020, IEEE T IMAGE PROCESS, P164
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang ZY, 2019, IEEE T CIRC SYST VID, V29, P2405, DOI 10.1109/TCSVT.2018.2864148
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
NR 58
TC 1
Z9 1
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15778-z
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600011
DA 2024-07-18
ER

PT J
AU Anushiadevi, R
   Amirtharajan, R
AF Anushiadevi, R.
   Amirtharajan, Rengarajan
TI Design and development of reversible data hiding- homomorphic encryption
   & rhombus pattern prediction approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDHEI; RDH; Lossless Data hiding; Embedding capacity; Steganography;
   Homomorphic encryption
ID IMAGE; CLASSIFICATION; DIFFERENCE; HISTOGRAM; SCHEME
AB In this modern era, a large amount of multimedia content plays an important role in various fields. For multimedia content, storage space and processing speed are more crucial. As a result, existing multimedia applications are moving to a cloud-based paradigm since it offers greater storage and faster processing capabilities. This ensures that more and more people choose to save and process their multimedia content on the cloud. However, this option might cause severe repercussions due to inadequate security. Homomorphic encryption is a type of encryption that enables users to do computations on encrypted data without having to decrypt it first. These resulting operations are then stored in an encrypted form, which when decrypted, produces the same outcomes as if the operations had been performed on the unencrypted data. This paper aims to present a promising solution to protect the data on the cloud through Reversible Data Hiding in an Encrypted Image (RDHEI), using homomorphic encryption and a rhombus pattern prediction scheme. Using this proposed method, any third party can perform data-hiding operations on an encrypted image without being aware of the original contents. Furthermore, this method has the advantage of protecting the image very securely. The entropy of the encrypted image is 7.999, deviations from ideality are 0.0245, diagonal correlation and vertical correlation are 0.0092 and - 0.0015, respectively, and embedding capacity is 0.498 bpp. Finally, flawless image recovery and covert extraction are possible.
C1 [Anushiadevi, R.] SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, India.
   [Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; R, Dr.
   Anushiadevi/0000-0002-5316-7096
FU Department of Science & Technology, New Delhi for the FIST
   [SR/FST/ET-I/2018/221(C)]
FX Authors thank Department of Science & Technology, New Delhi for the FIST
   funding (SR/FST/ET-I/2018/221(C)). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work.
CR Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Amirtharajan R, 2010, ARXIV
   Anushiadevi R, 2021, J INTELL FUZZY SYST, V41, P5583, DOI 10.3233/JIFS-189878
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V39, P2977, DOI 10.3233/JIFS-191478
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V38, P6403, DOI 10.3233/JIFS-179721
   Chang CC, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P506, DOI 10.1109/EUC.2008.20
   Chaudhary P, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S021812662250222X
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chen YY, 2018, CMC-COMPUT MATER CON, V56, P299, DOI 10.3970/cmc.2018.03179
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Cvejic N, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P336, DOI 10.1109/mmsp.2002.1203314
   Dasgupta K., 2012, INT J SECURITY PRIVA, V1
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Honsinger CW, 2001, GOOGLE PATENTS
   Li JX, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070625
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Mo Q, 2019, CMC-COMPUT MATER CON, V59, P119, DOI 10.32604/cmc.2019.05770
   Mstafa RJ, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Raj MG, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.300824
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P1355, DOI 10.1007/s11517-021-02374-2
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Rengarajan Amirtharajan M., 2013, RES J INFORM TECHNOL, V5, P329
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shirali-Shahreza M. H., 2006, IEEEACIS INT C COMPU, P310
   Shiu CW, 2019, KSII T INTERNET INF, V13, P1020, DOI 10.3837/tiis.2019.02.029
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang HJ, 2022, FUTURE GENER COMP SY, V137, P42, DOI 10.1016/j.future.2022.06.016
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
NR 44
TC 7
Z9 7
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46269
EP 46292
DI 10.1007/s11042-023-15455-1
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000983013200005
DA 2024-07-18
ER

PT J
AU Usmani, A
   Siddiqui, N
   Islam, S
AF Usmani, Atiya
   Siddiqui, Nadia
   Islam, Saiful
TI Skeleton joint trajectories based human activity recognition using deep
   RNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton joint; Human action recognition; Kinect; LSTM-RNN; UTD-MHAD;
   MSR DailyActivity
ID REPRESENTATION; MOTION; SEQUENCES; VIDEO
AB Human Activity Recognition is the act of recognizing activities performed by humans in real-time. This can be done using video data or more advanced forms of data like- inertial, depth maps, or human skeletal joint trajectories. In this work, we perform human action recognition through skeletal joint tracking of the human body using a deep recurrent neural network. Our proposed method was then tested on two standard databases, namely UTD-MHAD and MSR- Daily Activity 3D-Datasets. The judgement on the efficiency of our proposed model was made by comparing it to various, recently published, State-Of-The-Art (SOTA) methods.The evaluations of our model show that our method performs well on both the datasets and achieves an accuracy of 99.07%, and 91%, on UTD-MHAD and MSR Daily Activity databases respectively, and can recognize human activities from a variety of domains.
C1 [Usmani, Atiya; Siddiqui, Nadia; Islam, Saiful] Aligarh Muslim Univ, Zakir Husain Coll Engn & Technol, Dept Comp Engn, Aligarh 202001, Uttar Pradesh, India.
   [Siddiqui, Nadia] Aligarh Muslim Univ, Fac Engn & Technol, Interdisciplinary Ctr Artificial Intelligence, Aligarh 202001, Uttar Pradesh, India.
C3 Aligarh Muslim University; Zakir Husain College Of Engineering &
   Technology; Aligarh Muslim University
RP Siddiqui, N (corresponding author), Aligarh Muslim Univ, Zakir Husain Coll Engn & Technol, Dept Comp Engn, Aligarh 202001, Uttar Pradesh, India.; Siddiqui, N (corresponding author), Aligarh Muslim Univ, Fac Engn & Technol, Interdisciplinary Ctr Artificial Intelligence, Aligarh 202001, Uttar Pradesh, India.
EM atiya.usmani@zhcet.ac.in; nadia.siddiqui@zhcet.ac.in;
   saifulislam@zhcet.ac.in
CR Ahmad T, 2021, NEUROCOMPUTING, V423, P389, DOI 10.1016/j.neucom.2020.10.096
   Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Al-Faris M, 2020, PATTERN ANAL APPL, V23, P1587, DOI 10.1007/s10044-020-00886-5
   Aly WM, 2016, INT CONF SOFT COMP, P214, DOI 10.1109/ISCMI.2016.52
   Andrade-Ambriz YA, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116287
   Anjum ML, 2014, LECT NOTES ARTIF INT, V8755, P23, DOI 10.1007/978-3-319-11973-1_3
   [Anonymous], 2022, KINECT CAMERA
   Bulbul MF, 2019, J INTELL FUZZY SYST, V36, P3385, DOI 10.3233/JIFS-181136
   Cekova K, 2016, P ICAIIT, DOI [10.20544/aiit2016.31, DOI 10.20544/AIIT2016.31]
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Cho SS, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.3.033102
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Du YT, 2007, IEEE SIGNAL PROC LET, V14, P952, DOI 10.1109/LSP.2007.908035
   Duong TV, 2005, PROC CVPR IEEE, P838
   Foroughi H, 2008, INT CONF SIGN PROCES, P1500
   Geravesh S, 2023, MULTIMED TOOLS APPL, V82, P14815, DOI 10.1007/s11042-022-13716-z
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P36159, DOI 10.1007/s11042-021-11363-4
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981
   Lin CH, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/453064
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Lu X, 2004, INT C INF TECHN COD, DOI [10.1109/itcc.2004.1286534, DOI 10.1109/ITCC.2004.1286534]
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Park SU, 2016, PROCEDIA COMPUT SCI, V100, P78, DOI 10.1016/j.procs.2016.09.126
   Pham C, 2021, MULTIMED TOOLS APPL, V80, P28919, DOI 10.1007/s11042-021-11058-w
   Rajak S, 2022, MULTIMED TOOLS APPL, V81, P24887, DOI 10.1007/s11042-022-12261-z
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Singh R, 2020, MULTIMEDIA SYST, V26, P313, DOI 10.1007/s00530-019-00645-5
   Tasnim N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062675
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yazdansepas D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P423, DOI 10.1109/ICHI.2016.81
   Zhang CY, 2022, MULTIMED TOOLS APPL, V81, P8349, DOI 10.1007/s11042-022-11947-8
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhu S., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508443
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 42
TC 4
Z9 4
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46845
EP 46869
DI 10.1007/s11042-023-15024-6
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000003
DA 2024-07-18
ER

PT J
AU Zhao, W
   Lian, Y
   Chai, JP
   Tu, ZW
AF Zhao, Wei
   Lian, Yue
   Chai, Jianping
   Tu, Zhongwen
TI Multi-speaker Chinese news broadcasting system based on improved
   Tacotron2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tacotron2; Speech synthesis for news; Multi-Speaker; Chinese front-end
   processing
ID SPEECH; PITCH
AB In recent years, the demand for news broadcasting has increased with the explosion of information. The automatic news broadcasting system based on deep learning text-to-speech technology can solve the problems of working time limitation and errors caused by manual broadcasting. Most of the existing speech synthesis technologies cannot switch speakers in real-time and cannot solve a series of additional news broadcasting scenarios problems in Chinese. In this paper, we propose a multi-speaker Chinese news broadcasting system with switchable timbres based on our established Chinese news corpus CNews dataset for training. This system uses the CPM module to convert Chinese into pinyin phonemes more accurately. Then a timbre encoder is used to construct multi-speaker timbre feature embeddings. As for the problem of having long texts in news, the acoustic model of this system is improved based on Tacotron2 and uses Discrete Grave attention as the attention mechanism so that the model reduces the demand for audio data in the training phase and better extracts the information from the context. The HiFi-GAN vocoder is also used to generate time domain waveforms instead of the original WaveNet, reducing the synthesis time and improving the voice quality of the synthesized speech. Experiments show that the system can change the target timbre flexibly according to the reference speech compared with Tacotron2. Moreover, it is able to synthesize speech with the prosody and style of the target presenter under the training of limited data and with better naturalness as well as faster inference speed, which can be used for real-time news broadcasting.
C1 [Zhao, Wei; Lian, Yue; Chai, Jianping; Tu, Zhongwen] Commun Univ China, 1 Dingfuzhuang St E, Beijing, Peoples R China.
C3 Communication University of China
RP Zhao, W (corresponding author), Commun Univ China, 1 Dingfuzhuang St E, Beijing, Peoples R China.
EM zhao_wei@cuc.edu.cn; lianyue1998@126.com
FU Fundamental Research Funds for the Central Universities; National Key
   Ramp;D Program of China [2022YFC3302100]
FX This study is supported by the Fundamental Research Funds for the
   Central Universities, the National Key R&D Program of China (Grand
   No.2022YFC3302100). This paper is also the research result of a
   collaborative project between INSTEC Technology Co., Ltd. and INSTEC
   Import & Export Co, Ltd., and Communication University of China.
CR ALLEN J, 1979, J ACOUST SOC AM, V65, pS130, DOI 10.1121/1.2017051
   [Anonymous], 1977, ICASSP
   Arik SÖ, 2017, ADV NEUR IN, V30
   Arik SO, 2017, PR MACH LEARN RES, V70
   Battenberg E, 2020, INT CONF ACOUST SPEE, P6194, DOI [10.1109/icassp40776.2020.9054106, 10.1109/ICASSP40776.2020.9054106]
   Beliaev S, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.05514
   Chorowski J, 2015, ADV NEUR IN, V28
   COKER CH, 1976, P IEEE, V64, P452, DOI 10.1109/PROC.1976.10154
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Elias I, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.14574
   Elias I, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5709, DOI 10.1109/ICASSP39728.2021.9414718
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Graves A., 2013, ARXIV, DOI DOI 10.48550/ARXIV.1308.0850
   Hossfeld T., 2016, Quality and User Experience, V1, P1, DOI [10.1007/S41233-016-0002-1, DOI 10.1007/S41233-016-0002-1, 10.1007/s41233-016-0002-1]
   Huang ZX, 2020, IEEE SYS MAN CYBERN, P1566, DOI [10.1109/smc42975.2020.9283335, 10.1109/SMC42975.2020.9283335]
   Kawahara H, 2006, ACOUST SCI TECHNOL, V27, P349, DOI 10.1250/ast.27.349
   Kingma D. P., 2014, arXiv
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kong J., 2020, ADV NEURAL INFORM PR, V33, P17022
   Kumar A, 2021, INT C EL COMP COMM T, P01, DOI [10.1109/CONECCT52877.2021.9622581, DOI 10.1109/CONECCT52877.2021.9622581]
   Kumar K, 2019, ADV NEUR IN, V32
   Lee K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.09474
   Lewis, 2019, MELNET GENERATIVE MO
   Lim D, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.07799
   Lu YF, 2019, INT CONF ACOUST SPEE, P7050, DOI 10.1109/ICASSP.2019.8682368
   MELARA RD, 1990, PERCEPT PSYCHOPHYS, V48, P169, DOI 10.3758/BF03207084
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Oord A., 2016, ARXIV160903499
   Pan JJ, 2020, INT CONF ACOUST SPEE, P6689, DOI [10.1109/icassp40776.2020.9053390, 10.1109/ICASSP40776.2020.9053390]
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI [10.1109/ICASSP.2019.8683143, 10.1109/icassp.2019.8683143]
   Ren Y., 2020, INT C LEARNING REPRE
   Ren Y, 2019, ADV NEUR IN, V32
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salimans T, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1701.05517
   Sang D. V., 2021, 2021 INT C MULT ANAL, P1, DOI [10.1109/MAPR53640.2021.9585267, DOI 10.1109/MAPR53640.2021.9585267]
   Seeviour P. M., 1976, 1976 IEEE International Conference on Acoustics, Speech and Signal Processing, P690
   Shadle C H, 2002, PROSPECTS ARTICULATO
   Shen J, 2020, NON ATTENTIVE TACOTR
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Silva AD, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113193
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan X, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.15561
   Thangthai A, 2020, 2020 23 C OR COCOSD
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852
   Valle R, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.05957
   Vasquez S, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1906.01083
   Wan L, 2018, ARXIV
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Wei P, 2017, P ICLR, P214
   Wei P, 2018, INT C LEARNING REPRE
   Yang FY, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P208, DOI [10.1109/asru46091.2019.9003949, 10.1109/ASRU46091.2019.9003949]
   Yoshimura T., 1999, SIMULTANEOUS MODELIN, V83, P2099
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
   Zeng Z, 2020, INT CONF ACOUST SPEE, P6714, DOI [10.1109/ICASSP40776.2020.9054119, 10.1109/icassp40776.2020.9054119]
   Zhang CX, 2019, ASIAPAC SIGN INFO PR, P165, DOI 10.1109/APSIPAASC47483.2019.9023283
   Zhang H., 2022, arXiv
   Zhang H, 2019, COMPUT LINGUIST, V45, P293, DOI [10.1162/COLIa00349, 10.1162/coli_a_00349]
   Zhang JX., 2018, IEEE, DOI [10.1109/ICASSP.2018.8462020, DOI 10.1109/ICASSP.2018.8462020]
   Zhang Y, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2012.15404
   Zhu X., 2019, EMERGING CHAMPIONS D, DOI [10.1007/978-981-13-2628-8, DOI 10.1007/978-981-13-2628-8]
NR 62
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46905
EP 46937
DI 10.1007/s11042-023-15279-z
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000012
DA 2024-07-18
ER

PT J
AU Kaur, H
   Bansal, S
   Kumar, M
   Mittal, A
   Kumar, K
AF Kaur, Harmandeep
   Bansal, Shally
   Kumar, Munish
   Mittal, Ajay
   Kumar, Krishan
TI Worddeepnet: handwritten gurumukhi word recognition using convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CNN; Gurumukhi words; Handwritten word recognition;
   Holistic approach
ID ALGORITHM; DROPOUT; CNN
AB Deep learning models are considered a revolutionary learning paradigm in artificial intelligence and machine learning, piquing the interest of image recognition and computer vision experts. Because deep learning models have gained popularity and improved outcomes in the literature, this work provides a deep learning method based on a holistic approach to recognize offline handwritten Gurumukhi words. The holistic approach to word recognition treats a word as a separate entity rather than its component letters. Three characteristics are extracted from word pictures to train a Convolutional Neural Network (CNN), namely, zoning, diagonal, and centroid. Five performance measures are used to assess trained CNN performance, namely, Accuracy, True Positive Rate (TPR), False Positive Rate (FPR), Root Mean Square Error (RMSE), and Area Under Curve (AUC). The proposed model is trained and assessed using a 40,000 words benchmark dataset based on 70:30 partitioning technique, in which 70% of the data is used to train the model and 30% of the data is used to test the trained model. To assess the efficacy of the suggested technique, a fivefold cross validation process is performed. Using the partitioning method and cross-validation approach, the best accuracy rates of 95.11% and 94.96% are obtained after 30 epochs, respectively which surpassed the existing state-of-the-art offline handwritten Gurumukhi word recognition systems.
C1 [Kaur, Harmandeep] Akal Univ, Dept Comp Sci & Engn, Talwandi Sabo, Punjab, India.
   [Bansal, Shally] Arden Univ, Berlin, Germany.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Mittal, Ajay; Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM harmandeepk08@gmail.com; shallybansalonline@gmail.com;
   munishcse@gmail.com; ajaymittal@pu.ac.in; k.saluja@pu.ac.in
RI Kumar, Munish/P-7756-2018; KUMAR, KRISHAN/AAE-7003-2022
OI Kumar, Munish/0000-0003-0115-1620; KUMAR, KRISHAN/0000-0003-4020-4051;
   Kaur, Harmandeep/0000-0003-1230-1225
CR Abdurahman F, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04742-x
   Acharyya A., 2013, International Journal of Computer Science Issues, V10, P422
   Akbarpour S, 2011, THESIS U PUTRA MALAY
   Albawi S, 2017, I C ENG TECHNOL
   Alkhawaldeh RS, 2021, SOFT COMPUT, V25, P3131, DOI 10.1007/s00500-020-05368-8
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Almodfer R, 2017, LECT NOTES COMPUT SC, V10614, P260, DOI 10.1007/978-3-319-68612-7_30
   [Anonymous], 2012, Guide to OCR for Arabic Scripts
   [Anonymous], 2016, J AI DATA MIN
   [Anonymous], 2017, PROC INT C ADV INF S
   Arani SAAA, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500013
   Awni Mohamed, 2019, 2019 14th International Conference on Computer Engineering and Systems (ICCES). Proceedings, P40, DOI 10.1109/ICCES48960.2019.9068184
   Bhowmik S, 2019, NEURAL COMPUT APPL, V31, P5783, DOI 10.1007/s00521-018-3389-1
   Bhowmik S, 2015, INT J APPL PATTERN R, V2, P142, DOI 10.1504/IJAPR.2015.069539
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Bluche T, 2014, LECT NOTES COMPUT SC, V8791, P199, DOI 10.1007/978-3-319-11397-5_15
   Bluche T, 2017, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2017.111
   Bluche T, 2013, INT CONF ACOUST SPEE, P2390, DOI 10.1109/ICASSP.2013.6638083
   Blumenstein M., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P2893, DOI 10.1109/IJCNN.1999.833544
   Bonyani M, 2021, INT J DOC ANAL RECOG, V24, P133, DOI 10.1007/s10032-021-00368-2
   Bouadil S., 2014, 2014 INT C COMP MAT, DOI [10.1109/ICCMREA.2014.6843795, DOI 10.1109/ICCMREA.2014.6843795]
   Boualam Manal, 2022, WITS 2020: Proceedings of the 6th International Conference on Wireless Technologies, Embedded, and Intelligent Systems. Lecture Notes in Electrical Engineering (745), P877, DOI 10.1007/978-981-33-6893-4_79
   BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114
   Chergui L., 2015, INT J COMPUTATIONAL, V5, P441, DOI [10.1504/IJCVR.2015.072193, DOI 10.1504/IJCVR.2015.072193]
   Cilia ND, 2020, PATTERN RECOGN LETT, V129, P137, DOI 10.1016/j.patrec.2019.11.025
   Dasgupta J, 2016, PATTERN RECOGN LETT, V79, P73, DOI 10.1016/j.patrec.2016.05.017
   De Oliveira JJ, 2009, PROGR PATTERN RECOGN, V5856, DOI [10.1007/978-3-642-10268-4_44, DOI 10.1007/978-3-642-10268-4_44]
   EDELMAN S, 1990, INT J COMPUT VISION, V5, P303, DOI 10.1007/BF00126503
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Elleuch M, 2015, LECT NOTES COMPUT SC, V9489, P363, DOI 10.1007/978-3-319-26532-2_40
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Ghadikolaie MFY, 2016, ETRI J, V38, P703, DOI 10.4218/etrij.16.0115.0542
   Ghosh M, 2019, STUD COMPUT INTELL, V687, P103, DOI 10.1007/978-981-10-8974-9_6
   Giménez A, 2014, PATTERN RECOGN LETT, V35, P149, DOI 10.1016/j.patrec.2012.09.002
   Golzari S, 2022, MULTIMED TOOLS APPL, V81, P33785, DOI 10.1007/s11042-022-13101-w
   Haghighi F, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106940
   Hossain MA, 2021, VEH TECHNOL CONFE, DOI [10.1109/VTC2021-Spring51267.2021.9449068, 10.23919/EATS52162.2021.9704829]
   Jayadevan R, 2011, PROC INT CONF DOC, P304, DOI 10.1109/ICDAR.2011.69
   Jayech K, 2016, INT ARAB J INF TECHN, V13, P1024
   Jino PJ, 2019, ADV INTELL SYST COMP, V816, P913, DOI 10.1007/978-981-13-1592-3_73
   Jino PJ., 2017, INT J ENG TECHNOL, V9, P1
   Kaur H, 2021, DATA DRIVEN APPROACH, DOI 10.1007/978-981-15-9873-9_44
   Kaur H, 2019, DOCUMENT ANAL RECOGN, V1020, DOI [10.1007/978-981-13-9361-7_14, DOI 10.1007/978-981-13-9361-7_14]
   Kaur H, 2021, MULTIMED TOOLS APPL, V80, P11155, DOI 10.1007/s11042-020-10297-7
   Kaur H, 2021, SOFT COMPUT, V25, P4451, DOI 10.1007/s00500-020-05455-w
   Khosravi S, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/4894922
   Kumar M, 2011, P INT C IM INF PROC, P1
   Kumar N., 2018, Int J Pure Appl Math, V119, P14749
   Kumar R, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413530029
   Lee H, 2012, PATTERN RECOGN, V45, P1306, DOI 10.1016/j.patcog.2011.09.015
   Leila C., 2011, 2011 10th International Symposium on Programming and Systems, P74, DOI 10.1109/ISPS.2011.5898872
   Loey M, 2017, ARXIV
   Maalej R, 2019, LECT NOTES COMPUT SC, V11955, P534, DOI 10.1007/978-3-030-36718-3_45
   Madhvanath S, 2001, IEEE T PATTERN ANAL, V23, P149, DOI 10.1109/34.908966
   Mhiri M, 2018, PATTERN RECOGN LETT, V111, P87, DOI 10.1016/j.patrec.2018.04.025
   Mondal R, 2022, MULTIMED TOOLS APPL, V81, P975, DOI 10.1007/s11042-021-11425-7
   Mustafa ME, 2020, INT J ADV COMPUT SC, V11, P678
   Namane A, 2005, LECT NOTES COMPUT SC, V3686, DOI [10.1007/11551188_72, DOI 10.1007/11551188_72]
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P3193, DOI 10.1007/s11227-020-03388-7
   Nurseitov D., 2021, Adv. Sci. Technol. Eng. Syst. J, V5, P934, DOI DOI 10.25046/AJ0505114
   Pal U, 2009, IEICE T INF SYST, VE92D, P1146, DOI 10.1587/transinf.E92.D.1146
   Parseh M, 2020, INT ARAB J INF TECHN, V17, P572, DOI 10.34028/iajit/17/4/16
   Patel MS, 2015, ADV INTELL SYST, V328, P563, DOI 10.1007/978-3-319-12012-6_62
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Pramanik R, 2021, NEURAL COMPUT APPL, V33, P9329, DOI 10.1007/s00521-021-05693-5
   Pramanik R, 2020, IET IMAGE PROCESS, V14, P959, DOI 10.1049/iet-ipr.2019.0208
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Rahal Najoua, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P701, DOI 10.1109/ICDAR.2019.00117
   Rothacker L, 2016, INT CONF FRONT HAND, P199, DOI [10.1109/ICFHR.2016.0047, 10.1109/ICFHR.2016.44]
   Roy A, 2005, P DIG IM COMP TECHN, P1
   Roy K, 2005, PROC INT CONF DOC, P1060, DOI 10.1109/ICDAR.2005.259
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saeed U, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.5.051405
   Safarzadeh VM, 2020, 2020 25 INT COMP C C, P1, DOI DOI 10.1109/CSICC49403.2020.9050073
   Scheidl H, 2018, THESIS TU WIEN VIENN
   Sharma S, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/5945117
   SharmaA, 2009, 10 INT C DOC AN REC, P1241, DOI DOI 10.1109/ICDAR.2009.36
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Singh S, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100037
   Singh S, 2020, APPL INTELL, V50, P2093, DOI 10.1007/s10489-020-01632-4
   Singh S, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3282441
   Singh S, 2016, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/2896318
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Talaat M, 2016, INT J COMPUTER APPL, V5, P141
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   WafaMohamed Musa MEM A., 2009, COMPUTER STUDIES J, V1, P1
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yan RJ, 2019, INT J DOC ANAL RECOG, V22, P235, DOI 10.1007/s10032-019-00328-x
   Zamani Y, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P37, DOI 10.1109/IranianMVIP.2015.7397499
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zohrevand A, 2021, International Journal of Engineering, V34, P2028, DOI [10.5829/ije.2021.34.08b.24, DOI 10.5829/IJE.2021.34.08B.24]
NR 93
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46763
EP 46788
DI 10.1007/s11042-023-15527-2
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000012
DA 2024-07-18
ER

PT J
AU Harifi, S
   Mohamaddoust, R
AF Harifi, Sasan
   Mohamaddoust, Reza
TI Zigzag mutation: a new mutation operator to improve the genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Zigzag mutation; Gaussian mutation; Image
   segmentation; Benchmark test functions
AB Genetic algorithm is an exploratory method inspired by Darwin's theory of natural evolution. This algorithm reflects the natural selection process in which suitable individuals are selected for reproduction to produce the offspring of the next generation. The genetic algorithm uses three main operators, namely selection, crossover, and mutation, each of which is involved in producing better strings or chromosomes. Among the three main operators, the mutation operator is one of the most important operators to achieve the optimal solution. The mutation operator is an intelligent mechanism for local search in the problem-solving search space. Mutations are therefore used to maintain population diversity and prevent premature convergence in the problem-solving process. In this study, to improve the genetic algorithm, a new type of mutation is introduced, which is called the Zigzag mutation. This mutation, by observance the zigzag pattern and making sudden and noticeable mutants in the gene compared to the existing mutations, make the local search in the problem space more efficient and helps to improve the genetic algorithm. In this paper, the proposed Zigzag mutation-based genetic algorithm is compared with six other genetic algorithms with different mutations in similar competitive conditions. The state-of-the-art mutations used in this study include Gaussian, Insertion, Inversion, Scramble, Swap, and Uniform, which are compared one by one with the proposed Zigzag mutation. In the experiments, 27 benchmark test functions are used to evaluate the performance. The evaluation results show superiority in 21 benchmark functions. According to the results, the presented method alone is better than other comparable methods in 77% of the benchmark functions. The share of the other six methods is only 23%. Also as an application, the presented improved genetic algorithm has been used in the segmentation of miscellaneous and aerial images. The results and statistical analysis show that the Zigzag mutation can improve the genetic algorithm and make it more efficient to solve the problems.
C1 [Harifi, Sasan] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Mohamaddoust, Reza] Payame Noor Univ PNU, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 Islamic Azad University; Payame Noor University
RP Harifi, S (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM s.harifi@kiau.ac.ir; r.mohamaddoust@pnu.ac.ir
OI Harifi, Sasan/0000-0002-6788-8222
CR Alkafaween E., 2020, Komunikacie, V22, P12, DOI [10.26552/com.C.2020.3.128-139, DOI 10.26552/COM.C.2020.3.128-139]
   Ankenbrandt, 1991, P 4 INT C GEN ALG, P53, DOI [DOI 10.1016/B978-0-08-050684-5.50007-0, 10.1016/B978-0-08-050684-5.50007-0]
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Das AK, 2018, PROC INT CONF EMERG
   Dash S, 2018, ANALOG INTEGR CIRC S, V94, P27, DOI 10.1007/s10470-017-1090-4
   Deb Kalyanmoy, 2014, International Journal of Artificial Intelligence and Soft Computing, V4, P1, DOI 10.1504/IJAISC.2014.059280
   Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046
   Haghrah A, 2021, J AMB INTEL HUM COMP, V12, P8561, DOI 10.1007/s12652-020-02589-5
   Harifi S, 2022, SOFT COMPUT, V26, P12761, DOI 10.1007/s00500-022-07285-4
   Harifi S, 2021, EVOL INTELL, V14, P1743, DOI 10.1007/s12065-020-00451-3
   Hassanat A, 2019, INFORMATION, V10, DOI 10.3390/info10120390
   Hinterding R, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION, VOLS 1 AND 2, P384, DOI 10.1109/ICEC.1995.489178
   Hodan D, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P940, DOI 10.1145/3377930.3390188
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Mauldin M.L., 1984, Proceedings of the National Conference on Artificial Intelligence (AAAI 1984), P247
   Michalewicz Z., 2013, Genetic algorithms+data structures=evolution programs
   Michalewicz Z, 1996, EVOL COMPUT, V4, P1, DOI 10.1162/evco.1996.4.1.1
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Neubauer A, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P93, DOI 10.1109/ICEC.1997.592275
   Qaiduzzaman Khandker M., 2020, Embracing Industry 4.0. Selected Articles from MUCET 2019. Lecture Notes in Electrical Engineering (LNEE 678), P159, DOI 10.1007/978-981-15-6025-5_15
   Soni Nitasha., 2014, INT J COMPUTER SCI I, V5, P4519
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Tang PH, 2013, APPL SOFT COMPUT, V13, P600, DOI 10.1016/j.asoc.2012.08.035
   TSUTSUI S, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P206
NR 24
TC 3
Z9 3
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45411
EP 45432
DI 10.1007/s11042-023-15518-3
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000979973000003
DA 2024-07-18
ER

PT J
AU Li, D
   Yang, ZR
   Jin, X
AF Li, De
   Yang, Zhenren
   Jin, Xun
TI Zero watermarking scheme for 3D triangle mesh model based on global and
   local geometric features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero watermarking; 3D mesh model; Copyright protection; Octree
   segmentation; Two level wavelet transform
ID DCT
AB Copyright infringement of 3D models has become an issue for 3D printing ecosystem. However, the existing 3D model copyright protecting technologies are not robust enough to resist 3D model common attacks include cropping, noise and simplification. Therefore, we propose a robust zero watermarking scheme for 3D models using angle values of adjacent faces. To resist geometric attacks, we first normalize the 3D mesh model. We divide the mesh model from global to local into many blocks using an octree segmentation method. With the octree segmentation, we can obtain global and local information. Each vertex of a mesh model is defined as a center for establishing a number of bins. In each bin, the angle between each pair of faces is used to obtain eigenvalues. The eigenvalues will be optimized, and a two level wavelet transform is used to construct the zero watermark. The experimental results show that the normalized correlation between watermarks of the original and attacked models is about 90% using the proposed method, which is higher than those of existing methods after different strength of attacks.
C1 [Li, De; Yang, Zhenren; Jin, Xun] Yanbian Univ, Dept Comp Sci, Yanji, Peoples R China.
C3 Yanbian University
RP Jin, X (corresponding author), Yanbian Univ, Dept Comp Sci, Yanji, Peoples R China.
EM leader1223@ybu.edu.cn; ahyangyu@126.com; xunjin@ybu.edu.cn
RI Jin, Xun/JDD-3969-2023
OI Jin, Xun/0000-0002-5908-8321
FU National Natural Science Foundation of China [62062064]; Education
   Department of Jilin Province [JJKH20200511KJ]
FX AcknowledgementsThis research project was supported by the National
   Natural Science Foundation of China (Grant No. 62062064) and the
   Education Department of Jilin Province (Grant No. JJKH20200511KJ).
CR [Anonymous], 2013, NEW MATTER
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Ishengoma FR., 2014, ARXIV14105349, V104, P975
   Li PJ, 2012, THESIS BEIJING U
   Liu JL, 2019, CMC-COMPUT MATER CON, V61, P363, DOI 10.32604/cmc.2019.06037
   Liu Wang, 2009, Chinese Journal of Scientific Instrument, V30, P2635
   Nawaz Saqib Ali, 2020, Innovation in Medicine and Healthcare. Proceedings of 8th KES-InMed 2020. Smart Innovation Systems and Technologies (SIST 192), P47, DOI 10.1007/978-981-15-5852-8_5
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Pan XR, 2021, PROC CVPR IEEE, P7459, DOI 10.1109/CVPR46437.2021.00738
   Tamane SC, 2013, P INT CONF INTELL, P270, DOI 10.1109/ISMS.2013.63
   Wang H, 2021, PROC CVPR IEEE, P14610, DOI 10.1109/CVPR46437.2021.01438
   Wang Xinyu, 2011, Computer Engineering and Applications, V47, P7, DOI 10.3778/j.issn.1002-8331.2011.28.002
   Wang YK, 2022, PROC CVPR IEEE, P12104, DOI 10.1109/CVPR52688.2022.01180
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wu XQ, 2019, MULTIMED TOOLS APPL, V78, P8463, DOI 10.1007/s11042-018-6877-5
   Wu YB, 2012, COMPUT ENG, V38
   [徐涛 XU Tao], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1819
   Yu H.X., 2022, P IEEECVF C COMPUTER, P1456
   Zhang JW, 2009, I C COMP GRAPH IM VI, P510, DOI 10.1109/CGIV.2009.49
   Zhou K., 2002, COMPUT METHOD APPL M, V32, P1451
NR 20
TC 3
Z9 3
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43635
EP 43648
DI 10.1007/s11042-023-15288-y
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000971519600002
DA 2024-07-18
ER

PT J
AU Xu, N
   He, LZ
   Li, Q
AF Xu, Na
   He, Lizhi
   Li, Qing
TI Crack-Att Net: crack detection based on improved U-Net with parallel
   attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crack detection; Attention mechanism; Crack segmentation network
AB In recent years, the demand for automatic crack detection has increased rapidly. Due to the particularity of crack images, that is, the proportion of cracks in the entire images is very small, and some cracks in the image are particularly slender and light, it brings challenge for automatic crack detection. In this paper, we propose an end-to-end pixel-level crack segmentation network, named as "Crack-Att Net". In our approach, firstly, an encoder network is used to extract the crack features; then, crack features generated by the encoder and decoder networks at the same scale are pairwisely fused through a parallel attention mechanism added for accurately locating the cracks; finally, the fused crack feature maps at all scales are further fused into a multi-scale feature-fusion map for crack detection. Experiments results on three existing datasets and an augmented dataset show that our proposed Crack-Att Net outperforms the current state-of-the-art methods.
C1 [Xu, Na; He, Lizhi] China Univ Min & Technol Beijing, Coll Geosci & Survey Engn, Beijing 100083, Peoples R China.
   [Li, Qing] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Kowloon, Hong Kong, Peoples R China.
C3 China University of Mining & Technology; Hong Kong Polytechnic
   University
RP Xu, N (corresponding author), China Univ Min & Technol Beijing, Coll Geosci & Survey Engn, Beijing 100083, Peoples R China.
EM xuna1011@gmail.com
RI Wang, lingyu/JLM-2013-2023; Wang, Chao/JHT-6081-2023; Chen,
   Yu/JLL-0171-2023; liu, peng/JSL-1931-2023; WANG, YANG/JFA-8821-2023
OI Xu, Na/0000-0002-1406-9098
FU National Key Research and Development Program of China [2021YFC2902000]
FX AcknowledgementsThis research was funded by the National Key Research
   and Development Program of China (No. 2021YFC2902000). Thanks are given
   to the anonymous reviewers for their careful reviews and detailed
   comments.
CR Abdel-Qader L, 2003, J COMPUT CIVIL ENG, V17, P255, DOI 10.1061/(ASCE)0887-3801(2003)17:4(255)
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benz C, 2019, INT CONF IMAG VIS, DOI 10.1109/ivcnz48456.2019.8960998
   Cho H, 2018, IEEE ACCESS, V6, P60100, DOI 10.1109/ACCESS.2018.2875889
   Fan R, 2019, IEEE INT VEH SYM, P474, DOI [10.1109/IVS.2019.8814000, 10.1109/ivs.2019.8814000]
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kangcheng Liu, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P381, DOI 10.1109/ROBIO49542.2019.8961534
   Kaseko M. S., 1993, Transportation Research Part C (Emerging Technologies), V1C, P275, DOI 10.1016/0968-090X(93)90002-W
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li QQ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P792, DOI 10.1109/CISP.2008.13
   Lim RS, 2014, IEEE T AUTOM SCI ENG, V11, P367, DOI 10.1109/TASE.2013.2294687
   Liu HJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3763, DOI 10.1109/ICCV48922.2021.00376
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu ZT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3125055
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Medina R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071670
   Mohan A, 2018, ALEX ENG J, V57, P787, DOI 10.1016/j.aej.2017.01.020
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oliveira H., 2009, RECENT ADV SIGNAL PR, P159
   Park S, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000831
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Qu Z, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063004
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., 2016, ARXIV
   Shi Y, 2016, IEEE T INTELL TRANSP, V17, P3434, DOI 10.1109/TITS.2016.2552248
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Subirats P, 2006, IEEE IMAGE PROC, P3037, DOI 10.1109/ICIP.2006.313007
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang LF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3095899
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
   Zou Q, 2019, IEEE T IMAGE PROCESS, V28, P1498, DOI 10.1109/TIP.2018.2878966
   Zou Q, 2012, PATTERN RECOGN LETT, V33, P227, DOI 10.1016/j.patrec.2011.11.004
NR 45
TC 3
Z9 3
U1 20
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42465
EP 42484
DI 10.1007/s11042-023-15201-7
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000984450300006
DA 2024-07-18
ER

PT J
AU Sachin
   Singh, P
AF Sachin
   Singh, Phool
TI Asymmetric Cryptosystem Based on Biological Mutation Operation in
   Chirp-Z Domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA; Asymmetric cryptosystem; Chirp-z transform; DICOM image; Chaotic
   map; Tinkerbell map
ID EQUAL MODULUS DECOMPOSITION; IMAGE ENCRYPTION; COHERENT SUPERPOSITION;
   OPTICAL ENCRYPTION; PLAINTEXT ATTACK; Z-TRANSFORM; DNA; CRYPTANALYSIS;
   ALGORITHM; CHAOS
AB In this paper, we have proposed an asymmetric image encryption algorithm in the Chirp-Z domain using chaotic Tinkerbell map, DNA coding with biological mutation and phase truncation and phase reservation (PTFT) operation. Most of the DNA based encryption schemes involve XOR operator. The proposed asymmetric scheme uses biological mutation operator having more security features. The proposed cryptosystem is tested with various grayscale images and simulation results for Boy, Vegetable, and DICOM images are demonstrated in this paper. The proposed encryption algorithm is highly sensitive to the encryption parameters whereas DNA coding and PTFT provided an additional layer of security. The simulation result validates robustness of proposed image encryption algorithm against statistical attack, noise attack, chosen plaintext attack, special iterative attack for asymmetric schemes, and bruteforce attacks. The performance of proposed scheme is also compared with similar existing encryption algorithms. The results demonstrate that the proposed encryption algorithm can resist the existing cryptographic attacks.
C1 [Sachin] Cent Univ Haryana, Dept Math, Mahendergarh 123031, India.
   [Sachin] Kurukshetra Univ, Dept Math, IIHS, Kurukshetra 136119, India.
   [Singh, Phool] Cent Univ Haryana, Dept Math, SoET, Mahendergarh 123031, India.
C3 Central University of Haryana; Kurukshetra University; Central
   University of Haryana
RP Sachin (corresponding author), Cent Univ Haryana, Dept Math, Mahendergarh 123031, India.; Sachin (corresponding author), Kurukshetra Univ, Dept Math, IIHS, Kurukshetra 136119, India.
EM sachinmaths@kuk.ac.in
RI Yadav, Sachin/HZK-5298-2023
FU Council of Scientific & Industrial Research (CSIR), India, a premier
   national RD organization [09/1152(0012)/2019-EMR-1]
FX This work was funded by award reference number 09/1152(0012)/2019-EMR-1
   from Council of Scientific & Industrial Research (CSIR), India, a
   premier national R&D organization. The contents of the publication are
   solely the responsibility of the authors and do not necessarily
   represent the official views of the Council of Scientific & Industrial
   Research.
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Archana, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106399
   Archana Sachin, 2021, Lecture Notes in Networks and Systems, V148, P73, DOI [10.1007/978-981-15-7561-7_5, DOI 10.1007/978-981-15-7561-7_5]
   Cai JJ, 2015, OPT LETT, V40, P475, DOI 10.1364/OL.40.000475
   Chen H, 2021, OPT LASER ENG, V138, DOI 10.1016/j.optlaseng.2020.106448
   Chen H, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105809
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Deng XP, 2015, OPT LETT, V40, P3913, DOI 10.1364/OL.40.003913
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   El-Khamy SE, 2021, MULTIMED TOOLS APPL, V80, P23319, DOI 10.1007/s11042-021-10527-6
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Javidi B, 1997, OPT ENG, V36, P992, DOI 10.1117/1.601144
   Javidi B, 2000, OPT LETT, V25, P28, DOI 10.1364/OL.25.000028
   Kishk S, 2002, APPL OPTICS, V41, P5462, DOI 10.1364/AO.41.005462
   Krishna PR, 2018, P 2 INT C ELECT COMM, P578, DOI [10.1109/ICECA.2018.8474891, DOI 10.1109/ICECA.2018.8474891]
   Kumar Jaideep, 2018, Procedia Computer Science, V132, P1570, DOI 10.1016/j.procs.2018.05.121
   Kumar R, 2019, J MOD OPTIC, V66, P776, DOI 10.1080/09500340.2019.1572807
   Kumar R, 2018, J MOD OPTIC, V65, P321, DOI 10.1080/09500340.2017.1395486
   Kumari E, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100009
   Kumari E, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100005
   La CS, 2019, INFORM SCIENCES, V470, P58, DOI 10.1016/j.ins.2018.08.017
   Lyda R, 2007, IEEE SECUR PRIV, V5, P40, DOI 10.1109/MSP.2007.48
   Mosso E, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab015f
   Mosso E, 2019, APPL OPTICS, V58, P5674, DOI 10.1364/AO.58.005674
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   RABINER LR, 1969, BELL SYST TECH J, V48, P1249, DOI 10.1002/j.1538-7305.1969.tb04268.x
   Rakheja P, 2019, P INDIAN NATL SCI AC, V85, P803, DOI 10.16943/ptinsa/2019/49590
   Rakheja P, 2019, OPT QUANT ELECTRON, V51, DOI 10.1007/s11082-019-1921-x
   Rakheja P, 2019, OPTIK, V176, P425, DOI 10.1016/j.ijleo.2018.09.088
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Sachin Archana, 2021, P INT C DATA SCI APP, P249
   Sharma N, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0149-4
   Singh Phool, 2019, Engineering Vibration, Communication and Information Processing. ICoEVCI 2018, India. Lecture Notes in Electrical Engineering (LNEE 478), P317, DOI 10.1007/978-981-13-1642-5_29
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Singh P, 2017, AIP CONF PROC, V1802, DOI 10.1063/1.4973267
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Sukhoy V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50234-9
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Vijayalakshmi D, 2021, CIRC SYST SIGNAL PR, V40, P3929, DOI 10.1007/s00034-021-01655-3
   Vijayalakshmi D, 2020, PATTERN RECOGN IMAGE, V30, P691, DOI 10.1134/S1054661820040240
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   Wang J, 2019, IEEE ACCESS, V7, P66234, DOI 10.1109/ACCESS.2019.2917994
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wen HP, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030246
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JJ, 2015, APPL OPTICS, V54, P8921, DOI 10.1364/AO.54.008921
   Yadav AK, 2018, J OPT-INDIA, V47, P208, DOI 10.1007/s12596-017-0435-9
   Yuan SL, 2011, INT J BIFURCAT CHAOS, V21, P3137, DOI 10.1142/S0218127411030581
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y, 2020, IEEE ACCESS, V8, P94810, DOI 10.1109/ACCESS.2020.2995839
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 59
TC 5
Z9 5
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42439
EP 42463
DI 10.1007/s11042-023-15190-7
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200009
DA 2024-07-18
ER

PT J
AU Guo, RX
   Liang, RY
   Wang, QY
   Zou, CR
AF Guo, Ruxue
   Liang, Ruiyu
   Wang, Qingyun
   Zou, Cairong
TI Hearing loss classification algorithm based on the insertion gain of
   hearing aid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fitting-free hearing aids; Hearing loss; Insertion gain; Audiogram;
   Clustering
ID CONFIGURATIONS; PREVALENCE; CHILDREN
AB Hearing loss is one of the most prevalent chronic health problems worldwide and a common intervention is the wearing of hearing aids. However, the tedious fitting procedures and limited hearing experts pose restrictions for the popularity of hearing aids. This paper introduced a hearing loss classification method based on the insertion gain of hearing aids, which aims to simplify the fitting procedure and achieve a fitting-free effect of the hearing aid, in line with current research trends in key algorithms for fitting-free hearing aids. The proposed method innovatively combines the insertion gain of hearing aids with the covariates of patient's gender, age, wearing history to form a new set of hearing loss vectors, and then classifies the hearing loss into six categories by unsupervised cluster analysis method. Each category of representative parameters characterizes a typical type of hearing loss, which can be used as the initial parameter to improve the efficiency of hearing aid fitting. Compared with the traditional audiogram classification method AMCLASS (Automated Audiogram Classification System), the proposed classification method reflect the actual hearing loss of hearing impaired patients better. Moreover, the effectiveness of the new classification method was verified by the comparison between the obtained six sets of representative insertion gains and the inferred hearing personalization information.
C1 [Guo, Ruxue; Zou, Cairong] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
   [Liang, Ruiyu; Wang, Qingyun] Inst Nanjing Technol, Sch Informat & Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Tech University
RP Guo, RX (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM grx0904@sina.com; liangry@njit.edu.cn; wangqingyun@njit.edu.cn;
   cairong@seu.edu.cn
FU National Key Research and Development Program of China [2020YFC2004002,
   2020YFC2004003]
FX AcknowledgementsThis work was supported in part by the National Key
   Research and Development Program of China under grant No. 2020YFC2004002
   and 2020YFC2004003.
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anwar MN, 2010, 19 ANN BELG DUTCH C, P1
   Bhat GS, 2020, IEEE ENG MED BIO, P956, DOI 10.1109/EMBC44109.2020.9175693
   Bisgaard N, 2010, TRENDS AMPLIF, V14, P113, DOI 10.1177/1084713810379609
   CARHART R, 1945, LARYNGOSCOPE, V55, P640
   Chadha S, 2017, WHO offset publication
   Chadha S, 2021, B WORLD HEALTH ORGAN, V99, P242, DOI 10.2471/BLT.21.285643
   Charih F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60898-3
   Charih F, 2018, IEEE INT SYM MED MEA, P1029
   Demeester K, 2007, B-ENT, P37
   DILLON H, 1993, J SPEECH HEAR RES, V36, P621, DOI 10.1044/jshr.3603.621
   Elkhouly A, 2020, INT C COMMUNICATIONS, P1
   Hannula S, 2011, INT J AUDIOL, V50, P793, DOI 10.3109/14992027.2011.593562
   Isaac MJ, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.10.003
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Keidser G., 2006, Hearing care for adults, P133
   Keidser G, 2008, INT J AUDIOL, V47, P621, DOI 10.1080/14992020802178722
   Keidser G, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516643284
   Killion M.C., 1995, J ACOUST SOC AM, V98, P2927, DOI DOI 10.1121/1.414129
   Koyama H, 2021, OTOL NEUROTOL, V42, pE1286, DOI 10.1097/MAO.0000000000003271
   Lee CY, 2010, INT J AUDIOL, V49, P628, DOI 10.3109/14992021003796887
   Liang RY, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7030272
   Lopez RS, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518807400
   Maclennan-Smith F, 2013, INT J AUDIOL, V52, P66, DOI 10.3109/14992027.2012.736692
   Margolis RH, 2007, INT J AUDIOL, V46, P746, DOI 10.1080/14992020701572652
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Rasetshwane DM, 2014, IEEE T BIO-MED ENG, V61, P64, DOI 10.1109/TBME.2013.2276351
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Scollie Susan, 2005, Trends Amplif, V9, P159, DOI 10.1177/108471380500900403
   Scollie S, 2010, INT J AUDIOL, V49, pS49, DOI 10.3109/14992020903148038
   Warren E, 2017, JAMA INTERN MED, V177, P609, DOI 10.1001/jamainternmed.2017.0464
   Yuen KCP, 2002, DISABIL REHABIL, V24, P904, DOI 10.1080/09638280210148602
NR 35
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41225
EP 41239
DI 10.1007/s11042-023-14886-0
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900015
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, DZ
   Chen, ALP
AF Wu, Dongze
   Chen, Arbee L. P.
TI Classical Chinese poetry generation from vernacular Chinese: a
   word-enhanced supervised approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vernacular Chinese; Classical Chinese poetry; Deep learning; Text
   generation; Chinese word segmention
AB In recent years, with the rapid development of deep learning, natural language processing has achieved great progress in many aspects. In the field of text generation, classical Chinese poetry, as an important part of Chinese culture, also attached growing attention. However, the existing researches on neural-network-based classical Chinese poetry generation ignore the semantics contained in Chinese words. A sentence in Chinese is a sequence of characters without spaces, and thus it is of great significance to segment the sentence properly for understanding the original text correctly. Therefore, supposing that the model knows how to segment the sentence, the meaning of the sentence will be more accurately understood. In this paper, we propose a novel model, namely WE-Transformer (Word-Enhanced Transformer), to generate classical Chinese poetry from vernacular Chinese in a supervised approach, which incorporates external Chinese word segmentation knowledge. Our model learns word semantics based on character embeddings by bidirectional LSTM and enhances the quality of generated classical poems based on the Transformer with extra word encoders. Compared to the baselines and state-of-the-art models, our experiments on automatic and human evaluations have demonstrated that our method can bring better performance.
C1 [Wu, Dongze; Chen, Arbee L. P.] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Chen, Arbee L. P.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Tsing Hua University; Asia University Taiwan
RP Chen, ALP (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.; Chen, ALP (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM s107062466@m107.nthu.edu.tw; arbee@asia.edu.tw
CR [Anonymous], 2014, P 2014 C EMPIRICAL M
   [Anonymous], 2016, P 25 INT JOINT C ART
   Cai D, 2020, AAAI CONF ARTIF INTE, V34, P7464
   Che W, 2020, N LTP OPEN SOURCE NE
   Chen XX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1236
   Chen Yu, 2020, ICLR
   Chiu J.P., 2016, Named entity recognition with bidirectional lstm-cnns, V4, P357, DOI 10.1162/tacl_a_00104
   Cui Y, 2019, PRETRAINING WHOLE WO
   Deng LM, 2020, AAAI CONF ARTIF INTE, V34, P7643
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diao SZ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4729
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   He J, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON APAC 2011
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kingma D. P., 2014, arXiv
   Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039
   Li PJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P742
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Meng YX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3242
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Sun Y., 2019, ERNIE: Enhanced representation through knowledge integration
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Zhe, 2016, Proceedings of COL-ING 2016, the 26th International Conference on Computational Linguistics: Technical Papers
   Yan Rui, 2013, 23 INT JOINT C ART I, P2197
   Yang XP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4539
   Yang Z., 2019, Advances in neural information processing systems, P5753, DOI DOI 10.5555/3454287.3454804
   Yang ZC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6155, DOI 10.18653/v1/d19-1637
   Yi X., 2018, P 22 C COMP NAT LANG, P241, DOI DOI 10.18653/V1/K18-1024
   Yi XY, 2020, AAAI CONF ARTIF INTE, V34, P9450
   Yi XY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4553
   Zhang X, 2021, AUTOPHAGY, V17, P1519, DOI 10.1080/15548627.2020.1840796
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
NR 32
TC 0
Z9 0
U1 10
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39139
EP 39156
DI 10.1007/s11042-023-15137-y
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000961632300003
DA 2024-07-18
ER

PT J
AU Nachar, R
   Inaty, E
   Bonnin, PJ
AF Nachar, Rabih
   Inaty, Elie
   Bonnin, Patrick J.
TI A high performance neural network and fuzzy logic based edge corner
   detector (NF-ECD)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Fuzzy logic; Edge corners (ECs); Straight edges (SEs)
AB In recent years, Keypoints-based image detection algorithms have become essential to many image processing applications. They should be stable and invariant especially against image distortion and noise caused by different illumination conditions. Thus, the challenge is to design a faster and more robust detector in terms of accuracy and saliency of the detected keypoints. Toward this objective, the flexibility of artificial intelligence (AI) and its ability to learn and adapt has made it the primary choice to achieve this goal. In this paper, we propose a novel detector that combines the power of neural networks to detect robust feature points and fuzzy logic to select among them only the most significant. A neural network is implemented as a supervised machine learning technique. It is trained on a predefined database of straight edges (SEs) with different patterns representing a set of flow directions. The aim is to decompose a given contour into a set of connected straight edges (SEs) and estimate the flow direction for each. The transition points between nonlinear SEs are classified as edge corners (ECs). Finally, the set of these ECs is pruned by a fuzzy logic system to keep only the significant ones based on key corner parameters that can highly contribute in the matching process. Experimental results demonstrate clearly the robustness and saliency of our newly proposed NF-ECD in extracting keypoints. In addition, the NF-ECD achieves the best performance as compared to the state of the art keypoints detection algorithms. Using experiments conducted on the illumination set of the HPatches dataset, the repeatability score reaches 72.6%. On the other hand, the average computational time complexity obtained using the Object Recognition Dataset reaches 2.18 s which is the lowest among other similar detectors. In addition, NF-ECD shows an effective reduction in the matching runtime.
C1 [Nachar, Rabih] Univ Balamand, Dept Telecommun & Networks, POB 33, Balamand, Lebanon.
   [Inaty, Elie] Univ Balamand, Dept Comp Engn, POB 33, Balamand, Lebanon.
   [Bonnin, Patrick J.] Univ Versailles St Quentin, Lab Ingenierie Syst Versailles LISV, F-78140 Velizy Villacoublay, France.
C3 University Balamand; University Balamand; Universite Paris Saclay
RP Nachar, R (corresponding author), Univ Balamand, Dept Telecommun & Networks, POB 33, Balamand, Lebanon.
EM rabih.nachar@balamand.edu.lb
CR Ahmed ST, 2020, PROCEDIA COMPUT SCI, V167, P2617, DOI 10.1016/j.procs.2020.03.323
   Al Nachar R, 2014, INT J IMAGE GRAPH, V14, DOI 10.1142/S0219467814500181
   [Anonymous], 2006, P IEEE COMPUTER SOC
   Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410
   Barroso-Laguna A, 2023, IEEE T PATTERN ANAL, V45, P698, DOI 10.1109/TPAMI.2022.3145820
   Basak J, 2000, IEEE T NEURAL NETWOR, V11, P1124, DOI 10.1109/72.870044
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BIPM, 2008, GUM series of JCGM
   Csurka G, 2018, ARXIV
   Dias PGT, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2116, DOI 10.1109/ICNN.1995.489004
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Foo J., 2007, P 18 C AUSTRALASIAN, P63
   Garibaldi JM, 2003, IEEE INT CONF FUZZY, P578
   Harris C., 1988, Proc. Alvey Vision Conference
   Horak K, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P636, DOI 10.1109/TSP.2017.8076064
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Lee KJ, 1996, PATTERN RECOGN LETT, V17, P939, DOI 10.1016/0167-8655(96)00051-7
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li B, 2014, IEEE IMAGE PROC, P5741, DOI 10.1109/ICIP.2014.7026161
   Lindeberg T, 2009, ENCY COMPUTER SCI EN, VIV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   MIKOLAJCZYK K, 2004, ICCV
   Olson DL., 2008, Advanced data mining techniques, V1st, P138, DOI [10.1007/978-3-540-76917-0, DOI 10.1007/978-3-540-76917-0]
   Ono Y, 2018, ADV NEUR IN, V31
   Pimenov V, 2009, P 19 INT C COMP GRAP, P49
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schönberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736
   Sergieh HM, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P230, DOI 10.1109/SITIS.2012.42
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Tsai DM, 1997, PATTERN RECOGN, V30, P85, DOI 10.1016/S0031-3203(96)00057-X
   Tyszkiewicz M., 2020, ADV NEURAL INFORM PR
   Van Leekwijck W, 1999, FUZZY SET SYST, V108, P159, DOI 10.1016/S0165-0114(97)00337-0
   Zeng L, 2019, ARXIV
   Zhang X, 2017, PROC CVPR IEEE, P4923, DOI 10.1109/CVPR.2017.523
   Zhao J, 2002, IEEE IND ELEC, P229, DOI 10.1109/IECON.2002.1187512
NR 42
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39459
EP 39480
DI 10.1007/s11042-023-15053-1
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600001
DA 2024-07-18
ER

PT J
AU Amin, F
   Mondal, A
   Mathew, J
AF Amin, Fazail
   Mondal, Arijit
   Mathew, Jimson
TI Person re-identification using selective transformation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Convolutional neural networks; Transformation
   learning; Equivariant transformations
AB Applications like video surveillance, anomaly detection, ego-motion, recognition and re-identification (Re-ID), largely depend upon the ability of the models to learn efficient representations of the input data. Applications like re-identification or similarity matching needs the representations which can handle transformations in the input data in a predictable way. Any change in perspective and viewpoint should not change the identity of the person in re-ID systems and also, it must capture the differences accurately to discriminate two different persons correctly. We propose a Selective Transformation Learning (STL) based model which very efficiently learns to transform the image to obtain the right amount of cropping required to generate feature maps which are invariant to affine transformations of the input image. The STL approach selectively trains each of the spatial transformer modules for specific transformation in an end-to-end framework. Proposed model has very low memory footprint compared to state-of-the-art models yet performs substantially. Compared to the ResNet based or other high capacity models it performs substantially better with such a low capacity. To establish the performance quantitatively it has been tested on three publicly available re-identification datasets and on all the datasets it gives an average of 6% improvement in the mean average precision score as compared to the closest sized state-of-the-art model. This approach can be easily adapted to any other model without any special requirements.
C1 [Amin, Fazail; Mondal, Arijit; Mathew, Jimson] Indian Inst Technol, Comp Sci & Engn, Patna 801106, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Amin, F (corresponding author), Indian Inst Technol, Comp Sci & Engn, Patna 801106, Bihar, India.
EM fazail_1821cs01@iitp.ac.in; arijit@iitp.ac.in; jimson@iitp.ac.in
OI Amin, Fazail/0000-0003-1280-2775
CR [Anonymous], 2017, arXiv
   [Anonymous], 2017, ARXIV
   Bekkers EJ, 2018, INT C MED IM COMP CO, P40
   Bekkers EJ, 2018, IEEE T PATTERN ANAL, V40, P452, DOI 10.1109/TPAMI.2017.2652452
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cohen TS, 2016, PR MACH LEARN RES, V48
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2021, PROC CVPR IEEE, P2014, DOI 10.1109/CVPR46437.2021.00205
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ivanov Y, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P97, DOI 10.1109/CADSM.2015.7230806
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Lenc K, 2015, PROC CVPR IEEE, P991, DOI 10.1109/CVPR.2015.7298701
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JW, 2021, PROC CVPR IEEE, P4368, DOI 10.1109/CVPR46437.2021.00435
   Liu XH, 2021, PROC CVPR IEEE, P13329, DOI 10.1109/CVPR46437.2021.01313
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ni X, 2021, ARXIV
   Ouyang W, 2017, CVPR, P5790, DOI DOI 10.1109/CVPR.2017.499
   Peleshko D., 2011, 2011 11th International Conference The Experience of Designing and Application of CAD Systems in Microelectronics (CADSM 2011), P263
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P159, DOI 10.1109/DSMP.2016.7583531
   Rippel O, 2015, ARXIV
   RUBINSTEIN J, 1991, PATTERN RECOGN, V24, P959, DOI 10.1016/0031-3203(91)90093-K
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tai KS, 2019, PR MACH LEARN RES, V97
   Tan HC, 2022, IEEE T CIRC SYST VID, V32, P160, DOI 10.1109/TCSVT.2021.3061412
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Weiler M, 2018, PROC CVPR IEEE, P849, DOI 10.1109/CVPR.2018.00095
   Wojke N, 2018, IEEE WINT CONF APPL, P748, DOI 10.1109/WACV.2018.00087
   Worrall DE, 2017, PROC CVPR IEEE, P7168, DOI 10.1109/CVPR.2017.758
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Zang X, 2022, IEEE T INDUST INF
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 58
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38993
EP 39013
DI 10.1007/s11042-023-15116-3
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000006
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kori, N
   Chaurasiya, VK
AF Kumar, Ritesh
   Kori, Nikhil
   Chaurasiya, Vijay Kumar
TI Real-time data sharing, path planning and route optimization in urban
   traffic management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban traffic management system; Route optimization; Vehicular ad-hoc
   network(VANET); Load balancer
AB Sharing real-time traffic information can significantly improve traffic congestion. However, sharing traffic information in real-time and dynamically re-routing the vehicles is still a problem that needs a solution. Therefore, this paper proposes a solution for sharing real-time traffic information with low redundancy and complexity. The proposed information distribution technique will share data about abrupt crashes or overcrowding among Road Side Unit (RSU). All RSUs forward real-time traffic information to a central server using the proposed data sharing scheme. The central server then analyzes the data to plan a vehicle route to improve traffic conditions, prevent congestion scenarios, and provide the shortest route to vehicles which it forwards to the vehicles through the RSUs. Since the RSUs are aware of every street occupancy, the proposed approach uses a load balancer at the RSUs to decide whether the additional vehicles can be sent to a particular route or not to prevent overloads. For example, suppose the load balancer finds that no more vehicles can be sent to a particular road. In that case, it uses the k-optimized routes with constrained crossovers challenge algorithm to generate the substitute routes for the vehicles. The result shows that the proposed real-time information sharing algorithm has significantly reduced redundancy and computation complexity in scenarios such as abrupt overcrowding in the road network. In addition, the results show that the computational complexity had been lowered to O(n+m) from O(n x m), and the average traveling time of the vehicles is reduced by more than 50% compared to the existing approaches like System with CO operative Routing to imProve traffic cONdition (SCORPION) and DIstributed VEhicular Traffic Re-routing System for Congestion Avoidance (DIVERT) under the same simulation conditions.
C1 [Kumar, Ritesh; Kori, Nikhil; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol, Allahabad, India.
C3 Indian Institute of Information Technology Allahabad
RP Kumar, R (corresponding author), Indian Inst Informat Technol, Allahabad, India.
EM pwc2016002@iiita.ac.in; vijayk@iiita.ac.in
OI KUMAR, RITESH/0000-0001-7934-2369
CR Akabane AT, 2020, COMPUT COMMUN, V151, P306, DOI 10.1016/j.comcom.2020.01.002
   [Anonymous], 2007, Facebook white paper 5
   Bowen Yang, 2021, Journal of Physics: Conference Series, V1756, DOI 10.1088/1742-6596/1756/1/012005
   Brennand CARL, 2017, IEEE SYMP COMP COMMU, P377, DOI 10.1109/ISCC.2017.8024559
   Chakraborty B, 2005, SMCIA/05: PROCEEDINGS OF THE 2005 IEEE MID-SUMMER WORKSHOP ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS, P190
   Chondrogiannis T, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820858
   Collins KrystalM., 2008, PETROGRAPHY COOK MCC, P1, DOI [10.1061/41009(333)27, DOI 10.1061/41009(333)27]
   de Souza AM, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P726, DOI 10.1109/ISCC.2016.7543822
   de Souza AM, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P497, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.71
   Ely SR., 1990, Car and its Environment-What DRIVE and PROMETHEUS Have to Offer, IEE Colloquium on, P8
   Figueiredo L, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P1206, DOI 10.1109/ITSC.2001.948835
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Google, 2023, GOOGL MAPS
   Googlegroups, 2023, OMNET
   Guo C, 2018, IEEE T VEH TECHNOL, V67, P5635, DOI 10.1109/TVT.2018.2806979
   Hartenstein H., 2009, VANET: Vehicular Applications and Inter-Networking Technologies
   Kakahama HK., 2020, UHD J SCI TECHNOL, V4, P107, DOI [10.21928/uhdjst.v4n2y2020.pp107-116, DOI 10.21928/UHDJST.V4N2Y2020.PP107-116]
   Kenney JB, 2011, P IEEE, V99, P1162, DOI 10.1109/JPROC.2011.2132790
   Lin C, 2020, IEEE INTERNET THINGS, V7, P8012, DOI 10.1109/JIOT.2020.2994963
   Liu JP, 2019, INTELL AUTOM SOFT CO, V25, P65
   Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938
   Martins EQV, 2003, 4OR-Q J OPER RES, V1, P121, DOI 10.1007/s10288-002-0010-2
   Meneguette R.I., 2015, 2015 IEEE S COMPUTER, P1, DOI 10.1109/ISCC.2015.8897528
   Noori H, 2013, INT CONF CONNECT VEH, P654, DOI [10.1109/ICCVE.2013.161, 10.1109/ICCVE.2013.6799873]
   Pan J, 2012, 2012 IEEE 8TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS (DCOSS), P265, DOI 10.1109/DCOSS.2012.29
   Sommer C, 2023, VEINS
   Wang M, 2015, IEEE T VEH TECHNOL, V64, P1664, DOI 10.1109/TVT.2014.2335201
   Wang XJ, 2018, IEEE COMMUN MAG, V56, P19, DOI 10.1109/MCOM.2018.1701065
   YEN JY, 1970, Q APPL MATH, V27, P526, DOI 10.1090/qam/253822
NR 29
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36343
EP 36361
DI 10.1007/s11042-023-15148-9
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000958668000007
DA 2024-07-18
ER

PT J
AU Moral, P
   García-Martín, A
   Martínez, JM
   Bescós, J
AF Moral, Paula
   Garcia-Martin, Alvaro
   Martinez, Jose M.
   Bescos, Jesus
TI Enhancing vehicle re-identification via synthetic training datasets and
   re-ranking based on video-clips information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle re-identification; Deep learning; Image processing; Surveillance
   videos
ID PERSON REIDENTIFICATION
AB Vehicle re-identification (ReID) aims to find a specific vehicle identity across multiple non-overlapping cameras. The main challenge of this task is the large intra-class and small inter-class variability of vehicles appearance, sometimes related with large viewpoint variations, illumination changes or different camera resolutions. To tackle these problems, we proposed a vehicle ReID system based on ensembling deep learning features and adding different post-processing techniques. In this paper, we improve that proposal by: incorporating large-scale synthetic datasets in the training step; performing an exhaustive ablation study showing and analyzing the influence of synthetic content in ReID datasets, in particular CityFlow-ReID and VeRi-776; and extending post-processing by including different approaches to the use of gallery video-clips of the target vehicles in the re-ranking step. Additionally, we present an evaluation framework in order to evaluate CityFlow-ReID: as this dataset has not public ground truth annotations, AI City Challenge provided an on-line evaluation service which is no more available; our evaluation framework allows researchers to keep on evaluating the performance of their systems in the CityFlow-ReID dataset.
C1 [Moral, Paula; Garcia-Martin, Alvaro; Martinez, Jose M.; Bescos, Jesus] Univ Autonoma Madrid, Video Proc & Understanding Lab VPULab, Madrid 28049, Spain.
C3 Autonomous University of Madrid
RP Moral, P (corresponding author), Univ Autonoma Madrid, Video Proc & Understanding Lab VPULab, Madrid 28049, Spain.
EM paula.moral@estudiante.uam.es; alvaro.garcia@uam.es;
   josem.martinez@uam.es; j.bescos@uam.es
RI Martinez, Jose M./A-1185-2008
FU Ministerio de Ciencia e Innovacion of the Spanish Government
   [PID2021-125051OB-I00]
FX AcknowledgementsThis work is part of the preliminary tasks related to
   the Harvesting Visual Data (HVD) project (PID2021-125051OB-I00) funded
   by the Ministerio de Ciencia e Innovacion of the Spanish Government.
CR Ang KL, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11020085
   Ansari JA, 2018, IEEE INT C INT ROBOT, P8404, DOI 10.1109/IROS.2018.8593698
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Chang M.-C., 2020, P IEEECVF C COMPUTER, P620
   Chen XY, 2021, J INTELL TRANSPORT S, V26, P100, DOI 10.1080/15472450.2020.1797502
   Dai ZZ, 2021, Arxiv, DOI [arXiv:2103.11568, 10.48550/arXiv.2103.11568]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eckstein V, 2020, IEEE COMPUT SOC CONF, P2626, DOI 10.1109/CVPRW50498.2020.00316
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gao JY, 2018, Arxiv, DOI arXiv:1805.02104
   Ghosh A, 2021, Arxiv, DOI arXiv:2110.07933
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S., 2020, P IEEECVF C COMPUTER, P582
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Tsung-Wei., 2019, IEEE C COMPUT VIS PA, P434
   Huynh SV, 2021, IEEE COMPUT SOC CONF, P4142, DOI 10.1109/CVPRW53098.2021.00468
   Khan AW, 2021, IEEE ACCESS, V9, P107309, DOI 10.1109/ACCESS.2021.3100287
   Khan SD, 2019, COMPUT VIS IMAGE UND, V182, P50, DOI 10.1016/j.cviu.2019.03.001
   Kingma D. P., 2014, arXiv
   Lee S, 2020, PROC CVPR IEEE, P269, DOI 10.1109/CVPR42600.2020.00035
   Liu XC, 2016, IEEE INT CON MULTI
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lv K., 2019, P CVPR WORKSH LONG B, P399
   Ma Y, 2020, IEEE T INTELL TRANSP, P1
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Moral P, 2020, IEEE COMPUT SOC CONF, P2574, DOI 10.1109/CVPRW50498.2020.00310
   Naphade M, 2020, IEEE COMPUT SOC CONF, P2665, DOI 10.1109/CVPRW50498.2020.00321
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Parkhiya P, 2018, IEEE INT CONF ROBOT, P4517
   Peng JJ, 2020, MULTIMED TOOLS APPL, V79, P32731, DOI 10.1007/s11042-020-09356-w
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Sebastian C, 2020, P IEEE CVF C COMP VI, P580
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang Z, 2019, IEEE I CONF COMP VIS, P211, DOI 10.1109/ICCV.2019.00030
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yao Y, 2019, SIMULATING CONTENT C
   Zakira J, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9243162
   Zhao YZ, 2020, IEEE T INTELL TRANSP, V21, P723, DOI 10.1109/TITS.2019.2896273
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Z, 2019, PROC CVPR WORKSHOPS, V2, P1
   Zheng ZD, 2020, IEEE COMPUT SOC CONF, P2550, DOI 10.1109/CVPRW50498.2020.00307
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou Y., 2017, 1 AS AUSTR C PREC PA, P1, DOI DOI 10.5244/C.31.186
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhu JQ, 2019, MULTIMED TOOLS APPL, V78, P29043, DOI 10.1007/s11042-018-6270-4
   Zhu XY, 2020, IEEE COMPUT SOC CONF, P2566, DOI 10.1109/CVPRW50498.2020.00309
   Zhuge C, 2020, P IEEECVF C COMPUTER, P618
NR 55
TC 2
Z9 2
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-14511-0
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Pardhu, T
   Kumar, V
AF Pardhu, Thottempudi
   Kumar, Vijay
TI Human motion classification using Impulse Radio Ultra Wide Band
   through-wall RADAR model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human motion detection; Radar; Texture features; Deep learning; IR-UWB
ID ALGORITHM; TRANSFORM; TRACKING; SIGNAL
AB The detection of human motion is receiving more attention amongst researchers, and is important in several applications. However, the issue is to offer effective monitoring sensors amongst various platforms without diminishing privacy. The radar models are beneficial for detecting human motion due to their potential to detect targets from long ranges and work in all types of weather. This paper develops a technique for human motion classification using Impulse Radio Ultra Wide Band (IR-UWB) with a wall radar model. The goal is to devise a human motion classification framework using a Random Multimodal Deep Learning (RMDL), which is tuned by the proposed optimization algorithm. Here, the Ultra Wide Band (UWB) signals are employed in the gridding process to evaluate the grids. The grids are adapted for feature extraction wherein the Hilbert transform features and texture features, like Local Gradient Pattern (LGP) and Local Optimal Oriented Pattern (LOOP) are considered. These features are considered in RMDL for identifying human motion. The training of RMDL is done using the proposed Spotted Grey Wolf Optimizer (SGWO), which is obtained by combining Spotted Hyena Optimizer (SHO) and Grey Wolf optimizer (GWO). The developed SGWO-based RMDL offered effective performance with the highest accuracy of 0.956, smallest Mean square error (MSE) of 0.200, highest True negative rate (TNR) of 0.959, and highest true positive rate (TPR) of 0.956.
C1 [Pardhu, Thottempudi] VIT Univ, Sch Elect Engn, Vellore, TamilNadu, India.
   [Kumar, Vijay] VIT Univ, Sch Elect Engn, Vellore, TamilNadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Pardhu, T (corresponding author), VIT Univ, Sch Elect Engn, Vellore, TamilNadu, India.
EM thottempudi.pardhu2015@vit.ac.in; vijaykumar@vit.ac.in
RI thottempudi, pardhu/KVC-1655-2024
OI thottempudi, pardhu/0000-0002-9653-1951
CR Amit Sarkar, 2020, Multimedia Research, V3
   An Q, 2021, IEEE SENS J, V21, P19058, DOI 10.1109/JSEN.2021.3088122
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chang X, 2021, HINDAWI VISUAL SENSI
   Chen L, 2021, IEEE ACCESS, V9, P90529, DOI 10.1109/ACCESS.2021.3091430
   Choudhury A, 2020, JMIR MED INF, V8, DOI 10.2196/18599
   Cristin R, 2020, J NETWORKING COMMUNI, V3, DOI [10.46253/JNACS.V3I2.A3, DOI 10.46253/JNACS.V3I2.A3]
   Darekar A. P., 2019, Multimed Res., V2, P12
   Debes C, 2012, IEEE T GEOSCI REMOTE, V50, P1968, DOI 10.1109/TGRS.2011.2170077
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Gaikwad V. S, 2021, J. Comput. Mech., Power Syst. Control, V4, P35
   Gennarelli G, 2015, IEEE T GEOSCI REMOTE, V53, P6482, DOI 10.1109/TGRS.2015.2441957
   Gurbuz SZ, 2019, IEEE SIGNAL PROC MAG, V36, P16, DOI 10.1109/MSP.2018.2890128
   Hartikainen A, 2018, CONSTR BUILD MATER, V158, P1090, DOI 10.1016/j.conbuildmat.2017.10.075
   Jenik V, 2018, RADIOENGINEERING, V27, P620, DOI 10.13164/re.2018.0620
   Jia Y, 2011, IEEE RAD CONF, P103
   Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219
   Kaviyaraj R., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P47, DOI 10.1109/ICAIS50930.2021.9395838
   Kiliç A, 2019, INT J ANTENN PROPAG, V2019, DOI 10.1155/2019/7541814
   Kowsari K, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), P19, DOI 10.1145/3206098.3206111
   Li J, 2012, IEEE GEOSCI REMOTE S, V9, P1079, DOI 10.1109/LGRS.2012.2190707
   Marimuthu J, 2014, IEEE ANTENNAS PROP, P1909, DOI 10.1109/APS.2014.6905281
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Narayanan Ram M., 2014, International Journal of Microwave Science and Technology, DOI 10.1155/2014/958905
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Pieraccini M, 2000, NDT&E INT, V33, P565, DOI 10.1016/S0963-8695(00)00027-X
   Qi FG, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060885
   Rittiplang A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236828
   Saeed T., 2019, Int. J. Intell. Eng. Syst., V12, P317
   Shukla S, 2009, IEEE T POWER DELIVER, V24, P2159, DOI 10.1109/TPWRD.2009.2028792
   Smith GE, 2012, IEEE T IMAGE PROCESS, V21, P754, DOI 10.1109/TIP.2011.2166967
   Urban TM, 2014, J ARCHAEOL SCI, V42, P260, DOI 10.1016/j.jas.2013.11.017
   Wang H, 2009, IEEE ANTENN WIREL PR, V8, P802, DOI 10.1109/LAWP.2009.2021586
   Wang K, 2019, IEEE GEOSCI REMOTE S, V16, P717, DOI 10.1109/LGRS.2018.2881311
   Wang Y., 2016, EURASIP J. Wireless Commun. Netw, V2016, P1
   Wei XM, 2014, IEEE J-STARS, V7, P4860, DOI 10.1109/JSTARS.2014.2321710
   Will C, 2019, IEEE SENS J, V19, P7283, DOI 10.1109/JSEN.2019.2914365
   Wu SY, 2016, IET RADAR SONAR NAV, V10, P468, DOI 10.1049/iet-rsn.2015.0159
   Yang DG, 2019, IEEE ACCESS, V7, P178879, DOI 10.1109/ACCESS.2019.2958600
   Zhu ZL, 2021, J SYST ENG ELECTRON, V32, P1083, DOI 10.23919/JSEE.2021.000093
NR 40
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-14496-w
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900001
DA 2024-07-18
ER

PT J
AU Jeena, P
   Shreelekshmi, R
AF Jeena, P.
   Shreelekshmi, R.
TI High capacity reversible data hiding in encrypted images using block
   labeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Reversible data hiding; Huffman coding; Median edge
   detector
AB We propose a method of secure and reversible data hiding in encrypted images which ensures lossless recovery of image contents and data with very high embedding capacity. The proposed reversible data hiding method in encrypted images makes use of median edge detector predictor and Huffman coding for reducing the size of axillary information. The proposed method utilizes the spatial correlation of the image for reserving room for data embedding before encryption. Hiding capacity of each 2 x 2 block in the image is calculated based on the prediction error using the median edge detector. The hiding capacities of adjacent four blocks are labeled using Huffman coding, which reduces the size of the auxiliary information hidden along with secret data embedded in the encrypted image. Proposed method does data hiding without changing the characteristics of encrypted image for ensuring security and recovers data and image contents completely. The experimental results show that the proposed method hides higher payload with an average value of 3.34 bpp which is 25 percentage more than the state of the art methods.
C1 [Jeena, P.] Govt Engn Coll, Dept Comp Sci & Engn, Trichur 680009, Kerala, India.
   [Shreelekshmi, R.] Govt Engn Coll, Dept Comp Sci & Engn, Barton Hill, Thiruvananthapuram 695035, Kerala, India.
C3 Government Engineering College Thrissur
RP Jeena, P (corresponding author), Govt Engn Coll, Dept Comp Sci & Engn, Trichur 680009, Kerala, India.
EM tcr19csce09@gectcr.ac.in; shreelekshmir@gecbh.ac.in
RI R, Shreelekshmi/AAH-6910-2020
OI R, Shreelekshmi/0000-0002-6523-3652
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2017, Image database of BOWS-2
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Lee CF, 2011, IMAGING SCI J, V59, P278, DOI 10.1179/1743131X10Y.0000000018
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Ren H, 2019, IEEE ACCESS, V7, P149527, DOI 10.1109/ACCESS.2019.2946929
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 18
TC 1
Z9 1
U1 7
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25883
EP 25898
DI 10.1007/s11042-023-14455-5
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000947594500006
DA 2024-07-18
ER

PT J
AU Sani, MR
AF Sani, Mehran Rastegar
TI Multi object tracking in soccer video focusing on occlusion detection
   and resolving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi object tracking; Occlusion resolving; Field line detection;
   Playfield extraction; Player detection
ID PARTICLE SWARM OPTIMIZATION; EXTRACTION
AB Today, due to the growth of data and the development of receiving and storing technologies, large datasets have been created in various fields, such as soccer video datasets. Since obtaining the information manually from large datasets is very difficult, an automated system to capture important information from soccer videos is strongly needed. Automated analysis of soccer videos includes many applications such as: analyzing team tactics, confirming referees' decisions, summarizing videos, etc.In this paper, a forward-backward algorithm is proposed to increase the performance of player detection and tracking. The purpose of this algorithm is to identify and resolve the occlusions among the players and improve the preprocessing steps (playfield extraction and field lines elimination). We also proposed a new method for each preprocessing step to improve the performance of the tracking system. The evaluations show that our tracking algorithm has performed better than previous methods (89% locally and 78% globally).
C1 [Sani, Mehran Rastegar] Sadjad Univ Technol, Comp & Informat Technol Dept, Mashhad, Iran.
RP Sani, MR (corresponding author), Sadjad Univ Technol, Comp & Informat Technol Dept, Mashhad, Iran.
EM m.rastegar1993@gmail.com
OI RastegarSani, Mehran/0000-0001-5512-9205
CR [Anonymous], 2018, COMPUT VIS IMAGE UND
   Asghar Muhammad Nabeel, 2014, International Journal of Computer and Information Technology, V3, P148
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Choi K, 2011, PATTERN RECOGN LETT, V32, P1274, DOI 10.1016/j.patrec.2011.03.009
   Choros K, 2016, ADV INTELLIGENT SYST, P39
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Herrmann M, 2014, AASRI PROC, V8, P30, DOI 10.1016/j.aasri.2014.08.006
   Heydari M, 2012, INT CONF ROBOT ARTIF, P195, DOI 10.1109/ICRAI.2012.6413398
   Hu T, 2013, LECT NOTES COMPUT SC, V8157, P693, DOI 10.1007/978-3-642-41184-7_70
   Kim W, 2018, MULTIMEDIA SYST
   Li, 2012, 2012 IEEE INT C ACOU
   Mackowiak S, 2010, LECT NOTES COMPUT SC, V6375, P118, DOI 10.1007/978-3-642-15907-7_15
   Manafifard M, 2017, COMPUT VIS IMAGE UND, V159, P19, DOI 10.1016/j.cviu.2017.02.002
   Manafifard M, 2017, SIGNAL PROCESS-IMAGE, V55, P157, DOI 10.1016/j.image.2017.04.001
   Manafifard M, 2017, MULTIMED TOOLS APPL, V76, P12251, DOI 10.1007/s11042-016-3625-6
   Manafifard M, 2015, SCI IRAN, V22, P1031
   Mathes T, 2006, LECT NOTES COMPUT SC, V4174, P515
   Mentzelopoulos M, 2013, NEURAL PROCESS LETT, V37, P33, DOI 10.1007/s11063-012-9267-4
   Moyyila UR, 2015, THESIS
   Najafzadeh N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P310, DOI 10.1109/AISP.2015.7123503
   Patil, 2012, SOCCER VIDEOS, V3, P2365
   Sasithradevi A., 2016, Circuits Syst, V7, P2875, DOI [10.4236/cs.2016.710246, DOI 10.4236/CS.2016.710246]
   Schlipsing M, 2017, J REAL-TIME IMAGE PR, V13, P345, DOI 10.1007/s11554-014-0406-1
   Yang Y, 2017, J VIS COMMUN IMAGE R, V46, P81, DOI 10.1016/j.jvcir.2017.03.008
   Zhang P, 2018, MULTIMED TOOLS APPL, V77, P18935, DOI 10.1007/s11042-017-5316-3
   Zhang S., 2015, INT J MULTIMED UBIQU, V10, P75, DOI [10.14257/ijmue.2015.10.7.08, DOI 10.14257/IJMUE.2015.10.7.08]
NR 30
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35913
EP 35947
DI 10.1007/s11042-023-14798-z
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500011
DA 2024-07-18
ER

PT J
AU Zhang, ZC
   Gao, YH
   Xiong, MY
   Luo, XQ
   Wu, XJ
AF Zhang, Zhancheng
   Gao, Yuanhao
   Xiong, Mengyu
   Luo, Xiaoqing
   Wu, Xiao-Jun
TI A joint convolution auto-encoder network for infrared and visible image
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Joint convolution auto-encoder network; Infrared image;
   Visible image; Fusion rule
ID FRAMEWORK; TRANSFORM
AB Background: Leaning redundant and complementary relationships is a critical step in the human visual system. Inspired by the infrared cognition ability of crotalinae animals, we design a joint convolution auto-encoder (JCAE) network for infrared and visible image fusion. Methods: Our key insight is to feed infrared and visible pair images into the network simultaneously and separate an encoder stream into two private branches and one common branch, the private branch works for complementary features learning and the common branch does for redundant features learning. We also build two fusion rules to integrate redundant and complementary features into their fused feature which are then fed into the decoder layer to produce the final fused image. We detail the structure, fusion rule and explain its multi-task loss function. Results: Our JCAE network achieves good results in terms of both visual quality and objective evaluation metrics.
C1 [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Suzhou, Peoples R China.
   [Gao, Yuanhao; Xiong, Mengyu; Luo, Xiaoqing; Wu, Xiao-Jun] Jiangnan Univ, Wuxi, Peoples R China.
C3 Suzhou University of Science & Technology; Jiangnan University
RP Luo, XQ (corresponding author), Jiangnan Univ, Wuxi, Peoples R China.
EM xqluo@jiangnan.edu.cn
RI Luo, Xiaoqing/AAM-2176-2021; Gao, Yuanhao/KFS-3943-2024
FU National Natural Science Foundation of P. R. China [61772237]; Six
   Talent Peaks Project in Jiangsu Province [XYDXX-030]
FX This study was funded by the National Natural Science Foundation of P.
   R. China (grant number 61772237) and the Six Talent Peaks Project in
   Jiangsu Province (grant numbe XYDXX-030).
CR Bertinetto L., 2016, ARXIV
   [陈木生 Chen Musheng], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P39
   Deshmukh M., 2010, Int. J. Image Process. (IJIP), V4, P484
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Epstein B, 2017, ARXIV
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li Qi-shen, 2009, Application Research of Computers, V26, P1138
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo XQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3105250
   Luo XQ, 2017, IEEE SENS J, V17, P1760, DOI 10.1109/JSEN.2016.2646741
   Luo XQ, 2016, AEU-INT J ELECTRON C, V70, P186, DOI 10.1016/j.aeue.2015.11.004
   Luo XD, 2022, IEEE T NEUR NET LEAR, V33, P4173, DOI 10.1109/TNNLS.2021.3055991
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Pang HC, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P543, DOI 10.1109/CISP.2012.6469884
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Toet A, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.010901
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Wu F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107632
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Ye Chuan-qi, 2008, Systems Engineering and Electronics, V30, P593
   Yujian F, 2021, IEEE SIGNAL PROC LET, V28, P1425, DOI 10.1109/LSP.2021.3093865
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
NR 34
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29017
EP 29035
DI 10.1007/s11042-023-14758-7
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000945792800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kamil, MHM
   Zaini, N
   Mazalan, L
   Ahamad, AH
AF Kamil, Muhammad Haikal Mohd
   Zaini, Norliza
   Mazalan, Lucyantie
   Ahamad, Afiq Harith
TI Online attendance system based on facial recognition with face mask
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attendance system; Online; Face recognition; Face mask detection;
   OpenCV; Python
AB This paper presents an online system for recording attendance based on facial recognition incorporating facial mask detection. The main objective of this project is to develop an effective attendance system based on face recognition and face mask detection, and to provide this service online through a browser interface. This would allow any user to use this system without the need to install special software. They simply need to open the interface of this system in a browser through any terminal. Recording attendance information online allows data to be easily recorded in a centralized online database. Since faces are used as biometric signatures in this project, all users registered in the system will have their profiles loaded with their face-images samples. Initially, before face recognition can be done, the model training phase based on SVM will be carried out, mainly to develop a trained model that can perform face recognition. A set of synthetic data will also be used to train the same model so that it can perform identification for users wearing face masks. The server application is coded in Python and uses the Open-Source Computer Vision (OpenCV) library for image processing. For web interfaces and the database, PHP and MySQL are used. With the integration of Python and PHP scripting programs, the developed system will be able to perform processing on online servers, while being accessible to users through a browser from any terminal. According to the results and analysis, an accuracy of about 81.8% can be achieved based on a pre-trained model for face recognition and 80% for face mask detection.
C1 [Kamil, Muhammad Haikal Mohd; Zaini, Norliza; Mazalan, Lucyantie; Ahamad, Afiq Harith] Univ Teknol MARA, Coll Engn, Sch Elect Engn, Shah Alam 40450, Selangor, Malaysia.
C3 Universiti Teknologi MARA
RP Zaini, N (corresponding author), Univ Teknol MARA, Coll Engn, Sch Elect Engn, Shah Alam 40450, Selangor, Malaysia.
EM nzaini815@gmail.com
FU Universiti Teknologi MARA (UiTM) via the Lestari Covid-19 Research Grant
   [600-RMC/LESTARI COVID/5/3 (008/2020)]
FX We would like to extend our acknowledgment to those who have directly
   and indirectly contributed to our project. This research is funded by
   Universiti Teknologi MARA (UiTM) via the Lestari Covid-19 Research Grant
   registered as 600-RMC/LESTARI COVID/5/3 (008/2020).
CR Arulogun OT, 2013, INT J ENG SCI RES, V4
   Bhuiyan M.M., 2020, 2020 11 INT C COMPUT, P1, DOI DOI 10.1109/ICCCNT49239.2020.9225384
   Confusion Matrix, 2019, DAT SCI MACH LEARN
   Hameed MAJ., 2017, INT RES J ENG TECHNO, V12, P2395
   Hussain SMS, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960243
   Jacksi K, 2018, SCHOLARS J ENG TECHN, V6, P49, DOI DOI 10.21276/SJET.2018.6.2.1
   LAI CC, 2020, INT J ANTIMICROB AG, V55, DOI DOI 10.1016/J.IJANTIMICAG.2020.105924
   Lippert P, 2020, FACE MASK DETECTOR, DOI [10.13140/RG.2.2.32147.50725, DOI 10.13140/RG.2.2.32147.50725]
   Lu HZ, 2020, J MED VIROL, V92, P401, DOI [10.1002/jmv.2567, 10.1002/jmv.25678]
   Rosebrock A, 2020, COVID 19 FACE MASK D
   Rosebrock A, 2018, OPENCV FACE RECOGNIT
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Sajid M, 2014, 2014 NINTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P7, DOI 10.1109/ICDIM.2014.6991407
   Sunaryono D, 2021, J KING SAUD UNIV-COM, V33, P304, DOI 10.1016/j.jksuci.2019.01.006
NR 14
TC 2
Z9 2
U1 20
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34437
EP 34457
DI 10.1007/s11042-023-14842-y
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943966200001
PM 37362736
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Parida, P
   Pradhan, C
   Alzubi, JA
   Javadpour, A
   Gheisari, M
   Liu, Y
   Lee, CC
AF Parida, Priyansi
   Pradhan, Chittaranjan
   Alzubi, Jafar A.
   Javadpour, Amir
   Gheisari, Mehdi
   Liu, Yang
   Lee, Cheng-Chi
TI Elliptic curve cryptographic image encryption using Henon map and
   Hopfield chaotic neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Digital signature; Elliptic curve; Henon map; Hopfield
   neural network; Image encryption
ID DNA ENCRYPTION; ALGORITHM; SCHEME; CRYPTOSYSTEM; SYSTEM
AB In this paper, a new chaotic image encryption and authentication model based on Elliptic Curves is proposed. The Elliptic Curve Diffie-Hellman (ECDH) is used to generate a reliable session key prior to encryption. The scheme uses the Henon map for the initial shuffling of the pixels and the Hopfield chaotic neural network to compute random chaotic values. The chaotic matrix is XORed with henon shuffled image. The model encrypts the scrambled image using improved ElGamal encoding to obtain the cipher image. The model employs a low computational cost digital signature to check for the authenticity of the received encrypted images before decryption. The proposed model makes use of a large key space to resist brute force attacks, and produces randomized cipher images with high average Shannon's entropies, 7.9994 for grayscale and 7.9993 for color images, and lower adjacent pixel correlation to resist statistical attacks and ensure a good quality encryption. The model can withstand the chosen-plaintext and known-plaintext attacks, and attains average Number of Pixel Change Rate (NPCR) and Unified Average Change Intensity (UACI) values of (99.63%, 33.345%) for grayscale and (99.625%, 33.34%) for color images signifying its effectiveness against differential attacks. The ability to recover decipherable images after masking up to 75% of cipher image indicates the robustness of the proposed scheme against the occlusion attacks.
C1 [Parida, Priyansi; Pradhan, Chittaranjan] KIIT Univ, Sch Comp Engn, Bhubaneswar 751024, Orissa, India.
   [Alzubi, Jafar A.] Al Balqa Appl Univ, Fac Engn, Salt 19117, Jordan.
   [Javadpour, Amir; Gheisari, Mehdi; Liu, Yang] Harbin Inst Technol Shenzhen, Dept Comp Sci & Technol, Shenzhen, Peoples R China.
   [Gheisari, Mehdi] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Inst Comp Sci & Engn, Dept Cognit Comp, Chennai, India.
   [Gheisari, Mehdi] Islamic Azad Univ, Dept Comp Sci, Damavand, Iran.
   [Lee, Cheng-Chi] Fu Jen Catholic Univ, Res & Dev Ctr Phys Educ Hlth & Informat Technol, Dept Lib & Informat Sci, New Taipei City, Taiwan.
   [Lee, Cheng-Chi] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Kalinga Institute of Industrial Technology (KIIT); Al-Balqa Applied
   University; Harbin Institute of Technology; Saveetha Institute of
   Medical & Technical Science; Saveetha School of Engineering; Islamic
   Azad University; Fu Jen Catholic University; Asia University Taiwan
RP Gheisari, M; Liu, Y (corresponding author), Harbin Inst Technol Shenzhen, Dept Comp Sci & Technol, Shenzhen, Peoples R China.; Gheisari, M (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Inst Comp Sci & Engn, Dept Cognit Comp, Chennai, India.; Gheisari, M (corresponding author), Islamic Azad Univ, Dept Comp Sci, Damavand, Iran.
EM priyansiparida@gmail.com; chitaprakash@gmail.com;
   mehdi.gheisari61@gmail.com; liu.yang@hit.edu.cn
RI Pradhan, Chittaranjan/M-4989-2013; Javadpour, Amir/AEM-2932-2022; Lee,
   Cheng-Chi/AGH-0724-2022; Liu, Yang/D-2306-2013
OI Javadpour, Amir/0000-0002-4932-1660; Lee, Cheng-Chi/0000-0002-8918-1703;
   Liu, Yang/0000-0001-7300-9215; Liu, Yang/0000-0003-2486-5765; Gheisari,
   Mehdi/0000-0002-5643-0021
CR A Javadpour, 2016, J Biomed Phys Eng, V6, P95
   Abdelfatah RI, 2020, IEEE ACCESS, V8, P3875, DOI 10.1109/ACCESS.2019.2958336
   Al-Hazaimeh OM, 2019, NEURAL COMPUT APPL, V31, P2395, DOI 10.1007/s00521-017-3195-1
   Amina Souyah, 2018, Communications in Nonlinear Science and Numerical Simulation, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Brainpool ECC, 2021, ELL CURV CERYPT ECC
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Certicom Research, 2009, Stand Effic Cryptogr, V1, P1, DOI [10.1002/smj, DOI 10.1002/SMJ]
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Demir FB, 2020, NEURAL COMPUT APPL, V32, P14227, DOI 10.1007/s00521-020-04815-9
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Herbadji D, 2020, IET IMAGE PROCESS, V14, P40, DOI 10.1049/iet-ipr.2019.0123
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Luo YL, 2016, NONLINEAR DYNAM, V83, P2293, DOI 10.1007/s11071-015-2481-7
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Ping P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P429, DOI 10.1109/ICInfA.2015.7279326
   Saljoughi AS, 2019, PATTERN ANAL APPL, V22, P243, DOI 10.1007/s10044-018-0765-5
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P11675, DOI 10.1007/s11042-018-6711-0
   Science C., 2015, RECOGNITION PARADIGM, P21
   Shah Krishna, 2018, IEEE INT C EM TRENDS, P1, DOI 10.1109/ICINPRO43533.2018.9096789
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Sun S, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.3.034113
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Tang Z., 2019, Security and Communication Networks, V2019
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   USC-SIPI Image Database, 2021, USC SIGN IM PROC I S
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Ye GD, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/1/010501
   Yu ZQ, 2020, IEEE ACCESS, V8, P67085, DOI 10.1109/ACCESS.2020.2985839
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XP, 2018, CHINESE PHYS B, V27, DOI 10.1088/1674-1056/27/8/080701
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang ZJ, 2022, IEEE T NEUR NET LEAR, V33, P6856, DOI 10.1109/TNNLS.2021.3083710
NR 58
TC 13
Z9 13
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33637
EP 33662
DI 10.1007/s11042-023-14607-7
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943970200001
DA 2024-07-18
ER

PT J
AU Fu, XP
   Ding, XY
   Liang, Z
   Wang, YF
AF Fu, Xianping
   Ding, Xueyan
   Liang, Zheng
   Wang, Yafei
TI Jointly adversarial networks for wavelength compensation and dehazing of
   underwater images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Underwater image; Wavelength
   compensation; Dehazing
ID INHERENT OPTICAL-PROPERTIES; COLOR CORRECTION; ENHANCEMENT; RESTORATION
AB Severe color casts, low contrast, and blur of underwater images caused by light absorption and scattering result in a challenging task for exploring underwater environments. In this paper, we propose a novel joint wavelength compensation and dehazing network (JWCDN) to remove the degradation effects caused by light absorption and scattering. The joint learning framework is based on an improved underwater image formation model that takes into account the vertical (water surface-object path) and horizontal (object-camera path) effects of light propagation in water. By embedding the underwater image formation model into a generative adversarial network, we can jointly estimate the transmission map, wavelength attenuation, and background light via different network modules, and use the underwater image formation model to recover degraded underwater images. To further improve the recovered image, we use an edge-preserving network module to enhance the detail of the recovered image. Moreover, to train the proposed network, we present an effective underwater image synthesis method that generates underwater images using the optical attenuation coefficients of different water types. The synthesis method can simulate the color, contrast, and blur of different underwater imaging environments. Extensive experiments on synthetic and real-world underwater images demonstrate that the proposed method yields comparable or better results on both subjective and objective assessments, compared with several state-of-the-art methods.
C1 [Fu, Xianping; Ding, Xueyan; Liang, Zheng; Wang, Yafei] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Fu, Xianping] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
C3 Dalian Maritime University; Peng Cheng Laboratory
RP Wang, YF (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM fxp@dlmu.edu.cn; dingxueyan@dlmu.edu.cn; zliang@dlmu.edu.cn;
   wangyafei@dlmu.edu.cn
RI Ding, Xueyan/IAP-7838-2023
FU National Natural Science Foundation of China [62002043, 62176037,
   61802043]; Liaoning Applied Basic Research Project [2022JH2/101300264];
   Dalian Science and Technology Innovation Fund [2022JJ12GX016,
   2021JJ12GX028]; China Postdoctoral Science Foundation [2022M720630]
FX This work was supported in part by the National Natural Science
   Foundation of China Grants 62002043, 62176037, 61802043, by the Liaoning
   Applied Basic Research Project Grant 2022JH2/101300264, by the Dalian
   Science and Technology Innovation Fund Grants 2022JJ12GX016,
   2021JJ12GX028, by the China Postdoctoral Science Foundation Grant
   2022M720630.
CR Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Barshan E., 2015, FEATURE EXTRACTION M, P49
   Berman D, 2020, IEEE INT CONF COMPUT
   Bonin F., 2011, Journal of Maritime Research, V8, P65
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Ding XY, 2022, OPT LASER ENG, V152, DOI 10.1016/j.optlaseng.2022.106971
   Ding XY, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116408
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XP, 2020, OPT LASER ENG, V132, DOI 10.1016/j.optlaseng.2020.106115
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hassan N, 2021, MULTIMED TOOLS APPL, V80, P1839, DOI 10.1007/s11042-020-09752-2
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, MULTIMED TOOLS APPL, V79, P20199, DOI 10.1007/s11042-020-08759-z
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Jerlov N, 1968, OPTICAL OCEANOGRAPHY, P118
   Jiang N, 2021, IEEE T MULTIMEDIA
   Jiang Q, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108324
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim H., 2021, P IEEE CVF INT C COM, P4459
   Kingma D. P., 2014, arXiv
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Liang Z, 2021, IEEE T CIRC SYST VID
   Liang Z, 2020, IEEE T SYST MAN CY-S
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Ludvigsen M, 2007, OCEANOGRAPHY, V20, P140, DOI 10.5670/oceanog.2007.14
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Miller PA, 2010, IEEE J OCEANIC ENG, V35, P663, DOI 10.1109/JOE.2010.2052691
   Panetta K, 2022, IEEE J OCEANIC ENG, V47, P59, DOI 10.1109/JOE.2021.3086907
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Qi Q, 2021, IEEE T CIRC SYST VID
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schechner YY, 2004, PROC CVPR IEEE, P536
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Sheinin M, 2016, PROC CVPR IEEE, P3764, DOI 10.1109/CVPR.2016.409
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Solonenko MG, 2015, APPL OPTICS, V54, P5392, DOI 10.1364/AO.54.005392
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Wang K, 2021, IEEE ROBOT AUTOM LET, V6, P5121, DOI 10.1109/LRA.2021.3070253
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang YD, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116250
   Wu SC, 2021, IEEE J OCEANIC ENG, V46, P1213, DOI 10.1109/JOE.2021.3064093
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhou J, 2021, MULTIMED TOOLS APPL, P1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Y, 2017, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2017.8296389
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 72
TC 2
Z9 2
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32941
EP 32965
DI 10.1007/s11042-023-14871-7
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900009
DA 2024-07-18
ER

PT J
AU Bhattacharyya, A
   Bhattacharya, A
   Maity, S
   Singh, PK
   Sarkar, R
AF Bhattacharyya, Avirup
   Bhattacharya, Avigyan
   Maity, Sourajit
   Singh, Pawan Kumar
   Sarkar, Ram
TI JUVDsi v1: developing and benchmarking a new still image database in
   Indian scenario for automatic vehicle detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic vehicle detection; JUVD; Image database; Object detection;
   Deep learning; Ensemble
AB Designing an automatic vehicle detection (AVD) system from still images or videos would be a useful tool to cater to the requirements of the traffic management system. Over the past few years, numerous databases have been developed for the use of researchers in this field of AVD. However, most of them are not acceptable in the Indian scenarios due to certain practical constraints like the road infrastructure, nature of congestion, and vehicle types commonly found in India. The aim of this research is to develop a still image database, named as JUVDsi v1, which includes nine different types of vehicle classes collected through mobile phone cameras in various ways for designing an automated traffic management system. Identifying and analyzing the shortcomings of existing databases, the developed database presents an improvement to address such bottle-necks. Furthermore, the efficiency of this database is evaluated using an ensemble of three state-of-the-art deep learning architectures. At first, each vehicle in the scene images is localized and categorized. Five base object detection models, namely, YOLOv3, Faster-RCNN, RFCN, SSDv1 and SSDLitev2 are used. Finally, the Weighted Boxes Fusion technique is used as the ensemble method (ensemble of best three out of the five base learners), thereby enhancing the performance obtained by the individual object detection models. The database can be found at: https://github.com/JUVDsi/JUVD-StillImage-database.git.
C1 [Bhattacharyya, Avirup; Bhattacharya, Avigyan; Maity, Sourajit; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Mallick Rd, Kolkata 700032, West Bengal, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Campus 2,Plot 8,LB Block,Sect 3, Kolkata 700106, West Bengal, India.
C3 Jadavpur University; Jadavpur University
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Campus 2,Plot 8,LB Block,Sect 3, Kolkata 700106, West Bengal, India.
EM pawansingh.ju@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; Maity, Sourajit/0000-0001-5880-0930
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Appathurai A, 2020, CIRC SYST SIGNAL PR, V39, P734, DOI 10.1007/s00034-019-01224-9
   Arróspide J, 2013, J VIS COMMUN IMAGE R, V24, P1182, DOI 10.1016/j.jvcir.2013.08.001
   Azimi SM, 2021, INT C PATT RECOG, P6920, DOI 10.1109/ICPR48806.2021.9412353
   Bahnsen CH, 2019, IEEE T INTELL TRANSP, V20, P2802, DOI 10.1109/TITS.2018.2872502
   Batra P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145283
   Behrendt K, 2019, IEEE INT CONF COMP V, P840, DOI 10.1109/ICCVW.2019.00112
   Bhattacharya D., 2022, P INT C INTELLIGENCE
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Caraffi C, 2012, IEEE INT C INTELL TR, P975, DOI 10.1109/ITSC.2012.6338748
   Che ZP, 2019, Arxiv, DOI arXiv:1904.01975
   Chen LC, 2021, Arxiv, DOI arXiv:2011.11675
   Chen WP, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02085-w
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2023, Arxiv, DOI [arXiv:1605.06409, DOI 10.48550/ARXIV.1605.06409]
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   El-Sayed RS., 2020, IAES INT J ARTIF INT, V9, P700
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141
   Krause J, 2004, IEEE T SYST MAN CY-S, V1
   Lee HJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19050982
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2019, NEUROCOMPUTING, V347, P24, DOI 10.1016/j.neucom.2019.03.004
   Manzoor MA, 2019, MACH LEARN KNOW EXTR, V1, P611, DOI 10.3390/make1020036
   Mirthubashini J, 2020, INT CONF ADVAN COMPU, P142, DOI [10.1109/ICACCS48705.2020.9074280, 10.1109/icaccs48705.2020.9074280]
   Naseer S., 2020, 2020 IEEE 23 INT MUL, P1, DOI [10.1109/INMIC50486.2020.9318063, DOI 10.1109/INMIC50486.2020.9318063]
   Nazemi A, 2020, IEEE T INTELL TRANSP, V21, P3080, DOI 10.1109/TITS.2019.2924830
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezaei M., 2014, IROADS DATASET INTER, P10
   Sagar A, 2021, IEEE INT CONF COMP V, P2650, DOI 10.1109/ICCVW54120.2021.00299
   Sakaridis C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10745, DOI 10.1109/ICCV48922.2021.01059
   Sang J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124272
   Saravi S., 2013, 2013 18 INT C DIGITA, P1
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P906, DOI 10.1109/TITS.2013.2246835
   Sivaraman S, 2010, IEEE INT VEH SYM, P676, DOI 10.1109/IVS.2010.5547967
   Solovyev R, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104117
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190
   Vinh Dinh Nguyen, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P511, DOI 10.1007/978-3-030-44289-7_48
   Wang D., 2021, 2021 INT C SMART APP, P1
   Wang H, 2019, IEEE INTEL TRANSP SY, V11, P82, DOI 10.1109/MITS.2019.2903518
   Wang ZN, 2024, J MANAGE ORGAN, V30, P318, DOI [10.1017/jmo.2020.10, 10.1080/00221309.2020.1751043]
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wu H, 2019, INT CONF ACOUST SPEE, P3767, DOI 10.1109/ICASSP.2019.8683350
   Yang J, 2019, CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P276, DOI [10.1109/iccar.2019.8813345, 10.1109/ICCAR.2019.8813345]
   Yang Z, 2018, IMAGE VISION COMPUT, V69, P143, DOI 10.1016/j.imavis.2017.09.008
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25
   Zhang JM, 2021, IEEE INT C INT ROBOT, P1132, DOI 10.1109/IROS51168.2021.9636109
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 55
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32883
EP 32915
DI 10.1007/s11042-023-14661-1
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100011
DA 2024-07-18
ER

PT J
AU Wu, CM
   Zhang, JJ
   Huang, CC
AF Wu, Chengmao
   Zhang, Jiajia
   Huang, Congcong
TI Robust dynamic semi-supervised picture fuzzy local information
   clustering with kernel metric and spatial information for noisy image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Picture fuzzy clustering; Semi-supervised; Spatial
   information; Kernel function
ID C-MEANS ALGORITHM; NONLOCAL INFORMATION; FCM
AB Aiming at robust picture fuzzy clustering with weak anti-noise ability, which is difficult to meet the needs of high noise image segmentation. Hence, this paper proposes a robust dynamic semi-supervised picture fuzzy local information clustering with kernel metric and spatial information. Firstly, a robust weighted squared Euclidean distance between the current pixel and clustering center is constructed, and it is introduced into picture fuzzy clustering to form a robust spatial picture fuzzy clustering. Secondly, the membership degree of neighborhood pixels is linearly weighted to form local membership of the current pixel, which is used to supervise the picture fuzzy partition information of spatial picture fuzzy clustering, and a novel robust dynamic semi-supervised picture fuzzy clustering with spatial information is obtained. Subsequently, the fuzzy local information factor is embedded in dynamic semi-supervised spatial picture fuzzy clustering to obtain enhanced dynamic semi-supervised picture fuzzy local information clustering. Finally, to further improve the adaptability of dynamic semi-supervised spatial picture fuzzy local information clustering, a robust dynamic semi-supervised picture fuzzy local information clustering with kernel metric and spatial information constraints is proposed. Experimental results show that the proposed algorithm outperforms existing state-of-the-art robust picture fuzzy clustering-related algorithms for high noise image segmentation, and the Acc and PSNR indexes of the proposed algorithm in noisy images are significantly better than those of robust fuzzy clustering-related compared algorithms.
C1 [Wu, Chengmao; Zhang, Jiajia; Huang, Congcong] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications
RP Zhang, JJ (corresponding author), Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
EM wuchengmao123@sohu.com; zhang_jj97@163.com; huangcongcong_1234@163.com
OI Huang, Congcong/0000-0002-2971-8978; Wu, Chengmao/0000-0002-5881-4723;
   Zhang, JiajiaZ/0000-0002-3144-4179
FU National Natural Science Foundation of China [61671377,51709228];
   Shaanxi Natural Science Foundation of China [2016JM8034, 2017JM6107];
   School of Electronic Engineering, Xi'an University of Posts &
   Telecommunications, Xi'an, China
FX This work was supported by the National Natural Science Foundation of
   China (61671377,51709228) and the Shaanxi Natural Science Foundation of
   China (2016JM8034, 2017JM6107). The authors would like to thank the
   anonymous reviewers for their constructive suggestions to improve the
   overall quality of the paper. Besides, the authors would like to thank
   the School of Electronic Engineering, Xi'an University of Posts &
   Telecommunications, Xi'an, China, for financial support.
CR Adhikari SK, 2015, APPL SOFT COMPUT, V34, P758, DOI 10.1016/j.asoc.2015.05.038
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Beevi SZ., 2010, INT J COMPUT SCI INF, V7, P1, DOI [10.1109/ICCCNT.2010.5591787, DOI 10.1109/ICCCNT.2010.5591787]
   Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   Bhagyalakshmi S., 2015, Int. J. Eng. Res. Technol. (IJERT), V4, P68, DOI [10.17577/IJERTV4IS050183, DOI 10.17577/IJERTV4IS050183]
   Bharill N, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), P95, DOI 10.1109/BigDataService.2016.34
   Bouchachia A, 2003, LECT NOTES ARTIF INT, V2715, P328
   Bouchachia A, 2006, FUZZY SET SYST, V157, P1733, DOI 10.1016/j.fss.2006.02.015
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Carata SV, 2016, INT CONF COMM, P61, DOI 10.1109/ICComm.2016.7528317
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Fan JL, 2003, PATTERN RECOGN LETT, V24, P1607, DOI 10.1016/S0167-8655(02)00401-4
   Gharieb R, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141850012X
   Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo YH, 2013, CIRC SYST SIGNAL PR, V32, P1699, DOI 10.1007/s00034-012-9531-x
   Hayat AD, 2016, INT C DIGITAL IMAGE, DOI DOI 10.1109/DICTA.2016.7797066
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Hou, 2016, STUDY IMAGE SEGMENTA
   Jha P, 2021, COMPUT BIOL CHEM, V92, DOI 10.1016/j.compbiolchem.2021.107454
   Ji J, 2014, IEEE J-STARS, V7, P4929, DOI 10.1109/JSTARS.2014.2308531
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar Dhirendra, 2019, Multimedia Tools and Applications, V78, P12663, DOI 10.1007/s11042-018-5954-0
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   [雷涛 Lei Tao], 2019, [电子学报, Acta Electronica Sinica], V47, P1776
   Lei T, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091381
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li N, 2013, IEEE GEOSCI REMOTE S, V10, P1124, DOI 10.1109/LGRS.2012.2231662
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Luo J, 2017, ADV INTELL SYST, V541, P365, DOI 10.1007/978-3-319-49568-2_52
   Memon KH, 2018, FUZZY SET SYST, V340, P91, DOI 10.1016/j.fss.2018.01.019
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232
   Thong PH, 2016, SOFT COMPUT, V20, P3549, DOI 10.1007/s00500-015-1712-7
   Saha A, 2019, IEEE T CYBERNETICS, V49, P4229, DOI 10.1109/TCYB.2018.2861211
   Son LH, 2015, EXPERT SYST APPL, V42, P51, DOI 10.1016/j.eswa.2014.07.026
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tuan TM, 2016, APPL INTELL, V45, P402, DOI 10.1007/s10489-016-0763-5
   Tuan TM., 2016, J COMPUT SCI CYBERN, V31, P323, DOI [10.15625/1813-9663/31/4/7234, DOI 10.15625/1813-9663/31/4/7234]
   Werner F., 2006, MATH EC BUSINESS, DOI [10.4324/9780203401385, DOI 10.4324/9780203401385]
   Wu CM, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102905
   Wu CM, 2021, SOFT COMPUT, V25, P3751, DOI 10.1007/s00500-020-05403-8
   Wu CM, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106468
   Wu CM, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105888
   [吴成茂 Wu Chengmao], 2019, [兵工学报, Acta Armamentarii], V40, P1890
   Wu CM., 2017, J XIAN U POSTS TELEC, V22, P37, DOI [10.13682/j.issn.2095-6533.2017.05.006, DOI 10.13682/J.ISSN.2095-6533.2017.05.006]
   Xiang DL, 2014, IEEE GEOSCI REMOTE S, V11, P1290, DOI 10.1109/LGRS.2013.2292820
   Yang MS, 2015, INFORM SCIENCES, V309, P138, DOI 10.1016/j.ins.2015.03.006
   Yang Y, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5648206
   Zeng S, 2013, KNOWL INF SYST, V35, P585, DOI 10.1007/s10115-012-0521-x
   Zhang DQ, 2004, ARTIF INTELL MED, V32, P37, DOI [10.1016/j.artmed.2004.01.012, 10.1016/j.artmed. 2004.01.012]
   Zhang H, 2017, IEEE T GEOSCI REMOTE, V55, P5057, DOI 10.1109/TGRS.2017.2702061
   Zhang XF, 2021, INFORM SCIENCES, V550, P129, DOI 10.1016/j.ins.2020.10.039
   Zhang XF, 2017, MULTIMED TOOLS APPL, V76, P7869, DOI 10.1007/s11042-016-3399-x
   Zhao F, 2014, EXPERT SYST APPL, V41, P4083, DOI 10.1016/j.eswa.2014.01.003
NR 63
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 31869
EP 31911
DI 10.1007/s11042-023-14703-8
EA FEB 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000940729500005
DA 2024-07-18
ER

PT J
AU Tu, ZQ
   Weng, DD
   Liang, B
   Luo, L
AF Tu, Ziqi
   Weng, Dongdong
   Liang, Bin
   Luo, Le
TI 3D facial expression retargeting framework based on an
   identity-independent expression feature vector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual characters; 3D face model; Expression retargeting; Deep learning
AB One important aspect of multimedia application scenarios is the ability to control the facial expressions of virtual characters. One popular solution is to retarget the expressions of actors to virtual characters. Traditional 3D facial expression retargeting algorithms are mostly based on the Blendshape model. However, excessive reliance on the Blendshape model introduces several limitations. For example, the quality of the base expressions has a large influence on the expression retargeting results, requires large amounts of 3D face data, and must be calibrated for each user. We propose a 3D facial expression retargeting framework based on an identity-independent expression feature vector (hereafter referred to as the expression vector). This expression vector, which is related only to facial expressions, is originally extracted from face images; then, the corresponding expressions are transferred to the target (which can be any 3D face model) using V2ENet, a generative adversarial network (GAN)-structured model. Our framework requires only the expression vector and a neutral 3D face model to achieve natural and vivid expression retargeting, and it does not rely on the Blendshape model. When using the expression vector obtained from a cognitive perspective, our method can also perform 3D expression retargeting at the cognitive level. A series of experiments demonstrates that our method not only provides a simplified expression retargeting process but also achieves a better effect than the deformation transfer algorithm. The proposed framework is suitable for a wide range of applications and also achieves good expression retargeting for cartoon-style face models.
C1 [Tu, Ziqi; Weng, Dongdong; Liang, Bin; Luo, Le] Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Weng, DD (corresponding author), Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.
EM 350170359@qq.com; crgj@bit.edu.cn; 18203416228@163.com; l_luo@bit.edu.cn
FU National Key Research and Development Program of China [2022YFF0902303];
   Beijing Municipal Science & Technology Commission and Administrative
   Commission of Zhongguancun Science Park [Z221100007722002]
FX AcknowledgementsThis work was supported by the National Key Research and
   Development Program of China (No.2022YFF0902303) and the Beijing
   Municipal Science & Technology Commission and Administrative Commission
   of Zhongguancun Science Park under Grant Z221100007722002.
CR Ribera RBI, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073674
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Buck I, 2006, ACM SIGGRAPH 2006 CO, DOI [10.1145/1185657.1185865, DOI 10.1145/1185657.1185865]
   Cao C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275093
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chaudhuri Bindita, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P142, DOI 10.1007/978-3-030-58558-7_9
   Chaudhuri B, 2019, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR.2019.00995
   Chen K, 2021, ARXIV
   Chung JS, 2018, INTERSPEECH, P1086
   Dai JF, 2016, ADV NEUR IN, V29
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Friesen E., 1978, Environmental Psychology & Nonverbal Behavior, V3, P5, DOI 10.1037/t27734-000
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Lee GH, 2020, PROC CVPR IEEE, P6099, DOI 10.1109/CVPR42600.2020.00614
   Lewis JP, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Suwajanakorn S, 2015, IEEE I CONF COMP VIS, P3952, DOI 10.1109/ICCV.2015.450
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tu XG, 2021, IEEE T MULTIMEDIA, V23, P1160, DOI 10.1109/TMM.2020.2993962
   Vemulapalli R, 2019, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2019.00583
   Wang H, 2020, IEEE J-STSP, V14, P775, DOI 10.1109/JSTSP.2019.2961233
   Wu WN, 2018, LECT NOTES COMPUT SC, V11205, P622, DOI 10.1007/978-3-030-01246-5_37
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang J., 2019, arXiv
   Zhang JY, 2022, IEEE T VIS COMPUT GR, V28, P1274, DOI 10.1109/TVCG.2020.3013876
   Zhao CL, 2019, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2019.00289
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 41
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23017
EP 23034
DI 10.1007/s11042-023-14547-2
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000937854600007
DA 2024-07-18
ER

PT J
AU Wu, XY
   Qian, JY
   Wang, TT
AF Wu, Xiaoyu
   Qian, Jiayao
   Wang, Tiantian
TI Text-video retrieval method based on enhanced self-attention and
   multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-video retrieval; Self-attention; Multi-task learning; Semantic
   space
AB The explosive growth of videos on the Internet makes it a great challenge to use texts to retrieve the videos we need. The general method of text-video retrieval is to project them into a common semantic space to calculate the similarity score. The key technologies of a retrieval model are how to get strong feature representations of text and video and bridge the semantic gap between the two modalities. Moreover, most existing methods do not consider the strong consistency of text-video positive sample pairs. Considering the above problems, we proposed a text-video retrieval method based on enhanced self-attention and multi-task learning in this paper. Firstly, while encoding, the extracted text feature vectors and the extracted video feature vectors are input into Transformer based on enhanced self-attention mechanism for encoding and fusion. Then the text representations and video representations are projected into a common semantic space. Finally, by introducing multi-task learning in the common semantic space, our proposed approach combines the semantic similarity measurement task and the semantic consistency judgement task to optimize the common space through semantic consistency constraints. Our method obtains better retrieval performance on the MSR-Video to Text (MSRVTT), Large Scale Movie Description Challenge (LSMDC), and ActivityNet datasets than some existing approaches, which proves the effectiveness of our proposed strategies.
C1 [Wu, Xiaoyu; Qian, Jiayao; Wang, Tiantian] Commun Univ China, State Key Lab Media Convergence & Commun, 1 Dingfuzhuang East St, Beijing 10024, Peoples R China.
C3 Communication University of China
RP Wu, XY (corresponding author), Commun Univ China, State Key Lab Media Convergence & Commun, 1 Dingfuzhuang East St, Beijing 10024, Peoples R China.
EM wuxiaoyu@cuc.edu.cn; qjy759@cuc.edu.cn; tiantian_wong@cuc.edu.cn
RI wu, xiaoyu/GWM-9019-2022; Qian, Jiayao/HTR-1928-2023
FU state key development program in 14th Five-Year [2021YFF0900701,
   2021YFF0602103, 2021YFF0602102, 2021QY1702]; Natural Science Foundation
   of China [61801441]; Institute for Guo Qiang, Tsinghua University
   [2019GQG0001]; High-quality and Cutting-edge Disciplines Construction
   Project for Universities in Beijing (Internet Information, Communication
   University of China)
FX This work was supported by the state key development program in 14th
   Five-Year under Grant No. 2021YFF0900701, 2021YFF0602103,
   2021YFF0602102, 2021QY1702, and in part by Natural Science Foundation of
   China (No.61801441). We also thank for the research funds under Grant
   No. 2019GQG0001 from the Institute for Guo Qiang, Tsinghua University,
   and the High-quality and Cutting-edge Disciplines Construction Project
   for Universities in Beijing (Internet Information, Communication
   University of China)
CR Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Devlin J., 2018, BERT PRE TRAINING DE
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fang H., 2021, arXiv
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gabeur Valentin, 2020, P EUR C COMP VIS, V12349, P214, DOI [10.48550/arXiv.2007.10639, DOI 10.48550/ARXIV.2007.10639]
   Gao Z., 2021, arXiv
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Habibian A, 2014, ICMR
   Hernandez R, 2019, IMFD IMPRESEE TRECVI
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Li X, 2018, RENMIN U CHINA ZHEJI
   Liu Yinhan, 2019, ARXIV190711692
   Luo H., 2021, ARXIV
   Markatopoulou F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P412, DOI 10.1145/3078971.3079041
   Miech A, 2018, ARXIV
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Nguyen PA, 2019, VIREOEURECOM TRECVID
   Radford A, 2021, PR MACH LEARN RES, V139
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Sutskever I, 2014, ADV NEUR IN, V27
   Tao Y, 2019, TRECVID NIST
   Ueki Kazuya., 2017, Waseda meisei at trecvid 2017: Ad-hoc video search
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedaldi A., 2020, ARXIV
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
NR 35
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24387
EP 24406
DI 10.1007/s11042-023-14589-6
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000937854600008
DA 2024-07-18
ER

PT J
AU Teja, YD
AF Teja, Y. D.
TI Static object detection for video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Static objects; Video surveillance system; Abandoned object; Background
   subtraction; Hierarchical finite state machine; CNN
AB One essential component of security systems at public locations, such as airports, bus stops, train stations, marketplaces, etc., is the video surveillance. More powerful and efficient automated technical developments are needed for video surveillance. When an unattended object is left in the public places it will be considered as suspicious object as the terrorist assaults have escalated globally in recent years. The people in public areas must be protected from this attack by using safety precautions. Complex surveillance recordings make it difficult to identify abandoned or removed objects due to a number of factors, such as occlusion, abrupt changes in lighting, and so on. A novel approach is proposed in this article for the identification and classification of a static object in a public place. The main aim of this work is the automatic detection of abandoned objects. This method consists of two steps: static item detection using background subtraction and motion estimation; and (ii) abandoned luggage recognition using convolutional neural networks. (CNN). By applying the background subtraction method using fuzzy integral, the suggested method extracts foreground items. Afterwards the static object is detected using hierarchical Finite state machine (FSM). And finally, the object is classified using the CNN algorithm Yolo V5. In terms of accuracy, precision, and recall, the performance of the suggested algorithm is compared with that of traditional approaches.
C1 [Teja, Y. D.] JNTUKUCEV, Vizianagaram 535003, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Teja, YD (corresponding author), JNTUKUCEV, Vizianagaram 535003, Andhra Pradesh, India.
EM vijyaksha.yentrapragada@gmail.com
CR Ammar S, 2019, LECT NOTES COMPUT SC, V11845, P307, DOI 10.1007/978-3-030-33723-0_25
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Din M, 2020, INT J ADV COMPUT SC, V11, P676
   Dwivedi Neelam, 2020, Procedia Computer Science, V171, P1979, DOI 10.1016/j.procs.2020.04.212
   Elhoseny M, 2020, CIRC SYST SIGNAL PR, V39, P611, DOI 10.1007/s00034-019-01234-7
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Kalli SNR, 2021, J INTELL FUZZY SYST, P1
   Kiruthiga G., 2021, IMPROVED OBJECT DETE
   Lwin SP, 2022, DEEP CONVONLUTIONAL
   Mahalingam T, 2021, APPL COMPUT INFORM, V17, P2, DOI 10.1016/j.aci.2018.01.001
   Mohana, 2019, INT J ADV COMPUT SC, V10, P517
   Narwal P, 2019, P 2019 9 INT S EMBED, V6
   Omrani E, 2020, SHIPS OFFSHORE STRUC, V15, P711, DOI 10.1080/17445302.2019.1668642
   Ortego D, 2015, IEEE SIGNAL PROC LET, V22, P2368, DOI 10.1109/LSP.2015.2482598
   Palivela LH., 2018, J COMPUTAT THEORET N, V15, P121, DOI [10.1166/jctn.2018.7064, DOI 10.1166/JCTN.2018.7064]
   Park H, 2020, IEEE ACCESS, V8, P80010, DOI 10.1109/ACCESS.2020.2990618
   Park H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235114
   Preetha K., 2021, TURKISH J COMPUT MAT, V12, P3694, DOI [10.17762/turcomat.v12i3.1652, DOI 10.17762/TURCOMAT.V12I3.1652]
   Rehman Butt Waqqas Ur, 2019, 2019 Sixth HCT Information Technology Trends (ITT), P197, DOI 10.1109/ITT48889.2019.9075127
   Sajjanar S, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING, VLSI, ELECTRICAL CIRCUITS AND ROBOTICS (DISCOVER), P289, DOI 10.1109/DISCOVER.2016.7806248
   Samaila Y.A., 2020, Arid Zone J. Eng., Technol. Environ., V16, P48
   Sathesh A., 2021, J TRENDS COMPUT SCI, V3, P251, DOI [10.36548/jtcsst.2021.4.001, DOI 10.36548/JTCSST.2021.4.001]
   Shyam D, 2018, P 2018 IEEE INT C MU, P1
   Smeureanu S, 2018, EUR SIGNAL PR CONF, P1775, DOI 10.23919/EUSIPCO.2018.8553156
   Xu J, 2021, MULTIMED TOOLS APPL, V80, P5495, DOI 10.1007/s11042-020-09964-6
   Yadav P., 2016, STATIC OBJECT DETECT
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
NR 28
TC 0
Z9 1
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21627
EP 21639
DI 10.1007/s11042-023-14696-4
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936501100007
DA 2024-07-18
ER

PT J
AU Chen, CC
   Chang, C
   Lin, CS
   Chen, CH
   Chen, IC
AF Chen, Chien-Chang
   Chang, Chen
   Lin, Cheng-Shian
   Chen, Chien-Hua
   Chen, I. Cheng
TI Video based basketball shooting prediction and pose suggestion system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenPose; Bezier curve; KNN; The pix2pix conditional GAN (cGAN) model
ID TIME
AB Video based motion analysis, which aims to acquire the whole posture data by simple camera and without placing sensors on the body parts, has become the major analysis method in the sport domain. However, most video based motion analysis approaches either work only for some specific domain action recognition, or suffer from low prediction rates for practical applications in the sport domain. This paper presents an effective system to predict basketball shooting and to suggest corrected postures, as based on video based motion analysis with the OpenPose system. Given a basketball shooting video sequences, the proposed system first detects the human joint points acquired from the OpenPose system, and then, the video frames of the shooting period are detected by two important features of the shooting process. Basketball shooting is predicted using the adopted trajectory curves matching method and the K-nearest neighbor classification method. Finally, the wrong shooting posture is corrected and suggested based on the pix2pix conditional GAN (cGAN) model. Experimental results show that our approach can effectively estimate shooting results with high accuracy.
C1 [Chen, Chien-Chang; Chang, Chen; Lin, Cheng-Shian] Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei City 25137, Taiwan.
   [Chen, Chien-Hua; Chen, I. Cheng] Tamkang Univ, Off Phys Educ, 151 Yingzhuan Rd, New Taipei City 25137, Taiwan.
   [Chen, Chien-Hua] Natl Taiwan Normal Univ, Taipei City, Taiwan.
C3 Tamkang University; National Taiwan Normal University
RP Lin, CS (corresponding author), Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei City 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw; a22781911@gmail.com; 157446@mail.tku.edu.tw;
   132098@mail.tku.edu.tw; masa@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
CR ALT H, 1995, INT J COMPUT GEOM AP, V5, P75, DOI 10.1142/S0218195995000064
   Andrade-Campos A, 2012, INT J MECH SCI, V54, P294, DOI 10.1016/j.ijmecsci.2011.11.010
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Bezier PE, 1972, NUMERICAL CONTROL MA, V19
   Bringmann K, 2014, ANN IEEE SYMP FOUND, P661, DOI 10.1109/FOCS.2014.76
   Cao J, 2008, INT J MECH SCI, V50, P193, DOI 10.1016/j.ijmecsci.2007.07.003
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   De Smedt Q., 2017, P WORKSH 3D OBJ RETR, P33
   Devineau G., 2018, RECONNAISSANCE FORME
   Driemel A, 2012, DISCRETE COMPUT GEOM, V48, P94, DOI 10.1007/s00454-012-9402-z
   Eiter T., 1994, Computing Discrete Frechet Distance
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jekel CF, 2019, INT J MATER FORM, V12, P355, DOI 10.1007/s12289-018-1421-8
   Liu L, 2012, PROC IEEE INT C IMAG, P16
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nakai M, 2019, LECT NOTES ARTIF INT, V11717, P435, DOI 10.1007/978-3-030-31605-1_31
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Petitjean F, 2011, PATTERN RECOGN, V44, P678, DOI 10.1016/j.patcog.2010.09.013
   Qiao S., 2017, P 10 INT C IM SIGN P, P1, DOI [DOI 10.1109/CISP-BMEI.2017.8301910, 10.1109/CISP-BMEI.2017.8301910]
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Seyler SL, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004568
   Tormene P, 2009, ARTIF INTELL MED, V45, P11, DOI 10.1016/j.artmed.2008.11.007
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tsai YS, 2020, MATHEMATICS-BASEL, V8, P1
   Wei S.-E., 2014, P 1 ACM INT WORKSH H, P7
   Witowski K, 2012, PROCOF INT C AIAA AV, DOI DOI 10.2514/6.2012-5580
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 38
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27551
EP 27570
DI 10.1007/s11042-023-14490-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939670800001
DA 2024-07-18
ER

PT J
AU Wang, MY
   Qin, G
   Sun, M
   Zhao, J
   Qin, J
AF Wang Manying
   Qin Guihe
   Sun Minghui
   Zhao Jian
   Qin Jun
TI An exploration of pressure input with bare finger for Mobile interaction
   in stationary and Mobile situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pressure input; Mobile interaction; Pressure-based linear targeting;
   Pressure gesture; Touch
AB Nowadays, most mobile devices provide two-dimensional inputs, such as taps and slides. Although pressure input, which only operates along the z axis as a single dimensional input, has long been investigated, it is separated from the x-y plane. Combining touchscreen sliding gesture with force input to enlarge the operation space is still under explored. Besides, compared with tablets, mobile devices require input with bare fingers, of which users have a poorer control than using a stylus, and have a special usage scenario, walking. How these factors influence the user performance are waiting to be answered. To fill the gap, we conducted an empirical study to explore users' ability to control pressure on mobile devices. Participants were asked to perform pressure-based linear targeting in two postures (sitting and walking), with two types of visual feedback conditions (full and partial visual), and three confirmation methods (Dwell, Quick Release and Stroke). The results show that the number of pressure levels significantly affects error rate, movement time and number of crossings of selections. The pressure space can be divided into six levels with full visual feedback, while three levels with partial visual feedback, despite sitting or walking. The results indicate that Dwell is the most appropriate confirmation method. Based on our results, we also present a widget and discuss several applications for its potential use.
C1 [Wang Manying; Qin Guihe; Sun Minghui] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Wang Manying; Qin Guihe; Sun Minghui] Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhao Jian] Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON, Canada.
   [Qin Jun] Changchun Univ Sci & Technol, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; University of Waterloo; Changchun University of
   Science & Technology
RP Sun, M (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Sun, M (corresponding author), Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
EM smh@jlu.edu.cn
CR Arif A.S., Proceedings of the 11th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, MOBIQUITOUS'14, ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering), ICST, Brussels, Belgium, Belgium, 2014, P151
   Arif AhmedSabbir., 2013, Proceedings of the 25th Australian Computer-Human Interaction Conference on Augmentation, Application, Innovation, Collaboration - OzCHI'13, P383
   Bederson B. B., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P217, DOI 10.1145/354401.354782
   Besançon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1831, DOI 10.1145/3025453.3025890
   Brewster Stephen A., 2009, P 11 INT C HUM COMP
   Cechanowicz J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1385
   Corsten C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P246, DOI 10.1145/3132272.3134116
   Corsten C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300442
   Corsten C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174235
   Corsten C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4654, DOI 10.1145/3025453.3025565
   Crossan A., 2011, P 13 INT C HUM COMP, P147
   Exposito M., 2018, Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, P139, DOI DOI 10.1145/3236112.3236132
   Forlines C., 2005, CHI 05 EXTENDED ABST, P1375, DOI [10.1145/1056808.1056920, DOI 10.1145/1056808.1056920]
   Goel M, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P545
   Goguey A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174163
   Heo S., 2011, P 2011 ANN C HUMAN F, P1909, DOI 10.1145/1979742.1979895
   Hwang S., 2012, Proceedings of CHI '12 Extended Abstracts on Human Factors in Computing Systems, CHI EA '12, P1565, DOI DOI 10.1145/2212776.2223673
   Hwang Sungjae, 2013, P 15 INT C HUM COMP, P31
   Kim S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P211
   Li WHA, 2016, INT J MOB HUM COMPUT, V8, P1, DOI 10.4018/IJMHCI.2016010101
   Lim Hyunchul, 2016, P 29 ANN S USER INTE, P223
   McCallum David C, 2009, CHI 09 HUM FACT COMP, P4519
   McLachlan R, 2015, P 17 INT C HUM COMP, P547, DOI [10.1145/2785830.2785878, DOI 10.1145/2785830.2785878]
   McLachlan R, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P401, DOI 10.1145/2556288.2557260
   Mizobuchi S., 2005, Proceedings of the CHI '05 extended abstracts on Human factors in computing systems, P1661, DOI DOI 10.1145/1056808.1056991
   Negulescu M, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P173, DOI 10.1145/2254556.2254589
   Nelson RK, 2015, EXPLORING APPLES 3D
   Ng A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1981, DOI 10.1145/2556288.2557312
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Pedersen EW, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P421, DOI 10.1145/2556288.2557018
   Ramos G., 2005, Proceedings of the UIST '05 Symposium on User Interface Software and Technology, P143, DOI DOI 10.1145/1095034.1095059
   Ramos G., 2004, Proceedings of the CHI '04 Conference on Human Factors in Computing Systems, P487
   Rendl C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P431, DOI 10.1145/2556288.2557146
   Stewart C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P801
   Taher Faisal, 2014, P 9 ACM INT C INT TA, P195, DOI [10.1145/2669485.2669515, DOI 10.1145/2669485.2669515]
   Takada R, 2017, P 2017 CHI C HUM FAC, P2140, DOI DOI 10.1145/3027063.3053130
   Tu HW, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2797138
   Tung Yu-Chih, 2016, P 14 ANN INT C MOB S, P277, DOI DOI 10.1145/2906388.2906394
   Wang XY, 2019, COMPUT GRAPH FORUM, V38, P635, DOI 10.1111/cgf.13716
   Wilson G., 2010, Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services, P181, DOI [10.1145/1851600.1851631, DOI 10.1145/1851600.1851631]
   Yong S, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P489, DOI 10.1145/3024969.3025081
NR 42
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25711
EP 25731
DI 10.1007/s11042-023-14503-0
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000931739200004
DA 2024-07-18
ER

PT J
AU Jiang, DH
   Liu, LD
   Zhu, LY
   Wang, XY
   Chen, YP
   Rong, XW
AF Jiang, Donghua
   Liu, Lidong
   Zhu, Liya
   Wang, Xingyuan
   Chen, Yingpin
   Rong, Xianwei
TI An efficient meaningful double-image encryption algorithm based on
   parallel compressive sensing and FRFT embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double-image compression and encryption; Visually meaningful encrypted
   image; Quantum cellular neural network; Compressive sensing; Fractional
   Fourier transform
ID CHAOTIC SYSTEM
AB The transmission of images via the Internet has grown exponentially in the past few decades. However, the Internet considered as an insecure method of information transmission may cause serious privacy issues. To overcome such potential security issues, a novel visually meaningful double-image encryption (VMDIE) algorithm conjugating quantum cellular neural network (QCNN), compressive sensing (CS) and fractional Fourier transform (FRFT) is proposed in this paper. First, the wavelet coefficients of two plain images are scrambled by the Fisher-Yates confusion algorithm, and compressed by key-controlled partial Hadamard matrix. The final meaningful cipher image is generated by embedding the encrypted images into a same-scale host image via the FRFT-based embedding approach. Besides, the eigenvalues of plain images are utilized to generate secret key streams to improve the ability of proposed VMDIE algorithm to withstand various plaintext attacks. Afterward, the plaintext eigenvalues are hidden into the alpha channel of meaningful cipher image under control of keys to relieve unnecessary storage space and transmission cost. Ultimately, simulation results and security analyses indicate that the proposed VMDIE algorithm is effective and can withstand multiple attacks.
C1 [Jiang, Donghua; Liu, Lidong] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Liu, Lidong] Changan Univ, Sch Informat Engn, Xian, Peoples R China.
   [Zhu, Liya] Changan Univ, Sch Elect & Control Engn, Xian 710064, Peoples R China.
   [Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Chen, Yingpin] Minnan Normal Univ, Sch Phys & Informat Engn, Zhangzhou 363000, Peoples R China.
   [Rong, Xianwei] Harbin Normal Univ, Phys & Elect Engn Sch, Harbin 150025, Peoples R China.
C3 Sun Yat Sen University; Chang'an University; Chang'an University; Dalian
   Maritime University; MinNan Normal University; Harbin Normal University
RP Liu, LD (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.; Liu, LD (corresponding author), Changan Univ, Sch Informat Engn, Xian, Peoples R China.
EM jiangdh8@mail2.sysu.edu.cn; liulidong@chd.edu.cn
FU National Natural Science Foundation of China [61701043, 41874140];
   Shaanxi Province Science and Technology Program [2020JM-220,
   2020JQ-351]; Fundamental Research Funds for the Central Universities of
   China [300102240205]; Natural Science Foundation of Fujian Province
   [2020 J05169]; Natural Science Foundation of Heilongjiang Province
   [F2018022]
FX This work is supported by the National Natural Science Foundation of
   China [Grant No.61701043, 41874140], the Shaanxi Province Science and
   Technology Program [Grant No.2020JM-220, 2020JQ-351], the Fundamental
   Research Funds for the Central Universities of China [Grant
   No.300102240205], the Natural Science Foundation of Fujian Province
   [Grant No.2020 J05169] and the Natural Science Foundation of
   Heilongjiang Province [Grant No.F2018022].
CR Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elhoseny HM, 2016, OPTIK, V127, P315, DOI 10.1016/j.ijleo.2015.08.152
   Fan HJ, 2020, NEURAL COMPUT APPL, V32, P12771, DOI 10.1007/s00521-020-04724-x
   Gan ZH, 2020, NEURAL COMPUT APPL, V32, P14113, DOI 10.1007/s00521-020-04808-8
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hu GQ, 2017, OPT LASER ENG, V98, P123, DOI 10.1016/j.optlaseng.2017.06.013
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, IEEE T SYST MAN CY-S, V51, P3713, DOI 10.1109/TSMC.2019.2932616
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Khan JS, 2020, IEEE ACCESS, V8, P159732, DOI 10.1109/ACCESS.2020.3020917
   Li J, 2017, 2017 10 INT C IM SIG, P1
   Li M, 2021, J REAL-TIME IMAGE PR, V18, P2135, DOI 10.1007/s11554-021-01091-1
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Musanna F, 2020, MULTIMED TOOLS APPL, V79, P25115, DOI 10.1007/s11042-020-09034-x
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pan C, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/6572105
   Ping P, 2019, IEEE ACCESS, V7, P170168, DOI 10.1109/ACCESS.2019.2955570
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75562-z
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Yang FF, 2020, CHINA COMMUN, V17, P21, DOI 10.23919/JCC.2020.05.003
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Ye GD, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4071
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   [赵洪祥 Zhao Hongxiang], 2020, [计算机应用研究, Application Research of Computers], V37, P3726
   Zhao H, 2016, SIGNAL PROCESS, V123, P64, DOI 10.1016/j.sigpro.2015.12.016
   Zhou KL, 2019, DIGIT SIGNAL PROCESS, V93, P115, DOI 10.1016/j.dsp.2019.07.013
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
   Zhu LY, 2019, IEEE ACCESS, V7, P22161, DOI 10.1109/ACCESS.2019.2897721
NR 50
TC 2
Z9 2
U1 10
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27337
EP 27363
DI 10.1007/s11042-023-14601-z
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000933104800010
DA 2024-07-18
ER

PT J
AU Vishwanath, NV
   Manjunathachari, K
   Prasad, KS
AF Vishwanath, Neerugatti Varipally
   Manjunathachari, K.
   Prasad, K. Satya
TI Multi-lingual character segmentation and recognition based on adaptive
   projection profiles and composite feature vectors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recognition; Segmentation; Gradients; Telugu; Bangla; Accuracy
ID INDIAN SCRIPTS; HANDWRITTEN; HISTOGRAMS; TRANSFORM; SYSTEM; OCR
AB In recent years, multi-lingual character segmentation and recognition has attracted the wide range of researchers. However, the variations in the structures of characters in different languages, writing styles of different people and font sizes challenges that need further enhancement. Towards such objective, in this paper, we have proposed a novel multi-lingual handwritten character recognition framework for three different languages such as Bangla, Kannada and Telugu. At segmentation phase, this framework performs both word and character segmentation with the help of an Adaptive Projection Profiling (APP) and Edge Density Filter (EDF) respectively. Further at the recognition phase, we propose to use gradient based feature descriptors to extract a Composite Feature Vector (CFV) from handwritten character images, which are then fed to Support Vector Machine (SVM) algorithm for recognition. At experimental evaluation, we have simulated the proposed model over three different language scripts. The experimental results show that the proposed model outperforms the conventional method with an average improvement in the recognition accuracy of 3% for both cross validation and test simulations.
C1 [Vishwanath, Neerugatti Varipally; Prasad, K. Satya] JNTUK, Dept ECE, Kakinada, Andhra Pradesh, India.
   [Manjunathachari, K.] GITAM Univ, Dept ECE, Hyderabad Campus, Hyderabad, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Gandhi Institute
   of Technology & Management (GITAM)
RP Vishwanath, NV (corresponding author), JNTUK, Dept ECE, Kakinada, Andhra Pradesh, India.
EM visuresearch1@gmail.com
OI , Neerugatti varipally vishwanath/0000-0003-2270-5418
CR Amara M, 2016, ADV INTELL SYST, V420, P167, DOI 10.1007/978-3-319-27221-4_14
   Amirkhani-Shahraki A, 2014, UKSIM INT CONF COMP, P298, DOI 10.1109/UKSim.2014.93
   Anupama N, 2013, GLOBAL J COMPUT SCI, V13, P1
   Anwar K, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNESTAT), P111, DOI 10.1109/COMNETSAT.2015.7434299
   Aradhya VNM, 2008, ENG APPL ARTIF INTEL, V21, P658, DOI 10.1016/j.engappai.2007.05.009
   Arróspide J, 2013, J VIS COMMUN IMAGE R, V24, P1182, DOI 10.1016/j.jvcir.2013.08.001
   Bahashwan M, 2017, INT ARAB J INF TECHN, V14, P870
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Biswas M, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1703.10661
   Brink AA, 2012, PATTERN RECOGN, V45, P162, DOI 10.1016/j.patcog.2011.07.005
   Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das T. R., 2021, Journal of Computer and Communications, V9, P158
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Deshpande P., 2021, INT J FUTURE GENER C, V14, P4189
   Dhanikonda SR., 2021, MILITARY MED RES, V12, P999
   Inkeaw P, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106953
   Islam Noman., 2016, J INFORM COMMUNICATI, V10, P1
   Jebril Noor A., 2018, Pattern Recognition and Image Analysis, V28, P321, DOI 10.1134/S1054661818020141
   Kadam D, 2018, INT J PHARM SCI RES, V9, P72
   Kaur Amandeep, 2015, International Journal of Advances in Science Engineering and Technology, V3, P154
   Kumar R., 2014, ARPN J ENG APPL SCI, V9, P109
   Lee SE, 2013, COMPUT ELECTR ENG, V39, P1043, DOI 10.1016/j.compeleceng.2013.04.001
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoud SA, 2009, PATTERN ANAL APPL, V12, P353, DOI 10.1007/s10044-008-0128-8
   Mamatha H.R., 2012, Int. J. Appl. Inf. Syst, V4, P13, DOI [10.5120/ijais12-450704, DOI 10.5120/IJAIS12-450704]
   Mathew M, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P186, DOI 10.1109/DAS.2016.68
   Mohammad K, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043030
   Mousa MAA, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1707.00800
   Pal U., 2007, Proceedings of 10th International Conference on Information Technology (ICIT), P208, DOI [DOI 10.1109/ICIT.2007.62, 10.1109/ICIT.2007.43, DOI 10.1109/ICIT.2007.43]
   Poodikkalam SB, 2020, IMAGING SCI J, V68, P214, DOI 10.1080/13682199.2020.1827814
   Prasad JR, 2015, INT J MACH LEARN CYB, V6, P69, DOI 10.1007/s13042-013-0187-z
   Rahman A, 2013, INFORM PROCESS MANAG, V49, P852, DOI 10.1016/j.ipm.2012.12.010
   Raju G, 2014, SADHANA-ACAD P ENG S, V39, P1333, DOI 10.1007/s12046-014-0274-1
   Sahare P, 2017, INT J MULTIMED INF R, V6, P211, DOI 10.1007/s13735-017-0130-2
   Salmani Jelodar M, 2007, WATER AIR SOIL POLL, V1, P137
   Seo J, 2014, NEUROCOMPUTING, V129, P41, DOI 10.1016/j.neucom.2012.09.048
   Shakunthala BS, 2019, INT J INNOV TECHNOL, V8, P953
   Sheikh N.A., 2009, Australian Journal of Basic and Applied Science, V3, P4160
   Shi CZ, 2015, IEEE T IMAGE PROCESS, V24, P4952, DOI 10.1109/TIP.2015.2473105
   Siddhaling U., 2013, CCIS, V296, P137
   Singh P, 2015, SADHANA-ACAD P ENG S, V40, P1701, DOI 10.1007/s12046-015-0419-x
   Somashekar T., 2021, MILITARY MED RES, V23, P1019, DOI [10.51201/JUSST/21/05304, DOI 10.51201/JUSST/21/05304]
   Surinta O, 2015, ENG APPL ARTIF INTEL, V45, P405, DOI 10.1016/j.engappai.2015.07.017
   Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009
   Vapnik V. N., 1998, STAT LEARNING THEORY
NR 50
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24247
EP 24268
DI 10.1007/s11042-023-14523-w
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000931751400005
DA 2024-07-18
ER

PT J
AU Ren, F
   Liu, YG
   Zhang, X
   Li, Q
AF Ren, Fang
   Liu, Yuge
   Zhang, Xing
   Li, Qiang
TI Reversible information hiding scheme based on interpolation and
   histogram shift for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible information hiding; Medical image; Interpolation expansion;
   Histogram shift; Image segmentation; Privacy protection
ID CONTRAST ENHANCEMENT; HIGH-CAPACITY; WATERMARKING
AB Medical imaging and information management systems require transmission and storage of medical images over the Internet. Many reversible information hiding schemes for image have been proposed to ensure security and availability. In order to avoid the risk of medical information leakage and the medical image distortion, a reversible information hiding scheme based on interpolation and histogram shift for medical images has been proposed in this paper. The proposed adaptive interpolation between neighbor pixels (AIA) technique is used to obtain seed and non-seed pixels, which ensures the reversibility of the scheme while balancing the embedding capacity and the quality of marked image. Then, the image is divided into the region of interest (ROI) and the region of non-interest (NROI). Sensitive information such as electronic patient records (EPR) and electronic signatures of medical images are embedded as secret information. In the ROI, the corresponding bit histogram shift repeated embedding method (CBHSR) is adopted for embedding information to effectively avoid the problem of image distortion caused by histogram stretching. Experimental results show that algorithm not only has high embedding capacity, but also keeps the peak signal-to-noise ratio above 50dB, visual information fidelity and structural similarity above 0.99, which has good subjective and objective image quality.
C1 [Ren, Fang; Liu, Yuge; Zhang, Xing; Li, Qiang] Xian Univ Posts & Telecommun, Sch Cyberspace Secur, Xian 710121, Shaanxi, Peoples R China.
   [Ren, Fang; Liu, Yuge] Xian Univ Posts & Telecommun, Natl Engn Lab Wireless Secur, Xian 710121, Shaanxi, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications
RP Liu, YG (corresponding author), Xian Univ Posts & Telecommun, Sch Cyberspace Secur, Xian 710121, Shaanxi, Peoples R China.; Liu, YG (corresponding author), Xian Univ Posts & Telecommun, Natl Engn Lab Wireless Secur, Xian 710121, Shaanxi, Peoples R China.
EM 76487690@qq.com; 1842730383@qq.com; 3489354626@qq.com; Liliq97@163.comm
RI Ren, Fang/IUM-8990-2023
OI Ren, Fang/0000-0002-8442-4251; Liu, Yuge/0000-0002-7413-7988
FU National Nature Science Foundation of China [62202377]; Natural Science
   Basic Research Plan of Shaanxi Province of China [2021JM-463,
   2022JM-353]; Graduate Innovation Fund of Xi'an University of Posts and
   Telecommunications [CXJJDL2022015]
FX AcknowledgementsThis paper was supported by the National Nature Science
   Foundation of China (Program No. 62202377), the Natural Science Basic
   Research Plan of Shaanxi Province of China (Program No. 2021JM-463,
   2022JM-353), the Graduate Innovation Fund of Xi'an University of Posts
   and Telecommunications (CXJJDL2022015).
CR Abadi MAM, 2010, 5 INT S TEL KISH ISL
   Al-nuaimi AHH, 2017, IBN AL HAITHAM J PUR, V24
   Ashraf I, 2017, IEEE ACCESS, V5, P8250, DOI 10.1109/ACCESS.2017.2699686
   Avinashiappan A, 2022, DYNA-BILBAO, V97, P210, DOI 10.6036/10148
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bhardwaj R, 2024, J SOC ENTREP, V15, P400, DOI 10.1080/19420676.2021.1972030
   Chauhan SAAK, 2021, DATA SCI DATA ANAL O, V1, DOI [10.1109/TNSE.2021.3139671, DOI 10.1109/TNSE.2021.3139671]
   Dewangan P, 2021, REVERSIBLE REGION BA, P545, DOI [10.1007/978-981-33-4859-2_53, DOI 10.1007/978-981-33-4859-2_53]
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kapadia Amishi Mahesh, 2022, Artificial Intelligence and Technologies: Select Proceedings of ICRTAC-AIT 2020. Lecture Notes in Electrical Engineering (806), P489, DOI 10.1007/978-981-16-6448-9_48
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee HY, 2019, MULTIMED TOOLS APPL, V78, P19663, DOI 10.1007/s11042-019-7322-0
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Linhandev, 2020, MED IM DAT
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Loan NA, 2017, J BIOMED INFORM, V73, P125, DOI 10.1016/j.jbi.2017.08.002
   Mata-Mendoza D, 2021, HEALTH TECHNOL-GER, V11, P835, DOI 10.1007/s12553-021-00562-6
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Sh YQ, 2004, REVERSIBLE DATA HIDI, P1, DOI [10.1007/978-3-540-31805-7_1, DOI 10.1007/978-3-540-31805-7_1]
   Showkat S, 2021, MULTIMED TOOLS APPL, V80, P2009, DOI 10.1007/s11042-020-09732-6
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
NR 37
TC 1
Z9 2
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28445
EP 28471
DI 10.1007/s11042-022-14300-1
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000924482400001
PM 36778716
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Hosni, A
   Atef, M
AF Hosni, Asmaa
   Atef, Mohamed
TI Remote real-time heart rate monitoring with recursive motion artifact
   removal using PPG signals from a smartphone camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote Photoplethysmography; Heart rate; Wavelet transforms; Motion
   artifacts; Baseline wander
AB Remote photoplethysmography (rPPG) recorded by low-cost smartphone cameras is a promising method for noncontact monitoring of heart rate (HR). The main challenges of this method are the limited rPPG signal strength and motion artifacts (MAs). To obtain a clean signal while preserving photoplethysmography features, this study proposes algorithms to eliminate the noise and distortions of the extracted rPPG signal. To obtain the best point for the rPPG signal extraction, the highest green channel difference in two consecutive frames is calculated. Mexican hat wavelet transform decomposition is used for MA distortion elimination. Furthermore, we propose a recursive baseline-wander removal algorithm with an adaptive window to effectively remove baseline drift. The peak detection accuracy is enhanced by using an adaptive sliding-window size based on the detected fast Fourier transform beat frequency. Our proposed algorithm was validated using a range of HR values from seven subjects. The results of the algorithm validation showed a real-time operation and accuracy improvements of more than 37.5% for peak detection in the worst case. The proposed method can measure HR remotely from a 0.4 m distance without any additional sensors, achieving a mean absolute error +/- standard deviation of 3.58 +/- 2.4.
C1 [Hosni, Asmaa] United Arab Emirates Univ, Coll Informat Technol, Abu Dhabi 15551, U Arab Emirates.
   [Hosni, Asmaa; Atef, Mohamed] Assiut Univ, Assiut 71515, Egypt.
   [Atef, Mohamed] United Arab Emirates Univ, Elect Engn Dept, Abu Dhabi 15551, U Arab Emirates.
C3 United Arab Emirates University; Egyptian Knowledge Bank (EKB); Assiut
   University; United Arab Emirates University
RP Atef, M (corresponding author), Assiut Univ, Assiut 71515, Egypt.; Atef, M (corresponding author), United Arab Emirates Univ, Elect Engn Dept, Abu Dhabi 15551, U Arab Emirates.
EM moh_atef@uaeu.ac.ae
RI atef, mohamed/I-9063-2019
OI atef, mohamed/0000-0002-3344-6127; Hosni, Asmaa/0009-0003-1606-3399
FU United Arab Emirates University [G00003441]
FX AcknowledgmentsThis work was partially supported by the United Arab
   Emirates University under Grant G00003441.
CR Abate AF, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P539, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00097
   [Anonymous], 45471 BEUR ART
   Atef, 2016, IEEE 59 INT MIDWEST
   Blackford EB, 2018, PROC SPIE, V10501, DOI 10.1117/12.2291073
   Christinaki E, 2014, 2014 EAI 4TH INTERNATIONAL CONFERENCE ON WIRELESS MOBILE COMMUNICATION AND HEALTHCARE (MOBIHEALTH), P339, DOI 10.1109/MOBIHEALTH.2014.7015980
   Demirezen H, 2021, SIGNAL IMAGE VIDEO P, V15, P1415, DOI 10.1007/s11760-021-01873-x
   Duan KF, 2016, IEEE ENG MED BIO, P6385, DOI 10.1109/EMBC.2016.7592189
   Effil NJ, 2022, SIGNAL IMAGE VIDEO P, V16, P1, DOI 10.1007/s11760-021-01952-z
   Haque MA, 2016, IEEE INTELL SYST, V31, P40, DOI 10.1109/MIS.2016.20
   Hasan Z., 2021, IEEE DATAPORT
   Helleptte, 2021, 2021 18 INT SOC DESI
   Kong Y, 2019, IEEE ACCESS, V7, P152421, DOI 10.1109/ACCESS.2019.2948107
   Lee H, 2019, IEEE SENS J, V19, P1166, DOI 10.1109/JSEN.2018.2879970
   Liu F, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3125976
   Luguern D, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102263
   McDuff D, 2018, IEEE COMPUT SOC CONF, P1448, DOI 10.1109/CVPRW.2018.00185
   McDuff DJ, 2018, IEEE T BIO-MED ENG, V65, P1725, DOI 10.1109/TBME.2017.2771518
   Nabavi S, 2020, IEEE T INSTRUM MEAS, V69, P9599, DOI 10.1109/TIM.2020.3006636
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Singla M, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2020.3000327
   Tabei F, 2020, IEEE ACCESS, V8, P11534, DOI 10.1109/ACCESS.2020.2965082
   Tabei F, 2018, IEEE ACCESS, V6, P60498, DOI 10.1109/ACCESS.2018.2875873
   Wang GX, 2018, IEEE CIRC SYST MAG, V18, P6, DOI 10.1109/MCAS.2018.2849261
   Wang WJ, 2019, IEEE T BIO-MED ENG, V66, P2032, DOI 10.1109/TBME.2018.2882396
   Wu CC, 2017, BIOMED CIRC SYST C
   Zhang GB, 2020, IEEE T IND INFORM, V16, P7209, DOI 10.1109/TII.2020.2975222
   Zhang GX, 2021, IEEE ACCESS, V9, P20460, DOI 10.1109/ACCESS.2021.3054065
   ZHANG YF, 2019, SENSORS-BASEL, V19, DOI [10.3390/s19030673, DOI 10.3390/S19030673]
   Zhao C, 2021, IEEE SENS J, V21, P15962, DOI 10.1109/JSEN.2021.3075109
   Zheng K, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103609
NR 30
TC 3
Z9 3
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20571
EP 20588
DI 10.1007/s11042-023-14399-w
EA JAN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000922310300003
DA 2024-07-18
ER

PT J
AU Barman, U
   Pathak, C
   Mazumder, NK
AF Barman, Utpal
   Pathak, Chhandanee
   Mazumder, Nirmal Kumar
TI Comparative assessment of Pest damage identification of coconut plant
   using damage texture and color analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coconut Pest; Image segmentation; GLCM; ANN; SVM; Decision tree; Naive
   Bayes
AB Coconut cultivation is a promising agricultural activity. But to keep the coconut plants pest-free, the detection of various pest damage in coconut plants is of utmost importance for the cultivators. The processes that the cultivators use to detect pest damage in coconut plants are conventional methods, experts' views, or some laboratory techniques. But these procedures are not adequate in the detection of coconut damage identification. In this study, 16 different color and texture features are reported for 1265 coconut pest damage images by extracting the color and texture features of the damage images in the color and grey domain after the damage segmentation using the thresholding technique. The Gray Level Co-occurrence Matrix (GLCM) and Gray Level Run Length Matrix (GLRLM) techniques are applied to extract the texture features of the damages and two Artificial Neural Network (ANN) architectures are reported to classify the extracted data features of the damages into 5 different classes such as Eriophyid_Mite, Rhinoceros_Beetle, Red_Palm_Weevil, Rugose_Spiraling_White_fly, and Rugose_in_Mature with an average testing accuracy of almost 100% respectively. To compare the results with the other machine learning techniques, the Support Vector Machine(SVM), Decision Tree (DT), and Naive Bayes (NB) are also introduced for damage identification where the SVM methods also report almost 100% accuracy on the fuse features of GLCM and GLRLM. The results of the ANN and SVM are compared by finding the confusion matrix, precision, recall, and f-1 score of the ANN model with the DT and NB classifier. The ANN and SVM outperform in all matrices and they can be used as the base model for further study of coconut pest damage identification using deep learning techniques.
C1 [Barman, Utpal] Assam Kaziranga Univ, Dept CSE, Jorhat, Assam, India.
   [Pathak, Chhandanee] GIMT, Dept CSE, Gauhati, Assam, India.
   [Mazumder, Nirmal Kumar] AAU, BN Coll Agr, Dept Plant Pathol, Biswanath Chariali, Assam, India.
C3 Kaziranga University; Assam Agricultural University
RP Barman, U (corresponding author), Assam Kaziranga Univ, Dept CSE, Jorhat, Assam, India.
EM utpalbelsor@gmail.com; chhandaneepathak@gmail.com; nmazumder66@gmail.com
OI Barman, Dr. Utpal/0000-0002-2000-5007
FU CDB (Kerala), GoI under the Research Scheme [1345/2018/12671]
FX AcknowledgmentsThis research project is supported by the CDB (Kerala),
   GoI under the Research Scheme, vide Ref. No.: File No. 1345/2018/12671
   dated March 23, 2019.
CR Barman Utpal, 2021, Proceedings of the Sixth International Conference on Mathematics and Computing. ICMC 2020. Advances in Intelligent Systems and Computing (AISC 1262), P275, DOI 10.1007/978-981-15-8061-1_22
   Barman Utpal, 2020, Information Processing in Agriculture, V7, P318, DOI 10.1016/j.inpa.2019.08.001
   Barman U, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P682, DOI 10.1109/ComPE49325.2020.9200015
   Barman U, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105661
   Bharathi S, 2020, INT CONF ADVAN COMPU, P1265, DOI [10.1109/ICACCS48705.2020.9074357, 10.1109/icaccs48705.2020.9074357]
   Chandy A, 2019, Journal of Artificial Intelligence, V01, P10, DOI [10.36548/jaicn.2019.1., DOI 10.36548/JAICN.2019.1.002]
   Kumar N., 2020, Int. J. Adv. Sci. Technol., V29, P1471
   Loukas S, 2021, SCIKIT LEARNS STANDA
   Manjula DG, 2021, COCONUT TREE DIS IDE, V8, P5
   Mohajon J, 2021, CONFUSION MATRIX YOU
   Nesarajan Dhapitha, 2020, 2020 IEEE 4th International Conference on Image Processing, Applications and Systems (IPAS), P212, DOI 10.1109/IPAS50080.2020.9334934
   Ngugi LC, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105788
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Sharma AK, 2022, IEEE ACCESS, V10, P17920, DOI 10.1109/ACCESS.2022.3149824
   Shung K.P., 2020, Accuracy, Precision, Recall or F1?-Towards Data Science. Medium
   Singh P, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.105986
   Sreenivasa S, 2020, MEDIUM
   Verma SS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103272
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Zhang HL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37681-6
NR 20
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25083
EP 25105
DI 10.1007/s11042-023-14369-2
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000920621000005
PM 36712953
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yadav, GS
   Mangal, P
   Parmar, G
   Soliya, S
AF Yadav, Gyan Singh
   Mangal, Parth
   Parmar, Gaurav
   Soliya, Shubham
TI Genetic algorithm and hamilton path based data hiding scheme including
   embedding cost optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Genetic algorithm; Hamiltonian path; Embedding
   optimization; Histogram
ID IMAGE STEGANOGRAPHY SCHEME; QUALITY
AB Steganography is used at a large scale in various security systems. It is the science and art of hiding secret information into data. Various steganography schemes have been proposed over the years, but most of them are not promising enough to provide a large capacity of embedding and visually prevent the image's degradation. Histograms can reveal the existence of secret information, and it is also an essential issue in the security of the data. In this Paper, the main objective is to reduce the bit-flip cost count and maximize the PSNR value to reduce the image distortion and keep the data secure by using secret keys while embedding. In this proposed paper, the genetic algorithm (GA) is employed to select the best chromosome that has the minimum bit-flip cost count and maximum PSNR. Data security is achieved by the secret key generated from Hamiltonian path for embedding and retrieving of data. The proposed technique is robust against steganographic attacks and even if presence of data is observed it not possible to guess the embedding pattern. The result section demonstrates that the proposed technique outperform the existing techniques by increasing the PSNR significantly by approx 7 percent that lead to the increase in PSNR value up to 41.8dB for three bit per pixel embedding.
C1 [Yadav, Gyan Singh; Mangal, Parth; Parmar, Gaurav; Soliya, Shubham] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota, Rajasthan, India.
RP Yadav, GS (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kota, Rajasthan, India.
EM gyansingh.cse@iiitkota.ac.in; 2019kucp1019@iiitkota.ac.in;
   2019kucp1026@iiitkota.ac.in; 2019kucp1018@iiitkota.ac.in
OI Yadav, Gyan/0000-0003-2543-6719
CR Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Carvajal-Gamez BE, 2013, EXPERT SYST APPL, V40, P1132, DOI 10.1016/j.eswa.2012.08.024
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chefranov AG, 2022, J INF SECUR APPL, V70, DOI 10.1016/j.jisa.2022.103314
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Duric Z, 2005, HANDB STAT, V24, P171, DOI 10.1016/S0169-7161(04)24006-8
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Jafari R, 2013, EXPERT SYST APPL, V40, P6918, DOI 10.1016/j.eswa.2013.06.008
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kaur J, 2021, CMC-COMPUT MATER CON, V69, P2617, DOI 10.32604/cmc.2021.017470
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Sajedi H, 2010, EXPERT SYST APPL, V37, P7703, DOI 10.1016/j.eswa.2010.04.071
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Yadav GS, 2018, APPL SOFT COMPUT, V73, P497, DOI 10.1016/j.asoc.2018.08.034
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
NR 26
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20233
EP 20249
DI 10.1007/s11042-022-14322-9
EA JAN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926801100001
DA 2024-07-18
ER

PT J
AU Liao, KY
   Wang, K
   Zheng, YL
   Lin, GF
   Cao, CJ
AF Liao, Kaiyang
   Wang, Keer
   Zheng, Yuanlin
   Lin, Guangfeng
   Cao, Congjun
TI Multi-scale saliency features fusion model for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pedestrian re-identification; Deep learning; Saliency model; Multiscale
   feature; Weighted fusion strategy
ID NETWORK
AB Person re-identification mainly uses computer vision technology to determine whether there are specific pedestrians in the image or video. Belong to cross-device retrieval images, due to the changing style of the device led to more difficult person re-identification. The current algorithms use multi-feature fusion methods such as posture detection to match, ignoring the impact of different perspectives, postures and backgrounds on features. This paper proposes a multi-scale feature method based on saliency model. Which uses the salient image extraction algorithm to better filter out the interference of complex background parts, and uses the feature weighting method to fuse the global features and local features to achieve more robust features. Experimental results on three datasets show that the proposed method is superior to the existing method.
C1 [Liao, Kaiyang; Wang, Keer; Zheng, Yuanlin; Lin, Guangfeng; Cao, Congjun] Xian Univ Technol, Sch Printing Packaging & Digital Media, Xian, Shaanxi, Peoples R China.
   [Cao, Congjun] Printing & Packaging Engn Technol Res Ctr Shaanxi, Xian, Peoples R China.
C3 Xi'an University of Technology
RP Wang, K (corresponding author), Xian Univ Technol, Sch Printing Packaging & Digital Media, Xian, Shaanxi, Peoples R China.
EM liaokaiyang@xaut.edu.cn; 478791942@qq.com
RI Lin, Guangfeng/E-4420-2013
OI Lin, Guangfeng/0000-0002-6191-1102
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Bai ST, 2022, IEEE T CIRC SYST VID, V32, P3866, DOI 10.1109/TCSVT.2021.3119983
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   García J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154
   Ge Yixiao, 2020, ARXIV200101526
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Kim Y, 2014, Arxiv, DOI arXiv:1408.5882
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li DW, 2016, Arxiv, DOI arXiv:1603.07054
   Li H, 2021, 2021 IEEE T CIRCUITS
   Li JN, 2022, IEEE T PATTERN ANAL, V44, P622, DOI 10.1109/TPAMI.2019.2929036
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019
   [陆萍 Lu Ping], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P2424
   Mang Ye, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P105, DOI 10.1007/978-3-319-14445-0_10
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Singh NK, 2022, MULTIMED TOOLS APPL, V81, P15747, DOI 10.1007/s11042-022-12585-w
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tang YZ, 2019, IEEE INT CON MULTI, P706, DOI 10.1109/ICME.2019.00127
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang GS, 2018, Arxiv, DOI arXiv:1804.01438
   Wang HR, 2022, IEEE T NEUR NET LEAR, V33, P145, DOI 10.1109/TNNLS.2020.3027589
   Wu L, 2016, Arxiv, DOI arXiv:1601.07255
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Yang B, 2022, MULTIMED TOOLS APPL, V81, P39169, DOI 10.1007/s11042-022-13170-x
   Yang JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1074, DOI 10.1145/3240508.3240645
   Yuan Y, 2020, NEUROCOMPUTING, V378, P387, DOI 10.1016/j.neucom.2019.10.083
   Zhai Y, 2020, COMPUTER VISION ECCV, P594, DOI DOI 10.1007/978-3-030-58571-6_35
   Zhang YH, 2018, INT C PATT RECOG, P3341, DOI 10.1109/ICPR.2018.8545498
   Zhang Z, 2022, IEEE T CIRC SYST VID, V32, P1160, DOI 10.1109/TCSVT.2021.3074745
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2017, Arxiv, DOI arXiv:1701.07732
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou KY, 2022, IEEE T PATTERN ANAL, V44, P5056, DOI 10.1109/TPAMI.2021.3069237
NR 48
TC 2
Z9 2
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 4
PY 2023
DI 10.1007/s11042-022-14311-y
EA JAN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7O3GP
UT WOS:000907916500001
DA 2024-07-18
ER

PT J
AU Babu, A
   Jerome, SA
AF Babu, Anu
   Jerome, S. Albert
TI Automatic breast cancer detection using HGMMEM algorithm with DELMA
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Weiner filter with Unsharp masking; Adjusted intensity
   based adaptive histogram equalization; Hierarchical Gaussian mixture
   model with expectation maximization; GLCM; FOS; SVM classifier & deep
   extreme learning machine with autoencoder classifier
AB Breast cancer detection is a challenging task in the field of medical image processing. Nowadays huge amount of research is happening in this field. Usually, for an abnormal growth of tissues in the breast, one may examine their status by a doctor through mammography images. Here, in this research article, the experimental analysis work mammography images are taken from the both Public Digital Database of Screening Mammography (DDSM), the MIAS dataset, and the in-house clinical dataset from Metro scans and laboratories. The first stage is to remove noise from the input image and boost the contrast of the image's anomalous region. For noise reduction, a Weiner filter with unsharp masking is utilized first, followed by contrast enhancement utilizing adjusted intensity-based adaptive histogram equalization. Identifying the accurate breast tumor position is a challenge, for analyzing and segmenting the ROI Hierarchical Gaussian Mixture Model with Expectation-Maximization algorithm is adopted. Then GLCM and FOS features are extracted. Finally, images of benign and malignant breast cancer are classified using the machine learning classifier SVM, and a deep learning model based on Deep Extreme Learning Machine with Autoencoder classifier is developed. Using SVM, an accuracy of 70.2% is obtained. Deep Extreme Learning Machine with Autoencoder classifier has an accuracy of 99.1%, which aids in the diagnosis of cancer cells through the automatic feature extraction process.
C1 [Babu, Anu] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, TamilNadu, India.
RP Babu, A (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
EM anubabusa123@gmail.com; albertjerome@niuniv.com
RI Babu, Anu/KBR-0506-2024; JEROME, S ALBERT/AAJ-5555-2021
OI Babu, Anu/0000-0003-4304-5391; JEROME, S ALBERT/0009-0008-0155-8053
FU management of the Noorul Islam Center for Higher Education
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible public Digital Database of
   Screening Mammography (DDSM) dataset. Then we would like to acknowledge
   Metro scans and laboratories for providing the in-house clinical data.
   Finally, we would like to thank the anonymous reviewers for helping to
   organize this text.
CR Agrawal U, 2019, ARTIF INTELL MED, V97, P27, DOI 10.1016/j.artmed.2019.05.002
   Ahmed L, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01680-1
   Bhadauria HS, 2017, MULTIMED TOOLS APPL, P1
   Bosch Anna., 2006, COMPUTER VISION PATT, V2, P1552, DOI DOI 10.1109/CVPR.2006.188
   Brandt SS, 2011, IEEE T MED IMAGING, V30, P1841, DOI 10.1109/TMI.2011.2155082
   Charan S., 2018, P 2018 INT C COMP MA, P1
   Dhanaseelan FR, 2020, IRBM, V1, P1, DOI [10.1016/j.irbm.2020.05.002,2020, DOI 10.1016/J.IRBM.2020.05.002,2020]
   Eldin SN, 2021, P 2021 INT MOBILE IN
   Sousa JRFD, 2010, COMPUT METH PROG BIO, V98, P1, DOI 10.1016/j.cmpb.2009.07.006
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hussain Zeshan, 2017, AMIA Annu Symp Proc, V2017, P979
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Kallenberg MGJ, 2011, PHYS MED BIOL, V56, P2715, DOI 10.1088/0031-9155/56/9/005
   Kriti, 2015, INT J BIOMED ENG TEC, V19, P279, DOI 10.1504/IJBET.2015.072999
   Kumar I, 2017, BIOCYBERN BIOMED ENG, V37, P217, DOI 10.1016/j.bbe.2017.01.001
   Li YF, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105518
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Loizidou K, 2020, IEEE ACCESS, V8, P52785, DOI 10.1109/ACCESS.2020.2980616
   Masmoudi AD, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-19
   Mendel K, 2019, ACAD RADIOL, V26, P735, DOI 10.1016/j.acra.2018.06.019
   Mohamed EA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262349
   Mohamed H, 2014, COMPUT METH PROG BIO, V116, P226, DOI 10.1016/j.cmpb.2014.04.010
   Mustra M, 2013, ARXIV
   Oliver A, 2005, IEEE IMAGE PROC, P1805
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Oliver A, 2006, LECT NOTES COMPUT SC, V4191, P872
   Qingqing Liu, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P356, DOI 10.1109/BMEI.2011.6098327
   Rani KV, 2020, INT J IMAG SYST TECH, V30, P899, DOI 10.1002/ima.22422
   Salvi Siddhant, 2021, Journal of Physics: Conference Series, V1831, DOI 10.1088/1742-6596/1831/1/012030
   Sha ZJ, 2020, INT J IMAG SYST TECH, V30, P495, DOI 10.1002/ima.22400
   Siddeeq S, 2021, P 2021 4 INT C IMAGE
   Nguyen VD, 2012, 2012 FOURTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P313, DOI 10.1109/CCE.2012.6315919
   Wenda He, 2012, Breast Imaging. Proceedings 11th International Workshop, IWDM 2012, P40, DOI 10.1007/978-3-642-31271-7_6
   Yihua Lan, 2012, 2012 Fourth International Conference on Computational and Information Sciences (ICCIS), P309, DOI 10.1109/ICCIS.2012.18
   Youngwoo Kim, 2014, Breast Imaging. 12th International Workshop, IWDM 2014. Proceedings: LNCS 8539, P304, DOI 10.1007/978-3-319-07887-8_43
   Zebari DA, 2021, APPL ARTIF INTELL, V35, P2157, DOI 10.1080/08839514.2021.2001177
NR 36
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26771
EP 26795
DI 10.1007/s11042-022-14310-z
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000903837100002
DA 2024-07-18
ER

PT J
AU Azni, HM
   Afsharchi, M
   Allahverdi, A
AF Azni, Hamed Mohammadi
   Afsharchi, Mohsen
   Allahverdi, Armin
TI Improving brain tumor segmentation performance using CycleGAN based
   feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Transfer learning; CycleGAN; BraTs;
   Brain tumor segmentation
ID MODEL; CRF
AB The analysis of brain tumors plays a significant role in medical applications and provides a huge amount of anatomic and functional information. Automatic tumor segmentation is one of the most challenging issues among radiologists and other specialists intent on lowering and eliminating manual detection errors and speeding up the detection of tissue types. In recent years, automatic segmentation combined with deep learning has been proven to be more powerful than traditional approaches. This study introduces a two-step model for the segmentation of brain tumors on multi-channel MRI images based on the Generative Adversarial Network (GAN). First of all, we use CycleGAN and two segmentors added to its structure to train networks that produce new features appropriate for segmentation. Different modules of MRI images are fed into these two-way networks, and the same modules, along with the target tumor segment, are requested at the output. In addition to segmentation, features created in the middle layers of these networks are capable of mapping images to one another. In the second step, the transfer learning technique is used to extract the related subnets and inject the features produced into the main segmentation network. In fact, the present study attempts to find features with greater detection power by converting different MRI images to each other. It is assumed that features beneficial in the conversion of different MRI image modules to each other will also improve segmentation performance. The proposed method is evaluated on BraTS 2018, and the results demonstrate the superiority of this method over the majority of existing approaches.
C1 [Azni, Hamed Mohammadi; Afsharchi, Mohsen] Univ Zanjan, Dept Elect & Comp Engn, Zanjan, Iran.
   [Allahverdi, Armin] Mazandaran Univ Med Sciences, Radiol Dept, Sari, Iran.
C3 University Zanjan
RP Afsharchi, M (corresponding author), Univ Zanjan, Dept Elect & Comp Engn, Zanjan, Iran.
EM afsharchi@znu.ac.ir; afsharchi@znu.ac.ir; a.allahverdi@mazums.ac.ir
OI mohammadiazni, hamed/0000-0003-1650-6682
CR Abdul Khalid N., 2011, INT J COMPUTER SCI E, V3, P980
   [Anonymous], 2010, Leonardo J Sci, DOI DOI 10.4018/JSSCI.2011040102
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Chaddad A, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/868031
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Choudhury AR, 2019, LECT NOTES COMPUT SC, V11384, P154, DOI 10.1007/978-3-030-11726-9_14
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Conte GM, 2021, RADIOLOGY, V299, P313, DOI 10.1148/radiol.2021203786
   Dar SUH, 2019, IEEE T MED IMAGING, V38, P2375, DOI 10.1109/TMI.2019.2901750
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Gao H, 2021, IEEE T COMPUTAT SOCI
   Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kohl S., 2017, ARXIV
   Li B, 2021, MED PHYS, V48, P6962, DOI 10.1002/mp.15212
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mondal A.K, 2018, ARXIV
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Oh KT, 2020, J DIGIT IMAGING, V33, P816, DOI 10.1007/s10278-020-00321-5
   Pinto A, 2015, IEEE ENG MED BIO, P3037, DOI 10.1109/EMBC.2015.7319032
   Rai HM, 2021, MULTIMED TOOLS APPL, V80, P36111, DOI 10.1007/s11042-021-11504-9
   Ramesh S, 2021, MULTIMED TOOLS APPL, V80, P11789, DOI 10.1007/s11042-020-10351-4
   Rezaei M, 2018, LECT NOTES COMPUT SC, V10670, P241, DOI 10.1007/978-3-319-75238-9_21
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saman S, 2019, INT J MULTIMED INF R, V8, P79, DOI 10.1007/s13735-018-0162-2
   Shi YG, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0623-8
   Soleymanifard M, 2022, MULTIMED TOOLS APPL, V81, P8451, DOI 10.1007/s11042-022-12326-z
   Steenwijk MD, 2013, NEUROIMAGE-CLIN, V3, P462, DOI 10.1016/j.nicl.2013.10.003
   Swaraja K, 2022, MULTIMED TOOLS APPL, V81, P27363, DOI 10.1007/s11042-022-12414-0
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Wu MN, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P245
   Wu W, 2014, INT J COMPUT ASS RAD, V9, P241, DOI 10.1007/s11548-013-0922-7
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Xun SY, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105063
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhu HH, 2023, NEURAL COMPUT APPL, V35, P16051, DOI 10.1007/s00521-021-06684-2
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 45
TC 1
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18039
EP 18058
DI 10.1007/s11042-022-14174-3
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000890126800002
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Gao, TC
AF Zhang, Xiaoqiang
   Gao, Tiancong
TI Multiple-image encryption algorithm based on the bit plane and
   superpixel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; MIE; Bitplane; Pixelbit depth; Superpixel
ID PERMUTATION
AB Image security is becoming more and more important in recently years. To improve the efficiency and security, this paper defines the concepts of the superpixel and super image, and proposes a multiple-image encryption (MIE) algorithm based on the bit plane and superpixel. The superpixel is an integer formed by connecting the binary values of multiple pixels head to tail and then converting them into a decimal number. The proposed algorithm adopts the classical scrambling-diffusion structure. At the scrambling stage, our algorithm uses the scrambling operation among bit planes and the extended Zigzag transformation in the bit plane. At the diffusion stage, our algorithm performs the exclusive OR operation on the scrambled super image. Different from other MIE algorithms, our algorithm can encrypt multiple images with the workload of processing one image. The experiments and comparative analysis, i.e., the results such as key space, differential attack, etc., show that the proposed algorithm has excellent encryption efficiency and high security.
C1 [Zhang, Xiaoqiang; Gao, Tiancong] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM grayqiang@163.com
CR Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Alan Abdulla, 2019, THESIS U BUCKINGHAM, V12, P1
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Barik RC, 2021, MULTIMED TOOLS APPL, V80, P10723, DOI 10.1007/s11042-020-09930-2
   Chen H, 2021, OPT LASER ENG, V138, DOI 10.1016/j.optlaseng.2020.106448
   Chen Q, 2020, J MOD OPTIC, V67, P1388, DOI 10.1080/09500340.2020.1862327
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dai JY, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03187-w
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Jaehun S., 2021, OPT COMMUN, V485, P1
   Jain K, 2021, PATTERN RECOGN LETT, V152, P356, DOI 10.1016/j.patrec.2021.10.033
   Jain M, 2017, INT J MACH LEARN CYB, V8, P1695, DOI 10.1007/s13042-016-0542-y
   Jain Mamta, 2017, Brain Inform, V4, P95, DOI 10.1007/s40708-016-0057-z
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Laiphrakpam DS., 2021, J INFORM SEC APP, V63, P1
   Li TY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050510
   Luan G., 2020, OPTIK, V224, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Munir N, 2021, MATH COMPUT SIMULAT, V190, P826, DOI 10.1016/j.matcom.2021.06.008
   Qiao ZC, 2020, AEU-INT J ELECTRON C, V121, DOI 10.1016/j.aeue.2020.153205
   Ratan R, 2021, DEFENCE SCI J, V71, P209, DOI 10.14429/dsj.71.15643
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Sravanthi D, 2019, ADV INTELL SYST, V758, P717, DOI 10.1007/978-981-13-0514-6_68
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   ul Haq T, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102592
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wang XY, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110962
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang XQ, 2014, SIGNAL PROCESS-IMAGE, V29, P1171, DOI 10.1016/j.image.2014.09.003
   Zhang XQ, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043029
   Zhang YM, 2021, INT J INTELL SYST, V36, P7053, DOI 10.1002/int.22580
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 51
TC 4
Z9 4
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19969
EP 19991
DI 10.1007/s11042-022-14160-9
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000888710500004
DA 2024-07-18
ER

PT J
AU Jiang, N
   Zhuang, Y
AF Jiang, Nan
   Zhuang, Yi
TI Privacy-preserving personalized similarity retrieval of large CT image
   sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computed tomography image; Privacy preserving; Personalized similarity
   retrieval; Radiation model
AB As one of the most important means of the computer-aided diagnosis, the similarity retrieval of large-scale high-resolution computed tomography image(CI) sequences can effectively assist doctors in diagnosing diseases. In this paper, we present an effective and efficient privacy-preserving Personalized Retrieval method for CISequences based on the radiation model, called the Prcs method. To our knowledge, few studies have been touched on the personalized similarity retrieval of large CI sequence(CIS)s. To better facilitate the Prcs processing, three supporting techniques, i.e., 1) KCI-based similarity measure, 2) perturbation-based privacy preserving scheme, and 3) two indexing schemes, are devised. The experimental evaluation reveals that our proposed Prcs approach is more effective and efficient than the state-of-the-art methods while improving the user experiences.
C1 [Jiang, Nan] Zhejiang Univ, Affiliated Hangzhou Peoples Hosp 1, Sch Med, Hangzhou, Peoples R China.
   [Zhuang, Yi] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang Gongshang University
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou, Peoples R China.
EM zhuang@zjgsu.edu.cn
FU Zhejiang Province Philosophy and Social Science Planning Project
   [23NDJC165YB]; Zhejiang Provincial Natural Science Foundation of China
   [LY22F020010]; Zhejiang Public Welfare Technology Application Research
   Project [LGF22H180039]; Zhejiang Traditional Chinese Medicine Science
   and Technology Project [2023ZL119]
FX The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by Zhejiang
   Province Philosophy and Social Science Planning Project under Grant No.
   23NDJC165YB; Zhejiang Provincial Natural Science Foundation of China
   under Grant No. LY22F020010; the Zhejiang Public Welfare Technology
   Application Research Project under grant No. LGF22H180039; the Zhejiang
   Traditional Chinese Medicine Science and Technology Project under grant
   No. 2023ZL119.
CR Agrawal Shubham, 2022, Int J Inf Technol, V14, P3619, DOI 10.1007/s41870-022-01007-7
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P20271, DOI 10.1007/s11042-017-5453-8
   Anbarasi MS, 2009, INT C INT AG MULT SY
   [Anonymous], 2011, MYSQL
   Cancela B, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105326
   Chang, 1997, IEEE MULTIMEDIA
   Charisi A, 2010, ACM INT HLTH INFORMA, P724
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Galic Z, 2017, GEOINFORMATICA, V21, P263, DOI 10.1007/s10707-016-0264-z
   Gañán C, 2014, COMPUT STAND INTER, V36, P513, DOI 10.1016/j.csi.2013.08.002
   He L, 2008, 2008 INT C NEUR NETW
   Huang YG, 2014, MULTIMED TOOLS APPL, V73, P1963, DOI 10.1007/s11042-013-1685-4
   Huang YG, 2014, MULTIMED TOOLS APPL, V72, P2977, DOI 10.1007/s11042-013-1589-3
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Jia XW, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2735, DOI 10.1145/3394486.3403324
   Kasban H, 2019, MULTIMED TOOLS APPL, V78, P35211, DOI 10.1007/s11042-019-08100-3
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Lehmann TM, 2004, STUDIES HLTH TECHNOL
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Wang X, 2021, WIREL NETW, DOI 10.1007/s11276-021-02697-w
   Weltera P, 2012, COMPUT METH PROG BIO, V108, P589, DOI 10.1016/j.cmpb.2011.08.010
   Yuan CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102733
   Zhang J, 2010, INT J PATTERN RECOGN, V24, P401, DOI 10.1142/S0218001410008019
   Zhu YH, 2018, PATTERN RECOGN LETT, V109, P89, DOI 10.1016/j.patrec.2017.08.018
   Zhuang Y, 2014, INFORM SCIENCES, V263, P60, DOI 10.1016/j.ins.2013.10.013
   Zhuo W, 2022, MULTIMED TOOLS APPL, V81, P41527, DOI 10.1007/s11042-020-10499-z
NR 33
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20407
EP 20429
DI 10.1007/s11042-022-14114-1
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886859000002
DA 2024-07-18
ER

PT J
AU Liu, DK
   Liang, ZX
   Li, WL
   Liu, Y
   Li, JZ
AF Liu, Dakang
   Liang, Zexiao
   Li, Wenlang
   Liu, Yuan
   Li, Jianzhong
TI Improved KNN for face classification via high-frequency texture
   components extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face classification; High-frequency texture component; K-nearest
   neighbor (KNN)
ID REPRESENTATION; RECOGNITION
AB Face classification is an important direction in the face recognition research. Although face classification has been applied in various scenarios, there are still some problems that need to be overcome. Due to the partial occlusion or feeble lighting, the partial information of face will be corrupted, which adversely affects the classification results. According to human cognitive habits, the high-frequency texture component contains the essential features of human faces and can be applied effectively in face classification. Therefore, a method is proposed in this paper to improve the conventional KNN employing high-frequency texture components. The experiment results show that the proposed method outperforms other machine learning methods. Furthermore, the proposed method can even provide similar accuracy to deep learning methods which require much more computational resource.
C1 [Liu, Dakang; Liang, Zexiao; Liu, Yuan; Li, Jianzhong] Guangdong Univ Technol, Sch Integrated Circuits, Guangzhou 510000, Peoples R China.
   [Liu, Dakang] Guangdong Univ Technol, Sch Automat, Guangzhou 510000, Peoples R China.
   [Li, Wenlang] China Southern Airlines Co Ltd, Syst Operat Control Ctr, Guangzhou 510470, Peoples R China.
C3 Guangdong University of Technology; Guangdong University of Technology
RP Li, JZ (corresponding author), Guangdong Univ Technol, Sch Integrated Circuits, Guangzhou 510000, Peoples R China.
EM 2112004053@mail2.gdut.edu.cn; 1111904018@mail2.gdut.edu.cn;
   liwenlang@csair.com; eeliuyuan@gdut.edu.cn; jianzhong.li@gdut.edu.cn
RI Ding, Yang/JUV-4842-2023; Wang, Luyao/JLL-2001-2023; zhang,
   yimeng/JLL-7337-2023; xu, lingzhi/JVZ-8748-2024; Chen,
   Haili/KHE-2315-2024; Wang, zhenhua/KFA-8731-2024; Zhang,
   Lijun/JEZ-7925-2023; Zhang, Xiaofeng/JMC-6060-2023; Wang,
   Weiyi/JZC-7841-2024; Wang, Tianqi/JJD-7473-2023; liu, lin/JFK-3401-2023;
   Yang, Mei/JNS-2225-2023; yi, li/KFR-6141-2024; Wang, Siyi/JNT-2690-2023;
   CHEN, AN/KFT-3370-2024; peng, yan/JCO-1763-2023; Zhang,
   Yuyao/KEH-7175-2024; zhou, han/JUV-0193-2023; Li, Jiawei/JOJ-9277-2023;
   qi, li/JFE-7167-2023; Qi, Ling/KHE-3068-2024; Wang, Zejun/KBB-8454-2024
OI Zhang, Xiaofeng/0000-0003-2738-3286; 
FU National Natural Science Foundation of China [62001127];
   Industry-University Research Collaboration Project - Zhuhai City
   [ZH22017001200095PWC]; Guangzhou Basic and Applied Basic Research
   Project [202102020701]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62001127, Industry-University Research
   Collaboration Project Funded by Zhuhai City (No. ZH22017001200095PWC)
   and Guangzhou Basic and Applied Basic Research Project under grant
   202102020701. The authors declare that there is no conflict of interests
   regarding the publication of this article.
CR Adjabi I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081188
   Ameur B, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P453, DOI 10.1109/ATSIP.2016.7523134
   ANYANWU M.N., 2009, J COMPUTER SCI, V3, P230
   Biswas S, 2020, J KING SAUD UNIV-COM, V32, P718, DOI 10.1016/j.jksuci.2017.10.010
   Chi HM, 2020, PATTERN RECOGN LETT, V132, P46, DOI 10.1016/j.patrec.2018.06.019
   Damer N, 2020, LECT NOTE INFORM, VP-306
   Deng KK, 2020, SIAM J IMAGING SCI, V13, P1446, DOI 10.1137/19M1253873
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Green Janet, 2021, J Neonatal Nurs, V27, P21, DOI 10.1016/j.jnn.2020.10.005
   Guodong Guo, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P196, DOI 10.1109/AFGR.2000.840634
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Jia S, 2019, IEEE T GEOSCI REMOTE, V57, P7770, DOI 10.1109/TGRS.2019.2916329
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Kramer O., 2013, K-Nearest Neighbors
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Martinez A., 1998, AR FACE DATABASE
   Negi A., 2021, COMPUTATIONAL INTELL, P255
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Nejrs S., 2020, SOLID STATE TECHNOL, V63, P13515
   Noyes E, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.201169
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Sasankar P, 2021, EASYCHAIR
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Sim T, 2001, TECHNICAL REPORT CMU
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SOLANKIK K, 2016, INT J COMPUTER APPL, V133, P20, DOI DOI 10.5120/IJCA2016907994
   Song XN, 2019, PATTERN RECOGN, V88, P127, DOI 10.1016/j.patcog.2018.11.008
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Wang S, 2021, MACH VIS APPL, V32
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yin HF, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023014
   Zhang, 2018, IEEE ACCESS
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang HY, 2012, SCI WORLD J, P1, DOI 10.1100/2012/340565
   Zheng S, 2020, PATTERN RECOGN LETT, V131, P227, DOI 10.1016/j.patrec.2019.12.020
   Zhu YL, 2017, NEURAL COMPUT APPL, V28, P233, DOI 10.1007/s00521-015-2052-3
NR 39
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18585
EP 18597
DI 10.1007/s11042-022-14244-6
EA NOV 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886864200001
DA 2024-07-18
ER

PT J
AU Siddiqui, HUR
   Zafar, K
   Saleem, AA
   Raza, MA
   Dudley, S
   Rustam, F
   Ashraf, I
AF Siddiqui, Hafeez Ur Rehman
   Zafar, Kainat
   Saleem, Adil Ali
   Raza, Muhammad Amjad
   Dudley, Sandra
   Rustam, Furqan
   Ashraf, Imran
TI Emotion classification using temporal and spectral features from
   IR-UWB-based respiration data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion classification; Feature engineering; Spectral features;
   Non-intrusive approach
AB Emotions play an important part in our daily lives since they influence our feelings and interactions. Because of the involvement of various response channels, emotion identification is a sophisticated and complex process. Emotion recognition has recently attracted the attention of the research industries as well as the scientific communities in the medical area. A variety of approaches have been explored to detect emotions from facial features, speech, text, and physiological signals. This study focuses on the classification of three basic emotions, i.e. happiness, disgust, and fear using a new set of spectral features extracted from the raw chest signal. We have used previously gathered data and biological signals (respiration rate). A structured dataset of 96810 records and 16 columns is maintained for experiments. The prior study's accuracy was 76%, which served as the baseline. In this investigation, spectral and temporal features are used. Principal component analysis (PCA) is employed to select the best features. Extensive experiments are performed using several machine learning models for different scenarios of using all features, PCA-based selected features, and Chi-square selected features to analyze the efficacy of spectral features, as well as, feature selection approaches. Feature scaling is used to standardize the range of variables. Results indicate that using the PCA-based selective features, an accuracy of 98.52% can be obtained which is competitive with intrusive methods including electroencephalography and galvanic skin response signals while outperforming existing approaches.
C1 [Siddiqui, Hafeez Ur Rehman; Zafar, Kainat; Saleem, Adil Ali; Raza, Muhammad Amjad] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan 64200, Pakistan.
   [Dudley, Sandra] London South Bank Univ, Sch Engn & Design, London, England.
   [Rustam, Furqan] Univ Management & Technol, Dept Software Engn, Lahore, Pakistan.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; London South Bank University; University of Management &
   Technology (UMT); Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
EM siddiqov@gmail.com; Kainatzafar96@gmail.com; adilalisaleem@gmail.com;
   dudleyms@lsbu.ac.uk; furqan.rustaml@gmail.com; imranashraf@ynu.ac.kr
RI Siddiqui, Hafeez Ur/AAW-1737-2020; Rustam, Furqan/ABE-4772-2020; SALEEM,
   ADIL Ali/AAL-1968-2021; Ashraf, Imran/T-3635-2019
OI Siddiqui, Hafeez Ur/0000-0003-0671-2060; Rustam,
   Furqan/0000-0001-8403-1047; SALEEM, ADIL Ali/0000-0003-2468-8471;
   Ashraf, Imran/0000-0002-8271-6496; Raza, Muhammad
   Amjad/0000-0001-8881-1307
FU EPSRC [EP/M506734/1] Funding Source: UKRI
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Antoni J, 2006, MECH SYST SIGNAL PR, V20, P282, DOI 10.1016/j.ymssp.2004.09.001
   Aslan M, 2021, J KING SAUD UNIV-COM
   Ayyadevara VK, 2018, PROMACHINE LEARNING, ppp117, DOI [DOI 10.1007/978-1-4842-3564-56, 10.1007/978-1-4842-3564-5_6, DOI 10.1007/978-1-4842-3564-5]
   Beauchaine TP, 2015, CURR OPIN PSYCHOL, V3, P43, DOI 10.1016/j.copsyc.2015.01.017
   Bhattacharyya A, 2021, IEEE SENS J, V21, P3579, DOI 10.1109/JSEN.2020.3027181
   Brownlee J., 2020, Machine Learning Mastery
   Dhieb N, 2019, 2019 IEEE INTERNATIONAL CONFERENCE OF VEHICULAR ELECTRONICS AND SAFETY (ICVES 19), DOI 10.1109/icves.2019.8906396
   Domínguez-Jiménez JA, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101646
   He L, 2011, BIOMED SIGNAL PROCES, V6, P139, DOI 10.1016/j.bspc.2010.11.001
   Holland S.M., 2008, Principal Components Analysis (PCA), P30602
   Hosseinzadeh D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P365, DOI 10.1109/MMSP.2007.4412892
   Ikram ST, 2017, J KING SAUD UNIV-COM, V29, P462, DOI 10.1016/j.jksuci.2015.12.004
   Jia ZY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2909, DOI 10.1145/3394171.3413724
   Kanjo E, 2019, INFORM FUSION, V49, P46, DOI 10.1016/j.inffus.2018.09.001
   Khan AN, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0242946
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Lalitha S., 2015, 2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC), V6, P1
   Mannepalli K, 2017, ALEX ENG J, V56, P485, DOI 10.1016/j.aej.2016.09.002
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Radha Krishna S, 2017, INT J PURE APPL MATH, V114, P227
   Ramaiah VS, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P23, DOI 10.1109/ICCSP.2016.7754232
   Saha DP, 2015, INT CONF AFFECT, P49, DOI 10.1109/ACII.2015.7344550
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau A. O., 2020, Accent classification of the three major nigerian indigenous languages using 1D CNN LSTM network model, P1, DOI [10.1007/978-981-15-2620-6_1, DOI 10.1007/978-981-15-2620-6_1]
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Siddiqui HUR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248336
   Siddiqui HUR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144833
   Tae-Ki An, 2010, 2010 International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P359, DOI 10.1109/AICI.2010.82
   Tamarit L., 2008, P SPEECH AN PROC KNO, P169
   Wickramasuriya DS, 2019, 2019 IEEE HEALTHCARE INNOVATIONS AND POINT OF CARE TECHNOLOGIES (HI-POCT), P9, DOI [10.1109/HI-POCT45284.2019.8962891, 10.1109/hi-poct45284.2019.8962891]
   Wu S., 2009, DIGIT SIGNAL PROCESS, P1
   Yantorno RE, 2001, P IEEE INT WORKSH IN, V21
NR 36
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18565
EP 18583
DI 10.1007/s11042-022-14091-5
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887298100001
DA 2024-07-18
ER

PT J
AU Zhang, DZ
   Wen, XC
   Yan, C
   Li, TY
AF Zhang, Duzhong
   Wen, Xiancheng
   Yan, Chao
   Li, Taiyong
TI An image encryption algorithm based on joint RNA-level permutation and
   substitution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper-chaotic system; RNA-level operations; Joint permutation and
   diffusion; Image encryption
ID CHAOTIC SYSTEM; CRYPTANALYSIS; IMPROVEMENT; OPERATION
AB Permutation and substitution are two essential operations in image encryption. Classical image encryption algorithms usually apply these two operations separately in "permutation-substitution" scheme, i.e., first permutation then substitution, or first substitution then permutation. It has been reported that image algorithms using such scheme are of high risks because attackers may crack the two processes separately. To solve this problem, a novel joint RNA-level permutation and substitution (JRPS) based image encryption algorithm is presented in this paper. By employing a six-dimensional (6D) hyper-chaotic system to generate pseudo-random sequences, the proposed algorithm has sufficiently complex behaviors for encryption. And plaintext image is changed to RNA codon sequence according to RNA rules. Running the joint RNA-level permutation and substitution two rounds on this RNA codon sequence, a cipher image could be obtained. The simulations reveal that the proposed algorithm could withstand various attacks.
C1 [Zhang, Duzhong; Wen, Xiancheng; Yan, Chao; Li, Taiyong] Southwestern Univ Finance & Econ, Sch Comp & Artificial Intelligence, Chengdu 611130, Peoples R China.
   [Zhang, Duzhong; Li, Taiyong] Southwestern Univ Finance & Econ, Joint Inst Intelligent Payment, Chengdu 611130, Peoples R China.
C3 Southwestern University of Finance & Economics - China; Southwestern
   University of Finance & Economics - China
RP Li, TY (corresponding author), Southwestern Univ Finance & Econ, Sch Comp & Artificial Intelligence, Chengdu 611130, Peoples R China.; Li, TY (corresponding author), Southwestern Univ Finance & Econ, Joint Inst Intelligent Payment, Chengdu 611130, Peoples R China.
EM litaiyong@gmail.com
RI Li, Taiyong/ABE-4602-2021; Li, Taiyong/ABG-3630-2020
OI Li, Taiyong/0000-0002-1546-8015; Li, Taiyong/0000-0002-1546-8015
FU Ministry of Education of Humanities and Social Science Project
   [19YJAZH047]; Scientific Research Fund of Sichuan Provincial Education
   Department [17ZB0433]
FX This work was supported by the Ministry of Education of Humanities and
   Social Science Project (Grant no. 19YJAZH047) and the Scientific
   Research Fund of Sichuan Provincial Education Department (Grant no.
   17ZB0433).
CR Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   ASKAR SS, 2015, MATH PROBL ENG, P1, DOI DOI 10.1155/2015/341729
   Bouslehi H, 2018, MULTIMED TOOLS APPL, V77, P30841, DOI 10.1007/s11042-018-5997-2
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Devi RS, 2020, MULTIMED TOOLS APPL, V79, P12093, DOI 10.1007/s11042-019-08562-5
   DEWHIRST FE, 1993, ZBL BAKT-INT J MED M, V279, P35
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Diab H, 2018, SIGNAL PROCESS, V148, P172, DOI 10.1016/j.sigpro.2018.02.011
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kar M, 2020, IETE TECH REV, V37, P12, DOI 10.1080/02564602.2018.1544855
   Li CH, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8132547
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li TY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050510
   Li TY, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013008
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu LD, 2019, IEEE ACCESS, V7, P185796, DOI 10.1109/ACCESS.2019.2961164
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   Liu LD, 2019, IEEE ACCESS, V7, P126450, DOI 10.1109/ACCESS.2019.2938181
   Liu LD, 2017, IET SIGNAL PROCESS, V11, P869, DOI 10.1049/iet-spr.2016.0709
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shaikh N, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P239, DOI 10.1109/ICACA.2016.7887958
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   Sun Y, 2023, IEEE T INTELL TRANSP, V24, P1062, DOI 10.1109/TITS.2021.3129598
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Tu GY, 2013, OPTIK, V124, P5411, DOI 10.1016/j.ijleo.2013.03.113
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P23337, DOI 10.1007/s11042-020-10209-9
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Xian ZH, 2011, ADV MATER RES-SWITZ, V171-172, P299, DOI 10.4028/www.scientific.net/AMR.171-172.299
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Yang LB, 2020, COMMUN NONLINEAR SCI, V90, DOI 10.1016/j.cnsns.2020.105362
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zhang DZ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030361
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P13841, DOI 10.1007/s11042-020-10437-z
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 57
TC 6
Z9 6
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23401
EP 23426
DI 10.1007/s11042-022-14255-3
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000885231500007
DA 2024-07-18
ER

PT J
AU Patil, G
   Shivakumara, P
   Gornale, SS
   Pal, U
   Blumenstein, M
AF Patil, Gayatri
   Shivakumara, Palaiahnakote
   Gornale, Shivanand S.
   Pal, Umapada
   Blumenstein, Michael
TI A new robust approach for altered handwritten text detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document forgery; Altered text detection; Local binary patterns;
   Histogram of oriented gradients; Statistical features; Naive Bayesian
   classifier
AB Altering handwritten documents is receiving special attention from researchers because it is useful in several sensitive crime applications such as the identification of suicide notes, fraudulent certificates, fake answer scripts, bank and property documents etc. This paper aims at developing a robust method for detecting altered text in handwritten document images in noisy and blurry environments. This study considers ten classes of handwritten text affected by multiple forgery operations with noise and blur as follows: (i) Normal-original text, (ii) Copy-paste forgery, (iii) Insertion forgery, (iv) Copy-paste and insertion forgery, (v) Noisy text, (vi) Blurred text, (vii) Copy-paste forgery with noise, (viii) Copy-paste forgery with blur, (ix) Insertion forgery with noise and (x) Insertion with blur. For ten-class classification, the proposed work explores the combination of statistical, gradient and texture features with a Bayesian classifier. The proposed approach works based on the premise that altered content in noisy and blurry handwritten documents exhibits inconsistent patterns of pixel arrangements while the original text exhibits a regular pattern of pixel arrangements. Comprehensive experiments on our dataset of 10-class and three standard datasets, namely, a dataset of forged handwritten text, a dataset of altered receipt images, and a dataset of forged IMEI number images are conducted to show effectiveness and robustness of the proposed approach compared to the state-of-the-art methods.
C1 [Patil, Gayatri; Gornale, Shivanand S.] Rani Channamma Univ, Dept Comp Sci, Belagavi, India.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Blumenstein, Michael] Univ Technol Sydney, Fac Engn & IT, Sydney, NSW, Australia.
C3 Universiti Malaya; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; University of Technology Sydney
RP Patil, G (corresponding author), Rani Channamma Univ, Dept Comp Sci, Belagavi, India.
EM gayatripatil865@gmail.com; shiva@um.edu.my; shivanand1971@rcub.ac.in;
   umapada@isical.ac.in; michael.blumenstein@uts.edu.au
RI Pal, Umapada/AAC-4930-2022; Palaiahnakote, Shivakumara/ITU-6488-2023;
   Palaiahnakote, Shivakumara/B-6261-2013
OI Gornale, Prof. Shivanand Sharnappa/0000-0001-5373-4049
FU University of Malaya, Malaysia [GPF096A-2020, GPF096B-2020,
   GPF096C-2020]
FX The authors thank Mr. Lokesh, University of Malaya for sharing the code
   of existing methods and datasets to conduct comparative study
   experiments in this work. The author of this work received partial
   support from Faculty Grant (GPF096A-2020, GPF096B-2020 and
   GPF096C-2020), University of Malaya, Malaysia.
CR Artaud C, 2018, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2018.8545428
   Bouibed ML, 2022, MULTIMED TOOLS APPL, V81, P22629, DOI 10.1007/s11042-020-10162-7
   Chen Y, 2020, IEEE 5 INFORM TECHNO, DOI [10.1109/itoec49072.2020.91418, DOI 10.1109/ITOEC49072.2020.91418]
   Cruz F, 2017, PROC INT CONF DOC, P1223, DOI 10.1109/ICDAR.2017.202
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   Gaikwad A, 2018, INT J RES ENG APPL M, DOI [10.18231/2454-9150.2018.0687, DOI 10.18231/2454-9150.2018.0687]
   Gornale Shivanand S., 2017, International Journal of Image, Graphics and Signal Processing, V9, P41, DOI 10.5815/ijigsp.2017.12.05
   Gornale Shivanand S., 2018, International Journal of Image, Graphics and Signal Processing, V10, P52, DOI 10.5815/ijigsp.2018.02.06
   Gornale S.S., 2016, Int. J. Comput. Appl, V145, P20
   Khan MJ, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P393, DOI 10.1109/DAS.2018.26
   Khan RA, 2021, MULTIMED TOOLS APPL, V80, P7039, DOI 10.1007/s11042-020-10061-x
   Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008
   Krishnani D, 2021, MULTIMED TOOLS APPL, V80, P15589, DOI 10.1007/s11042-020-10404-8
   Kundu S., 2019, P ACPR, P136, DOI DOI 10.1007/978-3-030-41404-7_10
   Luo ZP, 2015, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2015.7333811
   Mallika R, 2017, INT J ADV RES COMPUT, DOI [10.17148/IJARCCE.2017.6602, DOI 10.17148/IJARCCE.2017.6602]
   Mushtaq S, 2014, 2014 INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH), P92, DOI 10.1109/CIPECH.2014.7019062
   Nandanwar Lokesh, 2021, Expert Systems with Applications, V164, DOI 10.1016/j.eswa.2020.114014
   Nandanwar Lokesh, 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P93, DOI 10.1007/978-3-030-59830-3_8
   Nandanwar L, 2021, INT C PATT RECOG, P6562, DOI 10.1109/ICPR48806.2021.9412179
   Raghunandan KS, 2016, INT CONF FRONT HAND, P25, DOI [10.1109/ICFHR.2016.0018, 10.1109/ICFHR.2016.15]
   Revathy GS, 2015, INT J ENG RES TECHNO, DOI [10.17577/IJERTV4IS060501, DOI 10.17577/IJERTV4IS060501]
   Sarma B., 2014, INT J ADV RES COMPUT, V4, P878
   Shivakumara P, 2018, INT CONF FRONT HAND, P386, DOI 10.1109/ICFHR-2018.2018.00074
NR 25
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20925
EP 20949
DI 10.1007/s11042-022-14242-8
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000884646000004
DA 2024-07-18
ER

PT J
AU Maurya, PK
   Bagchi, S
AF Maurya, Pramod Kumar
   Bagchi, Satya
TI Quadratic residue-based unilateral authentication protocol for RFID
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RFID system; Quadratic residue; Square root modulo N; Authentication
   protocol; Security; Privacy
ID SCHEME; PRIVACY
AB Nowadays, Radio frequency identification (RFID) plays an important role in many real-life applications for remotely identifying objects. RFID system works over a wireless communication environment. Because of this, the RFID system is not secure against various attacks such as user private data leakage, location tracking, and replay attack. To overcome these security flaws, we propose a quadratic residue-based authentication scheme for the RFID system. The scheme uses square root properties of quadratic residue to prevent existing possible attacks. Formal and informal security analysis of the proposed scheme shows that the proposed scheme resists various attacks. In addition, we use BAN logic and Scyther tool to simulate the scheme. The simulation results show that the proposed scheme withstands all possible attacks. Performance evaluation illustrates that the proposed scheme is efficient under a resource-constraints environment. Moreover, the proposed scheme does not store the private information of RFID tags in its database and identifies a tag with constant-time complexity.
C1 [Maurya, Pramod Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Bagchi, Satya] Natl Inst Technol Durgapur, Dept Math, Burdwan, W Bengal, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; National Institute
   of Technology (NIT System); National Institute of Technology Durgapur
RP Maurya, PK (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM pramod_kumar22490@hotmail.com; satya5050@gmail.com
RI Maurya, Pramod Kumar/V-8836-2019; Kumar, Pramod/HKM-9642-2023
OI Maurya, Pramod Kumar/0000-0002-9413-467X; Kumar,
   Pramod/0000-0002-9413-467X
CR Akgun M, 2013, CRYPTOLOGY EPRINT AR
   Avoine G., 2007, Proceedings of the IEEE International Symposium on a World of Wireless Mobile and Multimedia Networks, P1
   Benssalah M, 2017, WIRELESS PERS COMMUN, V96, P6221, DOI 10.1007/s11277-017-4474-y
   Burmester Mike., 2008, ASIACCS 08, P283
   Chatmon C, 2006, TR060112 FLOR STAT U
   Chen YL, 2008, COMPUT NETW, V52, P2373, DOI 10.1016/j.comnet.2008.04.016
   Chien HY, 2007, IEEE T DEPEND SECURE, V4, P337, DOI 10.1109/TDSC.2007.70226
   Chiou SY, 2018, AD HOC NETW, V71, P1, DOI 10.1016/j.adhoc.2017.12.004
   Cho JS, 2015, COMPUT MATH APPL, V69, P58, DOI 10.1016/j.camwa.2012.02.025
   Cremers C., 2012, OPERATIONAL SEMANTIC, DOI [10.1007/978- 3-540-78636-8, DOI 10.1007/978-3-540-78636-8]
   Doss R, 2020, DECIS SUPPORT SYST, V132, DOI 10.1016/j.dss.2020.113270
   Doss R, 2013, AD HOC NETW, V11, P383, DOI 10.1016/j.adhoc.2012.06.015
   Fan K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010152
   Gao LJ, 2014, J NETW COMPUT APPL, V41, P37, DOI 10.1016/j.jnca.2013.10.014
   han G. N., 2011, P 20 INT C COMPUTER, P1, DOI 10.1109/ICCCN.2011.6006010
   Jingxian Zhou, 2015, Journal of Communications, V10, P117, DOI 10.12720/jcm.10.2.117-123
   Kardas S., 2013, Journal of Communications Software Systems, V9, P128, DOI [10.24138/jcomss.v9i2.150, DOI 10.24138/JCOMSS.V9I2.150]
   Kaul SD, 2017, WIRELESS PERS COMMUN, V95, P2803, DOI 10.1007/s11277-017-3965-1
   Khalid M, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718795120
   Li CT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0260-0
   Luo HG, 2018, WIREL NETW, V24, P69, DOI 10.1007/s11276-016-1323-y
   Maurya PK, 2020, WIREL NETW, V26, P1005, DOI 10.1007/s11276-018-1850-9
   Maurya PK, 2018, WIRELESS PERS COMMUN, V103, P1699, DOI 10.1007/s11277-018-5875-2
   Maurya PK, 2017, WIRELESS PERS COMMUN, V97, P967, DOI 10.1007/s11277-017-4546-z
   Melià-Seguí J, 2011, IEEE IND ELEC, P3820, DOI 10.1109/IECON.2011.6119932
   Mujahid U., 2020, INT J ELECTR COMPUT, V14, P96
   Mushtaq MF, 2017, INT J ADV COMPUT SC, V8, P333
   Safkhani M., 2018, J ELECT COMPUT ENG I, V6, DOI 10.22061/jecei.2018.1103
   Safkhani M, 2019, IEEE ACCESS, V7, P23514, DOI 10.1109/ACCESS.2019.2896641
   Sarker IH, 2023, MOBILE NETW APPL, V28, P296, DOI 10.1007/s11036-022-01937-3
   Singh D, 2019, FUTURISTIC TRENDS NE
   Singh D, 2019, WIRELESS PERS COMMUN, V107, P1289, DOI 10.1007/s11277-019-06336-8
   Singh D, 2018, IEEE INT ADV COMPUT, P33, DOI 10.1109/IADCC.2018.8692098
   Srivastava K., 2014, J MED SYST, V39, P1
   Tian Y, 2012, IEEE COMMUN LETT, V16, P702, DOI 10.1109/LCOMM.2012.031212.120237
   Tianjie Cao, 2008, Journal of Communications, V3, P20
   Tsudik G, 2006, FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P640, DOI 10.1109/PERCOMW.2006.152
   Vaudenay S, 2007, LECT NOTES COMPUT SC, V4833, P68
   Weis SA, 2004, LECT NOTES COMPUT SC, V2802, P201, DOI 10.1007/978-3-540-39881-3_18
   Wu WL, 2014, LECT NOTES COMPUT SC, V8567, P291, DOI 10.1007/978-3-319-12087-4_19
   Yeh TC, 2011, COMPUT COMMUN, V34, P337, DOI 10.1016/j.comcom.2010.05.011
   Zheng LJ, 2018, IEEE ACCESS, V6, P60996, DOI 10.1109/ACCESS.2018.2875973
   Zhou ZP, 2019, J AMB INTEL HUM COMP, V10, P3603, DOI 10.1007/s12652-018-1088-5
   Zhuang X, 2014, WIRELESS PERS COMMUN, V79, P1787, DOI 10.1007/s11277-014-1958-x
NR 44
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16533
EP 16554
DI 10.1007/s11042-022-14170-7
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000884893600002
DA 2024-07-18
ER

PT J
AU Li, WJ
   Yang, XM
   Liu, YZ
   Ou, XF
AF Li, Wujing
   Yang, Ximing
   Liu, Yuze
   Ou, Xianfeng
TI Single underwater image enhancement based on the reconstruction from
   gradients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater; Image enhancement; Reconstruction from gradients; Color
   correction
ID RESTORATION
AB Since the light is absorbed, reflected and scattered during the transmission process, underwater images are degraded suffering from color casts and low contrast. In the paper, an effective enhancement method for single underwater image is proposed based on the reconstruction technique from gradients. The method firstly corrects color by a simple and effective white-balancing approach after the compensation of red attenuation. And then an improved DCP method is used to estimate the transmission indicating the absorption and reflection of light, based on a combination filter because of edge preservation and high efficiency. Last, the enhanced gradients are obtained based on the estimated transmission, and details enhancement is accomplished by image reconstruction from the enhanced gradients on the luminance layer in Lab color space. Experimental results show that our method achieves better visual results in qualitative and quantitative evaluation, which can effectively recover the color and improve the image contrast even in very dense regions. Additionally, running time shows that our method is competitive and can be applied for real-time tasks.
C1 [Li, Wujing; Yang, Ximing; Liu, Yuze; Ou, Xianfeng] Hunan Inst Sci & Technol, Sch Informat & Commun Engn, Yueyang 414006, Peoples R China.
   [Li, Wujing; Yang, Ximing; Liu, Yuze; Ou, Xianfeng] Hunan Inst Sci & Technol, Machine Vis & Artificial Intelligence Res Ctr, Yueyang 414006, Peoples R China.
C3 Hunan Institute of Science & Technology; Hunan Institute of Science &
   Technology
RP Liu, YZ (corresponding author), Hunan Inst Sci & Technol, Sch Informat & Commun Engn, Yueyang 414006, Peoples R China.; Liu, YZ (corresponding author), Hunan Inst Sci & Technol, Machine Vis & Artificial Intelligence Res Ctr, Yueyang 414006, Peoples R China.
EM yuzeliu22@126.com
RI Wang, Tianqi/JJD-7473-2023; Li, Jiawei/JOJ-9277-2023; Zhang,
   Xiaofeng/JMC-6060-2023; Zhang, Yuyao/KEH-7175-2024; Wang,
   Weiyi/JZC-7841-2024; zhang, yimeng/JLL-7337-2023; yi, li/KFR-6141-2024;
   zhou, han/JUV-0193-2023; qi, li/JFE-7167-2023; Li, Yaqi/JEF-2795-2023;
   Wang, Luyao/JLL-2001-2023; Liu, Yuze/HSD-6158-2023; peng,
   yan/JCO-1763-2023; Yang, Mei/JNS-2225-2023; Ding, Yang/JUV-4842-2023;
   Zhang, Lijun/JEZ-7925-2023
OI Zhang, Xiaofeng/0000-0003-2738-3286; Li, Wujing/0000-0002-7825-7805
FU Hunan Provincial Natural Science Foundation [2020JJ5218]; Scientific
   Research Fund of Education Department of Hunan Province [18B345];
   Engineering Research Center on 3D Reconstruction and Intelligent
   Application Technology of Hunan Province [2019-430602-73-03-006049]
FX This work was supported by Hunan Provincial Natural Science Foundation
   (2020JJ5218), by the Scientific Research Fund of Education Department of
   Hunan Province (18B345), by the Engineering Research Center on 3D
   Reconstruction and Intelligent Application Technology of Hunan Province
   (2019-430602-73-03-006049).
CR Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cheng HY, 2020, INT J REMOTE SENS, V41, P4947, DOI 10.1080/01431161.2019.1685725
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Desai C, 2021, SIGGRAPH ASIA
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li WJ, 2012, IET IMAGE PROCESS, V6, P589, DOI 10.1049/iet-ipr.2010.0574
   Li WJ, 2019, J VIS COMMUN IMAGE R, V62, P226, DOI 10.1016/j.jvcir.2019.05.008
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Mi ZT, 2016, IET IMAGE PROCESS, V10, P206, DOI 10.1049/iet-ipr.2015.0112
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Shashar N, 1998, NATURE, V393, P222, DOI 10.1038/30380
   Tan CS, 2005, OPT LASER ENG, V43, P995, DOI 10.1016/j.optlaseng.2004.10.005
   Ulucan O, 2021, IEEE IMAGE PROC, P1784, DOI 10.1109/ICIP42928.2021.9506168
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   Wu Q, 2021, MULTIMED TOOLS APPL, V80, P29985, DOI 10.1007/s11042-021-11200-8
   Xiong JY, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P1026, DOI [10.1109/SIPROCESS.2019.8868720, 10.1109/siprocess.2019.8868720]
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yin XJ, 2020, APPL OPTICS, V59, P370, DOI 10.1364/AO.59.000370
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16973
EP 16983
DI 10.1007/s11042-022-14158-3
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000878461100003
DA 2024-07-18
ER

PT J
AU Castellano, G
   De Carolis, B
   Macchiarulo, N
AF Castellano, Giovanna
   De Carolis, Berardina
   Macchiarulo, Nicola
TI Automatic facial emotion recognition at the COVID-19 pandemic time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions recognition; Masked face; Emotions
ID MASKS
AB People use various nonverbal communicative channels to convey emotions, among which facial expressions are considered the most important ones. Thus, automatic Facial Expression Recognition (FER) is a fundamental task to increase the perceptive skills of computers, especially in human-computer interaction. Like humans, state-of-art FER systems are able to recognize emotions from the entire face of a person. However, the COVID-19 pandemic has imposed a massive use of face masks that help in preventing infection but may hamper social communication and make the recognition of facial expressions a very challenging task due to facial occlusion. In this paper we propose a FER system capable to recognize emotions from masked faces. The system checks for the presence of a mask on the face image and, in case of mask detection, it extracts the eyes region and recognizes the emotion only considering that portion of the face. The effectiveness of the developed FER system was tested in recognizing emotions and their valence only from the eyes region and comparing the results when considering the entire face. As it was expected, emotions that are related mainly to the mouth region (e.g., disgust) are barely recognized, while positive emotions are better identified by considering only the eyes region. Moreover, we compared the results of our FER system to the human annotation of emotions on masked faces. We found out that the FER system outperforms the human annotation, thus showing that the model is able to learn proper features for each emotion leveraging only the eyes region.
C1 [Castellano, Giovanna; De Carolis, Berardina; Macchiarulo, Nicola] Univ Bari, Dept Comp Sci, Bari, Italy.
   [Macchiarulo, Nicola] Exprivia SpA, Molfetta, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP Macchiarulo, N (corresponding author), Univ Bari, Dept Comp Sci, Bari, Italy.; Macchiarulo, N (corresponding author), Exprivia SpA, Molfetta, Italy.
EM giovanna.castellano@uniba.it; berardina.decarolis@uniba.it;
   nicola.macchiarulo@exprivia.com
OI Macchiarulo, Nicola/0000-0002-3754-9991
FU Universita degli Studi di Bari Aldo Moro within the CRUICARE Agreement
FX Open access funding provided by Universita degli Studi di Bari Aldo Moro
   within the CRUICARE Agreement.
CR Akbar MT, 2019, PROCEDIA COMPUT SCI, V157, P388, DOI 10.1016/j.procs.2019.08.230
   [Anonymous], 2008, P INT C ADV COMPUTER, DOI [DOI 10.1145/1501750.1501809, 10.1145/1501750.1501809]
   Assari Mohammad Amin, 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P337, DOI 10.1109/ICSIPA.2011.6144162
   Barros P, 2021, IEEE COMPUT SOC CONF, P1226, DOI 10.1109/CVPRW53098.2021.00134
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Bo Y, 2021, IEEE IMAGE PROC, P240, DOI 10.1109/ICIP42928.2021.9506047
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carbon CC, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.566886
   Castellano G, 2021, PROCEEDINGS OF THE 14TH BIANNUAL CONFERENCE OF THE ITALIAN SIGCHI CHAPTER (CHIITALY 2021), DOI 10.1145/3464385.3464730
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Goodfellow I., 2013, Challenges in Representation Learning: A Report on Three Machine Learning Contests
   Grahlow M, 2021, PSYARXIV PREPRINT, DOI [10.31234/osf.io/6msz8, DOI 10.31234/OSF.IO/6MSZ8]
   Greco Antonio, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P472, DOI 10.1007/978-3-030-68790-8_37
   Grundmann F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249792
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kret ME, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00110
   Liu M. Y., 2019, ARXIV
   Marini M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84806-5
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mehrabian A., 1972, Nonverbal communication
   Meléndez JC, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101518
   Parada-Fernández P, 2022, PERS INDIV DIFFER, V184, DOI 10.1016/j.paid.2021.111195
   Park J, 2018, BMVC
   Ramachandra V, 2022, PERS INDIV DIFFER, V185, DOI 10.1016/j.paid.2021.111249
   Ramachandran V., 2012, Encyclopedia of human behavior, V2nd, DOI [10.1016/B978-0-12-375000-6.00087-2, DOI 10.1016/B978-0-12-375000-6.00087-2]
   Roberson D, 2012, COGNITION, V125, P195, DOI 10.1016/j.cognition.2012.06.018
   Ruba AL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243708
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Saxena S., 2020, INT C COMPUTER VISIO, P381
   Scherer K.R., 2008, NEW HDB METHODS NONV
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   Tegani S, 2021, 2021 4TH INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT), DOI 10.1109/ISAECT53699.2021.9668345
   Tkalcic M, 2019, PROCEEDINGS OF IUI 2019, P150, DOI 10.1145/3301275.3302266
   Yang B, 2020, FACIAL EXPRESSION RE
   Zakka B.E., 2021, P 11 INT C SOFT COMP, P217
   Zhang LG, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158369
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 42
TC 7
Z9 7
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12751
EP 12769
DI 10.1007/s11042-022-14050-0
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000870957200001
PM 36313484
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chou, YC
   Chen, CC
AF Chou, Yung-Chien
   Chen, Chao-Chun
TI Improving deep learning-based polyp detection using feature extraction
   and data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colonoscopy; Polyps; Discrete wavelet transform; StyleGAN2; YOLOv4
ID MISS RATE; WAVELET; COLONOSCOPY; DIAGNOSIS; CLASSIFICATION;
   DECOMPOSITION; SYSTEM
AB In recent years, Colorectal Cancer (CRC) has been common reasons of lethal disease and cancer. However, colonoscopy can examine this disease, and the location of polyps and tumors can be detected. However, the early symptoms of CRC are not evident and specific, which is easy to be ignored by patients and doctors. As a result, the opportunity for early diagnosis and treatment was missed. This study aims to provide auxiliary detection to obtain accurate polyp diagnosis and assist clinicians in more precise detection. This paper proposes a novel polyp detection method through deep learning, which uses a fusion module combining feature extraction and data augmentation to enhance images. The Discrete Wavelet Transform (DWT) is applied to extract the texture features of polyps and strengthen the texture features that are not obvious in the polyp image. Then style-based GAN2 is used to enhance the image data, increase the image training data of YOLOv4, and let YOLOv4 learn more features of polyps. According to the experimental results, our method is better than state-of-the-art methods in polyp detection efficiency. In addition, because we have enhanced the image, the detection rate of small polyps is significantly improved.
C1 [Chou, Yung-Chien; Chen, Chao-Chun] Natl Cheng Kung Univ, Inst Mfg Informat & Syst, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Chen, CC (corresponding author), Natl Cheng Kung Univ, Inst Mfg Informat & Syst, Tainan 701, Taiwan.
EM p98081069@gs.ncku.edu.tw; chaochun@mail.ncku.edu.tw
FU National Science and Technology Council (NSTC) of Taiwan [NSTC
   111-2221-E-006-202, 110-2221-E-006-124]; "Intelligent Manufacturing
   Research Center" (iMRC) from The Featured Areas Research Center Program
   within the Higher Education Sprout Project by the Ministry of Education
   in Taiwan
FX This work was supported by the National Science and Technology Council
   (NSTC) of Taiwan, under grants NSTC 111-2221-E-006-202 and
   110-2221-E-006-124. This work was also supported by the "Intelligent
   Manufacturing Research Center" (iMRC) from The Featured Areas Research
   Center Program within the framework of the Higher Education Sprout
   Project by the Ministry of Education in Taiwan.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Bochkovskiy Alexey, 2004, YOLOV4 OPTIMAL SPEED
   Cancer IAFRO, 2020, INT AG RES CANC
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Demirel H, 2011, IEEE T GEOSCI REMOTE, V49, P1997, DOI 10.1109/TGRS.2010.2100401
   Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8
   Engelhardt S., 2010, BILDVERARBEITUNG MED, V574, P350
   Fetty L, 2020, Z MED PHYS, V30, P305, DOI 10.1016/j.zemedi.2020.05.001
   Fonollà R, 2021, ARTIF INTELL MED, V121, DOI 10.1016/j.artmed.2021.102178
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hasan M, 2022, MULTIMED TOOLS APPL, P1
   He WP, 2015, MECH SYST SIGNAL PR, V54-55, P457, DOI 10.1016/j.ymssp.2014.09.007
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jiang GF, 2019, LECT NOTES COMPUT SC, V11769, P801, DOI 10.1007/978-3-030-32226-7_89
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kim SH, 2021, MULTIMED TOOLS APPL, V80, P35941, DOI 10.1007/s11042-021-10551-6
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee WL, 2003, IEEE T MED IMAGING, V22, P382, DOI 10.1109/TMI.2003.809593
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Liu DY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1063-x
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Öztürk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI [10.1109/EMBC.2019.8857958, 10.1109/embc.2019.8857958]
   Radford A., 2015, ARXIV
   Rasti P, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P153, DOI 10.1109/SIU.2016.7495700
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Schoofs N, 2006, ENDOSCOPY, V38, P971, DOI 10.1055/s-2006-944835
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Vazquez D, 2017, J HEALTHC ENG
   Velmurugan AK, 2013, 2013 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ENGINEERING AND TECHNOLOGY (ICCTET), P213, DOI 10.1109/ICCTET.2013.6675949
   Vieira PM, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102141
   Wang TC, 1998, IEEE T MED IMAGING, V17, P498, DOI 10.1109/42.730395
   Wang WCV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133661
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang TY, 2019, LECT NOTES COMPUT SC, V11767, P777, DOI 10.1007/978-3-030-32251-9_85
NR 72
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16817
EP 16837
DI 10.1007/s11042-022-13995-6
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000869194800001
DA 2024-07-18
ER

PT J
AU Dureja, A
   Pahwa, P
AF Dureja, Aman
   Pahwa, Payal
TI Integrating CNN along with FAST descriptor for accurate retrieval of
   medical images with reduced error probability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image retrieval; Deep learning; Modified CNN; FAST-CNN; Query
   image; Feature descriptor
ID EFFICIENT; NETWORK; SYSTEM
AB The size of medical image repositories is continuously growing due to the widespread use of digital imaging data in hospitals. This overlays the way for more medical records to be stored in the future. An effective image retrieval system must be designed to make retrieving medical images from datasets as simple as possible. Using diverse feature extraction procedures, a number of researchers have created several picture retrieval frameworks. However, a semantic gap caused by poor extraction of low and high-level features is a fundamental problem in traditional image retrieval frameworks. As a result, during the construction of a retrieval framework, an effective feature extraction technique must be included for proper extraction of both level characteristics. The present research aims at designing modified Convolutional Neural Network(CNN) for the effective retrieval of medical images. The proposed process is performed using two models such as training and testing model. In the training phase, the features are learned using Features from Accelerated Segment Test with CNN (FAST-CNN) and stored in the database. Subsequently, in the testing process, a query image is retrieved from the dataset based on the feature matching process using Minkowski distance. The performance of the proposed retrieval framework is tested on three medical datasets using some of the metrics such as accuracy, sensitivity, precision, and F1 score. Using the proposed retrieval framework, accurate retrieval with a lesser error rate is achieved and the accuracy reached using this proposed retrieval framework is around 94%.
C1 [Dureja, Aman] Guru Gobind Singh Indraprastha Univ, USICT, Comp Sci & Engn, Delhi 110078, India.
   [Dureja, Aman] Bhagwan Parshuram Inst Technol, Dept Informat Technol, Delhi 110089, India.
   [Pahwa, Payal] Bhagwan Parshuram Inst Technol, Comp Sci & Engn, Delhi 110089, India.
C3 GGS Indraprastha University; Bhagwan Parshuram Institute of Technology;
   Bhagwan Parshuram Institute of Technology
RP Dureja, A (corresponding author), Guru Gobind Singh Indraprastha Univ, USICT, Comp Sci & Engn, Delhi 110078, India.; Dureja, A (corresponding author), Bhagwan Parshuram Inst Technol, Dept Informat Technol, Delhi 110089, India.
EM amandureja@gmail.com
RI Dureja, Aman/AAP-8529-2021
OI Dureja, Aman/0000-0002-2792-9296
CR Cai YH, 2019, IEEE ACCESS, V7, P51877, DOI 10.1109/ACCESS.2019.2911630
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Dhingra Shefali, 2021, Proceedings of International Conference on Artificial Intelligence and Applications. ICAIA 2020. Advances in Intelligent Systems and Computing (AISC 1164), P337, DOI 10.1007/978-981-15-4992-2_32
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   Haripriya P, 2021, J AMB INTEL HUM COMP, V12, P781, DOI 10.1007/s12652-020-02077-w
   Hassan G, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500398
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   Intisar Rizwan I. Haque, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2020.100297
   Khalid H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080518
   Khwildi R, 2021, MULTIMED TOOLS APPL, V80, P15413, DOI 10.1007/s11042-020-10416-4
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Li XQ, 2020, IEEE ACCESS, V8, P57796, DOI 10.1109/ACCESS.2020.2982560
   Liu CY, 2019, IET IMAGE PROCESS, V13, P2058, DOI 10.1049/iet-ipr.2018.5298
   Lu HM, 2021, IEEE T FUZZY SYST, V29, P166, DOI 10.1109/TFUZZ.2020.2984991
   Montazeran M., 2021, Textbook of Patient Safety and Clinical Risk Management, P309
   Murugesan G, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/2653665
   Owais M, 2020, J MED INTERNET RES, V22, DOI 10.2196/18563
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Öztürk S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113693
   Qu Z, 2020, IEEE ACCESS, V8, P54564, DOI 10.1109/ACCESS.2020.2981561
   Rashad M., 2022, EFFECTIVE MODERN TEC
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Su Y, 2021, ISPRS J PHOTOGRAMM, V179, P50, DOI 10.1016/j.isprsjprs.2021.07.003
   Sun Q, 2017, ADV SPACE RES, V60, P2660, DOI 10.1016/j.asr.2017.05.017
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xiao JS, 2023, COMPUTING, V105, P717, DOI 10.1007/s00607-021-00907-z
   Yang X, 2021, ISPRS J PHOTOGRAMM, V177, P238, DOI 10.1016/j.isprsjprs.2021.05.004
   Yelmanov S, 2018, 2018 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P568, DOI 10.1109/DSMP.2018.8478441
   Zhang Z, 2018, SIGNAL PROCESS, V147, P173, DOI 10.1016/j.sigpro.2018.01.027
NR 35
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17659
EP 17686
DI 10.1007/s11042-022-13991-w
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000864310100002
DA 2024-07-18
ER

PT J
AU Sebastian, RA
   Sebastian, AM
AF Sebastian, Rinu Ann
   Sebastian, Anu Maria
TI Leveraging semantic similarity to mitigate the severity of
   misclassification for safety critical applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Severity of misclassification; Convolutional neural networks; Custom
   loss function; Safety-critical application; Semantic information;
   Hierarchy-based loss function; Custom cross entropy
ID RECOMMENDATION SYSTEM; RECOGNITION
AB Image classification finds wide applications in face recognition, cancer detection, and many more. However, the classifier models such as convolutional neural networks (CNN) used in safety-critical systems like self-driving cars, medical image diagnosis, etc., demand differential treatment of classification mistakes. This is because certain misclassifications may have grave impacts whereas certain others might have only minor adverse impacts. The idea of the severity of misclassification can be associated with the semantic information possessed by the classes. The objective of this work is to minimize the severity of misclassification which has high relevance in safety-critical applications. To achieve differential treatment of mistakes semantic information is incorporated into CNNs with a custom cross-entropy loss function. The semantic similarity information enables CNNs to distinguish between semantically similar and dissimilar images. We propose a model to build custom cross-entropy loss functions that penalise the classification mistakes according to their severity. In addition, we propose two novel methods to build the semantic similarity matrix between the classes to feed into the custom loss function. The first method used directed acyclic hierarchies from the data, and the second method uses a confusion matrix to build similarity matrices. The results showed that the proposed solutions were found to reduce the severity of misclassification and also achieve an overall improvement in the classification accuracy of the model. The First model achieved a classification accuracy of 78.8 +/- 0.3% and the second model achieved an accuracy of 79.2 +/- 0.3%. The First model reduced the severity of misclassification by a degree of 2 Superclass Misclassification Error (SCME) and the second model reduced it by 1.5 SCME than the base CNN model. In addition, we have also compared our methods to the recent related works in this domain to highlight the benefits of the proposed methods.
C1 [Sebastian, Rinu Ann] Univ Melbourne, Sch Comp & Informat Syst, Melbourne, Vic, Australia.
   [Sebastian, Anu Maria] Cochin Univ Sci & Technol, Dept Comp Sci, Artificial Intelligence Lab, Cochin, Kerala, India.
C3 University of Melbourne; Cochin University Science & Technology
RP Sebastian, AM (corresponding author), Cochin Univ Sci & Technol, Dept Comp Sci, Artificial Intelligence Lab, Cochin, Kerala, India.
EM rinu.ann.sebastian@gmail.com; anumseb@gmail.com
OI Sebastian, Anu Maria/0000-0002-2400-7691
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   An GZ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83503-7
   Balaji K, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P75, DOI 10.1016/B978-0-12-816718-2.00012-9
   Barua, 2019, SELF DRIVING CAR IMP, DOI [10.1109/iccs45141.2019.9065627, DOI 10.1109/ICCS45141.2019.9065627]
   Barz B, 2019, IEEE WINT CONF APPL, P638, DOI 10.1109/WACV.2019.00073
   Bertinetto L., 2020, IEEECVF C COMPUT VIS, P12506
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Brust C.-A., 2019, AS C PATT REC ACPR, P3, DOI DOI 10.1007/978-3-030-41404-7_1
   Cavalin P., 2018, IB C PATT REC, P271
   Chakraborty A, 2017, HANDBOOK OF NEURAL COMPUTATION, P67, DOI 10.1016/B978-0-12-811318-9.00004-1
   Chang JY, 2015, COMPUT VIS IMAGE UND, V132, P3, DOI 10.1016/j.cviu.2014.11.006
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhall A, 2020, IEEE COMPUT SOC CONF, P3649, DOI 10.1109/CVPRW50498.2020.00426
   Fan JP, 2017, IEEE T IMAGE PROCESS, V26, P1923, DOI 10.1109/TIP.2017.2667405
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Huang GL, 2017, IEEE ICC
   Kim JH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182271
   Kobs K, 2020, LECT NOTES COMPUT SC, V12117, P431, DOI 10.1007/978-3-030-59491-6_41
   Kowsari K, 2020, INFORMATION, V11, DOI 10.3390/info11060318
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23017, DOI 10.1007/s11042-016-4211-7
   Liu PH, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P7, DOI 10.1109/ICCSS.2015.7281139
   Lu L, 2019, IEEE T INTELL TRANSP, V20, P1774, DOI 10.1109/TITS.2018.2835471
   Miller GA., 1992, INTELLIGENT TUTORING, P89, DOI 10.1007/978-3-642-77202-3_7
   Roy D, 2020, NEURAL NETWORKS, V121, P148, DOI 10.1016/j.neunet.2019.09.010
   Seo Y, 2019, EXPERT SYST APPL, V116, P328, DOI 10.1016/j.eswa.2018.09.022
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Szoke, 2020, DRIVING HIGHWAY USIN, DOI [10.1109/ines49302.2020.9147185, DOI 10.1109/INES49302.2020.9147185]
   Urmson C, 2008, IEEE INTELL SYST, V23, P66, DOI 10.1109/MIS.2008.34
   Wu H, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P172, DOI 10.1145/2964284.2967205
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
NR 40
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12615
EP 12633
DI 10.1007/s11042-022-13781-4
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859866500001
DA 2024-07-18
ER

PT J
AU Yang, G
   Zhu, DA
AF Yang, Ge
   Zhu, Dian
TI Survey on algorithms of people counting in dense crowd and crowd density
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Crowd density estimation; Intelligent monitoring; Deep
   learning
AB The number of people and the estimation of the population density are one of the important information concerned by intelligent monitoring. This article reviews, summarizes, and classifies the research methods and status of population statistics and population density estimation. According to the different methods of obtaining crowd information, the research methods of population density statistics and population density estimation are divided into detection-based methods, regression-based methods, and density-based methods. The methods based on density estimation are studied in detail. The network structures based on density estimation are divided into a single-column deep convolutional neural network and a multi-column convolutional neural network. Summarized the basic ideas, advantages and disadvantages of each method, analyzed and introduced the representative algorithms of each method, analyzed and compared related experiments, and introduced common mainstream data sets and performance evaluations for population statistics and population density estimation. Indicators and evaluation methods, and prospects for future possible research directions and corresponding development trend in this field.
C1 [Yang, Ge; Zhu, Dian] Beijing Normal Univ, Res Ctr Intelligent Engn & Educ Applicat, Zhuhai 519087, Peoples R China.
   [Yang, Ge; Zhu, Dian] Beijing Normal Univ, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
   [Yang, Ge] Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen 518055, Peoples R China.
C3 Beijing Normal University; Beijing Normal University; Peking University
RP Yang, G (corresponding author), Beijing Normal Univ, Res Ctr Intelligent Engn & Educ Applicat, Zhuhai 519087, Peoples R China.; Yang, G (corresponding author), Beijing Normal Univ, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.; Yang, G (corresponding author), Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen 518055, Peoples R China.
EM yangge@pkusz.edu.cn
FU Major Scientific Research Project for Universities of Guangdong Province
   [2019KZDXM015, 2020ZDZX3058]; Guangdong Provincial special funds Project
   for Discipline Construction [2013WYXM0122]; Science and technology
   projects of Zhuhai in the field of social development [2220004000066];
   Key Laboratory of Intelligent Multimedia Technology [201762005]
FX This research was financially supported by Major Scientific Research
   Project for Universities of Guangdong Province (2019KZDXM015,
   2020ZDZX3058); Guangdong Provincial special funds Project for Discipline
   Construction (No.2013WYXM0122); Science and technology projects of
   Zhuhai in the field of social development (2220004000066); Key
   Laboratory of Intelligent Multimedia Technology(201762005).
CR Albiol A., 2009, 3International_Workshop_on Performance_Evaluation_of_Tracking_and_Surveillance, P31
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Biswas S, 2018, OPTIK, V168, P931, DOI 10.1016/j.ijleo.2018.05.011
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dharanipragada NVRA., 2018, AICHE J, V64, P64
   Ding XH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1942, DOI 10.1109/ICASSP.2018.8461772
   Dolz J, 2018, IEEE T MED IMAGING, V16, P34
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Gao F, 2019, IEEE ACCESS, V17, P11
   Gong L, 2019, IEEE J BIOMED HEALTH, V23, P766, DOI 10.1109/JBHI.2018.2836380
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, IEEE ADV INFORM MANA, P57
   Hu H, 2019, IEEE INT SYMP INFO, P375, DOI [10.1109/ISIT.2019.8849836, 10.1109/isit.2019.8849836]
   Huang LJ, 2021, IEEE ACCESS, V9, P136032, DOI 10.1109/ACCESS.2021.3115963
   Huang Y, 2019, SOL PHYS, V294, DOI 10.1007/s11207-019-1524-5
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Li T., 2015, IEEE T CIRCUITS SYST, V12, P67
   Li YZ, 2019, IEEE T CIRC SYST VID, V29, P1179, DOI 10.1109/TCSVT.2018.2825022
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang X, 2018, 2018 IEEE C MULTIMED, P124
   Lu R, 2019, ARXIV191111985, P11
   Lu RQ, 2019, IEEE IMAGE PROC, P1640, DOI [10.1109/ICIP.2019.8803090, 10.1109/icip.2019.8803090]
   Carmona JM, 2018, PATTERN RECOGN, V81, P443, DOI 10.1016/j.patcog.2018.04.015
   Marsden M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P27, DOI 10.5220/0006097300270033
   Martinho-Corbishley D, 2019, IEEE T PATTERN ANAL, V41, P1486, DOI 10.1109/TPAMI.2018.2836900
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Rodriguez M, 2011, IEEE INT C COMPUTER, P77
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Schmitt B, 2018, TOP WORKSH EL PART P
   Schulz E, 2018, J MATH PSYCHOL, V85, P1, DOI 10.1016/j.jmp.2018.03.001
   Shi C, 2018, IEEE T CIRC SYST VID, V28, P1021, DOI 10.1109/TCSVT.2016.2630848
   Shirvaikar MV, 2018, REAL TIME IMAGE VIDE, P481
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Song TA, 2020, IEEE T COMPUT IMAG, V6, P518, DOI [10.1109/TCI.2020.2964229, 10.1109/tci.2020.2964229]
   Tahboub K, 2017, IEEE IMAGE PROC, P4192, DOI 10.1109/ICIP.2017.8297072
   Tian YK, 2020, IEEE T IMAGE PROCESS, V29, P2714, DOI 10.1109/TIP.2019.2952083
   Tsalapati E., 2016, P IJCAI
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Xu BL, 2016, IEEE WINT CONF APPL
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Xue H, 2021, IEEE T NEUR NET LEAR, V32, P77, DOI 10.1109/TNNLS.2020.2975837
   Yousaf RM, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P96, DOI 10.1109/CIS2018.2018.00029
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang XC, 2019, IEEE T CIRC SYST VID, V29, P1530, DOI 10.1109/TCSVT.2018.2833743
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao S, 2018, CHIN CONT DECIS CONF, P5966, DOI 10.1109/CCDC.2018.8408176
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2376-5
   Zhou ZY, 2018, MAGN RESON MED, V80, P2759, DOI 10.1002/mrm.27229
NR 56
TC 2
Z9 2
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13637
EP 13648
DI 10.1007/s11042-022-13957-y
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866500003
DA 2024-07-18
ER

PT J
AU Todmal, S
   Mule, A
   Bhagwat, D
   Hazra, T
   Singh, B
AF Todmal, Shantanu
   Mule, Ashish
   Bhagwat, Devang
   Hazra, Tanmoy
   Singh, Bhupendra
TI Human face generation from textual description via style mapping and
   manipulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-face generation; Generative adversarial networks; Text encoding;
   Image quality; Image attribute diversity; Facial attribute
   disentanglement
AB Text-to-Face generation is an interesting and challenging task with great potential for diverse computer vision ap- plications in public safety domain. There has been very selective work in Text-to-Face synthesis than Text-to-Image due to diverse facial visual attributes and their corresponding descriptions. In this paper, we have proposed a Text-to-Face generative model that can produce high quality and high resolution images from a given textual description. The model is also able to produce a range of diverse images for a given description. In the proposed approach, the encoded text input is mapped to the generator to produce high quality output which is further manipulated to better reflect the described attributes. Apart from diversity (or in addition to diversity), the model is also able to significantly emphasize the facial attributes provided in the description. The applications of the proposed model include criminal investigation, character generation (video games, movies etc.), manipulating facial attributes according to brief textual description, text based style transfer, text based Image retrieval etc.
C1 [Todmal, Shantanu; Mule, Ashish; Bhagwat, Devang; Hazra, Tanmoy; Singh, Bhupendra] Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune, Maharashtra, India.
RP Hazra, T (corresponding author), Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune, Maharashtra, India.
EM shantanutodmal18@cse.iiitp.ac.in; ashislunule18@cse.iiitp.ac.in;
   devangbhagwat18@cse.iiitp.ac.in; tanmoyhazra316@gmail.com;
   bhupendra@iiitp.ac.in
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Barratt S, 2018, ARXIV
   Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460
   Chen X, 2019, ARXIV
   Garg K, 2020, 2020 JOINT 9 INT C I, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Karnewar Animesh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7796, DOI 10.1109/CVPR42600.2020.00782
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kettunen M, 2019, ARXIV
   Khan MZ, 2021, IEEE ACCESS, V9, P1250, DOI 10.1109/ACCESS.2020.3015656
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li B., 2019, arXiv
   Nasir OR, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P58, DOI [10.1109/BigMM.2019.00-42, 10.1109/BigMM.2019.00020]
   Patashnik O., 2021, arXiv
   Radford A., 2015, ARXIV
   Radford A, 2021, PR MACH LEARN RES, V139
   Reed S, 2016, PR MACH LEARN RES, V48
   Richardson E, 2020, ARXIV
   Salimans Tim, 2016, ARXIV
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao M, 2020, ARXIV
   Wang T., 2021, P IEEE CVF WINT C AP, P3380
   Xia W, 2021, ARXIV
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yongyi L., 2018, P EUR C COMP VIS, P282
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 37
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13579
EP 13594
DI 10.1007/s11042-022-13899-5
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600005
DA 2024-07-18
ER

PT J
AU Yu, XY
   Xie, W
   Zhang, LW
AF Yu, Xiaoyuan
   Xie, Wei
   Zhang, Langwen
TI From low to high: cascade network for restoring low-resolution face
   image via extracting and transforming edge feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cascade network; Extracting edge feature; Face image; Transforming
   feature; Self-attention; Single image super-resolution
ID SUPERRESOLUTION; RESTORATION; RECOGNITION; ALGORITHM; SPARSE
AB The super-resolution task about the single facial image is the specific task in single image super-resolution (SISR), which has attracted much attention from researchers. Various facial SISR methods based on deep learning have achieved excellent performance. Unfortunately, most existing methods perform poorly for generating the SR image with large upsampling factors when the input image has a lower resolution. To break the above limitations, we propose a two-stage cascade network (TSCnet) under an end-to-end manner to reconstruct SR face image with large upsampling factors. The coarse SR facial image with middle magnification is generated at the first stage while the final SR facial image is obtained at the second stage by concatenating the coarse SR image and the upsampling result of the input image. In particular, inspired by the physical model of image restoration, the blurry kernel predicted (BKP) module within the improved residual block (ImRB) is designed to transform useful intermediate features during each stage by combining the edge feature extracted from the coarse face image. Furthermore, we also design a self-attention U-net (SAUnet) to extract the correct edge feature of the coarse face image. Compared with the state-of-the-art methods, the proposed method improves the visual value by about 1.4% LPIPS on the test data. Expanded experiments demonstrate that the proposed method performs well in quantitative and qualitative evaluations when generating the facial SR image with size 256 x 256 from the LR image with size 16 x 16. The code is released in . https://github.com/Andyyu001/MTAP_SR.
C1 [Yu, Xiaoyuan] South China Univ Technol, Coll Software, Guangzhou, Peoples R China.
   [Xie, Wei; Zhang, Langwen] South China Univ Technol, Coll Automat Sci & Engn, Guangzhou, Peoples R China.
   [Xie, Wei] South China Univ Technol, Guangdong Prov Key Lab Polymer Adv Mfg Technol &, Guangzhou, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; South China University of Technology
RP Yu, XY (corresponding author), South China Univ Technol, Coll Software, Guangzhou, Peoples R China.
EM yuwspg@163.com; weixie@scut.edu.cn; aulwzhang@scut.edu.cn
RI Zhang, Lijuan/KAM-0174-2024; CAO, ying/KFA-2972-2024; qin,
   cheng/KHC-3344-2024; Wang, Huiyan/JXW-9178-2024; Guo, Lin/KFS-9366-2024;
   Wang, Yibin/KEZ-9645-2024; sun, yuan/KBD-3926-2024; cai,
   wen/JWP-4797-2024
FU Key-Area Research and Development Program of Guangdong Province
   [2018B010108001]; Science and Technology Plan Project of Jiangmen
   [2020030103080008999]
FX This work was supported by the Key-Area Research and Development Program
   of Guangdong Province under Grant no.2018B010108001. Science and
   Technology Plan Project of Jiangmen (2020030103080008999). The authors
   would like to thank the editors and reviewers for their valuable
   comments.
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Bao-Cheng Wang, 2019, Intelligent Computing Theories and Application. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11643), P296, DOI 10.1007/978-3-030-26763-6_28
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bhattacharjee Avishek, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P223, DOI 10.1109/TBIOM.2020.2983524
   Boyu Lu, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P26, DOI 10.1109/TBIOM.2019.2959133
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   CHEN TP, 1995, IEEE T NEURAL NETWOR, V6, P911, DOI 10.1109/72.392253
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cruz C, 2018, IEEE T IMAGE PROCESS, V27, P1376, DOI 10.1109/TIP.2017.2779265
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Ge W, 2018, SIGGRAPH ASIA 2018, V37
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Han YZ, 2021, IEEE COMPUT SOC CONF, P880, DOI 10.1109/CVPRW53098.2021.00098
   Hsu CC, 2019, IEEE T IMAGE PROCESS, V28, P6225, DOI 10.1109/TIP.2019.2924554
   Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Lu J, 2019, SIGNAL PROCESS-IMAGE, V70, P210, DOI 10.1016/j.image.2018.10.003
   Lu ZY, 2022, SIGNAL IMAGE VIDEO P, V16, P1143, DOI 10.1007/s11760-021-02063-5
   Montabone S, 2010, IMAGE VISION COMPUT, V28, P391, DOI 10.1016/j.imavis.2009.06.006
   Pan JS, 2020, AAAI CONF ARTIF INTE, V34, P11807
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Qian XL, 2021, IEEE SIGNAL PROC LET, V28, P180, DOI 10.1109/LSP.2021.3049997
   Ren WQ, 2019, IEEE I CONF COMP VIS, P9387, DOI 10.1109/ICCV.2019.00948
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29
   Shi JG, 2018, IEEE T IMAGE PROCESS, V27, P2980, DOI 10.1109/TIP.2018.2813163
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Xiaoyuan Yu, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P214, DOI 10.1109/TBIOM.2021.3051268
   Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Yang WM, 2020, NEUROCOMPUTING, V398, P291, DOI 10.1016/j.neucom.2019.09.091
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Zhang L, 2017, IEEE SIGNAL PROC MAG, V34, P172, DOI 10.1109/MSP.2017.2717489
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang X, 2018, ADV FUNCT MATER, V28, DOI 10.1002/adfm.201706523
   Zhang XY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1448, DOI 10.1109/ICASSP.2018.8462601
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhao D, 2019, MACH VISION APPL, V30, P153, DOI 10.1007/s00138-018-0983-2
   Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37
NR 62
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14441
EP 14470
DI 10.1007/s11042-022-13693-3
EA SEP 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000859771500002
DA 2024-07-18
ER

PT J
AU Sisodiya, N
   Garg, S
   Dube, N
   Thakkar, P
   Parmar, A
   Sharma, S
AF Sisodiya, Neha
   Garg, Sanjay
   Dube, Nitant
   Thakkar, Priyank
   Parmar, Akshay
   Sharma, Shashikant
TI Scalable clustering for EO data using efficient raster representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compact Data Structure; k(2)-raster; Earth observation data; Scalable
   clustering
ID ALGORITHM
AB Earth Observation (EO) data is a source of a wide range of information, in vegetation, oceanography, land use, land cover and many more applications. To uncover the hidden information in the data, unsupervised learning techniques like clustering is used popularly. With technological advancements, the amount of data received through satellites rises exponentially, possessing the properties of Big Data. Traditional implementations of clustering algorithms have processing limitations based on the memory capability of the system. In general, applying any clustering algorithm directly to the large EO raster data requires a considerably large amount of time, due to the spatio-temporal nature of the data. The data generated by remote sensors have significant redundant values, so we have made an attempt to use compressed raster data for clustering without decompressing it. In this work, we present the compact data structure, known as k(2)-raster, based technique for clustering raster data. k(2)-raster preserves the spatial context in the image and provides time efficient and lossless compression. We have applied this technique to OCM2-NDVI, in GeoTIFF format, single and stacked image to develop a compressed dataset for efficient representation. As partition based clustering algorithms are widely used in clustering EO data because of their simplicity and time efficiency, we have examined the results on k-means and mini-batch k-means. We have also assessed the performance of our algorithm on model based clustering algorithms. It has been demonstrated that, for datasets with larger numbers of raster values, the developed compact data structure based approach works very well in terms of compact representation of data as well as, with both the partition based and model based clustering techniques making the clustering scalable.
C1 [Sisodiya, Neha; Garg, Sanjay; Thakkar, Priyank; Parmar, Akshay] Nirma Univ, Dept CSE, Inst Technol, Ahmadabad, Gujarat, India.
   [Dube, Nitant; Sharma, Shashikant] India Space Res Org, Space Applicat Ctr, Ahmadabad, Gujarat, India.
C3 Nirma University; Department of Space (DoS), Government of India; Indian
   Space Research Organisation (ISRO); Space Applications Centre (SAC)
RP Sisodiya, N (corresponding author), Nirma Univ, Dept CSE, Inst Technol, Ahmadabad, Gujarat, India.
EM 17ptphde169@nirmauni.ac.in
RI Sisodiya, Neha/KQT-9766-2024; Garg, Sanjay/B-2609-2016
OI Garg, Sanjay/0000-0002-2279-9373; Dube, Nitant/0000-0002-2230-895X
FU Space Application Center-Indian Space Research Organization (SACISRO)
   under RESPOND program [OGP-142]
FX This work was supported by Space Application Center-Indian Space
   Research Organization (SACISRO) under RESPOND program OGP-142.
CR Alvarez-Garcia S, 2014, IEEE DATA COMPR CONF, P342, DOI 10.1109/DCC.2014.56
   Bahri M.A.S., 2019, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, V42, P563, DOI [10.5194/isprs-archives-XLII-4-W16-563-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W16-563-2019]
   Brisaboa NR, 2013, INFORM PROCESS MANAG, V49, P392, DOI 10.1016/j.ipm.2012.08.003
   Brisaboa NR, 2009, LECT NOTES COMPUT SC, V5721, P18, DOI 10.1007/978-3-642-03784-9_3
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chow K, 2019, REMOTE SENS-BASEL, V11
   Devi S., 2014, IMPACT INT J RES ENG, V2, P107
   Dunren Che, 2013, Database Systems for Advanced Applications. 18th International Conference, DASFAA 2013. International Workshops: BDMA, SNSM, SeCop. Proceedings: LNCS 7827, P1, DOI 10.1007/978-3-642-40270-8_1
   He Q, 2014, NEUROCOMPUTING, V128, P88, DOI 10.1016/j.neucom.2012.12.063
   Hung Yi Lin, 2008, 2008 International Conference on Service Systems and Service Management (ICSSSM 2008), P1, DOI 10.1109/ICSSSM.2008.4598528
   Ianni M, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P1073, DOI 10.1145/3297280.3297386
   Jiang YB, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P649, DOI 10.1109/ICSESS.2014.6933652
   Katajainen J, 2010, INFORM PROCESS LETT, V110, P1061, DOI 10.1016/j.ipl.2010.08.007
   Kim Y, 2014, INFORM SYST, V42, P15, DOI 10.1016/j.is.2013.11.002
   Koonsanit K, 2012, P 2011 9 INT C IEEE, P124
   Ladra S, 2016, 28TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT (SSDBM) 2016), DOI 10.1145/2949689.2949710
   Ladra S, 2017, INFORM SYST, V72, P179, DOI 10.1016/j.is.2017.10.007
   Lin HY, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P411
   Murtagh F, 2011, COMPUT RES REPOSITOR
   Nisha, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P304
   Park BH, 2003, HUM FAC ER, P341
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pingel, 2018, GEOGRAP INF SCI TECH, V2018, P10
   Rabbani M., 1991, DIGITAL IMAGE COMPRE
   Rahman MA, 2020, IOP C SER EARTH ENV, V540, DOI 10.1088/1755-1315/540/1/012067
   Rao, 2012, INT J SOFTWARE ENG A, V3, P125
   Saeed MM, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.321
   Sajana T., 2016, INDIAN J SCI TECHNOL, V9, P1
   scikit-learn, 2022, SET PYTH MOD MACH LE
   Sisodiya, 2020, NEXT GENERATION ARTI
   Xu XW, 1999, DATA MIN KNOWL DISC, V3, P263, DOI 10.1023/A:1009884809343
   Zhu YT, 2014, INT CONF COMP SCI ED, P573, DOI 10.1109/ICCSE.2014.6926527
NR 32
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12303
EP 12319
DI 10.1007/s11042-022-13726-x
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000857279500003
DA 2024-07-18
ER

PT J
AU Yu, JH
   Moon, JH
   Sohn, KA
AF Yu, Jun-Hyung
   Moon, Jeong-Hyeon
   Sohn, Kyung-Ah
TI Attention-guided residual frame learning for video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; ConvLSTM; Surveillance video; Self-attention
ID EVENT DETECTION
AB The problem of anomaly detection in video surveillance data has been an active research topic. The main difficulty of video anomaly detection is due to two different definitions of anomalies: semantically abnormal objects and motion caused by unauthorized changes in objects. We propose a new framework for video anomaly detection by designing a convolutional long short-term memory-based model that emphasizes semantic objects using self-attention mechanisms and concatenation operations to further improve performance. Moreover, our proposed method is designed to learn only the residuals of the next frame, which allows the model to better focus on anomalous objects in video frames and also enhances stability of the training process. Our model substantially outperformed previous models on the Chinese University of Hong Kong (CUHK) Avenue and Subway Exit datasets. Our experiments also demonstrated that each module of the residual frame learning and the attention block incorporated into our framework is effective in improving the performance.
C1 [Yu, Jun-Hyung] LG CNS, Seoul, South Korea.
   [Moon, Jeong-Hyeon; Sohn, Kyung-Ah] Ajou Univ, Dept Artificial Intelligence, Suwon, South Korea.
C3 Ajou University
RP Sohn, KA (corresponding author), Ajou Univ, Dept Artificial Intelligence, Suwon, South Korea.
EM 0416junhyung@gmail.com; mjh319@ajou.ac.kr; kasohn@ajou.ac.kr
OI Moon, Jeong-Hyeon/0000-0002-2805-7063; Sohn,
   Kyung-Ah/0000-0001-8941-1188
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2022R1A2C1007434]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2021-20180-01431]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2022R1A2C1007434), and also by the MSIT (Ministry of Science and
   ICT), Korea, under the ITRC (Information Technology Research Center)
   support program (IITP-2021-20180-01431).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Brown A, 2018, PROCEEDINGS OF THE 1ST WORKSHOP ON MACHINE LEARNING FOR COMPUTING SYSTEMS (MLCS 2018), DOI 10.1145/3217871.3217872
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chollet F, 2015, KERAS
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Peng L, 2021, MULTIMEDIA SYST, V27, P363, DOI 10.1007/s00530-020-00697-y
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ryan D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P230, DOI 10.1109/AVSS.2011.6027327
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang T, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P13, DOI 10.1109/AVSS.2012.39
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhou JT, 2020, IEEE T CIRC SYST VID, V30, P4639, DOI 10.1109/TCSVT.2019.2962229
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhou YR, 2020, INFORM SCIENCES, V513, P372, DOI 10.1016/j.ins.2019.10.071
NR 40
TC 1
Z9 1
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12099
EP 12116
DI 10.1007/s11042-022-13643-z
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000002
DA 2024-07-18
ER

PT J
AU Oussama, A
   Khaldi, B
   Kherfi, ML
AF Oussama, Aiadi
   Khaldi, Belal
   Kherfi, Mohammed Lamine
TI A fast weighted multi-view Bayesian learning scheme with deep learning
   for text-based image retrieval from unlabeled galleries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-based image retrieval; Bayesian learning; Deep features; naive
   Bayes classifier; Unlabeled image galleries
ID MODEL
AB In this paper, we propose a new computationally fast method for text-based image retrieval from unlabeled galleries, where retrieval is formulated as a multi-class learning problem. While most existing methods assign images representing the same concept with equal importance during learning, we propose a weighted multi-view likelihood term to deal with the intra-class variations within training set of each concept. At first, we cluster each training set to detect the concept's visual appearances (views). Because number of clusters may significantly vary from one set to another, abusively unifying such a hyper-parameter over all the sets could degrade the learning outcomes. We, therefore, propose to automatically and precisely accomplish this task using Davies-Bouldin index. Noting that images are represented using deep features, which are normalized using vanilla-L-2 rule to deal with bursty visual features. The proposed multi-view term is constructed by combining multivariate normal probability density functions related to the resulting clusters. This term is then incorporated within a naive Bayes classifier alongside with the prior probability of the concept, where each component is weighted using Expectation-Maximization (EM) algorithm. Given a textual query, relevant images are the ones that reach the maximum scores of posterior probability, which is calculated using our Bayesian learning scheme. Experimental results on public datasets demonstrate the effectiveness and rapidity of the proposed method compared to several other methods.
C1 [Oussama, Aiadi; Khaldi, Belal] Univ Kasdi Merbah, Dept Comp Sci, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
   [Kherfi, Mohammed Lamine] LAb Rech Math & Informat Appl LAMIA, 3351 Blvd Forges,CP 500, Trois Rivieres, PQ G9A 5H7, Canada.
C3 Universite Kasdi Merbah Ouargla
RP Oussama, A (corresponding author), Univ Kasdi Merbah, Dept Comp Sci, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM aiadi.oussama@univ-ouargla.dz; khaldi.belal@univ-ouargla.dz;
   Kherfi.Lamine@univ-ouargla.dz
OI aiadi, oussama/0000-0002-4102-1735; khaldi, belal/0000-0002-4905-5139
CR Aggarwal AK, 2015, INT J ELECT COMMUN E, V6
   Aiadi O, 2016, 2 INT C PATTERN ANAL, P218
   Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   [Anonymous], 1999, 1 INT WORKSH MULT IN
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Bello-Cerezo R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040738
   Cai X, 2013, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2013.104
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P2746, DOI 10.1109/TIP.2015.2428055
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen W., 2021, ARXIV
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Cusano C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061410
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Khaldi B, 2020, MULTIMED TOOLS APPL, V79, P8267, DOI 10.1007/s11042-019-08350-1
   Khaldi B, 2019, IET IMAGE PROCESS, V13, P1401, DOI 10.1049/iet-ipr.2018.6440
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Li HJ, 2021, IEEE ACCESS, V9, P135742, DOI 10.1109/ACCESS.2021.3117349
   Li ZX, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3426974
   Liu M, 2015, AAAI CONF ARTIF INTE, P2778
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Moran S, 2014, P INT C MULTIMEDIA R
   Nair LR, 2021, J AMB INTEL HUM COMP, V12, P5917, DOI 10.1007/s12652-020-02139-z
   Rao SSP, 2014, CELL, V159, P1665, DOI 10.1016/j.cell.2014.11.021
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Salih FAA., 2021, UHD J SCI TECHNOL, V5, P28, DOI [10.21928/uhdjst.v5n1y2021.pp28-40, DOI 10.21928/UHDJST.V5N1Y2021.PP28-40]
   Salih SF., 2021, UHD J SCI TECHNOL, V5, P1, DOI [10.21928/uhdjst.v5n1y2021.pp1-12, DOI 10.21928/UHDJST.V5N1Y2021.PP1-12]
   Song HY, 2020, IEEE ACCESS, V8, P76411, DOI 10.1109/ACCESS.2020.2989200
   Srivastava D, 2020, NEURAL COMPUT APPL, V32, P10819, DOI 10.1007/s00521-018-3611-1
   Sun FM, 2014, IEEE T IMAGE PROCESS, V23, P1028, DOI 10.1109/TIP.2014.2298978
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang W., 2021, P IEEE CVF INT C COM
   Xue Z, 2018, INFORM SCIENCES, V451, P180, DOI 10.1016/j.ins.2018.03.051
   Xue Z, 2016, AAAI CONF ARTIF INTE, P1366
   Youcefa A., 2019, Telkomnika, V17, P2572
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 44
TC 5
Z9 5
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10795
EP 10812
DI 10.1007/s11042-022-13788-x
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854848100004
DA 2024-07-18
ER

PT J
AU Azhar, M
   Ullah, S
   Raees, M
   Rahman, KU
   Rehman, IU
AF Azhar, Muhammad
   Ullah, Sehat
   Raees, Muhammad
   Rahman, Khaliq Ur
   Rehman, Inam Ur
TI A real-time multi view gait-based automatic gender classification system
   using kinect sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender classification; Gait recognition; Binary logistic regression
ID IMAGE RETRIEVAL APPROACH; RECOGNITION; MOTION; FEATURES; WALKING;
   FUSION; STYLE
AB Gender classification plays an important role in many applications such as security and medical applications. Human gender can be classified using different biometric techniques such as face recognition, voice recognition, activity recognition and gait recognition. Different approaches based on gait-recognition have been proposed for the identification of gender. However, performance and accuracy of such systems suffer from the recurring and inherent issues like occlusion of body parts, computational costs and false recognition of 3D joints. The problems can be subdued with deep feature-based analysis and extensive calculation but that may further degrade performance of the system. In this paper, we propose a limited feature-based, Three Dimensional (3D), real time, and multi-view gait-based automatic gender classification system using Microsoft kinect (MS Kinect). A statistical model is molded from the binary logistic regression of the gait data extracted at run time using the sensor. The proposed method is successfully implemented and evaluated by 80 (50 male and 30 female) users. The achieved accuracy rate (97.50%) proves applicability of the model.
C1 [Azhar, Muhammad; Ullah, Sehat; Raees, Muhammad; Rehman, Inam Ur] Univ Malakand, Dept Comp Sci & IT, Chakdara, Pakistan.
   [Rahman, Khaliq Ur] Abdul Wali Khan Univ, Dept Stat, Mardan, Pakistan.
C3 University of Malakand; Abdul Wali Khan University
RP Azhar, M (corresponding author), Univ Malakand, Dept Comp Sci & IT, Chakdara, Pakistan.
EM azharitteacher@gmail.com
RI Rehman, Inam Ur/Q-3254-2019; ullah, sehat/HTT-4581-2023
OI Rehman, Inam Ur/0000-0001-6625-6680; ullah, sehat/0000-0002-1193-9350
CR Abouelenien M, 2017, P 19 ACM INT C MULT, P302, DOI DOI 10.1145/3136755.3136770
   Ahmed F, 2015, KINECT BASED GAIT RE
   Ahmed MS, 2017, PROC ADAPT LEARN OPT, V8, P1, DOI 10.1007/978-3-319-49049-6_1
   Ahmed M, 2014, PROC SPIE, V9139, DOI 10.1117/12.2052588
   Alharbi A, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927703005
   [Anonymous], 2008, P 16 ACM INT C MULT, DOI [DOI 10.1145/1459359.1459470, DOI 10.1145/1459359.1459470.11.P]
   [Anonymous], 2012, INT J SCI RES
   Ball A, 2012, ACMIEEE INT CONF HUM, P225
   Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241
   BenAbdelkader C, 2001, LECT NOTES COMPUT SC, V2091, P284
   BenAkdelkader C., 2002, Motion-based recognition of people in EigenGait space, P155
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Burkhardt F, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1562
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Chen X, 2021, IEEE T IMAGE PROCESS, V30, P3041, DOI 10.1109/TIP.2021.3055936
   Chen Y, 2014, GAIT BASED GENDER CL
   Collins Matthew, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1235, DOI 10.1109/ICCVW.2009.5457467
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Davis JW, 2001, LECT NOTES COMPUT SC, V2091, P295
   De Marsico M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3340293
   Deligianni F, 2019, IEEE J BIOMED HEALTH, V23, P2302, DOI 10.1109/JBHI.2019.2938111
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dou H. Z., 2021, ARXIV
   Duong D, 2016, INT CONF KNOWL SYS, P91, DOI 10.1109/KSE.2016.7758035
   Echterhoff JM, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P88, DOI 10.1145/3267242.3267267
   Etemad SA, 2016, IEEE T HUM-MACH SYST, V46, P534, DOI 10.1109/THMS.2016.2537760
   Etemad SA, 2015, VISUAL COMPUT, V31, P1569, DOI 10.1007/s00371-014-1034-2
   Etemad SA, 2014, NEUROCOMPUTING, V129, P585, DOI 10.1016/j.neucom.2013.09.001
   Farooq A, 2015, KSII T INTERNET INF, V9, P1856, DOI 10.3837/tiis.2015.05.017
   Gianaria E, 2019, MULTIMED TOOLS APPL, V78, P13925, DOI 10.1007/s11042-018-6865-9
   Guo GD, 2010, LECT NOTES COMPUT SC, V5996, P236
   Gupta SK, 2021, MULTIMED TOOLS APPL, V80, P36033, DOI 10.1007/s11042-021-10941-w
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Jalal A, 2015, 2015 IEEE 29TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS WAINA 2015, P445, DOI 10.1109/WAINA.2015.38
   Jarchi Delaram, 2018, IEEE Rev Biomed Eng, V11, P177, DOI 10.1109/RBME.2018.2807182
   Jhapate AK., 2011, INT J COMPUT SCI TEC, V2, P128
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Kumar R, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P102, DOI 10.1109/ICACC.2013.26
   Li RX, 2020, MULTIMED TOOLS APPL, V79, P31069, DOI 10.1007/s11042-020-09150-8
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Lin F, 2016, INT J BIOMETRICS, V8, P275
   Lishani AO, 2019, MULTIMED TOOLS APPL, V78, P5715, DOI 10.1007/s11042-018-5752-8
   Liu LF, 2009, LECT NOTES ARTIF INT, V5755, P652
   Meinedo H, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2822
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Murray M P, 1967, Am J Phys Med, V46, P290
   Nambiar A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3243043
   Nixon, 2002, INFORM SECURITY TECH, V7, P23, DOI [10.1016/S1363-4127(02)00404-1, DOI 10.1016/S1363-4127(02)00404-1]
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Perry J., 1992, Journal of Pediatric Orthopaedics, V12, P815, DOI DOI 10.1097/01241398-199211000-00023
   Preis J., 2012, 1st international workshop on kinect in pervasive computing, P1
   Rao P.S., 2019, P INT C INN BIOINSP, P57
   Rida I, 2019, IET BIOMETRICS, V8, P14, DOI 10.1049/iet-bmt.2018.5063
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Seneviratne S, 2014, MOB COMPUT COMMUN RE, V18, P55, DOI 10.1145/2721896.2721908
   Sepas-Moghaddam Alireza, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P124, DOI 10.1109/TBIOM.2020.3031470
   Sepas-Moghaddam A, 2021, COMPUTER VISION PATT, P1
   Sepas-Moghaddam A, 2021, INT C PATT RECOG, P8045, DOI 10.1109/ICPR48806.2021.9412517
   Sepas-Moghaddam A, 2020, IET BIOMETRICS, V9, P58, DOI 10.1049/iet-bmt.2019.0001
   Singh J. P., 2010, 2nd International Conference on Trendz in Information Sciences & Computing (TISC 2010), P248, DOI 10.1109/TISC.2010.5714649
   Topaloglu M, 2017, EXPERT SYST APPL, V79, P236, DOI 10.1016/j.eswa.2017.03.001
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Verlekar TT, 2018, IEEE INT C BIOINFORM, P2376, DOI 10.1109/BIBM.2018.8621302
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang N, 2010, PROCEEDINGS OF THE 2ND (2010) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P320
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Winter D. A., 2009, Biomechanics and motor control of human movement, DOI 10.1002/9780470549148
   Wu Q, 2014, SCI WORLD J, DOI 10.1155/2014/513240
   XU C, 2021, P IEEE WINT C APPL C, P3460, DOI DOI 10.1109/WACV48630.2021.00350
   You QZ, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1026, DOI 10.1109/ICDMW.2014.93
   Zhang HH, 2020, IEEE T NEUR SYS REH, V28, P191, DOI 10.1109/TNSRE.2019.2958679
   Zhang J, 2016, IEEE DATA MINING, P649, DOI [10.1109/ICDM.2016.19, 10.1109/ICDM.2016.0076]
NR 83
TC 6
Z9 6
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11993
EP 12016
DI 10.1007/s11042-022-13704-3
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854429700010
DA 2024-07-18
ER

PT J
AU Bedoui, M
   Bouallegue, B
   Mestiri, H
   Hamdi, B
   Machhout, M
AF Bedoui, Mouna
   Bouallegue, Belgacem
   Mestiri, Hassen
   Hamdi, Belgacem
   Machhout, Mohsen
TI An improvement of both security and reliability for elliptic curve
   scalar multiplication Montgomery algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography (ECC); Montgomery ladder; Fault detection
   method; Fault injection attack
ID CONCURRENT ERROR-DETECTION; IMPLEMENTATION; ARCHITECTURE; ECC
AB Elliptic curve cryptosystems (ECC) are well suited to devices with limited memory and processing capabilities, such as smart cards, as well as devices with limited power, such as wireless handheld devices. This is because, for considerably smaller key sizes, elliptic curves over huge finite fields provide the same level of security as other cryptosystems like RSAECC-based circuits are vulnerable to physical attacks aimed at getting the secret key, despite its security. Fault injection attacks are a sort of physical attack that involves inserting a fault into a circuit during a cryptographic operation to alter its behavior. In this regard, we introduce a new fault detection approach based on time redundancy for the Montgomery Elliptic Curve Scalar Multiplication algorithm. We divided the ECC design into three blocks with registers placed between them. When compared to the original Montgomery ECSM algorithm, our solution takes roughly 11.65% more occupied slices overhead but yields a frequency gain of 51.27%.
C1 [Bedoui, Mouna; Bouallegue, Belgacem; Mestiri, Hassen; Hamdi, Belgacem; Machhout, Mohsen] Univ Monastir, Elect & Microelect Lab EuEL, Fac Sci Monastir, Monastir, Tunisia.
   [Bouallegue, Belgacem] King Khalid Univ, Coll Comp Sci, Dept Comp Engn, Abha, Saudi Arabia.
   [Mestiri, Hassen] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Engn, Al Kharj 11942, Saudi Arabia.
   [Mestiri, Hassen; Hamdi, Belgacem] Univ Sousse, Higher Inst Appl Sci & Technol Sousse, Sousse, Tunisia.
C3 Universite de Monastir; King Khalid University; Prince Sattam Bin
   Abdulaziz University; Universite de Sousse
RP Bedoui, M (corresponding author), Univ Monastir, Elect & Microelect Lab EuEL, Fac Sci Monastir, Monastir, Tunisia.
EM mouna.bedou11991@gmail.com; bbelgacem@kku.edu.sa; h.mestiri@psau.edu.sa;
   belgacem.hamdi@gmail.com; machhout@yahoo.fr
RI Mestiri, Hassen/GQQ-1465-2022; boulage, belgacem/AGY-7606-2022
OI Mestiri, Hassen/0000-0001-7226-3975; Bedoui, Mouna/0000-0002-2592-8388;
   Mohsen, Machhout/0000-0002-5629-0508
FU Deanship of Scientific Research at King Khalid University [RGP.2/208/43]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Khalid University for funding this work through
   research groups program under grant number RGP.2/208/43.
CR [Anonymous], 2011, J COMPUT
   Bedoui M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON DESIGN & TEST OF INTEGRATED MICRO & NANO-SYSTEMS (DTS), DOI 10.1109/dtss.2019.8914743
   Biehl I, 2000, LECT NOTES COMPUT SC, V1880, P131
   Chiou CW, 2006, IEICE T FUND ELECTR, VE89A, P566, DOI 10.1093/ietfec/e89-a.2.566
   Ciet M, 2005, DESIGN CODE CRYPTOGR, V36, P33, DOI 10.1007/s10623-003-1160-8
   Dominguez-Oviedo A, 2008, THESIS U WATERLOO
   Domínguez-Oviedo A, 2009, IEEE T DEPEND SECURE, V6, P175, DOI 10.1109/TDSC.2008.21
   Fournaris Apostolos P., 2016, 2016 International Conference on Design and Technology of Integrated Systems in Nanoscale Era (DTIS), P1, DOI 10.1109/DTIS.2016.7483807
   Hariri A, 2011, IEEE T COMPUT, V60, P1341, DOI 10.1109/TC.2010.258
   Karaklajic D, 2011, DES AUT TEST EUROPE, P1016
   Khan ZUA, 2015, I C FIELD PROG LOGIC
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Liu S, 2014, IEEE INT CONF TRUST, P148, DOI 10.1109/TrustCom.2014.23
   Ma K, 2014, IEEE T COMPUT AID D, V33, P627, DOI 10.1109/TCAD.2013.2293058
   Mahdizadeh H, 2013, IEEE T VLSI SYST, V21, P2330, DOI 10.1109/TVLSI.2012.2230410
   Marzouqi H, 2014, IEEE I C ELECT CIRC, P307, DOI 10.1109/ICECS.2014.7049983
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   PATEL JH, 1982, IEEE T COMPUT, V31, P589, DOI 10.1109/TC.1982.1676055
   PATEL JH, 1983, IEEE T COMPUT, V32, P417, DOI 10.1109/TC.1983.1676246
   Rashidi B, 2016, MICROELECTRON J, V52, P49, DOI 10.1016/j.mejo.2016.03.006
   Rodríguez-Henríquez F, 2004, MICROPROCESS MICROSY, V28, P329, DOI 10.1016/j.micpro.2004.03.003
   Saffar Z, 2019, ECC 2019 16 TH INT I, P104
   Saudy NF, 2019, AIN SHAMS ENG J, V10, P587, DOI 10.1016/j.asej.2018.11.007
NR 23
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11973
EP 11992
DI 10.1007/s11042-022-13749-4
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854695000007
DA 2024-07-18
ER

PT J
AU Fezai, L
   Urruty, T
   Bourdon, P
   Fernandez-Maloigne, C
AF Fezai, Lobna
   Urruty, Thierry
   Bourdon, Pascal
   Fernandez-Maloigne, Chrsitine
CA Alzheimer's Dis Neuroimaging Initi
TI Deep anonymization of medical imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anonymisation; Data privacy; MRI equipment identification; Deep
   learning; Convolutional neural networks; Classification; Auto-encoder
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Deep learning has shown record-shattering performance in multiple medical tasks. However, data quantity and quality are crucial requirements. As a matter of fact, data is one of the most challenging issues while deploying deep learning models for different tasks. One of the main challenges is the institutions' privacy protocols, in particular in the medical field. Indeed, the metadata is usually excluded from the database provided. Many invisible features in images can help tracing anonymized data. We propose to use deep learning to exclude these traces. This article focuses on Magnetic resonance imaging (MRI) and one of the most important features, the equipment used for acquisition. First, we aim to produce an algorithm able to perform well distinguishing multiple MRI equipment from different brands. To this end, we employ a convolution neural network architecture to work on this medical image classification task. The second part of this paper is dedicated to reconstructing the input MRI using a simple auto-encoder. The latter step is to use the auto-encoder in order to mislead the classifier classifying the MRI equipment.
C1 [Fezai, Lobna; Urruty, Thierry; Bourdon, Pascal; Fernandez-Maloigne, Chrsitine] Univ Poitiers, XLIM Res Inst, UMR CNRS 7252, Poitiers, France.
   [Fezai, Lobna; Urruty, Thierry; Bourdon, Pascal; Fernandez-Maloigne, Chrsitine] Siemens Univ, I3M, Common Lab, CNRS, Poitiers, France.
   [Fezai, Lobna; Urruty, Thierry; Bourdon, Pascal; Fernandez-Maloigne, Chrsitine] Hosp Poitiers, Poitiers, France.
C3 Universite de Poitiers; Universite de Poitiers; Centre National de la
   Recherche Scientifique (CNRS); Universite de Poitiers
RP Fezai, L (corresponding author), Univ Poitiers, XLIM Res Inst, UMR CNRS 7252, Poitiers, France.; Fezai, L (corresponding author), Siemens Univ, I3M, Common Lab, CNRS, Poitiers, France.; Fezai, L (corresponding author), Hosp Poitiers, Poitiers, France.
EM lobna.fezai@univ-poitiers.fr
OI Urruty, Thierry/0000-0003-1339-1920; FEZAI, Lobna/0000-0002-5387-7100
FU University of Poitiers doctoral scholarship
FX This study was funded by the University of Poitiers doctoral
   scholarship.
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bernau D, 2019, ARXIV
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Doersch Carl, 2016, ARXIV160605908
   Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gillies CE, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103528
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Hamidian S, 2017, PROC SPIE, V10134, DOI 10.1117/12.2255795
   Howard JP, 2019, JACC-CLIN ELECTROPHY, V5, P579, DOI 10.1016/j.jacep.2019.02.003
   Jafari H, 2018, IEEE MILIT COMMUN C, P913
   Jeong YU, 2020, J MED INTERNET RES, V22, DOI 10.2196/22739
   Jordon J, 2020, HIDE AND SEEK PRIVAC
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Kim T, 2019, IEEE ACCESS, V7, P84992, DOI 10.1109/ACCESS.2019.2924479
   Kotak J., 2021, 13 INT C COMP INT SE, P76
   Kuppa Aditya, 2021, Privacy Technologies and Policy. 9th Annual Privacy Forum, APF 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12703), P106, DOI 10.1007/978-3-030-76663-4_6
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P824, DOI 10.1145/3394486.3403125
   Livraga G, 1 REPORT PRIVACY MET
   Lu XG, 2013, INTERSPEECH, P436
   Makhzani A, 2013, ARXIV
   Makhzani A., 2015, ARXIV
   Merchant K, 2018, IEEE J-STSP, V12, P160, DOI 10.1109/JSTSP.2018.2796446
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Riyaz S, 2018, IEEE COMMUN MAG, V56, P146, DOI 10.1109/MCOM.2018.1800153
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ryu J., 2021, arXiv
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Vieira S, 2017, NEUROSCI BIOBEHAV R, V74, P58, DOI 10.1016/j.neubiorev.2017.01.002
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wu QY, 2018, ELECTRON LETT, V54, P1405, DOI 10.1049/el.2018.6404
   Xie L., 2018, DIFFERENTIALLY PRIVA
   Xu R, 2020, THESIS U PITTSBURGH
   Yoon J, 2020, IEEE J BIOMED HEALTH, V24, P2378, DOI 10.1109/JBHI.2020.2980262
   Yu Da, 2021, ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 43
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9533
EP 9547
DI 10.1007/s11042-022-13686-2
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854695000004
DA 2024-07-18
ER

PT J
AU Nasreen, G
   Haneef, K
   Tamoor, M
   Irshad, A
AF Nasreen, Ghazala
   Haneef, Kashif
   Tamoor, Maria
   Irshad, Azeem
TI Review: a comparative study of state-of-the-art skin image segmentation
   techniques with CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Dermatoscope; Image segmentation; Skin cancer; CNN; ISIC
ID CLASSIFICATION; CANCER
AB Skin cancer is caused by genetic uncertainty or an irregular growth of cells, mostly grows when our skin is exposed to sun. In people, melanoma is a common type of cancer irrespective of their age, gender or race. Skin cancer has mainly two types: malignant melanoma and non-melanoma. Now days, the leading cancer type in people is melanoma among many white-skinned populations, while non-melanoma skin cancer is common in light-skinned population. The melanoma can transfer to different body parts if it is left untreated. The computerized system is needed for melanoma cancer risk evaluation, as the dermatologist monitors the condition of the patient by using skin cancer images and dermatoscope. Its identification in advance, needs the proper identification of spots on skin which is based on some features, which are extracted. Different segmentation methods play very important role in skin lesion detection from images, in which segmentation performs the image classification, into the pixels of skin and non- skin based upon the texture of skin. The convolutional neural networks (CNNs) have presented better outcomes in the skin cancer classification as compared to the findings of dermatologists. This model will help people to get help from their installed applications on mobile phone or electronic devices, for the early diagnosis of cancer. In this review study, various research papers have been presented on the skin lesions classification based on CNNs. We have discussed how CNNs have a great impact in successful skin cancer classification and methods which are implemented with success rates. Deep learning using CNN also has many advantages and, there is some vulnerability as well in misclassifying the images, under some situations. In this paper we searched IEEE, Science Direct, Google Scholar, Elsevier, PubMed and Web of Science databases to obtain original published research articles and selected papers providing necessary information related to the research and finally we have produced a systematic review on published methodologies, datasets, algorithms, results, accuracy, sensitivity etc. using CNN model.
C1 [Nasreen, Ghazala; Haneef, Kashif] Govt Coll Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Tamoor, Maria] Forman Christian Coll Univ, Dept Comp Sci, Lahore, Pakistan.
   [Irshad, Azeem] Islamic Int Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 Government College University Faisalabad
RP Nasreen, G (corresponding author), Govt Coll Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM miscathwal@gmail.com
RI Irshad, Azeem/E-7400-2010; Nasreen, Ghazala/JLK-8804-2023
OI Irshad, Azeem/0000-0002-1366-2834; Tamoor, Dr. Maria/0000-0002-3023-6706
CR Abdul R, 2021, CANINTELLIIDS DETECT
   Albahar MA, 2019, IEEE ACCESS, V7, P38306, DOI 10.1109/ACCESS.2019.2906241
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   [Anonymous], TREAT MEL SKIN CANC
   [Anonymous], 2016, THESIS KTH ROY
   Arman H B, 2013, INT J SCI ENG RES, V4
   Barata C, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107413
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bobrowicz M., 2019, STATE ART FUTURE PER, V11
   Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936
   Cerwall P., 2016, Ericssons mobility report
   Damilola A O, 2018, BENTHAM OPEN, V12
   Dandu R, 2021, BIOMED ENG-APP BAS C, V33, DOI 10.4015/S1016237220500453
   Di Leo G, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P190, DOI 10.1109/VECIMS.2008.4592778
   Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fanizzi A, 2021, CANCERS, V13, DOI 10.3390/cancers13020352
   Florkowski Christopher M, 2008, Clin Biochem Rev, V29 Suppl 1, pS83
   FOGEL DB, 1991, IEEE T NEURAL NETWOR, V2, P490, DOI 10.1109/72.134286
   Fontanillas P, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20246-5
   Francesco F., 2021, INTRAREGIONAL CANC I, V13, P1383
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Fujisawa Y, 2019, BRIT J DERMATOL, V180, P373, DOI 10.1111/bjd.16924
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Girija R., 2014, INT J COMPUT APPL, V97, P0975
   Goodfellow I. J., 2014, ARXIV
   Goyal M, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104065
   Gutman D, ARXIV
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   Haider S., 2011, COMPUTER ENG INTELLI, V2, P96
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Harpur D., 2020, J INVEST DERMATOL
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoerter JD, 2012, STEM CELLS INT, V2012, DOI 10.1155/2012/407079
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Iqbal I, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101843
   Joanna J K, ASSESSMENT DOTS GLOB
   Kaganami Hassana Grema, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1217, DOI 10.1109/IIH-MSP.2009.13
   Katherine M L, 2018, SKIN LESION ANAL MEL
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Kazemi Farhad Mohamad, 2008, 2008 Canadian Conference on Electrical and Computer Engineering - CCECE, P001855, DOI 10.1109/CCECE.2008.4564866
   Keun K L, 2018, SKIN CANC CLASSIFICA
   Khan1 RafiqulZaman., 2012, International Journal of Computer and Information Science, V5, P110, DOI [10.5539/cis.v5n3p110, DOI 10.5539/CIS.V5N3P110]
   Kiran R, 2011, IEEE J TRANSL ENG HE, DOI [10.1109/jtehm.2015.2419612, DOI 10.1109/JTEHM.2015.2419612]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurrant D, 2021, J IMAGING, V7, DOI 10.3390/jimaging7010005
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Mahbod E, 2017, ARXIV
   Manne R., 2020, Int J Modern Trends Sci Technol, P2455, DOI [10.46501/IJMTST061118, DOI 10.46501/IJMTST061118]
   Margarida S, 2009, COMP SEGMENTATION ME, V3
   Marta C D, 2021, FRONT MED
   Mesut T., 2018, CHAOS SOLITON FRACT, V144
   Musarrat Y., 2013, WORLD APPL SCI J, V22, P85
   Naseer A, 2022, J X-RAY SCI TECHNOL, V30, P89, DOI 10.3233/XST-211047
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Navarrete-Dechent C, 2018, J INVEST DERMATOL, V138, P2277, DOI 10.1016/j.jid.2018.04.040
   Phillips M, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.13436
   Pomponiu V, 2016, IEEE IMAGE PROC, P2623, DOI 10.1109/ICIP.2016.7532834
   Poornima SD., 2020, CHSN 2020 IOP C SERI, V1074, DOI 10.1088/1757-899X/1074/1/012025
   Pumshothaman S., 2008, International Journal of Image Processing, V2, P1
   Qintao X, 2020, FACIAL EXPRESSION RE, DOI [10.1109/ITNEC48623.2020.9084763, DOI 10.1109/ITNEC48623.2020.9084763]
   R D Seeja, 2019, Asian Pac J Cancer Prev, V20, P1555
   Raja S, 2011, 11 INT C
   Rashi G, 2015, INT J COMPUT APPL, V112
   Rey-Barroso L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010252
   Rezvantalab A., 2018, arXiv
   Roman C., 2021, EUR J CANCER, V145, P81
   Sander J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77733-4
   Shi WY, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-20-2464
   Shikha R D, 2020, IJRTCC, V2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Subbarayan K., 1996, 30 ASILOMAR C SIGNAL, V2, P1171
   Szegedy C, 2014, INT C LEARN REPR
   Tamoor M, 2021, J XRAY SCI TECHNOL P, P1
   Thompson F, 2017, IJAER, V1758-64
   Titus J B, 2018, J MED INTERNET RES, V20
   Tschandl R, 2018, HAM10000 DATASET LAR
   Vargas R., 2017, DEEP LEARNING: A REVIEW, DOI [DOI 10.20944, 10.20944/preprints201810.0218.v1]
   Viloria Amelec, 2021, Proceedings of International Conference on Intelligent Computing, Information and Control Systems. (ICICCS 2020). Advances in Intelligent Systems and Computing (AISC 1272), P705, DOI 10.1007/978-981-15-8443-5_60
   Winkler JK, 2019, JAMA DERMATOL, V155, P1135, DOI 10.1001/jamadermatol.2019.1735
   Yu H W, TUTORIAL IMAGE SEGME
   Yu Z, 2017, I S BIOMED IMAGING, P301, DOI 10.1109/ISBI.2017.7950524
NR 82
TC 7
Z9 7
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10921
EP 10942
DI 10.1007/s11042-022-13756-5
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852346600002
DA 2024-07-18
ER

PT J
AU Saim, H
   Yassin, SNM
   Salim, MIM
   Jemon, K
   AlAshwal, RH
   Wahab, AA
   Sahalan, M
   Chai, HY
   Wee, LK
AF Saim, Hanim
   Yassin, Siti N. M.
   Salim, Maheza I. M.
   Jemon, Khairunadwa
   AlAshwal, Rania H.
   Wahab, Asnida A.
   Sahalan, Mariaulpa
   Chai, Hum Yan
   Wee, Lai K.
TI Antitumor effect of infrared whole-body hyperthermia with curcumin in
   breast Cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Curcumin; Infrared whole body hyperthermia
ID TUMOR-INFILTRATING LYMPHOCYTES; GROWTH IN-VITRO; RADIATION-THERAPY;
   PROGNOSTIC VALUE; CELLS; COMBINATION; APOPTOSIS; SURVIVAL; TRIAL; RATIO
AB Infrared Hyperthermia therapy (IHT) is a non-contacting method to elevate body temperature and treat malignant lesions such as breast cancer. Breast cancer is one of the major cancer types among females and over the years, its prevalence is increasing. Current treatments of breast cancer are surgery, radiotherapy, chemotherapy and thermotherapy via the use of IHT or combination of these. IHT is most commonly combined with chemotherapy as its effect as a stand alone treatment platform is short lasting. However, chemotherapy induced toxicity to patients. Curcumin has traditionally been used as a food additive or as a remedy in traditional medicine for its anticancer and non-toxic effects. Thus, this research proposed the combination of curcumin and IHT as an alternative to chemotherapy in breast cancer treatment. Mice were inoculated with EMT6 breast cancer cells and assigned to 4 treatment groups: (i) untreated (control), (ii) orally curcumin (CUR), (iii) whole-body hyperthermia (FRWBH), (iv) orally curcumin with whole-body hyperthermia (FRWBH+CUR). Results showed that tumor growth inhibition and body weight gain in the combination treatment group (FRWBH+CUR) are significantly different compared to control. The group also had the longest median survival time (42 days) with no mortality observed during the experiment. This result indicates that the combination treatment is well tolerated by the mice and has negligible levels of toxicity. However, frequent complications of cancer such as anaemia and thrombocytopenia are still observed in the combination treatment group. Platelet to Lymphocyte Ratio (PLR) and Neutrophils to Lymphocytes Ratio (NLR) results indicate that the combination treatment (FRWBH+CUR) has better prognosis outcome than single treatment and may become a potential alternative antitumor treatment of breast cancer.
C1 [Saim, Hanim; Yassin, Siti N. M.; Salim, Maheza I. M.; AlAshwal, Rania H.; Wahab, Asnida A.; Sahalan, Mariaulpa] Univ Teknol Malaysia, Fac Engn, Sch Biomed Engn & Hlth Sci, EngineeringDiagnost Res Grp, Johor Baharu 81310, Johor, Malaysia.
   [Jemon, Khairunadwa] Univ Teknol Malaysia, Fac Sci, Johor Baharu 81310, Johor, Malaysia.
   [Chai, Hum Yan] Univ Tun Abd Rahman, Lee Kong Chian Fac Engn & Sci, Cheras, Selangor, Malaysia.
   [Wee, Lai K.] Univ Malaya, Fac Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; Universiti
   Malaya
RP Yassin, SNM (corresponding author), Univ Teknol Malaysia, Fac Engn, Sch Biomed Engn & Hlth Sci, EngineeringDiagnost Res Grp, Johor Baharu 81310, Johor, Malaysia.
EM sitinorhayati.my@gmail.com
RI SALIM, MAHEZA IRNA MOHAMAD/N-2407-2013; Jemon, Khairunadwa/N-2401-2013;
   Lai, Khin Wee/A-2997-2011
OI Lai, Khin Wee/0000-0002-8602-0533
FU  [15H87];  [15J83];  [04G47]
FX This work was supported by Research University Grant 15H87 and 15J83 and
   High Impact Research Grant 04G47.
CR Abd Wahab NA, 2020, NUTRIENTS, V12, DOI 10.3390/nu12030679
   Annapurna A., 2011, Journal of Pharmacy Research, V4, P1274
   Asea A, 2001, INT J HYPERTHER, V17, P347, DOI 10.1080/02656730110053146
   Azab B, 2013, MED ONCOL, V30, DOI 10.1007/s12032-012-0432-4
   Azizah AM., 2016, NATL CANC I, V16, P203
   Bachmeier BE, 2007, CELL PHYSIOL BIOCHEM, V19, P137, DOI 10.1159/000099202
   Baronzio G., 2014, J INTEGR ONCOL, V3, P1, DOI DOI 10.4172/2329-6771.1000115
   Bayet-Robert M, 2010, CANCER BIOL THER, V9, P8, DOI 10.4161/cbt.9.1.10392
   Behrouzkia Zhaleh, 2016, Oman Med J, V31, P89, DOI 10.5001/omj.2016.19
   Bettaieb A., 2013, CANC TREATMENT CONVE, P257, DOI [DOI 10.5772/45937, DOI 10.5772/55795]
   Bimonte S, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/878134
   Birgegård G, 2005, ONCOLOGY-BASEL, V68, P3, DOI 10.1159/000083128
   Bull JMC, 2008, INT J HYPERTHER, V24, P649, DOI 10.1080/02656730802104740
   Busti F, 2018, PHARMACEUTICALS-BASE, V11, DOI 10.3390/ph11040094
   Carlson RW, 2009, J NATL COMPR CANC NE, V7, P122, DOI 10.6004/jnccn.2009.0012
   Castaman G, 2018, THROMB RES, V164, pS89, DOI 10.1016/j.thromres.2018.02.001
   Chen J, 2015, FEBS OPEN BIO, V5, P502, DOI 10.1016/j.fob.2015.05.003
   Conn JR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178059
   Decensi A, 2000, EUR J CANCER, V36, P694, DOI 10.1016/S0959-8049(00)00040-X
   Dutta S, 2016, LIFE SCI, V152, P244, DOI 10.1016/j.lfs.2015.10.025
   Falah RR, 2017, THER ADV MED ONCOL, V9, P235, DOI 10.1177/1758834016687482
   Falk MH, 2001, INT J HYPERTHER, V17, P1, DOI 10.1080/02656730150201552
   Farhangi B, 2015, EUR J PHARMACOL, V758, P188, DOI 10.1016/j.ejphar.2015.03.076
   Ghasemzadeh A, 2010, MOLECULES, V15, P4324, DOI 10.3390/molecules15064324
   Goel A, 2008, BIOCHEM PHARMACOL, V75, P787, DOI 10.1016/j.bcp.2007.08.016
   Gorczynski RM, 2010, BREAST CANCER RES TR, V123, P405, DOI 10.1007/s10549-009-0667-8
   Gu ML, 2016, BREAST CANCER-TOKYO, V23, P752, DOI 10.1007/s12282-015-0635-6
   Harrison L.B., 2000, ONCOLOGIST, V5, P1, DOI 10.1634/THEONCOLOGIST.5-SUPPL_2-1
   Hattori T, 2007, INT J HYPERTHER, V23, P591, DOI 10.1080/02656730701708328
   HERMAN TS, 1988, INT J HYPERTHER, V4, P143, DOI 10.3109/02656738809029305
   Ismail M, 2000, J NUTR BIOCHEM, V11, P536, DOI 10.1016/S0955-2863(00)00108-X
   Jia WJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143061
   Jones EL, 2005, J CLIN ONCOL, V23, P3079, DOI 10.1200/JCO.2005.05.520
   Jothy SL, 2011, MOLECULES, V16, P5268, DOI 10.3390/molecules16065268
   Kirshner J, 2004, ONCOLOGIST, V9, P25, DOI 10.1634/theoncologist.9-1-25
   Kossatz S, 2015, BREAST CANCER RES, V17, DOI 10.1186/s13058-015-0576-1
   Lai HW, 2012, EVID-BASED COMPL ALT, V2012, DOI 10.1155/2012/486568
   Lal I, 2013, BREAST CANCER RES, V15, DOI 10.1186/bcr3425
   Lee CL, 2017, ONCOTARGET, V8, P1569, DOI 10.18632/oncotarget.13679
   Lee H, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0087979, 10.1371/journal.pone.0095530]
   Liebman HA, 2014, THROMB RES, V133, pS63, DOI 10.1016/S0049-3848(14)50011-4
   Lissoni P, 2000, INT J BIOL MARKER, V15, P22, DOI 10.1177/172460080001500104
   Lv ZD, 2014, INT J CLIN EXP PATHO, V7, P2818
   Maheshwari RK, 2006, LIFE SCI, V78, P2081, DOI 10.1016/j.lfs.2005.12.007
   Maluta S, 2015, BREAST CARE, V10, P408, DOI 10.1159/000440792
   Manikandan R, 2012, MICROSC RES TECHNIQ, V75, P112, DOI 10.1002/jemt.21032
   Mantas D, 2016, ONCOL LETT, V12, P1610, DOI 10.3892/ol.2016.4760
   Mariotto Angela B, 2014, J Natl Cancer Inst Monogr, V2014, P145, DOI 10.1093/jncimonographs/lgu024
   Masuelli L, 2013, J BIOL REG HOMEOS AG, V27, P105
   Matsen, 2006, PET CLIN, V1, P2000
   Mitha S, 2013, J YOUNG PHARM, V5, P50, DOI 10.1016/j.jyp.2013.05.002
   Mullauer FB, 2010, ANTI-CANCER DRUG, V21, P215, DOI 10.1097/CAD.0b013e3283357c62
   Muthana M, 2010, INT J HYPERTHER, V26, P247, DOI 10.3109/02656730903413375
   Nair PKR, 2009, J ETHNOPHARMACOL, V122, P450, DOI 10.1016/j.jep.2009.02.001
   Nguyen N, 2016, HEAD NECK-J SCI SPEC, V38, P1074, DOI 10.1002/hed.24406
   Oh K, 2013, BREAST CANCER RES, V15, DOI 10.1186/bcr3473
   Okuturlar Yildiz, 2015, Asian Pac J Cancer Prev, V16, P2409
   Orditura M, 2016, ESMO OPEN, V1, DOI 10.1136/esmoopen-2016-000038
   Park B, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51832-3
   Pierce BL, 2009, J CLIN ONCOL, V27, P3437, DOI 10.1200/JCO.2008.18.9068
   Pisano ED, 2005, NEW ENGL J MED, V353, P1773, DOI 10.1056/NEJMoa052911
   Rakha EA, 2010, J CLIN ONCOL, V28, P99, DOI 10.1200/JCO.2009.23.5051
   Rana APS, 2015, INT J BREAST CANCER, V2015, DOI 10.1155/2015/964392
   Repasky EA, 2013, CANCER IMMUNOL RES, V1, P210, DOI 10.1158/2326-6066.CIR-13-0118
   ROBINS HI, 1988, CANCER RES, V48, P6587
   Rockwell S, 2012, INT J RADIAT BIOL, V88, P277, DOI 10.3109/09553002.2012.638359
   Rowe RW, 2010, INT J HYPERTHER, V26, P565, DOI 10.3109/02656736.2010.483635
   Shankar A, 2006, ARCH INTERN MED, V166, P188, DOI 10.1001/archinte.166.2.188
   Shen MX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098259
   Shiri Sadaf, 2015, Asian Pac J Cancer Prev, V16, P3917
   Shrivastava S., 2016, INT J RES MED SCI, V5, P311, DOI [10.18203/2320-6012.ijrms20164569, DOI 10.18203/2320-6012.IJRMS20164569]
   Smyth MJ, 2006, ADV IMMUNOL, V90, P1, DOI 10.1016/S0065-2776(06)90001-7
   Somers-Edgar TJ, 2008, INT J CANCER, V122, P1966, DOI 10.1002/ijc.23328
   Sugahara T, 2008, INT J HYPERTHER, V24, P123, DOI 10.1080/02656730701883675
   Talib WH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124384
   TEICHER BA, 1988, CANCER RES, V48, P6291
   TOMAYKO MM, 1989, CANCER CHEMOTH PHARM, V24, P148, DOI 10.1007/BF00300234
   Toyota N, 1998, INT J CANCER, V76, P499
   Ulas A, NEUTROPHIL LYMPHOCYT, V20, P714
   Ulas A, 2015, J BUON, V20, P714
   Uysal, 2018, J RADIOL ONCOL, V1, P79
   Vincze G., 2015, Open Journal of Biophysics, V5, P97, DOI DOI 10.4236/OJBIPHY.2015.54009
   Wei BJ, 2016, ONCOTARGETS THER, V9, P5567, DOI 10.2147/OTT.S108419
   Weigelt B, 2009, NAT REV CLIN ONCOL, V6, P718, DOI 10.1038/nrclinonc.2009.166
   WONDERGEM J, 1991, CANCER RES, V51, P3559
   Wust P, 2002, LANCET ONCOL, V3, P487, DOI 10.1016/S1470-2045(02)00818-5
   Yao MY, 2014, ONCOTARGETS THER, V7, P1743, DOI 10.2147/OTT.S69657
   Yu X, 2016, CLIN TRANSL ONCOL, V18, P497, DOI 10.1007/s12094-015-1391-y
   Zhou HY, 2011, CURR DRUG TARGETS, V12, P332, DOI 10.2174/138945011794815356
   Zhou QM, 2011, ACTA PHARMACOL SIN, V32, P1402, DOI 10.1038/aps.2011.97
   Zhu YY, 2017, ONCOTARGET, V8, P1023, DOI 10.18632/oncotarget.13714
   Zwiener I, 2011, DTSCH ARZTEBL INT, V108, P163, DOI [10.3238/arztebl.2011.0163, 10.3238/arztebl.2010.0163]
NR 92
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41851
EP 41868
DI 10.1007/s11042-022-13521-8
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000850418700001
DA 2024-07-18
ER

PT J
AU Amine, K
   Redouane, K
   Bilel, M
AF Amine, Khaldi
   Redouane, Kafi
   Bilel, Maghni
TI A redundant wavelet based medical image watermarking scheme for secure
   transmission in telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Digital watermarking; Absolute moment block truncation
   coding; Redundant discrete wavelet transform; Rivest cipher 4
ID ROBUST; BLIND; HYBRID
AB Watermarking is a method of protecting multimedia material, especially images, from malicious attacks by embedding a fingerprint. Whenever it comes to sensitive pictures, such as medical images, traditional watermarking methods, on the other hand, show their limitations. Indeed, the additional mark typically alters the picture in an irreversible manner and may conceal small details. In this paper, we propose a watermarking technique for patient identification and watermark integrity proof to solve these concerns. This approach uses a two-part watermark: the first carries the patient's information fingerprint, and the second includes the patient's encrypted photography. The frequency content of the image is extracted using a redundant discrete wavelet transform in this method. The resulting coefficients are then subjected to Schur decomposition, and the watermark bits are integrated by altering the least significant bit of the Eigen values. This method's capacity enables the integration of the patient's picture and fingerprint, as well as the insertion of an error-correcting code. The coefficient manipulation of the integration process allowed the watermark to be almost completely hidden. As a consequence, we were able to create a watermarked image that looked similar to the original. The method's performance, as well as its resistance to JPEG compression and noise addition, were evaluated through experiments on test images. However, these values are sometimes far from the optimal value of 1 for normalized correlation.
C1 [Amine, Khaldi] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
   [Redouane, Kafi] Univ Kasdi Merbah, Fac Sci & Technol, Elect Dept, Elect Engn Lab, Ouargla 30000, Algeria.
   [Bilel, Maghni] Badji Mokhtar Annaba Univ, Fac Engn Sci, Dept Elect Engn, LSEM Lab, Annaba 23000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Kasdi Merbah Ouargla;
   Universite Badji Mokhtar - Annaba
RP Amine, K (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.; Bilel, M (corresponding author), Badji Mokhtar Annaba Univ, Fac Engn Sci, Dept Elect Engn, LSEM Lab, Annaba 23000, Algeria.
EM Khaldi.Amine@univ-ouargla.dz; bilel.maghni@univ-annaba.dz;
   Kafi.Redouane@univ-ouargla.dz
RI Kafi, Mohamed Redouane/AAT-2301-2021; Khaldi, Amine/AAV-1266-2020
OI Kafi, Mohamed Redouane/0000-0002-5500-0943; Khaldi,
   Amine/0000-0002-1637-9129
FU "La Direction Generale de la Recherche Scientifique et du Developpement
   Technologique (DGRSDT)" of Algeria
FX This work was supported by "La Direction Generale de la Recherche
   Scientifique et du Developpement Technologique (DGRSDT)" of Algeria.
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Amine K, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622500979
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Boukela L, 2021, ANN TELECOMMUN, V76, P145, DOI 10.1007/s12243-020-00780-5
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Jelodar H, 2021, MULTIMED TOOLS APPL, V80, P4155, DOI 10.1007/s11042-020-09755-z
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi A, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103540
   Liao X, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116438
   Liao X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103244
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Moad MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103114
   Ocular Disease Recognition, Right and left eye fundus photographs of 5000 patients
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Sayah MM, 2022, MULTIMED TOOLS APPL, V81, P43613, DOI 10.1007/s11042-021-11791-2
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Verma U., 2019, Int J Innov Technol Explor Eng, V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Yang JX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102822
   Zermi N, 2022, CYBERNET SYST, V53, P282, DOI 10.1080/01969722.2021.1983700
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 48
TC 13
Z9 13
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7901
EP 7915
DI 10.1007/s11042-022-13649-7
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842423200001
DA 2024-07-18
ER

PT J
AU Klézl, V
   Kelly, S
AF Klezl, Vojtech
   Kelly, Stephen
TI Negativists, enthusiasts and others: a typology of players in
   free-to-play games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer games; Player typology; Free-to-play games; Purchasing
   behavior; Virtual goods
ID PURCHASE INTENTION; CONSUMER-BEHAVIOR; VIRTUAL WORLDS; PERSPECTIVE;
   CONSUMPTION; VALUES; PERSONALITY; PREFERENCES; GOODS; BUY
AB The purpose of this paper is to develop a novel multidimensional typology of free-to-play gamers, based on the theory of consumption values and to test whether these types of gamers differ in their premium content consumer purchasing behavior. The study uses a survey of 839 Czech free-to-play gamers, where the players' values are tested across 27 items. Factor analysis is used to identify 6 different factors (values) influencing the gamers, which are then used as variables in a cluster analysis to identify 5 distinct gamer types. Results show that each identified gamer type differs not only in gaming (length of gameplay) but also in purchasing behavior (current purchase and future purchase intention, average monthly spend). One new gamer type, previously unidentified in the literature, has been identified (the enthusiasts), alongside the development of additional details for three of the more "standard" game types (economic aesthetes, identification seekers and killers). Gamers from the Czech Republic are used in the sample, limiting the generalizability of the study. The research complements existing gamer typologies by developing an empirically supported view of free-to-play gamers that is based on value, which results in the identification of one new gamer type. We also extend consumption values theory by identifying the multi-dimensional impact of value characteristics on purchase behavior in a context of emerging commercial and social importance.
C1 [Klezl, Vojtech] Orebro Univ, Sch Business, Orebro, Sweden.
   [Klezl, Vojtech] VSB Tech Univ Ostrava, Fac Econ, Dept Mkt & Business, Ostrava, Czech Republic.
   [Kelly, Stephen] Edge Hill Univ, Business Sch, Ormskirk, England.
   [Kelly, Stephen] Salford Univ, Business Sch, Salford, Lancs, England.
C3 Orebro University; Technical University of Ostrava; Edge Hill
   University; University of Salford
RP Klézl, V (corresponding author), Orebro Univ, Sch Business, Orebro, Sweden.; Klézl, V (corresponding author), VSB Tech Univ Ostrava, Fac Econ, Dept Mkt & Business, Ostrava, Czech Republic.; Kelly, S (corresponding author), Edge Hill Univ, Business Sch, Ormskirk, England.; Kelly, S (corresponding author), Salford Univ, Business Sch, Salford, Lancs, England.
EM vojtech.klezl@oru.se; s.j.h.kelly@salford.ac.uk
RI Kelly, Stephen/GZH-1668-2022
OI Kelly, Stephen/0000-0003-2727-7109
FU Faculty of Economics, VSBTechnical University of Ostrava [SP2018/125]
FX This contribution was created within the project SGS funded by the
   Faculty of Economics, VSBTechnical University of Ostrava, project name
   Identification of Reference Groups Roles in Buying and Consumer
   Behaviour, project registration number SP2018/125.
CR Aarseth EspenJ., 2003, PLAYING RES METHODOL, DOI DOI 10.7238/A.V0I7.763
   Agarwal P., 2017, EC MICROTRANSACTIONS
   Aladwani AM, 2014, COMPUT HUM BEHAV, V33, P270, DOI 10.1016/j.chb.2014.01.005
   Alha K., 2014, P NORD DIGRA 2014, P1
   Angell R, 2012, J RETAIL CONSUM SERV, V19, P259, DOI 10.1016/j.jretconser.2012.01.007
   [Anonymous], 2018, Gaming disorder
   [Anonymous], 2012, LOADING
   [Anonymous], 2014, LONG TAIL WHALES HAL
   Bartle R., 1996, J MUD Res, V1, P19, DOI DOI 10.1007/S00256-004-0875-6
   Berlo K, 2016, THESIS JONKOPING U S
   Cheng-Hsun Ho, 2012, International Journal of Electronic Business Management, V10, P204
   Clement J., 2022, Gaming revenue worldwide 2022, by segment
   Clement J., 2020, Global video game market value from 2020 to 2025
   Clement J., 2022, Statista
   Coldewey D, 2019, TECHCRUNCH
   De Keyzer F., 2015, Journal of Interactive Advertising, V15, P124, DOI DOI 10.1080/15252019.2015.1082450
   Fabrigar LR, 1999, PSYCHOL METHODS, V4, P272, DOI 10.1037/1082-989X.4.3.272
   Field A, 2009, Discovering statistics using SPSS
   Frank L, 2015, BLED 2015 P, P503
   Fransen ML, 2015, INT J ADVERT, V34, P6, DOI 10.1080/02650487.2014.995284
   Fullerton Tracy., 2008, GAME DESIGN WORKSHOP
   Ghuman Davinder, 2012, International Journal of Cyber Behavior, Psychology and Learning, V2, P13, DOI 10.4018/ijcbpl.2012010102
   Gotzenbrucker G., 2009, Eludamos Journal for Computer Game Culture, V3, P309
   Grguric M, 2022, SUBSCRIPTION MONETIZ
   Hamari J, 2017, COMPUT HUM BEHAV, V71, P59, DOI 10.1016/j.chb.2017.01.042
   Hanner N, 2015, P ANN HICSS, P3326, DOI 10.1109/HICSS.2015.401
   Heerwegh D., 2005, INT J SOC RES METHOD, V8, P85, DOI [10.1080/1364557042000203107, DOI 10.1080/1364557042000203107]
   Hsiao KL, 2016, ELECTRON COMMER R A, V16, P18, DOI 10.1016/j.elerap.2016.01.001
   Hutcheson G.D., 1999, The Multivariate Social Scientist: Introductory Statistics Using Generalized Linear Models, DOI DOI 10.4135/9780857028075
   Ip B, 2008, AUSTRALAS J EDUC TEC, V24, P355
   Jansz J, 2007, CYBERPSYCHOL BEHAV, V10, P133, DOI 10.1089/cpb.2006.9981
   Jimenez N, 2019, J CONSUM MARK, V36, P218, DOI 10.1108/JCM-06-2017-2249
   Jin W, 2017, INTERNET RES, V27, P408, DOI 10.1108/IntR-04-2016-0091
   Kajtaz M, 2015, PROC TECH, V20, P191, DOI 10.1016/j.protcy.2015.07.031
   Kallio KP, 2011, GAMES CULT, V6, P327, DOI 10.1177/1555412010391089
   Kim HW, 2011, INFORM MANAGE-AMSTER, V48, P228, DOI 10.1016/j.im.2011.05.004
   Kimiloglu H, 2010, J CONSUM MARK, V27, P401, DOI 10.1108/07363761011063303
   Kumar V, 2014, HARVARD BUS REV, V92, P27
   Lilly B, 2003, J CONSUM MARK, V20, P252, DOI 10.1108/07363760310472272
   Lin Holin., 2007, Proceedings of DiGRA 2007: Situated Play, P335
   Lopez CE, 2019, COMPUT HUM BEHAV, V91, P333, DOI 10.1016/j.chb.2018.10.005
   Lu HP, 2010, INFORM MANAGE-AMSTER, V47, P150, DOI 10.1016/j.im.2010.01.003
   Macchiarella P, TRENDS DIGITAL GAMIN
   Maeda H, 2015, INT J SOC RES METHOD, V18, P15, DOI 10.1080/13645579.2014.885159
   Malhotra N.K., 2006, MARKETING RES APPL A, V2nd
   Mäntymäki M, 2015, INT J INFORM MANAGE, V35, P124, DOI 10.1016/j.ijinfomgt.2014.10.004
   Mäntymäki M, 2011, COMPUT HUM BEHAV, V27, P2088, DOI 10.1016/j.chb.2011.06.003
   Marczewski A., 2015, Even Ninja Monkeys Like to Play: Gamification, Game Thinking and Motivational Design, V1st, P65
   Mogre R, 2017, J BUS IND MARK, V32, P251, DOI 10.1108/JBIM-01-2016-0004
   Nacke LE, 2014, ENTERTAIN COMPUT, V5, P55, DOI 10.1016/j.entcom.2013.06.002
   Newzoo, 2018, TOP COUNT MARK GAM R
   Park BW, 2011, COMPUT HUM BEHAV, V27, P2178, DOI 10.1016/j.chb.2011.06.013
   Parks L, 2009, PERS INDIV DIFFER, V47, P675, DOI 10.1016/j.paid.2009.06.002
   Paul J, 2012, J CONSUM MARK, V29, P412, DOI 10.1108/07363761211259223
   Riedl M. O., 2010, COMP ENT, V8, P1, DOI [DOI 10.1145/1921141.1921146, 10.1145/1921141.1921146]
   Sandy CJ, 2013, PSYCHOL MARKET, V30, P937, DOI 10.1002/mar.20657
   Schuurman D., 2008, Proc. of the 3rd Int. Conf. on Digital Interactive Media in Entertainment and Arts, P46, DOI DOI 10.1145/1413634.1413647
   Sezgin S., 2020, Bartin Universitesi Egitim Fakultesi Dergisi, V9, P49
   Shang RA, 2012, COMPUT HUM BEHAV, V28, P2227, DOI 10.1016/j.chb.2012.06.030
   SHETH JN, 1991, J BUS RES, V22, P159, DOI 10.1016/0148-2963(91)90050-8
   Stack Exchange, 2016, WHATS DIFF FREE VERS
   statista, BEST R 2022 MOST POP
   Statista, 2020, Gaming: The Most Lucrative Entertainment Industry By Far
   Statista, 2021, OTT VIDE IND STAT MA
   Statistica, 2016, GLOB MOB OS MARK SHA
   Sweeney JC, 2001, J RETAILING, V77, P203, DOI 10.1016/S0022-4359(01)00041-0
   SYKES J, 2006, CHI 06 HUM FACT COMP, P1731, DOI [DOI 10.1145/1125451.1125774, 10.1145/1125451.1125774]
   Tanrikulu C, 2021, INT J CONSUM STUD, V45, P1176, DOI 10.1111/ijcs.12687
   Teng CI, 2018, DECIS SUPPORT SYST, V114, P49, DOI 10.1016/j.dss.2018.08.007
   Tseng FC, 2011, EXPERT SYST APPL, V38, P7693, DOI 10.1016/j.eswa.2010.12.142
   Turel O, 2010, INFORM MANAGE-AMSTER, V47, P53, DOI 10.1016/j.im.2009.10.002
   Tuunanen J, 2012, P INT NORD DIGRA 201
   Vahlo J, 2017, J COMPUT-MEDIAT COMM, V22, P88, DOI 10.1111/jcc4.12181
   Wang L, 2021, INFORM TECHNOL PEOPL, V34, P297, DOI 10.1108/ITP-10-2019-0527
   Wijman T., 2021, Global Games Market Report - The VR Metaverse Edition
   Wijman Tom., 2020, NEWZOO
   Xu Y., 2012, Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, P843, DOI [DOI 10.1145/2145204.2145330, 10.1145/2145204.2145330]
   Zheng P, 2017, PROC CIRP, V63, P2, DOI 10.1016/j.procir.2017.03.122
NR 78
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7939
EP 7960
DI 10.1007/s11042-022-13647-9
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840595500004
OA hybrid
DA 2024-07-18
ER

PT J
AU An, L
   Huang, YB
   Zhang, QY
AF An, Li
   Huang, Yi-bo
   Zhang, Qiu-yu
TI Verifiable speech retrieval algorithm based on KNN secure hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Verifiable speech retrieval; KNNSH; HL-CS; Biometric template; Security
ID DEEP; ATTACK
AB With the rapid development of mobile Internet, the dimension of speech data is too high and the space is complex. The existing speech retrieval algorithms can not meet the efficient retrieval efficiency and privacy security of speech data in massive applications. Aiming at the problems of retrieval efficiency and accuracy caused by high dimension and complex space of speech feature data, content verifiable retrieval after speech attack, and the security of speech storage and transmission process, a security framework based on KNN Secure Hash (KNNSH) is proposed for verifiable speech retrieval. In this algorithm, the spectral centroid of speech is used as the only input factor, and then KNN classification is used to train and learn the speech vector to obtain each speech centroid. Each speech centroid is assigned a specific hyperchaotic Lorenz compressed sensing encryption algorithm (HL-CS) key, and the security framework is constructed according to the revocable biometric template generated by the combination of classification and specific key. The binary hash vector is generated, and then the hash vector is encrypted by HL-CS. The same encryption algorithm is used to encrypt the original speech. Experimental results show that only one item needs to be matched in the intra class matching process after classification, which improves the retrieval efficiency and accuracy, and realizes the content verification of speech retrieval after content preservation operations. Speech encryption effectively prevents the disclosure of plaintext, ensures the security of speech storage and transmission process. It has a large key space, which is enough to resist exhaustive attacks.
C1 [An, Li; Huang, Yi-bo] Northwest Normal Univ, Coll Phys & Elect Engn, Peili St, Lanzhou 730070, Gansu, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Xihu St, Lanzhou 730070, Gansu, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Peili St, Lanzhou 730070, Gansu, Peoples R China.
EM anli18394493685@163.com; huang_yibo@nwnu.edu.cn; zhanggylz@163.com
RI zhang, qiu/GXG-5600-2022; Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X; /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Science and
   Technology program of Gansu Province of China [21JR7RA120]; Young doctor
   fund project of Gansu Provincial Department of Education [2022QB-033]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Science and Technology program of Gansu Province of
   China(No.21JR7RA120) Young doctor fund project of Gansu Provincial
   Department of Education(2022QB-033).
CR Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dong X, 2021, IEEE T CIRC SYST VID, V31, P3266, DOI 10.1109/TCSVT.2020.3035775
   Fujiwara M, 2016, SCI REP-UK, V6, DOI 10.1038/srep28988
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   He XY, 2019, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2019.00295
   Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363
   Huang YB, 2022, MULTIMED TOOLS APPL, V81, P13065, DOI 10.1007/s11042-022-12371-8
   Huang YB, 2020, MULTIMED TOOLS APPL, V79, P24889, DOI 10.1007/s11042-020-09211-y
   [黄羿博 Huang Yibo], 2020, [华中科技大学学报. 自然科学版, Journal of Huazhong University of Science and Technology. Nature Science], V48, P32
   Ji YY, 2020, APPL MATH COMPUT, V386, DOI 10.1016/j.amc.2020.125478
   Jin S, 2020, IEEE T IMAGE PROCESS, V29, P5336, DOI 10.1109/TIP.2020.2971105
   Kamper H., 2018, CVPR, P2514
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Lai YL, 2021, IEEE T INF FOREN SEC, V16, P3170, DOI 10.1109/TIFS.2021.3073802
   Langenberg B., 2020, IEEE Transactions on Quantum Engineering, V1, P1, DOI 10.1109/TQE.2020.2965697
   Liang W, 2020, IEEE T IND INFORM, V16, P6543, DOI 10.1109/TII.2020.2966069
   Liu YH, 2020, FUTURE GENER COMP SY, V106, P296, DOI 10.1016/j.future.2020.01.023
   Mai GC, 2021, IEEE T INF FOREN SEC, V16, P262, DOI 10.1109/TIFS.2020.3009590
   Ng WWY, 2022, MULTIMED TOOLS APPL, V81, P927, DOI 10.1007/s11042-021-11494-8
   Patil AT, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101281
   Qian YM, 2021, IEEE-ACM T AUDIO SPE, V29, P1079, DOI 10.1109/TASLP.2021.3057230
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI [10.1109/TKDE.2020.2970050, 10.1109/TNNLS.2020.2995708]
   Song YL, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177566
   Talreja V, 2021, IEEE T INF FOREN SEC, V16, P1306, DOI 10.1109/TIFS.2020.3033189
   Wang XG, 2015, SCI REP-UK, V5, DOI 10.1038/srep15668
   Wang XG, 2021, PROC CVPR IEEE, P16352, DOI 10.1109/CVPR46437.2021.01609
   Wang YT, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107785
   Wang Y, 2021, MULTIMED TOOLS APPL, V80, P10013, DOI 10.1007/s11042-020-09701-z
   Weng ZY, 2019, NEUROCOMPUTING, V364, P209, DOI 10.1016/j.neucom.2019.06.053
   Xie H, 2021, IEEE-ACM T AUDIO SPE, V29, P1233, DOI 10.1109/TASLP.2021.3065234
   Xu L, 2022, IEEE T IMAGE PROCESS
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang YL, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2021.102301
   Zhang Z, 2021, IEEE T NEUR NET LEAR, V32, P4514, DOI 10.1109/TNNLS.2020.3018790
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
NR 39
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7803
EP 7824
DI 10.1007/s11042-022-13387-w
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840056400003
DA 2024-07-18
ER

PT J
AU Sharma, M
   Sharma, B
   Gupta, AK
   Pandey, D
AF Sharma, Manvinder
   Sharma, Bikramjit
   Gupta, Anuj Kumar
   Pandey, Digvijay
TI Recent developments of image processing to improve explosive detection
   methodologies and spectroscopic imaging techniques for explosive and
   drug detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Explosive detection; Trace detection; Standoff distance; Spectroscopy;
   LIBS
ID COLORIMETRIC SENSOR ARRAYS; LASER; IDENTIFICATION; SPECTRUM; STATE; RDX
AB The use of explosive materials by terrorists for mass killing, creating chaos and producing threat to people initiated the research for developing the techniques and equipments which can detect explosives. Recently a vehicle borne suicide bomber attacked CRPF convoy at Lethpora in Pulwama district in India on 14th February 2019, which killed 40 CRPF personnel. From decades, real-time detection and identification of traces of explosives at a standoff distance has been an ongoing challenge and critical problems in public safety, defense and counter terrorism. A number of methods has been successfully developed and used commercially and by defense which involves fluorescence quenching sensor, colorimetric kits and ion mobility spectrometers. While several methods are under investigation for explosive trace detection. The ideal trace detection of explosives is which can detect traces from a standoff distance and ensures personnel safety. This paper provides study of explosive detection methods, standoff spectroscopy based methods, LIBS and compares the existing methods for trace detection. Also the paper provides review of world's smallest drone made by Israel (Spectrodrone) which can sniff explosives and drugs from 2.8 km.
C1 [Sharma, Manvinder] Chandigarh Grp Coll, Dept ECE, Landran, Mohali, India.
   [Sharma, Bikramjit] Thapar Inst Engn & Technol, Dept ME, Patiala, Punjab, India.
   [Gupta, Anuj Kumar] Chandigarh Grp Coll, Dept CSE, Landran, Mohali, India.
   [Pandey, Digvijay] Dept Tech Educ, Faizabad 224001, Uttar Pradesh, India.
C3 Thapar Institute of Engineering & Technology
RP Pandey, D (corresponding author), Dept Tech Educ, Faizabad 224001, Uttar Pradesh, India.
EM digit11011989@gmail.com
OI PANDEY, DIGVIJAY/0000-0003-0353-174X; Gupta, Anuj
   Kumar/0000-0002-7636-0817
CR Allis DG, 2006, J PHYS CHEM A, V110, P1951, DOI 10.1021/jp0554285
   [Anonymous], 2019, The Times of India
   [Anonymous], 2019, BBC 0216
   [Anonymous], 2019, EC TIMES
   Babushok VI, 2006, SPECTROCHIM ACTA B, V61, P999, DOI 10.1016/j.sab.2006.09.003
   BRUNO AE, 1988, CHEM PHYS, V120, P155, DOI 10.1016/0301-0104(88)87218-5
   Chatterjee S, 2017, CHEMOSPHERE, V184, P438, DOI 10.1016/j.chemosphere.2017.06.008
   Cooper P.W., 2018, EXPLOSIVES ENG
   De Lucia FC, 2003, APPL OPTICS, V42, P6148, DOI 10.1364/AO.42.006148
   Ewing RG, 2001, TALANTA, V54, P515, DOI 10.1016/S0039-9140(00)00565-8
   Frost RL, 2006, J MOL STRUCT, V788, P224, DOI 10.1016/j.molstruc.2005.12.003
   Howa JD, 2016, FORENSIC CHEM, V1, P6, DOI 10.1016/j.forc.2016.07.003
   Kangas MJ, 2017, CRIT REV ANAL CHEM, V47, P138, DOI 10.1080/10408347.2016.1233805
   Kavya BG, 2013, IETE J RES, V59, P719, DOI 10.4103/0377-2063.126972
   Li Z, 2019, CHEM REV, V119, P231, DOI 10.1021/acs.chemrev.8b00226
   Li Z, 2015, CHEM COMMUN, V51, P15312, DOI 10.1039/c5cc06221g
   Liu HB, 2006, OPT EXPRESS, V14, P415, DOI 10.1364/OPEX.14.000415
   Lu W, 2017, J HAZARD MATER, V326, P130, DOI 10.1016/j.jhazmat.2016.12.024
   Manvinder Sharma, 2021, Mobile radio communications and 5G networks, P57
   Mao XX, 2018, ADV MATER SCI ENG, V2018, DOI 10.1155/2018/5913216
   OSTMARK H, 1993, J APPL PHYS, V73, P1993, DOI 10.1063/1.353165
   Ostmark H., 1990, Journal of Energetic Materials, V8, P308
   Phifer CC., 2006, SAND20066697
   Ricci PP, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2019.2944587
   Roman N, 2002, 33 RD INT ANN C ICT
   Shahraki H, 2018, J HAZARD MATER, V357, P1, DOI 10.1016/j.jhazmat.2018.05.054
   Sharma M, 2022, SILICON-NETH, V14, P7121, DOI 10.1007/s12633-021-01561-y
   Singh S, 2007, J HAZARD MATER, V144, P15, DOI 10.1016/j.jhazmat.2007.02.018
   Siyech M. S., 2019, Counter Terrorist Trends and Analyses, V11, P6
   Warhade KK, 2011, IETE J RES, V57, P461, DOI 10.4103/0377-2063.90172
   WEBB HD, 1964, J GEOPHYS RES, V69, P545, DOI 10.1029/JZ069i003p00545
   Wu C, 2016, ANAL CHIM ACTA, V936, P216, DOI 10.1016/j.aca.2016.06.045
   Yinon J., 2011, Counterterrorist detection techniques of explosives
   Yong, 1995, DSTOTR0068
   Zapata F, 2018, SPECTROCHIM ACTA A, V204, P81, DOI 10.1016/j.saa.2018.06.002
NR 35
TC 5
Z9 5
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6849
EP 6865
DI 10.1007/s11042-022-13578-5
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000838552300004
DA 2024-07-18
ER

PT J
AU Guan, YC
   Tan, SQ
   Li, QF
AF Guan, Yucheng
   Tan, Shunquan
   Li, Qifen
TI Binary steganography based on generative adversarial nets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary image steganography; Generative adversarial network (GAN);
   Syndrome-trellis code (STC); Distortion measurement
ID IMAGE SPLICING DETECTION; DISTORTION; STEGANALYSIS; FEATURES
AB Some of the most advanced steganographic methods for binary images are to manually extract the features of binary images. And state-of-the-art binary image steganography techniques need to be promoted in the human visual system. This paper proposes a secure binary image steganography method by a generative adversarial network (GAN). The generator part of GAN simulates stego images, and the discriminator is designed to discriminate between the stego image produced by the generator and the cover image. The proposed GAN can automatically learn the most suitable flipped pixels in a binary image. Firstly, we learn the probability of embedded change from each pixel in the binary image, which can be converted into an embedded distortion map. Then we design an embedded function to simulate the steganography of the binary image. Experimental results show that the proposed method can find more suitable texture areas to embed secret information under the premise of ensuring security with fewer pixels flipped and better visual effects. The proposed network structure is different from the traditional binary image steganography by achieving more advanced content-adaptive embedding. Meanwhile, the proposed method is the first to apply GAN structure to the field of binary image steganography.
C1 [Guan, Yucheng; Tan, Shunquan; Li, Qifen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Tan, SQ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM tansq@szu.edu.cn
FU NSFC [U19B2022, 61772349, 61872244, 62072313, 61806131, 61802262];
   Guangdong Basic and Applied Basic Research Foundation [2019B151502001];
   Shenzhen RD Program [JCYJ20200109105008228, 20200813110043002]; Alibaba
   Group through Alibaba Innovative Research (AIR) Program
FX This work was supported in part by NSFC (U19B2022, 61772349, 61872244,
   62072313, 61806131, 61802262), Guangdong Basic and Applied Basic
   Research Foundation (2019B151502001), and Shenzhen R&D Program
   (JCYJ20200109105008228, 20200813110043002). This work was also supported
   in part by Alibaba Group through Alibaba Innovative Research (AIR)
   Program.
CR Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P683, DOI 10.1109/ARES.2010.65
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P653, DOI 10.1109/ARES.2010.66
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jetchev N., 2016, ARXIV
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Li M, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9803519
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P20739, DOI 10.1007/s11042-019-7342-9
   Liu JR, 2020, J REAL-TIME IMAGE PR, V17, P137, DOI 10.1007/s11554-019-00885-8
   Liu WT, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107287
   Liu XJ, 2019, MULTIMED TOOLS APPL, V78, P7947, DOI 10.1007/s11042-018-6411-9
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Lu W, 2020, IEEE T CIRC SYST VID, V30, P3081, DOI 10.1109/TCSVT.2019.2936028
   Lu W, 2019, IEEE T CIRC SYST VID, V29, P1608, DOI 10.1109/TCSVT.2018.2852702
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Muhammad Khan, 2018, Future Generation Computer Systems, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Radford A., 2015, ARXIV
   Sharma VK, 2018, IET IMAGE PROCESS, V12, P1065, DOI 10.1049/iet-ipr.2017.0965
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tuceryan M., 1993, HDB PATTERN RECOGNIT, V2, P207, DOI DOI 10.1142/9789814343138_0010
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xue F, 2020, MULTIMED TOOLS APPL, V79, P12427, DOI 10.1007/s11042-019-08304-7
   Xue YJ, 2019, J REAL-TIME IMAGE PR, V16, P601, DOI 10.1007/s11554-018-0822-8
   Yang S, 2022, P IEEECVF C COMPUTER, P18332
   Yeung YL, 2020, IEEE T CIRC SYST VID, V30, P1423, DOI 10.1109/TCSVT.2019.2903432
   Zeng LW, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107576
   Zhang F, 2019, MULTIMED TOOLS APPL, V78, P21891, DOI 10.1007/s11042-019-7519-2
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 52
TC 0
Z9 0
U1 8
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6687
EP 6706
DI 10.1007/s11042-022-13581-w
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590100009
DA 2024-07-18
ER

PT J
AU Paul, R
   Al Aman, MAA
   Sarkar, A
   Biswas, A
AF Paul, Raina
   Al Aman, Md Abdul Aziz
   Sarkar, Apurba
   Biswas, Arindam
TI A combinatorial algorithm to compute set operations on simple isothetic
   polygons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Isothetic polygons; Interval tree; Polygon intersection; Polygon union;
   Polygon set-difference
ID LINEAR ALGORITHM; CONVEX
AB A combinatorial algorithm is presented in this work to compute different set operations such as union, intersection, and difference on isothetic polygons. The algorithm constructs an interval tree and formulates a set of combinatorial rules to find the intersection points between two isothetic polygons and then perform the set operations respectively. The running time of the proposed algorithm is found to be O (n log n).
C1 [Paul, Raina; Al Aman, Md Abdul Aziz; Sarkar, Apurba] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Sibpur, India.
   [Biswas, Arindam] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Paul, R (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Sibpur, India.
EM rainapaul22@gmail.com; mdaman.iiest@gmail.com; as.besu@gmail.com;
   barindam@gmail.com
CR Biswas A, 2010, J VIS COMMUN IMAGE R, V21, P295, DOI 10.1016/j.jvcir.2010.02.001
   CHAZELLE B, 1992, SIAM J COMPUT, V21, P671, DOI 10.1137/0221041
   CHAZELLE B, 1987, J ACM, V34, P1, DOI 10.1145/7531.24036
   CYRUS M, 1978, COMPUT GRAPH, V3, P23, DOI 10.1016/0097-8493(78)90021-3
   Dobkin D. P., 1991, Computer-Aided Geometric Design, V8, P181, DOI 10.1016/0167-8396(91)90001-R
   DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0
   Muller D. E., 1978, Theoretical Computer Science, V7, P217, DOI 10.1016/0304-3975(78)90051-8
   OROURKE J, 1982, COMPUT VISION GRAPH, V19, P384, DOI 10.1016/0146-664X(82)90023-5
   Rivero M, 2000, COMPUT GRAPH-UK, V24, P881, DOI 10.1016/S0097-8493(00)00090-X
   Shamos M.I., 1975, P 16 ANN IEEE S FDN, P224, DOI DOI 10.1145/800116.803772
   Shamos MI, 1976, 17 ANN S FDN COMP SC, P208
NR 11
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6647
EP 6666
DI 10.1007/s11042-022-13579-4
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590100002
DA 2024-07-18
ER

PT J
AU Mondal, A
   Reddy, C
   Jawahar, CV
AF Mondal, Ajoy
   Reddy, Chetan
   Jawahar, C., V
TI Deep semantic binarization for document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document binarization; Deep learning; Pixel-wise classification;
   Camera-captured whiteboard images; Camera-captured glass board images;
   Degraded document images
ID COMPETITION
AB Binarization is an essential pre-processing step for many document image analysis tasks. Binarization of handwritten documents is more challenging than printed documents because of the non-uniform density of ink and the variable thickness of strokes. Instead of traditional scanners, people nowadays use the mobile camera to capture documents, including text written on white and glass boards. The quality of the camera-captured document images is often poor when compared with scanned document images. This impacts binarization accuracy. This paper presents a deep learning-based binarization framework called Deep Semantic Binarization (dsb) to binarize various document images. We pose document image binarization problem as a pixel-wise two-class classification task. Deep networks (including dsb) require many training images during training. However, the benchmark datasets with a limited number of training images are publicly available in the literature. We explore various training strategies, including transfer learning, to handle the data scarcity during training. Due to the unavailability of mobile-captured whiteboard and glass board images, we created two datasets, namely wbids-iiit and gbids-iiit, with associated ground truths. We validate dsbn on the public benchmark dibco dataset and wbids-iiit and gbids-iiit datasets. We empirically demonstrate that the dsb outperforms the state-of-the-art techniques for wbids-iiit, gbids-iiit and public datasets.
C1 [Mondal, Ajoy; Reddy, Chetan; Jawahar, C., V] Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad, India.
C3 International Institute of Information Technology Hyderabad
RP Mondal, A (corresponding author), Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad, India.
EM ajoy.mondal@iiit.ac.in; chetanmailbox1@gmail.com; jawahar@iiit.ac.in
CR Bataineh B, 2011, PATTERN RECOGN LETT, V32, P1805, DOI 10.1016/j.patrec.2011.08.001
   Bera SK, 2021, MULTIMED TOOLS APPL, V80, P7653, DOI 10.1007/s11042-020-09836-z
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Biswas B, 2014, INT C PATT RECOG, P3008, DOI 10.1109/ICPR.2014.519
   Bukhari SS, 2009, J UNIVERS COMPUT SCI, V15, P3343
   Calvo-Zaragoza J, 2019, PATTERN RECOGN, V86, P37, DOI 10.1016/j.patcog.2018.08.011
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chou CH, 2010, PATTERN RECOGN, V43, P1518, DOI 10.1016/j.patcog.2009.10.016
   Das S, 2019, MULTIMED TOOLS APPL, V78, P27449, DOI 10.1007/s11042-019-07857-x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gatos B, 2009, INT J DOC ANAL RECOG
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He S, 2019, PATTERN RECOGN, V91, P379, DOI 10.1016/j.patcog.2019.01.025
   Khurshid K., 2009, DRR
   Kim IJ, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P323
   Lazzara G, 2014, INT J DOC ANAL RECOG, V17, P105, DOI 10.1007/s10032-013-0209-0
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Lu SJ, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P3
   Niblack W., 1986, An Introduction to Digital Image Processing
   Ntirogiannis K, 2014, INT CONF FRONT HAND, P809, DOI 10.1109/ICFHR.2014.141
   Ntirogiannis K, 2013, IEEE T IMAGE PROCESS, V22, P595, DOI 10.1109/TIP.2012.2219550
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pastor-Pellicer J, 2015, LECT NOTES COMPUT SC, V9095, P115, DOI [10.1007/978-3-319-19222-2_10, 10.1007/978-3-319-19222_10]
   Peng XJ, 2017, PROC INT CONF DOC, P708, DOI 10.1109/ICDAR.2017.121
   Pratikakis I., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P727, DOI 10.1109/ICFHR.2010.118
   Pratikakis I, 2018, INT CONF FRONT HAND, P489, DOI 10.1109/ICFHR-2018.2018.00091
   Pratikakis I, 2017, PROC INT CONF DOC, P1395, DOI 10.1109/ICDAR.2017.228
   Pratikakis I, 2016, INT CONF FRONT HAND, P619, DOI [10.1109/ICFHR.2016.110, 10.1109/ICFHR.2016.0118]
   Pratikakis I, 2013, PROC INT CONF DOC, P1471, DOI 10.1109/ICDAR.2013.219
   Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216
   Pratikakis I, 2011, PROC INT CONF DOC, P1506, DOI 10.1109/ICDAR.2011.299
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Tensmeyer C, 2017, PROC INT CONF DOC, P99, DOI 10.1109/ICDAR.2017.25
   Vo QN, 2018, PATTERN RECOGN, V74, P568, DOI 10.1016/j.patcog.2017.08.025
   Wolf C, 2003, PATTERN ANAL APPL, V6, P309, DOI 10.1007/s10044-003-0197-7
   Zhang ZY, 2007, DIGIT SIGNAL PROCESS, V17, P414, DOI 10.1016/j.dsp.2006.05.006
   Zhao JY, 2018, INT CONF FRONT HAND, P339, DOI 10.1109/ICFHR-2018.2018.00066
   Zheng Sixiao, 2021, CVPR
NR 42
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6531
EP 6555
DI 10.1007/s11042-022-13431-9
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000836524700002
DA 2024-07-18
ER

PT J
AU Niu, DM
   Li, YX
   Zhang, ZY
   Song, B
AF Niu, Danmei
   Li, Yuxiang
   Zhang, Zhiyong
   Song, Bin
TI A service collaboration method based on mobile edge computing in
   internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; Internet of things; Service collaboration;
   Multimedia contents
ID CLOUD; EFFICIENT; FOG; NETWORKS; STRATEGY; P2P
AB In recent years, cloud computing can provide efficient data storage and processing infrastructure for Internet of things (IoT). However, the complete centralization of cloud computing brings inevitable limitations, such as the inability to support real-time service response. Mobile edge computing can solve the problems caused by traditional cloud computing. By placing computing and storage resources at the edge of the mobile network near the user, mobile edge computing extends the ability of cloud computing at the edge of the network. The advantage of mobile edge computing is that it reduces the amount of data sent to the cloud. Therefore, data processing is more flexible and convenient. Mobile edge computing can realize lower latency and higher data processing ratio, which will play an important role in the future application of IoT. Firstly, a system model for the application scenario is established, which is a real-time and context aware service resource collaboration model. Then a service collaboration method based on mobile edge computing is designed, which mainly includes service function description, service collaboration process and algorithm design. Finally, the simulation experiments are carried out. Compared with the other two existing methods, our method can effectively reduce service execution time and improve the success ratio of service requests. So the method presented in this paper is more effective and reliable. We provide a solution for service collaboration method based on mobile edge computing in IoT, which can make better use of various service resources.
C1 [Niu, Danmei; Li, Yuxiang; Zhang, Zhiyong; Song, Bin] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
   [Niu, Danmei] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Niu, Danmei; Li, Yuxiang; Zhang, Zhiyong; Song, Bin] Henan Univ Sci & Technol, Henan Int Joint Lab Cyberspace Secur Applicat, Luoyang 471023, Peoples R China.
C3 Henan University of Science & Technology; Beijing University of Posts &
   Telecommunications; Henan University of Science & Technology
RP Niu, DM (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.; Niu, DM (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Niu, DM (corresponding author), Henan Univ Sci & Technol, Henan Int Joint Lab Cyberspace Secur Applicat, Luoyang 471023, Peoples R China.
EM niudanmei@163.com; liyuxiang198412@163.com; xidianzzy@126.com;
   songbin@haust.edu.cn
RI LI, Wenhui/JCD-9947-2023; Li, Yuxiang/HNJ-4258-2023; LI,
   yi/HKO-0480-2023; Li, yu/HHZ-5236-2022
OI Niu, Danmei/0000-0003-2297-4634
FU National Natural Science Foundation of China [61972133, 12101195]; Henan
   Province Key Scientific and Technological Projects [202102210162,
   212102210383, 222102210177, 222102210072]; Open Foundation of State key
   Laboratory of Networking and Switching Technology (Beijing University of
   Posts and Telecommunications) [SKLNST-2018-1-09]; Project of Leading
   Talents in Science and Technology Innovation for Thousands of People
   Plan in Henan Province [204200510021]
FX This work was supported by National Natural Science Foundation of China
   Grant No.61972133 and No.12101195, Henan Province Key Scientific and
   Technological Projects Grant No.202102210162, No.212102210383,
   No.222102210177 and No.222102210072, Open Foundation of State key
   Laboratory of Networking and Switching Technology (Beijing University of
   Posts and Telecommunications) Grant No. SKLNST-2018-1-09, Project of
   Leading Talents in Science and Technology Innovation for Thousands of
   People Plan in Henan Province Grant No.204200510021.
CR Al Ridhawi I, 2017, IEEE ACCESS, V5, P23719, DOI 10.1109/ACCESS.2017.2766068
   Al-Dhuraibi Y, 2018, IEEE T SERV COMPUT, V11, P430, DOI 10.1109/TSC.2017.2711009
   Assila B, 2018, IEEE SYMP COMP COMMU, P1193, DOI 10.1109/ISCC.2018.8538661
   Bulut E, 2012, IEEE T PARALL DISTR, V23, P2254, DOI 10.1109/TPDS.2012.83
   Chen K, 2014, IEEE T MOBILE COMPUT, V13, P235, DOI 10.1109/TMC.2012.239
   Dbouk T, 2019, IEEE T NETW SERV MAN, V16, P1665, DOI 10.1109/TNSM.2019.2939221
   Deng RL, 2016, IEEE INTERNET THINGS, V3, P1171, DOI 10.1109/JIOT.2016.2565516
   Deng ZZ, 2020, IEEE ACCESS, V8, P53062, DOI 10.1109/ACCESS.2020.2981501
   Fan Q, 2020, IEEE T NETW SCI ENG, V7, P253, DOI 10.1109/TNSE.2018.2852762
   Grieco R, 2006, WORLD WIDE WEB, V9, P317, DOI 10.1007/s11280-006-8559-x
   Jin Y, 2019, MULTIMED TOOLS APPL, V78, P8911, DOI 10.1007/s11042-018-6680-3
   Johnson D.B., 1996, Mobile Computing, DOI DOI 10.1007/978-0-585-29603-65
   Kaur A., 2020, Fog Data Anal. IoT Appl.: Next Generation Process Model State Art Technol., P59, DOI 10.1007/978-981-15-6044-6_4
   Khan AUR, 2014, IEEE COMMUN SURV TUT, V16, P393, DOI 10.1109/SURV.2013.062613.00160
   Kiani A, 2017, IEEE INTERNET THINGS, V4, P2082, DOI 10.1109/JIOT.2017.2750030
   Kim WS, 2018, IEEE ACCESS, V6, P20262, DOI 10.1109/ACCESS.2018.2815629
   Krishnamurthi R, 2019, GREEN SMART TECHNOLO, P261
   Kumar A., 2020, MULTIMEDIA BIG DATA, P289
   Li W, 2017, FUTURE GENER COMP SY, V70, P104, DOI 10.1016/j.future.2016.06.019
   Li YF, 2014, DATA KNOWL ENG, V92, P20, DOI 10.1016/j.datak.2014.06.001
   Liu GX, 2015, IEEE T COMPUT, V64, P54, DOI 10.1109/TC.2013.201
   Luo CM, 2017, IEEE T IND ELECTRON, V64, P750, DOI 10.1109/TIE.2016.2609838
   Masip-Bruin X, 2016, IEEE WIREL COMMUN, V23, P120, DOI 10.1109/MWC.2016.7721750
   Nayyar, 2019, EVOLUTION BUSINESS C, P111
   Ni LN, 2017, IEEE INTERNET THINGS, V4, P1216, DOI 10.1109/JIOT.2017.2709814
   Niu DM, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2019), P982, DOI 10.1109/ICISCE48695.2019.00197
   Niu DM, 2017, MULTIMED TOOLS APPL, V76, P3255, DOI 10.1007/s11042-016-3963-4
   Niu DM, 2015, COMPUT J, V58, P700, DOI 10.1093/comjnl/bxu044
   Orsini G, 2015, 2015 8TH IFIP WIRELESS AND MOBILE NETWORKING CONFERENCE (WMNC), P112, DOI 10.1109/WMNC.2015.10
   Qi Q, 2014, 2014 IEEE 80TH VEHICULAR TECHNOLOGY CONFERENCE (VTC FALL)
   Qureshi Basit, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P413, DOI 10.1109/WAINA.2010.12
   Rathee D, 2019, IET BOOK SER E-HEAL, P131, DOI 10.1049/PBHE020E_ch6
   Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2
   Solanki A., 2019, HDB RES BIG DATA IOT, P379, DOI [10.4018/978-1-5225-7432-3.ch021, DOI 10.4018/978-1-5225-7432-3.CH021]
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Tran TV, 2016, IEEE SENS J, V16, P9021, DOI 10.1109/JSEN.2016.2616114
   Wang LJ, 2017, IEEE T CYBERNETICS, V47, P473, DOI 10.1109/TCYB.2016.2519525
   Wu DP, 2019, FUTURE GENER COMP SY, V99, P609, DOI 10.1016/j.future.2018.12.032
   Wu DP, 2017, IEEE T MULTIMEDIA, V19, P2197, DOI 10.1109/TMM.2017.2733300
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Yousefpour A, 2018, IEEE INTERNET THINGS, V5, P998, DOI 10.1109/JIOT.2017.2788802
   Yu L, 2017, FUTURE GENER COMP SY, V68, P128, DOI 10.1016/j.future.2016.06.039
   Zeng LZ, 2004, IEEE T SOFTWARE ENG, V30, P311, DOI 10.1109/TSE.2004.11
   Zhang MC, 2018, FUTURE GENER COMP SY, V81, P505, DOI 10.1016/j.future.2017.07.030
NR 45
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6505
EP 6529
DI 10.1007/s11042-022-13394-x
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000836524700003
DA 2024-07-18
ER

PT J
AU Joshi, P
   Alsadoon, OH
   Alsadoon, A
   AlSallami, N
   Rashid, TA
   Prasad, PWC
   Haddad, S
AF Joshi, Prakrit
   Alsadoon, Omar Hisham
   Alsadoon, Abeer
   AlSallami, Nada
   Rashid, Tarik A.
   Prasad, P. W. C.
   Haddad, Sami
TI Deep learning for size and microscope feature extraction and
   classification in Oral Cancer: enhanced convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Images classification; Autoencoder; Overfitting; Oral
   Cancer Feature extraction; Information compression
ID IMAGES; TOMOGRAPHY; METASTASIS; DIAGNOSIS; REGION; HEAD
AB Background and Aim: Deep learning technology has not been implemented successfully in oral cancer images classification due to the overfitting problem. Due to the network arrangement and lack of proper data set for training, the network might not produce the required feature map with dimension reduction which result in overfitting problems. This research aims to reduce the overfitting by producing the required feature map with dimension reduction through using Convolutional Neural Network. Methodology: The proposed system uses the Enhanced Convolutional Neural Network and the autoencoder technique to increase the efficiency of feature extraction process and compresses the information. In this technique. unpooling and deconvolution is done to generate the input data to minimize the difference between input and output data. Furthermore, it extracts characteristic features from the input data set which regenerates the input data from those features by learning a network to reduce the overfitting problem. Results: Different value of accuracy and processing time is achieved using different sample group of Confocal Laser Endomicroscopy (CLE) images. Based on result, it shows that the proposed solution is better than the current system. Also, the proposed system has improved the classification accuracy by 5 similar to 5.5% in average and reduced the processing time by 20 similar to 30 milliseconds in average. Conclusion: The proposed system is focused on accurately classifying the oral cancer cells of different anatomical locations from the CLE images. Finally, this study enhances the accuracy and processing time using autoencoder method and solve the problem of overfitting.
C1 [Joshi, Prakrit; Alsadoon, Abeer] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [AlSallami, Nada] Worcester State Univ, Comp Sci Dept, Worcester, MA USA.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, KRG, Erbil, Iraq.
   [Prasad, P. W. C.; Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Sydney, NSW, Australia.
C3 Charles Sturt University; Al-Iraqia University; Western Sydney
   University; Massachusetts System of Public Higher Education; Worcester
   State University; University of Kurdistan Hewler
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Antonio VAA, 2018, INT J COMPUT ASS RAD, V13, P1905, DOI 10.1007/s11548-018-1835-2
   Ariji Y, 2019, OR SURG OR MED OR PA, V127, P458, DOI 10.1016/j.oooo.2018.10.002
   Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8
   Awan KH, 2011, ORAL ONCOL, V47, P274, DOI 10.1016/j.oraloncology.2011.02.001
   Behrmann J, 2018, BIOINFORMATICS, V34, P1215, DOI 10.1093/bioinformatics/btx724
   Bur AM, 2019, ORAL ONCOL, V92, P20, DOI 10.1016/j.oraloncology.2019.03.011
   Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479
   Das DK, 2018, TISSUE CELL, V53, P111, DOI 10.1016/j.tice.2018.06.004
   De Silva RK, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201755
   De Vos W, 2009, INT J ORAL MAX SURG, V38, P609, DOI 10.1016/j.ijom.2009.02.028
   Feng YQ, 2018, INT J COMPUT ASS RAD, V13, P179, DOI 10.1007/s11548-017-1663-9
   Folmsbee J, 2018, I S BIOMED IMAGING, P770, DOI 10.1109/ISBI.2018.8363686
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Halicek M, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.6.060503
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Heuke S, 2016, HEAD NECK-J SCI SPEC, V38, P1545, DOI 10.1002/hed.24477
   Jain DK, 2018, J COMPUT SCI-NETH, V25, P252, DOI 10.1016/j.jocs.2017.07.016
   Jaremenko C, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P479, DOI 10.1007/978-3-662-46224-9_82
   Jeyaraj PR, 2019, J CANCER RES CLIN, V145, P829, DOI 10.1007/s00432-018-02834-7
   Liang SJ, 2019, EUR RADIOL, V29, P1961, DOI 10.1007/s00330-018-5748-9
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Nishio M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200721
   Poedjiastoeti W, 2018, HEALTHC INFORM RES, V24, P236, DOI 10.4258/hir.2018.24.3.236
   Rodner E, 2019, HEAD NECK-J SCI SPEC, V41, P116, DOI 10.1002/hed.25489
   Song BF, 2018, BIOMED OPT EXPRESS, V9, P5318, DOI 10.1364/BOE.9.005318
   Song Y, 2018, J MAGN RESON IMAGING, V48, P1570, DOI 10.1002/jmri.26047
   Sturm I, 2016, J NEUROSCI METH, V274, P141, DOI 10.1016/j.jneumeth.2016.10.008
   Sun J, 2015, ONCOTARGETS THER, V8, P1291, DOI 10.2147/OTT.S73924
   Yilmaz E, 2017, COMPUT METH PROG BIO, V146, P91, DOI 10.1016/j.cmpb.2017.05.012
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 32
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6197
EP 6220
DI 10.1007/s11042-022-13412-y
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836525000013
DA 2024-07-18
ER

PT J
AU Nayak, RP
   Sethi, S
   Bhoi, SK
   Sahoo, KS
   Nayyar, A
AF Nayak, Rajendra Prasad
   Sethi, Srinivas
   Bhoi, Sourav Kumar
   Sahoo, Kshira Sagar
   Nayyar, Anand
TI ML-MDS: Machine Learning based Misbehavior Detection System for
   Cognitive Software-defined Multimedia VANETs (CSDMV) in smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Misbehavior; ML-MDS; VANET; CSDMV; SDNC; Accuracy
ID BIG DATA ANALYTICS; INTRUSION DETECTION; NETWORK
AB Security is a major concern in vehicular networks for reliable communication between the source and the destination in smart cities. Data, these days, is in the form of safety or non-safety messages in formats like text, audio, images, video, etc. These information exchanges between the two parties need to be updated with a trust value (TV) by analyzing the communication data. In this paper, a machine learning-based misbehavior detection system (ML-MDS) is proposed for cognitive software-defined multimedia vehicular networks (CSDMV) in smart cities. In the proposed system, before communication, the vehicle must be aware of the TV of other vehicles. If the TV for a vehicle is higher than a threshold (th), then the communication happens and the whole transaction information is sent to the local software-defined network controller (LSDNC) for classification of behavior using the ML algorithm. After this, the TV is updated as per the last transaction status at LSDNC and the updated TV of the vehicle is sent to the main SDN controller for information gathering. In this system, the best ML algorithm for the ML-MDS model is selected by considering decision tree, support vector machine (SVM), neural network (NN), and logistic regression (LR) algorithms. The classification accuracy performance is evaluated using UNSW_NB-15 standard dataset for detecting the normal and malicious vehicles. NN shows better classification accuracy than other algorithms. The proposed ML-MDS is implemented and evaluated using OMNeT++ network simulator and the Simulation of Urban Mobility (SUMO) road traffic simulator by considering various parameters such as detection accuracy, detection time, and energy consumption. From the results, it is observed that the detection accuracy of proposed ML-MDS system is 98.4% as compared to Grover et al. scheme which was 80.2%. Also, for scalability issue the dataset size is increased and performance is evaluated in Orange 3.26.0 machine analytics tool and NN is found to be the best algorithm which shows high accuracy in detecting the attackers.
C1 [Nayak, Rajendra Prasad] BPUT, Dept Comp Sci & Engn, GCEK Govt, Bhawanipatna, Rourkela, India.
   [Sethi, Srinivas] BPUT, Dept Comp Sci Engn & Applicat, IGIT Govt, Sarang, Rourkela, India.
   [Bhoi, Sourav Kumar] BPUT, PMEC Govt, Dept Comp Sci Engn & Applicat, Berhampur, Rourkela, India.
   [Sahoo, Kshira Sagar] SRM Univ, Dept Comp Sci & Engn, Amaravati 522502, AP, India.
   [Sahoo, Kshira Sagar] Umea Univ, Dept Comp Sci, SE-90187 Umea, Sweden.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Fac Informat Technol, Da Nang, Vietnam.
C3 SRM University-AP; Umea University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Fac Informat Technol, Da Nang, Vietnam.
EM rajendra.cet07@gmail.com; srinivas_sethi@igitsarag.ac.in;
   sourav.cse@pmec.ac.in; kshirasagar12@gmail.com;
   anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Bhoi, Sourav Kumar/AAX-9796-2020
OI Nayyar, Anand/0000-0002-9821-6146; Bhoi, Sourav
   Kumar/0000-0002-5173-3453
FU Kempe fellowship, Sweden [SMK21-0061]; Wallenberg AI, Autonomous Systems
   and Software Program (WASP) - Knut and Alice Wallenberg Foundation
FX This work was supported by the Kempe fellowship via project no.
   SMK21-0061, Sweden. Additional support was provided by the Wallenberg
   AI, Autonomous Systems and Software Program (WASP) funded by Knut and
   Alice Wallenberg Foundation.
CR Akbar MS, 2014, PROCEDIA COMPUT SCI, V32, P953, DOI 10.1016/j.procs.2014.05.517
   Alheeti KMA, 2015, 2015 SIXTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P86, DOI 10.1109/EST.2015.10
   Alheeti KMA, 2015, COMPUT SCI ELECTR, P231, DOI 10.1109/CEEC.2015.7332730
   [Anonymous], AboutUs
   [Anonymous], 2016, IEEE ACCESS, DOI DOI 10.1109/access.2016.2645452
   Arif M, 2018, LECT NOTES COMPUT SC, V11342, P46, DOI 10.1007/978-3-030-05345-1_4
   Bedi P, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1677, DOI 10.1109/ICACCI.2014.6968352
   Bhoi SK, 2022, INTELL AUTOM SOFT CO, V32, P1493, DOI 10.32604/iasc.2022.022833
   Bhoi SK, 2016, WIREL NETW, V22, P285, DOI 10.1007/s11276-015-0970-8
   Bhoi SK, 2015, IET NETW, V4, P185, DOI 10.1049/iet-net.2014.0053
   Bhoi SK, 2014, IET NETW, V3, P204, DOI 10.1049/iet-net.2013.0065
   Bhoi SK, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1175, DOI 10.1109/iccsp.2013.6577241
   Bhoi SK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P545, DOI 10.1109/PDGC.2012.6449879
   Boeira F, 2017, IEEE VEHIC NETW CONF, P53, DOI 10.1109/VNC.2017.8275641
   Da Cunha FD, 2014, DATA COMMUNICATION V, V44, P90
   Garg S, 2019, IEEE NETWORK, V33, P72, DOI 10.1109/MNET.2019.1800239
   Ghaleb FA, 2017, 2017 IEEE CONFERENCE ON APPLICATION, INFORMATION AND NETWORK SECURITY (AINS), P13, DOI 10.1109/AINS.2017.8270417
   Grover J, 2011, COMM COM INF SC, V192, P644
   Gyawali S, 2020, IEEE T VEH TECHNOL, V69, P8871, DOI 10.1109/TVT.2020.2996620
   Gyawali Sohan., 2019, ICC 2019 2019 IEEE I, P1
   Hasrouny H, 2017, VEH COMMUN, V7, P7, DOI 10.1016/j.vehcom.2017.01.002
   Hu H, 2017, IEEE T VEH TECHNOL, V66, P1786, DOI 10.1109/TVT.2016.2565001
   Hu H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060803
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Ku Ian, 2014, 2014 13th Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), P103, DOI 10.1109/MedHocNet.2014.6849111
   Kumar N, 2014, COMPUT ELECTR ENG, V40, P1981, DOI 10.1016/j.compeleceng.2014.01.009
   Lal AS, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION & COMPUTING INDIA (ICCC), P664, DOI 10.1109/ICCC.2015.7432979
   Li F, 2007, IEEE VEH TECHNOL MAG, V2, P12, DOI 10.1109/MVT.2007.912927
   Li T, 2018, IEEE INTERNET THINGS, V5, P3474, DOI 10.1109/JIOT.2018.2847243
   Lyamin N, 2018, IEEE NETWORK, V32, P15, DOI 10.1109/MNET.2018.1800074
   Lyamin N, 2014, IEEE COMMUN LETT, V18, P110, DOI 10.1109/LCOMM.2013.102213.132056
   Mahmoudi Issam, 2020, Vehicular Ad-hoc Networks for Smart Cities. Third International Workshop, 2019. Advances in Intelligent Systems and Computing (AISC 1144), P73, DOI 10.1007/978-981-15-3750-9_6
   Marfia G, 2011, P 4 INT C COGN RAD A, P1
   Mejri MN, 2014, VEH COMMUN, V1, P53, DOI 10.1016/j.vehcom.2014.05.001
   Modha DS, 2011, COMMUN ACM, V54, P62, DOI 10.1145/1978542.1978559
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Moustafa N, 2019, IEEE T BIG DATA, V5, P481, DOI 10.1109/TBDATA.2017.2715166
   Moustafa N, 2017, DATA ANALYTIC, P127, DOI 10.1007/978-3-319-59439-2_5
   Moustafa N, 2016, INF SECUR J, V25, P18, DOI 10.1080/19393555.2015.1125974
   Olariu S, 2011, INT J PERVASIVE COMP, V7, P7, DOI 10.1108/17427371111123577
   Patounas G, 2015, IEEE INT C INTELL TR, P2153, DOI 10.1109/ITSC.2015.348
   Sahoo KS, 2022, IEEE INTERNET THINGS, V9, P10529, DOI 10.1109/JIOT.2021.3122255
   Sakiz F, 2017, AD HOC NETW, V61, P33, DOI 10.1016/j.adhoc.2017.03.006
   Shafiq H, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8631851
   Sharshembiev K, 2021, WIREL NETW, V27, P2103, DOI 10.1007/s11276-021-02565-7
   Singh P.K., 2019, INT C SEC PRIV, P166, DOI DOI 10.1007/978-981-13-7561-3_13
   So S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P564, DOI 10.1109/ICMLA.2018.00091
   Sommer C, 2019, EAI SPRINGER INNOVAT, P215, DOI 10.1007/978-3-030-12842-5_6
   Swain RR, 2018, AD HOC NETW, V69, P15, DOI 10.1016/j.adhoc.2017.10.012
   Truong NB, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P1202, DOI 10.1109/INM.2015.7140467
   Uprety A, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369513
   Vitelli D, 2016, THESIS
   Yu Y, 2018, IEEE ACCESS, V6, P44570, DOI 10.1109/ACCESS.2018.2854567
   Zhang T, 2018, IEEE T SIGNAL INF PR, V4, P148, DOI 10.1109/TSIPN.2018.2801622
NR 54
TC 14
Z9 14
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3931
EP 3951
DI 10.1007/s11042-022-13440-8
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000827365200002
DA 2024-07-18
ER

PT J
AU Barreto, F
   de Abreu, RS
   Josué, MIP
   Montevecchi, EBB
   Valentim, PA
   Muchaluat-Saade, DC
AF Barreto, Fabio
   de Abreu, Raphael S.
   Josue, Marina I. P.
   Montevecchi, Eyre Brasil B.
   Valentim, Pedro Alves
   Muchaluat-Saade, Debora C.
TI Providing multimodal and multi-user interactions for digital tv
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NCL; Ginga-NCL; Multimodal interaction; Multi-user interaction; Digital
   tv applications
C1 [Barreto, Fabio; de Abreu, Raphael S.; Josue, Marina I. P.; Montevecchi, Eyre Brasil B.; Valentim, Pedro Alves; Muchaluat-Saade, Debora C.] Fluminense Fed Univ, MidiaCom Lab, Niteroi, RJ, Brazil.
   [Barreto, Fabio; de Abreu, Raphael S.] Unilasalle RJ, Niteroi, RJ, Brazil.
C3 Universidade Federal Fluminense
RP Barreto, F (corresponding author), Fluminense Fed Univ, MidiaCom Lab, Niteroi, RJ, Brazil.; Barreto, F (corresponding author), Unilasalle RJ, Niteroi, RJ, Brazil.
EM fbarreto@midiacom.uff.br
OI Barreto, Fabio/0000-0003-4842-5238; Alves Valentim,
   Pedro/0000-0002-6697-003X
FU CAPES; CNPq; FAPERJ; CAPES PRINT; INCT-MACC
FX The authors would like to thank CAPES, CAPES PRINT, CNPq, INCT-MACC and
   FAPERJ for the partial financial support of this work.
CR ABNT, 2021, DIG TERR TEL DAT COD
   [Anonymous], 2014, HTML5, A vocabulary and associated APIs for HTML and XHTML, W3C Candidate Recommendation 04 February 2014
   [Anonymous], 2007, J BRAZ COMPUT SOC
   [Anonymous], 2020, THIS IS EYE TRACKING
   Barreto F, 2020, P BRAZILIAN S MULTIM, P281
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Card S., 1986, Handbook of Perception and Human Performance, V2, P45
   Carvalho LAMC, 2008, P 2008 EURO AM C TEL
   Casanova M. A., 1991, Third ACM Conference on Hypertext Proceedings, P193, DOI 10.1145/122974.122993
   Costa RMdR, 2009, P 15 BRAZILIAN S MUL
   Danesh Ali, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P1, DOI 10.1007/978-3-319-14442-9_1
   de Farias BC, 2020, IEEE ICCE, P195
   de Lima ES, 2011, P 2011 BRAZ S GAM DI, P206
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Furht B., 2008, Encyclopedia of Multimedia, P651, DOI 10.1007/978-0-387-78414-4_159
   Gilman, 2009, P INT C ADV COMP ENT, P19, DOI DOI 10.1145/1690388.1690392
   Gowing M., 2014, LECT NOTES COMPUT SC, V8325, P484, DOI DOI 10.1007/978-3-319-04114-8_41
   Hunkeler U, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P791, DOI 10.1109/COMSWA.2008.4554519
   Ierusalimschy R., 2006, Programming in lua, Roberto Ierusalimschy
   ITU, 2009, H761 ITU ITU T
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   Mo SY, 2020, LECT NOTES COMPUT SC, V11961, P278, DOI 10.1007/978-3-030-37731-1_23
   Montevecchi EBB, 2020, P BRAZILIAN S MULTIM, P297
   Muchaluat-Saade D. C., 2002, New Review of Hypermedia and Multimedia, V8, P139, DOI 10.1080/13614560208914739
   Luque FP, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617992
   Pedrosa D, 2011, P 2011 ACM S APPL CO, P1253
   Pereira DMG, 2021, MULTIMED TOOLS APPL, V80, P1813, DOI 10.1007/s11042-020-09645-4
   Silva ECO, 2013, 2013 IEEE INT C MULT, P1
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   Soares LFG, 2005, NESTED CONTEXT MODEL, P12
   Turabzadeh S, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010017
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Union IT, 2009, ITU R H761 NEST CONT
   Guedes ALV, 2017, MULTIMED TOOLS APPL, V76, P5691, DOI 10.1007/s11042-016-3846-8
   W3C, 2008, Synchronized multimedia integration language (SMIL 3.0)
NR 35
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4821
EP 4846
DI 10.1007/s11042-021-11847-3
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000826265100001
DA 2024-07-18
ER

PT J
AU Kiamari, N
   Hadian, M
   Mashhadi, S
AF Kiamari, Niloofar
   Hadian, Massoud
   Mashhadi, Samaneh
TI Non-interactive verifiable LWE-based multi secret sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Threshold secret sharing scheme; Lattice-based cryptography; Learning
   with errors; Multi secret sharing; Non-interactive verifiable
ID SIGNATURE
AB The learning with errors (LWE) problem has emerged as the most popular hard problem for constructing lattice based cryptographic solutions. In this paper, we propose a verifiable multi secret sharing scheme based on LWE problem and prove the security of our scheme in the standard model. It is a threshold scheme and every t participants (t <= n) can recover multiple secrets, in one stage. Moreover, it has a non-interactive verification and no extra communication is needed among participants and the dealer in the verification phase. In short, it is the first LWE based threshold multi secret sharing scheme that has formal security in the standard model.
C1 [Kiamari, Niloofar; Hadian, Massoud; Mashhadi, Samaneh] Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
C3 Iran University Science & Technology
RP Mashhadi, S (corresponding author), Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
EM smashhadi@iust.ac.ir
RI mashhadi, samaneh/S-8996-2018; mashhadi, samaneh/ISV-0962-2023
OI mashhadi, samaneh/0000-0001-9191-1376; mashhadi,
   samaneh/0000-0001-9191-1376
CR Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   [Anonymous], 2011, IJCA Special Issue on "Network Security and Cryptography"
   Bernstein Daniel J., 2009, Post-quantum cryptography, P1, DOI [10.1007/978-3-540-88702-71, 10.1007/978-3-540-88702-7, DOI 10.1007/978-3-540-88702-71, DOI 10.1007/978-3-540-88702-7, 10.1007/978-3-540-88702-7_1, DOI 10.1007/978-3-540-88702-7_1]
   Biggs N., 2002, Discrete Mathematics
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blundo C., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P150
   Chen D, 2019, IEEE ACCESS, V7, P107104, DOI 10.1109/ACCESS.2019.2929090
   Chor B., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P383, DOI 10.1109/SFCS.1985.64
   Dehkordi MH, 2019, WIRELESS PERS COMMUN, V104, P491, DOI 10.1007/s11277-018-6032-7
   Dehkordi MH, 2016, WIRELESS PERS COMMUN, V91, P1459, DOI 10.1007/s11277-016-3539-7
   El Bansarkhani Rachid, 2012, Information Security Theory and Practice. Security, Privacy and Trust in Computing Systems and Ambient Intelligent Ecosystems. 6th IFIP WG 11.2 International Workshop (WISTP 2012), P160, DOI 10.1007/978-3-642-30955-7_14
   Goldreich O, 1997, LECT NOTES COMPUT SC, V1294, P112
   Goldreich O., 1996, COLLISION FREE HASHI
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Hoffstein J., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P267, DOI 10.1007/BFb0054868
   [Каримани С Karimani S], 2019, [Математические вопросы криптографии, Matematicheskie voprosy kriptografii], V10, P97, DOI 10.4213/mvk287
   Khorasgani HA, 2016, ISECURE-ISC INT J IN, V8, P25
   Khorasgani HA, 2014, INT ISC CONF INFO SE, P173, DOI 10.1109/ISCISC.2014.6994043
   Knospe H, 2019, A course in cryptography
   Li CY, 2021, INFORM SCIENCES, V546, P253, DOI 10.1016/j.ins.2020.08.032
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Lipshutz S., 2017, SCHAUMS OUTLINES LIN
   Liu WL, 2020, SECURITY CRYPTOLOGY, V12309, P357, DOI 10.1007/978-3-030-59013-0_18
   Mashhadi S, 2020, J APPL SEC RES, V15, P84, DOI 10.1080/19361610.2019.1696607
   Mashhadi S, 2017, IET INFORM SECUR, V11, P326, DOI 10.1049/iet-ifs.2017.0111
   Mashhadi S, 2015, ISECURE-ISC INT J IN, V7, P91
   McEliece R. J., 1978, DGN Progres Report 42-44, P114, DOI 10.1109/JPHOT.2021.3069510
   Mesnager S, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122218
   Miao FY, 2017, CHINESE J ELECTRON, V26, P557, DOI 10.1049/cje.2016.08.014
   Mishra A, 2018, J INFORM OPTIM SCI, V39, P631, DOI 10.1080/02522667.2017.1385161
   Pilaram H, 2017, IEEE T DEPEND SECURE, V14, P2, DOI 10.1109/TDSC.2015.2432800
   Rajabi B, 2019, INFORM SCIENCES, V501, P655, DOI 10.1016/j.ins.2018.11.004
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Sehrawat VS, 2021, THEOR COMPUT SCI, V886, P106, DOI 10.1016/j.tcs.2021.07.022
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Sheikhi-Garjan M, 2019, IET INFORM SECUR, V13, P278, DOI 10.1049/iet-ifs.2018.5174
   SHOR PW, 1994, AN S FDN CO, P124
   Wu FG, 2019, MULTIMED TOOLS APPL, V78, P3511, DOI 10.1007/s11042-018-6330-9
   Xu ZY, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-1527-7
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
NR 40
TC 2
Z9 2
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22175
EP 22187
DI 10.1007/s11042-022-13347-4
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000820564000006
DA 2024-07-18
ER

PT J
AU Gowroju, S
   Aarti
   Kumar, S
AF Gowroju, Swathi
   Aarti
   Kumar, Sandeep
TI Review on secure traditional and machine learning algorithms for age
   prediction using IRIS image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Age; Pupil size; Pupil diameter; Classification; Feature extraction;
   CNN; Geometric features
ID INTERPUPILLARY DISTANCE; PUPIL DIAMETER; NEURAL-NETWORK; RECOGNITION;
   SCALE; SEGMENTATION; DEPENDENCE; FEATURES; SHAPE
AB Iris recognition is a secure and best-chosen biometric application in the digital world because of its unique characteristics. Day by day, the digital world plays a significant role in human life for various applications. The applications are vastly spread over secure applications of the nation such as border control applications, criminal investigations, postmortem studies, access the digital equipment, smart homes, smart appliances, smart cars etc. Due to the digitalization of the world, all the research communities, scientists, and industries are focusing on the biometric-based secured iris recognition system. Several researchers have done much work in this domain, but there is still a scope of improvement for various reasons, i.e., less speed and accuracy of the module. The researcher has implemented various algorithms based on traditional and neural network architectures. In this scenario, this paper gives a brief on different techniques and algorithms used by researchers to predict the age of human people using the iris. This paper discussed one hundred and one papers in the literature with various image segmentation, feature extraction and classification of the iris. This paper summarizes publicly available standard databases and various evaluation parameters, i.e., accuracy, precision, recall, f-score, etc. The research community evaluated the age prediction through the iris-based state-of-the-art algorithms with secure prediction, i.e., TPR, TNR, FPR, FNR. Finally, this paper provides the strengths and weaknesses of the various state of art algorithms, respectively, and summarizes the gaps in the existing technology with the scope of improvement.
C1 [Gowroju, Swathi] Lovely Profess Univ, Sreyas Inst Engn & Technol, Hyderabad, Punjab, India.
   [Aarti] Lovely Profess Univ, Phagwara, Punjab, India.
   [Kumar, Sandeep] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
C3 Lovely Professional University; Lovely Professional University; Koneru
   Lakshmaiah Education Foundation (K L Deemed to be University)
RP Gowroju, S (corresponding author), Lovely Profess Univ, Sreyas Inst Engn & Technol, Hyderabad, Punjab, India.
EM swathigowroju@sreyas.ac.in
RI Kumar, Sandeep/ADM-4627-2022; Aarti/AAK-8947-2021
OI Kumar, Sandeep/0000-0002-4752-7884; Aarti/0000-0002-1345-2669
CR Abbasi A, 2016, INT ARAB J INF TECHN, V13, P716
   Abdullah MAM, 2017, IEEE T SYST MAN CY-S, V47, P3128, DOI 10.1109/TSMC.2016.2562500
   Al-Allaf O, 2012, INT J INFORM COMMUNI, V2
   AlonsoFernandez F., 2009, Proceedings of the 2009 International Conference on Biometrics, Identity and Security (BIdS), P1, DOI DOI 10.1109/BIDS.2009.5507529
   Alrifaee Mustafa M, 2020, SHORT SURVEY IRIS IM
   Alvarez-Betancourt Y, 2016, KNOWL-BASED SYST, V92, P169, DOI 10.1016/j.knosys.2015.10.024
   Anderson JE, 1956, C PLANNING RES
   [Anonymous], 2013, INT J SCI ENG RES
   [Anonymous], 2003, Recognition of Human Iris Patterns for Biometric Identification
   Baker SE, 2009, LECT NOTES COMPUT SC, V5558, P1170, DOI 10.1007/978-3-642-01793-3_118
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bazrafkan S, 2018, NEURAL NETWORKS, V106, P79, DOI 10.1016/j.neunet.2018.06.011
   Belcher C, 2008, IEEE T INF FOREN SEC, V3, P572, DOI 10.1109/TIFS.2008.924606
   Belcher C, 2009, OPT LASER ENG, V47, P139, DOI 10.1016/j.optlaseng.2008.07.004
   Bennet J, 2014, SCI WORLD J, DOI 10.1155/2014/195470
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   Cakmak HB, 2012, INT J OPHTHALMOL-CHI, V5, P505, DOI 10.3980/j.issn.2222-3959.2012.04.19
   Chen JX, 2016, IEEE T INF FOREN SEC, V11, P1476, DOI 10.1109/TIFS.2016.2535901
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Daugman J., 1994, United StatesPatent, Patent No. [5,291,560, 5291560]
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dehkordi AB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P404, DOI 10.1109/ICSIPA.2015.7412224
   Dey S, 2010, INT J BIOMETRICS, V2, P250, DOI 10.1504/IJBM.2010.033389
   Dubbelman M, 2006, VISION RES, V46, P993, DOI 10.1016/j.visres.2005.09.021
   Elminir HK, 2007, ENERGY, V32, P1513, DOI 10.1016/j.energy.2006.10.010
   Erbilek M., 2014, 2014 International Conference of the Biometrics Special Interest Group, P1
   Erbilek M., 5 INT C IMAGING CRIM, DOI [DOI 10.1049/IC.2013.0258, 10.1049/ic.2013.0258]
   Fairhurst M, 2011, IET COMPUT VIS, V5, P358, DOI 10.1049/iet-cvi.2010.0165
   Fang YC, 2008, INT C WAVEL ANAL PAT, P373, DOI 10.1109/ICWAPR.2008.4635807
   Fenker SamuelP., 2011, WORKSHOP APPL COMPUT, P232, DOI DOI 10.1109/WACV.2011.5711508
   Fenker SP, 2012, 2012 IEEE COMP SOC C, P45, DOI DOI 10.1109/CVPRW.2012.6239214
   FLEDELIUS HC, 1986, ACTA OPHTHALMOL, V64, P481
   Gopikrishnan M., 2011, INT J REV COMPUTING, V7, P22
   Gowroju Swathi, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P105, DOI 10.1109/MIUCC52538.2021.9447658
   Gowroju Swathi, 2020, 2020 11th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0609, DOI 10.1109/IEMCON51383.2020.9284947
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Phuong HM, 2012, 2012 FOURTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P302, DOI 10.1109/CCE.2012.6315916
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hussain SJ., 2021, TURKISH J COMPUT MAT, V12, P2038
   Ibrahim MT, 2010, PROC SPIE, V7744, DOI 10.1117/12.863264
   Ince IF, 2019, COMPUT J, V62, P1001, DOI 10.1093/comjnl/bxy102
   Jones K, 1998, J NUCL MED, V39, P965
   KADLECOVA V, 1958, NATURE, V182, P1520, DOI 10.1038/1821520a0
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Khobragade K, 2014, INT J INNOV ENG TECH
   Kiranmayee BV, 2011, KGISL P
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Kohail S. N., 2012, 2012 International Conference on Innovations in Information Technology (IIT), P215, DOI 10.1109/INNOVATIONS.2012.6207735
   Krichen E, 2009, IEEE T SYST MAN CY B, V39, P924, DOI 10.1109/TSMCB.2008.2009770
   Kumar S, 2019, INT J COMPUT SCI ENG
   Kumar S, 2021, INT J BIOMETRICS, V13, P131, DOI 10.1504/IJBM.2021.114639
   Kumar S, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P648, DOI 10.1109/CCWC.2019.8666601
   Kumar S, 2018, WIRELESS PERS COMMUN, V103, P2353, DOI 10.1007/s11277-018-5913-0
   Kumar S, 2018, WIRELESS PERS COMMUN, V103, P2435, DOI 10.1007/s11277-018-5923-y
   Lanitis A, 2010, INT J BIOMETRICS, V2, P34, DOI 10.1504/IJBM.2010.030415
   Li PH, 2010, IMAGE VISION COMPUT, V28, P246, DOI 10.1016/j.imavis.2009.04.010
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2016, LECT NOTES COMPUT SC, V9907, P69, DOI 10.1007/978-3-319-46487-9_5
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2002, INT C PATT RECOG, P414, DOI 10.1109/ICPR.2002.1048327
   MacLachlan C, 2002, OPHTHAL PHYSL OPT, V22, P175, DOI 10.1046/j.1475-1313.2002.00023.x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Morrison Patrick J, 2010, ULSTER MED J, V79
   Ng TW, 2010, SIGN PROC SYST ICSPS, V1, P1
   Nkengne A, 2008, J EUR ACAD DERMATOL, V22, P982, DOI 10.1111/j.1468-3083.2008.02698.x
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ortega-Garcia, 2006, SOFTWARE TOOL ACQUIS
   Ortiz Estefan., 2013, IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1, DOI [10.1109/BTAS.2013.6712687, DOI 10.1109/BTAS.2013.6712687]
   Machado CEP, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180330
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Rapaka S., 2018, ASIAN J ENG APPL TEC, V7, P42
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Romer A.S., 1977, The Vertebrate Body, VFifth
   SAID FS, 1972, OPT ACTA, V19, P359, DOI 10.1080/713818582
   Salvi SM, 2006, POSTGRAD MED J, V82, P581, DOI 10.1136/pgmj.2005.040857
   SEITZ R, 1957, Klin Monbl Augenheilkd Augenarztl Fortbild, V131, P48
   Sgroi A., 2013, 2013 INT C BIOM ICB, P1
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   Shekar BH, 2017, INT ARCH PHOTOGRAMM, V42-2, P243, DOI 10.5194/isprs-archives-XLII-2-W4-243-2017
   Shrimal G, 2013, IJLTEMAS, P21
   Sung HH, 2004, INT C PATT RECOG, P857, DOI 10.1109/ICPR.2004.1333907
   Swathi A, 2021, INNOV SYST SOFTW ENG, V17, P29, DOI 10.1007/s11334-020-00382-3
   Swathi A., 2021, INTELLIGENT COMMUNIC, P157
   Tan TN, 2010, IMAGE VISION COMPUT, V28, P223, DOI 10.1016/j.imavis.2009.05.008
   Tanti M, 2017, ARXIV PREPRINT ARXIV
   Thalji Z., 2013, WORLD APPL SCI J, V25, P858, DOI [10.5829/idosi.wasj.2013.25.06.13345, DOI 10.5829/idosi.wasj.2013.25.06.13345]
   Thompson HS, 1979, TOPICS NEURO OPHTHAL, P124
   Trokielewicz M, 2018, ARXIV PREPRINT ARXIV
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zafar MF, 2013, INT BHURBAN C APPL S, P128, DOI 10.1109/IBCAST.2013.6512144
NR 100
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35503
EP 35531
DI 10.1007/s11042-022-13355-4
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000817856400001
DA 2024-07-18
ER

PT J
AU Pham, DT
   Pham, QT
   Nguyen, TT
   Le, TL
   Vu, H
AF Pham, Dinh-Tan
   Pham, Quang-Tien
   Nguyen, Tien-Thanh
   Le, Thi-Lan
   Vu, Hai
TI A lightweight graph convolutional network for skeleton-based action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Graph convolution network; Skeleton data;
   Informative joint selection
AB Human action recognition has been an attractive research topic in recent years due to its wide range of applications. Among existing methods, the Graph Convolutional Network achieves remarkable results by exploring the graph nature of skeleton data in both spatial and temporal domains. Noise from the pose estimation error is an inherent issue that could seriously degrade action recognition performance. Existing graph-based methods mainly focus on improving recognition accuracy, whereas low-complexity models are required for application development on devices with limited computation capacity. In this paper, a lightweight model is proposed by pruning layers, adding Feature Fusion and Preset Joint Subset Selection modules. The proposed model takes advantages of the recent Graph-based convolution networks (GCN) and selecting informative joints. Two graph topologies are defined for the selected joints. Extensive experiments are implemented on public datasets to evaluate the performance of the proposed method. Experimental results show that the method outperforms the baselines on the datasets with serious noise in skeleton data. In contrast, the number of parameters in the proposed method is 5.6 times less than the baseline. The proposed lightweight models therefore offer feasible solutions for developing practical applications.
C1 [Pham, Dinh-Tan] Hanoi Univ Min & Geol, Fac IT, Hanoi, Vietnam.
   [Pham, Quang-Tien; Nguyen, Tien-Thanh; Le, Thi-Lan; Vu, Hai] Hanoi Univ Sci & Technol, Sch Elect & Elect Engn SEEE, Hanoi, Vietnam.
   [Pham, Dinh-Tan; Le, Thi-Lan; Vu, Hai] Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.
C3 Hanoi University of Mining & Geology; Hanoi University of Science &
   Technology (HUST); Hanoi University of Science & Technology (HUST)
RP Vu, H (corresponding author), Hanoi Univ Sci & Technol, Sch Elect & Elect Engn SEEE, Hanoi, Vietnam.; Vu, H (corresponding author), Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.
EM hai.vu@hust.edu.vn
RI Pham, Dinh-Tan/JJF-1335-2023; Vu, Hai/AAI-9419-2020
OI Pham, Dinh-Tan/0000-0003-1366-0617; Vu, Hai/0000-0003-2880-4417; Nguyen,
   Thanh/0000-0001-7578-2789
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2017.315]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2017.315.
CR [Anonymous], 2021, MATPLOTLIB CHOOSING
   Cho K., 2014, ARXIV14061078
   Pham DT, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P61, DOI [10.1109/NICS48868.2019.9023859, 10.1109/nics48868.2019.9023859]
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ghorbel E, 2015, INT CONF IMAG PROC, P61, DOI 10.1109/IPTA.2015.7367097
   Heidari N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3220, DOI 10.1109/ICASSP39728.2021.9413860
   Hussein, 2013, INT JOINT C ART INT
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Le H, 2020, INT CONF IMAG VIS
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Li B, 2017, IEEE INT C COMPUT, P187, DOI 10.1109/CSE-EUC.2017.217
   Li C, 2018, ARXIV 180406055
   Li L, 2018, ARXIVHTTPARXIVORGABS, V1, P3
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2019, ARXIV 191006251
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Pham DT, 2021, IEEE ACCESS
   Pham DT, J SCI TECHNOL, P1
   Ren B, 2020, ARXIV 200205907
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi F, 2021, ARXIV 210707089
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Song YF, 2021, IEEE T CIRC SYST VID, V31, P1915, DOI 10.1109/TCSVT.2020.3015051
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tran TH, 2018, INT C PATT RECOG, P1947, DOI 10.1109/ICPR.2018.8546308
   Nguyen TN, 2018, INT CONF KNOWL SYS, P50, DOI 10.1109/KSE.2018.8573421
   Hoang VN, 2019, 2019 INTERNATIONAL CONFERENCE ON MULTIMEDIA ANALYSIS AND PATTERN RECOGNITION (MAPR), DOI 10.1109/mapr.2019.8743545
   Nguyen VT, 2021, MULTIMED TOOLS APPL, V80, P27757, DOI 10.1007/s11042-021-10866-4
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Xiao RY, 2019, IEEE INT CON MULTI, P1060, DOI 10.1109/ICME.2019.00186
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang ZY, 2019, IEEE T CIRC SYST VID, V29, P2405, DOI 10.1109/TCSVT.2018.2864148
   Zhang HY, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102942
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zou K, 2019, LECT NOTES COMPUT SC, V11901, P676, DOI 10.1007/978-3-030-34120-6_55
NR 49
TC 1
Z9 1
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3055
EP 3079
DI 10.1007/s11042-022-13298-w
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000812603300005
DA 2024-07-18
ER

PT J
AU Guo, WP
   Zhao, XM
   Zhang, SQ
   Pan, XZ
AF Guo, Wenping
   Zhao, Xiaoming
   Zhang, Shiqing
   Pan, Xianzhang
TI Learning inter-class optical flow difference using generative
   adversarial networks for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Generative adversarial networks;
   Convolutional neural networks; Optical flow; Inter-class
ID DATABASE
AB Facial expression recognition is a fine-grained task because different emotions have subtle facial movements. This paper proposes to learn inter-class optical flow difference using generative adversarial networks (GANs) for facial expression recognition. Initially, the proposed method employs a GAN to produce inter-class optical flow images from the difference between the static fully expressive samples and neutral expression samples. Such inter-class optical flow difference is used to highlight the displacement of facial parts between the neutral facial images and fully expressive facial images, which can avoid the disadvantage that the optical flow change between adjacent frames of the same video expression image is not obvious. Then, the proposed method designs four-channel convolutional neural networks (CNNs) to learn high-level optical flow features from the produced inter-class optical flow images, and high-level static appearance features from the fully expressive facial images, respectively. Finally, a decision-level fusion strategy is adopted to implement facial expression classification. The proposed method is validated on two public facial expression databases, BAUM_1a, SAMM and AFEW5.0, demonstrating its promising performance.
C1 [Guo, Wenping; Zhao, Xiaoming; Zhang, Shiqing; Pan, Xianzhang] Taizhou Univ, Inst Intelligent Informat Proc, Taizhou 318000, Zhejiang, Peoples R China.
   [Zhao, Xiaoming] Taizhou Univ, Taizhou Univ Hosp, Taizhou Cent Hosp, Taizhou 318000, Zhejiang, Peoples R China.
C3 Taizhou University; Taizhou University
RP Zhao, XM (corresponding author), Taizhou Univ, Inst Intelligent Informat Proc, Taizhou 318000, Zhejiang, Peoples R China.; Zhao, XM (corresponding author), Taizhou Univ, Taizhou Univ Hosp, Taizhou Cent Hosp, Taizhou 318000, Zhejiang, Peoples R China.
EM guowp@tze.edu.cn; tzxyzxm@163.com; tzczsq@163.com; pxz@tzc.edu.cn
OI Zhao, Xiaoming/0000-0002-4708-4171
FU Humanities and Social Science Project of the Chinese Ministry of
   Education [20YJAZH033]; Key Projects of Zhejiang Province's Educational
   Science Planning [2021SB081]; Zhejiang Provincial Public Welfare Project
   of China [LGF19F020009]; National Natural Science Foundation of China
   [61976149]; Zhejiang Provincial National Science Foundation of China
   [LZ20F020002]; Research Project of Education Department of Zhejiang
   Province [Y202045617]
FX This research was funded by the Humanities and Social Science Project of
   the Chinese Ministry of Education (20YJAZH033), the Key Projects of
   Zhejiang Province's Educational Science Planning (2021SB081), the
   Zhejiang Provincial Public Welfare Project of China (LGF19F020009), the
   National Natural Science Foundation of China (61976149), the Zhejiang
   Provincial National Science Foundation of China (LZ20F020002) and
   Research Project of Education Department of Zhejiang Province
   (Y202045617).
CR Breve B., 2021, P DMSVIVA, P46
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   Calvo MG, 2012, COGNITION, V125, P373, DOI 10.1016/j.cognition.2012.07.021
   Chen JY, 2018, MULTIMED TOOLS APPL, V77, P29871, DOI 10.1007/s11042-018-5909-5
   Clark EA, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00920
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Deriso DM, 2012, LECT NOTES COMPUT SC, V7584, P270, DOI 10.1007/978-3-642-33868-7_27
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Kamarol SKA, 2016, IET IMAGE PROCESS, V10, P534, DOI 10.1049/iet-ipr.2015.0519
   Kayaoglu M, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P519, DOI 10.1145/2818346.2830594
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Kommineni J, 2021, J SUPERCOMPUT, V77, P5019, DOI 10.1007/s11227-020-03468-8
   Li QC, 2021, INFORM FUSION, V65, P58, DOI 10.1016/j.inffus.2020.08.006
   Li QY, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620500061
   Li YT, 2021, IEEE T IMAGE PROCESS, V30, P249, DOI 10.1109/TIP.2020.3035042
   Li YT, 2018, IEEE IMAGE PROC, P3094, DOI 10.1109/ICIP.2018.8451376
   Liang LQ, 2021, IEEE T INF FOREN SEC, V16, P482, DOI 10.1109/TIFS.2020.3007327
   Liu C, 2021, IEEE ACCESS, V9, P18876, DOI 10.1109/ACCESS.2021.3054332
   Liu C, 2020, J ADV COMPUT INTELL, V24, P792
   Liu DZ, 2020, NEUROCOMPUTING, V413, P145, DOI 10.1016/j.neucom.2020.06.062
   Liu Y, 2021, ACTION UNITS CONSTIT
   Liu YC, 2019, IEEE INT CONF AUTOMA, P631, DOI 10.1109/fg.2019.8756583
   Lopez-Fuentes L, 2018, MULTIMED TOOLS APPL, V77, P17069, DOI 10.1007/s11042-017-5276-7
   Miao S, 2019, IEEE ACCESS, V7, P78000, DOI 10.1109/ACCESS.2019.2921220
   Pan H, 2020, MULTIMED TOOLS APPL, V79, P31451, DOI 10.1007/s11042-020-09475-4
   Pan XZ, 2020, IETE TECH REV, V37, P402, DOI 10.1080/02564602.2019.1645620
   Pochedly JT, 2012, EMOTION, V12, P1315, DOI 10.1037/a0027998
   Sadeghi H, 2019, MULTIMED TOOLS APPL, V78, P30335, DOI 10.1007/s11042-019-07863-z
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Verburg M, 2019, IEEE INT CONF AUTOMA, P652
   Wang L, 2019, SIGNAL PROCESS-IMAGE, V78, P246, DOI 10.1016/j.image.2019.07.011
   Wang XB, 2020, AAAI CONF ARTIF INTE, V34, P12241
   Wu C, 2021, IEEJ T ELECTR ELECTR, V16, P98, DOI 10.1002/tee.23272
   Yao AB, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P451, DOI 10.1145/2818346.2830585
   Yap JBH, 2020, PROD PLAN CONTROL, V31, P1061, DOI 10.1080/09537287.2019.1695292
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 42
TC 2
Z9 2
U1 12
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10099
EP 10116
DI 10.1007/s11042-022-13360-7
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000812445100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, SB
   Xia, Y
   You, LH
   Zhang, JJ
AF Wang, Shuangbu
   Xia, Yu
   You, Lihua
   Zhang, Jianjun
TI PDE-based surface reconstruction in automotive styling design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial differential equation; Surface reconstruction; Styling design;
   Feature curve; C-n continuity
ID HAUSDORFF DISTANCE COMPUTATION; PARTIAL-DIFFERENTIAL-EQUATIONS;
   APPROXIMATIONS; GENERATE
AB Surface reconstruction is an important part in automotive styling design. Existing reconstruction methods mainly rely on the proficiency of digital modelers who manually modify the surface shape to approximate the scanned data. Apart from manual modifications, the reconstructed surfaces cannot well reflect the design intent of designers since the feature curves of clay models have not been preserved accurately. In this paper, we propose a partial differential equation (PDE) based surface reconstruction method to analytically generate optimal surfaces with C-n continuity under the constraint of the feature curves. The proposed method accurately preserves automotive feature curves and achieves automatic reconstruction of Class-A surfaces without time-consuming manual work. The effectiveness of the proposed method is demonstrated by a number of experiments that reconstruct main parts of automotive exteriors.
C1 [Wang, Shuangbu] Southwest Jiaotong Univ, Inst Smart City & Intelligent Transportat, Chengdu 611756, Sichuan, Peoples R China.
   [Xia, Yu; You, Lihua; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth BH12 5BB, Dorset, England.
C3 Southwest Jiaotong University; Bournemouth University
RP Xia, Y (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth BH12 5BB, Dorset, England.
EM yxia@bournemouth.ac.uk
FU PDE-GIR project from the European Union [778035]
FX This research is supported by the PDE-GIR project which has received
   funding from the European Union's Horizon 2020 research and innovation
   programme under the Marie Sklodowska-Curie grant agreement No 778035.
CR Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Athanasopoulos M, 2009, ADV ENG SOFTW, V40, P479, DOI 10.1016/j.advengsoft.2008.08.001
   Barton M, 2010, COMPUT AIDED GEOM D, V27, P580, DOI 10.1016/j.cagd.2010.04.004
   BLOOR MIG, 1990, COMPUT AIDED DESIGN, V22, P324, DOI 10.1016/0010-4485(90)90083-O
   BLOOR MIG, 1990, COMPUT AIDED DESIGN, V22, P202, DOI 10.1016/0010-4485(90)90049-I
   Bloor MIG, 2005, COMPUT AIDED GEOM D, V22, P203, DOI 10.1016/j.cagd.2004.08.005
   BLOOR MIG, 1989, COMPUT AIDED DESIGN, V21, P165, DOI 10.1016/0010-4485(89)90071-7
   Bloor MIG, 1996, COMPUT AIDED DESIGN, V28, P145, DOI 10.1016/0010-4485(95)00060-7
   Brown JM, 1998, COMPUT METHOD APPL M, V158, P221, DOI 10.1016/S0045-7825(98)00252-7
   Castro GG, 2008, VISUAL COMPUT, V24, P213, DOI 10.1007/s00371-007-0190-z
   Chang Kuang-Hua., 2014, PRODUCT DESIGN MODEL
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Dey TK, 2012, COMPUT GRAPH FORUM, V31, P1787, DOI 10.1111/j.1467-8659.2012.03183.x
   Digne J, 2014, J MATH IMAGING VIS, V48, P369, DOI 10.1007/s10851-013-0414-y
   Du HX, 2005, GRAPH MODELS, V67, P43, DOI 10.1016/j.gmod.2004.06.002
   Du HX, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P213, DOI 10.1109/PCCGA.2000.883943
   Gálvez A, 2012, INFORM SCIENCES, V182, P56, DOI 10.1016/j.ins.2010.09.031
   Gálvez A, 2012, INFORM SCIENCES, V192, P174, DOI 10.1016/j.ins.2010.11.007
   Glvez A, 2008, INT C COMPUTATIONAL
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   He Y, 2004, GEOMETRIC MODELING AND PROCESSING 2004, PROCEEDINGS, P279
   Hosaka M., 2012, Modeling of Curves and Surfaces in CAD/CAM
   In Kyu Park, 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P312, DOI 10.1109/IM.1999.805361
   Jaguar, 2017, JAG XE SV PROJ 8 SVO
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kim YJ, 2013, COMPUT AIDED DESIGN, V45, P270, DOI 10.1016/j.cad.2012.10.010
   Lim SP, 2014, ARTIF INTELL REV, V42, P59, DOI 10.1007/s10462-012-9329-z
   Lin CY, 1997, COMPUT IND, V34, P73, DOI 10.1016/S0166-3615(96)00082-6
   LOWE TW, 1990, COMPUT AIDED DESIGN, V22, P655, DOI 10.1016/0010-4485(90)90012-2
   MA WY, 1995, COMPUT AIDED DESIGN, V27, P663, DOI 10.1016/0010-4485(94)00018-9
   Media F, 2013, FORDS LANG TAP
   Piegl L., 2012, The NURBS book
   SALOMONS OW, 1993, J MANUF SYST, V12, P113, DOI 10.1016/0278-6125(93)90012-I
   Sheng Y, 2011, MATH COMPUT MODEL, V54, P1536, DOI 10.1016/j.mcm.2011.04.025
   Tovey M., 1997, DESIGN STUD, V18, P5, DOI DOI 10.1016/S0142-694X(96)00006-3
   Tsuchie S, 2021, ENG COMPUT-GERMANY, V37, P211, DOI 10.1007/s00366-019-00817-x
   Tsuchie S, 2017, COMPUT GRAPH-UK, V68, P108, DOI 10.1016/j.cag.2017.08.015
   Ueng WD, 1998, COMPUT AIDED DESIGN, V30, P791, DOI 10.1016/S0010-4485(98)00037-2
   Ugail H, 1999, ACM T GRAPHIC, V18, P195, DOI 10.1145/318009.318078
   Wang SB, 2019, OPTIM ENG, V20, P907, DOI 10.1007/s11081-019-09425-6
   Weber C, 2012, GRAPH MODELS, V74, P335, DOI 10.1016/j.gmod.2012.04.012
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   You LH, 2011, COMPUT AIDED DESIGN, V43, P720, DOI 10.1016/j.cad.2011.01.021
   Zaiping Zhu, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12746), P207, DOI 10.1007/978-3-030-77977-1_16
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang HJ, 2002, COMPUT GRAPH-UK, V26, P89, DOI 10.1016/S0097-8493(01)00160-1
   Zhang JJ, 2004, COMPUT GRAPH FORUM, V23, P311, DOI 10.1111/j.1467-8659.2004.00762.x
   Zhao D., 2009, TRANSFER, V11, P12
NR 50
TC 2
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1185
EP 1202
DI 10.1007/s11042-022-13297-x
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800008
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Zhao, WK
   KinTak, U
   Luo, HB
AF Zhao, WeiKang
   KinTak, U.
   Luo, HuiBin
TI Image representation method based on Gaussian function and non-uniform
   partition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image representation; Image reconstruction; Gaussian function;
   Non-uniform partition; Watermark embedding
ID WATERMARKING
AB Image representation or reconstruction methods are important in digital image processing. Due to different image features happening in different regions, in this work, an image representation algorithm based on Gaussian function and non-uniform partition is proposed to represent the image with different functions in non-uniform regions. That means the pixel values in each region can be approximated by an extension of the Gaussian function after applying the least square approximation. The experimental results prove that the proposed algorithm has better performance than other non-uniform partition algorithms in terms of reconstructed image quality and time complexity. In addition, the partition mesh density can reflect the texture complexity of image regions and help to determine where the watermark can be embedded. Therefore, a novel watermark algorithm based on the proposed non-uniform partition is constructed and tested. The results show that it can embed a big gray watermark into the host image without causing its obvious distortion. This indicates some of the advantages of the proposed image representation algorithm.
C1 [Zhao, WeiKang; KinTak, U.; Luo, HuiBin] Macau Univ Sci & Technol, Fac Innovat Engn, Sch Comp Sci & Engn, Macau, Peoples R China.
C3 Macau University of Science & Technology
RP Zhao, WK (corresponding author), Macau Univ Sci & Technol, Fac Innovat Engn, Sch Comp Sci & Engn, Macau, Peoples R China.
EM zhaowk@126.com; ktu@must.edu.mo; zhbitluo@163.com
OI weikang, zhao/0000-0001-6222-6927
FU Macau University of Science and Technology Foundation [FRG-21-020-FI]
FX This study was funded by Macau University of Science and Technology
   Foundation (Grant numbers FRG-21-020-FI).
CR Bagchi S, 1996, IEEE T CIRCUITS-II, V43, P434, DOI 10.1109/82.502316
   Benouaz T, 1996, COMPUT MATH APPL, V31, P69, DOI 10.1016/0898-1221(96)00032-6
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Brynolfsson J, 2018, SIGNAL PROCESS, V150, P20, DOI 10.1016/j.sigpro.2018.03.022
   Candan Ç, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107256
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Craver S, 2000, LECT NOTES COMPUT SC, V1768, P101
   Dapprich S, 1999, J MOL STRUC-THEOCHEM, V461, P1, DOI 10.1016/S0166-1280(98)00475-8
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Eguchi T, 2003, WATERMARK INFORM EXT
   Gesell G., 2009, J ATMOS OCEAN TECH, V1, P147, DOI [10.1175/1520-0426(1984)0012.0.CO;2, DOI 10.1175/1520-0426(1984)0012.0.CO;2]
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Jabeen D, 2016, CIRC SYST SIGNAL PR, V35, P1783, DOI 10.1007/s00034-015-0138-x
   Kurita M., 1993, Transactions of the Japan Society of Mechanical Engineers. Part C, V59, P1086, DOI [10.1299/kikaic.59.1086, DOI 10.1299/KIKAIC.59.1086]
   Liang Y, 2009, NONUNIFORM V TRANSFO
   Liu XY, 2018, INT C WAVEL ANAL PAT, P238, DOI 10.1109/ICWAPR.2018.8521331
   Makur A, 2008, IEEE T CIRCUITS-I, V55, P2686, DOI 10.1109/TCSI.2008.921023
   Miyazaki A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P506, DOI 10.1109/ICIP.2001.958539
   Nilback W., 1985, An introduction to digital image processing
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Queluz MP, 2002, J ELECTRON IMAGING, V11, P275, DOI 10.1117/1.1455015
   Rao K. R., 1990, Discrete cosine transform. Algorithms, advantages, applications
   Sanjit K.M., 2006, DIGIT SIGNAL PROCESS
   Shen J, 2018, CHIN J LIQ CRYST DIS, V33, P511, DOI 10.3788/YJYXS20183306.0511
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Stankovic S, 2001, IEEE T IMAGE PROCESS, V10, P650, DOI 10.1109/83.913599
   Tak U. Kin, 2009, 2009 International Conference on Information and Automation (ICIA), P995, DOI 10.1109/ICINFA.2009.5205063
   2011, 2010 INT C FUTURE PO
   Wang YJ, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P994
   Wober M, 1998, CODING METHOD APPARA
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
   [余建德 Yu Jiande], 2009, [计算机研究与发展, Journal of Computer Research and Development], V46, P1432
   Yuan XF, 2018, IEEE T IND INFORM, V14, P3235, DOI 10.1109/TII.2018.2809730
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 39
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 839
EP 861
DI 10.1007/s11042-022-13213-3
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809315600002
DA 2024-07-18
ER

PT J
AU Rayani, PK
   Changder, S
AF Rayani, Praveen Kumar
   Changder, Suvamoy
TI Continuous user authentication on smartphone via behavioral biometrics:
   a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smartphone; Entry-point authentication; Potential breaches; Continuous
   authentication; Behavioral biometrics
ID DYNAMICS AUTHENTICATION; ACTIVE AUTHENTICATION; KEYSTROKE DYNAMICS;
   MOBILE DEVICES; FEATURE FUSION; SCHEME; VERIFICATION; RECOGNITION;
   SELECTION; STRATEGY
AB The use of ubiquitous devices is increasing worldwide due to signs of progress in sophisticated hardware technology with cutting-edge features. These features offer most users to store their personal information on the device. One of the most usable and off-the-shelf ubiquitous devices in our daily lives is the smartphone. To protect the stored information, the smartphone is enabled with entry-point authentication. Moreover, existing methods of entry-point authentication are not useful unless access control is vigilantly protected. To overcome these issues, the current trend in user authentication of the smartphone is implicit or continuous authentication. In the coming years, the smartphone is expected to enable with intelligent access control in support of continuous authentication. This article reviews available public datasets in continuous authentication of the smartphone. Then, we delve into unimodal and multimodal aspects of continuous authentication. We review the available literature on both aspects of continuous authentication that describe problems tackled, the methodology used, associated datasets, and approaches used for performance evaluation. At the end of each aspect, we highlight the lessons learned based on the literature. Furthermore, this article also reviews attacks on behavioral biometrics of the smartphone. Finally, this article confers open challenges and potential directions for future exploration that must be addressed. This article helps readers to understand the datasets, existing methods in this field, and fosters to implement new methods without pitfalls.
C1 [Rayani, Praveen Kumar; Changder, Suvamoy] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Rayani, PK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
EM rpk.17cs1106@phd.nitdgp.ac.in; suvamoy.changder@cse.nitdgp.ac.in
RI Rayani, Praveen Kumar/AID-3625-2022
OI Rayani, Praveen Kumar/0000-0001-7622-3620
CR Abate AF, 2019, IEEE T SYST MAN CY-S, V49, P469, DOI 10.1109/TSMC.2017.2698258
   Abuhamad M, 2021, IEEE INTERNET THINGS, V8, P65, DOI 10.1109/JIOT.2020.3020076
   Abuhamad M, 2020, IEEE INTERNET THINGS, V7, P5008, DOI 10.1109/JIOT.2020.2975779
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   Al-Jarrah M.M., 2012, Journal of Emerging Trends in Computing and Information Sciences, V3, P988
   Alghamdi SJ, 2018, ARAB J SCI ENG, V43, P789, DOI 10.1007/s13369-017-2758-x
   Ali Z, 2016, 2016 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2016), P272, DOI 10.1109/SPW.2016.29
   Alzubaidi A, 2016, IEEE COMMUN SURV TUT, V18, P1998, DOI 10.1109/COMST.2016.2537748
   Anderson J. P., 1980, TECHNICAL REPORT
   Andriotis P., 2013, Proceedings of the Sixth ACM Conference on Security and Privacy in Wireless and Mobile Networks, P1, DOI DOI 10.1145/2462096.2462098
   [Anonymous], 2016, MOBISYS
   Antal M, 2015, PROC TECH, V19, P820, DOI 10.1016/j.protcy.2015.02.118
   Antal M, 2015, PATTERN RECOGN LETT, V56, P7, DOI 10.1016/j.patrec.2015.01.011
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Aviv AJ, 2010, 4 USENIX WORKSHOP OF, V10, P1
   Baig AF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175967
   Ben-Hur A, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000173
   Bhattacharjee S, 2018, INT CONF BIOMETR THE
   Bhattarai, 2018, PROC 9 IEEE ANN UBIQ
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Bontrager P, 2018, INT CONF BIOMETR THE
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buriro A, 2019, J INF SECUR APPL, V44, P89, DOI 10.1016/j.jisa.2018.11.008
   Cao H, 2019, IEEE T KNOWL DATA EN, V31, P479, DOI 10.1109/TKDE.2018.2828309
   Centeno MP, 2017, ANN CONF PRIV SECUR, P147, DOI 10.1109/PST.2017.00026
   Cha S, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P313, DOI 10.1145/3052973.3052989
   Cilia D, 2018, IEEE I C CONS ELECT
   Cleary JG, 1995, P 12 INT C MACH LEAR
   Crammer K, 2013, MACH LEARN, V91, P155, DOI 10.1007/s10994-013-5327-x
   crowdsignals, 2016, BUILDING COMMUNITYS
   Darabseh A., 2015, Proceedings of the 2015 ACM International Workshop on International Workshop on Security and Privacy Analytics, V15, P49, DOI [10.1145/2713579, DOI 10.1145/2713579]
   Dee T, 2019, I CONF VLSI DESIGN, P539, DOI 10.1109/VLSID.2019.00125
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Eagle N, 2006, PERS UBIQUIT COMPUT, V10, P255, DOI 10.1007/s00779-005-0046-3
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Feng H, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P343, DOI 10.1145/3117811.3117823
   Ferreira, 2015, SECURACY, DOI [10.1145/2766498.2766506, DOI 10.1145/2766498.2766506]
   Fierrez J, 2018, IEEE T INF FOREN SEC, V13, P2720, DOI 10.1109/TIFS.2018.2833042
   Fierrez-Aguilar J, 2005, PATTERN RECOGN, V38, P1317, DOI 10.1016/j.patcog.2005.01.013
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Galbally J, 2008, INT CONF ACOUST SPEE, P1697, DOI 10.1109/ICASSP.2008.4517955
   Giot R., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P11, DOI 10.1109/IIH-MSP.2012.10
   Giuffrida C, 2014, LECT NOTES COMPUT SC, V8550, P92
   Gunn DJ, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P639, DOI 10.1109/SSCI.2018.8628762
   Gupta A, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P471, DOI 10.1109/SocialCom-PASSAT.2012.60
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Ho J, 2018, APPL INTELL, V48, P1547, DOI 10.1007/s10489-017-1020-2
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hriez, 2019, PROC INT C DATA SCI
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Huang ZJ, 2015, LECT NOTES COMPUT SC, V8957, P207, DOI 10.1007/978-3-319-16745-9_12
   Inguanez F, 2016, IEEE ICCE
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Kang P, 2015, INFORM SCIENCES, V308, P72, DOI 10.1016/j.ins.2014.08.070
   Kayacik H. G., 2014, P 3 WORKSH MOB SEC T, P2014
   Khan H, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P41, DOI 10.1145/3210240.3210317
   Khan WZ, 2013, IEEE COMMUN SURV TUT, V15, P402, DOI 10.1109/SURV.2012.031412.00077
   Killourhy KS, 2009, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN.2009.5270346
   Kudo, 2018, 31 ANN ACM S USER IN
   Kumar R, 2016, INT CONF BIOMETR THE
   Kumar R, 2015, INT CONF BIOMETR THE, DOI 10.1109/EnergyEconomics.2015.7235104
   Lamiche I, 2019, J AMB INTEL HUM COMP, V10, P4417, DOI 10.1007/s12652-018-1123-6
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lee H, 2019, PERVASIVE MOB COMPUT, V54, P45, DOI 10.1016/j.pmcj.2019.02.001
   Lee H, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2567463
   Lee WH, 2017, I C DEPEND SYS NETWO, P297, DOI 10.1109/DSN.2017.24
   Lee WH., 2016, PROC HARDWARE ARCHIT
   Lee YS, 2011, LECT NOTES ARTIF INT, V6678, P460, DOI 10.1007/978-3-642-21219-2_58
   Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd
   Leyfer K, 2019, PROC CONF OPEN INNOV, P228, DOI [10.23919/fruct.2019.8711941, 10.23919/FRUCT.2019.8711941]
   Li FD, 2014, INT J INF SECUR, V13, P229, DOI 10.1007/s10207-013-0209-6
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Li YT, 2018, IEEE ACCESS, V6, P32554, DOI 10.1109/ACCESS.2018.2841347
   Lin CC, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P212, DOI 10.1109/ISBAST.2013.37
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu X, 2012, PROC VLDB ENDOW, V5, P1040, DOI 10.14778/2336664.2336676
   Lu L, 2019, IEEE INFOCOM SER, P775, DOI 10.1109/INFOCOM.2019.8737591
   Maghsoudi J, 2016, EUR INTELL SECUR INF, P184, DOI [10.1109/EISIC.2016.047, 10.1109/EISIC.2016.32]
   Mahbub Upal, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P165, DOI 10.1109/TBIOM.2019.2918307
   Mahbub U, 2016, 2016 IEEE 7TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS MOBILE COMMUNICATION CONFERENCE (UEMCON)
   Mahbub U, 2016, INT CONF BIOMETR THE
   Mahfouz A, 2017, J INF SECUR APPL, V37, P28, DOI 10.1016/j.jisa.2017.10.002
   Malkin, 2017, COMPUT COMMUN, V20, P42
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Martinez-Diaz M, 2016, IEEE T HUM-MACH SYST, V46, P607, DOI 10.1109/THMS.2015.2504101
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   Meng WZ, 2019, IFIP ADV INF COMM TE, V562, P180, DOI 10.1007/978-3-030-22312-0_13
   Meng WZ, 2018, MULTIMED TOOLS APPL, V77, P30167, DOI 10.1007/s11042-018-6094-2
   Meng WZ, 2018, J NETW COMPUT APPL, V117, P1, DOI 10.1016/j.jnca.2018.05.010
   Mirsky, 2016, PROC ACM WORKSHOP AR
   Neverova N, 2016, IEEE ACCESS, V4, P1810, DOI 10.1109/ACCESS.2016.2557846
   Nickel C., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P16, DOI 10.1109/IIH-MSP.2012.11
   Ooi SY, 2019, IEEE SIGNAL PROC LET, V26, P1001, DOI 10.1109/LSP.2019.2916420
   Ooi SY, 2017, SOFT COMPUT, V21, P7039, DOI 10.1007/s00500-016-2242-7
   Orr M J L, 1996, Introduction to radial basis function networksJ
   Park, 2016, PROC INT C RES ADAPT
   Peng G, 2017, IEEE T HUM-MACH SYST, V47, P404, DOI 10.1109/THMS.2016.2623562
   Perera P, 2019, IEEE T INF FOREN SEC, V14, P1240, DOI 10.1109/TIFS.2018.2876748
   Peterson L.E., 2009, Scholarpedia, V4, P1883, DOI [DOI 10.4249/SCHOLARPEDIA.1883, 10.4249/scholarpedia.1883]
   Pozo A, 2017, INT CARN CONF SECU
   Primo A, 2017, P IEEE 8 ANN UB COMP
   Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77, DOI 10.1613/jair.279
   Rahman KA, 2013, IEEE T INF FOREN SEC, V8, P528, DOI 10.1109/TIFS.2013.2244091
   Rennie JD., 2003, P 20 INT C MACHINE L
   Samangouei P, 2015, INT CONF BIOMETR THE
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Serwadda A, 2016, ACM T INFORM SYST SE, V18, DOI 10.1145/2898353
   Serwadda A, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Shankar V, 2019, IEEE ACCESS, V7, P48645, DOI 10.1109/ACCESS.2019.2909536
   SHEN C, 2016, SENSORS-BASEL, V16
   Shen C, 2018, IEEE T INF FOREN SEC, V13, P48, DOI 10.1109/TIFS.2017.2737969
   Shen C, 2016, IEEE T INF FOREN SEC, V11, P498, DOI 10.1109/TIFS.2015.2503258
   Shepard C., 2011, ACM SIGMETRICS Performance Evaluation Review, V38, P15, DOI /10.1145/1925019.1925023
   Shi HB, 2018, IEEE ACCESS, V6, P8376, DOI 10.1109/ACCESS.2018.2808266
   Shi HB, 2018, INFORM SCIENCES, V436, P268, DOI 10.1016/j.ins.2018.01.032
   Shila DM, 2018, IEEE INTERNET THINGS, V5, P4042, DOI 10.1109/JIOT.2018.2851501
   Shixuan Wang, 2019, 2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI). Proceedings, P1623, DOI 10.1109/ICTAI.2019.00236
   Shukla D, 2019, IEEE T INF FOREN SEC, V14, P3086, DOI 10.1109/TIFS.2019.2911171
   Shukla D, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P904, DOI 10.1145/2660267.2660360
   Siegel R, 2012, CA-CANCER J CLIN, V62, P10, DOI 10.3322/caac.20138
   Sitová Z, 2016, IEEE T INF FOREN SEC, V11, P877, DOI 10.1109/TIFS.2015.2506542
   SMIRNOV N, 1948, ANN MATH STAT, V19, P279, DOI 10.1214/aoms/1177730256
   Smith-Creasey M, 2016, ANN CONF PRIV SECUR
   Smith-Creasey M, 2019, INT CONF BIOMETR, DOI [10.23919/PS.2019.8818140, 10.1109/icb45273.2019.8987390]
   Smith-Creasey M, 2019, COMPUT SECUR, V83, P140, DOI 10.1016/j.cose.2019.02.001
   Smith-Creasey M, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P644, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00115
   Smith-Creasey M, 2017, IEEE TRUST, P554, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.284
   Song, 2015, PROC 33 ANN ACM C HU
   Stanciu VD, 2016, CODASPY'16: PROCEEDINGS OF THE SIXTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P105, DOI 10.1145/2857705.2857748
   Stylios I, 2021, INFORM FUSION, V66, P76, DOI 10.1016/j.inffus.2020.08.021
   Suykens JAK, 1999, INT J CIRC THEOR APP, V27, P605, DOI 10.1002/(SICI)1097-007X(199911/12)27:6<605::AID-CTA86>3.0.CO;2-Z
   Tappert CC, 2010, INT J INF SECUR PRIV, V4, P32, DOI 10.4018/jisp.2010010103
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Teh PS, 2011, PATTERN ANAL APPL, V14, P23, DOI 10.1007/s10044-009-0167-9
   Temper M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON SOFTWARE SECURITY AND ASSURANCE (ICSSA), P17, DOI 10.1109/ICSSA.2016.10
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tihelka D, 2016, INT CONF SIGN PROCES, P578, DOI 10.1109/ICSP.2016.7877899
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   WALD A, 1945, ANN MATH STAT, V16, P117, DOI 10.1214/aoms/1177731118
   WU C, 2019, IEEE ICC
   Xu H., 2014, P S US PRIV SEC
   Yang, 2014, PROC 12 ACM C EMBED
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang YF, 2019, AD HOC NETW, V84, P9, DOI 10.1016/j.adhoc.2018.09.015
   Ye GX, 2018, ACM T PRIV SECUR, V21, DOI 10.1145/3230740
   Yoneda K, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P584, DOI 10.1109/UEMCON.2017.8249001
   Yuxin Meng, 2013, Information Security and Cryptology. 8th International Conference, Inscrypt 2012. Revised Selected Papers, P331, DOI 10.1007/978-3-642-38519-3_21
   Zhang, 2015, PROC 11 IEEE INT C W
   Zhu J, 2013, INT CONF COMPUT NETW
NR 154
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1633
EP 1667
DI 10.1007/s11042-022-13245-9
EA JUN 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000808527600002
DA 2024-07-18
ER

PT J
AU Thakur, PS
   Sheorey, T
   Ojha, A
AF Thakur, Poornima Singh
   Sheorey, Tanuja
   Ojha, Aparajita
TI VGG-ICNN: A Lightweight CNN model for crop disease identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop disease identification; Deep learning; Convolutional neural
   network; Classification
ID LEARNING-MODELS; PLANT; CLASSIFICATION; DIAGNOSIS; RECOGNITION; IMAGES
AB Crop diseases cause a substantial loss in the quantum and quality of agricultural production. Regular monitoring may help in early stage disease detection an d thereby reduction in crop loss. An automatic plant disease identification system based on visual symptoms can provide a smart agriculture solution to such problems. Various solutions for plant disease identification have been provided by researchers using image processing, machine learning and deep learning techniques. In this paper a lightweight Convolutional Neural Network 'VGG-ICNN' is introduced for the identification of crop diseases using plant-leaf images. VGG-ICNN consists of around 6 million parameters that are substantially fewer than most of the available high performing deep learning models. The performance of the model is evaluated on five different public datasets covering a large number of crop varieties. These include multiple crop species datasets: PlantVillage and Embrapa with 38 and 93 categories, respectively, and single crop datasets: Apple, Maize, and Rice, each with four, four, and five categories, respectively. Experimental results demonstrate that the method outperforms some of the recent deep learning approaches on crop disease identification, with 99.16% accuracy on the PlantVillage dataset. The model is also shown to perform consistently well on all the five datasets, as compared with some recent lightweight CNN models.
C1 [Thakur, Poornima Singh; Sheorey, Tanuja; Ojha, Aparajita] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482001, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Thakur, PS (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482001, India.
EM poornima@iiitdmj.ac.in; tanush@iiitdmj.ac.in; aojha@iiitdmj.ac.in
OI Ojha, Aparajita/0000-0003-1567-8378; Singh Thakur,
   Poornima/0000-0002-9836-0543
CR Abdalla A, 2019, COMPUT ELECTRON AGR, V162, P1057, DOI 10.1016/j.compag.2019.05.051
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Ashqar BA, 2020, AUG REPOSITORY
   Barbedo J. G. A., 2018, IEEE Latin America Transactions, V16, P1749
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   Brahimi M, 2019, SIG P ALGO ARCH ARR, P111, DOI [10.23919/SPA.2019.8936759, 10.23919/spa.2019.8936759]
   Chen JD, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114514
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Chen JD, 2021, PLANT PATHOL, V70, P630, DOI 10.1111/ppa.13322
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hernández S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106597
   Hughes D, 2020, ARXIV 151108060
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Islam M, 2017, CAN CON EL COMP EN
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur P, 2019, NEURAL COMPUT APPL, V31, P8749, DOI 10.1007/s00521-018-3939-6
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2020, SUSTAIN COMPUT-INFOR, V28
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Li ZB, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105792
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Owomugisha G, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P158, DOI [10.1109/ICMLA.2016.126, 10.1109/ICMLA.2016.0034]
   Picon A, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105093
   Radhakrishnan S, 2020, MATER TODAY-PROC, V33, P682, DOI 10.1016/j.matpr.2020.05.802
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Savary S, 2019, NAT ECOL EVOL, V3, P430, DOI 10.1038/s41559-018-0793-y
   Shruthi U, 2019, INT CONF ADVAN COMPU, P281, DOI [10.1109/icaccs.2019.8728415, 10.1109/ICACCS.2019.8728415]
   Szegedy C., 2015, Scene classification with Inception-7
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Thapa R, 2020, ARXIV 200411958
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Waghmare H, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P519
   Zeng WH, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105341
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
NR 54
TC 49
Z9 51
U1 15
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 497
EP 520
DI 10.1007/s11042-022-13144-z
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318300004
DA 2024-07-18
ER

PT J
AU Dong, QS
   Liu, Y
   Liu, XL
AF Dong, Qiushi
   Liu, Yu
   Liu, Xiaolin
TI Drone sound detection system based on feature result-level fusion using
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drone detection; Sound event detection; Deep learning; Evidence theory
ID EVENT DETECTION; NEURAL-NETWORKS; RADAR
AB Drones have attracted more and more attention due to the convenience and wide applications, and they are playing important roles for both civilian and military. But these also pose threats to human life and invasion to privacy, requiring effective and low-cost detection of drones in important unattended areas. In this paper, we propose the result-level fusion convolutional neural network (CNN) network to detect drones and distinguish whether there are drones in the surrounding environment. Log-Mel spectrogram and Mel frequency cepstral coefficient (MFCC) were used to extract the features of sound signals, and input the two features into the networks separately, then fuse the results from the two networks with evidence theory to obtain the final detection result. The experimental results show that the accuracy of the drone detection based on deep learning method is higher than the machine learning method, the result-level fusion can combine the advantages of different features and increase the accuracy to 94.5%. Furthermore, the results show that the proposed drone sound detection system can achieve effective detection within 50 m.
C1 [Dong, Qiushi; Liu, Yu; Liu, Xiaolin] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Liu, Y (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Peoples R China.
EM yuliu@me.neu.edu.cn
RI Liu, Xiaolin/AAR-1424-2020
OI Liu, Xiaolin/0000-0002-6909-117X
FU National Natural Science Foundation of China [51,875,094, 51,775,085];
   Fundamental Research Funds for the Central Universities [N2003011]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 51,875,094 and 51,775,085) and the Fundamental
   Research Funds for the Central Universities (Grant Nos. N2003011).
CR Anwar MZ, 2019, IEEE T VEH TECHNOL, V68, P2526, DOI 10.1109/TVT.2019.2893615
   Baek S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124226
   Cerutti G, 2020, IEEE J-STSP, V14, P654, DOI 10.1109/JSTSP.2020.2969775
   DEMPSTER AP, 1966, ANN MATH STAT, V37, P355, DOI 10.1214/aoms/1177699517
   Dogru S, 2020, IEEE ROBOT AUTOM LET, V5, P4156, DOI 10.1109/LRA.2020.2990605
   Espinosa R, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107465
   Fu H, 2018, IEEE COMMUN MAG, V56, P112, DOI 10.1109/MCOM.2018.1700424
   Guo JF, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-019-1632-9
   Khan T, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090987
   Kim J, 2020, BUILD ENVIRON, V181, DOI 10.1016/j.buildenv.2020.107092
   Kong QQ, 2020, IEEE-ACM T AUDIO SPE, V28, P2450, DOI 10.1109/TASLP.2020.3014737
   Kong QQ, 2019, IEEE-ACM T AUDIO SPE, V27, P777, DOI 10.1109/TASLP.2019.2895254
   Meng F, 2020, IEEE ACCESS, V8, P155710, DOI 10.1109/ACCESS.2020.3016748
   Musa SA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153332
   Mushtaq Z, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107389
   Park J, 2020, IEEE T MICROW THEORY, V68, P1858, DOI 10.1109/TMTT.2019.2961911
   Nguyen P, 2017, GETMOBILE-MOB COMPU, V21, P30, DOI 10.1145/3191789.3191800
   Rahman S, 2020, IET RADAR SONAR NAV, V14, P653, DOI 10.1049/iet-rsn.2019.0493
   Reineking T., 2014, Belief Functions: Theory and Algorithms
   Siddagangaiah S, 2020, ECOL INDIC, V117, DOI 10.1016/j.ecolind.2020.106559
   Siemiatkowska B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124150
   Su Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071733
   Suman A, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107205
   Uddin Z, 2020, COMPUT COMMUN, V154, P236, DOI 10.1016/j.comcom.2020.02.065
   Vafeiadis A, 2020, ENG APPL ARTIF INTEL, V89, DOI 10.1016/j.engappai.2019.08.020
   Xia XJ, 2020, IEEE T MULTIMEDIA, V22, P569, DOI 10.1109/TMM.2019.2933330
   Zegart A, 2020, J STRATEGIC STUD, V43, P6, DOI 10.1080/01402390.2018.1439747
   Zhu Y., 2019, IEEE ACCESS, VPP, P1
NR 28
TC 8
Z9 8
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 149
EP 171
DI 10.1007/s11042-022-12964-3
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749700001
DA 2024-07-18
ER

PT J
AU Mounika, BR
   Palanisamy, P
   Sekhar, HH
   Khare, A
AF Mounika, B. Reddy
   Palanisamy, P.
   Sekhar, Hotta Himanshu
   Khare, Ashish
TI Content based video retrieval using dynamic textures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pearson correlation coefficient (PCC); Color moments; Keyframes; Dynamic
   textures; LBP-TOP; CBVR
ID KEYFRAME EXTRACTION; IMAGE; FRAMEWORK
AB In recent days, design of smart city applications is attracting several researchers offering improvised services to citizens through efficient management of day to day life activities such as business, safety, public utility, transportation and hospitality etc. In most of the smart city applications video retrieval plays crucial role. Through implementation of video retrieval we can achieve several smart city innovates such as monitoring of traffic or crowd etc. The existing video retrieval system depends on either ontological concepts or training based concepts. Implementation of ontological concepts has shown drawbacks such as miss-assignment of tags to the database videos leads to poor efficiency and also needs huge manual effort for the purpose of onnotation. Training based concepts needs prior knowledge and also takes more time for the purpose of training and to overcome all these drawbacks content based video retrieval systems (CBVR) has been evolved. In most of the existing CBVR systems the principal challenge is semantic gap between the user defined rich semantics and the system defined low level features of the scene. In the present article, we propose an algorithm of CBVR using dynamic textures. Statistical textures with the inclusion of motion of the pattern, change in illumination of the pattern, intrinsic change to the pattern becomes dynamic textures. Dynamic textures are best suited to videos containing moving objects. In this article, LBP-TOP a variant of dynamic texture has been used as a feature for video retrieval. LBP-TOP has the capability of jointly describing motion and appearance features. The LBP-TOP features are invariant to illumination, rotation and local translation. These significant benefits support the use of LBP-TOP in the proposed method. The proposed method uses query video clip, which consists randomly selected ten example frames. The proposed CBVR has three stages offline processing, online processing, a matching & retrieval stage. In offline processing, we extract keyframes of database videos using Pearson Correlation Coefficient (PCC) and Color Moments (CM) and then LBP-TOP feature of keyframes have been extracted and used to represent entire database video. In online processing, we extract LBP-TOP features of query video and then these features will be given as input to matching & retrieval stage where, we calculate euclidean distance between LBP-TOP features of database keyframes and query video frames to retrieve videos with less distance. To prove effectiveness of the proposed method it have been tested on 108 videos of standard traffic dataset which is available publicly and compared with the other state-of-the-art methods, both qualitatively and quantitavely. Quantitative performance evaluation has been carried out using the evaluation parameters: Precision, Recall, Jaccard Index, Accuracy, Specificity and E-measure. Both qualitative and quantitative performance show that the proposed method performed well than the other state-of-the-art methods, and success of the proposed method lies under incorporation of dynamic textures. The proposed algorithm can be used in real-time applications like traffic monitoring. The proposed CBVR system can be used to monitor traffic through feature matching between query scene and the database video. If the query is matched with low traffic video of database then the algorithm displays output as low traffic time. In similar manner, medium traffic or heavy traffic times will be detected by the algorithm.
C1 [Mounika, B. Reddy; Palanisamy, P.; Sekhar, Hotta Himanshu] Natl Inst Technol, Dept Elect & Commun Engn, Tiruchirappalli, India.
   [Khare, Ashish] Univ Allahabad, Dept Elect & Commun Engn, Prayagraj, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; University of Allahabad
RP Palanisamy, P (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Tiruchirappalli, India.
EM mounika@nitt.edu; palan@nitt.edu; sekharanshu25@gmail.com;
   ashishkhare@hotmail.com
RI Khare, Ashish/D-4566-2012
CR Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Aote SS, 2019, MULTIMED TOOLS APPL, V78, P14465, DOI 10.1007/s11042-018-6826-3
   Araujo A, 2018, IEEE T CIRC SYST VID, V28, P1406, DOI 10.1109/TCSVT.2017.2667710
   Bommisetty RM, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S0219467822500188
   Bommisetty RM, 2020, MULTIMEDIA SYST, V26, P267, DOI 10.1007/s00530-019-00642-8
   Chatzigiorgaki M., 2009, Proceedings of the 16th International Conference on Digital Signal Processing, P1
   Dave N, 2020, INT J ENG ADV TECHNO, V9, DOI [10.35940/ijeat.C5264.029320, DOI 10.35940/IJEAT.C5264.029320]
   Fleischman M., 2007, 9 ACM WORKSH MULT IR
   Gornale SS., 2019, INT J IMAG GRAPH SIG, V11, P43, DOI [10.5815/ijigsp.2019.03.06, DOI 10.5815/IJIGSP.2019.03.06]
   Gu LC, 2017, INT J DIGIT CRIME FO, V9, P15, DOI 10.4018/IJDCF.2017100102
   Hou S., 2013, MATH PROBL ENG, V2013, P1
   Khare A, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559105
   Lee D., 2008, CIP GEGEVENS KONINKL
   Li Xirong, 2020, IEEE T MULTIMEDIA
   Liu YS, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7352691
   Loukas C, 2018, COMPUT METH PROG BIO, V165, P13, DOI 10.1016/j.cmpb.2018.07.004
   Lu GL, 2017, MULTIMED TOOLS APPL, V76, P6309, DOI 10.1007/s11042-016-3263-z
   Ma SC, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/3839104
   Memar S, 2013, MULTIMED TOOLS APPL, V64, P77, DOI 10.1007/s11042-011-0848-4
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Bommisetty RM, 2021, MULTIMED TOOLS APPL, V80, P15429, DOI 10.1007/s11042-020-10390-x
   Mounika BR, 2020, 12 INT C MACH VIS IC, V11433
   Mühling M, 2019, INT J DIGIT LIBRARIE, V20, P167, DOI 10.1007/s00799-018-0236-z
   Mühling M, 2017, MULTIMED TOOLS APPL, V76, P22169, DOI 10.1007/s11042-017-4962-9
   Nandini HM, 2020, SHOT BASED KEYFRAME
   Page KR, 2019, ACM-IEEE J CONF DIG, P434, DOI 10.1109/JCDL.2019.00106
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Rui Y., 2004, A unified framework for video summarization, browsing and retrieval
   Sandeep R, 2016, MULTIMED TOOLS APPL, V75, P7779, DOI 10.1007/s11042-015-2695-1
   Shekar BH, 2016, PROCEDIA COMPUT SCI, V89, P828, DOI 10.1016/j.procs.2016.06.068
   Shi Y, 2020, IEEE T MULTIMED, V2
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Thomas SS, 2017, SIGNAL IMAGE VIDEO P, V11, P549, DOI 10.1007/s11760-016-0993-3
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Yang HJ, 2014, IEEE T LEARN TECHNOL, V7, P142, DOI 10.1109/TLT.2014.2307305
   Yang Y, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P183, DOI 10.1109/DICTA.2009.36
   Yue H., 2018, INT J BIG DATA ANAL, V3, P28, DOI [10.4018/IJBDAH.2018070103, DOI 10.4018/IJBDAH.2018070103]
   Zhang CY, 2019, PATTERN RECOGN LETT, V123, P82, DOI 10.1016/j.patrec.2019.03.015
   Zhang LB, 2019, INT J REMOTE SENS, V40, P8270, DOI 10.1080/01431161.2019.1608384
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2006, INT C PATT RECOG, P211
   Zhou J, 2018, PROC SPIE, V10649, DOI 10.1117/12.2303651
   Zhou ZL, 2019, IEEE ACCESS, V7, P100658, DOI 10.1109/ACCESS.2019.2930173
   Zong ZK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P183, DOI 10.1109/ICInfA.2017.8078903
NR 45
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 59
EP 90
DI 10.1007/s11042-022-13086-6
EA JUN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749900004
DA 2024-07-18
ER

PT J
AU Xu, Y
   Zhao, YQ
   Lu, P
AF Xu, Yuan
   Zhao, Yaqin
   Lu, Peng
TI Mixed noise reduction via sparse error constraint representation of high
   frequency image for wildlife image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse error constraint representation; Proximal alternating
   linearization minimization; Zig-Zag sorting; 2D-DCT
AB Wildlife image noise reduction is a difficult and challenging problem since the images are inevitably corrupted by the mixed noise in the complex field environments. Most of the existing denoising methods focused on the noise removal added manually to pure images. However, the noise of wildlife images taken in the field is random mixed noise; thus, the existing noise reduction algorithms are not suitable for the denoising of wildlife images. In this paper, we propose a novel mixed noise reduction method based on sparse error constraint representation for removing the wildlife image noise. Firstly, we use 2D-DCT method to decompose a noisy image into a high frequency image and a low frequency image, and then rank 2D-DCT coefficients based on Zig-zag sorting algorithm. As we know, the high frequency image contains more noise, so the dictionary learning model of high frequency image is established to recover the images corrupted by the mixed noise. The sparse error term describes the error between the sparse coefficients of the original image and those obtained by the error constraint method. And then we utilize the algorithm proximal alternating linearization minimization to solve the objective function due to the nonconvex and non-smooth minimization problem. In order to update the dictionary, we apply the lp- l1- norm term for sparse coding to obtain the optimal solution of sparse coefficients. The experiment results show that the proposed method has good noise reduction results for both the noisy images recorded in the wild and the images artificially corrupted by mixed noise while retain more details of the wildlife objects in the restored images.
C1 [Xu, Yuan; Zhao, Yaqin; Lu, Peng] Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Peoples R China.
C3 Nanjing Forestry University
RP Zhao, YQ (corresponding author), Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Peoples R China.
EM yaqinzhao@163.com
RI Lu, Peng/ACL-2777-2022
OI Zhao, Yaqin/0000-0001-6144-8915
FU National Natural Science Foundation of China [31200496]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant. 31200496.
CR Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9
   Chanu PR, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1057-8
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Djurovic I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0113-x
   Gibran AB., 2021, IEEE GEOSCI REMOTE S, V19, P4018005
   Griffith, 2003, J REGIONALENCE, V44
   Guan JT, 2020, NEUROCOMPUTING, V377, P301, DOI 10.1016/j.neucom.2019.10.054
   Lei T, 2018, MULTIMED TOOLS APPL, V77, P689, DOI 10.1007/s11042-016-4298-x
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Pan H, 2018, IEEE T CYBERNETICS, V48, P2875, DOI 10.1109/TCYB.2017.2751585
   Sumit B., 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500170
   Shibu DS, 2021, INT J IMAG SYST TECH, V31, P2249, DOI 10.1002/ima.22592
   [魏东 Wei Dong], 2016, [应用声学, Journal of Applied Acoustics], V35, P95
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu TT, 2020, IEEE SIGNAL PROC LET, V27, P1635, DOI 10.1109/LSP.2020.3023299
   [徐久成 Xu Jiucheng], 2019, [智能系统学报, CAAI Transactions on Intelligent Systems], V14, P500
   Yu GS, 2010, IEEE IMAGE PROC, P1641, DOI 10.1109/ICIP.2010.5653853
   Zhuang L., 2021, REMOTING SENSING, V13, P1
NR 20
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44045
EP 44058
DI 10.1007/s11042-022-13247-7
EA MAY 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600002
DA 2024-07-18
ER

PT J
AU Cao, P
   Xie, FX
   Zhang, SC
   Zhang, ZP
   Zhang, JF
AF Cao, Ping
   Xie, Fangxin
   Zhang, Shichao
   Zhang, Zuping
   Zhang, Jianfeng
TI MSANet: Multi-scale attention networks for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Convolutional neural network; Multi-scale feature;
   Channel attention; Spatial attention
ID TEXTURE; SCALE
AB The classification of images based on the principles of human vision is a major task in the field of computer vision. It is a common method to use multi-scale information and attention mechanism to obtain better classification performance. The methods based on multi-scale can obtain more accurate feature description by fusing different levels of information, and the methods based on attention can make the deep learning models focus on more valuable information in the image. However, the current methods usually treat the acquisition of multi-scale feature maps and the acquisition of attention weights as two separate steps in sequence. Since human eyes usually use these two methods at the same time when observing objects, we propose a multi-scale attention (MSA) module. The proposed MSA module directly extracts the attention information of different scales from a feature map, that is, the multi-scale and attention methods are simultaneously completed in one step. In the MSA module, we obtain different scales of channel and spatial attention by controlling the size of the convolution kernel for cross-channel and cross-space information interaction. Our module can be easily integrated into different convolutional neural networks to form Multi-scale attention networks (MSANet) architectures. We demonstrate the performance of MSANet on CIFAR-10 and CIFAR-100 data sets. In particular, the accuracy of our ResNet-110 based model on CIFAR-10 is 94.39%. Compared with the benchmark convolution model, our proposed multi-scale attention module can bring a roughly 3% increase in accuracy rate on CIFAR-100. Experimental results show that the proposed multi-scale attention module is superior in image classification.
C1 [Cao, Ping; Xie, Fangxin; Zhang, Shichao; Zhang, Zuping] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Cao, Ping] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Zhang, Jianfeng] Natl Univ Def Technol, Coll Comp Sci, Changsha, Peoples R China.
C3 Central South University; Beijing Jiaotong University; National
   University of Defense Technology - China
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM pingcao@bjtu.edu.cn; xfxjacob@csu.edu.cn; zhangsc@csu.edu.cn;
   zpzhang@csu.edu.cn; jfzhang@nudt.edu.cn
RI Zhang, Shichao/JXW-9650-2024; Zhang, Shichao/AAA-7608-2020
FU National Natural Science Foundation of China [61836016, 61672177]
FX This work was supported in part by the National Natural Science
   Foundation of China (61836016, 61672177).
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Ali A, 2021, MULTIMED TOOLS APPL, P133
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2018, PROC IEEE C COMPUT V
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Banerji S, 2013, NEUROCOMPUTING, V117, P173, DOI 10.1016/j.neucom.2013.02.014
   Bay H., 2006, ECCV, P404417
   BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918
   Bramberger M, 2004, P RTAS 2004 10 IEEE
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen L., 2017, P IEEE C COMPUTER VI
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, 2005 IEEE COMP SOC C, V1
   Durand T, 2017, P IEEE C COMPUTER VI
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gan JZ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P580
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu Jie, 2018, P IEEE C COMP VIS PA
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jaderberg M, 2015, ADV NEUR IN, V28
   Khan A., 2020, ARTIF INTELL REV, V53, P5455, DOI [10.1007/s10462-020-09825-6, DOI 10.1007/s10462-020-09825-6]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H., 2018, P BRIT MACH VIS C
   Li X, 2019, P IEEECVF C COMPUTER
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei Y., 2020, ARXIV PREPRINT ARXIV
   Miao H, 2019, IEEE IJCNN
   Mnih V, 2014, ADV NEURAL INFORM PR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, pS27, DOI 10.1016/j.jag.2009.11.002
   Noi PT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010018
   Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smolensky P, 1986, INFO PROCESSING DYNA
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEE CVF C COMP VI
   Wang F, 2017, P IEEE C COMP VIS PA
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K., 2015, INT C MACHINE LEARNI
   Yan SY, 2018, SIGNAL PROCESS-IMAGE, V61, P73, DOI 10.1016/j.image.2017.11.005
   Yan Z, 2019, IEEE ACCESS, V7, P98005, DOI 10.1109/ACCESS.2019.2929512
   Yang YD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010101
   Zhang CY, 2020, NEUROCOMPUTING, V406, P386, DOI 10.1016/j.neucom.2019.11.119
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhang X, 2018, P IEEE C COMPUTER VI
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Q, 2019, P AAAI C ARTIFICIAL, V33
   Zhao T, 2019, P IEEE C COMPUTER VI
NR 58
TC 3
Z9 3
U1 10
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34325
EP 34344
DI 10.1007/s11042-022-12792-5
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000795177900004
DA 2024-07-18
ER

PT J
AU Kumar, V
   Dhingra, G
   Saxena, N
   Malhotra, R
AF Kumar, Vinay
   Dhingra, Gittaly
   Saxena, Nitin
   Malhotra, Reetu
TI Machine learning based analysis of learner-centric teaching of punjabi
   grammar with multimedia tools in rural indian environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia tools; Machine learning; Traditional teaching methods
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; CLASSIFICATION;
   FRAMEWORK
AB The advent of multimedia and its reach to everyone has made a massive change in life. Multimedia content enhances the learning trend and is playing a pivotal role in making the teaching and learning process more learners centric. In the present manuscript, authors use machine learning methods to find the impact of multimedia led teaching in government schools of Punjab, India. They promote the use of computer-based teaching in Punjabi for teaching the syllabus in schools. The secondary class students of Patiala and Mohali government schools affiliated to Punjab School Education Board are participants of this study. The students are divided in two groups. Twenty two topics of Punjabi grammar syllabus are taught to two student groups separately using different instructional strategies (multimedia presentations and traditional lectures). Achievement test, before and after the teaching, are conducted for all participants. The results support the hypothesis that multimedia does make a difference in the overall learning of the students. The descriptive statistics of achievement score shows the improvement in marks obtained by students after technology driven teaching. The average marks scored by students taught through multimedia system is 52.24% more than taught through traditional method. Nine machine learning models are used to find effectiveness of multimedia-based learning. Results shows that AdaBoost performs well with an accuracy of 99.8% respective to others based on student learning strategies.
C1 [Kumar, Vinay; Saxena, Nitin] Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Dhingra, Gittaly] Plaksha Univ, Sahibzada Ajit Singh Nag, Punjab, India.
   [Malhotra, Reetu] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Chitkara University,
   Punjab
RP Malhotra, R (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM vinay.kumar@thapar.edu; gittaly.dhingra@plaksha.edu.in;
   nitin.saxena@thapar.edu; reetu.malhotra@chitkarauniversity.edu.in
RI MALHOTRA, REETU/AAI-1559-2020
CR Acha J, 2009, BRIT J EDUC TECHNOL, V40, P23, DOI 10.1111/j.1467-8535.2007.00800.x
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], VISUAL DISPLAY QUANT
   [Anonymous], 2004, 670 UC BERK
   Bartlett PL, 2007, J MACH LEARN RES, V8, P2347
   Bartlett RM, 2003, TEACH PSYCHOL, V30, P335, DOI 10.1207/S15328023TOP3004_07
   Breiman, 2000, 577 UC BERK
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chambers JM., 1992, Statistical Models in S
   Crosby M. E., 1995, Journal of Educational Multimedia and Hypermedia, V4, P147
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dey P., 2016, BLENDED LEARNING IMP
   DIEBOLD FX, 1995, J BUS ECON STAT, V13, P253, DOI 10.2307/1392185
   Eisenbeis R.A., 1972, Discriminant analysis and classification procedures
   Embarak O., 2021, PROCED COMP SCI, V191, P445
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Glover KR, 2021, TECHTRENDS, V65, P379, DOI 10.1007/s11528-020-00577-2
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Huang WH, 2006, MULTIMED TOOLS APPL, V30, P205, DOI 10.1007/s11042-006-0024-4
   Iqbal MM, 2019, MULTIMED TOOLS APPL, V78, P3087, DOI 10.1007/s11042-018-5636-y
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jiang LX, 2009, IEEE T KNOWL DATA EN, V21, P1361, DOI 10.1109/TKDE.2008.234
   Jo J, 2016, INFORM TECHNOL MANAG, V17, P43, DOI 10.1007/s10799-015-0222-8
   Kim J, 2000, CHEMOMETR INTELL LAB, V51, P201, DOI 10.1016/S0169-7439(00)00070-8
   Krouska A, 2022, EDUC INF TECHNOL, V27, P229, DOI 10.1007/s10639-021-10672-3
   Kushik N, 2020, INT J INFORM MANAGE, V53, DOI 10.1016/j.ijinfomgt.2016.02.006
   Li EY, 1994, ARTIFICIAL NEURAL NE
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Liu M, 1997, J EDUC COMPUT RES, V16, P145, DOI 10.2190/27AT-YLJ3-3PVV-L0JY
   Malhotra S, 2021, EDUC INF TECHNOL, V26, P2607, DOI 10.1007/s10639-020-10376-0
   Min Liu, 2002, Journal of Interactive Learning Research, V13, P311
   PEA RD, 1991, IEEE COMPUT GRAPH, V11, P58, DOI 10.1109/38.126882
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rish, 2014, EMPIRICAL STUDY NAIV
   Sarkar P, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P314, DOI 10.1109/ISMAR-Adjunct51615.2020.00089
   Seber GA, 2012, Wiley Series in Probability and Statistics
   Soman K., 2009, Machine learning with SVM and other kernel methods
   Unlersen MF., 2016, INT J INTELL SYST AP, V4, P25, DOI [10.18201/ijisae.05552, DOI 10.18201/IJISAE.05552]
   VAPNIK VN, 1964, AUTOMAT REM CONTR+, V25, P103
   Vivekananda G.N., 2021, Aggress. Violent Behav.
   Weng F., 2018, Eurasia Journal of Mathematics, Science and Technology Education, V15, DOI [10.29333/ejmste/100389, DOI 10.29333/EJMSTE/100389]
   Xanthopoulos P., 2013, Robust data mining, P27, DOI [DOI 10.1007/978-0-387-78189-18, DOI 10.1007/978-1-4419-9878-1_4, 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-1-4419-9878-14]
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
   Zhang H., 2021, Aggress. Violent Behav.
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 51
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40775
EP 40792
DI 10.1007/s11042-022-12898-w
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900007
DA 2024-07-18
ER

PT J
AU Wang, QL
   Gao, XG
   Li, XY
   Hu, ZJ
   Wan, KF
AF Wang, Qianglong
   Gao, Xiaoguang
   Li, Xinyu
   Hu, Zijian
   Wan, Kaifang
TI A precise method for RBMs training using phased curricula
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Restricted boltzmann machines; Phased curricula; Improved
   dynamic learning rate
ID BOLTZMANN MACHINES
AB Restricted Boltzmann machines (RBMs) are efficacious undirected neural networks for generating features and reconstructing images. Nevertheless, the classical persistent chain sampling algorithm has the problem of refactoring failure in the early training stage, which significantly limits the feature extraction and application of RBM. In this paper, motivated by the cumulative nature of the curriculum learning, three Phased Gibbs Sampling (PGS) methods are proposed for more efficient feature extraction and reconstruction by training the RBM periodically. Then, to achieve an automatic and exclusive training step, the innovative Improved Dynamic Learning Rate (IDLR) is designed by cooperating with the reconstruction error and the anti-vibration coefficient. Extensive experimental results of MNIST, 20 Newsgroup, Olivetti face, MNORB, and USPS demonstrate the superiority of three PGS-IDLR algorithms in terms of reconstruction error, training time, and classification accuracy. More specifically, the proposed algorithms can improve the classification accuracy by at least 2% and shorten the training time, compared with the state-of-the-art approaches. Moreover, they achieve a better performance in log-likelihood indictor and image reconstruction.
C1 [Wang, Qianglong; Gao, Xiaoguang; Li, Xinyu; Hu, Zijian; Wan, Kaifang] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, QL (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
EM wql1995@mail.nwpu.edu.cn; xggao@nwpu.edu.cn; lxy_2017@mail.nwpu.edu.cn;
   huzijian@mail.nwpu.edu.cn; wankaifang@nwpu.edu.cn
RI GAO, XIAO/JED-3257-2023; YUE, CHENGFANG/KCY-6834-2024; Wan,
   Kaifang/AAL-8395-2020
OI Wang, Qianglong/0000-0001-5018-5013
FU National Natural Science Foundation of China [61573285]; Natural Science
   Foundation of Shaanxi Province [2020JQ-220]
FX The authors are grateful to Professor Gao for the discussions on this
   topic. This study was supported by the National Natural Science
   Foundation of China (Grant no. 61573285) and Natural Science Foundation
   of Shaanxi Province (Grant no. 2020JQ-220).
CR [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Brakel P, 2012, EUR S ART NEUR NETW
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cho K, 2011, P 28 INT C MACH LEAR
   Cho K, 2010, IEEE IJCNN
   Coates A, 2010, INT C ART INT STAT
   Desjardins G, 2010, ADV NEURAL INFORM PR
   EHINTON G, 2006, SCIENCE, V313, P504, DOI DOI 10.1126/SCIENCE.1127647
   EHINTON G, 2002, NEURAL COMPUT, V14, P1771, DOI DOI 10.1162/089976602760128018
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Fakhari A, 2021, MULTIMED TOOLS APPL, V80, P2047, DOI 10.1007/s11042-020-09685-w
   Fatemi M, 2019, MULTIMED TOOLS APPL, V78, P20637, DOI 10.1007/s11042-019-7427-5
   Fischer A., 2011, 5 WORKSH THEOR RAND
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Hinton G, 2009, NIPS
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hongmei W, 2021, MULTIMED TOOLS APPL, V80
   Jiang L., 2015, 20 9 AAAI C ART INT
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014
   Lang K, 1995, P 12 INT C MACH LEAR
   Larochelle H, 2008, MACH LEARN P 25 INT
   Lcun Y, 2004, P 2004 IEEE COMP SOC
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   [李飞 Li Fei], 2017, [自动化学报, Acta Automatica Sinica], V43, P753
   [李飞 Li Fei], 2016, [自动化学报, Acta Automatica Sinica], V42, P931
   Luo LK, 2016, INT CONF COMP SCI ED, P103, DOI 10.1109/ICCSE.2016.7581563
   Medhat F, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P199, DOI 10.1109/ICMLA.2017.0-158
   NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6
   Pawan Kumar M., 2010, NIPS
   Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1
   Sailor HB, 2016, IEEE 24 EUROPEAN SIG
   Salakhutdinov R., 2008, ICML, V25, P872
   Salakhutdinov R., 2009, AISTATS
   Salakhutdinov R, 2015, ANNU REV STAT APPL, V2, P361, DOI 10.1146/annurev-statistics-010814-020120
   SANGER TD, 1994, IEEE T ROBOTIC AUTOM, V10, P323, DOI 10.1109/70.294207
   Schwenk H, 2002, INT CONF ACOUST SPEE, P765
   Spitkovsky V.I., 2010, NAACL
   Swersky K, 2010, RESTR BOLTZM MACH DE
   Tang YC, 2012, PROC CVPR IEEE, P2264, DOI 10.1109/CVPR.2012.6247936
   Tehrani AA, 2021, MULTIMED TOOLS APPL, V80, P6171, DOI 10.1007/s11042-020-10025-1
   Tieleman T, 2008, INT C MACH LEARN
   Tieleman T, 2009, INT C MACH LEARN
   Wang Q, 2020, MATH PROBL ENG
   Wu QH, 2020, MULTIMED TOOLS APPL, V79, P9419, DOI 10.1007/s11042-019-7605-5
   Zhao YP, 2017, NEUROCOMPUTING, V258, P30, DOI 10.1016/j.neucom.2017.01.092
NR 50
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8013
EP 8047
DI 10.1007/s11042-022-12973-2
EA MAY 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000791885300008
DA 2024-07-18
ER

PT J
AU Devi, MD
   Saharia, N
AF Devi, Maibam Debina
   Saharia, Navanath
TI Unsupervised tweets categorization using semantic and statistical
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Social blogging; Semantic similarity; tf-idf;
   DBSCAN
AB Clustering is one of the widely used techniques in information retrieval. This experiment intends to categorize Tweets (based on their content) as representative of social media/user-generated content by exploiting statistical and semantic features. tf-idf, being widespread, is employed in combination with a synonym-based weighting scheme. The output of tf-idf in the form of the weight vector is transferred to the next phase as input, where based on the word synonyms, the system generate another weighted vector. Both vectors are used as a feature for clustering. The synonym-based feature technique adds semantic importance to the formation of the clusters. Using a density-based categorical clustering algorithm (with 8 as minpoints and 1.5 as epsilon), we categorized the Tweets into clusters. Six clusters are formed from 1K Tweets, which are evaluated manually and found cohesive. The Silhouette coefficient score (0.47) is used to validate the clusters.
C1 [Devi, Maibam Debina; Saharia, Navanath] IIIT Senapati, Data Engn Lab, Imphal 795002, Manipur, India.
RP Saharia, N (corresponding author), IIIT Senapati, Data Engn Lab, Imphal 795002, Manipur, India.
EM debina@iiitmanipur.ac.in; nsaharia@iiitmanipur.ac.in
RI Saharia, Navanath/GLQ-8035-2022
OI Saharia, Navanath/0000-0001-8908-9395
FU TEQIP Phase III, NPIU [IIITM/ACA-PhD/2017-18/10]
FX The first author acknowledge the financial supports received from TEQIP
   Phase III, NPIU (Ref. no.: IIITM/ACA-PhD/2017-18/10).
CR Agarwal V., 2015, International Journal of Computer Applications, V131, P30, DOI [DOI 10.5120/IJCA2015907309, https://doi.org/10.5120/ijca2015907309]
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   [Anonymous], 2013, English Letter Frequency Counts: Mayzner Revisited or ETAOIN SRHLDCU
   Arachie C, 2020, AAAI CONF ARTIF INTE, V34, P354
   Bafna P, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P61, DOI 10.1109/ICEEOT.2016.7754750
   Ben Aouicha M, 2016, NEUROCOMPUTING, V216, P816, DOI 10.1016/j.neucom.2016.08.045
   Bradley PS., 1998, SCALING EXPECTATION
   Chen JY, 2020, NEURAL COMPUT APPL, V32, P10809, DOI 10.1007/s00521-018-3442-0
   Clark E, 2011, PROCD SOC BEHV, V27, P2, DOI 10.1016/j.sbspro.2011.10.577
   Cotelo JM, 2016, INFORM FUSION, V31, P54, DOI 10.1016/j.inffus.2016.01.002
   Daouadi KE, 2021, INFORM SYST, V101, DOI 10.1016/j.is.2021.101801
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Devi MD., 2020, International Conference on Machine Learning, Image Processing, Network Security and Data Sciences, P411, DOI 10.1007/978-981-15-6318-8_34
   Dos Santos C., 2014, Coling, P69
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Firdaus Diaz Harizky, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P476, DOI 10.1109/ISRITI51436.2020.9315449
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   JIANQIANG Z, 2018, IEEE ACCESS, V6, P23253, DOI DOI 10.1109/ACCESS.2017.2776930
   Link A-K, 2018, CHALLENGES DBSCAN CL
   Meetei LS, 2021, LANG RESOUR EVAL, V55, P947, DOI 10.1007/s10579-021-09541-9
   Miller G. A., 1958, Information and control, V1, P370, DOI [10.1016/S0019-9958, DOI 10.1016/S0019-9958, 10.1016/S0019-9958(58)90229-8, DOI 10.1016/S0019-9958(58)90229-8]
   Miyamoto S, 2012, IEEE INT CONF FUZZY
   Mojiri MM, 2020, COMPUT INFORM, V39, P1336, DOI 10.31577/cai_2020_6_1336
   Munkova Dasa., 2013, International Conference on ICT Innovations, P67
   O'Connor B., 2010, ICWSM, P384
   Park S, 2016, 2016 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P39, DOI 10.1109/SERA.2016.7516126
   Rosa KD, 2011, P ACM SIGIR WORKSH S, V63
   Ruder S., ARXIV160904747
   Rudrapal D, 2017, P INT C REC ADV NAT, P618, DOI DOI 10.26615/978-954-452-049-6.080
   Saharia N, 2015, 2015 INT C SPEECH TE, P1, DOI [DOI 10.1007/S11356-015-5575-3, 10.1007/s11356-015-5575-3]
   Sahni T, 2017, INT C COMMUNICATION
   Saif H., 2013, Evaluation datasets for twitter sentiment analysis: a survey and a new dataset, the sts-gold
   Singh Thoudam Doren, 2021, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2020, NEHU. Lecture Notes in Networks and Systems (LNNS 170), P45, DOI 10.1007/978-981-33-4084-8_5
   Tang GY, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2262
   Teodorescu H-N, 2015, INT C SPEECH TECHNOL, P18
   Vosoughi S, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1041, DOI 10.1145/2911451.2914762
   Zhao JQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P832, DOI 10.1109/SmartCity.2015.171
   Zhou D, 2015, AAAI C ARTIFICIAL IN, V29
   Zou LY, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2016), P342, DOI 10.1109/ICCCBDA.2016.7529581
NR 40
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9047
EP 9064
DI 10.1007/s11042-022-13042-4
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000791638100004
DA 2024-07-18
ER

PT J
AU Vibhuti
   Jindal, N
   Singh, H
   Rana, PS
AF Vibhuti
   Jindal, Neeru
   Singh, Harpreet
   Rana, Prashant Singh
TI Face mask detection in COVID-19: a strategic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE COVID-19; Face mask detection; Object detection; Classification
ID DETECTION ALGORITHM; NETWORKS; SPREAD
AB With the outbreak of the Coronavirus Disease in 2019, life seemed to be had come to a standstill. To combat the transmission of the virus, World Health Organization (WHO) announced wearing of face mask as an imperative way to limit the spread of the virus. However, manually ensuring whether people are wearing face masks or not in a public area is a cumbersome task. The exigency of monitoring people wearing face masks necessitated building an automatic system. Currently, distinct methods using machine learning and deep learning can be used effectively. In this paper, all the essential requirements for such a model have been reviewed. The need and the structural outline of the proposed model have been discussed extensively, followed by a comprehensive study of various available techniques and their respective comparative performance analysis. Further, the pros and cons of each method have been analyzed in depth. Subsequently, sources to multiple datasets are mentioned. The several software needed for the implementation are also discussed. And discussions have been organized on the various use cases, limitations, and observations for the system, and the conclusion of this paper with several directions for future research.
C1 [Vibhuti; Jindal, Neeru] Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
   [Singh, Harpreet; Rana, Prashant Singh] Thapar Inst Engn & Technol, CSED, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Vibhuti (corresponding author), Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
EM vvibhuti_be17@thapar.edu; neeru.jindal@thapar.edu;
   harpreet.s@thapar.edu; prashant.singh@thapar.edu
RI Rana, Prashant Singh/AAE-1784-2019
OI Rana, Prashant Singh/0000-0002-0142-7925
CR Abdallah ZS., 2017, ENCY MACHINE LEARNIN
   Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   [Anonymous], 2017, J Comput Vis Imaging Syst, DOI 10.15353/vsnl.v3i1.171
   [Anonymous], 2021, Interim Infection Prevention and Control Recommendations for Healthcare Personnel During the Coronavirus Disease 2019 (COVID-19) Pandemic
   Ardabili S, 2020, LECT NOTE NETW SYST, V101, P215, DOI 10.1007/978-3-030-36841-8_21
   Basha C. Z., 2021, EAI Endorsed. Trans. Pervasive Health Technol, V7, DOI [10.4108/eai.8-1-2021.167843, DOI 10.4108/EAI.8-1-2021.167843]
   Benjdira B, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON UNMANNED VEHICLE SYSTEMS-OMAN (UVS), DOI 10.1109/uvs.2019.8658300
   Bhadani AK, 2020, ENG SCI TECHNOLOGY I
   Bhambani K., 2020, 2020 IEEE BANG HUM T, P1, DOI [10.1109/B-HTC50970.2020.9297902, DOI 10.1109/B-HTC50970.2020.9297902]
   Bin Xue, 2020, 2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P474, DOI 10.1109/MLBDBI51377.2020.00100
   Boyko N, 2018, 2018 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P478, DOI 10.1109/DSMP.2018.8478556
   Cao JW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164646
   Cao ZH, 2020, IET IMAGE PROCESS, V14, P4359, DOI 10.1049/iet-ipr.2020.1119
   Chandan G., 2018, 2018 INT C INVENTIVE, P1305
   Chavda C, 2020, ARXIV200907627
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Dai JF, 2016, ADV NEUR IN, V29
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dewani R, 2020, ANAL VIDYA
   Ding Y, 2021, ARXIV210501816
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   Draughon GTS, 2020, IEEE INT SM C CONF, DOI 10.1109/isc251055.2020.9239012
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ghasemi E, 2020, ENG COMPUT-GERMANY, V36, P213, DOI 10.1007/s00366-018-00695-9
   google, About us
   Guo GJ, 2020, NEUROCOMPUTING, V395, P128, DOI 10.1016/j.neucom.2018.02.110
   Gupta Sandeep, 2023, Mater Today Proc, V80, P3714, DOI 10.1016/j.matpr.2021.07.368
   Gupta V, 2021, INT RES J ENG TECHNO, V8
   Hammoudi K, 2020, CMES-COMP MODEL ENG, V124, P1049, DOI 10.32604/cmes.2020.011663
   Harsh Purvi Prajapati, 2018, International Journal of Computer Sciences and Engineering, V6, P74, DOI [DOI 10.26438/IJCSE/V6I10.7478, 10.26438/ijcse/v6i10.7478]
   Henderi, 2020, Journal of Physics: Conference Series, V1641, DOI 10.1088/1742-6596/1641/1/012063
   Houkang Deng, 2021, Journal of Physics: Conference Series, V1757, DOI 10.1088/1742-6596/1757/1/012140
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Hung J, 2018, ARXIV180409548
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Jiang X., 2019, DEEP LEARNING OBJECT, DOI [10.1007/978-981-10-5152-4, DOI 10.1007/978-981-10-5152-4]
   Jiang XB, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070837
   Joshi Aniruddha Srinivas, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P435, DOI 10.1109/CICN49253.2020.9242625
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Kim DY, 2021, MULTIMED TOOLS APPL, V80, P35851, DOI 10.1007/s11042-020-09603-0
   Kim J, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259352
   Kong XJ, 2021, IEEE INTERNET THINGS, V8, P15929, DOI 10.1109/JIOT.2021.3051844
   KOS M, 2019, P 2019 5 INT C COMPU, DOI DOI 10.1145/3323933.3324076
   Ku Hongchang., 2020, Frontiers in Signal Processing, V4, P37
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Li Z., 2017, CORR
   Lin J., 2018, IEEE INT C ACOUSTICS, DOI [10.1109/ICASSP.2018.8461733, DOI 10.1109/ICASSP.2018.8461733]
   Liu GX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072145
   Liu R, 2021, 2021 IEEE 13TH INTERNATIONAL CONFERENCE ON COMPUTER RESEARCH AND DEVELOPMENT (ICCRD 2021), P130, DOI 10.1109/ICCRD51685.2021.9386366
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Lynteris C, 2018, MED ANTHROPOL, V37, P442, DOI 10.1080/01459740.2017.1423072
   Magoo R, 2021, NEURAL COMPUT APPL, V33, P15807, DOI 10.1007/s00521-021-06201-5
   Mahurkar Rutuja R., 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1250, DOI 10.1109/ICESC51422.2021.9533008
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Mohammed T, 2017, SPR PROC BUS ECON, P1, DOI 10.1007/978-3-319-48454-9_1
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nath ND, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103085
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Ning CC, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026312
   Oh C, 2020, 21ST ACM SIGPLAN/SIGBED CONFERENCE ON LANGUAGES, COMPILERS, AND TOOLS FOR EMBEDDED SYSTEMS (LCTES '20), P136, DOI 10.1145/3372799.3394366
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Oumina A., 2020, 2020 IEEE 2 INT C EL, P1, DOI [10.1109/ICECOCS50124.2020.9314511, DOI 10.1109/ICECOCS50124.2020.9314511]
   Pandiyan, 2020, SOCIAL DISTANCE MONI
   Pooja S, 2021, Predictive and Preventive Measures for COVID-19 Pandemic, P293
   Qi R, 2019, IEEE ACCESS, V7, P110740, DOI 10.1109/ACCESS.2019.2934563
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Rahman MM, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172295
   Ramos L, 2020, ARXIV200913743
   Razavi M, 2021, ARXIV210101373
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   REKA S, 2019, WIRELESS PERS COMMUN, DOI DOI 10.1007/S11277-019-06294-1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodriguez Rodriguez Ciro, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P423, DOI 10.1109/CICN49253.2020.9242584
   Sethi S, 2021, CMES-COMP MODEL ENG, V127, P389, DOI 10.32604/cmes.2021.014478
   Sharma S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P192, DOI 10.1109/ICACCCT.2016.7831628
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Somaldo P, 2020, 2020 IEEE 8 R10 HUMA, P1, DOI [10.1109/R10-HTC49770.2020.9357040, DOI 10.1109/R10-HTC49770.2020.9357040]
   Somvanshi M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Soofi A.A., 2017, J. Basic Appl. Sci., V13, P459, DOI [10.6000/1927-5129.2017.13.76, DOI 10.6000/1927-5129.2017.13.76]
   Soviany Petru, 2018, 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC). Proceedings, P209, DOI 10.1109/SYNASC.2018.00041
   Su XP, 2022, MULTIMED TOOLS APPL, V81, P4475, DOI 10.1007/s11042-021-11772-5
   SUFIAN A, 2020, RECENT TRENDS ADV AR, DOI DOI 10.1007/978-3-030-32644-9_36
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Susanto, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON APPLIED ENGINEERING (ICAE), DOI 10.1109/ICAE50557.2020.9350556
   Tang H, 2019, COMPUTERS MAT CONTIN, V61
   Teboulbi S, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/8340779
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Tomè D, 2016, SIGNAL PROCESS-IMAGE, V47, P482, DOI 10.1016/j.image.2016.05.007
   Trabelsi A, 2019, FUZZY SET SYST, V366, P46, DOI 10.1016/j.fss.2018.11.006
   Vijitkunsawat Wuttichai, 2020, 2020 5th International Conference on Information Technology (InCIT), P39, DOI 10.1109/InCIT50588.2020.9310963
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wan SH, 2020, COMPUT NETW, V168, DOI 10.1016/j.comnet.2019.107036
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wang JH, 2019, CHIN CONTR CONF, P8507, DOI [10.23919/chicc.2019.8865157, 10.23919/ChiCC.2019.8865157]
   Wang R., 2019, 2019 INT C COMM INF, DOI [10.1109/CISCE.2019.00127, DOI 10.1109/CISCE.2019.00127]
   Wang Z, 2003, ARXIV09093V2
   Wang ZQ, 2017, CHIN CONTR CONF, P11104, DOI 10.23919/ChiCC.2017.8029130
   Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698
   Wu D, 2020, INT J INFECT DIS, V94, P44, DOI 10.1016/j.ijid.2020.03.004
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   Xu Guo, 2020, Journal of Physics: Conference Series, V1544, DOI 10.1088/1742-6596/1544/1/012146
   Xu M., 2020, INNOVATIVE COMPUTING, DOI [10.1007/978-981-15-5959-4_177, DOI 10.1007/978-981-15-5959-4_177]
   Yadav N, 2017, INT RES J ENG TECHNO, V4
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Yin SL, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00314-2
   Yu JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093263
   Yu P, 2020, J INFECT DIS, V221, P1757, DOI 10.1093/infdis/jiaa077
   Zhang N., 2020, IEEE, DOI [10.1109/iccnea50255.2020.00040, DOI 10.1109/ICCNEA50255.2020.00040]
   Zhang RY, 2020, P NATL ACAD SCI USA, V117, P14857, DOI 10.1073/pnas.2009637117
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhong Z, 2018, SIGNAL IMAGE VIDEO P, V12, P1619, DOI 10.1007/s11760-018-1319-4
   Zidi S, 2018, IEEE SENS J, V18, P340, DOI 10.1109/JSEN.2017.2771226
NR 118
TC 12
Z9 12
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40013
EP 40042
DI 10.1007/s11042-022-12999-6
EA MAY 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791088200004
PM 35528282
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, ZW
   Feng, J
   Zhang, YF
AF Wang, Zhiwen
   Feng, Jing
   Zhang, Yifeng
TI Pedestrian detection in infrared image based on depth transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Transfer learning; SSD; Pedestrian detection
AB Because of the difficulty in feature extraction of infrared pedestrian images, the traditional methods of object detection usually make use of the labor to obtain pedestrian features, which suffer from the low-accuracy problem. With the development and the progress of science and technology, deep learning has gradually stepped into the problem of object detection, and achieved good results. In this paper, aiming at the defects of deep convolutional neural network, such as the high cost on training time and slow convergence, a new algorithm of MoblieNet V2(1.4) + SSD infrared image pedestrian detection based on transfer learning is proposed, which adopts a transfer learning method and the Adam optimization algorithm to accelerate network convergence. For the experiments, we augmented the OUS thermal infrared pedestrian dataset and our solution enjoys a higher mAP of 94.8% on the test dataset. The experimental results show that our proposed method has the characteristics of fast convergence, high detection accuracy and short detection time.
C1 [Wang, Zhiwen] Guangxi Univ Sci & Technol, Sch Comp Sci & Telecommun Engn, Liuzhou 545006, Peoples R China.
   [Feng, Jing; Zhang, Yifeng] Guangxi Univ Sci & Technol, Sch Elect & Informat Engn, Liuzhou 545006, Peoples R China.
   [Feng, Jing] GU, South China Inst Software Engn, Guangzhou 510990, Guangdong, Peoples R China.
C3 Guangxi University of Science & Technology; Guangxi University of
   Science & Technology
RP Wang, ZW (corresponding author), Guangxi Univ Sci & Technol, Sch Comp Sci & Telecommun Engn, Liuzhou 545006, Peoples R China.
EM wzw69@126.com
RI Han, Yang/JVN-5921-2024; Zhang, Yanyan/JFA-9161-2023; wen,
   liang/JNR-7720-2023; wang, zhiwen/JDV-9990-2023; wu,
   yunhui/JGD-6838-2023; XIE, WANYING/JNR-9259-2023; li,
   xinke/JTU-3633-2023; WANG, JIAXUAN/JMP-8599-2023; Zhang,
   Jun/JPK-7723-2023
OI wang, zhiwen/0000-0003-2309-7282
FU National Natural Science Foundation of China [6192007, 61462008,
   61751213, 61866004]; Key projects of Guangxi Natural Science Foundation
   [2018GXNSFDA294001, 2018GXNSFDA281009]; Natural Science Foundation of
   Guangxi [2018GXNSFAA294050, 2017GXNSFAA198365]; 2015 Innovation Team
   Project of Guangxi University of Science and Technology [gxkjdx201504];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS19-04]; Natural Science School-level Project of Software
   Engineering Institute of Guangzhou [ky202108]; Guangxi Postgraduate
   Education Innovation Project [GKYC202106, GKYC202104, YCSW2021320];
   College Students' innovation and Entrepreneurship Project [202110594133,
   202110594134]
FX This research was funded by the National Natural Science Foundation of
   China, grant number 6192007, 61462008, 61751213, 61866004; the Key
   projects of Guangxi Natural Science Foundation, grant number
   2018GXNSFDA294001,2018GXNSFDA281009; the Natural Science Foundation of
   Guangxi, grant number 2018GXNSFAA294050, 2017GXNSFAA198365; 2015
   Innovation Team Project of Guangxi University of Science and Technology,
   grant number gxkjdx201504; Research Fund of Guangxi Key Lab of
   Multi-source Information Mining & Security, grant number MIMS19-04;
   Natural Science School-level Project of Software Engineering Institute
   of Guangzhou, grant number ky202108; Guangxi Postgraduate Education
   Innovation Project, grant number GKYC202106, GKYC202104, YCSW2021320;
   College Students' innovation and Entrepreneurship Project 202110594133,
   202110594134.
CR [Anonymous], 2018, COMPUT APPL
   [常亮 Chang Liang], 2016, [自动化学报, Acta Automatica Sinica], V42, P1300
   [车凯 Che Kai], 2018, [红外技术, Infrared Technology], V40, P578
   Dai JF, 2016, ADV NEUR IN, V29
   Dianwei W., 2018, J XIAN U POSTS TELEC, V23, P48
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jianting S., 2020, J HEILONG JIANG U SC, V30, P442
   Junyu Z., 2017, COMPUT ENG APPL, V53, P34
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Yandong, 2016, Journal of Computer Applications, V36, P2508, DOI 10.11772/j.issn.1001-9081.2016.09.2508
   Liu Xue, 2020, Electronics Optics & Control, V27, P42, DOI 10.3969/j.issn.1671-637X.2020.01.009
   Ming X., 2018, CHIN J IMAGE GRAPH, V23, P1829
   Qi L., 2018, AGR ENG, V8, P31
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Song W., 2019, Indust. Control Comput, V32, P103
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Xudong L., 2017, COMPUT APPL RES, V34, P2881
   Yancheng W., 2018, COMPUT ENG, V44, P196
   Zhihua Z, 2016, MACH LEARN, P121
   Zhihua Z, 2016, MACH LEARN
NR 25
TC 9
Z9 9
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39655
EP 39674
DI 10.1007/s11042-022-13058-w
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789073100003
DA 2024-07-18
ER

PT J
AU Fini, RM
   Mahlouji, M
   Shahidinejad, A
AF Fini, Reza Mohammadian
   Mahlouji, Mahmoud
   Shahidinejad, Ali
TI Performance improvement in face recognition system using optimized Gabor
   filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Evolutionary algorithm; Silhouette value; Virtual sample
   generation; Smote; One-vs-all classification
ID FEATURES; DESCRIPTOR; PCA
AB A biometric method for identifying people is face recognition. In the face recognition process, the key step is to extract the distinctive features of each person's image. One of the most widely used tools for this purpose is the Gabor filter bank. A Gabor filter bank can extract powerful distinguishing features from a face image, but the disadvantage is that it imposes a high computational complexity on the face recognition system. The present paper introduces two new Gabor filter banks, i.e., the Optimal Gabor Filter Bank (OGFB) and the Personal Gabor Filter Bank (PGFB), which can reduce the computational complexity of a face recognition system by more than 7.5 and 30 times, respectively. It also introduces a new feature called Square Region of Face (SRoF) which is as easy to implement as global features, while taking into account the geometric position of facial features, including eyes, nose, and lips. This new feature is resistant to changes of hairstyle, eyebrows shape, and their color, as well as to the covered part of faces especially by different types of Islamic veils. Experiments on benchmark datasets of Caltech, Yale, Feret, and CsetM show that the proposed methods achieve better or competitive classification accuracy compared to several recent face recognition systems.
C1 [Fini, Reza Mohammadian; Shahidinejad, Ali] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
   [Mahlouji, Mahmoud] Islamic Azad Univ, Dept Telecommun, Kashan Branch, Kashan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Mahlouji, M (corresponding author), Islamic Azad Univ, Dept Telecommun, Kashan Branch, Kashan, Iran.
EM mmahlouji@yahoo.com
RI Shahidinejad, Ali/V-5523-2019; Mohammadian Fini, Reza/HLW-0422-2023
OI Shahidinejad, Ali/0000-0003-4856-9119; mohammadian fini,
   reza/0000-0003-4868-3034
CR Abderazek H, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105237
   Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Agrawal Sanjay, 2019, Revue d'Intelligence Artificielle, V33, P111, DOI 10.18280/ria.330205
   Alagarsamy SB, 2022, WIRELESS PERS COMMUN, V124, P1061, DOI 10.1007/s11277-021-09394-z
   Alphonse AS, 2017, EXPERT SYST APPL, V90, P127, DOI 10.1016/j.eswa.2017.08.013
   [Anonymous], 1999, MARKUS WEBER IMAGE D
   [Anonymous], 2003, FERET IMAGE DATABASE
   Bartholomew DJ., 2010, International Encyclopedia of Education, P374, DOI [DOI 10.1016/B978-0-08-044894-7.01358-0, 10.1016/B978-0-08-044894-7.01358-0]
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Beli ILK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030037
   Biswas S, 2020, J KING SAUD UNIV-COM, V32, P718, DOI 10.1016/j.jksuci.2017.10.010
   Cament LA, 2015, PATTERN RECOGN, V48, P3371, DOI 10.1016/j.patcog.2015.05.017
   Chahla C, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550095
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dora L, 2017, ENG APPL ARTIF INTEL, V62, P286, DOI 10.1016/j.engappai.2017.04.011
   Dumitrescu CM, 2019, I C CONTR SYS COMP S, P216, DOI 10.1109/CSCS.2019.00043
   Dumitrescu CM, 2019, STUD INFORM CONTROL, V28, P221, DOI 10.24846/v28i2y201910
   El Khadiri I, 2018, COMPUT VIS IMAGE UND, V169, P14, DOI 10.1016/j.cviu.2018.01.004
   El Merabet Y, 2019, ENG APPL ARTIF INTEL, V78, P158, DOI 10.1016/j.engappai.2018.11.011
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Fini RM, 2022, SIGNAL IMAGE VIDEO P, V16, P1081, DOI 10.1007/s11760-021-02057-3
   Fuentes-Hurtado F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211314
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Han J, 2012, MOR KAUF D, P1
   He F, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-95
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Kamaruzaman F, 2016, PATTERN RECOGN, V53, P102, DOI 10.1016/j.patcog.2015.11.020
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khana S, 2016, APPL SOFT COMPUT, V44
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Krishna S., 2010, BIOMETRICS THEORY ME, P113
   Li CR, 2019, EXPERT SYST APPL, V137, P453, DOI 10.1016/j.eswa.2019.05.034
   Li L, 2016, OPTIK, V127, P7408, DOI 10.1016/j.ijleo.2016.05.105
   Li MJ, 2018, CLUSTER COMPUT, V21, P1117, DOI 10.1007/s10586-017-0806-7
   Lin WY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77264-y
   Masi I, 2019, INT J COMPUT VISION, V127, P642, DOI 10.1007/s11263-019-01178-0
   Masi I, 2019, IEEE T PATTERN ANAL, V41, P379, DOI 10.1109/TPAMI.2018.2792452
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadian Fini R., 2020, J AI DATA MINING, V8, P461
   Mohammed K.M.C., 2015, ADV MODEL ANAL B, V58, P67
   Moussa M, 2018, STUD INFORM CONTROL, V27, P127, DOI 10.24846/v27i1y201813
   Ouarda W, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P89, DOI 10.1109/SOCPAR.2014.7007987
   Ouslimani F, 2019, NEURAL COMPUT APPL, V31, P6393, DOI 10.1007/s00521-018-3462-9
   Park YS, 2016, DEV ENVIRON MODEL, V28, P123, DOI 10.1016/B978-0-444-63623-2.00007-4
   Pawara P, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107528
   Peng CL, 2019, PATTERN RECOGN, V90, P161, DOI 10.1016/j.patcog.2019.01.041
   Perez CA, 2011, PATTERN RECOGN, V44, P951, DOI 10.1016/j.patcog.2010.10.017
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Tong L, 2016, NEUROCOMPUTING, V173, P1386, DOI 10.1016/j.neucom.2015.09.011
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   Xu YP, 2020, SHOCK VIB, V2020, DOI 10.1155/2020/2606178
   Yang X.-S., 2017, Engineering Mathematics with Examples and Applications, P267
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
   Zhou NN, 2018, NEURAL COMPUT APPL, V30, P3791, DOI 10.1007/s00521-017-2963-2
   Zhu N, 2020, IEEE ACCESS, V8, P91303, DOI 10.1109/ACCESS.2020.2994207
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 61
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38375
EP 38408
DI 10.1007/s11042-022-13167-6
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700012
DA 2024-07-18
ER

PT J
AU Huang, YB
   Yuan-Zhang
   Chen, TF
   Yan, SH
   Zhang, QY
AF Huang, Yi-bo
   Yuan-Zhang
   Chen, Teng-Fei
   Yan, Shao-Hui
   Zhang, Qiu-yu
TI Speech BioHashing security authentication algorithm based on CNN
   hyperchaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech content authentication; CNN hyperchaotic map; Biosafety template;
   BioHashing; Tamper detection and location
ID BIOMETRIC TEMPLATE PROTECTION; TRANSFORM; AUDIO
AB The current speech content authentication process directly constructs the extracted biometrics into a binary hashing sequence and stores them in the cloud for hashing matching, so the authentication process is vulnerable to similarity attacks, which may lead to the disclosure of biometrics and hash sequences. In order to solve the above problem, this paper proposes an algorithm that is speech BioHashing security authentication algorithm based on CNN hyperchaotic map. Firstly, the user terminal conducts on linear prediction coefficients (LPC) analysis for the pre-processed speech signal, then extracts the improved Mel frequency cepstral coefficients (MFCC) features to obtains the new feature parameter, and calculates the Euclidean distance of the parameter as the biometric vector. Then, the biometrics and the orthogonal set matrix which is constructed by the improved random Fourier measurement matrix are inner product to form biosafety templates, and the templates are further quantified into BioHashing sequences. Finally, the BioHashing sequences are encrypted by CNN hyperchaotic map encryption algorithm and upload them to the cloud server. The experimental results show that the biosafety template not only provides the safe template for the biometric, but also the encryption algorithm of CNN hyperchaotic map guarantees the safety of the BioHashing sequence. At the same time, the algorithm has better robustness and discrimination, and tamper detection and location can better detect and locate mute attacks and substitution attacks.
C1 [Huang, Yi-bo; Yuan-Zhang; Chen, Teng-Fei; Yan, Shao-Hui] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@nwnu.edu.cn; zy13037100557@163.com; ctf122508@163.com;
   ysh022402@nwnu.edu.cn; zhangqylz@163.com
RI zhang, qiu/GXG-5600-2022
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Science and
   Technology Program of Gansu Province of China [21JR7RA120]
FX Y This work is supported by the National Natural Science Foundation of
   China (No.61862041), Science and Technology Program of Gansu Province of
   China (No.21JR7RA120).
CR Ajish S, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2020.101714
   [Anonymous], 2015, J INF HIDING MULTIME
   Bedad F, 2019, LECT NOTE NETW SYST, V62, P70, DOI 10.1007/978-3-030-04789-4_7
   Chang D, 2020, IEEE T INF FOREN SEC, V15, P3152, DOI 10.1109/TIFS.2020.2983250
   Chen YZ, 2019, SIGNAL PROCESS, V154, P314, DOI 10.1016/j.sigpro.2018.09.013
   Deng MQ, 2020, NEURAL NETWORKS, V130, P22, DOI 10.1016/j.neunet.2020.06.015
   Dong XB, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185997
   Feng YC, 2014, PATTERN RECOGN, V47, P3019, DOI 10.1016/j.patcog.2014.03.003
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Jiang YT, 2019, MULTIMED TOOLS APPL, V78, P30011, DOI 10.1007/s11042-018-6802-y
   Joseph T, 2021, J AMB INTEL HUM COMP, V12, P6141, DOI 10.1007/s12652-020-02184-8
   Kadyan Virender, 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 767), P149, DOI 10.1007/978-981-13-9680-9_12
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Krobba A, 2020, MULTIMED TOOLS APPL, P1
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Kumar S, 2021, COMPUT MATH ORGAN TH, V27, P109, DOI 10.1007/s10588-019-09305-5
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Liu NH, 2019, IEEE T GEOSCI REMOTE, V57, P7849, DOI 10.1109/TGRS.2019.2916792
   Morampudi MK, 2020, MULTIMED TOOLS APPL, V79, P19215, DOI 10.1007/s11042-020-08680-5
   Olanrewaju L, 2020, SIGNAL IMAGE VIDEO P, V14, P847, DOI 10.1007/s11760-019-01609-y
   Oo Z, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0151-2
   Oo ZY, 2018, MULTIMED TOOLS APPL, V77, P18865, DOI 10.1007/s11042-018-5686-1
   Parkavi R, 2018, L N COMPUT VIS BIOME, V28, P652, DOI 10.1007/978-3-319-71767-8_57
   Pawade Dipti, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P233, DOI 10.1007/978-981-13-3600-3_22
   Ponnaian D, 2017, OPTIK, V147, P263, DOI 10.1016/j.ijleo.2017.07.063
   Qiu J, 2019, COMPUT SECUR, V82, P1, DOI 10.1016/j.cose.2018.12.003
   Qiuyu Z., 2018, J HUAZHONG U SCI TEC, V28, P11
   Sandhya M, 2017, SIGNAL PROC SEC TEC, P323, DOI 10.1007/978-3-319-47301-7_14
   Sheela SJ, 2020, SN Comput Sci, V1, P1
   Sonnleitner R, 2016, IEEE-ACM T AUDIO SPE, V24, P409, DOI 10.1109/TASLP.2015.2509248
   Nguyen AT, 2019, ADV INTELL SYST, V935, P723, DOI 10.1007/978-3-030-19063-7_58
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Yadav IC, 2021, DIGIT SIGNAL PROCESS, V109, DOI 10.1016/j.dsp.2020.102922
   Yang JC, 2020, IEEE T INF FOREN SEC, V15, P2160, DOI 10.1109/TIFS.2019.2956589
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang QY, 2020, TURK J ELECTR ENG CO, V28, P2467, DOI 10.3906/elk-1907-94
   Zhao S., 2020, IEEE T SYST MAN CYB, V15, P2160
NR 42
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37953
EP 37979
DI 10.1007/s11042-022-12985-y
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700007
DA 2024-07-18
ER

PT J
AU Akoushideh, A
   Rasoulnejad, SMF
   Shahbahrami, A
AF Akoushideh, Alireza
   Rasoulnejad, Sayed Mohammad Fallah
   Shahbahrami, Asadollah
TI Text localization in digital images using a hybrid method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text localization; Stroke width transform; Local adaptive thresholding;
   Maximally stable extremal regions; Text detection
AB Text localization in digital images includes various applications such as routing in auto-driving, postal services, identifying containers in ports, robotic navigation in urban environments, and so on. Multiple methods such as Stroke Width Transform (SWT), Local Adaptive Thresholding (LAT), and Maximally Stable Extremal Regions (MSER) have already been noticed by many researchers. These methods address specific challenges such as text orientation, font variations, size, and non-uniform illuminations. Additionally, deep methods with high accuracy are not optimal regarding computation time and data required for training. Our research considers the SWT, LAT, and MSER methods as a pre-processing step with some improvement techniques to simultaneously deal with the challenges above and improve the text localization result. Maximally Stable Extremal Regions, multilevel binarization, and non-maximum suppression techniques have been used in our proposed approach. Our proposed approach has reasonable results compared with the none-deep state-of-the-art algorithms and deep learning-based methods on the ICDAR 2013 dataset. Recall, precision, and f-measure are 0.7442, 0.9116, and 0.8195, respectively.
C1 [Akoushideh, Alireza] Tech & Vocat Univ TVU, Guilan Branch, Fac Shahid Chamran, Dept Elect Engn, Rasht, Iran.
   [Rasoulnejad, Sayed Mohammad Fallah] Lahijan Islamic Azad Univ, Dept Comp Sci, Lahijan, Iran.
   [Shahbahrami, Asadollah] Univ Guilan, Fac Engn, Dept Comp Engn, Rasht, Iran.
C3 Islamic Azad University; University of Guilan
RP Akoushideh, A (corresponding author), Tech & Vocat Univ TVU, Guilan Branch, Fac Shahid Chamran, Dept Elect Engn, Rasht, Iran.
EM akushide@tvu.ac.ir
RI Akoushideh, Alireza/K-8143-2019; Shahbahrami, Asadollah/ABD-2432-2020
OI Akoushideh, Alireza/0000-0001-9958-4613; Shahbahrami,
   Asadollah/0000-0002-5195-1688
CR Agrahari Anurag, 2020, Procedia Computer Science, V171, P322, DOI 10.1016/j.procs.2020.04.033
   [Anonymous], 2019, TEXT DETECTION LOCAL, V49
   Ansari GJ, 2018, FUTURE GENER COMP SY, V87, P328, DOI 10.1016/j.future.2018.04.074
   Bandyopadhyay A, 2016, Patent, Patent No. [US9448072B2, 9448072]
   Chen K, 2015, PROC INT CONF DOC, P291, DOI 10.1109/ICDAR.2015.7333770
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Guan LB, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P26, DOI 10.1109/ICIVC.2017.7984452
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khlif W, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P79, DOI 10.1109/DAS.2018.65
   Kumuda, 2015, DETECTION LOCALIZATI, P1
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   Liao MH, 2021, IEEE T PATTERN ANAL, V43, P532, DOI 10.1109/TPAMI.2019.2937086
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2015, PROC INT CONF DOC, P746, DOI 10.1109/ICDAR.2015.7333861
   Pham Van Khien, 2017, [Smart Media Journal, 스마트미디어저널], V6, P32
   Shavitt Y, 2011, IEEE J SEL AREA COMM, V29, P2044, DOI 10.1109/JSAC.2011.111214
   Shores T. S., 2018, Applied linear algebra and matrix analysis, DOI [10.1007/978-3-319-74748-4, DOI 10.1007/978-3-319-74748-4]
   Sun Y, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P826, DOI 10.1109/ICSCSE.2018.00178
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YN, 2018, NEUROCOMPUTING, V295, P46, DOI 10.1016/j.neucom.2017.12.058
   Wu Y, 2017, IEEE I CONF COMP VIS, P5010, DOI 10.1109/ICCV.2017.535
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Ye J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P516
   Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 33
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34047
EP 34066
DI 10.1007/s11042-022-13179-2
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300022
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, HR
   Yu, X
AF Yang, Xu
   Li, Hongru
   Yu, Xia
TI Adaptive heterogeneous comprehensive learning particle swarm
   optimization with history information and dimensional mutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization (PSO); Adaptive inertia weight (AIW);
   Dynamic-opposite learning (DOL); Adaptive dimension mutation (ADM)
ID ALGORITHM; SEARCH
AB In many multimedia systems, optimization problems tend to be multimodal, complex and high-dimensional. Although particle swarm optimization (PSO) algorithm has excellent performance in solving optimization problems, how to avoid premature convergence in complex and multimodal situations is the problem that need to be solved urgently. To overcome this problem, an adaptive heterogeneous comprehensive learning particle swarm optimization with history information and dimensional mutation (AHPSO) is proposed in this paper. In order to keep the population diversity, the whole population is divided into two subpopulations and particles' information and knowledge are mined to provide adaptive strategy in both subpopulations. In exploitation subpopulation, an adaptive inertia weight (AIW) method is proposed according to the particles' historical information. In exploration subpopulation, adaptive dimension mutation strategy (ADM) is introduced to improve the ability of the method to solve multimodal and complex problems in multimedia systems. Meanwhile, in order to increase particle diversity, dynamic-opposite learning (DOL) is used in exploration subpopulation. The exploration subpopulation does not learn from any particles in the exploitation subpopulation, so the information passing between subpopulations is one-way. The diversity in the exploration subpopulation can be maintained even if the exploitation subpopulation converges prematurely. In CEC 2013 test suite, in terms of Friedman test result, compared with traditional two swarm method, the solution accuracy of the proposed AHPSO in this paper is improved by 22.4 percentage points. The performance of AHPSO is compared with 8 peer variants and 8 other evolutionary algorithms on CEC2013 and CEC2017 test suites. Experimental results verify that AHPSO has a remarkable performance in complex and multimodal conditions.
C1 [Yang, Xu; Li, Hongru; Yu, Xia] Northeastern Univ, Informat Sci & Engn, 11 St 3,Wenhua Rd, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Li, HR (corresponding author), Northeastern Univ, Informat Sci & Engn, 11 St 3,Wenhua Rd, Shenyang 110819, Peoples R China.
EM 13998346746@163.com; lihongru@ise.neu.edu.cn; yuxia@ise.neu.edu.cn
OI Yang, Xu/0000-0001-6853-9449
FU National Key R&D Program of China [2019YFF0302203]; National Natural
   Science Foundation of China [61973067]; Open Research Fund from the
   State Key Laboratory of Rolling and Automation, Northeastern University
   [2019RALKFKT004]
FX This work was supported by the National Key R&D Program of China
   (2019YFF0302203), the National Natural Science Foundation of China
   (61973067), and the Open Research Fund from the State Key Laboratory of
   Rolling and Automation, Northeastern University(2019RALKFKT004).
CR Agrawal S, 2019, MULTIMED TOOLS APPL, V78, P9801, DOI 10.1007/s11042-018-6542-z
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Carrasco J, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100665
   Chen K, 2019, EXPERT SYST APPL, V128, P140, DOI 10.1016/j.eswa.2019.03.039
   Chen K, 2018, KNOWL-BASED SYST, V139, P23, DOI 10.1016/j.knosys.2017.10.011
   Chen K, 2018, INFORM SCIENCES, V422, P218, DOI 10.1016/j.ins.2017.09.015
   Chen YG, 2018, ENG APPL ARTIF INTEL, V70, P159, DOI 10.1016/j.engappai.2018.01.009
   Chen YG, 2017, APPL SOFT COMPUT, V61, P314, DOI 10.1016/j.asoc.2017.07.020
   Dhanachandra N, 2020, MULTIMED TOOLS APPL, V79, P18839, DOI 10.1007/s11042-020-08699-8
   Draa A, 2015, APPL SOFT COMPUT, V27, P99, DOI 10.1016/j.asoc.2014.11.003
   Du SY, 2020, MULTIMED TOOLS APPL, V79, P4619, DOI 10.1007/s11042-019-08142-7
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Engelbrecht A. P., 2005, FUNDAMENTALS COMPUTA
   Engin O, 2018, APPL SOFT COMPUT, V72, P166, DOI 10.1016/j.asoc.2018.08.002
   Gong YJ, 2016, IEEE T CYBERNETICS, V46, P2277, DOI 10.1109/TCYB.2015.2475174
   Hosseinabadi AAR, 2019, SOFT COMPUT, V23, P5099, DOI 10.1007/s00500-018-3177-y
   Jain M, 2018, J INTELL FUZZY SYST, V34, P1573, DOI 10.3233/JIFS-169452
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liang JJ, 2005, 2005 IEEE SWARM INTELLIGENCE SYMPOSIUM, P124
   Liang JJ, 2013, PROBLEM DEFINITIONS, DOI [10.1016/j.knosys.2017.10.011, DOI 10.1016/J.KNOSYS.2017.10.011]
   Lim WH, 2014, INFORM SCIENCES, V273, P49, DOI 10.1016/j.ins.2014.03.031
   Lin AP, 2019, SWARM EVOL COMPUT, V44, P571, DOI 10.1016/j.swevo.2018.07.002
   Liu H, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113353
   Lynn N, 2017, APPL SOFT COMPUT, V55, P533, DOI 10.1016/j.asoc.2017.02.007
   Lynn N, 2015, SWARM EVOL COMPUT, V24, P11, DOI 10.1016/j.swevo.2015.05.002
   Mendes R, 2004, IEEE T EVOLUT COMPUT, V8, P204, DOI [10.1109/TEVC.2004.826074, 10.1109/tevc.2004.826074]
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Molaei S, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106768
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Suganthan P, 2016, Problem definitions and evaluation criteria for the CEC 2017 special session and competition on single objective bound constrained real-parameter numerical optimization
   Tanweer MR, 2015, INFORM SCIENCES, V294, P182, DOI 10.1016/j.ins.2014.09.053
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Vitorino LN, 2015, NEUROCOMPUTING, V148, P39, DOI 10.1016/j.neucom.2013.03.076
   Walton S, 2011, CHAOS SOLITON FRACT, V44, P710, DOI 10.1016/j.chaos.2011.06.004
   Wang F, 2018, INFORM SCIENCES, V436, P162, DOI 10.1016/j.ins.2018.01.027
   Wang SH, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105496
   Wei B, 2020, SWARM EVOL COMPUT, V57, DOI 10.1016/j.swevo.2020.100731
   Xia XW, 2020, INFORM SCIENCES, V508, P105, DOI 10.1016/j.ins.2019.08.065
   Xia XW, 2019, SWARM EVOL COMPUT, V44, P349, DOI 10.1016/j.swevo.2018.04.006
   Xia XW, 2018, APPL SOFT COMPUT, V67, P126, DOI 10.1016/j.asoc.2018.02.042
   Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613
NR 47
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9785
EP 9817
DI 10.1007/s11042-022-13044-2
EA APR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000784679300017
DA 2024-07-18
ER

PT J
AU Sivaraman, R
   Vijaykumar, A
   Savarinathan, P
   Jayapalan, A
AF Sivaraman, R.
   Vijaykumar, Ajay
   Savarinathan, Prem
   Jayapalan, Avila
TI Chaos blended cellular automata on fractals: the effective way of
   reconfigurable hardware assisted medical image privacy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FPGA; Cellular automata; LFSR; Hardware security; Chaos; Fractals
AB In more recent times data continues to be generated at a very unprecedented scale. This is a result of the pervasive nature of modern-day digitisation. As such, it is absolutely critical that this data only be accessed by the trusted parties concerned in an effort to maintain the privacy of individuals. One particular type data that could severely compromise the identity and privacy of an individual is 'medical data'. With a focus on medical images, this work proposes a novel 'fractalized' chaos-cellular automata encryption scheme, implemented on Cyclone IV EP2C35F672C6 FPGA, resulting in a hardware-based concurrent security solution. The scheme entails three stages of diffusion, which arise from different mechanisms. In tandem with the diffusion process is the "On the Fly" process of confusion governed by a Linear feedback Shift Register (LFSR), all of which in implemented by applying the nature of fractals. The security architecture occupies 16,351 Logic Elements (LEs) with 230 registers on the target FPGA with the power dissipation of 133.39 mW. Further, the encryption achieves near zero correlation with the average entropy of 15.17156 that ensures the statistical properties. In addition, the security framework requires 12.13 ms to encrypt a 256 x 256 x 16 DICOM image which results in the throughput of 86.44 Mbps. The proposed encryption resists the brute force attack and chosen plain text attack by achieving a very large span of keyspace.
C1 [Sivaraman, R.; Vijaykumar, Ajay; Savarinathan, Prem; Jayapalan, Avila] SASTRA Deemed Univ, Thanjavur 613401, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Jayapalan, A (corresponding author), SASTRA Deemed Univ, Thanjavur 613401, Tamil Nadu, India.
EM avila@ece.sastra.edu
RI R, Sivaraman/ABB-1397-2020
OI R, Sivaraman/0000-0001-5989-4422; Savarinathan,
   Prem/0000-0001-7074-1881; Rethinam, Sivaraman/0000-0001-9292-8524;
   jayapalan, Avila/0000-0002-1370-0423
CR Anandkumar R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P204, DOI 10.1109/I-SMAC.2018.8653652
   [Anonymous], 2016, 2016 AL SADEQ INT C, DOI DOI 10.1109/AIC-MITCSA.2016.7759903
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Banerjee Ayan, 2020, 2020 IEEE 1st International Conference for Convergence in Engineering (ICCE), P458, DOI 10.1109/ICCE50343.2020.9290694
   Benssalah M, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMMUNICATIONS IN NETWORK TECHNOLOGIES (SACONET), P222, DOI 10.1109/SaCoNeT.2018.8585512
   Bhushan K, 2021, J MAXILLOFAC ORAL SU, V20, P409, DOI 10.1007/s12663-020-01449-1
   Das Madhusmita, 2019, 2019 International Conference on Applied Machine Learning (ICAML). Proceedings, P21, DOI 10.1109/ICAML48257.2019.00012
   Datta D, 2017, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON 2017 DEVICES FOR INTEGRATED CIRCUIT (DEVIC), P346, DOI 10.1109/DEVIC.2017.8073966
   Gangadari BR, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P281, DOI 10.1109/ICCSP.2017.8286361
   Garcia-Bosque M, 2016, PROC 12 C PHD RES MI, P1, DOI [10.1109/PRIME.2016.7519519, DOI 10.1109/PRIME.2016.7519519]
   Koppanati RK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1820, DOI 10.1109/ICCONS.2018.8662840
   Kumar R, 2019, ANNU IEEE IND CONF, DOI 10.1109/indicon47234.2019.9030349
   Li XF, 2016, Adv Inform Managemen, P253, DOI 10.1109/IMCEC.2016.7867211
   Mao W, 2017, IEEE INT SYMP CIRC S, P886
   Mizher MAA-JA., 2018, CYBER RESILIENCE C C, P1, DOI [10.1109/CR.2018.8626820, DOI 10.1109/CR.2018.8626820]
   Phan RCW, 2007, COMPUT STAND INTER, V29, P528, DOI 10.1016/j.csi.2006.11.010
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Rajagopalan S, 2019, MULTIMED TOOLS APPL, V78, P10513, DOI 10.1007/s11042-018-6574-4
   Rajagopalan S, 2018, MICROPROCESS MICROSY, V61, P257, DOI 10.1016/j.micpro.2018.06.011
   Ravichandran D, 2019, J SIGNAL PROCESS SYS, V91, P475, DOI 10.1007/s11265-018-1337-z
   Saha Sourav, 2018, 2018 International Conference on Communication and Signal Processing (ICCSP). Proceedings, P0295, DOI 10.1109/ICCSP.2018.8523833
   Sharma D. K., 2021, MATER TODAY-PROC
   Sheikhpour S, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103740
   Vuppala Akshitha, 2020, Procedia Computer Science, V171, P1054, DOI 10.1016/j.procs.2020.04.113
   Wan Chun Qiu, 2019, 2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings, P684, DOI 10.1109/EITCE47263.2019.9094882
   Yi W, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P439, DOI 10.1109/CIS2018.2018.00104
   Yuan Wenting, 2017, 2017 19 INT C TRANSP, P1, DOI [10.1109/ICTON.2017.8025092, DOI 10.1109/ICTON.2017.8025092]
NR 27
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33087
EP 33106
DI 10.1007/s11042-022-13165-8
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800002
PM 35463222
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Cheng, C
   Zhang, YD
AF Zhang, Yong
   Cheng, Cheng
   Zhang, YiDie
TI Multimodal emotion recognition based on manifold learning and
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Emotion recognition; Physiological signals; Manifold
   learning; Convolution neural network
ID FEATURE-SELECTION
AB Multimodal emotion recognition task based on physiological signals is becoming a research hotspot. Traditional methods need to design and extract a series of features from single-channel or multi-channel physiological signals on the basis of extensive domain knowledge. These methods cannot make full use of the relevant information among channels, and the emotion recognition of a single modality cannot fully express the emotional state. This paper proposes a multimodal emotion recognition model based on manifold learning and a convolutional neural network (CNN). The electroencephalograph (EEG) signals are combined with peripheral physiological signals and eye movement signals respectively, the multivariate synchrosqueezing transform (MSST) is used to simulate the joint oscillation structure of multi-channel signals, and then the related feature parameters are extracted and fused into feature vectors. The proposed method finds the corresponding low dimensional embedding features for given high-dimensional features by an improved manifold learning method, which feeds into the deep convolutional neural network (DCNN) model for emotion recognition. We perform extensive four-category experiments on the dimensions of arousal and valence. Results indicate that our proposed model achieves average accuracies of 90.05% and 88.17% on the DEAP and MAHNOB-HCI datasets respectively, which both receive better performances than most of the compared studies, verifying the effectiveness of the model.
C1 [Zhang, Yong] Huzhou Univ, Sch Informat Engn, Huzhou 313000, Peoples R China.
   [Zhang, Yong; Cheng, Cheng; Zhang, YiDie] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
C3 Huzhou University; Liaoning Normal University
RP Zhang, Y (corresponding author), Huzhou Univ, Sch Informat Engn, Huzhou 313000, Peoples R China.; Zhang, Y (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
EM zhyong@lnnu.edu.cn
OI Zhang, Yong/0000-0003-1024-5741
FU National Natural Science Foundation of China [61772252]; Natural Science
   Foundation of Liaoning Province [2019-MS-216]; Scientific Research
   Foundation of the Education Department of Liaoning Province [LJKZ0965]
FX This research was funded by the National Natural Science Foundation of
   China (No. 61772252), the Natural Science Foundation of Liaoning
   Province (No. 2019-MS-216), and the Scientific Research Foundation of
   the Education Department of Liaoning Province (No. LJKZ0965).
CR Ahrabian A, 2015, SIGNAL PROCESS, V106, P331, DOI 10.1016/j.sigpro.2014.08.010
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Campbell Andrew., 2010, Proceedings of the second ACM SIGCOMM workshop on Networking, systems, and applications on mobile handhelds, MobiHeld '10, P3, DOI DOI 10.1145/1851322.1851326
   Chao H, 2020, IEEE ACCESS, V8, P33002, DOI 10.1109/ACCESS.2020.2974009
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Hassouneh A., 2020, Inf. Med. Unlocked, V20, DOI DOI 10.1016/J.IMU.2020.100372
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P8213, DOI 10.1007/s11042-020-10030-4
   Huang HP, 2020, IEEE ACCESS, V8, P3265, DOI 10.1109/ACCESS.2019.2962085
   Huang J., 2017, P 7 ANN WORKSH AUD V, P11
   Huang W, 2021, IEEE GEOSCI REMOTE S, V18, P436, DOI 10.1109/LGRS.2020.2980933
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lee J, 2020, IEEE T IMAGE PROCESS, V29, P6977, DOI 10.1109/TIP.2020.2996086
   Lichtenauer J., 2011, Mahnob-hci-tagging database
   Ma JX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P176, DOI 10.1145/3343031.3350871
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Nakisa B, 2018, EXPERT SYST APPL, V93, P143, DOI 10.1016/j.eswa.2017.09.062
   Pandey P, 2019, LECT NOTE NETW SYST, V56, P41, DOI 10.1007/978-981-13-2354-6_5
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Ren WJ, 2019, NEURAL PROCESS LETT, V50, P1281, DOI 10.1007/s11063-018-9919-0
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Shukla J, 2021, IEEE T AFFECT COMPUT, V12, P857, DOI 10.1109/TAFFC.2019.2901673
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Su YY, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00046
   Taran S, 2019, COMPUT METH PROG BIO, V173, P157, DOI 10.1016/j.cmpb.2019.03.015
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thiam P, 2021, IEEE T AFFECT COMPUT, V12, P743, DOI 10.1109/TAFFC.2019.2892090
   Torres-Valencia C, 2017, J MULTIMODAL USER IN, V11, P9, DOI 10.1007/s12193-016-0222-y
   Wu M., 2020, IEEE T AFFECT COMPUT
   Xing XF, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00037
   Yin Z, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113768
   Zhang G, 2019, C IND ELECT APPL, P596, DOI [10.1109/iciea.2019.8834030, 10.1109/ICIEA.2019.8834030]
   Zhang HL, 2020, IEEE ACCESS, V8, P164130, DOI 10.1109/ACCESS.2020.3021994
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang W, 2020, CHIN CONTR CONF, P6256, DOI 10.23919/CCC50068.2020.9188573
   Zhao X, 2019, ARXIV190205373V1
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
NR 41
TC 17
Z9 18
U1 7
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33253
EP 33268
DI 10.1007/s11042-022-13149-8
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800009
DA 2024-07-18
ER

PT J
AU Urkude, G
   Pandey, M
AF Urkude, Giridhar
   Pandey, Manju
TI Design and Development of Density-Based Effective Document Clustering
   Method Using Ontology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology; Conventional k-means; Density-based clustering; Precision
AB Text document clustering is used to separate a collection of documents into several clusters by allowing the documents in a cluster to be substantially similar. The documents in one cluster are distinct from documents in other clusters. The high-dimensional sparse document term matrix reduces the clustering process efficiency. This study proposes a new way of clustering documents using domain ontology and WordNet ontology. The main objective of this work is to increase cluster output quality. This work aims to investigate and examine the method of selecting feature dimensions to minimize the features of the document name matrix. The sports documents are clustered using conventional K-Means with the dimension reduction features selection process and density-based clustering. A novel approach named ontology-based document clustering is proposed for grouping the text documents. Three critical steps were used in order to develop this technique. The initial step for an ontology-based clustering approach starts with data pre-processing, and the characteristics of the DR method are reduced with the Info-Gain collection. The documents are clustered using two clustering methods: K-Means and Density-Based clustering with DR Feature Selection Process. These methods validate the findings of ontology-based clustering, and this study compared them using the measurement metrics. The second step of this study examines the sports field ontology development and describes the principles and relationship of the terms using sports-related documents. The semantic web rational process is used to test the ontology for validation purposes. An algorithm for the synonym retrieval of the sports domain ontology terms has been proposed and implemented. The retrieved terms from the documents and sport ontology concepts are mapped to the retrieved synonym set words from the WorldNet ontology. The suggested technique is based on synonyms of mapped concepts. The proposed ontology approach employs the reduced feature set in order to clustering the text documents. The results are compared with two traditional approaches on two datasets. The proposed ontology-based clustering approach is found to be effective in clustering the documents with high precision, recall, and accuracy. In addition, this study also compared the different RDF serialization formats for sports ontology.
C1 [Urkude, Giridhar; Pandey, Manju] Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Urkude, G (corresponding author), Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Madhya Pradesh, India.
EM giridharurkude@gmail.com; manjutiwa@gmail.com
RI Urkude, Giridhar/GNP-2348-2022
OI Urkude, Giridhar/0000-0001-6998-6953
CR Abualigah LM, 2018, NOVEL WEIGHTING SCHE
   [Anonymous], 2015, IEEE T POWER SYST
   Balabantaray R, 2015, ABS15020 ARXIV
   Basov N, 2018, EMERGENT MEANING STR
   Dou DJ, 2015, IEEE INT C SEMANT CO, P244, DOI 10.1109/ICOSC.2015.7050814
   Gupta M., 2016, INT RES J ENG TECHNO, V3, P1583
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Jang M, 2017, IMPROVING DOCUMENT C
   Jia CY, 2018, PATTERN RECOGN, V76, P691, DOI 10.1016/j.patcog.2017.09.045
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Khan A, 2015, APPL SOFT COMPUT, V30, P737, DOI 10.1016/j.asoc.2015.01.070
   Li P., 2016, Semantic reasoning on the edge of internet of things
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Narzary J, 2016, METHODOLOGY INCORPOR
   Oladele TO., 2019, INT J ENG RES TECHNO, V12, P2529
   Saad A, 2016, INT J ADV COMPUT SC, V7, P557
   Saiyad NY, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2555, DOI 10.1109/ICEEOT.2016.7755154
   Soliman Sara Saad, 2015, Scientific World Journal, V2015, DOI 10.1155/2015/931258
   Sulthana A.R., 2016, INDIAN J SCI TECHNOL, V9, DOI DOI 10.17485/ijst/2016/v9i15/87328
   Thijs B., 2015, P 1 WORKSH MIN SCI P, V1384, P28
   Wei TT, 2015, EXPERT SYST APPL, V42, P2264, DOI 10.1016/j.eswa.2014.10.023
   Yue L, 2015, DATA KNOWL ENG, V100, P148, DOI 10.1016/j.datak.2015.04.008
   Zheng CT, 2018, NEUROCOMPUTING, V275, P2444, DOI 10.1016/j.neucom.2017.11.019
NR 23
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32995
EP 33015
DI 10.1007/s11042-022-12506-x
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782888500001
DA 2024-07-18
ER

PT J
AU Chandaliya, PK
   Nain, N
AF Chandaliya, Praveen Kumar
   Nain, Neeta
TI PlasticGAN: Holistic generative adversarial network on face plastic and
   aesthetic surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plastics surgery; Generative adversarial networks; Cross-age face
   recognition; Face aging; Face masks
ID AGE; RECOGNITION
AB By embracing Generative Adversarial Networks (GAN), several face-related applications have significantly benefited and achieved unparalleled success. Inspired by the latest advancement in GAN, we propose the PlasticGAN which is a holistic framework for generating images of post-surgery faces as well as reconstruction of faces after surgery completion. This preliminary model works as a helping hand in assisting surgeons, biometric researchers, and practitioners in clinical decision-making by identifying patient cohorts that require building up of confidence with the help of vivid visualizations prior to treatment. It helps them better provide the tentative alternatives by simulating aging patterns. We used the face recognition system for evaluating the same individual with and without masks on surgery face, keeping the current trends in mind such as forensic and security application and recent worldwide COVID scenario. The experimental results suggested that plastic surgery-based synthetic cross-age face recognition (PSBSCAFR) is an arduous research challenge, and state-of-art face recognition systems can negatively affect face recognition performance. This can present a new dimension for the research community.
C1 [Chandaliya, Praveen Kumar; Nain, Neeta] Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Chandaliya, PK (corresponding author), Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
EM 2016rcp9511@mnit.ac.in; nnain.cse@mnit.ac.in
OI Chandaliya, Praveen Kumar/0000-0003-3229-2637
FU Ministry of Electronics and Information Technology (Meity), Government
   of India [4 (13)/2019-ITEA]; NVIDIA Corporation
FX This research is based upon work supported by the Ministry of
   Electronics and Information Technology (Meity), Government of India,
   under Grant No. 4 (13)/2019-ITEA. We gratefully acknowledge the support
   of NVIDIA Corporation with the donation of the TITAN V GPU used for this
   research. We would like to thank Anjali Vijayvargiya for her insight and
   helpful comments.
CR Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chandaliya PK, 2020, BIOSIG 2020, P255
   CHANDALIYA PK, 2019, 12 INT C BIOM ICB, P1
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Chen H, 2019, LECT NOTES COMPUT SC, V11477, P34, DOI 10.1007/978-3-030-17656-3_2
   Deb D, 2021, INT C PATT RECOG, P10540, DOI 10.1109/ICPR48806.2021.9411913
   Deb D, 2018, INT CONF BIOMETR, P225, DOI 10.1109/ICB2018.2018.00042
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Di X, 2018, FACE SYNTHESIS VISUA
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harjani M, 2020, COMPUTER VISION IMAG, P294, DOI [10.1007/978-981-15-4018-927, DOI 10.1007/978-981-15-4018-927]
   Hensel M, 2017, ADV NEUR IN, V30
   Hou XX, 2019, NEUROCOMPUTING, V341, P183, DOI 10.1016/j.neucom.2019.03.013
   Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131
   Gulrajani I, 2017, ADV NEUR IN, V30
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma D. P., 2014, arXiv
   Kushwaha R, 2020, MULTIMED TOOLS APPL, V79, P2671, DOI 10.1007/s11042-019-08149-0
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Makhzani A., 2015, ARXIV
   Maleki D, 2018, IEEE CVPRW
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nappi M, 2016, IMAGE VISION COMPUT, V54, P71, DOI 10.1016/j.imavis.2016.08.012
   Ngan, 2021, ONGOING FACE RECOGNI
   Rathgeb C, 2019, IEEE ACCESS, V7, P152667, DOI 10.1109/ACCESS.2019.2948526
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans, 2016, IMPROVED TECHNIQUES, P29
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Richa, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P72, DOI 10.1109/CVPR.2009.5204287
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Suri S, 2018, INT CONF BIOMETR THE
   Wang, 2018, WL GAO S FACE AGING
   Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011
   Yang L, 2021, MULTIMED TOOLS APPL
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao J, 2019, AAAI CONF ARTIF INTE, P9251
   Zhu HP, 2020, INT CONF ACOUST SPEE, P1963, DOI [10.1109/ICASSP40776.2020.9054553, 10.1109/icassp40776.2020.9054553]
NR 40
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32139
EP 32160
DI 10.1007/s11042-022-12865-5
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600001
PM 35431610
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Liu, XL
   Wu, YF
   Gao, PT
   Ouyang, JL
   Shao, ZH
AF Liu, Xilin
   Wu, Yongfei
   Gao, Peiting
   Ouyang, Junlin
   Shao, Zhuhong
TI Color image watermarking based on singular value decomposition and
   generalized regression neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Color image; Singular value decomposition; GRNN
ID DISCRETE WAVELET TRANSFORM; SCHEME
AB In this paper, a novel singular value decomposition (SVD) based color image watermarking scheme is proposed. Each color image block is processed by converting it into the two dimensional (2D) matrix followed by SVD. Then watermark is embedded into the first singular value of each 2D matrix. The original singular value information is generalized by taking advantage of nonlinear map ability of generalized regression neural network (GRNN). Finally, watermark can be recovered using the modified singular value and the generalized neural network model. Without directly providing the original singular value information at the extraction stage, the proposed algorithm can reduce the risk of cracking original image. Moreover, watermark invisibility and robustness of the proposed watermarking scheme is achieved by adaptively selecting the embedding strength of each image block. Experimental results show that the proposed algorithm is reliable and robust to most common attacks, such as filtering, JPEG compression.
C1 [Liu, Xilin; Wu, Yongfei; Gao, Peiting] Taiyuan Univ Technol, Coll Data Sci, Taiyuan, Shanxi, Peoples R China.
   [Ouyang, Junlin] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan, Peoples R China.
   [Shao, Zhuhong] Capital Normal Univ, Coll Informat Engn, Beijing, Peoples R China.
C3 Taiyuan University of Technology; Hunan University of Science &
   Technology; Capital Normal University
RP Liu, XL (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Taiyuan, Shanxi, Peoples R China.
EM xilinliu168@163.com
RI Shao, Zhuhong/AAD-4129-2022; Liu, Xilin/AFQ-1082-2022
OI Liu, Xilin/0000-0002-1136-6783
FU National Natural Science Foundation of China [61901292]; Project of
   Beijing Excellent Talents [2016000020124G088]; Beijing Municipal
   Education Research Plan Project [SQKM201810028018]; Fundamental Research
   Program of Shanxi Province, China [202103021224057]; Natural Science
   Foundation of Shanxi Province, China [201801D221186, 201901D211080];
   Scientific and Technological Innovation Programs of Higher Education
   Institutions in Shanxi [2019 L0145]; School Foundation of Taiyuan
   University of Technology [2017QN11, 2017QN12]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61901292, Project of Beijing Excellent Talents
   (No.2016000020124G088), Beijing Municipal Education Research Plan
   Project (SQKM201810028018), Project supported by Fundamental Research
   Program of Shanxi Province, China (202103021224057), the Natural Science
   Foundation of Shanxi Province, China (Nos. 201801D221186, and
   201901D211080), Scientific and Technological Innovation Programs of
   Higher Education Institutions in Shanxi (No. 2019 L0145), and School
   Foundation of Taiyuan University of Technology (Nos. 2017QN11 and
   2017QN12).
CR Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Bas P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P521
   Chen BJ, 2018, MULTIMED TOOLS APPL, V77, P20809, DOI 10.1007/s11042-017-5511-2
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Cigizoglu HK, 2006, ADV ENG SOFTW, V37, P63, DOI 10.1016/j.advengsoft.2005.05.002
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fernández-Gámez MA, 2016, EXPERT SYST APPL, V46, P69, DOI 10.1016/j.eswa.2015.10.028
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Ghazy RA, 2015, INT J ELECTRON, V102, P1091, DOI 10.1080/00207217.2014.963892
   Goulermas JY, 2007, IEEE T NEURAL NETWOR, V18, P1683, DOI 10.1109/TNN.2007.902730
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Hu R, 2017, NEUROCOMPUTING, V221, P24, DOI 10.1016/j.neucom.2016.09.027
   Hua KL, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0162-1
   Huang HN, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0073-6
   Jiao SM, 2019, OPT LASER TECHNOL, V109, P370, DOI 10.1016/j.optlastec.2018.08.011
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei BY, 2014, NONLINEAR DYNAM, V78, P2897, DOI 10.1007/s11071-014-1634-4
   Li B, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114232
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha K, 2016, ADV ENG SOFTW, V93, P44, DOI 10.1016/j.advengsoft.2015.12.006
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Pei SC, 2010, IEEE INT CON MULTI, P122, DOI 10.1109/ICME.2010.5583883
   Pei SC, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P273, DOI 10.1109/ICVGIP.2008.99
   Rui H, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115785
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Savelonas MA, 2010, SIGNAL PROCESS, V90, P2521, DOI 10.1016/j.sigpro.2010.02.021
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Sun L, 2018, NEURAL COMPUT APPL, V30, P2425, DOI 10.1007/s00521-016-2788-4
   Sun YA, 2022, MULTIMED TOOLS APPL, V81, P6091, DOI 10.1007/s11042-021-11815-x
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang F, 2009, SPRINGERLINK ONLINE
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wu YD, 2005, IEEE T MULTIMEDIA, V7, P624, DOI 10.1109/TMM.2005.846774
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhu T, 2022, J SUPERCOMPUT, V78, P222, DOI 10.1007/s11227-021-03886-2
NR 44
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32073
EP 32091
DI 10.1007/s11042-022-12990-1
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779973300005
DA 2024-07-18
ER

PT J
AU Pourhashemi, R
   Mahmoudzadeh, E
AF Pourhashemi, R.
   Mahmoudzadeh, E.
TI Supervised anomaly detection by convolutional sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Supervised learning; Convolutional sparse
   representation; Texture
AB Anomalies are known as patterns which are not conforming expected structures; therefore, they must be detected to inhibit future hazards. A common method for defect detection in images is background modeling in which characteristics of normal structures are captured and employed for detecting anomalous regions. In this paper, we utilize convolutional sparse representation method for capturing normal structures and feature extractions. Indeed, normal patterns are recorded as atoms of a dictionary in the phase of dictionary learning. Then for abnormality detection, new images are divided into patches, which encompass normal and/ or abnormal structures, and afterwards they are encoded into coefficient maps with respect to the learned dictionary atoms, in the phase of sparse coding technique. Subsequently, coefficient maps are utilized for the purpose of feature extraction and finally, anomaly detection will be done using supervised learning approaches. Simulation results demonstrate remarkable capabilities of the proposed approach. It is worth mentioning that the presented approach leads to higher True Positive Rate (TPR) and lower False Positive Rate (FPR) up to 0.95 and 0.005 respectively in comparison with reviewed methods.
C1 [Pourhashemi, R.; Mahmoudzadeh, E.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
C3 Isfahan University of Technology
RP Mahmoudzadeh, E (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
EM r.pourhashemi@alumni.iut.ac.ir; mahmoudzadeh@iut.ac.ir
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Agrawal S, 2015, PROCEDIA COMPUT SCI, V60, P708, DOI 10.1016/j.procs.2015.08.220
   AIGER D, 2010, PROC CVPR IEEE, P295, DOI DOI 10.1109/CVPR.2010.5540198
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Boracchi G, 2014, 2014 IEEE SYMPOSIUM ON INTELLIGENT EMBEDDED SYSTEMS (IES), P47, DOI 10.1109/INTELES.2014.7008985
   Brodatz P., 1981, TEXTURES PHOTOGRAPHI
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Carrera D, 2015, IEEE IJCNN
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Davy A, 2018, IEEE IMAGE PROC, P1058, DOI 10.1109/ICIP.2018.8451059
   Ehret T, 2019, J MATH IMAGING VIS, V61, P710, DOI 10.1007/s10851-019-00885-0
   Galerne B, 2011, IMAGE PROCESS ON LIN, V1, P213, DOI 10.5201/ipol.2011.ggm_rpn
   Gao D., 2008, Advances in Neural Information Processing Systems 20, P497
   Grosjean B, 2009, J MATH IMAGING VIS, V33, P313, DOI 10.1007/s10851-008-0111-4
   Li Y., 2013, Advances in Artificial Intell, V7884, P352, DOI DOI 10.1007/978-3-642-38457-8_38
   Mishne Gal, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2823, DOI 10.1109/ICASSP.2014.6854115
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Wohlberg B, 2017, SPORCO PYTHON PACKAG
   Wohlberg B, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854992
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zontak M, 2010, MACH VISION APPL, V21, P129, DOI 10.1007/s00138-008-0146-y
NR 23
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31493
EP 31508
DI 10.1007/s11042-022-13020-w
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336100005
DA 2024-07-18
ER

PT J
AU Jiang, YF
   Yang, F
   Bian, ZX
   Lu, CS
   Xia, SY
AF Jiang, Yefan
   Yang, Fan
   Bian, Zhangxing
   Lu, Changsheng
   Xia, Siyu
TI Mask removal : Face inpainting via attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Mask removal; Face attributes; GAN
AB Due to the outbreak of the COVID-19 pandemic, wearing masks in public areas has become an effective way to slow the spread of disease. However, it also brings some challenges to applications in daily life as half of the face is occluded. Therefore, the idea of removing masks by face inpainting appeared. Face inpainting has achieved promising performance but always fails to guarantee high-fidelity. In this paper, we present a novel mask removal inpainting network based on face attributes known in advance including nose, chubby, makeup, gender, mouth, beard and young, aiming to ensure the repaired face image is closer to ground truth. To achieve this, a dual pipeline network based on GANs has been proposed, one of which is a reconstructive path used in training that utilizes missing regions in ground truth to get prior distribution, while the other is a generative path for predicting information in the masked region. To establish the process of mask removal, we build a synthetic facial occlusion that mimics the real mask. Experiments show that our method not only generates faces more similarly aligned with real attributes, but also ensures semantic and structural rationality compared with state-of-the-art methods.
C1 [Jiang, Yefan; Xia, Siyu] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
   [Yang, Fan] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing, Peoples R China.
   [Bian, Zhangxing] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
   [Lu, Changsheng] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT, Australia.
C3 Southeast University - China; Nanjing University of Posts &
   Telecommunications; University of Michigan System; University of
   Michigan; Australian National University
RP Xia, SY (corresponding author), Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Peoples R China.
EM xsy@seu.edu.cn
RI AVCI, Meryem Beyza/ACZ-9792-2022; Yu, Chongxiu/KDM-7354-2024; Li,
   Chun/KBC-9591-2024; Lu, Changsheng/AFS-6142-2022
OI Yu, Chongxiu/0000-0002-8221-6221; Lu, Changsheng/0000-0002-1894-286X;
   Xia, Siyu/0000-0002-0953-6501; Yang, Fan/0009-0003-8289-3462; Bian,
   Zhangxing/0000-0003-3603-0650
CR Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Han C, 2021, IEEE SIGNAL PROC LET, V28, P190, DOI 10.1109/LSP.2020.3048608
   Hensel M, 2017, ADV NEUR IN, V30
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Qin J, 2020, NEUROCOMPUTING, V386, P54, DOI 10.1016/j.neucom.2019.12.079
   Jin KH, 2015, IEEE T IMAGE PROCESS, V24, P3498, DOI 10.1109/TIP.2015.2446943
   Kawai N, 2016, IEEE T VIS COMPUT GR, V22, P1236, DOI 10.1109/TVCG.2015.2462368
   Kingma D. P., 2014, arXiv
   Lin C, 2019, IEEE I CONF COMP VIS, P6578, DOI 10.1109/ICCV.2019.00668
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu HY, 2018, MULTIMED TOOLS APPL, V77, P5969, DOI 10.1007/s11042-017-4509-0
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mo JC, 2019, CLUSTER COMPUT, V22, pS7593, DOI 10.1007/s10586-018-2323-8
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Sagong MC, 2019, PROC CVPR IEEE, P11352, DOI 10.1109/CVPR.2019.01162
   Sridevi G, 2019, CIRC SYST SIGNAL PR, V38, P3802, DOI 10.1007/s00034-019-01029-w
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Visin F., 2015, Renet: A recurrent neural network based alternative to convolutional networks
   Wang Y, 2020, VCNET ROBUST APPROAC
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu H, 2020, DEEP GENERATIVE MODE
   Xiao TH, 2018, LECT NOTES COMPUT SC, V11214, P172, DOI 10.1007/978-3-030-01249-6_11
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Yang XH, 2021, IEEE ACCESS, V9, P42100, DOI 10.1109/ACCESS.2021.3065661
   Yi Z, 2020, C COMP VIS PATT REC
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang L, 2020, ABS200403212 ARXIV
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao L, 2020, PROC CVPR IEEE, P5740, DOI 10.1109/CVPR42600.2020.00578
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29785
EP 29797
DI 10.1007/s11042-022-12912-1
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500022
PM 35401028
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, XH
   Hu, SH
AF Wang, Xiuhui
   Hu, Shaohui
TI Visual gait recognition based on convolutional block attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Deep learning; Convolutional block attention network;
   Human identification
AB Gait recognition has many advantages, such as non-invasive and easy to recognize from a long distance. It has a broad application prospect in the field of human identification. However, due to the sensitivity of gait recognition to sample collection perspective, there is no effective solution to cross-view gait recognition. To solve the above problems, this paper proposes a visual gait recognition method based on convolutional block attention network. Firstly, the method takes frame by frame gait energy images as the input, and makes each frame go through the attention neural network with the same structure to extract whole gait features. Then, the whole gait features are divided into two parts to train the network model and recognize the unknown gaits. Finally, the experimental results on the open-accessed gait data sets CASIA-B and OU-ISIR-MVLP show that the proposed method is more accurate than the existing methods, i.e., the Rank 1 rate is increased by at least 2.8% on CASIA gait dataset B, and more than 10% on OU-ISIR MVLP dataset.
C1 [Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou 310018, Peoples R China.
   [Hu, Shaohui] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
C3 China Jiliang University; China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
RI Hu, Shaohui/AAE-4433-2020
OI Wang, Xiuhui/0000-0003-1773-9760
FU Natural Science Foundation of Zhejiang Province [Y20F020018]; Key RAMP;D
   project of Zhejiang Province, China [2021C03151]
FX This research was funded by the Natural Science Foundation of Zhejiang
   Province, grant number No.Y20F020018 and the Key R&D project of Zhejiang
   Province, China, grant number No. 2021C03151.
CR Chen Q, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P54, DOI 10.1109/BTAS.2017.8272682
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Holzinger A, 2021, INFORM FUSION, V71, P28, DOI 10.1016/j.inffus.2021.01.008
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Jeevan M, 2013, IEEE IMAGE PROC, P4195, DOI 10.1109/ICIP.2013.6738864
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   LI C, 2017, APPL SCI-BASEL, V7
   Li SQ, 2019, IEEE T MULTIMEDIA, V21, P2361, DOI 10.1109/TMM.2019.2900134
   Liang F, 2018, IEEE J-STSP, V12, P144, DOI 10.1109/JSTSP.2018.2794062
   [鲁继文 LU JiWen], 2007, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V20, P365
   Miljkovic D, 2016, LECT NOTES COMPUT SC, V9605, P209, DOI 10.1007/978-3-319-50478-0_10
   More SA, 2018, IEEE-CAA J AUTOMATIC, V5, P718, DOI 10.1109/JAS.2018.7511081
   Padole C, 2017, PATTERN ANAL APPL, V20, P73, DOI 10.1007/s10044-015-0468-0
   Qinyong, 2007, ACTA ELECT SIN, V35, P2078
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shiraga K, 2016, INT CONF BIOMETR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   [王修晖 Wang Xiuhui], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P709
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2016, INT C PATT RECOG, P889, DOI 10.1109/ICPR.2016.7899748
   Zhang C, 2016, INT CONF ACOUST SPEE, P2832, DOI 10.1109/ICASSP.2016.7472194
NR 33
TC 0
Z9 0
U1 6
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29459
EP 29476
DI 10.1007/s11042-022-12831-1
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700003
DA 2024-07-18
ER

PT J
AU Das, A
   Dhal, KG
   Ray, S
   Galvez, J
   Das, S
AF Das, Arunita
   Dhal, Krishna Gopal
   Ray, Swarnajit
   Galvez, Jorge
   Das, Sanjoy
TI Fitness based weighted flower pollination algorithm with mutation
   strategies for image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evolutionary algorithms; Flower pollination algorithm (FPA); Image
   enhancement; Swarm intelligence; Inertia weight; Mutation
ID CUCKOO SEARCH ALGORITHM; BAT ALGORITHM; DIFFERENTIAL EVOLUTION;
   HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT
AB Flower Pollination Algorithm (FPA) is a well-known swarm intelligence optimization algorithm, which has shown an effective performance by solving many optimization problems. The performance of the FPA significantly depends on the balance among exploration and exploitation stages. However, FPA operators may cause false positive optima location in multimodal surfaces. Under such circumstances, modifying the original structure of the FPA can increase the ability of FPA to effectively locate optima in multimodal surfaces. In this study, fitness based dynamic inertia weight and two popular mutation techniques of differential evolution (DE) have been employed to increase the performance of FPA which helps to achieve a higher balance among evolutionary stages and effectively locate optima in multimodal surfaces. The proposed modified FPA (PMFPA) has been employed in image enhancement field to measure the efficiency. The experimental study corroborates the effectiveness of the PMFPA over popular swarm intelligence algorithms, original FPA and some of its variants by producing more robust, scalable and precise results.
C1 [Das, Arunita; Dhal, Krishna Gopal] Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
   [Ray, Swarnajit] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
   [Galvez, Jorge] Univ Guadalajara, Dept Elect, CUCEI Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [Das, Sanjoy] Univ Kalyani, Dept Engn & Technol Studies, Kalyani, Nadia, India.
C3 Midnapore College; Maulana Abul Kalam Azad University of Technology;
   Universidad de Guadalajara; Kalyani University
RP Dhal, KG (corresponding author), Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
EM arunita17@gmail.com; krishnagopal.dhal@midnaporecollege.ac.in;
   swamajit32@gmail.com; jorge.galvez@cutonala.udg.mx;
   dassanjoy0810@hotmail.com
RI Dhal, Krishna Gopal/JCD-8250-2023
OI dhal, krishna gopal/0000-0002-6748-0569
CR Abdel-Basset M, 2019, ARTIF INTELL REV, V52, P2533, DOI 10.1007/s10462-018-9624-4
   Adam SP, 2019, SPRINGER OPTIM APPL, V145, P57, DOI 10.1007/978-3-030-12767-1_5
   [Anonymous], 2018, INCORPORATING NATURE, DOI DOI 10.4018/978-1-5225-5020-4.CH004
   [Anonymous], 2015, IEEE INT C FUZZY SYS, DOI DOI 10.1109/FUZZ-IEEE.2015.7338111
   Asokan A., 2020, ARTIF INTELL, P83, DOI 10.1007/978-3-030-24178-0_5
   Banharnsakun A, 2019, EVOL SYST-GER, V10, P679, DOI 10.1007/s12530-018-9255-7
   Bansal J C, 2011, 3 WORLD C NAT BIOL I, P633, DOI [10.1109/NaBIC.2011.6089659, DOI 10.1109/NABIC.2011.6089659]
   Bejinariu S.-I., 2019, P INT S SIGN CIRC SY, P1
   Bhandari AK, 2020, SOFT COMPUT, V24, P1619, DOI 10.1007/s00500-019-03992-7
   Bujok P, 2019, SWARM EVOL COMPUT, V50, DOI 10.1016/j.swevo.2019.01.006
   Chakraborty S, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P712, DOI [10.1109/aicai.2019.8701367, 10.1109/AICAI.2019.8701367]
   Chen Y, 2020, APPL MATH MODEL, V83, P237, DOI 10.1016/j.apm.2020.02.023
   Chien CL, 2011, INT J INNOV COMPUT I, V7, P6691
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhabal Supriya, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P619, DOI 10.1007/978-981-13-7403-6_54
   Dhal, 2017, CHAOTIC DIFFERENTIAL, P71
   Dhal Krishna Gopal, 2018, International Journal of Medical Engineering and Informatics, V10, P164
   Dhal Krishna Gopal, 2017, Pattern Recognition and Image Analysis, V27, P695, DOI 10.1134/S1054661817040046
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Dhal KG, 2020, INT J COMPUT SCI MAT, V11, P1, DOI 10.1504/IJCSM.2020.105447
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, IJST-T ELECTR ENG, V43, P645, DOI 10.1007/s40998-019-00175-w
   Dhal KG, 2019, EVOL SYST-GER, V10, P129, DOI 10.1007/s12530-018-9216-1
   Dhal KG, 2018, INT J BIOMED ENG TEC, V28, P160
   Dhal KG, 2017, INT J SWARM INTELL R, V8, P1, DOI 10.4018/IJSIR.2017010101
   Dhal KG, 2016, NAT COMPUT, V15, P307, DOI 10.1007/s11047-015-9496-3
   Dhal KG, 2015, INT J APPL METAHEUR, V6, P69, DOI 10.4018/ijamc.2015070104
   Dhal KG, 2015, ADV INTELL SYST, V339, P233, DOI 10.1007/978-81-322-2250-7_23
   Dubey H, 2015, COGN COMPUT, V7, P594, DOI 10.1007/s12559-015-9324-1
   Gatta C, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P316
   Gong WY, 2013, IEEE T CYBERNETICS, V43, P2066, DOI 10.1109/TCYB.2013.2239988
   Gorai A, 2009, WOR CONG NAT BIOL, P72, DOI 10.1109/NABIC.2009.5393603
   Gowacz A, 2010, ANN TELECOMMUN, V65, P3, DOI 10.1007/s12243-009-0146-6
   Jasmine J, 2019, MEASUREMENT, V145, P833, DOI 10.1016/j.measurement.2018.12.105
   Jiageng Yu, 2012, 2012 International Conference on Software Security and Reliability Companion, P1, DOI 10.1109/SERE-C.2012.26
   Kamoona AM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105749
   Keerthanaa K., 2020, 2020 4 INT C COMP ME, P255
   Kumar Anurag, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0480, DOI 10.1109/ICCSP.2019.8697947
   Lazim D, 2019, ARTIF INTELL REV, V52, P1547, DOI 10.1007/s10462-017-9580-4
   Leon M, 2014, LECT NOTES ARTIF INT, V8467, P372, DOI 10.1007/978-3-319-07173-2_32
   Malik R, 2019, J AMB INTEL HUM COMP, V10, P3563, DOI 10.1007/s12652-018-1082-y
   Mary GG, 2019, INTEL SYST REF LIBR, V150, P147, DOI 10.1007/978-3-319-96002-9_6
   Muniyappan S, 2019, MULTIMED TOOLS APPL, V78, P6487, DOI 10.1007/s11042-018-6355-0
   Nabil E, 2016, EXPERT SYST APPL, V57, P192, DOI 10.1016/j.eswa.2016.03.047
   Opara K, 2018, SWARM EVOL COMPUT, V39, P53, DOI 10.1016/j.swevo.2017.12.007
   Pan, 2019, ENJOYPATH
   Paramanandam M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162053
   Pauline O, 2017, AIP CONF PROC, V1870, DOI 10.1063/1.4995922
   Rundo L, 2019, EXPERT SYST APPL, V119, P387, DOI 10.1016/j.eswa.2018.11.013
   Salgotra R, 2017, EXPERT SYST APPL, V79, P112, DOI 10.1016/j.eswa.2017.02.035
   Sam B.B., 2019, 2019 INT C REC ADV E, P1, DOI 10.1109/ICRAECC43874.2019.8995015
   Shanmugavadivu P, 2014, VISUAL COMPUT, V30, P387, DOI 10.1007/s00371-013-0863-8
   Singh H, 2020, RECENT ADV MEMETIC A, V873, DOI [10.1007/978-981-15-1362-6 2, DOI 10.1007/978-981-15-1362-62]
   Wang R, 2015, BIO-MED MATER ENG, V26, pS1345, DOI 10.3233/BME-151432
   Wang WC, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113216
   Wang YX, 2017, INT C INTEL HUM MACH, P337, DOI 10.1109/IHMSC.2017.188
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Xing Fuyong, 2016, IEEE Rev Biomed Eng, V9, P234, DOI 10.1109/RBME.2016.2515127
   Yang XS, 2020, J COMPUT SCI-NETH, V46, DOI 10.1016/j.jocs.2020.101104
   Yang XS, 2014, NATURE-INSPIRED OPTIMIZATION ALGORITHMS, P1
   Yousri D, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105889
   Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613
NR 62
TC 5
Z9 5
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28955
EP 28986
DI 10.1007/s11042-022-12879-z
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900013
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Zhou, TC
   Li, Z
   Huang, H
   Qu, BY
AF Wang, Yanzhao
   Zhou, Tongchi
   Li, Zheng
   Huang, Hu
   Qu, Boyang
TI Salient object detection based on multi-feature graphs and improved
   manifold ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Manifold ranking; Multi-feature; Boundary
   connectivity
ID REGION DETECTION; MODEL
AB In this paper, a salient object detection model based on multi-feature and modified manifold ranking is proposed. Different from traditional manifold ranking based models, the graphs in the proposed model are constructed by multiple features, and the energy function of manifold ranking is modified to accurately indicate the queries ranking process. Then, the four boundary regions of the image are ranked respectively based on multi-feature graphs with the improved ranking process to get the boundary based salient maps. And the final salient map is generated by integrating the boundary based maps with boundary connectivity prior. Qualitative and quantitative experiments on five public datasets demonstrate that the proposed model performs better than 10 state-of-the-art models under PR curve and Max F-measure measurements and provides robust and balanced results compared with the other models under MAE and AUC measurements.
C1 [Wang, Yanzhao; Zhou, Tongchi; Li, Zheng; Huang, Hu; Qu, Boyang] Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou 450007, Peoples R China.
C3 Zhongyuan University of Technology
RP Wang, YZ (corresponding author), Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou 450007, Peoples R China.
EM wangyzzut@163.com; Tongchizhou@zut.edu.cn; lizh0316@163.com;
   huanghu1997@163.com; quboyang@zut.edu.cn
RI Huang, Hu/A-3650-2012
FU National Natural Science Foundation of China [61976237, 61673404,
   61922072]; Key Scientific Research Projects in Colleges and Universities
   of Henan Province [19A120014, 20A120013]; Zhongyuan Qianren Project
   [ZYQR201810162]
FX This work is supported in part by National Natural Science Foundation of
   China(61976237, 61673404, 61922072), Zhongyuan Qianren Project
   (ZYQR201810162), and the Key Scientific Research Projects in Colleges
   and Universities of Henan Province (Grant Nos. 19A120014, 20A120013).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chaabouni S, 2019, J VIS COMMUN IMAGE R, V60, P79, DOI 10.1016/j.jvcir.2019.02.004
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Dong B, 2021, NEUROCOMPUTING, V437, P58, DOI 10.1016/j.neucom.2021.01.034
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fu KR, 2018, NEUROCOMPUTING, V275, P788, DOI 10.1016/j.neucom.2017.09.028
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji W, 2020, IEEE T IMAGE PROCESS, V29, P8177, DOI 10.1109/TIP.2020.3002083
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Le Callet P, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57687-9_1
   Li GB, 2018, IEEE T NEUR NET LEAR, V29, P6038, DOI 10.1109/TNNLS.2018.2817540
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang YZ, 2019, SIGNAL IMAGE VIDEO P, V13, P1603, DOI 10.1007/s11760-019-01507-3
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang PP, 2021, IEEE T IMAGE PROCESS, V30, P3204, DOI 10.1109/TIP.2020.3045624
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou L, 2017, IEEE T IMAGE PROCESS, V26, P5882, DOI 10.1109/TIP.2017.2738839
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu XZ, 2018, NEUROCOMPUTING, V312, P239, DOI 10.1016/j.neucom.2018.05.106
NR 40
TC 4
Z9 4
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27551
EP 27567
DI 10.1007/s11042-022-12839-7
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800006
DA 2024-07-18
ER

PT J
AU Hassan, MF
AF Hassan, Mohd Fikree
TI A uniform illumination image enhancement via linear transformation in
   CIELAB color space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color enhancement method; Luminance enhancement; Chrominance
   enhancement; CIELAB color space
ID LIGHTNESS; ALGORITHM
AB Digital devices such as digital cameras and smartphones are important tools in capturing color images. However, images captured under a low-light condition have low contrast, low brightness, and they lose their color information. In this paper, we propose a uniform illumination image enhancement via linear transformation in CIELAB color space. The main objective of the proposed method is to preserve the image features and the hue of the enhanced images as close as possible to the original images. It is achieved by using a linear transformation of the chroma and lightness in the CIELAB color space. The proposed method consists of two main stages known as luminance and chrominance enhancements. The proposed method produces enhanced images having lesser distortion and higher similarity indexes than the other four enhancement methods.
C1 [Hassan, Mohd Fikree] UCSI Univ, Inst Comp Sci & Digital Innovat, Kuala Lumpur, Malaysia.
C3 UCSI University
RP Hassan, MF (corresponding author), UCSI Univ, Inst Comp Sci & Digital Innovat, Kuala Lumpur, Malaysia.
EM fikree@ucsiuniversity.edu.my
RI Hassan, Mohd Fikree/AAD-8538-2021
OI Hassan, Mohd Fikree/0000-0003-4878-4695
CR Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Dixit A.K., 2019, INT J COMPUT SCI ENG, V7, P263
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fairchild M.D., 2005, Color Appearance Models, V2nd
   FAIRCHILD MD, 1991, COLOR RES APPL, V16, P385, DOI 10.1002/col.5080160608
   Gonzalez R.C., 2018, Digital Image Processing
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Jiang XS, 2013, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2013.6738114
   Kim D, 2017, IEEE SIGNAL PROC LET, V24, P804, DOI 10.1109/LSP.2017.2687945
   Ko S, 2017, SIGNAL PROCESS-IMAGE, V58, P99, DOI 10.1016/j.image.2017.06.016
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li GL, 2020, MULTIMED TOOLS APPL, V79, P30883, DOI 10.1007/s11042-020-09586-y
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma SP, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103583
   Mandal S, 2020, SOFT COMPUT, V24, P2151, DOI 10.1007/s00500-019-04048-6
   Nandal A, 2018, IET SIGNAL PROCESS, V12, P514, DOI 10.1049/iet-spr.2017.0272
   Pascale D., 2003, REV RGB COLOR SPACES
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh HR, 2005, 1 INT WORKSH VID PRO, V7
   Shi ZH, 2020, IET IMAGE PROCESS, V14, P747, DOI 10.1049/iet-ipr.2019.0992
   Singh G, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P265, DOI 10.1109/SPIN.2016.7566701
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu F, 2017, 10 INT C IM SIGN PRO
   Yan L, 2021, MULTIMEDIA TOOLS APP
   Zhang L, 2016, IET IMAGE PROCESS, V10, P840, DOI 10.1049/iet-ipr.2015.0844
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang ML, 2017, SMART INNOV SYST TEC, V64, P19, DOI 10.1007/978-3-319-50212-0_3
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 34
TC 4
Z9 4
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26331
EP 26343
DI 10.1007/s11042-022-12429-7
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900017
DA 2024-07-18
ER

PT J
AU Das, D
   Biswas, SK
   Bandyopadhyay, S
AF Das, Dolly
   Biswas, Saroj Kr
   Bandyopadhyay, Sivaji
TI A critical review on diagnosis of diabetic retinopathy using machine
   learning and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Diabetic retinopathy; Image processing; Machine learning; Retinal
   lesions; Feature extraction; Deep learning
ID CONVOLUTIONAL NEURAL-NETWORKS; RETINAL FUNDUS IMAGES; OPTIC DISC;
   AUTOMATIC DETECTION; MICROANEURYSM DETECTION; FEATURE-EXTRACTION; LESION
   DETECTION; BLOOD-VESSELS; FOVEA; SEGMENTATION
AB Diabetic Retinopathy (DR) is a health condition caused due to Diabetes Mellitus (DM). It causes vision problems and blindness due to disfigurement of human retina. According to statistics, 80% of diabetes patients battling from long diabetic period of 15 to 20 years, suffer from DR. Hence, it has become a dangerous threat to the health and life of people. To overcome DR, manual diagnosis of the disease is feasible but overwhelming and cumbersome at the same time and hence requires a revolutionary method. Thus, such a health condition necessitates primary recognition and diagnosis to prevent DR from developing into severe stages and prevent blindness. Innumerable Machine Learning (ML) models are proposed by researchers across the globe, to achieve this purpose. Various feature extraction techniques are proposed for extraction of DR features for early detection. However, traditional ML models have shown either meagre generalization throughout feature extraction and classification for deploying smaller datasets or consumes more of training time causing inefficiency in prediction while using larger datasets. Hence Deep Learning (DL), a new domain of ML, is introduced. DL models can handle a smaller dataset with help of efficient data processing techniques. However, they generally incorporate larger datasets for their deep architectures to enhance performance in feature extraction and image classification. This paper gives a detailed review on DR, its features, causes, ML models, state-of-the-art DL models, challenges, comparisons and future directions, for early detection of DR.
C1 [Das, Dolly; Biswas, Saroj Kr; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Cachar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, D (corresponding author), Natl Inst Technol Silchar, Cachar, Assam, India.
EM das.dolly0019@gmail.com; bissarojkum@yahoo.com; director@nits.ac.in
OI Das, Dolly/0000-0003-1518-3332
CR Abed S, 2016, APPL SOFT COMPUT, V49, P146, DOI 10.1016/j.asoc.2016.08.015
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Agurto C, 2014, IEEE J BIOMED HEALTH, V18, P1328, DOI 10.1109/JBHI.2013.2296399
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Al-Bander B, 2018, BIOMED SIGNAL PROCES, V40, P91, DOI 10.1016/j.bspc.2017.09.008
   Alghamdi HS., 2017, Automatic optic disc abnormality detection in fundus images: a deep learning approach, P17, DOI [10.17077/omia.1042, DOI 10.17077/OMIA.1042]
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Amin J, 2017, J COMPUT SCI-NETH, V19, P153, DOI 10.1016/j.jocs.2017.01.002
   Andrew D, RETINA DIABETIC RETI
   Annunziata R, 2016, IEEE J BIOMED HEALTH, V20, P1129, DOI 10.1109/JBHI.2015.2440091
   [Anonymous], 1991, OPHTHALMOLOGY, V98, P741
   [Anonymous], 1991, Ophthalmology, V98, P823
   [Anonymous], 1991, Ophthalmology, V98, P786
   [Anonymous], 2013, INT J ADV COMPUT THE
   [Anonymous], 2013, International Journal of Computer Science and Information Technology, DOI [DOI 10.5121/IJCSIT.2013.5502, 10.5121/ijcsit.2013.5502]
   [Anonymous], 2016, Report of standford education
   [Anonymous], DIABETIC RETINOPATHY
   [Anonymous], 2016, 2016 IEEE REG 10 HUM, DOI DOI 10.1109/R10-HTC.2016.7906821
   [Anonymous], RET BLOOD VESS
   Antal B, 2012, IEEE ENG MED BIO, P5955, DOI 10.1109/EMBC.2012.6347350
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   Aquino A, 2014, COMPUT BIOL MED, V55, P61, DOI 10.1016/j.compbiomed.2014.10.007
   Argade KS, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P517, DOI 10.1109/ICGCIoT.2015.7380519
   Asha P. R., 2015, P INT C ADV COMP COM, V2, P573
   Aslam Tariq, 2009, BMC Res Notes, V2, P196, DOI 10.1186/1756-0500-2-196
   Banerjee S, 2016, BIOCYBERN BIOMED ENG, V36, P679, DOI 10.1016/j.bbe.2016.07.001
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P923, DOI 10.1007/s11760-020-01816-y
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chatterjee S, 2022, APPL ECON PERSPECT P, V44, P434, DOI 10.1002/aepp.13127
   Cheng XG, 2012, IEEE ENG MED BIO, P4954, DOI 10.1109/EMBC.2012.6347104
   Chetoui M, 2020, IEEE ENG MED BIO, P1966, DOI 10.1109/EMBC44109.2020.9175664
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Duanggate C, 2011, COMPUT MED IMAG GRAP, V35, P51, DOI 10.1016/j.compmedimag.2010.09.004
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   Ege BM, 2000, COMPUT METH PROG BIO, V62, P165, DOI 10.1016/S0169-2607(00)00065-1
   Fadzil MHA, 2011, MED BIOL ENG COMPUT, V49, P693, DOI 10.1007/s11517-011-0734-2
   Fadzil MHA, 2010, COMPUT BIOL MED, V40, P657, DOI 10.1016/j.compbiomed.2010.05.004
   Fong DS, 2004, DIABETES CARE, V27, P2540, DOI 10.2337/diacare.27.10.2540
   Fraz MM, 2017, BIOMED SIGNAL PROCES, V35, P50, DOI 10.1016/j.bspc.2017.02.012
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Gardner GG, 1996, BRIT J OPHTHALMOL, V80, P940, DOI 10.1136/bjo.80.11.940
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Geetharamani R, 2015, SADHANA-ACAD P ENG S, V40, P1715, DOI 10.1007/s12046-015-0411-5
   Gegundez-Arias ME, 2013, COMPUT MED IMAG GRAP, V37, P386, DOI 10.1016/j.compmedimag.2013.06.002
   Goh James Kang Hao, 2016, J Diabetes Sci Technol, V10, P282, DOI 10.1177/1932296816629491
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Habib M. M., 2017, Informatics in Medicine Unlocked, V9, P44, DOI 10.1016/j.imu.2017.05.006
   Hani AFM, 2010, IEEE ENG MED BIO, P5632, DOI 10.1109/IEMBS.2010.5628041
   Harangi B, 2015, COMPUT BIOL MED, V65, P10, DOI 10.1016/j.compbiomed.2015.07.002
   Hattiya T., 2021, MAHASARAKHAM INT J E, V7, P50, DOI [10.14456/mijet.2021.8, DOI 10.14456/MIJET.2021.8]
   Hou SQ, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON ELECTROMAGNETICS: APPLICATIONS AND STUDENT INNOVATION COMPETITION (IWEM)
   Hsiao HK, 2012, EXPERT SYST APPL, V39, P10600, DOI 10.1016/j.eswa.2012.02.157
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Islam S. R., 2018, ARXIV PREPRINT ARXIV
   Iwendi C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092559
   Jelinek H.F., 2012, Computer-Based Medical Systems (CBMS), 2012 25th International Symposium, P1, DOI DOI 10.1109/CBMS.2012.6266342
   Ji QG, 2019, ALGORITHMS, V12, DOI 10.3390/a12030051
   Jin C, 2016, IEEE T MED IMAGING, V35, P1395, DOI 10.1109/TMI.2015.2512606
   Kale P., 2017, INT J ADV RES COMPUT, V6, P1002, DOI [10.17148/IJARCCE.2017.63233, DOI 10.17148/IJARCCE.2017.63233]
   Kamble R, 2017, IEEE IMAGE PROC, P4442, DOI 10.1109/ICIP.2017.8297122
   Kamble R, 2017, COMPUT BIOL MED, V87, P382, DOI 10.1016/j.compbiomed.2017.04.016
   Kamel M, 2001, IEEE IJCNN, P2695, DOI 10.1109/IJCNN.2001.938798
   Kao EF, 2014, COMPUT METH PROG BIO, V117, P92, DOI 10.1016/j.cmpb.2014.08.003
   Kamal KC, 2021, SIGNAL IMAGE VIDEO P, V15, P959, DOI 10.1007/s11760-020-01820-2
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khojasteh P, 2018, BMC OPHTHALMOL, V18, DOI 10.1186/s12886-018-0954-4
   Kirkpatrick C, 2013, INTRARETINAL MICROVA
   Kokame GT, 2012, INTRARETINAL MICROVA
   Kulenovic I., 2006, BOSNIAN J BASIC MED, V6, P47, DOI [10.17305/bjbms.2006.3171, DOI 10.17305/BJBMS.2006.3171]
   Kumar PNS, 2016, PROCEDIA COMPUT SCI, V93, P486, DOI 10.1016/j.procs.2016.07.237
   Lachure J, 2015, IEEE INT ADV COMPUT, P617, DOI 10.1109/IADCC.2015.7154781
   Lam C., 2018, AMIA JT SUMMITS TRAN, V2017, P147
   Lam C, 2018, INVEST OPHTH VIS SCI, V59, P590, DOI 10.1167/iovs.17-22721
   Lazar I, 2013, IEEE T MED IMAGING, V32, P400, DOI 10.1109/TMI.2012.2228665
   Lee J, 2020, J GLAUCOMA, V29, P287, DOI 10.1097/IJG.0000000000001458
   Li BX, 2013, CURR DIABETES REP, V13, P453, DOI 10.1007/s11892-013-0393-9
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Manjaramkar A, 2018, J DIGIT IMAGING, V31, P224, DOI 10.1007/s10278-017-0008-0
   Mann KS., 2017, INT J RES APPL SCI E, V5, P2811, DOI [10.1063/1.4981966, DOI 10.1063/1.4981966]
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mansour Romany F, 2017, IEEE Rev Biomed Eng, V10, P334, DOI 10.1109/RBME.2017.2705064
   Massey EM, 2011, IEEE ENG MED BIO, P3967, DOI 10.1109/IEMBS.2011.6090985
   Medhi JP, 2016, COMPUT BIOL MED, V74, P30, DOI 10.1016/j.compbiomed.2016.04.007
   Memari N, 2019, J MED BIOL ENG, V39, P713, DOI 10.1007/s40846-018-0454-2
   Michalska, 2019, COMPUTER VISION MACH, DOI [10.1101/763136, DOI 10.1101/763136]
   Microaneyrysms, COMS GRAD SCHEM GRAD
   Mizutani A, 2009, PROC SPIE, V7260, DOI 10.1117/12.813468
   Pour AM, 2020, IEEE ACCESS, V8, P136668, DOI 10.1109/ACCESS.2020.3005044
   Mookiah MRK, 2013, KNOWL-BASED SYST, V39, P9, DOI 10.1016/j.knosys.2012.09.008
   Niemeijer M, 2005, IEEE T MED IMAGING, V24, P584, DOI 10.1109/TMI.2005.843738
   Noor-ul-huda M, 2019, BIOMED ENG-BIOMED TE, V64, P297, DOI 10.1515/bmt-2018-0098
   Nugroho H.A., 2017, J TELECOMMUN ELECT C, V9, P107
   Oliveira WS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149943
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Patwari RRMaYMR M. B, 2013, INT J APPL INFORM SY, P11
   Pentland BT, 2020, MIS QUART, V44, P19, DOI 10.25300/MISQ/2020/14458
   Pereira C, 2015, INFORM SCIENCES, V296, P14, DOI 10.1016/j.ins.2014.10.059
   Pereira C, 2014, ARTIF INTELL MED, V60, P179, DOI 10.1016/j.artmed.2013.12.005
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Prentasic P, 2016, COMPUT METH PROG BIO, V137, P281, DOI 10.1016/j.cmpb.2016.09.018
   Quellec G, 2008, IEEE T MED IMAGING, V27, P1230, DOI 10.1109/TMI.2008.920619
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qureshi RJ, 2012, COMPUT VIS IMAGE UND, V116, P138, DOI 10.1016/j.cviu.2011.09.001
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Raja D. S. S., 2015, Applied Medical Informatics, V36, P13
   Rajput YM., 2015, INT J COMPUT APPL, V975, P1
   Rakhlin, 2017, DIABETIC RETINOPATHY, DOI 10.1101/225508
   Ravishankar S, 2009, PROC CVPR IEEE, P210, DOI 10.1109/CVPRW.2009.5206763
   Reza MN, 2018, BIOMED SIGNAL PROCES, V45, P274, DOI 10.1016/j.bspc.2018.05.027
   Rosas-Romero R, 2015, COMPUT MED IMAG GRAP, V44, P41, DOI 10.1016/j.compmedimag.2015.07.001
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483
   Senapati R. K., 2016, B ELECT ENG INFORM, V5, P92, DOI DOI 10.11591/EEI.V5I1.553
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Sinthanayothin C, 2002, DIABETIC MED, V19, P105, DOI 10.1046/j.1464-5491.2002.00613.x
   Sopharak Akara, 2011, IAENG International Journal of Computer Science, V38, P295
   Sopharak A, 2009, SENSORS-BASEL, V9, P2148, DOI 10.3390/s90302148
   Spencer T, 1996, COMPUT BIOMED RES, V29, P284, DOI 10.1006/cbmr.1996.0021
   Stewart JM., 2000, ENDOTEXT
   Takahashi H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179790
   Tobin KW, 2007, IEEE T MED IMAGING, V26, P1729, DOI 10.1109/TMI.2007.902801
   Tymchenko B, 2020, ARXIV PREPRINT ARXIV
   Usher D, 2004, DIABETIC MED, V21, P84, DOI 10.1046/j.1464-5491.2003.01085.x
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wang Z., 2018, WORKSH 32 AAAI C ART
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Wu B, 2017, COMPUT MED IMAG GRAP, V55, P106, DOI 10.1016/j.compmedimag.2016.08.001
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yu FL, 2017, IEEE ENG MED BIO, P664, DOI 10.1109/EMBC.2017.8036912
   Zhang B, 2012, INFORM SCIENCES, V200, P78, DOI 10.1016/j.ins.2012.03.003
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
   Zhou W, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/8973287
NR 142
TC 33
Z9 34
U1 8
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25613
EP 25655
DI 10.1007/s11042-022-12642-4
EA MAR 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200005
PM 35342328
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Nguyen, TD
   Le, HQ
AF Tuan Duc Nguyen
   Hai Quoc Le
TI A secure image steganography based on modified matrix encoding using the
   adaptive region selection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive embedding; Hamming code; Ensemble classifier; Steganalysis;
   Image complexity; Anti-detection Security
ID SCHEME; CODE; LSB
AB This paper introduced an image steganography technique based on modified matrix encoding to enhance the perceptual quality of the stego images. Additionally, more pixel bit-planes are exploited in the data hiding process to improve the embedding capacity. The number of used image layers depends on the size of the given secret message and the texture characteristic of the cover image. The complexity of the pixel block is identified by the difference between the middle pixel and its neighbors. By performing the suitable embedding solutions of modified matrix encoding, the complexity is unchanged by the data hiding stage. Therefore, the used image regions could be determined precisely in the extraction process without using any additional information. The experimental results proved that the stego images created by the proposed approach achieved higher security against statistical and visual steganalysis techniques than the previous methods. The improvement of the security against detection by Ensemble Classifier is four times as secure as the best security performance of the existing methods.
C1 [Tuan Duc Nguyen] Hanoi Open Univ, Hanoi, Vietnam.
   [Hai Quoc Le] Quang Tri Teacher Training Coll, Dong Ha City, Vietnam.
RP Nguyen, TD (corresponding author), Hanoi Open Univ, Hanoi, Vietnam.
EM nguyenductuan@hou.edu.vn; hai_ly@qtttc.edu.vn
OI DUC TUAN, NGUYEN/0000-0001-5261-271X
FU Hanoi Open University
FX We gratefully acknowledge the financial support of Hanoi Open
   University.
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   [Anonymous], 2017, J INFORM HIDING MULT
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Crandall R., 1998, Steganography Mailing List, V1998, P1
   Dahiya P, 2019, J ADV RES DYNAMICAL, V11, P335
   Darsana R, 2011, COMM COM INF SC, V197, P11
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Girdhar A, 2019, J AMB INTEL HUM COMP, V10, P4947, DOI 10.1007/s12652-019-01179-4
   Ho LH, 2012, OPTO-ELECTRON REV, V20, P367, DOI 10.2478/s11772-012-0046-6
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosam O, 2016, SECUR COMMUN NETW, V9, P5036, DOI 10.1002/sec.1676
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Jain M, 2017, INT J MACH LEARN CYB, V8, P1695, DOI 10.1007/s13042-016-0542-y
   Jain Mamta, 2017, Brain Inform, V4, P95, DOI 10.1007/s40708-016-0057-z
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Kim C, 2018, DIGIT SIGNAL PROCESS, V78, P284, DOI 10.1016/j.dsp.2018.03.016
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P115, DOI 10.1007/s11554-017-0674-7
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Lee CF, 2018, DISPLAYS, V53, P30, DOI 10.1016/j.displa.2018.06.001
   Lin J, 2020, IEEE ACCESS, V8, P21534, DOI 10.1109/ACCESS.2019.2962230
   Manoharan Sathiamoorthy, 2008, Third International Conference on Internet Monitoring and Protection - ICIMP 2008, P172, DOI 10.1109/ICIMP.2008.15
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sahu AK, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102808
   Sahu AK, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0188-5
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Shang YY, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091446
   Swain G, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/4847098
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Watermarking Virtual Laboratory (Wavila) of the European Network of Excellence ECRYPT, BREAK OUR WATERMARKI
NR 37
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25251
EP 25281
DI 10.1007/s11042-022-12677-7
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300006
DA 2024-07-18
ER

PT J
AU Zhong, HY
   Li, GD
AF Zhong, Huiyan
   Li, Guodong
TI Multi-image encryption algorithm based on wavelet transform and 3D
   shuffling scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-image encryption; Wavelet transform; 3D shuffling scrambling;
   Dynamic chaos library
ID MULTIPLE-IMAGE ENCRYPTION; CHAOTIC SYSTEM; STEGANOGRAPHY
AB To solve the problems of low efficiency and poor resistance to attack, this paper proposes the multi-image encryption algorithm based on Haar wavelet transform and 3D shuffling scrambling. Taking advantage of the high computational efficiency of low-dimensional chaotic maps, this paper designs the dynamic pseudo-random sequence generator based on a dynamic chaotic library with three one-dimension chaotic maps and the roulette algorithm, which is highly associated with the plaintext image. To better scramble the image cube, this paper proposes a 3D shuffling scrambling algorithm, which divides the cube into one-dimensional vectors and scrambles the order of the one-dimensional vectors, then reorganizes the cube. To encrypt multiple images, first, reconstruct the images into an image cube and perform wavelet transformation on each layer of the cube. Then, use the 3D shuffling algorithm to scramble the low-frequency coefficient and reconstruct the cube with the scrambled low-frequency coefficient and high-frequency parts. Last, the chaotic matrix is XOR with each layer of the image cube. The algorithm can encrypt grayscale or color images of any size, which is flexible. In the simulation experiments, the algorithm has ideal ciphertext statistical characteristics, high running speed, and the ability of anti-attack, which is better than encryption algorithm in other references.
C1 [Zhong, Huiyan; Li, Guodong] Guilin Univ Elect Technol, Sch Math & Computat Sci, Guilin 541004, Guangxi, Peoples R China.
C3 Guilin University of Electronic Technology
RP Li, GD (corresponding author), Guilin Univ Elect Technol, Sch Math & Computat Sci, Guilin 541004, Guangxi, Peoples R China.
EM lgdzhy@126.com
RI Zhong, Huiyan/GQQ-9903-2022; Li, Guodong/JDX-1233-2023
OI Zhong, Huiyan/0000-0002-6102-3148; Li, Guodong/0000-0003-1275-2982
FU Guangxi Natural Science Foundation [2018GXNSFAA138177]; Guilin
   University of Electronic Technology Fund [C21YJM00QX99]; Innovation
   Project of GUET Graduate Education [2021YCXS119, 2022YCX139]; Data
   Analysis and Computing Laboratory of Guangxi University Key Laboratory
FX This work was funded by Guangxi Natural Science Foundation
   (No.2018GXNSFAA138177), Guilin University of Electronic Technology Fund
   (No. C21YJM00QX99) the Innovation Project of GUET Graduate Education
   (No.2021YCXS119, No.2022YCX139) and supported by Data Analysis and
   Computing Laboratory of Guangxi University Key Laboratory.
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   An FP, 2019, J SENSORS, V2019, DOI 10.1155/2019/2768121
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Dai WY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010017
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Guo Y, 2020, ACTA PHOTONICA SINIC, V49, DOI 10.3788/gzxb20204904.0410002
   Guo-dong Li, 2014, Journal of Digital Information Management, V12, P151
   Han SM, 2020, ACTA PHOTONICA SINIC, V49, DOI 10.3788/gzxb20204903.0310002
   Hassaballah M., 2020, Digital Media Steganography, P1
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Jiang X, 2021, OPT COMMUN, V484, DOI 10.1016/j.optcom.2020.126683
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kumar D., 2020, RESULTS OPTICS, V1, P100031, DOI 10.1016/j.rio.2020.100031
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li GD, 2019, VISUAL COMPUT, V35, P1267, DOI 10.1007/s00371-018-1574-y
   Liu YJ, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106171
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   Song XM, 2021, J WEB ENG, V20, P1115, DOI 10.13052/jwe1540-9589.20410
   [孙克辉 Sun Kehui], 2013, [电子学报, Acta Electronica Sinica], V41, P1765
   Xu XL, 2021, FRACTALS, V29, DOI 10.1142/S0218348X21502455
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhao HX, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023007
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 30
TC 29
Z9 29
U1 9
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24757
EP 24776
DI 10.1007/s11042-022-12479-x
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960000003
DA 2024-07-18
ER

PT J
AU Neves, PLT
   Fornari, J
   Florindo, JB
AF Tomaz Neves, Pedro Lucas
   Fornari, Jose
   Florindo, Joao Batista
TI Self-attention generative adversarial networks applied to conditional
   music generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Generative adversarial networks; Music generation; Music
   information retrieval
AB The task of audio and music generation in the waveform domain has become possible due to recent advances in deep learning. Generative Adversarial Networks (GANs) are a type of generative model that has achieved success in areas such as image, video and audio generation. However, realistic audio generation with GANs is still a challenge, thanks to the specific characteristics inherent to this kind of data. In this paper we propose a GAN model that employs the self-attention mechanism and produces small chunks of music conditioned by instrument. We compare our model to a baseline and run ablation studies in order to demonstrate its superiority. We also suggest some applications of the model, particularly in the area of computer assisted composition.
C1 [Tomaz Neves, Pedro Lucas; Florindo, Joao Batista] Univ Estadual Campinas, UNICAMP, Inst Math Stat & Sci Comp IMECC, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
   [Fornari, Jose] Univ Estadual Campinas, UNICAMP, Interdisciplinary Nucleus Sound Commun NICS, Rua Sergio Buarque de Holanda 165, BR-13083872 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual de Campinas
RP Neves, PLT (corresponding author), Univ Estadual Campinas, UNICAMP, Inst Math Stat & Sci Comp IMECC, Rua Sergio Buarque de Holanda 651, BR-13083859 Campinas, SP, Brazil.
EM p185770@dac.unicamp.br; fornari@unicamp.br; jbflorindo@ime.unicamp.br
RI Florindo, Joao/S-5823-2019; Fornari, José E/R-7163-2018
OI Florindo, Joao/0000-0002-0071-0227; Neves, Pedro/0000-0002-8902-5743
CR [Anonymous], 2018, P 19 INT SOC MUS INF
   Barratt Shane, 2018, ARXIV180101973
   Binkowski M., 2019, INT C LEARN REPR
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Cella C. E, 2016, ISMIR
   Cordonnier J.B., 2019, INT C LEARNING REPRE
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhariwal Prafulla, 2020, ARXIV200500341
   Dieleman Sander, 2018, ARXIV180610474
   Donahue C., 2018, Adversarial audio synthesis
   Donahue J., 2021, ICLR
   dos Santos Tanaka F.H.K., 2019, Proc. Mach. Learn. Res
   Engel J., 2019, P INT C LEARN REPR, P1
   Ferreira LN, 2021, ARXIV210306125
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guangul FM, 2019, 2019 4TH MEC INTERNATIONAL CONFERENCE ON BIG DATA AND SMART CITY (ICBDSC), P99, DOI [10.1109/icbdsc.2019.8645580, 10.1109/ijcnn.2019.8852291]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Kingma D. P., 2014, arXiv
   Lim J. H., 2017, Geometric gan
   Mao HH, 2018, IEEE INT C SEMANT CO, P377, DOI 10.1109/ICSC.2018.00077
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T., 2018, Proceedings of the 6th International Conference on Learning Representations, P1
   Miyato T, 2018, INT C LEARN REPR
   Muhamed A, 2021, AAAI CONF ARTIF INTE, V35, P408
   Oord A., 2016, ARXIV160903499
   Paszke A, 2019, ADV NEUR IN, V32
   Razavi A, 2019, ADV NEUR IN, V32
   Salimans T, 2016, ADV NEUR IN, V29
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   van den Broek K, 2021, ARXIV210104785
   van den Oord A, 2017, ADV NEUR IN, V30
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Weiss RJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5679, DOI 10.1109/ICASSP39728.2021.9413851
   Yang Li-Chia, 2017, ARXIV170310847
   Yu Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3424116
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhao S., 2020, ARXIV200610738
NR 41
TC 3
Z9 3
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24419
EP 24430
DI 10.1007/s11042-022-12116-7
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000005
DA 2024-07-18
ER

PT J
AU Cui, Z
   Hu, YL
   Sun, YF
   Gao, JB
   Yin, BC
AF Cui, Zheng
   Hu, Yongli
   Sun, Yanfeng
   Gao, Junbin
   Yin, Baocai
TI Cross-modal alignment with graph reasoning for image-text retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-text retrieval; Multi-step graph reasoning; Self-attention
   mechanism; Fine-grained alignment
AB Image-text retrieval task has received a lot of attention in the modern research field of artificial intelligence. It still remains challenging since image and text are heterogeneous cross-modal data. The key issue of image-text retrieval is how to learn a common feature space while semantic correspondence between image and text remains. Existing works cannot gain fine cross-modal feature representation because the semantic relation between local features is not effectively utilized and the noise information is not suppressed. In order to address these issues, we propose a Cross-modal Alignment with Graph Reasoning (CAGR) model, in which the refined cross-modal features in the common feature space are learned and then a fine-grained cross-modal alignment method is implemented. Specifically, we introduce a graph reasoning module to explore semantic connection for local elements in each modality and measure their importance by self-attention mechanism. In a multi-step reasoning manner, the visual semantic graph and textual semantic graph can be effectively learned and the refined visual and textual features can be obtained. Finally, to measure the similarity between image and text, a novel alignment approach named cross-modal attentional fine-grained alignment is used to compute similarity score between two sets of features. Our model achieves the competitive performance compared with the state-of-the-art methods on Flickr30K dataset and MS-COCO dataset. Extensive experiments demonstrate the effectiveness of our model.
C1 [Cui, Zheng; Hu, Yongli; Sun, Yanfeng; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
   [Gao, Junbin] Univ Sydney, Univ Sydney Business Sch, Discipline Business Analyt, Sydney, NSW, Australia.
C3 Beijing University of Technology; University of Sydney
RP Hu, YL (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
EM CuiZ@emails.bjut.edu.cn; huyongli@bjut.edu.cn; yfsun@bjut.edu.cn;
   junbin.gao@sydney.edu.au; ybc@bjut.edu.cn
RI Gao, Junbin/C-6566-2008
FU National Key R&D Program of China [2021ZD0111900]; Natural Science
   Foundation of China [U21B2038, U1811463, U19B2039]
FX This work is supported by National Key R&D Program of China
   (No.2021ZD0111900), Natural Science Foundation of China (U21B2038,
   U1811463, U19B2039).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Chen TL, 2020, AAAI CONF ARTIF INTE, V34, P10583
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Eisenschtat A, 2017, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2017.201
   Faghri Fartash, 2017, ARXIV170705612
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gabeur Valentin, 2020, P EUR C COMP VIS, V12349, P214, DOI [10.48550/arXiv.2007.10639, DOI 10.48550/ARXIV.2007.10639]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang YF, 2017, IEEE INT CONF COMP V, P2313, DOI 10.1109/ICCVW.2017.273
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   King DB, 2015, ACS SYM SER, V1214, P1
   Kipf TN, 2017, INT C LEARN REPR
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li XR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1786, DOI 10.1145/3343031.3350906
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C., 2020, P IEEE CVF C COMP VI, P10921, DOI DOI 10.1109/CVPR42600.2020.01093
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu Yang, 2019, BMVC
   Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442
   Ma L, 2019, NEUROCOMPUTING, V345, P36, DOI 10.1016/j.neucom.2018.11.089
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Niu ZX, 2017, IEEE I CONF COMP VIS, P1899, DOI 10.1109/ICCV.2017.208
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang ZH, 2019, IEEE I CONF COMP VIS, P5763, DOI 10.1109/ICCV.2019.00586
   Wu J, 2021, IEEE T CIRC SYST VID
   Yang X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1339, DOI 10.1145/3397271.3401151
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhai DM, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168767
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
   Zolfaghari Mohammadreza, 2020, ARXIV201100597
NR 51
TC 2
Z9 2
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23615
EP 23632
DI 10.1007/s11042-022-12444-8
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800030
DA 2024-07-18
ER

PT J
AU Kour, H
   Gupta, MK
AF Kour, Harnain
   Gupta, Manoj K.
TI An hybrid deep learning approach for depression prediction from user
   tweets using feature-rich CNN and bi-directional LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mental health; Twitter data; Convolutional and recurrent neural
   networks; Long short-term memory model
ID SUICIDE; ANXIETY
AB Depression has become one of the most widespread mental health disorders across the globe. Depression is a state of mind which affects how we think, feel, and act. The number of suicides caused by depression has been on the rise for the last several years. This issue needs to be addressed. Considering the rapid growth of various social media platforms and their effect on society and the psychological context of a being, it's becoming a platform for depressed people to convey feelings and emotions, and to study their behavior by mining their social activity through social media posts. The key objective of our study is to explore the possibility of predicting a user's mental condition by classifying the depressive from non-depressive ones using Twitter data. Using textual content of the user's tweet, semantic context in the textual narratives is analyzed by utilizing deep learning models. The proposed model, however, is a hybrid of two deep learning architectures, Convolutional Neural Network (CNN) and bi-directional Long Short-Term Memory (biLSTM) that after optimization obtains an accuracy of 94.28% on benchmark depression dataset containing tweets. CNN-biLSTM model is compared with Recurrent Neural Network (RNN) and CNN model and also with the baseline approaches. Experimental results based on various performance metrics indicate that our model helps to improve predictive performance. To examine the problem more deeply, statistical techniques and visualization approaches were used to show the profound difference between the linguistic representation of depressive and non-depressive content.
C1 [Kour, Harnain; Gupta, Manoj K.] Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Katra, India.
C3 Shri Mata Vaishno Devi University
RP Kour, H (corresponding author), Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Katra, India.
EM 18dcs008@smvdu.ac.in; manoj.gupta@gmail.com
OI Kour, Harnain/0000-0002-3261-6278
FU Shri Mata Vaishno Devi University under TEQIP-III (Technical Education
   Quality Improvement Program-III)
FX The authors are thankful to Shri Mata Vaishno Devi University for
   funding the research grant under TEQIP-III (Technical Education Quality
   Improvement Program-III).
CR Agarap A. F., 2018, ARXIV
   Alabdulkreem E, 2021, J DECIS SYST, V30, P102, DOI 10.1080/12460125.2020.1859745
   Albawi S, 2017, I C ENG TECHNOL
   Almeida H., 2017, CLEF WORKING NOTES
   Alsagri HS, 2020, IEICE T INF SYST, VE103D, P1825, DOI 10.1587/transinf.2020EDP7023
   Alshaer HN, 2021, MULTIMED TOOLS APPL, V80, P10373, DOI 10.1007/s11042-020-10074-6
   [Anonymous], TENSORFLOW TEXT PREP
   Arora Priyanka, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P186
   Beard C, 2016, PSYCHOL MED, V46, P3359, DOI 10.1017/S0033291716002300
   Biradar A., 2018, International conference on recent trends in image processing and pattern recognition, P716
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Birjali M., 2016, INT C HYBRID INTELLI, P413, DOI [10.1007/978-3-319-52,941-7_41, DOI 10.1007/978-3-319-52,941-7_41]
   Brahma S, 2018, ARXIV PREPRINT ARXIV
   Chenhao Lin, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P407, DOI 10.1145/3372278.3391932
   Chevance A, 2020, LANCET PSYCHIAT, V7, P692, DOI 10.1016/S2215-0366(20)30191-7
   Chiu CY, 2021, J INTELL INF SYST, V56, P25, DOI 10.1007/s10844-020-00599-5
   Costello C, 2021, COLLABRA-PSYCHOL, V7, DOI 10.1525/collabra.18731
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Depression WHO., 2017, OTH COMM MENT DIS GL, P1
   Eichstaedt JC, 2018, P NATL ACAD SCI USA, V115, P11203, DOI 10.1073/pnas.1802331115
   Fatima I, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12409
   Gilbert Paul., 2007, PSYCHOTHERAPY COUNSE, V3rd
   Guntuku SC, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2019-030355
   Hameed Z, 2020, IEEE ACCESS, V8, P73992, DOI 10.1109/ACCESS.2020.2988550
   Hiraga M, 2017, P ACL 2017 STUD RES, P107
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang YC, 2019, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P32, DOI 10.5220/0007833600320040
   Islam MR, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0046-0
   Jamil Z., 2017, THESIS U OTTAWA
   Jue Wu, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3434174
   Kim Kyuri, 2020, [The journal of Convergence on Culture Technology, 문화기술의 융합], V6, P449
   King DB, 2015, ACS SYM SER, V1214, P1
   Kohrt BA, 2009, ANN HUM BIOL, V36, P261, DOI 10.1080/03014460902839194
   Kumar R, DEPRESSION DETECTION, DOI 10.24113/ojssports.v7i1.115
   Leiva V, 2017, LECT NOTES COMPUT SC, V10673, P428, DOI 10.1007/978-3-319-70284-1_34
   Li YYR, 2018, LECT NOTES COMPUT SC, V11186, P176, DOI 10.1007/978-3-030-01159-8_17
   Mandelbaum A, 2016, ARXIV PREPRINT ARXIV
   Mori K, 2021, J PERS, V89, P228, DOI 10.1111/jopy.12578
   Murfi H, 2019, INT J INTELL COMPUT
   Nadeem Moin, 2016, ARXIV PREPRINT ARXIV
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Oquendo MA, 2001, AM J PSYCHIAT, V158, P1652, DOI 10.1176/appi.ajp.158.10.1652
   Orabi P., 2018, P 5 WORKSHOP COMPUTA, P88, DOI DOI 10.18653/V1/W18-0609
   PAFFENBARGER RS, 1994, ACTA PSYCHIAT SCAND, V89, P16, DOI 10.1111/j.1600-0447.1994.tb05796.x
   Park CW, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P495, DOI 10.1109/IEA.2018.8387151
   Pranav KR, 2018, NEURAL NETWORK BASED, DOI 10.1136/bmjopen-2019-030355
   Priya A, 2020, PROCEDIA COMPUT SCI, V167, P1258, DOI 10.1016/j.procs.2020.03.442
   Rao GZ, 2020, IEEE ACCESS, V8, P32395, DOI 10.1109/ACCESS.2020.2973737
   Rosa RL, 2019, IEEE T IND INFORM, V15, P2124, DOI 10.1109/TII.2018.2867174
   Rustagi A., 2020, International conference on innovative computing and communications: proceedings of ICICC 2020, Volume 2, P19, DOI 10.1007/978-981-15-5148-2_3
   Samuel J, 2020, INFORMATION, V11, DOI 10.3390/info11060314
   Seo J, 2019, MULTIMED TOOLS APPL, V78, P28649, DOI 10.1007/s11042-018-6211-2
   Shen GY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3838
   Shetty N., 2020, Int. J. Electr. Comput. Eng., V10, ppp3751, DOI [10.11591/ijece.v10i4, DOI 10.11591/IJECE.V10I4]
   Shrestha A, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-0226-0
   Shuai HH, 2018, IEEE T KNOWL DATA EN, V30, P1212, DOI 10.1109/TKDE.2017.2786695
   Sood A., 2018, INDIAN J SCI TECHNOL, V11, P1, DOI [10.17485/ijst/2018/v11i4/119594, DOI 10.17485/ijst/2018/v11i4/119594]
   Soutner D, 2013, LECT NOTES COMPUT SC, V8082, P105, DOI 10.1007/978-3-642-40585-3_14
   Stephen JJ., 2019, Int J Electr Comput Eng, V9, P3247
   Suman S.K., 2020, NOVEL SENTIMENT ANAL
   Tommasel A, 2021, ARXIV PREPRINT ARXIV
   Tong L., 2019, ARXIV PREPRINT ARXIV
   Trotzek M, 2020, IEEE T KNOWL DATA EN, V32, P588, DOI 10.1109/TKDE.2018.2885515
   Uddin AH, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068794
   W. H. Organization, 2019, SUIC DAT
   Wang Y, 2020, ARCH DERMATOL RES, V312, P581, DOI 10.1007/s00403-020-02044-7
   Wolohan JT., 2020, P 1 WORKSHOP NLP COV
   Wu Yonghui., 2016, arXiv preprint arXiv:1609.08144, P1, DOI DOI 10.1109/ICASI.2016.7539822
   Xezonaki D, 2020, ARXIV PREPRINT ARXIV
   Xiaohui Tao, 2016, Advanced Data Mining and Applications. 12th International Conference, ADMA 2016. Proceedings: LNAI 10086, P807, DOI 10.1007/978-3-319-49586-6_59
   Zafar A, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P88, DOI [10.1109/Confluence47617.2020.9058189, 10.1109/confluence47617.2020.9058189]
   Zhang YH, 2020, IEEE INT CONF AUTOMA, P356, DOI 10.1109/FG47880.2020.00134
   Zheng WY, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348207
   Zhou TH, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16060953
   Zogan H, 2020, ARXIV PREPRINT ARXIV
   Zucco C, 2017, IEEE INT C BIOINFORM, P1988, DOI 10.1109/BIBM.2017.8217966
NR 76
TC 33
Z9 33
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23649
EP 23685
DI 10.1007/s11042-022-12648-y
EA MAR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800032
PM 35317471
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Pathak, S
   Raj, R
   Singh, K
   Verma, PK
   Kumar, B
AF Pathak, Shashwat
   Raj, Rahul
   Singh, Kartik
   Verma, Pawan Kumar
   Kumar, Basant
TI Development of portable and robust cataract detection and grading system
   by analyzing multiple texture features for Tele-Ophthalmology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cataract; Intensity; Uniformity; Standard deviation; Randomness;
   K-means; Machine learning; Grading; Cloud computing; Tele-ophthalmology
AB This paper presents a low cost, robust, portable and automated cataract detection system which can detect the presence of cataract from the colored digital eye images and grade their severity. Ophthalmologists detect cataract through visual screening using ophthalmoscope and slit lamps. Conventionally a patient has to visit an ophthalmologist for eye screening and treatment follows the course. Developing countries lack the proper health infrastructure and face huge scarcity of trained medical professionals as well as technicians. The condition is not very satisfactory with the rural and remote areas of developed nations. To bridge this barrier between the patient and the availability of resources, current work focuses on the development of portable low-cost, robust cataract screening and grading system. Similar works use fundus and retinal images which use costly imaging modules and image based detection algorithms which use much complex neural network models. Current work derives its benefit from the advancements in digital image processing techniques. A set of preprocessing has been done on the colored eye image and later texture information in form of mean intensity, uniformity, standard deviation and randomness has been calculated and mapped with the diagnostic opinion of doctor for cataract screening of over 200 patients. For different grades of cataract severity edge pixel count was calculated as per doctor's opinion and later these data are used for calculating the thresholds using hybrid k-means algorithm, for giving a decision on the presence of cataract and grade its severity. Low value of uniformity and high value of other texture parameters confirm the presence of cataract as clouding in eye lens causes the uniformity function to take lower value due to presence of coarse texture. Higher the edge pixel count value, this confirms the presence of starting of cataract as solidified regions in lens are nonuniform. Lower value corresponds to fully solidified region or matured cataract. Proposed algorithm was initially developed on MATLAB, and tested on over 300 patients in an eye camp. The system has shown more than 98% accuracy in detection and grading of cataract. Later a cloud based system was developed with 3D printed image acquisition module to manifest an automated, portable and efficient cataract detection system for Tele-Ophthalmology. The proposed system uses a very simple and efficient technique by mapping the diagnostic opinion of the doctor as well, giving very promising results which suggest its potential use in teleophthalmology applications to reduce the cost of delivering eye care services and increasing its reach effectively. Developed system is simple in design and easy to operate and suitable for mass screening of cataracts. Due to non-invasive and non-mydriatic and mountable nature of device, in person screening is not required. Hence, social distancing norms are easy to follow and device is very useful in COVID-19 like situation.
C1 [Pathak, Shashwat] MIET, Dept Elect & Commun Engn, Meerut 250005, Uttar Pradesh, India.
   [Raj, Rahul] Incubat Ctr IIT Patna, Electro Curietech Private Ltd, Patna 801103, Bihar, India.
   [Singh, Kartik] Deepcompute Software India Pvt Ltd, Comp Sci Dept, Bengaluru, India.
   [Verma, Pawan Kumar] Dr BR Ambedkar NIT Jalandhar, Dept Elect & Commun, Jalandhar 144011, Punjab, India.
   [Kumar, Basant] MNNIT Allahabad, ECED, Prayagraj 211004, India.
C3 Meerut Institute of Engineering & Technology; National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Pathak, S (corresponding author), MIET, Dept Elect & Commun Engn, Meerut 250005, Uttar Pradesh, India.
EM shashwat.pathak@miet.ac.in; rr@ecpl-global.com; kartik.ynwa@gmail.com;
   vermapk@nitj.ac.in; singhbasant@mnnit.ac.in
RI Pathak, Shashwat/HGU-8359-2022; Verma, Pawan Kumar/Y-2197-2019; Verma,
   Pawan/ABA-0143-2022
OI Pathak, Shashwat/0000-0002-0883-4929; 
FU Ministry of Electronics and IT (MeitY), Government of India
FX Authors are very thankful to Ministry of Electronics and IT (MeitY),
   Government of India for funding the development of this device. We thank
   the Incubation Center IIT Patna for helping us develop this system,
   Ophthalmologists and all the supporting staff from LLHRC, Barauni for
   their invaluable support in development of the presented system, their
   full support during field trial and testing of initial algorithm to the
   final developed cataract screening and grading system.
CR Ackland P, 2012, INDIAN J OPHTHALMOL, V60, P380, DOI 10.4103/0301-4738.100531
   [Anonymous], 2009, INT C INSTRUMENTATIO, DOI DOI 10.1109/ICICIBME.2009.5417287
   [Anonymous], 2013, Signal Image Process. Int. J, DOI DOI 10.5121/SIPIJ.2013.4306
   Caixinha M, 2015, PHYSCS PROC, V70, P1221, DOI 10.1016/j.phpro.2015.08.263
   Caixinha M, 2014, IEEE INT ULTRA SYM, P2402, DOI 10.1109/ULTSYM.2014.0599
   Charoenpong T, 2013, IEEE INT C NETW SENS, P300, DOI 10.1109/ICNSC.2013.6548754
   Comas O, 2010, LECT NOTES COMPUT SC, V5958, P160, DOI 10.1007/978-3-642-11615-5_17
   DENG G, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1615, DOI 10.1109/NSSMIC.1993.373563
   Dey S, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P382, DOI 10.1109/ADCOM.2007.79
   Dixit A, 2018, 2018 9 INT C COMP CO, P1
   El-Zaart A, 2010, COMP ENG TECHN ICCET, V4, pV4
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Gary B, 2001, B WORLD HEALTH ORGAN
   German A, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P81, DOI 10.1109/CRV.2005.38
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Li HQ, 2010, IEEE T BIO-MED ENG, V57, P1690, DOI 10.1109/TBME.2010.2041454
   Liu YL, 2016, INT C COMP SUPP COOP, P373, DOI 10.1109/CSCWD.2016.7566017
   Meimei Yang, 2013, 2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013), P674, DOI 10.1109/HealthCom.2013.6720761
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Nayak J., 2013, P WORLD C ENG COMPUT, V1, P23
   Pathak S, 2016, ELECTRONICS-SWITZ, V5, DOI 10.3390/electronics5030057
   Sepasian M, 2008, LECT NOTES ENG COMP, P1199
   Shen HL, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 1, PROCEEDINGS, P583, DOI 10.1109/ISCSCT.2008.78
   Singh N., 2011, INT J ADVANC ENG TEC, V1, P221
   Srivastava R, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.1.014502
   Supriyanti R, 2008, PROC SPIE, V6915, DOI 10.1117/12.770069
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Wang XM, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.563
   Yang JJ, 2016, COMPUT METH PROG BIO, V124, P45, DOI 10.1016/j.cmpb.2015.10.007
NR 29
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23355
EP 23371
DI 10.1007/s11042-022-12544-5
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800022
PM 35317470
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hu, HT
   Lu, YH
   Lee, TT
AF Hu, Hwai-Tsu
   Lu, Ying-Hsiang
   Lee, Tung-Tsun
TI Blind image watermarking via psychovisual-based relative modulation in
   DCT domain with performance optimized by GWO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image watermarking; Discrete cosine transform; Psychovisual-based
   relative modulation; Grey wolf optimizer
ID SINGULAR-VALUE DECOMPOSITION; INTERBLOCK PREDICTION; WAVELET DOMAIN;
   ROBUST; SCHEME
AB A psychovisual-based relative modulation (PRM) scheme with performance fine-tuned by the grey wolf optimizer (GWO) is introduced to carry out effective blind image watermarking. This watermarking scheme starts with partitioning the host image into blocks of equal size and then applies the two-dimensional discrete cosine transform (DCT) to each block. Binary embedding in each DCT block is achieved by manipulating a strategically selected DCT coefficient with the embedding strength adaptively governed by a psychovisual model. The most appropriate DCT coefficient for PRM watermarking has been theoretically investigated and experimentally verified. The GWO plays the role of pursuing the optimal parameters that jointly attain a balanced performance in imperceptibility and robustness. Experimental results indicate that the proposed PRM-GWO scheme is competent to cope with a wide variety of attacks including image compression (JPEG and JPEG2000), noise contamination (white Gaussian, salt-and-pepper, speckle), filtering (lowpass, unsharp, median, Wiener), histogram equalization, geometric correction, and luminance adjustment. Furthermore, the PRM-GWO outperforms the other four DCT-based schemes in terms of the bit error rates of the recovered watermarks.
C1 [Hu, Hwai-Tsu; Lu, Ying-Hsiang; Lee, Tung-Tsun] Natl Ilan Univ, Dept Elect Engn, Yilan City, Taiwan.
C3 National Ilan University
RP Hu, HT (corresponding author), Natl Ilan Univ, Dept Elect Engn, Yilan City, Taiwan.
EM hthu@niu.edu.tw
OI Hu, Hwai-Tsu/0000-0001-6519-7535
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   108-2221-E-197-013]
FX This research work was supported in part by the Ministry of Science and
   Technology, Taiwan, ROC under Grants MOST 108-2221-E-197-013.
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P6897, DOI 10.1007/s11042-014-1934-1
   Ahumada A. J.  Jr., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1666, P365, DOI 10.1117/12.135982
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Arnold M., 2003, ARTECH H COMP SEC LI
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Hsu LY, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113225
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P172, DOI 10.1016/j.aeue.2015.11.003
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Li L, 2017, MODIFIED DISCRETE GR
   Li LG, 2016, IEEE ACCESS, V4, P6438, DOI 10.1109/ACCESS.2016.2613940
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Sun R, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1592, DOI 10.1109/ICOSP.2002.1180102
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Zhang T, 2015, P INT C EL ENG INF S
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
NR 41
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21675
EP 21695
DI 10.1007/s11042-022-12645-1
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800005
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhang, Y
   Yang, FB
   Wang, XX
   Ji, LN
AF Zhang, Lei
   Zhang, Yu
   Yang, Fengbao
   Wang, Xiaoxia
   Ji, Linna
TI Multi-modal image fusion with the hybrid
   <i>l</i><sub>0</sub><i>l</i><sub>1</sub> layer decomposing and
   multi-directional filter banks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal image; The hybrid l(0)l(1) layer decomposing;
   Multi-directional filter banks; Image fusion
ID QUALITY ASSESSMENT; SIMILARITY; TRANSFORM
AB The key problem of multi-modal image fusion is that the complementary features of the source images are easily lose in the fusion. In this paper, the fusion algorithm is proposed with the hybrid l(0)l(1) layer decomposing and multi-directional filter banks to extract edge, contour, and detail features from images and fuse the complementary features well. First, the hybrid l(0)l(1) layer decomposing is ability to effectively overcome halo artifacts and over-enhancement, when the detail features are eliminated, so the low-frequency and detail features of the source images are separated. Then, the visual salient detection based on ant colony optimisation and local phase coherenceis is introduced to guide the fusion of the base lay images. Then the detail image is decomposed by using multi-directional filter banker, and the different direction detail features are extracted, and the fusion rule multi-directional gradient and principal component analysis are adopted for the detail sub-band images to prevent the loss of detail features. Finally, the final fused image is reconstructed by the inverse transformation of the hybrid l(0)l(1) layer decomposing. Experimental results demonstrate that the values of the spatial frequency, the the standard deviation, the edge strength,the difference seminary index, and the difference structural similarity are increased significantly, so the proposed fusion algorithm can effectively preserve the complementary information between images and improve the quality of fused images.
C1 [Zhang, Lei; Zhang, Yu] Nan Yang Normal Univ, Nan Yang 473061, Peoples R China.
   [Yang, Fengbao; Wang, Xiaoxia; Ji, Linna] North Univ China, Taiyuan 030051, Peoples R China.
C3 North University of China
RP Zhang, L (corresponding author), Nan Yang Normal Univ, Nan Yang 473061, Peoples R China.
EM zhanglei000223@163.com
FU National Natural Science Foundation of China [61672472]; Key Lab of
   Dynamic Measurement Technology in North University of China; programs of
   innovative research teams of the North University of China; Tianjin
   Natural Science Foundation [16JCYBJC42000]; Doctoral Program of Nanyang
   normal University; open fund project in 2020 of Key Laboratory of Marine
   Environmental Information Technology (The research on remote sensing
   image sea ice classification based on generated adversarial network)
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant No. 61672472), the Fund from Key Lab of
   Dynamic Measurement Technology in North University of China, and the
   programs of innovative research teams of the North University of China,
   Tianjin Natural Science Foundation(16JCYBJC42000, Doctoral Program of
   Nanyang normal University. The open fund project in 2020 of Key
   Laboratory of Marine Environmental Information Technology (The research
   on remote sensing image sea ice classification based on generated
   adversarial network).
CR Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Budhiraja S., 2018, BIOMED PHARMACOL J, V11, P1937, DOI [10.13005/bpj/1566, DOI 10.13005/BPJ/1566]
   Chen J, 2021, SIGNAL PROCESS, V182, DOI 10.1016/j.sigpro.2020.107936
   Ganasala P, 2014, BIOMED ENG LETT, V4, P414, DOI 10.1007/s13534-014-0161-z
   He KJ, 2018, J SENSORS, V2018, DOI 10.1155/2018/5754702
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Hu JW, 2012, INFORM FUSION, V13, P196, DOI 10.1016/j.inffus.2011.01.002
   Jin XZ, 2021, IEEE T SYST MAN CY-S, V51, P2272, DOI 10.1109/TSMC.2019.2911269
   Li JJ, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00282-7
   Li J, 2021, IEEE T MULTIMEDIA, V23, P1383, DOI 10.1109/TMM.2020.2997127
   Li M, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012151
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Long Y., 2020, 2020 57th ACM/IEEE Design Automation Conference (DAC), P1, DOI DOI 10.1109/I2MTC43012.2020.9129204
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma L, 2010, ELECTRON LETT, V46, P1066, DOI 10.1049/el.2010.0072
   Mendi E, 2015, J INTELL FUZZY SYST, V28, P1039, DOI 10.3233/IFS-141387
   Song MH, 2019, INFRARED PHYS TECHN, V101, P45, DOI 10.1016/j.infrared.2019.05.017
   Tan W, 2019, APPL OPTICS, V58, P3064, DOI 10.1364/AO.58.003064
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan L., 2019, ISA T, P1
   Yan X, 2015, APPL OPTICS, V54, P4299, DOI 10.1364/AO.54.004299
   [闫翔宇 Yan Xiangyu], 2019, [建筑钢结构进展, Progress in Steel Building Structures], V21, P23
   Yang Y., 2020, HERALD MED, P1
   Zhang JH, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023021
   Zhang L, 2016, INFRARED PHYS TECHN, V79, P91, DOI 10.1016/j.infrared.2016.09.014
   Zhang S, 2020, ELECTRON LETT, V56, P761, DOI 10.1049/el.2020.0557
   Zhang SQ, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2020.103626
   Zhang XY, 2017, J OPT SOC AM A, V34, P1400, DOI 10.1364/JOSAA.34.001400
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
NR 40
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21369
EP 21384
DI 10.1007/s11042-022-12749-8
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700009
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, TD
   Bandyopadhyay, S
AF Singh, Alok
   Singh, Thoudam Doren
   Bandyopadhyay, Sivaji
TI V2T: video to text framework using a novel automatic shot boundary
   detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Illumination; Motion effect; Abrupt transition;
   Video captioning
AB The generation of natural language descriptions for a video has been reported by many researchers till now. But, it is still the most interesting research topic among the researchers due to the emerging interdisciplinary problem of Computer Vision (CV), Natural Language Processing (NLP) and Deep Learning (DL). The results of a video description are still not convincing due to the redundancy of a large number of similar frames in a video. In this paper, we propose dual-stage based text generation approach in which the first stage is for reducing redundancy due to the similar frames by processing selected sets of frames and keyframe from the shots of a video and in the second stage, the text generator module will generate relevant text for a video using the selected sets of frames and keyframes of each shot. In the first stage, a flexible novel shot boundary detection (SBD or temporal boundaries) approach is proposed which will segment the video into shots and then keyframe and set of frames are selected from each shot using frame selection policy. Then, the spatio-temporal features for each segment and 2D features for each keyframe are extracted respectively using the 3D convolutional network and VGG19. These features are passed to the next stage where these features are embedded with semantic concepts related to video and then text generation will take place using Long Short Term Memory (LSTM) recurrent network. The proposed approach is the amalgamation of classical and modern computer vision techniques. In the first stage, the Noise-Resistant Local Binary Pattern (NRLBP) feature is used for detecting illumination and motion invariant temporal boundaries in a video and processing keyframes and sets of frames for the further text generation. TRECVid 2001 and 2007 datasets are used to validate the exactness of the proposed SBD approach and MSR-VTT (Microsoft Research Video to Text ) and YouTube2text (MSVD) datasets are applied to analyze and validate the performance of proposed video to text generation approach.
C1 [Singh, Alok; Singh, Thoudam Doren; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.
   [Singh, Alok; Singh, Thoudam Doren; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Singh, A (corresponding author), Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.; Singh, A (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
EM alok_rs@cse.nits.ac.in
OI SINGH, ALOK/0000-0002-2683-0542
FU Scheme for Promotion of Academic and Research Collaboration (SPARC)
   under MHRD, Govt of India [P995, SPARC/2018-2019/119/SL]
FX This work is supported by Scheme for Promotion of Academic and Research
   Collaboration (SPARC) Project Code: P995 of No: SPARC/2018-2019/119/SL
   (IN) under MHRD, Govt of India.
CR Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   [Anonymous], 2014, ARXIV14124729
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Chakraborty S., 2019, ARXIV190704373, P1
   Chakraborty S, 2022, VISUAL COMPUT, V38, P445, DOI 10.1007/s00371-020-02027-9
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Cherian A, 2020, IEEE WINT CONF APPL, P1606, DOI 10.1109/WACV45572.2020.9093291
   Daskalakis E, 2018, PATTERN RECOGN LETT, V116, P143, DOI 10.1016/j.patrec.2018.09.022
   Ding ST, 2019, FUTURE GENER COMP SY, V93, P583, DOI 10.1016/j.future.2018.10.054
   Gao L, 2019, NEUROCOMPUTING
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Hassanien A., 2017, Large-scale, fast and accurate shot boundary detection through spatio-temporal convolutional neural networks
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Li W, 2018, PATTERN RECOGN LETT, V105, P23, DOI 10.1016/j.patrec.2017.10.012
   Liu AA, 2017, COMPUT VIS IMAGE UND, V163, P113, DOI 10.1016/j.cviu.2017.04.013
   Long Xiang, 2018, T ASSOC COMPUT LING, V6, P173, DOI DOI 10.1162/TACL_A_00013
   Nabati M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102302
   Nabati M, 2020, COMPUT VIS IMAGE UND, V190, DOI 10.1016/j.cviu.2019.102840
   Nian FD, 2017, COMPUT VIS IMAGE UND, V163, P126, DOI 10.1016/j.cviu.2017.06.012
   Pini S, 2019, MULTIMED TOOLS APPL, V78, P14007, DOI 10.1007/s11042-018-7040-z
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   Shin A, 2016, IEEE IMAGE PROC, P3364, DOI 10.1109/ICIP.2016.7532983
   Singh A, 2020, ARXIV201114752
   Singh Alok, 2020, ARXIV200604058
   Singh A, 2020, SOFTWARE PRACT EXPER, V50, P2012, DOI 10.1002/spe.2722
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Venugopalan S., 2016, EMNLP, P1961
   Wang HY, 2020, PATTERN RECOGN LETT, V130, P327, DOI 10.1016/j.patrec.2018.07.024
   Xiao, 2020, PATTERN RECOGN LETT
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YC, 2019, NEUROCOMPUTING, V357, P24, DOI 10.1016/j.neucom.2019.05.027
NR 38
TC 6
Z9 7
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17989
EP 18009
DI 10.1007/s11042-022-12343-y
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701800002
DA 2024-07-18
ER

PT J
AU Rani, S
   Lakhwani, K
   Kumar, S
AF Rani, Shilpa
   Lakhwani, Kamlesh
   Kumar, Sandeep
TI Three dimensional objects recognition & pattern recognition technique;
   related challenges: A review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Local feature; Global feature; 3D object recognition; Pattern
   recognition
ID PRINCIPAL COMPONENT ANALYSIS; HIDDEN MARKOV-MODELS; FACE-RECOGNITION;
   RANGE IMAGES; NEURAL-NETWORKS; 3D; MACHINE; CLASSIFICATION;
   REPRESENTATION; PCA
AB 3D object recognition and pattern recognition are active and fast-growing research areas in the field of computer vision. It is mandatory to define the pattern class, feature extraction, design classifiers, clustering, and selection of test datasets and evaluate performance for any pattern recognition system. The pattern recognition system recognizes the object, so it is required to extract the features in such a way that it will be suitable for a particular recognition method. Features can be retrieved either locally or globally. The object recognition technique is divided into two parts: the local feature extraction method and the global feature extraction method. Many researchers have done admirable work in the field of local and global feature extraction. Local feature-based techniques are more suitable for the real-world scene. The Global feature-based methods are more suitable for retrieving the 3D model & identifying the object's shape when the object's geometric structure is fragile. A lot of research has been done on pattern recognition in the last 50 years. Still, no single technique can be used for all types of applications, such as bioinformatics, data mining, speech recognition, remote sensing, multimedia applications, text detection, localization, etc. The main agenda of this paper is to summarize the 3D object recognition methodologies. This paper provides a complete study of 3D object recognition based on local and global feature-based methods and different techniques of pattern recognition. We have tried to summarize the results of different technologies and the future scope of this paper's particular technique. We enlisted the accessible online 3D database and their attributes, evaluation parameters of the 3D datasets. This paper will immensely help the researchers to Identify the research gap and limitations in pattern recognition and object recognition so that the researchers will be motivated to do something new in this field.
C1 [Rani, Shilpa] Lovely Profess Univ, Phagwara, Punjab, India.
   [Rani, Shilpa] Neil Gogte Inst Technol, Dept CSE, Hyderabad, Telangana, India.
   [Lakhwani, Kamlesh] JECRC Univ, Jaipur, Rajasthan, India.
   [Kumar, Sandeep] Koneru Lakshmaiah Educ Fdn, Dept CSE, Hyderabad, Andhra Pradesh, India.
C3 Lovely Professional University; Koneru Lakshmaiah Education Foundation
   (K L Deemed to be University)
RP Rani, S (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.; Rani, S (corresponding author), Neil Gogte Inst Technol, Dept CSE, Hyderabad, Telangana, India.
EM shilpachoudhary2020@gmail.com; kamlesh.lakhwani@gmail.com;
   er.sandeepsahratia@gmail.com
RI Kumar, Sandeep/ADM-4627-2022; Lakhwani, Kamlesh/AFU-0937-2022;
   choudhary, shilpa/HKV-1084-2023
OI Kumar, Sandeep/0000-0002-4752-7884; Lakhwani,
   Kamlesh/0000-0002-4731-5179; choudhary, shilpa/0000-0001-5809-6269
CR Abarghouei AA, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P448, DOI 10.1109/SoCPaR.2009.93
   Abiodun OI, 2019, IEEE ACCESS, V7, P158820, DOI 10.1109/ACCESS.2019.2945545
   Ahmad T., 2011, Proceedings of the 1st International Conference on Computer Networks and Information Technology (ICCNIT 2011), P87, DOI 10.1109/ICCNIT.2011.6020913
   Aldoma Aitor, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P113, DOI 10.1007/978-3-642-32717-9_12
   Aldoma A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P585, DOI 10.1109/ICCVW.2011.6130296
   Aldoma A, 2012, LECT NOTES COMPUT SC, V7574, P511, DOI 10.1007/978-3-642-33712-3_37
   Altun Y, 2003, ADV NEURAL INFORM PR, P1001
   Altun Y., 2003, ICML
   Aly S, 2019, IEEE ACCESS, V7, P52024, DOI 10.1109/ACCESS.2019.2911851
   Ariesta MC, 2018, 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL CONFERENCE (INAPR), P16, DOI 10.1109/INAPR.2018.8627016
   ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255
   Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170
   Badr G, 2006, IEEE T SYST MAN CY B, V36, P611, DOI 10.1109/TSMCB.2005.861860
   Bariya P, 2012, INT J COMPUT VISION, V99, P232, DOI 10.1007/s11263-012-0526-7
   Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774
   Bauer A, 2014, IEEE T NEUR NET LEAR, V25, P870, DOI 10.1109/TNNLS.2013.2281761
   Bayramoglu Neslihan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P352, DOI 10.1109/ICPR.2010.95
   BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081
   Bingjie Wang, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P650, DOI 10.1109/ICIG.2013.133
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Brady J. P., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P85, DOI 10.1109/ICPR.1988.28178
   Bricq S, 2008, INT CONF ACOUST SPEE, P517, DOI 10.1109/ICASSP.2008.4517660
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Burnham AJ, 1999, CHEMOMETR INTELL LAB, V48, P167, DOI 10.1016/S0169-7439(99)00018-0
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Chaa M, 2019, IET IMAGE PROCESS, V13, P736, DOI 10.1049/iet-ipr.2018.5642
   Chang A. X., 2015, ARXIV
   Chatterjee A, 2017, OPT LASER ENG, V95, P1, DOI 10.1016/j.optlaseng.2017.03.007
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003
   Chen TT, 2014, IEEE INT VEH SYM, P667, DOI 10.1109/IVS.2014.6856425
   Chen ZH, 2017, IEEE T IND INFORM, V13, P3070, DOI 10.1109/TII.2017.2712746
   Chiswell Ian., 2007, Mathematical Logic
   Choudhary S, 2012, INT J ENG RES TECHNO, V8
   Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Cui LX, 2016, LECT NOTES COMPUT SC, V10029, P3, DOI 10.1007/978-3-319-49055-7_1
   Cunhe L, 2010, 2 INT C FUTURE COMPU
   D'Addona DM, 2017, J INTELL MANUF, V28, P1285, DOI 10.1007/s10845-015-1155-0
   Davis C.S., 1992, Advances in Limnology, V36, P67
   Deng WH, 2014, IEEE T PATTERN ANAL, V36, P1275, DOI 10.1109/TPAMI.2013.194
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Dong M, 2008, IEEE IMAGE PROC, P185, DOI 10.1109/ICIP.2008.4711722
   Donghui Wang, 2006, The 12th International Multi-Media Modelling Conference Proceedings
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   Durbin R., 2000, BIOL SEQUENCE ANAL
   Dutton DM, 1997, KNOWL ENG REV, V12, P341, DOI 10.1017/S026988899700101X
   Flint A., 2007, 9 BIENN C AUSTR PATT, P182, DOI [DOI 10.1109/DICTA.2007.4426794, 10.1109/DICTA.2007.4426794]
   Fookes C, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P447, DOI 10.1109/ICIP.2000.899444
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Ganapathi II, 2018, IET BIOMETRICS, V7, P232, DOI 10.1049/iet-bmt.2017.0212
   Gao GW, 2017, PATTERN RECOGN, V66, P129, DOI 10.1016/j.patcog.2016.12.021
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Germann M, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P81
   Ghasemzadeh A, 2018, IET BIOMETRICS, V7, P49, DOI 10.1049/iet-bmt.2017.0082
   Ghinea G, 2014, IEEE ACCESS, V2, P914, DOI 10.1109/ACCESS.2014.2348018
   Guo YL, 2013, OPTIK, V124, P2727, DOI 10.1016/j.ijleo.2012.08.035
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Guo Yulan., 2013, Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications, V1, P86, DOI [10.5220/0004277600860093, DOI 10.5220/0004277600860093]
   Han XX, 2010, IEEE ACM T COMPUT BI, V7, P537, DOI 10.1109/TCBB.2009.36
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   Helmer S, 2011, LECT NOTES COMPUT SC, V6492, P464, DOI 10.1007/978-3-642-19315-6_36
   Hetzel G., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pII, DOI 10.1109/CVPR.2001.990988
   Huang KY, 2019, IEEE J-STARS, V12, P2453, DOI 10.1109/JSTARS.2019.2908690
   Husen MN, 2016, 2016 PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICICTM), P71, DOI 10.1109/ICICTM.2016.7890780
   Hussein S, 2019, IEEE T MED IMAGING, V38, P1777, DOI 10.1109/TMI.2019.2894349
   Iwana BK, 2017, PATTERN RECOGN, V64, P268, DOI 10.1016/j.patcog.2016.11.013
   Jaf S, 2019, IEEE ACCESS, V7, P131363, DOI 10.1109/ACCESS.2019.2939687
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56
   Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382
   Jasmin G.D., 2013, Global Journal of Computer Science and Technology, V11, P207
   Kamper H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P678
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   Kasaei SH, 2016, PATTERN RECOGN LETT, V83, P312, DOI 10.1016/j.patrec.2016.07.006
   Kiran P. Sasi, 2019, 2019 IEEE International Conference on Intelligent Systems and Green Technology (ICISGT). Proceedings, P31, DOI 10.1109/ICISGT44072.2019.00022
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43
   Kubo Y, 2010, IEEE J-STSP, V4, P974, DOI 10.1109/JSTSP.2010.2076030
   Kumar DA, 2019, IEEE SIGNAL PROC LET, V26, P169, DOI 10.1109/LSP.2018.2883864
   Kumar Sandeep, 2019, Data and Communication Networks. Proceedings of GUCON 2018. Advances in Intelligent Systems and Computing (AISC 847), P253, DOI 10.1007/978-981-13-2254-9_23
   Kumar S, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P648, DOI 10.1109/CCWC.2019.8666601
   Kumar S, 2018, WIRELESS PERS COMMUN, V103, P2353, DOI 10.1007/s11277-018-5913-0
   Kumar S, 2018, WIRELESS PERS COMMUN, V103, P2435, DOI 10.1007/s11277-018-5923-y
   Kumar S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1001, DOI 10.1109/CCAA.2017.8229960
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Kwan RKS, 1996, LECT NOTES COMPUT SC, V1131, P135, DOI 10.1007/BFb0046947
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Thang LQ, 2012, INT CONF ASIAN LANG, P25, DOI 10.1109/IALP.2012.12
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lee JS, 2010, IEEE T SYST MAN CY B, V40, P1188, DOI 10.1109/TSMCB.2009.2036753
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lee LM, 2013, IEEE T CYBERNETICS, V43, P2114, DOI 10.1109/TCYB.2013.2240450
   Lei YJ, 2014, PATTERN RECOGN, V47, P509, DOI 10.1016/j.patcog.2013.07.018
   Li XJ, 2007, IEEE I CONF COMP VIS, P9
   Li ZY, 2018, I S BIOMED IMAGING, P926, DOI 10.1109/ISBI.2018.8363722
   Lisin D, 2005, 2005 IEEE COMP SOC C, P47, DOI [10.1109/CVPR.2005.433, 10/c3854f, DOI 10.1109/CVPR.2005.433]
   Liu FY, 2017, IEEE I CONF COMP VIS, P5679, DOI 10.1109/ICCV.2017.605
   Liu Q, 2007, P 2007 2 IEEE INT WO, P1, DOI DOI 10.1109/CAMSAP.2007.4497950
   Liu YT, 2016, IEEE T NEUR NET LEAR, V27, P347, DOI 10.1109/TNNLS.2015.2496330
   Lou ZY, 2015, IEEE T IMAGE PROCESS, V24, P3098, DOI 10.1109/TIP.2015.2431443
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madry M, 2012, IEEE INT C INT ROBOT, P1379, DOI 10.1109/IROS.2012.6385874
   Mage L, 2017, PROCESS SAF ENVIRON, V110, P43, DOI 10.1016/j.psep.2017.02.017
   Maharani DA, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P1, DOI 10.1109/ISCAIE.2018.8405435
   Mahendran S, 2017, IEEE COMPUT SOC CONF, P494, DOI 10.1109/CVPRW.2017.73
   Mall Shachi, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P55, DOI 10.1109/ICCCT.2014.7001469
   Mamic G, 2002, DIGIT SIGNAL PROCESS, V12, P47, DOI 10.1006/dspr.2001.0412
   Manning C., 1999, FDN STAT NATURAL LAN, P1
   Martinez A., 1998, AR FACE DATABASE
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   Muja M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P2939, DOI 10.1109/ICRA.2011.5980153
   Naeimizaghiani M, 2011, P 2011 INT C ELECT E, P1
   Nascimento JC, 2010, IEEE T IMAGE PROCESS, V19, P1338, DOI 10.1109/TIP.2009.2039664
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Naz S, 2017, NEUROCOMPUTING, V243, P80, DOI 10.1016/j.neucom.2017.02.081
   Niu J. W., 2011, 2011 IEEE 18th International Conference on Industrial Engineering and Engineering Management (IE&EM 2011), P600, DOI 10.1109/ICIEEM.2011.6035230
   Nock R, 2006, IEEE T PATTERN ANAL, V28, P1223, DOI 10.1109/TPAMI.2006.168
   Ogiela MR, 2000, P SOC PHOTO-OPT INS, V4057, P308, DOI 10.1117/12.381746
   Onishi K, 2008, INT C PATT RECOG, P1466
   Orabona F, 2015, MACH LEARN, V99, P411, DOI 10.1007/s10994-014-5474-8
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Pan X, 2019, IEEE ACCESS, V7, P172403, DOI 10.1109/ACCESS.2019.2954693
   Papaioannou A, 2014, IEEE T NEUR NET LEAR, V25, P1719, DOI 10.1109/TNNLS.2013.2285783
   PAPALEXOPOULOS AD, 1990, IEEE T POWER SYST, V5, P1535, DOI 10.1109/59.99410
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pavlidis T., 1977, STRUCTURAL PATTERN R
   Peralta D, 2018, INT J INTELL SYST, V33, P213, DOI 10.1002/int.21948
   Peralta D, 2017, KNOWL-BASED SYST, V126, P91, DOI 10.1016/j.knosys.2017.03.014
   Perez-Cortes JC, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P19, DOI 10.1109/DEXA.2009.87
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Ramanathan R, 1997, INT J FORECASTING, V13, P161, DOI 10.1016/S0169-2070(97)00015-0
   REDDY TA, 1995, J SOL ENERG-T ASME, V117, P31, DOI 10.1115/1.2847720
   REDDY TA, 1994, ENERG BUILDINGS, V21, P35, DOI 10.1016/0378-7788(94)90014-0
   Rusu Radu Bogdan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P47, DOI 10.1109/ICCVW.2009.5457718
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Salem MZ, 2021, TURKISH J COMPUT MAT, V12, P3286
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sarker J, 2019, 2019 1 INT C ADV SCI, P1
   Sarwinda Devvi, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P457, DOI 10.1109/ICIS.2018.8466524
   Seo M, 2016, ARXIV PREPRINT ARXIV, V534
   Shafer CM, 2011, BIOM SCI ENG C BSEC, P1
   Shang LM, 2010, INT J COMPUT VISION, V89, P211, DOI 10.1007/s11263-009-0276-3
   Shen Y, 2008, IEEE T NEURAL NETWOR, V19, P528, DOI 10.1109/TNN.2007.911751
   Shuai Tang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P525, DOI 10.1007/978-3-642-37444-9_41
   Lima JPSD, 2016, SIBGRAPI, P56, DOI [10.1109/SIBGRAPI.2016.017, 10.1109/SIBGRAPI.2016.16]
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sok P, 2018, IEEE SENS J, V18, P6369, DOI 10.1109/JSEN.2018.2845749
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Söylemez ÖF, 2017, SIG PROCESS COMMUN
   Sturm J., 2011, RGB D WORKSH ADV REA, P1
   Sukno FM, 2012, LECT NOTES COMPUT SC, V7432, P92, DOI 10.1007/978-3-642-33191-6_10
   Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634
   Taati B., 2007, 11 IEEE INT C COMPUT, P1
   Taati B, 2011, COMPUT VIS IMAGE UND, V115, P681, DOI 10.1016/j.cviu.2010.11.021
   Taskar B, 2004, ADV NEUR IN, V16, P25
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Tomita M, 1991, GEN LR PARSING, DOI [10.1007/978-1-4615-4034-2_1, DOI 10.1007/978-1-4615-4034-2_1]
   Ueda M, 2019, I S BIOMED IMAGING, P380, DOI [10.1109/isbi.2019.8759392, 10.1109/ISBI.2019.8759392]
   Uhlmann E, 2017, PROC CIRP, V62, P458, DOI 10.1016/j.procir.2016.06.060
   Wang Z, 2019, IEEE ACCESS, V7, P152658, DOI 10.1109/ACCESS.2019.2948088
   Weinzaepfel P, 2019, PROC CVPR IEEE, P5617, DOI 10.1109/CVPR.2019.00578
   Wen MR, 2012, CHIN CONTR CONF, P3779
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760
   Wohlkinger W, 2012, IEEE INT C SIGNAL IM, P115
   Wozniak M., 2010, 2 ND INT C COMPUTER
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xin YW, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2584
   Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806
   Yong-Hui Xu, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1188, DOI 10.1109/ICMLC.2012.6359524
   Yu YJ, 2007, PROC INT CONF DOC, P516
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zeng YJ, 2017, IEEE T INTELL TRANSP, V18, P1647, DOI 10.1109/TITS.2016.2614916
   Zhang Q, 2015, IEEE T PATTERN ANAL, V37, P1206, DOI 10.1109/TPAMI.2014.2361121
   Zhang X, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P61, DOI 10.1109/IITA.2008.314
   Zhang YJ, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P3840
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
   Zheng Q, 2018, MATH PROBL ENG, P105
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhun Fan, 2017, 2017 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII). Proceedings, P47, DOI 10.1109/ICIICII.2017.52
NR 187
TC 12
Z9 12
U1 9
U2 97
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17303
EP 17346
DI 10.1007/s11042-022-12412-2
EA MAR 2022
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900006
DA 2024-07-18
ER

PT J
AU Fang, J
   Jiang, MH
   Yin, NN
   Wei, D
   Zhang, Y
AF Fang, Jie
   Jiang, Minghao
   Yin, Nannan
   Wei, Da
   Zhang, Yin
TI An image block encryption algorithm based on hyperchaotic system and DNA
   encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image block; DNA encoding; Hyperchaotic system;
   Fractional Fourier transform
ID CHAOTIC SYSTEM
AB This paper presents an innovative image block encryption algorithm adopting fractional Fourier transform (FRFT), hyperchaotic system, improved logistic map and Deoxyribonucleic Acid (DNA) encoding. Initially, the plaintext image is performed FRFT twice, and the processed image is decomposed into three components according to the RGB channels. Then, three components and the matrix created by logistic map are divided into several sub-blocks. The sub-blocks are performed DNA encoding. Furthermore, perform DNA operation between the three components sub-blocks and the corresponding sub-blocks of the logistic matrix, and then decode and merge the sub-blocks into one image. Finally, chaotic sequences are used to scramble the merged images to gain the ciphertext image. The DNA encoding, decoding and operation rules of each sub-block are randomly determined by the chaotic sequences, which can effectively improve the complexity of DNA encoding, decoding and calculation rules. The algorithm possesses huge key space, high key sensitivity, extreme complexity and security demonstrated from simulation results and security performance analysis.
C1 [Fang, Jie; Jiang, Minghao; Yin, Nannan; Wei, Da; Zhang, Yin] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou, Peoples R China.
   [Fang, Jie; Jiang, Minghao; Yin, Nannan; Wei, Da; Zhang, Yin] Henan Key Lab Informat Based Elect Appliances, Zhengzhou, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Fang, J (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou, Peoples R China.; Fang, J (corresponding author), Henan Key Lab Informat Based Elect Appliances, Zhengzhou, Peoples R China.
EM fang0511jie@126.com
FU National Natural Science Foundation of China [61775198, 62076222,
   61703313]; Science and technology project of Henan Province
   [222102210059, 222102210266]; Science and Technology Innovation Team
   Project of Henan Province [19IRTSTHN013]
FX This work is supported by the National Natural Science Foundation of
   China (Grant no. 61775198, 62076222, 61703313), Science and technology
   project of Henan Province(Grant no. 222102210059, 222102210266) and
   Science and Technology Innovation Team Project of Henan Province (Grant
   no. 19IRTSTHN013).
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Anandkumar R, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102390
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   [方洁 Fang Jie], 2021, [复杂系统与复杂性科学, Complex Systems and Complexity Science], V18, P30
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Peng ZP, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.240506
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Tang HQ, 2018, IEEE ACCESS, V6, P26059, DOI 10.1109/ACCESS.2018.2832854
   Tong XJ, 2010, SCI CHINA INFORM SCI, V53, P191, DOI 10.1007/s11432-010-0010-3
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Yan XP, 2021, MULTIMED TOOLS APPL, V80, P10949, DOI 10.1007/s11042-020-10218-8
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang YB, 2021, OPT LASER ENG, V143, DOI 10.1016/j.optlaseng.2021.106626
   Zhao SM, 2020, OPT COMMUN, V474, DOI 10.1016/j.optcom.2020.126086
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 29
TC 5
Z9 5
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17245
EP 17262
DI 10.1007/s11042-022-12604-w
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200013
DA 2024-07-18
ER

PT J
AU Kumaraswamy, B
AF Kumaraswamy, Balachandra
TI Optimized deep learning for genre classification via improved moth flame
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genre classification; STFT features; NMF features; Pitch features;
   DBN; Improved MFO
ID MUSIC CLASSIFICATION; ACOUSTIC FEATURES; NETWORK; EXTRACTION; RETRIEVAL;
   TRANSFORM
AB Musical genres are categorical labels created by humans for characterizing pieces of music. This categorization of musical genre is done by the common characteristics shared by its members. Typically these are associated to the rhythmic structure, instrumentation, and harmonic content of the music. In fact, automated musical genre classification could replace or assist the human user in this categorization process and might be the valuable one along with music information retrieval systems. This paper intends to propose a new automated music genre classification model with the aid of an enhanced deep learning model. The proposed model includes two major phases: (a) Feature Extraction and (b) Classification. In the feature extraction phase, the most relevant features like Non-Negative Matrix Factorization (NMF) features, Short-Time Fourier Transform (STFT) features and pitch features are extracted from the given music signal. Subsequently, a weight function is multiplied with the extracted features, particularly to enhance the association between them. Further, these weighted features are subjected to classification via an Optimized Deep belief Network (DBN), where the weights and activation function are fine-tuned. A new Improved Moth Flame Optimization Algorithm (IMFO) is introduced in this work for fine-tuning. The performance of adopted work is evaluated over other existing approaches with respect to Type I and Type II measures, and error analysis, respectively.
C1 [Kumaraswamy, Balachandra] BMS Coll Engn, Bangalore, Karnataka, India.
C3 BMS College of Engineering
RP Kumaraswamy, B (corresponding author), BMS Coll Engn, Bangalore, Karnataka, India.
EM balachandrak.tce@bmsce.ac.in
RI Kumaraswamy, Balachandra/HPE-9800-2023; Kumaraswamy,
   Balachandra/Q-3211-2016
OI Kumaraswamy, Balachandra/0000-0002-1946-1697
CR Abdalla Hemn B., 2016, International Journal of Information and Electronics Engineering, V6, P84, DOI 10.18178/ijiee.2016.6.2.600
   Abdalla HB, 2020, KSII T INTERNET INF, V14, P1886, DOI 10.3837/tiis.2020.05.002
   Adiyansjah, 2019, PROCEDIA COMPUT SCI, V157, P99, DOI 10.1016/j.procs.2019.08.146
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   Baniya BK, 2016, MULTIMED TOOLS APPL, V75, P3013, DOI 10.1007/s11042-014-2418-z
   Belfi AM, 2017, NEUROPSYCHOLOGIA, V97, P29, DOI 10.1016/j.neuropsychologia.2017.01.030
   Bisandu DB, 2019, J STAT MANAG SYST, V22, P901, DOI 10.1080/09720510.2019.1565443
   Coca AE, 2016, INFORM SCIENCES, V329, P819, DOI 10.1016/j.ins.2015.09.030
   Corrêa DC, 2016, EXPERT SYST APPL, V60, P190, DOI 10.1016/j.eswa.2016.04.008
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Di Mauro M., 2014, 2014 INT CARN C SEC, P1, DOI [10.1093/acprof:oso/9780199671656.001.0001, DOI 10.1093/ACPROF:OSO/9780199671656.001.0001]
   Di Mauro M, 2015, 2015 12TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS (ICETE), VOL 4, P259
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Durak L, 2003, IEEE T SIGNAL PROCES, V51, P1231, DOI 10.1109/TSP.2003.810293
   Fan JY, 2013, APPL MATH COMPUT, V219, P9438, DOI 10.1016/j.amc.2013.03.026
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Gangappa M., 2019, Multi Res, V2, P12, DOI DOI 10.46253/J.MR.V2I3.A2
   Gonzalez S, 2011, EUR SIGNAL PR CONF, P451
   Han Y, 2017, IEEE-ACM T AUDIO SPE, V25, P208, DOI 10.1109/TASLP.2016.2632307
   Jakubec M, 2019, TRANSP RES PROC, V40, P1364, DOI 10.1016/j.trpro.2019.07.189
   Klec M, 2014, PROC TECH, V18, P133, DOI 10.1016/j.protcy.2014.11.025
   Kumaraswamy B, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107446
   Leartpantulak K, 2019, INT ELECT ENG CONGR, DOI 10.1109/ieecon45304.2019.8938995
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Lijun Zhang, 2011, Frontiers of Electrical and Electronic Engineering in China, V6, P192, DOI 10.1007/s11460-011-0128-0
   Lizardo O, 2018, POETICS, V68, P52, DOI 10.1016/j.poetic.2018.04.003
   Lokesh Kumar R., 2019, J COMPUT MECH POWER, V2, P1, DOI [10.46253/jcmps.v2i3.a1, DOI 10.46253/JCMPS.V2I3.A1]
   da Silva ACM, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113071
   Michael Mahesh K., 2020, MULTIMEDIA RES, V3
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Muñoz-Romero S, 2018, IEEE T MULTIMEDIA, V20, P1751, DOI 10.1109/TMM.2017.2778568
   Nanni L, 2016, EXPERT SYST APPL, V45, P108, DOI 10.1016/j.eswa.2015.09.018
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar BR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P606
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Rajesh B, 2016, INT J SPEECH TECHNOL, V19, P551, DOI 10.1007/s10772-016-9347-3
   Raposo F, 2016, IEEE-ACM T AUDIO SPE, V24, P1119, DOI 10.1109/TASLP.2016.2541299
   Rosner A, 2018, J INTELL INF SYST, V50, P363, DOI 10.1007/s10844-017-0464-5
   Shin SH, 2019, IET SIGNAL PROCESS, V13, P230, DOI 10.1049/iet-spr.2018.5158
   Sonnett J, 2016, POETICS, V54, P38, DOI 10.1016/j.poetic.2015.09.002
   Swamy S. M., 2013, IET CHENN 4 INT C SU, DOI [DOI 10.1049/IC.2013.0361, 10.1049/ic.2013.0361]
   Vlegels J, 2017, POETICS, V60, P76, DOI 10.1016/j.poetic.2016.08.004
   Wassi G, 2018, J PARALLEL DISTR COM, V119, P146, DOI 10.1016/j.jpdc.2018.02.011
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Yu Y, 2020, NEUROCOMPUTING, V372, P84, DOI 10.1016/j.neucom.2019.09.054
NR 50
TC 7
Z9 7
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17071
EP 17093
DI 10.1007/s11042-022-12254-y
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200006
DA 2024-07-18
ER

PT J
AU Esmaeeli, H
   Rezaei, M
AF Esmaeeli, Hadi
   Rezaei, Mehdi
TI A content-based intra rate-distortion model for HEVC-SCC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Screen content; Intra frame; Rate control; Rate-distortion model;
   Content-based
ID RATE CONTROL ALGORITHM; RATE CONTROL SCHEME; FRAME RATE CONTROL; VIDEO;
   OPTIMIZATION
AB Screen content (SC) videos have different characteristics compared to camera-captured videos. New encoding modes such as Intra Block Copy (IBC) and Palette modes have been introduced to the SC coding (SCC) extension of the high-efficiency video coding (HEVC) standard. In SCC, a large percentage of bits is consumed by periodic intra frames and also by the abrupt-change frame changes in which all or most of the coding units are coded as intra modes (e.g. Intra, IBC, and Palette modes). Therefore, a proper intra rate-distortion (RD) model is required to support these encoding modes. The RD model must be content-based to be able to independently encode the intra frames and abrupt frames. The existing RD models are not content-based or do not support the new encoding modes. In this paper, a new content-based intra RD model for HEVC-SCC is proposed. The proposed model is adapted for different sizes and modes of the coding units and it consists of two parts. One part depends on the coding complexity of video content and the second part is a function of the encoder RD operating point. The experimental results show that the model parts are regular functions of the quantization parameter. However, these functions depend on the size and mode of the coding units. According to the results, the model performs with high degrees of accuracy and fitness in terms of the average estimation error and the coefficient of determination criteria, respectively. Also, it shows a very good performance while using it in two low delay rate control algorithms.
C1 [Esmaeeli, Hadi] Univ Sistan & Baluchestan, Informat Technol Engn Dept, Zahedan, Iran.
   [Rezaei, Mehdi] Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
C3 University of Sistan & Baluchestan; University of Sistan & Baluchestan
RP Rezaei, M (corresponding author), Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
EM esmaeeli@ece.usb.ac.ir; mehdi.rezaei@ece.usb.ac.ir
RI Rezaei, Mehdi/HPC-0221-2023; Esmaeeli, Hadi/AFU-1202-2022
OI Esmaeeli, Hadi/0000-0001-6953-1035; Rezaei, Mehdi/0000-0002-6918-9767
CR ANDREWS HC, 1968, PR INST ELECTR ELECT, V56, P113, DOI 10.1109/PROC.1968.6181
   [Anonymous], 2017, 2017 IEEE VISUAL COM
   [Anonymous], 2018, H265V5 ITUT
   Chang C. Y., 2006, P INT C AC SPEECH SI, P929
   Chen Y, 2020, INT CONF ACOUST SPEE, P4422, DOI [10.1109/icassp40776.2020.9054633, 10.1109/ICASSP40776.2020.9054633]
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi H, 2012, JCTVCH021 ITU
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Fani D, 2018, IEEE T CIRC SYST VID, V28, P1379, DOI 10.1109/TCSVT.2017.2669214
   Gao YB, 2017, IEEE T IMAGE PROCESS, V26, P4457, DOI 10.1109/TIP.2017.2713598
   Guo YY, 2015, IEEE INT SYMP CIRC S, P1118, DOI 10.1109/ISCAS.2015.7168834
   HE Z, 2001, THESIS U CALIFORNIA
   Hu HM, 2017, MULTIMED TOOLS APPL, V76, P12917, DOI 10.1007/s11042-016-3666-x
   Hyun MH, 2020, IEEE ACCESS, V8, P227255, DOI 10.1109/ACCESS.2020.3046043
   Kao JY, 2015, INT CONF IMAG PROC, P504, DOI 10.1109/IPTA.2015.7367197
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Li B., 2014, document JCTVC-S0085
   Li B, 2012, JCTVC10426 ITUTISOIE, P27
   Li B, 2012, JT COLLAB TEAM VIDEO, P10
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li S, 2016, IEEE T CIRC SYST VID, V26, P117, DOI 10.1109/TCSVT.2015.2450131
   Li W, 2019, SIGNAL IMAGE VIDEO P, V13, P17, DOI 10.1007/s11760-018-1323-8
   Li X, 2009, IEEE T CIRC SYST VID, V19, P193, DOI 10.1109/TCSVT.2008.2009255
   Li YM, 2020, IEEE IMAGE PROC, P1176, DOI 10.1109/ICIP40778.2020.9191125
   Lu QH, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P1329, DOI 10.1109/ICNC.2013.6818185
   Lu X, 2020, IEEE DATA COMPR CONF, P382, DOI 10.1109/DCC47342.2020.00055
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Pu W, 2016, IEEE J EM SEL TOP C, V6, P420, DOI 10.1109/JETCAS.2016.2605661
   Rezaei, 2008, THESIS TAMPERE U TEC
   Rezaei M, 2005, IEEE WRK SIG PRO SYS, P550, DOI 10.1109/SIPS.2005.1579928
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Sanchez V, 2021, IEEE T CIRC SYST VID, V31, P4422, DOI 10.1109/TCSVT.2020.3047296
   Sun L, 2012, APSIPA ASC, P1
   Tang T, 2019, IEEE ACCESS, V7, P139560, DOI 10.1109/ACCESS.2019.2943887
   Tang T, 2019, MULTIMED TOOLS APPL, V78, P28231, DOI 10.1007/s11042-019-07910-9
   Tian L, 2012, J VIS COMMUN IMAGE R, V23, P873, DOI 10.1016/j.jvcir.2012.05.005
   Viterbi A. J., 1979, Principles of Digital Communication and Coding
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang SS, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351596
   Xiaohua Jian, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8091746
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Xu XZ, 2022, IEEE T CIRC SYST VID, V32, P839, DOI 10.1109/TCSVT.2021.3064210
   Xu XZ, 2016, IEEE J EM SEL TOP C, V6, P409, DOI 10.1109/JETCAS.2016.2597645
   Yang H, 2020, IEEE T BROADCAST, V66, P333, DOI 10.1109/TBC.2019.2954062
   Yang KF, 2017, SIGNAL PROCESS-IMAGE, V57, P68, DOI 10.1016/j.image.2017.05.006
   Yang Y, 2019, J VIS COMMUN IMAGE R, V60, P328, DOI 10.1016/j.jvcir.2019.02.031
   Yaoyao Guo, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457809
   Yimin Zhou, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P648, DOI 10.1109/ICCNC.2013.6504163
   Yuan L, 2018, LECT NOTES ELECT ENG, V464, DOI [10.1007/978-981-10-7398-4_21, DOI 10.1007/978-981-10-7398-4_21]
   Zhang F, 2015, IEEE IMAGE PROC, P671, DOI 10.1109/ICIP.2015.7350883
   Zhang L, 2016, IEEE J EM SEL TOP C, V6, P446, DOI 10.1109/JETCAS.2016.2599860
   Zhou YM, 2009, SIGNAL PROCESS-IMAGE, V24, P345, DOI 10.1016/j.image.2009.02.014
NR 52
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16515
EP 16536
DI 10.1007/s11042-022-12361-w
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300002
DA 2024-07-18
ER

PT J
AU Li, SG
   Wang, R
   Lu, HY
   Yu, ZX
AF Li, Shugang
   Wang, Ru
   Lu, Hanyu
   Yu, Zhaoxu
TI The recommendation of satisfactory product for new users in social
   commerce website
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE New user; Satisfactory product recommendation; Homogeneity; Consensus
   prediction; Social commerce
ID EMPIRICAL-ANALYSIS; PREDICTION; INNOVATION; CONTAGION; BEHAVIOR
AB Recommending the post-use satisfactory product for new users can allow more effectively escalating the sale of products and expanding the new customers. When recommending a post-use satisfactory product for new users, the existing methods often suffer cold-start problems, which have tremendous consequences for their recommendation accuracy. To fill this gap, this study develops the consensus interest prediction model (CIPM) to predict new user's post-use satisfaction for the recommended products, which overcomes the cold-start problems by improving the robustness of the prediction model and deep extraction of user information based on the homogeneity in social commerce website. Specifically, we extract the five types of homogeneity characteristics between the active users and new users from the aspects of product homogeneity and user social relationship homogeneity. Then the multidimensional homogeneity user interest prediction models are designed with direct linear fusion, direct nonlinear fusion, and indirect fusion of multiple homogeneity indices. Subsequently, in order to improve the robustness of the model, the suitable interest prediction model is nominated for a given new user satisfactory product recommendation (NUSPR) scenario. The upper and lower bounds of the prediction error of each interest prediction model are calculated to estimate the similarity between it and other models in predicting results. The weight voting algorithm selects the model with the highest consensus as the final prediction model. Accordingly, the NUSPR strategies are proposed according to the model predicted result. Relying on Yelp's social commerce website, we verify that our CIPM can accurately predict the new users' satisfaction level.
C1 [Li, Shugang; Wang, Ru; Lu, Hanyu] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Lu, HY (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
EM westside_li@163.com; Ruwang311@163.com; luhanyuwill@126.com;
   yyzx@ecust.edu.cn
RI Wang, Ru/IXW-6013-2023
OI Yu, Zhaoxu/0000-0002-2375-0213
FU Chinese National Natural Science Foundation [71871135]
FX This work was supported by the Chinese National Natural Science
   Foundation (No. 71871135).
CR Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Alghofaily B, 2020, P IEEE I C SERV COMP, P84, DOI 10.1109/SCC49832.2020.00020
   Aral S, 2011, MARKET SCI, V30, P217, DOI 10.1287/mksc.1100.0596
   Baskin TW, 2003, J CONSULT CLIN PSYCH, V71, P973, DOI 10.1037/0022-006X.71.6.973
   Bikhchandani S, 2001, IMF STAFF PAPERS, V47, P279
   Bikhchandani S, 1998, J ECON PERSPECT, V12, P151, DOI 10.1257/jep.12.3.151
   Boratto L, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102387
   BURT RS, 1987, AM J SOCIOL, V92, P1287, DOI 10.1086/228667
   Byun H., 2019, P 17 ANN INT C MOBIL, P520
   Cruz AFT, 2020, LECT NOTES ELECTR EN, V621, P451, DOI 10.1007/978-981-15-1465-4_45
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Falk A, 2006, GAME ECON BEHAV, V54, P293, DOI 10.1016/j.geb.2005.03.001
   Ghritlahre HK, 2018, J ENVIRON MANAGE, V223, P566, DOI 10.1016/j.jenvman.2018.06.033
   Gopi Arepalli Peda, 2023, International Journal of Information Technology, P965, DOI 10.1007/s41870-019-00409-4
   GOULDNER AW, 1960, AM SOCIOL REV, V25, P161, DOI 10.2307/2092623
   Greene W.H., 2007, Econometric analysis
   Han X, 2015, DECIS SUPPORT SYST, V69, P92, DOI 10.1016/j.dss.2014.11.008
   He C, 2016, EXPERT SYST APPL, V56, P9, DOI 10.1016/j.eswa.2016.02.013
   Hung LP, 2005, EXPERT SYST APPL, V29, P383, DOI 10.1016/j.eswa.2005.04.016
   Jabakji A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1742, DOI 10.1109/BigData.2016.7840789
   Kavitha M., 2020, Int. J. Eng. Res. Technol, V3, P1
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kossinets G, 2006, SCIENCE, V311, P88, DOI 10.1126/science.1116869
   Lai CH, 2019, INT J HUM-COMPUT ST, V121, P42, DOI 10.1016/j.ijhcs.2018.04.002
   Lee D H., 2010, Proceedings of the 21st ACM Conference on Hypertext and Hypermedia, P151
   Lewis K, 2012, P NATL ACAD SCI USA, V109, P68, DOI 10.1073/pnas.1109739109
   Li CL, 2018, COMPUT ELECTR ENG, V66, P40, DOI 10.1016/j.compeleceng.2018.02.005
   Li J, 2018, J COMPUT SCI-NETH, V26, P128, DOI 10.1016/j.jocs.2018.03.009
   Ma LY, 2015, MANAGE SCI, V61, P454, DOI 10.1287/mnsc.2014.1928
   Ma X, 2018, MULTIMED TOOLS APPL, V77, P6425, DOI 10.1007/s11042-017-4550-z
   Mashal I, 2016, J AMB INTEL HUM COMP, V7, P889, DOI 10.1007/s12652-016-0357-4
   Steck H., 2013, P 7 ACM C REC SYST, P213, DOI DOI 10.1145/2507157.2507160
   Xu N, 2016, PLOS ONE, V11, DOI [10.1371/journal.pone.0159623, 10.1371/journal.pone.0152463]
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Yadav MS, 2013, J INTERACT MARK, V27, P311, DOI 10.1016/j.intmar.2013.09.001
   Yang C, 2021, J THEOR APPL EL COMM, V16, P1598, DOI 10.3390/jtaer16050090
   Young HP, 2009, AM ECON REV, V99, P1899, DOI 10.1257/aer.99.5.1899
   Yunju Lee, 2020, [Journal of Intelligence and Information Systems, 지능정보연구], V26, P151
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zheng JX, 2018, SCI PROGRAMMING-NETH, V2018, DOI 10.1155/2018/8503452
   Zheng XH, 2019, MULTIMED TOOLS APPL, V78, P32755, DOI 10.1007/s11042-018-7009-y
NR 41
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16219
EP 16241
DI 10.1007/s11042-022-12491-1
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600012
DA 2024-07-18
ER

PT J
AU Alshekly, TK
   Albahrani, EA
   Lafta, SH
AF Alshekly, Tayseer Karam
   Albahrani, Ekhlas Abbas
   Lafta, Sadeq H.
TI 4D chaotic system as random Substitution-Box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-Box; Qi Hyperchaotic System; Image encryption; Encryption algorithm
ID MAP; CONSTRUCTION
AB Substitution -boxes have a significant role in cryptographic algorithms and they are remarkably non-linear parts of block cryptography. There are large numbers of S-Boxes algorithm designs had been proposed based on chaotic theory. Due to the demand of existence of both confusion and diffusion process, which is not available in most S-Boxes algorithms, an effective way to build Substitution-Permutation boxes based on the Qi Hyperchaotic System was included in this study. The object of this proposition is to generate S-Boxes that are more robust and can be provided both diffusion and confusion properties (substitution and permutation). The substitution process in the S-Box is stochastic through changing every byte of the state by different byte from a replacement table. Analyzing and testing were conducted for the new S-Box for the following criteria: avalanche effect, strict avalanche effect (SAC), nonlinearity, key sensitivity, differential and linear cryptanalysis. The whole results proved that the proposed method is an excellent candidate for designing S-Boxes that can be widely used in block cipher. The proposed S-Boxes are applied to a new image encryption algorithm where two S-Box for each color channel are created to perform permutation and substitution operations. Also, performance tests of the encryption algorithm have been presented.
C1 [Alshekly, Tayseer Karam] Al Imam Al Atham Univ Coll, Dept Banking & Finance Sci, Baghdad, Iraq.
   [Albahrani, Ekhlas Abbas] Mustansiriyah Univ, Dept Comp Sci, Baghdad, Iraq.
   [Lafta, Sadeq H.] Univ Technol Iraq, Dept Appl Sci, Baghdad, Iraq.
C3 Mustansiriya University; University of Technology- Iraq
RP Lafta, SH (corresponding author), Univ Technol Iraq, Dept Appl Sci, Baghdad, Iraq.
EM tayseer.karam@yahoo.com; akhlas_abas@uomustansiriyah.edu.iq;
   sadeq.h.lafta@uotechnology.edu.iq
RI Albahrani, Abbas/AFU-8110-2022; Alshekly, Tayseer Karam/AAL-7961-2020;
   H.Lafta, Sadeq/D-1092-2019
OI Alshekly, Tayseer Karam/0000-0002-8502-097X; H.Lafta,
   Sadeq/0000-0002-7000-8337; Albahrani, Ekhlas/0000-0002-1535-0033
FU University of Technology in Baghdad-Iraq
FX The authors are grateful and appreciative to their institutes,
   Mustansiriyah University and University of Technology in Baghdad-Iraq,
   due to institute roles in supporting and providing academic time for
   performing the research.
CR Abbas EA, 2019, EURASIAN J MATH COMP, V7, P4, DOI 10.32523/2306-6172-2019-7-4-4-17
   Ahmad M., 2013, INT S SEC COMP COMM, P130
   Al-Bahrani EA, 2019, BAGHDAD SCI J, V16, P270, DOI 10.21123/bsj.2019.16.1(Suppl.).0270
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Albahrani EA, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102445
   Awad A., 2010, IAENG INT J COMPUT S, V37, P34
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Bin Faheem Z, 2020, ETRI J, V42, P619, DOI 10.4218/etrij.2019-0138
   Cassal-Quiroga BB, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2702653
   Daemen J, 2011, The Design of Rijndael: AES-The Advanced Encryption Standard
   Abd El-Latif AA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121392
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Francois M, 2013, INFORMATICA-LITHUAN, V24, P181
   Ghebleh M, 2019, NEURAL COMPUT APPL, V31, P2415, DOI 10.1007/s00521-017-3199-x
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussain I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030351
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2015, J INTELL FUZZY SYST, V28, P1509, DOI 10.3233/IFS-141434
   Kim S, 2004, CORRECTIONS NIST STA
   Lambic D, 2018, J INFORM TELECOMMUN, V2, P181, DOI 10.1080/24751839.2018.1434723
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Mahmood SA., 2019, INDONES J ELECT ENG, V18, P101, DOI [10.11591/ijeecs.v18.i1.pp101-111, DOI 10.11591/IJEECS.V18.I1.PP101-111]
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Qi GY, 2006, PHYS LETT A, V352, P386, DOI 10.1016/j.physleta.2005.12.030
   Soto J, 2000, RANDOMNESS TESTING A, DOI [10.6028/NIST.IR.6483, DOI 10.6028/NIST.IR.6483]
   Tian Y, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6969312
   Tian Y, 2017, AIP ADV, V7, DOI 10.1063/1.4994860
   Wan YJ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020171
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Wang Y, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501278
   Yao W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165937
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 41
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15793
EP 15814
DI 10.1007/s11042-022-11928-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200006
DA 2024-07-18
ER

PT J
AU Pan, JS
   Liu, T
   Yan, B
   Yang, HM
   Chu, SC
AF Pan, Jeng-Shyang
   Liu, Tao
   Yan, Bin
   Yang, Hong-Mei
   Chu, Shu-Chuan
TI Using color QR codes for QR code secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color OR; Color QR code; Secret sharing
ID OPTIMIZATION ALGORITHM
AB The secret sharing scheme can share the secret image with several shares. The secure transmission of the quick response (QR) code can be enhanced by the secret sharing scheme on the Internet. This paper proposes the QR code secret sharing scheme (QRCSSS) by using color QR codes. The standard QR code is modified to a color QR code. The color of the secret image is shared by the color of the share (color QR code). QRCSSS can generate two color QR codes. When two color QR codes are performed color OR, a secret color QR code is restored. The restored color QR code has contrast in color. It can be converted to a standard QR code by the proposed contrast enhancer. This paper analyzes how the color QR code can be decoded correctly by the general QR code decoder. The experimental results show that the proposed scheme is feasible.
C1 [Pan, Jeng-Shyang; Liu, Tao; Yang, Hong-Mei; Chu, Shu-Chuan] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Chu, SC (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM jengshyangpan@gmail.com; taoliu0201@163.com; yanbinhit@hotmail.com;
   yhm1998@163.com; scchu0803@gmail.com
RI Chu, Shu-Chuan/AFQ-6798-2022; Pan, Jeng-Shyang/AEO-3450-2022
OI Chu, Shu-Chuan/0000-0003-2117-0618; Pan, Jeng-Shyang/0000-0002-3128-9025
FU National Natural Science Foundation of China [61872085]; Natural Science
   Foundation of Fujian Province [2018J01638]; Fujian Provincial Department
   of Science and Technology [2018Y3001]
FX This work is supported by the National Natural Science Foundation of
   China (61872085), the Natural Science Foundation of Fujian Province
   (2018J01638) and the Fujian Provincial Department of Science and
   Technology (2018Y3001).
CR [Anonymous], 2008, DIGITAL IMAGE PROCES
   [Anonymous], 2000, 18004 ISOIEC
   Burger W., 2009, Principles of Digital Image Processing
   Cai HL, 2019, MULTIMED TOOLS APPL, V78, P22575, DOI 10.1007/s11042-019-7504-9
   Chen CM, 2021, ENTERP INF SYST-UK, V15, P1200, DOI 10.1080/17517575.2020.1712746
   Chen Y., 2020, INT J NETW SECUR, V22, P551
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, P286, DOI [10.22266/ijies2020.1031.26, DOI 10.22266/IJIES2020.1031.26]
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, DOI DOI 10.22266/IJIES2020.1231.32
   Dehghani M., 2019, International Journal of Innovative Technology and Exploring Engineering, V9, P5306, DOI [10.35940/ijitee.A4215.119119, DOI 10.35940/IJITEE.A4215.119119]
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Fairman HS, 1997, COLOR RES APPL, V22, P11, DOI 10.1002/(SICI)1520-6378(199702)22:1<11::AID-COL4>3.0.CO;2-7
   Fu ZX, 2019, MEASUREMENT, V141, P267, DOI 10.1016/j.measurement.2019.03.080
   Github, 2019, ZXING LIB
   Guild J, 1932, PHILOS T R SOC LOND, V230, P149, DOI 10.1098/rsta.1932.0005
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang PC, 2020, IEEE ACCESS, V8, P86706, DOI 10.1109/ACCESS.2020.2992694
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   Liu T, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214670
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Tan LD, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P961, DOI 10.1109/ICIVC.2018.8492724
   Wang FH, 2007, INFORM SCIENCES, V177, P2522, DOI 10.1016/j.ins.2006.12.025
   Wen-Pinn Fang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P89, DOI 10.1109/IIHMSP.2011.10
   Weng C.J., 2018, P INT C INTELLIGENT, P124, DOI [10.1007/978-3-030-03745-1_16, DOI 10.1007/978-3-030-03745-1_16]
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wright W.D., 1929, T OPTICAL SOC, V30, P141, DOI DOI 10.1088/1475-4878/30/4/301
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yang CN, 2019, IEEE T CIRC SYST VID, V29, P252, DOI 10.1109/TCSVT.2017.2771255
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 43
TC 4
Z9 5
U1 6
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15545
EP 15563
DI 10.1007/s11042-022-12423-z
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600019
DA 2024-07-18
ER

PT J
AU Goyal, H
   Sidana, K
   Singh, C
   Jain, A
   Jindal, S
AF Goyal, Hiten
   Sidana, Karanveer
   Singh, Charanjeet
   Jain, Abhilasha
   Jindal, Swati
TI A real time face mask detection system using convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenCV; Convolutional neural network (CNN); COVID-19; Deep learning;
   Real-time face mask detection
AB In current times, after the rapid expansion and spread of the COVID-19 outbreak globally, people have experienced severe disruption to their daily lives. One idea to manage the outbreak is to enforce people wear a face mask in public places. Therefore, automated and efficient face detection methods are essential for such enforcement. In this paper, a face mask detection model for static and real time videos has been presented which classifies the images as "with mask" and "without mask". The model is trained and evaluated using the Kaggle data-set. The gathered data-set comprises approximately about 4,000 pictures and attained a performance accuracy rate of 98%. The proposed model is computationally efficient and precise as compared to DenseNet-121, MobileNet-V2, VGG-19, and Inception-V3. This work can be utilized as a digitized scanning tool in schools, hospitals, banks, and airports, and many other public or commercial locations.
C1 [Goyal, Hiten; Sidana, Karanveer; Singh, Charanjeet; Jain, Abhilasha; Jindal, Swati] Maharaja Ranjit Singh Punjab Tech Univ, Dept Comp Sci & Engn, Bathinda, India.
RP Jain, A (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Comp Sci & Engn, Bathinda, India.
EM abhilasha_cse@mrsptu.ac.in
RI Jain, Abhilasha/A-7745-2018
OI Jain, Abhilasha/0000-0003-3758-9712
CR Chen D, 2016, LECT NOTES COMPUT SC, V9909, P122, DOI 10.1007/978-3-319-46454-1_8
   Chen YZ, 2021, IEEE SENS J, V21, P11084, DOI 10.1109/JSEN.2021.3061178
   Chong Li, 2020, Recent Trends in Intelligent Computing, Communication and Devices. Proceedings of ICCD 2018. Advances in Intelligent Systems and Computing (AISC 1031), P277, DOI 10.1007/978-981-13-9406-5_34
   Cruz AP, 2021, P INT C INN SPFTW AR, P1
   Din NU, 2020, IEEE ACCESS, V8, P44276, DOI 10.1109/ACCESS.2020.2977386
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang YB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071974
   Hussain S.A., 2020, J. Phys.: Conf. Series, V1432, DOI DOI 10.1088/1742-6596/1432/1/012087
   Khan N, 2014, SCI WORLD J, DOI 10.1155/2014/712826
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li S., 2020, 2020 INT C HIGH PERF, P1
   Mednikov Y, 2018, IEEE ENG MED BIO, P2587, DOI 10.1109/EMBC.2018.8512750
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Militante SV, 2019, PROCEEDINGS OF THE 2019 IEEE EURASIA CONFERENCE ON IOT, COMMUNICATION AND ENGINEERING (ECICE), P579, DOI 10.1109/ecice47484.2019.8942686
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Nwankpa C., 2018, ARXIV181103378
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Sharma Ochin, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P72, DOI 10.1109/COMITCon.2019.8862453
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Venkateswarlu I.B., 2020, 2020 IEEE 4 C INF CO, P1, DOI DOI 10.1109/CICT51604.2020.9312083
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Yang GF, 2018, INT GEOSCI REMOTE SE, P2595, DOI 10.1109/IGARSS.2018.8517520
NR 23
TC 20
Z9 20
U1 6
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14999
EP 15015
DI 10.1007/s11042-022-12166-x
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761979300024
PM 35233179
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mahaur, B
   Singh, N
   Mishra, KK
AF Mahaur, Bharat
   Singh, Navjot
   Mishra, K. K.
TI Road object detection: a comparative study of deep learning-based
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous vehicles; Intelligent transportation system (ITS); Object
   detection; Deep learning
ID VEHICLE DETECTION
AB Deep learning field has progressed the vision-based surround perception and has become the most trending area in the field of Intelligent Transportation System (ITS). Many deep learning-based algorithms using two-dimensional images have become an essential tool for autonomous vehicles with object detection, tracking, and segmentation for road target detection, primarily including pedestrians, vehicles, traffic lights, and traffic signs. Autonomous vehicles rely heavily on visual data to classify and generalize target objects which can satisfy pedestrians' and other vehicles' safety requirements in their environment. In real-time, outstanding results are obtained by deep learning-based algorithms for object detection. While several studies have thoroughly examined different types of deep learning-based object detection methods, there are a few comparable studies that either test the detection speed or accuracy of the object detection algorithms. In addition to speed and accuracy, autonomous driving also depends on model size and energy efficiency. However, there is a lack of comparison on various such metrics among existing deep learning-based methods. This article aims to provide a detailed and systematic comparative analysis of five independent mainstream deep learning-based algorithms for road object detection, namely the R-FCN, Mask R-CNN, SSD, RetinaNet, and YOLOv4 on a large-scale Berkeley DeepDrive (BDD100K) dataset. The experimental results are analyzed using the mean Average Precision (mAP) value and inference time. Additionally, various practical metrics, such as model size, computational complexity, and energy efficiency of deep learning-based models are precisely computed. Furthermore, the performance of each algorithm is evaluated under different road environmental conditions at various times of day and night. The comparison presented in this article helps to gain insight into the strengths and limitations of the popular deep learning-based algorithms under practical constraints with their real-time deployment feasibility. Code is publicly available at: https://github.com/bharatmahaur/ComparativeStudy
C1 [Mahaur, Bharat; Mishra, K. K.] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Allahabad, Uttar Pradesh, India.
   [Singh, Navjot] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Indian Institute of Information Technology
   Allahabad
RP Singh, N (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM bharatmahaur@gmail.com; navjot@iiita.ac.in; kkm@mnnit.ac.in
RI Mishra, K.K/AAT-3083-2021; Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Aziz L, 2020, IEEE ACCESS, V8, P170461, DOI 10.1109/ACCESS.2020.3021508
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Broggi Alberto, 2014, 2014 IEEE Intelligent Vehicles Symposium Proceedings, P912, DOI 10.1109/IVS.2014.6856490
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chen L, 2021, IEEE T INTELL TRANSP, V22, P3234, DOI 10.1109/TITS.2020.2993926
   Chen ZQ, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P365, DOI 10.1109/CSA.2013.92
   Coppola P, 2019, AUTONOMOUS VEHICLES AND FUTURE MOBILITY, P1, DOI 10.1016/B978-0-12-817696-2.00001-9
   Dai JF, 2016, ADV NEUR IN, V29
   Devi S, 2020, WIRELESS PERS COMMUN, V114, P2121, DOI 10.1007/s11277-020-07468-y
   Feng D., 2020, ARXIV201110671
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Geiger A., 2012, CVPR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gupta A, 2021, WIRELESS PERS COMMUN, V117, P2341, DOI 10.1007/s11277-020-07976-x
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622
   Hnewa M, 2021, IEEE SIGNAL PROC MAG, V38, P53, DOI 10.1109/MSP.2020.2984801
   Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141
   Huang Yu, 2020, ARXIV200606091
   Husain AA, 2020, IET IMAGE PROCESS, V14, P1, DOI 10.1049/iet-ipr.2018.5351
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuutti S, 2021, IEEE T INTELL TRANSP, V22, P712, DOI 10.1109/TITS.2019.2962338
   Lee Y., 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition workshops
   Li H, 2021, MULTIMED TOOLS APPL, P38
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Majid Azimi S, 2018, P EUR C COMP VIS ECC, P0
   Minaei S, 2022, INT J SPORT NUTR EXE, V32, P16, DOI 10.1123/ijsnem.2021-0090
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rybski PE, 2010, IEEE INT VEH SYM, P921, DOI 10.1109/IVS.2010.5547996
   Silva PB, 2020, J TRAFFIC TRANSP ENG, V7, P775, DOI 10.1016/j.jtte.2020.07.004
   Simhambhatla R., 2019, SMU Data Sci. Rev., V2, P23
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Srivastava S, 2021, J SYST ARCHITECT, V117, DOI 10.1016/j.sysarc.2021.102152
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang H, 2019, IEEE INTEL TRANSP SY, V11, P82, DOI 10.1109/MITS.2019.2903518
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zaidi SSA, 2021, ARXIV210411892
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zou Z, 2019, ARXIV
NR 58
TC 19
Z9 20
U1 12
U2 80
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14247
EP 14282
DI 10.1007/s11042-022-12447-5
EA FEB 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300008
DA 2024-07-18
ER

PT J
AU Anari, MS
   Rezaee, K
   Ahmadi, A
AF Anari, Maryam Saberi
   Rezaee, Khosro
   Ahmadi, Ali
TI TraitLWNet: a novel predictor of personality trait by analyzing Persian
   handwriting based on lightweight deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality trait; Light-weight structure; Convolutional neural network;
   Persian handwriting; Human behavior prediction
ID WRITER IDENTIFICATION; ALGORITHM
AB Based on psychologists' theories, an individual's handwriting somehow symbolizes a type of personality trait that can be a projection of the person's innate. A person's handwriting is the result of an organized system and has scientific bases that make it possible to analyze and specify individuals' nature. This paper presents a novel real-time model based on handwriting samples collected from Persian-speaking people, which predicts their personality traits for the first time. Initially, 400 handwriting samples with a repetition of four different texts and psychological questionnaires and three psychologists' comments have been collected. The pre-processing step is applied to the image samples and the decision-maker model was designed using a lightweight deep convolutional neural network (LWDCNN) structure. The texts were selected based on the psychologists' guidance. The meaningful relation between the personality trait characters extracted from Persian handwriting and each of the personality traits of the person under-study is matched to a magnificent extent. Finally, the LWDCNN structure is evaluated based on the training samples. The proposed convolutional neural network provides reasonable accuracy for six different and three overlapping personality traits. Despite computational complexity and little time spent by the designed pre-train network to respond, the deep structure's error level with limited layers is estimated smaller than 10%. The proposed algorithm's efficiency has been proved by repeating the experiment and assessing measures such as accuracy and mean squared error (MSE).
C1 [Anari, Maryam Saberi] Tech & Vocat Univ TVU, Dept Comp Engn, Tehran, Iran.
   [Rezaee, Khosro] Meybod Univ, Dept Biomed Engn, Meybod, Iran.
   [Ahmadi, Ali] KN Toosi Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 K. N. Toosi University of Technology
RP Rezaee, K (corresponding author), Meybod Univ, Dept Biomed Engn, Meybod, Iran.
EM Kh.rezaee@meybod.ac.ir
RI ahmadi, ali/JMC-5690-2023; Rezaee, Khosro/AAA-9586-2021; saberi anari,
   maryam/ABF-8256-2021
OI Rezaee, Khosro/0000-0001-6763-6626; saberi Anari,
   maryam/0000-0003-4125-4368
CR Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   [Anonymous], 2010, International Journal of Computer Applications
   Asra S, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P260
   Aubin V, 2017, EXPERT SYST APPL, V89, P241, DOI 10.1016/j.eswa.2017.07.039
   Ayzeren YB, 2019, IEEE ACCESS, V7, P164759, DOI 10.1109/ACCESS.2019.2952313
   Boutarfass S, 2019, EUR W VIS INF PROCES, P199, DOI [10.1109/EUVIP47703.2019.8946200, 10.1109/euvip47703.2019.8946200]
   Champa H. N., 2010, Proceedings of the 2010 First International Conference on Integrated Intelligent Computing (ICIIC 2010), P160, DOI 10.1109/ICIIC.2010.29
   Chaudhari K, 2019, EXPERT SYST APPL, V124, P282, DOI 10.1016/j.eswa.2019.01.028
   Cordasco G, 2019, SMART INNOV SYST TEC, V103, P73, DOI 10.1007/978-3-319-95095-2_7
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   Djamal EC, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P163, DOI 10.1109/IC3INA.2013.6819167
   Durga L, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1160, DOI 10.1109/ICACCI.2018.8554416
   Fallah B, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P120, DOI 10.1109/RIOS.2016.7529501
   Fatimah Sri Hastuti, 2019, 2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE), P119, DOI 10.1109/ICITISEE48480.2019.9003855
   Ferrer MA, 2017, IEEE T PATTERN ANAL, V39, P1041, DOI 10.1109/TPAMI.2016.2582167
   Garoot AH, 2017, PROC INT CONF DOC, P621, DOI 10.1109/ICDAR.2017.107
   Górska Z, 2012, PERCEPT MOTOR SKILL, V114, P857, DOI 10.2466/03.09.28.PMS.114.3.857-869
   Hashemi S., 2015, IOSR J ELECT COMMUN, V10, P1
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Joshi P, 2015, Int J Comput Appl, V130
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Kedar S., 2018, INDIAN J PUBLIC HLTH, V9, P2235, DOI [10.5958/0976-5506.2018.01780.1, DOI 10.5958/0976-5506.2018.01780.1]
   Krishnan P, 2019, INT J DOC ANAL RECOG, V22, P387, DOI 10.1007/s10032-019-00336-x
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lemos N, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P110, DOI 10.1109/CTEMS.2018.8769221
   Mostafa MA, 2019, SPRINGER PR COMPLEX, P557, DOI 10.1007/978-3-030-30809-4_51
   Park H, 2017, INT CONF COMPIL ARCH, DOI 10.1145/3125501.3125512
   Pathak AR, 2020, J DISCRET MATH SCI C, V23, P19, DOI 10.1080/09720529.2020.1721856
   Costa EP, 2019, LECT NOTES COMPUT SC, V11188, P146, DOI 10.1007/978-3-030-05792-3_14
   Porwal U, 2012, INT CONF FRONT HAND, P417, DOI 10.1109/ICFHR.2012.277
   Prasad S., 2010, INT J COMPUTER APPL, V8, P25, DOI [10.5120/1256-1758, DOI 10.5120/1256-1758]
   Pratiwi D., 2016, INT J COMPUTERS APPL, V147, P9, DOI [10.5120/ijca2016911181, DOI 10.5120/IJCA2016911181]
   Qiao JF, 2018, NEURAL NETWORKS, V107, P61, DOI 10.1016/j.neunet.2018.02.010
   Rahaman M. E., 2019, INT CONF COMPUT, P1, DOI [10.1109/icccnt45670.2019.8944534, DOI 10.1109/icccnt45670.2019.8944534]
   Rezaee A, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2699-y
   Rezaee Khosro, 2020, 2020 27th National and 5th International Iranian Conference on Biomedical Engineering (ICBME), P234, DOI 10.1109/ICBME51989.2020.9319426
   Rodgers, 2013, YOUR HANDWRITING CAN
   Sandyal KS, 2019, INT C INT DAT COMM T, P546, DOI [10.1007/978-3-030-34080-3_62, DOI 10.1007/978-3-030-34080-3_62]
   Shanthi N, 2010, PATTERN ANAL APPL, V13, P173, DOI 10.1007/s10044-009-0147-0
   Thomas S, 2020, J BEHAV EXP FINANC, V26, DOI 10.1016/j.jbef.2020.100315
   Valdez-Rodríguez JE, 2019, LECT NOTES COMPUT SC, V11188, P140, DOI 10.1007/978-3-030-05792-3_13
   Varshney A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2017), P63
   Weng Y, 2020, MOBILE NETW APPL, V25, P402, DOI 10.1007/s11036-019-01243-5
NR 44
TC 6
Z9 6
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10673
EP 10693
DI 10.1007/s11042-022-12295-3
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700022
DA 2024-07-18
ER

PT J
AU van Kasteren, A
   Brunnström, K
   Hedlund, J
   Snijders, C
AF van Kasteren, Anouk
   Brunnstrom, Kjell
   Hedlund, John
   Snijders, Chris
TI Quality of experience of 360 video - subjective and eye-tracking
   assessment of encoding and freezing distortions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; Quality of experience; 360-video; Visual attention; Quality
   perception; Eye-tracing; Perceptual load; Selective attention;
   Cybersickness
ID LOAD
AB The research domain on the Quality of Experience (QoE) of 2D video streaming has been well established. However, a new video format is emerging and gaining popularity and availability: VR 360-degree video. The processing and transmission of 360-degree videos brings along new challenges such as large bandwidth requirements and the occurrence of different distortions. The viewing experience is also substantially different from 2D video, it offers more interactive freedom on the viewing angle but can also be more demanding and cause cybersickness. The first goal of this article is to complement earlier research by Tran, et al. (2017) [39] testing the effects of quality degradation, freezing, and content on the QoE of 360-videos. The second goal is to test the contribution of visual attention as an influence factor in the QoE assessment. Data was gathered through subjective tests where participants watched degraded versions of 360-videos through a Head-Mounted Display with integrated eye-tracking sensors. After each video they answered questions regarding their quality perception, experience, perceptual load, and cybersickness. Our results showed that the participants rated the overall QoE rather low, and the ratings decreased with added degradations and freezing events. Cyber sickness was found not to be an issue. The effects of the manipulations on visual attention were minimal. Attention was mainly directed by content, but also by surprising elements. The addition of eye-tracking metrics did not further explain individual differences in subjective ratings. Nevertheless, it was found that looking at moving objects increased the negative effect of freezing events and made participants less sensitive to quality distortions. More research is needed to conclude whether visual attention is an influence factor on the QoE in 360-video.
C1 [van Kasteren, Anouk; Brunnstrom, Kjell; Hedlund, John] RISE Res Inst Sweden AB, Kista, Sweden.
   [van Kasteren, Anouk; Snijders, Chris] Eindhoven Univ Technol, Eindhoven, Netherlands.
   [Brunnstrom, Kjell] Mid Sweden Univ, Sundsvall, Sweden.
C3 RISE Research Institutes of Sweden; Eindhoven University of Technology;
   Mid-Sweden University
RP Brunnström, K (corresponding author), RISE Res Inst Sweden AB, Kista, Sweden.; Brunnström, K (corresponding author), Mid Sweden Univ, Sundsvall, Sweden.
EM kjell.brunnstrom@ri.se
OI van Kasteren, Anouk/0000-0001-7134-233X
FU RISE Research Institutes of Sweden - VINNOVA (Sweden's innovation
   agency) [2018-00735]; Vinnova [2018-00735] Funding Source: Vinnova
FX Open access funding provided by RISE Research Institutes of Sweden.
   (information that explains whether and by whom the research was
   supported); This project was funded by an internal funding at RISE and
   VINNOVA (Sweden's innovation agency, grant nr 2018-00735).
CR Aggarwal N., 2014, RECENT ADV ENG COMPU, P1
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Azevedo RGD, 2020, IEEE T CIRC SYST VID, V30, P2524, DOI 10.1109/TCSVT.2019.2927344
   Bindemann M, 2005, PSYCHON B REV, V12, P1048, DOI 10.3758/BF03206442
   Brunnstrom K., 2012, Tech. Rep. Version 1.2, V3, P1
   Brunnström K, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053013
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Engelke U., 2010, 2010 2 INT WORKSH QU
   Engelke U, 2017, IEEE J-STSP, V11, P6, DOI 10.1109/JSTSP.2016.2609843
   Engelke U, 2010, PROC SPIE, V7744, DOI 10.1117/12.863508
   FFmpeg, 2020, FFmpeg: A complete, cross-platform solution to record, convert and stream audio and video
   Gutierrez Jesus, 2021, IEEE Transactions on Multimedia, P1
   HART S G, 1988, P139
   Holmqvist K., 2017, EYE TRACKING COMPREH
   Ikehara C. S., 2005, P 38 ANN HAW INT C S
   ITU-R, 2019, BT50014 ITUR
   ITU-T, 2014, P913 ITUT P913 ITUT
   ITU-T, 2008, ITU T P910 SUBJECTIV
   ITU-T, 2020, P919 ITUT
   ITU-T, 2017, P10G100 ITUT, P20
   Kuipers F, 2010, LECT NOTES COMPUT SC, V6074, P216
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Ninassi A, 2007, IEEE IMAGE PROC, P733
   Palmer S., 1999, VISION SCI PHOTONS P
   Pastrana-Vidal R.R., 2006, AUTOMATIC QUALITY AS
   Porcino TM, 2017, IEEE INT CONF SERIOU
   Raudenbush S., 2001, HIERARCHICAL LINEAR
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Robitza, 2017, SITI SPATIAL INFORM
   Robitza, 2017, BUFFERER
   Robitza W., 2019, VQEGNUMSUBJTOOL CALC
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Schatz R, 2017, INT WORK QUAL MULTIM
   Sogaard J, 2017, MULTIMED TOOLS APPL, V76, P16727, DOI 10.1007/s11042-016-3948-3
   Sweller J, 2011, PSYCHOL LEARN MOTIV, V55, P37
   Tobii, 2019, TOB PRO LAB US MAN
   Tobii, 2019, TOBII PROLAB 111
   Tran H.T., 2017, IEEE INT WORKSH MULT, P1
   van Kasteren A., 2019, 0845668 EINDH U TECH
   van Kester S., 2011, P SPIE IS T HUM VIS
   Wang QZ, 2014, DECIS SUPPORT SYST, V62, P1, DOI 10.1016/j.dss.2014.02.007
   Zu T., 2018, ARXIV180302499
   2014, T-LAB SER TELECOMMUN, P1
NR 43
TC 7
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9771
EP 9802
DI 10.1007/s11042-022-12065-1
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Assuncao, WG
   Piccolo, LSG
   Zaina, LAM
AF Assuncao, Willian G.
   Piccolo, Lara S. G.
   Zaina, Luciana A. M.
TI Considering emotions and contextual factors in music recommendation: a
   systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Music recommendation; Emotion; Context; User experience
ID AWARE; RESPONSES
AB In recent years, several music recommendation systems have been developed with the aim of incorporating valuable information into the user's modeling and recommendation process. The inclusion of emotions and contextual information in music recommendation applications is increasingly becoming a relevant aspect to improve the listening experience. Thus, the main aim of this systematic literature review (SLR) is investigating the music recommendation approaches that considers emotions and/or context (research question 1) as well as to identify the main gaps and challenges that still remain and need to be addressed by future research (research question 2). After an extensive research, 64 publications were identified to answer the research questions. The studies were analyzed and evaluated for relevance. The main approaches that consider emotions and context were identified. The results of the review indicate that most studies in the field that combine multiple approach related to emotions or context factors have improved the user's hearing experience. The main contributions of this review are a set of aspects that we consider important to be addressed by the music recommendation systems, such as: user activity, satisfaction, feedback, cold-start problems, cognitive load, learning, personality, and user preference. In addition, we also present a broad discussion about the challenges, difficulties and limitations that exist in music recommendation systems that consider emotions and contextual factors.
C1 [Assuncao, Willian G.; Zaina, Luciana A. M.] Univ Fed Sao Carlos, Dept Comp Sci, Sao Carlos, Brazil.
   [Piccolo, Lara S. G.] Open Univ, Knowledge Media Inst, Milton Keynes, Bucks, England.
C3 Universidade Federal de Sao Carlos; Open University - UK
RP Assuncao, WG (corresponding author), Univ Fed Sao Carlos, Dept Comp Sci, Sao Carlos, Brazil.
EM willian.assuncao@ufscar.br; lara.piccolo@open.ac.uk; lzaina@ufscar.br
RI Assuncao, Willian Garcias/AAL-1703-2020
OI Assuncao, Willian Garcias/0000-0002-0552-9013
CR Aalbers S, 2020, ART PSYCHOTHER, V71, DOI 10.1016/j.aip.2020.101720
   Abdul A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071103
   Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Andjelkovic I, 2019, INT J HUM-COMPUT ST, V121, P142, DOI 10.1016/j.ijhcs.2018.04.004
   [Anonymous], 2017, PROC CVPR IEEE
   [Anonymous], 2014, P 4 ACM INT C MULT R
   [Anonymous], 2017, Math. Models Methods Appl. Sci., DOI DOI 10.1142/S0218202517500373
   [Anonymous], 2013, P ACM MULTIMEDIA, DOI DOI 10.1145/2502081.2502170
   Aucouturier JJ, 2013, J INTELL INF SYST, V41, P483, DOI 10.1007/s10844-013-0251-x
   Ayata D, 2018, IEEE T CONSUM ELECTR, V64, P196, DOI 10.1109/TCE.2018.2844736
   Baltes FR, 2011, BRAIN COGNITION, V76, P146, DOI 10.1016/j.bandc.2011.01.012
   Barrett LF, 2006, CURR DIR PSYCHOL SCI, V15, P79, DOI 10.1111/j.0963-7214.2006.00411.x
   Bauer JS, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON SUPPORTING GROUP WORK, GROUP 2018, P27, DOI 10.1145/3148330.3148331
   Bogdanov D, 2013, INFORM PROCESS MANAG, V49, P13, DOI 10.1016/j.ipm.2012.06.004
   Braunhofer M, 2013, INT J MULTIMED INF R, V2, P31, DOI 10.1007/s13735-012-0032-2
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Buchinger D, 2014, REV BRAS COMPUT APL, V6, P108, DOI 10.5335/rbca.2014.3452
   Çano E, 2017, L N INST COMP SCI SO, V188, P154, DOI 10.1007/978-3-319-52569-3_14
   Carter, 2020, THESIS U MISSISSIPPI
   Casillo M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03438-9
   Champiri ZD, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673410
   Chang JW, 2021, MULTIMED TOOLS APPL, V80, P34037, DOI 10.1007/s11042-019-08356-9
   Chen CM, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P65, DOI 10.1109/WI-IAT.2013.10
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Chingshun Lin, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P375, DOI 10.1109/ICMLC.2016.7860930
   Chiu MC, 2017, MULTIMED TOOLS APPL, V76, P15607, DOI 10.1007/s11042-016-3860-x
   Das D., 2017, Int. J. Comput. Appl., V160
   de Assuncao WG, 2019, PROCEEDINGS OF THE 18TH BRAZILIAN SYMPOSIUM ON HUMAN FACTORS IN COMPUTING SYSTEMS (IHC 2019), DOI 10.1145/3357155.3358459
   de Assuncao WG, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P205, DOI 10.1145/3282894.3282915
   Deldjoo Yashar, 2021, ARXIV210711803
   Deng JJ, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2723575
   Deng JJ, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION SCIENCE, SERVICE SCIENCE AND DATA MINING (ISSDM2012), P796
   Dey AK, 2000, PROVIDING ARCHITECTU
   Dias R, 2014, CBRECSYS RECSYS, P26
   Eerola T., 2012, MUSIC PERCEPT INTERD, V30, p307 340
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ferwerda B., 2014, UMAP WORKSHOPS
   Fessahaye F, 2019, I SYMP CONSUM ELECTR, DOI 10.1109/icce.2019.8662028
   Geetha G, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012101
   Gilda S, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P154, DOI 10.1109/WiSPNET.2017.8299738
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Han WH, 2018, IEEE SYS MAN CYBERN, P1903, DOI 10.1109/SMC.2018.00329
   Hansen C, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P53, DOI 10.1145/3383313.3412248
   Harrison R., 2013, J INTERACTION SCI, V1, P1, DOI [10.1186/2194-0827-1-1, DOI 10.1186/2194-0827-1-1]
   Helmholz Patrick, 2014, Advancing the Impact of Design Science: Moving from Theory to Practice. 9th International Conference, DESRIST 2014. Proceedings: LNCS 8463, P393, DOI 10.1007/978-3-319-06701-8_32
   Helmholz P, 2019, BLED EC, P50
   Hodges D.A., 2019, Music in the human experience: an introduction to music psychology, V2nd
   Hong J., 2014, P 29 ANN ACM S APPL, P1463
   Hsu JL, 2018, MULTIMEDIA SYST, V24, P195, DOI 10.1007/s00530-017-0542-0
   Hu XP, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P793, DOI 10.1145/3041021.3054259
   Hu XP, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808201
   Hyung Z, 2017, INFORM PROCESS MANAG, V53, P1185, DOI 10.1016/j.ipm.2017.04.006
   Inzunza S, 2017, ADV INTELL SYST COMP, V569, P899, DOI 10.1007/978-3-319-56535-4_88
   Iso W., 1998, The international organization for standardization, V45
   Iyer AV, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1573, DOI 10.1109/RTEICT.2017.8256863
   Janssen JH, 2012, USER MODEL USER-ADAP, V22, P255, DOI 10.1007/s11257-011-9107-7
   Jazi SY, 2021, MULTIMED TOOLS APPL, V80, P13559, DOI 10.1007/s11042-020-10386-7
   Jenkins E, 2016, LECT NOTES COMPUT SC, V9828, P201, DOI 10.1007/978-3-319-44406-2_15
   Jiang CK, 2016, INT C PAR DISTRIB SY, P133, DOI [10.1109/ICPADS.2016.0027, 10.1109/ICPADS.2016.25]
   Jin YC, 2019, ACM UMAP '19: PROCEEDINGS OF THE 27TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P294, DOI 10.1145/3320435.3320445
   Kamalzadeh M, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P19, DOI 10.1145/2856767.2856780
   Kaminskas M., 2013, P 7 ACM C REC SYST N, P17
   Kaminskas M, 2011, LECT NOTES COMPUT SC, V6787, P183, DOI 10.1007/978-3-642-22362-4_16
   Kang D, 2019, MULTIMED TOOLS APPL, V78, P3267, DOI 10.1007/s11042-018-6733-7
   Karlsson B., 2012, Artificial Intelligence Applications and Innovations, V382, P520
   Kasinathan V., 2019, Indonesian J. Electr. Eng. Comput. Sci., V16, P275, DOI [10.11591/ijeecs.v16.i1.pp275-282, DOI 10.11591/IJEECS.V16.I1.PP275-282]
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kittimathaveenan K, 2020, 2020 6 INT C ENG APP, P1
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Ko YJ, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P628, DOI 10.1109/WF-IoT.2015.7389127
   Konstan JA, 2012, USER MODEL USER-ADAP, V22, P101, DOI 10.1007/s11257-011-9112-x
   Lee, 2018, MUSIC ITS LOVERS EMP
   Lee M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P95, DOI 10.1145/2638728.2638749
   Lee WP, 2017, KNOWL-BASED SYST, V131, P70, DOI 10.1016/j.knosys.2017.06.002
   Lehtiniemi A., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P143, DOI 10.1109/IV.2012.34
   Li Q, 2017, INT C INT INT SYST A, P469
   LOCKNER D, 2014, P ERG INF AV C DES E
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Magara MB, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND INNOVATIVE BUSINESS PRACTICES FOR THE TRANSFORMATION OF SOCIETIES (EMERGITECH), P309, DOI 10.1109/EmergiTech.2016.7737358
   Mariappan MB, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P84, DOI 10.1109/ISM.2012.24
   Mastrika Giri G.A.V., 2016, INDONES J ELECT ENG, V4, P459, DOI 10.11591/ijeecs.v4.i2.pp459-464
   Melchiorre Alessandro B., 2020, RecSys '20: Fourteenth ACM Conference on Recommender Systems, P533, DOI 10.1145/3383313.3412223
   Miller S., 2010, P ISMIR, P237
   Moore AF, 2012, ASHG POP FOLK MUSIC, P1
   Mroz B., 2016, J FINANCIAL CRIME, V23, P637, DOI [10.1108/JFC-04-2015-0022, DOI 10.1108/JFC-04-2015-0022]
   Nair Amrita, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1767, DOI 10.1109/ICCES51350.2021.9489138
   Nakahara H, 2011, INT J PSYCHOPHYSIOL, V81, P152, DOI 10.1016/j.ijpsycho.2011.06.003
   Narducci Fedelucio., 2015, P 3 WORKSHOP EMOTION, P3, DOI DOI 10.1145/2809643.2809648
   Nielsen, 1994, USABILITY ENG
   Okada K, 2013, SIGGRAPH AS 2013 S M, P1, DOI [10.1145/2543651.2543655, DOI 10.1145/2543651.2543655]
   Padovani RR, 2017, 13 ART INT INT DIG E
   Peters J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2219, DOI 10.1109/IROS.2006.282564
   Plutchik R., 1980, EMOTION: Theory, Research, and Experience
   Polignano M, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114382
   Rho S, 2013, MULTIMED TOOLS APPL, V65, P259, DOI 10.1007/s11042-011-0803-4
   Rosa RL, 2015, IEEE T CONSUM ELECTR, V61, P359, DOI 10.1109/TCE.2015.7298296
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sagar K., 2017, International Journal of Information Technology, P1, DOI DOI 10.1007/S41870-017-0048-1
   Schedl M., 2013, P INT C ADV MOB COMP, P3, DOI [10.1145/2536853.2536856, DOI 10.1145/2536853.2536856]
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Sen A., 2015, LOC AW REC LOC C REC, V1405, P40
   Shakirova E, 2017, IEEE NW RUSS YOUNG, P548, DOI 10.1109/EIConRus.2017.7910613
   Shen TC, 2020, AAAI CONF ARTIF INTE, V34, P206
   Song Y., 2012, 9 INT S COMP MUS MOD, V4, P395
   Song Y., 2016, THESIS QUEEN MARY U
   Song YD, 2016, MUSIC PERCEPT, V33, P472, DOI 10.1525/MP.2016.33.4.472
   Srikanth B., 2020, Int J Innov Sci Res Tech, V5, P390
   Teng Y, 2013, 2013 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P9, DOI 10.1109/CogSIMA.2013.6523817
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Uitdenbogerd A, 2002, ISMIR 2002, P204
   Vateekul P, 2015, PRINCIPLES PRACTICE, P155
   Volokhin S, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P313, DOI 10.1145/3176349.3176885
   Volokhin S, 2018, ACM/SIGIR PROCEEDINGS 2018, P1045, DOI 10.1145/3209978.3210154
   Wang CY, 2018, J INTERNET TECHNOL, V19, P765, DOI 10.3966/160792642018051903013
   Wang DJ, 2021, IEEE T NEUR NET LEAR, V32, P1375, DOI 10.1109/TNNLS.2020.2984665
   Wang X., 2011, 12 INT SOC MUSIC INF, P765
   Wang Xinxi., 2012, Proceedings of the 20th ACM international conference on Multimedia, P99, DOI [DOI 10.1145/2393347.2393368, 10.1145/2393347.2393368]
   Welch KC, 2012, IEEE INSTRU MEAS MAG, V15, P28, DOI 10.1109/MIM.2012.6145259
   Wohlfahrt-Laymann J, 2017, FRONT ARTIF INTEL AP, V292, P303, DOI 10.3233/978-1-61499-720-7-303
   Wood PA, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS, P474, DOI 10.1109/CTS.2015.7210471
   Yang J, 2016, LECT NOTES COMPUT SC, V9747, P110, DOI 10.1007/978-3-319-40355-7_11
   Yang YH, 2011, MULTIMEDIA COMPUT CO, P1
   Yang YH, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2738220
   Yike Guo, 2012, Brain Informatics. International Conference, BI 2012. Proceedings, P265, DOI 10.1007/978-3-642-35139-6_25
   Yoon K, 2012, IEEE T CONSUM ELECTR, V58, P612, DOI 10.1109/TCE.2012.6227467
   Yu Tao, 2019, 2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC). Proceedings, P54, DOI 10.1109/DSC.2019.00017
NR 131
TC 12
Z9 12
U1 4
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8367
EP 8407
DI 10.1007/s11042-022-12110-z
EA FEB 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Rani, M
   Gagandeep
AF Rani, Manisha
   Gagandeep
TI Effective network intrusion detection by addressing class imbalance with
   deep neural networks multimedia tools and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data Normalization; Neural Networks; Class Imbalance; Intrusion
   Detection System
ID LEARNING APPROACH; DETECTION SYSTEM; MODEL; SVM
AB The Intrusion Detection System plays a significant role in discovering malicious activities and provides better network security solutions than other conventional defense techniques such as firewalls. With the aid of machine learning-based techniques, such systems can detect attacks more accurately by identifying the relevant data patterns. However, the nature of network data, time-varying environment, and unknown occurrence of attacks made the learning task very complex. We propose a deep neural network that utilizes the classifier-level class imbalance solution to solve this problem effectively. Initially, the network data is preprocessed through data conversion followed by the min-max normalization method. Then, normalized data is fed to neural network where the cross-entropy function is modified to address the class imbalance problem. It is achieved by weighting the classes while training the classifier. The extensive experiments are performed on two challenging datasets, namely NSL-KDD and UNSW-NB15, to establish the superiority of the proposed approach. It includes comparisons with commonly employed imbalance approaches such as under-sampling, over-sampling, and bagging as well as existing works. The proposed approach attains 85.56% and 90.76% classification accuracy on NSL-KDD and UNSW-NB15 datasets, respectively. These outcomes outperformed data-level imbalance methods and existing works that validate the need to incorporate class imbalance for network traffic categorization.
C1 [Rani, Manisha; Gagandeep] Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
C3 Punjabi University
RP Rani, M (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
EM manishabhandari1993@gmail.com; gdeep.pbi@gmail.com
CR Al-Qatf M, 2018, IEEE ACCESS, V6, P52843, DOI 10.1109/ACCESS.2018.2869577
   Aldwairi T, 2018, COMPUT NETW, V144, P111, DOI 10.1016/j.comnet.2018.07.025
   Aleesa AM, 2021, J ENG SCI TECHNOL, V16, P711
   Almi'ani M, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P138, DOI 10.1109/SDS.2018.8370435
   Alsaadi Hajar Saif, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P195, DOI 10.1109/ICIoT48696.2020.9089659
   Ashfaq RAR, 2017, INFORM SCIENCES, V378, P484, DOI 10.1016/j.ins.2016.04.019
   Ashiku L, 2021, PROCEDIA COMPUT SCI, V185, P239, DOI 10.1016/j.procs.2021.05.025
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Çavusoglu Ü, 2019, APPL INTELL, V49, P2735, DOI 10.1007/s10489-018-01408-x
   Clevert D., 2016, ARXIV151107289
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Ding S, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1474, DOI 10.1109/CompComm.2017.8322786
   Dong RH, 2020, IET INFORM SECUR, V14, P166, DOI 10.1049/iet-ifs.2019.0294
   Fasih M, 2014, INT J ENHANCED RES S, V3, P259
   Gao JL, 2019, CHIN CONTR CONF, P8909, DOI [10.23919/ChiCC.2019.8865258, 10.23919/chicc.2019.8865258]
   García-Teodoro P, 2009, COMPUT SECUR, V28, P18, DOI 10.1016/j.cose.2008.08.003
   Garg S, 2020, J PARALLEL DISTR COM, V135, P219, DOI 10.1016/j.jpdc.2019.09.013
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hagan MT, 1997, NEURAL NETWORK DESIG
   Hardt M, 2016, PR MACH LEARN RES, V48
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Ibrahim LM, 2013, J ENG SCI TECHNOL, V8, P107
   Ieracitano C, 2020, NEUROCOMPUTING, V387, P51, DOI 10.1016/j.neucom.2019.11.016
   Ingre B, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P92, DOI 10.1109/SPACES.2015.7058223
   Injadat MN, 2021, IEEE T NETW SERV MAN, V18, P1803, DOI 10.1109/TNSM.2020.3014929
   Jiang KY, 2020, IEEE ACCESS, V8, P32464, DOI 10.1109/ACCESS.2020.2973730
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kasongo SM, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00379-6
   Kasongo SM, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101752
   Khan FA, 2019, IEEE ACCESS, V7, P30373, DOI 10.1109/ACCESS.2019.2899721
   Khan MA, 2021, PROCESSES, V9, DOI 10.3390/pr9050834
   Khraisat A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010173
   Kim J, 2017, INT CONF BIG DATA, P313, DOI 10.1109/BIGCOMP.2017.7881684
   King G., 2001, POLIT ANAL, V9, P137, DOI [DOI 10.1093/OXFORDJOURNALS.PAN.A004868, https://doi.org/10.1093/oxfordjournals.pan.a004868]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krömer P, 2011, IEEE SYS MAN CYBERN, P313, DOI 10.1109/ICSMC.2011.6083684
   Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9
   Li WJ, 2011, PROCEDIA ENVIRON SCI, V11, P256, DOI 10.1016/j.proenv.2011.12.040
   Li ZP, 2017, LECT NOTES COMPUT SC, V10638, P858, DOI 10.1007/978-3-319-70139-4_87
   Liao HJ, 2013, J NETW COMPUT APPL, V36, P16, DOI 10.1016/j.jnca.2012.09.004
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Man JR, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5593435
   Manda B, 2021, IEEE ACCESS, V9, P22711, DOI 10.1109/ACCESS.2021.3055826
   Mebawondu JO, 2020, SCI AFR, V9, DOI 10.1016/j.sciaf.2020.e00497
   Mighan SN, 2021, INT J INF SECUR, V20, P387, DOI 10.1007/s10207-020-00508-5
   Mohammadi M, 2012, SECUR COMMUN NETW, V5, P1296, DOI 10.1002/sec.403
   Moukhafi M, 2018, INT C ADV INT SYST S, P393
   Mulyanto M, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010004
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nguyen S-N, 2018, P 2 INT C MACHINE LE, P34, DOI DOI 10.1145/3184066.3184089
   Patel A, 2013, J NETW COMPUT APPL, V36, P25, DOI 10.1016/j.jnca.2012.08.007
   Paulauskas N, 2017, 2017 OPEN CONFERENCE OF ELECTRICAL, ELECTRONIC AND INFORMATION SCIENCES (ESTREAM)
   Peng P, 2020, NEUROCOMPUTING, V407, P232, DOI 10.1016/j.neucom.2020.04.075
   Pervez MS, 2014, I C SOFTWARE KNOWL I
   Praneeth NSKH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1344, DOI 10.1109/RTEICT.2016.7808050
   Priyadarsini Pullagura Indira, 2021, Proceedings of International Conference on Computational Intelligence and Data Engineering. ICCIDE 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 56), P15, DOI 10.1007/978-981-15-8767-2_2
   Rani, 2019, REV INTRUSION DETECT
   Rani M., 2021, 2021 8 INT C COMP SU, P496
   Rawat S, 2022, INTERNET TECHNOL LET, V5, DOI 10.1002/itl2.232
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sethi K, 2020, INT CONF COMMUN SYST, DOI 10.1109/comsnets48256.2020.9027452
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Su TT, 2020, IEEE ACCESS, V8, P29575, DOI 10.1109/ACCESS.2020.2972627
   Tan XP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010203
   Tao W, 2021, INTRUSION DETECTION
   Tavallaee M, 2009, 2009 IEEE S COMP INT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Tchakoucht TA, 2018, IEEE ACCESS, V6, P72458, DOI 10.1109/ACCESS.2018.2867345
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Umar Mubarak Albarka, 2020, ICICSE '20: Proceedings of the 2020 International Conference on Internet Computing for Science and Engineering, P5, DOI 10.1145/3424311.3424330
   Umar M.A., 2020, EFFECTS FEATURE SELE
   Verma Ashish Kumar, 2019, 2019 International Conference on Communication and Electronics Systems (ICCES), P409, DOI 10.1109/ICCES45898.2019.9002221
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Wang Y, 2016, INT CONF SOFTW ENG, P422, DOI 10.1109/ICSESS.2016.7883100
   Wu KH, 2018, IEEE ACCESS, V6, P50850, DOI 10.1109/ACCESS.2018.2868993
   Wu YK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195710
   Wu YK, 2020, IEEE ACCESS, V8, P98600, DOI 10.1109/ACCESS.2020.2994947
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Xu J, 2020, IEEE SYMP COMP COMMU, P703, DOI 10.1109/iscc50000.2020.9219587
   Yeung DY, 2003, PATTERN RECOGN, V36, P229, DOI 10.1016/S0031-3203(02)00026-2
   Yin CL, 2017, IEEE ACCESS, V5, P21954, DOI 10.1109/ACCESS.2017.2762418
   Yousefi-Azar M, 2017, IEEE IJCNN, P3854, DOI 10.1109/IJCNN.2017.7966342
   Zhang CZ, 2019, PROC INT CONF ANTI, P41, DOI [10.1109/icasid.2019.8925239, 10.1109/ICASID.2019.8925239]
   Zwane S., 2018, P INT C INT INN COMP, V2018, P1, DOI DOI 10.1109/ICONIC.2018.8601203
NR 86
TC 18
Z9 18
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8499
EP 8518
DI 10.1007/s11042-021-11747-6
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800001
DA 2024-07-18
ER

PT J
AU Cao, SX
   Shu, ZC
   Xu, ZP
   Xie, DL
   Xu, Y
AF Cao, Songxiao
   Shu, Zichao
   Xu, Zhipeng
   Xie, Dailiang
   Xu, Ya
TI Character segmentation and restoration of Qin-Han bamboo slips using
   local auto-focus thresholding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto thresholding; Historical Chinese character restoration;
   Multi-gaussian fit
ID RECOGNITION
AB This paper presents a novel auto-thresholding method for character segmentation and restoration of historical Chinese documents. The objective was to segment and restore the characters of Qin-Han bamboo slips effectively with complex background noise. To that end, giving a whole page image with several bamboo slips, the proposed method first extracted and straightened every single slip by connected component analysis. Furthermore, for every straightened slip, a horizontal histogram projection method was used to segment all character regions. After that, a novel auto thresholding method, which was motivated by the auto-focus process of camera, was used to find the optimal threshold of every character region. In this method, the algorithm traversed all the thresholds in a certain range and generated an Effective Character Contour Length (ECCL) value for each threshold, then multi-Gaussian model was used to fit the ECCL curve and the global peak position of ECCL curve was the needed final optimal threshold for the character region. Experimental results showed that the proposed method was effective for historical character segmentation and restoration under complex background noise. Compared to five existing state of the art algorithms, including Otsu, integral image adaptive thresholding method, Sauvola, GAN denoising and SAE algorithm, the proposed method can not only restore the whole characters more completely, but also suppress the noise better.
C1 [Cao, Songxiao; Shu, Zichao; Xu, Zhipeng; Xie, Dailiang; Xu, Ya] China Jiliang Univ, Coll Metrol & Measurement Engn, Hangzhou 310018, Peoples R China.
C3 China Jiliang University
RP Cao, SX (corresponding author), China Jiliang Univ, Coll Metrol & Measurement Engn, Hangzhou 310018, Peoples R China.
EM caosongxiao@cjlu.edu.cn
RI Cao, Songxiao/HKE-6408-2023
OI Cao, Songxiao/0000-0001-5122-3472
FU Natural Science Foundation of Zhejiang Province, China
FX Natural Science Foundation of Zhejiang Province, China (No.LY18E050009
   and No.Q19E060008).
CR Babu NSA, 2019, P 2019 INT C COMM SI
   Calvo-Zaragoza J, 2019, PATTERN RECOGN, V86, P37, DOI 10.1016/j.patcog.2018.08.011
   dos Santos Rodolfo P., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P651, DOI 10.1109/ICDAR.2009.183
   Huang ZK, 2016, LECT NOTES ARTIF INT, V9773, P171, DOI 10.1007/978-3-319-42297-8_17
   Kehtarnavaz N, 2003, REAL-TIME IMAGING, V9, P197, DOI 10.1016/S1077-2014(03)00037-8
   Nguyen KC, 2017, IEICE T INF SYST, VE100D, P2962, DOI 10.1587/transinf.2017EDP7225
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Liu SX, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0368-5
   Messina R, 2015, PROC INT CONF DOC, P171
   Panichkriangkrai Chulapong., 2013, P 2 INT WORKSHOP HIS, P118
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   SHIRAI K, 2013, 2013 12 INT C DOC AN
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
   Watanabe Kei, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P934, DOI 10.1109/ICDAR.2019.00154
   Wu YC, 2018, P 2017 14 IAPR INT C
   Xie ZC, 2016, INT C PATT RECOG, P4011
   Xu X, 2011, SENSORS-BASEL, V11, P8281, DOI 10.3390/s110908281
   Yang HL, 2018, IEEE ACCESS, V6, P30174, DOI 10.1109/ACCESS.2018.2840218
   Zhang JL, 2020, MULTIMED TOOLS APPL, V79, P119, DOI 10.1007/s11042-019-08052-8
NR 19
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8199
EP 8213
DI 10.1007/s11042-022-11988-z
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749407800002
DA 2024-07-18
ER

PT J
AU Bansal, P
   Vaid, M
   Gupta, S
AF Bansal, Priti
   Vaid, Mayur
   Gupta, Shivam
TI OBCD-HH: an object-based change detection approach using multi-feature
   non-seed-based region growing segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bi-temporal Satellite Images; Object-Based Change Detection;
   Multi-Feature Non-Seed-Based Region Growing; Harris Hawk; Histogram
   Trend Similarity
ID COVER CHANGE DETECTION; IMAGE SEGMENTATION; LAND-USE; OPTIMIZATION;
   ALGORITHM; NETWORK; IMPACT; SCALE; INDEX
AB There is an increasing need to get updated information regarding the changes on earth's surface. The information obtained can be used in a wide range of applications including disaster management, land-use investigation etc. The high-resolution remote sensing images obtained from satellites provide us with an opportunity to detect changes on earth's surface between various time intervals. In this paper, an unsupervised object-based change detection (OBCD) method is proposed to detect changes in high resolution bi-temporal satellite images. To detect changes, a novel multi-feature non-seed-based region growing (MF-NSRG) algorithm is proposed for image segmentation based on heterogeneity minimization that uses textural heterogeneity along with spectral and spatial heterogeneity during region growing. The performance of MF-NSRG algorithm is further improved by using Harris Hawk, a recently proposed metaheuristic algorithm, which is used to obtain optimal values of segmentation parameters. Finally, the feature maps extracted from the pre-change and post-change segmented images are analysed using histogram trend similarity (HTS) approach to detect changes. The proposed approach is known as object-based change detection using Harris Hawk (OBCD-HH). The proposed OBCD-HH approach is applied on two datasets: xBD and Onera Satellite Change Detection (OSCD) dataset. Its performance is compared with existing state-of-the-art algorithms and results show the superiority of the proposed approach.
C1 [Bansal, Priti; Vaid, Mayur; Gupta, Shivam] Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Bansal, P (corresponding author), Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
EM bansalpriti79@gmail.com; mayur26vaid@gmail.com; shivamgupta077@gmail.com
RI Gupta, Shivam/JNE-3789-2023; Bansal, Priti/AES-0554-2022
OI Bansal, Priti/0000-0002-0806-7125
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Aldhshan SRS, 2019, ARAB J GEOSCI, V12, DOI 10.1007/s12517-019-4597-4
   Amit SNKB, 2016, INT GEOSCI REMOTE SE, P5189, DOI 10.1109/IGARSS.2016.7730352
   [Anonymous], 1974, P 2 INT JOINT C PATT
   Baatz M., 2000, Multiresolution Segmentation: an optimization approach for high quality multi-scale image segmentation, DOI DOI 10.1016/J.ISPRSJPRS.2003.10.002
   Bolorinos J, 2020, WATER RESOUR RES, V56, DOI 10.1029/2019WR025812
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cao G, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083678
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen S., 2021, ARXIV PREPRINT ARXIV
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   De Bie C.A., 2008, INT ARCH PHOTOGRAMME, V37, P803
   Do CB, 2008, NAT BIOTECHNOL, V26, P897, DOI 10.1038/nbt1406
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Gupta R., 2019, P IEEE CVF C COMP VI, P10
   Han Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060983
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hegazy Ibrahim Rizk, 2015, International Journal of Sustainable Built Environment, V4, P117, DOI 10.1016/j.ijsbe.2015.02.005
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hossain MD, 2019, ISPRS J PHOTOGRAMM, V150, P115, DOI 10.1016/j.isprsjprs.2019.02.009
   [黄维 Huang Wei], 2016, [国土资源遥感, Remote Sensing for Land & Resources], V28, P22
   Ikonomakis N, 1997, DSP 97: 1997 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P299, DOI 10.1109/ICDSP.1997.628077
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Jian P, 2016, INT J REMOTE SENS, V37, P1814, DOI 10.1080/2150704X.2016.1163744
   Johnson BA, 2015, ISPRS INT J GEO-INF, V4, P2292, DOI 10.3390/ijgi4042292
   Jong K. L., 2019, 2019 INT JOINT C NEU, P1, DOI [DOI 10.1109/IJCNN.2019.8851762, 10.1109/IJCNN.2019.8851762]
   Kalpana V, 2018, MULTIMED TOOLS APPL, V77, P30487, DOI 10.1007/s11042-018-6125-z
   Karaboga D., 2005, Technical report-tr06
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Koshimura S, 2011, INT GEOSCI REMOTE SE, P1993
   Lin Wu, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9217, P263, DOI 10.1007/978-3-319-21978-3_24
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liu T, 2021, REMOTE SENS ENVIRON, V256, DOI 10.1016/j.rse.2021.112308
   Long X-Y., 2008, GEO INF SCI, V10, P121, DOI [10.3724/SP.J.1047.2008.00121, DOI 10.3724/SP.J.1047.2008.00121]
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Lv ZY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111809
   Mallupattu PK, 2013, SCI WORLD J, DOI 10.1155/2013/268623
   Malmir M, 2015, ENVIRON MONIT ASSESS, V187, DOI 10.1007/s10661-015-4295-y
   Mas JF, 2017, EUR J REMOTE SENS, V50, P626, DOI 10.1080/22797254.2017.1387505
   Mishra PK, 2020, EGYPT J REMOTE SENS, V23, P133, DOI 10.1016/j.ejrs.2019.02.001
   Möller M, 2007, INT J APPL EARTH OBS, V9, P311, DOI 10.1016/j.jag.2006.10.002
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pati C, 2020, ENG SCI TECHNOL, V23, P973, DOI 10.1016/j.jestch.2020.01.002
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2017, INT J REMOTE SENS, V38, P3886, DOI 10.1080/01431161.2017.1308033
   Peng DF, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.016024
   Pitts DAD, 2017, INT J APPL EARTH OBS, V57, P49, DOI 10.1016/j.jag.2016.12.004
   Salazar A, 2015, GLOBAL PLANET CHANGE, V128, P103, DOI 10.1016/j.gloplacha.2015.02.009
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shah-Hosseini R, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.095992
   Shanmugam T., 2013, European Journal of Geography, V4, P50
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Thunig H, 2011, PROC SPIE, V8181, DOI 10.1117/12.897581
   Tolessa T, 2017, ECOSYST SERV, V23, P47, DOI 10.1016/j.ecoser.2016.11.010
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   van de Weijer J, 2004, IEEE IMAGE PROC, P1835
   Venugopal N, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0252-0
   Wang DC, 2021, INT J APPL EARTH OBS, V101, DOI 10.1016/j.jag.2021.102348
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wu L, 2014, COMM COM INF SC, V483, P314
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhang Z., 2018, ARXIV180709562, V1812, P04202
NR 73
TC 5
Z9 6
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8059
EP 8091
DI 10.1007/s11042-021-11779-y
EA JAN 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750341800004
DA 2024-07-18
ER

PT J
AU Jan, TG
   Khurana, SS
   Kumar, M
AF Jan, Tabassum Gull
   Khurana, Surinder Singh
   Kumar, Munish
TI Semi-supervised labeling: a proposed methodology for labeling the
   twitter datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Spam labeling; Clustering; Spam detection; Tweets
ID SPAMMERS
AB Twitter has nowadays become a trending microblogging and social media platform for news and discussions. Since the dramatic increase in its platform has additionally set off a dramatic increase in spam utilization in this platform. For Supervised machine learning, one always finds a need to have a labeled dataset of Twitter. It is desirable to design a semi-supervised labeling technique for labeling newly prepared recent datasets. To prepare the labeled dataset lot of human affords are required. This issue has motivated us to propose an efficient approach for preparing labeled datasets so that time can be saved and human errors can be avoided. Our proposed approach relies on readily available features in real-time for better performance and wider applicability. This work aims at collecting the most recent tweets of a user using Twitter streaming and prepare a recent dataset of Twitter. Finally, a semi-supervised machine learning algorithm based on the self-training technique was designed for labeling the tweets. Semi-supervised support vector machine and semi-supervised decision tree classifiers were used as base classifiers in the self-training technique. Further, the authors have applied K means clustering algorithm to the tweets based on the tweet content. The principled novel approach is an ensemble of semi-supervised and unsupervised learning wherein it was found that semi-supervised algorithms are more accurate in prediction than unsupervised ones. To effectively assign the labels to the tweets, authors have implemented the concept of voting in this novel approach and the label pre-directed by the majority voting classifier is the actual label assigned to the tweet dataset. Maximum accuracy of 99.0% has been reported in this paper using a majority voting classifier for spam labeling.
C1 [Jan, Tabassum Gull; Khurana, Surinder Singh] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
C3 Central University of Punjab
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
EM tabassumgull2012@gmail.com; surinder.seeker@gmail.com;
   munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Al-Zoubi AM, 2017, INT CONF INFORM COMM, P130, DOI 10.1109/IACS.2017.7921959
   [Anonymous], 2012, CSE508 STON BROOK U
   Abkenar SB, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6381
   Benevenuto Fabricio., 2010, CEAS
   Eshraqi N, 2015, SECOND INTERNATIONAL CONGRESS ON TECHNOLOGY, COMMUNICATION AND KNOWLEDGE (ICTCK 2015), P347, DOI 10.1109/ICTCK.2015.7582694
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Gautam G, 2014, INT CONF CONTEMP, P437, DOI 10.1109/IC3.2014.6897213
   Herzallah W, 2018, J INF SCI, V44, P230, DOI 10.1177/0165551516684296
   Inuwa-Dutse I, 2018, NEUROCOMPUTING, V315, P496, DOI 10.1016/j.neucom.2018.07.044
   Lin PC, 2013, INT CONF ADV COMMUN, P841
   Liu C, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P2526, DOI 10.1109/CompComm.2016.7925154
   Peikari M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24876-0
   Sedhai S, 2018, IEEE T COMPUT SOC SY, V5, P169, DOI 10.1109/TCSS.2017.2773581
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Sun N, 2020, IEEE T AUTOM SCI ENG, V17, P1017, DOI [10.1109/TASE.2019.2961258, 10.1080/1206212X.2020.1751387]
NR 15
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7669
EP 7683
DI 10.1007/s11042-022-12221-7
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749232600002
DA 2024-07-18
ER

PT J
AU Mehrotra, R
   Agrawal, R
   Ansari, MA
AF Mehrotra, Rajat
   Agrawal, Rajeev
   Ansari, M. A.
TI Diagnosis of hypercritical chronic pulmonary disorders using dense
   convolutional network through chest radiography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chronic pulmonary disorders; COVID-19; Pneumonia; Chest x-ray (CXR);
   Deep learning; CNN
ID DEEP; CLASSIFICATION; ALGORITHMS; CAD
AB Lung-related ailments are prevalent all over the world which majorly includes asthma, chronic obstructive pulmonary disease (COPD), tuberculosis, pneumonia, fibrosis, etc. and now COVID-19 is added to this list. Infection of COVID-19 poses respirational complications with other indications like cough, high fever, and pneumonia. WHO had identified cancer in the lungs as a fatal cancer type amongst others and thus, the timely detection of such cancer is pivotal for an individual's health. Since the elementary convolutional neural networks have not performed fairly well in identifying atypical image types hence, we recommend a novel and completely automated framework with a deep learning approach for the recognition and classification of chronic pulmonary disorders (CPD) and COVID-pneumonia using Thoracic or Chest X-Ray (CXR) images. A novel three-step, completely automated, approach is presented that first extracts the region of interest from CXR images for preprocessing, and they are then used to detects infected lungs X-rays from the Normal ones. Thereafter, the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD), which might be utilized in the current scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases. And finally, highlight the regions in the CXR which are indicative of severe chronic pulmonary disorders like COVID-19 and pneumonia. A detailed investigation of various pivotal parameters based on several experimental outcomes are made here. This paper presents an approach that detects the Normal lung X-rays from infected ones and the infected lung images are further classified into COVID-pneumonia, pneumonia, and other chronic pulmonary disorders with an utmost accuracy of 96.8%. Several other collective performance measurements validate the superiority of the presented model. The proposed framework shows effective results in classifying lung images into Normal, COVID-pneumonia, pneumonia, and other chronic pulmonary disorders (OCPD). This framework can be effectively utilized in this current pandemic scenario to help the radiologist in substantiating their diagnosis and in starting well in time treatment of these deadly lung diseases.
C1 [Mehrotra, Rajat] GL Bajaj Inst Technol & Management, Dept Elect & Elect Engn, Gr Noida, India.
   [Agrawal, Rajeev] GL Bajaj Inst Technol & Management, Dept Elect & Commun Engn, Gr Noida, India.
   [Ansari, M. A.] Gautam Buddha Univ, Sch Engn, Dept Elect Engn, Gr Noida, India.
C3 Gautam Buddha University
RP Mehrotra, R (corresponding author), GL Bajaj Inst Technol & Management, Dept Elect & Elect Engn, Gr Noida, India.
EM rajjatmehrootra@gmail.com; rajkecd@gmail.com; ma.ansari@gbu.ac.in
OI Mehrotra, Rajat/0000-0002-7170-4895
CR [Anonymous], 2017, DEEP LEARNING LUNG C
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Baker JA, 2003, AM J ROENTGENOL, V181, P1083, DOI 10.2214/ajr.181.4.1811083
   Barrientos F, 2016, 2016 IEEE 36 CENTR A, P1
   Behzadi-khormouji H, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105162
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bharati S., 2019, INT J HYBRID INTELLI, V15, P91, DOI [DOI 10.3233/HIS-190263, 10.3233/HIS-190263]
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Cheng YT, 2017, IEEE J BIOMED HEALTH, V21, P303, DOI 10.1109/JBHI.2017.2657802
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Cisneros-Velarde P, 2016, IEEE ENG MED BIO, P4117, DOI 10.1109/EMBC.2016.7591632
   Datta Priyanka, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P222, DOI 10.1109/MedCom.2014.7006008
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Eshaghi H, 2021, CASE REP INFECT DIS, V2021, DOI 10.1155/2021/6629966
   Gu Y, 2018, COMPUT BIOL MED, V103, P220, DOI 10.1016/j.compbiomed.2018.10.011
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Hina K, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P285, DOI 10.1109/INTECH.2016.7845039
   Horváth G, 2009, IFMBE PROC, V25, P210, DOI 10.1007/978-3-642-03904-1_59
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Kallianos K, 2019, CLIN RADIOL, V74, P338, DOI 10.1016/j.crad.2018.12.015
   Karargyris A, 2011, IEEE ENG MED BIO, P7779, DOI 10.1109/IEMBS.2011.6091917
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang CH, 2020, CLIN RADIOL, V75, P38, DOI 10.1016/j.crad.2019.08.005
   Liu J, 2018, BIG DATA MIN ANAL, V1, P1, DOI 10.26599/BDMA.2018.9020001
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Mehrotra R, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100003
   Mohammed MA, 2021, CMC-COMPUT MATER CON, V66, P3289, DOI 10.32604/cmc.2021.012874
   Mojoli F, 2019, AM J RESP CRIT CARE, V199, P701, DOI 10.1164/rccm.201802-0236CI
   Mondal M Rubaiyat Hossain, 2020, Inform Med Unlocked, V20, P100374, DOI 10.1016/j.imu.2020.100374
   Murray CJL, 1997, LANCET, V349, P1498, DOI 10.1016/S0140-6736(96)07492-2
   Nasrullah, 2019, PROC SPIE, V10995, DOI 10.1117/12.2520333
   Nielsen KG, 2000, AM J RESP CRIT CARE, V162, P1500, DOI 10.1164/ajrccm.162.4.2002019
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Song QZ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8314740
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Sun W., 2016, SPIE Medical Imaging, p97850Z, DOI DOI 10.1117/12.2216307
   Sun WQ, 2017, COMPUT BIOL MED, V89, P530, DOI 10.1016/j.compbiomed.2017.04.006
   van der Burgh HK, 2017, NEUROIMAGE-CLIN, V13, P361, DOI 10.1016/j.nicl.2016.10.008
   Vieira SM, 2010, IEEE INT CONF FUZZY, DOI 10.1109/FUZZY.2010.5584447
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zenteno O, 2016, IEEE ENG MED BIO, P4129, DOI 10.1109/EMBC.2016.7591635
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079
NR 54
TC 7
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7625
EP 7649
DI 10.1007/s11042-021-11748-5
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600002
PM 35125924
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Rao, CS
   Karunakara, K
AF Rao, Champakamala Sundar
   Karunakara, K.
TI Efficient Detection and Classification of Brain Tumor using Kernel based
   SVM for MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Magnetic Resonance Imaging; Segmentation; Classification;
   Optimization; BRATS
ID SEGMENTATION; ALGORITHM
AB Tumor classification with MRI (Magnetic Resonance Imaging) is critical, as it consumes an enormous amount of time. Furthermore, this detection method is complicated due to the similarity of both abnormal and normal brain tissues. For earlier treatment planning and clinical assessment of brain tumors, automatic segmentation and classification process using medical images are very challenging. Computerized medical imaging aids clinicians in providing critical therapies to patients while allowing faster decision-making. This work focus on efficient segmentation and classification using machine learning (ML) models motivated by diagnosing tumor growth and treatment processes. To achieve efficient brain tumor detection, different stages in the proposed methodology are pre-processing, segmentation, extraction, selection and classification. Initially, blur-removal is done using NMF (Normalized Median Filter) for image smoothening and quality enhancement. Then segmentation is done using binomial thresholding method. The next step is feature extraction, which is the fusion of GLCM (Gray level co-occurrence matrix), and SGLDM (Spatial Grey Level Dependence Matrix) techniques. Harris hawks optimization (HHO) algorithm is used for feature selection. Finally, KSVM-SSD is used for effective and accurate classification. Here, the brain tumor is classified as benign and malignant using KSVM (Kernel Support Vector Machine) and further classification of the malignant tumor as low, medium, and high using social ski driver (SSD) optimization algorithm. The simulation/implementation tool used here is the PYTHON platform. The performance is analyzed on multiple datasets such as BRATS 2018, 2019 and 2020. Hence, it is proved that the segmentation and classification outcomes are superior compared to existing methods with precision, accuracy, recall, and F1 score. The superiority of the proposed KSVM-SSD model is identified in terms of classification accuracy tested on the BRATS datasets with accuracy as 99.2%, 99.36% and 99.15%, respectively for 2018, 2019 and 2020 BRATS datasets. Higher detection accuracy offers timely and proper diagnosis that can save the lives of people. Hence, these outcomes on tumor detection and classification signifiy improved performance when compared to baseline models.
C1 [Rao, Champakamala Sundar; Karunakara, K.] Siddhartha Acad Higher Educ, Sri Siddhartha Inst Technol, Dept Informat Sci & Engn, Tumakuru 572107, Karnataka, India.
RP Rao, CS (corresponding author), Siddhartha Acad Higher Educ, Sri Siddhartha Inst Technol, Dept Informat Sci & Engn, Tumakuru 572107, Karnataka, India.
EM champaka.ssit@gmail.com
CR Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P497, DOI 10.1109/iccisci.2019.8716449
   Anand Kumar G., 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P703, DOI 10.1007/978-981-13-1906-8_71
   [Anonymous], 2018, P 2 INT C MICR EL TE
   Ayadi W, 2019, BIOMED SIGNAL PROCES, V48, P144, DOI 10.1016/j.bspc.2018.10.010
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bousselham A, 2019, INT J BIOMED IMAGING, V2019, DOI 10.1155/2019/1758948
   Busa Srikanth, 2019, Innovations in Computer Science and Engineering. Proceedings of the Fifth ICICSE 2017. Lecture Notes in Networks and Systems (LNNS 32), P249, DOI 10.1007/978-981-10-8201-6_28
   Chatterjee B, 2020, IEEE ACCESS, V8, P75393, DOI 10.1109/ACCESS.2020.2988157
   Chen H, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P301, DOI [10.1109/ICAIBD.2019.8836968, 10.1109/icaibd.2019.8836968]
   Deepa AR, 2019, MULTIMED TOOLS APPL, V78, P11799, DOI 10.1007/s11042-018-6731-9
   Devkota B, 2018, PROCEDIA COMPUT SCI, V125, P115, DOI 10.1016/j.procs.2017.12.017
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Islam R., 2018, INT C COMPUTER COMMU, P1, DOI [10.1109/IC4ME2.2018.8465663, DOI 10.1109/IC4ME2.2018.8465663]
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Nayak T, 2019, LECT NOTE NETW SYST, V43, P347, DOI 10.1007/978-981-13-2514-4_29
   Nazir M, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P434, DOI 10.1109/iccisci.2019.8716413
   Pandiselvi T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1253-1
   Polepaka S, 2019, LECT NOTE NETW SYST, V33, P61, DOI 10.1007/978-981-10-8204-7_6
   Qasem SN, 2019, CMC-COMPUT MATER CON, V59, P713, DOI 10.32604/cmc.2019.05617
   Safira L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P98, DOI [10.1109/ICIAICT.2019.8784856, 10.1109/iciaict.2019.8784856]
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Shah N, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P718, DOI 10.1109/ECTICon.2017.8096339
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Sharif MI, 2021, COMPLEX INTELL SYST, V7, P2023, DOI 10.1007/s40747-021-00310-3
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Shivhare SN, 2019, ADV INTELL SYST COMP, V748, P485, DOI 10.1007/978-981-13-0923-6_42
   Ural B, 2018, J MED BIOL ENG, V38, P867, DOI 10.1007/s40846-017-0353-y
NR 33
TC 27
Z9 27
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7393
EP 7417
DI 10.1007/s11042-021-11821-z
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300005
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
AF Sasikaladevi, N.
TI Robust and fast Plant Pathology Prognostics (P<SUP>3</SUP>) tool based
   on deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease detection; Deep convolutional neural network; Hypergraph
   neural network; Artificial intelligence
ID DISEASE; THREAT
AB Deep learning is emerging as an automatic and accurate model for image classification. Plant diseases are significant threats to food security. Rapid and accurate identification of plant pathology is difficult due to the lack of infrastructure and techniques. The recent advancements of deep learning in computer vision have paved a new horizon for plant pathology diagnosis. Early detection of plant pathology is a demanding task today. This paper proposes a deep convolutional neural network model for the accurate and rapid identification of plant disease. The deep convolutional neural network is designed based on Hypergraph modeling. The plant village dataset covers 38 different classes of 14 other plants. Experimental results show that the proposed model provides the maximum accuracy of 99.7%. Precision, recall, and F1 scores are computed to validate the model. Micro precision and Micro recall analysis are performed to validate the model at the micro-level. Furthermore, it is proved that the proposed model outperforms all the state-of-the-art deep learning models for plant disease detection based on images.
C1 [Sasikaladevi, N.] SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
EM sasikalade@gmail.com
OI , Sasikaladevi N/0000-0002-0841-502X
CR [Anonymous], 2013, SMALLH FOOD SEC ENV
   [Anonymous], 2012, INT C SYST INFORMAT
   Athanikar G., 2016, International Journal of Computer Science and Mobile Computing, V5, P76
   Deepa S, 2017, Int.J. Adv. Res. Comput. Sci., V8, P1503
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Ehler LE, 2006, PEST MANAG SCI, V62, P787, DOI 10.1002/ps.1247
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Guettari N, 2016, IEEE IMAGE PROC, P2742, DOI 10.1109/ICIP.2016.7532858
   Kipf TN, 2016, ARXIV
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ramezani M, 2010, CONSUM COMM NETWORK, P239
   Reyes A.K., 2015, CLEF
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Samanta D., 2012, International Journal of Computer Trends and Technology, V3, P109
   Sanchez PA, 2005, SCIENCE, V307, P357, DOI 10.1126/science.1109057
   Sheikhan M, 2012, NEURAL COMPUT APPL, V21, P1717, DOI 10.1007/s00521-011-0729-9
   Shi HY, 2019, IEEE T NEUR NET LEAR, V30, P2963, DOI 10.1109/TNNLS.2018.2869747
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839
   Tai APK, 2014, NAT CLIM CHANGE, V4, P817, DOI [10.1038/nclimate2317, 10.1038/NCLIMATE2317]
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
NR 24
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7271
EP 7283
DI 10.1007/s11042-022-11902-7
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700006
DA 2024-07-18
ER

PT J
AU Wang, Y
   Yu, ZX
   Long, HY
AF Wang Yang
   Yu Zhenxin
   Long Haiyan
TI Research on style transfer for multiple regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style transfer; Multiple regions; Semantic segmentation
AB The exciting method of creating unique visual experiences through composing a complex interplay between the content and style of an image has been extended to art works, creative design, video processing and other fields. Image style transfer technology is used to create images colorful styles automatically. Most of the existing researches focus on the style transfer of the whole image or a single region in the image, which is inevitably not adequate for practical applications. In this work, we introduce an approach of differential stylization for image different areas. Considering the human visual attention mechanism, the saliency regions in the training image data set are labeled, and the salient regions are trained in the semantic segmentation model. The structure of the neural style transfer model is simplified to improve the operation efficiency. In our approach, each local target region in the image is stylized evenly and carefully. Different regions are well integrated to achieve more realistic and pleasing effect, while more dominant operation efficiency is achieved. We separately perform experiments with the Cityscapes and the Microsoft COCO 2017 database. The performance is also compared with some reported methods and shown improved, while considering the accuracy and efficiency as performance metrics.
C1 [Wang Yang; Yu Zhenxin; Long Haiyan] Hebei Univ Technol, Coll Elect & Informat Engn, Tianjin Key Lab Elect Mat & Devices, Tianjin, Peoples R China.
C3 Hebei University of Technology
RP Wang, Y (corresponding author), Hebei Univ Technol, Coll Elect & Informat Engn, Tianjin Key Lab Elect Mat & Devices, Tianjin, Peoples R China.
EM please1615@sohu.com
FU Key Project of Hebei Provincial Department of Education [ZD2020304]
FX This work is supported by Key Project of Hebei Provincial Department of
   Education(ZD2020304).
CR Benedetti L., 2014, P UIST
   Castillo C, 2017, INT CONF ACOUST SPEE, P1348, DOI 10.1109/ICASSP.2017.7952376
   Champandard AJ, ARXIV160301768
   Changshen Zhao, 2020, Journal of Physics: Conference Series, V1453, DOI 10.1088/1742-6596/1453/1/012129
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen TC, 2017, AGEING SOC, V37, P1798, DOI 10.1017/S0144686X16000623
   Choi HC, 2020, IEEE ACCESS, V8, P196600, DOI 10.1109/ACCESS.2020.3034306
   Faridul HS, 2016, COMPUT GRAPH FORUM, V35, P59, DOI 10.1111/cgf.12671
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   HEEGER DJ, 1995, P 22 ANN C COMP GRAP, pC648
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hu C, 2020, P 7 INT FOR EL ENG A, P451
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jin ZG., 2021, J HEFEI U COMPREHENS, V38, P27
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Julesz B., 1962, IEEE T INFORM THEORY, V8, P84, DOI DOI 10.1109/TIT.1962.1057698
   Kalnins D, 2002, ACM T GRAPHIC, V21
   Kolliopoulos A., 2005, Image segmentation for stylized nonphotorealistic rendering and animation
   Li C, 2016, IEEE LATAMER CONF
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li SH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1716, DOI 10.1145/3123266.3123425
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Li YJ, 2017, ADV NEUR IN, V30
   Liu T, 2020, IEEE INT VEH SYM, P1394, DOI 10.1109/IV47402.2020.9304613
   Lu M, 2017, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2017.270
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lum EB, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P322, DOI 10.1109/PCCGA.2001.962888
   O'Donovan P., 2012, IEEE TVCG, V18
   Park JH, 2019, IMAGE VISION COMPUT, V87, P13, DOI 10.1016/j.imavis.2019.04.001
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Qiao YX, 2021, IEEE T IMAGE PROCESS, V30, P3154, DOI 10.1109/TIP.2021.3058566
   Risser E., 2017, ARXIV PREPRINT ARXIV
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Tongtong Wei, 2021, 2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP), P1011, DOI 10.1109/ICSP51882.2021.9408938
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov Dmitry, 2016, arXiv
   Wang WJ, 2020, IEEE T IMAGE PROCESS, V29, P9125, DOI 10.1109/TIP.2020.3024018
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xia XD, 2021, IEEE WINT CONF APPL, P1088, DOI 10.1109/WACV48630.2021.00113
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Ye HM, 2020, P IEEE 9 JOINT INT I, P410
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhao HH, 2020, VISUAL COMPUT, V36, P1307, DOI 10.1007/s00371-019-01726-2
NR 48
TC 1
Z9 1
U1 10
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7183
EP 7200
DI 10.1007/s11042-022-12121-w
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700008
DA 2024-07-18
ER

PT J
AU Kaur, R
AF Kaur, Ramanpreet
TI Hidden Markov Model for short term churn forecast in the structured
   overlay networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Churn; Hidden Markov Model; Stabilization; Maintenance; Availability
AB The inherent scalability and flexibility of structured overlay networks makes them an excellent choice to support modern day applications with complex, volatile, mobile, and heterogeneous infrastructure. However, this heterogeneity and volatility of the infrastructure increase the need for more reliable maintenance mechanisms to guarantee the availability and performance of structured overlay networks in the presence of autonomous participants. This paper focus on the implementation of the state-based predictive maintenance mechanism that is based on the intelligent prediction of the dynamics of the neighbouring node (k closest successors as defined in a DHT finger table) to schedule proactive maintenance of the nodes having periodic availabilities. The paper provides the predictive analysis of the uptime patterns of the machines specified in the Microsoft trace file using rapid miner and yielded 95% prediction accuracy. The proposed predictive framework is also tested in the simulation environments and the results show significant performance improvements by implementing the predictive maintenance approach as compared to the state-of-the-art statically scheduled maintenance actions. The simulation results report 54.23% increase in the average lookup success ratio and 59% reduction in the maintenance overhead of chord-based overlay network by the implementation of the proposed technique.
C1 [Kaur, Ramanpreet] Jozef Stefan Inst, Lab Open Syst & Networks, Ljubljana, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute
RP Kaur, R (corresponding author), Jozef Stefan Inst, Lab Open Syst & Networks, Ljubljana, Slovenia.
EM raman@e5.ijs.si
OI kaur, Ramanpreet/0000-0001-6053-3704
CR Alima LO, 2003, CCGRID 2003: 3RD IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P344, DOI 10.1109/CCGRID.2003.1199386
   [Anonymous], 2013, RAPIDMINER DATA MINI
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Bhagwan R, 2003, LECT NOTES COMPUT SC, V2735, P256
   Bolosky WJ, 2000, PERF E R SI, V28, P34, DOI 10.1145/345063.339345
   Chu J, 2002, P SOC PHOTO-OPT INS, V4868, P310, DOI 10.1117/12.475282
   Dotan M, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453161
   Douceur J. R., 2003, Performance Evaluation Review, V31, P25, DOI 10.1145/974036.974039
   Feldmann M, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3397190
   Foreback D, 2018, INT C NETW SYST, P303
   Ghinita G., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Ghodsi A, 2005, P IEEE 38 ANN HAW IN, p302a
   Guha S., 2006, Proceedings of The 5th International Workshop on Peer-to-Peer Systems (IPTPS'06), P1
   Guidi Barbara, 2018, Online Social Networks and Media, V7, P12, DOI 10.1016/j.osnem.2018.07.001
   Hassanzadeh-Nazarabadi Y, 2021, J PARALLEL DISTR COM, V149, P13, DOI 10.1016/j.jpdc.2020.10.008
   Hassanzadeh-Nazarabadi Y, 2020, IEEE T PARALL DISTR, V31, P1183, DOI 10.1109/TPDS.2019.2960018
   Javadi B, 2009, IEEE INT S MOD AN SI, P276
   Javadi B, 2013, J PARALLEL DISTR COM, V73, P1208, DOI 10.1016/j.jpdc.2013.04.002
   Kaur R., 2016, P 16 EUR C RAD EFF C, P1
   Kaur R, 2022, IETE TECH REV, V39, P179, DOI 10.1080/02564602.2020.1830001
   Kaur R, 2017, ENG SCI TECHNOL, V20, P310, DOI 10.1016/j.jestch.2016.06.015
   Khan MA, 2020, J NETW COMPUT APPL, V150, DOI 10.1016/j.jnca.2019.102499
   Koutsopoulos A, 2017, INFORM COMPUT, V255, P408, DOI 10.1016/j.ic.2016.12.006
   Liu H, 2019, DIGIT COMMUN NETW, V5, P69, DOI 10.1016/j.dcan.2018.03.005
   LONG D, 1995, 14TH SYMPOSIUM ON RELIABLE DISTRIBUTED SYSTEMS, PROCEEDINGS, P2, DOI 10.1109/RELDIS.1995.518718
   Luo LH, 2019, INT PARALL DISTRIB P, P845, DOI 10.1109/IPDPS.2019.00093
   Mickens JW, 2006, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD SYMPOSIUM ON NETWORKED SYSTEMS DESIGN & IMPLEMENTATION (NSDI 06), P73
   Miguel EC, 2021, MULTIMED TOOLS APPL, V80, P20255, DOI 10.1007/s11042-021-10604-w
   Nadir, 2018, INT J OPEN INF TECHN, V6, P504
   Pace A, 2011, SYM REL DIST SYST, P111, DOI 10.1109/SRDS.2011.22
   Pirozmand P, 2014, J NETW COMPUT APPL, V42, P45, DOI 10.1016/j.jnca.2014.03.007
   Porter B, 2006, SYM REL DIST SYST, P132
   Shukla N, 2021, PEER PEER NETW APPL, V14, P1242, DOI 10.1007/s12083-021-01112-7
   Song G, 2010, INT J ADV NETW SERV, V3, P237
   Song G, 2013, IEEE INT CONF PEER
   Steiner M, 2009, IEEE ACM T NETWORK, V17, P1371, DOI 10.1109/TNET.2008.2009053
   Stoica I, 2003, IEEE ACM T NETWORK, V11, P17, DOI 10.1109/TNET.2002.808407
   Tang YJ, 2019, IEEE T VEH TECHNOL, V68, P3967, DOI 10.1109/TVT.2019.2899627
   Vrignat P, 2015, IEEE T RELIAB, V64, P1038, DOI 10.1109/TR.2015.2423191
   Xie RJ, 2019, COMPUT NETW, V149, P127, DOI 10.1016/j.comnet.2018.11.002
NR 40
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34481
EP 34499
DI 10.1007/s11042-021-11831-x
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000744378900003
DA 2024-07-18
ER

PT J
AU Deshmukh, S
   Khaparde, A
AF Deshmukh, Sonal
   Khaparde, Arti
TI Multi-objective segmentation approach for bone age assessment using
   parameter tuning-based U-net architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone age assessment; Multi-objective segmentation; Optimized U-net
   architecture; Whale-based class topper optimization; Deep convolutional
   neural network
ID GREULICH; CHILDREN; PYLE; PREDICTION; INFANTS; TANNER
AB Bone age assessment investigates the ossification improvement for estimating the skeletal age of the pediatrics for analyzing their skeletal growth and forecast their future adult height. The main intent of this paper is to contribute a novel deep learning-based bone segmentation for bone age assessment. Here, the datasets are gathered from both the manual as well as the RSNA database. The segmentation of 5 regions "Distal Phalanx of thumb, middle phalanx, third metacarpal, radius, and ulna" is performed by the optimized U-Net model. As an improvement in the existing U-Net architecture, tuning of the activation function is adopted by the hybridization of two meta-heuristic algorithms such as Class Topper Optimization (CTO) and Whale Optimization Algorithm (WOA) termed as Whale-based Class Topper Optimization (W-CTO). This improved model is developed with the intention of solving the multi-objective segmentation that concerns the parameters like entropy and variance. Moreover, the effect of the proposed segmentation is analyzed by estimating the bone age with the deep Convolutional Neural Network (Deep CNN). From the analysis, the overall MASE of W-CTO-U-Net+CNN is 14.66%, 22.06%, and 5.53% higher than RNN, CNN, and NN, respectively, and RMSE of W-CTO-U-Net+CNN is 53.28%, 22.02%, and 32.87% better than RNN, CNN, and NN, respectively.. The performance comparison of the proposed segmentation model over the conventional approaches confirms its effective performance with relatively high accuracy.
C1 [Deshmukh, Sonal] Maharashtra Inst Technol, Dept Elect & Telecommun, Pune, Maharashtra, India.
   [Khaparde, Arti] Dr Vishwanath Karadmit World Peace Univ, Sch Elect & Commun Engn, Pune, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University; Dr. Vishwanath Karad
   MIT World Peace University
RP Deshmukh, S (corresponding author), Maharashtra Inst Technol, Dept Elect & Telecommun, Pune, Maharashtra, India.
EM sonaldeshmukh848@gmail.com
RI khaparde, arti/O-5305-2016; Khaparde, Arti/AAY-8397-2021
OI khaparde, arti/0000-0001-8724-1525; 
CR Alshamrani K, 2020, CLIN RADIOL, V75, DOI 10.1016/j.crad.2019.08.029
   Baliarsingh SK, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107009
   Baliarsingh SK, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105625
   Baliarsingh SK, 2020, IET SYST BIOL, V14, P85, DOI 10.1049/iet-syb.2019.0028
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Berst MJ, 2001, AM J ROENTGENOL, V176, P507, DOI 10.2214/ajr.176.2.1760507
   Birhade P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Breen MA, 2016, PEDIATR RADIOL, V46, P1269, DOI 10.1007/s00247-016-3618-7
   Bull RK, 1999, ARCH DIS CHILD, V81, P172, DOI 10.1136/adc.81.2.172
   Chai HY., 2011, INT J MATH MODELS ME, V5, P628
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chaumoître K, 2006, J RADIOL, V87, P1679, DOI 10.1016/S0221-0363(06)74146-4
   Chen Y, 2017, NEUROCOMPUTING, V219, P26, DOI 10.1016/j.neucom.2016.09.015
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Christoforidis A, 2007, PEDIATR RADIOL, V37, P1241, DOI 10.1007/s00247-007-0656-1
   Daneff M, 2015, PEDIATR RADIOL, V45, P1007, DOI 10.1007/s00247-014-3253-0
   Das P, 2020, IEEE T EMERG TOP COM, V8, P948, DOI 10.1109/TETC.2018.2812927
   Dwivedi S, 2020, COMPUT NETW, V176, DOI 10.1016/j.comnet.2020.107251
   Gertych A, 2007, COMPUT MED IMAG GRAP, V31, P322, DOI 10.1016/j.compmedimag.2007.02.012
   Giordano D, 2016, COMPUT METH PROG BIO, V124, P138, DOI 10.1016/j.cmpb.2015.10.012
   Gomes GF, 2019, ENG COMPUT-GERMANY, V35, P619, DOI 10.1007/s00366-018-0620-8
   Gonzalez Cristina, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P753, DOI 10.1007/978-3-030-59725-2_73
   Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Harmsen M, 2013, IEEE J BIOMED HEALTH, V17, P190, DOI 10.1109/TITB.2012.2228211
   Hayyolalam V, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103249
   Hsieh CW, 2010, MED BIOL ENG COMPUT, V48, P579, DOI 10.1007/s11517-010-0609-y
   Hu B, 2020, J PHYS C SERIES, V1646
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   KING DG, 1994, BRIT J RADIOL, V67, P848, DOI 10.1259/0007-1285-67-801-848
   Liang BY, 2019, FUTURE GENER COMP SY, V98, P54, DOI 10.1016/j.future.2019.01.057
   Liu B, 2019, IEEE ACCESS, V7, P120976, DOI 10.1109/ACCESS.2019.2937341
   Liu J, 2008, COMPUT MED IMAG GRAP, V32, P678, DOI 10.1016/j.compmedimag.2008.08.005
   Merzban MH, 2019, EXPERT SYST APPL, V116, P299, DOI 10.1016/j.eswa.2018.09.008
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Ontell FK, 1996, AM J ROENTGENOL, V167, P1395, DOI 10.2214/ajr.167.6.8956565
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Pietka E, 2003, COMPUT MED IMAG GRAP, V27, P217, DOI 10.1016/S0895-6111(02)00076-9
   Pietka E, 2001, IEEE T MED IMAGING, V20, P715, DOI 10.1109/42.938240
   Ren XH, 2019, IEEE J BIOMED HEALTH, V23, P2030, DOI 10.1109/JBHI.2018.2876916
   Ronneberger O., 2015, P INT C MED IM COMP, P234, DOI 10.1007/978-3-319-24574-4_28
   Son SJ, 2019, IEEE ACCESS, V7, P33346, DOI 10.1109/ACCESS.2019.2903131
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   Bui TD, 2019, ARTIF INTELL MED, V97, P1, DOI 10.1016/j.artmed.2019.04.005
   Tong C, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1091-6
   Varma R. K., 2016, IEEE Power Energy Technol. Syst. J., V3, P155, DOI DOI 10.1109/JPETS.2016.2592465
   Zarie M, 2020, MINER ENG, V155, DOI 10.1016/j.mineng.2020.106443
NR 53
TC 6
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6755
EP 6800
DI 10.1007/s11042-021-11793-0
EA JAN 2022
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743863400003
DA 2024-07-18
ER

PT J
AU Ayas, S
   Ayas, MS
AF Ayas, Selen
   Ayas, Mustafa Sinasi
TI A novel bearing fault diagnosis method using deep residual learning
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; CWRU bearing dataset; Deep residual
   network; Fault diagnosis; Motor bearing
ID NEURAL-NETWORK
AB Bearing fault diagnosis is a serious problem on which researchers have focused to ensure the reliability and availability of rotating machinery. Knowledge-based methods are capable of providing promising solution to bearing diagnosis problem with high accuracy performance thanks to effectively processing collected sensor and actuator data. Deep learning (DL) has the advantage of ignoring feature extraction and providing accurate diagnosis among the machine learning algorithms. In order to address this issue, in this paper, a novel DL based model is presented for fault detection and classification of motor bearing. In this work, first, time domain signals are converted to images by a proposed signal-toimage conversion approach. Then, the converted gray-scale images are fed into a novel deep residual learning (DRL) network structured to learn end-to-end mapping between images and health condition of the motor bearing. The performance of the proposed DRL network is evaluated on a commonly used real vibration dataset provided by Case Western Reserve University (CWRU). Experimental results obtained for 10 different health condition demonstrate encouraging and outperforming performance with an average accuracy of 99.98% compared to the state-of-art knowledge-based bearing fault diagnosis methods.
C1 [Ayas, Selen] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
   [Ayas, Mustafa Sinasi] Karadeniz Tech Univ, Dept Elect & Elect Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University; Karadeniz Technical University
RP Ayas, S (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM selenguven@ktu.edu.tr
RI Ayas, Mustafa Sinasi/AAG-5553-2019; Ayas, Selen/AAJ-8030-2021
OI Ayas, Mustafa Sinasi/0000-0001-8113-4817; Ayas,
   Selen/0000-0002-8226-2359
CR Baraldi P, 2016, ENG APPL ARTIF INTEL, V56, P1, DOI 10.1016/j.engappai.2016.08.011
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bjorck J, 2018, ADV NEUR IN, V31
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Chen ZY, 2020, MECH SYST SIGNAL PR, V140, DOI 10.1016/j.ymssp.2020.106683
   Cho HC, 2010, IEEE T CONTR SYST T, V18, P430, DOI 10.1109/TCST.2009.2020863
   Dhamande LS., 2016, INT J VEH STRUCT SYS, V8, P229, DOI DOI 10.4273/IJVSS.8.4.09
   Ding XX, 2017, IEEE T INSTRUM MEAS, V66, P1926, DOI 10.1109/TIM.2017.2674738
   Eren L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/8617315
   Gan M, 2016, MECH SYST SIGNAL PR, V72-73, P92, DOI 10.1016/j.ymssp.2015.11.014
   Gao ZW, 2015, IEEE T IND ELECTRON, V62, P3768, DOI [10.1109/TIE.2015.2419013, 10.1109/TIE.2015.2417501]
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo L, 2019, IEEE T IND ELECTRON, V66, P7316, DOI 10.1109/TIE.2018.2877090
   Guo L, 2017, NEUROCOMPUTING, V240, P98, DOI 10.1016/j.neucom.2017.02.045
   Guo XJ, 2016, MEASUREMENT, V93, P490, DOI 10.1016/j.measurement.2016.07.054
   Han T, 2016, SHOCK VIB, V2016, DOI 10.1155/2016/5957179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XH, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2957083
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Janssens O, 2016, J SOUND VIB, V377, P331, DOI 10.1016/j.jsv.2016.05.027
   Jia F, 2018, NEUROCOMPUTING, V272, P619, DOI 10.1016/j.neucom.2017.07.032
   Kang M, 2015, INFORM SCIENCES, V294, P423, DOI 10.1016/j.ins.2014.10.014
   Khorram A, 2021, APPL INTELL, V51, P736, DOI 10.1007/s10489-020-01859-1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei YG, 2016, IEEE T IND ELECTRON, V63, P3137, DOI 10.1109/TIE.2016.2519325
   Liu ZH, 2021, IEEE T SYST MAN CY-S, V51, P4217, DOI 10.1109/TSMC.2019.2932000
   Loparo K., 2012, Case western reserve university bearing data center
   Pons-Llinares J, 2015, IEEE T IND ELECTRON, V62, P1791, DOI 10.1109/TIE.2014.2355816
   Ripley BD, 1996, PATTERN RECOGNITION
   Shao HD, 2015, MEAS SCI TECHNOL, V26, DOI 10.1088/0957-0233/26/11/115002
   Soualhi A, 2015, IEEE T INSTRUM MEAS, V64, P52, DOI 10.1109/TIM.2014.2330494
   Venables W.N., 2013, MODERN APPL STAT S P, DOI DOI 10.1007/978-0-387-21706-2
   Wang ZW, 2017, IEEE SENS J, V17, P5581, DOI 10.1109/JSEN.2017.2726011
   Wen L, 2019, IEEE T SYST MAN CY-S, V49, P136, DOI 10.1109/TSMC.2017.2754287
   Wen L, 2018, IEEE T IND ELECTRON, V65, P5990, DOI 10.1109/TIE.2017.2774777
   Xia M, 2018, IEEE-ASME T MECH, V23, P101, DOI 10.1109/TMECH.2017.2728371
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yan XA, 2018, ISA T, V73, P165, DOI 10.1016/j.isatra.2018.01.004
   Zhang XY, 2015, MEASUREMENT, V69, P164, DOI 10.1016/j.measurement.2015.03.017
NR 39
TC 18
Z9 20
U1 17
U2 119
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22407
EP 22423
DI 10.1007/s11042-021-11617-1
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000740429700002
DA 2024-07-18
ER

PT J
AU Preiss, J
AF Preiss, Judita
TI Predicting the impact of online news articles - is information
   necessary? Application to COVID-19 articles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Popularity prediction; Grammatical relations; SemRep relations
ID FORMULA; SYSTEM; SMOTE
AB We exploit the Twitter platform to create a dataset of news articles derived from tweets concerning COVID-19, and use the associated tweets to define a number of popularity measures. The focus on (potentially) biomedical news articles allows the quantity of biomedically valid information (as extracted by biomedical relation extraction) to be included in the list of explored features. Aside from forming part of a systematic correlation exploration, the features - ranging from the semantic relations through readability measures to the article's digital content - are used within a number of machine learning classifier and regression algorithms. Unsurprisingly, the results support that for more complex articles (as determined by a readability measure) more sophisticated syntactic structure may be expected. A weak correlation is found with information within an article suggesting that other factors, such as numbers of videos, have a notable impact on the popularity of a news article. The best popularity prediction performance is obtained using a random forest machine learning algorithm, and the feature describing the quantity of biomedical information is in the top 3 most important features in almost a third of the experiments performed. Additionally, this feature is found to be more valuable than the widely used named entity recognition.
C1 [Preiss, Judita] Univ Salford, Sch Sci Engn & Environm, Salford M5 4WT, Lancs, England.
C3 University of Salford
RP Preiss, J (corresponding author), Univ Salford, Sch Sci Engn & Environm, Salford M5 4WT, Lancs, England.
EM j.preiss@salford.ac.uk
FU Greater Manchester AI Foundry project
FX The work was partly supported by the Greater Manchester AI Foundry
   project.
CR Acuna DE, 2012, NATURE, V489, P201, DOI 10.1038/489201a
   Alizadeh M, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abb5824
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2018, Bots in the Twittersphere
   Antenore M, 2021, ARXIV210201148
   Banda JM, 2021, EPIDEMIOLOGIA-BASEL, V2, P315, DOI 10.3390/epidemiologia2030024
   Bandari R., 2012, ICWSM, P26
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   BOUKES M, 2020, J THEORY PRACT CRIT
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Choudhary S, 2017, ADV INTELL SYST, V556, P133, DOI 10.1007/978-981-10-3874-7_13
   COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dale E, 1948, EDUC RES BULL, V27, P11
   De Marneffe M.-C., 2006, LREC, V6, P449
   Dunning T., 1994, MCCS94273 CRL NEW ME
   Fazel S, 2017, EVID-BASED MENT HEAL, V20, P33, DOI 10.1136/eb-2017-102668
   Fernandes K, 2015, LECT NOTES ARTIF INT, V9273, P535, DOI 10.1007/978-3-319-23485-4_53
   Ferrara E., 2020, First Monday, V25, DOI [10.5210/FM.V25I6.10633, https://doi.org/10.5210/fm.v25i6.10633, DOI 10.5210/FM.V25I6.10633]
   Finkel J. R., 2005, P 43 ANN M ASS COMPU, P363
   Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Gabielkov M, 2016, SIGMETRICS/PERFORMANCE 2016: PROCEEDINGS OF THE SIGMETRICS/PERFORMANCE JOINT INTERNATIONAL CONFERENCE ON MEASUREMENT AND MODELING OF COMPUTER SCIENCE, P179, DOI [10.1145/2896377.2901462, 10.1145/2964791.2901462]
   Gui Yaocheng, 2012, INT C ADV DAT MIN AP, P318
   Gunning R, 1952, TECHNIQUE CLEAR WRIT
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Haykin S, 1998, Neural Networks: A Comprehensive Foundation
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Hensinger E, 2013, PATTERN ANAL APPL, V16, P623, DOI 10.1007/s10044-012-0314-6
   Himelein-Wachowiak M, 2021, J MED INTERNET RES, V23, DOI 10.2196/26933
   Hu Y, 2015, ICWSM
   Keller TR, 2019, POLIT COMMUN, V36, P171, DOI 10.1080/10584609.2018.1526238
   Keneshloo Y., 2016, P 2016 SIAM INT C DA, P441, DOI DOI 10.1137/1.9781611974348.50
   Lehmann J., 2013, 7 INT AAAI C WEBL SO, V7, P351
   Liu CY, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P9, DOI 10.1109/CIT.2017.36
   MCLAUGHLIN GH, 1969, J READING, V12, P639
   Nguyen Hien M., 2011, International Journal of Knowledge Engineering and Soft Data Paradigms, V3, P4, DOI 10.1504/IJKESDP.2011.039875
   Obiedat, 2020, J THEORETICAL APPL I, V98, P1163
   OHayre J., 1966, Gobbledygook Has Gotta Go
   Orellana-Rodriguez C, 2018, COMPUT SCI REV, V29, P74, DOI 10.1016/j.cosrev.2018.07.001
   Petrovic S., 2011, P 5 INT AAAI C WEBL, P586
   Preiss J, 2015, J AM MED INFORM ASSN, V22, P987, DOI 10.1093/jamia/ocv002
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Ren H., 2015, PREDICTING EVALUATIN
   Rindflesch TC, 2003, J BIOMED INFORM, V36, P462, DOI 10.1016/j.jbi.2003.11.003
   Sayyadiharikandeh M, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2725, DOI 10.1145/3340531.3412698
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Smith E A, 1967, AMRL TR, P1
   Tatar A, 2014, J INTERNET SERV APPL, V5, DOI 10.1186/s13174-014-0008-y
NR 51
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8791
EP 8809
DI 10.1007/s11042-021-11621-5
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000740429700019
PM 35035262
OA hybrid, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Gupta, V
   Jain, N
   Garg, H
   Jhunthra, S
   Mohan, S
   Omar, AH
   Ahmadian, A
AF Gupta, Vedika
   Jain, Nikita
   Garg, Harshit
   Jhunthra, Srishti
   Mohan, Senthilkumar
   Omar, Abdullah Hisam
   Ahmadian, Ali
TI Predicting attributes based movie success through ensemble machine
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boosting ensemble technique; IMDb; KNN; Machine learning; Movie success
   prediction; MLP-NN; Naive bayes; SVM; Voting ensemble technique
AB The film industry has grown into a multi-billionaire industry in terms of entertainment. The success of the film industry depends on the criteria that how much profit a movie would make which gives the tag of a 'hit' or a 'flop'. Predicting the success is guided by various factors like genre, date of release, actors, net gross and many more. Understanding the stakes involved with a movie release that can affect its success or a failure, before-hand can be a great step towards the expansion of the film industry business. Therefore, this study proposes an ensemble learning strategy as a solution to analyze such understanding where predictions from previously guided attribute calculations can be used to enhance future success/failure accuracy. This study shows various strategies used in the literature to analyze and compare the results obtained. The various machines learning algorithms SVM, KNN, Naive Bayes, Boosting Ensemble Technique, Stacking Ensemble Technique, Voting Ensemble Technique, and MLP Neural Network are applied on the dataset to predict the box office success of a movie. The paper uses various algorithms and their trends in predicting the outcome of a movie and shows that the proposed methodology outperforms the existing studies. The most effective algorithm in the study is Gradient Boosting with a success rate of 84.1297%.
C1 [Gupta, Vedika; Jain, Nikita; Garg, Harshit; Jhunthra, Srishti] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi, India.
   [Mohan, Senthilkumar] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Omar, Abdullah Hisam] Univ Teknol Malaysia, Fac Built Environm & Surveying, Skudai 81310, Johor Bahru, Malaysia.
   [Ahmadian, Ali] Natl Univ Malaysia, Inst IR 4 0, UKM, Bangi 43600, Selangor, Malaysia.
   [Ahmadian, Ali] Near East Univ, Dept Math, TRNC, TR-10 Mersin, Turkey.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Universiti Teknologi
   Malaysia; Universiti Kebangsaan Malaysia; Near East University
RP Ahmadian, A (corresponding author), Natl Univ Malaysia, Inst IR 4 0, UKM, Bangi 43600, Selangor, Malaysia.; Ahmadian, A (corresponding author), Near East Univ, Dept Math, TRNC, TR-10 Mersin, Turkey.
EM ali.ahmadian@ukm.edu.my
RI Gupta, Vedika/JXL-2328-2024; Gupta, Vedika/JNR-1706-2023; ,
   m.senthilkumar/L-5551-2015; Ahmadian, Ali/N-3697-2015
OI , m.senthilkumar/0000-0002-8114-3147; Ahmadian, Ali/0000-0002-0106-7050
CR Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Bhave A, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Das AK, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110713
   Dhir R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P385, DOI 10.1109/ICSCCC.2018.8703320
   Doshi L, 2010, PROCD SOC BEHV, V2, P6423, DOI 10.1016/j.sbspro.2010.04.052
   García-Laencina PJ, 2009, NEUROCOMPUTING, V72, P1483, DOI 10.1016/j.neucom.2008.11.026
   Jain N, 2022, NEURAL COMPUT APPL, V34, P21481, DOI 10.1007/s00521-021-06003-9
   Jain N, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2021.103813
   Jain Vasu, 2013, International Journal of Soft Computing and Software Engineering, V3, P308, DOI 10.7321/jscse.v3.n3.46
   JernBacker C., 2017, Predicting Movie Success Using Machine Learning Techniques
   Kanitkar A, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CIRCUITS, CONTROL, COMMUNICATION AND COMPUTING (I4C)
   Kumar V, 2021, EVOL INTELL, V14, P47, DOI 10.1007/s12065-019-00291-w
   Lash MT, 2016, J MANAGE INFORM SYST, V33, P874, DOI 10.1080/07421222.2016.1243969
   Latif MH, 2016, INT J COMPUT SCI NET, V16, P127
   Liu H, 2015, ENERG CONVERS MANAGE, V92, P67, DOI 10.1016/j.enconman.2014.12.053
   Modi A, 2020, ADV COMPUTING TECHNO, P633
   Nithin V., 2014, International Journal of Data Mining Techniques and Applications, V3, P365
   Peters J, 2017, ADAPT COMPUT MACH LE
   Piryani R, 2017, ADV COMPUTER COMPUTA, P201
   Piryani R, 2017, J INTELL FUZZY SYST, V32, P3297, DOI 10.3233/JIFS-169272
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7_1
   Pradeep K., 2020, 2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC), P853
   Quader N, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Tzanos G, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST), DOI 10.1109/mocast.2019.8741875
   Verma H, 2020, REV SOCIONETWORK STR, V14, P1, DOI 10.1007/s12626-019-00040-6
   Xu Q, 2017, J THEOR BIOL, V417, P1, DOI 10.1016/j.jtbi.2017.01.019
   Zare M, 2013, LANDSLIDE SUSCEPTIBI
   Zare M, 2013, ARAB J GEOSCI, V6, P2873, DOI 10.1007/s12517-012-0610-x
   Zhang WB, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P301
   Zheng A., 2018, Feature Engineering for Machine Learning
NR 32
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9597
EP 9626
DI 10.1007/s11042-021-11553-0
EA JAN 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000739790800012
DA 2024-07-18
ER

PT J
AU Ray, S
   Parai, S
   Das, A
   Dhal, KG
   Naskar, PK
AF Ray, Swarnajit
   Parai, Santanu
   Das, Arunita
   Dhal, Krishna Gopal
   Naskar, Prabir Kumar
TI Cuckoo search with differential evolution mutation and Masi entropy for
   multi-level image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Masi entropy; Swarm intelligence; Cuckoo search;
   Differential evolution; Mutation strategies
ID OPTIMIZATION; ALGORITHM; HISTOGRAM
AB Since the beginning of the twenty-first century, the Cuckoo Search (CS) algorithm has emerged as one of the robust, flexible, fast, and easily implementable techniques for the global search to solve many complex problems over continuous spaces. CS operates like other Nature-Inspired Algorithms (NIOA) whose effectiveness significantly depends on the exploration and exploitation phases. CS already proofs its efficiency in solving real-world optimization problems in various application domains. In this study, the author tries to enhance the efficiency of the CS by incorporating six different mutation strategies of Differential Evolution (DE). The performance of the proposed CS variants has been investigated over Multi-level thresholding based image segmentation field as it is considered one of the dominant image segmentation techniques of the recent era. It is known that computation of the optimal set of thresholds is significantly influenced by the considered objective function, and it can be trapped into local optima. On the other hand, the computational time of Multi-level thresholding increases exponentially when the number of threshold points increases. To overcome these problems, this study introduces CS variants over this segmentation field, where Masi entropy is maximized to find the optimal threshold points. The experiment has been conducted on various color pathology images. The results of such a comparative study provide valuable insight and information to develop efficient CS variants using optimal or adaptive mutation strategies of DE.
C1 [Ray, Swarnajit] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
   [Parai, Santanu; Das, Arunita; Dhal, Krishna Gopal] Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
   [Naskar, Prabir Kumar] Govt Coll Engn & Text Technol, Dept Comp Sci & Engn, Serampore, W Bengal, India.
C3 Maulana Abul Kalam Azad University of Technology; Midnapore College
RP Dhal, KG (corresponding author), Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
EM swarnajit.ray@learningmate.com; paraisantanu@gmail.com;
   arunita17@gmail.com; krishnagopal.dhal@midnaporecollege.ac.in;
   cse.prabir@gmail.com
RI Dhal, Krishna Gopal/JCD-8250-2023
OI NASKAR, PRABIR KUMAR/0000-0002-7456-7566; dhal, krishna
   gopal/0000-0002-6748-0569
CR Abd ElAziz M, 2016, HYBRID SOFT COMPUTIN, P1, DOI DOI 10.1007/978-3-319-47223-2_1
   Acharya V, 2019, MED BIOL ENG COMPUT, V57, P1783, DOI 10.1007/s11517-019-01984-1
   Aja-Fernández S, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4053
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2019, INFRARED PHYS TECHN, V98, P132, DOI 10.1016/j.infrared.2019.03.010
   Chi R, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/7051248
   Chi R, 2019, NEURAL COMPUT APPL, V31, P653, DOI 10.1007/s00521-017-3012-x
   Dhal Krishna Gopal, 2017, Pattern Recognition and Image Analysis, V27, P695, DOI 10.1134/S1054661817040046
   Dhal K. G., 2018, Critical Developments and Applications of Swarm Intelligence, P339, DOI [10.4018/978-1-5225-5134-8.ch013, DOI 10.4018/978-1-5225-5134-8.CH013]
   Dhal KG, 2021, EVOL SYST-GER, V12, P779, DOI 10.1007/s12530-019-09318-0
   Dhal KG, 2020, MULTIMED TOOLS APPL, V79, P12227, DOI 10.1007/s11042-019-08417-z
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Dhal KG, 2020, NEURAL COMPUT APPL, V32, P3059, DOI 10.1007/s00521-019-04585-z
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, PATTERN RECOGN IMAGE, V29, P344, DOI 10.1134/S1054661819030052
   Dhal KG, 2019, J INDIAN SOC REMOTE, V47, P1391, DOI 10.1007/s12524-019-01005-6
   Dhal KG, 2019, IJST-T ELECTR ENG, V43, P645, DOI 10.1007/s40998-019-00175-w
   Dhal KG, 2017, INT J SWARM INTELL R, V8, P1, DOI 10.4018/IJSIR.2017010101
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Jia HM, 2019, IEEE ACCESS, V7, P134448, DOI 10.1109/ACCESS.2019.2942064
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080942
   Kandhway P, 2019, CIRC SYST SIGNAL PR, V38, P3058, DOI 10.1007/s00034-018-0993-3
   Khobragade S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P435, DOI 10.1109/INFOP.2015.7489422
   Labati RD, 2011, IEEE IMAGE PROC
   Leblebici SY, 2016, NAT ENERGY, V1, DOI [10.1038/nenergy.2016.93, 10.1038/NENERGY.2016.93]
   Leon M, 2014, LECT NOTES ARTIF INT, V8467, P372, DOI 10.1007/978-3-319-07173-2_32
   Lin H, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19103181
   Mareli M., 2018, Applied Computing and Informatics, V14, P107, DOI 10.1016/j.aci.2017.09.001
   Mousavirad SJ, 2017, EVOL INTELL, V10, P45, DOI 10.1007/s12065-017-0152-y
   Opara K, 2018, SWARM EVOL COMPUT, V39, P53, DOI 10.1016/j.swevo.2017.12.007
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Price K.V, 1999, New Ideas in Optimization, P79
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Suresh S, 2017, APPL SOFT COMPUT, V55, P503, DOI 10.1016/j.asoc.2017.02.005
   Tuba E, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P240, DOI 10.1109/EMES.2017.7980424
   Wahid F, 2019, ARAB J SCI ENG, V44, P4027, DOI 10.1007/s13369-019-03759-0
   Wang GG, 2018, OPER RES-GER, V18, P731, DOI 10.1007/s12351-016-0251-z
   Wei JM, 2018, IEEE ACCESS, V6, P6560, DOI 10.1109/ACCESS.2017.2738006
   Wu B, 2011, J COMPUT, V6, P841, DOI 10.4304/jcp.6.5.841-848
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
NR 48
TC 10
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4073
EP 4117
DI 10.1007/s11042-021-11633-1
EA NOV 2021
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000723529100003
DA 2024-07-18
ER

PT J
AU Jain, M
   Suvarna, A
   Jain, A
AF Jain, Minni
   Suvarna, Ashima
   Jain, Amita
TI An evolutionary game theory based approach for query expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Ambiguous terms; Evolutionary game theory; Query
   expansion; WordNet; BabelNet
ID RETRIEVAL; RELEVANCE; WORDNET; LOGIC
AB In Information Retrieval (IR) Systems, an essential technique employed to improve accuracy and efficiency is Query Expansion (QE). QE is the technique that reformulates the original query by adding the relevant terms that aid the retrieval process in generating more relevant outcomes. Numerous methods have been proposed in the literature that generates desirable results, however they do not provide evenly favourable results for all types of queries. One of the primary reasons for this is their inability to capture holistic relationships among the query terms. To tackle this issue, we have proposed a novel technique for QE that leverages a game-theoretic framework to recommend contextually relevant expansion terms for each query. In our approach, the query terms are interpreted as players that play a game with the other terms in the query in order to maximize their payoffs; the payoffs are determined using similarity measures between two query terms in the game. Our framework also works best for disambiguating polysemous query terms. The experimental section presents an analysis of the combination of various similarity and association measures employed in the proposed framework and a comparative analysis against state-of-art approaches. In addition to this, we present our analysis over three datasets, namely AP89, INEX and CLUEWEB in combination with WordNet and BabelNet as knowledge bases. The results show that the proposed work outperforms state-of-art algorithms.
C1 [Jain, Minni; Suvarna, Ashima] Delhi Technol Univ, NCT Delhi, Dept Comp Engn, New Delhi, India.
   [Jain, Amita] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, East Campus, New Delhi, India.
C3 Delhi Technological University; Netaji Subhas University of Technology
RP Jain, A (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, East Campus, New Delhi, India.
EM minnijain@dtu.ac.in; asuvarna31@gmail.com; amita.jain@nsut.ac.in
RI Jain, Minni/HCI-6045-2022
CR Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   [Anonymous], 2008, P 31 ANN INT ACM SIG, DOI DOI 10.1145/1390334.1390420
   Araujo, 2008, EVOLUTIONARY ALGORIT
   Arora Piyush, 2017, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 8th International Conference of the CLEF Association, CLEF 2017. Proceedings: LNCS 10456, P97, DOI 10.1007/978-3-319-65813-1_8
   Azad HK, 2019, INFORM SCIENCES, V492, P147, DOI 10.1016/j.ins.2019.04.019
   Bhogal J, 2007, INFORM PROCESS MANAG, V43, P866, DOI 10.1016/j.ipm.2006.09.003
   Bodner R. C., 1996, Advances in Artificial Intelligence. 11th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI'96. Proceedings, P146
   Buckley C., 1995, AUTOMATIC QUERY EXPA, P69
   Buyse K, 2011, STUD CORPUS LINGUIST, V47, P191
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Colace F, 2015, INFORM PROCESS MANAG, V51, P179, DOI 10.1016/j.ipm.2014.07.004
   Collins-Thompson Kevyn., 2005, PROC 14 INT C INFORM, P704
   Dhungana UR, 2015, IEEE INT C SEMANT CO, P148, DOI 10.1109/ICOSC.2015.7050794
   Durao F, 2014, MULTIMED TOOLS APPL, V71, P905, DOI 10.1007/s11042-012-1316-5
   Erdem A, 2012, NEURAL COMPUT, V24, P700, DOI 10.1162/NECO_a_00233
   GALE WA, 1992, SPEECH AND NATURAL LANGUAGE, P233
   Grootjen FA, 2006, DATA KNOWL ENG, V56, P174, DOI 10.1016/j.datak.2005.03.006
   Jeon Wook Kang, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P172, DOI 10.1109/AICI.2010.159
   Jiang J, 1997, INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, 1997 DIGEST OF TECHNICAL PAPERS, P94
   Laorden C, 2013, ADV INTELL SYST, V189, P261
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Lu ML, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P545, DOI 10.1109/SANER.2015.7081874
   Lv YH, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P579
   Manning C, 2009, EVALUATION INFORMATI
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Nasir JA, 2019, INFORM PROCESS MANAG, V56, P1605, DOI 10.1016/j.ipm.2019.04.007
   Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P216
   Neumann J. V, 1966, THEORY GAMES EC BEHA
   Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Raifer N, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P465, DOI 10.1145/3077136.3080785
   Robertson S. E., 1996, Fourth Text REtrieval Conference (TREC-4) (NIST SP 500-236), P73
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Roy Dwaipayan, 2016, arXiv
   Saxena A., 2020, P 28 INT C COMPUTATI, P2037
   Sharma DK, 2022, MULTIMED TOOLS APPL, V81, P35195, DOI 10.1007/s11042-020-09172-2
   Singh J, 2018, SWARM EVOL COMPUT, V38, P295, DOI 10.1016/j.swevo.2017.09.007
   Singh J, 2017, NEURAL COMPUT APPL, V28, P2557, DOI 10.1007/s00521-016-2207-x
   SMITH JM, 1973, NATURE, V246, P15, DOI 10.1038/246015a0
   Soldaini L, 2016, INFORM RETRIEVAL J, V19, P149, DOI 10.1007/s10791-015-9258-y
   Song RH, 2009, INFORM PROCESS MANAG, V45, P216, DOI 10.1016/j.ipm.2008.09.005
   Szabó G, 2007, PHYS REP, V446, P97, DOI 10.1016/j.physrep.2007.04.004
   TAYLOR PD, 1978, MATH BIOSCI, V40, P145, DOI 10.1016/0025-5564(78)90077-9
   Tripodi R, 2017, COMPUT LINGUIST, V43, P31, DOI 10.1162/COLI_a_00274
   Vechtomova O., 2009, Encyclopedia of database systems, P2254, DOI [10.1007/978-0-387-39940-9_947, DOI 10.1007/978-0-387-39940-9_947]
   Voorhees E. M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P61
   Wasim M, 2019, MULTIMED TOOLS APPL, V78, P29681, DOI 10.1007/s11042-018-6060-z
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Zhai CX, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P543, DOI 10.1145/2766462.2767853
   Zhao X, 2017, MULTIMED TOOLS APPL, V76, P12133, DOI 10.1007/s11042-016-4142-3
   Zhi Z, 2012, Long Papers, V1, P273
NR 54
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1971
EP 1995
DI 10.1007/s11042-021-11297-x
EA OCT 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000708822400004
DA 2024-07-18
ER

PT J
AU Hassan, MA
   Khan, MUG
   Iqbal, R
   Riaz, O
   Bashir, AK
   Tariq, U
AF Hassan, Muhammad Ahmed
   Khan, Muhammad Usman Ghani
   Iqbal, Razi
   Riaz, Omer
   Bashir, Ali Kashif
   Tariq, Usman
TI Predicting humans future motion trajectories in video streams using
   generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GAN; Future motion trajectories; LSTM; Object detection; Human
   re-identification; Path planning
ID ACTIVITY RECOGNITION; TRANSFORM
AB Understanding the behavior of human motion in social environments is important for various domains of a smart city, e.g, smart transportation, automatic navigation of service robots, efficient navigation of autonomous cars and surveillance systems. Examining past trajectories or environmental factors alone are not enough to address this problem. We propose a novel methodology to predict future motion trajectories of humans based on past attitude of individuals, crowd attitude and environmental context. Many researchers have proposed different techniques based on different features extraction and features fusion to predict the future motion trajectory. They used traditional machine learning algorithms like SVM,social forces, probabilistic models and LSTM to analyze the heuristic motion trajectories but they didn't consider the other environmental factors e.g relative positions of other humans present in environment and positions of objects present in environment which can affect the motion trajectories of humans. We intend to achieve this goal by employing Long Short Term Memory(LSTM) units to analyze motion histories, convolution neural networks to environmental facts e.g. human-human, human-object interaction and relative positioning of 80 different objects including pedestrians and generative adversarial networks(GANs) to predict possible future motion paths. Our proposed method achieved 70% lower Average Displacement Error(ADE) and 41% lower Final Displacement Error(FDE) in comparison to other state of the art techniques.
C1 [Hassan, Muhammad Ahmed; Khan, Muhammad Usman Ghani] UET, Dept Comp Sci, Lahore, Pakistan.
   [Hassan, Muhammad Ahmed; Khan, Muhammad Usman Ghani] UET, KICS, Natl Ctr Artificial Intelligence, Lahore, Pakistan.
   [Iqbal, Razi] UET, Al Khawarizmi Inst Comp Sci, Lahore, Pakistan.
   [Riaz, Omer] Islamia Univ, Bahawalpur, Pakistan.
   [Bashir, Ali Kashif] Manchester Metropolitan Univ, Manchester, Lancs, England.
   [Tariq, Usman] Prince Sattam Bin Abdulaziz Univ, Al Kharj, Saudi Arabia.
C3 Manchester Metropolitan University; Prince Sattam Bin Abdulaziz
   University
RP Hassan, MA (corresponding author), UET, Dept Comp Sci, Lahore, Pakistan.; Hassan, MA (corresponding author), UET, KICS, Natl Ctr Artificial Intelligence, Lahore, Pakistan.
EM ahmed.hasan@kics.edu.pk; usman.ghani@kics.edu.pk; razi.iqbal@ieee.org;
   omer.riaz@iub.edu.pk; dr.alikashif.b@ieee.org; u.tariq@psau.edu.sa
RI Tariq, Usman/AAE-8037-2022; Bashir, Ali Kashif/R-4015-2019; Tariq,
   Usman/AAF-8954-2020; Khan, Muhammad Umair/AAX-3351-2021; Khan, Muhammad
   Usman/AAM-1695-2021
OI Tariq, Usman/0000-0001-7672-1187; Bashir, Ali
   Kashif/0000-0003-2601-9327; Khan, Muhammad Umair/0000-0002-1403-2359;
   Khan, Muhammad Usman/0000-0002-6260-6679; Hassan deif,
   Ahmed/0009-0002-7989-0466
FU National Center For Artificial Intelligence at University of Engineering
   and Technology, Lahore, Pakistan
FX Financial support for this study was provided by a grant from the
   National Center For Artificial Intelligence at University of Engineering
   and Technology, Lahore, Pakistan. The authors wish to thank
   Al-Khawarizimi Institute of Computer Science, UET Lahore for providing
   research platform and technical support.
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Ali A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030678
   Azad MA, 2020, FUTURE GENER COMP SY, V105, P297, DOI 10.1016/j.future.2019.11.007
   Azad MA, 2013, COMPUT SECUR, V39, P219, DOI 10.1016/j.cose.2013.07.006
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Ballan L, 2016, LECT NOTES COMPUT SC, V9905, P697, DOI 10.1007/978-3-319-46448-0_42
   Bhatti MH, 2019, IEEE T IND INFORM, V15, P5747, DOI 10.1109/TII.2019.2925624
   Bush PCM, 2019, Police with the latest information on the mosque shootings
   Chathuramali KGM, 2012, INT CONF ADV ICT, P197, DOI 10.1109/ICTer.2012.6421415
   Chorowski J, 2014, END END CONTINUOUS S
   Chung J, 2015, ADV NEUR IN, V28
   Coscia P, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1961
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Gambrell J, 2015, New tally shows at least 1,621 killed in saudi hajj tragedy
   Gashteroodkhani OA, 2019, ELECTR POW SYST RES, V170, P205, DOI 10.1016/j.epsr.2019.01.023
   Goel K., 2015, Conference on computer vision and pattern recognition
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   He ZY, 2009, IEEE SYS MAN CYBERN, P5041, DOI 10.1109/ICSMC.2009.5346042
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hussain CS, 2013, INTELL AUTOM SOFT CO, V19, P439, DOI 10.1080/10798587.2013.794613
   Jiang S, 2019, ENERG EXPLOR EXPLOIT, V37, P1125, DOI 10.1177/0144598718816604
   Karpathy A, 2014, ADV NEUR IN, V27
   Khan G, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106524
   Khan Muhammad Zeeshan, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P197, DOI 10.1109/ICAEM.2019.8853663
   Khan MZ, 2019, IEEE ACCESS, V7, P72622, DOI 10.1109/ACCESS.2019.2918275
   Kim B, 2016, INT J SOC ROBOT, V8, P51, DOI 10.1007/s12369-015-0310-2
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Luber M, 2010, IEEE INT CONF ROBOT, P464, DOI 10.1109/ROBOT.2010.5509779
   Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493
   Master N, 2010, Intentional homicide, number and rate per 100,000 population
   Peltier E, 2010, France declares strasbourg shooting an act of terrorism
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Saleem S, 2019, COMPUT ELECTR ENG, V78, P108, DOI 10.1016/j.compeleceng.2019.07.009
   Satake S., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P109
   Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sultan S, 2019, J AMB INTEL HUM COMP, V10, P4197, DOI 10.1007/s12652-019-01444-6
   Vasquez D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P82
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
NR 45
TC 6
Z9 6
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15289
EP 15311
DI 10.1007/s11042-021-11457-z
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000695454400003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Su, KQ
   Yan, WQ
   Wei, X
   Gu, MQ
AF Su, Kaiqi
   Yan, Weiqing
   Wei, Xin
   Gu, Meiqi
TI Stereo VoVNet-CNN for 3D object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic images; VoVNet; 3D object detection
ID SALIENCY DETECTION
AB 3D object detection is a key issue and research in autonomous vehicle and computer vision. 3D detection methods based on stereoscopic images estimate 3D boxes and regress the object pose by exploiting the sparse and dense, semantic and geometry information of stereoscopic images. In this paper, we propose stereo VoVNet-CNN for 3D object detection. In this network, we adopt VoVNet as the backbone to extract feature, and Stereo Region Proposal Network(RPN) to refine 2D box, moreover, align and extract 3D box by stereo regression with 3D constraint of stereo images. The VoVNet module considers local and global feature information by integrating the contextual information from different receptive fields and inputting initial feature into the final output feature map. Therefore, the proposed stereo VoVNet can provide high accuracy for feature extraction. We evaluate the proposed network on KITTI dataset by comparing it with other state-of-the-art methods. Experimental results demonstrate well the effectiveness of the proposed network.
C1 [Su, Kaiqi; Yan, Weiqing; Wei, Xin; Gu, Meiqi] Yantai Univ, Sch Comp & Control Engn, Yantai 264005, Peoples R China.
C3 Yantai University
RP Yan, WQ (corresponding author), Yantai Univ, Sch Comp & Control Engn, Yantai 264005, Peoples R China.
EM wqyan@ytu.edu.cn
RI Su, Kai-Qi/AAW-4154-2020
OI Su, Kai-Qi/0000-0002-7362-3482
FU National Natural Science Foundation of China [61801414, 61802331];
   Natural Science Foundation of Shandong Province [ZR2017QF006, J18KZ016,
   ZR2019MF060, ZR2018BF008]
FX This work was supported by National Natural Science Foundation of China
   under Grants 61801414, 61802331, Natural Science Foundation of Shandong
   Province under Grants ZR2017QF006, J18KZ016, ZR2019MF060, ZR2018BF008.
CR Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen Z., 2020, IEEE Trans. Image Process.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eskil J, 2019, ARXIV190608070
   Geiger A., 2012, CVPR
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lee Y, 2020, P IEEE CVF C COMP VI
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu ZY, 2019, MULTIMED TOOLS APPL, V78, P6787, DOI 10.1007/s11042-018-6319-4
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Ng MY, 2020, IEEE COMPUT SOC CONF, P4306, DOI 10.1109/CVPRW50498.2020.00508
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qin ZY, 2019, PROC CVPR IEEE, P7607, DOI 10.1109/CVPR.2019.00780
   Qin ZY, 2019, AAAI CONF ARTIF INTE, P8851
   Roddick Thomas, 2018, ARXIV181108188
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208
   Wang HQ, 2018, MULTIMED TOOLS APPL, V77, P14655, DOI 10.1007/s11042-017-5052-8
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Yilun Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12533, DOI 10.1109/CVPR42600.2020.01255
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 36
TC 2
Z9 2
U1 2
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35803
EP 35813
DI 10.1007/s11042-021-11506-7
EA SEP 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000695102100001
DA 2024-07-18
ER

PT J
AU Yin, MH
   Liu, YH
   Zhou, X
   Sun, G
AF Yin, Minghao
   Liu, Yanheng
   Zhou, Xu
   Sun, Geng
TI A tensor decomposition based collaborative filtering algorithm for
   time-aware POI recommendation in LBSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI recommendation; Tensor decomposition; Location based social network
ID USER ACTIVITY; MODEL; PREFERENCE
AB Point of interest (POI) recommendation problem in location based social network (LBSN) is of great importance and the challenge lies in the data sparsity, implicit user feedback and personalized preference. To improve the precision of recommendation, a tensor decomposition based collaborative filtering (TDCF) algorithm is proposed for POI recommendation. Tensor decomposition algorithm is utilized to fill the missing values in tensor (user-category-time). Specifically, locations are replaced by location categories to reduce dimension in the first phase, which effectively solves the problem of data sparsity. In the second phase, we get the preference rating of users to POIs based on time and user similarity computation and hypertext induced topic search (HITS) algorithm with spatial constraints, respectively. Finally the user's preference score of locations are determined by two items with different weights, and the Top-N locations are the recommendation results for a user to visit at a given time. Experimental results on two LBSN datasets demonstrate that the proposed model gets much higher precision and recall value than the other three recommendation methods.
C1 [Yin, Minghao; Liu, Yanheng; Sun, Geng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Liu, Yanheng; Zhou, Xu] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
   [Zhou, Xu] Jilin Univ, Ctr Comp Fundamental Educ, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Zhou, X (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
EM zhoux16@jlu.edu.cn
RI Yin, Minghao/E-9611-2015; liu, yan/HGV-1365-2022
OI Yin, Minghao/0000-0002-6226-2394; , Xu Zhou/0000-0003-1890-7033
FU National Natural Science Foundation of China [61806083, 61872158];
   Fundamental Research Funds for the Central Universities [93K172021Z02];
   Excellent Young Talents Program for department of Science and Technology
   of Jilin Province of China [20190103051JH]; Science and Technology
   program of the 13th Five-Year Plan for education department of Jilin
   Province of China [JJKH20190161KJ]
FX This research is supported by National Natural Science Foundation of
   China grants 61806083, 61872158; The Fundamental Research Funds for the
   Central Universities,JLU grants 93K172021Z02; Excellent Young Talents
   Program for department of Science and Technology of Jilin Province of
   China grants 20190103051JH, Science and Technology program of the 13th
   Five-Year Plan for education department of Jilin Province of China
   grants JJKH20190161KJ.
CR Chen BL, 2017, EXPERT SYST APPL, V79, P225, DOI 10.1016/j.eswa.2017.01.037
   Cheng C., 2012, P AAAI C ART INT, P17
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Gao, 2014, PERSONALIZED POI REC
   Gao R, 2018, NEUROCOMPUTING, V273, P159, DOI 10.1016/j.neucom.2017.08.020
   Goodman MK, 2011, GEOGR J, V177, P102, DOI 10.1111/j.1475-4959.2011.00401.x
   Guo L, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/3574194
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hu B, 2014, IEEE DATA MINING, P845, DOI 10.1109/ICDM.2014.124
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Leung KWT, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P305
   Li HY, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P975, DOI 10.1145/2939672.2939767
   Li X, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3057283
   Liu B, 2015, IEEE T KNOWL DATA EN, V27, P1167, DOI 10.1109/TKDE.2014.2362525
   Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978
   Park MH, 2007, LECT NOTES COMPUT SC, V4611, P1130
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Ren XY, 2017, NEUROCOMPUTING, V241, P38, DOI 10.1016/j.neucom.2017.02.005
   Saleem Muhammad Aamir, 2013, Inclusive Society: Health and Wellbeing in the Community, and Care at Home. 11th International Conference on Smart Homes and Health Telematics, ICOST 2013. Proceedings. LNCS 7910, P86
   Si YL, 2017, DESTECH TRANS COMP, P17
   Si YL, 2019, KNOWL-BASED SYST, V163, P267, DOI 10.1016/j.knosys.2018.08.031
   Si YL, 2017, KNOWL-BASED SYST, V128, P59, DOI 10.1016/j.knosys.2017.04.013
   Wang H., 2013, P 21 ACM SIGSPATIAL, P364
   Yang DQ, 2015, IEEE T SYST MAN CY-S, V45, P129, DOI 10.1109/TSMC.2014.2327053
   Ying YK, 2017, NEUROCOMPUTING, V242, P195, DOI 10.1016/j.neucom.2017.02.067
   Yochum P, 2020, IEEE ACCESS, V8, P16409, DOI 10.1109/ACCESS.2020.2967120
   Yuan Q., 2014, P 23 ACM INT C C INF, P659, DOI DOI 10.1145/2661829.2661983
   Yuan Q, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P363
   Zhao SL, 2016, AAAI CONF ARTIF INTE, P315
NR 30
TC 4
Z9 5
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36215
EP 36235
DI 10.1007/s11042-021-11407-9
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000691930500003
DA 2024-07-18
ER

PT J
AU Abbasi, S
   Rezaeian, M
AF Abbasi, Soolmaz
   Rezaeian, Mehdi
TI Visual object tracking using similarity transformation and adaptive
   optical flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object tracking; Similarity transformation; Optical flow; Local
   binary patterns; Histogram orientation gradient
ID FEATURES
AB Visual object tracking is among the most attractive topics in various applications of vision system. Target objects' appearance often drastically changes over time therefore Object tracking is challenging issue. In recent years, adaptive correlation filters have been satisfactorily employed in object tracking due to high efficiency and robustness. In this paper, a correlation filter-based tracker is proposed, which combines Histograms of Oriented Gradients (HOG), Local Binary Pattern (LBP) and optical flow as the feature set to extract textural, and motion model information. Proposed framework is capable of handling tracking attributes, especially occlusion and out-of-view. Adaptive threshold for optical flow is formulated to robust estimation. Threshold in each frame is calculated based on background properties, and similarity transformation is utilized for predicting scale, rotation and translation changes. The experimental results on OTB-100 indicate that the proposed tracker obtains promising prediction performance with respect to the state-of-the-art visual tracking approaches. This method exploits the advantages of conventional correlation filter-based tracking methods as well as purposeful features simultaneously. Proposed tracker is executable online and does not necessitate pre-training.
C1 [Abbasi, Soolmaz; Rezaeian, Mehdi] Yazd Univ, Comp Engn Dept, Yazd, Iran.
C3 University of Yazd
RP Rezaeian, M (corresponding author), Yazd Univ, Comp Engn Dept, Yazd, Iran.
EM soulmaz.abbasi@stu.yazd.ac.ir; mrezaeian@yazd.ac.ir
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Azad P, 2014, 2009 IEEERSJ INT C I, P4275
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fiaz M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309665
   Fleet D, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P239
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Gupta DK, 2020, TACKLING OCCLUSION I
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Ivanov Y, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P97, DOI 10.1109/CADSM.2015.7230806
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li Y, 2019, AAAI CONF ARTIF INTE, P8666
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Mehmood K, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010043
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P159, DOI 10.1109/DSMP.2016.7583531
   Routray S, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Sotoodeh M, 2019, MULTIMED TOOLS APPL, V78, P34513, DOI 10.1007/s11042-019-08050-w
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Wang Q., 2017, ARXIV PREPRINT ARXIV
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y, 2019, MULTIMED TOOLS APPL, V78, P31633, DOI 10.1007/s11042-019-07851-3
   Wu F, 2020, NEUROCOMPUTING, V402, P1, DOI 10.1016/j.neucom.2020.03.026
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Xu Z, 2019, CHIN CONT DECIS CONF, P5284, DOI [10.1109/CCDC.2019.8833463, 10.1109/ccdc.2019.8833463]
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
NR 44
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33455
EP 33473
DI 10.1007/s11042-021-11344-7
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512900005
DA 2024-07-18
ER

PT J
AU Zhang, J
   He, FZ
   Yan, XH
   Duan, YS
AF Zhang, Jian
   He, Fazhi
   Yan, Xiaohu
   Duan, Yansong
TI Single image haze removal for aqueous vapour regions based on optimal
   correction of dark channel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aqueous vapour regions; Dehazing; Optimal correction; Dark channel
ID QUALITY ASSESSMENT; COLOR TRANSFER; ALGORITHM; VISIBILITY; EFFICIENT;
   WEATHER; ROBUST
AB Haze removal is an interesting topic in multimedia and image processing for many applications. Specially for the automatic piloting of ships, the haze removal technology for aqueous vapour regions plays a key role in safe piloting. However, the existing haze removal methods did not dehaze well for these areas. Based on this motive, this paper presents a new haze removal approach to improve the dehazing effect for aqueous vapour regions, in which we design two new computing mechanisms. The first one is to propose a new gradient change model of the dark channel value related to aqueous vapour regions. The second one is to design an optimized and iterated correction method for the dark channel of aqueous vapour regions. Finally, based on these two computing mechanisms, a dynamic iterative optimal correction model is presented to solve the proposed method. Both the visual and the quantitative experiments demonstrate the proposed method outperforms both the family methods of dark channel prior and the deep learning-based methods in aqueous vapour regions. In conclusion, the proposed method can effectively remove the haze in aqueous vapour regions.
C1 [Zhang, Jian; He, Fazhi] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Zhang, Jian] Wuhan Sports Univ, Coll Sport Engn & Informat Technol, Wuhan, Peoples R China.
   [Yan, Xiaohu; Duan, Yansong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan Sports University; Wuhan University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM fzhe@whu.edu.cn
RI He, Fazhi/Q-3691-2018
FU National Science Foundation of China [62072348]; National Key RAMP;D
   Program of China [2019YFC1509604]; Science and Technology Major Project
   of Hubei Province (Next-Generation AI Technologies) [2019AEA170]
FX This work is supported by the National Science Foundation of China under
   Grant No 62072348, the National Key R&D Program of China under Grant No
   2019YFC1509604 and the Science and Technology Major Project of Hubei
   Province (Next-Generation AI Technologies) under Grant No 2019AEA170.
CR Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2014, ELECTRON LETT, V50, P516, DOI 10.1049/el.2013.3652
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Ding M, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4566-y
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Feng C, 2013, IEEE IMAGE PROC, P2363, DOI 10.1109/ICIP.2013.6738487
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Li HZ, 2019, IEEE ANN INT CONF CY, P1, DOI 10.1109/CYBER46603.2019.9066601
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Bo L, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P145, DOI 10.1109/ITNEC.2016.7560337
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo J, 2022, International Journal of Bio-Inspired Computation, V18, P1, DOI [10.1504/IJBIC.2020.10036562, DOI 10.1504/IJBIC.2020.10036562]
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nishita Tomoyuki., 1987, COMPUTER GRAPHICS P, V21, P303, DOI [10.1145/37401.37437, DOI 10.1145/37401.37437]
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Qian W, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4945214
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Raikwar SC, 2020, MULTIMED TOOLS APPL, V79, P891, DOI 10.1007/s11042-019-08120-z
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sugimoto K, 2015, IEEE T IMAGE PROCESS, V24, P3357, DOI 10.1109/TIP.2015.2442916
   Sun L, 2020, IEEE T CIRC SYST VID, V30, P3829, DOI 10.1109/TCSVT.2019.2946723
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang J., 2020, IEEE ACCESS, P1
   Wang TJ, 2012, ATMOS ENVIRON, V58, P70, DOI 10.1016/j.atmosenv.2012.01.014
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Dui, 2006, Acta Meteorologica Sinica, V64, P510
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhu QS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2414, DOI 10.1109/ROBIO.2013.6739832
NR 56
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32665
EP 32688
DI 10.1007/s11042-021-11223-1
EA AUG 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000680314900002
DA 2024-07-18
ER

PT J
AU Ashrafi, SS
   Shokouhi, SB
   Ayatollahi, A
AF Ashrafi, Seyed Sajad
   Shokouhi, Shahriar B.
   Ayatollahi, Ahmad
TI Action recognition in still images using a multi-attention guided
   network with weakly supervised saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Still image-based action recognition; Convolutional neural network;
   Multi-attention; Teacher-student network
ID MOTION
AB Action recognition in still images is an interesting subject in computer vision. One of the most important problems in still image-based action recognition is the lack of temporal information; At the same time, other existing problems such as cluttered backgrounds and diverse objects make the recognition task more challenging. However, there may be several salient regions in each action image, employing of which could lead to an improvement in the recognition performance. Moreover, since no unique and clear definition exists for detecting these salient regions in action recognition images, therefore, obtaining reliable ground truth salient regions is a highly challenging task. This paper presents a multi-attention guided network with weakly-supervised multiple salient regions detection for action recognition. A teacher-student structure is used to guide the attention of the student model into the salient regions. The teacher network with Salient Region Proposal (SRP) module generates weakly-supervised data for the student network in the training phase. The student network, with Multi-ATtention (MAT) module, proposes multiple salient regions and predicts the actions based on the found information in the evaluation phase. The proposed method obtains mean Average Precision (mAP) value of 94.2% and 93.80% on Stanford-40 Actions and PASCAL VOC2012 datasets, respectively. The experimental results, based on the ResNet-50 architecture, show the superiority of the proposed method compared to the existing ones on Stanford-40 and VOC2012 datasets. Also, we have made a major modification to the BU101 dataset which is now publicly available. The proposed method achieves mAP value of 90.16% on the new BU101 dataset.
C1 [Ashrafi, Seyed Sajad; Shokouhi, Shahriar B.; Ayatollahi, Ahmad] Iran Univ Sci & Technol IUST, Elect Engn Dept, Tehran, Iran.
C3 Iran University Science & Technology
RP Shokouhi, SB (corresponding author), Iran Univ Sci & Technol IUST, Elect Engn Dept, Tehran, Iran.
EM s_ashrafi@elec.iust.ac.ir; bshokouhi@iust.ac.ir; ayatollahi@iust.ac.ir
RI Shokouhi, shahriar Baradaran/T-5578-2018; Ayatollahi, Ahmad/S-5984-2018
CR Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   Amirkhani D, 2019, INPAINTED IMAGE QUAL, DOI [10.1109/ICSPIS48872.2019.9066140, DOI 10.1109/ICSPIS48872.2019.9066140]
   [Anonymous], 2006, Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Bulbul MF, 2019, J INTELL FUZZY SYST, V36, P3385, DOI 10.3233/JIFS-181136
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Delaitre V., 2010, Proceedings of the British Machine Vision Conference, P1, DOI DOI 10.5244/C.24.97
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu Tao, 2019, See better before looking closer: Weakly supervised data augmentation network for fine-grained visual classification
   Ikizler N, 2008, RECOGNIZING ACTIONS, DOI [10.1109/icpr.2008.4761663, DOI 10.1109/ICPR.2008.4761663]
   Li Y, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107341
   Li ZF, 2019, MULTIMED TOOLS APPL, V78, P19587, DOI 10.1007/s11042-019-7356-3
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu L, 2019, LECT NOTES COMPUT SC, V11365, P152, DOI 10.1007/978-3-030-20873-8_10
   LONG QX, 2020, NAT MED, V26, P845, DOI [10.1101/2020.03.18.20038018, DOI 10.1038/S41591-020-0897-1, 10.1038/s41591-020-0897-1]
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ludl D, 2019, IEEE INT C INTELL TR, P581, DOI 10.1109/ITSC.2019.8917128
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   McAuley J, 2012, LECT NOTES COMPUT SC, V7575, P828, DOI 10.1007/978-3-642-33765-9_59
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Qi TQ, 2017, NEUROCOMPUTING, V267, P475, DOI 10.1016/j.neucom.2017.06.041
   Raja K, 2011, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2011.6116197
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thurau C, 2008, POSE PRIMITIVE BASED, DOI [10.1109/CVPR.2008.4587721, DOI 10.1109/CVPR.2008.4587721]
   Tian D, 2020, MULTIMED TOOLS APPL, V79, P12679, DOI 10.1007/s11042-020-08611-4
   Xin M, 2019, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2019.00183
   Yan SY, 2017, SIGNAL PROCESS-IMAGE, V54, P118, DOI 10.1016/j.image.2017.03.010
   Yan SY, 2018, IEEE T COGN DEV SYST, V10, P1116, DOI 10.1109/TCDS.2017.2783944
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zagoruyko S, 2016, 5 INT C LEARN REPR I
   Zeng HL, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.2
   Zhao ZC, 2017, IEEE I CONF COMP VIS, P3411, DOI 10.1109/ICCV.2017.367
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
NR 47
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32567
EP 32593
DI 10.1007/s11042-021-11215-1
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679762700003
DA 2024-07-18
ER

PT J
AU Cai, WW
   Wei, ZG
   Song, YP
   Li, ML
   Yang, XC
AF Cai, Weiwei
   Wei, Zhanguo
   Song, Yaping
   Li, Meilin
   Yang, Xuechun
TI Residual-capsule networks with threshold convolution for segmentation of
   wheat plantation rows in UAV images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Threshold convolution; Residual-capsule networks; Wheat plantation rows;
   Image segmentation
ID NEURAL-NETWORK; ROBUST CROP
AB The early growth process of wheat is vulnerable to various factors, and poor growth leads to vacancies in the planting row. Therefore, the wheat images captured by unmanned aerial vehicles (UAV) are essential for monitoring the growth of wheat and preventing diseases and insect pests. This paper uses wheat images captured by UAV as a dataset, and propose a novel residual-capsule network with threshold convolution (RCTC) for segmentation of wheat plantation rows. The network is achieved by replacing the AveragePooling of the improved ResNet34 with Capsule. Since the capsule network represents the features by vectors, it can explain the direction of features and the relative positions between features. Therefore, deeper feature information can be extracted. In addition, to reduce redundant features and enhance effective features, a new threshold convolution is also proposed. Experiments on the wheat field dataset show that our proposed algorithm can effectively segment the wheat plantation rows images collected by UAV, and is superior to some existing well-known algorithms, and can provide scientific support and reference for the decision-making process of smart agriculture.
C1 [Cai, Weiwei; Wei, Zhanguo; Song, Yaping; Li, Meilin] Cent South Univ Forestry & Technol, Changsha 410004, Peoples R China.
   [Cai, Weiwei] Changsha Astra Informat Technol Co Ltd, Changsha 410219, Peoples R China.
   [Yang, Xuechun] Hefei Univ, Hefei 230009, Peoples R China.
C3 Central South University of Forestry & Technology; Hefei University
RP Wei, ZG (corresponding author), Cent South Univ Forestry & Technol, Changsha 410004, Peoples R China.
EM t20110778@csuft.edu.cn
RI Cai, Weiwei/AAH-5456-2020; Cai, Weiwei/AAH-5456-2020
OI Cai, Weiwei/0000-0001-8992-9999; Cai, Weiwei/0000-0001-6795-6152
FU Hunan Key Laboratory of Intelligent Logistics Technology [2019TP1015]
FX This research was funded by the Hunan Key Laboratory of Intelligent
   Logistics Technology under Grant 2019TP1015.
CR Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   de Castro AI, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020285
   Deng F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093153
   Fareed N, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9030151
   Feng AJ, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105711
   Ganchenko V, 2019, COMM COM INF SC, V1055, P52, DOI 10.1007/978-3-030-35430-5_5
   Gao HM, 2019, IEEE ACCESS, V7, P176587, DOI 10.1109/ACCESS.2019.2957163
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu WJ, 2020, IEEE ACCESS, V8, P115287, DOI 10.1109/ACCESS.2020.3001237
   Huang ZH, 2020, IEEE T GEOSCI REMOTE, V58, P6958, DOI 10.1109/TGRS.2020.2978276
   Huang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P759, DOI 10.1109/LGRS.2018.2796604
   Jeon HY, 2011, SENSORS-BASEL, V11, P6270, DOI 10.3390/s110606270
   Kingma D. P., 2014, arXiv
   Kurup R. V., 2019, INT C COMPUTATIONAL, V186, P413, DOI 10.1007/978-3-030- 37218-7.
   Li K, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050789
   Li Y, 2019, CLUSTER COMPUT, V22, pS9515, DOI 10.1007/s10586-018-2482-7
   Lottes P, 2018, IEEE ROBOT AUTOM LET, V3, P2870, DOI 10.1109/LRA.2018.2846289
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P740, DOI 10.1109/TGRS.2018.2860125
   Pereira PC, 2020, APPL ARTIF INTELL, V34, P271, DOI 10.1080/08839514.2020.1720131
   Rocha BM, 2020, CAN CON EL COMP EN, DOI 10.1109/ccece47787.2020.9255701
   Sabour S, 2017, ADV NEUR IN, V30
   Salman M, 2018, SIG PROCESS COMMUN
   Tang YC, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00510
   Wang AC, 2020, IEEE ACCESS, V8, P81724, DOI 10.1109/ACCESS.2020.2991354
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Xu QF, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3022512
   Yang GF, 2018, INT GEOSCI REMOTE SE, P2595, DOI 10.1109/IGARSS.2018.8517520
   Yang QC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11172008
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang C, 2017, SEGMENTATION MODEL E
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zheng HB, 2020, COMPUT ELECTRON AGR, V169, DOI [10.1016/j.compag.2020.105223, 10.1016/j.comp]
NR 33
TC 20
Z9 20
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32131
EP 32147
DI 10.1007/s11042-021-11203-5
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000677229000003
DA 2024-07-18
ER

PT J
AU Liu, TC
   Liu, HX
   Wang, YL
AF Liu, Tongcun
   Liu, Haoxin
   Wang, Yulong
TI Exploiting local spatio-temporal characteristics for effective video
   understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video understanding; video representation; Spatio-temporal
   characteristics; Part channel fusion; Neural networks
AB The explosive growth in online video streaming presents challenges for video understanding with high accuracy and low computation complexity. Recent methods have realized global video representation without considering the local spatial structures of the videos over time. In this paper, we propose a method called partial channel fusion (PCF), which exploits local spatio-temporal characteristics for video understanding. We also present an agnostic and effective module for PCF which can provide both high efficiency and high performance in a variety of networks. Rather than independently modeling the spatial structure and motion structure of videos, the PCF module enables information exchange among multiple frames by partially fusing channels over the temporal dimension. By inserting the PCF module into different layers of a 2D convolutional network (2D-convNets), the local and global spatio-temporal characteristics of videos can be captured. Experimental results on two challenging datasets demonstrate the superiority of PCF in improving the accuracy of a 2D-convNets, advancing the state-of-the-art without increasing computational complexity.
C1 [Liu, Tongcun] Zhejiang A&F Univ, Sch Informat Engn, Hangzhou, Peoples R China.
   [Liu, Haoxin; Wang, Yulong] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
C3 Zhejiang A&F University; Beijing University of Posts &
   Telecommunications
RP Liu, TC (corresponding author), Zhejiang A&F Univ, Sch Informat Engn, Hangzhou, Peoples R China.
EM tongcun.liu@gmail.com
OI Liu, TongCun/0000-0002-0520-7807
FU National Natural Science Foundation of China [61771068, 61671079,
   61471063, 61372120, 61421061, 31971493]; Beijing Municipal Natural
   Science Foundation [4182041, 4152039]; National Basic Research Program
   of China [2013CB329102]; Research and Development Fund Talent Startup
   Project of Zhejiang AF University [2019FR070]
FX This research was jointly supported by (1) the National Natural Science
   Foundation of China (Nos. 61771068, 61671079, 61471063, 61372120,
   61421061, and 31971493); (2) the Beijing Municipal Natural Science
   Foundation (Nos. 4182041 and 4152039); (3) the National Basic Research
   Program of China (No. 2013CB329102); (4) the Research and Development
   Fund Talent Startup Project of Zhejiang A&F University (No. 2019FR070).
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Girdhar R., 2017, PROC CVPR IEEE, P971, DOI DOI 10.1109/CVPR.2017.337
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khurram S, 2012, ARXIV14091556CS
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nogueira TDC, 2020, MULTIMED TOOLS APPL, V79, P30615, DOI 10.1007/s11042-020-09539-5
   Priyanka S, 2020, MULTIMED TOOLS APPL, V79, P2263, DOI 10.1007/s11042-019-08113-y
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Tran D, 2017, ARXIV170805038CS
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 36
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31821
EP 31836
DI 10.1007/s11042-021-11093-7
EA JUL 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674549700001
DA 2024-07-18
ER

PT J
AU Mohseni, AH
   Jahangir, AH
   Hosseini, SM
AF Mohseni, A. Hesam
   Jahangir, A. H.
   Hosseini, S. M.
TI Toward a comprehensive subjective evaluation of VoIP users' quality of
   experience (QoE): a case study on Persian language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience (QoE); Voice over IP (VoIP); Quality of service
   (QoS); Subjective test; Artificial neural network (ANN); Support vector
   regression (SVR)
ID PREDICTION; SERVICES; MODEL
AB Quality of Experience (QoE) measures the overall quality of a service from users' point of view by considering several system, human, and contextual factors. There exist various objective and subjective methods for QoE prediction. Although the subjective approach is more expensive and challenging than the objective approach, QoE's level can be more accurately determined by a subjective test. This paper investigates various features affecting QoE by proposing a comprehensive subjective evaluation. First, we show that many unconsidered factors can significantly affect QoE. We have generated voice samples featuring different values for novel factors related to the speaker, signal, and network. Regarding the speaker, we take into account the accent and gender of Persian-speaking people. We conduct an extensive survey by employing a large number of users. Our comprehensive analysis reveals that the users' identity has a significant influence on QoE. Our experiments show that many previously studied parameters do not affect QoE in the same way for various users with different genders and accents. Finally, we show that QoE can be accurately predicted using Artificial Neural Network (ANN) and Support Vector Regression (SVR) techniques if the new identity features are taken into account.
C1 [Mohseni, A. Hesam] Sharif Univ Technol, Fac Engn, Intl Campus, Kish Isl, Iran.
   [Jahangir, A. H.; Hosseini, S. M.] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Jahangir, AH (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM jahangir@sharif.ir
OI Jahangir, Amir Hossein/0000-0002-8837-0668; Hosseini,
   Mohammad/0000-0002-1911-9234
CR Alreshoodi M, 2015, IEEE T CONSUM ELECTR, V61, P546, DOI 10.1109/TCE.2015.7389811
   [Anonymous], 2018, ITU T RECOMMENDATION
   Asterisk, 2018, FREE OP SOURC FRAM B
   Bijankhan Mahmood, 1994, P AUSTR C SPEECH SCI, P826
   Brooks P, 2010, IEEE NETWORK, V24, P8, DOI 10.1109/MNET.2010.5430138
   Charonyktakis P, 2016, IEEE T MOBILE COMPUT, V15, P1443, DOI 10.1109/TMC.2015.2461216
   Chen S, 2014, IEEE ACM T NETWORK, V22, P1781, DOI 10.1109/TNET.2013.2286624
   Cipressi Elena, 2020, IEEE Networking Letters, V2, P90, DOI 10.1109/LNET.2020.2984721
   Daengsi T, 2013, IEEE GLOB COMM CONF, P1329, DOI 10.1109/GLOCOM.2013.6831258
   de Fez I, 2020, COMPUT COMMUN, V158, P126, DOI 10.1016/j.comcom.2020.05.011
   Elastix, 2019, UN COMM SERV
   FarsDat, 2019, SPEECH DAT FARS SPOK
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Gatofrod J, 1993, DARPA TIMIT ACOUSTIC
   Goudarzi, 2009, P MEAS SPEECH AUD VI
   Hamam A, 2013, IEEE T INSTRUM MEAS, V62, P3315, DOI 10.1109/TIM.2013.2272859
   Hoene, 2004, MEASUREMENT SPEECH A
   International Telecommunication Union (ITU), 1996, ITU-T Recommendation P.830
   *ITU T, 2017, ITU T RECOMMENDATION
   ITU-T, 2015, ITU T RECOMMENDATION
   ITU-T Study Group 12, 2009, METH TOOLS TEST PLAN
   Jaiswal, 2020, JUN 2020 31 IR SIGN, DOI 10.1109/ISSC49989.2020.9180171
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jurgelionis A, 2011, IEEE IC COMP COM NET
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Mitchell T.M., 1997, Machine learning, V45, P81
   Mitchell ThomasM., 1997, Machine Learning, V1, P154
   Mitra K, 2015, IEEE T MOBILE COMPUT, V14, P920, DOI 10.1109/TMC.2013.155
   Netem, 2018, LIN NETW EM
   Nihei K, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511338
   Oche M, 2017, COMPUT COMMUN, V104, P88, DOI 10.1016/j.comcom.2016.12.022
   Parkash Roy O, 2020, 6 INT C COMP MAN MAT, DOI 10.1088/1757-899X/1020/1/012015
   Rapid Miner, 2020, RAP MIN DOC
   Sameti H, 2011, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2011-426795
   Sanchez-Iborra R, 2014, IEEE T WIREL COMMUN, V13, P4947, DOI 10.1109/TWC.2014.2321576
   Steinwart Ingo, 2008, SUPPORT VECTOR MACHI
   Takahashi A, 2006, IEEE T AUDIO SPEECH, V14, P1984, DOI 10.1109/TASL.2006.883261
   Wuttidittachotti P, 2017, MULTIMED TOOLS APPL, V76, P8329, DOI 10.1007/s11042-016-3389-z
   Wuttidittachotti P, 2013, INT CONF UBIQ FUTUR, P401, DOI 10.1109/ICUFN.2013.6614850
   Hu ZG, 2020, NEUROCOMPUTING, V386, P63, DOI 10.1016/j.neucom.2019.12.072
NR 40
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31783
EP 31802
DI 10.1007/s11042-021-11190-7
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000002
DA 2024-07-18
ER

PT J
AU Sachdeva, K
   Gosain, A
AF Sachdeva, Kavita
   Gosain, Anjana
TI Materialized view selection applying differential evolution algorithm
   combined with ensembled constraint handling techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Constraints in view selection; Constraint handling methods; Evolutionary
   optimization; Penalty function
ID OPTIMIZATION; CUBE
AB Materialized view selection problem is a NP-hard, constrained optimization problem where the pre-computation of views is censorious for query performance enhancement and expediting the data warehouse tasks. The pervasive presence of disk space and cost constraints heightens the intricacy of constrained optimization Materialized view selection (MVS) problem. Thus, the problem of MVS becomes prominent among data warehouse researchers. In the last few years, various evolutionary algorithms (EA) have been applied for the optimal selection of views. The present study handles the MVS problem using Ensembled Constraint Handling Techniques (ECHT) composed of (i) Self Adaptive Penalty (SP), (ii) - Constraint (EC) and (iii) Stochastic Ranking (SR) integratedwithDifferential Evolution (DE) algorithm. Authors have used TPC-H star schema benchmark dataset for testing. Simulated results were compared with three existing work i.e. PSO, genetic algorithm and EA and it was observed that our proposed ensemble method ECHTDEMVS, outperforms than single constraint handling methods and minimizes the total processing cost of query and is scalable.
C1 [Sachdeva, Kavita; Gosain, Anjana] GGS Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi 110078, India.
C3 GGS Indraprastha University
RP Sachdeva, K (corresponding author), GGS Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi 110078, India.
EM kavitasachdeva4@gmail.com; anjana_gosain@hotmail.com
CR Abdelmadjid b, 2016, INT C BUS INT APPL I
   [Anonymous], 2014, INT J INNOVATIVE COM
   [Anonymous], 1994, Computational Intelligence: Imitating Life
   Biswas PP, 2018, ENG APPL ARTIF INTEL, V68, P81, DOI 10.1016/j.engappai.2017.10.019
   Boukra A., 2007, International Journal of Computational Intelligence Research, V3, P327, DOI [10.5019/j.ijcir.2007.113, DOI 10.5019/J.IJCIR.2007.113]
   Chaudhuri S., 1997, SIGMOD Record, V26, P65, DOI 10.1145/248603.248616
   Coello CAC, 2002, COMPUT METHOD APPL M, V191, P1245, DOI 10.1016/S0045-7825(01)00323-1
   Coello Carlos Ac, 2012, GENETIC EVOLUTIONARY
   Farmani R, 2003, IEEE T EVOLUT COMPUT, V7, P445, DOI 10.1109/TEVC.2003.817236
   Golfarelli M, 2004, DATA KNOWL ENG, V49, P325, DOI 10.1016/j.datak.2003.11.001
   Gosain A, 2016, PROCEDIA COMPUT SCI, V79, P2, DOI 10.1016/j.procs.2016.03.002
   Goswami R, 2013, LECT NOTES COMPUT SC, V8298, P95, DOI 10.1007/978-3-319-03756-1_9
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Gupta H, 1997, PROC INT CONF DATA, P208, DOI 10.1109/ICDE.1997.581755
   Gupta H, 2005, IEEE T KNOWL DATA EN, V17, P24, DOI 10.1109/TKDE.2005.16
   Gupta H, 1997, LECT NOTES COMPUT SC, V1186, P98
   Gupta H, 1999, LECT NOTES COMPUT SC, V1540, P453
   Han J., 2001, Data Mining: Concepts and Techniques, V3rd edn
   Harinarayan V., 1996, SIGMOD Record, V25, P205, DOI 10.1145/235968.233333
   He J, 2001, ARTIF INTELL, V127, P57, DOI 10.1016/S0004-3702(01)00058-3
   Hung MC, 2007, INFORM SCIENCES, V177, P1333, DOI 10.1016/j.ins.2006.09.007
   INMON WH, 1993, RDB VMS DEV DATA WAR
   Jain H. K., 2012, ACM SIGSOFT SOFTW EN, V37, P1
   Lee MS, 2001, INT J COOP INF SYST, V10, P327, DOI 10.1142/S0218843001000370
   Lin WY, 2004, KNOWL INF SYST, V6, P83, DOI 10.1007/s10115-003-0093-x
   Mallipeddi R, 2010, IEEE T EVOLUT COMPUT, V14, P561, DOI 10.1109/TEVC.2009.2033582
   Morse S., 1998, PARALLEL SYSTEMS DAT
   O'Neil Patrick., 2007, The star schema benchmark
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Runarsson TP, 2000, IEEE T EVOLUT COMPUT, V4, P284, DOI 10.1109/4235.873238
   Shukla A., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P488
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Takahama T, 2006, IEEE C EVOL COMPUTAT, P1
   Tessema B, 2006, IEEE C EVOL COMPUTAT, P246, DOI 10.1109/CEC.2006.1688315
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yang J, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P136
   Yu JX, 2003, IEEE T SYST MAN CY C, V33, P458, DOI 10.1109/TSMCC.2003.818494
   Zhang C, 2001, IEEE T SYST MAN CY C, V31, P282, DOI 10.1109/5326.971656
NR 38
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31619
EP 31645
DI 10.1007/s11042-021-11181-8
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000673927900002
DA 2024-07-18
ER

PT J
AU Pang, SR
   Chen, Z
   Yin, FL
AF Pang, Shurong
   Chen, Zhe
   Yin, Fuliang
TI Lightweight multi-scale aggregated residual attention networks for image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight network; Image super-resolution; Multi-scale aggregated
   residual attention; Multi-level fusion
ID CONVOLUTIONAL NETWORK; INTERPOLATION
AB Recently, single image super-resolution (SISR) based on convolutional neural networks (CNNs) has represented great progress. However, due to the huge number of parameters, these models cannot work well in many real-world applications, most of which fail to exploit the multi-scale features and the hierarchical features for lightweight and accurate image SR. In this paper, a lightweight multi-scale aggregated residual attention network (MARAN) is proposed by exploring multi-scale contextual information and multi-level features. The network consists of shallow feature extraction, recursively stacked multiple multi-scale aggregated residual attention groups (MARAGs), multi-level feature fusion block (MLFFB), and reconstruction part. Specifically, the MARAGs produce the hierarchical multi-scale deep features, the MLFFB effectively fuses the hierarchical features with multi-scale aggregated residual attention. Each MARAG is composed of cascaded multi-scale aggregated residual attention blocks (MARABs) and each MARAB contains a multi-scale aggregated unit and a dual-attention unit. The multi-scale aggregated unit expands group convolution with cross-path connection. The dual-attention unit can adaptively modulate region-based information and channel-wise features. Qualitative and quantitative experiments on four benchmark datasets demonstrate that the proposed MARAN achieves better performance against state-of-the-art methods with fewer parameters.
C1 [Pang, Shurong; Chen, Zhe; Yin, Fuliang] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
C3 Dalian University of Technology
RP Chen, Z (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
EM zhechen@dlut.edu.cn
RI CHEN, ZHE/B-1176-2011
OI CHEN, ZHE/0000-0002-6822-9667
FU Natural Science Foundations of China [61771091, 61871066]; National High
   Technology Research and Development Program (863 Program) of China
   [2015AA016306]; Natural Science Foundation of Liaoning Province of China
   [20170540159]; Fundamental Research Fund for the Central Universities of
   China
FX This work was supported by Natural Science Foundations of China
   (Nos.61771091, 61871066), National High Technology Research and
   Development Program (863 Program) of China (No. 2015AA016306), Natural
   Science Foundation of Liaoning Province of China (No. 20170540159), and
   Fundamental Research Fund for the Central Universities of China
   (No.DUT17LAB04).
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Aitken A, 2017, ARXIV170702937
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Brownlee J, 2016, MACHINE LEARNING MAS, V21
   Cao FL, 2019, KNOWL-BASED SYST, V178, P98, DOI 10.1016/j.knosys.2019.04.021
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Howard A. G., 2017, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jiang K, 2018, IEEE SIGNAL PROC LET, V25, P1630, DOI 10.1109/LSP.2018.2870536
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin F, 2007, LECT NOTES COMPUT SC, V4642, P1
   Lu P, 2018, IEEE T BIO-MED ENG, V65, P178, DOI 10.1109/TBME.2017.2697916
   Pang SR, 2021, IEEE SENS J, V21, P9314, DOI 10.1109/JSEN.2021.3052879
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Qiao JJ, 2019, IET IMAGE PROCESS, V13, P2673, DOI 10.1049/iet-ipr.2018.6570
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Su Y, 2020, MULTIMED TOOLS APPL, P1
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang ZM, 2019, IEEE ACCESS, V7, P24775, DOI 10.1109/ACCESS.2019.2898846
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xue SK, 2020, NEUROCOMPUTING, V382, P116, DOI 10.1016/j.neucom.2019.11.044
   Yang AP, 2020, INFORM SCIENCES, V516, P220, DOI 10.1016/j.ins.2019.12.057
   Yang WM, 2019, IEEE SIGNAL PROC LET, V26, P538, DOI 10.1109/LSP.2018.2890770
   Yang X, 2021, MULTIMED TOOLS APPL, V80, P7063, DOI 10.1007/s11042-020-09958-4
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang S, 2020, IEEE T GEOSCI REMOTE, V58, P4764, DOI 10.1109/TGRS.2020.2966805
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319
   Zhang Yang, 2019, INT C LEARN REPR
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zhou LG, 2019, IEEE T NEUR NET LEAR, V30, P3275, DOI 10.1109/TNNLS.2018.2890550
   Zhu LL, 2019, NEUROCOMPUTING, V345, P58, DOI 10.1016/j.neucom.2018.12.077
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 54
TC 8
Z9 8
U1 12
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4797
EP 4819
DI 10.1007/s11042-021-11138-x
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000669309500001
DA 2024-07-18
ER

PT J
AU Lin, CC
   He, SL
   Chang, CC
AF Lin, Chia-Chen
   He, Si-Liang
   Chang, Chin-Chen
TI Pixel-based fragile image watermarking based on absolute moment block
   truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Absolute moment block truncation coding; Fragile
   watermarking; Pixel-based; Tamper detection; Turtle shell-based data
   hiding
ID SCHEME
AB A pixel-based fragile image watermarking method based on s absolute moment block truncation coding (AMBTC) is proposed in this paper. To enhance the readability of the tampered image, we apply pixel concept to design pixel-based tampering detection and content recovery mechanisms. In the proposed scheme, recovery information is derived from the AMBTC compression codes of the original image, and authentication codes are generated by a pseudo random generator (PRG). Both data are then discretely embedded into the two least significant bits (LSBs) of pixels in the original image with turtle shell-based data hiding method. Therefore, each non-overlapped pixel pair in a watermarked image has 2 bits of recovery information and 2 bits of authentication code. When the recipient suspects that the received image may have been tampered with, the hidden authentication code can be used to locate tampered pixels, and then the hidden recovery information can be extracted and then used to restore the tampered pixels.
C1 [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [He, Si-Liang; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
C3 National Chin-Yi University of Technology; Feng Chia University
RP Lin, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM ally.cclin@ncut.edu.tw; ruby3896976@gmail.com; ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
CR Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen CC, 2019, IEEE ACCESS, V7, P149515, DOI 10.1109/ACCESS.2019.2944833
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2013, PROC TECH, V10, P95, DOI 10.1016/j.protcy.2013.12.341
   Gola KK., 2014, INT J COMPUTER APPL, V106, P13
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin CC, 2014, KSII T INTERNET INF, V8, P4588, DOI 10.3837/tiis.2014.12.020
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Mandal JK, 2013, ADV INTELL SYST, V177, P767
   National Institute of Standards and Technology, 2015, 1803 NAT I STAND TEC
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Raj IK, 2012, COMM COM INF SC, V283, P456
   Singh D., 2013, INTELLIGENT INTERACT, V10, P111, DOI DOI 10.1007/978-3-642-37463-0_10
   Stallings W., 2016, Cryptography and Network Security: Principles and Practice, V7th
   Su GD, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11080996
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang SS, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P130, DOI 10.1109/IIH-MSP.2014.39
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 32
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29497
EP 29518
DI 10.1007/s11042-021-10598-5
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000668401600002
DA 2024-07-18
ER

PT J
AU Alshayeji, M
   Al-Buloushi, J
   Ashkanani, A
   Abed, S
AF Alshayeji, Mohammad
   Al-Buloushi, Jassim
   Ashkanani, Ali
   Abed, Sa'ed
TI Enhanced brain tumor classification using an optimized multi-layered
   convolutional neural network architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmentation; Bayesian optimization; Brain tumor; Convolutional neural
   networks; Deep learning; Image processing
ID IMAGES
AB Detecting and classifying a brain tumor is a challenge that consumes a radiologist's time and effort while requiring professional expertise. To resolve this, deep learning techniques can be used to help automate the process. The aim of this paper is to enhance the accuracy of brain tumor classification using a new layered architecture of deep neural networks rather than the current state-of-the-art algorithms. In this paper, we propose automated tumor classification by concatenating two convolutional neural network structures of layers and tuning the hyperparameters by utilizing Bayesian optimization. The proposed solution focuses on enhancing the accuracy of classifying tumors to increase the level of trust in the technologies employed in the medical field. The work is tested and evaluated to predict the classification of magnetic resonance imaging inputs and achieving a higher accuracy (97.37%) than other similar works, with accuracies between 84.19% and 96.13%, for the same dataset.
C1 [Alshayeji, Mohammad; Al-Buloushi, Jassim; Ashkanani, Ali; Abed, Sa'ed] Kuwait Univ, Coll Engn & Petr, Comp Engn Dept, POB 5969, Safat 13060, Kuwait.
C3 Kuwait University
RP Alshayeji, M (corresponding author), Kuwait Univ, Coll Engn & Petr, Comp Engn Dept, POB 5969, Safat 13060, Kuwait.
EM m.alshayeji@ku.edu.kw; jassim.albuloushi@grad.ku.edu.kw;
   ali.ashkanani@grad.ku.edu.kw; s.abed@ku.edu.kw
RI Alshayeji, Mohammad/HIZ-5938-2022
OI Abed, Sa'ed/0000-0003-1849-9316
CR Abd-Ellah MK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0332-4
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Akram M. U., 2011, Proceedings of the 1st International Conference on Computer Networks and Information Technology (ICCNIT 2011), P299, DOI 10.1109/ICCNIT.2011.6020885
   Alshayeji MH, 2018, COMPUT ELECTR ENG, V71, P191, DOI 10.1016/j.compeleceng.2018.07.020
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Bankman I., 2008, HDB MED IMAGE PROCES
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Carneiro T, 2018, IEEE ACCESS, V6, P61677, DOI 10.1109/ACCESS.2018.2874767
   Chen X, 2018, LECT NOTES COMPUT SC, V11217, P674, DOI 10.1007/978-3-030-01261-8_40
   Cheng J, 2017, Dataset, DOI 10.6084002Fm9.figshare.1512427.v5
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Jannesari M, 2018, IEEE INT C BIOINFORM, P2405, DOI 10.1109/BIBM.2018.8621307
   Karako K, 2018, BIOSCI TRENDS, V12, P553, DOI 10.5582/bst.2018.01264
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   LAWS ER, 1993, CA-CANCER J CLIN, V43, P263, DOI 10.3322/canjclin.43.5.263
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   Othman M. F., 2011, 2011 Second International Conference on Intelligent Systems, Modelling and Simulation, P136
   Papanastasopoulos Z, 2020, EXPLAINABLE AL MED I, P52, DOI DOI 10.1117/12.2549298
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Pelikan M, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P525
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saraswathi Vishlavath, 2019, 2019 11th International Conference on Communication Systems & Networks (COMSNETS), P440, DOI 10.1109/COMSNETS.2019.8711010
   Schiff GD, 2008, AM J MED, V121, P38, DOI 10.1016/j.amjmed.2008.02.004
   Shallu, 2018, ICT EXPRESS, V4, P247, DOI 10.1016/j.icte.2018.10.007
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Wang G., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508369
NR 40
TC 14
Z9 14
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28897
EP 28917
DI 10.1007/s11042-021-10927-8
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661795800002
DA 2024-07-18
ER

PT J
AU Thakker, U
   Patel, R
   Shah, M
AF Thakker, Urvish
   Patel, Ruhi
   Shah, Manan
TI A comprehensive analysis on movie recommendation system employing
   collaborative filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Recommender systems; Movie recommendation
   system
ID AUTOENCODER
AB Collaborative Filtering (CF) is one of the most extensively used technologies for Recommender Systems (RS), it shows an improved intelligent searching mechanism for recommending personalized items. It effectively makes use of the information retained by the application to find similarities between the sections of the application. Apart from RS, other applications of CF making use of the sensing and monitoring of data are environmental sensing, mineral study, financial services, marketing, and many more. Different industries like Tourism, Television, E-Learning, etc. make use of this technology, software such as Customer Relationship Management also make use of this technology. This paper discusses the prowess CF algorithm and its applications for Movie Recommendation System (MRS). It gives a brief overview of collaborative filtering consisting of two major approaches: user-based approach and Item-based approaches. Further, in model-based filtering methodology, it is discussed how machine learning algorithms can be implemented for movie recommendation purposes and also to predict the ratings of the unrated movies and bifurcate or sort movies as per the user preference. Followed by, it throws some light on the methodologies used in the late past and some of the basic approaches that are taken into consideration to incorporate it into MSR. Additionally, this paper anatomized many of the recent past studies in depth to draw out the essence of the researches and studies, its crucial steps, results, future scope and methodologies, followed and suggested by multiple researchers. Finally, we have discussed various challenges in MRS and probable future developments in this field. It is to be noted that various challenges in the field of CF recommendation systems like cold start, data sparsity, scalability issues, etc. were raised and many approaches tried to tackle these challenges in innovative and novel ways. Conclusively CF algorithm is a highly efficacious technique for the application of MRS and its integration with other techniques will lead students, researchers and enthusiasts to more cogent approaches for MRS.
C1 [Thakker, Urvish; Patel, Ruhi] Nirma Univ, Dept Informat Technolgy, Ahmadabad, Gujarat, India.
   [Shah, Manan] Pandit Deendayal Energy Univ, Sch Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
C3 Nirma University; Pandit Deendayal Energy University
RP Shah, M (corresponding author), Pandit Deendayal Energy Univ, Sch Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
EM manan.shah@spt.pdpu.ac.in
RI Thakker, Urvish/JAS-1189-2023; Shah, Manan/Y-9430-2019
OI Shah, Manan/0000-0002-8665-5010
CR Aggarwal C C., 2016, Recommender Systems, P139
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   Al-Bashiri H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204434
   Alhijawi B., 2019, Proceedings of the 2019 3rd International Conference on Advances in Artificial Intelligence, P183, DOI DOI 10.1145/3369114.3369126
   Arora P., 2017, SEARCH ENGINE ARCHIT, P1
   Avery C, 1997, RECOM SYSTEM, V40, P88
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Banweer K, 2018, PROCEEDINGS OF THE 2ND ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON RECOMMENDATIONS FOR LOCATION-BASED SERVICES AND SOCIAL NETWORKS (LOCALREC 2018), DOI 10.1145/3282825.3282831
   Barla M., 2011, Information Sciences and Technologies Bulletin of the ACM Slovakia, V3, P52
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Billsus D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P46
   Biyun Hu, 2012, Web Technologies and Applications. Proceedings of the 14th Asia-Pacific Web Conference, APWeb 2012, P602, DOI 10.1007/978-3-642-29253-8_55
   Bobadilla J, 2012, INFORM PROCESS MANAG, V48, P204, DOI 10.1016/j.ipm.2011.03.007
   Breese J., 1998, P 14 C UNC ART INT, P43
   Cami BR, 2017, 2017 3RD IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P121, DOI 10.1109/ICSPIS.2017.8311601
   Campos PG, 2014, USER MODEL USER-ADAP, V24, P67, DOI 10.1007/s11257-012-9136-x
   Cao D., MOVIE RECOMMENDER SY, P427
   Chen HW, 2017, INT CONF MACH LEARN, P504
   Chen MH, 2015, ADV ENG INFORM, V29, P830, DOI 10.1016/j.aei.2015.04.005
   Chen VX, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (PRAI 2019), P12, DOI 10.1145/3357777.3357782
   Chen Y, 2016, COURSE SELECTION STU, P594, DOI [10.2991/emcs-16.2016.144, DOI 10.2991/EMCS-16.2016.144]
   Chen YC, 2021, J SUPERCOMPUT, V77, P244, DOI 10.1007/s11227-020-03266-2
   Cho Junghoo, 2004, WWW'04, Proceedings of the 13th international conference on World Wide Web, P20, DOI DOI 10.1145/988672.988676
   Christakou C, 2007, INT J ARTIF INTELL T, V16, P771, DOI 10.1142/S0218213007003540
   Chu-Hsing Lin, 2020, Advanced Information Networking and Applications. Proceedings of the 33rd International Conference on Advanced Information Networking and Applications (AINA-2019). Advances in Intelligent Systems and Computing (AISC 926), P895, DOI 10.1007/978-3-030-15032-7_75
   Claypool M., 1999, Combing content-based and collaborative filters in an online newspaper
   Cui G, 2018, INT J DIGIT EARTH, V11, P284, DOI 10.1080/17538947.2017.1326535
   Das D, 2018, ADV INTELL SYST, V710, P339, DOI 10.1007/978-981-10-7871-2_33
   De Vries AP.., 2006, DUCHENNE MUSCULAR DY, DOI [10.1145/1148170.1148257, DOI 10.1145/1148170.1148257]
   Deldjoo Y, 2019, USER MODEL USER-ADAP, V29, P291, DOI 10.1007/s11257-019-09221-y
   Devooght R.H. Bersini., 2016, Collaborative filtering with recurrent neural networks
   Ding, METHOD NEIGHBORHOOD
   Do MPT., 2010, P 6 INT C INF TECHN, P217
   Dou YT, 2016, INT CONF SEMANT, P40, DOI [10.1109/SKG.2016.014, 10.1109/SKG.2016.23]
   Fernández-Tobías I, 2016, USER MODEL USER-ADAP, V26, P221, DOI 10.1007/s11257-016-9172-z
   Ferwerda B, 2016, LECT NOTES ARTIF INT, V9853, P254, DOI 10.1007/978-3-319-46131-1_29
   Foster D. P., 1998, AAAI WORKSH REC SYST, P114
   Fragopoulou P., 2017, ACM INT C P SER, DOI [10.1145/3139367.3139383, DOI 10.1145/3139367.3139383]
   Gandhi S., 2018, P INT C CONV TECHN P 2018 3 INT C CONV TE, P1
   Gao C., 2017, P 13 WEB INF SYST AP, P51, DOI [10.1109/WISA.2016.20, DOI 10.1109/WISA.2016.20]
   Gao Fengrong, 2007, Tsinghua Science and Technology, V12, P1, DOI 10.1016/S1007-0214(07)70001-9
   Geetha G, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012101
   Ghazi MR, 2015, PROCEDIA COMPUT SCI, V48, P45, DOI 10.1016/j.procs.2015.04.108
   Gomez-Uribe CA, 2016, ACM TRANS MANAG INF, V6, DOI 10.1145/2843948
   Gorbunov RD, 2019, INTEGR COMPUT-AID E, V26, P185, DOI 10.3233/ICA-180590
   Grcar M, 2006, STUD CLASS DATA ANAL, P251, DOI 10.1007/3-540-34416-0_27
   Gurcan F, 2016, LECT NOTES ELECTR EN, V363, P159, DOI 10.1007/978-3-319-22635-4_14
   Hasan M, 2019, ICCAI '19 - PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE, P185, DOI 10.1145/3330482.3330518
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P241, DOI 10.1145/358916.358995
   Hill W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P194
   Himel MT, 2017, I C INF COMM TECH CO, P1302, DOI 10.1109/ICTC.2017.8190928
   Hsu C., 2015, 2 RELATED WORK 21 CO, P53
   Hu YT, 2020, NEUROCOMPUTING, V398, P485, DOI 10.1016/j.neucom.2019.03.098
   Huang Z., 2019, P 21 IEEE INT C HIGH, V5, P2559, DOI [10.1109/HPCC/900SmartCity/DSS.2019.00358, DOI 10.1109/HPCC/900SMARTCITY/DSS.2019.00358]
   Jafar O., EMERGING RS P IC 201
   Jain Kartik Narendra, 2018, Intelligent Computing and Information and Communication. Proceedings of 2nd International Conference, ICICC 2017. Advances in Intelligent Systems and Computing (AISC 673), P677, DOI 10.1007/978-981-10-7245-1_66
   Jing Jiang, 2011, Proceedings of the 2011 IEEE World Congress on Services (SERVICES 2011), P490, DOI 10.1109/SERVICES.2011.66
   Jones MT, 2013, RECOMMENDER SYSTEM 2, P1
   Kannan R, 2015, INFORM PROCESS MANAG, V51, P286, DOI 10.1016/j.ipm.2014.12.001
   Katarya R, 2017, EGYPT INFORM J, V18, P105, DOI 10.1016/j.eij.2016.10.002
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Kermarrec AM, 2010, LECT NOTES COMPUT SC, V6490, P48, DOI 10.1007/978-3-642-17653-1_4
   Kharita MK, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P340, DOI 10.1109/ICSCCC.2018.8703362
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Koohi H, 2016, MEASUREMENT, V91, P134, DOI 10.1016/j.measurement.2016.05.058
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kosir A., 2009, PERSONALITY BASED US
   Lee C, 2013, INT C BUS INF
   Lee D.-h., 2014, Proc. of IEEE Workshop on Signal Processing Systems (SiPS), P1
   Lekakos G, 2008, MULTIMED TOOLS APPL, V36, P55, DOI 10.1007/s11042-006-0082-7
   Li J, 2018, J COMPUT SCI-NETH, V26, P128, DOI 10.1016/j.jocs.2018.03.009
   Li Y, 2005, EXPERT SYST APPL, V28, P67, DOI 10.1016/j.eswa.2004.08.013
   Lim KH, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1778
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu GJ, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1461, DOI [10.1109/itnec.2019.8729076, 10.1109/ITNEC.2019.8729076]
   Liu HF, 2015, IEEE ACCESS, V3, P1695, DOI 10.1109/ACCESS.2015.2481320
   Lops P, 2019, USER MODEL USER-ADAP, V29, P239, DOI 10.1007/s11257-019-09231-w
   Maheswari M, 2019, CLUSTER COMPUT, V22, P12325, DOI 10.1007/s10586-017-1616-7
   Manjaiah, 2019, DATA MANAGEMENT ANAL
   Manjaiah DH., 2019, MOVIE RECOMMENDER SY, DOI [10.1007/978-981-13-1274-8_22, DOI 10.1007/978-981-13-1274-8_22]
   Moshfeghi Y, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P625
   Mu RH, 2020, KSII T INTERNET INF, V14, P2310
   Nugroho R., 2019, MOVIE RECOMMENDER SY, DOI [10.4108/eai.19-10-2018.2282541, DOI 10.4108/EAI.19-10-2018.2282541]
   Okyay, 2015, P AIEEE RIG LATV NOV, P1, DOI [10.1109/AIEEE.2015.7367282, DOI 10.1109/AIEEE.2015.7367282]
   Özbal G, 2011, COMPUT J, V54, P1535, DOI 10.1093/comjnl/bxr001
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Parapar J., USING GRAPH PARTITIO
   Patra S., 2019, J Oper Strateg Plan, V2, P22, DOI DOI 10.1177/2516600X19848956
   Pirasteh P, 2014, LECT NOTES ARTIF INT, V8398, P245, DOI 10.1007/978-3-319-05458-2_26
   PONNAM LT, 2016, 1 INT C EMERG TRENDS, P1, DOI DOI 10.1109/ICETETS.2016.7602983
   Purnomo JE, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2019), DOI 10.1109/icicos48119.2019.8982385
   Quynh HGE, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P154, DOI 10.1145/3380688.3380712
   Ranasinghe T., USER PROFILE FEATURE
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rich E., 1979, Cognitive Science, V3, P329, DOI [DOI 10.1016/S0364-0213, DOI 10.1207/S15516709COG0304_3, 10.1016/S0364-0213]
   Ruotsalo T, 2013, J WEB SEMANT, V20, P50, DOI 10.1016/j.websem.2013.03.001
   Sanchez J. L., 2008, Second IEEE International Conference on Digital Ecosystems and Technologies (IEEE DEST 2008), P432, DOI 10.1109/DEST.2008.4635147
   Schafer B.J., 2006, RES J APPL SCI ENG T, V5, P4168, DOI 10.19026/rjaset.5.4644
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Schwartz B., 2005, FINANCE, V265
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Sheugh L, 2015, 2015 AI & ROBOTICS (IRANOPEN)
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Shristi JAK., 2018, A collaborative filtering approach for movies recommendation based on user clustering and item clustering, DOI [10.1007/978-981-13-1813-9_19, DOI 10.1007/978-981-13-1813-9_19]
   Singh VK, 2011, LECT NOTES ARTIF INT, V7080, P38, DOI 10.1007/978-3-642-25725-4_4
   SongJie Gong, 2010, Journal of Software, V5, P745, DOI 10.4304/jsw.5.7.745-752
   Subramaniyaswamy V., 2017, International Journal of High Performance Computing and Networking, V10, P54
   Uyangoda Lasitha, 2018, 2018 Thirteenth International Conference on Digital Information Management (ICDIM), P24, DOI 10.1109/ICDIM.2018.8847002
   Vimala SV, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0708-9
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang L.C., 2011, J CONVERGENCE INF TE, V6, P339
   Wang Z, 2014, J VISUAL LANG COMPUT, V25, P667, DOI 10.1016/j.jvlc.2014.09.011
   Weber I, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P523
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Wu CS, 2018, INT CONF SOFTW ENG, P11, DOI 10.1109/ICSESS.2018.8663822
   Xiao P, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS, P349, DOI 10.1109/ISDEA.2013.483
   Yang CR, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1173, DOI 10.1145/3292500.3330909
   Yang Z, 2016, IEEE ACCESS, V4, P3273, DOI 10.1109/ACCESS.2016.2573314
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
   Zanitti M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1381, DOI 10.1145/3184558.3191580
   Zargany Ebtesam, 2015, International Journal of Electronic Finance, V8, P97
   Zhao DP, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P874, DOI 10.1109/CompComm.2016.7924828
   Zhou TQ, 2017, IEEE INT C COMPUT, P46, DOI 10.1109/CSE-EUC.2017.194
NR 132
TC 14
Z9 15
U1 21
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28647
EP 28672
DI 10.1007/s11042-021-10965-2
EA JUN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659016500001
DA 2024-07-18
ER

PT J
AU Al-Roithy, BO
   Gutub, A
AF Al-Roithy, Budoor Obid
   Gutub, Adnan
TI Remodeling randomness prioritization to boost-up security of RGB image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Pseudo random number generator (PRNG); Digital image;
   Image scrambling; Image shuffling
ID TRANSFORMATION
AB Securing information became essential to exchange multimedia information safely. The exchanged data need to be transformed in a well-managed, secure, and reliable manner. In this paper, we will focus on securing RGB images via cryptography during transmission among users using our effective proposal of utilizing appropriate Pseudo Random Number Generator (PRNG). We implement many techniques of PRNG involved in two consecutive crypto-processes of substitution and transposition to present secure image transformation. Our technique proposal of PRNGs selection is based on testing to encrypt RGB images to be compared with current related used approaches. The work experimentation aims to identify suitability and reliability through security measures standard parameters. The research justifies its proper PRNG selection to model our approach as attractive effective work worth remarking.
C1 [Al-Roithy, Budoor Obid; Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Al-Roithy,
   Budoor/0000-0002-9643-2873
FU Umm Al-Qura University
FX This work has been supported by Umm Al-Qura University. We thank our
   college of computer and information system for providing assistance to
   make this research possible.
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   Al-Otaibi N., 2014, LECT NOTES INFORM TH, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Roithy BO, 2020, INT J COMPUT SCI NET, V20, P167, DOI 10.22937/IJCSNS.2020.20.12.18
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   AlKhodaidi T, 2020, ARAB J SCI ENG, V45, P3403, DOI 10.1007/s13369-020-04422-9
   Altalhi S, 2021, J AMB INTEL HUM COMP, V12, P10209, DOI 10.1007/s12652-020-02789-z
   Andreatos AS, 2014, P MMCTSE MATH METH C, P146
   Anley C, 2007, WEAK RANDOMNESS PART
   [Anonymous], 2016, An Enhanced Least Significant Bit Steganography Technique
   Ayushi A., 2010, INT J COMPUT APP, V1, P1
   Bani MA., 2008, IJCSNS INT J COMPUT, V8, P191
   Banthia AK, 2013, INT J COMPUTERS APPL, V67
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Behnia S, 2013, J SYST SOFTWARE, V86, P2429, DOI 10.1016/j.jss.2013.04.088
   Bhattacharjee K, 2018, ARXIV PREPRINT ARXIV
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Ding Wei, 2001, Journal of Computer Aided Design & Computer Graphics, V13, P338
   Drutarovsky M., 2006, Journal of Electrical Engineering, V57, P218
   Easttom, 2017, GENERATING CRYPTOGRA, P22
   Elsayed M, INT J SIMUL SYST SCI, V19, P4
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fathi-Vajargah Behrouz, 2018, Journal of Computers, V13, P309, DOI 10.17706/jcp.13.3.309-326
   Fazal-E-Malik, 2011, Journal of Theoretical and Applied Information Technology, V34, P1
   Francois M, 2013, INFORMATICA-LITHUAN, V24, P181
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gashim Linda Lafta, 2018, [المجلة العراقية لتكنولوجيا المعلومات, Iraqi Journal of Information Technology, Al-Maǧallaẗ al-ʻiraqiyyaẗ li-tiknuluǧiya al-maʻlumat], V9, P1, DOI 10.34279/0923-009-002-001
   Gutub A, 2011, INT C SOFTW ENG COMP
   Gutub AAA, 2004, INTEGRATION, V37, P103, DOI 10.1016/j.vlsi.2003.12.001
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Haahr M., Introduction to randomness and random numbers
   Hassan M., 2012, International Journal of Computer Applications, V43, P7
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Janke W., 2002, LECT NOTES JOHN NEUM, V10, P447
   Kapur V., 2015, INT J COMPUT APPL, V115, P12
   Kelsey J, 1998, INT WORKSHOP FAST SO
   Kuo C-J, E MAIL JIMKUO AA NCT
   LI TY, 1975, AM MATH MON, V82, P985, DOI 10.2307/2318254
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Marsaglia G., 2000, Journal of statistical software, V5, P1, DOI [10.18637/jss.v005.i08, DOI 10.18637/JSS.V005.I08]
   Marsaglia George., 1991, ANN APPL PROBAB, V1, P462, DOI DOI 10.1214/A0AP/1177005878
   Mascagni M, 2004, PARALLEL COMPUT, V30, P899, DOI 10.1016/j.parco.2004.06.001
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Nasrullah, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101963
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Patidar V., 2009, Electronic Journal of Theoretical Physics, V20, P327
   Peterson G., 1997, ARNOLDS CAT MAP, V45, P1
   Preiss, 2015, THESIS TU
   Pu C, 2015, COMPUT MODEL NEW TEC, P489
   Rajkumar S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i47/105556, DOI 10.17485/IJST/2016/V9I47/105556]
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Ramesh A., 2015, 2015 INT C TRENDS AU, P1, DOI [10.1109/ITACT.2015.7492652, DOI 10.1109/ITACT.2015.7492652]
   ROHITH S, 2014, 2014 INT C ADV EL CO
   Saha S, 2018, IEEE INT C COMM SIGN
   Saito M, 2009, MONTE CARLO AND QUASI-MONTE CARLO METHODS 2008, P589, DOI 10.1007/978-3-642-04107-5_38
   Saputra I, 2017, IJICS INT J INF COMP, V1
   Sarma K, 2017, 2017 INT C CIRC POW
   Savvidy KG, 2015, COMPUT PHYS COMMUN, V196, P161, DOI 10.1016/j.cpc.2015.06.003
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shure SEaL, 2001, MATR IND MATLAB
   Sivakumar T., 2017, INT J COMPUTERS APPL, V975, P8887
   Som S, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON BUSINESS AND INFORMATION MANAGEMENT (ICBIM)
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
   Stinson D. R., 2018, Cryptography Theory and Practice
   Tomassini M., 2001, Applied Soft Computing, V1, P151, DOI 10.1016/S1568-4946(01)00015-1
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2011, ARXIV PREPRINT ARXIV
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yang YG, 2016, SCI REP-UK, V6, DOI 10.1038/srep20362
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yen K, 1996, INEFFECTIVENESS CORR
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang L, 2011, 2011 INT C MULT SIGN
   Zhang Q, 2012, SCI WORLD J, DOI 10.1100/2012/286741
   Zheng Fan, 2008, Journal of China Universities of Posts and Telecommunications, V15, P64, DOI 10.1016/S1005-8885(08)60109-0
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
NR 90
TC 24
Z9 24
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28521
EP 28581
DI 10.1007/s11042-021-11051-3
EA JUN 2021
PG 61
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658627400001
DA 2024-07-18
ER

PT J
AU Chen, TH
   Yan, JY
AF Chen, Tzung-Her
   Yan, Jing-Ya
TI Commutative encryption and authentication for OpenEXR high dynamic range
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range image; Image encryption; Image authentication;
   Commutative; OpenEXR
ID SCHEME
AB For the sake of image security, confidentiality and integrity are always the first two concerns and can be further guaranteed by image encryption and authentication techniques, respectively. However, traditional image encryption and authentication for low dynamic range (LDR) images are not suitable to protect high dynamic range (HDR) images directly. Thus, encryption and authentication of HDR images should be redesigned and tailor-made. In this paper, a commutative HDR image encryption and authentication scheme is proposed to protect the promising one of HDR image formats, i.e., OpenEXR. Each HDR pixel value, which is recorded by 16-bit half floating-point numbers in the chunks part of the OpenEXR file layout, is split into the confidentiality part and the integrity part of the images. The most significant part is encrypted for confidentiality and the least significant one is used to embed the authentication bits. The proposed scheme not only guarantees the confidentiality and integrity of HDR images but also achieves format-compliance. To the best of our knowledge, this is the first attempt of research in terms of commutative encryption and authentication to HDR images. It enables the convenience or flexibility of verifying the integrity before/after decryption such that the proposed scheme is practical in real applications. The experimental results and theoretical analyses demonstrate that the proposed scheme does work well.
C1 [Chen, Tzung-Her; Yan, Jing-Ya] Natl Chiayi Univ, Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Comp Sci & Informat Engn, Chiayi, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology of Taiwan [MOST 107-2221-E-415 -001
   -MY3]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under grant MOST 107-2221-E-415 -001 -MY3.
CR Anand A, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P159, DOI 10.1109/ICICCS.2016.7542294
   Autrusseau F, 2013, IEEE IMAGE PROC, P4527, DOI 10.1109/ICIP.2013.6738932
   Brooker D., 2012, ESSENTIAL CG LIGHTIN
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P145, DOI 10.1007/s11042-014-2279-5
   Chen T.-H., 2014, INT J ENG SCI, V4, P19
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Chen WH, 2016, IEEE T NEUR NET LEAR, V27, P2696, DOI 10.1109/TNNLS.2015.2512849
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Chin-Chen Chang, 2013, Journal of Electronic Science and Technology, V11, P20, DOI 10.3969/j.issn.1674-862X.2013.01.005
   Gong XH, 2020, MULTIMED TOOLS APPL, V79, P18071, DOI 10.1007/s11042-019-08594-x
   Guerrini F, 2011, IEEE T INF FOREN SEC, V6, P283, DOI 10.1109/TIFS.2011.2109383
   Heidrich Wolfgang, ERIK REINHARD
   Hoefflinger B, 2007, SPR SER ADV MICROELE, V26, P1, DOI 10.1007/978-3-540-44433-6
   Huang YY, 2020, IEEE ACCESS, V8, P135308, DOI 10.1109/ACCESS.2020.3011524
   Kahan W, 1996, IEEE STANDARD 754 BI, V754, P11
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Khurana M, 2020, MULTIMED TOOLS APPL, V79, P13967, DOI 10.1007/s11042-020-08658-3
   Kwon HJ, 2019, SIGNAL PROCESS-IMAGE, V70, P1, DOI 10.1016/j.image.2018.08.010
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Li MT, 2011, INT J INNOV COMPUT I, V7, P2021
   Li X, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2372473
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Lin K.-S., 2014, GENETIC EVOLUTIONARY, P183
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Mahmalat S, 2018, IEEE T CIRC SYST VID, V28, P3467, DOI 10.1109/TCSVT.2017.2758268
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Stallings W., 2013, Cryptography and network security: Principles and practice, V6th
   Stanczyk P, 2009, ISO 690, V21
   Voyatzis G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P237, DOI 10.1109/ICIP.1996.560753
   Ward G, 1991, REAL PIXELS GRAPHIC
   Yan J.Y., 2014, P 5 INT C SYST INN
   Yan JY, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P493, DOI 10.1109/IIH-MSP.2013.128
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
NR 38
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27807
EP 27828
DI 10.1007/s11042-021-11002-y
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000654112900001
DA 2024-07-18
ER

PT J
AU Chotikawanid, P
   Amornraksa, T
AF Chotikawanid, Piyanart
   Amornraksa, Thumrongrat
TI Color image watermarking based on reflectance component modification and
   guided image filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reflectance component; HSV color space; Image watermarking; Just
   noticeable difference (JND); Guided image filter; Blind watermark
   extraction
ID ROBUST
AB Digital images available on the Internet can be effortlessly copied and redistributed. Many image watermarking methods have been developed and are used as technical solutions to trace the ownership. Various watermark embedding and extraction techniques were considered and used in order to obtain reliable extraction and robustness against attacks. This paper presents a new color image watermarking method based on modification of the reflectance component in the Hue-Saturation-Value (HSV) color space. In the watermark embedding process, the reflectance component extracted from the S component is modified in accordance with Just Noticeable Difference (JND) thresholds derived from the V component. Guided image filtering is used in watermark extraction to predict the original reflectance component, and blind extraction is achieved by subtracting the predicted component from the watermarked one. The performances of five watermarking methods, including the proposed method, were evaluated and compared for accuracy and robustness at the equivalent quality of watermarked images. The results demonstrate that the proposed method provides an improved quality of extracted watermark by both objective and subjective quality measures. It is also more robust than the previous methods against various types of image processing based attacks, including the Stirmark benchmark.
C1 [Chotikawanid, Piyanart; Amornraksa, Thumrongrat] King Mongkuts Univ Technol Thonburi, Fac Engn, Multimedia Commun Lab, Comp Engn Dept, Bangkok, Thailand.
C3 King Mongkuts University of Technology Thonburi
RP Amornraksa, T (corresponding author), King Mongkuts Univ Technol Thonburi, Fac Engn, Multimedia Commun Lab, Comp Engn Dept, Bangkok, Thailand.
EM t_amomraksa@cpe.kmutt.ac.th
RI Chotikawanid, Piyanart/AAV-3726-2021
OI Chotikawanid, piyanart/0000-0001-6186-7626
FU Prince of Songkla University [70292/2557]
FX This research was financially supported by scholarship no. (70292/2557)
   from the Prince of Songkla University. We would like to thank Miss
   Thitiporn Pramoun and Miss Khirittha Thongkor for their fruitful
   discussions. The first author would like to thank Master Dhan and Mr.
   Teerasak Chotikawanid for their support, and Assoc. Prof. Dr. Seppo
   Karrila for proofreading this manuscript.
CR Abdallah HA, 2014, INFORM PROCESS MANAG, V50, P909, DOI 10.1016/j.ipm.2014.07.001
   Abdel-Aziz B, 2004, LECT NOTES COMPUT SC, V2939, P277
   Amornraksa T, 2006, IMAGE VISION COMPUT, V24, P111, DOI 10.1016/j.imavis.2005.09.018
   [Anonymous], 2009, PEARSON ED INDIA
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Guo JM, 2017, MULTIMED TOOLS APPL, V76, P9803, DOI 10.1007/s11042-016-3580-2
   Hanbury A, 2003, LECT NOTES COMPUT SC, V2749, P804
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Loukhaoukha K, 2016, INFORM PROCESS MANAG, V52, P644, DOI 10.1016/j.ipm.2015.12.009
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mettripun N, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033009
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Petitcolas F, 2019, INFORM HIDING HOMEPA
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Reed A, 2002, P SOC PHOTO-OPT INS, V4675, P222, DOI 10.1117/12.465279
   Shahamat H, 2014, J VIS COMMUN IMAGE R, V25, P970, DOI 10.1016/j.jvcir.2014.02.007
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Thanh TM, 2016, MULTIMED TOOLS APPL, V75, P11097, DOI 10.1007/s11042-015-2836-6
   Tu GJ, 2015, SENSORS-BASEL, V15, P21407, DOI 10.3390/s150921407
   Wang XC, 2020, VISUAL COMPUT, V36, P2201, DOI 10.1007/s00371-020-01909-2
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
NR 30
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27615
EP 27648
DI 10.1007/s11042-021-10756-9
EA MAY 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652940300003
DA 2024-07-18
ER

PT J
AU Mijwil, MM
AF Mijwil, Maad M.
TI Skin cancer disease images classification using deep learning solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Medical images; Skin Cancer; Classification; Machine
   learning; Convolutional neural network; Artificial intelligence
ID NEURAL-NETWORKS; DERMOSCOPY; MELANOMA
AB Skin cancer is a type of dangerous disease, and early detection is necessary to increases the survival rate. In recent years, deep learning models applied to computerized skin cancer discovery has become a standard. These models can improve their performance by being able to access more data and its main task is to the classification of images. This task is exceptionally valuable in the field of medicine, it has the ability to assist doctors and specialists to make the right decision and diagnose the patient's condition with high accuracy. In this paper, a deep learning network has been selected and trained by the author for the analysis of more than 24,000 skin cancer images by convolutional neural network (ConvNet) model applying with three architectures (InceptionV3, ResNet, and VGG19) with many parameters to identify the best architectures in the classification of these images and getting extremely acceptable results; and classifying the cancer type as benign or malignant with high accuracy. The dataset contains high-resolution images obtained from the ISIC archive between 2019 and 2020. After all the tests were done, the best architecture is InceptionV3. This architecture has achieved a diagnostic accuracy of approximately 86.90%, precision of 87.47%, sensitivity of 86.14%, and the specificity of 87.66%.
C1 [Mijwil, Maad M.] Baghdad Coll Econ Sci Univ, Comp Tech Engn Dept, Baghdad, Iraq.
C3 Baghdad College of Economic Science University
RP Mijwil, MM (corresponding author), Baghdad Coll Econ Sci Univ, Comp Tech Engn Dept, Baghdad, Iraq.
EM mr.maad.alnaimiy@baghdadcollege.edu.iq
RI Mijwil, Maad M./M-8031-2019
OI Mijwil, Maad M./0000-0002-2884-2504
CR Abbas Q, 2013, SKIN RES TECHNOL, V19, P314, DOI 10.1111/srt.12047
   Agilandeeswari L., 2019, INT J INNOV TECHNOL, V9, P2117, DOI [10.35940/ijitee.B7085.129219, DOI 10.35940/IJITEE.B7085.129219]
   Attaran Mohsen, 2018, International Journal of Knowledge Engineering and Data Mining, V5, P277
   Bajwa MN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072488
   Barbu T., 2003, P ROM AC A, V4, P143
   Basharpoora S, 2021, APPL NEUROPSYCH-ADUL, V28, P310, DOI 10.1080/23279095.2019.1632860
   Bomm L, 2013, AN BRAS DERMATOL, V88, P125, DOI 10.1590/S0365-05962013000100020
   Carcagnì P, 2019, LECT NOTES COMPUT SC, V11751, P335, DOI 10.1007/978-3-030-30642-7_30
   Carli P, 2003, BRIT J DERMATOL, V148, P981, DOI 10.1046/j.1365-2133.2003.05023.x
   Carrera C, 2016, JAMA DERMATOL, V152, P798, DOI 10.1001/jamadermatol.2016.0624
   Chang CW, 2018, INVENTIONS-BASEL, V3, DOI 10.3390/inventions3030041
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dascalu A, 2019, EBIOMEDICINE, V43, P107, DOI 10.1016/j.ebiom.2019.04.055
   Demir A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P533, DOI [10.1109/tiptekno47231.2019.8972045, 10.1109/CLEOE-EQEC.2019.8871518]
   Dinnes J, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011902.pub2
   Dirik AE, 2008, IEEE T INF FOREN SEC, V3, P539, DOI 10.1109/TIFS.2008.926987
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287
   Emuoyibofarhe J.O., 2020, Int. J. Inf. Eng. Electron. Bus., V12, P21, DOI DOI 10.5815/IJIEEB.2020.02.04
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Factors R, 2019, BASAL SQUAMOUS CELL
   Fujisawa Y, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00191
   Gandhi SA, 2015, MED CLIN N AM, V99, P1323, DOI 10.1016/j.mcna.2015.06.002
   Gómez DD, 2008, IEEE T BIO-MED ENG, V55, P157, DOI 10.1109/TBME.2007.910651
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Haenssle HA, 2018, ANN ONCOL, V29, P1836, DOI 10.1093/annonc/mdy166
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Harrison SC, 2009, SPORTS HEALTH, V1, P335, DOI 10.1177/1941738109338923
   Hekler A, 2019, EUR J CANCER, V118, P91, DOI 10.1016/j.ejca.2019.06.012
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hoeser T, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101667
   Hordri N. F., 2016, P C POSTGR ANN RES I, P1
   Jacob S.a., 2012, training, V4
   Jianli Feng, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022030
   Julian CG, 1999, BRIT J DERMATOL, V141, P518
   Kalouche S., 2016, MEDICINE, V1, P1
   Kato J, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00180
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Kerr OA, 2010, CLIN EXP DERMATOL, V35, P380, DOI 10.1111/j.1365-2230.2009.03586.x
   Kharazmi P, 2017, IEEE J BIOMED HEALTH, V21, P1675, DOI 10.1109/JBHI.2016.2637342
   Kia S, 2019, J APPL CLIN MED PHYS, V20, P153, DOI 10.1002/acm2.12671
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Luo G, 2015, HEALTH INF SCI SYST, V3, DOI 10.1186/s13755-015-0011-0
   Masood A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/323268
   Munir K, 2019, CANCERS, V11, DOI 10.3390/cancers11091235
   Nada E., 2017, AL AZHAR ASSIUT MED, V15, P203, DOI [10.4103/AZMJ.AZMJ_67_17, DOI 10.4103/AZMJ.AZMJ_67_17, 10.4103/azmj.azmj_67_17]
   Nahata Hardik., 2020, Machine Learning with Health Care Perspective: Machine Learning and Healthcare, P159, DOI [DOI 10.1007/978-3-030-40850-3_8, 10.1007/978-3-030-40850-3_8]
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nath RP, 2011, IOSR J COMPUTER ENG, P01
   Phillips M, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.13436
   Ramya M., 2018, Int. J. Eng. Technol, V7, P717, DOI DOI 10.14419/IJET.V7I2.7.10930
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Sahin ÜA, 2011, ATMOS RES, V101, P314, DOI 10.1016/j.atmosres.2011.03.005
   Sarvepalli S K., 2015, Out. de, DOI DOI 10.13140/RG.2.2.22512.71682
   Shaikhina Torgyn, 2015, IFAC - Papers Online, V48, P469, DOI 10.1016/j.ifacol.2015.10.185
   Silpa SR., 2013, Int Res J Pharm, V4, P83, DOI [DOI 10.7897/2230-8407.04814, 10.7897/2230-8407, DOI 10.7897/2230-8407]
   Sivadasan B., 2018, P NATL C EMERGING RE, VERTEE-2018, P105
   Sozontov Andrey, 2019, E3S Web of Conferences, V114, DOI 10.1051/e3sconf/201911401009
   Vijayalakshmi M., 2019, Int J Trend Sci Res Dev, V3, P780
   Wang L., 2015, Computer Engineering and Applications Journal, V4, P143
   Whiteman DC, 2016, J INVEST DERMATOL, V136, P1161, DOI 10.1016/j.jid.2016.01.035
   Wu SW, 2017, JNCI-J NATL CANCER I, V109, DOI 10.1093/jnci/djw268
   Xie FY, 2013, PATTERN RECOGN, V46, P1012, DOI 10.1016/j.patcog.2012.08.012
   Xu YQ, 2019, ENERGIES, V12, DOI 10.3390/en12214128
   Yang J, 2018, ALGORITHMS, V11, DOI 10.3390/a11030028
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang L, 2020, OPEN MED-WARSAW, V15, P27, DOI 10.1515/med-2020-0006
   Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004
NR 72
TC 34
Z9 36
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26255
EP 26271
DI 10.1007/s11042-021-10952-7
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645497000001
DA 2024-07-18
ER

PT J
AU Alghamdi, RS
   Alshehri, NO
AF Alghamdi, Rania S.
   Alshehri, Noura O.
TI Fusion of infrared and visible images using neutrosophic fuzzy sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neutrosophic fuzzy sets; Neutrosophic fuzzy image; Image fusion;
   Infrared and visible images
ID MULTISCALE-DECOMPOSITION; PERFORMANCE; TRANSFORM; WAVELET; LIGHT
AB Fusion of infrared and visible image is a technology which combines information from two different sensors for the same scene. It also gives extremely effective information complementation, which is widely used for the monitoring systems and military fields. Due to limited field depth in an imaging device, visible images can't identify some targets that may not be apparent due to poor lighting conditions or because that the background color is similar to the target. To deal with this problem, a simple and efficient image fusion approach of infrared and visible images is proposed to extract target's details from infrared images and enhance the vision in order to improve the performance of monitoring systems. This method depends on maximum and minimum operations in neutrosophic fuzzy sets. Firstly, the image is transformed from its spatial domain to the neutrosophic domain which is described by three membership sets: truth membership, indeterminacy membership, and falsity membership. The indeterminacy in the input data is handled to provide a comprehensive fusion result. Finally, deneutrosophicised process is made which means that the membership values are retransformed into a normal image space. At the end of the study, experimental results are applied to evaluate the performance of this approach and compare it to the recent image fusion methods using several objective evaluation criteria. These experiments demonstrate that the proposed method achieves outstanding visual performance and excellent objective indicators.
C1 [Alghamdi, Rania S.] King Abdulaziz Univ, Fac Sci, Dept Math, POB 21323, Jeddah 21589, Saudi Arabia.
   [Alghamdi, Rania S.; Alshehri, Noura O.] Univ Jeddah, Fac Sci, Dept Math, POB 80327, Jeddah 21589, Saudi Arabia.
C3 King Abdulaziz University; University of Jeddah
RP Alghamdi, RS (corresponding author), King Abdulaziz Univ, Fac Sci, Dept Math, POB 21323, Jeddah 21589, Saudi Arabia.; Alghamdi, RS (corresponding author), Univ Jeddah, Fac Sci, Dept Math, POB 80327, Jeddah 21589, Saudi Arabia.
EM rsaalghamdi@kau.edu.sa; noal-shehri@uj.edu.sa
RI Alshehri, Noura/C-6991-2013
OI Alghamdi, R. S./0000-0001-6313-6376
CR Bavirisetti D.P., 2017, P INT C INF FUS, P1
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Cheng HD, 2008, NEW MATH NAT COMPUT, V4, P291, DOI 10.1142/S1793005708001082
   Choi M, 2005, IEEE GEOSCI REMOTE S, V2, P136, DOI 10.1109/LGRS.2005.845313
   Guo YH, 2009, NEW MATH NAT COMPUT, V5, P653, DOI 10.1142/S1793005709001490
   Guo YH, 2009, PATTERN RECOGN, V42, P587, DOI 10.1016/j.patcog.2008.10.002
   Kong WW, 2014, INFRARED PHYS TECHN, V67, P161, DOI 10.1016/j.infrared.2014.07.019
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu YP, 2014, SIGNAL PROCESS, V97, P9, DOI 10.1016/j.sigpro.2013.10.010
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Rajkumar S, 2014, ADV INTELL SYST, V248, P93, DOI 10.1007/978-3-319-03107-1_11
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Sharma R., 2016, IOSR J COMPUT ENG, V18, P32
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Smarandache F., 1998, Neutrosophy: Neutrosophic Probability, Set, and Logic: Analytic Synthesis & Synthetic Analysis, V1st ed.
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang XY, 2017, J OPT SOC AM A, V34, P1400, DOI 10.1364/JOSAA.34.001400
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   Zhao JF, 2017, INFRARED PHYS TECHN, V81, P201, DOI 10.1016/j.infrared.2017.01.012
   Zhao JF, 2014, INFRARED PHYS TECHN, V62, P86, DOI 10.1016/j.infrared.2013.11.008
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
NR 30
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25927
EP 25941
DI 10.1007/s11042-021-10911-2
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643591800001
DA 2024-07-18
ER

PT J
AU Thapa, A
   Alsadoon, A
   Prasad, PWC
   Dawoud, A
   Alrubaie, A
AF Thapa, Ashutosh
   Alsadoon, Abeer
   Prasad, P. W. C.
   Dawoud, Ahmed
   Alrubaie, Ahmad
TI A novel augmented reality for hidden organs visualisation in surgery:
   enhanced super-pixel with sub sampling and variance adaptive algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Reconstruction; Super-pixel refinement; Segmentation;
   Registration; Depth perception
ID REGISTRATION; RECONSTRUCTION; IMAGE
AB In recent years, Augmented Reality (AR) has gained more attention as an effective tool in medical surgeries. The potentials of using AR in the medical field can change conventional medical procedures. However, the technology still facing fundamental challenges, especially hidden organs, for example, the organs behind the bowel and liver. The surgeries in these areas lack accuracy in the visualization of the soft tissues behind the bowel and liver like the uterus and gall bladder. This research aims to improve the accuracy of visualisation and the processing time of the augmented video. The proposed system consists of an enhanced super-pixel algorithm with variance weight adaptation and subsampling method. The simulation studies show significant improvements in visualization accuracy and a reduction in processing time. The results show reduced visualisation error by 0.23 mm. It provides better accuracy of the video in terms of visualization error from 1.58 similar to 1.83 mm to 1.35 similar to 1.60 mm, and the processing time decreases from 50 similar to 58 ms/frames to 40 similar to 48 ms/frames. The proposed system \ focused on the pixel refinement for the 3d reconstruction of the soft tissue, which helps solve the issue of visualising the bowel and liver in an augmented video.
C1 [Thapa, Ashutosh; Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; University of New
   South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Dawoud, Ahmed/AAD-1295-2022; Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Dawoud,
   Ahmed/0000-0002-2051-5920; withana, chandana/0000-0002-3007-687X
CR Aarts JWM, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003677.pub5
   Akladios C, 2019, SURG ENDOSC
   Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bernhardt S, 2016, MED IMAGE ANAL, V30, P130, DOI 10.1016/j.media.2016.01.008
   Chen L, 2018, COMPUT METH PROG BIO, V158, P135, DOI 10.1016/j.cmpb.2018.02.006
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   Haddad, 2019, NOVEL NAVIGATION ALG
   Haouchine N, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P495, DOI 10.1109/IROS.2016.7759099
   Kalinin P, 2015, COMPUT VIS IMAGE UND, V130, P80, DOI 10.1016/j.cviu.2014.09.007
   Kou F, 2016, C IND ELECT APPL, P1671, DOI 10.1109/ICIEA.2016.7603854
   Liu J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219174
   Mahmoud N, 2019, IEEE T MED IMAGING, V38, P79, DOI 10.1109/TMI.2018.2856109
   Menhaj MB, 2016, NONLOCAL MEANS APPRO
   Modat M, 2010, COMPUT METH PROG BIO, V98, P278, DOI 10.1016/j.cmpb.2009.09.002
   Montiel, 2017, SLAM BASED QUASIDENS
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nicolau SA, 2009, MED IMAGE ANAL, V13, P494, DOI 10.1016/j.media.2009.02.003
   Özgür E, 2018, INT J COMPUT ASS RAD, V13, P1629, DOI 10.1007/s11548-018-1842-3
   Penza V, 2016, INT J COMPUT ASS RAD, V11, P197, DOI 10.1007/s11548-015-1276-0
   Peterlík I, 2018, MED IMAGE ANAL, V45, P24, DOI 10.1016/j.media.2017.12.006
   Reichard D, 2017, INT J COMPUT ASS RAD, V12, P1101, DOI 10.1007/s11548-017-1613-6
   Suwelack S, 2014, MED PHYS, V41, DOI 10.1118/1.4896021
   Wang H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9030031
   Wang R, 2017, DISPLAYS, V48, P50, DOI 10.1016/j.displa.2017.03.003
   Wang YY, 2018, COMP M BIO BIO E-IV, V6, P182, DOI 10.1080/21681163.2016.1197798
   Weon C, 2017, MED PHYS, V44, P5824, DOI 10.1002/mp.12524
   Yu F, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0992-8
   Zhang XH, 2019, INT J COMPUT ASS RAD, V14, P1285, DOI 10.1007/s11548-019-01974-6
   Zou HX, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071107
NR 30
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25411
EP 25432
DI 10.1007/s11042-021-10869-1
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600002
DA 2024-07-18
ER

PT J
AU Di, YD
   Zhu, XK
   Jin, X
   Dou, QW
   Zhou, W
   Duan, Q
AF Di, Yide
   Zhu, Xiaoke
   Jin, Xin
   Dou, Qiwei
   Zhou, Wei
   Duan, Qing
TI Color-UNet plus plus : A resolution for colorization of grayscale images
   using improved UNet plus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colorization; Deep learning; Convolutional netural network; Image
   processing
AB Colorization is the computer-assisted application of color to a gray scale image, which presents two problems to modern deep learning-based approaches. One is to provide colorization models with both high expressibility and strong learning ability, as current models have difficulty both excelling at coloring and being easy to train. The other is to return a picture without uneven overlap. This paper proposes a deep convolutional network framework called Color-UNet++ for the end-to-end solution of these colorization problems. Color-UNet++ is adjusted to settle gradient dispersion and explosion by capturing more transfer and intermediate results during backpropagation. We adjust the de-convolution structure to solve the problem of uneven overlap. We design the model in YUV instead of RGB color space, with an objective function that is appropriate to the coloring problem and can capture a wide range of colors. A large number of experimental results on LFW and LSUN datasets confirm the method's superiority.
C1 [Di, Yide; Zhu, Xiaoke; Jin, Xin; Dou, Qiwei; Zhou, Wei; Duan, Qing] Yunnan Univ, Natl Pilot Sch Software, Kunming, Yunnan, Peoples R China.
   [Jin, Xin; Zhou, Wei; Duan, Qing] Yunnan Univ, Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
C3 Yunnan University; Yunnan University
RP Duan, Q (corresponding author), Yunnan Univ, Natl Pilot Sch Software, Kunming, Yunnan, Peoples R China.; Duan, Q (corresponding author), Yunnan Univ, Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
EM ghostdyd@126.com; qduan@ynu.edu.cn
RI jin, xin/GQZ-5811-2022; ZHOU, WEI/HNP-4799-2023
OI Di, Yide/0000-0003-3802-6620
FU National Natural Science Foundation of China [61762089, 61663047,
   61863036, 61762092, 62002313]; Key Areas Research Program of Yunnan
   Province [202001BB050076]; Yunnan Applied Basic Research Projects
   [202001BB050034]; Open Foundation of Key Laboratory in Software
   Engineering of Yunnan Province [2020SE307, 2020SE408]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61762089, Grant 61663047, Grant
   61863036, Grant 61762092, and 62002313, Key Areas Research Program of
   Yunnan Province under Grant No.202001BB050076 and the Yunnan Applied
   Basic Research Projects under Grant No.202001BB050034. The Open
   Foundation of Key Laboratory in Software Engineering of Yunnan Province
   under Grant No.2020SE307 and No. 2020SE408.
CR [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Aoki T, 2016, AUTOMATIC IMAGE COLO
   Bao B, 2019, COMPUT GRAPH-UK, V81, P73, DOI 10.1016/j.cag.2019.04.003
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Cao Y, 2017, LECT NOTES ARTIF INT, V10534, P151, DOI 10.1007/978-3-319-71249-9_10
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Efros AA, 2017, COLORIZE PHOTOS
   Fang FM, 2020, IEEE T VIS COMPUT GR, V26, P2931, DOI 10.1109/TVCG.2019.2908363
   Huang G. B., 2012, NIPS
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kuzovkin D, 2015, LECT NOTES COMPUT SC, V9016, P59, DOI 10.1007/978-3-319-15979-9_6
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2019, IEEE T IMAGE PROCESS, V28, P4606, DOI 10.1109/TIP.2019.2912291
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Limmer M, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P61, DOI [10.1109/ICMLA.2016.0019, 10.1109/ICMLA.2016.114]
   Luan Q., 2007, Proceedings of the 18th Eurographics conference on Rendering Techniques, P309
   Morimoto Y, 2009, SIGGRAPH 2009 TALKS
   Nazeri Kamyar, 2018, AMDO 2018. Lecture Notes in Computer Science, P85, DOI DOI 10.1007/978-3-319-94544-6_9
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Roohi S, 2019, ENTERTAIN COMPUT, V30, DOI 10.1016/j.entcom.2019.100298
   Thibault M, 2018, COLORUNET CONVOLUTIO
   Varga D, 2017, LECT NOTES COMPUT SC, V10424, P184, DOI 10.1007/978-3-319-64689-3_15
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yu F., 2015, abs/1506.03365
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 36
TC 9
Z9 9
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35629
EP 35648
DI 10.1007/s11042-021-10830-2
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000635061800002
DA 2024-07-18
ER

PT J
AU Yang, J
   Qiu, K
AF Yang, Jin
   Qiu, Kai
TI An improved segmentation algorithm of CT image based on U-Net network
   and attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT image segmentation; U-Net network structure; Batch standardization
   layer; Attention mechanism; Cross entropy loss functions; Dice
   coefficient
AB Medical image segmentation is one of the important steps in clinical diagnosis, and accurate segmentation of lesions is of great significance to clinical treatment. Therefore, a CT image segmentation algorithm based on depth learning is proposed to solve the problems of poor robustness, weak anti noise ability and low segmentation accuracy of existing image segmentation algorithms.. Firstly, we improve the u-net network structure, increase the batch standardization layer to improve the robustness of the network model, and introduce the attention mechanism to focus on specific things according to the needs, improve the recognition ability of the model. Then, the improved U-Net network structure is applied to CT image segmentation, and the cross entropy loss function is used to reduce the possibility of insufficient segmentation and segmentation leakage, and improve the accuracy of image segmentation. Finally, on the basis of data preprocessing, the segmentation network is trained to get the image segmentation model based on deep learning, and the prediction is made on the test set to get the segmentation results. The experimental results show that compared with other algorithms, the proposed method achieves 0.9594 in the common evaluation standard Dice coefficient, and has strong robustness. It can accurately segment the lung organs in CT images, which is helpful for doctors to obtain pathological information and assist in the diagnosis of lung diseases.
C1 [Yang, Jin] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Yang, Jin; Qiu, Kai] Changsha Social Work Coll, Informat Ctr, Changsha 410004, Hunan, Peoples R China.
C3 Central South University; Changsha Social Work College
RP Yang, J (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.; Yang, J (corresponding author), Changsha Social Work Coll, Informat Ctr, Changsha 410004, Hunan, Peoples R China.
EM yangjin@csu.edu.cn; 1300003@csmzxy.edu.cn
FU National Science and Technology Support Program [2015BAH05F00]
FX This work was supported by the National Science and Technology Support
   Program (No. 2015BAH05F00).
CR Chaitanya Kaul, 2019, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), P455, DOI 10.1109/ISBI.2019.8759477
   Chen CM, 2020, ENTERP INF SYST-UK, V14, P159, DOI 10.1080/17517575.2019.1575985
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Duan JM, 2019, IEEE T MED IMAGING, V38, P2151, DOI 10.1109/TMI.2019.2894322
   Gupta KK., 2018, 2018 4 INT C COMPUT, P1, DOI DOI 10.1109/CCAA.2018.8777561
   Harouni A, 2018, I S BIOMED IMAGING, P872, DOI 10.1109/ISBI.2018.8363710
   Ji X, 2018, 2018 11 INT C IM SIG, P1, DOI [10.1109/CISP-BMEI.2018.8633257, DOI 10.1109/CISP-BMEI.2018.8633257]
   Li AJ, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P470, DOI 10.1109/CISP.2015.7407926
   Lian J, 2019, NEUROCOMPUTING, V333, P292, DOI 10.1016/j.neucom.2018.12.007
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nguyen TT, 2019, PATTERN RECOGN LETT, V117, P97, DOI 10.1016/j.patrec.2018.12.009
   Nie D, 2019, IEEE T CYBERNETICS, V49, P1123, DOI 10.1109/TCYB.2018.2797905
   Ramu SM, 2019, MULTIMED TOOLS APPL, V78, P21391, DOI 10.1007/s11042-019-7328-7
   Rebouças PP, 2019, APPL SOFT COMPUT, V76, P649, DOI 10.1016/j.asoc.2018.10.057
   Sudha S, 2019, TENCON IEEE REGION, P767, DOI [10.1109/TENCON.2019.8929648, 10.1109/tencon.2019.8929648]
   TengkuAlang TAI, 2016, 2016 INT C ROB AUT S, P1, DOI [10.1109/ICORAS.2016.7872623, DOI 10.1109/ICORAS.2016.7872623]
   van Opbroek A, 2019, IEEE T MED IMAGING, V38, P213, DOI 10.1109/TMI.2018.2859478
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P10393, DOI 10.1007/s11042-016-4222-4
   Wang Y, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS 2019), P15, DOI 10.1109/ICoIAS.2019.00009
   Yang X, 2019, IEEE T MED IMAGING, V38, P180, DOI 10.1109/TMI.2018.2858779
   Yu, 2015, IEEE-CAA J AUTOMATIC, V2, P159
   [张天驰 Zhang Tianchi], 2019, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V40, P338
   Zhou YF, 2019, FRESEN ENVIRON BULL, V28, P9906
NR 25
TC 11
Z9 11
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35983
EP 36006
DI 10.1007/s11042-021-10841-z
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000635488800003
DA 2024-07-18
ER

PT J
AU Qaisar, ZH
   Li, RX
AF Qaisar, Zahid Hussain
   Li, Ruixuan
TI Multimodal information fusion for android malware detection using lazy
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal fusion; Malware detection; Lazy learning; Case-based
   reasoning; Android security
ID MOBILE MULTIMEDIA APPLICATIONS; ATTACKS
AB Android has a large number of users that are accumulating with each passing day. Security of the Android ecosystem is a major concern for these users with the provision of quality services. In this paper, multimodal analysis of malware apps has been presented. We exploit static, dynamic, and visual features of apps to predict the malicious apps using information fusion. The proposed study applies case-based reasoning; for catalyzing the process of training and validation over renowned datasets with enriched feature-set. Our proposed semi-supervised technique uses benign and malicious apps to predict and classify malware. The prediction process uses a hybrid analysis of malware. The proposed approach, due to the efficient and adaptive nature of CBR, outperforms prevalent approaches. Our approach has an accuracy of 95% and reduced rate of false negative rate and a better precision metric, which beat the state-of-the-art techniques.
C1 [Qaisar, Zahid Hussain; Li, Ruixuan] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology
RP Qaisar, ZH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM zahidqaisar@hust.edu.cn
RI Wang, Shan/JPX-1098-2023
CR Adebayo OS, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2850932
   Allix K, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P468, DOI [10.1145/2901739.2903508, 10.1109/MSR.2016.056]
   [Anonymous], 2013, Inter- national Journal of Scientific and Technology Research
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Aswini AM, 2014, LECT NOTES COMPUT SC, V8804, P303, DOI 10.1007/978-3-319-12060-7_20
   Bai H, 2020, IEEE ACCESS
   Bakour K, 2021, NEURAL COMPUT APPL, V33, P3133, DOI 10.1007/s00521-020-05195-w
   Bhuiyan FA, 2020, 33 INT FLAIRS C
   Coban O, 2019, COMPUTER SCI, V20
   Gandotra E, 2017, CYBERNET SYST, V48, P29, DOI 10.1080/01969722.2016.1262704
   Gibert D, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101873
   Hernandez Jimenez Jarilyn M., 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P1383, DOI 10.1007/978-3-030-44041-1_117
   Huanyu Wu, 2020, ICSCA 2020: Proceedings of the 2020 9th International Conference on Software and Computer Applications, P177, DOI 10.1145/3384544.3384546
   Jeong ES, 2017, MULTIMED TOOLS APPL, V76, P18153, DOI 10.1007/s11042-016-4189-1
   Karbab EB, 2020, COMPUT SECUR, V96, DOI 10.1016/j.cose.2020.101932
   Kim T, 2019, IEEE T INF FOREN SEC, V14, P773, DOI 10.1109/TIFS.2018.2866319
   Kiss N, 2016, LASER WORKSH LEARN A, P1
   Krutz DE, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), P522, DOI 10.1109/MSR.2015.79
   Kumar Ajit., 2016, 2016 10th international conference on intelligent systems and control (ISCO), P1, DOI DOI 10.1109/ISCO.2016.7726949
   Kumar R, 2019, IEEE ACCESS, V7, P64411, DOI 10.1109/ACCESS.2019.2916886
   Lakovic V, 2020, ANN DATA SCI, P1
   Lashkari AH, 2018, INT CARN CONF SECU, P242
   Lee CH, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113062
   Li J, 2018, IEEE T IND INFORM, V14, P3216, DOI 10.1109/TII.2017.2789219
   Li O, 2018, AAAI CONF ARTIF INTE, P3530
   Maiorca D, 2015, COMPUT SECUR, V51, P16, DOI 10.1016/j.cose.2015.02.007
   McGiff J, 2019, INT CONF COMPUT NETW, P432, DOI [10.1109/ICCNC.2019.8685502, 10.1109/iccnc.2019.8685502]
   Millar S, 2020, PROCEEDINGS OF THE TENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, CODASPY 2020, P353, DOI 10.1145/3374664.3375746
   Niu WN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133645
   Pan Y, 2020, IEEE ACCESS, V8, P116363, DOI 10.1109/ACCESS.2020.3002842
   Sangal Aviral, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P48, DOI 10.1109/ICOSEC49089.2020.9215355
   Souri A, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0125-x
   Soviany S, 2018, 2018 IEEE 16TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (EUC 2018), P14, DOI 10.1109/EUC.2018.00010
   Spreitzenbarth M., 2013, P 28 ANN ACM S APPL, DOI [DOI 10.1145/2480362.2480701, 10.1145/2480362.2480701]
   Sun Y, 2019, 3 INT C MECH ENG INF
   Wu LF, 2014, IEEE COMMUN MAG, V52, P80, DOI 10.1109/MCOM.2014.6766089
   Yen YS, 2019, MICROELECTRON RELIAB, V93, P109, DOI 10.1016/j.microrel.2019.01.007
   Zaw SK, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/7198435
   Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16
   Zhu D., 2020, IEEE SYMP COMP COMMU, P1, DOI [10.1109/ISCC50000.2020.9219652, DOI 10.1109/iscc50000.2020.9219652]
   Zhu DL, 2019, MSWIM'19: PROCEEDINGS OF THE 22ND INTERNATIONAL ACM CONFERENCE ON MODELING, ANALYSIS AND SIMULATION OF WIRELESS AND MOBILE SYSTEMS, P51, DOI 10.1145/3345768.3355915
NR 41
TC 9
Z9 9
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12077
EP 12091
DI 10.1007/s11042-021-10749-8
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000635061900006
DA 2024-07-18
ER

PT J
AU Harizi, R
   Walha, R
   Drira, F
   Zaied, M
AF Harizi, Riadh
   Walha, Rim
   Drira, Fadoua
   Zaied, Mourad
TI Convolutional neural network with joint stepwise character/word modeling
   based system for scene text recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Data Paper
DE Scene text; Text recognition; Deep learning; Linguistic verification
ID IMAGES; LINE
AB Text recognition in the wild is a challenging task in the field of computer vision and machine learning. Existing optical character recognition engines cannot perform well in the natural scene. In this context, deep learning models have emerged as a powerful state-of-the-art technique in the classification and recognition process. This study proposes a new Convolutional Neural Network based system for scene text reading. We investigate how to combine the character recognition module followed by the word recognition module to achieve the overall system goal. The first module analyzes characters within multi-scale images by relaying on the power of the convolutional network and the fully connected network for character recognition. The second module relies on the Viterbi search to find the closest word to a given characters sequence. For the sake of more precision, a bigram based linguistic module is applied. The proposed system achieves the state-of-the-art performance on three standard scene text recognition benchmarks: chars74k, ICDAR 2003 and ICDAR 2013. In particular, this performance is proven on both of character and word recognition accuracy as well as speed aspects via a comparative study between different deep learning architectures.
C1 [Harizi, Riadh; Walha, Rim; Drira, Fadoua] Univ Sfax, REGIM Lab, ENIS, BP 1173, Sfax 3038, Tunisia.
   [Zaied, Mourad] Univ Gabes, Res Team Intelligent Machines, ENIG, Gabes, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Gabes
RP Walha, R (corresponding author), Univ Sfax, REGIM Lab, ENIS, BP 1173, Sfax 3038, Tunisia.
EM riadh.harizi@isimg.tn; rim.walha@isims.usf.tn; fadoua.drira@ieee.org;
   mourad.zaied@ieee.org
RI harizi, riadh/IQT-8744-2023; WALHA, RIM/D-9499-2013; Harizi,
   Riadh/JXM-5960-2024
OI Walha, Rim/0000-0002-0483-6329; Harizi, Riadh/0000-0003-4096-8959;
   DRIRA, Fadoua/0000-0001-6706-4218
FU Ministry of Higher Education and Scientific Research
FX This work was carried out with the support of the Ministry of Higher
   Education and Scientific Research and within the framework of
   Tunisian-Indian cooperation in the field of scientific research and
   technology.
CR Ahmed SB, 2020, TEXT WILD ITS CHALLE, P13, DOI [10.1007/978-981-15-1297-1-2, DOI 10.1007/978-981-15-1297-1-2]
   Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   [Anonymous], 2018, ABS181104256 CORR
   Arafat SY, 2020, IEEE ACCESS, V8, P96787, DOI 10.1109/ACCESS.2020.2994214
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Bhunia AK, 2018, MULTIMED TOOLS APPL, V77, P8551, DOI 10.1007/s11042-017-4750-6
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335
   Chen XX, 2020, NEUROCOMPUTING, V381, P261, DOI 10.1016/j.neucom.2019.11.049
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   El Bahi H, 2019, MULTIMED TOOLS APPL, V78, P26453, DOI 10.1007/s11042-019-07855-z
   Elagouni K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P120, DOI 10.1109/DAS.2012.26
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Goel V, 2013, PROC INT CONF DOC, P398, DOI 10.1109/ICDAR.2013.87
   Gómez L, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P192, DOI 10.1109/DAS.2016.64
   Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914
   Guemri K, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P174, DOI 10.5220/0006129001740181
   Hassaballah M., 2019, Recent advances in computer vision: theories and applications, P113, DOI DOI 10.1007/978-3-030-03000-1
   Hassaballah M., 2020, DEEP LEARNING COMPUT, V1st, DOI [10.1201/9781351003827, DOI 10.1201/9781351003827]
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Lecun Y, 2007, PROC INT CONF DOC, P337
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu XH, 2016, INT C PATT RECOG, P3999, DOI 10.1109/ICPR.2016.7900259
   Liu XH, 2016, INT CONF ACOUST SPEE, P1322, DOI 10.1109/ICASSP.2016.7471891
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mallek A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P243, DOI 10.5220/0006129102430250
   Mishra A., 2012, CVPR
   Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Neycharan JG, 2018, MULTIMED TOOLS APPL, V77, P7615, DOI 10.1007/s11042-017-4663-4
   Novikova T, 2012, LECT NOTES COMPUT SC, V7577, P752, DOI 10.1007/978-3-642-33783-3_54
   Portaz M, 2019, MULTIMED TOOLS APPL, V78, P2747, DOI 10.1007/s11042-018-5798-7
   Pullayikodi SK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3040046
   Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6
   Rothe R, 2015, LECT NOTES COMPUT SC, V9003, P290, DOI 10.1007/978-3-319-16865-4_19
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, PROC INT CONF DOC, P126, DOI 10.1109/ICDAR.2011.34
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Thillou C, 2005, EURASIP J APPL SIG P, V2005, P2127, DOI 10.1155/ASP.2005.2127
   Tian SX, 2013, PROC INT CONF DOC, P912, DOI 10.1109/ICDAR.2013.186
   Tong GF, 2020, INT J DOC ANAL RECOG, V23, P103, DOI 10.1007/s10032-019-00348-7
   Tounsi M, 2018, ABS180607374 CORR
   Tounsi M, 2016, INT C PATT RECOG, P3987, DOI 10.1109/ICPR.2016.7900257
   Wang D, 2015, ABS151208669 CORR
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang T, 2012, INT C PATT RECOG, P3304
   Xu CY, 2019, MULTIMED TOOLS APPL, V78, P573, DOI 10.1007/s11042-017-5262-0
   Yi CC, 2013, PROC INT CONF DOC, P907, DOI 10.1109/ICDAR.2013.185
   Yin MX, 2019, MULTIMED TOOLS APPL, V78, P237, DOI 10.1007/s11042-017-5561-5
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
NR 59
TC 6
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3091
EP 3106
DI 10.1007/s11042-021-10663-z
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000629886000004
DA 2024-07-18
ER

PT J
AU Sabahno, M
   Safara, F
AF Sabahno, Mahdieh
   Safara, Fatemeh
TI ISHO: improved spotted hyena optimization algorithm for phishing website
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phishing webpages; Meta-heuristic algorithm; Spotted hyena optimization
   algorithm; Feature selection; Classification
AB One of the major challenges in cyber space and Internet of things (IoT) environments is the existence of fake or phishing websites that steal users' information. A website as a multimedia system provides access to different types of data such as text, image, video, audio. Each type of these data are prune to be used by fishers to perform a phishing attack. In phishing attacks, people are directed to fake pages and their important information is stolen by a thief or phisher. Machine learning and data mining algorithms are the widely used algorithms for classifying websites and detecting phishing attacks. Classification accuracy is highly dependent on the feature selection method employed to choose appropriate features for classification. In this research, an improved spotted hyena optimization algorithm (ISHO algorithm) is proposed to select proper features for classifying phishing websites through support vector machine. The proposed ISHO algorithm outperformed the standard spotted hyena optimization algorithm with better accuracy. In addition, the results indicate the superiority of ISHO algorithm to three other meta-heuristic algorithms including particle swarm optimization, firefly algorithm, and bat algorithm. The proposed algorithm is also compared with a number of classification algorithms proposed before on the same dataset.
C1 [Sabahno, Mahdieh] Islamic Azad Univ, Elect Branch, Dept Comp Engn, Tehran, Iran.
   [Safara, Fatemeh] Islamic Azad Univ, Islamshahr Branch, Dept Comp Engn, Islamshahr, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Safara, F (corresponding author), Islamic Azad Univ, Islamshahr Branch, Dept Comp Engn, Islamshahr, Iran.
EM mahsalife@gmail.com; safara@iiau.ac.ir
RI safara, fatemeh/B-1308-2012
OI safara, fatemeh/0000-0003-3513-3789
CR Aldawood H, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P110, DOI 10.1145/3309074.3309083
   Babagoli M, 2019, SOFT COMPUT, V23, P4315, DOI 10.1007/s00500-018-3084-2
   Benavides E, 2020, SMART INNOV SYST TEC, V152, P51, DOI 10.1007/978-981-13-9155-2_5
   Cosar A, 2018, SOFT COMPUT, P1
   Dhiman G, 2019, ADV INTELL SYST, V741, P857, DOI 10.1007/978-981-13-0761-4_81
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dua D, 2019, UCI MACHINE LEARNING
   Feng Fang, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1865, DOI 10.1007/s12652-018-0786-3
   Jain A, 2018, JCO PRECIS ONCOL, V2, P1, DOI 10.1200/PO.17.00080
   Latif RMA, 2019, INT BHURBAN C APPL S, P589, DOI 10.1109/IBCAST.2019.8667255
   Le Page S, 2018, PROCEEDINGS OF THE 2018 APWG SYMPOSIUM ON ELECTRONIC CRIME RESEARCH (ECRIME), P13, DOI 10.1109/ECRIME.2018.8376215
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Nagpal R., 2020, INT J INF TECHNOL, V16, P1
   Nair Sarath Raman, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8872972
   Niu WN, 2017, IEEE INT SYMP PARAL, P1054, DOI 10.1109/ISPA/IUCC.2017.00160
   Rao RS, 2019, NEURAL COMPUT APPL, V31, P3851, DOI 10.1007/s00521-017-3305-0
   Rao RS, 2019, COMPUT SECUR, V83, P246, DOI 10.1016/j.cose.2019.02.011
   Sahingoz OK, 2019, EXPERT SYST APPL, V117, P345, DOI 10.1016/j.eswa.2018.09.029
   Salahdine F, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040089
   Xiao X, 2020, NEURAL NETWORKS, V125, P303, DOI 10.1016/j.neunet.2020.02.013
NR 20
TC 8
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34677
EP 34696
DI 10.1007/s11042-021-10678-6
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000625612900009
DA 2024-07-18
ER

PT J
AU Ju, FJ
   Sun, YF
   Li, MY
AF Ju, Fujiao
   Sun, Yanfeng
   Li, Mingyang
TI Non-parametric Bayesian dictionary learning based on Laplace noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Dictionary learning; Variational inference; Image
   denosing
ID K-SVD; DISCRIMINATIVE DICTIONARY
AB Sparse representation based on over-complete dictionaries is a hot issue in the field of computer vision and machine learning. In probability theory, over-complete dictionary can be learned by non-parametric Bayesian techniques with Beta Process. However, traditional probabilistic dictionary learning method assumes noise follows Gaussian distribution, which can only remove Gaussain noise. In order to remove outlier or complex noise, we propose a dictionary learning method based on non-parametric Bayesian technology by assuming the noise follows Laplacian distribution. Because the non-conjugacy of Laplacian distribution makes the calculation of posteriors of latent variables more complicate, thus we utilize a superposition of an infinite number of Gaussian distributions to substitute for L1 density function. The weights of mixture Gaussian distribution are controlled by an extra hidden variable. Then the Bayesian inference is applied to learn all the key parameters in the proposed probabilistic model, which avoids the processing of parameter setting and fine tuning. In the experiments, we mainly test the performance of different algorithms in removing salt-and-pepper noise and mixture noises. The experimental results show that the PSNRs of our algorithm are higher 2-4 dB at least than other classic algorithms.
C1 [Ju, Fujiao; Sun, Yanfeng; Li, Mingyang] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Sun, YF (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
EM jfj2017@bjut.edu.cn; yfsun@bjut.edu.cn; limingyang@emails.bjut.edu.cn
FU National Natural Science Foundation of China [61806014, 61772048,
   61672071]; Beijing Natural Science Foundation [4172003]; Beijing
   Municipal Science and Technology Project [KM201910005028,
   Z191100009119013]
FX This research was supported by National Natural Science Foundation of
   China under Grant 61806014, 61772048 and 61672071, in part by the
   Beijing Natural Science Foundation under Grant 4172003, in part by
   Beijing Municipal Science and Technology Project KM201910005028, in part
   by Beijing Municipal Science and Technology Project with no.
   Z191100009119013.
CR Aharon M, 2005, INT SOC OPTICAL ENG, P327
   Aharon M., 2005, PROC SPARS, V5, P9, DOI DOI 10.1109/TSP.2006.881199
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akhtar N, 2018, IEEE T NEUR NET LEAR, V29, P4038, DOI 10.1109/TNNLS.2017.2742528
   [Anonymous], 2006, ADV NEURAL INF PROCE
   Bao CL, 2013, IEEE I CONF COMP VIS, P3384, DOI 10.1109/ICCV.2013.420
   Bibi A, 2017, IEEE I CONF COMP VIS, P1790, DOI 10.1109/ICCV.2017.197
   Carin L, 2016, INT JOINT C ART INT, P2364
   Choudhury B, 2017, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2017.459
   Ding XH, 2014, JMLR WORKSH CONF PRO, V33, P176
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Fu Y, 2015, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2015.47
   Ghahramani Z., 2006, NIPS 2005), P475
   He YJ, 2016, NEUROCOMPUTING, V173, P471, DOI 10.1016/j.neucom.2015.03.061
   Huang Y, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2360122
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Li SY, 2017, INT CONF ACOUST SPEE, P2691, DOI 10.1109/ICASSP.2017.7952645
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Paisley J., 2009, P 26 ANN INT C MACH, P777
   Papyan V, 2017, IEEE I CONF COMP VIS, P5306, DOI 10.1109/ICCV.2017.566
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Quan YH, 2015, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2015.17
   Sertoglu S, 2015, EUR SIGNAL PR CONF, P2771, DOI 10.1109/EUSIPCO.2015.7362889
   Song XN, 2014, NEUROCOMPUTING, V123, P131, DOI 10.1016/j.neucom.2013.06.017
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yin ZP, 2015, INT J SMART SENS INT, V8, P1123
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zheng H, 2015, NEUROCOMPUTING, V162, P9, DOI 10.1016/j.neucom.2015.03.071
   Zhou M., 2009, NIPS
   ZHOU M., 2011, INT C ART INT STAT, P883
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
   Zhou Y, 2014, NEUROCOMPUTING, V137, P223, DOI 10.1016/j.neucom.2013.02.045
NR 35
TC 0
Z9 0
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35993
EP 36007
DI 10.1007/s11042-020-10349-y
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000624399500006
DA 2024-07-18
ER

PT J
AU Nair, RR
   Singh, T
AF Nair, Rekha R.
   Singh, Tripty
TI MAMIF: multimodal adaptive medical image fusion based on B-spline
   registration and non-subsampled shearlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE B-Spline registration; NSST; MAMIF; Log Gabor filter; Medical image
   fusion
ID SALIENCY MAP; MRI; MULTISENSOR; DICTIONARY; PET
AB Off late, medical image fusion has emerged as an inspiring approach in merging different modalities of medical images. The fused image helps the medicos to diagnose various critical diseases quickly and precisely. This paper proposes two fusion algorithim named Multimodal Adaptive Medical Image Fusion (MAMIF) and Multimodal without Denoised Medical Image Fusion (MDMIF) and both of the method uses Non-Subsampled Shearlet Transform (NSST) and B-spline registration model. However as MAMIF uses denoise method, it provides better visually enhanced images. The presented MAMIF algorithim fuses the images without losing any vital information for the given set of real-time and public datasets. The entire fusion framework uses features extracted from NSST decomposed images by using Human Visual System (HVS) based Low Frequency (LF) sub-band fusion and Log-Gabor energy-based High Frequency (HF) sub-band fusion. The proposed framework is agnostic of source image size (pairs should be of the same size). The experiments were carried out leveraging 14 sets of image dataset that includes grayscale and color images. The performance calculation of the proposed MAMIF is evaluated based on the dataset collected from HCG hospital, Bangalore, and further validated by radiologists from the same hospital. Comparing the simulated results, the proposed adaptive model MAMIF produced superior visually fused images compared to other approaches such as MDMIF and MMDWT.
C1 [Nair, Rekha R.; Singh, Tripty] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Bengaluru, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Bengaluru
RP Singh, T (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Bengaluru, India.
EM tripty_singh@blr.amrita.edu
RI Nair, Rekha R/IUQ-1674-2023
OI Nair, Rekha R/0000-0002-7207-2877; Singh, Tripty/0000-0002-3688-4392
CR Amini Nasrin, 2014, Journal of Medical Engineering & Technology, V38, P211, DOI 10.3109/03091902.2014.904014
   Asha CS, 2019, IEEE ACCESS, V7, P40782, DOI 10.1109/ACCESS.2019.2908076
   Ch MMI, 2019, SIGNAL IMAGE VIDEO P, V13, P1157, DOI 10.1007/s11760-019-01459-8
   Du XG, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/7419307
   Ganasala P, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0478-5
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Ganasala P, 2014, BIOMED ENG LETT, V4, P414, DOI 10.1007/s13534-014-0161-z
   Goshtasby AA, 2005, 2-D AND 3-D IMAGE REGISTRATION FOR MEDICAL, REMOTE SENSING, AND INDUSTRIAL APPLICATIONS, P1
   Haddadpour M, 2017, BIOMED J, V40, P219, DOI 10.1016/j.bj.2017.05.002
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jiang Q, 2019, IEEE ACCESS, V7, P83484, DOI 10.1109/ACCESS.2019.2924033
   Kong W, 2011, IET SIGNAL PROCESS, V5, P75, DOI 10.1049/iet-spr.2009.0263
   Kong WW, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.1.017001
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu XB, 2016, SIGNAL IMAGE VIDEO P, V10, P959, DOI 10.1007/s11760-015-0846-5
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Luo XQ, 2017, IEEE SENS J, V17, P1760, DOI 10.1109/JSEN.2016.2646741
   Mandhare R.A., 2013, Int. J. Adv. Res. Electr., Electron. Instrum. Eng., V2, P2690
   Naidu VPS, 2010, DEFENCE SCI J, V60, P48, DOI 10.14429/dsj.60.105
   Naidu VPS., 2017, CONTROL DATA FUSION, V1, P13
   Nair R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P2026, DOI 10.1109/ICPCSI.2017.8392071
   Nair RR, 2018, INT CONF ADV COMPU, P249
   Nair RR, 2019, IET IMAGE PROCESS, V13, P1447, DOI 10.1049/iet-ipr.2018.6556
   Nair RR, 2017, INT CONF ADV COMPU, P186, DOI 10.1109/ICoAC.2017.8441362
   Nair Rekha R., 2020, IJAST, V29, P5353
   Parvathy VS, 2020, HEALTH CARE MANAG SC, V23, P661, DOI 10.1007/s10729-019-09492-2
   Prakash O, 2015, ADV INTELL SYST, V332, P199, DOI 10.1007/978-81-322-2196-8_23
   Qian J, 2016, TJFEONLINE, V39, P380
   Shahdoosti HR, 2018, MULTIMED TOOLS APPL, V77, P22649, DOI 10.1007/s11042-017-5067-1
   Shandoosti HR, 2019, BIOMED SIGNAL PROCES, V47, P63, DOI 10.1016/j.bspc.2018.08.017
   Singh S, 2019, INT J IMAG SYST TECH, V29, P50, DOI 10.1002/ima.22294
   Srivastava HB, 2009, DEFENCE SCI J, V59, P166, DOI 10.14429/dsj.59.1505
   Sun B, 2019, INT J IMAG SYST TECH, V29, P29, DOI 10.1002/ima.22292
   Suriya TSU, 2017, BIOMED RES-INDIA, V28, P684
   Wang LF, 2019, MULTIMED TOOLS APPL, V78, P929, DOI 10.1007/s11042-018-5907-7
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Yang Y, 2017, IEEE ACCESS, V5, P16985, DOI 10.1109/ACCESS.2017.2741500
   Yang Y, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/835481
   Yang Y, 2020, IEEE SYST J, V14, P852, DOI [10.1007/s13198-019-00887-6, 10.1109/JSYST.2019.2900336]
   Yin SL, 2019, INT J IMAGE DATA FUS, V10, P146, DOI 10.1080/19479832.2018.1487886
NR 41
TC 13
Z9 13
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 19079
EP 19105
DI 10.1007/s11042-020-10439-x
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000621282300006
DA 2024-07-18
ER

PT J
AU Adam, T
   Paramesran, R
   Mingming, Y
   Ratnavelu, K
AF Adam, Tarmizi
   Paramesran, Raveendran
   Mingming, Yin
   Ratnavelu, Kuru
TI Combined higher order non-convex total variation with overlapping group
   sparsity for impulse noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-convex; Image restoration; Total variation; ADMM; Overlapping group
   sparsity
ID AUGMENTED LAGRANGIAN METHOD; PRIMAL-DUAL METHOD; IMAGE-RESTORATION;
   MATRIX COMPLETION; MODEL; OPTIMIZATION; EFFICIENT; ALGORITHM; RECOVERY;
   NORM
AB A typical approach to eliminate impulse noise is to use the l(1)-norm for both the data fidelity term and the regularization terms. However, the l(1)-norm tends to over penalize signal entries which is one of its underpinnings. Hence, we propose a variational model that uses the non-convex l(p)-norm, 0 < p < 1 for both the data fidelity and a second-order total variation regularization term combined with an overlapping group sparse regularizer. Specifically, to robustly eliminate impulse noise, the proposed method uses a non-convex data fidelity term. The hybrid combination of a second-order non-convex total variation and an overlapping group sparse regularization term is used to eliminate the remaining staircase artifacts while maintaining a sharp restored image. A mathematical formulation is derived and to implement it, the iterative re-weighted l(1) (IRL1) based alternating direction method of multipliers (ADMM) is used to solve the constraints and the subproblems. Experimental results for image denoising and deblurring on several widely used standard images demonstrate that the proposed method performed better when compared to the l(1)-norm total variation (TV), total generalized variation (TGV) model, and the non-convex l(p)-norm TV-based data fidelity model in terms of peak signal-to-noise ratio (PSNR) and structure similarity index measure (SSIM).
C1 [Adam, Tarmizi; Paramesran, Raveendran; Ratnavelu, Kuru] UCSI Univ, Inst Comp Sci & Digital Innovat, Kuala Lumpur 56000, Malaysia.
   [Mingming, Yin] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.
C3 UCSI University; Universiti Malaya
RP Adam, T (corresponding author), UCSI Univ, Inst Comp Sci & Digital Innovat, Kuala Lumpur 56000, Malaysia.
EM tarmizi_adam2005@yahoo.com; ravee58@gmail.com; 841034627@qq.com;
   kurunathan@ucsiuniversity.edu.my
RI BIN ADAM, TARMIZI/GPX-5943-2022; Ratnavelu, Kurunathan/A-5463-2009
OI BIN ADAM, TARMIZI/0000-0002-5599-5071; 
CR Adam T, 2020, SIGNAL IMAGE VIDEO P, V14, P115, DOI 10.1007/s11760-019-01531-3
   Adam T, 2019, MULTIDIM SYST SIGN P, V30, P503, DOI 10.1007/s11045-018-0567-3
   ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chan RH, 2013, SIAM J IMAGING SCI, V6, P680, DOI 10.1137/110860185
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chen PY, 2014, IEEE T SIGNAL PROCES, V62, P3464, DOI 10.1109/TSP.2014.2329274
   Chen XJ, 2014, COMPUT OPTIM APPL, V59, P47, DOI 10.1007/s10589-013-9553-8
   Chen XJ, 2012, IEEE T IMAGE PROCESS, V21, P4709, DOI 10.1109/TIP.2012.2214051
   Cui ZX, 2018, APPL MATH MODEL, V62, P254, DOI 10.1016/j.apm.2018.05.035
   Fu B., 2019, MULTIMED TOOLS APPL, V78, p30 707
   Gong Pinghua, 2013, JMLR Workshop Conf Proc, V28, P37
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gu GY, 2017, INVERSE PROBL, V33, DOI 10.1088/1361-6420/aa9383
   Hao Y, 2014, COMPUT ELECTR ENG, V40, P808, DOI 10.1016/j.compeleceng.2013.08.010
   Jiang DD, 2017, CIRC SYST SIGNAL PR, V36, P3702, DOI 10.1007/s00034-016-0478-1
   Jidesh P, 2018, COMPUT ELECTR ENG, V67, P114, DOI 10.1016/j.compeleceng.2018.03.014
   Kuang SF, 2018, NEUROCOMPUTING, V316, P190, DOI 10.1016/j.neucom.2018.07.066
   Liu GY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142680
   Liu J, 2016, NEUROCOMPUTING, V216, P502, DOI 10.1016/j.neucom.2016.07.049
   Liu J, 2015, INFORM SCIENCES, V295, P232, DOI 10.1016/j.ins.2014.10.041
   Liu Q, 2018, SIGNAL PROCESS, V152, P84, DOI 10.1016/j.sigpro.2018.05.020
   Liu XW, 2019, CIRC SYST SIGNAL PR, V38, P1318, DOI 10.1007/s00034-018-0918-1
   Liu X, 2019, MULTIMED TOOLS APPL, V78, P24555, DOI 10.1007/s11042-018-6649-2
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Lyu Q, 2013, NEUROCOMPUTING, V119, P413, DOI 10.1016/j.neucom.2013.03.017
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Peyré G, 2011, EUR SIGNAL PR CONF, P303
   Qiao, 2019, INVERSE PROBL SCI EN, P1
   Ren DW, 2015, NEUROCOMPUTING, V170, P201, DOI 10.1016/j.neucom.2014.08.101
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Ren YJ, 2020, MULTIMED TOOLS APPL, V79, P1445, DOI 10.1007/s11042-019-08179-8
   Rodriguez P, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/217021
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Selesnick IW, 2013, INT CONF ACOUST SPEE, P5696, DOI 10.1109/ICASSP.2013.6638755
   Wang S, 2018, NUMER ALGORITHMS, V78, P513, DOI 10.1007/s11075-017-0386-x
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen F, 2017, IEEE T COMPUT IMAG, V3, P566, DOI 10.1109/TCI.2017.2744626
   Wen F, 2017, IEEE T SIGNAL PROCES, V65, P105, DOI 10.1109/TSP.2016.2598316
   Wong RKW, 2017, J MACH LEARN RES, V18
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yang X, 2017, MACROMOL RES, P1
   Yuan GZ, 2019, IEEE T PATTERN ANAL, V41, P352, DOI 10.1109/TPAMI.2017.2783936
   Zeng WJ, 2018, IEEE T SIGNAL PROCES, V66, P1125, DOI 10.1109/TSP.2017.2784361
   Zhang BX, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107631
   Zhang HL, 2018, SIGNAL PROCESS, V143, P69, DOI 10.1016/j.sigpro.2017.08.021
   Zhang J., 2020, IEEE Access, V8, p58 533
   Zhang XJ, 2017, SIAM J IMAGING SCI, V10, P1627, DOI 10.1137/16M1076034
NR 55
TC 13
Z9 15
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18503
EP 18530
DI 10.1007/s11042-021-10583-y
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300009
DA 2024-07-18
ER

PT J
AU Kumar, S
   Pradhan, J
   Pal, AK
   Islam, SH
   Khan, MK
AF Kumar, Sumit
   Pradhan, Jitesh
   Pal, Arup Kumar
   Islam, S. K. Hafizul
   Khan, Muhammad Khurram
TI Radiological image retrieval technique using multi-resolution texture
   and shape features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modified block difference of inverse probability (BDIP); Block level
   variance of local variance (BVLC); Content based image retrieval (CBIR);
   Radiological image retrieval; Multi-resolution texture and shape
   features
ID COLOR; PATTERNS; CLASSIFICATION; DESCRIPTOR; TRANSFORM; FRAMEWORK
AB Medical image analysis plays a very indispensable role in providing the best possible medical support to a patient. With the rapid advancements in modern medical systems, these digital images are growing exponentially and reside in discrete places. These images help a medical practitioner in understanding the problem and then the best suitable treatment. Radiological images are very often found to be the critical constituent of medical images. So, in health care, manual retrieval of visually similar images becomes a very tedious task. To address this issue, we have suggested a content-based medical image retrieval (CBMIR) system that effectively analyzes a Radiological image's primitive visual features. Since radiological images are in gray-scale form, these images contain rich texture and shape features only. So, we have suggested a novel multi-resolution radiological image retrieval system that uses texture and shape features for content analysis. Here, we have employed a multi-resolution modified block difference of inverse probability (BDIP) and block-level variance of local variance (BVLC) for shape and texture features, respectively. Our proposed scheme uses a multi-resolution and variable window size feature extraction strategy to maintain the block-level co-relation and extract more salient visual features. Further, we have used the MURA x-ray image dataset, which has 40561 images captured from 12173 different patients to demonstrate the proposed scheme's retrieval performance. We have also performed and compared image retrieval experiments on Brodatz and STex texture, Corel-1K, and GHIM-10K natural image datasets to demonstrate the robustness and improvement over other contemporaries.
C1 [Kumar, Sumit; Pradhan, Jitesh; Pal, Arup Kumar] Indian Inst Technol ISM Dhanbad, Dept Comp Sci Engn, Dhanbad 826004, Jharkhand, India.
   [Islam, S. K. Hafizul] Indian Inst Informat Technol Kalyani, Dept Comp Sci Engn, Kalyani 826004, W Bengal, India.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Coll Comp & Informat Sci, Riyadh 11451, Saudi Arabia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; King Saud University
RP Islam, SH (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci Engn, Kalyani 826004, W Bengal, India.
EM hafi786@gmail.com
RI KHAN, MUHAMMAD KHURRAM/E-4836-2014; Khan, Muhammad/IXN-8470-2023; Nusa,
   Nuhammad/JXY-5819-2024; Kumar, Sumit/HHS-8959-2022; kumar,
   sumit/HDM-6772-2022
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Pradhan,
   Jitesh/0000-0002-6264-4093
FU IIT[ISM] Dhanbad, Jharkhand, India [2015DR0056]; King Saud University,
   Riyadh, Saudi Arabia [RSP-2020/12]
FX The author Mr. Sumit Kumar (Admission No: 2015DR0056) is supported by
   the institute Ph.D. scholarship, IIT[ISM] Dhanbad, Jharkhand, India. The
   author Prof. Muhammad Khurram Khan acknowledges that his work is
   supported by Researchers Supporting Project number (RSP-2020/12), King
   Saud University, Riyadh, Saudi Arabia.
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Ashraf R, 2015, ENTROPY-SWITZ, V17, P3552, DOI 10.3390/e17063552
   Backes AR, 2017, NEUROCOMPUTING, V266, P1, DOI 10.1016/j.neucom.2017.05.020
   Backes AR, 2013, PATTERN RECOGN LETT, V34, P1455, DOI 10.1016/j.patrec.2013.05.008
   Backes AR, 2010, PATTERN RECOGN, V43, P685, DOI 10.1016/j.patcog.2009.07.017
   Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Khokher A, 2017, MULTIMED TOOLS APPL, V76, P21787, DOI 10.1007/s11042-016-4096-5
   Kim DH., 2011, INT J COMPUT TECHNOL, V1, P1
   Kumar S., 2016, IJCTA, V9, P889
   Kumar S, 2018, ADV INTELL SYST, V706, P737, DOI 10.1007/978-981-10-8237-5_71
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Kwitt R, 2012, SALZBURG TEXTURE IMA
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu ML, 2015, OPTIK, V126, P2629, DOI 10.1016/j.ijleo.2015.06.058
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Niu DM, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115911
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pandey S, 2016, INFORM PROCESS MANAG, V52, P571, DOI 10.1016/j.ipm.2015.12.005
   Pradhan J, 2017, 2017 IEEE INT C COMP, P1
   Pradhan J, 2020, IET IMAGE PROCESS, V14, P1303, DOI 10.1049/iet-ipr.2018.6619
   Pradhan J, 2019, MULTIMED TOOLS APPL, V78, P1685, DOI 10.1007/s11042-018-6246-4
   Pradhan J, 2018, DIGIT SIGNAL PROCESS, V82, P258, DOI 10.1016/j.dsp.2018.07.016
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   RYOO YJ, 1988, ELECTRON LETT, V24, P461, DOI 10.1049/el:19880312
   Sang Yong Seo, 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V4310, P694
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Varish N, 2017, FUND INFORM, V156, P209, DOI 10.3233/FI-2017-1605
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Vimina ER, 2020, MULTIMED TOOLS APPL, V79, P25357, DOI 10.1007/s11042-020-09207-8
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 47
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13633
EP 13660
DI 10.1007/s11042-021-10525-8
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000619425300002
DA 2024-07-18
ER

PT J
AU Li, CL
   Zhou, Y
   Li, HM
   Feng, W
   Du, JR
AF Li, Chun-Lai
   Zhou, Yang
   Li, Hong-Min
   Feng, Wei
   Du, Jian-Rong
TI Image encryption scheme with bit-level scrambling and multiplication
   diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary tree; Chaos dynamics; Multiplication diffusion; Image encryption
AB As the most effective method of multimedia security protection, image encryption is widely used in data hiding, security authentication and content protection. However, the security and efficiency are still the key issues of image encryption algorithm. In this paper, a grayscale image encryption scheme based on the architecture of bit-level scrambling and multiplication diffusion is proposed. Firstly, the input image is decomposed into eight bit planes and randomly divided into three parts. Secondly, the scrambling process of each part is respectively realized by using binary tree, flip scrambling and improved circle index scrambling. Finally, the diffusing operation of the scrambled components is executed by improving the GF (257) domain multiplication. The remarkable advantage of the scrambling operation is that it not only effectively permutes the pixels, but also permutes the bits in each pixel, and consequently it sufficiently destroys the correlation of adjacent pixels. And the parallel processing of different scrambling operations will increase the confusion effect and real-time performance. Moreover, the key stream for scrambling and diffusion operations is designed and selected strictly dependent on the plain-image. Therefore, our encryption scheme significantly improves the security by disturbing known-plaintext and chosen-plaintext attacks. Simulation experiments and security analyses further verify that the proposed algorithm is secure and effective to withstand various attacks.
C1 [Li, Chun-Lai; Zhou, Yang; Li, Hong-Min; Feng, Wei; Du, Jian-Rong] Hunan Inst Sci & Technol, Key Lab Hunan Prov Informat Photon & Freespace Op, Yueyang 414006, Peoples R China.
C3 Hunan Institute of Science & Technology
RP Li, CL (corresponding author), Hunan Inst Sci & Technol, Key Lab Hunan Prov Informat Photon & Freespace Op, Yueyang 414006, Peoples R China.
EM lichunlai33@126.com
RI Feng, Wei/ABO-6199-2022; Li, Hongmin/JNE-4835-2023
OI Feng, Wei/0000-0003-3023-5225; Li, Hongmin/0009-0009-7380-0029; LI,
   ChunLai/0000-0001-6329-7719
FU Hunan Provincial Natural Science Foundation of China [2019JJ40109,
   2020JJ4338, 2020JJ4337]; Research Foundation of Education Bureau of
   Hunan Province of China [18A314]; Science and Technology Program of
   Hunan Province [2019TP1014]; Hunan Institute of Science and Technology
   [YCX2019A12, YCX2020A40]; Science and Research Creative Team of Hunan
   Institute of Science and Technology [2019-TD-10]
FX This work was supported in part by Hunan Provincial Natural Science
   Foundation of China (Nos. 2019JJ40109, 2020JJ4338, 2020JJ4337); Research
   Foundation of Education Bureau of Hunan Province of China (No. 18A314);
   Science and Technology Program of Hunan Province (No. 2019TP1014);
   research and innovation project of the graduate students of Hunan
   Institute of Science and Technology (Nos. YCX2019A12, YCX2020A40);
   Science and Research Creative Team of Hunan Institute of Science and
   Technology (No. 2019-TD-10).
CR Atkins R, 2019, ANN COMB, V23, P1, DOI 10.1007/s00026-018-0410-4
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Carbajal-Gómez VH, 2019, NONLINEAR DYNAM, V98, P2389, DOI 10.1007/s11071-019-05288-9
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P8065, DOI 10.1007/s00521-019-04312-8
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chang D, 2018, AEU-INT J ELECTRON C, V88, P20, DOI 10.1016/j.aeue.2018.03.007
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Feng W, 2019, IEEE ACCESS, V7, P181589, DOI 10.1109/ACCESS.2019.2959137
   Feng W, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2880590
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Glück R, 2019, INFORM PROCESS LETT, V147, P32, DOI 10.1016/j.ipl.2019.03.002
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   [郭毅 Guo Yi], 2015, [计算机应用研究, Application Research of Computers], V32, P1131
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li CL, 2019, AEU-INT J ELECTRON C, V110, DOI 10.1016/j.aeue.2019.152861
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2765, DOI 10.1109/TCSVT.2019.2924910
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rajagopal K, 2018, AEU-INT J ELECTRON C, V94, P55, DOI 10.1016/j.aeue.2018.06.043
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Sivaraman R, 2020, MULTIMED TOOLS APPL, V79, P13841, DOI 10.1007/s11042-019-08592-z
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Pham VT, 2017, AEU-INT J ELECTRON C, V78, P134, DOI 10.1016/j.aeue.2017.05.034
   Volos C, 2017, NONLINEAR DYNAM, V89, P1047, DOI 10.1007/s11071-017-3499-9
   Wang FQ, 2019, ELECTRON LETT, V55, P884, DOI 10.1049/el.2019.1637
   Wang XY, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919502634
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1595, DOI 10.1007/s11071-015-2590-3
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang JM, 2019, ENG ANAL BOUND ELEM, V103, P80, DOI 10.1016/j.enganabound.2019.03.007
   Zhang Y, 2019, IETE J RES, V65, P4, DOI 10.1080/03772063.2017.1400406
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
   Zhu HG, 2017, NONLINEAR DYNAM, V89, P61, DOI 10.1007/s11071-017-3436-y
NR 55
TC 65
Z9 68
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18479
EP 18501
DI 10.1007/s11042-021-10631-7
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300005
DA 2024-07-18
ER

PT J
AU Sarkar, A
AF Sarkar, Arindam
TI Secure exchange of information using artificial intelligence and chaotic
   system guided neural synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural synchronization; Tree Parity Machine (TPM); Session key; Chaos;
   Information
ID NETWORKS
AB In this paper, a chaos-based neural synchronization has been proposed for the development of the public-key exchange protocol. A special neural network structure called Tree Parity Machine (TPM) is used for neural synchronization. Two TPMs accept the common input and different weight vector and update the weights using neural learning rule by exchanging their output. In some steps, it results in complete synchronization, and the weights of the two TPMs become identical. These identical weights serve as a secret key. There is, however, hardly some investigation to investigate the randomness of the common input vector used in the synchronization process. In this paper, logistic Chaos system based Tree Parity Machine (CTPM) is proposed. For faster synchronization, this proposed CTPM model uses logistic chaos generated random common input vector. This proposed CTPM model is faster and has better security than TPM with the same input, output, and hidden neurons. This proposed technique has been passed through a series of parametric tests. The results have been compared with some recent techniques. The results of the proposed technique have shown effective and robust potential.
C1 [Sarkar, Arindam] Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
RP Sarkar, A (corresponding author), Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
EM arindam.vb@gmail.com
OI Sarkar, Arindam/0000-0002-4951-4729
CR Allandadi A, 2013, PROCEEDINGS OF THE 2013 38TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS), P1, DOI 10.1109/LCNW.2013.6758491
   Balasubramaniam P., 2014, J EGYPT MATH SOC, V22, P365, DOI DOI 10.1016/J.JOEMS.2013.10.003
   Bauer FL, 2011, ENCY CRYPTOGRAPHY SE, P283, DOI DOI 10.1007/978-1-4419-5906-5
   Chen HB, 2019, IEEE T NEUR NET LEAR, V30, P3246, DOI 10.1109/TNNLS.2018.2890269
   Chen HB, 2017, IEEE T NEUR NET LEAR, V28, P1618, DOI 10.1109/TNNLS.2016.2546962
   Desai V, 2011, RECENT ADV INTELLIGE, P251, DOI DOI 10.1109/RAICS.2011.6069312
   Desai V., 2012, WORLD, V2, P165
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dolecki M, 2013, ADV SCI TECHNOL-RES, V7, P20, DOI 10.5604/20804075.1049490
   Dolecki M, 2015, LECT NOTES COMPUT SC, V9339, P451, DOI 10.1007/978-3-319-24369-6_37
   Dolecki M, 2013, LECT NOTES COMPUT SC, V8104, P241, DOI 10.1007/978-3-642-40925-7_23
   Dong T, 2020, IEEE T NEUR NET LEAR, V31, P4999, DOI 10.1109/TNNLS.2019.2955165
   Dong T, 2018, PHYSICA A, V495, P454, DOI 10.1016/j.physa.2017.12.008
   Eftekhari M, 2012, GROUPS COMPLEX CRYPT, V4, P167, DOI 10.1515/gcc-2012-0001
   Elashry IF, 2020, MULTIMED TOOLS APPL, V79, P20665, DOI 10.1007/s11042-019-08322-5
   Gomez H, 2017, INTEGRATION, V58, P430, DOI 10.1016/j.vlsi.2017.01.010
   Jeong YS, 2018, INT CONF BIG DATA, P541, DOI 10.1109/BigComp.2018.00091
   Kamrani A, 2020, MULTIMED TOOLS APPL, V79, P20263, DOI 10.1007/s11042-020-08879-6
   Kanter I, 2002, EUROPHYS LETT, V57, P141, DOI 10.1209/epl/i2002-00552-9
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Katz J., 2014, Introduction to modern cryptography
   Kinzel W, 2002, ADV SOLID STATE PHYS, V42, P383, DOI 10.1007/3-540-45618-X_30
   Klimov A, 2002, LECT NOTES COMPUT SC, V2501, P288
   Lakshmanan S, 2018, IEEE T NEUR NET LEAR, V29, P195, DOI 10.1109/TNNLS.2016.2619345
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Liu P, 2019, IEEE T NEUR NET LEAR, V30, P2358, DOI 10.1109/TNNLS.2018.2884620
   Meneses F, 2016, INT J COMPUT SCI NET, V16, P55
   Mu NK, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.062804
   Nankun Mu, 2013, Advances in Neural Networks - ISNN 2013. 10th International Symposium on Neural Networks. Proceedings: LNCS 7951, P99, DOI 10.1007/978-3-642-39065-4_13
   Ni Z, 2019, IEEE T NEUR NET LEAR, V30, P2684, DOI 10.1109/TNNLS.2018.2885530
   Niemiec M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2296-4
   NIST, 2020, NIST STAT TEST
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Pu X, 2017, MULTIMED TOOLS APPL, V76, P19881, DOI 10.1007/s11042-016-3728-0
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P20319, DOI 10.1007/s11042-020-08683-2
   Rosen-Zvi M, 2002, J PHYS A-MATH GEN, V35, pL707, DOI 10.1088/0305-4470/35/47/104
   Ruttor A, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.036121
   Ruttor A, 2007, NEURAL SYNCHRONIZATI
   Santhanalakshmi S, 2015, COMM COM INF SC, V536, P207, DOI 10.1007/978-3-319-22915-7_20
   Speck T, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/12/P12001
   Steiner M., 1996, 3rd ACM Conference on Computer and Communications Security, P31, DOI 10.1145/238168.238182
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Tirdad, 2010, 2010 ANN M N AM FUZZ, DOI 10.1109/NAFIPS.2010.5548182
   Tirdad, 2010, HOPFIELD NEURAL NETW, DOI 10.1109/NAFIPS.2010.5548182
   Wang AJ, 2016, NEURAL NETWORKS, V74, P52, DOI 10.1016/j.neunet.2015.11.002
   Wang J, 2018, IEEE T NEUR NET LEAR, V29, P353, DOI 10.1109/TNNLS.2016.2626466
   Wang JL, 2019, IEEE T NEUR NET LEAR, V30, P2434, DOI 10.1109/TNNLS.2018.2884954
   Xiao Q, 2019, IEEE T NEUR NET LEAR, V30, P1854, DOI 10.1109/TNNLS.2018.2874982
   Xin Zhou, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P1118, DOI 10.1109/IFOST.2011.6021216
   Zhang ZQ, 2020, NEUROCOMPUTING, V373, P15, DOI 10.1016/j.neucom.2019.09.034
   Zhang ZQ, 2019, IEEE T NEUR NET LEAR, V30, P1476, DOI 10.1109/TNNLS.2018.2868800
   Zhang ZQ, 2018, NEUROCOMPUTING, V318, P248, DOI 10.1016/j.neucom.2018.08.063
NR 52
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18211
EP 18241
DI 10.1007/s11042-021-10554-3
EA FEB 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700008
DA 2024-07-18
ER

PT J
AU Patil, DO
   Hamde, ST
AF Patil, Deepak O.
   Hamde, Satish T.
TI Automated detection of brain tumor disease using empirical wavelet
   transform based LBP variants and ant-lion optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor detection; MR images; Empirical wavelet transform; SVM
   classifier; Ant lion optimization
ID FEATURE-EXTRACTION; SEGMENTATION; IMAGES; CLASSIFICATION; MRI
AB Early detection of brain tumor is a challenging task that assists medical practitioners in disease diagnosis. This article presents a computer-assisted brain tumor detection scheme using empirical wavelet transform based local binary pattern variant features and ant-lion optimization. Firstly, the input magnetic resonance (MR) image is enhanced using brightness preserving dynamic fuzzy histogram equalization (DFHE) algorithm. Then, significant modes from the input brain MR image are extracted using empirical wavelet transform (EWT), and five different local binary variants are extracted from each EWT mode. Further, the ant-lion feature selection algorithm is employed to select discriminating and relevant features and remove redundant descriptors that lower feature dimensionality. Finally, a support vector machine (SVM) classifier is used to detect the input MR image as healthy or tumorous. The proposed algorithm performance is validated on two widely and publicly available databases using different statistical measures including sensitivity, specificity, precision, F1-measure, and accuracy. A substantial set of experiments are carried out to evaluate the effect of individual descriptors, descriptor fusion, number of EWT decomposition levels, and DFHE enhancement on the classification accuracy. The simulation results obtained confirm that the presented approach performance is better as compared to other existing methods in terms of detection rate.
C1 [Patil, Deepak O.; Hamde, Satish T.] SGGS Inst Engn & Technol, Dept Instrumentat Engn, Nanded 431606, Maharashtra, India.
   [Patil, Deepak O.] PDEAs Coll Engn, Dept Instrumentat & Control, Pune 412307, Maharashtra, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Patil, DO (corresponding author), SGGS Inst Engn & Technol, Dept Instrumentat Engn, Nanded 431606, Maharashtra, India.; Patil, DO (corresponding author), PDEAs Coll Engn, Dept Instrumentat & Control, Pune 412307, Maharashtra, India.
EM dopatil25@gmail.com
OI Patil, Deepak/0000-0002-9260-9483
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Ahonen Timo., 2007, Proceedings of the Finnish Signal Processing Symposium, FINSIG, P1
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2020, MULTIMED TOOLS APPL, V79, P10955, DOI 10.1007/s11042-019-7324-y
   [Anonymous], 2019, EHEALTH LAB DATABASE
   [Anonymous], 2019, HARVARD MEDIAL SCH D
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Bhuvaneswari KS, 2017, J EXP THEOR ARTIF IN, V29, P663, DOI 10.1080/0952813X.2016.1212106
   Chandra GR, 2016, PROCEDIA COMPUT SCI, V79, P449, DOI 10.1016/j.procs.2016.03.058
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chowdhary, 2017, HYBRID SCHEME BREAST, DOI [10.4018/978-1-5225-0983-7.ch047, DOI 10.4018/978-1-5225-0983-7.CH047]
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhury AA, 2020, J EXP THEOR ARTIF IN, V32, P111, DOI 10.1080/0952813X.2019.1631392
   Emary E, 2016, NEUROCOMPUTING, V213, P54, DOI 10.1016/j.neucom.2016.03.101
   Garud H., 2011, 2011 INT C IM INF PR, V2011, P1, DOI DOI 10.1109/ICIIP.2011.6108964
   Gilles J, 2014, SIAM J IMAGING SCI, V7, P157, DOI 10.1137/130923774
   Gilles J, 2013, IEEE T SIGNAL PROCES, V61, P3999, DOI 10.1109/TSP.2013.2265222
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Gupta M, 2019, J EXP THEOR ARTIF IN, V31, P57, DOI 10.1080/0952813X.2018.1518997
   Gupta N, 2018, J COMPUT SCI-NETH, V25, P213, DOI 10.1016/j.jocs.2017.02.009
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Holzinger A, 2019, APPL INTELL, V49, P2401, DOI 10.1007/s10489-018-1361-5
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Jambholkar T, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P200, DOI 10.1109/ISPCC.2015.7375025
   Jayachandran A, 2013, INT J IMAG SYST TECH, V23, P97, DOI 10.1002/ima.22041
   Kirar BS, 2019, IET IMAGE PROCESS, V13, P73, DOI 10.1049/iet-ipr.2018.5297
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Li Y, 2017, KNOWL INF SYST, V53, P551, DOI 10.1007/s10115-017-1059-8
   Mahesh KM, 2018, EVOL INTELL, V11, P19, DOI 10.1007/s12065-018-0156-2
   Manohar L, 2018, J MED BIOL ENG, V38, P917, DOI 10.1007/s40846-017-0355-9
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   National Brain Tumor Society, 2020, QUICK BRAIN TUMOR FA
   Oung QW, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0877-2
   Panda Abhilash, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS-2018. Advances in Intelligent Systems and Computing (AISC 851), P117, DOI 10.1007/978-981-13-2414-7_12
   Polepaka S, 2020, HEALTH TECHNOL-GER, V10, P249, DOI 10.1007/s12553-018-00290-4
   Ragab M, 2020, NEURAL COMPUT APPL, V32, P2705, DOI 10.1007/s00521-018-3812-7
   Saman S, 2019, INT J MULTIMED INF R, V8, P79, DOI 10.1007/s13735-018-0162-2
   Sathish P, 2019, COMP M BIO BIO E-IV, V7, P273, DOI 10.1080/21681163.2017.1386593
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Su H, 2016, IEEE T MED IMAGING, V35, P1575, DOI 10.1109/TMI.2016.2520502
   Subudhi A, 2018, MED BIOL ENG COMPUT, V56, P795, DOI 10.1007/s11517-017-1726-7
   Suneetha Bobbillapati, 2019, First International Conference on Artificial Intelligence and Cognitive Computing (AICC 2018). Advances in Intelligent Systems and Computing (AISC 815), P549, DOI 10.1007/978-981-13-1580-0_53
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Vidyaratne L, 2018, PROC SPIE, V10575, DOI 10.1117/12.2292930
   Wang QS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082621
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Ylioinas Juha, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P375, DOI 10.1007/978-3-642-37431-9_29
   Zafar, 2019, TECHNICAL J U ENG TE, V24, P83
NR 60
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17955
EP 17982
DI 10.1007/s11042-020-10434-2
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617667500004
DA 2024-07-18
ER

PT J
AU Ingaleshwar, S
   Dharwadkar, NV
   Jayadevappa, D
AF Ingaleshwar, Subodh
   Dharwadkar, Nagaraj, V
   Jayadevappa, D.
TI Water chaotic fruit fly optimization-based deep convolutional neural
   network for image watermarking using wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network (deep CNN); Image watermarking;
   Embedding; Wavelet transform; Optimal region selection
AB Due to the rapid growth of multimedia in network technology, accessing the digital media becomes very easy. Hence, protecting the intellectual property requires more interest in image watermarking. For this sake, different image watermarking approaches are developed, but it poses robustness and transparency issues. Therefore, an effective image watermarking method named Water Chaotic fruit fly Optimization algorithm-based Deep Convolutional neural network (WCFOA-based Deep CNN) is developed for embedding the secret message to the cover media. The proposed WCFOA is developed by integrating the Water Wave Optimization (WWO) with the Chaotic Fruit Fly Optimization algorithm (CFOA). The inspiration of propagation operator and the refraction operator increases the diversity of population and minimizes the premature convergence. However, the breaking, propagation and the refraction operator of the proposed optimization shows the effectiveness of balance between the exploitation of exploration phase in search space using the fitness measure. Accordingly, the embedding process is achieved using the wavelet transform with the selected optimal region using the evaluated fitness value. Several images of brain tumors from BRATS dataset, with tumors having different contrast and form, are used to assess the proposed method. The experimental analysis shows that, the proposed WCFOA-based Deep CNN obtained better performance using the metrics, like correlation coefficient and Peak signal-to-noise ratio (PSNR) with the values of 1 and 45.2157 using without noise scenario and the correlation coefficient and PSNR of 0.9918 and 45.0627 for Impulse noise. By considering the salt and pepper noise, the correlation coefficient and PSNR is 0.9918 and 47.001 and in the Gaussian noise scenario the values of correlation coefficient and PSNR is 0.990 and 46.985, respectively.
C1 [Ingaleshwar, Subodh; Jayadevappa, D.] JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru, India.
   [Dharwadkar, Nagaraj, V] Rajarambapu Inst Technol, Dept Comp Sci & Engn, Sangli, Maharashtra, India.
RP Ingaleshwar, S (corresponding author), JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru, India.
EM subodh.ingaleshwar@gmail.com; nagaraj.dharwadkar@gmail.com;
   devappa22@gmail.com
RI Devappa, Jayadevappa/W-3766-2018; Ingaleshwar, Subodh/AAJ-7458-2021;
   Dharwadkar, Nagaraj V./AGQ-4597-2022
OI Ingaleshwar, Subodh/0000-0002-4425-1317; Dharwadkar, Nagaraj
   V./0000-0003-3017-0011
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   [Anonymous], BRATS 2018 DATASET
   Arora M, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-019-2130-3
   Bagheri M., 2020, ADAPTIVE CONTROL EMB
   Dharwadkar N. V., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P489, DOI 10.1109/ICCSP.2011.5739368
   Dharwadkar N. V., 2010, Int. J. Signal Process., V6, P93
   Dharwadkar NV., 2010, INT J COMPUTER APPL, V2, P60
   Dutta MK, 2017, J KING SAUD U COMPU
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Gao YC, 2019, J REAL-TIME IMAGE PR, V16, P565, DOI 10.1007/s11554-018-0812-x
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Jiao SM, 2019, OPT LASER TECHNOL, V109, P370, DOI 10.1016/j.optlastec.2018.08.011
   Kaur M., 2012, International Journal of Research in Engineering & Applied Sciences, V2, P126
   Kumar C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4912
   Lei XJ, 2014, LECT NOTES COMPUT SC, V8794, P74, DOI 10.1007/978-3-319-11857-4_9
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Ma B, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107544
   Mairgiotis A, 2017, IEEE IMAGE PROC, P520, DOI 10.1109/ICIP.2017.8296335
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Rouhani B.D., 2018, DeepSigns: a generic watermarking framework for protecting the ownership of deep learning models
   Roy A, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500158
   Sadeghi M, 2019, SIGNAL PROCESS, V163, P213, DOI 10.1016/j.sigpro.2019.05.026
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Shu-Fen, 2019, MULTIMED TOOLS APPL, P1
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
NR 33
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21957
EP 21981
DI 10.1007/s11042-020-10498-0
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000615174300003
DA 2024-07-18
ER

PT J
AU Khan, SU
   Hussain, T
   Ullah, A
   Baik, SW
AF Khan, Samee Ullah
   Hussain, Tanveer
   Ullah, Amin
   Baik, Sung Wook
TI Deep-ReID: deep features and autoencoder assisted image patching
   strategy for person re-identification in smart cities surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart surveillance; Person re-identification; Deep autoencoder; Deep
   learning; Learned features extraction; Hybrid CNN
ID MODEL
AB Person Re-identification (P-ReID) task searches for true matches of a given query from a large repository of non-overlapping camera's images/videos. In smart cities surveillance, P-ReID is challenging due to variation in human's appearance, illumination affects, and difference in viewpoints. The mainstream approaches achieve P-ReID by implementing supervised learning strategies, requiring exhaustive manual annotation, which is probably erroneous due to human involvement. In addition, the employed methods use high-dimensional feature maps to identify a person, which is not a realistic approach in terms of storage resources and computational complexity. To tackle these issues, we incorporate learned features and deep autoencoder under the umbrella of a unified framework for P-ReID. First, we apply a unique image patching strategy by dividing the input image into two parts (upper and lower) and acquire learned features from fully connected layer of a pretrained Convolutional Neural Network (CNN) model for both patches. To achieve efficient and high performance, the proposed framework utilizes a self-tuned autoencoder to acquire low-dimensional representative features. The obtained features are matched with the patterns of database via cosine similarity measurement to re-identify a person's appearance. The proposed framework provides a trade-off between time complexity and accuracy, where a lightweight model can be incorporated with reduced number of autoencoder layers to obtain fast and comparatively flexible results. The major novelty of the proposed framework includes implementation of a hybrid network mechanism for P-ReID, which shows convincing real-time results and best fits for smart cities surveillance. The proposed framework is tested over several P-ReID datasets to prove its influence over the existing works with reduced computational complexity.
C1 [Khan, Samee Ullah; Hussain, Tanveer; Ullah, Amin; Baik, Sung Wook] Sejong Univ, Seoul 143747, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Seoul 143747, South Korea.
EM sameek3797@gmail.com; tanveerkhattak3797@gmail.com; qamin3797@gmail.com;
   sbaik@sejong.ac.kr
RI Hussain, Tanveer/AAF-7138-2019; KHAN, SAMEE ULLAH/AAU-2504-2020; Ullah,
   Amin/JPA-6034-2023; Hussain, Tanveer/GWQ-5172-2022; Ullah,
   Amin/AAH-5034-2020
OI Hussain, Tanveer/0000-0003-4861-8347; KHAN, SAMEE
   ULLAH/0000-0001-5640-4942; Ullah, Amin/0000-0001-7538-2689; Khan,
   Samee/0009-0007-6641-9735
FU Institute of Information AMP; communications Technology Planning AMP;
   Evaluation (IITP) - Korea government (MSIT) [2019-0-00136]
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (2019-0-00136, Development of AI-Convergence
   Technologies for Smart City Industry Productivity Innovation).
CR Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107256
   Almasawa MO, 2019, IEEE ACCESS, V7, P175228, DOI 10.1109/ACCESS.2019.2957336
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], arXiv preprint arXiv:2002.05202
   [Anonymous], 2014, ADV COMPUT VIS PATT, DOI DOI 10.1007/978-1-4471-6296-4
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Chen Weifeng, 2016, ADV NEURAL INFORM PR, V29, P730, DOI DOI 10.5555/3157096.3157178
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chu H, 2019, MULTIMED TOOLS APPL, P1
   Da Silva I.N., 2017, ARTIFICIAL NEURAL NE, P39, DOI [DOI 10.1007/978-3-319-43162-8, 10.1007/978-3-319-43162-8]
   Dai CQ, 2020, MULTIMED TOOLS APPL, V79, P12597, DOI 10.1007/s11042-019-08604-y
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fawad, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040647
   Fu K., 2020, P IEEE CVF C COMP VI, P3052
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hussain T, 2021, IEEE INTERNET THINGS, V8, P9634, DOI 10.1109/JIOT.2020.3027483
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Jia JR, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107568
   Jiao SS, 2019, IEEE ACCESS, V7, P90497, DOI 10.1109/ACCESS.2019.2927170
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Khan SU, 2020, PROCESSES, V8, DOI 10.3390/pr8060725
   Khan SU, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224963
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HF, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107414
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Liu YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112255
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Öztürk S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113693
   Perwiaz N, 2018, IEEE ACCESS, V6, P77334, DOI 10.1109/ACCESS.2018.2882254
   Sang HF, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7028107
   Sural S., 2003, INT C INF TECHN CIT
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Ul Haq I, 2019, COMPLEXITY, DOI 10.1155/2019/3581419
   Ullah, NEUROCOMPUTING
   Ullah A., 2020, DEEP LEARNING COMPUT, P127, DOI DOI 10.1201/9781351003827-5
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Ustinova E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang FY, 2020, PATTERN RECOGN LETT, V130, P293, DOI 10.1016/j.patrec.2018.11.016
   Wang G, 2020, Deep Learning in Computer Vision: Principles and Applications, V30, P41, DOI DOI 10.1201/9781351003827-2
   Wang SQ, 2020, J REAL-TIME IMAGE PR, V17, P73, DOI 10.1007/s11554-019-00908-4
   Wang Z, 2018, IEEE T CYBERNETICS, V48, P3006, DOI 10.1109/TCYB.2017.2755044
   Watson G, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051215
   Wu, 2016, 2016 IEEE WINT C APP
   Wu D, 2019, COGN SYST RES, V54, P74, DOI 10.1016/j.cogsys.2018.04.003
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu MY, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/9874345
   Yang XJ, 2020, MULTIMED TOOLS APPL, V79, P9299, DOI 10.1007/s11042-019-7387-9
   You DG, 2023, COMPUTING, V105, P577, DOI 10.1007/s00607-020-00865-y
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yukun Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14072, DOI 10.1109/CVPR42600.2020.01409
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang QC, 2018, IEEE T IND INFORM, V14, P3170, DOI 10.1109/TII.2018.2808910
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2021, IEEE T PATTERN ANAL, V43, P2723, DOI 10.1109/TPAMI.2020.2976933
   Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534
   Zhu XK, 2019, PATTERN RECOGN, V95, P211, DOI 10.1016/j.patcog.2019.06.007
   Zhu XK, 2018, IEEE T IMAGE PROCESS, V27, P5683, DOI 10.1109/TIP.2018.2861366
NR 71
TC 29
Z9 29
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15079
EP 15100
DI 10.1007/s11042-020-10145-8
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000610019400011
DA 2024-07-18
ER

PT J
AU Raj, S
   Mahanand, BS
   Vinod, DS
AF Raj, Shyla
   Mahanand, B. S.
   Vinod, D. S.
TI Diffuse lung disease classification based on texture features and
   weighted extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffuse lung diseases; Texture features; Intuitionistic local binary
   pattern; Extreme learning machine; Sample imbalance
ID CONVOLUTIONAL NEURAL-NETWORKS; ROTATION-INVARIANT; TISSUE-ANALYSIS;
   SCALE
AB Diffuse lung diseases are a group of chronic disorders that affect the lungs. The highly prevalent lung patterns associated with diffuse lung diseases are emphysema, fibrosis, ground-glass opacity, and micro-nodules. For diffuse lung classification problem, TALISMAN (Texture Analysis of Lung ImageS for Medical diagnostic AssistaNce) is one of the widely studied dataset in the literature. It is observed in the dataset that there exists sample imbalance among different tissue patterns. To address the sample imbalance in the data weighted extreme learning machine classifier is employed in this work. To overcome the intra-class and inter-class variation among the diffuse lung patterns features are extracted using the modified intuitionistic local binary pattern along with Gabor filter bank and grey level co-occurrence matrix. These combined texture features are then used to train the weighted extreme learning machine to classify the diffuse lung patterns. The performance of the proposed approach is compared with the existing works in the literature. The comparison results indicate better performance of the proposed approach for diffuse lung classification with sample imbalance.
C1 [Raj, Shyla; Mahanand, B. S.; Vinod, D. S.] JSS Sci & Technol Univ, Sri Jayachamarajendra Coll Engn, Dept Informat Sci & Engn, Mysuru, Karnataka, India.
C3 Sri Jayachamarajendra College of Engineering; JSS Science & Technology
   University
RP Mahanand, BS (corresponding author), JSS Sci & Technol Univ, Sri Jayachamarajendra Coll Engn, Dept Informat Sci & Engn, Mysuru, Karnataka, India.
EM shylaraj@jssstuniv.in; bsmahanand@sjce.ac.in; dsvinod@daad-alumni.de
CR Ansari M. D., 2018, INT J INFORM COMMUNI, V13, P83, DOI DOI 10.1504/ijict.2018.090435
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bagci U, 2012, COMPUT MED IMAG GRAP, V36, P72, DOI 10.1016/j.compmedimag.2011.06.002
   Bermejo-Peláez D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56989-5
   Bustince H, 2000, FUZZY SET SYST, V114, P485, DOI 10.1016/S0165-0114(98)00279-6
   Dalpiaz G, 2013, GERIATRIC IMAGING, P365
   Dash JK, 2017, MULTIMED TOOLS APPL, V76, P2535, DOI 10.1007/s11042-015-3231-z
   Depeursinge A, 2012, IEEE T INF TECHNOL B, V16, P665, DOI 10.1109/TITB.2012.2198829
   Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003
   Doddavarapu VNS, 2020, IMAGING SCI J, V68, P170, DOI 10.1080/13682199.2020.1781394
   Gao MC, 2018, COMP M BIO BIO E-IV, V6, P1, DOI 10.1080/21681163.2015.1124249
   Guo WP, 2019, MULTIMED TOOLS APPL, V78, P30615, DOI 10.1007/s11042-018-6535-y
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang S, 2020, MED BIOL ENG COMPUT, V58, P725, DOI 10.1007/s11517-019-02111-w
   Joyseeree R, 2019, MED IMAGE ANAL, V56, P172, DOI 10.1016/j.media.2019.06.006
   Joyseeree R, 2018, COMPUT MED IMAG GRAP, V64, P1, DOI 10.1016/j.compmedimag.2018.01.005
   Li L, 2019, MULTIMED TOOLS APPL, V78, P33375, DOI 10.1007/s11042-019-7543-2
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Richhariya B, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107150
   Richhariya B, 2018, APPL SOFT COMPUT, V71, P418, DOI 10.1016/j.asoc.2018.07.003
   Ross T. J., 2004, FUZZY LOGIC ENG APPL
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753
   Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648, DOI 10.1164/ajrccm.160.2.9804094
   van Ginneken B, 2003, PATTERN RECOGN, V36, P899, DOI 10.1016/S0031-3203(02)00118-8
   Vasconcelos V, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/672520
   Wang QC, 2018, IEEE J BIOMED HEALTH, V22, P184, DOI 10.1109/JBHI.2017.2685586
   Xu Z, 2019, INFORM SOFTWARE TECH, V106, P182, DOI 10.1016/j.infsof.2018.10.004
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P30723, DOI 10.1007/s11042-018-6500-9
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 34
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35467
EP 35479
DI 10.1007/s11042-020-10469-5
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000610019400001
DA 2024-07-18
ER

PT J
AU Urvashi, S
   Sood, M
   Puthooran, E
AF Urvashi, S.
   Sood, Meenakshi
   Puthooran, Emjee
TI Region of interest based selective coding technique for volumetric MR
   image sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-lossless compression; Region of interest; Resolution independent
   gradient edge predictor; Block-based encoding
AB Advanced image scanning techniques produce high resolution medical images such as CT, MRI which in turn needs large storage space and bandwidth for transmitting over a network. Lossless compression is preferred for medical images to preserve important diagnostic details. However, it is only sufficient to maintain the high quality of an image in a diagnostically important region, namely Region of interest (ROI) for an accurate diagnosis. Non -ROI portion when compressed near-losslessly does not affect the image quality but reduces the file size effectively. We propose a compression technique where the prediction is done by Resolution Independent Gradient Edge Detector (RIGED) to de-correlate the image pixels and block-based arithmetic coding is used for encoding. The optimal threshold value, optimal q-level and the block-based coding removes inter-pixel, psycho-visual and coding redundancy from non-ROI part to achieve high compression whereas ROI part is compressed losslessly by removing inter-pixel and coding redundancy only. In this paper, optimal threshold-based predictive lossless compression in the ROI and optimal quantization (q) based near-lossless compression in the rest of the region is proposed. The proposed method is evaluated on volumetric 8 bit and 16 bit standard MR image data-set and validated on real patient's 16 bit depth MR images collected from local hospitals. The performance of the proposed technique showed improvement over the existing techniques JPEG 2000, JPEG-LS, M-CALIC, JP3D, and CALIC by 40.89%, 34.50%, 32.92%, 22.36%, and 17.25% respectively in terms of Bits per Pixel (BPP).
C1 [Urvashi, S.; Puthooran, Emjee] Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat, HP, India.
   [Sood, Meenakshi] Natl Inst Tech Teachers Training & Res, Chandigarh, India.
C3 Jaypee University of Information Technology; National Institute of
   Technical Teachers Training & Research, Chandigarh
RP Urvashi, S (corresponding author), Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat, HP, India.
EM survashi2793@gmail.com
RI Puthooran, Emjee/I-8660-2017
CR [Anonymous], 2012, TELFOR J
   Anusuya V, 2014, J DIGIT IMAGING, V27, P594, DOI 10.1007/s10278-014-9697-9
   Ayoobkhan M., 2017, EURASIP J IMAGE VIDE, V7, P1
   Bairagi VK, 2013, SADHANA-ACAD P ENG S, V38, P123, DOI 10.1007/s12046-013-0126-4
   Barboriak D., 2015, DATA RIDER NEURO MRI, DOI 10.7937/K9/TCIA2015VOSN3HN1
   Bhardwaj C., 2017, Journal of Global Pharma Technology, V6, P123
   Cavaro-Menard Christine, 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P277, DOI 10.1109/EUVIP.2010.5699147
   Chavada P., 2014, INT J INNOVAT RES CO, V2, P2747
   CHEN KS, 1994, IEEE T MED IMAGING, V13, P538, DOI 10.1109/42.310885
   Dayal S., 2015, INT J COMPUT SCI APP, V5, P81
   Fidler A, 2006, MED PHYS, V33, P2832, DOI 10.1118/1.2218316
   Fouad MM., 2015, INT J ENG TECHNOL, V15, P155604
   Gupta M., 2014, INT J ADV RES COMPUT, V2, P340
   Jiang J, 2001, IMAGE VISION COMPUT, V19, P153, DOI 10.1016/S0262-8856(00)00064-0
   Joshi PV., 2016, INT J CURRENT ENG SC, V3, P2394
   Kaur A., 2014, INT J COMPUT SCI TRE, V2, P2347
   Lon MR, 2020, J KING SAUD UNIV-COM
   Lucas LFR, 2017, IEEE T MED IMAGING, V36, P2250, DOI 10.1109/TMI.2017.2714640
   Meyer, 2015, **DATA OBJECT**, DOI [10.7937/K9/TCIA.2015.H1SXNUXL, DOI 10.7937/K9/TCIA.2015.H1SXNUXL]
   Prabhash C, 2016, GADL J INVENT COMPUT, V2
   Puthooran E, 2013, INT J COMPUT INT SYS, V6, P1082, DOI 10.1080/18756891.2013.816059
   Rajkumar TMP, 2015, INT ARAB J INF TECHN, V12, P220
   Ramadoss M, 2019, DESIGN LOSSY LOSSLES
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sharma Urvashi, 2021, International Journal of Computers and Applications, V43, P764, DOI 10.1080/1206212X.2019.1610994
   Sharma U, 2020, J DIGIT IMAGING, V33, P516, DOI 10.1007/s10278-019-00283-3
   Shen HD, 2017, IEEE T GEOSCI REMOTE, V55, P173, DOI 10.1109/TGRS.2016.2603527
   Shuai D., 2006, IEEE INT SYMPOS, V1, P565
   Sneyers J, 2016, IEEE IMAGE PROC, P66, DOI 10.1109/ICIP.2016.7532320
   Song XY, 2016, J DIGIT IMAGING, V29, P706, DOI 10.1007/s10278-016-9892-y
   Sood, 2018, COMMUN COMPUT INFORM, V955, P1, DOI 10.1007/978-981-13-3140-4_18.
   Sreenivasulu R, 2020, J INTELL SYST, V29, P1063, DOI 10.1515/jisys-2018-0180
   Urvashi MS, 2018, INT J ELECT COMPUT E, V9
   Vivek PJ., 2016, INT J COMPUTATION RE, V1, P26
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
NR 36
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12857
EP 12879
DI 10.1007/s11042-020-10396-5
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607504000010
DA 2024-07-18
ER

PT J
AU He, SF
   Sun, DQ
   Wang, Z
AF He, Shufeng
   Sun, Dianqi
   Wang, Zhao
TI Named entity recognition for Chinese marine text with knowledge-based
   self-attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese named entity recognition; Self-attention mechanism; Knowledge
   graph
AB Chinese named entity recognition has been widely used in many fields, such as species recognition in marine information, and so on. Compared with the standard named entity recognition (NER), the performance of the Chinese marine named entity recognition is low, which is mainly limited by the normative nature of the text and the scale of the tagged corpus. In recent years, the research of named entity recognition primarily focuses on the small scale of the tagged corpus. It tends to use external knowledge or use joint training to improve final recognition performance. However, there is little research on the problem that the accuracy of NER will be suboptimal if the model is trained inadequately. To this end, in order to improve the accuracy of naming entity recognition and recognize more entities in corpus, this paper proposes a named entity recognition method that combines knowledge graph embedding with a self-attention mechanism. The entity embeddings of the marine knowledge graph (KG) are empolyed for the hidden units of NER model with attention mechanism in an end-to-end way. Therefore, the model can get additional auxiliary information to improve performance. Lastly, we conduct extensive experiments on marine corpus and other public datasets. The experimental results verify the effectiveness of our proposed method.
C1 [He, Shufeng; Sun, Dianqi; Wang, Zhao] China Geol Survey, Qingdao Inst Marine Geol, Qingdao, Peoples R China.
C3 China Geological Survey; Qingdao Institute of Marine Geology (QIMG)
RP He, SF (corresponding author), China Geol Survey, Qingdao Inst Marine Geol, Qingdao, Peoples R China.
EM hshufeng@mail.cgs.gov.cn; sdianqi@mail.cgs.gov.cn;
   wzhao_qds@mail.cgs.gov.cn
FU Second Level Research Project of China Geological Survey [DD20191008]
FX This work is supported by the Second Level Research Project of China
   Geological Survey (Grant No. DD20191008).
CR [Anonymous], 2016, ARXIV160706450
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, ARXIV160300786
   [Anonymous], 2013, P 26 INT C NEUR INF, DOI DOI 10.5555/2999792.2999923
   [Anonymous], 2013, P 51 ANN M ASS COMP
   Bunescu RC, 2005, P C HUM LANG TECHN E, P724, DOI DOI 10.3115/1220575.1220666
   Chen Lin, 2017, [Computational Visual Media, 计算可视媒体], V3, P83
   Chen YB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P167
   Chorowski J, 2015, ADV NEUR IN, V28
   Devlin J., 2018, PRE
   Ebisu T, 2018, AAAI CONF ARTIF INTE, P1819
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Greenberg N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2824
   Guo S, 2018, AAAI CONF ARTIF INTE, P4816
   Han SQ, 2018, ELECTRON COMMER R A, V28, P244, DOI 10.1016/j.elerap.2018.02.006
   He HF, 2017, AAAI CONF ARTIF INTE, P3216
   He Hangfeng, 2016, ARXIV161104234
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ju M., 2018, P 2018 C N AM CHAPT, P1446
   Kingma D. P., 2014, arXiv
   Lafferty J., 2001, ICML 01 P 18 INT C M
   Lample M., 2016, P NAACL HLT, P260, DOI DOI 10.18653/V1/N16-1030
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Liu W, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2379
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   McClosky D, 2011, HLT, P1626
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105
   Ng A. Y., 2004, P INT C MACH LEARN, P78
   Park G, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10020488
   Peng DL, 2020, INFORM SYST FRONT, V22, P1291, DOI 10.1007/s10796-019-09932-y
   Peng Nanyun, 2015, P 2015 C EMPIRICAL M, P548, DOI DOI 10.18653/V1/D15-1064
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   이동엽, 2017, [Journal of the Korea Convergence Society, 한국융합학회논문지], V8, P55, DOI 10.15207/JKCS.2017.8.12.055
   Shijia E, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2055, DOI 10.1145/3132847.3133088
   Singaravelan S., 2013, 2013 International Conference on Advanced Computing and Communication Systems (ICACCS), P1, DOI 10.1109/ICACCS.2013.6938716
   Stokes N, 2006, COMPUT LINGUIST, V32, P563, DOI 10.1162/coli.2006.32.4.563
   Upadhyay S, 2018, EMNLP, P2486
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Xiankai Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8957, DOI 10.1109/CVPR42600.2020.00898
   Xin J, 2018, AAAI CONF ARTIF INTE, P5997
   Xiong CY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1271, DOI 10.1145/3038912.3052558
   Xu CW, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2269, DOI 10.1145/3357384.3358117
   Xu D, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P672, DOI 10.1145/3336191.3371778
   Yao XC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P956
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1554
   Zhang ZJ, 2018, PROCEEDINGS OF GEOSHANGHAI 2018 INTERNATIONAL CONFERENCE: FUNDAMENTALS OF SOIL BEHAVIOURS, P185, DOI 10.1007/978-981-13-0125-4_20
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
NR 57
TC 9
Z9 9
U1 11
U2 151
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19135
EP 19149
DI 10.1007/s11042-020-10089-z
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000607369100007
DA 2024-07-18
ER

PT J
AU Zabihi, SM
   Ghanei-Yakhdan, H
   Mehrshad, N
AF Zabihi, Seyyed Mohammad
   Ghanei-Yakhdan, Hossein
   Mehrshad, Nasser
TI Content-based hybrid error concealment approach for packet video
   communication over the noisy channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatio-temporal error concealment; Video frame content; Non-local means;
   Motion vector; Retrieval
ID ALGORITHM; RECOVERY; SCHEME
AB Video compression makes the encoded video stream more vulnerable to the channel errors so that, the quality of the received video is exposed to severe degradation when the compressed video is transmitted over the error-prone environments. Therefore, it is necessary to apply error concealment (EC) techniques in the decoder to improve the quality of the received video. In this regard, an Adaptive Content-based EC Approach (ACBECA) is proposed in this paper, which exploits both the spatial and temporal correlations within the video sequences for the EC purpose. The proposed approach adaptively utilizes two EC techniques, including new spatial-temporal error concealment (STEC) technique, and a temporal error concealment (TEC) technique, to recover the lost regions of the frame. The STEC technique proposed in this paper is established on the basis of non-Local Means concept and tries to recover each lost macroblock (MB) as the weighted average of the similar MBs in the reference frame, whereas the TEC technique recovers the motion vector of the lost MB adaptively by analyzing the behavior of the MB in the frame. The decision on temporally or spatially reconstructing the degraded frames is made dynamically according to the content of the degraded frame (i.e., structure or texture), type of the error and also block loss rate (BLR). Compared with the state-of-the-art EC techniques, the simulation results indicate the superiority of the ACBECA in terms of both the objective and subjective quality assessments.
C1 [Zabihi, Seyyed Mohammad; Ghanei-Yakhdan, Hossein] Yazd Univ, Elect Engn Dept, Yazd, Iran.
   [Mehrshad, Nasser] Univ Birjand, Elect & Comp Engn Dept, Birjand, Iran.
C3 University of Yazd; University of Birjand
RP Ghanei-Yakhdan, H (corresponding author), Yazd Univ, Elect Engn Dept, Yazd, Iran.
EM mzabihi@stu.yazd.ac.ir; hghaneiy@yazd.ac.ir; nmehrshad@birjand.ac.ir
RI Ghanei-Yakhdan, Hossein/D-7382-2018; Ghanei-Yakhdan,
   Hossein/JAC-4508-2023; Mehrshad, Nasser/AAG-1976-2021
OI Ghanei-Yakhdan, Hosein/0000-0003-4575-1062
CR Akbari A, 2017, IEEE GLOB CONF SIG, P6, DOI 10.1109/GlobalSIP.2017.8308593
   Akbari A, 2017, IEEE T MULTIMEDIA, V19, P1339, DOI 10.1109/TMM.2017.2662203
   Aldahdooh A, 2017, INT CONF ACOUST SPEE, P1632, DOI 10.1109/ICASSP.2017.7952433
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen XM, 2008, IEEE T CONSUM ELECTR, V54, P154, DOI 10.1109/TCE.2008.4470038
   Cui SH, 2014, SIGNAL IMAGE VIDEO P, V8, P1533, DOI 10.1007/s11760-012-0390-5
   Ebdelli M, 2015, IEEE T IMAGE PROCESS, V24, P3034, DOI 10.1109/TIP.2015.2437193
   Gadgil N, 2016, ELECT IMAGING, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.2.VIPC-234, DOI 10.2352/ISSN.2470-1173.2016.2.VIPC-234]
   Gang HS, 2017, IEICE T COMMUN, VE100B, P657, DOI 10.1587/transcom.2016EBP3221
   Ghanei-Yakhdan H, 2013, 1 IR C PATT REC IM A
   Ha H, 2016, WIRELESS PERS COMMUN, V89, P1103, DOI 10.1007/s11277-016-3307-8
   Kazemi M, 2014, MULTIMEDIA SYST, V20, P283, DOI 10.1007/s00530-013-0319-z
   Kim DH, 2018, ETRI J, V40, P266, DOI 10.4218/etrij.2017-0078
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lee YH, 2017, J SIGNAL PROCESS SYS, V88, P13, DOI 10.1007/s11265-016-1112-y
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Lin TL, 2017, MULTIMED TOOLS APPL, V76, P397, DOI 10.1007/s11042-015-3056-9
   Lin TL, 2013, IEEE T BROADCAST, V59, P705, DOI 10.1109/TBC.2013.2275056
   Lin TC, 2014, INT J SCI EDUC, V36, P1346, DOI 10.1080/09500693.2013.864428
   Liu J, 2015, IEEE T CIRC SYST VID, V25, P353, DOI 10.1109/TCSVT.2014.2359145
   Marvasti-Zadeh SM, 2016, TURK J ELECTR ENG CO, V24, P5195, DOI 10.3906/elk-1409-88
   Ni HX, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540143
   Patel D, 2014, EM TECHN TRENDS EL C
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Rajani PK, 2016, P 8 INT C SIGN PROC, P70, DOI 10.1145/3015166.3015202
   Thaipanich T, 2007, INT SOC OPTICS PHOTO
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wells JW, 2017, IEEE T CIRC SYST VID, V27, P1077, DOI 10.1109/TCSVT.2016.2527303
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xutao Wei, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P1335, DOI 10.1109/ICASI.2017.7988151
   Zabihi SM, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P193, DOI 10.1109/ICCKE.2017.8167874
   Zhang L, 2014, J SIGNAL PROCESS SYS, V74, P103, DOI 10.1007/s11265-013-0747-1
   Zhang YB, 2012, IEEE T CIRC SYST VID, V22, P12, DOI 10.1109/TCSVT.2011.2130450
   Zhou ZH, 2017, MULTIMED TOOLS APPL, V76, P16045, DOI 10.1007/s11042-016-3894-0
NR 34
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12335
EP 12365
DI 10.1007/s11042-020-10290-0
EA JAN 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606723900001
DA 2024-07-18
ER

PT J
AU Deng, X
   Liao, KY
   Zheng, YL
   Lin, GF
   Lei, H
AF Deng, Xuan
   Liao, Kaiyang
   Zheng, Yuanlin
   Lin, Guangfeng
   Lei, Hao
TI A deep multi-feature distance metric learning method for pedestrian
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian re-identification; Regional integration feature; Weighted
   fusion strategy
ID PERSON REIDENTIFICATION; SCALE
AB Consider the problem that handcrafted features are limited by not being directly applicable to practical problems. Additionally, the deep convolution feature is a high-dimensional feature, and if it is directly used to match the image, it will consume considerable time and memory. Moreover, features from higher levels may be contaminated by dramatic variations in the human pose or background clutter. This paper proposes a method based on deep multi-feature distance metric learning. First, each spatial position and channel are weighted after extracting the deep convolution feature from the last layer of the CNN, and the final aggregation result, that is, the feature of the image, is obtained by sum-pooling. Second, a new method to improve and integrate the convolution feature of the region is proposed. The convolution features are processed by the sliding frame technique, and the low-dimensional eigenvector with dimensions equal to the number of convolution layer channels is obtained. Third, a distance learning algorithm is proposed by cross-view quadratic discriminant analysis metric learning. Finally, the weighted fusion strategy is used to accomplish the collaboration between the handcrafted and deep convolution features. On the Market-1501 and VIPeR datasets, the experimental results show that the rank 1 values of the proposed method on three experimental datasets reach 90.02% and 68.74%, respectively. Under the new classification rules of the CHUK03 dataset, the rank 1 performance of the proposed method reaches 34.2%. The experimental results show that the accuracy of pedestrian re-identification after distance-weighted fusion is higher than that obtained by the separate feature distance metric.
C1 [Deng, Xuan; Liao, Kaiyang; Zheng, Yuanlin; Lin, Guangfeng; Lei, Hao] Xian Univ Technol, Coll Fac Printing Packaging Engn & Digital Media, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
   [Liao, Kaiyang] Printing & Packaging Engn Technol Res Ctr Shaanxi, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
   [Zheng, Yuanlin] Key Lab Printing & Packaging Engn Shaanxi Prov, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Liao, KY (corresponding author), Xian Univ Technol, Coll Fac Printing Packaging Engn & Digital Media, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.; Liao, KY (corresponding author), Printing & Packaging Engn Technol Res Ctr Shaanxi, 5 South Jinhua Rd, Xian 710048, Shaanxi, Peoples R China.
EM 1320670926@qq.com; liaokaiyang@xaut.edu.cn
RI lei, hao/IYJ-8690-2023; Lin, Guangfeng/E-4420-2013
OI Lin, Guangfeng/0000-0002-6191-1102
FU National Natural Science Foundation of China [61671376, 61771386];
   Scientific Research Project of Shaanxi Provincial Department of
   Education [18JK0556]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61671376 and Grant 61771386 and in part
   by the Scientific Research Project of Shaanxi Provincial Department of
   Education under Grant 18JK0556.
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Bai S, 2019, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2019.00083
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Chen CH, 2018, STUD COMPUT INTELL, V769, P387, DOI 10.1007/978-3-319-76081-0_33
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu MX, 2019, IEEE ACCESS, V7, P73253, DOI 10.1109/ACCESS.2019.2920426
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Johnson DM, 2016, IEEE T KNOWL DATA EN, V28, P1035, DOI 10.1109/TKDE.2015.2507130
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kan SC, 2019, IEEE T IMAGE PROCESS, V28, P5809, DOI 10.1109/TIP.2019.2901407
   Kuo CH, 2013, IEEE WORKSH APPL COM
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu Hao, 2016, ARXIV160604404
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P366, DOI 10.1109/TCYB.2013.2256347
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Sarfraz M. S., 2017, ARXIV171110378, P420
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tao D., 2017, IEEE T CIRCUITS SYST, P1
   Nguyen TB, 2018, LECT NOTES ARTIF INT, V10751, P433, DOI 10.1007/978-3-319-75417-8_41
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Wu L., 2016, ARXIV160107255
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zhong ZF, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/5812394
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 51
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23113
EP 23131
DI 10.1007/s11042-020-10458-8
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000606296900005
DA 2024-07-18
ER

PT J
AU Panda, N
   Majhi, SK
AF Panda, Nibedan
   Majhi, Santosh Kumar
TI Oppositional salp swarm algorithm with mutation operator for global
   optimization and application in training higher order neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Swarm based algorithm; Salp swarm algorithm; Oppositional based learning
   (OBL); Optimization; Classification; Higher order neural network (HONN)
ID FEATURE-SELECTION; ENSEMBLE
AB Effectiveness of any swarm based metaheuristic optimization algorithm focuses on perfect mishmash of operator's castoff for exploration and exploitation. The absenteeism of balance between this two factors leads to deprived performance in terms of attaining global optimum by stagnating in local optimum and untimely convergence. Salp Swarm Algorithm (SSA) is a recently evolved optimization technique, intended to resolve continuous, non-linear and multifaceted real world optimization glitches. For solving complex day to day life problems the explorative strength of existing SSA is not adequate. So, this paper proposes a new improved algorithm termed as OBL-MO-SSA to enhance the performance of existing SSA. Two techniques such as normal distributed mutation operator and oppositional learning concept is embedded to achieve the purpose. Oppositional learning concept ensures the current as well as opposite candidate solutions in the search region simultaneously to evaluate the closer solutions during ongoing evolution process. Mutation operator avoids the arbitrary positions in the search region by choosing lesser and larger mutations for balanced motion in current and opposite directions. The proposed method OBL-MO-SSA improves the exploration and exploitation strength inside search region at the same time exhibiting better convergence speed by successfully avoiding local optima stagnation. To confirm the efficiency of proposed OBL-MO-SSA algorithm, the same is assessed by benchmark problems pertaining to IEEE-CEC-2017. The competence and strength of the proposed OBL-MO-SSA is characterised by using performance metrics, complexity analysis, convergence rate and statistical significance. Friedman and Holms test has been accomplished to substantiate its statistical significance. Furthermore to elucidate complex difficulties, the proposed method used to train higher order neural network (FLANN) by the help of 10 customary datasets preferred from UCI storehouse. The simulated outcomes reveals that the developed OBL-MO-SSA might be cast-off for resolving various optimization complications efficiently.
C1 [Panda, Nibedan; Majhi, Santosh Kumar] Veer Surendra Sai Univ Technol, Dept Comp Sci & Engn, Burla 768018, Odisha, India.
   [Panda, Nibedan] Aditya Inst Technol & Management, Dept Informat Technol, Tekkali 532201, AP, India.
C3 Veer Surendra Sai University of Technology
RP Panda, N (corresponding author), Veer Surendra Sai Univ Technol, Dept Comp Sci & Engn, Burla 768018, Odisha, India.; Panda, N (corresponding author), Aditya Inst Technol & Management, Dept Informat Technol, Tekkali 532201, AP, India.
EM nibedan.panda@gmail.com; smajhi_cse@vssut.ac.in
RI Panda, Nibedan/AAO-2137-2021
OI Panda, Nibedan/0000-0002-3051-7487; Majhi, Santosh
   Kumar/0000-0002-8887-6933
CR Abou El-Ela AA, 2018, PROC INT MID EAST P, P19, DOI 10.1109/MEPCON.2018.8635119
   Abusnaina AA, 2018, ICFNDS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON FUTURE NETWORKS AND DISTRIBUTED SYSTEMS, DOI 10.1145/3231053.3231070
   Ahmed Ishtiaq, 2014, International Journal of Machine Learning and Computing, V4, P183, DOI 10.7763/IJMLC.2014.V4.409
   Ahmed S, 2018, ISMSI 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS, METAHEURISTICS & SWARM INTELLIGENCE, P65, DOI 10.1145/3206185.3206198
   [Anonymous], 2018, F Distribution Table
   Sicilia JA, 2016, J COMPUT APPL MATH, V291, P468, DOI 10.1016/j.cam.2015.03.050
   Asaithambi S, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5020999
   Bache K, 2013, UCI machine learning repository
   Can U., 2015, Am. J. Inf. Sci. Comput. Eng, V1, P94
   Chakri A, 2017, EXPERT SYST APPL, V69, P159, DOI 10.1016/j.eswa.2016.10.050
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Dinkar SK, 2017, APPL SOFT COMPUT, V66, P473
   Dinkar SK, 2018, ARAB J SCI ENG, V44, P1
   Ekinci S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC ENGINEERING (ICEEE), P143, DOI 10.1109/ICEEE2.2018.8391318
   Ferreira AD, 2018, APPL SOFT COMPUT, V65, P1, DOI 10.1016/j.asoc.2017.12.043
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Green RC, 2012, EXPERT SYST APPL, V39, P555, DOI 10.1016/j.eswa.2011.07.046
   Han XH, 2017, ENG APPL ARTIF INTEL, V61, P1, DOI 10.1016/j.engappai.2016.11.003
   Hegazy AE, 2020, J KING SAUD UNIV-COM, V32, P335, DOI 10.1016/j.jksuci.2018.06.003
   Hong LB, 2018, APPL SOFT COMPUT, V62, P162, DOI 10.1016/j.asoc.2017.10.002
   Ibrahim HT, 2017, INT J COMPUT SCI NET, V17, P13
   Jordehi AR, 2014, NEURAL COMPUT APPL, V25, P1329, DOI 10.1007/s00521-014-1613-1
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Meraihi Y, 2019, LECT NOTE NETW SYST, V64, P106, DOI 10.1007/978-3-030-05481-6_8
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Misra B.B., 2007, FUNCTIONAL LINK ARTI
   Nag K, 2016, IEEE T CYBERNETICS, V46, P499, DOI 10.1109/TCYB.2015.2404806
   Panda Nibedan, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P579, DOI 10.1007/978-981-13-9042-5_49
   Panda N, 2019, INT J RECENT TECHNOL, P4915
   Panda N, COMPUT INTELL
   Pandit NR, 2020, ARCH AGRON SOIL SCI, V66, P250, DOI 10.1080/03650340.2019.1610168
   Pappula L, 2018, APPL SOFT COMPUT, V66, P473, DOI 10.1016/j.asoc.2018.02.012
   PATNANA N, 2018, INT J PURE APPL MATH, V119, P12707
   Saghatforoush A, 2016, ENG COMPUT-GERMANY, V32, P255, DOI 10.1007/s00366-015-0415-0
   Schmidt DP, 2000, J COMPUT PHYS, V164, P62, DOI 10.1006/jcph.2000.6568
   Ting CK, 2018, MEMET COMPUT, V10, P15, DOI 10.1007/s12293-016-0220-3
   Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wang H, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P537
   Wang JZ, 2018, WORLD J CLIN CASES, V6, P167, DOI 10.12998/wjcc.v6.i8.167
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu G., 2017, Tech. Rep.
   Wu GH, 2018, INFORM SCIENCES, V423, P172, DOI 10.1016/j.ins.2017.09.053
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang XS, 2013, ENG COMPUT-GERMANY, V29, P175, DOI 10.1007/s00366-012-0254-1
   Zhang L, 1999, IEEE T NEURAL NETWOR, V10, P925, DOI 10.1109/72.774263
   2020, TOB CESS PRACT MAN, P1
NR 54
TC 14
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35415
EP 35439
DI 10.1007/s11042-020-10304-x
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000606409000001
DA 2024-07-18
ER

PT J
AU Li, SG
   Liu, X
   Sun, N
   Yu, ZX
   Zhang, FF
AF Li, Shugang
   Liu, Xin
   Sun, Nan
   Yu, Zhaoxu
   Zhang, Fangfang
TI The construction of a high-active EVCARD online community based on user
   content adoption and generation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EVCARD online community; User-generated content; Marketer; generated
   content; O2O interaction; Fuzzy system dynamic model
ID INTEGRATING SYSTEM DYNAMICS; SOURCE CREDIBILITY; QUALITY; RISK; FIRM
AB Constructing a high-active EVCARD online community (EOC)(HEOC) is a particularly effective approach for the emerging car-sharing company to trumpet its new products/services and stabilize its customer base. Although there is plenty of research on the model of user-generated content (UGC), the model of interaction between users and marketers on the generation and adoption of UGC and marketer- generated content (MGC) in the online marketing community is very much under-explored. To fill this gap, this study proposes the user content adoption and generation fuzzy system dynamic model (UCAAGFSDM) for building a HEOC where offline activities and online experience topics are mixed in a dynamic way, namely Offline-to-Online (O2O) content continuous interaction (OCCI). In UCAAGFSDM, user content adoption model for MGC is constructed based on the information adoption theory and user content generation model is developed according to the social cognition theory. And subsequently, the system dynamic model (SDM) is built for completely and meticulously describing mechanisms of user content adoption and generation and the interaction between users and marketers on the content in EOC. Since the cognitive behaviors of user in the process of adoption and generation content are uncertain and vague, to further improve the accuracy of the proposed model, Zadeh's extension principle and alpha-cut concept are used to solve the uncertain factors, which can flexibly and accurately descript the fuzzy cognitive behaviors of user variables. Based on UCAAGFSDM, the complex mechanism of OCCI in EOC is accurately depicted and optimal construction strategies for EOC are provided for community managers by comprehensively analyzing the cost, income and profit of EOC.
C1 [Li, Shugang; Liu, Xin; Sun, Nan; Zhang, Fangfang] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
   [Zhang, Fangfang] SAIC Maxus Automobile Co Ltd, Shanghai 200000, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Zhang, FF (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.; Zhang, FF (corresponding author), SAIC Maxus Automobile Co Ltd, Shanghai 200000, Peoples R China.
EM fangfangzhang1@163.com
RI Zhang, Fang/HHN-2153-2022
OI Yu, Zhaoxu/0000-0002-2375-0213
FU Chinese National Natural Science Foundation [71871135]
FX This work was supported by the Chinese National Natural Science
   Foundation (No. 71871135).
CR Akar E, 2019, INT J HUM-COMPUT INT, V35, P495, DOI 10.1080/10447318.2018.1465325
   Aladwani AM, 2017, INT J INFORM MANAGE, V37, P576, DOI 10.1016/j.ijinfomgt.2017.05.014
   [Anonymous], 2011, INT J LATEST TRENDS
   Ayman N, 2020, PHYSICA A, V553, P124247, DOI 10.1016/j.physa.2020.124247
   Bahtar AZ, 2015, PROC ECON FINANC, V37, P337, DOI 10.1016/S2212-5671(16)30134-4
   Bandura A., 1977, Social Learning Theory
   Bandura A., 2002, HLTH PSYCHOL READER, P94, DOI [10.4135/9781446221129.n6, DOI 10.4135/9781446221129.N6]
   Barnes GN, 2020, OVERSATURATION DISEN
   Barnes GN, 2020, INCREASES USE INSTAG
   Bhattacharya P, 2019, INFORM SYST RES, V30, P117, DOI 10.1287/isre.2018.0790
   Choi B, 2017, TELEMAT INFORM, V34, P550, DOI 10.1016/j.tele.2016.11.005
   Colicev A, 2019, INT J RES MARK, V36, P100, DOI 10.1016/j.ijresmar.2018.09.005
   Fani H, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102056
   Feng B, 2019, INFORM MANAGE-AMSTER, V56, P196, DOI 10.1016/j.im.2018.05.004
   Gordon T.J., 1994, FUTURES RES METHODOL
   Hellendoorn H., 1993, J INTELLIGENT FUZZY, V1, P109, DOI DOI 10.3233/IFS-1993-1202
   Hopp T, 2018, TELEMAT INFORM, V35, P1237, DOI 10.1016/j.tele.2018.02.006
   Hua F, 2017, SOCIAL MEDIA MARKETI, P160
   Hussain S, 2017, COMPUT HUM BEHAV, V66, P96, DOI 10.1016/j.chb.2016.09.034
   Kang JW, 2019, INT J HOSP MANAG, V78, P189, DOI 10.1016/j.ijhm.2018.10.011
   Katsamakas E, 2007, P 25 INT C SYST DYN
   Khanzadi M, 2012, AUTOMAT CONSTR, V22, P368, DOI 10.1016/j.autcon.2011.09.015
   Lin MJJ, 2009, COMPUT HUM BEHAV, V25, P929, DOI 10.1016/j.chb.2009.03.008
   Liu YZ, 2019, J ASSOC INF SCI TECH, V70, P660, DOI 10.1002/asi.24160
   Liu Y, 2016, PHYSICA A, V463, P202, DOI 10.1016/j.physa.2016.07.022
   Nasirzadeh F, 2008, CONSTR MANAG ECON, V26, P1197, DOI 10.1080/01446190802459924
   Nisar TM, 2018, TRANSPORT RES A-POL, V113, P318, DOI 10.1016/j.tra.2018.04.026
   Otto P, 2008, SYST DYNAM REV, V24, P321, DOI 10.1002/sdr.403
   Pan YC, 2019, INFORM SCIENCES, V479, P180, DOI 10.1016/j.ins.2018.11.009
   Prateek M, 2016, PROCEEDINGS OF THE INTERNATIONAL FRUCT CONFERENCE ON INTELLIGENCE, SOCIAL MEDIA AND WEB (ISMW FRUCT 2016), P49
   Schultz D.E., 1992, Journal of Promotion Management, V1, P99, DOI DOI 10.1300/J057V01N01_07
   Ukpabi DC, 2018, TOUR MANAG PERSPECT, V28, P251, DOI 10.1016/j.tmp.2018.03.006
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Wang Y., 2016, J BUS ECON MANAG, V4, P618, DOI [https://doi.org/10.18178/joebm.2016.4.11.462, DOI 10.18178/JOEBM.2016.4.11.462]
   Xu B, 2015, INFORM MANAGE-AMSTER, V52, P275, DOI 10.1016/j.im.2014.12.003
   Zhu DH, 2016, J RETAIL CONSUM SERV, V31, P287, DOI 10.1016/j.jretconser.2016.04.013
NR 36
TC 2
Z9 2
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11395
EP 11421
DI 10.1007/s11042-020-10027-z
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700012
DA 2024-07-18
ER

PT J
AU Huang, JC
   Zhang, PY
   Zhou, ZH
   Fan, KF
AF Huang, Junchu
   Zhang, Pengyu
   Zhou, Zhiheng
   Fan, Kefeng
TI Domain compensatory adversarial networks for partial domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Deep learning; Image classification
ID ALIGNMENT
AB Recently, domain adaptation has stimulated interest in the community of machine learning since it can improve the performance of the model in a new domain (target domain) by borrowing knowledge from a labeled source domain. At the same time, the presence of large-scale labeled datasets also raised significant attention in this scenario: the class labels in the new domain are only a subset of those in the source domain. We propose an adversarial-net-based method in this paper, called domain compensatory adversarial network (DCAN). The critical difficulty of this problem is to reduce the negative impact of source instances with weak discriminability and filter out outlier source classes by exploiting the prior probability of classes. DCAN can identify source instances with weak discriminability and reverse its domain label to compensate for the target label space, which alleviates the negative effect of mismatching label space. Besides, DCAN reweights outlier source classes with the class prior distributions of source data for both category classifier and domain classifier to promote positive transfer. Experiments have revealed the superiority of DCAN compared to the existing methods.
C1 [Huang, Junchu; Zhang, Pengyu; Zhou, Zhiheng] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Zhou, Zhiheng] South China Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou, Peoples R China.
   [Fan, Kefeng] China Elect Standardizat Inst, Beijing 100007, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.; Zhou, ZH (corresponding author), South China Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023; Fan, K/GXH-3734-2022
FU National Key R&D Program of China [2018YFC030940 0]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC030940 0), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research
   projects(201902020008).
CR Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Blitzer J., 2008, ADV NEURAL INFORM PR, P129, DOI DOI 10.5555/2981562.2981579
   Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9
   Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288
   Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542
   Chen C, 2019, AAAI CONF ARTIF INTE, P3296
   Chen XY, 2019, PR MACH LEARN RES, V97
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116
   Hui Tang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8722, DOI 10.1109/CVPR42600.2020.00875
   Kumar A, 2018, ADV NEUR IN, V31
   Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058
   Lee S, 2019, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2019.00018
   LeTien N, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2852
   Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174
   Li K, 2020, P IEEECVF C COMPUTER, P12915
   Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528
   Li X, 2020, NEURAL NETWORKS, V129, P313, DOI 10.1016/j.neunet.2020.06.014
   Liang J, 2019, PROC CVPR IEEE, P2970, DOI 10.1109/CVPR.2019.00309
   Long MS, 2016, ADV NEUR IN, V29
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Mengxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13933, DOI 10.1109/CVPR42600.2020.01395
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9210, DOI 10.1109/CVPR42600.2020.00923
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Volpi R, 2018, PROC CVPR IEEE, P5495, DOI 10.1109/CVPR.2018.00576
   Wang J, 2019, IEEE INT CON MULTI, P1210, DOI 10.1109/ICME.2019.00211
   Xie S., 2018, P 35 INT C MACHINE L, P5423
   Xie SN, 2019, IEEE I CONF COMP VIS, P1284, DOI 10.1109/ICCV.2019.00137
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Zellinger Werner, 2017, ARXIV170208811
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
   Zohrizadeh F., 2019, CVPR WORKSH
   Zou H, 2019, AAAI CONF ARTIF INTE, P5997
NR 53
TC 2
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11255
EP 11272
DI 10.1007/s11042-020-10193-0
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605119800003
DA 2024-07-18
ER

PT J
AU Fu, KL
AF Fu, Kaili
TI Balancing user requirements and implementation difficulties in the
   requirements engineering of production tools for user-generated content:
   a case study of an animation application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision making; Quality function deployment; Requirements engineering;
   User-generated animation; Design process
ID WEB APPLICATION; DEPLOYMENT
AB Some content forms, such as animation, are superior in many aspects but rarely created in UGC systems partially due to the lack of available content-producing tools. Requirements engineering of User-Generated Content project can be difficult because of the diversities of user types, user abilities and client performance resulted from heterogeneous stakeholders. Based on the joint perspective of requirement analysis and quality control, this paper aims to propose an Exploratory Factor Analysis (EFA) integrated Quality Function Deployment (QFD) method. It divides users into expert and regular users, and allows the former to directly participate in design decisions and the latter to participate in prioritization. A case study of the requirements engineering of a Web-based animation application was carried out. The results showed the applicability of the proposed method to develop and manage requirements from all stakeholders. The integration of EFA contributed to the identification of unstated requirements to some extent. Also, the House of Quality was constructed and the quality requirements were obtained during the analysis. This approach helps analysts to sort out the priorities of user and technical requirements and achieve balance between them.
C1 [Fu, Kaili] Shanghai Jiao Tong Univ, Sch Design, 800 Dongchuan Rd, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Fu, KL (corresponding author), Shanghai Jiao Tong Univ, Sch Design, 800 Dongchuan Rd, Shanghai, Peoples R China.
EM lily.fkl@qq.com
RI fu, kaili/GXZ-8250-2022
OI fu, kaili/0000-0001-9528-244X
CR Afshan N., 2013, IUP Journal of Operations Management, V12, P48
   Ahmed M, 2015, LECT NOTES ELECTR EN, V315, P491, DOI 10.1007/978-3-319-07674-4_48
   Akao Y., 1990, QUALITY FUNCTION DEP
   Alder J., 2013, Eos, Transactions American Geophysical Union, V94, P197, DOI DOI 10.1002/2013EO220001
   Alrabghi L.O, 2013, QFD SOFTWARE ENG
   Anderson D.J., 2010, Kanban: successful Evolutionary Change for Your Technology Business
   [Anonymous], 2011, LATENT VARIABLE MODE
   [Anonymous], 2013, DESIGN USER EXPERIEN, DOI DOI 10.1007/978-3-642-39229-0_1
   Bai SS, 2013, DYNAMIC ANALYSIS AND CONTROL SYSTEM DESIGN OF AUTOMATIC TRANSMISSIONS, P185
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Beck K., 2000, EXTREME PROGRAMMING
   Beer D, 2010, J CONSUM CULT, V10, P3, DOI 10.1177/1469540509354009
   Berney S, 2016, COMPUT EDUC, V101, P150, DOI 10.1016/j.compedu.2016.06.005
   Boehm B, 2000, COMPUTER, V33, P99, DOI 10.1109/2.869384
   Bratteteig T., 2012, ASS COMPUTING MACHIN, V1, P41
   Brhel M, 2015, INFORM SOFTWARE TECH, V61, P163, DOI 10.1016/j.infsof.2015.01.004
   Brunt CS, 2020, J CULT ECON, V44, P35, DOI 10.1007/s10824-019-09349-0
   Burger D, 2013, ASTRON COMPUT, V2, P40, DOI 10.1016/j.ascom.2013.06.002
   Burgess J., 2009, YouTube: Online video and participatory culture
   Carmit S, 2012, ALBANY LAW J SCI TEC, V22, P279
   Chang YS, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON ADVANCED MANUFACTURING (IEEE ICAM), P477, DOI 10.1109/AMCON.2018.8614758
   Chen SC, 2004, HUM EXP TOXICOL, V23, P1, DOI 10.1191/0960327104ht407oa
   Child D., 2006, ESSENTIALS FACTOR AN, Vthird
   Constantine LL, 2002, IEEE SOFTWARE, V19, P42, DOI 10.1109/52.991331
   Crowston K, 2018, INT J HUM-COMPUT ST, V109, P89, DOI 10.1016/j.ijhcs.2017.08.005
   Garrigós I, 2009, LECT NOTES COMPUT SC, V5648, P151, DOI 10.1007/978-3-642-02818-2_11
   Geng LS, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4615320
   Gervais DanielJ., 2009, VANDERBILT J ENTERTA, V11, P841
   Grosser KM, 2019, JOURNALISM STUD, V20, P500, DOI 10.1080/1461670X.2017.1392255
   HAUSER JR, 1988, HARVARD BUS REV, V66, P63
   Herzwurm G, 2003, 11TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE, PROCEEDINGS, P330
   Herzwurm G, 2000, JOINT REQUIREMENTS E
   Inayat I, 2015, COMPUT HUM BEHAV, V51, P915, DOI 10.1016/j.chb.2014.10.046
   Ioannou G., 2004, Management Technology, V13, P1
   Kakar AS, 2016, J ORGAN END USER COM, V28, P32, DOI 10.4018/JOEUC.2016010103
   Kano N., 1984, Journal of The Japanese Society for Quality Control, V31, P147, DOI [DOI 10.20684/QUALITY.14.2_147, 10.20684/quality.14.2_147]
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kim AJ, 2016, COMPUT HUM BEHAV, V58, P98, DOI 10.1016/j.chb.2015.12.047
   Kramer S, 2016, CULT EXPR WOR WAR II, P69
   Kutschenreiter-Praszkiewicz I, 2013, J INTELL MANUF, V24, P397, DOI 10.1007/s10845-011-0604-7
   Lee E, 2015, CYBERPSYCH BEH SOC N, V18, P552, DOI 10.1089/cyber.2015.0157
   Li K, 2016, COMPUT HUM BEHAV, V54, P522, DOI 10.1016/j.chb.2015.08.056
   LIU K, 2019, SYMMETRY BASEL, V11
   Lukyanenko Roman, 2016, Scandinavian Journal of Information Systems, V28, P37
   Magee J, 2000, TENTH INTERNATIONAL WORKSHOP ON SOFTWARE SPECIFICATION AND DESIGN, P3, DOI 10.1109/IWSSD.2000.891121
   Midler Christophe, 2008, International Journal of Project Management, V26, P479, DOI 10.1016/j.ijproman.2008.05.003
   Nielsen Jakob, 2006, Jakob Nielsen's Alertbox, V107, P108
   Obendorf H., 2008, Proc. Conference on Human Factors in Computing Systems (CHI '08), P2159
   Offutt J, 2002, IEEE SOFTWARE, V19, P25, DOI 10.1109/52.991329
   OHMORI A, 1994, SOFTWARE QUAL J, V3, P209, DOI 10.1007/BF00403558
   Olsson HH, 2015, LECT NOTES BUS INF P, V210, P154, DOI 10.1007/978-3-319-19593-3_13
   Pandey D., 2010, Proceedings of 2010 International Conference on Advances in Recent Technologies in Communication and Computing (ARTCom 2010), P287, DOI 10.1109/ARTCom.2010.24
   PFITZNER D., 2003, PROC ASIA PACIFIC S, P57
   Raptis D., 2013, Proceedings of the 15th International Conference on Human-Computer Interaction with Mobile Devices and Services, P127, DOI 10.1145/2493190.2493204
   REES CA, 2004, BMC BIOINFORMATICS, V5
   Ritzer G, 2012, AM BEHAV SCI, V56, P379, DOI 10.1177/0002764211429368
   Schön EM, 2017, COMPUT STAND INTER, V49, P79, DOI 10.1016/j.csi.2016.08.011
   Schwaber K., 2009, AGILE PROJECT MANAGE
   Shimamura A.P., 2012, Aesthetic Science: Connecting Minds, Brains, and Experience
   Shindo H., 1999, PREC WORKSH 5 INT S
   Sivasamy K, 2016, QUAL QUANT, V50, P1399, DOI 10.1007/s11135-015-0212-2
   Stoica Marian, 2013, Informatica Economica, V17, P64
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Toffler A., 1981, The Third Wave
   Ukpabi DC, 2018, TOUR MANAG PERSPECT, V28, P251, DOI 10.1016/j.tmp.2018.03.006
   van Dijck J, 2009, MEDIA CULT SOC, V31, P41, DOI 10.1177/0163443708098245
   Vickery G., 2007, Participative web and user-created content: Web 2.0, wikis
   Wang YC, 2017, INT J INFORM MANAGE, V37, P179, DOI 10.1016/j.ijinfomgt.2015.11.005
   Xiao L., 2013, International Journal of Information and Education Technology, V3, P286, DOI [10.7763/IJIET.2013.V3.282, DOI 10.7763/IJIET.2013.V3.282]
   ZULTNER RE, 1994, ASQC 48TH ANNUAL QUALITY CONGRESS PROCEEDINGS, P783
NR 70
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11133
EP 11153
DI 10.1007/s11042-020-10216-w
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604816700006
DA 2024-07-18
ER

PT J
AU Francese, R
   Risi, M
   Tortora, G
AF Francese, Rita
   Risi, Michele
   Tortora, Genoveffa
TI A user-centered approach for detecting emotions with low-cost sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; Affective analysis; Artificial intelligence; Low-cost
   sensors
AB Detecting emotions is very useful in many fields, from health-care to human-computer interaction. In this paper, we propose an iterative user-centered methodology for supporting the development of an emotion detection system based on low-cost sensors. Artificial Intelligence techniques have been adopted for emotion classification. Different kind of Machine Learning classifiers have been experimentally trained on the users' biometrics data, such as hearth rate, movement and audio. The system has been developed in two iterations and, at the end of each of them, the performance of classifiers (MLP, CNN, LSTM, Bidirectional-LSTM and Decision Tree) has been compared. After the experiment, the SAM questionnaire is proposed to evaluate the user's affective state when using the system. In the first experiment we gathered data from 47 participants, in the second one an improved version of the system has been trained and validated by 107 people. The emotional analysis conducted at the end of each iteration suggests that reducing the device invasiveness may affect the user perceptions and also improve the classification performance.
C1 [Francese, Rita; Risi, Michele; Tortora, Genoveffa] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
C3 University of Salerno
RP Francese, R (corresponding author), Univ Salerno, Dept Comp Sci, Fisciano, Italy.
EM francese@unisa.it; mrisi@unisa.it; tortora@unisa.it
RI Tortora, Genoveffa/M-8155-2019
OI FRANCESE, Rita/0000-0002-6929-0056
FU Universit degli Studi di Salerno within the CRUI-CARE Agreement
FX Open access funding provided by Universit degli Studi di Salerno within
   the CRUI-CARE Agreement.
CR Agrafioti F, 2012, IEEE T AFFECT COMPUT, V3, P102, DOI 10.1109/T-AFFC.2011.28
   Alonso-Martín F, 2013, SENSORS-BASEL, V13, P15549, DOI 10.3390/s131115549
   [Anonymous], 2013, EMOTION FACE GUIDELI
   [Anonymous], 2017, Data Sci. Patt. Recogn, DOI DOI 10.3390/S22155775
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Bradley MM, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P581, DOI 10.1017/CBO9780511546396.025
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chao L, 2015, P 5 INT WORKSH AUD V, P65, DOI [DOI 10.1145/2808196.2811634, 10.1145/2808196.2811634]
   Citarella AA, 2019, IEEE INT CON INF VIS, P269, DOI 10.1109/IV.2019.00052
   Di Bitonto P, 2010, LECT NOTES ARTIF INT, V6070, P32, DOI 10.1007/978-3-642-13480-7_5
   Fritz T, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P402, DOI 10.1145/2568225.2568266
   Geisser, 1993, PREDICTIVE INFERENCE
   Girardi D, 2017, INT CONF AFFECT, P125, DOI 10.1109/ACII.2017.8273589
   Gong P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P140, DOI 10.1109/RCAR.2016.7784015
   Grissom R. J., 2005, EFFECT SIZES RES BRO
   Hartson HR, 2003, BEHAV INFORM TECHNOL, V22, P315, DOI 10.1080/01449290310001592587
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   Khan A.M., 2016, Proceedings of the 8th International Conference on eHealth, Telemedicine, and Social Medicine (eTELEMED), P131
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kurdi B, 2017, BEHAV RES METHODS, V49, P457, DOI 10.3758/s13428-016-0715-3
   Lang P. J., 1999, A4 U FLOR CTR RES PS
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Mehmood RM, 2017, IEEE ACCESS, V5, P14797, DOI 10.1109/ACCESS.2017.2724555
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Plutchik R., 1984, APPROACHES EMOTION, P197, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Pollreisz D, 2017, IEEE ENG MED BIO, P2353, DOI 10.1109/EMBC.2017.8037328
   Rattanadoung K, 2018, INT CONF CIRC SYST S, P79, DOI 10.1109/ICSIGSYS.2018.8373573
   Read JP, 2016, PSYCHOL ASSESSMENT, V28, P1276, DOI 10.1037/pas0000251
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Shu L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030718
   Stevenson RA, 2008, BEHAV RES METHODS, V40, P315, DOI 10.3758/BRM.40.1.315
   Sullivan Gail M, 2013, J Grad Med Educ, V5, P541, DOI 10.4300/JGME-5-4-18
   Valenza G., 2013, Autonomic Nervous System Dynamics for Mood And Emotional-State Recognition: Significant Advances
NR 36
TC 8
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35885
EP 35907
DI 10.1007/s11042-020-09576-0
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000593002500001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Touil, DE
   Terki, N
AF Touil, Djamel Eddine
   Terki, Nadjiba
TI Optimized color space for image compression based on DCT and Bat
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; DCT; PSNR; bpp; BA; Color base
ID WAVELET TRANSFORM
AB This paper develops an efficient color image compression method based on the DCT and a new color base. Digital color images are commonly represented in RGB space. Generally, it is noted that a strong correlation exists between the three planes R, G, and B of a color image. The reduction of this correlation certainly offers an advantage in the compression of RGB images. In this context, there is an infinite number of possible spaces to represent the RGB image. The main contributions of this paper are summarized in two main points. First, we design an optimized color space B1B2B3 using the Bat algorithm (BA) to pass from the RGB space to space more appropriate for each image. This space is produced by maximizing the energy of the image in the plane B-1 more than in B-2 and B-3. Second, we produce optimized thresholds appropriate to each plane of the converted image. The Bat algorithm optimizes the cost function to compute thresholds to partially reduce the number of the less significant DCT coefficients that correspond to the lower quantity of energy. The reported results against those of recent methods prove that the proposed method presents high performances in terms of peak signal to noise ratio (PSNR) on the commonly used test color images as well as the test medical images in literature.
C1 [Touil, Djamel Eddine] Univ Biskra, Energy Syst Modeling Lab, Biskra, Algeria.
   [Terki, Nadjiba] Univ Biskra, Dept Elect Engn, LESIA Lab, Biskra, Algeria.
C3 Universite Mohamed Khider Biskra; Universite Mohamed Khider Biskra
RP Touil, DE (corresponding author), Univ Biskra, Energy Syst Modeling Lab, Biskra, Algeria.
EM tde.touil@gmail.com
CR Al-Khafaji1 G., 2019, INT J COMPUTER SCI M, V8, P65
   [Anonymous], 1994, Mathematica Journal, DOI DOI 10.1016/0165-1684(90
   Author, 2013, INT J COMPUT SCI INF, V11, P51
   Boucetta A., 2012, LECT NOTES COMPUTER, V7340, P476
   Douak F, 2011, AEU-INT J ELECTRON C, V65, P16, DOI 10.1016/j.aeue.2010.03.003
   Hassan Enas Kh, 2018, Journal of Theoretical and Applied Information Technology, V96, P3160
   Jagadeesh B., 2013, INT J ENG TECHNOL, V12, P3216
   Jangbari P., 2016, Int. J. Comput. Appl, V134, P1, DOI [DOI 10.5120/IJCA2016907859, 10.5120/ijca2016907859]
   Kaur D, 2013, INT J ADV RES COMPUT, V2, P3145
   Martin A, 2010, REPRESENTATIONS PARC
   Mathur M. K., 2012, INT J COMPUT TECHNOL, V3, P76
   Messaoudi A, 2016, ELECTRON LETT, V52, P1685, DOI 10.1049/el.2016.2115
   Messaoudi A, 2019, SIGNAL IMAGE VIDEO P, V13, P1441, DOI 10.1007/s11760-019-01492-7
   Mody D, 2020, P 3 INT C ADV SCI TE
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Rathee M, 2014, INT J ENG INNOV TECH, V3
   Surabhi N., 2017, International Journal of Engineering Development and Research (IJEDR), V5, P585
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2014, NONLINEAR DYNAM, V75, P439, DOI 10.1007/s11071-013-1076-4
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2009, FRACTALS, V17, P109, DOI 10.1142/S0218348X09004247
   Wang XY, 2013, NONLINEAR DYNAM, V73, P347, DOI 10.1007/s11071-013-0790-2
   Wu MS, 2014, J VIS COMMUN IMAGE R, V25, P1835, DOI 10.1016/j.jvcir.2014.09.001
   Yang CX, 2018, SIGNAL IMAGE VIDEO P, V12, P1437, DOI 10.1007/s11760-018-1299-4
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
   Zhao Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P1, DOI [10.1109/aicas.2019.8771573, 10.1109/AICAS.2019.8771573]
NR 29
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9547
EP 9567
DI 10.1007/s11042-020-09754-0
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588614300005
DA 2024-07-18
ER

PT J
AU Shakoor, MH
   Boostani, R
AF Shakoor, Mohammad Hossein
   Boostani, Reza
TI Noise robust and rotation invariant texture classification based on
   local distribution transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local distribution transform; Local variance; Local binary pattern;
   Texture classification; Noise robust descriptor
ID BINARY PATTERNS; FEATURES; DESCRIPTOR
AB Applying local binary pattern (LBP) to images with uniform distribution leads to generate discriminative features; however, the distribution of all images is not necessarily uniform. The distribution of an image can be uniformzed if it passes through its cumulative distribution function (CDF), while estimation of CDF is highly sensitive to additive noises. In this paper, we propose a novel transform, which locally uniformize all patches of an image and approximately estimate a robust CDF. The proposed local distribution transform (LDT) generates continuous values and by quantizing them into discrete values, a histogram of features is constructed. We have fused the LDT features to the features of rotation invariant LBP and local variance (VAR) in order to provide a rich set of robust-to-noise features, which can detect both uniform and non-uniform patterns. The performance of the proposed LDT-LBP_VAR is assessed over a wide range of datasets like Outex, UIUC, CUReT, Coral Reef, Virus and ORL. The datasets are also corrupted by additive Gaussian noise with different signal to noise ratio (SNR) and the empirical results demonstrate that the proposed hybrid features provide superior classification results (P < 0.05) to the plenty of advanced descriptors over the datasets in both noise-free and noisy conditions.
C1 [Shakoor, Mohammad Hossein] Arak Univ, Dept Comp Engn, Fac Engn, Arak 3815688349, Iran.
   [Boostani, Reza] Shiraz Univ, Sch Elect & Comp Engn, Dept Comp Engn, Shiraz, Iran.
C3 Arak University; Shiraz University
RP Shakoor, MH (corresponding author), Arak Univ, Dept Comp Engn, Fac Engn, Arak 3815688349, Iran.
EM mh-shakoor@araku.ac.ir; boostani@shirazu.ac.ir
RI Boostani, Reza/ABC-5999-2021
OI Boostani, Reza/0000-0003-0055-4452
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen Timo., 2007, Proceedings of the Finnish Signal Processing Symposium, FINSIG, P1
   [Anonymous], 2007, Computer Vision
   [Anonymous], 2015, J INF HIDING MULTIME
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   AT& T Laboratories, 2002, DAT FAC
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Fathi A, 2012, PATTERN RECOGNITION
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Guo Z, 2014, IEEE T IMAGE PROCESS, V9, P1657
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Kylberg G., 2012, Virus Texture Dataset V. 1.0
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, LECT NOTES COMPUT SC, V9907, P69, DOI 10.1007/978-3-319-46487-9_5
   Mir AH, 1995, ENG MED BIOL MAGAZIN, V14
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papoulis A., 1965, PROBABILITY RANDOM V
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Qiao YL, 2010, DIGIT SIGNAL PROCESS, V20, P837, DOI 10.1016/j.dsp.2009.10.011
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Robert M.Haralick, 1979, IEEE T SYSTEMS MAN C
   Shakoor MH, 2017, SCI IRAN, V24, P1419, DOI 10.24200/sci.2017.4124
   Shakoor MH, 2018, MULTIMED TOOLS APPL, P1
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shakoor MH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500197
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   T Ojala, 1997, ACTA U IS OULU ENSIS, V105
   Talab ARR, 2018, INT C INT SYST COMP, P1
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang JW, 1998, IEICE T FUND ELECTR, VE81A, P1635
   Yuan FN, 2018, INFORM SCIENCES, V460, P202, DOI 10.1016/j.ins.2018.05.033
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 51
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8639
EP 8666
DI 10.1007/s11042-020-10084-4
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500007
DA 2024-07-18
ER

PT J
AU Setiadi, DIM
AF Setiadi, De Rosal Igantius Moses
TI PSNR vs SSIM: imperceptibility quality assessment for image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imperceptibility; Image&#160; Quality assessment; Image steganography;
   PSNR; SSIM; Image histogram
AB Peak signal to noise ratio (PSNR) and structural index similarity (SSIM) are two measuring tools that are widely used in image quality assessment. Especially in the steganography image, these two measuring instruments are used to measure the quality of imperceptibility. PSNR is used earlier than SSIM, is easy, has been widely used in various digital image measurements, and has been considered tested and valid. SSIM is a newer measurement tool that is designed based on three factors i.e. luminance, contrast, and structure to better suit the workings of the human visual system. Some research has discussed the correlation and comparison of these two measuring tools, but no research explicitly discusses and suggests which measurement tool is more suitable for steganography. This study aims to review, prove, and analyze the results of PSNR and SSIM measurements on three spatial domain image steganography methods, i.e. LSB, PVD, and CRT. Color images were chosen as container images because human vision is more sensitive to color changes than grayscale changes. Based on the test results found several opposing findings, where LSB has the most superior value based on PSNR and PVD get the most superior value based on SSIM. Additionally, the changes based on the histogram are more noticeable in LSB and CRT than in PVD. Other analyzes such as RS attack also show results that are more in line with SSIM measurements when compared to PSNR. Based on the results of testing and analysis, this research concludes that SSIM is a better measure of imperceptibility in all aspects and it is preferable that in the next steganographic research at least use SSIM.
C1 [Setiadi, De Rosal Igantius Moses] Dian Nuswantoro Univ, Dept Informat Engn, Semarang 50131, Indonesia.
C3 Dian Nuswantoro University
RP Setiadi, DIM (corresponding author), Dian Nuswantoro Univ, Dept Informat Engn, Semarang 50131, Indonesia.
EM moses@dsn.dinus.ac.id
RI Setiadi, De Rosal Ignatius Moses/V-1891-2019
OI Setiadi, De Rosal Ignatius Moses/0000-0001-6615-4457
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Aini Devita Nurul, 2019, 2019 International Seminar on Application for Technology of Information and Communication (iSemantic). Proceedings, P434, DOI 10.1109/ISEMANTIC.2019.8884333
   Akbar JM, 2023, APPL COMPUT INFORM, V19, P226, DOI 10.1016/j.aci.2019.10.002
   Al-Dmour H, 2015, I S BIOMED IMAGING, P1486, DOI 10.1109/ISBI.2015.7164158
   Aqeel I, 2019, COMM COM INF SC, V932, P713, DOI 10.1007/978-981-13-6052-7_61
   Arun C, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P674, DOI 10.1109/ICCSP.2017.8286444
   Astuti YP, 2018, 2018 INT C INF COMM
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chatterjee A, 2020, MULTIMED TOOLS APPL, V79, P11747, DOI 10.1007/s11042-019-08472-6
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Darbani A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P617, DOI 10.1109/KBEI.2019.8735054
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Grover R, 2018, 3RD INTERNATIONAL CONFERENCE ON INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH-18), P125
   Gupta Aditi, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P335, DOI 10.1109/ICACCCN.2018.8748477
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Horé A, 2013, IET IMAGE PROCESS, V7, P12, DOI 10.1049/iet-ipr.2012.0489
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Islam AU, 2017, 2016 6 INT C INN COM, P265
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Krasula L, 2017, IEEE T IMAGE PROCESS, V26, P1496, DOI 10.1109/TIP.2017.2651374
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Li XP, 2014, COMMUN NONLINEAR SCI, V19, P2373, DOI 10.1016/j.cnsns.2013.10.034
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Mukherjee S, 2019, MULTIMED TOOLS APPL, V78, P16363, DOI 10.1007/s11042-018-6975-4
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Patel N, 2017, 2016 INT C EM TRENDS
   Rashid RD, 2019, INT C COMM SIG PROC, DOI 10.1109/iccspa.2019.8713712
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Setiadi De Rosal Ignatius Moses, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P186, DOI 10.1109/ICOIACT.2018.8350670
   Setiadi D.R.I.M., 2019, INT J ELECT TELECOMM, V65, P295, DOI [10.24425/ijet.2019.126313, DOI 10.24425/IJET.2019.126313]
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shukla AK, 2020, MULTIMED TOOLS APPL, V79, P14201, DOI 10.1007/s11042-020-08641-y
   Singh A, 2015, P 2015 IEEE INT C EL
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Subong RA, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666228
   Sudibyo U, 2018, P 2017 4 INT C INF T
   Sundararajan D, 2017, DIGITAL IMAGE PROCES, P407
   Tan HL, 2013, IEEE T IMAGE PROCESS, V22, P4447, DOI 10.1109/TIP.2013.2273671
   Verma V, 2020, MULTIMED TOOLS APPL, V79, P7471, DOI 10.1007/s11042-019-08283-9
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P555, DOI 10.1007/s11042-019-08065-3
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
NR 52
TC 239
Z9 254
U1 48
U2 112
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8423
EP 8444
DI 10.1007/s11042-020-10035-z
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000585022600002
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Darwish, SM
   Almajtomi, AAJ
AF Darwish, Saad M.
   Almajtomi, Ahmed A. J.
TI Metaheuristic-based vector quantization approach: a new paradigm for
   neural network-based video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Intelligent vector quantization; Optimal codebook;
   Optimization
ID ALGORITHM
AB Video compression has great significance in the communication of motion pictures. Video compression techniques try to remove the different types of redundancy within or between video sequences. In the temporal domain, the video compression techniques remove the redundancies between the highly correlated consequence frames of the video. In the spatial domain, the video compression techniques remove the redundancies between the highly correlated consequence pixels (samples) in the same frame. Evolving neural-networks based video coding research efforts are focused on improving existing video codecs by performing better predictions that are incorporated within the same codec framework or holistic methods of end-to-end video compression schemes. Current neural network-based video compression adapts static codebook to achieve compression that leads to learning inability from new samples. This paper proposes a modified video compression model that adapts the genetic algorithm to build an optimal codebook for adaptive vector quantization that is used as an activation function inside the neural network's hidden layer. Background subtraction algorithm is employed to extract motion objects within frames to generate the context-based initial codebook. Furthermore, Differential Pulse Code Modulation (DPCM) is utilized for lossless compression of significant wavelet coefficients; whereas low energy coefficients are lossy compressed using Learning Vector Quantization (LVQ) neural networks. Finally, Run Length Encoding (RLE) is engaged to encode the quantized coefficients to achieve a higher compression ratio. Experiments have proven the system's ability to achieve higher compression ratio with acceptable efficiency measured by PSNR.
C1 [Darwish, Saad M.] Alexandria Univ, Inst Grad Studies & Res, Dept Informat Technol, 163 Horreya Ave,POB 832, Alexandria 21526, Egypt.
   [Almajtomi, Ahmed A. J.] Al Nahrain Univ, Coll Sci, Dept Comp Sci, Baghdad, Iraq.
C3 Egyptian Knowledge Bank (EKB); Alexandria University; Al-Nahrain
   University
RP Darwish, SM (corresponding author), Alexandria Univ, Inst Grad Studies & Res, Dept Informat Technol, 163 Horreya Ave,POB 832, Alexandria 21526, Egypt.
EM saad.darwish@alexu.edu.eg
RI Darwish, Saad Mohamed/ISB-6375-2023
OI Darwish, Saad/0000-0003-2723-1549
CR Afrabandpey H, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P1, DOI 10.1109/ICCKE.2014.6993337
   Atheeshwar M, 2014, INT J ADV RES ENG TE, V2, P5
   Bernatin T, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P452, DOI 10.1109/ICCICCT.2014.6993004
   Boufares O, 2016, INT J ADV COMPUT SC, V7, P29
   Chavan PU, 2009, INT C COMP ELEC ENG, P280, DOI 10.1109/ICCEE.2009.193
   Chen T, 2017, ADV MAT SCI ENG, V2017, P1, DOI DOI 10.1109/NAPS.2017.8107189
   Choi YJ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090993
   Duch W, 2005, P 15 INT C SCI BUS M, P11
   Elmolla AM, 2015, INT J COMPUT SCI TEL, V6, P7
   Elsayad AM, 2016, TECHNICAL REPORT
   Epitropakis MG, 2008, IEEE C EVOL COMPUTAT, P2686, DOI 10.1109/CEC.2008.4631159
   Esakkirajan S, 2009, 2009 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES, P40, DOI 10.1109/MSPCT.2009.5164169
   George NP, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P730, DOI 10.1109/ECS.2015.7125007
   Goswami K., 2017, J MULTIMED INF SYST, V4, P311
   Guo J, 2017, AAAI CONF ARTIF INTE, P4053
   Han Feng, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1315, DOI 10.1109/CISP.2011.6100502
   Ida MP, 2006, FUNDAMENTAL DATA COM, P49
   Inoue K, 2015, IEEE C EVOL COMPUTAT, P2548, DOI 10.1109/CEC.2015.7257202
   Kanithi A. K., 2011, THESIS
   Kim BG, 2008, IEEE T CIRC SYST VID, V18, P273, DOI 10.1109/TCSVT.2008.918121
   Kim BG, 2008, IEEE T CIRC SYST VID, V18, P127, DOI 10.1109/TCSVT.2007.913748
   Kim BG, 2017, J SUPERCOMPUT, V73, P1063, DOI 10.1007/s11227-016-1730-y
   Kim HS, 2012, IEEE T CIRC SYST VID, V22, P1280, DOI 10.1109/TCSVT.2012.2198137
   Knop M, 2016, LECT NOTES ARTIF INT, V9693, P660, DOI 10.1007/978-3-319-39384-1_58
   Knop M, 2014, LECT NOTES ARTIF INT, V8467, P715, DOI 10.1007/978-3-319-07173-2_61
   Kumar G, 2016, PROCEDIA COMPUT SCI, V93, P1010, DOI 10.1016/j.procs.2016.07.304
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Lin HY, 2014, IRBM, V35, P351, DOI 10.1016/j.irbm.2014.10.004
   Lu G., 2019, IEEE C COMP VIS PATT
   Lu T.C., 2010, J. Inf. Hiding Multim. Signal Process., V1, P190
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Ma XX, 2015, IET IMAGE PROCESS, V9, P290, DOI 10.1049/iet-ipr.2014.0125
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Montgomery C., VIDEO TEST MEDIA
   Nithin S, 2016, P IEEE INT C CIRC PO
   Patel B, 2013, INT J PHARM RES REV, V2, P1
   Ponlatha S., 2013, International Journal of Computer and Electrical Engineering, V5, P549, DOI 10.7763/IJCEE.2013.V5.770
   Rubina IS, 2015, COMM COM INF SC, V535, P674, DOI 10.1007/978-3-319-23766-4_53
   Singh AV, 2013, LECT NOTES ELECT ENG, V258, P179
   Singh MP, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P272, DOI 10.1109/ICIINFS.2009.5429851
   Sivanandam S., 2007, INTRO GENETIC ALGORI, P15
   Sun HW, 2005, NEURAL COMPUT APPL, V14, P203, DOI 10.1007/s00521-004-0455-7
   Suri A, 2014, INT J COMPUT APPL, V97, P26
   Tomar RRS, 2015, INT CONF COMPUT INTE, P397, DOI 10.1109/CICN.2015.84
   Wang W, 2005, WIREL NETW MOB COMP, V3, P21
   Wei J, 2015, I C INTELL COMPUT TE, P209, DOI 10.1109/ICICTA.2015.60
   Zhang L, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 5, PROCEEDINGS, P559, DOI 10.1109/ICNC.2008.252
NR 47
TC 7
Z9 7
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7367
EP 7396
DI 10.1007/s11042-020-10003-7
EA OCT 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400001
DA 2024-07-18
ER

PT J
AU Sejwal, VK
   Abulaish, M
AF Sejwal, Vineet Kumar
   Abulaish, Muhammad
TI CAMO: A context-aware movie ontology generated from LOD and movie
   databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology engineering; Movie ontology; Contextual features;
   Representational features; Interactional features; Linked open data
ID RECOMMENDER SYSTEMS; INFORMATION
AB An ontology is a formal representation of domain knowledge as a set of concepts and their relationships in structured format. Besides various applications, ontology has been frequently used for the development of movie recommender systems that aim to predict the rating a user would give to a movie. Though recommender system is a well-studied research field, issues like cold-start, data sparsity, limited-content, and long tail are still open challenges. Context-aware recommender systems have been considered by many researchers to deal with some of these issues. However, non-existence of domain ontology containing contextual information is the major hindrance for the development of such systems. This is mainly due to the fact that datasets used in most of the existing context-aware recommender systems are either synthetic or generated through surveys. In this paper, we present the development of a context-aware movie ontology (CAMO) that contains movie concepts, relationships, and various representational and interactional contextual features. Since existing movie databases do not contain all contextual features, we have generated a real-world movie dataset from Linked Open Data (LOD) and movie databases like IMDB and Rotten Tomatoes that contain complete context-based movie profiles. CAMO contains the conceptualization of total 1103 movies. Since users generally express their opinion over the interactional features like story, direction, music, visual effects, etc. of the movies, CAMO also contains aspect-based sentiment polarity identified from the reviews generated by 78056 users and 235 critics. The usefulness of CAMO is empirically evaluated using two similarity measures and two state-of-the-art recommendation methods, and it seems a useful movie knowledgebase for the development of context-aware movie recommendation systems. The source code of CAMO is uploaded at for research and academic reference purposes. The generated movie dataset containing movie details, user ratings, and reviews generated by both users and critics is also uploaded, and it can be used as a benchmark dataset to evaluate movie recommender systems.
C1 [Sejwal, Vineet Kumar] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
   [Abulaish, Muhammad] South Asian Univ, Dept Comp Sci, New Delhi, India.
C3 Jamia Millia Islamia; South Asian University (SAU)
RP Abulaish, M (corresponding author), South Asian Univ, Dept Comp Sci, New Delhi, India.
EM vineetsejwal.jmi@gmail.com; abulaish@sau.ac.in
RI ; Abulaish, Muhammad/L-7397-2014
OI Imene, Cheniki/0009-0008-6743-9137; Abulaish,
   Muhammad/0000-0003-3387-4743
CR Abowd GD, 1999, P 1 INT S HANDH UB C, P3014
   Abulaish M, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P379, DOI 10.1109/WI.2005.43
   Abulaish M, 2007, DATA KNOWL ENG, V61, P228, DOI 10.1016/j.datak.2006.06.007
   Aciar S, 2007, IEEE INTELL SYST, V22, P39, DOI 10.1109/MIS.2007.55
   Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Aguilar Jose, 2018, Applied Computing and Informatics, V14, P202, DOI 10.1016/j.aci.2017.08.001
   Bouza A., 2010, MO THE MOVIE ONTOLOG
   Celjuska D, 2004, P 3 INT C NAT LANG P, P1
   Domingues MA, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P210, DOI 10.1109/WI-IAT.2014.100
   Dourish P, 2004, PERS UBIQUIT COMPUT, V8, P19, DOI 10.1007/s00779-003-0253-8
   Glimm B, 2014, J AUTOM REASONING, V53, P245, DOI 10.1007/s10817-014-9305-1
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Hariri N., 2011, Proceedings of the 9th Workshop on Intelligent Techniques for Web Personalization and Recommender Systems (ITWP 2011), P30
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Kosir A, 2011, ELEKTROTEH VESTN, V78, P270
   Li Yongming, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P692, DOI 10.1109/ICCIS.2010.172
   Lu ZJ, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY PROCEEDINGS - CYBERC 2016, P128, DOI 10.1109/CyberC.2016.34
   Ruiz-Martínez JM, 2011, INT J INNOV COMPUT I, V7, P6115
   Maynard D, 2009, P 3 INT C DIG LIB SE
   Meymandpour R, 2016, KNOWL-BASED SYST, V109, P276, DOI 10.1016/j.knosys.2016.07.012
   Mirizzi Roberto., 2012, HR, P101
   Navigli R., 2006, Proceedings of the 2nd workshop on ontology learning and population: Bridging the gap between text and knowledge, P1
   Noy NF, 2009, SMI20010880
   Colombo-Mendoza LO, 2015, EXPERT SYST APPL, V42, P1202, DOI 10.1016/j.eswa.2014.09.016
   Ostuni VC, 2012, P 1 INT WORKSH SEM T, P25
   Ou S, 2008, P 6 LANG RES EV C LR
   Schafer J. B., 2007, LECT NOTES COMPUT SC, V4321, P29
   Sieg A, 2004, INFERRING USERS INFO
   Sulthana AR, 2019, COMPUT ELECTR ENG, V74, P498, DOI 10.1016/j.compeleceng.2018.01.034
   Tanev S, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2400239
   Todoroki E, 2009, WOR BANK WORK PAPER, P1, DOI 10.1596/978-0-8213-7919-6
   Velardi P., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P270, DOI 10.1145/505168.505194
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Zheng Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1668, DOI 10.1109/ICDMW.2015.222
NR 36
TC 3
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7247
EP 7269
DI 10.1007/s11042-020-10076-4
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568200003
DA 2024-07-18
ER

PT J
AU Li, XL
   Li, RG
   Zhao, YQ
   Zhao, J
AF Li, Xuelei
   Li, Rengang
   Zhao, Yaqian
   Zhao, Jian
TI An improved model training method for residual convolutional neural
   networks in deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Residual convolutional neural network; Deep
   learning; Artificial intelligence
AB Residual convolutional neural network (R-CNN) has become a promising method for image recognition in deep learning applications. The application accuracy, as a key indicator, has a close relationship with filter weights in trained R-CNN models. In order to make filters work at full capacity, we find out that lower relevancy between filters in the same layer promotes higher accuracy for R-CNN applications. Furthermore, we propose an improved R-CNN model training method to acquire a higher accuracy and a better generalization ability. In this paper, the main focus is to control the update of filter weights during model training. The key mechanism is achieved through computing the relevancy between filters in the same layer. The relevancy is quantified by a correlation coefficient, e.g., Pearson Correlation Coefficient (PCC). The mechanism takes a larger probability to utilize the updated filter weights with a lower correlation coefficient, and vice versa. In order to validate our proposal, we construct an experiment through PCC on residual networks. The experiment demonstrates that the improved model training method is a promising mean with better generalization ability and higher recognition accuracy (0.52%-1.83%) for residual networks.
C1 [Li, Xuelei] Inspur Beijing Elect Informat Ind Co Ltd, Beijing 100876, Peoples R China.
   [Li, Rengang; Zhao, Yaqian; Zhao, Jian] Inspur Elect Informat Ind Co Ltd, Jinan 250101, Peoples R China.
   [Li, Rengang; Zhao, Yaqian; Zhao, Jian] State Key Lab High End Server & Storage Technol, Jinan 250101, Peoples R China.
C3 Inspur; Inspur
RP Li, XL (corresponding author), Inspur Beijing Elect Informat Ind Co Ltd, Beijing 100876, Peoples R China.
EM will8898@163.com
OI Li, Xuelei/0000-0002-7935-6290
FU Major Innovation Project of Shandong Province [2019TSLH0201]
FX We would like to thank the anonymous reviewers for their valuable
   comments and professional suggestions on previous drafts of this paper.
   Moreover, we would like to thank my colleagues for their technical help,
   including Xin Zhang, Li Wang, Zhenhua Guo at Inspur, and Hongwei Wang
   from Kingsoft, Xiaomin Zhu from Jinan. This work is supported by Major
   Innovation Project of Shandong Province (Grant No. 2019TSLH0201):
   Research, Development and Industrialization of Artificial Intelligence
   Chip for Streaming Media.
CR Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Galton F., 1886, The Journal of the Anthropological Institute of Great Britain and Ireland, V15, P246, DOI [10.2307/2841583, DOI 10.2307/2841583]
   Genovese A, 2019, IEEE IMAGE PROC, P3806, DOI [10.1109/icip.2019.8803616, 10.1109/ICIP.2019.8803616]
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li XL, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P837, DOI 10.1109/ITNEC.2017.8284852
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI [DOI 10.1098/RSPL.1895.0041, 10.1098/rspl.1895.0041]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI [DOI 10.1145/2684746.2689060, 10.1145/2684746.2689060]
   Zhao YQ, 2019, 2019 ELEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI 2019), P13, DOI [10.1109/icaci.2019.8778613, 10.1109/ICACI.2019.8778613]
NR 16
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6811
EP 6821
DI 10.1007/s11042-020-10031-3
EA OCT 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569800004
DA 2024-07-18
ER

PT J
AU Diaz-Guerra, D
   Miguel, A
   Beltran, JR
AF Diaz-Guerra, David
   Miguel, Antonio
   Beltran, Jose R.
TI gpuRIR: A python library for room impulse response simulation with GPU
   acceleration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Room impulse response (RIR); Image source method (ISM); Room acoustics;
   Graphic processing units (GPUs)
ID MULTIPLE; ENVIRONMENT; ROBUSTNESS
AB The Image Source Method (ISM) is one of the most employed techniques to calculate acoustic Room Impulse Responses (RIRs), however, its computational complexity grows fast with the reverberation time of the room and its computation time can be prohibitive for some applications where a huge number of RIRs are needed. In this paper, we present a new implementation that dramatically improves the computation speed of the ISM by using Graphic Processing Units (GPUs) to parallelize both the simulation of multiple RIRs and the computation of the images inside each RIR. Additional speedups were achieved by exploiting the mixed precision capabilities of the newer GPUs and by using lookup tables. We provide a Python library under GNU license that can be easily used without any knowledge about GPU programming and we show that it is about 100 times faster than other state of the art CPU libraries. It may become a powerful tool for many applications that need to perform a large number of acoustic simulations, such as training machine learning systems for audio signal processing, or for real-time room acoustics simulations for immersive multimedia systems, such as augmented or virtual reality.
C1 [Diaz-Guerra, David; Miguel, Antonio; Beltran, Jose R.] Univ Zaragoza, Dept Elect Engn & Commun, Zaragoza, Spain.
C3 University of Zaragoza
RP Diaz-Guerra, D (corresponding author), Univ Zaragoza, Dept Elect Engn & Commun, Zaragoza, Spain.
EM ddga@unizar.es
RI Diaz-Guerra, David/E-2561-2019; Beltran, Jose Ramon/K-7693-2015; Miguel,
   Antonio/B-6044-2017
OI Diaz-Guerra, David/0000-0002-1041-0498; Beltran, Jose
   Ramon/0000-0002-7500-4650; 
FU Regional Government of Aragon (Spain); Operative Program FSE Aragon
   2014-2020; Google Cloud
FX This work was supported in part by the Regional Government of Aragon
   (Spain) with a grant for postgraduate research contracts (2017-2021)
   co-funded by the Operative Program FSE Aragon 2014-2020. This material
   is based upon work supported by Google Cloud.
CR Alexandridis A, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/718574
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], 1962, J. Audio Eng. Soc.
   Antonio J, 2002, ACTA ACUST UNITED AC, V88, P10
   Ceolini E, 2020, IEEE-ACM T AUDIO SPE, V28, P1428, DOI 10.1109/TASLP.2020.2989545
   Chao Weng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5532, DOI 10.1109/ICASSP.2014.6854661
   Diaz-Guerra D, 2020, ARXIV200609006CSEESS
   Fu ZH, 2016, MULTIMED TOOLS APPL, V75, P5205, DOI 10.1007/s11042-015-2943-4
   Griffin A, 2015, SIGNAL PROCESS, V107, P54, DOI 10.1016/j.sigpro.2014.08.013
   Habets E. A. P, 2010, Tech. Rep.
   Hassani A, 2017, IEEE J-STSP, V11, P518, DOI 10.1109/JSTSP.2017.2676982
   Lehmann EA, 2018, MATLAB IMPLEMENTATIO
   Lehmann EA, 2008, J ACOUST SOC AM, V124, P269, DOI 10.1121/1.2936367
   Lehmann EA, 2010, IEEE T AUDIO SPEECH, V18, P1429, DOI 10.1109/TASL.2009.2035038
   Luo Y, 2020, INT CONF ACOUST SPEE, P6394, DOI [10.1109/ICASSP40776.2020.9054177, 10.1109/icassp40776.2020.9054177]
   Luo Y, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P260, DOI [10.1109/asru46091.2019.9003849, 10.1109/ASRU46091.2019.9003849]
   Markovich S, 2009, IEEE T AUDIO SPEECH, V17, P1071, DOI 10.1109/TASL.2009.2016395
   Marvin182, 2018, ROOM IMPULSE RESPONS
   Mirbagheri M, 2020, ARXIV200605071CSEESS
   Mosner L, 2019, INT CONF ACOUST SPEE, P6475, DOI 10.1109/ICASSP.2019.8683422
   Myklebust TGJ, 2015, ARXIV150803211CSMATH
   Nickolls J, 2008, ACM SIGGRAPH 2008 CL, P16
   Pavlidi D, 2012, INT CONF ACOUST SPEE, P2625, DOI 10.1109/ICASSP.2012.6288455
   PETERSON PM, 1986, J ACOUST SOC AM, V80, P1527, DOI 10.1121/1.394357
   Qin XY, 2019, INTERSPEECH, P4045, DOI 10.21437/Interspeech.2019-1542
   Radlovic BD, 2000, IEEE T SPEECH AUDI P, V8, P311, DOI 10.1109/89.841213
   Sabine W.C., 1922, Collected papers on acoustics
   Scheibler R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P351, DOI 10.1109/ICASSP.2018.8461310
   Severini M, 2019, IEEE ACCESS, V7, P51982, DOI 10.1109/ACCESS.2019.2911427
   Wang D, 2020, ARXIV200413670CSEESS
   Williamson DS, 2017, IEEE-ACM T AUDIO SPE, V25, P1492, DOI 10.1109/TASLP.2017.2696307
   Ziegler P, 2020, MECH MACH THEORY, V148, DOI 10.1016/j.mechmachtheory.2020.103785
NR 32
TC 47
Z9 51
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5653
EP 5671
DI 10.1007/s11042-020-09905-3
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600004
DA 2024-07-18
ER

PT J
AU Massa, L
   Barbosa, A
   Oliveira, K
   Vieira, T
AF Massa, Lucas
   Barbosa, Adriano
   Oliveira, Krerley
   Vieira, Thales
TI LRCN-RetailNet: A recurrent neural network architecture for accurate
   people counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People counting; Retail analysis; Surveillance; Deep learning; LRCN
ID TRACKING; SEGMENTATION; MULTIPLE; HUMANS; SCENES
AB Measuring and analyzing the flow of customers in retail stores is essential for a retailer to better comprehend customers' behavior and support decision-making. Nevertheless, not much attention has been given to the development of novel technologies for automatic people counting. We introduce LRCN-RetailNet: a recurrent neural network architecture capable of learning a non-linear regression model and accurately predicting the people count from videos captured by low-cost surveillance cameras. The input video format follows the recently proposed RGBP image format, which is comprised of color and people (foreground) information. Our architecture is capable of considering two relevant aspects: spatial features extracted through convolutional layers from the RGBP images; and the temporal coherence of the problem, which is exploited by recurrent layers. We show that, through a supervised learning approach, the trained models are capable of predicting the people count with high accuracy. Additionally, we present and demonstrate that a straightforward modification of the methodology is effective to exclude salespeople from the people count. Comprehensive experiments were conducted to validate, evaluate and compare the proposed architecture. Results corroborated that LRCN-RetailNet remarkably outperforms both the previous RetailNet architecture, which was limited to evaluating a single image per iteration; and two state-of-the-art neural networks for object detection. Finally, computational performance experiments confirmed that the entire methodology is effective to estimate people count in real-time.
C1 [Massa, Lucas; Vieira, Thales] Univ Fed Alagoas, Inst Comp, Maceio, Al, Brazil.
   [Barbosa, Adriano] Fed Univ Grande Dourados, Fac Exact Sci & Technol, Dourados, MS, Brazil.
   [Oliveira, Krerley] Univ Fed Alagoas, Inst Math, Maceio, AL, Brazil.
C3 Universidade Federal de Alagoas; Universidade Federal da Grande
   Dourados; Universidade Federal de Alagoas
RP Vieira, T (corresponding author), Univ Fed Alagoas, Inst Comp, Maceio, Al, Brazil.
EM lmm@ic.ufal.br; adrianobarbosa@ufgd.edu.br; krerley@im.ufal.br;
   thales@ic.ufal.br
RI de Almeida Vieira, Thales Miranda/C-7689-2017; Barbosa,
   Adriano/C-9060-2015
OI de Almeida Vieira, Thales Miranda/0000-0001-7775-5258; 
FU CNPq/PIBITI/UFAL; PRMB Comercio e Distribuidora de Calcados LTDA
FX The authors would like to thank CNPq/PIBITI/UFAL for the first author's
   scholarship and PRMB Comercio e Distribuidora de Calcados LTDA for
   partially financing this research.
CR Amaral L, 2019, PALG STUD ECON HIST, P309, DOI 10.1007/978-3-030-24548-1_8
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao CQ, 2016, MULTIMED TOOLS APPL, V75, P9315, DOI 10.1007/s11042-016-3344-z
   Hawkins D., 2015, Consumer behavior: Building marketing strategy, V11th
   Huang X., 2020, P IEEE CVF C COMP VI, P10747, DOI DOI 10.1109/CVPR42600.2020.01076
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Kingma D. P., 2014, arXiv
   Lam SY, 1998, J RETAILING, V74, P61, DOI 10.1016/S0022-4359(99)80088-8
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li M, 2008, INT C PATT RECOG, P1998
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu GJ, 2017, KNOWL-BASED SYST, V123, P102, DOI 10.1016/j.knosys.2017.02.016
   Liu JW, 2017, MULTIMED TOOLS APPL, V76, P6595, DOI 10.1007/s11042-016-3342-1
   Liu J, 2013, IEEE IMAGE PROC, P3088, DOI 10.1109/ICIP.2013.6738636
   Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773
   Nogueira V, 2019, SIBGRAPI, P155, DOI 10.1109/SIBGRAPI.2019.00029
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Rauter M, 2013, IEEE COMPUT SOC CONF, P529, DOI 10.1109/CVPRW.2013.84
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabzmeydani P., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383134
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Sun SJ, 2019, IEEE T INTELL TRANSP, V20, P3599, DOI 10.1109/TITS.2019.2911128
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Wei XL, 2019, PATTERN RECOGN LETT, V119, P12, DOI 10.1016/j.patrec.2017.12.002
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Xu B, 2016, Int J Photoenergy, V2016, P1, DOI DOI 10.1155/2016/4749278
   Xuangeng Chu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12211, DOI 10.1109/CVPR42600.2020.01223
   Yang YF, 2020, PROC CVPR IEEE, P4373, DOI 10.1109/CVPR42600.2020.00443
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang XC, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P215, DOI 10.1109/AVSS.2012.82
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 43
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5517
EP 5537
DI 10.1007/s11042-020-09971-7
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577469600004
DA 2024-07-18
ER

PT J
AU Xu, J
AF Xu, Jie
TI A deep learning approach to building an intelligent video surveillance
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Video surveillance; Machine learning; Object detection;
   Face recognition
ID OBJECT DETECTION
AB Recent advances in the field of object detection and face recognition have made it possible to develop practical video surveillance systems with embedded object detection and face recognition functionalities that are accurate and fast enough for commercial uses. In this paper, we compare some of the latest approaches to object detection and face recognition and provide reasons why they may or may not be amongst the best to be used in video surveillance applications in terms of both accuracy and speed. It is discovered that Faster R-CNN with Inception ResNet V2 is able to achieve some of the best accuracies while maintaining real-time rates. Single Shot Detector (SSD) with MobileNet, on the other hand, is incredibly fast and still accurate enough for most applications. As for face recognition, FaceNet with Multi-task Cascaded Convolutional Networks (MTCNN) achieves higher accuracy than advances such as DeepFace and DeepID2+ while being faster. An end-to-end video surveillance system is also proposed which could be used as a starting point for more complex systems. Various experiments have also been attempted on trained models with observations explained in detail. We finish by discussing video object detection and video salient object detection approaches which could potentially be used as future improvements to the proposed system.
C1 [Xu, Jie] Univ Manchester, Dept Comp Sci, Manchester, Lancs, England.
C3 University of Manchester
RP Xu, J (corresponding author), Univ Manchester, Dept Comp Sci, Manchester, Lancs, England.
EM jie.xu-4@student.manchester.ac.uk
OI Xu, Jie/0000-0002-2287-9971
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Dai JF, 2016, ADV NEUR IN, V29
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elkin M, 2020, CRIME ENGLAND WALES
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farrington D.P., 2007, Journal of Experimental Criminology, V3, P21, DOI [DOI 10.1007/s11292-007-9024-2, DOI 10.1007/S11292-007-9024-2]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He S, 2019, IEEE IC COMP COM NET, DOI 10.1109/icccn.2019.8847016
   Howard A. G., 2017, arXiv
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lomonaco V, 2019, CORE50
   Lomonaco V., 2017, P 1 ANN C ROB LEARN, P17
   Lomonaco V, 2019, ARXIV190703799
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   McCabe Donald L., 2017, Cheating in College: Why Students do it and What Educators can do About it
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sandberg D, 2018, FACE RECOGNITION USI
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu XZ, 2018, PROC CVPR IEEE, P7210, DOI 10.1109/CVPR.2018.00753
NR 45
TC 21
Z9 21
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5495
EP 5515
DI 10.1007/s11042-020-09964-6
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577469600006
OA hybrid
DA 2024-07-18
ER

PT J
AU Hussein, A
   El-Rabaie, S
   El-Mashed, MG
AF Hussein, A.
   El-Rabaie, S.
   El-Mashed, M. G.
TI Proactive discovery protocol with security enhancement for D2D
   communication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE D2D communication; Discovery; Overhead; Security; Elliptic curve;
   Diffie-Hellman and ElGamal
AB With the increase in mobile traffic and the band-width demand, Device-to-Device (D2D) communication has gained tremendous interest by the researchers, cellular operators and equipment manufacturers. However, D2D communication has been limited to study the converge services at cell edge. D2D users that located outside the cellular network coverage haven't received enough attention. Some of the problems faced in this case are discovering process of neighbor user equipment (UE) and services, as well as designing suitable and secure protocols for D2D communication. Toward these problems, in this paper, we propose security enhancement for D2D communication based on modified elliptic curve cryptography (MECC), which provides greater efficiency in computational overhead, key sizes and bandwidths for user's authentication applied on proactive routing protocol for neighbor and service discovery. We studyDiffie-Hellman, ElGamal andMECC techniques to improve service of D2D users at cell edge. Results show that the proposed scheme can strength the secrecy with less control overhead and can increase the robustness in a wide range of scenarios for service discovery in D2D networks.
C1 [Hussein, A.] El Arish Higher Inst Engn & Tech, Dept Elect & Commun Engn, Arish, Egypt.
   [El-Rabaie, S.; El-Mashed, M. G.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Shibin Al Kawm, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hussein, A (corresponding author), El Arish Higher Inst Engn & Tech, Dept Elect & Commun Engn, Arish, Egypt.
EM prof.ahmad.25488@gmail.com
OI EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abdellatif Sami, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P910, DOI 10.1007/978-3-030-44041-1_79
   Adhikari S, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3839
   Ahishakiye F, 2014, 2014 IEEE GLOB WORKS
   Al-Ayyoub M, 2019, COMPUT ELECTR ENG, V74, P533, DOI 10.1016/j.compeleceng.2018.01.003
   Almiani Muder, 2018, International Journal of High Performance Computing and Networking, V12, P251
   Alvarez R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071517
   [Anonymous], 2011, INFORM SECURITY PRIN
   [Anonymous], 2014, 2014 IEEE GLOB COMM
   Bharathi R, 2019, INT J SOFTW SCI COMP, V11, P1, DOI 10.4018/IJSSCI.2019070101
   Cao MS, 2019, IEEE ACCESS, V7, P33759, DOI 10.1109/ACCESS.2019.2900727
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Hussein HH, 2020, WIREL NETW, V26, P3183, DOI 10.1007/s11276-019-02131-2
   Javed Y, 2018, EEOP LIGHTWEIGHT SEC, V9, P3
   Khalique A., 2010, Int J Comput Appl, V2, P21, DOI [10.5120/631876, DOI 10.5120/631876]
   Kim S, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/3540674
   Kota Sujatha, 2018, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V99, P343, DOI 10.1007/s40031-018-0324-x
   Nasraoui L, 2017, 2017 IEEE 28 ANN
   Olakanmi OO, 2019, INT J CLOUD APPL COM, V9, P79, DOI 10.4018/IJCAC.2019040105
   Qureshi B, 2018, INT J CLOUD APPL COM, V8, P27, DOI 10.4018/IJCAC.2018040102
   Roy S., 2017, CRYPTOGRAPHY-BASEL, V1, P9, DOI DOI 10.3390/CRYPTOGRAPHY1010009
   Sun YQ, 2019, INT C INTEL HUM MACH, P3, DOI 10.1109/IHMSC.2019.10096
   Tayeb Shahab, 2019, International Journal of e-Education, e-Business, e-Management and e-Learning, V9, P108, DOI 10.17706/ijeeee.2019.9.2.108-115
   Vassilev TS, 2013, ALGORITHMS RES, V1, P31
   Wang JH, 2016, IEEE SIGNAL PROC LET, V23, P1622, DOI 10.1109/LSP.2016.2611614
   Wang W, 2017, IEEE WIREL COMMUN LE, V6, P106, DOI 10.1109/LWC.2016.2634559
   Waqas M, 2018, IEEE T WIREL COMMUN, V17, P3918, DOI 10.1109/TWC.2018.2817607
   Yan Z, 2018, FUTURE GENER COMP SY, V82, P738, DOI 10.1016/j.future.2017.08.052
NR 27
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5047
EP 5066
DI 10.1007/s11042-020-09799-1
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600001
DA 2024-07-18
ER

PT J
AU Monika, R
   Samiappan, D
   Kumar, R
AF Monika, R.
   Samiappan, Dhanalakshmi
   Kumar, R.
TI Adaptive block compressed sensing-a technological analysis and survey on
   challenges, innovation directions and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Block compressed sensing; Adaptive block compressed
   sensing; Saliency; Image perception; Texture contrast; Spatial entropy
ID SPARSE REPRESENTATION; SIGNAL RECOVERY
AB In today's digital world, data transmission and storage is becoming a massive problem. This is because the data produced by various sensors worldwide is outstripping the ability to store them. Pre-processing the entire data before transmission is the best solution for reducing the storage issue. 'Compressed sensing'(CS) is a pre-processing technique that exploits the sparsity of the signal for sampling the data. Since most of the natural signals are sparse, CS allows sampling at a rate lesser than that required in Nyquist sampling theorem. However, in conventional CS, sampling is done for the entire image at once which increases processing time and reduces visual quality. In block compressed sensing (BCS), blocks of the images are processed simultaneously which increases processing speed and decreases the processing time. To improve the quality of the reconstructed signal, a variant of BCS, Adaptive block compressed sensing (ABCS) is used. This review paper studies the advantages, challenges and applications of applying ABCS for image compression.
C1 [Monika, R.; Samiappan, Dhanalakshmi; Kumar, R.] SRM Inst Sci & Technol, Fac Engn & Technol, Coll Engn & Technol, Dept ECE, Kattankulathur 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Samiappan, D (corresponding author), SRM Inst Sci & Technol, Fac Engn & Technol, Coll Engn & Technol, Dept ECE, Kattankulathur 603203, Tamil Nadu, India.
EM dhanalas@srmist.edu.in
RI Dhanalakshmi, S./J-2073-2018; R, Monika/AAE-7469-2021
OI Dhanalakshmi, S./0000-0002-6970-2719; R, Monika/0000-0002-7814-6611
CR Amir A, 2011, J COMPUT BIOL, V18, P1723, DOI 10.1089/cmb.2011.0189
   Bajwa WU, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P294, DOI 10.1109/SSP.2007.4301266
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Baraniuk RG, 2010, P IEEE, V98, P906, DOI 10.1109/JPROC.2010.2047424
   Bhateja AK, 2016, PATTERN RECOGN LETT, V73, P13, DOI 10.1016/j.patrec.2015.12.009
   Binev P., 2012, Modelling Nanoscale Imaging in Electron Microscopy, P73, DOI DOI 10.1007/978-1-4614-2191-7_4
   Candes E., 2004, Wavelet Applications in Signal and Image Processing XI, P5914
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   CANH TN, 2014, P IEEE INT C MULT EX, P1, DOI DOI 10.1109/ICME.2014.6890251
   Dai W, 2009, EURASIP J BIOINFORM, DOI 10.1155/2009/162824
   Deng CW, 2010, IEEE INT CON MULTI, P462, DOI 10.1109/ICME.2010.5583387
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fang Wang, 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P351, DOI 10.1109/ICIS.2012.83
   FORNASIER M., 2011, Handbook of Mathematical Methods in Imaging, P187, DOI [DOI 10.1007/978-0-387-92920-0_6, DOI 10.1007/978-0-387-92920-0.6, 10.1007/978-0-387-92920-0.6]
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Han B, 2010, J VIS COMMUN IMAGE R, V21, P325, DOI 10.1016/j.jvcir.2010.02.007
   Jarchi D, 2009, 2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P17, DOI 10.1109/SSP.2009.5278649
   Kang B, 2015, IET IMAGE PROCESS, V9, P811, DOI 10.1049/iet-ipr.2015.0103
   Lee DU, 2009, IEEE T IMAGE PROCESS, V18, P2100, DOI 10.1109/TIP.2009.2022438
   Li R, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718781751
   Li R, 2018, MULTIMED TOOLS APPL, V77, P12139, DOI 10.1007/s11042-017-4862-z
   Li RQ, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6758147
   Marcelloni F, 2009, COMPUT J, V52, P969, DOI 10.1093/comjnl/bxp035
   Monika R, 2015, IEEE SENSOR, P1835
   Nagesh P, 2009, PROC CVPR IEEE, P1518, DOI 10.1109/CVPRW.2009.5206657
   Nandhini SA, 2016, J REAL-TIME IMAGE PR, P1
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Orovic I., 2016, MATH PROBL ENG, V2016, P1, DOI [DOI 10.1155/2016/7616393, 10.1155/2016/7616393]
   Otazo R, 2015, MAGN RESON MED, V73, P1125, DOI 10.1002/mrm.25240
   Razzaque MA, 2014, SENSORS-BASEL, V14, P2822, DOI 10.3390/s140202822
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   Sermwuthisarn P, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P212, DOI 10.1109/ISPACS.2009.5383863
   Sun F, 2017, INT J DIGIT MULTIMED, V2017, DOI 10.1155/2017/3902543
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Wang LJ, 2012, IEEE T IMAGE PROCESS, V21, P2980, DOI 10.1109/TIP.2012.2188810
   [王蓉芳 Wang Rongfang], 2013, [电子学报, Acta Electronica Sinica], V41, P1506
   Wiaux Y, 2009, MON NOT R ASTRON SOC, V395, P1733, DOI 10.1111/j.1365-2966.2009.14665.x
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xin Y, 2017, IMAGE COMPRESSION BA
   Yang JB, 2015, IEEE T IMAGE PROCESS, V24, P106, DOI 10.1109/TIP.2014.2365720
   Yang Y, 2009, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2009.5202443
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
   Zhang L, 2010, IEEE T GEOSCI REMOTE, V48, P3824, DOI 10.1109/TGRS.2010.2048575
   Zhang Shu-fang, 2012, Journal of Tianjin University, V45, P319
   Zhang YF, 2008, INT CONF ACOUST SPEE, P1361
   Zhou SW, 2019, MULTIMED TOOLS APPL, V78, P537, DOI 10.1007/s11042-017-5249-x
   Zhu SY, 2014, IEEE INT SYMP CIRC S, P1, DOI 10.1109/ISCAS.2014.6865050
   Zonoobi D, 2014, HEALTHC TECHNOL LETT, V1, P68, DOI 10.1049/htl.2013.0038
NR 54
TC 11
Z9 11
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4751
EP 4768
DI 10.1007/s11042-020-09932-0
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574376900006
DA 2024-07-18
ER

PT J
AU An, XW
   Liang, QQ
   Sun, NL
AF An, Xiaowei
   Liang, Quanquan
   Sun, Nongliang
TI Augmented particle samples based optimal convolutional filters for
   object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented particle samples; Optimal convolutional filters; Laplacian
   group reverse sparse representation; Laplacian score; Particle filtering
ID ROBUST VISUAL TRACKING; MANIFOLD RANKING
AB This paper presents the augmented particle samples based optimal convolutional filters that preserve the appearance model robustness for object tracking in both temporal and spatial levels. In temporal level, augmented particle samples provided by Laplacian group reverse sparse representation exploit the potential geometrical correlation among the different patches that keep the inherent potential distribution which facilitates the update scheme of appearance model between continuous frames in the particle filtering framework. In spatial level, structural information of multi-scale patches extraction can preserve highly stable attributes that significantly improve the object representation robustness in multi-scenarios. Moreover, the optimal convolutional filters that resulted from laplacian score exploits the coherence of high similarity in both positive and negative sets effectively that can guarantee the template update procedures discriminatively. Experimental results demonstrate that the proposed approach achieves better performance on multiple dynamic scenes.
C1 [An, Xiaowei] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Shandong, Peoples R China.
   [Liang, Quanquan; Sun, Nongliang] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Liang, QQ; Sun, NL (corresponding author), Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Shandong, Peoples R China.
EM anxiaowei2017@aliyun.com; quanquan406@gmail.com; nl_jackson@aliyun.com
OI liang, quanquan/0000-0002-6374-2402
FU Leading Talents of Shandong University of Science and Technology; 863
   project Physical Model Based Dynamic Evolution Technology of Complex
   Scene [2015AA016404]; Shandong Province Higher Educational Science and
   Technology Program [J17KA075]; National Nature Science Foundation of
   China [61801270]
FX Sincerely thanks to the professor Nongliang Sun and professor Quanquan
   Liang, who are crucial for the preparation of the article. This study
   acknowledges the financial support from the 'Leading Talents of Shandong
   University of Science and Technology', '863 project Physical Model Based
   Dynamic Evolution Technology of Complex Scene' (2015AA016404), 'Shandong
   Province Higher Educational Science and Technology Program' (J17KA075)
   and 'National Nature Science Foundation of China' (61801270).
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Gao J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P145, DOI 10.1109/ICCVW.2013.25
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kang B, 2019, OPTIK, V183, P232, DOI 10.1016/j.ijleo.2019.02.025
   Li CL, 2018, SIGNAL PROCESS-IMAGE, V68, P207, DOI 10.1016/j.image.2018.08.004
   Li X, 2019, KNOWL-BASED SYST, V166, P71, DOI 10.1016/j.knosys.2018.12.011
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu B, 2019, NEUROCOMPUTING, V362, P175, DOI 10.1016/j.neucom.2019.07.024
   Liu FH, 2017, IEEE T MULTIMEDIA, V19, P2680, DOI 10.1109/TMM.2017.2708424
   Lu XQ, 2013, PATTERN RECOGN, V46, P1762, DOI 10.1016/j.patcog.2012.11.016
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Rao C, 2012, INT C PATT RECOG, P1447
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen WC, 2019, IEEE T CIRC SYST VID, V29, P2012, DOI 10.1109/TCSVT.2018.2862151
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang HJ, 2017, OPTIK, V138, P68, DOI 10.1016/j.ijleo.2017.02.100
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Wu YW, 2014, IEEE T CIRC SYST VID, V24, P865, DOI 10.1109/TCSVT.2013.2291283
   Xiao L, 2018, IEEE ACCESS, V6, P41955, DOI 10.1109/ACCESS.2018.2857702
   Yang M, 2016, IEEE T CIRC SYST VID, V26, P1279, DOI 10.1109/TCSVT.2015.2395791
   Yang X, 2015, NEUROCOMPUTING, V159, P35, DOI 10.1016/j.neucom.2015.02.046
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yun S, 2018, IEEE T NEUR NET LEAR, V29, P2239, DOI 10.1109/TNNLS.2018.2801826
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang SL, 2018, PATTERN RECOGN, V84, P112, DOI 10.1016/j.patcog.2018.07.012
   Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P473, DOI 10.1109/TPAMI.2018.2797082
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou T, 2015, PATTERN RECOGN, V48, P2459, DOI 10.1016/j.patcog.2015.03.008
   Zhu L, 2012, CHIN C PATT REC
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 52
TC 0
Z9 0
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4473
EP 4491
DI 10.1007/s11042-020-09724-6
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100006
DA 2024-07-18
ER

PT J
AU Rahman, SU
   Khan, A
   Abbas, S
   Alam, F
   Rashid, N
AF Rahman, Sami Ur
   Khan, Adnan
   Abbas, Sohail
   Alam, Fakhre
   Rashid, Nasir
TI Hybrid system for automatic detection of gunshots in indoor environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gunshots; Muzzle Blast; Shook Wave; Audio Energy; Antilog Energy
ID SURVEILLANCE; RECOGNITION
AB Automatic gunshot detection technology allows incidence response system to counteract the potential of crimes. However, the surveillance systems suffer from various detection problems, such as difficulty in differentiating gunshot, fire work and other similar sounds. To improves the accuracy and reduces processing time, we have proposed hybrid algorithm for automatic detection of gunshots in indoor environment. In the proposed approach, we have used pre-processing steps which filters the input audio signals with a threshold. During pre-processing, the signals having smaller energy than the threshold value are discarded because these low energy signals are normal sound signals. When energy of audio signal is more than the threshold value and deemed ambiguous audio, such signal is forwarded to next step for further processing. The second step of the proposed approach is based on features based algorithm, in which antilog energy features are implemented to increase accuracy. These features extend energy band to easily differentiate between gunshot and normal scream. For classification purpose, SVM, Tree and KNN classifiers are used comparatively to differentiate a classifier which will show more accuracy with minimal computational cost. The proposed approach provides 94.97% accuracy for SVM,92.56% accuracy for KNN classifier, and 91.65% accuracy for Tree classifier. The pre-processing step reduces computational time by 5%, 13.61% and 34.56% for KNN, Tree and SVM classifiers respectively. The pre-processing step in the proposed algorithm requires 5.80% processing time of features based approach to filter an audio signal.
C1 [Rahman, Sami Ur; Khan, Adnan; Alam, Fakhre; Rashid, Nasir] Univ Malakand, Dept Comp Sci, Chakdara, Pakistan.
   [Abbas, Sohail] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
C3 University of Malakand; University of Sharjah
RP Alam, F (corresponding author), Univ Malakand, Dept Comp Sci, Chakdara, Pakistan.
EM fakhrealam@uom.edu.pk1
RI Abbas, Sohail/ABH-5056-2020
CR Arslan Y, 2017, ARXIV170608759
   Chacón-Rodríguez A, 2011, IEEE T CIRCUITS-I, V58, P363, DOI 10.1109/TCSI.2010.2072052
   Chan C-F, 2010, 2010 18 EUR SIGN PRO
   Clavel C, 2008, SPEECH COMMUN, V50, P487, DOI 10.1016/j.specom.2008.03.012
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Djeddou M, 2013, ARAB J SCI ENG, V38, P3399, DOI 10.1007/s13369-013-0655-5
   Dufaux A, 2000, SIGN PROC C 2000 10
   Ge Z, 2018, SYSTEM METHOD SPEAKE
   Gerosa L, 2007, 2007 15 EUR SIGN PRO
   Hrabina M, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P902, DOI 10.1109/SAI.2016.7556087
   Kahrs M, 1998, APPLICATIONS OF DIGI, V437
   Laffitte P, 2019, EXPERT SYST APPL, V117, P29, DOI 10.1016/j.eswa.2018.08.052
   Mulimani M, 2019, DIGIT SIGNAL PROCESS, V87, P1, DOI 10.1016/j.dsp.2019.01.001
   Piza EL, 2019, CRIMINOL PUBLIC POL, V18, P135, DOI 10.1111/1745-9133.12419
   Ribeiro JGC, 2018, PROC SPIE, V10648, DOI 10.1117/12.2307657
   Robert LB, 2008, DIRECTIONAL AUDIO SI
   Schindler A, 2019, INT C MULT MOD
   Sigtia S, 2016, IEEE-ACM T AUDIO SPE, V24, P2096, DOI 10.1109/TASLP.2016.2592698
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Xia X, 2018, IEEE INT C AC SPEECH
   Xia X, 2017, 2017 P INT SWED
NR 21
TC 3
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4143
EP 4153
DI 10.1007/s11042-020-09936-w
EA SEP 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572865900003
DA 2024-07-18
ER

PT J
AU Mohammadi, A
   Nakhkash, M
AF Mohammadi, Ammar
   Nakhkash, Mansor
TI Sorting methods and adaptive thresholding for histogram based reversible
   data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Embedded capacity; Histogram modification
ID WATERMARKING; SCHEME
AB This paper presents a histogram based reversible data hiding (RDH) scheme, which divides image pixels into different cell frequency bands to sort them for data embedding. Data hiding is more efficient in lower cell frequency bands because it provides prediction that is more accurate. Using pixel existence probability for some pixels of ultra-low cell frequency band, another sorting is performed. Employing these two novel sorting methods, we determine smooth areas of an image more efficient than other schemes. The smoother area of the image is selected for data embedding, the less distortion of the marked image may be achieved. In another proposal, we introduce hiding intensity analysis to determine optimum prediction error to embed data. In comparison with methods that sequentially choose prediction error, this analysis results in better quality of the marked image. In effect, the proposed scheme increases the hiding capacity for a specific level of the distortion comparing to existent RDH algorithms. Experimental results confirm that the proposed algorithm outperforms state of the art ones.
C1 [Mohammadi, Ammar; Nakhkash, Mansor] Yazd Univ, Dept Elect Engn, Yazd, Iran.
C3 University of Yazd
RP Nakhkash, M (corresponding author), Yazd Univ, Dept Elect Engn, Yazd, Iran.
EM nakhkash@yazd.ac.ir
OI Mohammadi, Ammar/0000-0003-2407-9051
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Huang D, 2020, MULTIMED TOOLS APPL, P1
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lee SK, 2006, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2006.312690
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P1155, DOI 10.1109/TIFS.2012.2197614
   Liu ZL, 2019, MULTIMED TOOLS APPL, V78, P16311, DOI 10.1007/s11042-018-6958-5
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P12569, DOI 10.1007/s11042-019-08335-0
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Weng SW, 2019, IEEE ACCESS, V7, P34570, DOI 10.1109/ACCESS.2019.2904174
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Zhang WM, 2015, IEEE T IMAGE PROCESS, V24, P294, DOI 10.1109/TIP.2014.2358881
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhou JT, 2012, IEEE SIGNAL PROC LET, V19, P287, DOI 10.1109/LSP.2012.2190508
NR 33
TC 8
Z9 8
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3307
EP 3325
DI 10.1007/s11042-020-09719-3
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571253200008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pandeya, YR
   Lee, J
AF Pandeya, Yagya Raj
   Lee, Joonwhoan
TI Deep learning-based late fusion of multimodal information for emotion
   classification of music video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion classification; Music video dataset; CNN; Multimodal approach;
   Late fusion
ID REPRESENTATION; RECOGNITION; CATEGORIES; MODEL
AB Affective computing is an emerging area of research that aims to enable intelligent systems to recognize, feel, infer and interpret human emotions. The widely spread online and off-line music videos are one of the rich sources of human emotion analysis because it integrates the composer's internal feeling through song lyrics, musical instruments performance and visual expression. In general, the metadata which music video customers to choose a product includes high-level semantics like emotion so that automatic emotion analysis might be necessary. In this research area, however, the lack of a labeled dataset is a major problem. Therefore, we first construct a balanced music video emotion dataset including diversity of territory, language, culture and musical instruments. We test this dataset over four unimodal and four multimodal convolutional neural networks (CNN) of music and video. First, we separately fine-tuned each pre-trained unimodal CNN and test the performance on unseen data. In addition, we train a 1-dimensional CNN-based music emotion classifier with raw waveform input. The comparative analysis of each unimodal classifier over various optimizers is made to find the best model that can be integrate into a multimodal structure. The best unimodal modality is integrated with corresponding music and video network features for multimodal classifier. The multimodal structure integrates whole music video features and makes final classification with the SoftMax classifier by a late feature fusion strategy. All possible multimodal structures are also combined into one predictive model to get the overall prediction. All the proposed multimodal structure uses cross-validation to overcome the data scarcity problem (overfitting) at the decision level. The evaluation results using various metrics show a boost in the performance of the multimodal architectures compared to each unimodal emotion classifier. The predictive model by integration of all multimodal structure achieves 88.56% in accuracy, 0.88 in f1-score, and 0.987 in area under the curve (AUC) score. The result suggests human high-level emotions are automatically well classified in the proposed CNN-based multimodal networks, even though a small amount of labeled data samples is available for training.
C1 [Pandeya, Yagya Raj; Lee, Joonwhoan] Jeonbuk Natl Univ, Div Comp Sci & Engn, Jeonju, South Korea.
C3 Jeonbuk National University
RP Lee, J (corresponding author), Jeonbuk Natl Univ, Div Comp Sci & Engn, Jeonju, South Korea.
EM yagyapandeya@gmail.com; chlee@chonbuk.ac.kr
RI Pandeya, Yagya Raj/ACR-3691-2022
OI Pandeya, Yagya Raj/0000-0002-9842-8704
FU National Research Foundation of Korea (NRF) under Basic Science Research
   Program [NRF-2019R1A6A1A09031717]; Brain Korea 21 PLUS Project, National
   Research Foundation of Korea
FX This work was supported by the National Research Foundation of Korea
   (NRF) under Basic Science Research Program NRF-2019R1A6A1A09031717 and
   Brain Korea 21 PLUS Project, National Research Foundation of Korea.
CR [Anonymous], 2014, LARGE SCALE VIDEO CL
   [Anonymous], 2016, ARXIV151107289
   [Anonymous], 2017, ARXIV170405665
   [Anonymous], 2015, ARXIV150301800V2
   Bahuleyan H, 2018, ARXIV180401149V1
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Carreira J., 2018, ARXIV170507750V3
   Chang WY, 2017, 21607516 IEEE
   Cowen AS, 2017, P NATL ACAD SCI USA, V114, pE7900, DOI 10.1073/pnas.1702247114
   Dai W, 2016, ARXIV161000087V1
   Das A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P141, DOI 10.1145/3017680.3017713
   Deng Jia, 2009, IEEE C COMP VIS PATT, P1063
   Ding W, 2016, INT C MULT INT JAP T
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elshaer MEA, 2019, ARXIV190202120V1
   Fan Y, 2016, INT C MULT INT JAP T
   Fridman L, 2019, ARXIV171106976V4
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2018, IEEE INTERNET THINGS
   Garces MLE, 2018, ARXIV180602682V1
   Grekow, 2018, CONTENT BASED MUSIC, DOI 10.1007/978-3-319-70609-2
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Hinton G, 2012, LECT 6D SEPARATE ADA
   Hong S, 2017, ARXIV170406761V2
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kingma D. P., 2014, arXiv
   Koelstra S., 2012, IEEE T AFFECT COMPUT
   Kunze J, 2017, ARXIV170600290V1
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Lövheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   Minaee S, 2019, ARXIV190201019V1
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nguyen D, 2017, DEEP SPATIO TEMPORAL
   Noroozi F, 2017, INT J SPEECH TECHNOL, V20, P239, DOI 10.1007/s10772-017-9396-2
   Ortega JDS, 2019, ARXIV190703196V1
   Ouyang, 2017, INT C MULT INT UK GL
   Pandeya YR, 2018, INT J FUZZY LOG INTE, V18, P154, DOI 10.5391/IJFIS.2018.18.2.154
   Pandeya YR, 2018, APPL SCI, V1949
   Pini S, 2017, INT C MULT INT UK GL
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Rozgic V., 2013, IEEE INT C AC SPEECH
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shiqing Z, 2018, IEEE T CIRCUITS SYST, P28
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su YC, 2015, ARXIV14094127V2
   Sun K, 2009, IMPROVED VALENCE ARO
   Tan C, 2018, ARXIV180801974V1
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Tian HM, 2019, WORLD WIDE WEB, V22, P1325, DOI 10.1007/s11280-018-0548-3
   Tiwari S.N., 2016, DEEP FEATURES FOR MULTIMODAL EMOTION CLASSIFICATION
   Torrey L, 2009, IGI GLOBAL PUBLICATI
   Tremblay J, 2018, ARXIV180910790V1
   Tripathi Samarth., 2017, Using deep and convolutional neural networks for accurate emotion classification on DEAP dataset
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Wang D, 2015, APSIPA ANN SUMM C 20
   Wang S, 2015, IEEE T AFFECT COMPUT
   Wu H, 2019, ARXIV190706390V2
   Xu YS, 2018, ARXIV180400931V2
   Yang YH, 2012, ACM T INTEL SYST TEC
   Zhang L, 2018, ARXIV180600257
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P1067, DOI 10.1016/j.imavis.2014.09.005
   Zhang SQ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P281, DOI 10.1145/2911996.2912051
NR 69
TC 79
Z9 82
U1 11
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2887
EP 2905
DI 10.1007/s11042-020-08836-3
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570470300002
OA hybrid
DA 2024-07-18
ER

PT J
AU Shanableh, T
AF Shanableh, Tamer
TI Feature extraction and machine learning solutions for detecting motion
   vector data embedding in HEVC videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Machine learning; Steganalysis; Steganography; Video
   coding
ID STEGANALYSIS; ALGORITHM
AB This paper proposed three feature extraction solutions suitable for detecting data embedding in motion vectors (MVs) of coded HEVC videos. In the first feature extraction solution, videos under consideration are reencoded and features are extracted from both videos from Coding Units (CUs). The difference between the two feature sets form a feature vector at a CU level. The CU level feature vectors are then summarized by computing the average and standard deviation of individual features. This summarization is computed at a frame-level and at a video sequence level. Detection models are then used to detect MV data embedding. To generate the detection models, HEVC videos are reencoded whilst employing two different data embedding solutions. Feature variables are then computed and the detection models at frame and sequence levels are generated. The second solution is an extension of an existing work that uses the concept of MV consistency for computing feature variables. In this work, we extent the MV consistency concept to HEVC coded videos by grouping sub CUs based on their coding depths. One set of features is computed by finding the joint probability that a CU has a given coding depth and the bitrate of the MV differences of the sub CUs are smaller than or equal to the between-CU MV differences. Another set of features is computed by finding a similar probability but for sub CUs with MV differences greater than the between-CU MV differences. The third solution combines the features of all of the aforementioned solutions resulting in a set of 16 feature variables. The feature variables are visualized by projecting them using spectral regression where it is shown that the third solution results in separable features. In comparison to existing work, experimental results show excellent classification accuracies for HEVC videos coded at different spatio-temporal resolutions and different bitrates.
C1 [Shanableh, Tamer] Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
C3 American University of Sharjah
RP Shanableh, T (corresponding author), Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
EM tshanableh@aus.edu
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669
   Fan MQ, 2016, TELECOMMUN SYST, V63, P523, DOI 10.1007/s11235-016-0139-5
   Li B, 2008, TEXTURAL FEATURES BA
   Li SB, 2014, ANN TELECOMMUN, V69, P461, DOI 10.1007/s12243-013-0381-8
   Li ZH, 2019, CMC-COMPUT MATER CON, V59, P563, DOI 10.32604/cmc.2019.05565
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Reinel TS, 2019, IEEE ACCESS, V7, P68970, DOI 10.1109/ACCESS.2019.2918086
   Shanableh T, 2019, IET IMAGE PROCESS, V13, P1909, DOI 10.1049/iet-ipr.2018.5782
   Shanableh T, 2018, MULTIMED TOOLS APPL, V77, P8939, DOI 10.1007/s11042-017-4787-6
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Shanableh T, 2012, SIGNAL PROCESS-IMAGE, V27, P1025, DOI 10.1016/j.image.2012.06.003
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Team J. V., 2003, ADV VIDEO CODING GEN
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang KR, 2014, MULTIMED TOOLS APPL, V72, P313, DOI 10.1007/s11042-013-1373-4
   [王丽娜 Wang Lina], 2014, [电子学报, Acta Electronica Sinica], V42, P1457
   Yanbin Zhao, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P119, DOI 10.1007/978-3-319-31960-5_11
   Yang J, 2018, MULTIMED TOOLS APPL, V77, P11979, DOI 10.1007/s11042-017-4844-1
   Zarmehi N, 2016, IET IMAGE PROCESS, V10, P1, DOI 10.1049/iet-ipr.2014.1019
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
NR 24
TC 8
Z9 8
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27047
EP 27066
DI 10.1007/s11042-020-09826-1
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000570470300001
DA 2024-07-18
ER

PT J
AU Kani-Zabihi, E
   Hussain, N
   Mesfin, G
   Covaci, A
   Ghinea, G
AF Kani-Zabihi, Elahe
   Hussain, Nadia
   Mesfin, Gebremariam
   Covaci, Alexandra
   Ghinea, Gheorghita
TI On the influence of individual differences in cross-modal Mulsemedia QoE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mulsemedia; Individual differences; Quality of experience; Cross-modal
   correspondence
ID VIDEO QUALITY; IDENTIFICATION; MULTIMEDIA; ODORS
AB Quality of Experience (QoE) is inextricably linked to the human side of the multimedia experience. Whilst there has been a considerable amount of research undertaken to explore the various dimensions of QoE, one facet which been relatively unexplored is the role of individual differences in determining an individual's QoE. Whereas this is certainly true of multimedia applications, when it comes to mulsemedia (multiple media engaging three or more human senses) this is even more so, given its emerging and novel nature. Accordingly, in this paper we report the results of a study which investigated the role that individual differences (such as age, gender, education, and smell sensitivity) have on QoE, when mulsemedia incorporating olfactory and haptic stimuli is experienced in cross-modal environments. Our results reveal that whilst users had a satisfying overall mulsemedia experience the specific use of cross modally matched odours did not result in significantly higher QoE levels than when a control scent (rosemary) was employed. However, aspects of QoE are impacted upon by all individual differences dimensions considered in our study.
C1 [Kani-Zabihi, Elahe] Univ West London, London, England.
   [Hussain, Nadia; Ghinea, Gheorghita] Brunel Univ London, Uxbridge, Middx, England.
   [Mesfin, Gebremariam] Kristiania Univ Coll, Oslo, Norway.
   [Covaci, Alexandra] Univ Kent, Canterbury, Kent, England.
C3 University of West London; Brunel University; Kristiania University
   College; University of Kent
RP Ghinea, G (corresponding author), Brunel Univ London, Uxbridge, Middx, England.
EM george.ghinea@brunel.ac.uk
RI Hussain, Nadia/GXH-7350-2022; Assres, Gebremariam Mesfin/AFM-0811-2022;
   Ghinea, Gheorghita/AAG-6770-2020
OI Assres, Gebremariam Mesfin/0000-0002-6760-690X; Ghinea,
   Gheorghita/0000-0003-2578-5580; Covaci, Alexandra/0000-0002-3205-2273;
   Kani-Zabihi, Elahe/0000-0002-5679-8512
CR [Anonymous], 2010, COMPUTERS ENTERTAINM
   Bangor A, 2009, J USABILITY STUD, V4, P114
   CAIN WS, 1982, CHEM SENSES, V7, P129, DOI 10.1093/chemse/7.2.129
   Covaci A, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES'18), P176, DOI 10.1145/3281375.3281387
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   Covaci A, 2018, MULTIMED TOOLS APPL, V77, P21245, DOI 10.1007/s11042-017-5459-2
   Demattè ML, 2006, CHEM SENSES, V31, P531, DOI 10.1093/chemse/bjj057
   Diego MA, 1998, INT J NEUROSCI, V96, P217, DOI 10.3109/00207459808986469
   Doty RL, 2009, PHYSIOL BEHAV, V97, P213, DOI 10.1016/j.physbeh.2009.02.032
   DOTY RL, 1984, PHYSIOL BEHAV, V32, P489, DOI 10.1016/0031-9384(84)90269-5
   Ghinea G, 2006, MULTIMEDIA SYST, V11, P271, DOI 10.1007/s00530-005-0007-8
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071398
   Ghinea G, 2008, COMPUT HUM BEHAV, V24, P1317, DOI 10.1016/j.chb.2007.07.013
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Ghinea G, 2011, MULTIMED TOOLS APPL, V55, P601, DOI 10.1007/s11042-010-0581-4
   Gilbert AN, 1996, AM J PSYCHOL, V109, P335, DOI 10.2307/1423010
   Hancock PA, 2013, ERGONOMICS, V56, P729, DOI 10.1080/00140139.2013.771219
   Hanson-Vaux G, 2013, CHEM SENSES, V38, P161, DOI 10.1093/chemse/bjs087
   Hoshino S., 2011, P IEEE INT WORKSH TE, P1, DOI [10.1109/CQR.2011.5996082, DOI 10.1109/CQR.2011.5996082]
   Jalal L, 2017, IEEE INT SYM BROADB, P199
   Kemp SE, 1997, AM J PSYCHOL, V110, P35, DOI 10.2307/1423699
   Kjell Brunnstrom Sergio Ariel Beker Katrien de Moor Ann Dooms Sebastian Egger, 2013, QUALINET WHITE PAPER
   KOR-FX, 2014, KOR FX GAM VES
   Murray N, 2013, IEEE INT CON MULTI
   Murray N, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3108243
   Murray N, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2540994
   Murray Niall., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys'13, P162, DOI [https://doi.org/10.1145/2483977.2483999, DOI 10.1145/2483977.2483999]
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   Narumi T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P93
   Rao D., 2010, P 2 INT WORKSHOP SEA, P37, DOI DOI 10.1145/1871985.1871993
   Scott MJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P481, DOI 10.1145/2733373.2806254
   Scott MJ, 2016, IEEE T MULTIMEDIA, V18, P1796, DOI 10.1109/TMM.2016.2574623
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P957, DOI 10.1109/TMM.2015.2431915
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zhang LK, 2016, LECT NOTES COMPUT SC, V9654, P111, DOI 10.1007/978-3-319-40259-8_10
   Zhu Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183512
   Zhu Y, 2015, COMPUT HUM BEHAV, V49, P412, DOI 10.1016/j.chb.2015.02.054
NR 39
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2377
EP 2394
DI 10.1007/s11042-020-09757-x
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569773300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Yan, JR
   Zhong, LC
   Yao, YB
   Xu, X
   Du, CJ
AF Yan, Junrong
   Zhong, Luchao
   Yao, Yingbiao
   Xu, Xin
   Du, Chenjie
TI Dual-template adaptive correlation filter for real-time object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive threshold; Correlation filter; Dual templates; Visual tracking
ID VISUAL TRACKING
AB Visual object tracking is a hot topic in the field of computer vision. The drift of the tracking box or loss of the tracking target often occurs for existing correlation filter based trackers when the target moves quickly or deforms. Focusing on this problem, we propose a dual-template adaptive correlation filter for real-time object tracking. First, we trained templates for different size levels. Second, the best template was selected based on the target response confidence during estimation of the target translation. Third, the dual templates, scale estimation component, and feature fusion component were integrated into the benchmark tracker, the kernelized correlation filter. The object tracking benchmark was used to evaluate the performance of the proposed algorithm. The experimental results show that compared with the benchmark tracker, the average overlap precision and distance precision of this proposed algorithm are increased by 23.2% and 9.4% in OTB-100. The average running frame rate reaches 42 frames per second, which can meet the real-time requirements. At the same time, five algorithms, DSST, SAMF, KCF, CN, and CSK, appear to drift or even lose the target among the four selected typical video sequences, while our algorithm can successfully track the target.
C1 [Yan, Junrong; Zhong, Luchao; Yao, Yingbiao; Xu, Xin; Du, Chenjie] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Yao, YB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
EM Yjrcn@163.com; 505542220@qq.com; yaoyb@hdu.edu.cn; xuxin@hdu.edu.cn;
   du526292624@163.com
RI yao, yao/HHZ-7438-2022
FU Zhejiang Province Science Foundation for Public Welfare [LGG19F020014];
   National Natural Science Foundation of China [61671192]; China
   Postdoctoral Science Foundation [2017 M621796]
FX This work was supported by Zhejiang Province Science Foundation for
   Public Welfare (LGG19F020014), National Natural Science Foundation of
   China (61671192) and China Postdoctoral Science Foundation (2017
   M621796).
CR Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Akin O, 2014, INT C PATT RECOG, P4229, DOI 10.1109/ICPR.2014.725
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chu J, 2020, IEEE ACCESS, V8, P856, DOI 10.1109/ACCESS.2019.2961778
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, BRIT MACH VIS C
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu HW, 2019, IEEE T MULTIMEDIA, V21, P510, DOI 10.1109/TMM.2018.2859831
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Lee M, 2019, IEEE ACCESS, V7, P11554, DOI 10.1109/ACCESS.2019.2892429
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Liu QB, 2018, IEEE ACCESS, V6, P43302, DOI 10.1109/ACCESS.2018.2861827
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Sheng J, 2019, IEEE T APPL SUPERCON, V29, DOI 10.1109/TASC.2019.2903269
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tan K, 2019, IEEE ACCESS, V7, P53476, DOI 10.1109/ACCESS.2019.2912527
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
NR 38
TC 6
Z9 8
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2355
EP 2376
DI 10.1007/s11042-020-09644-5
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569773300003
DA 2024-07-18
ER

PT J
AU Huang, DY
   Chen, CH
   Chen, TY
   Hu, WC
   Guo, ZB
   Wen, CK
AF Huang, Deng-Yuan
   Chen, Chao-Ho
   Chen, Tsong-Yi
   Hu, Wu-Chih
   Guo, Zhi-Bin
   Wen, Cheng-Kang
TI High-efficiency face detection and tracking method for numerous
   pedestrians through face candidate generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Face tracking; Numerous pedestrians; Histogram of
   oriented gradient (HOG); Support vector machine (SVM)
AB This paper is dedicated to developing high-efficiency face detection and tracking method for big dynamic crowds or numerous pedestrians. Three modules constitute the proposed method, i.e., face candidate generation, face candidate verification, and face target tracking. In this work, face candidates are localized using the features of the face area, edge information, and skin color. Non-face parts in the face candidates are further verified by the C-SVM learning model and then removed, by which the face targets can be generated with lower computation-complexity and satisfactory accuracy than other approaches. Finally, the face targets are tracked by an efficient and reliable searching scheme for improving the effective face detection rate. Experimental results show that the average face detection rate (FDR) of 85%, average effective FDR of 95%, a frame rate of 28-66 frames per second (fps), and about 30 faces detected per frame are obtained from various test videos with big dynamic crowds or numerous pedestrians, indicating the feasibility of the proposed method to achieve unconstrained face detection with high-efficiency and cost-effectiveness. This result makes the proposed method more attractive for the video surveillance system as compared to other approaches, especially in the high computational complexity-based methods.
C1 [Huang, Deng-Yuan] Da Yeh Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Changhua 515, Taiwan.
   [Chen, Chao-Ho; Chen, Tsong-Yi; Guo, Zhi-Bin] Natl Kaohsiung Univ Sci & Technol, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.
   [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung 880, Penghu, Taiwan.
   [Wen, Cheng-Kang] Tainan Univ Technol, Dept Informat Management, 529 Zhongzheng Rd, Tainan 71002, Taiwan.
C3 Da Yeh University; National Kaohsiung University of Science &
   Technology; National Penghu University of Science & Technology
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.
EM kevin@mail.dyu.edu.tw; thouho@nkust.edu.tw; chentso@nkust.edu.tw;
   wchu@npu.edu.tw; 1103305120@gm.kuas.edu.tw; ckwen@venus.tut.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST 107-2221-E-212-012,
   MOST 107-2622-E-992-024-CC3, MOST 106-2221-E-151-061]
FX This work was partly supported by a grant from Ministry of Science and
   Technology, Taiwan, under the contracts MOST 107-2221-E-212-012, MOST
   107-2622-E-992-024-CC3 and MOST 106-2221-E-151-061.
CR Bochkovskiy A., 2020, PREPRINT
   Cardenas Rolando J., 2019, International Journal of Machine Learning and Computing, V9, P189, DOI 10.18178/ijmlc.2019.9.2.785
   Chen Cheng Chen Cheng, 2018, The Proceedings of the Annual Meeting of Chinese Grassland Society in 2018, Sichuan, China, 7-10 December, 2018, P76
   Chen JC, 2018, INT J COMPUT VISION, V126, P272, DOI 10.1007/s11263-017-1029-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fukui H, 2015, IEEE INT VEH SYM, P223, DOI 10.1109/IVS.2015.7225690
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Huang D-Y, 2016, J INFORM HIDING MULT, V7, P101
   Ishii I, 2013, J REAL-TIME IMAGE PR, V8, P379, DOI 10.1007/s11554-012-0255-8
   Ishii Y, 2004, INT C PATT RECOG, P298, DOI 10.1109/ICPR.2004.1334526
   Ji PF, 2016, ACSIS-ANN COMPUT SCI, V8, P253, DOI 10.15439/2016F508
   Ji SP, 2014, PROCESSING OF 2014 INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INFORMATION INTEGRATION FOR INTELLIGENT SYSTEMS (MFI)
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon HJ, 2017, IEEE INT SYMP SIGNAL, P51, DOI 10.1109/ISSPIT.2017.8388318
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JJ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P46, DOI 10.1109/ICIVC.2017.7984516
   Li Zhengming, 2010, PROGR INF COMP PIC 2, V2, P723
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Niu G, 2018, J VIS COMMUN IMAGE R, V55, P457, DOI 10.1016/j.jvcir.2018.07.001
   Phung SL, 2002, IEEE IMAGE PROC, P289
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Rajeshwari J, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P728, DOI 10.1109/IC3I.2014.7019746
   Redmon J, 2018, ARXIV180402767V2
   Rekha N., 2014, INT J ADV RES COMPUT, V3, P1345
   Sobel I., 1968, STANF ART PROJ, P271
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Tan MX, 2019, PR MACH LEARN RES, V97
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xiong Z, 2019, P IEEE INT C ADV VID, V1, P1
   Yu M, 2017, P INT C SIGN PROC CO, P1
   Zakaria Z, 2018, APPL SOFT COMPUT, V68, P172, DOI 10.1016/j.asoc.2018.03.030
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
NR 35
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1247
EP 1272
DI 10.1007/s11042-020-09780-y
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700004
DA 2024-07-18
ER

PT J
AU Saha, A
   Chatterjee, A
   Ghosh, S
   Kumar, N
   Sarkar, R
AF Saha, Akash
   Chatterjee, Agneet
   Ghosh, Soulib
   Kumar, Neeraj
   Sarkar, Ram
TI An ensemble approach to outlier detection using some conventional
   clustering algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier detection; K-means; Fuzzy C-means; K-means plus plus; Ensemble
   approach
ID ANOMALY DETECTION; K-MEANS; HYBRID
AB Outlier detection is an important requirement in data mining and machine learning. When data mining and machine learning algorithms are applied on the datasets with outliers, it leads to erroneous conclusion about the data. Therefore, researchers have been working in this field to remove outliers from dataset so that meaningful information from the datasets can be retrieved. In this paper, we take a cluster based ensemble approach for outlier detection, the backbone of which are some conventional clustering algorithms. Keeping in mind the drawbacks of supervised and semi supervised learning, we have relied on unsupervised learning algorithms. For our cluster based ensemble approach, we use three clustering algorithms, namely K-means, K-means++, and Fuzzy C-means. Our model intelligently combines results from individual clustering algorithms, assigning probabilities to each data point in order to decide its belongingness to a certain cluster. We have proposed a technique to assign a membership value to a data point in case of hard clustering algorithms, as we want to keep the flexibility of combining hard and soft clustering algorithms. From the probabilities assigned by the ensemble model, we then identify the outliers from the dataset. After removing these data points from the dataset, we obtain better values of cluster validity indices, thus reaffirming that removal of outliers has resulted in more stringent clusters of data. We have used five different cluster validity indices in our work to measure the goodness of the clusters formed, considering eight widely used datasets for evaluation of the proposed model amongst which three are large datasets. We have noticed a significant improvement in the cluster validity indices after applying our outlier detection algorithm. The experimental results prove that the proposed method is empirically sound.
C1 [Saha, Akash; Chatterjee, Agneet; Ghosh, Soulib; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Kumar, Neeraj] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Neeraj] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Jadavpur University; Thapar Institute of Engineering & Technology; Asia
   University Taiwan
RP Kumar, N (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.; Kumar, N (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM akash16112013@gmail.com; agneet257@gmail.com; ghoshsoulib@gmail.com;
   neeraj.kumar@thapar.edu; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Kumar, Neeraj/L-3500-2016
OI Sarkar, Ram/0000-0001-8813-4086; Kumar, Neeraj/0000-0002-3020-3947
CR Ahmed M, 2013, C IND ELECT APPL, P577
   Ahmed S, 2020, IEEE ACCESS, V8, P102629, DOI 10.1109/ACCESS.2020.2999093
   Baek JY, 2019, IEEE WCNC
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bezdek JC, 2016, IEEE T FUZZY SYST, V24, P1500, DOI 10.1109/TFUZZ.2016.2540063
   Boddy AJ, 2019, IEEE ACCESS, V7, P40285, DOI 10.1109/ACCESS.2019.2906503
   Bzdok D, 2018, NAT METHODS, V15, P5, DOI 10.1038/nmeth.4551
   Campos GO, 2016, DATA MIN KNOWL DISC, V30, P891, DOI 10.1007/s10618-015-0444-8
   Chakraborty D, 2019, PATTERN RECOGN, V89, P161, DOI 10.1016/j.patcog.2019.01.002
   Chawla S., 2013, P 2013 SIAM INT C DA, P189, DOI [DOI 10.1137/1.9781611972832.21, 10.1137/1.9781611972832.21]
   Dasgupta D, 2002, IEEE C EVOL COMPUTAT, P1039, DOI 10.1109/CEC.2002.1004386
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Hautamäki V, 2005, LECT NOTES COMPUT SC, V3540, P978
   He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Jana P, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P332
   Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8
   Jiang SY, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P429, DOI 10.1109/FSKD.2008.244
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Liu YZ, 2020, IEEE T ENG MANAGE, V67, P483, DOI 10.1109/TEM.2018.2887118
   Mandal A, 2018, INT C EM TECHN SUST
   Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856
   NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203
   Onan A, 2016, EXPERT SYST APPL, V62, P1, DOI 10.1016/j.eswa.2016.06.005
   Panwar LK, 2018, SWARM EVOL COMPUT, V38, P251, DOI 10.1016/j.swevo.2017.08.002
   Pendharkar PC, 2004, COMPUT OPER RES, V31, P481, DOI 10.1016/S0305-0548(02)00229-0
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Qadri YA, 2020, FUTURE HEALTHCARE IN
   Rish I, 2014, EMPIRICAL STUDY NAIV, V2001, P41
   Saha S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082816
   SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262
   Starczewski A, 2015, LECT NOTES COMPUT SC, V9120, P49, DOI 10.1007/978-3-319-19369-4_5
   Stucker C., 2018, ISPRS ANN PHOTOGRAMM, V4, P263, DOI [DOI 10.5194/ISPRS-ANNALS-IV-2-263-2018, DOI 10.5194/isprs-annals-IV-2-263-2018]
   Wang YF, 2019, SUSTAIN CITIES SOC, V45, P197, DOI 10.1016/j.scs.2018.11.031
   Whang JJ, 2015, P 2015 SIAM INT C DA, P936, DOI DOI 10.1109/TPAMI.2018.2863278
   Yan HQ, 2019, NEUROCOMPUTING, V329, P348, DOI 10.1016/j.neucom.2018.10.067
   Yi Y, 2018, IEEE ACCESS, V6, P63923, DOI 10.1109/ACCESS.2018.2877701
   Yu QY, 2016, APPL INTELL, V45, P1179, DOI 10.1007/s10489-016-0813-z
   Zhang J, 2006, IEEE ICC, P2388
   Zhang K, 2009, LECT NOTES ARTIF INT, V5476, P813, DOI 10.1007/978-3-642-01307-2_84
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou YH, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P476, DOI 10.1109/FITME.2009.125
NR 46
TC 3
Z9 3
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35145
EP 35169
DI 10.1007/s11042-020-09628-5
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000566043500001
DA 2024-07-18
ER

PT J
AU Huang, CF
AF Huang, Chih-Fang
TI An innovative method of algorithmic composition using musical tension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Narratology; Automated music composition; Music tension energy; Music
   parameters; Algorithmic composition (AC)
ID ELEMENTARY; MODEL
AB According to narratology or narrative theory, a piece of artwork should tell a story based on its various tensions. In this study, an automated music composition algorithm using musical tension energy was proposed; this algorithm can generate a musical piece by changing the musical tension. The proposed innovative Algorithmic Composition Musical Tension Energy (ACMTE) method uses the level of musical tension; this level is determined primarily by the chord progression and also the musical parameters of pitch interval and rhythm. The effects of musical tension energy on those parameters were analyzed. This paper presents a formula that unifies all generated parts. The experimental results demonstrate that thousands of beautiful pieces can easily be made without the use of a music database. This algorithmic composition method can be easily applied in both streaming media and to portable music devices, such as smart phones, notebooks, and MP3 players.
C1 [Huang, Chih-Fang] Kainan Univ, Dept Hlth & Mkt Informat Commun, 1 Kainan Rd, Taoyuan 33857, Taiwan.
C3 Nan Kai University Technology
RP Huang, CF (corresponding author), Kainan Univ, Dept Hlth & Mkt Informat Commun, 1 Kainan Rd, Taoyuan 33857, Taiwan.
EM jeffh.me83g@gmail.com
OI Huang, Chih-Fang/0000-0002-0111-0653
FU Ministry of Science and Technology project of Taiwan [MOST
   108-2511-H-424 -001 -MY3]
FX The author is appreciative of the support from the Ministry of Science
   and Technology project of Taiwan: MOST 108-2511-H-424 -001 -MY3.
CR Aldwell E, 2018, HARMONY VOICE LEADIN
   Alpern A, 1995, TECHNIQUES ALGORITHM, V95, P120
   [Anonymous], 2004, Psychol. Music, DOI [DOI 10.1177/0305735604046096, 10.1177%2F0305735604046096]
   Benson D. J., 2008, MATH INTELLIGENCER, V30, P76, DOI DOI 10.1007/BF02985765
   Chen Y., 2007, 1. Y. Chen, Z. Liang. E. Hannum, A. Park, ed. 2007. " Educational attainment of migrant children: The forgotten story of China's urbanization ",.
   Clendinning J-P, 2016, MUSICIANS GUIDE THEO
   COHEN ES, 1990, GERONTOLOGIST, V30, P345, DOI 10.1093/geront/30.3.345
   COPE D, 1987, COMPUT MUSIC J, V11, P30, DOI 10.2307/3680238
   Erisman SM, 2010, EMOTION, V10, P72, DOI 10.1037/a0017162
   Fredrickson WE, 1997, J RES MUSIC EDUC, V45, P626, DOI 10.2307/3345427
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711
   Harkleroad L, 2006, MATH MUSIC, V1
   Huang CF, 2014, MUSIC SCI, V18, P84, DOI 10.1177/1029864913514596
   Kathiresan T, 2015, SIGNAL PROCESSING, VSecond
   Le Groux S, 2010, P 6 SOUND MUS C BARC, V134
   Lin H-M, 2010, ALGORITHMIC COMPOSIT
   Loy G, 2011, MUSIMATHICS MATH FDN, V1
   Madsen ST, 2006, ENTROPY, V1-4, P1
   Margulis EH, 2008, COMPUT MUSIC J, V32, P64, DOI 10.1162/comj.2008.32.4.64
   Maus Fred E., 1991, INDIANA THEORY REV, V12, P1
   Nierhaus G, 2009, ALGORITHMIC COMPOSIT
   Pierce A-D, 1981, WAVE THEORY SOUND AC, P122
   Randel D-M, 1999, HARVARD CONCISE DICT
   Roederer J-G., 2012, INTRO PHYS PSYCHOPHY
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Ryan M-L, 2005, AESTHETICS NET LIT W, P257
   Supper M, 2001, COMPUT MUSIC J, V25, P48, DOI 10.1162/014892601300126106
   Tatlow Ruth, 2007, UNDERSTANDING BACH, V2, P37
   TERHARDT E, 1984, MUSIC PERCEPT, V1, P276
   Thayer R-E., 1997, ORIGIN EVERYDAY MOOD
   Todorov T., 1971, DIACRITICS, V1, P37, DOI [10.2307/464558, DOI 10.2307/464558]
   VieIllard S, 2008, COGNITION EMOTION, V22, P720, DOI 10.1080/02699930701503567
   Winsor P., 1988, COMPUTER ASSISTED MU
   Zajenkowski M, 2012, PERS INDIV DIFFER, V52, P858, DOI 10.1016/j.paid.2012.01.007
   Zhou H, 2006, J APPL POLYM SCI, V101, P2675, DOI 10.1002/app.23911
NR 35
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32119
EP 32136
DI 10.1007/s11042-020-09506-0
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697300002
DA 2024-07-18
ER

PT J
AU Keyvanpour, MR
   Vahidian, S
   Ramezani, M
AF Keyvanpour, Mohammad Reza
   Vahidian, Shokofeh
   Ramezani, Mahin
TI HMR-vid: a comparative analytical survey on human motion recognition in
   video data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human motion recognition; Video; Machine vision; Comprehensive
   framework; Analytical comparison
ID INVARIANT FEATURE-EXTRACTION; BACKGROUND SUBTRACTION; EVENT RECOGNITION;
   POINT DETECTORS; ROBUST; TRACKING; SYSTEM; MIXTURE; REPRESENTATION;
   MOVEMENT
AB According to the rapid spread of multimedia data and online observations by users, the importance of researching on machine vision also, analyzing and automatic understanding of video data content is progressively increasing. Human motion recognition in video data is a crucial research subject in machine vision science that has plenty of applications, for instance, video surveillance, video indexing, robotics, human-computer interface and multimedia retrieval. Despite a high number of researches conducted on this topic, there is a necessity to achieve a more in-depth understanding, complete classification, and evaluation of existing human motion recognition stages. The novelty of this paper, our comparative analytical framework includes three major parts. Firstly, three different stages are introduced in recognizing human motion consisting of background subtraction, feature extraction, and machine learning classification. Secondly, five essential criteria are defined for evaluating the proposed human motion recognition methods. Finally, our comparative analysis of human motion recognition stages comprises two models. The analysis of background subtraction methods is based on applying the criteria for a qualitative comparison. Next, the feature extraction and machine learning classification methods are examined by specifying their main idea, benefits and challenges. Our comparative analytical framework can be beneficial for every researcher in this field by simplifying accurate selection and development of human motion recognition methods in future works.
C1 [Keyvanpour, Mohammad Reza] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Vahidian, Shokofeh; Ramezani, Mahin] Alzahra Univ, Comp Engn & Data Min Lab, Tehran, Iran.
C3 Alzahra University; Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
EM keyvanpour@alzahra.ac.ir
RI Keyvanpour, Mohammad Reza/AAL-5574-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099; Vahidian,
   Shokofeh/0000-0002-6464-6842
CR Aanæs H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8
   Abidine BM, 2018, PATTERN ANAL APPL, V21, P119, DOI 10.1007/s10044-016-0570-y
   Afsar P, 2015, EXPERT SYST APPL, V42, P6935, DOI 10.1016/j.eswa.2015.05.023
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal J. K., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P2, DOI 10.1109/MNRAO.1994.346261
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ahmadi M, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0456-x
   Al-Maadeed S, 2018, COMPUT IND, V100, P129, DOI 10.1016/j.compind.2018.04.014
   ALAWI MA, 2013, WORLD APPL SCI J, V21, P109, DOI DOI 10.5829/idosi.wasj.2013.21.mae.99934
   Ali KH, 2014, LECT NOTES ARTIF INT, V8589, P298, DOI 10.1007/978-3-319-09339-0_31
   Ali N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1356-9
   [Anonymous], 2016, Oxid. Med. Cell Longev, DOI DOI 10.1155/2016/7954154
   [Anonymous], 2016, INT C INT SYST DES A
   [Anonymous], 2009, P 1 NORW ART INT S
   [Anonymous], 2016, COMPUT VISUAL MEDIA
   [Anonymous], 2007, NIK 2007 C
   Awad A.I., 2016, STUDIES COMPUTATIONA, V630
   Awad M., 2015, Springer Nature, DOI [10.1007/978-1-4302-5990-9, DOI 10.1007/978-1-4302-5990-9]
   Baf FE, 2008, IEEE IMAGE PROC, P2648, DOI 10.1109/ICIP.2008.4712338
   Bello AA, 2020, NEURAL COMPUT APPL, V32, P13651, DOI 10.1007/s00521-020-04775-0
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bhatia A, 2007, THESIS
   Bobick AF, 1997, PHILOS T ROY SOC B, V352, P1257, DOI 10.1098/rstb.1997.0108
   Boghdady R, 2015, 2015 TENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P34, DOI 10.1109/ICCES.2015.7393013
   Bouttefroy PLM, 2010, INT CONF ACOUST SPEE, P4042, DOI 10.1109/ICASSP.2010.5495760
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Braham M., 2016, 2016 INT C SYST SIGN, P1
   Bux A, 2017, ADV INTELL SYST COMP, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   C'ulibrk D, 2010, GPU BASED COMPLEX BA, P21000
   Cabani C, 2006, 2006 C COMP VIS PATT
   Calvo-Gallego E, 2016, J REAL-TIME IMAGE PR, V12, P681, DOI 10.1007/s11554-014-0455-5
   Cano A, 2018, J REAL-TIME IMAGE PR, V14, P453, DOI 10.1007/s11554-014-0467-1
   Cao DW, 2009, COMPUT VIS IMAGE UND, V113, P1064, DOI 10.1016/j.cviu.2009.06.002
   Carr P, 2008, DIGITAL IMAGE COMPUT
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Chacon-Murguia MI, 2015, APPL SOFT COMPUT, V36, P570, DOI 10.1016/j.asoc.2015.08.007
   Chandrasekhar U., 2011, UNIASCIT, V1, P107
   Chang-Hyun Kim, 2003, Artificial Life and Robotics, V7, P86, DOI 10.1007/s10015-002-0240-6
   Cheng L, 2011, IEEE T IMAGE PROCESS, V20, P1401, DOI 10.1109/TIP.2010.2087764
   Cheng LA, 2008, IEEE GEOSCI REMOTE S, V5, P246, DOI 10.1109/LGRS.2008.915599
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Chiu CC, 2010, IEEE T CIRC SYST VID, V20, P518, DOI 10.1109/TCSVT.2009.2035843
   Cho SG, 2019, INT J INTELL ROBOT, V3, P418, DOI 10.1007/s41315-019-00115-1
   Choudhury SK, 2016, IEEE ACCESS, V4, P6133, DOI 10.1109/ACCESS.2016.2608847
   COHIGNAC T, 1994, INT C PATT RECOG, P164, DOI 10.1109/ICPR.1994.576250
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dadi H.S., 2018, Ann. Data Sci, V5, P157
   Dai C, 2019, IEEE NETWORK, V33, P206, DOI 10.1109/MNET.2019.1800310
   Dai KX, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1144
   Darwich A, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070092
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   de los Guachi Guachi A, 2016, THESIS
   Debnath S, 2021, SIGNAL IMAGE VIDEO P, V15, P25, DOI 10.1007/s11760-020-01717-0
   Dewan A, 2018, IEEE INT C INT ROBOT, P4774, DOI 10.1109/IROS.2018.8594420
   Dhome Y, 2010, 2010 2 INT C IM PROC
   Ding C, 2015, MULTIMED TOOLS APPL, V74, P9871, DOI 10.1007/s11042-014-2156-2
   Ding CW, 2018, IEEE J EM SEL TOP C, V8, P306, DOI 10.1109/JETCAS.2018.2797313
   Domale M, 2017, INT J ENG RES TECHNO, V6, P227
   Drosou A, 2012, COMPUT VIS IMAGE UND, V116, P411, DOI 10.1016/j.cviu.2011.08.009
   El Baf F., 2008, IEEE INT C FUZZ SYST
   El Baf F, 2008, LECT NOTES COMPUT SC, V5358, P772, DOI 10.1007/978-3-540-89639-5_74
   Elgammal A., 2000, COMPUTER VISION ECCV, V1843
   Elhoushi M, 2017, IEEE T INTELL TRANSP, V18, P1662, DOI 10.1109/TITS.2016.2617200
   Fergus R, 2003, PROC CVPR IEEE, P264
   Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Giannarou S, 2009, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2009.5193238
   Gong MM, 2020, IEEE ACCESS, V8, P25811, DOI 10.1109/ACCESS.2020.2971283
   Goyal K, 2018, ARTIF INTELL REV, V50, P241, DOI 10.1007/s10462-017-9542-x
   Grimson WEL, 1998, 1998 IEEE COMP SOC C
   Guler P, 2016, J REAL-TIME IMAGE PR, V11, P457, DOI 10.1007/s11554-013-0337-2
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Han BH, 2007, LECT NOTES COMPUT SC, V4842, P162
   Hao Z, 2020, CSI HC WIFI BASED IN, V2020, P20
   Hasan H, 2014, ARTIF INTELL REV, V41, P147, DOI 10.1007/s10462-011-9303-1
   Hassaballah M, 2020, PATTERN ANAL APPL, V23, P1505, DOI 10.1007/s10044-020-00874-9
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Höferlin B, 2009, IEEE INT VEH SYM, P324, DOI 10.1109/IVS.2009.5164298
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Hruz M, 2011, SOFTWARE HARDWARE PA, V21, P389
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Jabri S, 2000, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2000.902997
   Jalal A, 2019, INT BHURBAN C APPL S, P371, DOI 10.1109/IBCAST.2019.8667145
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji XF, 2014, INT J AUTOM COMPUT, V11, P500, DOI 10.1007/s11633-014-0831-4
   Jiang QN, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3279-x
   JOSHI H, 2020, INT J ADV SCI TECHNO, V29
   Joudaki S, 2015, 2015 4 INT C INT DIG, P1, DOI DOI 10.1109/IDM.2015.7516329
   Ju ZJ, 2012, PATTERN RECOGN, V45, P1146, DOI 10.1016/j.patcog.2011.08.028
   Kale GV, 2016, INT J AMBIENT COMPUT, V7, P75, DOI 10.4018/IJACI.2016070104
   Kalsotra R, 2017, INT J SCI RES COMPUT, V2
   Kavitha P, 2018, MULTIMED TOOLS APPL, V77, P26509, DOI 10.1007/s11042-018-5877-9
   Kellokumpu V., 2007, MACH VISION APPL, V22, P767
   Khalifa AF, 2019, IMAGE VISION COMPUT, V85, P1, DOI 10.1016/j.imavis.2019.02.010
   Krig S., 2016, Comput. Vis. Metrics Textb. Ed, P187
   Kumar M, 2020, SOFT COMPUT, V24, P13197, DOI 10.1007/s00500-020-04733-x
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laugraud B, 2015, LECT NOTES COMPUT SC, V9281, P477, DOI 10.1007/978-3-319-23222-5_58
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee J, 2008, PATTERN RECOGN LETT, V29, P1934, DOI 10.1016/j.patrec.2008.06.006
   Lee MS, 2014, I C INF COMM TECH CO, P630, DOI 10.1109/ICTC.2014.6983234
   Leng CC, 2019, IEEE ACCESS, V7, P6424, DOI 10.1109/ACCESS.2018.2888856
   Li CL, 2009, PATTERN RECOGN LETT, V30, P544, DOI 10.1016/j.patrec.2008.12.004
   Li C, 2007, MULTIMED TOOLS APPL, V35, P55, DOI 10.1007/s11042-007-0119-6
   Li J, 2017, ADV INTELL SYST, V454, P173, DOI 10.1007/978-3-319-38789-5_27
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu H., 2017, STUDIES COMPUTATIONA, P675
   Liu Z, 2015, NEURAL COMPUT APPL, V26, P2013, DOI 10.1007/s00521-015-1863-6
   Lu S, 2020, INT J MACH LEARN CYB, V11, P1267, DOI 10.1007/s13042-019-01037-x
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Maale BR, 2019, INT J ENG TRENDS TEC, V67, P17, DOI DOI 10.14445/22315381/IJETT-V67I10P204
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2009, LECT NOTES COMPUT SC, V5807, P422
   Matsui YI, 2007, IEEE SENS J, V7, P1447, DOI 10.1109/JSEN.2007.905040
   Matsuyama T, 2006, SYSTEMS COMPUTERS JA, V37, P2201
   Mayo Z., 2009, P ANN S PRASA STELL, P77
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Miao Q, 2011, PATTERN RECOGN LETT, V32, P1564, DOI 10.1016/j.patrec.2011.05.017
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mishra S., 2015, ENVIRONMENT, V4, P1044
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mohamed A. N., 2013, JES. J. Eng. Sci., V41, P1928, DOI [10.21608/jesaun.2013.114925, DOI 10.21608/JESAUN.2013.114925]
   Mohanty A, 2015, INT J COMPUT APPL, V975
   Mu KN, 2016, OPTIK, V127, P4794, DOI 10.1016/j.ijleo.2016.01.017
   Mubarak Sh, 2013, SPRINGER SCI BUSINES, V9
   NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7
   NAQVI SZH, 2013, J INF ASSUR SECUR, V8
   Ng CC, 2015, IEEE ACCESS, V3, P1079, DOI 10.1109/ACCESS.2015.2455871
   Niebles JC, 2007, PROC CVPR IEEE, P1235
   Nikolov B, 2014, RADIOENGINEERING, V23, P652
   Nurhadiyatna Adi, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P459, DOI 10.1007/978-981-10-0557-2_46
   Nweke HF, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0194-5
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Olver PJ, 1999, ACTA APPL MATH, V59, P45, DOI 10.1023/A:1006295328209
   Oyallon E, 2015, IMAGE PROCESS ON LIN, V5, P176, DOI 10.5201/ipol.2015.69
   Pal SK, 2019, NEURAL COMPUT APPL
   Panahi Sorayya, 2008, 2008 Digital Image Computing: Techniques and Applications, P357, DOI 10.1109/DICTA.2008.52
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Parks Donovan H., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P192, DOI 10.1109/AVSS.2008.19
   Patel TP, 2014, INT J ENG DEV RES, V2, P3680
   Pattar S. Y., 2015, INT J INNOVATIVE RES, V4, P2780
   Phapatanaburi K, 2016, MULTIMED TOOLS APPL, V75, P5109, DOI 10.1007/s11042-015-2935-4
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Ramamurthy Sreenivasan Ramasamy, 2018, WILEY INTERDISC REW, V8, P4
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Reyneke C, 2014, PATT REC ASS S AFR P
   Rodríguez-Moreno I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143160
   Roshanbin N, 2017, PATTERN ANAL APPL, V20, P1145, DOI 10.1007/s10044-016-0554-y
   Sajid H, 2019, SIGNAL PROCESS-IMAGE, V75, P11, DOI 10.1016/j.image.2019.03.003
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Santoyo-Morales JE, 2014, J APPL RES TECHNOL, V12, P527, DOI 10.1016/S1665-6423(14)71632-3
   Saremi M, 2020, MULTIMED TOOLS APPL, V79, P6025, DOI 10.1007/s11042-019-08483-3
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sehairi K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023025
   Seib V, 2014, WORKSH EL COMP ENG S
   Seki M, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P207, DOI 10.1109/WACV.2000.895424
   Seo S, 2020, MULTIMED TOOLS APPL
   Setiono R, 1998, FEATURE EXTRACTION V, P192
   Shahbaz A, 2015, EVALUATION BACKGROUN
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P15, DOI 10.1007/978-3-319-07386-6_3
   Sharma R, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-018-0024-9
   SHARMA TK, 2013, ADV INTELL SYST, V174, P101
   Shi ZF, 2020, J SIGNAL PROCESS SYS, V92, P435, DOI 10.1007/s11265-019-01477-2
   Shirazi MS, 2019, MACH VISION APPL, V30, P1097, DOI 10.1007/s00138-019-01040-w
   Shunzhi Z, 2015, MULTIMEDIA SYSTEMS, V23, P105
   Sigari MH, 2008, INT J COMPUT SCI NET, V8, P138
   Smach F, 2008, J MATH IMAGING VIS, V30, P43, DOI 10.1007/s10851-007-0036-3
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Su ZX, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P1, DOI 10.1109/SMI.2009.5170156
   Suhr JK, 2011, IEEE T CIRC SYST VID, V21, P365, DOI 10.1109/TCSVT.2010.2087810
   Sun L, 2015, MULTIMED TOOLS APPL, V74, P3947, DOI 10.1007/s11042-013-1806-0
   Sykora P, 2014, AASRI PROC, V9, P19, DOI 10.1016/j.aasri.2014.09.005
   Takatoo M, 1998, SYSTEMS COMPUTERS JA, V29, P2976
   Takhar G, 2016, IEEE INT C REC ADV I, P23
   Takhar G, 2016, 2016 INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (ICRAIE)
   Tang YH, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P156, DOI 10.1109/ICMIP.2017.65
   Thangaraju B, 2012, J DIGIT IMAGING, V25, P607, DOI 10.1007/s10278-012-9489-z
   Tian YL, 2012, MACH VISION APPL, V23, P967, DOI 10.1007/s00138-011-0377-1
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Tuncer T, 2019, PHYSICA A, V526, DOI 10.1016/j.physa.2019.04.191
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Vafadar M, 2015, MULTIMED TOOLS APPL, V74, P7515, DOI 10.1007/s11042-014-1989-z
   Varkey JP, 2012, PERS UBIQUIT COMPUT, V16, P897, DOI 10.1007/s00779-011-0455-4
   Vishwakarma DK, 2019, VISUAL COMPUT, V35, P1595, DOI 10.1007/s00371-018-1560-4
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vosters L. P. J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P384, DOI 10.1109/AVSS.2010.72
   Vosters L, 2012, IMAGE VISION COMPUT, V30, P1004, DOI 10.1016/j.imavis.2012.08.017
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.4028/www.scientific.net/AMM.36.96, 10.1109/ICICTA.2010.35]
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang MY, 2019, DIGIT SIGNAL PROCESS, V87, P125, DOI 10.1016/j.dsp.2019.01.013
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wei H, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418783633
   Wei HQ, 2019, INT J DIGIT EARTH, V12, P415, DOI 10.1080/17538947.2018.1429503
   Wei Wei, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P386, DOI 10.1109/ICINIS.2009.105
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   White B, 2007, 2007 IEEE INT C MULT
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xiao JZ, 2012, INT J MACH LEARN CYB, V3, P77, DOI 10.1007/s13042-011-0035-y
   Xu WR, 2015, MULTIMED TOOLS APPL, V74, P7711, DOI 10.1007/s11042-014-2007-1
   Xu XM, 2015, J CENT SOUTH UNIV, V22, P593, DOI 10.1007/s11771-015-2560-4
   Xu Y, 2019, OPTIK, V207, P1
   Yadav Y., 2017, INT J SCI TECHNOL RE, V6, P191
   Yao G, 2017, SENSORS, V17
   Yi Y, 2017, MULTIMED TOOLS APPL, V76, P18891, DOI 10.1007/s11042-017-4416-4
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zacharatos H, 2014, IEEE COMPUT GRAPH, V34, P35, DOI 10.1109/MCG.2014.106
   Zhang CL, 2014, PROC INT CONF PARAL, P182, DOI 10.1109/ICPP.2014.27
   Zhang H, 2019, J BIOMOL STRUCT DYN, V5, P1
   Zhang T, 2020, INT J FUZZY SYST, V22, P1330, DOI 10.1007/s40815-020-00825-w
   Zhao L, 2018, MULTIMED TOOLS APPL, V77, P19415, DOI 10.1007/s11042-017-5380-8
   Zhao XM, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-20
   Zheng WB, 2020, NEUROCOMPUTING, V394, P178, DOI 10.1016/j.neucom.2019.04.088
   Zhou XX, 2020, COMPUT COMMUN, V150, P62, DOI 10.1016/j.comcom.2019.11.008
   Zhu HP, 2018, BMC ENDOCR DISORD, V18, DOI 10.1186/s12902-018-0230-x
   Ziqiang Wang, 2012, Journal of Multimedia, V7, P387, DOI 10.4304/jmm.7.6.387-393
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
   2013, VIST NAN, P1
NR 239
TC 16
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31819
EP 31863
DI 10.1007/s11042-020-09485-2
EA AUG 2020
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200002
DA 2024-07-18
ER

PT J
AU Zaaraoui, H
   El Kaddouhi, S
   Saaidi, A
   Abarkan, M
AF Zaaraoui, H.
   El Kaddouhi, S.
   Saaidi, A.
   Abarkan, M.
TI Face recognition with a new local descriptor based on strings of
   successive values
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Local descriptor; Strings of successive values;
   Levenshtein distance; Hellinger distance
ID BINARY PATTERNS; EIGENFACES
AB In this paper, a novel face recognition approach based on strings of successive values (SSV) is presented. In contrast to most of the existing local descriptors which encode only a limited number of pixels included in a mask, the strings extract more discriminative information over the whole face region, by moving from the current pixel to the next one, and to the other next, and so on, according to the variations of their intensities. Therefore, the SSV can be stopped in any place of the face area, which allows us to encode more edge information and texture information than the existing methods. The proposed face recognition scheme requires several steps. Firstly, the images are divided into non-overlapping sub-regions from which the strings are extracted since each pixel produces two different strings. Thereafter, the dictionary of visual words is created to reduce the number of strings obtained from each patch of the image. Therefore, the face image is described only by visual words, because each string is replaced by its nearest dictionary word. As a result, the occurrence of visual words is computed in a histogram as a face descriptor. Finally, the recognition is performed by using the nearest neighbor classifier with the Hellinger distance. The effectiveness of the proposed approach is evaluated on three different databases, and the experimental results show that the recognition performances achieved are competitive or even outperform the literature state of the art methods.
C1 [Zaaraoui, H.; El Kaddouhi, S.; Saaidi, A.; Abarkan, M.] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Comp Sci, LSI, Taza 1223, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Zaaraoui, H (corresponding author), Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Comp Sci, LSI, Taza 1223, Morocco.
EM hicham.zaaraoui@usmba.ac.ma; samir.elkaddouhi@usmba.ac.ma;
   abderrahim.saaidi@usmba.ac.ma; mustapha.abarkan@usmba.ac.ma
OI zaaraoui, hicham/0000-0003-4332-7444
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Almabdy S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204397
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bharkad SD, 2011, INT J PATTERN RECOGN, V25, P777, DOI 10.1142/S0218001411009007
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Chan CH, 2015, PATTERN RECOGN, V48, P1328, DOI 10.1016/j.patcog.2014.10.010
   Chihaoui M, 2016, COMPUTERS, V5, DOI 10.3390/computers5040021
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   El Kaddouhi S, 2017, MULTIMED TOOLS APPL, V76, P23077, DOI 10.1007/s11042-017-4415-5
   el Kaddouhi S., 2018, INT J CONTROL AUTOM, V11, P59, DOI [10.14257/ijca.2018.11.5.06, DOI 10.14257/IJCA.2018.11.5.06]
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Gao GW, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106183
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Guo GD, 2001, IMAGE VISION COMPUT, V19, P631, DOI 10.1016/S0262-8856(01)00046-4
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Jabid T, 2010, IEEE ICCE
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Kas M, 2018, EXPERT SYST APPL, V114, P119, DOI 10.1016/j.eswa.2018.07.035
   Kasar MM, 2016, INT J SECUR APPL, V10, P81, DOI 10.14257/ijsia.2016.10.3.08
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P1819, DOI 10.3233/IFS-141468
   Khan SA, 2014, J INTELL FUZZY SYST, V27, P3131, DOI 10.3233/IFS-141270
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li LJ, 2016, OPTIK, V127, P3935, DOI 10.1016/j.ijleo.2016.01.033
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu J, 2019, MULTIMED TOOLS APPL, V78, P18735, DOI 10.1007/s11042-018-7095-x
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Rikhtegar A, 2016, IET COMPUT VIS, V10, P559, DOI 10.1049/iet-cvi.2015.0037
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang WH, 2015, LECT NOTES COMPUT SC, V8944, P812, DOI 10.1007/978-3-319-15554-8_73
   Wen Y, 2016, DIGIT SIGNAL PROCESS, V50, P103, DOI 10.1016/j.dsp.2015.11.001
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zeng HQ, 2016, NEUROCOMPUTING, V217, P3, DOI 10.1016/j.neucom.2015.11.130
   Zeng JX, 2019, IEEE ACCESS, V7, P57163, DOI 10.1109/ACCESS.2019.2913688
NR 54
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27017
EP 27044
DI 10.1007/s11042-020-09400-9
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000562006600001
DA 2024-07-18
ER

PT J
AU Abasi, AK
   Khader, AT
   Al-Betar, MA
   Naim, S
   Makhadmeh, SN
   Alyasseri, ZAA
AF Abasi, Ammar Kamal
   Khader, Ahamad Tajudin
   Al-Betar, Mohammed Azmi
   Naim, Syibrah
   Makhadmeh, Sharif Naser
   Alyasseri, Zaid Abdi Alkareem
TI A novel ensemble statistical topic extraction method for scientific
   publications based on optimization clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic extraction; Ensemble methods; Multi-Verse optimizer; Scientific
   text clustering; Metaheuristic algorithm
ID MULTI-VERSE OPTIMIZER; KEYPHRASE EXTRACTION; KRILL HERD; ALGORITHM;
   CLASSIFICATION; PARAMETERS; MACHINE; SIZE
AB The automatic topic extraction (TE) from scientific publications provides a very compact summary of the clusters' contents. This often helps in locating information easily. TE enables us to define the boundaries of the scientific fields. Text Document Clustering (TDC) represents, in general, the first step of topic identification to identify the documents, which address a related subject matter. Metaheuristics are typically used as efficient approaches for TDC. The multi-verse optimizer algorithm (MVO) involves a stochastic population-based algorithm. It has been recently proposed and successfully utilized to tackle many hard optimization problems. In the TE process, the focus of each statistical TE method is placed on various language feature space aspects. The aim of this paper is to design a novel ensemble method for an automatic TE from a collection of scientific publications based on MVO as the clustering algorithm. The automatic TE, which is used in our approach, is term frequency-inverse document frequency (TF-IDF), most frequent based keyword extraction (TF), co-occurrence statistical information-based keyword extraction (CSI), TextRank (TR), and mutual information (MI). A group of candidate topics can be provided by each automatic TE method for the proposed ensemble method. Next, the ensemble approach prunes the candidate topics' set via the application of a specific filtering heuristic. Then, their scores are recalculated based on the prescribed metrics. After that, for selecting a set of topics for certain scientific publications, dynamic threshold functions are applied. The findings emphasized the refined candidate set's efficiency, as well as effectiveness. The results also showed that the system's quality has been improved by new topics. The proposed method achieved better precision, as well as recall on a similar dataset compared to the state-of-the-art TE methods.
C1 [Abasi, Ammar Kamal; Khader, Ahamad Tajudin; Makhadmeh, Sharif Naser; Alyasseri, Zaid Abdi Alkareem] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence, Bangi 43600, Selangor, Malaysia.
   [Al-Betar, Mohammed Azmi] Ajman Univ, Coll Engn & Informat Technol, Dept Informat Technol MSAI, Ajman, U Arab Emirates.
   [Al-Betar, Mohammed Azmi] Al Balqa Appl Univ, Al Huson Univ Coll, Dept Informat Technol, POB 50, Irbid, Jordan.
   [Naim, Syibrah] Woosong Univ, Endicott Coll Int Studies ECIS, Technol Dept, Daejeon, South Korea.
   [Alyasseri, Zaid Abdi Alkareem] Univ Kufa, ECE Dept, Fac Engn, Najaf, Iraq.
C3 Universiti Kebangsaan Malaysia; Ajman University; Al-Balqa Applied
   University; Woosong University; University of Kufa
RP Abasi, AK (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence, Bangi 43600, Selangor, Malaysia.
EM ammar.abasi@student.usm.my; tajudin@usm.my; mohbetar@bau.edu.jo;
   syibrah@wsu.ac.kr; m_shareef_cs@yahoo.com; zaid.alyasseri@uokufa.edu.iq
RI Khader, Ahamad Tajudin/H-4923-2013; Alyasseri, Zaid Abdi
   Alkareem/H-5280-2013; Naim, Syibrah/Q-8940-2016; Al-Betar, Al-betar
   Azmi/E-9758-2017; Makhadmeh, Sharif N/A-3428-2019; Abasi, Ammar
   Kamal/AAF-5246-2019; Naim, Syibrah/B-7383-2018
OI Alyasseri, Zaid Abdi Alkareem/0000-0003-4228-9298; Al-Betar, Al-betar
   Azmi/0000-0003-1980-1791; Makhadmeh, Sharif N/0000-0002-2894-7998;
   Abasi, Ammar Kamal/0000-0003-0725-6167; Naim,
   Syibrah/0000-0002-7575-0426
FU universiti sains malaysia (USM) [1001/PK OMP/8014016]
FX This work was supported by universiti sains malaysia (USM) under Grant
   (1001/PK OMP/8014016).
CR Abasi Ammar Kamal, 2019, 2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT). Proceedings, P1, DOI 10.1109/JEEIT.2019.8717491
   Abasi AK, NOVEL HYBRID MULTIVE
   Abasi AK, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.106002
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Ahn H, 2018, SOCIO-ECON PLAN SCI, V61, P1, DOI 10.1016/j.seps.2017.06.001
   Alia OM, 2011, LECT NOTES COMPUT SC, V7077, P79, DOI 10.1007/978-3-642-27242-4_10
   Aljarah I., 2020, Nature-Inspired Optimizers, P123, DOI DOI 10.1007/978-3-030-12127-3_8
   Alyasseri ZAA, 2020, IEEE ACCESS, V8, P10584, DOI 10.1109/ACCESS.2019.2962658
   Alyasseri ZAA, 2019, INTERNATIONAL CONFERENCE OF INFORMATION AND COMMUNICATION TECHNOLOGY (ICICT 2019), P139, DOI 10.1145/3321289.3321327
   [Anonymous], ARXIV10052908
   [Anonymous], APPL INTELL
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Barrow J.D., 2004, SCI ULTIMATE REALITY
   Beliga S, 2015, J INF ORGAN SCI, V39, P1
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bornmann L, 2015, J ASSOC INF SCI TECH, V66, P2215, DOI 10.1002/asi.23329
   Bouras C, 2012, KNOWL-BASED SYST, V36, P115, DOI 10.1016/j.knosys.2012.06.015
   Cagnina L, 2014, INFORM SCIENCES, V265, P36, DOI 10.1016/j.ins.2013.12.010
   Chen CH, 2017, PATTERN RECOGN LETT, V93, P113, DOI 10.1016/j.patrec.2016.11.004
   Chouksey M, 2020, MULTIMED TOOLS APPL, V79, P19075, DOI 10.1007/s11042-019-08138-3
   Collective Evolution, 2018, NEW PHYS THEOR QUEST
   Davidson I, 2005, LECT NOTES ARTIF INT, V3721, P59
   Deepa M., 2012, International Journal of Advanced Research in Computer and Communication Engineering, V1, P147
   Degertekin SO, 2013, COMPUT STRUCT, V119, P177, DOI 10.1016/j.compstruc.2012.12.011
   Del Buono N, 2015, INFORM SCIENCES, V301, P13, DOI 10.1016/j.ins.2014.12.058
   Du SY, 2020, MULTIMED TOOLS APPL, V79, P4619, DOI 10.1007/s11042-019-08142-7
   Ewees AA, 2019, NEURAL COMPUT APPL, V31, P991, DOI 10.1007/s00521-017-3131-4
   Faris H, 2018, NEURAL COMPUT APPL, V30, P2355, DOI 10.1007/s00521-016-2818-2
   Faris H, 2016, APPL INTELL, V45, P322, DOI 10.1007/s10489-016-0767-1
   Fathy A, 2018, ENERGY, V143, P634, DOI 10.1016/j.energy.2017.11.014
   Forsati R, 2015, NEUROCOMPUTING, V159, P9, DOI 10.1016/j.neucom.2015.02.048
   Forsati R, 2013, INFORM SCIENCES, V220, P269, DOI 10.1016/j.ins.2012.07.025
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Grineva M., 2009, P 18 INT C WORLD WID, P661, DOI DOI 10.1145/1526709.1526798
   HaCohen-Kerner Y, 2005, LECT NOTES COMPUT SC, V3406, P657
   Huang A., 2008, Proceedings of the sixth new zealand computer science research student conference (NZCSRSC2008), V4, P9
   Huang C, 2006, IEEE DATA MINING, P275
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Hussain SF, 2019, EXPERT SYST APPL, V118, P20, DOI 10.1016/j.eswa.2018.09.006
   Ienco D, 2018, SOFT COMPUT, V22, P1719, DOI 10.1007/s00500-016-2435-0
   Janiga D, 2017, J PETROL SCI ENG, V154, P354, DOI 10.1016/j.petrol.2017.04.010
   Jayapal J, 2020, MULTIMED TOOLS APPL, V79, P4041, DOI 10.1007/s11042-019-07803-x
   Karaa WB, 2016, INTEL SYST REF LIBR, V96, P267, DOI 10.1007/978-3-319-21212-8_12
   Kaveh A, 2014, ADV ENG SOFTW, V67, P136, DOI 10.1016/j.advengsoft.2013.09.006
   Kaveh A, 2013, ADV ENG SOFTW, V59, P53, DOI 10.1016/j.advengsoft.2013.03.004
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Koopman R, 2017, SCIENTOMETRICS, V111, P1157, DOI 10.1007/s11192-017-2305-2
   Koopman R, 2017, SCIENTOMETRICS, V111, P1119, DOI 10.1007/s11192-017-2303-4
   Krapivin M, 2010, LECT NOTES COMPUT SC, V6102, P102, DOI 10.1007/978-3-642-13654-2_12
   Kumar P, IEEE INTERNET THINGS
   Lee S, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P554, DOI 10.1109/NCM.2008.199
   Lin YS, 2014, IEEE T KNOWL DATA EN, V26, P1575, DOI 10.1109/TKDE.2013.19
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mafarja MM, 2019, SOFT COMPUT, V23, P6249, DOI 10.1007/s00500-018-3282-y
   Makhadmeh SN, 2019, RENEW SUST ENERG REV, V115, DOI 10.1016/j.rser.2019.109362
   Makhadmeh SN, 2019, J AMB INTEL HUM COMP, V10, P3643, DOI 10.1007/s12652-018-1085-8
   Makhadmeh SN, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P672, DOI 10.1109/JEEIT.2019.8717468
   Makin ADJ, 2020, J COGNITIVE NEUROSCI, V32, P353, DOI 10.1162/jocn_a_01485
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Medelyan O, 2006, OPENING INFORMATION HORIZONS, P296
   Meshkat M, 2017, 2017 2ND CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC), P42, DOI 10.1109/CSIEC.2017.7940155
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Najafi E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130617
   Nguyen TD, 2007, LECT NOTES COMPUT SC, V4822, P317
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Pan W, 2017, INT J COMPUT SCI MAT, V8, P115, DOI 10.1504/IJCSM.2017.083758
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Patel MRR, 2017, INT J ENG COMPUTER S, V6
   Pay T, 2017, IEEE INT CONF BIG DA, P4816, DOI 10.1109/BigData.2017.8258552
   Pierezan J, 2019, ENERG CONVERS MANAGE, V199, DOI 10.1016/j.enconman.2019.111932
   Pierezan J, 2018, IEEE C EVOL COMPUTAT, P2633, DOI 10.1109/CEC.2018.8477769
   Pijarski P, 2019, ENG OPTIM, P1
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   Rana S, 2011, ARTIF INTELL REV, V35, P211, DOI 10.1007/s10462-010-9191-9
   Role F, 2014, KNOWL-BASED SYST, V56, P141, DOI 10.1016/j.knosys.2013.11.005
   Rose D., 2010, TEXT MINING APPL THE, V1, P1, DOI [DOI 10.1002/9780470689646.CH1, 10.1002/9780470689646.CH1]
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Sayed GI, 2018, J EXP THEOR ARTIF IN, V30, P293, DOI 10.1080/0952813X.2018.1430858
   Seifert C, 2011, LECT NOTES ARTIF INT, V6926, P292, DOI 10.1007/978-3-642-24477-3_24
   Shafiabady N, 2016, NEUROCOMPUTING, V211, P4, DOI 10.1016/j.neucom.2015.10.137
   Shaikh ZA, 2018, ENG TECHNOL APPL SCI, V8, P2590
   Shukri S, 2018, ENG APPL ARTIF INTEL, V72, P54, DOI 10.1016/j.engappai.2018.03.013
   Smithsonian Institution, 2016, CAN PHYS EV PROV MUL
   Tan SC, 2011, PATTERN RECOGN, V44, P2786, DOI 10.1016/j.patcog.2011.04.001
   Turney PD, ARXIVCS0308033
   Vishwakarma S, INT J, V2, P297
   Wang SH, 2017, SCIENTOMETRICS, V111, P1017, DOI 10.1007/s11192-017-2298-x
   Wang Z, 2018, MULTIMED TOOLS APPL, V77, P4339, DOI 10.1007/s11042-017-5513-0
   Wei TT, 2015, EXPERT SYST APPL, V42, P2264, DOI 10.1016/j.eswa.2014.10.023
   Zeng S, 2014, APPL SOFT COMPUT, V16, P89, DOI 10.1016/j.asoc.2013.11.020
   Zhang C, 2008, J Comput Inf Syst, V4, P1169
   Zhang Y, 2016, TECHNOL FORECAST SOC, V105, P179, DOI 10.1016/j.techfore.2016.01.015
   Zhang ZQ, 2018, PROCEDIA COMPUT SCI, V137, P102, DOI 10.1016/j.procs.2018.09.010
NR 101
TC 13
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 37
EP 82
DI 10.1007/s11042-020-09504-2
EA AUG 2020
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000561718500003
DA 2024-07-18
ER

PT J
AU Cheng, Z
   Li, HJ
   Zeng, XY
   Wang, MQ
   Duan, XL
AF Cheng, Zhuo
   Li, Hongjian
   Zeng, Xiangyan
   Wang, Meiqi
   Duan, Xiaolin
TI Hierarchical saliency mapping for weakly supervised object localization
   based on class activation mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object localization; Weak supervision; Saliency map; CNNs
ID KRILL HERD ALGORITHM
AB Weakly supervised object localization is a basic research in the field of computer vision. In this paper, a hierarchical saliency mapping network for object localization is proposed and designed to avoid missing detailed information of potential object. Based on the classical convolution network, we remove the fully connected part and add multiple information extraction branches. The network extracts information from convolution layers of different scales to generate Hierarchical Saliency Map. Hierarchical Saliency Maps that include Hierarchical-Class Activation Map and Hierarchical-Spatial Pyramid Saliency Map fuse deep-level features and low-level features to locate object. The datasets used for testing are Caltech-UCSD Birds 200, Caltech101 and ImageNet. Compared with Class Activation Map and Spatial Pyramid Saliency Map, the localization accuracy has been improved. This method can be used for fine-grained classification, object tracking and other fields.
C1 [Cheng, Zhuo; Li, Hongjian; Zeng, Xiangyan; Wang, Meiqi; Duan, Xiaolin] Chongqing Univ Posts & Telecommun, Dept Comp Sci & Technol, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Li, HJ (corresponding author), Chongqing Univ Posts & Telecommun, Dept Comp Sci & Technol, Chongqing, Peoples R China.
EM lihj@cqupt.edu.cn
RI jin, chen/KBQ-8592-2024
FU Chongqing Science and Technology Commission Project
   [cstc2017jcyj-AX0142, cstc2018jcyjAX0525]; Key Research and Development
   Projects of Sichuan Science and Technology Department [2019YFG0107]
FX This work was supported by Chongqing Science and Technology Commission
   Project (Grant No:cstc2017jcyj-AX0142 and cstc2018jcyjAX0525), Key
   Research and Development Projects of Sichuan Science and Technology
   Department (Grant No: 2019YFG0107).
CR Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Bosi I, 2016, 2016 INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON COMPUTER AND ENERGY SCIENCE (SPLITECH), P1
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan DP, 2019, RETHINKING RGB D SAL
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton G. E., 2012, 12070580 ARXIV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li D, 2019, IEEE T PATTERN ANAL
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Oquab M., 2015, PROC CVPR IEEE, P685
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Preeti, 2017, International Journal of Information Technology, V9, P411, DOI 10.1007/s41870-017-0051-6
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song H, 2018, JOINT INT CONF SOFT, P718, DOI 10.1109/SCIS-ISIS.2018.00119
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang S, 2017, IEEE T MULTIMEDIA, V19, P2105, DOI 10.1109/TMM.2017.2729786
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wan ZQ, 2017, IEEE IMAGE PROC, P4177, DOI 10.1109/ICIP.2017.8297069
   Xia SF, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101072
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhou B., 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.5555/2968826.2968881
   Zhou B., 2014, CORR, V1412, P6856
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 47
TC 1
Z9 2
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31283
EP 31298
DI 10.1007/s11042-020-09556-4
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400007
DA 2024-07-18
ER

PT J
AU Shah, AM
   Yan, XB
   Khan, S
   Khurrum, W
   Khan, QR
AF Shah, Adnan Muhammad
   Yan, Xiangbin
   Khan, Salim
   Khurrum, Waqas
   Khan, Qasim Raza
TI A multi-modal approach to predict the strength of doctor-patient
   relationships
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physician reviews; Doctor-patient relationship; Deep learning;
   Multi-modal fusion; Image processing
ID SENTIMENT ANALYSIS; NEURAL-NETWORKS; BIG DATA; SATISFACTION; QUALITY;
   TRUST; CLASSIFICATION; CONSULTATIONS; ATTACHMENT; ADHERENCE
AB Advances in healthcare social media and information about the doctor-patient (D-P) communication regarding the prior patients' treatment experience, can positively influence the D-P relationship. In pace with prior patients' photo-sharing on healthcare social media websites from personal computers and smartphones regarding their treatment experience, the amount of multi-modal content has been growing exponentially. Therefore, there is an increasing need for coping with such information to mine useful knowledge about the D-P communication. Scraping 68,610 reviews, including 4618 photos from a popular physician-rating site,, this study proposes a novel, real-time, multi-modal classification framework, which uses textual and visual modalities as a source of information. Furthermore, this work suggests a social media image filtering mechanism that filters duplicate and irrelevant information from the data. Results show that the data filtering enhances the information reliability, whereas the addition of novel text and visual feature sets improves the classification accuracy up to 16.94%. In addition, fusing textual and visual features enhance the performance of the classifier by 18.24%, which produces better results than considering them separately. The findings also revealed that deep learning algorithms outperformed the classical machine learning algorithms across the entire novel features model, indicating the usefulness and suitability of the proposed methodology. Lastly, the findings from extensive experiments on the physicians' reviews dataset will guide the doctors to demonstrate the implication of the proposed system for improving the D-P relationship.
C1 [Shah, Adnan Muhammad; Yan, Xiangbin; Khan, Salim; Khurrum, Waqas] Harbin Inst Technol, Sch Management, Dept Management Sci & Engn, Harbin 150001, Peoples R China.
   [Khan, Qasim Raza] Beijing Technol & Business Univ, Dept Finance, Beijing 100048, Peoples R China.
C3 Harbin Institute of Technology; Beijing Technology & Business University
RP Shah, AM (corresponding author), Harbin Inst Technol, Sch Management, Dept Management Sci & Engn, Harbin 150001, Peoples R China.
EM adnanshah486@gmail.com; xbyan@hit.edu.cn; salim@hit.edu.cn;
   waqaskhurum@hit.edu.cn; qasimraza@cuilahore.edu.pk
RI Khuram, Waqas/AAN-7775-2021; Yan, xiangbin/AAF-8402-2019; Khan, Qasim
   Raza/IQT-2925-2023; Khan, Salim/AHC-6626-2022; Shah, Adnan/AAF-4027-2021
OI Khuram, Waqas/0000-0002-8940-6802; Khan, Salim/0000-0003-4569-1346;
   Shah, Adnan/0000-0002-9638-3514; Khan, Qasim/0000-0001-5103-2844; Khan,
   Qasim Raza/0000-0003-1835-0239
FU National Natural Science Foundation, People's Republic of China
   [71531013, 71729001]
FX This research is supported by the National Natural Science Foundation,
   People's Republic of China (No.71531013, 71729001).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alam F, 2018, INT J HUM-COMPUT INT, V34, P311, DOI 10.1080/10447318.2018.1427831
   Alemi Farrokh, 2012, Qual Manag Health Care, V21, P9, DOI 10.1097/QMH.0b013e3182417fc4
   Amplayo RK, 2017, DATA KNOWL ENG, V110, P54, DOI 10.1016/j.datak.2017.03.009
   [Anonymous], 2016, THEAN PYTH FRAM FAST
   [Anonymous], 2016, Scientific Programming
   [Anonymous], 2020, US VIS AN BIG DAT DA
   Audrain-Pontevia AF, 2018, HEALTH SERV MANAG RE, V31, P154, DOI 10.1177/0951484817748462
   Basole Rahul C, 2015, Proc 2015 Workshop Vis Anal Healthc (2015), V2015, DOI 10.1145/2836034.2836040
   Batarseh FA, 2016, BIG DATA RES, V4, P13, DOI 10.1016/j.bdr.2015.10.001
   Bennett JK, 2011, PATIENT EDUC COUNS, V85, P53, DOI 10.1016/j.pec.2010.08.005
   Bertaglia TFC, 2016, P 26 INT C COMP LING, P112
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boquiren VM, 2015, PATIENT EDUC COUNS, V98, P1465, DOI 10.1016/j.pec.2015.05.020
   Cambria E, 2013, PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), P108, DOI 10.1109/CIHLI.2013.6613272
   Cambria E, 2010, INT CONF SIGN PROCES, P1279, DOI 10.1109/ICOSP.2010.5657072
   Campbell TA, 2007, J AM COLL HEALTH, V55, P333, DOI 10.3200/JACH.55.6.333-340
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Caropreso MF, 2001, TEXT DATABASES AND DOCUMENT MANAGEMENT: THEORY AND PRACTICE, P78
   CDC, 2016, DEATHS MORT
   Chang MK, 2013, INFORM MANAGE-AMSTER, V50, P439, DOI 10.1016/j.im.2013.06.003
   Chen XY, 2017, IEEE IMAGE PROC, P1557, DOI 10.1109/ICIP.2017.8296543
   Cherry MG, 2018, PATIENT EDUC COUNS, V101, P659, DOI 10.1016/j.pec.2017.10.017
   Deng SM, 2018, INQUIRY-J HEALTH CAR, V55, DOI 10.1177/0046958018790831
   Detz A, 2013, J MED INTERNET RES, V15, P157, DOI 10.2196/jmir.2552
   Dhankhar P., 2019, Int. J. Innov. Eng. Technol, V13, P126
   Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59
   Goldberg Y, 2014, ARXIV PREPRINT ARXIV
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gotz DH, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2199170
   Greaves F, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2721
   Grünloh C, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8444
   Guo SS, 2018, INFORM TECHNOL DEV, V24, P279, DOI 10.1080/02681102.2017.1283287
   Haluza D, 2017, HEALTH COMMUN, V32, P1342, DOI 10.1080/10410236.2016.1220044
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Hao HJ, 2017, INT J MED INFORM, V99, P37, DOI 10.1016/j.ijmedinf.2016.12.007
   Hao HJ, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.4430
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   James TL, 2017, EXPERT SYST APPL, V71, P479, DOI 10.1016/j.eswa.2016.11.004
   Kamal N., 2014, J Health Med Informat, V5, pe125, DOI [10.4172/2157-7420.1000e125, DOI 10.4172/2157-7420.1000E125]
   Kaymak S, 2017, PROCEDIA COMPUT SCI, V120, P126, DOI 10.1016/j.procs.2017.11.219
   Kee JWY., 2018, Health Prof Educ, V4, P97, DOI [10.1016/j.hpe.2017.03.006, DOI 10.1016/J.HPE.2017.03.006]
   Kingma D. P., 2014, arXiv
   Kuang W, 2017, DESTECH TRANS SOC, P1
   Laugesen J, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4333
   Li WF, 2014, 2014 IEEE JOINT INTELLIGENCE AND SECURITY INFORMATICS CONFERENCE (JISIC), P64, DOI 10.1109/JISIC.2014.19
   Loane SS, 2014, AUSTRALAS MARK J, V22, P238, DOI 10.1016/j.ausmj.2014.08.007
   Lu XY, 2019, J MED INTERNET RES, V21, DOI 10.2196/12891
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Jiménez-Zafra SM, 2019, ARTIF INTELL MED, V93, P50, DOI 10.1016/j.artmed.2018.03.007
   Martinez D, 2015, J BIOMED INFORM, V53, P251, DOI 10.1016/j.jbi.2014.11.009
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Fernandez JM, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0724-5
   Niaz U., 2013, 2013 14 INT WORKSHOP, P1
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Paolanti M, 2017, ANAL PROCESSING ICIA, P402
   PORIA S, 2016, IEEE DATA MINING, P439, DOI [DOI 10.1109/ICDM.2016.178, DOI 10.1109/ICDM.2016.0055]
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Preim B, 2020, COMPUT GRAPH FORUM, V39, P543, DOI 10.1111/cgf.13891
   Qian XM, 2019, KNOWL-BASED SYST, V164, P107, DOI 10.1016/j.knosys.2018.10.028
   Truong QT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1274, DOI 10.1145/3123266.3123374
   Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1
   Reddy BK, 2018, COMPUT BIOL MED, V101, P199, DOI 10.1016/j.compbiomed.2018.08.029
   Roberts L, 2018, J SURG EDUC, V75, P1180, DOI 10.1016/j.jsurg.2018.02.005
   Roettl J, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5244
   Rothenfluh F, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6875
   Sacha D, 2017, NEUROCOMPUTING, V268, P164, DOI 10.1016/j.neucom.2017.01.105
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002
   Segal J, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.2005
   Shah AM, 2020, J AMB INTEL HUM COMP, V11, P2925, DOI 10.1007/s12652-019-01434-8
   Simonyan K., 2014, CORR
   Simpao AF, 2015, BRIT J ANAESTH, V115, P350, DOI 10.1093/bja/aeu552
   Singh Narinder, 2017, Journal of Applied Mathematics, V2017, DOI 10.1155/2017/2030489
   Strang KD, 2020, HEALTH INFORM J, V26, P981, DOI 10.1177/1460458219854603
   Sudha G, 2018, 2018 IADS INT C COMP, P1, DOI [10.2139/ssrn.3165309, DOI 10.2139/SSRN.3165309]
   Tan SSL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5729
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Tucker JD, 2015, BMJ OPEN, V5, DOI 10.1136/bmjopen-2015-008221
   Umar N, 2012, BMC HEALTH SERV RES, V12, DOI 10.1186/1472-6963-12-1
   Ureña R, 2019, INFORM SCIENCES, V478, P461, DOI 10.1016/j.ins.2018.11.037
   Vaitsis C, 2014, PEERJ, V2, DOI 10.7717/peerj.683
   Vellappally S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1037-z
   Wang JR, 2019, NEUROCOMPUTING, V329, P53, DOI 10.1016/j.neucom.2018.10.049
   Wu B, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9127
   Wu H, 2017, INT J MED INFORM, V107, P107, DOI 10.1016/j.ijmedinf.2017.08.009
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   YANG ZM, 2016, ALGORITHMS, V9, DOI DOI 10.3390/A902004107042350
   Yellowlees P, 2015, INT REV PSYCHIATR, V27, P476, DOI 10.3109/09540261.2015.1082987
   You QZ, 2017, AAAI CONF ARTIF INTE, P231
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zanini C, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/514230
   Zhai C., 2016, Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining, DOI DOI 10.1145/2915031
   Zhang Y, 2017, COMPUT HUM BEHAV, V67, P303, DOI 10.1016/j.chb.2016.11.008
   Zolnierek KBH, 2009, MED CARE, V47, P826, DOI 10.1097/MLR.0b013e31819a5acc
NR 101
TC 4
Z9 4
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23207
EP 23240
DI 10.1007/s11042-020-09596-w
EA AUG 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000560645600001
DA 2024-07-18
ER

PT J
AU Zhang, SW
   Huang, WZ
   Wang, HX
AF Zhang, Shanwen
   Huang, Wenzhun
   Wang, Haoxiang
TI Crop disease monitoring and recognizing system by soft computing and
   image processing models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop disease recognition; Crop disease monitoring system; Internet of
   things (IoT); Sum and difference histogram (SADH)
ID PLANT-DISEASE; AGRICULTURE; INTERNET; THINGS
AB In order to make the crop disease intelligent diagnosis system more cheap, convenient and efficient for common farmers, an effective and general monitoring system of crop diseases is constructed by Internet of Things (IoT). In the system, crop disease images are collected by IoT and passed to the Web server by wireless network. First, a crop disease image dataset is constructed. Second, a K-mean clustering algorithm is utilized to segment disease leaf images, and the sum and difference histogram (SADH) feature vector is extracted from each segmented defect image based on the intensity values of the neighboring pixels. Finally, a reasoning process is built on the reasoning decision tree for monitoring system. The results validates that the proposed system is benefit for monitoring and controlling crop diseases in practice.
C1 [Zhang, Shanwen; Huang, Wenzhun] Xijing Univ, Sch Informat Engn, Xian 710123, Peoples R China.
   [Wang, Haoxiang] GoPercept Labs, Ithaca, NY 14853 USA.
C3 Xijing University
RP Wang, HX (corresponding author), GoPercept Labs, Ithaca, NY 14853 USA.
EM hw496@goperception.com
FU National Science Foundation of China [61473237]; Key research and
   development plan of Shaanxi Province [2017ZDXM-NY-088]
FX This work was supported by the grants of the National Science Foundation
   of China (No. 61473237). It is also supported by the Key research and
   development plan of Shaanxi Province (No. 2017ZDXM-NY-088).
CR Abdulhussain SH, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851750
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Alehegn E., 2019, Int. J. Comput. Vision Robotics, V9, P90, DOI [10.1504/IJCVR.2019.098012, DOI 10.1504/IJCVR.2019.098012]
   [Anonymous], 2014, INT C ADV COMP EL EL
   Dubey SR, 2014, INT J APPL PATTERN R, V1, P199, DOI 10.1504/IJAPR.2014.063759
   Gayatri MK, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT TIAR 2015, P40, DOI 10.1109/TIAR.2015.7358528
   George W, 2015, P 2 INT AFR EUR C IN, P57
   Hossain MS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P150, DOI 10.1109/CSPA.2018.8368703
   Hu X, 2012, INT C COMPUT SCI CON, P129
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Liu D, 2016, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA AND SMART CITY (ICITBS), P487, DOI 10.1109/ICITBS.2015.126
   Markovic D., 2015, Acta Agriculturae Serbica, V20, P145
   Parikshith H, 2020, ADV INTELL SYST COMP, V1108, P304, DOI 10.1007/978-3-030-37218-7_35
   Shi Y, 2015, P INT C APPL SCI ENG, DOI [10.2991/asei-15.2015.7, DOI 10.2991/ASEI-15.2015.7]
   Shi Y, 2015, AER ADV ENG RES, V12, P31
   Thorat N, 2016, INT J EMERG TRENDS T, V42, P155, DOI [10.14445/22312803/IJCTT-V42P126, DOI 10.14445/22312803/IJCTT-V42P126]
   Oliver ST, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11020416
   Tzounis A, 2017, BIOSYST ENG, V164, P31, DOI 10.1016/j.biosystemseng.2017.09.007
   Wang XF, 2015, ACSR ADV COMPUT, V28, P112
   Wu YR, 2019, APPL ECOL ENV RES, V17, P9229, DOI 10.15666/aeer/1704_92299245
   Yang CH, 2020, ENGINEERING-PRC, V6, P528, DOI 10.1016/j.eng.2019.10.015
   Yuan QH, 2014, ADV MAT RES, V655-657, P773
NR 22
TC 10
Z9 10
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30905
EP 30916
DI 10.1007/s11042-020-09577-z
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297200002
DA 2024-07-18
ER

PT J
AU Gao, X
AF Gao, Xin
TI Performance evaluation of automatic object detection with
   post-processing schemes under enhanced measures in wide-area aerial
   imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Post-processing; Wide-area aerial imagery;
   Segmentation; Enhanced measures
ID VEHICLE DETECTION; SALIENCY DETECTION; VIDEO; TRANSFORM; TRACKING
AB Performance analysis of object detection combined with post-processing schemes are challenging especially that the spatial resolution of images is low in wide-area aerial imagery. In this paper, we present the quantitative results of ten object detection algorithms combined with several post-processing schemes including filtered dilation, heuristic filtering, sieving and closing, a three-stage scheme which involves thresholding with respect to area and compactness, and the proposed scheme of median filtering, opening and closing, followed by linear Gaussian filtering with nonmaximum suppression. We verified the sieving and closing as well as the three-stage scheme display better F-beta-score and PASCAL value via four vehicle detection algorithms. We evaluated combinations of ten object detection and segmentation methods with two post-processing schemes by adopting a set of recent evaluation metrics, i.e., Jaccard Index (JI), Fbw measure, the structure similarity measure (SSIM) and the enhanced alignment measure (EAM). Automatic detection outputs are compared with their ground truth in low-resolution aerial datasets. Classified detection results are established on ten algorithms each combined with the selected post-processing schemes. We take two widely used datasets (VIVID and VEDAI) for performance analysis, compare the detections and time cost of each algorithm either without or with the proposed scheme, and verified our approach via replacing either datasets or algorithms. Quantitative evaluation under a set of enhanced measures proves our test with validity, efficiency, and accuracy.
C1 [Gao, Xin] Univ Arizona, Dept Elect & Comp Engn, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Gao, X (corresponding author), Univ Arizona, Dept Elect & Comp Engn, Tucson, AZ 85721 USA.
EM xgao1985@email.arizona.edu
RI Gao, Xin/AAT-3228-2021
OI Gao, Xin/0000-0003-0058-3579
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ali F.B., 2014, Journal of Image and Graphics, V2, P1
   [Anonymous], 2017, THESIS
   Bernard J., 2018, International Conference on Complex Networks and their Applications, P578
   Chen C, 2020, IEEE T CIRC SYST VID, V30, P1, DOI 10.1109/TCSVT.2018.2886310
   Chen C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182176
   Chen KQ, 2018, IEEE GEOSCI REMOTE S, V15, P173, DOI 10.1109/LGRS.2017.2778181
   Chen WP, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02085-w
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Franchi G, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107246
   Fu ZH, 2019, IEEE T IMAGE PROCESS, V28, P6077, DOI 10.1109/TIP.2019.2922095
   Gao X., 2016, THESIS
   Gao X., 2019, Practical Applications of Electrocardiogram, P3
   Gao X., 2018, Int. J. Image Mining, V3, P106
   Gao X, 2020, SIGNAL IMAGE VIDEO P, V14, P625, DOI 10.1007/s11760-019-01592-4
   Gao X, 2018, INT J SIGNAL IMAGING, V11, P217, DOI 10.1504/IJSISE.2018.093827
   Gao X, 2016, IEEE SW SYMP IMAG, P125, DOI 10.1109/SSIAI.2016.7459191
   Gleason J, 2011, IEEE INT CONF ROBOT, P2065
   Han S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183958
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Huang XH, 2020, ACM TRANS SPAT ALGOR, V6, DOI 10.1145/3373647
   Huang Z.-H., 2014, J DIGIT INF MANAG, V12, P246
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Karim S, 2019, MULTIMED TOOLS APPL, V78, P32565, DOI 10.1007/s11042-019-08033-x
   Kasturi R, 2006, PERFORMANCE EVALUATI, P17
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Koga Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030575
   Kurz F, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010047
   Li J., 2018, J EC SURV, V1, P14
   Li S, 2013, INT GEOSCI REMOTE SE, P2645, DOI 10.1109/IGARSS.2013.6723366
   Liu CY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153294
   Liu LC, 2018, IEEE T CIRC SYST VID, V28, P2177, DOI 10.1109/TCSVT.2017.2722232
   Liu ZY, 2020, MULTIMED TOOLS APPL, V79, P25403, DOI 10.1007/s11042-020-09188-8
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Ma BD, 2019, IEEE ACCESS, V7, P59613, DOI 10.1109/ACCESS.2019.2915368
   Mancas M., 2007, P ICVS WORKSH COMP A, P1
   Mandal M, 2020, IEEE GEOSCI REMOTE S, V17, P494, DOI 10.1109/LGRS.2019.2923564
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Murray N, 2013, IEEE T PATTERN ANAL, V35, P2810, DOI 10.1109/TPAMI.2013.108
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Pan C, 2020, MULTIMED TOOLS APPL, V79, P19925, DOI 10.1007/s11042-020-08866-x
   Pan ZW, 2019, COMPUT SECUR, V85, P181, DOI 10.1016/j.cose.2019.04.011
   Pflugfelder R, 2020, P IEEE C COMP VIS PA, P1
   Philip RC, 2014, IEEE SW SYMP IMAG, P109, DOI 10.1109/SSIAI.2014.6806041
   Porter R, 2010, IEEE SIGNAL PROC MAG, V27, P56, DOI 10.1109/MSP.2010.937396
   Prokaj J, 2013, THESIS, P1
   Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155
   Qiu H., 2020, P IEEE C COMPUTER VI, P13188
   Qiu HQ, 2020, IEEE T MULTIMEDIA, V22, P3039, DOI 10.1109/TMM.2020.2971175
   Qiu HQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131594
   Ram S, 2016, IEEE IMAGE PROC, P3817, DOI 10.1109/ICIP.2016.7533074
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Razaque A, 2020, IEEE ACCESS, V8, P80812, DOI 10.1109/ACCESS.2020.2987735
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryu S, 2013, IEEE IMAGE PROC, P201, DOI 10.1109/ICIP.2013.6738042
   Saha BN, 2009, PATTERN RECOGN, V42, P843, DOI 10.1016/j.patcog.2008.09.033
   Salem M.A., 2009, Informatik-Berichte, V229, P8
   Samarabandu J., 2007, Int'l J. Signal Process, V3, P273
   Seo J, 2019, IEEE ACCESS, V7, P134071, DOI 10.1109/ACCESS.2019.2941005
   Shaikh SH, 2014, SPRINGERBRIEF COMPUT, P15, DOI 10.1007/978-3-319-07386-6_3
   Shao S.-C., 2019, IEEE T INSTRUM MEAS, P1
   Shao S, 2017, 2017 IEEE 2ND INTERNATIONAL WORKSHOPS ON FOUNDATIONS AND APPLICATIONS OF SELF* SYSTEMS (FAS*W), P318, DOI 10.1109/FAS-W.2017.166
   Sharma B., 2014, J. Transp. Technol, V4, P150
   Shen JQ, 2019, IEEE ACCESS, V7, P148119, DOI 10.1109/ACCESS.2019.2947143
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi SJ, 2018, IOP CONF SER-MAT SCI, V423, DOI 10.1088/1757-899X/423/1/012031
   Sommer L, 2019, IEEE T CIRC SYST VID, V29, P2733, DOI 10.1109/TCSVT.2018.2874396
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Tayara H, 2018, IEEE ACCESS, V6, P2220, DOI 10.1109/ACCESS.2017.2782260
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Trujillo-Pino A, 2013, IMAGE VISION COMPUT, V31, P72, DOI 10.1016/j.imavis.2012.10.005
   Turmer S., 2014, THESIS
   Unser M, 2011, IEEE T IMAGE PROCESS, V20, P2705, DOI 10.1109/TIP.2011.2138147
   Vasu B-K, 2018, THESIS
   Wang HR, 2018, SIGNAL IMAGE VIDEO P, V12, P1009, DOI 10.1007/s11760-018-1249-1
   Wilson JN, 2000, HDB COMPUTER VISION, P114
   Wu Y.-Q., 2011, T TIANJIN U, V17, P215
   Xiang XZ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082560
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yang B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071728
   Yang G.-B., 2010, Application and Practical Examples of MATLAB Image / Video Processing, P149
   Yang JX, 2019, IEEE ACCESS, V7, P85042, DOI 10.1109/ACCESS.2019.2923407
   Yang MY, 2018, IEEE IMAGE PROC, P3079, DOI 10.1109/ICIP.2018.8451454
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang T, 2020, IEEE T PARALL DISTR, V31, P595, DOI 10.1109/TPDS.2019.2940192
   Zhang W, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111760
   Zhang X-X, 2020, INT J REMOTE SENS, V41, P4335
   Zhang XF, 2010, COMPUT ELECTR ENG, V36, P160, DOI 10.1016/j.compeleceng.2009.08.002
   Zhao DS, 2021, INT J CLIMATOL, V41, P316, DOI 10.1002/joc.6622
   Zhao Z-Q, 2019, IEEE T NEURAL NETWOR, V30, P3231
   Zheng ZZ, 2013, IEEE J-STARS, V6, P2338, DOI 10.1109/JSTARS.2013.2266131
   Zhou GY, 2010, ELECTRON LETT, V46, P167, DOI 10.1049/el.2010.2888
   Zhou H, 2017, ELECTRON LETT, V53, P1406, DOI 10.1049/el.2017.2087
   Zhou Y.-F., 2019, FUSION, P1, DOI [10.1073/pnas.1912623117., DOI 10.1073/PNAS.1912623117]
   Zhu XZ, 2018, PROC CVPR IEEE, P7210, DOI 10.1109/CVPR.2018.00753
NR 99
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30357
EP 30386
DI 10.1007/s11042-020-09201-0
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900017
DA 2024-07-18
ER

PT J
AU Tasci, E
AF Tasci, Erdal
TI Voting combinations-based ensemble of fine-tuned convolutional neural
   networks for food image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food recognition; Deep learning; CNN; Image processing; Ensemble
   learning; Classification; Voting; Optimization
AB Obesity is one of today's most visible, uncared, and common public health problems worldwide. To manage weight loss, obtain calorie intake and record eating lists, the development of the diverse automatic dietary assessment applications has great importance. Recently, deep learning becomes a popular approach that provides outstanding image recognition results. In this paper, we use ResNet, GoogleNet, VGGNet, and InceptionV3 with fine-tuning based on deep learning for image-based and computer-aided food recognition task. We also apply six voting combination rules (namely, minimum probability, average of probabilities, median, maximum probability, product of probabilities, and weighted probabilities) for ensemble methods. The experimental results demonstrate that our proposed ensemble voting scheme with transfer learning gives promising results compared to the state-of-the-art methods on Food-101, UEC-FOOD100, and UEC-FOOD256 image datasets.
C1 [Tasci, Erdal] Ege Univ, Dept Comp Engn, Izmir, Turkey.
C3 Ege University
RP Tasci, E (corresponding author), Ege Univ, Dept Comp Engn, Izmir, Turkey.
EM arif.erdal.tasci@ege.edu.tr
RI Taşcı, Erdal/AAB-7693-2020
OI Taşcı, Erdal/0000-0001-6754-2187
CR Aguilar E, 2017, LECT NOTES COMPUT SC, V10485, P213, DOI 10.1007/978-3-319-68548-9_20
   [Anonymous], 2021, Obesity and overweight
   Arora S, 2019, ADV INTELL SYST, V731, P551, DOI 10.1007/978-981-10-8848-3_53
   Attokaren DJ, 2017, TENCON IEEE REGION, P2801, DOI 10.1109/TENCON.2017.8228338
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Ciocca G, 2018, COMPUT VIS IMAGE UND, V176, P70, DOI 10.1016/j.cviu.2018.09.001
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gelbart MA, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P250
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo TM, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P721, DOI 10.1109/ICBDA.2017.8078730
   Hassannejad H, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P41, DOI 10.1145/2986035.2986042
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kawano Yoshiyuki, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P369, DOI 10.1007/978-3-319-04117-9_38
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu C, 2018, IEEE T SERV COMPUT, V11, P249, DOI 10.1109/TSC.2017.2662008
   Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Mandal B, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2886427
   Martinel N, 2017, MACH GRAP VISION, V26, P13
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   McAllister P, 2018, COMPUT BIOL MED, V95, P217, DOI 10.1016/j.compbiomed.2018.02.008
   McGuinness K, 2017, INSIGHT DCU DEEP LEA
   *NAT HEART LUNG BL, 2019, OV OB
   Ponti M. P.  Jr., 2011, 2011 24th SIBGRAPI Conference on Graphics, Patterns and Images: Tutorials, P1, DOI 10.1109/SIBGRAPI-T.2011.9
   Reyes LQ, 2020, MACROMOL MATER ENG, V305, DOI 10.1002/mame.201900546
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tasci E, 2019, INT C COMP TECHN APP, P14
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Yanai K, 2015, 2015 IEEE INT C MULT, P1, DOI DOI 10.1109/ICMEW.2015.7169816
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 39
TC 16
Z9 16
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30397
EP 30418
DI 10.1007/s11042-020-09486-1
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900010
DA 2024-07-18
ER

PT J
AU Jaiprakash, SP
   Desai, MB
   Prakash, CS
   Mistry, VH
   Radadiya, KL
AF Jaiprakash, Sahani Pooja
   Desai, Madhavi B.
   Prakash, Choudhary Shyam
   Mistry, Vipul H.
   Radadiya, Kishankumar Lalajibhai
TI Low dimensional DCT and DWT feature based model for detection of image
   splicing and copy-move forgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Copy-move; Splicing; DCT; DWT; MSER; Region
   duplication
ID TRANSFORM; ALGORITHM
AB Digital images are being used as a prominent carrier of visual information in this age of digitization. Images become more and more omnipresent in everyday life. The images can be easily manipulated due to the accessibility of many internet tools and advanced software. Previously many techniques have been developed to authenticate the images. But all the previous techniques have high dimension of feature vectors. Here, a low dimensional DCT and DWT based features have been introduced to authenticate the images. In this work, we are dealing with both the passive forgery (splicing and copy-move) simultaneously. Features are extracted through image statistics and pixel correlation from DCT and DWT domain. Ensemble classifier has been selected for training and testing. The classifier classifies whether the given images are forged or authentic. Further, it also classifies the forgery in spliced or copy-move. If there is copy-move, the proposed work also perform the region detection using a novel key-point based method. The proposed model gives good detection accuracy and high generalization capability which is independent of image formats. Experimental results demonstrate the performance of proposed work against different post-processing operations like scaling, rotation, and Gaussian noise. Also, the comparative results against different existing methods show the effectiveness of the proposed model.
C1 [Jaiprakash, Sahani Pooja; Radadiya, Kishankumar Lalajibhai] CGPIT, Dept Comp Sci, Engn, Surat, India.
   [Desai, Madhavi B.] GTU, RNG Patel Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
   [Prakash, Choudhary Shyam] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
   [Mistry, Vipul H.] SN Patel Inst Technol & Res Ctr, Dept Elect & Commun Engn, Umarakh, Gujarat, India.
C3 UKA Tarsadia University; Gujarat Technological University; Koneru
   Lakshmaiah Education Foundation (K L Deemed to be University)
RP Jaiprakash, SP (corresponding author), CGPIT, Dept Comp Sci, Engn, Surat, India.
EM sahanipooja26@gmail.com; desaimadhavi30@gmail.com;
   shyamprakash2008@yahoo.com; vipul.mistry.2019@gmail.com
RI Prakash, Choudhary/Y-2314-2019
OI Prakash, Dr. Choudhary Shyam/0000-0002-9305-3472; desai,
   Madhavi/0000-0002-8922-8364
CR Abd El-Latif EI, 2020, ARAB J SCI ENG, V5, P1
   Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Agarwal S, 2018, J APPL SEC RES, V13, P209, DOI 10.1080/19361610.2017.1422367
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alyammahi S, 2015, IEEE IND ELEC, P65, DOI 10.1109/IECON.2015.7392966
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 1992, R. woods digital image processing
   Bayram Sevinc, 2005, 2005 13th European Signal Processing Conference, P1
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen W., 2007, P SOC PHOTO-OPT INS, V6505, P65050
   Dua S, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2020.115778
   ELLATIF EIA, 2019, J ENG APPL SCI, V14, P7679, DOI DOI 10.36478/JEASCI.2019.7679.7684
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   Hakimi F, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1074, DOI 10.1109/KBEI.2015.7436195
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hsu CM, 2015, ASIA JT CONF INF SEC, P33, DOI 10.1109/AsiaJCIS.2015.16
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Huynh-Kha T, 2016, J SCI TECHNOL ISSUE, V2, P55
   Kanwal N, 2020, PATTERN MULTIMED TOO, V79, P1
   Kaur M, 2016, COMM COM INF SC, V625, P318, DOI 10.1007/978-981-10-2738-3_27
   Kumar A, 2019, ADV INTELL SYST, V670, P17, DOI 10.1007/978-981-10-8971-8_2
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Li C, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P5, DOI 10.1145/3007669.3007689
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin JQ, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2238, DOI 10.1109/ICMLC.2009.5212213
   Mahalakshmi S D, 2013, 2013 IEEE INT C EM T, P2013
   Mahale VH, 2017, PROCEDIA COMPUT SCI, V115, P501, DOI 10.1016/j.procs.2017.09.097
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Park TH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0136-3
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Prakash CS, 2017, ADV INTELL SYST, V509, P257, DOI 10.1007/978-981-10-2525-9_25
   Rathore Y., 2012, INT J COMPUT SCI ENG, V4, P565
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Salahat E, 2015, IEEE IND ELEC, P2812, DOI 10.1109/IECON.2015.7392528
   Singh R., 2014, INT J COMPUTER APPL, V98, P17
   Su B, 2014, J WIREL COMMUN NETW, V2014, P1
   Sudhakar K., 2014, 2014 International Conference on Advances in Electronics, Computers and Communications, P1
   Travis D., 1991, EFFECTIVE COLOR DISP
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Uliyan DM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8070062
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
NR 48
TC 24
Z9 24
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29977
EP 30005
DI 10.1007/s11042-020-09415-2
EA AUG 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400001
DA 2024-07-18
ER

PT J
AU Wang, JC
   Zhang, JG
   Wen, XB
AF Wang, Jianchen
   Zhang, Jianguang
   Wen, Xianbin
TI Non-full multi-layer feature representations for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Multi-layer; Multi-task learning; Pooling
   strategy
ID NETWORK
AB Person re-identification(Re-ID) has attracted increasing attention in the field of computer vision due to its great significance for the potential real-world applications. Profited from the success of convolutional neural networks(CNNs), existing multi-layer approaches leverage different scales of convolutional layers to learn more discriminative features, improving the Re-ID performance to some extent. However, these methods do not further explore whether all the scales of convolutional layers are positive for person re-identification. In this work, we propose a novel non-full multi-layer(NFML) network, which can jointly learn discriminative feature embeddings from positive multiple layers with the manner of combining global and local cues. Moreover, considering few works focus on how to effectively handle the feature maps, a simple yet effective feature progressing module named Pooling Batch Normalization(PBN), consisting of pooling, reduction and batch normalization operations, is introduced to optimize the model structure and further improve the Re-ID performance. Results on three mainstream benchmark datasets Market-1501, DukeMTMC-reID and CUHK03 demonstrate that our method can significantly boost the performances, outperforming the state-of-the-art methods.
C1 [Wang, Jianchen; Wen, Xianbin] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Wang, Jianchen; Wen, Xianbin] Tianjin Univ Technol, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.
   [Zhang, Jianguang] Hengshui Univ, Coll Math & Comp Sci, Hengshui 053000, Hebei, Peoples R China.
   [Zhang, Jianguang] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518000, Guangdong, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Hengshui University; Shenzhen University
RP Wen, XB (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.; Wen, XB (corresponding author), Tianjin Univ Technol, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.; Zhang, JG (corresponding author), Hengshui Univ, Coll Math & Comp Sci, Hengshui 053000, Hebei, Peoples R China.; Zhang, JG (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518000, Guangdong, Peoples R China.
EM 183128311@stud.tjut.edu.cn; lynxzjg@tju.edu.cn; xbwen@tjut.edu.cn
FU Chinese Natural Science Foundation (CNSF) [61472278, 61702165]; Major
   Project of Tianjin [18ZXZNGX00150]; Hebei Provincial Natural Science
   Foundation, China [F2020111001]; Foundation for Talents Program
   Fostering of Hebei Province
FX This work was supported in part by the Chinese Natural Science
   Foundation (CNSF) (under Grant 61472278, Grant 61702165). This work was
   supported in part by the Major Project of Tianjin (under Grant
   18ZXZNGX00150). This work was supported in part by the Hebei Provincial
   Natural Science Foundation, China (under Grant No. F2020111001). This
   work was supported in part by the Foundation for Talents Program
   Fostering of Hebei Province (No.A201803025).
CR Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cai HL, 2019, IEEE COMPUT SOC CONF, P1555, DOI 10.1109/CVPRW.2019.00197
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang H, 2018, ARXIV181211369
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu J, 2016, BIOMED SIGNAL PROCES, V24, P19, DOI 10.1016/j.bspc.2015.09.004
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   TianyiZhou J., 2018, ARXIV180711042
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Zhang J, 2019, INT CONF ACOUST SPEE, P2072, DOI [10.1109/ICASSP.2019.8683858, 10.1109/icassp.2019.8683858]
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 53
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17205
EP 17221
DI 10.1007/s11042-020-09410-7
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000555361800003
DA 2024-07-18
ER

PT J
AU Chen, J
   Luo, S
   Xiong, MF
   Peng, T
   Zhu, P
   Jiang, MH
   Qin, X
AF Chen, Jia
   Luo, Shuang
   Xiong, Mingfu
   Peng, Tao
   Zhu, Ping
   Jiang, Minghua
   Qin, Xiao
TI HybridGAN: hybrid generative adversarial networks for MR image synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative models; Generative adversarial networks; MR image synthesis;
   Deep learning
AB In this paper, we proposeHybridGAN -a new medical MR image synthesis methods via generative adversarial learning. Specifically, our synthesizer generates MRI data in a sequential manner: first in order to improve the robustness of image synthesis, an input full-size real MR image is divided into an array of sub-images. Then, to avoid overfitting limited MRI encodings, these sub-images and an unlimited amount of random latent noise vectors become the input of automatic encoder for learning the marginal image distributions of real images. Finally, pseudo patches with constrained noise vectors are put intoRU-NET which is a component of ourHybridGANto generate a large number of synthetic MR images. InRU-NET, ASpliceLayeris then employed to fuse sub-images together in an interlaced manner into a full-size image. The experimental results show thatHybridGANcan effectively synthesize a large variety of MR images and display a good visual quality. Compared to the state-of-the-art synthesis methods, our method achieves a significant improvement in terms of both visual and quantitative evaluation metrics.
C1 [Chen, Jia; Luo, Shuang; Xiong, Mingfu; Peng, Tao; Zhu, Ping; Jiang, Minghua] Wuhan Text Univ, Sch Math & Comp Sci, Wuhan 430074, Peoples R China.
   [Chen, Jia] Wuhan Text Univ, Engn Res Ctr Hubei Prov Clothing Informat, Wuhan 430073, Peoples R China.
   [Qin, Xiao] Auburn Univ, Samuel Ginn Coll Engn, Shelby Ctr Engn Technol, Dept Comp Sci & Software Engn, Auburn, AL 36849 USA.
C3 Wuhan Textile University; Wuhan Textile University; Auburn University
   System; Auburn University
RP Xiong, MF (corresponding author), Wuhan Text Univ, Sch Math & Comp Sci, Wuhan 430074, Peoples R China.
EM j_chen@wtu.edu.cn; 1932290107@qq.com; xiongmingfu@163.com;
   pt@wtu.edu.cn; zhuping@wtu.edu.cn; jmh@wtu.edu.cn; xqin@auburn.edu
FU Hubei Provincial Department of Education [D20181705]; U.S. National
   Science Foundation [IIS-1618669, CCF-0845257, CNS-0917137, OCI-0753305]
FX Chen's research was sponsored by Hubei Provincial Department of
   Education under a Career Development Award No. D20181705. Xiao Qin's
   work is supported by the U.S. National Science Foundation under Grants
   IIS-1618669, CCF-0845257 (CAREER), CNS-0917137, and OCI-0753305.
CR [Anonymous], 2017, Advances in neural information processing systems
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Bikowski M, 2018, ARXIV180101401
   Bousquet O., 2017, ARXIV170507642
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Genevay Aude, 2017, ARXIV170601807
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I., 2017, Advances in neural information processing systems, P5769
   Han C, 2018, I S BIOMED IMAGING, P734, DOI 10.1109/ISBI.2018.8363678
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kingma D. P., 2014, arXiv
   Kommrusch S, 2018, ARXIV181107999
   Lau F, 2018, LECT NOTES COMPUT SC, V11045, P343, DOI 10.1007/978-3-030-00889-5_39
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li Z, 2019, ARXIV190206455
   Makhzani A., 2015, ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Olut S, 2018, LECT NOTES COMPUT SC, V11121, P147, DOI 10.1007/978-3-030-00320-3_18
   Pan YS, 2018, LECT NOTES COMPUT SC, V11072, P455, DOI 10.1007/978-3-030-00931-1_52
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   Regmi K, 2018, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2018.00369
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29
   Saltzer JH, 1984, TECHNOLOGY, P100
   Shin HO, 2018, INT J CONCR STRUCT M, V12, DOI 10.1186/s40069-018-0249-4
   Sohn K., 2015, ADV NEURAL INFORM PR, P3483, DOI DOI 10.5555/2969442.2969628
   Sohn Kihyuk, 2015, NIPS, P3483
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang Z, 2018, ARXIV181206625
   White Tom, 2016, ARXIV160904468
   Yang S, 2017, INT CONF SOFTW ENG, P426, DOI 10.1109/ICSESS.2017.8342947
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Zhao H, 2018, MED IMAGE ANAL, V49, P14, DOI 10.1016/j.media.2018.07.001
   ZHU JY, 2017, NIPS
NR 37
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27615
EP 27631
DI 10.1007/s11042-020-09387-3
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000553305500001
DA 2024-07-18
ER

PT J
AU Sun, YX
   Li, Q
   Yan, B
   Pan, JS
   Yang, HM
AF Sun, Yu-Xia
   Li, Qi
   Yan, Bin
   Pan, Jeng-Shyang
   Yang, Hong-Mei
TI Reversible data hiding in dual encrypted halftone images using matrix
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Halftone image; Image encryption; Reversible data hiding; Matrix
   embedding; Hamming code
ID SCHEME; WATERMARKING; TRANSFORM; ALGORITHM
AB Reversible data hiding (RDH) is a data-hiding technique that embeds data into cover media such that it can be recovered distortion-free after the embedded data are retrieved. Currently, for RDH in encrypted halftone images (RDH-EH), the original cover image cannot be recovered once the watermark is extracted. In this paper, we present a RDH method for encrypted halftone images based on matrix embedding, which can achieve a high embedding capacity with low distortion. Since minimal information redundancy exists in encrypted halftone images, perfectly reversible algorithms appear to be difficult to implement. Nevertheless, we proposed a completely reversible RDH method for encrypted halftone images with high embedding capacity. To address the drawback of information redundancy, the pixels of the cover image are copied into two images to guarantee reversibility. The watermark is embedded into the first cover image by changing one pixel of each block using syndrome encoding, and into the second cover image by bit replacement. The experimental results show that the halftone image can be completely recovered after the embedded data are extracted. Furthermore, our algorithm can achieve moderate computational complexity, high embedding capacity and high visual quality of marked images. This scheme is suitable for data-hiding applications such as the medical or printing applications where the reversibility is crucial.
C1 [Sun, Yu-Xia; Li, Qi; Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
   [Pan, Jeng-Shyang; Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
EM yanbinhit@hotmail.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National Natural Science Foundation of China (NSFC) [61272432]; Shandong
   Provincial Natural Science Foundation [ZR2014JL044]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) (No. 61272432) and Shandong Provincial Natural Science
   Foundation (No. ZR2014JL044).
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   Alassaf N, 2019, INT J E-HEALTH MED C, V10, P1, DOI 10.4018/IJEHMC.2019100101
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Alotaibi M, J INFORM SECUR CYBER, V2
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen XY, 2019, MULTIMED TOOLS APPL, V78, P7499, DOI 10.1007/s11042-018-6446-y
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Farooqi N, LIFE SCI J, V16
   FLOYD RW, 1976, P SID, V17, P75
   Freitas PG, 2016, SIGNAL PROCESS-IMAGE, V48, P1, DOI 10.1016/j.image.2016.08.007
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Fu MS, 2002, IEEE T IMAGE PROCESS, V11, P477, DOI 10.1109/TIP.2002.999680
   Galand F, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P151, DOI 10.1109/ITW.2003.1216717
   Guo JM, 2014, IEEE T IMAGE PROCESS, V23, P1269, DOI 10.1109/TIP.2013.2257812
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim SH, 2002, IEEE T IMAGE PROCESS, V11, P258, DOI 10.1109/83.988959
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Lien B. K., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P76
   Lo CC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P265, DOI 10.1109/IIH-MSP.2008.272
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Moon TK, 2005, ERROR CORRECTION CODING: MATHEMATICAL METHODS AND ALGORITHMS
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Rivest RL, 1992, RC4 ENCRYPTION ALGOR, V12, P9
   Shi H, 2017, MULTIMED TOOLS APPL, P1
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Ulichney R., 1987, DIGITAL HALFTONING
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3304, P115
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
   Zhou Z, 2019, INT J HIGH PERFORM C, V14, P1, DOI [10.1504/IJHPCN.2019.10025200, DOI 10.1504/IJHPCN.2019.099740]
NR 57
TC 9
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27659
EP 27682
DI 10.1007/s11042-020-08626-x
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554200001
DA 2024-07-18
ER

PT J
AU Choudhary, N
   Minz, S
   Bharadwaj, KK
AF Choudhary, Nirmal
   Minz, Sonajharia
   Bharadwaj, K. K.
TI Negotiation framework for group recommendation based on fuzzy
   computational model of trust and distrust
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Group recommender systems; Multi-agent negotiation;
   Fuzzy trust and distrust; Memory
ID SYSTEMS; NETWORK
AB Group recommender system (GRS) is the gradually prospering type of recommender system (RS) which tends to provide recommendations for the group of users rather than the individual. Most of the existing GRS obtain group preferences using equal weighing of the individual preferences, ignoring the relationship among group members within the group. But this is not a practical scenario because each member has different behavior. Therefore, in this article, we introduce a multiagent based negotiation mechanism between agents, each of them acts in favor of one group member. The proposed negotiation protocol allows agents to accept or discard a part of the offer based on trust and distrust among users, which gives more agility to the negotiation process. Further, we use memory for each agent in the group that records the previously proposed offers for that agent. The efficiency of trust-distrust enhanced GRSs is compared with traditional techniques and the outcomes of computational experiments confirm the supremacy of our proposed models over baseline GRSs techniques.
C1 [Choudhary, Nirmal; Minz, Sonajharia; Bharadwaj, K. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Choudhary, N (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM nirmal32_scs@jnu.ac.in; sonaminz@jnu.ac.in; kbharadwaj@gmail.com
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Agarwal A, 2017, EXPERT SYST APPL, V82, P115, DOI 10.1016/j.eswa.2017.03.069
   Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Anand D, 2013, SOC NETW ANAL MIN, V3, P65, DOI 10.1007/s13278-012-0049-9
   [Anonymous], AUTON AGENT MULTIAGE
   [Anonymous], 2002, P WORKSH MOB TOUR SY
   [Anonymous], 2016, J INTELLIGENT INFORM
   Ardissono L, 2003, APPL ARTIF INTELL, V17, P687, DOI [10.1080/713827254, 10.1080/08839510390225050]
   Baarslag T, 2016, AUTON AGENT MULTI-AG, V30, P849, DOI 10.1007/s10458-015-9309-1
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Bekkerman P., 2006, P WORKSH REC SYST 17, P72
   Bharadwaj KK, 2009, ELECTRON COMMER R A, V8, P37, DOI 10.1016/j.elerap.2008.08.001
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Chevaleyre Y, 2009, J AUTONOMOUS AGENTS
   Choudhary N, 2018, MULTIMED TOOLS APPL, P1
   Choudhary N, 2019, STUD COMPUT INTELL, V771, P41, DOI 10.1007/978-981-10-8797-4_5
   Dara S., 2019, J INTELL INF SYST, P1
   Felfernig A., 2018, Group Recommender Systems: An Introduction
   Garcia I., 2009, Proceedings of the 2009 International Conference on Artificial Intelligence. ICAI 2009, P919
   Garcia I, 2014, EXPERT SYST APPL, V41, P1245, DOI 10.1016/j.eswa.2013.07.111
   Girdhar N, 2019, SOFT COMPUT, P1
   Jameson A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P596
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Kant V, 2013, INT J INTELL SYST, V28, P332, DOI 10.1002/int.21579
   Lenar M, 2007, J UNIVERS COMPUT SCI, V13, P267
   Li WM, 2018, J PARALLEL DISTR COM, V118, P81, DOI 10.1016/j.jpdc.2017.10.003
   Lieberman H, 1999, KNOWL-BASED SYST, V12, P427, DOI 10.1016/S0950-7051(99)00036-2
   Liu YJ, 2017, KNOWL-BASED SYST, V119, P221, DOI 10.1016/j.knosys.2016.12.014
   McCarthy J. F., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P363, DOI 10.1145/289444.289511
   McCarthy K., 2006, FLAIRS Conference, P86
   Nepal S, 2015, WORLD WIDE WEB, V18, P1, DOI 10.1007/s11280-013-0252-2
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Quijano-Sanchez L, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414433
   Quijano-Sánchez L, 2010, PROC INT C TOOLS ART, P121, DOI 10.1109/ICTAI.2010.92
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Rosaci D, 2012, INT J INTELL SYST, V27, P1, DOI 10.1002/int.20513
   Villavicencio C, 2016, LECT NOTES ARTIF INT, V9662, P294, DOI 10.1007/978-3-319-39324-7_34
   Villavicencio C, 2016, LECT NOTES ARTIF INT, V9662, P219, DOI 10.1007/978-3-319-39324-7_19
   Wang Y, 2015, WORLD WIDE WEB, V18, P159, DOI 10.1007/s11280-013-0241-5
   Wu J, 2017, KNOWL-BASED SYST, V122, P39, DOI 10.1016/j.knosys.2017.01.031
   Yera R, 2017, INT J COMPUT INT SYS, V10, P776, DOI 10.2991/ijcis.2017.10.1.52
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 42
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27337
EP 27364
DI 10.1007/s11042-020-09339-x
EA JUL 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000004
DA 2024-07-18
ER

PT J
AU Chung, GS
   Won, CS
AF Chung, Gi Su
   Won, Chee Sun
TI Filter pruning by image channel reduction in pre-trained convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network pruning; CNN filter compression; Facial emotion classification;
   Image channel reduction
AB There are domain-specific image classification problems such as facial emotion and house-number classifications, where the color information in the images may not be crucial for recognition. This motivates us to convert RGB images to gray-scale ones with a single Y channel to be fed into the pre-trained convolutional neural networks (CNN). Now, since the existing CNN models are pre-trained by three-channel color images, one can expect that some trained filters are more sensitive to colors than brightness. Therefore, adopting the single-channel gray-scale images as inputs, we can prune out some of the convolutional filters in the first layer of the pre-trained CNN. This first-layer pruning greatly facilitates the filter compression of the subsequent convolutional layers. Now, the pre-trained CNN with the compressed filters is fine-tuned with the single-channel images for a domain-specific dataset. Experimental results on the facial emotion and Street View House Numbers (SVHN) datasets show that we can achieve a significant compression of the pre-trained CNN filters by the proposed method. For example, compared with the fine-tuned VGG-16 model by color images, we can save 10.538 GFLOPs computations, while keeping the classification accuracy around 84% for the facial emotion RAF-DB dataset.
C1 [Chung, Gi Su; Won, Chee Sun] Dongguk Univ Seoul, Dept Elect & Elect Engn, Seoul 04620, South Korea.
C3 Dongguk University
RP Won, CS (corresponding author), Dongguk Univ Seoul, Dept Elect & Elect Engn, Seoul 04620, South Korea.
EM whtnek@gmail.com; cswon@dongguk.edu
RI Won, Chee Sun/AAI-1101-2020
OI Won, Chee Sun/0000-0002-3400-0792
FU Basic Science Research Program of the National Research Foundation of
   Korea (NRF) - Ministry of Education [NRF-2018R1D1A1B07043542]
FX This work was supported by the Basic Science Research Program of the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education under Grant NRF-2018R1D1A1B07043542.
CR [Anonymous], 2016, PRUNING CONVOLUTIONA
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Cheng Yu, 2017, ARXIV
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Han  S., 2015, ARXIV151000149
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang H, 2018, BIOCOMPUT-PAC SYM, P304
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jaderberg M., 2014, CORR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Luo J.-H., 2017, An entropy-based pruning method for cnn compression
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Paszke A., 2019, Automatic differentiation in PyTorch
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2020, IEEE WINT CONF APPL, P824, DOI [10.13140/rg.2.2.28674.94402, 10.1109/WACV45572.2020.9093331]
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
NR 24
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30817
EP 30826
DI 10.1007/s11042-020-09373-9
EA JUL 2020
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000551736500001
DA 2024-07-18
ER

PT J
AU Raghuwanshi, J
   Mishra, A
   Singh, N
AF Raghuwanshi, Jitendra
   Mishra, Amit
   Singh, Narendra
TI The wavelet transform-domain adaptive filter for nonlinear acoustic echo
   cancellation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlinear acoustic echo cancellation; Functional link; Adaptive filter;
   Wavelet transform
ID ALGORITHM; REDUCTION
AB The usage of low-quality components in communicating devices introduces acoustic nonlinearity. The presence of nonlinearity creates challenges in noise cancellation applications, especially the acoustic echo cancellation (AEC) that requires an adaptive filter of a very high order. However, the functional link adaptive filter (FLAF) algorithm models the acoustic nonlinearity efficiently but shows slow convergence performance due to a very high filter order. To improve the convergence performance of the FLAF, the wavelet transform-domain FLAF (WTD-FLAF) is proposed for nonlinear AEC (NAEC) applications. The convergence rate is improved by decomposing a higher-order adaptive filter into smaller-order subfilters. The convergence speed improvement is gained at the expense of increased computational complexity. A low complexity version of the WTD-FLAF, named as selective update WTD-FLAF (SU-WTD-FLAF) algorithm, is also presented. The SU-WTD-FLAF algorithm is based on the selective coefficient update approach. Computer simulations demonstrate that the convergence performance of the proposed algorithms outperforms the standard FLAF.
C1 [Raghuwanshi, Jitendra; Singh, Narendra] Jaypee Univ Engn & Technol, Dept Elect & Commun Engn, AB Rd, Guna, India.
   [Mishra, Amit] Thapar Inst Engn & Technol, Dept Elect & Commun Engineeirng, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Raghuwanshi, J (corresponding author), Jaypee Univ Engn & Technol, Dept Elect & Commun Engn, AB Rd, Guna, India.
EM jitendra.raghuwanshi@juet.ac.in
RI Singh, Narendra/AAH-5380-2021; raghuwanshi, dr jitendra/KAM-6819-2024
OI Raghuwanshi, Jitendra/0000-0002-4123-3455
CR Abadi MSE, 2017, DIGIT SIGNAL PROCESS, V69, P94, DOI 10.1016/j.dsp.2017.05.012
   Aboulnasr T, 1999, IEEE T SIGNAL PROCES, V47, P1421, DOI 10.1109/78.757235
   Attallah S, 2006, IEEE T CIRCUITS-II, V53, P8, DOI 10.1109/TCSII.2005.855042
   Attallah S, 2000, IEEE T CIRCUITS-II, V47, P209, DOI 10.1109/82.826747
   Barr M, 2020, IET IMAGE PROCESS, V14, P697, DOI 10.1049/iet-ipr.2018.5868
   Birkett A. N., 1995, 1995 IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics (Cat. No.95TH8144), P103, DOI 10.1109/ASPAA.1995.482968
   Borwankar R, 2018, IEEE T INSTRUM MEAS, V67, P690, DOI 10.1109/TIM.2017.2783098
   Breining C, 1999, IEEE SIGNAL PROC MAG, V16, P42, DOI 10.1109/79.774933
   Campbell D. R., 2005, COMPUT INF SYST, V9, P48
   Carini A, 2014, SIGNAL PROCESS, V94, P183, DOI 10.1016/j.sigpro.2013.06.018
   Comminiello D, 2014, IEEE-ACM T AUDIO SPE, V22, P1172, DOI 10.1109/TASLP.2014.2324175
   Comminiello D, 2013, IEEE T AUDIO SPEECH, V21, P1502, DOI 10.1109/TASL.2013.2255276
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Dai HY, 2006, IEEE T CIRCUITS-II, V53, P1190, DOI 10.1109/TCSII.2006.882344
   Das DP, 2004, IEEE T SPEECH AUDI P, V12, P313, DOI 10.1109/TSA.2003.822741
   Erdol N, 1996, IEEE T SIGNAL PROCES, V44, P2163, DOI 10.1109/78.536674
   Guérin A, 2003, IEEE T SPEECH AUDI P, V11, P672, DOI 10.1109/TSA.2003.818077
   Halimeh M. M., 2018, IEEE INT C AC SPEECH
   Halimeh MM, 2019, IEEE SIGNAL PROC LET, V26, P1827, DOI 10.1109/LSP.2019.2951311
   Hou WL, 2019, IEEE ACCESS, V7, P71374, DOI 10.1109/ACCESS.2019.2920021
   Knuth D, 1998, Sorting and Searching: The art of Computer Programming
   LEE JC, 1986, IEEE T ACOUST SPEECH, V34, P499, DOI 10.1109/TASSP.1986.1164850
   Lee K, 2015, IEEE T CIRCUITS-II, V62, P881, DOI 10.1109/TCSII.2015.2435711
   Li JH, 2019, IEEE ACCESS, V7, P179339, DOI 10.1109/ACCESS.2019.2959081
   Mathews V. G., 2000, POLYNOMIAL SIGNAL PR
   Mayyas K, 2004, IEEE T CIRCUITS-II, V51, P136, DOI 10.1109/TCSII.2003.822437
   NARAYAN SS, 1983, IEEE T ACOUST SPEECH, V31, P609, DOI 10.1109/TASSP.1983.1164121
   Pao YH., 1989, Adaptive Pattern Recognition and Neural Networks
   Patra JC, 1999, IEEE T SYST MAN CY B, V29, P254, DOI 10.1109/3477.752797
   Samantaray AK, 2020, IET IMAGE PROCESS, V14, P679, DOI 10.1049/iet-ipr.2019.1024
   Sayed A.H., 2008, Adaptive Filters
   Stenger A, 1999, INT WORKSH AC ECH NO
   Sundararajan D, 2015, HAAR DISCRETE WAVELE
   UNCINI A, 2002, P EUR SIGN PROC C EU, V1, P535
   Vargas RN, 2018, IET SIGNAL PROCESS, V12, P1165, DOI 10.1049/iet-spr.2018.5162
   Xu XB, 2019, IEEE ACCESS, V7, P67402, DOI 10.1109/ACCESS.2019.2918218
   Zhang S, 2018, IEEE T NEUR NET LEAR, V29, P4314, DOI 10.1109/TNNLS.2017.2761259
NR 37
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25853
EP 25871
DI 10.1007/s11042-020-09218-5
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545938600001
DA 2024-07-18
ER

PT J
AU Xu, XG
   Yang, P
   Xian, H
   Liu, Y
AF Xu, Xinggui
   Yang, Ping
   Xian, Hao
   Liu, Yong
TI Shape point set matching based on oriented shape context in
   turbulence-cluttered scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imaging through turbulent media; Shape invariant descriptor; Cluttered
   scene; Shape context; Contour shape recognition
ID RECOGNITION
AB The main challenges of shape point set matching in a long-distance imaging scene stem from the optical turbulence effects, which lead to shape object deformation, rotation, shifted object positions, and cluttered outliers. To address this problem, we propose an effective energy cost model with figural continuity constraint. We first construct an Oriented Shape Context (OSC) descriptor using attributes of shape edges' length and direction, which represent rotation invariance, by adding the oriented model (prototype) edges point set. Then, inspired by the figural continuity prior between the model and target point set, we transform the continuity constraint into a matching energy cost model. Lastly, we develop a simple 2-tree graph to minimize the matching cost function using the Dynamic Program (DP) optimization algorithm. The extensive experiments on both synthetic and real data validate that the proposed method can effectively detect the desired shapes in the complex and highly turbulence-cluttered scenes.
C1 [Xu, Xinggui] Yunnan Univ, Dept Phys, Ctr Optoelect Engn Res, Kunming 650091, Yunnan, Peoples R China.
   [Xu, Xinggui; Liu, Yong] Univ Elect Sci & Technol China, Sch Optoelect Sci & Engn, Chengdu 610054, Peoples R China.
   [Yang, Ping; Xian, Hao] Chinese Acad Sci, Key Lab Adapt Opt, Chengdu 610209, Peoples R China.
   [Yang, Ping; Xian, Hao] Chinese Acad Sci, Inst Opt & Elect, Chengdu 610209, Peoples R China.
C3 Yunnan University; University of Electronic Science & Technology of
   China; Chinese Academy of Sciences; Chinese Academy of Sciences;
   Institute of Optics & Electronics, CAS
RP Xu, XG (corresponding author), Yunnan Univ, Dept Phys, Ctr Optoelect Engn Res, Kunming 650091, Yunnan, Peoples R China.; Xu, XG (corresponding author), Univ Elect Sci & Technol China, Sch Optoelect Sci & Engn, Chengdu 610054, Peoples R China.
EM xu_xinggui@126.com
RI cheng, shu/IZE-4788-2023; cheng, cheng/JBR-8359-2023; liang,
   YU/IYT-4334-2023
OI xu, xinggui/0000-0002-0579-2209; liang, YU/0009-0007-3922-3454
FU National Natural Science Foundation of China (NSFC) [60978049]; Sciences
   Innovation Found, Chinese Academy of Sciences [CXJJ16 M208]
FX The work was supported by the National Natural Science Foundation of
   China (NSFC) (Grant No.60978049); Sciences Innovation Found, Chinese
   Academy of Sciences (Grant No. CXJJ16 M208).We particularly thank Dr.
   Goyette and Dr. Nil for the Dataset and the constructive suggestions of
   reviewers.
CR AGRAWAL H, 1990, SIGPLAN NOTICES, V25, P246, DOI 10.1145/93548.93576
   [Anonymous], 1999, ICCV
   Bai S, 2019, IEEE T PATTERN ANAL, V41, P1213, DOI 10.1109/TPAMI.2018.2828815
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   [郭娟娟 Guo Juanjuan], 2014, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V27, P683
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Li H, 2010, IEEE C COMP VIS PATT
   Lian W, 2017, IEEE T PATTERN ANAL, V39, P1281, DOI 10.1109/TPAMI.2016.2603988
   Lian W, 2012, IEEE T IMAGE PROCESS, V21, P2786, DOI 10.1109/TIP.2012.2186309
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Scott C, 2006, IEEE T IMAGE PROCESS, V15, P1831, DOI 10.1109/TIP.2006.877038
   Sebastian TB, 2004, RECOGNITION SHAPES E
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Shen W, 2016, PATTERN RECOGN LETT, V83, P321, DOI 10.1016/j.patrec.2016.02.002
   Thayananthan A, 2003, PROC CVPR IEEE, P127
   Torki M, 2010, IEEE C COMP VIS PATT
   Xu XG, 2018, J OPT, V21, P10
   Xu XG, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/aaf191
   Yu T, 2018, 32 C NEUR INF PROC S
   Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81
NR 26
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25817
EP 25834
DI 10.1007/s11042-020-09215-8
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222500004
DA 2024-07-18
ER

PT J
AU Mondonneix, G
   Mari, JM
   Chabrier, S
   Gabillon, A
AF Mondonneix, Gael
   Mari, Jean Martial
   Chabrier, Sebastien
   Gabillon, Alban
TI A kernel machine for hidden object-ranking problems (HORPs)
   Formalization and application to Tahitian black pearls quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ordinal learning; Classification; Object-ranking; Instance-ranking;
   Learning bias; Kernel machine; Support vector machine; Pearls quality
   assessment
ID REGRESSION-MODELS
AB Hidden Object-Ranking Problems (HORPs) are object-ranking problems stated as classification or instance-ranking problems. There exists so far no dedicated algorithm for solving them properly and HORPs are usually solved as if they were classification (multi-class or ordinal) or instance-ranking problems. In the former case, item-related ordinal information is negated and only class-related information is retained; in the latter case, item-related ordinal information is considered, but in a way that emphasizes class-related information, so that the items are not only sorted but also clustered. We propose a kernel machine that allows retaining item-related ordinal information while avoiding emphasizing class-related information. We show how this kernel machine can be implemented with standard optimization libraries provided slight modifications on the original kernel. The proposed approach is tested on Tahitian pearls quality assessment and compared with four other classical methods. It yields better results (93.6%+/- 3.9%of correct predictions without feature selection, 94.3%+/- 3.4%with feature selection) than the best of the other tested methods (91.3%+/- 3.4%and 92.6%+/- 4.3%without and with feature selection for the instance-ranking approach), this improvement being significant (p-value < 0.05). Moreover, this method exhibits no significant difference in the results with and without feature selection (p-value = 0.33), which may be a hint that its learning bias fits the problem well and can thus alleviate the data preprocessing workload.
C1 [Mondonneix, Gael; Mari, Jean Martial; Chabrier, Sebastien; Gabillon, Alban] Univ French Polynesia, LABEX CORAIL, Geopole Pacif Sud EA4238, Punaauia, French Polynesi, France.
RP Mondonneix, G (corresponding author), Univ French Polynesia, LABEX CORAIL, Geopole Pacif Sud EA4238, Punaauia, French Polynesi, France.
EM gaelmondonneix@yahoo.fr
RI Chabrier, Sébastien/AAE-8293-2022; Mari, Jean Martial/B-8980-2009
CR Amini M.-R., 2015, Learning with Partially Labeled and Interdependent Data
   [Anonymous], 2007, PROGRAMMING COLLECTI
   Ashby D., 1991, STAT MED, V10, P1635, DOI DOI 10.1002/SIM.4780101015
   Cardoso JS, 2011, INT J PATTERN RECOGN, V25, P1173, DOI 10.1142/S0218001411009093
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohen WW, 1999, J ARTIF INTELL RES, V10, P243, DOI 10.1613/jair.587
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Frank Eibe, 2001, EUR C MACH LEARN, P145, DOI 10.1007/3-540-44795-413
   Fürnkranz J, 2010, PREFERENCE LEARNING, P65, DOI 10.1007/978-3-642-14125-6_4
   Herbrich R, 1999, SCIENCE, DOI [10.1049/cp:19991091, DOI 10.1049/CP:19991091]
   Hudry O, 2010, EUR J OPER RES, V203, P216, DOI 10.1016/j.ejor.2009.07.034
   Janson S, 2004, RANDOM STRUCT ALGOR, V24, P234, DOI 10.1002/rsa.20008
   Koltchinskii V, 2000, HIGH DIMENSIONAL PRO, DOI [10.1007/978-1-4612-1358-1-29, DOI 10.1007/978-1-4612-1358-1-29]
   MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109
   MCKELVEY RD, 1975, J MATH SOCIOL, V4, P103, DOI 10.1080/0022250X.1975.9989847
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   Misganaw Burook, 2015, IEEE Life Science Letters, V1, P15, DOI 10.1109/LLS.2015.2451291
   Mitchell T, 1997, MACH LEARN, DOI [10.1007/BF00116892, DOI 10.1007/BF00116892]
   Mondonneix G, 2017, P 19 IR MACH VIS IM, P186
   Mondonneix G, 2017, IEEE APP IMG PAT
   Mondonneix G, 2018, LECT NOTES COMPUT SC, V10884, P90, DOI 10.1007/978-3-319-94211-7_11
   Shmoys David., 1996, APPROXIMATION ALGORI, P192
   SLATER P, 1961, BIOMETRIKA, V48, P303
   STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677
   WINSHIP C, 1984, AM SOCIOL REV, V49, P512, DOI 10.2307/2095465
NR 25
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35093
EP 35107
DI 10.1007/s11042-020-09184-y
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000545195600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Vimina, ER
   Divya, MO
AF Vimina, E. R.
   Divya, M. O.
TI Maximal multi-channel local binary pattern with colour information for
   CBIR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Local binary pattern; Multi-channel feature extraction; RGB colour
   quantization; Feature fusion; Image matching
ID IMAGE RETRIEVAL; HISTOGRAM FEATURES; FRAMEWORK
AB Content Based Image Retrieval (CBIR) focuses on retrieving images from repositories based on visual features extracted from the images. Texture and colour are one of the popularly used feature combination in CBIR. A major challenge in colour image retrieval is the characterization of features of the constituent channels and their integration. The commonly adopted methodology include extraction of features of various channels followed by their concatenation. However, the resulting image feature vector is generally of high dimensionality. To address this problem, in this paper a texture-colour descriptor is proposed integrating the multi-channel features. For texture computation, a fixed sized local intensity based descriptor, Maximal Multi-channel Local Binary Pattern (MMLBP), which integrates the multi-channel local binary information through an adder-map followed by thresholding is introduced. The histogram of the obtained patterns is used for representing the image texture. Colour information is captured by quantizing the RGB colour space and is represented with histogram. The colour-texture descriptors are further fused to characterize the images. The efficacy of the descriptor is evaluated by carrying out retrieval on benchmarked datasets for image retrieval such as Wang's 1 K, Corel 5 K, Corel 10 K, Coloured Brodatz Texture and Zubud, using precision and recall measures as evaluation metrics. It is observed that the proposed descriptor presents improved retrieval performance over the databases under consideration and outperforms other descriptors.
C1 [Vimina, E. R.; Divya, M. O.] Amrita Sch Arts & Sci, Dept Comp Sci & IT, Amrita Viswa Vidyapeetham Kochi Campus, Ernakulam, India.
C3 Amrita Vishwa Vidyapeetham
RP Vimina, ER (corresponding author), Amrita Sch Arts & Sci, Dept Comp Sci & IT, Amrita Viswa Vidyapeetham Kochi Campus, Ernakulam, India.
EM vimina.er@gmail.com; divyammo@gmail.com
RI , Divya/GYE-1088-2022
OI , Divya/0000-0003-1983-7364; E R, Vimina/0000-0002-8451-0395
CR Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   [Anonymous], 2014, 2014 4 INT S ISKO MA
   Armi L., 2019, International Online Journal of Image Processing and Pattern Recognition, V2, P1, DOI DOI 10.48550/ARKXIV.1904.06554
   Arya R, 2020, LECT NOTES NETWORKS
   Balntas V, 2020, IEEE T PATTERN ANAL, V42, P2825, DOI 10.1109/TPAMI.2019.2915233
   Bello-Cerezo R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040738
   Bianconi F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011002
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Choi JY, 2010, IEEE IMAGE PROC, P4541, DOI 10.1109/ICIP.2010.5653653
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Galshetwar GM, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102615
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Han XH, 2013, INT CONF BIOMED, P846, DOI 10.1109/BMEI.2013.6747059
   Heng CK, 2012, PROC CVPR IEEE, P3250, DOI 10.1109/CVPR.2012.6248061
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Maani R, 2015, HDB PATTERN RECOGNIT, P351, DOI [10.1142/9789814656535_0019, DOI 10.1142/9789814656535_0019]
   Matharage S., 2017, 2017 14 IEEE IND COU, P1
   Murala S, 2013, PROC SPIE, V8663, DOI 10.1117/12.2002185
   Murala S, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1411, DOI 10.1109/IADCC.2009.4809223
   Napoletano P, 2017, LECT NOTES COMPUTER
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Raza A, 2019, MULTIMED TOOLS APPL, V78, P2719, DOI 10.1007/s11042-018-5795-x
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vimina ER, 2019, IET IMAGE PROCESS, V13, P1979, DOI 10.1049/iet-ipr.2018.5381
   Vimina ER, 2018, THESIS
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang TQ, 2011, IN C IND ENG ENG MAN, P610, DOI 10.1109/IEEM.2011.6117989
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Yang M., 2008, PATTERN RECOGN, P43, DOI DOI 10.5772/6237
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
   Zhou W., 2017, Recent Advance in Content-based Image Retrieval: A Literature Survey
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 43
TC 13
Z9 13
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25357
EP 25377
DI 10.1007/s11042-020-09207-8
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545796600001
DA 2024-07-18
ER

PT J
AU Abdelfatah, RI
AF Abdelfatah, Roayat Ismail
TI A color image authenticated encryption using conic curve and Mersenne
   twister
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Signature; Conic curve; Messene's twister
ID RSA; SCHEME; ALGORITHM; EFFICIENT; SECURITY; CRYPTOGRAPHY;
   CRYPTANALYSIS; SYSTEM; CHAOS
AB A robust secure image transmission scheme has to achieve all the security services as confidentiality, authentication, integrity and nonrepudiation with a reasonable efficiency. An authenticated image encryption scheme which achieves all these services is proposed in this paper. The scheme uses pseudorandom sequence Public-key cryptosystem design based on factoring and discrete logarithmsenerated by Mersenne's twister with XOR operation for image encryption and proposes two hard problems based digital signature: conic curve discrete logarithm problem (CCDLP) and Integer Factorization Problem (IFP) which achieves a highly secure system with efficient point operations and inverses. For efficient transmission, the image signature is embedded in the cipher image. Security analysis of the scheme is provided. According to the results, the proposed scheme is efficient and achieves an excellent long term security.
C1 [Abdelfatah, Roayat Ismail] Tanta Univ, Elect & Elect Commun Dept, Tanta, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University
RP Abdelfatah, RI (corresponding author), Tanta Univ, Elect & Elect Commun Dept, Tanta, Egypt.
EM royat_esmaeel@f-eng.tanta.edu.eg
RI ismail, roayat/HKN-0154-2023
OI ismail, roayat/0000-0003-0283-8336
CR Amounas F., 2012, Int. J. Inform. Netw. Sec, V1, P216
   [Anonymous], 1996, J SICHUAN U NATURAL
   [Anonymous], 2011, INT J COMPUTER SCI E
   Ayoup AM, 2016, MULTIMED TOOLS APPL, V75, P17171, DOI 10.1007/s11042-015-2985-7
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bellini E, 2016, FINITE FIELDS TH APP, V39, P179, DOI 10.1016/j.ffa.2016.01.011
   Biao Wang, 2009, Science in China Series F (Information Science), V52, P602, DOI 10.1007/s11432-009-0083-z
   Boneh D, 1998, LECT NOTES COMPUT SC, V1403, P59, DOI 10.1007/BFb0054117
   Boneh D., 1999, Not. AMS, V46, P203
   Cao ZF, 2000, SCI CHINA SER E, V43, P349, DOI 10.1007/BF02916982
   CAO ZF, 1998, ADV CRYPTOLOGY CHINA, P45
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Chen TH, 2005, APPL MATH COMPUT, V169, P1070, DOI 10.1016/j.amc.2004.11.007
   Chen ZG, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2183
   Cheng B., 2010, P ARTIFICIAL NEURAL, P379
   Coppersmith D, 1997, J CRYPTOL, V10, P233, DOI 10.1007/s001459900030
   Dai ZD, 2001, ELECTRON LETT, V37, P426, DOI 10.1049/el:20010272
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dong Xiao-lei, 2006, Journal of Shanghai Jiaotong University, V40, P1174
   Dong XL, 2009, WIREL COMMUN MOB COM, V9, P217, DOI 10.1002/wcm.602
   Elkamchouchi H, 2009, IEEE SYS MAN CYBERN, P5123, DOI 10.1109/ICSMC.2009.5346018
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Essaid M, 2018, PROCEDIA COMPUT SCI, V127, P539, DOI 10.1016/j.procs.2018.01.153
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   HARN L, 1995, IEE P-COMPUT DIG T, V142, P376, DOI 10.1049/ip-cdt:19952125
   HARN L, 1994, IEE P-COMPUT DIG T, V141, P193, DOI 10.1049/ip-cdt:19941040
   HASTAD J, 1988, SIAM J COMPUT, V17, P336, DOI 10.1137/0217019
   Hsiao FH, 2017, INT J SYST SCI, V48, P3044, DOI 10.1080/00207721.2017.1364446
   Ismail E. S., 2011, ISRN Communications and Networking, DOI 10.5402/2011/231649
   Jing Qiu, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P784, DOI 10.1109/CIS.2011.178
   Kannammal A, 2012, COMM COM INF SC, V330, P349
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   KOYAMA K, 1992, LECT NOTES COMPUT SC, V576, P252
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   LEE NY, 1995, IEE P-COMPUT DIG T, V142, P370, DOI 10.1049/ip-cdt:19951994
   Li CT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071482
   Li JH, 1998, ELECTRON LETT, V34, P2401, DOI 10.1049/el:19981657
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Li YT, 2016, CHAOS SOLITON FRACT, V91, P639, DOI 10.1016/j.chaos.2016.08.014
   Li YT, 2016, NONLINEAR DYNAM, V84, P2387, DOI 10.1007/s11071-016-2652-1
   Lin Q, 2018, IEEE ACCESS, V6, P20632, DOI 10.1109/ACCESS.2018.2809426
   Madhur K., 2012, INT J ADV RES COMPUT, V2, P289
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Poulakis D., 2015, COMPUTATION CRYPTOGR, P441
   Rajput A S., 2015, ADV INTELLIGENT INFO, P277
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shao Z, 2005, INT J COMPUT MATH, V82, P1215, DOI 10.1080/00207160500154433
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   [孙琦 Sun Qi], 2005, [四川大学学报. 自然科学版, Journal of Sichuan University.Natural Science edition], V42, P471
   [孙琦 SUN Qi], 2007, [四川大学学报. 自然科学版, Journal of Sichuan University. Natural Science Edition], V44, P213
   Tawalbeh L, 2013, IET INFORM SECUR, V7, P67, DOI 10.1049/iet-ifs.2012.0147
   Verma S., 2011, INT J PURE APPL SCI, V5, P55
   Vishnoi S., 2012, International Journal of Computer Trends and Technology, V3, P653
   [王标 Wang Biao], 2005, [四川大学学报. 工程科学版, Journal of Sichuan University. Engineering Science Edition], V37, P112
   Wang XM, 2019, INFORM SCIENCES, V505, P294, DOI 10.1016/j.ins.2019.07.023
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wei, 2004, KLUWER INTERNAT ECS, V769, P107
   WIENER MJ, 1990, IEEE T INFORM THEORY, V36, P553, DOI 10.1109/18.54902
   Wu Qiu-xin, 2001, Journal of Beijing University of Posts and Telecommunications, V24, P61
   Xiao Long, 2006, Journal of Xi'an Jiaotong University, V40, P648
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang DL, 2004, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON E-COMMERCE TECHNOLOGY FOR DYNAMIC E-BUSINESS, P216
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhu Wen-yu, 2005, Acta Electronica Sinica, V33, P83
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 84
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24731
EP 24756
DI 10.1007/s11042-020-09092-1
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543064800003
DA 2024-07-18
ER

PT J
AU Naqvi, N
   Ye, ZF
AF Naqvi, Nuzhat
   Ye, ZhongFu
TI Image captions: global-local and joint signals attention model (GL-JSAM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Global and local signals; Soft and hard visual
   attention; CNN; RNN; LSTM; and Faster-RCNN
AB For automated visual captioning, existing neural encoder-decoder methods commonly use a simple sequence-to-sequence or an attention-based mechanism. The attention-based models pay attention to specific visual areas or objects; using a single heat map that indicates which portion of the image is most important rather than treating the objects (within the image) equally. These models are usually a mixture of Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) architectures. CNN's generally extract global visual signals that only provide global information of main objects, attributes, and their relationship, but fail to provide local (regional) information within objects, such as lines, corners, curve and edges. On one hand, missing some of the information and details of local visual signals may lead to misprediction, misidentification of objects or completely missing the main object(s). On the other hand, additional visual signals information produces meaningless and irrelevant description, which may be coming from objects in foreground or background. To address these concerns, we created a new joint signals attention image captioning model for global and local signals that is adaptive by nature. Primarily, proposed model extracts global visual signals at image-level and local visual signals at object-level. The joint signal attention model (JSAM) plays a dual role in visual signal extraction and non-visual signal prediction. Initially, JSAM selects meaningful global and regional visual signals to discard irrelevant visual signals and integrates selected visual signals smartly. Subsequently, in a language model, smart JSAM decides at each time-step (level) on how to attend visual or non-visual signals to generate accurate, descriptive, and elegant sentences. Lastly, we examine the efficiency and superiority of the projected model over recent similar image captioning models by conducting essential experimentations on the MS-COCO dataset.
C1 [Naqvi, Nuzhat; Ye, ZhongFu] Univ Sci & Technol China USTC, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Naqvi, N (corresponding author), Univ Sci & Technol China USTC, Hefei, Peoples R China.
EM nuzhatnaqvi@mail.ustc.edu.cn; yezf@ustc.edu.cn
FU Fundamental Research Funds for the Central Universities [WK2350000002]
FX This research is supported by the Fundamental Research Funds for the
   Central Universities (Grant no.WK2350000002). In the end, we
   collectively thanks all fellow researchers namely Asad Khan, Rashid
   Khan, M Shujah Islam, Mansoor Iqbal and, Aliya Abbasi for their
   insightful help that allowing us to improved the quality of revise
   manuscript and make it fully considerable for publication.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen H, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P606, DOI 10.1109/ITME.2018.00139
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Gupta A, 2012, LECT NOTES COMPUT SC, V7667, P196, DOI 10.1007/978-3-642-34500-5_24
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2013, ARXIV13126114
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova P., 2012, Long Papers, P359
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Long C, 2019, MULTIMED TOOLS APPL, P1
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Vanderwende L., 2004, WORKING NOTES DUC, P127
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang LQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020646
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang T., 2019, NEURAL PROCESS LETT, P1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zhou Y, 2019, ARXIV190108942
NR 36
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24429
EP 24448
DI 10.1007/s11042-020-09128-6
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542143000006
DA 2024-07-18
ER

PT J
AU Vishwakarma, A
   Bhuyan, MK
AF Vishwakarma, Amit
   Bhuyan, M. K.
TI Image mosaicking using improved auto-sorting algorithm and local
   difference-based harris features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sobel edge detector; Mosaic image; Harris corners; Local difference;
   Phase corelation; Structural similarity (SSIM)
AB Image mosaicking is an image processing technique which is useful for tiling images. Image Mosaicing stitches many correlated images to get a picture of a greater field of view. General-purpose cameras, which have a low field of view, can not create images with a higher field of view while mosaicking can help us achieve it. One important step in an image mosaicking framework is the auto-sorting algorithm, which is to be performed to minimize registration errors in the mosaic image. Another step in mosaicking is the detection of interest points for matching of the source images obtained after auto-sorting. However, in the presence of noisy and pseudo-periodic structures in the source images, the existing auto-sorting methods generally produce distortions in the final mosaic image. Secondly, most of the popular interest point detection algorithms do not specifically consider computational issues. So, this work mainly addresses the above-mentioned problems which are generally encountered during image mosaicking. The problem of image auto-sorting can be partially solved by adopting a phase correlation strategy. In our method, the sorting procedure is further improved by deploying the structural similarity index (SSIM) measure instead of using the phase correlation. The issue of high time complexity of conventional corner detectors is reduced by using our proposed local difference operation in place of standard Sobel edge detector. Experimental results show the efficacy of the proposed method.
C1 [Vishwakarma, Amit; Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Bhuyan, MK (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM a.vishwakarma@iitg.ac.in; mkb@iitg.ac.in
RI Vishwakarma, Amit/ABE-7268-2020
OI Vishwakarma, Amit/0000-0002-0591-8940
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   DAI H, 2017, 2017 12 INT C INT SY, P1, DOI DOI 10.1109/ISKE.2017.8258831
   DAWN S, 2018, 2018 5 IEEE UTT PRAD, P1, DOI DOI 10.1109/UPCON.2018.8597171
   Fu ZX, 2014, MULTIMED TOOLS APPL, V72, P503, DOI 10.1007/s11042-013-1387-y
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   GAO G, 2007, 2 INT C INN COMP INF, P471
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HUANG KY, 2017, SENSORS BASEL, V17
   JU MY, 2018, IEEE SIGNAL PROCESSI, P1
   Lama RK, 2014, MULTIMED TOOLS APPL, V73, P873, DOI 10.1007/s11042-013-1381-4
   Laraqui A, 2017, MULTIMED TOOLS APPL, V76, P8803, DOI 10.1007/s11042-016-3478-z
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Liu H, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1, DOI [10.1109/INTMAG.2017.8007847, 10.1109/ITNEC.2017.8284747]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Okumura KI, 2013, IEEE INT C INT ROBOT, P2665, DOI 10.1109/IROS.2013.6696732
   Pandey A, 2013, ANNU IEEE IND CONF
   Patil Venkat P., 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P2547, DOI 10.1109/ICECDS.2017.8389913
   Plant W, 2013, MULTIMED TOOLS APPL, V64, P695, DOI 10.1007/s11042-011-0951-6
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Shao W, 2012, CHIN CONT DECIS CONF, P3251, DOI 10.1109/CCDC.2012.6244514
   Sharma N., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P63, DOI 10.1109/DAS.2012.72
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Song R, 2008, ELECTRON LETT, V44, P798, DOI 10.1049/el:20080713
   SZELISKI R, 2004, TECHNICAL REPORT
   Vishwakarma A, 2018, MULTIMED TOOLS APPL, V77, P32013, DOI 10.1007/s11042-018-6254-4
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu YN, 2002, IEEE SIGNAL PROC LET, V9, P269, DOI 10.1109/LSP.2002.803405
   Xiong YL, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P69, DOI 10.1109/ACV.1998.732860
   Yao W, 2015, IEEE SIGNAL PROC LET, V22, P6, DOI 10.1109/LSP.2014.2345773
   Ye JS, 2019, PUBLIC HEALTH NUTR, V22, P1048, DOI [10.1017/s1368980018003129, 10.1017/S1368980018003129]
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
NR 35
TC 10
Z9 10
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23599
EP 23616
DI 10.1007/s11042-020-09124-w
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000539889900004
DA 2024-07-18
ER

PT J
AU Li, CY
   Feng, SX
   Sun, GL
AF Li Chengyan
   Feng, Shixiang
   Sun, Guanglu
TI DCE -miner: an association rule mining algorithm for multimedia based on
   the MapReduce framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Data mining; Association rule; Big data; MapReduce
AB The amount of multimedia data has grown rapidly because of improvements in data collection and storage technologies. The association rule mining (ARM) technique is a type of data mining method widely used to extract useful information from data warehouses. In real-world big data applications, fast and effective data mining algorithms are emerging as a valuable approach. In this paper, we propose DCE-Miner, a fast association rule mining algorithm with low memory requirements based on the MapReduce framework. In the precomputation phase, we split large datasets into equal-sized smaller ones using data division method. In the frequent K-itemsets mining phase, the mappers read the small datasets and distribute the data to reducers based on the closed set characteristics associated with each partition. The reducers use bitmaps to accelerate the computation speed and store the possible frequent 2-itemsets to reduce future computation. Extensive experimental results show that on large-scale datasets with up to 40 million transactions, DCE-Miner achieves better performance and is more robust with respect to dataset sizes and support level than are the current algorithms.
C1 [Li Chengyan; Feng, Shixiang; Sun, Guanglu] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
C3 Harbin University of Science & Technology
RP Sun, GL (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM hrbustlcy@163.com
FU Fundamental Research Fundation for Universities of Heilongjiang Province
   [JMRH2018XM04]; Natural Science Foundation of Heilongjiang Province of
   China [LC2018030]
FX Supported by the Fundamental Research Fundation for Universities of
   Heilongjiang Province (JMRH2018XM04) and Natural Science Foundation of
   Heilongjiang Province of China (LC2018030).
CR Agrawal R., 1994, P C VER LARG DAT BAS, P487
   [Anonymous], 2018, DISTRIB PARALLEL DAT
   [Anonymous], 2000, P 2000 ACM SIGMOD IN
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Chavan K, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P1365, DOI 10.1109/ICGCIoT.2015.7380679
   Chon KW, 2018, CLUSTER COMPUT, V1, P1
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Fournier-Viger P, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1207
   Gatuha G, 2017, TURK J ELECTR ENG CO, V25, P2096, DOI 10.3906/elk-1602-113
   Grahne G, 2005, IEEE T KNOWL DATA EN, V17, P1347, DOI 10.1109/TKDE.2005.166
   Güder M, 2018, MULTIMEDIA SYST, V24, P55, DOI 10.1007/s00530-017-0535-z
   Li H., 2008, P 2008 ACM C REC SYS
   Lin M. Y., 2012, INT C UBIQUITOUS INF, P1
   Lin X.Y., 2014, 2014 5 IEEE INT C SO
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Oswald C, 2018, J AMB INTEL HUM COMP, V9, P803, DOI 10.1007/s12652-017-0540-2
   Padillo F, 2018, INTEGR COMPUT-AID E, V25, P31, DOI 10.3233/ICA-170555
   [屈志坚 Qu Zhijian], 2013, [电力系统自动化, Automation of Electric Power Systems], V37, P93
   Rathore MM, 2018, INT J PARALLEL PROG, V46, P630, DOI 10.1007/s10766-017-0513-2
   Tang Z, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9401-y
   Tsai CF, 2010, EXPERT SYST APPL, V37, P2006, DOI 10.1016/j.eswa.2009.06.076
   Verma N, 2017, IND MANAGE DATA SYST, V117, P1503, DOI 10.1108/IMDS-09-2016-0367
   Wang L., 2014, J INFORM COMPUTATION, V11, P2809, DOI [10.12733/jics20103619, DOI 10.12733/jics20103619]
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Yan XW, 2017, SOFT COMPUT, V21, P2237, DOI 10.1007/s00500-015-1930-z
   Yang Y, 2011, WORLD WIDE WEB, V14, P133, DOI 10.1007/s11280-010-0099-8
   Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P283
   Zeng Y, 2015, SCI PROGRAMMING-NETH, V2015, DOI 10.1155/2015/910281
NR 30
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16771
EP 16793
DI 10.1007/s11042-019-08361-y
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000538712600001
DA 2024-07-18
ER

PT J
AU Ashiba, MI
   Ashiba, HI
   Tolba, MS
   El-Fishawy, AS
   Abd El-Samie, FE
AF Ashiba, M., I
   Ashiba, H., I
   Tolba, M. S.
   El-Fishawy, A. S.
   Abd El-Samie, F. E.
TI An efficient proposed framework for infrared night vision imaging system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night vision; IR images; AGC; CLAHE; HM; AWT; Homomorphic processing
ID CONTRAST ENHANCEMENT; IMAGES
AB This research presents new three proposed approaches to enhancement the visibility of the Infrared (IR) night vision images. The first proposed approach depends on Hybrid Adaptive Gamma Correction (AGC) with Histogram Matching (HGCHM). The second proposed approach stands up Merging Gamma Correction with Contrast Limited Adaptive Histogram Equalization (MGCCLAHE). The HM uses a reference visual image for converting of night vision images into daytime images. The third approach mixes the benefits of the CLAHE with the undecimated Additive Wavelet Transform (AWT) Using Homomorphic processing (CSAWUH). The quality assessments for the suggested approaches are entropy, average gradient, contrast improvement factor, Sobel edge magnitude, spectral entropy, lightness order error and the similarity of edges. Simulation results clear that the third proposed approach gives superior results to the two proposed approaches from entropy, average gradient, contrast improvement factor, Sobel edge magnitude, spectral entropy and the computation time perspectives. On the other hand, the second proposed approach takes long computation time in the implementation with respect to the two proposed approaches. The second proposed approach gives better results to the first proposed approach entropy, average gradient, contrast improvement factor, Sobel edge magnitude, and spectral entropy perspectives. The first proposed approach gives better results to the two proposed approaches from lightness order error and the similarity of edges perspectives.
C1 [Ashiba, M., I] Bilbis Higher Inst Elect Engn, Dept Comp & Syst Engn, Bilbis, Sharqia, Egypt.
   [Ashiba, H., I] Bilbis Higher Inst Elect Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
   [Tolba, M. S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Fishawy, A. S.; Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Elect Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; ashiba, huda/GQI-4310-2022
OI Sayed, Fathi/0000-0001-8749-9518; El-Fishawy, Adel/0000-0003-1567-457X;
   ashiba, huda/0000-0002-4926-8919
CR Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Dey N, 2019, OPTIK, V183, P483, DOI 10.1016/j.ijleo.2019.02.118
   Garg R., 2011, International Journal of Electronics and Comunication Technologies, V2, P107
   Gonzalez RJ, 2009, PLOS NEGLECT TROP D, V3, DOI 10.1371/journal.pntd.0000404
   Gu K, 2019, ARXIV190408632V1CSCV
   Gupta B, 2016, OPTIK, V127, P1671, DOI 10.1016/j.ijleo.2015.10.068
   Hel-Or Y, 2011, IEEE I CONF COMP VIS, P1355, DOI 10.1109/ICCV.2011.6126389
   Helakari H, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101763
   Hollnagel E, 2001, P DRIV ASS SNOWM CO
   Li S, 2018, IEEE ACCESS, V6, P57341, DOI 10.1109/ACCESS.2018.2873743
   Li YT, 2019, OPTIK, V199, DOI 10.1016/j.ijleo.2019.163300
   Liang YH, 2019, APPL SOFT COMPUT, V77, P484, DOI 10.1016/j.asoc.2019.01.024
   Miezianko R., 2005, P IEEE OTCBVS WS SER
   Nicolini C, 2020, NEUROIMAGE, V211, DOI 10.1016/j.neuroimage.2020.116603
   Parameshwaran D, 2019, J NEUROSCI METH, V325, DOI 10.1016/j.jneumeth.2019.108313
   Pratt K.W., 1991, DIGITAL IMAGE PROCES
   Qiu S, 2019, INFRARED PHYS TECHN, V98, P285, DOI 10.1016/j.infrared.2019.03.022
   RABIN J, 1994, AVIAT SPACE ENVIR MD, V65, P327
   Renukalatha S., 2016, INT J COMPUTER APPL, V141, P0975
   Rolland JP, 2000, J ELECTRON IMAGING, V9, P39, DOI 10.1117/1.482725
   유지현, 2012, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V13, P61, DOI 10.7472/jksii.2012.13.3.61
   Shome Saikat Kumar, 2011, IJCSIT, V2, P2694
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Yu T-H, 2009, MVA IAPR C MACH VIS
   Yu X, 2017, OPTIK INT J LIGHT EL, DOI [10.1016/j.ijleo.2017.05.012, DOI 10.1016/J.IJLE0.2017.05.012]
   Zhang HP, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8102003
   Zhiming W, 2006, IEEE ICSP P
   Zhou DM, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103236
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 31
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23111
EP 23146
DI 10.1007/s11042-020-09039-6
EA JUN 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382100004
DA 2024-07-18
ER

PT J
AU Bhargava, A
   Bansal, A
AF Bhargava, Anuja
   Bansal, Atul
TI Machine learning based quality evaluation of mono-colored apples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple; Defect detection; SVM; Textural features; Geometrical features;
   Statistical features
ID GOLDEN-DELICIOUS APPLES; VISION SYSTEM; DEFECTS; FEATURES; SEGMENTATION;
   BRUISES; FILTER; SHAPE
AB In the field of agriculture science, automatic visual inspection improves the commercial, quality and fertility of the country. It is very challenging to sort the fruit based on quality because of varieties of fruits available in the market. Human grades the fruit but it is inconsistent, stagnant, and expensive and influenced by the surrounding. Thus an effective system for grading of fruit is desired. In this paper, an automated fruit grading system is developed for apple to classify based on external quality. The different combination of several features are considered depending on the damages exposed on apple fruits. In this work, these features are considered as input to train Support Vector Machine (SVM). The classifier has been contemplated with two different database of apple: one having 100 color images out of which 24 are of apples with various defects and the other dataset having 112 color images out of which 56 are of apples with various defects. The system performance has been validated using k-fold cross validation technique by considering different values of k. The maximum accuracy 96.81% and 93.00% for two dataset respectively, achieved by the system is encouraging and is comparable with the state of art techniques.
C1 [Bhargava, Anuja; Bansal, Atul] GLA Univ, Dept Elect & Commun, Mathura 281406, India.
C3 GLA University
RP Bhargava, A (corresponding author), GLA Univ, Dept Elect & Commun, Mathura 281406, India.
EM anuja1012@gmail.com; atul.bansal@gla.ac.in
RI BHARGAVA, ANUJA/AAP-5094-2021; Bansal, Atul/I-1823-2019
OI BHARGAVA, ANUJA/0000-0002-2387-2552; Bansal, Atul/0000-0002-8012-0349
CR Ali MAH., 2017, INT S ROB MAN AUT
   Anderson ER, 2006, QUANT EL LAS SCI C
   Arlimatti S. R., 2012, INT J ENG RES APPL, V2, P1010
   Ashok V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P308, DOI 10.1109/IC3I.2014.7019807
   Baranowski P, 2012, J FOOD ENG, V110, P345, DOI 10.1016/j.jfoodeng.2011.12.038
   Bennedsen BS, 2007, T ASABE, V50, P2257, DOI 10.13031/2013.24078
   Bennedsen BS, 2005, COMPUT ELECTRON AGR, V48, P92, DOI 10.1016/j.compag.2005.01.003
   Bhargava A., 2018, FRUITS VEGETABLES QU, DOI [10.1016/j.jksuci.2018.06.002, 10.1016/j. jksuci.2018.06.002.]
   Bhargava A, 2020, FOOD ANAL METHOD, V13, P751, DOI 10.1007/s12161-019-01690-6
   Bhargava A, 2020, MULTIMED TOOLS APPL, V79, P7857, DOI 10.1007/s11042-019-08564-3
   Blasco J, 2003, BIOSYST ENG, V85, P415, DOI 10.1016/S1537-5110(03)00088-6
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Dubey SR, 2012, INT C COMP COMM TECH, V12012
   European Commission, 2004, Off. J. Eur. Union L, V13, P3
   Fan DP, 2018, SALIENT OBJECTS CLUT, P1
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Ghabousian A, 2012, ADV DIGITAL MULTIMED
   Gopal A, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P1, DOI 10.1109/MVIP.2012.6428746
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jawale D, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1080, DOI 10.1109/ICCSP.2017.8286542
   Kalluri SR, APPLE ORANGE BANANA
   Kavdir Ismail, 2003, Turkish Journal of Agriculture and Forestry, V27, P375
   Khade S, 2016, INT J ADV SCI ENG TE, V4, P27
   Khoje S., 2013, Int J Eng Technol, V5, P3251, DOI DOI 10.1016/J.POSTHARVBIO.2013.02.016
   Kleynen O, 2005, J FOOD ENG, V69, P41, DOI 10.1016/j.jfoodeng.2004.07.008
   Kleynen O, 2003, POSTHARVEST BIOL TEC, V30, P221, DOI 10.1016/S0925-5214(03)00112-1
   Leemans V, 2004, J FOOD ENG, V61, P83, DOI 10.1016/S0260-8774(03)00189-4
   Leemans V, 2002, BIOSYST ENG, V83, P397, DOI 10.1006/bioe.2002.0131
   Leemans V, 1999, COMPUT ELECTRON AGR, V23, P43, DOI 10.1016/S0168-1699(99)00006-X
   Leemans V, 1998, COMPUT ELECTRON AGR, V20, P117, DOI 10.1016/S0168-1699(98)00012-X
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Lv X, 2019, FUTURE GENER COMP SY, V100, P473, DOI 10.1016/j.future.2019.05.021
   Moallem Payman, 2017, Information Processing in Agriculture, V4, P33, DOI 10.1016/j.inpa.2016.10.003
   Moradi G, 2011, IR C MACH VIS IM PRO
   Ou X, 2014, INT J PHARMACEUT, V460, P28, DOI 10.1016/j.ijpharm.2013.10.024
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pereira AC, 2011, CHEMOMETR INTELL LAB, V105, P43, DOI 10.1016/j.chemolab.2010.10.009
   Radojevic RL, 2011, AFR J AGR RES, V6, P3131
   Raheja JL, 2013, OPTIK, V124, P6469, DOI 10.1016/j.ijleo.2013.05.004
   Raihana A, 2016, INT J SCI TECHNOL EN, V3, P75
   Rennick G, 1999, INT S SIGN PROC APPL, V567
   Seng WC, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P125, DOI 10.1109/ICEEI.2009.5254804
   Singh Shiksha, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P377, DOI 10.1007/978-981-13-2685-1_36
   Suresha M, 2012, INT J COMPUTER APPL, P0975
   Unay, 2005, INT C IM PROC
   Unay D, 2004, TECH REP
   Unay D, 2011, COMPUT ELECTRON AGR, V75, P204, DOI 10.1016/j.compag.2010.11.006
   Vijayarekha K., 2008, IECON 2008 - 34th Annual Conference of IEEE Industrial Electronics Society, P1499, DOI 10.1109/IECON.2008.4758175
   Wang J, 2009, IEEE INT C INF AUT
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xing J, 2005, BIOSYST ENG, V90, P27, DOI 10.1016/j.biosystemseng.2004.08.002
   Yang Q, 1995, IMAGE PROCESS ITS AP, V529
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhao JJ, 2019, PROCEEDINGS OF THE 2ND ACM SIGSOFT INTERNATIONAL WORKSHOP ON SOFTWARE QUALITIES AND THEIR DEPENDENCIES (SQUADE' 19), P1, DOI 10.1145/3340495.3342749
   Zhou J, 2012, INT CONF AUTOM CONTR
   Zhu B, 2007, GABOR FEATURE BASED
   Zou XB, 2005, IEEE SENSOR, P389
   Zou XB, 2010, COMPUT ELECTRON AGR, V70, P129, DOI 10.1016/j.compag.2009.09.014
   Zou XB, 2007, PATTERN RECOGN LETT, V28, P2046, DOI 10.1016/j.patrec.2007.06.001
NR 64
TC 14
Z9 14
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22989
EP 23006
DI 10.1007/s11042-020-09036-9
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000537402700001
DA 2024-07-18
ER

PT J
AU Rastgoo, R
   Kiani, K
   Escalera, S
AF Rastgoo, Razieh
   Kiani, Kourosh
   Escalera, Sergio
TI Video-based isolated hand sign language recognition using a deep
   cascaded model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Deep learning; Dataset; Single Shot Detector (SSD); Hand
   pose; Video
AB In this paper, we propose an efficient cascaded model for sign language recognition taking benefit from spatio-temporal hand-based information using deep learning approaches, especially Single Shot Detector (SSD), Convolutional Neural Network (CNN), and Long Short Term Memory (LSTM), from videos. Our simple yet efficient and accurate model includes two main parts: hand detection and sign recognition. Three types of spatial features, including hand features, Extra Spatial Hand Relation (ESHR) features, and Hand Pose (HP) features, have been fused in the model to feed to LSTM for temporal features extraction. We train SSD model for hand detection using some videos collected from five online sign dictionaries. Our model is evaluated on our proposed dataset (Rastgoo et al., Expert Syst Appl 150: 113336, 2020), including 10'000 sign videos for 100 Persian sign using 10 contributors in 10 different backgrounds, and isoGD dataset. Using the 5-fold cross-validation method, our model outperforms state-of-the-art alternatives in sign language recognition
C1 [Rastgoo, Razieh; Kiani, Kourosh] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Barcelona, Spain.
   [Escalera, Sergio] UAB, Comp Vis Ctr, Barcelona, Spain.
C3 Semnan University; University of Barcelona; Centre de Visio per
   Computador (CVC); Autonomous University of Barcelona
RP Kiani, K (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
EM rrastgoo@semnan.ac.ir; Kouroshliani@semnan.ac.ir; sergio@maia.ub.es
RI Escalera, Sergio/L-2998-2015; Kiani, Kourosh/T-7468-2019
OI Kiani, Kourosh/0000-0001-6582-8691; Rastgoo, Razieh/0000-0001-7963-9461
FU Spanish project (MINECO/FEDER,UE) [TIN2016-74946-P]; CERCA
   Programme/Generalitat de Catalunya, ICREA under the ICREA Academia
   programme; High Intelligent Solution (HIS) company of Iran
FX This work is partially supported by the Spanish project TIN2016-74946-P
   (MINECO/FEDER,UE), CERCA Programme/Generalitat de Catalunya, ICREA under
   the ICREA Academia programme, and High Intelligent Solution (HIS)
   company of Iran. We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the Titan XP GPU used for this
   research. Also, we would like to thank two deaf centers of Iran (Semnan
   and Tehran) and the Computer Vision Center (CVC) of Spain for their
   collaborations.
CR [Anonymous], 2017, Hand keypoint detection in single images using multiview bootstrapping
   CHEN C, 2017, MULTIMEDIA TOOLS APP
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   DUAN J, 2016, MULTIMODALITY FUSION
   ELKHATTABI Z, 2015, INT J COMPUT INF SCI, V4, P9
   FORSTER, 2012, WTH PHOENIX V1 GERMA
   GE L, 2018, IEEE T IMAGE PROCESS
   Goodwyn SW, 2000, J NONVERBAL BEHAV, V24, P81, DOI 10.1023/A:1006653828895
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   JAMESON L, 2004, AM SIGN LANGUAGE
   KANG B, 2015, 3 IAPR AS C PATT REC
   Kapuscinski T, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60091
   Kim S, 2017, J SENSORS, V2017, DOI 10.1155/2017/6747921
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   LE TH, 2018, 7 IEEE INT S NEXT GE
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma BP, 2013, IEEE INT CONF AUTOMA
   MIAO Q, 2017, P IEEE C COMP VIS PA
   MILLER J, 2019, SIGNING SAVVY
   Narayana P, 2018, PROC CVPR IEEE, P5235, DOI 10.1109/CVPR.2018.00549
   Neverova N, 2015, LECT NOTES COMPUT SC, V9005, P687, DOI 10.1007/978-3-319-16811-1_45
   ONG WJ, 2012, CVPR
   OSZUST M, 2013, 6 INT C HUM SYST INT
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   RONCHETTI F, 2016, JCS T
   Ronchetti F., 2016, P 22 C ARG CIENC COM
   SCOGIN J, 2008, TEXAS MATH SIGN LANG
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   THANGALI A, 2011, CVPR
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   WILLIAM V, 2013, AM SIGN LANGUAGE
   Yan S., 2017, APPL COMPUT INTELL S, V2017, DOI DOI 10.1155/2017/9830641
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11205, P242, DOI 10.1007/978-3-030-01246-5_15
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 39
TC 37
Z9 37
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22965
EP 22987
DI 10.1007/s11042-020-09048-5
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000537401900001
DA 2024-07-18
ER

PT J
AU Cai, GX
   Guo, YH
   Chen, WG
   Zeng, H
   Zhou, YP
   Lu, Y
AF Cai, Guanxiong
   Guo, Yanhui
   Chen, Weiguo
   Zeng, Hui
   Zhou, Yuanpin
   Lu, Yao
TI Computer-aided detection and diagnosis of microcalcification clusters on
   full field digital mammograms based on deep learning method using
   neutrosophic boosting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Full-field digital mammogram (FFDM); Microcalcification (MC); Deep
   convolution neural network (DCNN)
ID SEGMENTATION; SELECTION
AB Computer-aided detection (CADe) and diagnosis (CADx) system of mammographic microcalcification clusters (MCCs) is built for helping human observers to find suspicious areas of MCC and providing risk predictions of malignancy as a reference, since it is challenging and time consuming for radiologists to manually identify some subtle microcalcifications (MCs) and perform precise interpretation in mammograms. However, the performance of traditional CADe and CADx systems is not good enough, thus it is difficult to combine them into a whole system that integrates detection and diagnosis together. The purpose of this study is to develop a fully automatic computer-aided MCC detection and diagnosis system based on deep learning method. In order to detect subtle MCs accurately, a MC candidate detection system is used to obtain a great number of potential MC candidates, then a deep convolution neural network (DCNN) is trained specially to discriminate true MCs from detected MC candidates. Different from previous literatures committing to finding and selecting effective features, the proposed method replaces manual feature extraction step by using DCNN. To accelerate the training procedure of the DCNN, a neutrosophic boosting (NB) strategy is applied in the training stage. Then a density-based regional clustering method is imposed on those true MCs to form MCCs. Finally, another DCNN is employed to differentiate benign from malignant MCC lesions. For cluster-based MCC detection evaluation, a sensitivity of 90% is achieved at 0.14 false positives (FPs) per image. For case-based MCC classification evaluation, the area under the receiver operating characteristic curves (AUCs) on validation and testing sets are 0.945, 0.933 for proposed system, respectively. Our obtained results demonstrated the effectiveness of the proposed method for automated detection and classification of MCCs.
C1 [Cai, Guanxiong; Zhou, Yuanpin; Lu, Yao] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.
   [Guo, Yanhui] Univ Illinois, Dept Comp Sci, Springfield, IL USA.
   [Chen, Weiguo; Zeng, Hui] Nanfang Hosp, Dept Diagnost Radiol, Guangzhou, Peoples R China.
   [Cai, Guanxiong; Zhou, Yuanpin; Lu, Yao] Sun Yat Sen Univ, Computat Med Imaging Lab, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University; University of Illinois System; University of
   Illinois Springfield; Southern Medical University - China; Sun Yat Sen
   University
RP Lu, Y (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.; Lu, Y (corresponding author), Sun Yat Sen Univ, Computat Med Imaging Lab, Guangzhou, Guangdong, Peoples R China.
EM luyao23@mail.sysu.edu.cn
RI Zhou, Yuanpin/IVV-4778-2023
OI Zhou, Yuanpin/0000-0002-6297-9600
CR [Anonymous], BREAST IMAGING ATLAS
   Bankman I N, 1997, IEEE Trans Inf Technol Biomed, V1, P141, DOI 10.1109/4233.640656
   Bazzani A, 2001, PHYS MED BIOL, V46, P1651, DOI 10.1088/0031-9155/46/6/305
   Bengio Yoshua, 2012, P ICML WORKSH UNS TR, P17
   BUJA A., 2005, Working draft
   CHAN HP, 1987, MED PHYS, V14, P538, DOI 10.1118/1.596065
   CHAN HP, 1995, MED PHYS, V22, P1555, DOI 10.1118/1.597428
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Cheng HD, 2003, PATTERN RECOGN, V36, P2967, DOI 10.1016/S0031-3203(03)00192-4
   DENGLER J, 1993, IEEE T MED IMAGING, V12, P634, DOI 10.1109/42.251111
   Foggia P, 2001, INT WORKSH MULT CLAS, P208
   Ge J, 2006, MED PHYS, V33, P2975, DOI 10.1118/1.2211710
   Guo YH, 2015, PATTERN RECOGN, V48, P2710, DOI 10.1016/j.patcog.2015.02.018
   Guo YH, 2014, MEASUREMENT, V58, P175, DOI 10.1016/j.measurement.2014.08.039
   Gurcan MN, 2002, PROC SPIE, V4684, P1325, DOI 10.1117/12.467095
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Joseph JYL, 2003, PROC SPIE, V5032, P882, DOI 10.1117/12.480869
   Kallergi M, 2004, MED PHYS, V31, P314, DOI 10.1118/1.1637972
   Kriegel H.-P., 1996, KNOWLEDGE DISCOVERY, P226, DOI DOI 10.5555/3001460
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lashari SA, 2014, 2014 4th World Congress on Information and Communication Technologies (WICT), P353, DOI 10.1109/WICT.2014.7077293
   Lindgren A, 2003, ACM INT S MOB AD HOC
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944
   NISHIKAWA RM, 1995, MED BIOL ENG COMPUT, V33, P174, DOI 10.1007/BF02523037
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sahli IS, 2015, INT CONF IMAG PROC, P180, DOI 10.1109/IPTA.2015.7367122
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strickland RN, 1997, IEEE T IMAGE PROCESS, V6, P724, DOI 10.1109/83.568929
   Strickland RN, 1996, IEEE T MED IMAGING, V15, P218, DOI 10.1109/42.491423
   Svozil D, 1997, CHEMOMETR INTELL LAB, V39, P43, DOI 10.1016/S0169-7439(97)00061-0
   Valvano G, 2018, IFMBE PROC, V65, P438, DOI 10.1007/978-981-10-5122-7_110
   Wang JW, 2016, SCI REP-UK, V6, DOI [10.1038/srep24660, 10.1038/srep19883]
   YOSHIDA H, 1994, P SOC PHOTO-OPT INS, V2167, P868, DOI 10.1117/12.175126
   ZHANG W, 1994, MED PHYS, V21, P517, DOI 10.1118/1.597177
NR 40
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17147
EP 17167
DI 10.1007/s11042-019-7726-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600075
DA 2024-07-18
ER

PT J
AU Gersak, G
   Lu, HM
   Guna, J
AF Gersak, Gregor
   Lu, Huimin
   Guna, Joze
TI Effect of VR technology matureness on VR sickness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; VR sickness; SSQ; Physiology; Psychophysiology
AB In this paper relationship of perceived virtual reality (VR) sickness phenomenon with different generations of virtual reality head mounted displays (VR HMD) is presented. Action content type omnidirectional video clip was watched by means of four HMDs of different levels of technological matureness, with a 2D monitor used as a reference point. In addition to subjective estimation of VR sickness effects by means of the SSQ questionnaire, psychophysiology of the participants was monitored. Participant's electrodermal activity, heart rate, skin temperature and respiration rate were measured. Results of the study indicate differences between HMDs in both SSQ score and changes of physiology. Skin conductance was found to be significantly correlated with VR sickness. Mobile HMD did not induce significantly higher levels of VR sickness. Disorientation SSQ was proven to be a useful tool for assessing the VR sickness effects.
C1 [Gersak, Gregor; Guna, Joze] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
   [Lu, Huimin] Kyushu Inst Technol, Tobata Ku, 1-1 Sensui Cho, Kitakyushu, Fukuoka, Japan.
C3 University of Ljubljana; Kyushu Institute of Technology
RP Guna, J (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
EM gregor.gersak@fe.uni-lj.si; dr.huimin.lu@ieee.org;
   joze.guna@fe.uni-lj.si
RI Guna, Jože/AAO-8714-2020
OI Guna, Jože/0000-0002-5161-7751
CR [Anonymous], 2017, P IEEE INT C QUAL MU
   [Anonymous], 2006, P 8 C HUMAN COMPUTER, DOI [10.1145/1152215.1152263, DOI 10.1145/1152215.1152263]
   [Anonymous], 2017, VIRTUAL REALITY VR, DOI DOI 10.1109/VR.2017.7892230
   [Anonymous], 2017, 2017 9 INT C QUAL MU, DOI [10.1109/QoMEX.2017.7965679, DOI 10.1109/QOMEX.2017.7965679]
   [Anonymous], 2005, Introduction to and review of simulator sickness research
   [Anonymous], 2016, IEEE, DOI DOI 10.1109/QOMEX.2016.7498964
   [Anonymous], 2015, ACM International Conference Proceeding Series, DOI DOI 10.1145/2735711.2735785
   Anthes C, 2016, IEEE AEROSPACE C IEE
   Bojko A., 2013, EYE TRACKING USER EX
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Castelvecchi D, 2016, GARTNERS 2016 HYPE C
   Castelvecchi D, 2016, NATURE, V533, P153, DOI 10.1038/533153a
   Chen M, 2018, IEEE J SEL AREA COMM, V36, P587, DOI 10.1109/JSAC.2018.2815360
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Chirico A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01242-0
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis S, 2015, P 11 AUS C INT ENT I, V27, P2015
   Earnshaw RA, 2017, OCULUS RIFT CV1
   Earnshaw RA, 2017, GOOGLE VR
   Earnshaw RA, 2017, SONY PSVR
   Earnshaw RA, 2017, SAMSUNG GALAXY GEARV
   Earnshaw RA, 2017, HTC VIVE
   Earnshaw RaeA., 2014, VIRTUAL REALITY SYST
   Frelih NG, 2017, MEASUREMENT, V98, P186, DOI 10.1016/j.measurement.2016.11.039
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Ishihara Shinobu., 1960, TESTS COLOUR BLINDNE, V15th
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kren M, 2017, IEEE T IND INFORM, V13, P2077, DOI 10.1109/TII.2017.2695371
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Macedonio MF, 2007, CYBERPSYCHOL BEHAV, V10, P508, DOI 10.1089/cpb.2007.9997
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Ogorevc J, 2013, MEASUREMENT, V46, P2993, DOI 10.1016/j.measurement.2013.06.024
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rosa PJ, 2016, CYBERPSYCH BEH SOC N, V19, P209, DOI 10.1089/cyber.2015.0130
   Settgast V, 2016, LECT NOTES COMPUTER, V9926
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Steinicke F, 2014, P 2 ACM S SPAT US IN, P66, DOI DOI 10.1145/2659766.2659767
   Tong X, 2016, MMVR
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Webb CM, 2009, AVIAT SPACE ENVIR MD, V80, P541, DOI 10.3357/ASEM.2454.2009
NR 48
TC 26
Z9 31
U1 22
U2 124
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14491
EP 14507
DI 10.1007/s11042-018-6969-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900010
DA 2024-07-18
ER

PT J
AU Khan, G
   Ghani, MU
   Siddiqi, A
   Zahoor-ur-Rehman
   Seo, S
   Baik, SW
   Mehmood, I
AF Khan, Gulraiz
   Ghani, Muhammad Usman
   Siddiqi, Aiman
   Zahoor-ur-Rehman
   Seo, Sanghyun
   Baik, Sung Wook
   Mehmood, Irfan
TI Egocentric visual scene description based on human-object interaction
   and deep spatial relations among objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene description; Classification; Surveillance; Human-object
   interaction; Spatial relations; Deep neural network
AB Visual Scene interpretation is one of the major areas of research in the recent past. Recognition of human object interaction is a fundamental step towards understanding visual scenes. Videos can be described via a variety of human-object interaction scenarios such as when both human and object are static (static-static), one is static while other is dynamic (static-dynamic) and both are dynamic (dynamic-dynamic). This paper presents a unified framework for the explanation of these interactions between humans and a variety of objects using deep learning as a pivot methodology. Human-object interaction is extracted through native machine learning techniques, while spatial relations are captured by training a model through convolution neural network. We also address the recognition of human posture in detail to provide egocentric visual description. After extracting visual features, sequential minimal optimization is employed for training our model. Extracted inter-action, spatial relations and posture information are fed into natural language generation module along with interacting object label to generate scene understanding. Evaluation of the proposed framework is done for two state of the art datasets i.e., MSCOCO and MSR3D Daily activity dataset; where achieved results are 78 and 91.16% accurate, respectively.
C1 [Khan, Gulraiz; Ghani, Muhammad Usman; Siddiqi, Aiman] Al Khwarizmi Inst Comp Sci UET, Lahore, Pakistan.
   [Ghani, Muhammad Usman] Univ Engn & Technol Lahore, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Zahoor-ur-Rehman] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock, Pakistan.
   [Seo, Sanghyun] Sungkyul Univ, Dept Media Software, Anyang Si, South Korea.
   [Baik, Sung Wook; Mehmood, Irfan] Sejong Univ, Dept Software, Seoul, South Korea.
C3 University of Engineering & Technology Lahore; COMSATS University
   Islamabad (CUI); Sungkyul University; Sejong University
RP Mehmood, I (corresponding author), Sejong Univ, Dept Software, Seoul, South Korea.
EM irfanmehmood@ieee.org
RI rehman, zahoor/AAE-2164-2021; Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
CR [Anonymous], IEEE ACCESS
   [Anonymous], 2014, PROC COMPUT VIS PATT
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2012, COMP VIS PATT REC WO
   [Anonymous], 2011, ICCV
   Aydemir A, 2011, ROBOTICS AUTOMATION
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Jain P, 2015, COMP COMM CONTR IC4
   Karpathy A., 2015, P IEEE C COMP VIS PA
   Li W., 2010, IEEE CVPR WORKSH HUM
   Muhammad K, 2018, IEEE T IND INFO
   Redmon J., 2016, 2016 IEEE Conf. Comp. Vis. Patt. Recog. (CVPR), P779
   Sjöö K, 2012, ROBOT AUTON SYST, V60, P1093, DOI 10.1016/j.robot.2012.06.001
   Sung J, 2012, P INT C ROB AUT
   Welke K, 2013, HUM ROB HUM 2013 13
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
NR 21
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15859
EP 15880
DI 10.1007/s11042-018-6286-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600005
DA 2024-07-18
ER

PT J
AU Perumal, TSR
   Dhanasekaran, R
AF Perumal, T. Sudarson Rama
   Dhanasekaran, R.
TI RETRACTED: Early diagnosis of Glaucoma in retinal images using multi
   structure descriptor and hybrid neural network classifiers (Retracted
   article. See MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Glaucoma; Textons; Segmentation; Retinal images; SVM; Classification;
   Texture
ID BRAIN-TUMOR; SEVERITY ANALYSIS; LEVEL; CLASSIFICATION; SEGMENTATION;
   COLOR
AB Medical imaging is extensively being used to automatically detect and diagnose various diseases. Medical imaging provides a way to diagnose the diseases in their very early stages by classifying the diseases into their different stages. Diabetes mellitus is an ailment around the world, which can cause genuine outcomes. The assessed predominance of diabetes for all age bunches worldwide was 2.8% in 2000 and is required to be 4.4% in 2030. Glaucoma is an optic neuropathy defined by characteristic damage to the optic nerve and accompanying visual field deficits. This paper proposes an image highlight portrayal strategy, in particular Multi Structure Descriptor (MSD), it uses all together change of pixels to represent the neighborhood spatial structure data for image include extraction. The component assurance step is joined into the framework to diminish the figuring multifaceted nature. A high request precision of 95.8% is cultivated using hybrid neural framework based classifiers. A glaucoma integrative record (GRI) is moreover intended to procure a trustworthy and effective system. The exploratory results are affirmed using the K-cover cross endorsement strategy. The overall classification accuracy of MSD with HNN is 93.45%, MSD with FSVM is 90.12%, MSD with SVM is 84.11 and MSD with RBF is 77.23%.
C1 [Perumal, T. Sudarson Rama] CAPE Inst Technol, Dept CSE, Tirunelveli, Tamil Nadu, India.
   [Dhanasekaran, R.] Syed Ammal Engn Coll, Ramanathapuram, Tamil Nadu, India.
C3 Syed Ammal Engineering College
RP Dhanasekaran, R (corresponding author), Syed Ammal Engn Coll, Ramanathapuram, Tamil Nadu, India.
EM sudarson.srp@Gmail.com; rdhanashekar@yahoo.com
OI , Dr .R. Dhanasekaran/0000-0003-2648-8414
CR BAUDOIN CE, 1984, REV EPIDEMIOL SANTE, V32, P254
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P599
   Hariharan G, 2017, J COMPUT THEOR NANOS, V14, P3609, DOI [10.1166/jctn.2017.6865, DOI 10.1166/jctn.2017.6865]
   Jayachandran A, 2017, IRAN J FUZZY SYST, V14, P41
   Jayachandran A, 2015, INT J FUZZY SYST, V17, P434, DOI 10.1007/s40815-015-0064-x
   Jayachandran A, 2014, ARAB J SCI ENG, V39, P7073, DOI 10.1007/s13369-014-1334-x
   Jayachandran A, 2013, J IMAGING SCI TECHN, V57, DOI 10.2352/J.ImagingSci.Technol.2013.57.1.010507
   JAYACHANDRAN A, 2013, RES J APPL SCI ENG T, V6, P2264
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Juuti-Uusitalo K, 2013, INVEST OPHTH VIS SCI, V54, P3510, DOI 10.1167/iovs.13-11800
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Kolár R, 2008, RADIOENGINEERING, V17, P109
   Kramer G, 2016, COLOR RES APPL, V41, P457, DOI 10.1002/col.21979
   Kumar T., 2010, Int J Comput Appl, V7, P7, DOI DOI 10.5120/1140-1493
   Kurnar M, 2017, BIOMED SIGNAL PROCES, V31, P301, DOI 10.1016/j.bspc.2016.08.018
   Larose Daniel T., 2014, Discovering Knowledge in Data: An Introduction to Data Mining, P149, DOI [10.1002/9781118874059.ch7, DOI 10.1002/9781118874059.CH7, 10.1002/9781118874059.CH7, DOI 10.1002/0471687545.CH5]
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Mahiba C, 2019, MEASUREMENT, V135, P762, DOI 10.1016/j.measurement.2018.12.032
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Nosaka R, 2014, PATTERN RECOGN, V47, P2428, DOI 10.1016/j.patcog.2013.09.018
   Prabhu LAJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1094-3
   Wang XY, 2013, COMPUT ELECTR ENG, V39, P746, DOI 10.1016/j.compeleceng.2013.01.005
   Zhu W, 2010, P SAS C BALT MAR, V9
NR 26
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16915
EP 16925
DI 10.1007/s11042-019-7428-4
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600060
DA 2024-07-18
ER

PT J
AU Sun, XY
   Zhang, KD
   Ji, YF
   Wang, SH
   Yan, SQ
   Wu, SY
AF Sun, Xiyan
   Zhang, Kaidi
   Ji, Yuanfa
   Wang, Shouhua
   Yan, Suqing
   Wu, Sunyong
TI Correlation filter tracking algorithm based on multiple features and
   average peak correlation energy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation filter; Target tracking; Deep features; Average peak
   correlation energy
AB Since traditional target tracking algorithms employ artificial features, they are not robust enough to describe the appearance of a target. Therefore, it is difficult to apply them to complex scenes. Moreover, the traditional target tracking algorithms do not measure the confidence level of the response. When the confidence level is low, the appearance model of the target is easily disturbed, and the tracking performance is degraded. This paper proposes the Multiple Features and Average Peak Correlation Energy (MFAPCE) tracking algorithm. The MFAPCE tracking algorithm combines deep features with color features and uses average peak correlation energy to measure confidence level. The algorithm uses multiple convolution layers and color histogram features to describe the target appearance. The response is obtained by optimizing the context information using a correlation filter framework. The average peak correlation energy is used to determine the final confidence level of the response and thus determines whether to update the model. The experiments showed that the MFAPCE algorithm improves the tracking performance compared with traditional tracking algorithms.
C1 [Sun, Xiyan; Zhang, Kaidi; Ji, Yuanfa; Wang, Shouhua; Yan, Suqing; Wu, Sunyong] Guilin Univ Elect Technol, Guangxi Key Lab Precis Nav Technol & Applicat, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology
RP Ji, YF (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Precis Nav Technol & Applicat, Guilin 541004, Peoples R China.
EM 920849560@qq.com; jiyuanfa@163.com
RI xiao, wei/KCK-6954-2024
OI zhang, kaidi/0000-0002-1640-9068; sun, xiyan/0000-0002-4227-2499
CR [Anonymous], 2014, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-10599-4_13
   [Anonymous], 2017, 2017 IEEE C COMP VIS
   [Anonymous], 2017, 2017 IEEE C COMP VIS
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, 2016 IEEE C COMP VIS
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2016, 2016 IEEE C COMP VIS
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Felsberg M, 2014, 2014 IEEE C COMP VIS, P1090
   Galoogahi HK, 2015, 2015 IEEE C COMP VIS
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim N, 2010, 25TH WORLD BATTERY, HYBRID AND FUEL CELL ELECTRIC VEHICLE SYMPOSIUM AND EXHIBITION PROCEEDINGS, VOLS 1 & 2, P1016
   Lan RS, 2017, IEEE J BIOMED HEALTH, V21, P1338, DOI 10.1109/JBHI.2016.2623840
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lukezic Alan, 2017, 2017 IEEE C COMP VIS
   Ma C, 2015, INT CONF MACH LEARN, P151, DOI 10.1109/ICMLC.2015.7340914
   Min S, 2016, INT CONF UBIQ ROBOT, P163, DOI 10.1109/URAI.2016.7625728
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Possegger TM, 2015, 2015 IEEE C COMP VIS
   Qi Y, 2016, 2016 IEEE C COMP VIS
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sakai Y, 2019, FUTURE GENER COMP SY, V92, P157, DOI 10.1016/j.future.2018.09.068
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song S, 2013, 2013 IEEE INT C COMP
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wu Y., 2013, 2013 IEEE C COMP VIS
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Zhong W, 2012, 2012 IEEE C COMP VIS
NR 44
TC 1
Z9 1
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14671
EP 14688
DI 10.1007/s11042-019-7216-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900020
DA 2024-07-18
ER

PT J
AU Wang, YC
   Chen, ZX
   Wu, QMJ
   Rong, XW
AF Wang, Yanchun
   Chen, Zhenxue
   Wu, Q. M. Jonathan
   Rong, Xuewen
TI Deep mutual learning network for gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Incomplete cycles; Deep mutual learning; Triplet loss
ID VIEW TRANSFORMATION MODEL
AB Human identification plays a significant role in ensuring social security. However, face-based and appearance-based retrieval methods are not effective in monitoring due to the long distance and low camera resolution. Compared with other biological characteristics, the gait of humans has a strong discriminating ability even at long distance and low resolution. In this paper, the deep mutual learning strategy is applied to gait recognition, and by training collaboratively with other networks, the generalization ability of the network is improved simply and effectively. We use a set of independent frames of gait as input to two convolutional neural networks. This method is unaffected by frame alignment and can naturally integrate video frames of different walking conditions (e.g. different viewing angles, different clothing/carrying conditions). At the same time, the set can extract gait features from incomplete gait cycles due to occlusion. A mutual learning strategy can improve the running speed appropriately and realize the compactness and accuracy of the model. Two convolutional networks learn simultaneously and solve problems together. To evaluate the method's performance, we compare it to several methods on the CASIA and OU-ISIR gait databases, and construct different sets of gaits with incomplete periods to compare the accuracy of identification with them and the complete gait set. Experimental results show that the method is effective.
C1 [Wang, Yanchun; Chen, Zhenxue; Rong, Xuewen] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 Shandong University; University of Windsor
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM 201714402@mail.sdu.edu.cn; chenzhenxue@sdu.edu.cn; wu@uwindsor.ca;
   rongxw@sdu.edu.cn
RI Wang, Yu/GZL-9655-2022; Wang, Yin/HCI-9352-2022; Wang,
   yanru/JAX-5241-2023; Wang, Yiru/JMB-2281-2023; YAN, LING/JXY-6904-2024;
   Wu, Yiping/JJF-6185-2023; wang, yiran/IAP-0414-2023; wang,
   yi/GVT-8516-2022; chen, qiang/JXY-6982-2024; wang, yi/KBB-3614-2024;
   Wang, Yixuan/GZK-6559-2022; wang, ya/HQZ-7558-2023; Wang,
   Yijun/GXW-1763-2022; luo, yuan/JLS-6416-2023; wang, yi/HOF-6668-2023;
   wang, yixuan/GXW-2866-2022
OI Wu, Yiping/0009-0000-6223-5786; Wu, Q.M. Jonathan/0000-0002-5208-7975;
   Chen, Zhenxue/0000-0001-9637-5170
FU National Key RAMP;D Program of China [2018YFB1307403, 2019YFB1311001];
   National Natural Science Foundation of China [61876099]; Scientific and
   Technological Development Project of Shandong Province [2019GSF111002]
FX This work was supported in part by the National Key R&D Program of China
   (2018YFB1307403 and 2019YFB1311001), in part by the National Natural
   Science Foundation of China (61876099), in part by the Scientific and
   Technological Development Project of Shandong Province (2019GSF111002).
   We are very grateful to the CASIA-B Database from Institute of
   Automation, Chinese Academy of Sciences and the OU-ISIR Gait Database
   from Institute of Scientific and Industrial Research (ISIR), Osaka
   University (OU).
CR [Anonymous], 2017, CoRR
   Ba LJ, 2014, ADV NEUR IN, V27
   Ben X, 2019, IEEE T CIRCUITS SYST, P1
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Connie T, 2018, MULTIMEDIA TOOLS APP
   Dohl J, 2011, IEEE ICC
   Fu Yang, 2018, ABS180405275 CORR
   GENG Q, 2019, PROC IEEE INT C COMM, P1
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton G., 2015, COMPUT SCI, P1, DOI [DOI 10.48550/ARXIV.1503.02531, 10.48550/arXiv.1503.02531]
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Kusakunniran W, 2010, COMPUTER VISION PATT
   Kusakunniran W, 2010, MULTIPLE VIEWS GAIT
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2014, IMAGE PROCESSING IEE, V24
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Souri Yaser, 2019, ARXIV190403116
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wolf Thomas, 2016, IEEE INT C IM PROC
   Wu D., 2018, CoRR
   Wu H, 2018, J VIS COMMUN IMAGE R
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Yu S, 2006, INT C PATT REC
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 38
TC 5
Z9 6
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22653
EP 22672
DI 10.1007/s11042-020-09003-4
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500006
DA 2024-07-18
ER

PT J
AU Medjram, S
   Brethe, JF
   Benali, K
AF Medjram, Sofiane
   Brethe, Jean-Francois
   Benali, Khairidine
TI Markerless Vision-Based One Cardboard Box Grasping using Dual Arm Robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Cardboard box; Projective transformation; Dual arm
   robot; RGB-D camera
AB Nowadays, robots are indispensable in industry, especially logistics industry, to replace human employees performing heavy lifting tasks. Introducing robots prevents musculoskeletal disorders that are common in ageing workforce. We designed and implemented a dual arm robot to grasp cardboard boxes of different dimensions using a hydrid force/position control. In a first step, the position of the cardboard was estimated using markers and ARtags, and an integrated camera. However this solution showed some limitation, because it is not possible to place ARtag on every cardboard of a logistic warehouse. In this paper, we propose a new method to estimate one cardboard box position based on vision without the need of markers at all. Our method explores the advantages of the RGBD integrated camera through the use of strong features and perspective geometry. Our method is very adequate to the case of one cardboard box due to the simplicity of its geometric shape. The experiments show that our method is fast, robust and precise, and of course is better suited to the logistics warehouse environment than the marker estimation procedure for palletization applications.
C1 [Medjram, Sofiane; Brethe, Jean-Francois; Benali, Khairidine] La Havre Univ, Le Havre, France.
   [Medjram, Sofiane; Brethe, Jean-Francois; Benali, Khairidine] Elect & Automat Reasearch Grp GREAH, Rue Bellot, F-76058 Le Havre, France.
C3 Universite Le Havre Normandie; Universite Le Havre Normandie
RP Medjram, S (corresponding author), La Havre Univ, Le Havre, France.; Medjram, S (corresponding author), Elect & Automat Reasearch Grp GREAH, Rue Bellot, F-76058 Le Havre, France.
EM medjram.sofiane@gmail.com; jean-francois.brethe@univ-lehavre.fr;
   khairidine.benali@univ-lehavre.fr
CR [Anonymous], 2013, CVPR
   Benali K, 2018, IEEE INT CONF INDUST, P147, DOI 10.1109/ICIT.2018.8352167
   Benchmarks L, 2019, RETHINKING RGB D SAL, VX, P1
   Bergamasco F, 2016, IEEE T PATTERN ANAL, V38, P2359, DOI 10.1109/TPAMI.2016.2519024
   Bouwmans T, BACKGROUND MODELING
   Degol J, 2017, IEEE I CONF COMP VIS, P1481, DOI 10.1109/ICCV.2017.164
   Ghazaei G, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa6802
   GREAH, 2019, XTERM PROJ 2019
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Khan MS, 2009, ENVIRON CHEM LETT, V7, P1, DOI 10.1007/s10311-008-0155-0
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Medjram S, 2018, MULTIMED TOOLS APPL, V77, P13821, DOI 10.1007/s11042-017-4995-0
   Medjram S, 2017, MULTIMED TOOLS APPL, V76, P15297, DOI 10.1007/s11042-016-3820-5
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Redmon J, 2015, REAL TIME OBJECT DET, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saxena V.K., 2018, APPL GENETICS GENOMI, P19
   Schwarz M, 2018, IEEE INT CONF ROBOT, P3347
   Shrivastava A., 2016, Beyond skip connections: Top-down modulation for object detection
   Sigari M. H., 2008, INT MULT ENG COMP SC, P19
   Smith C, 2012, ROBOT AUTON SYST, V60, P1340, DOI 10.1016/j.robot.2012.07.005
   Sun L, 2016, ROBOT VISION ARCHITE, V14, P1
   Wang J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4193, DOI 10.1109/IROS.2016.7759617
   Zhao J, CONTRAST PRIOR FLUID, P3927
NR 29
TC 5
Z9 7
U1 6
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22617
EP 22633
DI 10.1007/s11042-020-08996-2
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000553994700002
DA 2024-07-18
ER

PT J
AU Yu, J
   Wu, XJ
AF Yu, Jun
   Wu, Xiao-Jun
TI Cross-modal subspace learning via kernel correlation maximization and
   discriminative structure-preserving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Subspace learning; Kernel correlation;
   Discriminative; HSIC
ID INFORMATION
AB How to measure the distance between heterogeneous data is still an open problem. Many research works have been developed to learn a common subspace where the similarity between different modalities can be calculated directly. However, most of existing works focus on learning a latent subspace but the semantically structural information is not well preserved. Thus, these approaches cannot get desired results. In this paper, we propose a novel framework, termed Cross-modal subspace learning via Kernel correlation maximization and Discriminative structure-preserving (CKD), to solve this problem in two aspects. Firstly, we construct a shared semantic graph to make each modality data preserve the neighbor relationship semantically. Secondly, we introduce the Hilbert-Schmidt Independence Criteria (HSIC) to ensure the consistency between feature-similarity and semantic-similarity of samples. Our model not only considers the inter-modality correlation by maximizing the kernel correlation but also preserves the semantically structural information within each modality. The extensive experiments are performed to evaluate the proposed framework on the three public datasets. The experimental results demonstrate that the proposed CKD is competitive compared with the classic subspace learning methods.
C1 [Yu, Jun; Wu, Xiao-Jun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Yu, Jun; Wu, Xiao-Jun] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Wu, XJ (corresponding author), Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
EM wu_xiaojun@jiangnan.edu.cn
OI Wu, Xiao-Jun/0000-0002-0310-5778
FU national natural science foundation of china [61672265, u1836218]; 111
   project of ministry of education of china [b12018]
FX The paper is supported by the national natural science foundation of
   china(grant no.61672265,u1836218), and the 111 project of ministry of
   education of china (grant no. b12018).
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2012, INT J COMPUT VIS
   [Anonymous], 2011, P ICML
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2012 IEEE C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INT C MACH LEARN WOR
   [Anonymous], P INT M PSYCHOMETRIC
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2018, IEEE T PATTERN ANAL
   Ciocca G, 2003, J ELECTRON IMAGING, V12, P161, DOI 10.1117/1.1526844
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Davis J. V., 2007, ICML, P209
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Jiang SQ, 2014, MULTIMEDIA SYST, V20, P645, DOI 10.1007/s00530-012-0299-4
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Peng Yuxin, 2016, IJCAI, P3846
   Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia Nikhil., 2010, P ACM INT C MULTIMED, P251
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Song GL, 2017, IEEE T IMAGE PROCESS, V26, P4168, DOI 10.1109/TIP.2017.2713045
   Song TC, 2017, PATTERN RECOGN, V68, P99, DOI 10.1016/j.patcog.2017.03.004
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang D, 2018, IEEE SYST J, V12, P916, DOI 10.1109/JSYST.2016.2585681
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xu MX, 2018, NEUROCOMPUTING, V309, P94, DOI 10.1016/j.neucom.2018.04.073
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yu J, 2019, IMAGE VISION COMPUT, V89, P50, DOI 10.1016/j.imavis.2019.06.004
   Yu J, 2018, INT C PATT RECOG, P958, DOI 10.1109/ICPR.2018.8546254
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182
NR 44
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34647
EP 34663
DI 10.1007/s11042-020-08989-1
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000533058700004
DA 2024-07-18
ER

PT J
AU Lu, Z
   Huang, GH
   Pun, CM
   Cheng, LL
AF Lu, Zeng
   Huang, Guoheng
   Pun, Chi-Man
   Cheng, Lianglun
TI Person re-identification based on multi-level feature complementarity of
   cross-attention with part metric learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-id; Multi-level complementation; Cross attention; Part triple
   loss function; Joint training
AB Person re-identification is an image retrieval task, and its task is to perform a person matching in different cameras by a given person target. This research has been noticed and studied by more and more people. However, pose changes and occlusions often occur during a person walking. Especially in the most related methods, local features are not used to simply and effectively solve the problems of occlusion and pose changes. Moreover, the metric loss functions only consider the image-level case, and it cannot adjust the distance between local features well. To tackle the above problems, a novel person re-identification scheme is proposed. Through experiments, we found that we paid more attention to different parts of a person when we look at him from a horizontal or vertical perspective respectively. First, in order to solve the problem of occlusion and pose changes, we propose a Cross Attention Module (CAM). It enables the network to generate a cross attention map and improve the accuracy of person re-identification via the enhancement of the most significant local features of persons. The horizontal and vertical attention vectors of the feature maps are extracted and a cross attention map is generated, and the local key features are enhanced by this attention map. Second, in order to solve the problem of the lack of expression ability of the single-level feature maps, we propose a Multi-Level Feature Complementation Module (MLFCM). In this module, the missing information of high-level features is complemented by low-level features via short skip. Feature selection is also performed among deep features maps. The purpose of this module is to get the feature maps with complete information. Further, this module solves the problem of missing contour features in high-level semantic features. Third, in order to solve the problem that the current metric loss function cannot adjust the distance between local features, we propose Part Triple Loss Function (PTLF). It can reduce both within-class and increase between-class distance of the person parts. Experimental results show that our model achieves high values on Rank-k and mAP on Market-1501, Duke-MTMC and CUHK03-NP.
C1 [Lu, Zeng; Huang, Guoheng; Cheng, Lianglun] Guangdong Univ Technol, Guangzhou, Guangdong, Peoples R China.
   [Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China.
C3 Guangdong University of Technology; University of Macau
RP Huang, GH (corresponding author), Guangdong Univ Technol, Guangzhou, Guangdong, Peoples R China.
EM zenglu@mail2.gdut.edu.cn; kevinwong@gdut.edu.cn
RI Pun, Chi Man/GRJ-3703-2022
OI Huang, Guoheng/0000-0002-3640-3229
CR ADAIMI G, 2019, ARXIV190604692
   [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gao Y, 2019, PROC CVPR IEEE, P3200, DOI 10.1109/CVPR.2019.00332
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HSU HC, 2017, ARXIV171206820
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   LAN X, 2010, ARXIV190709511
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Lu KK, 2018, INT C PATT RECOG, P489, DOI 10.1109/ICPR.2018.8545190
   Ma B, 2012, WORK HYPERSP IMAG
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Qiang-Qiang Ren, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P65, DOI 10.1007/978-3-030-26766-7_7
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Xiao Q., 2017, ARXIV171000478
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Z, 2019, PROC IEEE C COMPUT V, P2147
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 56
TC 0
Z9 0
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21409
EP 21439
DI 10.1007/s11042-020-08972-w
EA MAY 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531339200005
DA 2024-07-18
ER

PT J
AU Shambharkar, PG
   Doja, MN
AF Shambharkar, Prashant Giridhar
   Doja, M. N.
TI Movie trailer classification using deer hunting optimization based deep
   convolutional neural network in video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive median filtering; Background subtraction; Deep convolution
   neural network; Movie trailer classification
ID REPRESENTATION
AB In current situation, video classification is one of the important research domains. Since video is a complex media with various components, classification of video is normally a complex process. This paper presented a human action based movie trailer classification using optimized deep convolutional neural network in video sequences. Initially, images are converted into the grayscale conversion. Using the adaptive median filtering process, the pre-processing stage is accomplished. Threshold based segmentation approach is utilized for subtracting the background from the video frames and to extract the foreground portion. In the feature extraction stage, the visual features (color and texture features) and motion features are extracted from the segmented portion. Finally, the mined features are trained and classified with the help of optimized deep convolutional neural network (DCNN) for the movie trailer classifications. Here, the deer hunting optimization (DHO) is introduced to optimize the weight values of DCNN. The proposed (DCNN-DHO) human action based movie trailer classification is executed in the MATLAB environment. The experimental results are evaluated and compared with the existing methods in terms of accuracy, false alarm rate, sensitivity, specificity, precision, F-measure and false discovery rate. The results of the proposed method are compared with filtering process and without filtering process in which 95.23% of accuracy is achieved for the suggested approach with filtering and 90.91% of accuracy is achieved for the suggested approach without filtering process.
C1 [Shambharkar, Prashant Giridhar] Delhi Technol Univ, Delhi, India.
   [Shambharkar, Prashant Giridhar; Doja, M. N.] Jamia Millia Islamia, New Delhi, India.
C3 Delhi Technological University
RP Shambharkar, PG (corresponding author), Delhi Technol Univ, Delhi, India.; Shambharkar, PG (corresponding author), Jamia Millia Islamia, New Delhi, India.
EM prashant.shambharkar@dtu.ac.in; mdoja@jmi.ac.in
RI Shambharkar, Prashant Giridhar/AAW-9704-2021
OI Shambharkar, Prashant Giridhar/0000-0002-5064-1653
CR Acar E, 2017, MULTIMED TOOLS APPL, V76, P11809, DOI 10.1007/s11042-016-3618-5
   [Anonymous], ARXIV14102175
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2010, Journal of Computing
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Ben-Ahmed O, 2018, 2018 INT C CONT BAS
   Brammya G, 2019, COMPUT J
   Choros K, 2018, VIDEO GENRE CLASSIFI, P509
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   Dandotiya Y, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P662, DOI 10.1109/ICECA.2017.8212748
   de Amorim MN, 2019, MULTIMED TOOLS APPL, V78, P19201, DOI 10.1007/s11042-019-7312-2
   Kumar V, 2018, SIGNAL IMAGE VIDEO P, V12, P141, DOI 10.1007/s11760-017-1140-5
   Li F, 2018, IEEE T MULTIMEDIA, V20, P1154, DOI 10.1109/TMM.2017.2764329
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Malakar A, 2013, INT J SCI REIJSR
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ogawa T, 2018, IEEE ACCESS, V6, P61401, DOI 10.1109/ACCESS.2018.2876710
   Ou WH, 2018, PATTERN RECOGN LETT, V107, P41, DOI 10.1016/j.patrec.2017.07.006
   Qin Z, 2017, IEEE T IMAGE PROCESS, V26, P5680, DOI 10.1109/TIP.2017.2745209
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Singh J, 2018, FRONT MATER SCI, V12, P1, DOI 10.1007/s11706-018-0409-0
   Singhal A, 2018, COGN SYST RES, V52, P917, DOI 10.1016/j.cogsys.2018.09.019
   Tian Y, 2018, IEEE T IMAGE PROCESS, V27, P1748, DOI 10.1109/TIP.2017.2788196
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Ye Z., 2011, 2011 3 INT WORKSH IN, P1, DOI [10.1109/ISA.2011.5873357, DOI 10.1109/ISA.2011.5873357]
   Yoo J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010034
   Zhang Pengfei, 2019, IEEE transactions on pattern analysis and machine intelligence
   Zhang WS, 2016, IEEE SOFTWARE, V33, P44, DOI 10.1109/MS.2016.31
NR 35
TC 9
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21197
EP 21222
DI 10.1007/s11042-020-08922-6
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768200003
DA 2024-07-18
ER

PT J
AU Li, HJ
   Qiu, J
   Teoh, ABJ
AF Li, Hengjian
   Qiu, Jian
   Teoh, Andrew Beng Jin
TI Palmprint template protection scheme based on randomized cuckoo hashing
   and MinHash
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable Palmprint template; Privacy-preserving; Random cuckoo hash;
   MinHash
ID CANCELABLE BIOMETRICS; SECURITY
AB To provide the necessary security and privacy privileges for registered users of biometric systems, a novel template protection method for generating cancelable palmprint features based on randomized cuckoo hashing and minHash is proposed in this paper. Firstly, the orthogonal features of palmprint are extracted using the anisotropic filter. Then, a novel randomized cuckoo hashing is applied on the binary palmprint feature as a means of first layer security. Randomized cuckoo hashing composes of two hash tables; before hashing, each column of original biometric template is filtered with a random matrix to improve discriminative ability. For the randomized cuckoo hashing with the same positions, we use different Gray coding methods instead, which improves irreversibility. Furthermore, to improve the efficiency and resist unlinkability attacks, another layer of privacy protection, MinHash is adopted. Experimental results on PolyU database show that our method can nearly preserve the original verification performance. The irreversibility, unlinkability and revocability properties are examined experimentally. Also, the privacy of palmprint protection scheme is analyzed under the Brute-force Attack, False Accept Attack and Birthday attack.
C1 [Li, Hengjian; Qiu, Jian] Univ Jinan, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
C3 University of Jinan; Yonsei University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
EM bjteoh@yonsei.ac.kr
RI Teoh, Andrew Beng Jin/F-4422-2010
OI Li, Hengjian/0000-0002-9702-824X
CR [Anonymous], 2008, EURASIP J ADV SIGNAL
   [Anonymous], 2014, P 10 ACM INT C EM NE
   [Anonymous], SCI WORLD J
   [Anonymous], SCI RES ESS
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Bringer J, 2017, IMAGE VISION COMPUT, V58, P239, DOI 10.1016/j.imavis.2016.08.002
   Bringer J, 2015, INT CONF BIOMETR, P527, DOI 10.1109/ICB.2015.7139069
   Broder Andrei, 2003, Internet Math, V1, DOI DOI 10.1080/15427951.2004.10129096
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380
   Drozdowski P, 2018, P EUR SIGN PROC C EU
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Hermand Jean-Pierre, 2014, OCEANS 2014, DOI 10.1109/OCEANS-TAIPEI.2014.6964569
   Indyk P, 1999, P 10 ANN ACM SIAM S
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kong A, 2008, PATTERN RECOGN, V41, P1329, DOI 10.1016/j.patcog.2007.09.002
   Lee M, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON BRAIN-COMPUTER INTERFACE (BCI), P31
   Leng L, 2013, P 6 INT C IM SIGN PR, P1694
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Li HJ, 2010, INFORM SCIENCES, V180, P3876, DOI 10.1016/j.ins.2010.06.040
   MCKINNEY EH, 1966, AM MATH MON, V73, P385, DOI 10.2307/2315408
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Pagh R, 2004, J ALGORITHMS, V51, P122, DOI 10.1016/j.jalgor.2003.12.002
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Qiu J, 2018, PROCEEDINGS OF 2018 6TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (ICBCB 2018), P78, DOI 10.1145/3194480.3194488
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2013, INT CONF BIOMETR
   Sadhya D, 2019, IEEE T INF FOREN SEC, V14, P2972, DOI 10.1109/TIFS.2019.2907014
   Sadhya D, 2017, COMPUT SECUR, V67, P59, DOI 10.1016/j.cose.2017.02.013
   Sun ZN, 2014, IEEE T IMAGE PROCESS, V23, P3922, DOI 10.1109/TIP.2014.2332396
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tams B, 2015, IEEE T INF FOREN SEC, V10, P985, DOI 10.1109/TIFS.2015.2392559
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
NR 39
TC 16
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11947
EP 11971
DI 10.1007/s11042-019-08446-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400031
DA 2024-07-18
ER

PT J
AU Dai, YL
   Wang, GJ
   Muhammad, K
   Liu, S
AF Dai, Yinglong
   Wang, Guojun
   Muhammad, Khan
   Liu, Shuai
TI A closed-loop healthcare processing approach based on deep reinforcement
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Deep reinforcement learning; Healthcare;
   Simulation; Multimedia data processing
ID CLASSIFICATION; NETWORKS
AB In healthcare, the human body is a controlled input-output system, which generates different observations with the variations of external interventions. The intervention acts as the input, and the output is the phenotype observation that reflects the latent health state of the body system. The objective of healthcare is to determine effective intervention strategies that can nurse an unhealthy human body to a healthy state. With the advances of Internet-of-Things (IoT) and body sensor networks, it becomes convenient to observe the multimedia data of the human body anywhere and anytime. To aid healthcare decision making, we put forward to construct the human body simulators based on deep neural networks (DNNs) for healthcare research. At first, we formulate the model of the human body system based on DNNs. During our analysis, we realize that DNN-based models could simulate practical situations, e.g. some health states are unreachable. Then, we combine deep reinforcement learning (DRL) with conceptual embedding techniques to explore effective healthcare strategies for simulated human bodies. We implement a virtual human body simulator, which can take interventions and represent its hidden states by high-dimensional images, and a DRL-based treatment module, which can diagnose latent health state through the image observations and choose interventions to nurse the simulated body to a target state. By combining the body simulator and treatment module, we create a dynamic closed-loop for healthcare information processing. Experimental simulations are performed to validate the feasibility of the offered approach.
C1 [Dai, Yinglong; Liu, Shuai] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language In, Changsha 410081, Hunan, Peoples R China.
   [Wang, Guojun] Guangzhou Univ, Sch Comp Sci, Guangzhou 510006, Peoples R China.
   [Muhammad, Khan] Sejong Univ, Dept Software, Seoul 143747, South Korea.
C3 Hunan Normal University; Guangzhou University; Sejong University
RP Muhammad, K (corresponding author), Sejong Univ, Dept Software, Seoul 143747, South Korea.
EM daiyl@hunnu.edu.cn; csgjwang@gmail.com; khan.muhammad.icp@gmail.com;
   cs.liu.shuai@gmail.com
RI Liu, Shuai/P-3939-2017; Muhammad, Khan/L-9059-2016; Khan,
   Muhammad/IXN-8470-2023
OI Liu, Shuai/0000-0001-9909-0664; Muhammad, Khan/0000-0003-4055-7412;
   Muhammad, Khan/0000-0002-5302-1150
FU National Natural Science Foundation of China [61632009]; Guangdong
   Provincial Natural Science Foundation [2017A030308006]; High Level
   Talents Program of Higher Education in Guangdong Province [2016ZJ01];
   Hunan Provincial Science and Technology Project Foundation [2018TP1018,
   2018RS3065]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant Numbers 61632009, the Guangdong
   Provincial Natural Science Foundation under Grant Number 2017A030308006,
   the High Level Talents Program of Higher Education in Guangdong Province
   under Funding Support Number 2016ZJ01, Hunan Provincial Science and
   Technology Project Foundation under Grant Numbers 2018TP1018 and
   2018RS3065.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2018, BRIEF BIOINFORM, DOI DOI 10.1093/bib/bbx044
   Caggianese G, 2019, IEEE T IND INFORM, V15, P517, DOI 10.1109/TII.2018.2856097
   Choi Edward, 2016, JMLR Workshop Conf Proc, V56, P301
   Dai YL, 2020, PATTERN RECOGN LETT, V139, P17, DOI 10.1016/j.patrec.2018.02.009
   Dai Y, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P635, DOI 10.1109/SmartWorld.2018.00128
   Dai YL, 2017, IEEE INT SYMP PARAL, P959, DOI 10.1109/ISPA/IUCC.2017.00147
   Dai YL, 2018, J INTELL FUZZY SYST, V34, P1631, DOI 10.3233/JIFS-169457
   Dai YL, 2018, IEEE ACCESS, V6, P5962, DOI 10.1109/ACCESS.2017.2788849
   Dartmann G., 2019, Big Data Analytics For Cyber-Physical Systems: Machine Learning For the Internet of Things
   Doody RS, 2010, ALZHEIMERS RES THER, V2, DOI [10.1186/alzrt25, 10.1186/alzrt38]
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gu S., 2017, 2017 IEEE INT C ROB, P3389, DOI DOI 10.1109/ICRA.2017.7989385
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hovorka R, 2011, NAT REV ENDOCRINOL, V7, P385, DOI 10.1038/nrendo.2011.32
   Hu Y, 2018, MULTIMED TOOLS APPL, V77, P3729, DOI 10.1007/s11042-016-3719-1
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li J., 2016, EMNLP, DOI [DOI 10.18653/V1/D16-1127.URL, 10.18653/v1/D16-1127, DOI 10.18653/V1/D16-1127]
   Lillicrap, 2015, ARXIV150902971, P1
   Liu S, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106537
   Liu S, 2019, IEEE ACCESS, V7, P62412, DOI 10.1109/ACCESS.2019.2916934
   Liu Y, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P380, DOI 10.1109/ICHI.2017.45
   Liu YX, 2019, INT CONF COMPUT NETW, P797, DOI [10.1109/ICCNC.2019.8685670, 10.1109/iccnc.2019.8685670]
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mould DR, 2012, CLIN PHARMACOL THER, V92, P125, DOI 10.1038/clpt.2012.53
   Nemati S, 2016, IEEE ENG MED BIO, P2978, DOI 10.1109/EMBC.2016.7591355
   Orphanou K, 2014, ARTIF INTELL MED, V60, P133, DOI 10.1016/j.artmed.2013.12.007
   Nguyen P, 2017, IEEE J BIOMED HEALTH, V21, P22, DOI 10.1109/JBHI.2016.2633963
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sukkar R, 2012, IEEE ENG MED BIO, P2845, DOI 10.1109/EMBC.2012.6346556
   Pham T, 2017, J BIOMED INFORM, V69, P218, DOI 10.1016/j.jbi.2017.04.001
   Wang L, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2447, DOI 10.1145/3219819.3219961
   Wang X, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P85, DOI 10.1145/2623330.2623754
   Zhang Y, 2014, IEEE INTERNET THINGS, V1, P311, DOI 10.1109/JIOT.2014.2329462
   Zhao XF, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6362010
NR 39
TC 9
Z9 9
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3107
EP 3129
DI 10.1007/s11042-020-08896-5
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000529585600004
DA 2024-07-18
ER

PT J
AU Tripathi, S
   Singh, SK
AF Tripathi, Suvidha
   Singh, Satish Kumar
TI Ensembling handcrafted features with deep features: an analytical study
   for classification of routine colon cancer histopathological nuclei
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nuclei classification; Colon cancer; Deep ensemble; Handcrafted
   features; Convolutional neural networks; Cascaded ensemble; Feature
   concatenation; Deep and handcrafted feature combination; Transfer
   learning; Ensemble methods; Deep learning; Feature fusion
ID DESCRIPTOR; DIAGNOSIS
AB The use of Deep Learning (DL) based methods in medical histopathology images have been one of the most sought after solutions to classify, segment, and detect diseased biopsy samples. However, given the complex nature of medical datasets due to the presence of intra-class variability and heterogeneity, the use of complex DL models might not give the optimal performance up to the level which is suitable for assisting pathologists. Therefore, ensemble DL methods with the scope of including domain agnostic handcrafted Features (HC-F) inspired this work. We have, through experiments, tried to highlight that a single DL network (domain-specific or state of the art pre-trained models) cannot be directly used as the base model without proper analysis with the relevant dataset. We have used F1-measure, Precision, Recall, AUC, and Cross-Entropy Loss to analyse the performance of our approaches. We observed from the results that the DL features ensemble bring a marked improvement in the overall performance of the model, whereas, domain agnostic HC-F remains dormant on the performance of the DL models.
C1 [Tripathi, Suvidha; Singh, Satish Kumar] Indian Inst Informat Technol Allahabad, Prayagraj 211015, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Tripathi, S (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj 211015, Uttar Pradesh, India.
EM suvitri24@gmail.com
RI Tripathi, Suvidha/ABA-4736-2020; Singh, Dr Satish Kumar/JMP-6186-2023;
   singh, satish/U-7158-2018
OI Singh, Dr Satish Kumar/0000-0003-1991-7727; singh,
   satish/0000-0002-8536-4991
FU Ministry of Human Resource and Development, Government of India; NVIDIA
   corporation
FX This research was carried out in the Indian Institute of Information
   Technology, Allahabad and supported by the Ministry of Human Resource
   and Development, Government of India. We are also grateful to the NVIDIA
   corporation for supporting our research in this area by granting us
   TitanX (PASCAL) GPU.
CR [Anonymous], [No title captured]
   [Anonymous], INT C REC TRENDS IM
   [Anonymous], 2009, handbook of research on machine learning applications
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Carneiro G, 2015, IEEE I CONF COMP VIS, P648, DOI 10.1109/ICCV.2015.81
   Chen CM, 2016, SCI REP-UK, V6, DOI 10.1038/srep18711
   Demir Cigdem., 2005, Automated cancer diagnosis based on histopathological images: a systematic survey
   Dhandra BV, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P167
   Diamond J, 2004, HUM PATHOL, V35, P1121, DOI 10.1016/j.humpath.2004.05.010
   Doyle S, 2007, I S BIOMED IMAGING, P1284, DOI 10.1109/ISBI.2007.357094
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao ZM, 2017, IEEE J BIOMED HEALTH, V21, P416, DOI 10.1109/JBHI.2016.2526603
   Genest C., 1986, STAT SCI, V1, P114
   Gil J, 2002, MICROSC RES TECHNIQ, V59, P109, DOI 10.1002/jemt.10182
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Gurcan M.N., 2009, IEEE REV BIOMED ENG, V2, P147, DOI DOI 10.1109/RBME.2009.2034865
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jafari-Khouzani K, 2003, IEEE T BIO-MED ENG, V50, P697, DOI 10.1109/TBME.2003.812194
   Keenan SJ, 2000, J PATHOL, V192, P351, DOI 10.1002/1096-9896(2000)9999:9999<::AID-PATH708>3.0.CO;2-I
   Litjens G, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy065
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sims AJ, 2003, PHYS MED BIOL, V48, pN183, DOI 10.1088/0031-9155/48/13/401
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sirinukunwattana K, 2015, PROC SPIE, V9420, DOI 10.1117/12.2082010
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Weyn B, 1998, CYTOMETRY, V33, P32, DOI 10.1002/(SICI)1097-0320(19980901)33:1<32::AID-CYTO4>3.0.CO;2-D
   Xu Y, 2015, INT CONF ACOUST SPEE, P947, DOI 10.1109/ICASSP.2015.7178109
   Yuan YY, 2012, SCI TRANSL MED, V4, DOI 10.1126/scitranslmed.3004330
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
NR 43
TC 12
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34931
EP 34954
DI 10.1007/s11042-020-08891-w
EA APR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000529074000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jain, A
   Singh, SK
   Singh, KP
AF Jain, Anamika
   Singh, Satish Kumar
   Singh, Krishna Pratap
TI Handwritten signature verification using shallow convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Behavioral biometrics; Offline signature Verification; CNN
ID SYSTEM; FEATURES; RECOGNITION; SHAPE
AB Handwritten signatures are an undeniable and unique way to prove the identity of persons. Owing to the simplicity and uniqueness, it finds an essential place in the area of behavioral biometric. Signatures are the most widely accepted biometric trait by law enforcement agencies/personnel for verification purposes, especially in financial institutions, legal transactions, etc. and hence secured authentication becomes imperative. In the era of a digital age, numerous transactions are taking place, where handwritten signature verification is required by the agencies, e.g., banks, etc. In such scenarios, the process of signature verification, besides being accurate and secure, should be very fast, i.e., the real-time verification can be done. In this paper, we have proposed a convolutional neural network-based language-independent shallow architecture (sCNN(Shallow Convolutional Neural Network)) for signature verification. The proposed architecture is very simple but extremely efficient in terms of accuracy. A custom shallow convolution neural network is used to automatically learn the features of signature from the provided training data. Another contribution of the research work, which is the handwritten signature data collection for 137 subjects and 467 subjects, which are named as CVBLSig-V1 and CVBLSig-V2 respectively, has been reported in this paper. The performance of the proposed architecture has been evaluated on publicly available datasets, i.e., MCYT-75, MCYT-100, and GPDS, as well as CVBLSig-V1 and CVBLSig-V2. The performance was also compared with state of the art reported methods and shown improved, while considering the accuracy and equal error rate (EER) as performance metrics.
C1 [Jain, Anamika; Singh, Satish Kumar; Singh, Krishna Pratap] Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Jain, A (corresponding author), Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM anamika06jain@gmail.com; sk.singh@iiita.ac.in; kpsingh@iiita.ac.in
RI JAIN, ANAMIKA/IAO-0486-2023; singh, satish/U-7158-2018; Singh, Dr Satish
   Kumar/JMP-6186-2023
OI singh, satish/0000-0002-8536-4991; Singh, Dr Satish
   Kumar/0000-0003-1991-7727; Jain, Anamika/0000-0003-3612-8690; Singh,
   Krishna Pratap/0000-0003-3347-8521
FU Ministry of Human Resource and Development, Government of India; NVIDIA
   Corporation
FX This research is conducted in Indian Institute of Information Technology
   Allahabad and supported by the Ministry of Human Resource and
   Development, Government of India. We are grateful to the support of
   NVIDIA Corporation. NVIDIA Corporation has donated TITANX(PASCAL) GPU
   with 3584 CUDA cores.
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Azmi AN, 2017, MULTIMED TOOLS APPL, V76, P15341, DOI 10.1007/s11042-016-3831-2
   Bajaj R, 1997, PATTERN RECOGN, V30, P1, DOI 10.1016/S0031-3203(96)00059-3
   Baltzakis H, 2001, ENG APPL ARTIF INTEL, V14, P95, DOI 10.1016/S0952-1976(00)00064-6
   Bhukya RK, 2018, CIRC SYST SIGNAL PR, V37, P5507, DOI 10.1007/s00034-018-0827-3
   Bouamra W, 2018, EXPERT SYST APPL, V107, P182, DOI 10.1016/j.eswa.2018.04.035
   Charfi N, 2017, MULTIMED TOOLS APPL, V76, P20457, DOI 10.1007/s11042-016-3987-9
   Chaudhry SA, 2018, MULTIMED TOOLS APPL, V77, P5503, DOI 10.1007/s11042-017-4464-9
   De Marsico M, 2016, PATTERN RECOGN LETT, V82, P106, DOI 10.1016/j.patrec.2016.02.001
   Dey S., 2017, Pattern Recognition Letters
   Dutta A, 2016, INT C PATT RECOG, P3422, DOI 10.1109/ICPR.2016.7900163
   Ferrer Marie-Helene, 2013, Instituto Diplomatico, P1, DOI [DOI 10.1109/ICB.2013.6612969, 10.1145/2501907.2501963, 10.1109/ICB.2013.6612969]
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281
   Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523
   Hadjadji B, 2017, NEUROCOMPUTING, V265, P66, DOI 10.1016/j.neucom.2017.01.108
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Hafemann LG, 2016, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2016.7900092
   Hafemann LG, 2016, IEEE IJCNN, P2576, DOI 10.1109/IJCNN.2016.7727521
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He L, 2019, MULTIMED TOOLS APPL, V78, P19253, DOI 10.1007/s11042-019-7264-6
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Lai SX, 2017, PROC INT CONF DOC, P400, DOI 10.1109/ICDAR.2017.73
   Liu WY, 2016, PR MACH LEARN RES, V48
   Manjunatha KS, 2016, PATTERN RECOGN LETT, V80, P129, DOI 10.1016/j.patrec.2016.06.016
   Okawa M, 2018, PATTERN RECOGN LETT, V113, P75, DOI 10.1016/j.patrec.2018.05.019
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P72, DOI 10.1109/DAS.2016.48
   Pascual-Gaspar JM, 2009, LECT NOTES COMPUT SC, V5558, P1180, DOI 10.1007/978-3-642-01793-3_119
   Ruder S., 2016, ARXIV
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472
   Sharma A, 2017, IEEE T INF FOREN SEC, V12, P705, DOI 10.1109/TIFS.2016.2632063
   Sharma S, 2015, EXPERT SYST APPL, V42, P821, DOI 10.1016/j.eswa.2014.08.052
   Van BL, 2007, IEEE T SYST MAN CY B, V37, P1237, DOI 10.1109/TSMCB.2007.895323
   VARGAS JF, 2010, 2010 12 INT C FRONT, P587
   Vezzetti E, 2012, COMPUT METH PROG BIO, V108, P1078, DOI 10.1016/j.cmpb.2012.07.008
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   YILMAZ MB, 2018, P IEEE C COMP VIS PA, P526
   Zhang C., 2016, UNDERSTANDING DEEP L
   Zois EN, 2019, EXPERT SYST APPL, V125, P14, DOI 10.1016/j.eswa.2019.01.058
NR 45
TC 22
Z9 23
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19993
EP 20018
DI 10.1007/s11042-020-08728-6
EA APR 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000525106300001
DA 2024-07-18
ER

PT J
AU Amin, J
   Sharif, M
   Yasmin, M
   Saba, T
   Raza, M
AF Amin, Javeria
   Sharif, Muhammad
   Yasmin, Mussarat
   Saba, Tanzila
   Raza, Mudassar
TI Use of machine intelligence to conduct analysis of human brain data for
   detection of abnormalities in its cognitive functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging (MRI); Gray level co-occurrence matrix
   (GLCM); Potential differential diffusion filter (PDDF); Local binary
   pattern (LBP); LBP based GLCM (C2LBPGLCM)
ID TUMOR SEGMENTATION; FEATURE-SELECTION; CLASSIFICATION; FEATURES;
   RECOGNITION; DIAGNOSIS; IMAGES; TISSUE
AB The physical appearance of a brain tumor in human beings may be an indication of problems in psychological (cognitive) functions. Such functions include learning, understanding, problem solving, decision making, and planning. Early brain tumor detection can be done by using the proper procedure of screening. MRI is used for the detection of disease staging and follow-up without ionization radiation. In this manuscript, an automated system is proposed for the analysis of brain data and detection of cognitive functions abnormalities. The region of interest (ROI) is enhanced using a proposed partial differential diffusion filter (PDDF) which is a modified form of anisotropic diffusion filter. Otsu algorithm is used for better segmentation. Moreover, a new method is also proposed for feature extraction which is a concatenation of local binary pattern (LBP) and Gray level co-occurrence matrix (C2LBPGLCM). The proposed method accurately distinguishes between healthy and unhealthy images with high specificity, sensitivity, and area under the curve.
C1 [Amin, Javeria; Sharif, Muhammad; Yasmin, Mussarat; Raza, Mudassar] Univ Wah, Dept Comp Sci, Wah Cantonment, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ Riyadh Saudi Arabia, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
RP Yasmin, M (corresponding author), Univ Wah, Dept Comp Sci, Wah Cantonment, Pakistan.
EM javeria.amin@uow.edu.pk; mussaratabdullah@gmail.com
RI Saba, Tanzila/D-4593-2018; Yasmin, Mussarat/HPC-9476-2023; AMIN,
   JAVARIA/IAQ-1843-2023; Sharif, Muhammad/ACD-2598-2022; Raza,
   Mudassar/I-4000-2015
OI Saba, Tanzila/0000-0003-3138-3801; Sharif, Muhammad/0000-0002-7258-8400;
   Raza, Mudassar/0000-0001-9124-9298
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Abdulbaqi H. S., 2016, J TELECOMMUNICATION, V8, P9
   Ain Q, 2014, APPL SOFT COMPUT, V21, P330, DOI 10.1016/j.asoc.2014.03.019
   Alfonse M., 2016, Egyptian Computer Science Journal, V40, P11
   Amin HH, 2017, INT CONF UBIQ FUTUR, P1
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Amin J, 2017, J COMPUT SCI-NETH, V19, P153, DOI 10.1016/j.jocs.2017.01.002
   [Anonymous], ARXIV170503820
   [Anonymous], 2012, MICCAI BRATS WORKSH
   [Anonymous], 2013, MULTIMODAL BRAIN TUM
   [Anonymous], P 2 INT C MICR EL TE
   [Anonymous], 2013, P NCI MICCAI BRATS
   [Anonymous], 2014, P BRATS CHALL MICCAI
   Ansari GJ, 2018, FUTURE GENER COMP SY, V87, P328, DOI 10.1016/j.future.2018.04.074
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Banerjee S, 2018, INFORM SCIENCES, V424, P337, DOI 10.1016/j.ins.2017.10.011
   Banerjee S, 2016, INFORM SCIENCES, V330, P88, DOI 10.1016/j.ins.2015.10.018
   Benson CC, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING APPLICATIONS (ICICA 2014), P254, DOI 10.1109/ICICA.2014.61
   Binczyk F, 2017, INFORM SCIENCES, V384, P235, DOI 10.1016/j.ins.2016.07.052
   Bokhari STF, 2018, CURR MED IMAGING REV, V14, P77, DOI 10.2174/1573405613666170405145913
   Chen Xiaoran, 2018, ARXIV180604972
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Desai U, 2018, SMART INNOV SYST TEC, V77, P421, DOI 10.1007/978-981-10-5544-7_41
   Desai U, 2016, J MECH MED BIOL, V16, DOI 10.1142/S0219519416400054
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Fernandes SL, 2016, J INTEGR DES PROCESS, V20, P33, DOI 10.3233/jid-2016-0002
   Gatenby RA, 2013, RADIOLOGY, V269, P8, DOI 10.1148/radiol.13122697
   Gondal Anjum Hayat, 2013, International Journal of Modern Education and Computer Science, V5, P55, DOI 10.5815/ijmecs.2013.02.08
   Guo Xiaotao., 2013, Multimodal Brain Tumor Seg- mentation, P27
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Holland EC, 2000, P NATL ACAD SCI USA, V97, P6242, DOI 10.1073/pnas.97.12.6242
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   Huang QH, 2015, INFORM SCIENCES, V314, P293, DOI 10.1016/j.ins.2014.08.021
   Kadkhodaei M, 2016, IEEE ENG MED BIO, P5945, DOI 10.1109/EMBC.2016.7592082
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khan MW, 2016, J INTEGR DES PROCESS, V20, P77, DOI 10.3233/jid-2016-0004
   Kong YY, 2015, IEEE SIGNAL PROC LET, V22, P573, DOI 10.1109/LSP.2014.2364612
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Louis D.N., 2007, ACTA NEUROPATHOL, V114, P97, DOI [10.1007/s00401-007-0243-4, DOI 10.1007/s00401-007-0243-4]
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mitra S, 2015, INFORM SCIENCES, V306, P111, DOI 10.1016/j.ins.2015.02.015
   Murino V, 2017, COMPUT VIS PATT REC, P1, DOI 10.1016/B978-0-12-809276-7.00001-1
   Naqi SM, 2018, CURR MED IMAGING, V14, P108, DOI 10.2174/1573405613666170306114320
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nida N, 2016, IIOAB J, V7, P202
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parmar C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102107
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Raza M, 2018, FUTURE GENER COMP SY, V88, P28, DOI 10.1016/j.future.2018.05.002
   Reza SMS, 2015, PROC SPIE, V9414, DOI 10.1117/12.2083596
   Shil SK, 2017, I C INF COMM TECH CO, P54, DOI 10.1109/ICTC.2017.8190941
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Torheim T, 2014, IEEE T MED IMAGING, V33, P1648, DOI 10.1109/TMI.2014.2321024
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zanaty E.A., 2012, International Journal of Computer Applications, V45, P16
NR 61
TC 34
Z9 34
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10955
EP 10973
DI 10.1007/s11042-019-7324-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600066
DA 2024-07-18
ER

PT J
AU Kavitha, E
   Tamilarasan, R
AF Kavitha, E.
   Tamilarasan, R.
TI AGGLO-Hi clustering algorithm for gene expression micro array data using
   proximity measures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Clustering; Microarray
AB Gene selection is imperative to clustering in light of gene articulation information, as a result of high Clustering quality. Clustering gene articulation information is a vital research subject in bioinformatics on the grounds that knowing which genes act correspondingly can prompt the disclosure of vital natural data. Many clustering systems have been proposed to the examination of gene articulation information got from microarray innovation. Clustering is one of the major procedures of investigating gene articulation information, fundamentally by contrasting gene articulation profiles or test articulation profiles. The Proposed strategy is an Agglo-Hi clustering algorithm which is accounted for the fuse of vicinity similarity estimates like Euclidean Distance, Manhattan Distance Chebyshev Distance, and Cosine Similarity for their execution. The technique is quality articulation information in microarray which is extricated and quality can be chosen from the preprocessed information, at that point the Agglo-Hi Clustering algorithm is utilized for quality information. The grouped information get approved utilizing legitimacy file and the outcome is gotten in light of nearness measures. To refine quality articulation information onto enhanced bunch quality by accelerating Unsupervised Learning stage and the execution of Agglo-Hi algorithm figures the Clustering quality, exactness and time unpredictability.
C1 [Kavitha, E.] Univ Coll Engn, Dept Comp Sci & Engn, Villupuram, India.
   [Kavitha, E.] Univ Coll Engn, Dept Informat Technol, Villupuram, India.
   [Tamilarasan, R.] Univ Coll Engn, Dept Chem, Pattukotai, India.
RP Kavitha, E (corresponding author), Univ Coll Engn, Dept Comp Sci & Engn, Villupuram, India.; Kavitha, E (corresponding author), Univ Coll Engn, Dept Informat Technol, Villupuram, India.
EM ekavithavrs@gmail.com; rrtamilk@yahoo.co.in
RI Kavitha, E/AAL-2254-2021
OI Tamilarasan, Rengasamy/0000-0003-2157-6917
CR Bala Subramaniyan R, 2004, BIOINFORMATICS
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Boeva V, 2010, STUD COMPUT INTELL, V299, P445
   Borg A, 2013, 12 SCAND C ART INT
   Bryan J, 2004, J MULTIVARIATE ANAL, V90, P44, DOI 10.1016/j.jmva.2004.02.011
   Chan EY, 2004, PATTERN RECOGN, V37, P943, DOI 10.1016/j.patcog.2003.11.003
   Chen HH, 2016, J BIOMED INFORM, V62, P12, DOI 10.1016/j.jbi.2016.05.007
   Costa IG, 2004, GENET MOL BIOL, V27, P623, DOI 10.1590/S1415-47572004000400025
   Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370, DOI 10.1109/TKDE.2004.68
   Kerr G, 2008, COMPUT BIOL MED, V38, P283, DOI 10.1016/j.compbiomed.2007.11.001
   Koestler DC, 2014, BMC MED GENOMICS, V7, DOI 10.1186/1755-8794-7-8
   Kormaksson M, 2012, ANN APPL STAT, V6, P1327, DOI 10.1214/11-AOAS533
   Liu J, 2006, BIOINFORMATICS, V22, P1971, DOI 10.1093/bioinformatics/btl185
   Mahima KM, 2015, INT J INNOVATIVE RES, V3
   Makolo A, 2016, INT J COMPUT APPL, V139
   McNicholas PD, 2010, BIOINFORMATICS, V26, P2705, DOI 10.1093/bioinformatics/btq498
   Moller-Levet C, 2003, TECHNICAL REPORT
   Pirim H, 2012, COMPUT OPER RES, V39, P3046, DOI 10.1016/j.cor.2012.03.008
   Romdhane LB, 2009, MINING MICROARRAY GE
   Sarmah S, 2010, INT J COMPUTER SCI I, V7, P3
   Seal S, 2005, INFORM PROCESS LETT, V93, P143, DOI 10.1016/j.ipl.2004.11.001
   Visvanathan M, 2009, IEEE INT C BIOINF BI
   Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-5-r34
   Zareizadeh Z, 2018, EXPERT SYSTEMS APPL
   Zhang W, 2013, PATTERN RECOGN, V46, P3056, DOI 10.1016/j.patcog.2013.04.013
NR 25
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9003
EP 9017
DI 10.1007/s11042-018-7112-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600033
DA 2024-07-18
ER

PT J
AU Khan, FA
   Rahman, A
   Alharbi, M
   Qawqzeh, YK
AF Khan, Fakhri Alam
   Rahman, Attaur
   Alharbi, Mafawez
   Qawqzeh, Yousef Kamel
TI Awareness and willingness to use PHR: a roadmap towards cloud-dew
   architecture based PHR framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal health record systems; Awareness; Willingness
ID HEALTH; RECORDS
AB Personal health record systems (PHR) assists people to access, manage and share their own health information. PHR is getting increasingly popular these days. However, there is not even a single PHR system being deployed in Saudi Arabia considering the special needs of Saudi Arabian society. Before a PHR system is deployed, it is mandatory to know the awareness and willingness of the people so that usability of the system can be defined. In this research, we have conducted a survey in Saudi Arabia to know the level of awareness of PHR systems and the willingness of people to adopt and use such systems. In order to conduct the survey, a total of one hundred and sixty four individuals from different age groups were selected randomly keeping in perspective the target population. For reaching to the ends that stretch beyond the immediate data alone, we have used the inferential statistics for our research work. During our inferential analysis, we have selected the cross-tabulation method for comparing two different variables. The cross-tabulation of categorical and ordinal data is a good tool for summarizing demographic information and searching for blueprints. We used the Chi-Square tests to find out whether an association (or relationship) between 2 categorical variables in a sample is likely to contemplate a substantial association between these 2 variables in the population. The results indicate that the level of awareness about PHR systems is still low in the Saudi society but the people are willing to use a personalized electronic system to manage their own health. The results further indicate that the availability of the internet is a major barrier to the realization of PHR systems. These results encourage to adopt a Cloud-Dew Architecture based Layered PHR system that goes beyond the trivial network/storage/service concept to a new micro-service concept offering high scalability and availability in vertically distributed computing hierarchy.
C1 [Khan, Fakhri Alam; Rahman, Attaur] Inst Management Sci, Ctr Excellence IT, Peshawar, Pakistan.
   [Alharbi, Mafawez; Qawqzeh, Yousef Kamel] Majmah Univ, Dept Comp Sci & Informat, Al Majmaah, Saudi Arabia.
C3 Majmaah University
RP Khan, FA (corresponding author), Inst Management Sci, Ctr Excellence IT, Peshawar, Pakistan.
EM fakhri.alam@imsciences.edu.pk; attaurrahman@imsciences.edu.pk;
   m.alharbi@mu.edu.sa; y.qawqzeh@mu.edu.sa
RI Khan, Fakhri Alam/GPP-4180-2022; Khan, Fakhri Alam/S-5340-2017; Rahman,
   Atta ur/G-2895-2015
OI Rahman, Atta ur/0000-0001-9977-1451; Alharbi, Mafawez
   T./0000-0001-8174-9475; Khan, Fakhri Alam/0000-0002-9130-1874
CR Borycki E M, 2012, Yearb Med Inform, V7, P56
   Chrischilles EA, 2014, J AM MED INFORM ASSN, V21, P679, DOI 10.1136/amiajnl-2013-002284
   Dontje K, 2014, JNP-J NURSE PRACT, V10, P824, DOI 10.1016/j.nurpra.2014.09.009
   Dunlop Laura, 2007, SHIDLER J L COM TECH, V3, P16
   Fricton J.C., 2009, PERSONAL HLTH RECORD
   Friedman C.P., 2006, EVALUATION METHODS B
   HIMSS, 2006, HIMSS FED HIT LEG CR
   Imran M, 2018, FUTURE GENER COMP SY, V81, P348, DOI 10.1016/j.future.2017.10.027
   Khan A., 2016, Business Economic Review, V8, P67, DOI [10.22547/ber/8.se.5, DOI 10.22547/BER/8.SE.5]
   Khan Fakhri Alam, 2008, 2008 Fourth International Conference on Semantics, Knowledge and Grid (SKG), P173, DOI 10.1109/SKG.2008.86
   Krist AH, 2011, JAMA-J AM MED ASSOC, V305, P300, DOI 10.1001/jama.2010.2011
   Li JQ, 2015, COMPUTER, V48, P24, DOI 10.1109/MC.2015.43
   Liu L.S., 2011, BARRIERS ADOPTION US
   Peters K, 2009, CONSUMERS COMP ONLIN
   Smolij K, 2006, P PERSP HLTH NF MAN
   Vance B., 2015, 2015 BUS HLTH ADM AS
   Winkelman WJ, 2004, J AM MED INFORM ASSN, V11, P151, DOI 10.1197/jamia.M1274
NR 17
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8399
EP 8413
DI 10.1007/s11042-018-6692-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600005
DA 2024-07-18
ER

PT J
AU Ma, XL
   Lu, Y
   Lu, YA
   Pei, ZL
AF Ma, Xiaolei
   Lu, Yang
   Lu, Yinan
   Pei, Zhili
TI RETRACTED: Medical image analysis of phosphorylated protein interaction
   extraction algorithm based on text mining technology (Retracted article.
   See vol. 82, pg. 17519, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Medical image; Phosphorylated protein; Interaction extraction algorithm;
   Text mining technology
ID DISEASE; GENE; WEB
AB Medical images have been widely used in the analysis of phosphorylated protein interactions, Medical image segmentation separates different regions of a particular meaning in an image. These regions make each region that does not intersect with each other satisfy the consistency of a particular region. In bioinformatics, measurement on protein interaction is one of the key points, which plays a very important role in understanding various biological processes and in the treatment and diagnosis of diseases. The physiological functions of organisms are mainly regulated by proteins in cells, so studying the interaction between proteins becomes the basis for understanding life activities. Using text mining methods to study protein interactions can make full use of the vast literature available to reveal potential knowledge associated with proteins and construct protein interaction networks. Therefore, this paper proposes a method for automatically extracting protein interaction pairs from the literature by studying the extraction principle of protein interactions and their interaction words. At the same time, the method of protein interaction relationship mining is developed. The research and the results obtained in this paper have certain reference value for the study of protein relations in the future.
C1 [Ma, Xiaolei; Lu, Yang; Lu, Yinan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Ma, Xiaolei; Lu, Yang] Inner Mongolia Univ Nationalities, Lib, Tongliao 028000, Inner Mongolia, Peoples R China.
   [Pei, Zhili] Inner Mongolia Univ Nationalities, Coll Comp Sci & Technol, Tongliao 028000, Inner Mongolia, Peoples R China.
C3 Jilin University; Inner Mongolia University for Nationalities; Inner
   Mongolia University for Nationalities
RP Lu, YA (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM mxl840101@163.com; luyang3252@163.com; luyn_jlu@sina.com;
   zhilipei@sina.com
CR [Anonymous], 2014, NUCLEIC ACIDS RES, V42, pD7
   Atkinson-Abutridy J, 2004, IEEE INTELL SYST, V19, P22, DOI 10.1109/MIS.2004.4
   Basit AH, 2018, J BIOINF COMPUT BIOL, V16, DOI 10.1142/S0219720018500142
   Benson DA, 2004, NUCLEIC ACIDS RES, V32, pD23, DOI 10.1093/nar/gkh045
   Damanhuri NS, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/645732
   Guo XZ, 2014, CLIN BIOCHEM, V47, P1220, DOI 10.1016/j.clinbiochem.2014.05.060
   Hayashi T, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2073-x
   Hu YH, 2018, NUCLEIC ACIDS RES, V46, pD567, DOI 10.1093/nar/gkx1116
   Huang CC, 2016, BRIEF BIOINFORM, V17, P132, DOI 10.1093/bib/bbv024
   Huang L, 2016, EURASIP J BIOINFORM, DOI 10.1186/s13637-016-0040-2
   Kaur J, 2013, INT NANO LETT, V3, DOI 10.1186/2228-5326-3-4
   Krallinger M, 2012, DATABASE-OXFORD, DOI 10.1093/database/bas017
   Kreuzthaler M, 2016, STUD HEALTH TECHNOL, V228, P582, DOI 10.3233/978-1-61499-678-1-582
   Miller CM, 2012, SLEEP, V35, P279, DOI 10.5665/sleep.1640
   Moraes F, 2016, BIOCHEM MOL BIOL EDU, V44, P215, DOI 10.1002/bmb.20952
   Moraux A, 2013, BMC MUSCULOSKEL DIS, V14, DOI 10.1186/1471-2474-14-104
   Nguyen D. -T., 2016, NUCLEIC ACIDS RES, V45, P1
   Raja K, 2014, INT J DATA MIN BIOIN, V10, P315, DOI 10.1504/IJDMB.2014.064545
   Raja K, 2013, DATABASE-OXFORD, DOI 10.1093/database/bas052
   Ramos RP, 2012, EXPERT SYST APPL, V39, P11036, DOI 10.1016/j.eswa.2012.03.020
   Ravikumar KE, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0609-x
   Salgado D, 2012, BIOINFORMATICS, V28, P2285, DOI 10.1093/bioinformatics/bts435
   Selkoe DJ, 2016, EMBO MOL MED, V8, P595, DOI 10.15252/emmm.201606210
   Sorokina S Iu, 2013, Izv Akad Nauk Ser Biol, P261
   Sorokina SY, 2013, BIOL BULL+, V40, P233, DOI 10.1134/S1062359013030096
   Spielman DA, 2013, SIAM J COMPUT, V42, P1, DOI 10.1137/080744888
   Subramani S, 2015, J BIOMED INFORM, V54, P121, DOI 10.1016/j.jbi.2015.01.006
   Subramani S, 2014, J BIOMED INFORM, V47, P131, DOI 10.1016/j.jbi.2013.10.003
   Toulouse T, 2016, SIGNAL IMAGE VIDEO P, V10, P647, DOI 10.1007/s11760-015-0789-x
   Turner Marc L, 2018, Handb Clin Neurol, V153, P463, DOI 10.1016/B978-0-444-63945-5.00026-X
   Wang J, 2017, MOLECULES, V22, DOI 10.3390/molecules22122179
   Wang Y, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17010039
   Xia KJ, 2019, CLUSTER COMPUT, V22, P10969, DOI 10.1007/s10586-017-1264-y
   Xue YL, 2017, SHOCK VIB, V2017, DOI 10.1155/2017/1396567
   Yadav S, 2017, SOFT COMPUT, P1
   You ZH, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-343
   Zhang SW, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-326
   Zhao RQ, 2016, IEEE T PATTERN ANAL, V38, P1640, DOI 10.1109/TPAMI.2015.2481404
NR 38
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10551
EP 10579
DI 10.1007/s11042-019-07853-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600045
DA 2024-07-18
ER

PT J
AU Wang, J
   Liu, WY
   Zhang, S
AF Wang, Jian
   Liu, Wenyuan
   Zhang, Shuai
TI Adaptive encryption of digital images based on lifting wavelet
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Adaptive wavelet; Chaotic map; Adaptive encryption
ID COMPRESSION; SCHEME
AB A large number of digital pictures have many security threats in the transmission on the Internet, and various encryption technologies for images have been proposed. The existing image encryption technology has a simple structure and a small key space, which cannot meet the requirement for image information security at this stage. In order to improve the effectiveness of image encryption and enhance the adaptive ability of image encryption, based on the theory of wavelet transform, chaos theory and adaptive encryption, this paper designs the overall framework of image encryption, and proposes a digital image adaptive encryption method based on lifting wavelet optimization. Firstly, the framework of image frequency domain adaptive encryption algorithm is designed, wavelet transform based on lifting is studied and analyzed, and lifting wavelet optimization method based on improved threshold method and particle swarm algorithm is given to improve the adaptability to image decomposition, so that the frequency domain coefficients obtained after wavelet decomposition can better represent the image content, thus making frequency domain encryption more targeted. Chaos mapping is used to encrypt the pixel gray value and scramble the pixel position of the decomposed low frequency coefficients of the image, thus achieving good image adaptive encryption.
C1 [Wang, Jian; Liu, Wenyuan; Zhang, Shuai] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Wang, Jian] First Hosp Qinhuangdao, Qinhuangdao 066000, Hebei, Peoples R China.
   [Zhang, Shuai] Hebei Normal Univ Sci & Technol, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Hebei Normal University of Science & Technology
RP Liu, WY (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM 15903363750@163.com
CR [Anonymous], 2000, TECHNOMETRICS, P323
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Hu H., 2016, COMMUN APPL MATH COM, V30, P156
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   Li X., 2011, P ENG, V15, P2118, DOI DOI 10.1016/j.proeng.2011.08.396
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Lv XP, 2018, MULTIMED TOOLS APPL, V77, P28633, DOI 10.1007/s11042-018-6013-6
   Ma XM, 2019, MULTIMED TOOLS APPL, V78, P8889, DOI 10.1007/s11042-018-6629-6
   Mallat S, 2009, BIOMETRICS, V65, P143
   Mallat SG, 2009, WAY, V31, P83
   Ren K, 2012, VIDEO ENG, V89, P131
   Roy T, 2019, COMMUN NONLINEAR SCI, V67, P162, DOI 10.1016/j.cnsns.2018.07.008
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tang L, 2017, INT J IMAG SYST TECH, V27, P57, DOI 10.1002/ima.22210
   Tang P, 2017, KNOWL INF SYST, V52, P509, DOI 10.1007/s10115-016-1015-z
   Uehara T, 2000, SECURING WAVELET COM
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Wang YM, 2012, ADV MATER RES-SWITZ, V403-408, P3054, DOI 10.4028/www.scientific.net/AMR.403-408.3054
   Wu YX, 2018, IEEE T CYBERNETICS, V48, P2809, DOI 10.1109/TCYB.2017.2750691
   Xingmin M, 2018, WIREL COMMUN MOB COM, V9, P1441
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yu X, 2018, IEEE T CYBERNETICS, V48, P2139, DOI 10.1109/TCYB.2017.2728120
NR 24
TC 7
Z9 7
U1 11
U2 107
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9363
EP 9386
DI 10.1007/s11042-019-7704-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600057
DA 2024-07-18
ER

EF