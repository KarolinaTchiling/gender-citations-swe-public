FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Begum, SS
   Lakshmi, DR
AF Begum, S. Salma
   Lakshmi, D. Rajya
TI Combining optimal wavelet statistical texture and recurrent neural
   network for tumour detection and classification over MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Wavelet statistical texture; Recurrent neural network;
   Feature extraction; Segmentation; Dominant run length; Co-occurrence
   texture features
ID SEGMENTATION; IMAGES; RECOGNITION; SELECTION; FEATURES
AB Brain tumor is one of the major causes of death among other types of the cancer because brain is a very sensitive, complex and central part of the body. Proper and timely diagnosis can prevent the life of a person to some extent. Therefore, in this paper, an efficient brain tumor detection system is proposed using combining optimal wavelet statistical texture features and recurrent neural network (RNN). The proposed system consists of four phases namely; feature extraction feature selection, classification and segmentation. First, noise removal is performed as the preprocessing step on the brain MR images. After that, texture features (both the dominant run length and co-occurrence texture features) are extracted from these noise free MR images. The high number of features is reduced based on oppositional gravitational search algorithm (OGSA). Then, selected features are given to the Recurrent Neural Network (RNN) classifier to classify an image as normal or abnormal. After the classification process, abnormal images are given to the segmentation stage to segment the ROI region with the help of modified region growing algorithm (MRG). The performance of the proposed methodology is analyzed in terms of different metrics and experimental results are compared with existing methods.
C1 [Begum, S. Salma] JNTUK Univ, Dept Comp Sci & Engn, Kakinada, India.
   [Lakshmi, D. Rajya] JNTUK, CSE, Narasaraopet, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Jawaharlal Nehru
   Technological University - Kakinada
RP Begum, SS (corresponding author), JNTUK Univ, Dept Comp Sci & Engn, Kakinada, India.
EM salmabegums2186@gmail.com
OI Davuluri, Rajya Lakshmi/0000-0002-8310-2760; shaik, salma
   begum/0000-0002-0939-8495
CR Acir N, 2006, ENG APPL ARTIF INTEL, V19, P209, DOI 10.1016/j.engappai.2005.08.004
   Ain Q, 2014, APPL SOFT COMPUT, V21, P330, DOI 10.1016/j.asoc.2014.03.019
   Akay MF, 2009, EXPERT SYST APPL, V36, P3240, DOI 10.1016/j.eswa.2008.01.009
   Almuallim H., 1991, AAAI-91. Proceedings Ninth National Conference on Artificial Intelligence, P547
   [Anonymous], 2013, INT J COMPUTER SCI E
   [Anonymous], 2012, INT J COMPUT SCI INF, DOI DOI 10.47893/IJCSI.2012.1075
   [Anonymous], 2009, ICGST GVIP J
   Bankman IN, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P1
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P307
   Biji CL, 2011, COMM COM INF SC, V193, P300
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Borden Neil M., 2011, PATTERN RECOGNITION
   Cho S.B., 2003, P 1 AS PAC BIOINF C, V19, P189
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Hamamci A, 2012, IEEE T MED IMAGING, V31, P790, DOI 10.1109/TMI.2011.2181857
   Hsieh TM, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-54
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Jiang J, 2013, COMPUT MED IMAG GRAP, V37, P512, DOI 10.1016/j.compmedimag.2013.05.007
   Jong K, 2004, P EUR C MACH LEARN P
   Karabatak M, 2009, EXPERT SYST APPL, V36, P3465, DOI 10.1016/j.eswa.2008.02.064
   Kavitha A. R., 2019, International Journal of Business Intelligence and Data Mining, V15, P71
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Krishna Murali, 2013, INT C SIGN PROC IM P
   Kumar P., 2015, MIDDLE-EAST J SCI RE, V23, P2106, DOI DOI 10.5829/idosi.mejsr.2015.23.09.22458
   Li Darden, 2001, COMBINATIONAL CHEM H, V4, P727, DOI DOI 10.2174/1386207013330733
   Luo L, 2012, BMC NEPHROL, V13, DOI 10.1186/1471-2369-13-53
   Nanthagopal AP, 2013, IET IMAGE PROCESS, V7, P25, DOI 10.1049/iet-ipr.2012.0073
   Osareh A, 2011, IJCSI INT J COMPUTER, V8
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Preethi S, 2017, J INTELLEGENT SYSTEM
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Saha BN, 2012, COMPUT MED IMAG GRAP, V36, P95, DOI 10.1016/j.compmedimag.2011.06.001
   Sapra Pankaj, 2013, INT J SCI MODERN ENG, V1
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Tan AC., 2003, Appl Bioinformatics, V2, pS75, DOI DOI 10.1186/1471-2105-9-275
   Valentini G, 2004, NEUROCOMPUTING, V56, P461, DOI 10.1016/j.neucom.2003.09.001
   Wang Z. J., 2004, P SPIE
   Zhang YL, 2005, INT J ADV MANUF TECH, V25, P1191, DOI 10.1007/s00170-003-1942-1
NR 41
TC 29
Z9 30
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14009
EP 14030
DI 10.1007/s11042-020-08643-w
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515931100003
DA 2024-07-18
ER

PT J
AU Yahia, S
   Said, S
   Zaied, M
AF Yahia, Siwar
   Said, Salwa
   Zaied, Mourad
TI A novel classification approach based on Extreme Learning Machine and
   Wavelet Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Extreme Learning machine; Wavelet neural networks; Data
   classification; Fast wavelet transform
ID BREAST-CANCER DIAGNOSIS; ALGORITHM; FEATURES; SCHEME
AB In this paper, we present a novel classification approach based on Extreme Learning Machine (ELM) and Wavelet Neural Networks. We introduce two novel contributions. The first is Extreme Learning Machine based on Fast Wavelet Transform (ELM-FWT) algorithm aiming to solve the problem of matrix inversion which represents several limitations to ELM method. The second contribution is dedicated to solving another problem of machine learning algorithms, i.e. the number of neurons in the hidden nodes. It consists in allocating automatically and efficiently the number of neurons in the hidden layer. To demonstrate the effectiveness of our proposal, we realized numerous experiments and comparisons using 19 algorithms from Breast Cancer Wisconsin database which are considered as references in machine learning. Experimental results clearly demonstrate the stability and robustness of the proposed approach.
C1 [Yahia, Siwar; Said, Salwa; Zaied, Mourad] Univ Gabes, Natl Engn Sch Gabes, RTIM, Gabes, Tunisia.
C3 Universite de Gabes
RP Yahia, S (corresponding author), Univ Gabes, Natl Engn Sch Gabes, RTIM, Gabes, Tunisia.
EM yahiasiwar@yahoo.fr; salwa.said@ieee.org; mourad.zaied@ieee.org
OI Said, Salwa/0009-0005-3260-5949
CR Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Agarap AFM, 2015, 2ND INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2018), P5, DOI 10.1145/3184066.3184080
   Albadra MAA, 2017, INT J APPL ENG RES, V12, P4610, DOI DOI 10.37622/000000
   Asri H, 2016, PROCEDIA COMPUT SCI, V83, P1064, DOI 10.1016/j.procs.2016.04.224
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Fernández-Delgado M, 2014, NEURAL NETWORKS, V50, P60, DOI 10.1016/j.neunet.2013.11.002
   Hamsagayathri P, 2017, Int J Curr Pharm Res, V9, P19, DOI [10.22159/ijcpr.2017v9i2.17383, DOI 10.22159/ijcpr.2017v9i2.17383]
   Hoang A, 1997, SUPERVISED CLASSIFIE
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Iosifidis A, 2017, NEURAL PROCESS LETT, V45, P577, DOI 10.1007/s11063-016-9541-y
   Jemai O., 2010, IJCNN, P1
   Jemai O, 2011, INT J PATTERN RECOGN, V25, P1297, DOI 10.1142/S0218001411009111
   Kumar UK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P108, DOI 10.1109/ICSTM.2017.8089135
   Latchoumi TP, 2017, BIOMEDICAL RES, V28, P0970
   Leng Q, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/412957
   Li S, 2016, IEEE T CYBERNETICS, V46, P1229, DOI 10.1109/TCYB.2015.2434841
   MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570
   Osman AH, 2017, INT J ADV COMPUT SC, V8, P158
   Pal Shankho Subhra, 2018, International Journal of Applied Industrial Engineering, V5, P21, DOI 10.4018/IJAIE.2018070102
   Pourtaghi A, 2012, TUNN UNDERGR SP TECH, V28, P257, DOI 10.1016/j.tust.2011.11.008
   Rajesh R., 2011, International Journal of Wisdom Based Computing, P35
   Utomo Chandra Prasetyo, 2014, International Journal of Advanced Research in Artificial Intelligence, V3, P10
   WOLBERG WH, 1994, CANCER LETT, V77, P163, DOI 10.1016/0304-3835(94)90099-X
   Yahia S, 2017, 9 INT C MACH VIS ICM, V10341, p103412K
   Zaied M, 2011, INT J WAVELETS MULTI, V9, P923, DOI 10.1142/S0219691311004389
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
NR 30
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13869
EP 13890
DI 10.1007/s11042-019-08248-y
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000511062200002
DA 2024-07-18
ER

PT J
AU Fooladgar, F
   Kasaei, S
AF Fooladgar, Fahimeh
   Kasaei, Shohreh
TI A survey on indoor RGB-D semantic segmentation: from hand-crafted
   features to deep convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-Depth images; Semantic segmentation; Deep learning; Hand-crafted
   features
ID IMAGE SEGMENTATION
AB Semantic segmentation is one of the most important tasks in the field of computer vision. It is the main step towards scene understanding. With the advent of RGB-Depth sensors, such as Microsoft Kinect, nowadays RGB-Depth images are easily available. This has changed the landscape of some tasks such as semantic segmentation. As the depth images are independent of illumination, the combination of depth and RGB images can improve the quality of semantic labeling. The related research has been divided into two main categories, based on the usage of hand-crafted features and deep learning. Although the state-of-the-art results are mainly achieved by deep learning methods, traditional methods have also been at the center of attention for some years and lots of valuable work have been done in that category. As the field of semantic segmentation is very broad, in this survey, a comprehensive analysis has been carried out on RGB-Depth semantic segmentation methods, their challenges and contributions, available RGB-Depth datasets, metrics of evaluation, state-of-the-art results, and promising directions of the field.
C1 [Fooladgar, Fahimeh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Kasaei, Shohreh] Sharif Univ Technol, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Tehran, Iran.
EM fahimehfooladgar@ce.sharif.edu; kasaei@sharif.edu
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2018, ARXIV180501556
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], 2013, 3 WORKSH SEM PERC MA
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banica D, 2015, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2015.7298974
   Bo L., 2010, ADV NEURAL INFORM PR, V23, P244
   Chang Angel, 2017, 3DV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Couprie C., 2013, ARXIV13013572, P1
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Fooladgar F., 2015, 2015 INT C DIGITAL I, P1
   Fooladgar F, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P176, DOI 10.1109/IranianMVIP.2015.7397531
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kendall A., 2015, ARXIV 151102680
   Kindermann R., 1980, Markov random fields and their applications, V547, DOI DOI 10.1090/CONM/001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714
   Liu H, 2018, MULTIMED TOOLS APPL, V77, P22475, DOI 10.1007/s11042-018-6056-8
   Liu W., 2015, ARXIV150604579
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   McCormac J, 2017, IEEE I CONF COMP VIS, P2697, DOI 10.1109/ICCV.2017.292
   Müller AC, 2014, IEEE INT CONF ROBOT, P6232, DOI 10.1109/ICRA.2014.6907778
   NASEER M, 2018, ARXIV180303352
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Reynolds J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P175, DOI 10.1109/CRV.2007.32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabour S, 2017, ADV NEUR IN, V30
   Savarese S., 2017, Joint 2d-3d-semantic data for indoor scene understanding
   Seyedhosseini M, 2016, IEEE T PATTERN ANAL, V38, P951, DOI 10.1109/TPAMI.2015.2473846
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, 14091556 ARXIV
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song X, 2018, Multimed Tools Appl, P1
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Stückler J, 2015, J REAL-TIME IMAGE PR, V10, P599, DOI 10.1007/s11554-013-0379-5
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Yang Michael Ying, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P196, DOI 10.1109/ICCVW.2011.6130243
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zheng S, 2014, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2014.411
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
NR 68
TC 20
Z9 22
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4499
EP 4524
DI 10.1007/s11042-019-7684-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500015
DA 2024-07-18
ER

PT J
AU Ganesan, R
   Chamundeeswari, VV
AF Ganesan, R.
   Chamundeeswari, V.
TI Composite algorithm for pervasive healthcare system - a solution to find
   optimized route for closest available health care facilities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geographic information system; Android operating system; Health care
   system; Pervasive system; Google API
ID SERVICES; MODEL
AB There are many solutions available for healthcare issues, like increasing the Qos, Handling multimedia data, providing Security, compressing multimedia files, finding a shortest path, etc. This paper addresses the problem pertaining to finding the optimized route for closest available healthcare facilities. Location Based Services (LBS) in healthcare has been widely used to deliver detailed information like availability of health care facility, finding location, navigation and etc. However, in some places, the use of LBS in healthcare is limited because of lack of resources or information for getting timely information to users or patients who need health care services. The problem that can be detected is that the vital information needed by the patients or users such as the availability of health care facilities like pharmacy, hospital, clinic, blood bank, etc. has to be seamlessly reached. This work focus to solve the problem by creating a application for patients to get the information about nearest health care facilities by using any android based mobile phone. The proposed system uses composite algorithm. Composite algorithm comprises of three algorithms namely, Information Retrieval R-Tree (IR2) algorithm for filtering process, K-Nearest Neighbour (KNN) query Technique for path and distance verification and Ahuja- Dijkstras algorithm to find optimized path. The information have taken from the Google web server (real time data) by using Google API, We have collected more than 1000 data pertaining to healthcare facilities like longitude latitude, speciality, contact details and etc. This system was developed by Android OS. The algorithm running at this system was very efficient of about 20% from the existing system. This work tries to focus on algorithm for lower time-complexity (O(logn)) and for more speed up processing.
C1 [Ganesan, R.; Chamundeeswari, V.] Velammal Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Velammal Engineering College
RP Ganesan, R (corresponding author), Velammal Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM rganesan1978@gmail.com
RI Chamundeeswari, Vijaya/GMX-4394-2022
OI Ramasamy, Ganesan/0000-0002-9125-0114; Chamundeeswari,
   Vijaya/0000-0001-6624-9042
CR Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   Abu-Mahfouz A, 2013, IEEE T IND INFORM, V9, P16, DOI 10.1109/TII.2012.2218252
   [Anonymous], NEURAL COMPUTING APP
   [Anonymous], IJCSI INT J COMPUT S
   [Anonymous], FUTURE GEN COMPUT SY
   [Anonymous], ELSEVIER EXPERT SYST
   [Anonymous], PERSONAL UBIQUITOUS
   [Anonymous], INT J ADV ENG TECHNO
   [Anonymous], INT J GEOMAT GEOSCI
   [Anonymous], IEEE INT C GREEN COM
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], J GEOGRAPH INFO SYST
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], INT J INNOV SCI MODE
   [Anonymous], IEEE ASME T MECHATRO
   [Anonymous], J AMBIENT INTEL HUMA
   Dalal VL, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Drawil NM, 2013, IEEE T INTELL TRANSP, V14, P262, DOI 10.1109/TITS.2012.2213815
   Edward J, 2017, J RACIAL ETHN HEALTH, V4, P297, DOI 10.1007/s40615-016-0229-9
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gandhi UD, 2018, WIRELESS PERS COMMUN, V103, P1179, DOI 10.1007/s11277-018-5307-3
   Jing YN, 2014, IEEE T KNOWL DATA EN, V26, P1494, DOI 10.1109/TKDE.2013.174
   Kumar P. M., 2017, J SUPERCOMPUT, P1
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Lokhman Mohamad Taufik, 2012, Proceedings of the 2012 IEEE Control and System Graduate Research Colloquium (ICSGRC 2012), P267, DOI 10.1109/ICSGRC.2012.6287174
   Manogaran Thota., 2018, HCI CHALLENGES PRIVA, P1, DOI DOI 10.4018/978-1-5225-2863-0.CH001
   Mathew KS, 2018, SHIPBUILDING, NAVIGATION AND THE PORTUGUESE IN PRE-MODERN INDIA, P1
   Navaneethakkannan C, 2013, INT CONF COMP COMMUN
   Rawal BS, WIRELESS PERSONAL CO, P1
   Rojas E, 2016, J BIOMED INFORM, V61, P224, DOI 10.1016/j.jbi.2016.04.007
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Wu CC, 2014, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2014.11
   Zhang Y, 2017, IEEE SYST J, V11, P88, DOI 10.1109/JSYST.2015.2460747
NR 34
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5125
EP 5148
DI 10.1007/s11042-018-6136-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500051
DA 2024-07-18
ER

PT J
AU Shi, L
   Zheng, MG
   Li, FY
AF Shi, Lei
   Zheng, Minggang
   Li, Fuyou
TI RETRACTED: The energy management strategy for parallel hybrid electric
   vehicles based on MNN (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Parallel hybrid electric vehicle; Dynamic programming; Multi neural
   network; Kernel fuzzy c-means clustering; Energy management strategy
AB The energy management of the hybrid electric vehicle is still the research hotspot. In order to improve the fuel economy of the parallel hybrid electric vehicle, a new energy management design method based on the kernel fuzzy C clustering (KFCM) for multi neural network (MNN) is proposed. The global optimal solution is obtained by the dynamic programming global optimization off-line simulation, and the KFCM algorithm is used to cluster the global optimal data set according to the vehicle running mode, and the neural network is established for each cluster. The MNN model structure after training is used as the output of the energy management strategy to realize the real-time optimal allocation of engine and motor torque according to the real-time condition. The simulation results show that the energy management strategy based on KFCM-MNN has good learning simulation ability for dynamic planning energy management strategy, and it is a quasi-optimal control strategy.
C1 [Shi, Lei; Zheng, Minggang] Shandong Jianzhu Univ, Mech & Elect Engn, Jinan, Peoples R China.
   [Li, Fuyou] Univ Sheffield, Elect & Elect Engn, Sheffield, S Yorkshire, England.
C3 Shandong Jianzhu University; University of Sheffield
RP Zheng, MG (corresponding author), Shandong Jianzhu Univ, Mech & Elect Engn, Jinan, Peoples R China.
EM why1318@sdjzu.edu.cn
OI Li, Fuyou/0000-0001-8168-5475
CR Gupta V, 2014, HCTL OPEN INT J TECH, V10, P2321
   Huang YJ, 2009, INT J AUTO TECH-KOR, V10, P513, DOI 10.1007/s12239-009-0059-4
   Kitayama S, 2015, STRUCT MULTIDISCIP O, V52, P595, DOI 10.1007/s00158-015-1254-8
   Liang JY, 2013, J ZHEJIANG UNIV-SC A, V14, P535, DOI 10.1631/jzus.A1300068
   Wu Jian, 2008, Control and Decision, V23, P46
   Wu SF, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415400398
   [肖仁鑫 Xiao Renxin], 2013, [汽车工程, Automotive Engineering], V35, P317
   Zhang Y, 2014, IEEE T VEH TECHNOL, V63, P603, DOI 10.1109/TVT.2013.2276432
NR 8
TC 16
Z9 18
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5321
EP 5333
DI 10.1007/s11042-018-6317-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500062
DA 2024-07-18
ER

PT J
AU Aymaz, S
   Köse, C
   Aymaz, S
AF Aymaz, Samet
   Kose, Cemal
   Aymaz, Seyma
TI Multi-focus image fusion for different datasets with super-resolution
   using gradient-based new fusion rule
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus; Super-resolution; New dataset; Image fusion; SWT; Sobel;
   New fusion rule
ID ALGORITHM; TRANSFORM; NETWORKS; DEPTH
AB Multi-focus image fusion methods combine two or more images which have blurred and defocused parts to create an all-in-focused image. All-in-focused image has more information, clearer parts and clearer edges than the source images. In this paper, a new approach for multi-focus image fusion is proposed. Firstly, the information of source images is enhanced using bicubic interpolation-based super-resolution method. Secondly, source images with high resolution are decomposed into four sub-bands which are LL (low-low), LH (low-high), HL (high-low) and HH (high-high) using Stationary Wavelet Transform with dmey (Discrete Meyer) filter. Then, a new fusion rule which depend on gradient-based method with sobel operator is implemented to create fused images with good visuality. The weight coefficients which show the importance rates of corresponding pixels in source images for fused image are calculated using designed formula based on gradient magnitudes. The each pixel of fused sub-bands is created using these weight coefficients and fused image is reconstructed using Inverse Stationary Wavelet Transform. Lastly, the performance evaluation of proposed method is measured using three different metrics which are objective, subjective and time criterion metrics. Besides these features, the new dataset which is different from the datasets in the literature is created and used firstly in this paper. The results show that the proposed method produces high quality images with clear edges and transmits most of the information of source images into all-in-focused image.
C1 [Aymaz, Samet; Kose, Cemal; Aymaz, Seyma] Karadeniz Tech Univ, Trabzon, Turkey.
C3 Karadeniz Technical University
RP Aymaz, S (corresponding author), Karadeniz Tech Univ, Trabzon, Turkey.
EM samet.aymaz@saglik.gov.tr
RI KÖSE, Cemal/V-9731-2017; Aymaz, Samet/ABE-7361-2021; aymaz,
   şeyma/JEP-5707-2023; Aymaz, Şeyma/AAW-5250-2020
OI KÖSE, Cemal/0000-0002-5982-4771; 
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Anandhi D, 2018, COMPUT ELECTR ENG, V65, P139, DOI 10.1016/j.compeleceng.2017.04.002
   Aymaz S, 2019, INFORM FUSION, V45, P113, DOI 10.1016/j.inffus.2018.01.015
   Chaudhary V, 2018, SIGNAL IMAGE VIDEO P, V12, P271, DOI 10.1007/s11760-017-1155-y
   Chen C, 2015, MULTIFOCUSIMAGE FUSI
   Du CB, 2019, OPTIK, V176, P567, DOI 10.1016/j.ijleo.2018.09.089
   Du CB, 2018, OPTIK, V157, P1003, DOI 10.1016/j.ijleo.2017.11.162
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Fu W, 2016, METHODSX, V3, P87, DOI 10.1016/j.mex.2015.12.004
   Garnico-Carrillo A, 2018, SIGNAL
   Guo D, 2015, OPT COMMUN, V338, P138, DOI 10.1016/j.optcom.2014.10.031
   He K, 2018, METHODOLOGIES APPL, V127
   He KJ, 2019, SOFT COMPUT, V23, P4685, DOI 10.1007/s00500-018-3118-9
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Hua KL, 2014, J VIS COMMUN IMAGE R, V25, P951, DOI 10.1016/j.jvcir.2014.02.009
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Jiang Q., 2016, NEUROCOMPUTING, V174, P733, DOI [10.1016/j.neucom.2015.09.092, DOI 10.1016/J.NEUCOM.2015.09.092]
   Li HF, 2016, INFORM SCIENCES, V349, P25, DOI 10.1016/j.ins.2016.02.030
   Li HF, 2012, OPT COMMUN, V285, P91, DOI 10.1016/j.optcom.2011.08.078
   Liu Y, 2018, VISUAL COMPUT, V34, P589, DOI 10.1007/s00371-017-1363-z
   LU J, 2012, RES J APPL SCI ENG T, V4, P3905
   Mirulanni K, 2017, INT C ADV COMP COMM
   Moushmi S, 2016, ADV INTELLIGENT SYST
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Sharma Mamta, 2016, INT J COMPUTER APPL, V152, P30, DOI [10.5120/ijca2016911861, DOI 10.5120/IJCA2016911861]
   Shinde A, 2017, INT J CONTROL THEORY, V10
   Shukla J, 2018, BIOMED SIGNAL PROCES, V42, P45, DOI 10.1016/j.bspc.2018.01.009
   Stramaglia S, 2017, MULTISCALE GRANGER C
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tuna C, 2018, INT J REMOTE SENS, V39, P2463, DOI 10.1080/01431161.2018.1425561
   Vijitha B., 2016, INT J RES COMPUT APP, V4, P36
   Yang Y, 2014, JVISCOMMUNMAGE R, V25, P951
   Yin HP, 2016, NEUROCOMPUTING, V216, P216, DOI 10.1016/j.neucom.2016.07.039
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang XL, 2016, SIGNAL PROCESS, V123, P127, DOI 10.1016/j.sigpro.2016.01.006
   Zhang YX, 2019, SIGNAL IMAGE VIDEO P, V13, P727, DOI 10.1007/s11760-018-1402-x
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 40
TC 20
Z9 20
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13311
EP 13350
DI 10.1007/s11042-020-08670-7
EA JAN 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000518165600001
DA 2024-07-18
ER

PT J
AU Sarkar, R
   Choudhury, S
   Dutta, S
   Roy, A
   Saha, SK
AF Sarkar, Rajib
   Choudhury, Sombuddha
   Dutta, Saikat
   Roy, Aneek
   Saha, Sanjoy Kumar
TI Recognition of emotion in music based on deep convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music emotion recognition; Convolutional neural network; Deep learning;
   Audio features
ID SPEECH; FEATURES
AB In the domain of music information retrieval, emotion based classification is an active area of research. Emotion being a perceptual and subjective concept, the task is quite challenging. It is very difficult to design signal based descriptors to represent emotions. In this work deep leaning network is proposed and experiment is done with benchmark datasets namely, Soundtracks, Bi-Modal and MER_taffc. Experiment has also been done with hand crafted descriptor consisting of different time domain and spectral features, linear predictive coding and MFCC based features. Different classifiers like, neural network, support vector machine and random forest are tried. Although the combined feature set with neural network provides an optimal result for the datasets, but in general the performance of such approaches is limited. It is difficult to obtain a consistent feature set that works across the classifier and datasets. To get rid of the issue of feature design, deep learning based approach is followed. A convolutional neural network built around VGGNet and a novel post-processing technique are proposed. Proposed methodology provides substantial improvement of performance for the datasets. Comparison with other reported works on three different datasets also establishes the superiority of the proposed methodology. The improvement in performance has been substantiated by Z test.
C1 [Sarkar, Rajib; Choudhury, Sombuddha; Dutta, Saikat; Roy, Aneek; Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Sarkar, Rajib] Derozio Mem Coll, Dept Comp Sci, Kolkata 700136, India.
C3 Jadavpur University; Derozio Memorial College
RP Sarkar, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.; Sarkar, R (corresponding author), Derozio Mem Coll, Dept Comp Sci, Kolkata 700136, India.
EM rjbskar@gmail.com; sombuddha.choudhury@gmail.com;
   saikat.dutta779@gmail.com; aneek.roy5@gmail.com; sks_ju@yahoo.in
OI Sarkar, Rajib/0000-0002-7498-1628; Dutta, Saikat/0000-0001-6021-5407
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Albornoz EM, 2014, LECT NOTES COMPUT SC, V8827, P104, DOI 10.1007/978-3-319-12568-8_13
   [Anonymous], 2018, IEEE T AFFECTIVE COM
   [Anonymous], INT WORKSH MUS MACH
   [Anonymous], MEDIAEVAL
   [Anonymous], 2015, Language Identification Using Spectral and Prosodic Features
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2013, MEDIAEVAL
   [Anonymous], 2010, 11 INT SOC MUS INF R
   [Anonymous], INT SOC MUSIC INFORM
   [Anonymous], 2017, ARXIV170405665
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], J NEUROLOGY NEUROSCI
   [Anonymous], 2012, ACM T INTEL SYST TEC, DOI DOI 10.1145/2168752.2168754
   [Anonymous], ELEMENTS STAT LEARNI
   [Anonymous], 2002, STAT INFERENCE
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cabrera D., 1999, Australian Acoustical Society Conference, V24, P47
   Chollet F, 2015, KERAS
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P478, DOI 10.1145/3123266.3123371
   Droit-Volet S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00417
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Gabrielsson A., 2001, The influence of musical structure on emotional expression
   Gharavian D, 2017, MULTIMED TOOLS APPL, V76, P2331, DOI 10.1007/s11042-015-3180-6
   Goldberg Yoav., 2017, Synthesis Lectures on Human Language Technologies
   Han B.-j., 2009, ISMIR, P651
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hassan A, 2013, IEEE T AUDIO SPEECH, V21, P1458, DOI 10.1109/TASL.2013.2255278
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Huq A, 2010, J NEW MUSIC RES, V39, P227, DOI 10.1080/09298215.2010.513733
   Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Kingma D. P., 2014, arXiv
   Krumhansl CL, 2002, CURR DIR PSYCHOL SCI, V11, P45, DOI 10.1111/1467-8721.00165
   Lerch Alexander, 2012, An introduction to audio content analysis: Applications in signal processing and music informatics
   Lin YC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037683
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Lu Qi., 2010, 11th International Society for Music Information and Retrieval Conference, P105
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Minsky M., 1969, Perceptrons
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nordström H, 2019, J ACOUST SOC AM, V145, P3058, DOI 10.1121/1.5108601
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saari P, 2011, IEEE T AUDIO SPEECH, V19, P1802, DOI 10.1109/TASL.2010.2101596
   Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thammasan N, 2016, IEEE IJCNN, P881, DOI 10.1109/IJCNN.2016.7727292
   Thayer R.E., 1990, BIOPSYCHOLOGY MOOD A, V1
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Tzanetakis G., 2000, Organised Sound, V4, P169, DOI DOI 10.1017/S1355771800003071
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yeh CH, 2014, MULTIMED TOOLS APPL, V73, P2103, DOI 10.1007/s11042-013-1687-2
   Zao L, 2014, IEEE SIGNAL PROC LET, V21, P620, DOI 10.1109/LSP.2014.2311435
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang F, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1728, DOI 10.1109/FSKD.2016.7603438
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 67
TC 35
Z9 38
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 765
EP 783
DI 10.1007/s11042-019-08192-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600031
DA 2024-07-18
ER

PT J
AU Zhang, ZC
   Cohen, F
AF Zhang, Zhongchuan
   Cohen, Fernand
TI 3D pedestrian tracking and frontal face image capture based on head
   point detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D head position detection; Pedestrian tracking; Overhead camera;
   Crowded scene; Facial image capture; Pan-tilt-zoom camera scheduling
ID MULTIVIEW APPROACH; MEAN SHIFT; PEOPLE
AB This paper proposes a method to track pedestrians in crowded scenes and capture the close-up frontal face images of a person of interest (POI) for recognition. Pedestrians are tracked via 3D positions of the head points (the highest point of a person) using 2 static overhead cameras. Head points are located and tracked based on the geometric and color cues in the scene. Possible head areas in a frame acquired from one of the overhead cameras are determined based on projective geometry. Head areas belonging to a person are clustered. Without creating a full disparity map of the scene, the 3D position of a pedestrian is obtained by utilizing the disparity along the line segment that passes through his/her head top. The 3D head position is then tracked using common assumptions on motion velocity. If the tracking is not accurate enough, the color distribution of a head top is integrated as a complementary method. With the 3D head point information, a set of pan-tilt-zoom (PTZ) cameras are scheduled to capture the frontal face images of POI. A most suitable PTZ camera is selected by evaluating the capture quality of each PTZ camera and its current state. The approach is tested using a publicly available visual surveillance simulation test bed. The experiments show that the 3D tracking errors are around 4 cm and high quality frontal face images are captured.
C1 [Zhang, Zhongchuan] Appl Mat Inc, Santa Clara, CA 95054 USA.
   [Cohen, Fernand] Drexel Univ, Elect & Comp Engn Dept, Philadelphia, PA 19104 USA.
C3 Applied Materials Inc; Drexel University
RP Zhang, ZC (corresponding author), Appl Mat Inc, Santa Clara, CA 95054 USA.
EM zhongchuan_zhang@amat.com; fscohen@coe.drexel.edu
OI Zhang, Zhongchuan/0000-0001-5413-2103
CR [Anonymous], IEEE INT 1 C IM PROC
   [Anonymous], INT VIS INF C
   [Anonymous], AS C COMP VIS
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   Boltes M, 2013, NEUROCOMPUTING, V100, P127, DOI 10.1016/j.neucom.2012.01.036
   Boltes M, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P43, DOI 10.1007/978-3-642-04504-2_3
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Del Bimbo A, 2006, PATTERN RECOGN LETT, V27, P1826, DOI 10.1016/j.patrec.2006.02.014
   Delannay D, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P15
   Eshel R., 2008, IEEE C COMPUT VIS PA, P1
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hampapur A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P13, DOI 10.1109/AVSS.2003.1217896
   Jin ZX, 2015, COMPUT VIS IMAGE UND, V134, P48, DOI 10.1016/j.cviu.2014.10.001
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kawanaka H, 2006, INT C PATT RECOG, P826
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Marchesotti L, 2003, IEEE IMAGE PROC, P681
   Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Ozturk Ovgu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1020, DOI 10.1109/ICCVW.2009.5457590
   Prince SJD, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P439
   Qureshi FZ, 2006, MULTIMEDIA SYST, V12, P269, DOI 10.1007/s00530-006-0059-4
   Rougier C, 2013, IMAGE VISION COMPUT, V31, P246, DOI 10.1016/j.imavis.2012.11.003
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Santos TT, 2011, PATTERN RECOGN LETT, V32, P47, DOI 10.1016/j.patrec.2010.05.016
   Sasi RK, 2016, ENG SCI TECHNOL, V19, P1067, DOI 10.1016/j.jestch.2016.01.001
   Taylor GR, 2007, PROC CVPR IEEE, P3883
   van Oosterhout Tim, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P404
   van Oosterhout T, 2015, MACH VISION APPL, V26, P561, DOI 10.1007/s00138-015-0678-x
   van Oosterhout T, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P620
   Veksler O, 2003, PROC CVPR IEEE, P556
   Vincent L., 1993, 1 WORKSH MATH MORPH, P22
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xu YZ, 2010, 2010 INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION AND 2010 ASIA-PACIFIC CONFERENCE ON INFORMATION TECHNOLOGY AND OCEAN ENGINEERING: CICC-ITOE 2010, PROCEEDINGS, P366, DOI 10.1109/CICC-ITOE.2010.104
   Zhang YB, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P113
   Zhang ZF, 2013, SCI REP-UK, V3, DOI [10.1038/srep01327, 10.1038/srep01066]
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
   Zhongchuan Zhang, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P382
NR 47
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 737
EP 764
DI 10.1007/s11042-019-08121-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600030
DA 2024-07-18
ER

PT J
AU Zhou, W
   Jia, JY
AF Zhou, Wen
   Jia, Jinyuan
TI Training deep convolutional neural networks to acquire the best view of
   a 3D shape
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiviewpoints; Best view; Convolutional neural networks; Transfer
   learning; Sketch-based model retrieval
ID SKETCH; RETRIEVAL
AB In a 3D shape retrieval system, when attempting to select the best view from many view images, the ability to project a 3D shape into related view images from multiple viewpoints is important. Furthermore, learning the best view from benchmark sketch datasets is one of the best approaches to acquire the best view of a 3D shape. In this paper, we propose a learning framework based on deep neural networks to obtain the best shape views. We apply transfer learning to obtain features, i.e., we use two Alex convolutional neural networks (CNNs) for feature extraction: one for the view images and the other for the sketches. Specifically, the connections to learn an automatic best-view selector for different types of 3D shapes are obtained through the proposed learning framework. We perform training on the Shape Retrieval Contest's 2014 Sketch Track Benchmark (SHREC'14) to capture the related rules. Finally, we report experiments to demonstrate the feasibility of our approach. In addition, to better evaluate our proposed framework and show its superiority, we apply our proposed approach to a sketch-based model retrieval task, where it outperforms other state-of-the-art methods.
C1 [Zhou, Wen] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Anhui, Peoples R China.
   [Jia, Jinyuan] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
C3 Anhui Normal University; Tongji University
RP Zhou, W (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Anhui, Peoples R China.
EM w.zhou@ahnu.edu.cn
OI ZHOU, WEN/0000-0002-1266-1864
FU National Natural Science Foundation of China (NSFC) [61902003]; Key
   Research Projects of Central University of Basic Scientific Research
   Funds for Cross Cooperation [201510-02]; Research Funds for the Doctoral
   Program of Higher Education of China [2013007211-0035]; Key Project in
   Science and Technology of Jilin Province of China [20140204088GX];
   Doctoral Scientific Research Foundation of Anhui Normal University
FX The authors appreciate the comments and suggestions of all the anonymous
   reviewers, whose comments helped us to significantly improve this paper.
   This work is supported in part by National Natural Science Foundation of
   China (NSFC Grant No. 61902003), The Key Research Projects of Central
   University of Basic Scientific Research Funds for Cross Cooperation
   (Grant No. 201510-02), Research Funds for the Doctoral Program of Higher
   Education of China (Grant No. 2013007211-0035), the Key Project in
   Science and Technology of Jilin Province of China (Grant No.
   20140204088GX) and the Doctoral Scientific Research Foundation of Anhui
   Normal University.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2014, P EG3DOR 2014
   [Anonymous], 2011, Advances in Neural Information Processing Systems
   Chang AX, 2016, ARXIV151203012
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Dutagaci H., 2010, P ACM WORKSH 3D OBJ, P45, DOI DOI 10.1145/1877808.1877819
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Giorgi D, 2010, P ACM WORKSH 3D OBJ, P9
   Hinton G. E., 2012, 12070580 ARXIV
   Kim SH, 2017, COMPUT GRAPH FORUM, V36, P313, DOI 10.1111/cgf.13082
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laga H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516975
   Laga Hamid., 2008, J SOC ART SCI, V7, P124
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Liu H, 2012, VISUAL COMPUT, V28, P279, DOI 10.1007/s00371-011-0638-z
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   Ma C, 2016, IMAGE VISION COMPUT, V46, P64, DOI 10.1016/j.imavis.2015.11.007
   Mortara M, 2009, COMPUT GRAPH-UK, V33, P280, DOI 10.1016/j.cag.2009.03.003
   Shao TJ, 2011, COMPUT GRAPH FORUM, V30, P2011, DOI 10.1111/j.1467-8659.2011.02050.x
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Shtrom E, 2013, IEEE I CONF COMP VIS, P3591, DOI 10.1109/ICCV.2013.446
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tatsuma A., 2012, Signal Information Processing Association Annual Summit and Conference (APSIPA ASC), 2012 Asia-Pacific, P1
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Xie J, 2017, PROC CVPR IEEE, P3615, DOI 10.1109/CVPR.2017.385
   Xie J, 2016, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2016.360
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Yamauchi H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P265
   Yih Wen-tau, 2011, P 15 C COMPUTATIONAL, P247
   Zhao L, 2015, VISUAL COMPUT, V31, P765, DOI 10.1007/s00371-015-1091-1
   Zhou W, 2017, DESTECH T COMPUTER S
   Zhou W, 2019, PATTERN RECOGN LETT, V117, P119, DOI 10.1016/j.patrec.2018.09.005
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
NR 42
TC 1
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 581
EP 601
DI 10.1007/s11042-019-08107-w
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600023
DA 2024-07-18
ER

PT J
AU Halabi, O
AF Halabi, Osama
TI Immersive virtual reality to enforce teaching in engineering education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Interactive learning environments; 3D modeling;
   Project-based learning; First-year students
AB Prior studies on the use of digital prototyping and virtual reality (VR) in designing as well as evaluating new products have shown that VR reduces both development time and costs whilst augmenting student motivation and creativity. The current study demonstrates that VR and 3D prototyping in the context of project-based learning (PBL) promote effective communication, increase problem solving skills, and enhance learning outcomes. VR and digital prototyping have been extensively used in industries for the purpose of product design and usability evaluation. In the context of engineering education, many research studies have attempted to explore the effect of VR on teamwork, engagement, retention, and motivation. In this paper, VR is used in conjunction with PBL in self-directed approach to design and implement a product using 3D software whilst also using virtual reality immersive CAVE display to evaluate their design. The hypothesis is that the use of VR with a project-based-learning approach to facilitate the attainment of desirable goals in the engineering design project, improved achievement of course learning outcomes and promoted effective communication. According to the research findings, VR approach significantly affected the distribution of cumulative project grades. Students' project grades improved, particularly the implementation component. In addition, the course outcomes related to project design were better achieved in VR approach. The communication and problem-solving skills were improved in the VR approach as compared to traditional approach.
C1 [Halabi, Osama] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
C3 Qatar University
RP Halabi, O (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
EM ohalabi@qu.edu.qa
RI Halabi, Osama/C-6985-2014
OI Halabi, Osama/0000-0002-2052-0500
FU Qatar National Library
FX Open Access funding provided by the Qatar National Library.
CR ABET, 2017, 2016 2017 CRIT ACCR
   Abulrub AG, 2011, INT J EMERG TECHNOL, V6, P4, DOI 10.3991/ijet.v6i4.1766
   Ai-Lim Lee E, 2010, COMPUT ED
   Andersen I. N. S. K., 2018, FOOD RES INT
   Barata PNA, 2015, IEEE T ED
   Becker JP, 2014, IEEE T EDUC, V57, P75, DOI 10.1109/TE.2013.2273311
   Bell S., 2010, The Clearing House: A Journal of Educational Strategies, Issues and Ideas, V83, P39, DOI [10.1080/00098650903505415, DOI 10.1080/00098650903505415]
   Boy GA, 2013, EUR C COGN ERG, P8
   Chuah KM, INCORPORATING KANSEI
   de Oliveira FS, 2016, PROC FRONT EDUC CONF
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   Falcao CS, 2015, APPL VIRTUAL REALITY, V9186, P342
   Froyd JE, 2011, 2011 FRONT ED C FIE
   Guerlesquin J, 2012, J SYSTEMICS CYBERNET, V10, P51
   Hafner P, 2013, PROCEDIA COMPUTER SC
   Halabi O, 2018, ADV INTELL SYST, V716, P27, DOI 10.1007/978-3-319-73204-6_4
   Harms S, 2016, 2016 IEEE FRONT ED C, P1
   Holtzapple MT, 2007, CONCEPTS ENG
   Jette S, 2012, WORLD FUTURE REV WOR, V4, P199
   Kolmos A, 2009, UNIVERSITY SCIENCE AND MATHEMATICS EDUCATION IN TRANSITION, P261, DOI 10.1007/978-0-387-09829-6_13
   Laseinde OT, 2016, IEEE INT C IND ENG E
   Lee EA-L, 2008, REV USING VIRTUAL RE
   Lee MJW, 2016, IEEE T ED
   Liang W, 2019, MULTIMED TOOLS APPL, V78, P4767, DOI 10.1007/s11042-018-7070-6
   Martínez F, 2011, IEEE T EDUC, V54, P87, DOI 10.1109/TE.2010.2044506
   Nam C, 2020, MULTIMED TOOLS APPL, V79, P1221, DOI 10.1007/s11042-019-08176-x
   Rivera A, 2018, WWWBUSINESSCOM
   Saorin JL, 2017, THINK SKILLS CREAT
   Sattar MU, 2019, PAK J MED SCI, V35, P852, DOI 10.12669/pjms.35.3.44
   Seo J.H., 2019, J. Comput. Sci. Educ, V10, P81, DOI DOI 10.22369/ISSN.2153-4136/10/1/13
   Sochacka NW, 2016, J ENG EDUC, V105, P15, DOI 10.1002/jee.20112
   Tan S, HYBRID PROBLEM BASED
   Valdez MT, 2015, INT CONF INFO TECH
   Valdez MT, 3D VIRTUAL LAB TEACH
   Yang JC, 2010, COMPUT ED
   Youssef BB, 2012, P 2 INT ENG DES ED C
NR 36
TC 50
Z9 55
U1 13
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2987
EP 3004
DI 10.1007/s11042-019-08214-8
EA DEC 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500612000005
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Alam, MS
   Natesha, BV
   Ashwin, TS
   Guddeti, RMR
AF Alam, Md Shahzad
   Natesha, B., V
   Ashwin, T. S.
   Guddeti, Ram Mohana Reddy
TI UAV based cost-effective real-time abnormal event detection using edge
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time object detection; Unmanned aerial vehicle; Real-time
   surveillance system; Edge computing
AB Recent advancements in computer vision led to the development of a real-time surveillance system which ensures the safety and security of the people in public places. An aerial surveillance system will be advantageous in this scenario using a platform like Unmanned Aerial Vehicle (UAV) will be very reliable and can be considered as a cost-effective option for this task. To make the system fully autonomous, we require real-time abnormal event detection. But, this is computationally complex and time-consuming due to the heavy load on the UAV, which affords limited processing and payload capacity. In this paper, we propose a cost-effective approach for aerial surveillance in which we move the large computation tasks to the cloud while keeping limited computation on-board UAV device using edge computing technique. Further, our proposed system will maintain the minimum communication between UAV and cloud. Thus it not only reduces the network traffic but also reduces the end-to-end delay. The proposed method is based on the state-of-the-art YOLO (You Only Look Once) technique for real-time object detection deployed on edge computing device using Intel neural compute stick Movidius VPU (Vision Processing Unit), and we applied abnormal event detection using motion influence map on the cloud. Experimental results demonstrate that the proposed system reduces the end-to-end delay. Further, Tiny YOLO is six times faster while processing the frames per second (fps) when compared to other state-of-the-art methods.
C1 [Alam, Md Shahzad; Natesha, B., V; Ashwin, T. S.] Natl Inst Technol Karnataka, Surathkal, India.
   [Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; National Institute of Technology (NIT System);
   National Institute of Technology Karnataka
RP Ashwin, TS (corresponding author), Natl Inst Technol Karnataka, Surathkal, India.
EM shahzadalam98@gmail.com; nateshbv18@gmail.com; ashwindixit9@gmail.com;
   profgrmreddy@nitk.edu.in
RI V, Natesha B/AAW-5621-2020; S, ASHWIN T/Z-2285-2019; Guddeti, Ram Mohana
   Reddy/W-9494-2018; B V, Dr. Natesha/ADM-9906-2022; Guddeti, Ram Mohana
   Reddy/ABB-5181-2021
OI S, ASHWIN T/0000-0002-1690-1626; B V, Dr. Natesha/0000-0003-4175-4776;
   Guddeti, Ram Mohana Reddy/0000-0003-1361-3837
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Amraee S, 2017, MULTIMED TOOLS APPL, P1
   Chen P, 2018, IEEE T INTELL TRANSP, V19, P131, DOI 10.1109/TITS.2017.2750091
   Djeraba C, 2010, MULTIMED SYST APPL, P11, DOI 10.1007/978-1-4419-0316-7_2
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gnouma M, 2018, MULTIMED TOOLS APPL, V77, P24843, DOI 10.1007/s11042-018-5701-6
   Huang C, 2017, ARXIV171209162
   Kim B, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P123, DOI 10.1145/2987386.2987437
   Le T-L, 2015, SOME CURRENT ADV RES, P17, DOI DOI 10.1007/978-3-319-14633-1_2
   Lee J, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P36, DOI 10.1109/IRC.2017.77
   Leyva R, 2017, 2017 40 INT C TEL SI
   Li A, 2017, MULTIMED TOOLS APPL, V76, P26249, DOI 10.1007/s11042-016-4115-6
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nam Y, 2014, MULTIMED TOOLS APPL, V72, P3001, DOI 10.1007/s11042-013-1593-7
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi-Tehran P, 2014, 2014 IEEE SYMPOSIUM ON EVOLVING AND AUTONOMOUS LEARNING SYSTEMS (EALS), P43, DOI 10.1109/EALS.2014.7009502
   Shi Y, 2010, 2010 20 INT C PATT R
   Sun JY, 2019, MULTIMED TOOLS APPL, V78, P3633, DOI 10.1007/s11042-017-5244-2
   Zhu SH, 2016, MULTIMED TOOLS APPL, V75, P9445, DOI 10.1007/s11042-015-3122-3
NR 22
TC 17
Z9 18
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35119
EP 35134
DI 10.1007/s11042-019-08067-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800039
DA 2024-07-18
ER

PT J
AU Malandrino, D
   Pirozzi, D
   Zaccagnino, R
AF Malandrino, Delfina
   Pirozzi, Donato
   Zaccagnino, Rocco
TI Learning the harmonic analysis: is visualization an effective approach?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music visualization; Harmonic analysis visualization; Tool; Learning;
   Evaluation
ID MUSIC
AB Understanding the structure of music compositions requires an ability built over time, through the study of the music theory and the application of countless hours of practice. In particular for beginner learners, it can be a time-consuming and a tedious task due to the steep learning curve, especially for classical music. In this work we focus on a specific type of classical music composition, that is music in chorale style. Composing such type of music requires the study of rules that are related to many structural aspects of music, such as melodic and mainly harmonic aspects. To overcome these difficulties, interdisciplinary techniques could be exploited to understand whether extra (visual) information, provided through a specific software tool, could be useful to improve learning in a quick and effective way. We introduce therefore VisualHarmony, a tool that allows users to perform the harmonic analysis of music compositions by exploiting visual clues superimposed on the music scores. Since the harmonic analysis requires to identify similar tonalities and relevant degrees, the visualization approach proposed uses closest colors to represent similar tonalities and degrees. To assess the effectiveness of our idea, we performed an evaluation study involving 60 participants among experts (with a conservatory degree) and music students from conservatory classes. We derived interesting results about the overall learning capabilities (when using visualization in supporting learning) and music information retention when using VisualHarmony in a first phase to study rules, and then move on to the classic way of performing harmonization. This result allowed us to further demonstrate the effectiveness of visualization to learn classic music rules. Finally, we also obtained positive feedback about the system usability and the satisfaction of the users with regard to the easiness and the usefulness of the tested tool.
C1 [Malandrino, Delfina; Pirozzi, Donato; Zaccagnino, Rocco] Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II,132, I-84084 Fisciano, SA, Italy.
C3 University of Salerno
RP Malandrino, D (corresponding author), Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II,132, I-84084 Fisciano, SA, Italy.
EM dmalandrino@unisa.it; dpirozzi@unisa.it; rzaccagnino@unisa.it
RI Pirozzi, Donato/U-6339-2019; MALANDRINO, Delfina/GSE-2906-2022;
   MALANDRINO, Delfina/JAX-3427-2023; Zaccagnino, Rocco/ADA-9205-2022
OI Pirozzi, Donato/0000-0002-4315-0231; Zaccagnino,
   Rocco/0000-0002-9089-5957; Malandrino, Delfina/0000-0003-2693-0196
CR Al-Musawi M, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P156, DOI 10.1109/BHI.2016.7455858
   [Anonymous], MUSIC ANIMATION MACH
   Bergstrom Tony, 2007, Proceedings Graphics Interface 2007, P297, DOI 10.1145/1268517.1268565
   Blake A., 2014, VISUAL INFORM COMMUN
   Chan WY, 2010, IEEE T VIS COMPUT GR, V16, P161, DOI 10.1109/TVCG.2009.63
   Ciuha P., 2010, P INT C MULT, P1677
   Conati C, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12393
   De Felice C, 2017, INFORM SCIENCES, V385, P196, DOI 10.1016/j.ins.2017.01.004
   De Haas WB, 2013, COMPUT MUSIC J, V37, P37, DOI 10.1162/COMJ_a_00209
   De Prisco R, 2018, 22 INT C INF VIS 4 2
   De Prisco R., 2010, P 12 ANN C GEN EV CO, P817
   De Prisco R, 2017, LECT NOTES COMPUT SC, V10198, P97, DOI 10.1007/978-3-319-55750-2_7
   De Prisco R, 2017, INFORM VISUAL, V16, P139, DOI 10.1177/1473871616655468
   De Prisco R, 2016, IEEE INT CONF INF VI, P177, DOI 10.1109/IV.2016.56
   De Prisco R, 2011, IEEE SYMP DIFF EVOL, P65
   Doolittle P., 2003, THEOR RES SOC EDUC, V31, P72
   Erra Ugo, 2007, Universal Access in the Information Society, V6, P285, DOI 10.1007/s10209-007-0091-y
   Erra U, 2018, J VISUAL LANG COMPUT, V44, P13, DOI 10.1016/j.jvlc.2017.11.002
   Fonteles JH, 2013, J VISUAL LANG COMPUT, V24, P472, DOI 10.1016/j.jvlc.2013.10.002
   Iaccarino Gennaro., 2006, P 2006 INT CROSS DIS, P23
   Koelle D., MUSIC PROGRAMMING JA
   Kroger Pedro., 2008, P INT COMP MUS C BEL, P273
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Leon P.G., 2012, P SIGCHI C HUMAN FAC, P589, DOI DOI 10.1145/2207676.2207759
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Malandrino D, 2018, 22 INT C INF VIS 4 2
   Malandrino D, 2015, IEEE INT CONF INF VI, P56, DOI 10.1109/iV.2015.21
   Malandrino D, 2015, IEEE T LEARN TECHNOL, V8, P18, DOI 10.1109/TLT.2014.2365026
   Mardirossian Arpi, 2007, ISMIR PP
   Maxwell L, 2018, BMJ GLOB HEALTH, V3, DOI 10.1136/bmjgh-2017-000304
   Miyake RK, 2003, ACM SIGGRAPH 2003 SK, P1
   Muelder C., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P129, DOI 10.1109/ISM.2010.27
   Ono J. P., 2015, SIBGRAPI
   Piston W., 1987, HARMONY
   Purchase H, 2012, Experimental Human-Computer Interaction-A Prac- tical Guide With Visual Examples
   Ramirez R, 2018, P 5 INT C MOV COMP G, P49
   Rentfrow PJ, 2012, SOC PERSONAL PSYCHOL, V6, P402, DOI 10.1111/j.1751-9004.2012.00434.x
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Roediger HL, 2006, PERSPECT PSYCHOL SCI, V1, P181, DOI 10.1111/j.1745-6916.2006.00012.x
   Roediger HL, 2011, TRENDS COGN SCI, V15, P20, DOI 10.1016/j.tics.2010.09.003
   Sapp CraigStuart., 2005, COMPUTERS ENTERTAINM, V3, P1, DOI DOI 10.1145/1095534.1095544
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sidorov KirillA., 2014, P 15 INT SOC MUS INF, P301
   Smith SM, 1997, VISUALIZATION '97 - PROCEEDINGS, P499, DOI 10.1109/VISUAL.1997.663931
   Snydal J., 2005, CHI 05 EXTENDED ABST, P1805
   Soriano A, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P25, DOI 10.1109/SIBGRAPI.2014.53
   van der Linden J, 2011, IEEE T INSTRUM MEAS, V60, P104, DOI 10.1109/TIM.2010.2065770
   Wattenberg M, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P110, DOI 10.1109/INFVIS.2002.1173155
   Wattenberg Martin., The Shape of Song
NR 49
TC 6
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32967
EP 32998
DI 10.1007/s11042-019-07879-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600017
DA 2024-07-18
ER

PT J
AU Abdelhakim, A
   Saleh, HI
   Abdelhakim, M
AF Abdelhakim, Assem
   Saleh, Hassan I.
   Abdelhakim, Mai
TI Fragile watermarking for image tamper detection and localization with
   effective recovery capability using K-means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Tampering localization; Fragile watermarking;
   Discrete Cosine Transform; Unsupervised machine learning; K-means
   clustering
ID FORGERY DETECTION; AUTHENTICATION; SCHEME; SECURE
AB The continuous development of forgery attacks on critical multimedia applications necessitates having accurate image tamper detection and localization techniques. In this paper, an image authentication approach is designed using a block-based fragile watermarking. Moreover, an effective recovery technique based on unsupervised machine learning is proposed. The authentication data is generated, for each 8 x 8 image block, using the Discrete Cosine Transform. A block dependency is established, for authenticating an image block, through using part of the authentication data of a distant block. Such block-dependency provides more accurate tamper detection and enables precise localization of tampered regions. At the recovery phase, a block is divided into smaller sub-blocks of size 2 x 2, where the recovery data is calculated through the K-means clustering. A fragile watermarking, in the spatial domain, is employed for embedding the watermark that is generated from the authentication and recovery data. We examine the effectiveness of the proposed approach under some of the most common attacks of image tampering, including copy move, constant average, and vector quantization attacks. Our approach is compared with several existing methods. Experimental results show that the proposed technique provides superior tampering detection and localization performance, and is capable of recovering the tampered regions more effectively.
C1 [Abdelhakim, Assem; Saleh, Hassan I.; Abdelhakim, Mai] Egyptian Atom Energy Author, NCRRT, Dept Radiat Engn, Cairo, Egypt.
   [Abdelhakim, Mai] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA USA.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Abdelhakim, A (corresponding author), Egyptian Atom Energy Author, NCRRT, Dept Radiat Engn, Cairo, Egypt.
EM assemh81@gmail.com; h_i_saleh@hotmail.com; maia@pitt.edu
RI saleh, hassan I./ABA-6608-2022; Abdelhakim, Assem/HIK-1016-2022
OI Saleh, Hassan/0000-0001-5395-2214; abdelhakim, Mai/0000-0001-8442-0974;
   Abdelhakim, Assem/0000-0003-0730-2012
CR Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Bohra A, 2009, AEU-INT J ELECTRON C, V63, P703, DOI 10.1016/j.aeue.2008.05.010
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gareth J., 2010, INTRO STAT LEARNING
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Hasan Y, 2004, SIGN PROC INF TECHN
   He H, 2007, BIOINSP COMP THEOR A
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Ho ATS, 2008, IEEE T INF FOREN SEC, V3, P567, DOI 10.1109/TIFS.2008.926994
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Huang P-W, 2004, VQ ATTACK RESILIENT
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Kumar A, 2017, PERTANIKA J SCI TECH, V25, P57
   Kumar A, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P531, DOI 10.1109/ICIIP.2015.7414830
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   Mahdian B, 2010, IEEE AERO EL SYS MAG, V25, P18, DOI 10.1109/MAES.2010.5467652
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh B, 2014, CONS EL GCCE 2014 IE
   Singh D., 2013, INTELLIGENT INTERACT, V10, P111, DOI DOI 10.1007/978-3-642-37463-0_10
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Walia E, 2014, SIGNAL IMAGE VIDEO P, V8, P859, DOI 10.1007/s11760-012-0312-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang HJ, 2006, IEEE SIGNAL PROC LET, V13, P741, DOI 10.1109/LSP.2006.879829
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
   Zhou WJ, 2016, AEU-INT J ELECTRON C, V70, P77, DOI 10.1016/j.aeue.2015.10.006
NR 45
TC 26
Z9 26
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32523
EP 32563
DI 10.1007/s11042-019-07986-3
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000065
DA 2024-07-18
ER

PT J
AU Fadele, AA
   Othman, M
   Hashem, IAT
   Yaqoob, I
   Imran, M
   Shoaib, M
AF Fadele, Alaba Ayotunde
   Othman, Mazliza
   Hashem, Ibrahim Abaker Targio
   Yaqoob, Ibrar
   Imran, Muhammad
   Shoaib, Muhammad
TI A novel countermeasure technique for reactive jamming attack in internet
   of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Network security; Jamming attack; Countermeasures
ID SECURITY
AB In recent years, Internet of Things (IoT) has attracted significant attention because of its wide range of applications in various domains. However, security is a growing concern as users of small devices in an IoT network are unable to defend themselves against reactive jamming attacks. These attacks negatively affect the performance of devices and hinder IoT operations. To address such an issue, this paper presents a novel countermeasure detection and consistency algorithm (CDCA), which aims to fight reactive jamming attacks on IoT networks. The proposed CDCA uses a change in threshold value to detect and treat an attack. The algorithm employs channel signal strength to check packet consistency by determining if the data transmission value contradicts the threshold value. The node that sends the threshold value is periodically checked and the threshold value is compared with the current value after data transmission to find out if an attack has occurred in the network. Based on realistic simulation scenarios (e.g., with varying traffic interval, number of malicious nodes, and random mobility patterns), the performance of the proposed CDCA is evaluated using a Cooja simulator. Simulation results demonstrate the superiority of the proposed technique compared with contemporary schemes in terms of performance metrics such as energy consumption, traffic delay, and network throughput.
C1 [Fadele, Alaba Ayotunde; Othman, Mazliza] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
   [Hashem, Ibrahim Abaker Targio] Taylors Univ, Sch Comp & IT, Subang Jaya 47500, Selangor, Malaysia.
   [Yaqoob, Ibrar] Kyung Hee Univ, Dept Comp Sci & Engn, Yongin 446701, South Korea.
   [Imran, Muhammad; Shoaib, Muhammad] King Saud Univ, Coll Appl Comp Sci, Almuzahmiyah 11451, Saudi Arabia.
C3 Universiti Malaya; Taylor's University; Kyung Hee University; King Saud
   University
RP Fadele, AA; Othman, M (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.; Hashem, IAT (corresponding author), Taylors Univ, Sch Comp & IT, Subang Jaya 47500, Selangor, Malaysia.
EM ayotundefadele@siswa.um.edu.my; mazliza@um.edu.my;
   ibrahimabaker.targiohashem@taylors.edu.my
RI Hashem, Ibrahim Abaker Targio/AAP-1204-2020; Shoaib,
   Muhammad/F-8861-2011; Yaqoob, Ibrar/ABE-3344-2020; imran,
   Muhammad/Q-2375-2017
OI Hashem, Ibrahim Abaker Targio/0000-0001-7611-9540; Shoaib,
   Muhammad/0000-0002-0051-6803; Yaqoob, Ibrar/0000-0002-8438-3429; imran,
   Muhammad/0000-0002-6946-2591
FU Geran Bantuan Khas Penyelidikan [BKS084-2017]; Deanship of Scientific
   Research at King Saud University [RG-1435-051]
FX The work is supported by Geran Bantuan Khas Penyelidikan (BKS084-2017)
   and Deanship of Scientific Research at King Saud University through
   Research Group Project NO. (RG-1435-051).
CR Abdalzaher MS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071003
   Alaba FA, 2017, J NETW COMPUT APPL, V88, P10, DOI 10.1016/j.jnca.2017.04.002
   Aman W, 2015, INT CONF INTERNET, P362, DOI 10.1109/ICITST.2015.7412122
   [Anonymous], P 2013 3 INT C WIR C
   Beddy P, 2011, INSIGHTS IMAGING, V2, P1, DOI 10.1007/s13244-010-0050-7
   Derhab A, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/608162
   Ergul E, 2017, CAAI T INTELL TECHNO, V2, P1, DOI 10.1016/j.trit.2017.01.001
   Fu HS, 2017, PARALLEL COMPUT, V61, P68, DOI 10.1016/j.parco.2016.10.004
   Ganeshkumar P, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0528-1
   Goyal D., 2012, Proceedings of the 2012 Second International Conference on Advanced Computing & Communication Technologies (ACCT 2012), P474, DOI 10.1109/ACCT.2012.98
   Hatzivasilis G, 2017, IEEE INTERNET THINGS, V73100, P1
   Heo J, 2017, IEEE ACCESS, V2, P345
   Huang KX, 2017, IEEE T SYST MAN CY-S, V47, P2704, DOI 10.1109/TSMC.2017.2698457
   Hui Suo, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P648, DOI 10.1109/ICCSEE.2012.373
   Kasinathan P, 2013, IEEE CONF WIREL MOB, P600, DOI 10.1109/WiMOB.2013.6673419
   Lee JJ, 2012, IEEE COMMUN LETT, V16, P1903, DOI 10.1109/LCOMM.2012.091712.121811
   Li SC, 2016, INTERNET RES, V26, P337, DOI 10.1108/IntR-07-2014-0173
   Liu H, 2017, CAAI T INTELL TECHNO, V2, P48, DOI 10.1016/j.trit.2017.04.001
   Lu C., 2014, OVERVIEW SECURITY PR, P1
   Lu Y, 2017, FUTURE GENER COMP SY, V77, P149, DOI 10.1016/j.future.2017.07.013
   Mpitziopoulos A, 2009, IEEE COMMUN SURV TUT, V11, P42, DOI 10.1109/SURV.2009.090404
   Nolin J, 2016, INTERNET RES, V26, P360, DOI 10.1108/IntR-03-2014-0082
   Pei ER, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0354-x
   Qiu Y, 2016, IEEE T IND INFORM, V12, P2074, DOI 10.1109/TII.2016.2604681
   Raymond DR, 2009, IEEE T VEH TECHNOL, V58, P367, DOI 10.1109/TVT.2008.921621
   Rehab I, 2018, INT J HYDROMECHATRON, V1, P16
   Restuccia F., 2018, ARXIV180305022
   Romdhani I, 2016, COOJA SIMULATOR MANU
   Sankaran S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P880, DOI 10.1109/ICACCI.2016.7732156
   Strasser M, 2010, ACM T SENSOR NETWORK, V7, DOI 10.1145/1824766.1824772
   Tarkowski M, 2017, 17TH IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES - IEEE EUROCON 2017 CONFERENCE PROCEEDINGS, P496, DOI 10.1109/EUROCON.2017.8011161
   Weber C, 2010, ESACT PROCEED, V4, P29, DOI 10.1007/978-90-481-3419-9_6
   Wood AD, 2011, IEEE SENS J, V2, P60
   Xu W, 2013, IEEE NETWORK, V20, P41
   Yang XJ, 2017, CAAI T INTELL TECHNO, V2, P56, DOI 10.1016/j.trit.2016.12.002
   Yaqoob I, 2017, COMPUT NETW, V129, P444, DOI 10.1016/j.comnet.2017.09.003
   Zhang W, 2018, J SUPERCOMPUT, V74, P1779, DOI 10.1007/s11227-017-2150-3
   Zou YL, 2016, P IEEE, V104, P1727, DOI 10.1109/JPROC.2016.2558521
NR 38
TC 21
Z9 22
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29899
EP 29920
DI 10.1007/s11042-018-6684-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200015
DA 2024-07-18
ER

PT J
AU Kuang, YQ
   Guo, M
   Peng, YL
   Pei, Z
AF Kuang, Yuqian
   Guo, Min
   Peng, Yali
   Pei, Zhao
TI Learner posture recognition via a fusing model based on improved SILTP
   and LDP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learner posture recognition; Scale invariant local ternary pattern;
   Local directional pattern; Adaptive threshold; Feature fusion
ID FACE RECOGNITION; FEATURES; PATTERN
AB The learner's body posture reflects the learner's learning state. The learner's posture recognition can effectively evaluate their learning state, which plays an important role in the teacher's teaching process. In this paper, a new method for learner's gesture recognition is proposed, which fuses the improved scale invariant local ternary pattern (SILTP) and the local directional pattern (LDP). Firstly, a multi-scale weighted adaptive SILTP (MWA-SILTP) algorithm is proposed. The dynamic threshold of the current neighborhood is adaptively generated according to the dispersion degree of contrast values in global and local neighborhoods, and SILTP coding is carried out to obtain adaptive SILTP. And the concept of multi-scale is introduced. By changing the sampling radius, the adaptive SILTPs of different scales are obtained. The adaptive SILTPs of different scales are merged with different weights to represent the image in multi-resolution. The MWA-SILTP algorithm is used to extract the feature of the learner's posture image. Secondly, the LDP algorithm is used to extract the feature of the learner's posture image. Finally, the two features are merged, and the support vector machine is used for classification and recognition. The improved SILTP can get more feature information and has stronger adaptability. The LDP algorithm has advantages in anti-interference and can extract edge information better. The fusing model of this paper fully utilizes the advantages of the two algorithms. Experimental results show that the proposed method can effectively recognize learner's posture of sitting, raising hand and lowering head.
C1 [Kuang, Yuqian; Guo, Min; Peng, Yali; Pei, Zhao] Shaanxi Normal Univ, Sch Comp Sci, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China.
C3 Shaanxi Normal University
RP Guo, M (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China.
EM guomin@snnu.edu.cn
FU National Natural Science Foundation of China [61873155]; Science
   Research and Development Program of Shaanxi Province of China
   [2016NY-176]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61873155), the Science Research and Development Program of
   Shaanxi Province of China (No. 2016NY-176).
CR Choi SI, 2018, IEEE ACCESS, V6, P13663, DOI 10.1109/ACCESS.2018.2812725
   CHU H, 2017, MULTIMED TOOLS APPL, P1
   Hu MC, 2018, IEEE T INTELL TRANSP, V19, P2582, DOI 10.1109/TITS.2017.2758387
   Huazhong Xu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P869, DOI 10.1109/ICIG.2013.176
   Ji LP, 2018, IEEE T CYBERNETICS, V48, P2683, DOI 10.1109/TCYB.2017.2748500
   Ji ZJ, 2014, PATTERN RECOGN, V47, P2952, DOI 10.1016/j.patcog.2014.03.016
   Lenc L, 2016, INTEGR COMPUT-AID E, V23, P129, DOI 10.3233/ICA-150506
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Ma MS, 2018, CHINA COMMUN, V15, P156, DOI 10.1109/CC.2018.8424611
   Min Guo, 2017, Multimedia Tools and Applications, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Mohamed MA, 2014, IEEE T CIRC SYST VID, V24, P1499, DOI 10.1109/TCSVT.2014.2308628
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Uddin MZ, 2017, IEEE ACCESS, V5, P26146, DOI 10.1109/ACCESS.2017.2777003
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Wu HF, 2014, SIGNAL IMAGE VIDEO P, V8, P665, DOI 10.1007/s11760-013-0576-5
NR 18
TC 3
Z9 3
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30443
EP 30456
DI 10.1007/s11042-019-07862-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200045
DA 2024-07-18
ER

PT J
AU García, FT
   Villalba, LJG
   Orozco, ALS
   Ruiz, FDA
   Juárez, AA
   Kim, TH
AF Turrado Garcia, Fernando
   Garcia Villalba, Luis Javier
   Sandoval Orozco, Ana Lucila
   Aranda Ruiz, Francisco Damian
   Aguirre Juarez, Andres
   Kim, Tai-Hoon
TI Locating similar names through locality sensitive hashing and graph
   theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Locality sensitive hashing; Entity deduplication;
   Textual similarity
ID ALGORITHM
AB Locality Sensitive Hashing is a known technique applied for finding similar texts and it has been applied to plagiarism detection, mirror pages identification or to identify the original source of a news article. In this paper we will show how can Locality Sensitive Hashing be applied to identify misspelled people names (name, middle name and last name) or near duplicates. In our case, and due to the short length of the texts, using two similarity functions (the Jaccard Similarity and the Full Damerau-Levenshtein Distance) for measuring the similarity of the names allowed us to obtain better results than using a single one. All the experimental work was made using the statistical software R and the libraries: textreuse and stringdist.
C1 [Turrado Garcia, Fernando; Garcia Villalba, Luis Javier; Sandoval Orozco, Ana Lucila; Aranda Ruiz, Francisco Damian; Aguirre Juarez, Andres] Univ Complutense Madrid, Off 431, Fac Informat Technol & Comp Sci, GASS,Dept Software Engn & Artificial Intelligence, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, E-28040 Madrid, Spain.
   [Kim, Tai-Hoon] Sungshin Womens Univ, Dept Convergence Secur, 249-1 Dongseon Dong 3 Ga, Seoul 136742, South Korea.
C3 Complutense University of Madrid; Sungshin Women's University
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, Off 431, Fac Informat Technol & Comp Sci, GASS,Dept Software Engn & Artificial Intelligence, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, E-28040 Madrid, Spain.
EM fturrado@fdi.ucm.es; javiergv@fdi.ucm.es; asandoval@fdi.ucm.es;
   fraranda@ucm.es; andragui@ucm.es; taihoonn@daum.net
RI Orozco, Ana Lucila Sandoval/H-4148-2012; Villalba, Luis Javier
   Garcí­a/N-4631-2014
FU Sungshin Women's University; European Union [700326]
FX This research work was supported by Sungshin Women's University. In
   addition, L.J.G.V. and A.L.S.O thanks to RAMSES project. This project
   has received funding from the European Union's Horizon 2020 research and
   innovation programme under grant agreement No 700326. Website:
   http://ramses2020.eu.
CR [Anonymous], 2017, COMPUT LINGUISTICS N
   [Anonymous], 2016, Dplyr: A Grammar of Data Manipulation Software
   Chollampatt S, 2018, P ASS ADV ART INT NE
   Csardi G., 2006, InterJournal, (Complex Systems), V1695, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   HOPCROFT J, 1973, COMMUN ACM, V16, P372, DOI 10.1145/362248.362272
   Karp Richard M, 1972, COMPLEXITY COMPUTER, P85, DOI DOI 10.1007/978-1-4684-2001-2_9
   Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5
   Lai KH, 2015, J BIOMED INFORM, V55, P188, DOI 10.1016/j.jbi.2015.04.008
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Malhotra P., 2014, P CEUR WORKSHOP, V1133, P41
   Morris MR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173609
   Mullen Lincoln., 2016, textreuse: Detect Text Reuse and Document Similarity
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Pérez A, 2018, INT J MED INFORM, V110, P111, DOI 10.1016/j.ijmedinf.2017.12.007
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rajaraman Anand., 2011, Mining of Massive Datasets, DOI DOI 10.1017/CBO9781139058452
   Satuluri V, 2012, PROC VLDB ENDOW, V5, P430, DOI 10.14778/2140436.2140440
   Shapiro D, 2018, APPL ARTIF INTELL, V32, P1, DOI 10.1080/08839514.2018.1448137
   Subhashree VK, 2017, J HIGH SPEED NETW, V23, P15, DOI 10.3233/JHS-170554
   Tong QH, 2017, PATTERN RECOGN LETT, V89, P1, DOI 10.1016/j.patrec.2017.01.016
   van der Loo MPJ, 2014, R J, V6, P111
   Yuhua Jia, 2016, MULTIMEDIA MODELING, P550
NR 24
TC 0
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29853
EP 29866
DI 10.1007/s11042-018-6375-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200012
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Lin, YW
   Zhu, L
   Yuan, XP
   Long, J
   Huang, F
AF Zhang, Chengyuan
   Lin, Yunwu
   Zhu, Lei
   Yuan, XinPan
   Long, Jun
   Huang, Fang
TI Hierarchical one permutation hashing: efficient multimedia near
   duplicate detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical one permutation hashing; Multimedia data; Near duplicate
   detection
ID NETWORKS
AB With advances in multimedia technologies and the proliferation of smart phone, digital cameras, storage devices, there are a rapidly growing massive amount of multimedia data collected in many applications such as multimedia retrieval and management system, in which the data element is composed of text, image, video and audio. Consequently, the study of multimedia near duplicate detection has attracted significant concern from research organizations and commercial communities. Traditional solution minwish hashing (MinWise) faces two challenges: expensive preprocessing time and lower comparison speed. Thus, this work first introduce a hashing method called one permutation hashing (OPH) to shun the costly preprocessing time. Based on OPH, a more efficient strategy group based one permutation hashing (GOPH) is developed to deal with the high comparison time. Based on the fact that the similarity of most multimedia data is not very high, this work design an new hashing method namely hierarchical one permutation hashing (HOPH) to further improve the performance. Comprehensive experiments on real multimedia datasets clearly show that with similar accuracy HOPH is five to seven times faster than MinWise.
C1 [Zhang, Chengyuan; Lin, Yunwu; Zhu, Lei; Long, Jun; Huang, Fang] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Zhang, Chengyuan; Lin, Yunwu; Zhu, Lei; Long, Jun] Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Hunan, Peoples R China.
   [Yuan, XinPan] Hunan Univ Technol, Sch Comp, Zhuzhou, Peoples R China.
C3 Central South University; Central South University; Hunan University of
   Technology
RP Long, J (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.; Long, J (corresponding author), Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Hunan, Peoples R China.; Yuan, XP (corresponding author), Hunan Univ Technol, Sch Comp, Zhuzhou, Peoples R China.
EM cyzhang@csu.edu.cn; lywcsu@csu.edu.cn; leizhu@csu.edu.cn;
   xpyuan@hut.edu.cn; jlong@csu.edu.cn; hfang@csu.edu.cn
RI HUANG, FANG/JBS-3517-2023; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-5348-7532; Yuan, XinPan/0000-0001-9509-0755
FU National Natural Science Foundation of China [61379110, 61472450,
   61702560]; Key Research Program of Hunan Province [2016JC2018]; project
   of Science and Technology Plan of Hunan Province [2016JC2011,
   2018JJ3691]; Fundamental Research Funds for Central Universities of
   Central South University [2018zzts588]
FX This work was supported in part by the National Natural Science
   Foundation of China (61379110, 61472450, 61702560), the Key Research
   Program of Hunan Province(2016JC2018), project (2016JC2011, 2018JJ3691)
   of Science and Technology Plan of Hunan Province, and Fundamental
   Research Funds for Central Universities of Central South University
   (2018zzts588).
CR [Anonymous], 2011, P 24 INT C NEUR INF
   Bayardo R. J., 2007, P 16 INT C WORLD WID, P131, DOI [DOI 10.1145/1242572.1242591, 10.1145/1242572.1242591]
   Broder AZ, 2000, J COMPUT SYST SCI, V60, P630, DOI 10.1006/jcss.1999.1690
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Chum Ondrej., 2007, CIVR 07, P549, DOI DOI 10.1145/1282280.1282359
   Hassanian-esfahani R, 2018, EXPERT SYST APPL, V99, P203, DOI 10.1016/j.eswa.2018.01.014
   Henzinger M., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P284, DOI 10.1145/1148170.1148222
   Hoad TC, 2003, J AM SOC INF SCI TEC, V54, P203, DOI 10.1002/asi.10170
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jain P, 2008, 2008 IEEE COMP SOC C
   Li P, 2012, MATHEMATICS
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister David, 2006, CVPR
   Pagh R, 2014, PODS'14: PROCEEDINGS OF THE 33RD ACM SIGMOD-SIGACT-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P109, DOI 10.1145/2594538.2594554
   Philbin James, 2007, 2007 IEEE COMP SOC C
   Qu Y, 2013, INT C INT MULT COMP, P287
   Shao J, 2012, PATTERN RECOGN LETT, V33, P271, DOI 10.1016/j.patrec.2011.10.018
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Torralba A, 2008, 2008 IEEE COMP SOC C
   Vsemirnov M, 2005, SIAM J DISCRETE MATH, V18, P592, DOI 10.1137/S089548010241818X
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, IEEE IMAGE PROC, P805, DOI 10.1109/ICIP.2013.6738166
   Wang Yuan-sheng, 2014, COMPUTER MODELLING N, V16, P13
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Yang H., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P421, DOI 10.1145/1148170.1148243
   ZHANG D.-Q., 2004, PROC ACM INT C MULTI, P877, DOI DOI 10.1145/1027527.1027730
   Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573
   Zhou D, 2016, IEEE IMAGE PROC, P2445, DOI 10.1109/ICIP.2016.7532798
   Zhou W., 2012, Proceedings of the second ACM conference on Data and Application Security and Privacy, P1
   Zhu GQ, 2016, ONCOTARGETS THER, V9, P2153, DOI 10.2147/OTT.S97864
   Zobel J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132956.1132959
NR 45
TC 3
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30537
EP 30560
DI 10.1007/s11042-018-6178-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200051
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Prazák, A
   Loose, Z
   Psutka, JV
   Radová, V
   Psutka, J
AF Prazak, Ales
   Loose, Zdenek
   Psutka, Josef V.
   Radova, Vlasta
   Psutka, Josef
TI Live TV subtitling through respeaking with remote cutting-edge
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live subtitling; Respeaking; Automatic speech recognition
AB This article presents an original system for live TV subtitling using respeaking and automatic speech recognition. Unlike several commercially available live subtitling solutions, the technology presented in this article comprises a speech recognition system specifically designed for live subtitling, realizing the full potential of state-of-the-art speech technology. The enhancements implemented in our remote live subtitling system architecture are described and accompanied by real-world parameters obtained during several years of deployment at the public service broadcaster in the Czech Republic. This article also presents our four-phase respeaker training system and some new techniques related to the whole life cycle of live subtitles, such as a method for automatic live subtitle retiming or a technique for live subtitle delay elimination. This article can serve as an inspiration for how to deal with live subtitling, especially in minor languages.
C1 [Prazak, Ales; Psutka, Josef V.; Radova, Vlasta; Psutka, Josef] Univ West Bohemia, Univ 8, Plzen 30100, Czech Republic.
   [Loose, Zdenek] SpeechTech Sro, Hodoninska 61, Plzen 32300, Czech Republic.
C3 University of West Bohemia Pilsen
RP Prazák, A (corresponding author), Univ West Bohemia, Univ 8, Plzen 30100, Czech Republic.
EM aprazak@ntis.zcu.cz
RI Radova, Vlasta/U-8011-2019; Loose, Zdeněk/GOH-1461-2022
OI Radova, Vlasta/0000-0002-3258-8430; Prazak, Ales/0000-0001-9453-0034
FU European structural and investment funds (ESIF)
   [CZ.02.1.01/0.0/0.0/17_048/0007267]
FX This work was supported by European structural and investment funds
   (ESIF) (No. CZ.02.1.01/0.0/0.0/17_048/0007267).
CR [Anonymous], 2018, DRAGON NATURALLYSPEA
   [Anonymous], 2018, IBM DESKTOP VIAVOICE
   [Anonymous], 2018, SPEECHTECH MEGAWORD
   [Anonymous], 2011, 2011 IEEE WORKSH AUT
   Braunschweiler N, 2010, INTERSPEECH
   British Broadcasting Corporation, 2018, WINCAPS Q LIVE
   de Castro M, 2011, 2011 IEEE INT S BROA
   Evans MJ, 2003, 065 WHP BRIT BROADC
   Hrúz M, 2018, INTERSPEECH, P3529, DOI 10.21437/Interspeech.2018-1748
   Lehecka J, 2018, LECT NOTES ARTIF INT, V11107, P334, DOI 10.1007/978-3-030-00794-2_36
   Levin K, 2014, INTERSPEECH, P1438
   *OFCOM, 2017, OFC COD TEL ACC SERV
   Praak A, 2012, INTERSPEECH
   Prazák A, 2006, LECT NOTES ARTIF INT, V4188, P501
   Psutka Josef V., 2014, Text, Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655, P515, DOI 10.1007/978-3-319-10816-2_62
   Romero-Fresco P., 2015, RECEPTION SUBTITLES
   Romero-Fresco P, 2015, PALGR STUD TRANSL, P28
   Romero-Fresco P, 2016, LANG COMMUN, V49, P56, DOI 10.1016/j.langcom.2016.06.001
   Romero-Fresco P, 2009, VIAL-VIGO INT J APPL, V6, P109
   Stan A, 2012, IEEE W SP LANG TECH, P286, DOI 10.1109/SLT.2012.6424237
   Svec J, 2014, LANG RESOUR EVAL, V48, P227, DOI 10.1007/s10579-013-9246-z
   Van Waes L, 2011, 3 INT S LIV SUBT EXP
   Vanek Jan, 2017, Statistical Language and Speech Processing. 5th International Conference, SLSP. Proceedings: LNAI 10583, P204, DOI 10.1007/978-3-319-68456-7_17
   Vanek J, 2012, IEEE T AUDIO SPEECH, V20, P1818, DOI 10.1109/TASL.2012.2190928
   Ware T, 2016, 318 WHP BRIT BROADC
NR 25
TC 6
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1203
EP 1220
DI 10.1007/s11042-019-08235-3
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492559900001
DA 2024-07-18
ER

PT J
AU Ahmadi, SBB
   Zhang, GX
   Wei, SJ
AF Ahmadi, Sajjad Bagheri Baba
   Zhang, Gongxuan
   Wei, Songjie
TI Robust and hybrid SVD-based image watermarking schemes: A survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decompositions; Watermarking; Robustness;
   Imperceptibility
ID SINGULAR-VALUE DECOMPOSITION; DISCRETE WAVELET TRANSFORM; DIFFERENTIAL
   EVOLUTION; SECURITY
AB These days, researchers have used many techniques in e-multimedia data for intellectual property protection. One of these important techniques is watermarking which is superior to Digital Signature because it does not rise overhead and it can prevent unauthorized users from misusing digital information. However, the number of attacks with aim of distorting watermark signal or disturbing watermarks detecting are exploding. Consequently, the watermark techniques have became more complicated, but still they are not fully robust against some geometric distortions. To overcome this issue and to be enough robust against the malicious attacks, and provide a high level of imperceptibility,the watermark schemes have discovered and developed the advantages by means of Singular-value decomposition. Therefore, in recent decades there has been a significant increasing in using of SVD domain in many new image watermarking schemes, which show high robustness and imperceptibility. This discussion of SVD in image watermarking schemes included: a concise overview on watermarking systems, a brief review on SVD properties in image processing and its weaknesses, the concept of SVD components, the main classification of different SVD based image-watermarking schemes; a brief summary of various secure SVD-based watermarking techniques and all major SVD coefficients modifying strategies are presented. In addition, potential issues and some existing solutions and guidelines are provided. Furthermore, the performance comparisons of the discussed techniques are presented in tabular format. This article contribution provides essential and potential information for the researchers to design, develop and implement efficient robust and hybrid SVD-based image watermarking systems.
C1 [Ahmadi, Sajjad Bagheri Baba; Zhang, Gongxuan; Wei, Songjie] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Ahmadi, SBB; Zhang, GX (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM s.bagheri@njust.edu.cn; gongxuan@njust.edu.cn; swei@njust.edu.cn
RI Bagheri Baba Ahmadi, Sajjad/ABG-5654-2020; Zhang, Gongxuan/HKE-1007-2023
OI Bagheri Baba Ahmadi, Sajjad/0000-0003-0382-0832; Zhang,
   Gongxuan/0000-0003-2925-5624
FU National Science Foundation of China [61272420, 61472189]
FX This article has been awarded by the National Science Foundation of
   China under grant numbers 61272420 and 61472189.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Akhaee MA, 2013, ISECURE-ISC INT J IN, V5, P5
   Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], 2009, INT J COMPUT THEORY
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Assini I., 2018, Int. J. Intell. Eng. Syst., V11, P169, DOI [10.22266/ijies2018.0630.18, DOI 10.22266/IJIES2018.0630.18]
   Barni M, 2001, IEEE COMMUN MAG, V39, P102, DOI 10.1109/35.940048
   Cayre F, 2005, IEEE T SIGNAL PROCES, V53, P3976, DOI 10.1109/TSP.2005.855418
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Cox IJ, 2008, MKS MULTIMED INFORM, P61, DOI 10.1016/B978-012372585-1.50006-1
   Dharwadkar N. V., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P489, DOI 10.1109/ICCSP.2011.5739368
   Dili R. Buse, 2007, P AFRICON SEP, P1
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Golea N., 2010, IEEE INT C COMPUTER, P1
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   He KF, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P2352
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Li L, 2011, J SYST SOFTWARE, V84, P923, DOI 10.1016/j.jss.2011.01.025
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Majumder S, 2013, IET BIOMETRICS, V2, P21, DOI 10.1049/iet-bmt.2012.0052
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Roy S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170326
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Sadek R. A., 2012, SVD BASED IMAGE PROC
   Shih FY, 2017, DIGITAL WATERMARKING, P35
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Yin CQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2607, DOI 10.1109/ICAL.2007.4339020
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhou B, 2004, PHYS REV A, V70, DOI 10.1103/PhysRevA.70.022311
NR 58
TC 36
Z9 37
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1075
EP 1117
DI 10.1007/s11042-019-08197-6
EA OCT 2019
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000491401600001
DA 2024-07-18
ER

PT J
AU Cao, SX
   Wang, XY
AF Cao, Songxiao
   Wang, Xuanyin
TI Real-time dynamic gesture recognition and hand servo tracking using PTZ
   camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Fingertip detection; PTZ servo tracking; Bezier
   curve fitting
ID LOCALIZATION
AB A technology of real-time dynamic gesture recognition and hand tracking using a Pan-Tilt-Zoom (PTZ) camera was presented in this study. It was aimed to achieve robust scheme that stably recognized simple hand gestures and tracked the hand by means of a PTZ camera to keep the fingertip remaining in the center of the camera. For this purpose, the hand region was initially segmented in a cluttered environment using skin color segmentation in YCbCr color space to get the silhouette of the hand. Furthermore, the Monte Carlo Sampling method was used to estimate the Cubic Bezier curves best fitted to the sub contour points centralized in each contour point, and the fingertips were detected by combining the local maximums of a cumulative curvature with detection of convex defects. After that, feature triangle analysis was utilized to achieve dynamic recognition of simple gestures including "right click down" and "right click up". Finally, the PTZ camera was driven by the algorithm to achieve servo tracking with the target fingertip when the gesture "right click down" was detected. As is shown by the experimental results, the proposed approach recognized the dynamic gestures and located the fingertips' positions precisely, and realized the follow-up servo tracking using PTZ camera in real-time.
C1 [Cao, Songxiao] China Jiliang Univ, Coll Metrol & Measurement Engn, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Xuanyin] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Zhejiang, Peoples R China.
C3 China Jiliang University; Zhejiang University
RP Cao, SX (corresponding author), China Jiliang Univ, Coll Metrol & Measurement Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM caosongxiao@cjlu.edu.cn; xywang@zju.edu.cn
RI wang, xuan/GXF-3679-2022; Cao, Songxiao/HKE-6408-2023; wang,
   xuan/JBJ-6948-2023
OI Cao, Songxiao/0000-0001-5122-3472
CR ANDERSON KR, 1978, INFORM PROCESS LETT, V7, P53, DOI 10.1016/0020-0190(78)90041-8
   [Anonymous], 2021, ACM TRANSACTIONS ON, DOI DOI 10.1145/3404374
   [Anonymous], INTELLIGENT USER INT
   Argyros AA, 2006, LECT NOTES COMPUT SC, V3979, P40
   Barrho J, 2006, I C CONT AUTOMAT ROB, P943
   Barros P, 2017, COMPUT VIS IMAGE UND, V155, P139, DOI 10.1016/j.cviu.2016.10.006
   Bhuyan M.K., 2011, 2011 National Conference on Communications (NCC), P1
   Chai D, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P124, DOI 10.1109/AFGR.1998.670936
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Gurav RM, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P974, DOI 10.1109/IIC.2015.7150886
   Hart R. P., 2017, INT ENCY COMMUNICATI, P1, DOI [10.1002/9781118901731.iecrm0066, DOI 10.1002/9781118901731.IECRM0066]
   Jo KH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P468, DOI 10.1109/AFGR.1998.670992
   Kim J, 2017, PATTERN RECOGN, V61, P139, DOI 10.1016/j.patcog.2016.07.039
   Koike H., 2001, ACM Transactions on Computer-Human Interaction, V8, P307, DOI 10.1145/504704.504706
   Letessier Julien., 2004, P 17 ANN ACM S USER, P119, DOI DOI 10.1145/1029632.1029652
   Malik S, 2004, VISUAL TOUCHPAD 200, P289
   Malima A, 2006, 2006 IEEE 14TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS, VOLS 1 AND 2, P762
   Morshidi M, 2014, PATTERN RECOGN, V47, P194, DOI 10.1016/j.patcog.2013.06.032
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   O'Hagan R, 2000, FIRST AUSTRALASIAN I, P73
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Oka K, 2002, REAL TIME TRACKING M, V568, P25
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Premaratne P, 2017, NEUROCOMPUTING, V228, P79, DOI 10.1016/j.neucom.2016.06.075
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Segen J., 1998, Proceedings ACM Multimedia 98, P455, DOI 10.1145/290747.290822
   Segen J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P188, DOI 10.1109/ICIP.1998.727164
   Suau X, 2014, IMAGE VISION COMPUT, V32, P522, DOI 10.1016/j.imavis.2014.04.015
   Tsironi E, 2017, NEUROCOMPUTING, P268
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wu XY, 2015, OPTIK, V126, P2757, DOI 10.1016/j.ijleo.2015.07.027
   Yan CK, 2019, J COMPUT BIOL, V26, P1230, DOI 10.1089/cmb.2019.0063
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang XQ, 2015, NEUROCOMPUTING, V157, P296, DOI 10.1016/j.neucom.2015.01.002
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 37
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27403
EP 27424
DI 10.1007/s11042-019-07869-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000028
OA Bronze
DA 2024-07-18
ER

PT J
AU Li, QY
   Zhan, S
   Xu, LF
   Wu, CZ
AF Li, Qiuyu
   Zhan, Shu
   Xu, Liangfeng
   Wu, Congzhong
TI Facial micro-expression recognition based on the fusion of deep learning
   and enhanced optical flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression; Recognition; Convolutional network; Optical flow
ID BINARY PATTERNS
AB Micro-expression is a kind of split-second subtle expression which could not be controlled by the autonomic nervous system. Micro-expression indicates that a person is hiding his truly emotion consciously. Because the micro-expression is closely interrelated with lie detection, micro-expression recognition has various potential applications in many domains, such as the public security, the clinical medicine, the investigation and the interrogation. Because recognizing the micro-expression through human observation is very difficult, researchers focus on the automatic micro-expression recognition. This research proposed a novel algorithm for automatic micro-expression recognition which combined a deep multi-task convolutional network for detecting the facial landmarks and a fused deep convolutional network for estimating the optical flow features of the micro-expression. Firstly, this research employed the deep multi-task convolutional network to detect facial landmarks with the manifold related tasks and divided the facial region by utilizing these facial landmarks. Furthermore, a fused convolutional network was applied for extracting the optical flow features from the facial regions which contain the muscle changes when the micro-expression presents. Finally the enhanced optical flow was applied for refining the information of the features and these refined optical flow features were classified by Support Vector Machine classifier for recognizing the micro-expression. The result of experiments on two spontaneous micro-expression database demonstrated that the method proposed in this paper achieved good performance in micro-expression recognition.
C1 [Li, Qiuyu; Zhan, Shu; Xu, Liangfeng; Wu, Congzhong] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Zhan, S (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM lqy@mail.hfut.edu.cn; shu_zhan@hfut.edu.cn
FU National Nature Science Foundation of China [61371156]
FX This work was supported in part by National Nature Science Foundation of
   China GrandNo: 61371156.
CR [Anonymous], PATT REC ICPR 2014 2
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2016, PATT REC ICPR 2016 2
   [Anonymous], INT C MULT MOD
   [Anonymous], 2014, P AS C COMP VIS
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], VIS SURV PERF EV TRA
   [Anonymous], 2011, COMP VIS ICCV 2011 I
   [Anonymous], SIGN PROC ICSP 2016
   [Anonymous], 2015, DIG SIGN PROC DSP 20
   [Anonymous], COMP VIS WORKSH ICCV
   [Anonymous], 2003, MICROEXPRESSIONS TRA
   [Anonymous], 2009, Facial micro-expressions recognition using high speed camera and 3d-gradient descriptor, DOI DOI 10.1049/IC.2009
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   [Anonymous], 2009, COMP VIS PATT REC 20
   Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Chan CH, 2012, IEEE T INF FOREN SEC, V7, P602, DOI 10.1109/TIFS.2011.2175920
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Ekman P., 2009, Telling lies: Clues to deceit in the marketplace, politics, and marriage
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Ngo AC, 2014, P AS C COMP VIS
   Le Ngo AC, 2017, IEEE T AFFECT COMPUT
   Li X., 2017, IEEE Transactions on Affective Computing
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma L, 2004, IEEE T SYST MAN CY B, V34, P1588, DOI 10.1109/TSMCB.2004.825930
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Ni ZK, 2016, IEEE SIGNAL PROC LET, V23, P1394, DOI 10.1109/LSP.2016.2599294
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YT, 2011, IEEE T IMAGE PROCESS, V20, P43, DOI 10.1109/TIP.2010.2080277
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2013, IEEE INT CONF AUTOMA
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yang AS, 2017, MULTIDIM SYST SIGN P, V28, P1249, DOI 10.1007/s11045-016-0395-2
   Zeng HQ, 2016, NEUROCOMPUTING, V217, P3, DOI 10.1016/j.neucom.2015.11.130
   Zeng HQ, 2015, SIGNAL PROCESS-IMAGE, V36, P53, DOI 10.1016/j.image.2015.05.008
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zeng HQ, 2011, IEEE T CIRC SYST VID, V21, P1659, DOI 10.1109/TCSVT.2011.2133350
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zeng HQ, 2009, IEEE T CIRC SYST VID, V19, P491, DOI 10.1109/TCSVT.2009.2014014
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu JH, 2017, IEEE CUST INTEGR CIR
   Zhu Z., 2013, ICCV
NR 60
TC 20
Z9 21
U1 2
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29307
EP 29322
DI 10.1007/s11042-018-6857-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700049
DA 2024-07-18
ER

PT J
AU Camarena-Ibarrola, A
   Figueroa, K
   Tejeda, H
   Valero, L
AF Camarena-Ibarrola, Antonio
   Figueroa, Karina
   Tejeda, Hector
   Valero, Luis
TI Ocelot identification through spots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocelot identification; Ellipse fitting; Contour closing; Minutiae
   matching
AB Ocelots are big felines in danger to be extinct but still found in some areas in Mexico, the spots in the body of ocelots make a pattern that is unique to each specimen and can be used for identification purposes. Ecologists are interested in non-intrusive census of these wild felines. In this paper, a method for automatic identification of specific individuals among ocelots is proposed. The proposed method maps each spot to the ellipse that best fits the spot, then keeps only the center of the ellipse and a vector that shows the orientation of the ellipse. Each animal is then characterized by a set of dots and associated vectors, just as human fingerprints are characterized after minutiae has been extracted. The proposed technique identifies individual ocelots by searching for local structures in the corresponding set of dots and associated vectors. According to the experiments, the proposed method outperforms Scale Invariant Feature Transform (SIFT), Speed Up Robust Feature (SURF), and Oriented fast and Rotated Brief (ORB) based identification systems in the ocelot identification problem.
C1 [Camarena-Ibarrola, Antonio] Univ Michoacana, Fac Ingn Elect, Morelia, Michoacan, Mexico.
   [Figueroa, Karina; Tejeda, Hector; Valero, Luis] Univ Michoacana, Fac Ciencias Fis Matemat, Morelia, Michoacan, Mexico.
C3 Universidad Michoacana de San Nicolas de Hidalgo; Universidad Michoacana
   de San Nicolas de Hidalgo
RP Camarena-Ibarrola, A (corresponding author), Univ Michoacana, Fac Ingn Elect, Morelia, Michoacan, Mexico.
EM camarena@umich.mx; karina@fismat.umich.mx; htejeda@fismat.umich.mx;
   valero@fismat.umich.mx
OI Camarena-Ibarrola, Antonio/0000-0002-7610-3562
FU Scientific Research Coordination of Universidad Michoacana de San
   Nicolas de HIdalgo
FX We are thankful to Dr. Tiberio Monterrubio for sharing his collection of
   photos with us. This work was supported by the Scientific Research
   Coordination of Universidad Michoacana de San Nicolas de HIdalgo
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bolger DT, 2012, METHODS ECOL EVOL, V3, P813, DOI 10.1111/j.2041-210X.2012.00212.x
   Charre-Medellín JF, 2013, SOUTHWEST NAT, V58, P264, DOI 10.1894/0038-4909-58.2.264
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Figueroa K, 2016, LECT NOTES COMPUT SC, V9703, P23, DOI 10.1007/978-3-319-39393-3_3
   Figueroa K, 2014, LECT NOTES COMPUT SC, V8827, P940, DOI 10.1007/978-3-319-12568-8_114
   Foster RJ, 2011, J WILDLIFE MANAGEMEN
   Gauthier-Clerc M, 2004, P ROY SOC B-BIOL SCI, V271, pS423, DOI 10.1098/rsbl.2004.0201
   Hartog J, 2014, INTRACTIVE INDIVIDUA
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kelly MJ, 2001, J MAMMAL, V82, P440, DOI 10.1644/1545-1542(2001)082<0440:CAPMIS>2.0.CO;2
   Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
   Tempa T., 2011, Results from a camera trapping exercise for estimating tiger population size in the lower foothills of Royal Manas National Park
   Whitehead H, 2000, STUDYING CETACEAN SO
   Yu XY, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-52
   Zhang JE, 2011, PROC CVPR IEEE, P1393, DOI 10.1109/CVPR.2011.5995678
NR 22
TC 0
Z9 1
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26239
EP 26262
DI 10.1007/s11042-019-07837-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700045
DA 2024-07-18
ER

PT J
AU Firdous, A
   Rehman, AU
   Missen, MMS
AF Firdous, Amnah
   Rehman, Aqeel Ur
   Missen, Malik M. Saad
TI A highly efficient color image encryption based on linear transformation
   using chaos theory and SHA-2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear transformation; SHA; Noise resistance; Chaotic maps; Color
   encryption; Highly efficient
ID DNA; ALGORITHM
AB An innovative and highly efficient color image encryption technique based on the concept of linear transformation is presented in this paper. A 24-bit color image is split into the channels called Red, Green, Blue and afterwards each channel is permuted via cyclic shift on rows and columns using chaotic sequences. For substitution, pseudo-random numbers are generated using chaotic maps, which are then build into pseudo-random matrices through Linear Transformations. These random matrices are bonded with permuted colored channel under Exclusive-OR (XOR) operation. The control parameters and initial conditions for chaotic maps are obtained from 256-bits hash value of the original image to avoid the chosen-plaintext attacks. The comparison of simulated results with existing algorithms has shown the proposed algorithm is better in encryption robustness and better in noise repulsion during transmission. The proposed technique is most suitable for real time applications due to better efficiency.
C1 [Firdous, Amnah; Missen, Malik M. Saad] Islamia Univ Bahawalpur, Dept Comp Sci & IT, Bahawalpur, Pakistan.
   [Rehman, Aqeel Ur] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400716, Peoples R China.
   [Rehman, Aqeel Ur] COMSATS Univ Islamabad, Dept Comp Sci, Vehari, Pakistan.
C3 Islamia University of Bahawalpur; Southwest University - China; COMSATS
   University Islamabad (CUI)
RP Rehman, AU (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400716, Peoples R China.; Rehman, AU (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Vehari, Pakistan.
EM rehmancqu@gmail.com
RI Rehman, Aqeel ur/R-4559-2018
OI Rehman, Aqeel ur/0000-0002-3083-6066; , Amnah/0000-0001-9821-4872
CR Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Ameta R, 2016, CHEM APPL SYMMETRY G
   [Anonymous], 2014, 3D RES
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Biham E., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P487
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Bruss D, 2000, PHYS REV A, V62, DOI [10.1103/PhysRevA.62.012302, 10.1103/PhysRevA.62.062302]
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Daemen J., 2012, DESIGN RIJNDAEL AES
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Glotzer SC, 2009, INTERNATIONAL ASSESS
   Golan JS, LINEAR ALGEBRA BEGIN, P79
   Gotz M, 1997, IEEE T CIRCUITS-I, V44, P963, DOI 10.1109/81.633885
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kim HI, 2016, DATA KNOWL ENG, V104, P32, DOI 10.1016/j.datak.2015.05.002
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Schneier B., 1996, NETWORK, V2nd, P631
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P281, DOI 10.1109/81.915385
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 35
TC 25
Z9 26
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24809
EP 24835
DI 10.1007/s11042-019-7623-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900052
DA 2024-07-18
ER

PT J
AU Naskar, PK
   Paul, S
   Nandy, D
   Chaudhuri, A
AF Naskar, Prabir Kumar
   Paul, Soumya
   Nandy, Dipta
   Chaudhuri, Atal
TI DNA Encoding and Channel Shuffling for Secured Encryption of Audio Data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio encryption; DNA encoding; Logistic chaotic map; Channel shuffling;
   Statistical analysis
ID IMAGE; ALGORITHM; CHAOS
AB Multimedia file like audio demands special encryption technique due to its large data capacity without compromising correlation between it's original and encrypted version (closer to zero). Most of the popular block cipher techniques work on multiple rounds whereas the proposed scheme guarantees the necessary low correlation between the original and the encrypted file without multiple rounds. The unique feature is that the consecutive blocks use different keys derived from the original one using the proposed key chaining algorithm and experimental results show that the correlation between the consecutive keys is also close to zero. The used encryption technique is based on DNA encoding with logistic chaotic map using the generated chain of keys. Furthermore, the concept of channel shuffling is introduced to make the encrypted data more secure. The experimental results confirm that the correlation between the original and ciphered block is close to zero and number of samples change rate value is close to 100. Again correlation between the two consecutive ciphered blocks is also close to zero, which conforms the acceptability of proposed scheme.
C1 [Naskar, Prabir Kumar; Nandy, Dipta] Govt Coll Engn & Text Technol, Dept Comp Sci & Engn, Serampore, WB, India.
   [Paul, Soumya] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, WB, India.
   [Chaudhuri, Atal] Veer Surendra Sai Univ Technol, Sambalpur, Odisha, India.
C3 Jadavpur University; Veer Surendra Sai University of Technology
RP Naskar, PK (corresponding author), Govt Coll Engn & Text Technol, Dept Comp Sci & Engn, Serampore, WB, India.
EM cse.prabir@gmail.com
OI Chaudhuri, Atal/0000-0003-4253-1216; NASKAR, PRABIR
   KUMAR/0000-0002-7456-7566
CR Adleman LM, 1998, SCI AM, V279, P54, DOI 10.1038/scientificamerican0898-54
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   [Anonymous], 2020, NEURAL COMPUT APPL, DOI DOI 10.1007/s00521-018-3801-x
   [Anonymous], 1999, ALMANAC, V46, P1
   Barker W.C., 2012, RECOMMENDATION TRIPL
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Daemen J, 2001, DR DOBBS J, V26, P137
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jiao SH, 2008, INT CONF SIGN PROCES, P2163
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Naskar PK, 2016, IMAGING SCI J, V64, P460, DOI 10.1080/13682199.2016.1239427
   Naskar P. K., 2011, INT J COMPUTER APPL, V19, P68, DOI DOI 10.5120/2375-3129
   Naskar PK., 2011, INT J COMPUT APPL, V26, P5
   Naskar PK, 2015, INT J ELECTRON SECUR, V7, P358
   Naskar PK, 2014, 2014 APPLICATIONS AND INNOVATIONS IN MOBILE COMPUTING (AIMOC), P67, DOI 10.1109/AIMOC.2014.6785521
   Naskar PK, 2011, COMM COM INF SC, V245, P286
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   SATHIYAMURTHI P, 2017, EURASIP J AUDIO SPEE, V2017, P00001
   Servetti A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P668
   Servetti A, 2002, IEEE T SPEECH AUDI P, V10, P637, DOI 10.1109/TSA.2002.804300
   Yakubu M. Abukari, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P396, DOI 10.1007/978-3-319-14445-0_34
   Yan WQ, 2008, IEEE T MULTIMEDIA, V10, P960, DOI 10.1109/TMM.2008.2001373
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu ZM, 2018, IEEE ACCESS, V6, P31918, DOI 10.1109/ACCESS.2018.2840119
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhou JT, 2010, INT CONF ACOUST SPEE, P1802, DOI 10.1109/ICASSP.2010.5495410
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   [No title captured]
   [No title captured]
NR 39
TC 29
Z9 30
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25019
EP 25042
DI 10.1007/s11042-019-7696-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900061
DA 2024-07-18
ER

PT J
AU Prasetyo, H
   Hsia, CH
AF Prasetyo, Heri
   Hsia, Chih-Hsien
TI Lossless progressive secret sharing for grayscale and color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eXclusive-OR; Progressive secret sharing; Image quality assessments;
   Random grids
ID SCHEME; WATERMARKING
AB A new technique on progressive secret sharing is presented. The proposed method offers two different approaches on converting a secret image into a set of shared images. The first approach exploits the generalized random grids or bitwise level computation, whereas the second approach utilizes the eXclusive-OR (XOR) operation to generate a set of shared images. The proposed method has lossless ability in the recovery process of secret image. This scheme performs well not only for binary image, but it also gives satisfactory result for grayscale and color secret image. As results show that the proposed method yields better results compared to the former existing schemes under visual investigation and objective assessment on the recovered secret image. In addition, the proposed method does not require high computational burden in the shared image generation as well as in the secret image recovery process. Yet, it can be regarded as good candidate for applying the progressive secret sharing with lossless reconstruction constraint.
C1 [Prasetyo, Heri] Univ Sebelas Maret UNS, Dept Informat, Tengah, Indonesia.
   [Hsia, Chih-Hsien] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
C3 Sebelas Maret University; National Ilan University
RP Hsia, CH (corresponding author), Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
EM chhsia625@gmail.com
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832; Hsia, Chih-Hsien/0000-0003-2665-0821
CR Bharti SS, 2018, MULTIMED TOOLS APPL, V77, P25629, DOI 10.1007/s11042-018-5810-2
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Chen TH, 2013, J SYST SOFTWARE, V86, P1267, DOI 10.1016/j.jss.2012.12.022
   Chen Y, 2019, J BUS ETHICS, V159, P587, DOI 10.1007/s10551-018-3847-9
   Chen YY, 2018, MULTIMED TOOLS APPL, V77, P8019, DOI 10.1007/s11042-017-4697-7
   Fang W.-P., 2006, Pattern Recognition and Image Analysis, V16, P632, DOI 10.1134/S1054661806040080
   Guo C, 2018, MULTIMED TOOLS APPL, V77, P19569, DOI 10.1007/s11042-017-5412-4
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Harjito B, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P143, DOI 10.1109/ISESD.2016.7886708
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Prasetyo H, 2018, INT C COMP CONT INF
   Prasetyo H., 2018, MULTIMED TOOLS APPL, P1
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yan XH, 2017, DIGIT SIGNAL PROCESS, V71, P36, DOI 10.1016/j.dsp.2017.08.006
   Zarepour-Ahmadabadi J, 2018, MULTIMED TOOLS APPL, V77, P24073, DOI 10.1007/s11042-018-5717-y
NR 21
TC 20
Z9 20
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24837
EP 24862
DI 10.1007/s11042-019-7710-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900053
DA 2024-07-18
ER

PT J
AU Revina, IM
   Emmanuel, WRS
AF Revina, I. Michael
   Emmanuel, W. R. Sam
TI MDTP: a novel multi-directional triangles pattern for face expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MDTP descriptor; FER; SVNN; MDTP-FES; Triangle pattern
ID FEATURES
AB Face expression recognition is a key-subject of machine learning, and the primary issue on it is lack of accuracy. This paper proposes a novel face expression recognition method using Decision Based Rule-Oriented Median Filter (DBROMF) and Multi-Directional Triangles Pattern (FER-MDTP). The DBROMF is a novel noise reduction method which removes the impulse noise from the facial images. This FER method enriched with a new image descriptor (MDTP) which is structured via multi-directional triangle pattern to provide a superior image description. An unparalleled novel algorithm to locate the human face organ viz. lip and eyeball stuffed in this research by getting assistance with fuzzy edge strength and abbreviated as an MDTP-FES method. These landmarks of features extracted, and the histogram oriented features tailored with the classification division. The support vector neural network classifier (SVNN) is integrated to conduct the classification job. The JAFFE, CK, TFEID, and ADFES databases are linked to perform the simulation which telescoped with six face expressions. The proposed method lifts the accuracy to a significant range than the existing state-of-the-art methods.
C1 [Revina, I. Michael; Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Revina, IM (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM michaelrevina09@gmail.com; sam_emmanuel@nmcc.ac.in
RI EMMANUEL, W R SAM/E-5526-2018; Revina, Michael/AAO-3279-2021
CR [Anonymous], 2000, COHN KANADE AU CODED
   [Anonymous], 2007, TFEID TAIWANESE FACI
   BETTADAPURA V, 2012, COMPUTER SCI
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Ding YY, 2017, IEEE ACCESS, V5, P19409, DOI 10.1109/ACCESS.2017.2737821
   Hawk ST, 2011, MOVING FACES LOOKING, V11, P907, DOI [10.1037/a0023853, DOI 10.1037/A0023853]
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Kumar S, 2016, IET COMPUT VIS, V10, P567, DOI 10.1049/iet-cvi.2015.0273
   Liu ZT, 2017, IEEE-CAA J AUTOMATIC, V4, P668, DOI 10.1109/JAS.2017.7510622
   Ludwig O, 2014, NEUROCOMPUTING, V124, P33, DOI 10.1016/j.neucom.2013.08.005
   Mao QR, 2017, IEEE T MULTIMEDIA, V19, P861, DOI 10.1109/TMM.2016.2629282
   Meena HK, 2017, ELECTRON LETT, V53, P721, DOI 10.1049/el.2017.0420
   Meng HY, 2016, IEEE T CYBERNETICS, V46, P916, DOI 10.1109/TCYB.2015.2418092
   Michael L, 1999, FACIAL EXPRESSION DA
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Muhammad G, 2017, IEEE ACCESS, V5, P10871, DOI 10.1109/ACCESS.2017.2712788
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   Nazir M, 2018, CLUSTER COMPUT, V21, P539, DOI 10.1007/s10586-017-0921-5
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Cruz EAS, 2018, PATTERN RECOGN LETT, V114, P13, DOI 10.1016/j.patrec.2017.08.008
   Uddin MZ, 2017, IEEE ACCESS, V5, P26146, DOI 10.1109/ACCESS.2017.2777003
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Yan H, 2012, IET BIOMETRICS, V1, P160, DOI 10.1049/iet-bmt.2012.0006
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Yi JZ, 2014, IET COMPUT VIS, V8, P429, DOI 10.1049/iet-cvi.2013.0171
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
NR 30
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26223
EP 26238
DI 10.1007/s11042-019-7711-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700044
DA 2024-07-18
ER

PT J
AU Bulbul, MF
   Islam, S
   Ali, H
AF Bulbul, Mohammad Farhad
   Islam, Saiful
   Ali, Hazrat
TI 3D human action analysis and recognition through GLAC descriptor on 2D
   motion and static posture images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; l2-CRC; Motion history images; Static history
   images
ID REPRESENTATION; GRADIENTS; FUSION; HISTOGRAMS; ENSEMBLE; NETWORK;
   VISION; SCALE; POSE
AB In this paper, we present an approach for identification of actions within depth action videos. First, we process the video to get motion history images (MHIs) and static history images (SHIs) corresponding to an action video based on the use of 3D Motion Trail Model (3DMTM). We then characterize the action video by extracting the Gradient Local Auto-Correlations (GLAC) features from the SHIs and the MHIs. The two sets of features i.e., GLAC features from MHIs and GLAC features from SHIs are concatenated to obtain a representation vector for action. Finally, we perform the classification on all the action samples by using the l2-regularized Collaborative Representation Classifier (l2-CRC) to recognize different human actions in an effective way. We perform evaluation of the proposed method on three action datasets, MSR-Action3D, DHA and UTD-MHAD. Through experimental results, we observe that the proposed method performs superior to other approaches.
C1 [Bulbul, Mohammad Farhad] Jashore Univ Sci & Technol, Dept Math, Jashore, Bangladesh.
   [Islam, Saiful] Bangabandhu Sheikh Mujibur Rahman Sci & Technol U, Dept Math, Gopalganj, Bangladesh.
   [Ali, Hazrat] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Abbottabad Campus, Abbottabad, Pakistan.
C3 Bangabandhu Sheikh Mujibur Rahman Science & Technology University;
   COMSATS University Islamabad (CUI)
RP Ali, H (corresponding author), COMSATS Univ Islamabad, Dept Elect & Comp Engn, Abbottabad Campus, Abbottabad, Pakistan.
EM farhad@just.edu.bd; saifulislambsmrstu@gmail.com;
   hazratali@cuiatd.edu.pk
RI ISLAM, SAIFUL/HMD-6072-2023; Ali, Hazrat/J-2920-2019
OI ISLAM, SAIFUL/0000-0001-6693-0559; Ali, Hazrat/0000-0003-3058-5794
CR Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulbul MF, 2015, INT J MULTIMED DATA, V6, P23, DOI 10.4018/IJMDEM.2015100102
   Bulbul MF, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P389, DOI 10.1109/BigMM.2015.82
   Chen C., 2016, P 25 INT JOINT C ART, P3331
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2015, LECT NOTES COMPUT SC, V9474, P613, DOI 10.1007/978-3-319-27857-5_55
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen C, 2014, IEEE ENG MED BIO, P4135, DOI 10.1109/EMBC.2014.6944534
   Chen C, 2014, IEEE ENG MED BIO, P4983, DOI 10.1109/EMBC.2014.6944743
   Chen C, 2014, IEEE T GEOSCI REMOTE, V52, P365, DOI 10.1109/TGRS.2013.2240307
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Chen C, 2012, CONF REC ASILOMAR C, P608, DOI 10.1109/ACSSC.2012.6489079
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen E., 2017, Int J Multimed Ubiquit Eng, V12, P203, DOI [10.14257/ijmue.2017.12.1.17, DOI 10.14257/IJMUE.2017.12.1.17]
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Farhad M, 2015, P INT C INT COMP FUZ
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hossein Rahmani Q, 2015, DISCRIMINATIVE HUMAN
   Jia XF, 2012, INT C PATT RECOG, P3001
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V5302, P346, DOI 10.1007/978-3-540-88682-2_27
   Lei Q, 2018, MULTIMED TOOLS APPL, V77, P11403, DOI 10.1007/s11042-018-5626-0
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang B, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P684, DOI 10.1109/ICCVW.2013.94
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu H, 2015, IEEE IMAGE PROC, P4674, DOI 10.1109/ICIP.2015.7351693
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Theodoridis T, 2008, IEEE INT CONF ROBOT, P3064, DOI 10.1109/ROBOT.2008.4543676
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L, 2015, LECT NOTES COMPUT SC, V9428, P581, DOI 10.1007/978-3-319-25417-3_68
   Wiliem A., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P270, DOI 10.1109/DICTA.2010.55
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang R, 2014, ASIAN C COMPUTER VIS, P37
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yu Kong, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163084
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zeng SC, 2018, SIGNAL IMAGE VIDEO P, V12, P1551, DOI 10.1007/s11760-018-1311-z
   Zhang B, 2017, IEEE T IMAGE PROCESS, V26
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhu HM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1082, DOI 10.1109/ICInfA.2013.6720456
NR 67
TC 11
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21085
EP 21111
DI 10.1007/s11042-019-7365-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400024
DA 2024-07-18
ER

PT J
AU Guo, DL
   Wen, QY
   Jin, ZP
   Zhang, H
   Li, WM
AF Guo, Dianli
   Wen, Qiaoyan
   Jin, Zhengping
   Zhang, Hua
   Li, Wenmin
TI Authenticated public key broadcast encryption with short ciphertexts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broadcast encryption; Public key; Broadcaster authentication; Constant
   sized ciphertext
ID SECURE; SCHEME
AB Broadcast encryption allows a broadcaster, who wants to distribute messages to a chosen subset of receivers, to produce an encrypted content and transmit it via a broadcast channel. Normally we think that it is preferable if the broadcast encryption system is a public-key cryptosystem, which permits anybody could encrypt and distribute messages with public parameters. Nevertheless, such a broadcast strategy brings along a slew of diffusions of the spam that are uncontrollable. Authenticated public key broadcast encryption ensures that no such strategy can succeed - the encryption algorithm creates ciphertext with public key and the broadcaster's secret key. It means that each broadcasted message is associated to the content distributor in order to ensure accountability. Technically, it embeds a signature in the ciphertext and each authorized users could verify it during decrypting. In this paper, we construct a solution for authenticated public key broadcast encryption using bilinear maps where the ciphertext is of O(1) (only constant number of group elements). The public key size and user private key are of size O(N) (N is the total number of users). The simulation experiment results indicated that the size of public key (private key) is about 4MB where we arbitrarily set N = 100000. Finally, we define the security for authenticated public key broadcast encryption and show that our construction captures static security in the standard model.
C1 [Guo, Dianli; Wen, Qiaoyan; Jin, Zhengping; Zhang, Hua; Li, Wenmin] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Guo, Dianli] Natl Comp Syst Engn Res Inst China, Beijing 100083, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Guo, DL; Jin, ZP (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Guo, DL (corresponding author), Natl Comp Syst Engn Res Inst China, Beijing 100083, Peoples R China.
EM guodianlil@163.com; zhpjin@bupt.edu.cn
FU NSFC [61502044]; Fundamental Research Funds for the Central Universities
   [2015RC23]
FX The authors are grateful to the editor and anonymous reviewers for their
   valuable suggestions. This work is supported by NSFC (Grant Nos.
   61502044), the Fundamental Research Funds for the Central Universities
   (Grant No. 2015RC23).
CR Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D., 2006, P ACM C COMPUTER COM, P211, DOI DOI 10.1145/1180405.1180432
   Boneh D., 2003, CONT MATH, V324, P71, DOI DOI 10.1090/CONM/324/05731
   Boneh D, 2006, LECT NOTES COMPUT SC, V4004, P573
   Boneh D, 2014, LECT NOTES COMPUT SC, V8616, P480, DOI 10.1007/978-3-662-44371-2_27
   Boneh D, 2014, LECT NOTES COMPUT SC, V8616, P206, DOI 10.1007/978-3-662-44371-2_12
   Boneh D, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P501
   Chor B, 2000, IEEE T INFORM THEORY, V46, P893, DOI 10.1109/18.841169
   Coron JS, 2016, LECT NOTES COMPUT SC, V9815, P607, DOI 10.1007/978-3-662-53008-5_21
   Coron JS, 2013, LECT NOTES COMPUT SC, V8042, P476, DOI 10.1007/978-3-642-40041-4_26
   De Salve A, 2020, IEEE T DEPEND SECURE, V17, P2, DOI 10.1109/TDSC.2017.2729553
   Du XJ, 2005, IEEE T BROADCAST, V51, P264, DOI 10.1109/TBC.2005.847600
   Elhoseny M, 2016, SECUR COMMUN NETW, V9, P2024, DOI 10.1002/sec.1459
   Elhoseny M, 2016, J KING SAUD UNIV-COM, V28, P262, DOI 10.1016/j.jksuci.2015.11.001
   Fiat A., 1993, LECT NOTES COMPUTER, P480, DOI DOI 10.1007/3-540-48329-2
   Garg S, 2013, ANN IEEE SYMP FOUND, P40, DOI 10.1109/FOCS.2013.13
   Garg S, 2013, LECT NOTES COMPUT SC, V7881, P1, DOI 10.1007/978-3-642-38348-9_1
   Garg S, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P121, DOI 10.1145/1866307.1866322
   Gentry C, 2009, LECT NOTES COMPUT SC, V5479, P171, DOI 10.1007/978-3-642-01001-9_10
   Guo DL, 2016, IEEE T BROADCAST, V62, P709, DOI 10.1109/TBC.2016.2550759
   Hu YP, 2016, LECT NOTES COMPUT SC, V9665, P537, DOI 10.1007/978-3-662-49890-3_21
   Joux A, 2004, J CRYPTOL, V17, P263, DOI 10.1007/s00145-004-0312-y
   Joux A, 2003, J CRYPTOL, V16, P239, DOI 10.1007/s00145-003-0052-4
   Kim J, 2015, IEEE T INF FOREN SEC, V10, P679, DOI 10.1109/TIFS.2014.2388156
   Laarhoven T, 2013, IEEE T INFORM THEORY, V59, P4230, DOI 10.1109/TIT.2013.2251756
   Langlois A, 2014, LECT NOTES COMPUT SC, V8441, P239, DOI 10.1007/978-3-642-55220-5_14
   Lee K, 2014, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-04462-0
   Liu WR, 2016, INT J INF SECUR, V15, P35, DOI 10.1007/s10207-015-0287-8
   Nishimaki R, 2016, LECT NOTES COMPUT SC, V9666, P388, DOI 10.1007/978-3-662-49896-5_14
   Park C, 2012, MATH COMPUT MODEL, V55, P113, DOI 10.1016/j.mcm.2011.01.056
   Park JH, 2008, IEEE T BROADCAST, V54, P401, DOI 10.1109/TBC.2008.919940
   Park JH, 2011, J COMMUN NETW-S KOR, V13, P428, DOI 10.1109/JCN.2011.6112299
   Selvi S. Sharmila Deva, 2008, Information Security Applications. 9th International Workshop, WISA 2008. Revised Selected Papers, P115
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Waters B, 2009, LECT NOTES COMPUT SC, V5677, P619, DOI 10.1007/978-3-642-03356-8_36
   Zhandry M, 2014, IACR CRYPTOLOGY EPRI, V757
   Zhang LY, 2012, MATH COMPUT MODEL, V55, P12, DOI 10.1016/j.mcm.2011.01.004
NR 38
TC 2
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23399
EP 23414
DI 10.1007/s11042-019-7598-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400053
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Gupta, R
   Son, LH
   Kumar, R
   Jha, S
AF Kapoor, Rajiv
   Gupta, Rashmi
   Son, Le Hoang
   Kumar, Raghvendra
   Jha, Sudan
TI Fog removal in images using improved dark channel prior and contrast
   limited adaptive histogram equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atmospheric dichromatic model; Computer vision; Contrast limited
   adaptive histogram equalization; Dark channel prior; Defogging; Guided
   filter
ID HAZE; RESTORATION; FRAMEWORK
AB It is necessary to perform fog removal from an image based on the estimation of depth to increase the visibility of a scene. In this paper, we propose a new algorithm to eradicate fog from images in which fog is defined as a state or cause of perplexity or confusion with respect to the image. It runs at high speed and simultaneously minimizes the halo-artifact with a new median operator in dark channel prior. The proposed method is based on Guided Filter for transmission-map refinement and Contrast Limited Adaptive Histogram Equalization (CLAHE) for visibility improvement. It preserves small details while remaining robust against density of fog, and recovers scene contrast simultaneously. Guided filter improved the transmission map acquired from Median dark channel prior (MDCP), which is an improvement of the Dark Channel Prior DCP by the use of median operation. All of the parameters used in our method are data driven. The quality of algorithm has been validated on several types of fog-degraded images where considerable variation in contrast and illumination exists. Moreover, its performance is compared with the other state-of-the-art methods. The experimental results indicate that the proposed method effectively restores the color and contrast of scene as well as produces satisfactory information in homogeneous fog. It outperforms the existing fog removal methods for run time computational time and other evaluation metrics for rating of visibility enhancement. The proposed method conserves small details part of the image when outstanding vigorous against concentration of fog, and recuperate scene contrast instantaneously. It controls at a high speed than the existing approaches and can diminish the halo effect.
C1 [Kapoor, Rajiv] Delhi Technol Univ, ECE Dept, Delhi, India.
   [Gupta, Rashmi] GGSIPU, AIACT&R, ECE Dept, Delhi, India.
   [Son, Le Hoang] Duy Tan Univ, Inst Res & Dev, Da Nang, Vietnam.
   [Son, Le Hoang] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Kumar, Raghvendra] LNCT Coll, Comp Sci & Engn Dept, Bhopal, India.
   [Jha, Sudan] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar, Odisha, India.
C3 Delhi Technological University; Netaji Subhas University of Technology;
   Netaji Subhas University of Technology (East Campus); GGS Indraprastha
   University; Duy Tan University; Vietnam National University Hanoi;
   Kalinga Institute of Industrial Technology (KIIT)
RP Son, LH (corresponding author), Duy Tan Univ, Inst Res & Dev, Da Nang, Vietnam.; Son, LH (corresponding author), Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
EM rajivkapoor@dce.ac.in; rashmig71@yahoo.com; sonlh@vnu.edu.vn;
   raghvendraagrawal7@gmail.com; jhasudan@hotmail.com
RI Jha, Sudan/P-9823-2018; Gupta, Rashmi/KMY-3135-2024; Kapoor,
   Rajiv/AAA-2011-2022; Gupta, Rashmi/HLH-0461-2023
OI Jha, Sudan/0000-0003-0074-2584; Gupta, Rashmi/0000-0003-3983-4638;
   Kapoor, Rajiv/0000-0003-3020-1455; Hoang Son, Le/0000-0001-6356-0046
FU Duy Tan University
FX The author (Le Hoang Son) would like to express a sincere thank to the
   sponsor of a project regarding Computer Vision and Artificial
   Intelligence from the Duy Tan University
CR Ancuti CO, 2011, LECT NOTES COMPUT SC, V6493, P501
   [Anonymous], P 2001 IEEE COMP VIS
   [Anonymous], ARTIFICIAL NEURAL NE
   [Anonymous], ARXIV150500996
   Vo BN, 2017, IEEE T SIGNAL PROCES, V65, P1975, DOI 10.1109/TSP.2016.2641392
   Berman D., 2016, CVPR
   Chaker A, 2018, MULTIMED TOOLS APPL, V77, P1, DOI 10.1007/s11042-016-4205-5
   Cheng FC, 2015, ENG APPL ARTIF INTEL, V43, P27, DOI 10.1016/j.engappai.2015.03.011
   Dobler G, 2011, ASTROPHYS J, V741, DOI 10.1088/0004-637X/741/1/25
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   [蒋建国 Jiang Jianguo], 2011, [电路与系统学报, Journal of Circuits and Systems], V16, P7
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim JH, 2011, INT CONF ACOUST SPEE, P1273
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kundur D, 1998, IEEE T SIGNAL PROCES, V46, P375, DOI 10.1109/78.655423
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Park D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P139, DOI 10.1109/ICCE.2012.6161832
   Qiao T, 2018, MULTIMED TOOLS APPL, V77, P1501, DOI 10.1007/s11042-016-4314-1
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi L, 2016, MATEC WEB CONF, V75, DOI 10.1051/matecconf/20167503008
   [孙小明 Sun Xiaoming], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P381
   Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tran Manh Tuan, 2017, International Journal of Fuzzy Systems Applications, V6, P1, DOI 10.4018/IJFSA.2017010101
   Tuan TM, 2016, APPL INTELL, V45, P402, DOI 10.1007/s10489-016-0763-5
   Ngan TT, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0634-y
   Wang GX, 2013, GENET MOL RES, V12, P1168, DOI 10.4238/2013.April.12.3
   Wang Y, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 3, P1270, DOI 10.1109/ICEMI.2015.7494515
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2225, DOI 10.1109/ICACCI.2014.6968569
   Yang S, 2013, ADV INTEL SYS RES, V84, P279
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao SY, 2016, IEEE T SIGNAL PROCES, V64, P2284, DOI 10.1109/TSP.2016.2516960
NR 45
TC 17
Z9 18
U1 4
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23281
EP 23307
DI 10.1007/s11042-019-7574-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400049
DA 2024-07-18
ER

PT J
AU Li, XD
   Li, WH
   Liu, B
   Yu, NH
AF Li, Xiaodan
   Li, Weihai
   Liu, Bin
   Yu, Nenghai
TI Object and patch based anomaly detection and localization in crowded
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly; Object; Colorizing; Patch; Re-targeting
ID ABNORMAL EVENT DETECTION; HISTOGRAMS
AB Detecting and localizing anomalies in crowded scenes is an ongoing challenge for public security. Existing approaches are mainly based on patches and trajectories. However, they fall short in semantic understanding of scenes and tackling the depth-of-field problem, respectively. In this paper, we put forward a novel object and patch based framework for anomaly detection and localization. Specifically, we propose to colorize images for precise object detection in dim scenarios. Categories of the objects are used for appearance anomaly justification. For motion anomaly, we propose a new patch-based algorithm which is robust to the depth-of-field problem, which can also be used to detect location anomalies. Besides, a new object re-targeting method is proposed to find the missing objects in detection. It can also handle drift and occlusions in tracking, which can avoid false alarms. Extensive experiments are conducted on several benchmark datasets for anomaly detection. The results show that the proposed method can achieve comparable accuracy in anomaly detection with state-of-the-arts methods and at the same time, localize anomalies precisely.
C1 [Li, Xiaodan; Li, Weihai; Liu, Bin; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
   [Li, Xiaodan; Li, Weihai; Liu, Bin; Yu, Nenghai] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences
RP Li, WH (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.; Li, WH (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
EM lxd1030@mail.ustc.edu.cn; whli@ustc.edu.cn; flowice@ustc.edu.cn;
   ynh@ustc.edu.cn
RI liu, bb/GXA-2527-2022
FU National Natural Science Foundation of China [61371192]; Key Laboratory
   Foundation of the Chinese Academy of Sciences [CXJJ-17S044]; Fundamental
   Research Funds for the Central Universities [WK2100330002, WK3480000005]
FX We thank Mahmudul Hasan, W.Luo, W.Liu for sharing their codes and data.
   This work is supported by the National Natural Science Foundation of
   China (Grant No. 61371192), the Key Laboratory Foundation of the Chinese
   Academy of Sciences (CXJJ-17S044) and the Fundamental Research Funds for
   the Central Universities (WK2100330002, WK3480000005).
CR [Anonymous], 2018, IEEE T PATTERN ANAL
   [Anonymous], 2017, ARXIV171209867
   [Anonymous], ARXIV180408381
   Antonakaki P, 2009, SIGNAL PROCESS, V89, P1723, DOI 10.1016/j.sigpro.2009.03.016
   Calderara S, 2011, COMPUT VIS IMAGE UND, V115, P1099, DOI 10.1016/j.cviu.2011.03.003
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Khalid S, 2010, PATTERN RECOGN, V43, P3636, DOI 10.1016/j.patcog.2010.05.006
   Li Q, 2016, INT SYM COMPUT INTEL, P455, DOI [10.1109/ISCID.2016.1112, 10.1109/ISCID.2016.111]
   Liu JW, 2017, IEEE INT C SEMANT CO, P316, DOI 10.1109/ICSC.2017.69
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo Wei, 2017, 2017 IEEE Electrical Design of Advanced Packaging and Systems Symposium (EDAPS), DOI 10.1109/EDAPS.2017.8276933
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sabokrou Mohammad, 2018, COMPUTER VISION IMAG
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
NR 40
TC 4
Z9 4
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21375
EP 21390
DI 10.1007/s11042-019-7447-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400039
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Cheng, YQ
   Yu, B
AF Fu, Zhengxin
   Cheng, Yuqiao
   Yu, Bin
TI Rich QR code with three-layer information using visual secret sharing
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Visual secret sharing scheme; Three-layer information storage;
   Low computational complexity
ID AUTHENTICATION; CRYPTOGRAPHY; ALGORITHM
AB Owing to efficient machine recognition, QR codes have been widely used in many aspects such as information management, electronic identity and mobile payment. Any QR code reader has access to the message contained in a QR code; therefore, in formation security becomes a major challenge to QR codes for private use. Moreover, human vision is hard to distinguish a QR code from others because its appearance looks randomly. In this paper, we propose a visual secret sharing scheme to achieve a rich QR code with three-layer information storage. In the three layers, the first one and the second one are respectively recognizable by human vision and QR code readers, while the third layer is designed for storing private data. Additionally, we also highlight the low computational complexity of secret extraction from the rich QR code.
C1 [Fu, Zhengxin; Cheng, Yuqiao] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Cheng, YQ (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM xdqiao2015@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU National Natural Science Foundation of China [61602513]; Outstanding
   Youth Foundation of Zhengzhou Information Science and Technology
   Institute [2016611303]
FX This work was supported by the National Natural Science Foundation of
   China (grant 61602513) and the Outstanding Youth Foundation of Zhengzhou
   Information Science and Technology Institute (grant 2016611303).
CR [Anonymous], 2017, J REAL-TIME IMAGE PR
   [Anonymous], 2000, 180042000 ISOIEC
   Biswas R, 2012, PROC TECH, V4, P820, DOI 10.1016/j.protcy.2012.05.134
   Chen CS, 2017, MOBILE NETW APPL, V22, P383, DOI 10.1007/s11036-016-0772-y
   Cheng Y, 2017, MULTIMED TOOLS APPL, P1
   Chuang Jun-Chou., 2010, International Journal of Image Processing (IJIP), V4, P468
   Jiang DD, 2018, IEEE T INTELL TRANSP, V19, P3305, DOI 10.1109/TITS.2017.2778939
   Jiang DD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194302
   Jiang DD, 2016, IEEE INTERNET THINGS, V3, P1437, DOI 10.1109/JIOT.2016.2613111
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14281, DOI 10.1007/s11042-016-3402-6
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang DD, 2015, T EMERG TELECOMMUN T, V26, P308, DOI 10.1002/ett.2619
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Krishna MB, 2016, WIRELESS PERS COMMUN, V90, P381, DOI 10.1007/s11277-016-3374-x
   Lin PY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0155-0
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   [刘莺迎 Liu Yingying], 2016, [计算机应用研究, Application Research of Computers], V33, P3460
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Wang JD, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0796-3
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yamashita K, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS 2016), P191, DOI 10.1109/QRS.2016.31
   Yang CN, 2016, THEOR COMPUT SCI, V609, P143, DOI 10.1016/j.tcs.2015.09.016
NR 28
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19861
EP 19875
DI 10.1007/s11042-019-7333-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800042
DA 2024-07-18
ER

PT J
AU Kaur, P
   Kumar, R
   Kumar, M
AF Kaur, Pavleen
   Kumar, Ravinder
   Kumar, Munish
TI A healthcare monitoring system using random forest and internet of
   things (IoT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Data mining; Machine learning; Healthcare
AB The Internet of Things (IoT) enabled various types of applications in the field of information technology, smart and connected health care is notably a crucial one is one of them. Our physical and mental health information can be used to bring about a positive transformation change in the health care landscape using networked sensors. It makes it possible for monitoring to come to the people who don't have ready access to effective health monitoring system. The captured data can then be analyzed using various machine learning algorithms and then shared through wireless connectivity with medical professionals who can make appropriate recommendations. These scenarios already exist, but we intend to enhance it by analyzing the past data for predicting future problems using prescriptive analytics. It will allow us to move from reactive to visionary approach by rapidly spotting trends and making recommendations on behalf of the actual medical service provider. In this paper, the authors have applied different machine learning techniques and considered public datasets of health care stored in the cloud to build a system, which allows for real time and remote health monitoring built on IoT infrastructure and associated with cloud computing. The system will be allowed to drive recommendations based on the historic and empirical data lying on the cloud. The authors have proposed a framework to uncover knowledge in a database, bringing light to disguise patterns which can help in credible decision making. This paper has evaluated prediction systems for diseases such as heart diseases, breast cancer, diabetes, spect_heart, thyroid, dermatology, liver disorders and surgical data using a number of input attributes related to that particular disease. Experimental results are conducted using a few machine learning algorithms considered in this paper like K-NN, Support Vector Machine, Decision Trees, Random Forest, and MLP.
C1 [Kaur, Pavleen; Kumar, Ravinder] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM amicablepavleen@gmail.com; ravinder@thapar.edu; munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; Kumar, Ravinder/JLL-7567-2023
OI Kumar, Munish/0000-0003-0115-1620; Kumar, Ravinder/0000-0002-0271-2373
CR Agarwal S., 2013, INT J BIOSCI BIOTECH, V5, P241, DOI [DOI 10.14257/IJBSBT.2013.5.5.25, 10.14257/ijbsbt.2013.5.5.25]
   [Anonymous], 2015, INT J CYBERNETICS IN, DOI DOI 10.5121/IJCI.2015.440213
   [Anonymous], OXFORD J INTELL DECI
   Costa K, 2013, P 3 INT C INN COMP T, P344
   Devi MRenuka., 2016, International Journal of Applied Engineering Research, V11, P727
   Díaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3
   Forkan ARM, 2017, COMPUT NETW, V113, P244, DOI 10.1016/j.comnet.2016.12.019
   Hameed R. T., 2015, 5 IEEE INT C E HLTH, P1
   Hsu JL, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0210-x
   Jahangir M, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P722, DOI 10.1109/IntelliSys.2017.8324209
   Osman AH, 2017, INT J ADV COMPUT SC, V8, P236
   Parekh M, 2015, PROCEDIA COMPUT SCI, V50, P537, DOI 10.1016/j.procs.2015.04.029
   Tao DP, 2016, IEEE INTERNET THINGS, V3, P1124, DOI 10.1109/JIOT.2016.2561962
   Tao DP, 2017, IEEE T CIRC SYST VID, V27, P62, DOI 10.1109/TCSVT.2016.2539778
   Verikas A, 2011, PATTERN RECOGN, V44, P330, DOI 10.1016/j.patcog.2010.08.011
   Verma L, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0536-z
   Zhang L, 2018, APPL INTELL, V48, P1878, DOI 10.1007/s10489-017-1056-3
NR 17
TC 115
Z9 118
U1 2
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19905
EP 19916
DI 10.1007/s11042-019-7327-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800044
DA 2024-07-18
ER

PT J
AU Varshovi, H
   Kavian, YS
   Ansari-Asl, K
AF Varshovi, Hamzeh
   Kavian, Yousef Seifi
   Ansari-Asl, Karim
TI Design and implementing wireless multimedia sensor network for movement
   detection using FPGA local co-processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Image processing; FPGA; Local
   processing
ID ARCHITECTURE; ALGORITHM; COVERAGE; QOS
AB In recent years, many researches have been conducted on designing wireless multimedia sensor networks. But, implementing these networks faces several challenges. One of these challenges is the bulky nature of the multimedia data which needs powerful radios with high data rates for transmission and requires much more energy. So, in some applications it is more efficient to process the data locally and send the results to the base station which allows WMSNs to be implemented using simple and cheap network nodes. In this paper a wireless multimedia sensor network has been designed which processes the images locally using small FPGA processors in order to detect possible motions and the time and location of the detected movements will be sent to the base station. The network is implemented to perform two motion detection algorithms separately using Spartan 6 FPGAs and the local results of motion detection and global result of the network are presented.
C1 [Varshovi, Hamzeh; Kavian, Yousef Seifi; Ansari-Asl, Karim] Shahid Chamran Univ Ahvaz, Dept Elect Engn, Fac Engn, Ahvaz, Iran.
C3 Shahid Chamran University of Ahvaz
RP Kavian, YS (corresponding author), Shahid Chamran Univ Ahvaz, Dept Elect Engn, Fac Engn, Ahvaz, Iran.
EM y.s.kavian@scu.ac.ir
RI Ansari-Asl, Karim/H-7619-2016
OI Ansari-Asl, Karim/0000-0002-3953-8962; Ansari-Asl,
   Karim/0000-0003-1655-131X
FU Shahid Chamran University of Ahvaz [96/3/02/16670]
FX This work was supported in part by Shahid Chamran University of Ahvaz
   under Grant Number 96/3/02/16670.
CR [Anonymous], 2014, IEEE FAIBLE TENSION
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Chaple G., 2014, International Conference on Communication and Digital Processing, India, P788
   Chen HC, 2017, MULTIMED TOOLS APPL, V76, P25231, DOI 10.1007/s11042-016-4302-5
   Chen J, 2013, IEEE SENS J, V13, P2077, DOI 10.1109/JSEN.2013.2248144
   Chowdary MK, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1032, DOI 10.1109/iccsp.2013.6577213
   Dash P.K., 2014, INT C INFORM COMMUNI, P1, DOI DOI 10.1109/PESTSE.2014.6805295
   Demir AK, 2014, WIREL NETW, V20, P655, DOI 10.1007/s11276-013-0628-3
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Gujrathi P, 2014, 2014 FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC), P117, DOI 10.1109/ICACC.2014.34
   Guo G, 2015, CAN CON EL COMP EN, P118, DOI 10.1109/CCECE.2015.7129171
   Hamid Z, 2014, WIRELESS PERS COMMUN, V75, P729, DOI 10.1007/s11277-013-1389-0
   Hasan KK, 2014, WIRELESS PERS COMMUN, V77, P1415, DOI 10.1007/s11277-013-1588-8
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim YM, 2017, MULTIMED TOOLS APPL, V76, P19707, DOI 10.1007/s11042-016-3440-0
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lloret J, 2011, SENSORS-BASEL, V11, P6165, DOI 10.3390/s110606165
   Lopez-Bravo A, 2013, INT CONF ELECTR COMM, P92, DOI 10.1109/CONIELECOMP.2013.6525766
   Mahesh CP, 2014, INT J EMERGING TREND, V3, P215
   Manzanera A, 2007, LECT NOTES COMPUTER, V4756
   Mekonnen T, 2017, IEEE ACCESS, V5, P15848, DOI 10.1109/ACCESS.2017.2737078
   Nandhini SA, 2017, COMPUT ELECTR ENG, V60, P175, DOI 10.1016/j.compeleceng.2017.01.027
   Possa PR, 2014, IEEE T COMPUT, V63, P2376, DOI 10.1109/TC.2013.130
   Rehman YAU, 2016, IEEE SENS J, V16, P5942, DOI 10.1109/JSEN.2016.2574989
   Rodrigues IN, 2015, 2015 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON), P841, DOI 10.1109/Chilecon.2015.7404670
   Rodriguez-Gomez R, 2015, J REAL-TIME IMAGE PR, V10, P43, DOI 10.1007/s11554-012-0249-6
   Shen B, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/184639
   Wang HG, 2013, J SUPERCOMPUT, V64, P883, DOI 10.1007/s11227-010-0500-5
   Wang P, 2013, IEEE T MULTIMEDIA, V15, P684, DOI 10.1109/TMM.2012.2236304
   Wang R, 2014, INT CONF SIGN PROCES, P434, DOI 10.1109/ICOSP.2014.7015043
   Yap FGH, 2014, SENSORS-BASEL, V14, P3506, DOI 10.3390/s140203506
   Zhang B, 2013, IEEE T CIRC SYST VID, V23, P823, DOI 10.1109/TCSVT.2012.2223872
   Zhang XF, 2018, MULTIMED TOOLS APPL, V77, P13679, DOI 10.1007/s11042-017-4981-6
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 38
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17413
EP 17435
DI 10.1007/s11042-018-7104-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200005
DA 2024-07-18
ER

PT J
AU Chen, JW
   Jin, Y
   Akram, MW
   Li, K
   Chen, EH
AF Chen, Jiongwei
   Jin, Yi
   Akram, Muhammad Waqar
   Li, Kuan
   Chen, Enhong
TI Novel multi-convolutional neural network fusion approach for smile
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smile recognition; Convolutional neural networks; Deep learning; Model
   fusion; Unconstrained face images
AB The smile is one of the most common human facial expressions encountered in our daily lives. Smile recognition can be used in many scenarios, such as emotion monitoring, human-to-robot games, and camera shutter control, which is why smile recognition has received significant attention of researchers. This topic is a significant but challenging problem, particularly in unconstrained scenarios. The variety of facial sizes, illumination conditions, head poses, occlusions, and other factors increases the difficulty of this problem. To address this problem, we propose a novel multiple convolutional neural network (CNN) fusion approach in which a face-based CNN and a mouth-based CNN are used to perform smile recognition. According to the results obtained using the two CNNs, we fuse the two networks using a specified weight and choose the higher-probability result as the final result. Experimental results indicate that the method is effective on a real-world smile dataset (GENKI-4K). The smile recognition rate of the proposed method is improved by 1.6% and 3.3% relative to the face-based CNN and mouth-based CNN, respectively, and the proposed method outperforms the most of previous methods.
C1 [Chen, Jiongwei; Jin, Yi; Akram, Muhammad Waqar; Li, Kuan] Univ Sci & Technol China, Sch Engn Sci, Hefei 230026, Anhui, Peoples R China.
   [Chen, Enhong] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Jin, Y (corresponding author), Univ Sci & Technol China, Sch Engn Sci, Hefei 230026, Anhui, Peoples R China.
EM jinyi08@ustc.edu.cn
RI Jin, Yi/ABG-3022-2022; Akram, Muhammad Waqar/T-7150-2018
OI Akram, Muhammad Waqar/0000-0001-5559-043X; Chen,
   Enhong/0000-0002-4835-4102
FU National Science Foundation of China [51605464]; National Basic Research
   Program of China (973Program) [2014CB049500]; Research on the Major
   Scientific Instrument of National Natural Science Foundation of China
   [61727809]
FX This research was supported by the National Science Foundation of China
   (Grant Nos. 51605464), National Basic Research Program of China
   (973Program) (2014CB049500) and Research on the Major Scientific
   Instrument of National Natural Science Foundation of China (61727809).
CR An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   [Anonymous], URBAN WATER QUALITY
   [Anonymous], 2018, MPLAB GENKI 4K DATAB
   Bianco S, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063002
   Bogdan P, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2435227.2435246
   Chen JK, 2017, MACH VISION APPL, V28, P173, DOI 10.1007/s00138-016-0817-z
   Cui DS, 2016, IEEE IJCNN, P2298, DOI 10.1109/IJCNN.2016.7727484
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   González JD, 2007, RICYDE-REV INT CIENC, V3
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gao Y, 2016, NEUROCOMPUTING, V174, P1077, DOI 10.1016/j.neucom.2015.10.022
   Glauner PO, 2015, COMPUT SCI
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Glorot X., 2010, P INT C ART INT STAT, P249
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jain V, 2014, INT C PATT RECOG, P3987, DOI 10.1109/ICPR.2014.683
   Kahou SE, 2015, LECT NOTES COMPUT SC, V8926, P135, DOI 10.1007/978-3-319-16181-5_10
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li S., 2012, Asian Conference on Computer Vision, P577
   Liu C, 2016, MULTIMED TOOLS APPL, V75, P13023, DOI 10.1007/s11042-015-2550-4
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   RUBIN LR, 1974, PLAST RECONSTR SURG, V53, P384, DOI 10.1097/00006534-197404000-00002
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Zhang KH, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P534, DOI 10.1109/ACPR.2015.7486560
   Zhang YZ, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P482, DOI 10.1109/ICMLA.2012.88
NR 37
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15887
EP 15907
DI 10.1007/s11042-018-6945-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500008
DA 2024-07-18
ER

PT J
AU Nguyen, DC
   Nguyen, TS
   Hsu, FR
   Hsien, HY
AF Dinh-Chien Nguyen
   Thai-Son Nguyen
   Hsu, Fang-Rong
   Hsien, Hsieh-Yung
TI A novel steganography scheme for video H.264/AVC without distortion
   drift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Data hiding; DCT; H; 264; AVC; Distortion drift; QDCT
ID DATA HIDING ALGORITHM; ROBUST WATERMARKING; SMVQ
AB Many steganography schemes have been proposed for video sequences. However, the embedding capacity obtained by these schemes is still unsatisfactory. In this paper, a novel steganography scheme has proposed to further improve the embedding capacity while guaranteeing high visual quality of embedded video H.264/AVC sequences. In the proposed scheme, quantized DCT coefficients are divided into two different clusters, hiding cluster and preventing cluster. Then, the hiding cluster is used for embedding the secret data with small distortion while the preventing cluster is used for avoiding the distortion drift in stego video sequence. In the proposed scheme, the embedding modification direction table is constructed for embedding data. By doing so, the distortion in the embedded video sequence is maintained as small as possible. Experimental results demonstrated that the proposed scheme outperforms to other existing schemes in terms of embedding capacity while maintaining good visual quality.
C1 [Dinh-Chien Nguyen; Hsu, Fang-Rong; Hsien, Hsieh-Yung] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   [Dinh-Chien Nguyen] Hung Yen Univ Technol & Educ, Fac Informat Technol, Hung Yen, Vietnam.
   [Thai-Son Nguyen] Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Vietnam.
C3 Feng Chia University; Tra Vinh University
RP Nguyen, TS (corresponding author), Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Vietnam.
EM chienql@gmail.com; thaison@tvu.edu.vn; frhsu888@gmail.com;
   transforu@seed.net.tw
RI Nguyen, Thai-Son/AGD-3594-2022
OI Nguyen, Thai-Son/0000-0001-7008-0462
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2016.06]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2016.06.
CR [Anonymous], CHI SQUAR STEG TEST
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Chang CC, 2014, INFORMATICA-LITHUAN, V25, P523, DOI 10.15388/Informatica.2014.27
   Dalal M., 2018, International Journal of Computer Sciences and Engineering Open Access H . 264 / AVC Video Steganography Techniques: An Overview, DOI [DOI 10.26438/IJCSE/V6I5.297303, 10.26438/ijcse/v6i5.297303]
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Huo WJ, 2011, IEEE SIGNAL PROC LET, V18, P535, DOI 10.1109/LSP.2011.2162061
   Kapotas SK, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P373, DOI 10.1109/MMSP.2007.4412894
   Lin TJ, 2013, J SYST SOFTWARE, V86, P604, DOI 10.1016/j.jss.2012.10.922
   Liu YX, 2018, IEEE ACCESS, V6, P53984, DOI 10.1109/ACCESS.2018.2869148
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Liu YX, 2014, MULTIMED TOOLS APPL, V72, P613, DOI 10.1007/s11042-013-1393-0
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Muhit AA, 2010, IEEE T CIRC SYST VID, V20, P661, DOI 10.1109/TCSVT.2010.2045804
   Nguyen CV, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P81
   Nguyen T.S., 2014, SMART COMPUT REV, V4, P230, DOI [10.6029/smartcr.2014.03.008, DOI 10.6029/SMARTCR.2014.03.008]
   Niu K, 2017, TSINGHUA SCI TECHNOL, V22, P489
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Pan ZB, 2018, J VIS COMMUN IMAGE R, V50, P186, DOI 10.1016/j.jvcir.2017.11.020
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Stalling W., 2003, CRYPTOGRAPHY NETWORK
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
NR 26
TC 15
Z9 15
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16033
EP 16052
DI 10.1007/s11042-018-6976-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500014
DA 2024-07-18
ER

PT J
AU El Hazzat, S
   Merras, M
   El Akkad, N
   Saaidi, A
   Satori, K
AF El Hazzat, Soulaiman
   Merras, Mostafa
   El Akkad, Nabil
   Saaidi, Abderrahim
   Satori, Khalid
TI Enhancement of sparse 3D reconstruction using a modified match
   propagation based on particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matching; 3D point cloud; 3D reconstruction; Particle swarm optimisation
ID STEREO; CAMERA; CALIBRATION; RETRIEVAL; SYSTEM
AB Sparse 3D reconstruction, based on interest points detection and matching, does not allow to obtain a suitable 3D surface reconstruction because of its incapacity to recover a cloud of well distributed 3D points on the surface of objects/scenes. In this work, we present a new approach to retrieve a 3D point cloud that leads to a 3D surface model of quality and in a suitable time. First of all, our method uses the structure from motion approach to retrieve a set of 3D points (which correspond to matched interest points). After that, we proposed an algorithm, based on the match propagation and the use of particle swarm optimization (PSO), which significantly increases the number of matches and to have a regular distribution of these matches. It takes as input the obtained matches, their corresponding 3D points and the camera parameters. Afterwards, at each time, a match of best ZNCC value is selected and a set of these neighboring points is defined. The point corresponding to a neighboring point and its 3D coordinates are recovered by the minimization of a nonlinear cost function by the use of PSO algorithm respecting the constraint of photo-consistency. Experimental results show the feasibility and efficiency of the proposed approach.
C1 [El Hazzat, Soulaiman; Merras, Mostafa; El Akkad, Nabil; Saaidi, Abderrahim; Satori, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, Fes, Morocco.
   [El Akkad, Nabil] Mohamed First Univ, Natl Sch Appl Sci ENSA Al Hoceima, Dept Math & Comp Sci, Oujda, Morocco.
   [Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Informat, LSI, Taza, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed First University
   of Oujda; Sidi Mohamed Ben Abdellah University of Fez
RP El Hazzat, S (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, Fes, Morocco.
EM soulaiman.elhazzat@usmba.ac.ma; merras.mostafa@gmail.com;
   nabil.elakkad@usmba.ac.ma; abderrahim.saaidi@usmba.ac.ma;
   khalidsatorim3i@yahoo.fr
RI Merras, Mostafa/AAJ-4405-2020; satori, khalid/GSE-3077-2022; AKKAD,
   Nabil EL/AAL-4049-2020; El Hazzat, Soulaiman/AAI-6689-2020
OI Merras, Mostafa/0000-0002-3020-726X; AKKAD, Nabil
   EL/0000-0003-0277-8003; Saaidi, Abderrahim/0000-0003-1708-0468; El
   Hazzat, Soulaiman/0000-0002-6647-1767; SATORI,
   khalid/0000-0001-6055-4169
CR Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2008, P IEEE C COMP VIS PA
   Deep K, 2013, APPL ARTIF INTELL, V27, P618, DOI 10.1080/08839514.2013.813191
   Deng L, 2016, NEUROCOMPUTING, V174, P456, DOI 10.1016/j.neucom.2015.03.119
   El Akkad N, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0082-y
   El Akkad N, 2014, VISUAL COMPUT, V30, P519, DOI 10.1007/s00371-013-0877-2
   El hazzat Soulaiman, 2014, 2014 Fifth International Conference on Next-Generation Networks and Services (NGNS), P194, DOI 10.1109/NGNS.2014.6990252
   El Hazzat S., 2015, Complex Systems (WCCS), 2015 Third World Conference on, P1
   El Hazzat S, 2018, VISUAL COMPUT, V34, P1443, DOI 10.1007/s00371-017-1451-0
   El Hazzat S, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0041-z
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   Lim SP, 2014, ARTIF INTELL REV, V42, P59, DOI 10.1007/s10462-012-9329-z
   Lin C, 2017, SIGNAL PROCESS-IMAGE, V52, P64, DOI 10.1016/j.image.2017.01.001
   Liu J, 2015, VISUAL COMPUT, V31, P1253, DOI 10.1007/s00371-014-1009-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Merras M, 2017, INT J AUTOM COMPUT, V14, P661, DOI 10.1007/s11633-016-0999-x
   Saaidi A., 2008, WSEAS Transactions on Computers Research, V3, P295
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Wong Y.-P., 2010, IEEE C EVOLUTIONARY, P1, DOI DOI 10.1109/CEC.2010.5586426
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Zhang K, 2006, INT J ADV MANUF TECH, V29, P722, DOI 10.1007/s00170-005-2566-4
   Zhang Y, 2016, NEUROCOMPUTING, V195, P40, DOI 10.1016/j.neucom.2015.09.118
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhou Y, 2009, IEEE C EVOL COMPUTAT, P1493, DOI 10.1109/CEC.2009.4983119
   Zou KS, 2014, MULTIMED TOOLS APPL, V69, P799, DOI 10.1007/s11042-012-1130-0
NR 37
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14251
EP 14276
DI 10.1007/s11042-018-6828-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700007
DA 2024-07-18
ER

PT J
AU Hemdan, AM
   Faragallah, OS
   Elshakankiry, O
   Elmhalaway, A
AF Hemdan, Ayman M.
   Faragallah, Osama S.
   Elshakankiry, Osama
   Elmhalaway, Ahmed
TI A fast hybrid image cryptosystem based on random generator and modified
   logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pseudo-random number generator (PRNG); Chaos; Logistic map; Diffusion;
   Image encoding
ID ENCRYPTION ALGORITHM
AB This paper demonstrates an image encryption technique using a hybrid method. This method consists of two stages. The image is XORed with the Pseudo-Random Number Generator (PRNG) in the first stage. The confusion and diffusion processes are applied by using the Logistic map and its' three modifications in the second stage. The original Logistic map has a small range of key-space. The three modifications of Logistic map increased key-space range due to expanding the range of the original Logistic map parameter. Multiple tests have been performed on the hybrid method such as security analysis and encryption quality. The hybrid method presented a good evaluation.
C1 [Hemdan, Ayman M.; Faragallah, Osama S.; Elshakankiry, Osama; Elmhalaway, Ahmed] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.; Elshakankiry, Osama] Taif Univ, Dept Informat Technol, Coll Comp & Informat Technol, Al Hawiya 21974, Taif, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Taif University
RP Faragallah, OS (corresponding author), Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.; Faragallah, OS (corresponding author), Taif Univ, Dept Informat Technol, Coll Comp & Informat Technol, Al Hawiya 21974, Taif, Saudi Arabia.
EM ay_hamdan@hotmail.com; o.salah@tu.edu.sa; o.bahgat@tu.edu.sa;
   ahmed.elmahalawy@el-eng.menofia.edu.eg
RI Faragallah, Osama S./AHB-8031-2022; Elmahalawy, Ahmed
   Moustafa/AAB-9802-2022; Hemdan, Ayman/M-8119-2017
OI Faragallah, Osama S./0000-0003-1982-335X; Elmahalawy, Ahmed
   Moustafa/0000-0001-5739-8628; Hemdan, Ayman/0000-0001-6020-2630
CR Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Elabady NF, 2015, ICET 2 INT C ENG TEC, P851
   Elkamchouchi HM, 2005, RAD SCI C 2005 NRSC, P277, DOI DOI 10.1109/NRSC.2005.194011
   Farajallah M, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500218
   Gokavarapu S, 2015, ADV INTELLIGENT SYST, V1
   Gray R. M., 2010, ENTROPY INFORM THEOR
   Haliuk S, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON MODERN PROBLEMS OF RADIO ENGINEERING, TELECOMMUNICATIONS AND COMPUTER SCIENCE (TCSET), P519, DOI 10.1109/TCSET.2016.7452103
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kamali S., 2010, EL INF ENG ICEIE 201, V1, pV1, DOI DOI 10.1109/ICEIE.2010.5559902
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Martin MT, 2006, PHYSICA A, V369, P439, DOI 10.1016/j.physa.2005.11.053
   Mukhopadhyay D, 2011, CRYPTOGRAPHY NETWORK
   Murillo-Escobar MA, 2016, MICROPROCESS MICROSY, V45, P297, DOI 10.1016/j.micpro.2016.06.004
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rohith S, 2015, INT C ADV EL COMP CO, V6, P1124
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   VOLOS CK, 2013, J APPL MATH BIOINFOR, V3, P123
   Wang CQ, 2017, MULTIMED TOOLS APPL, V76, P24251, DOI 10.1007/s11042-016-4102-y
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Xu SJ, 2008, INT CONF SIGN PROCES, P1014, DOI 10.1109/ICOSP.2008.4697300
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou Y., 2012, IEEE T CYBERNETICS, V45, P2001, DOI DOI 10.1109/TCYB.2014.2363168
NR 24
TC 12
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16177
EP 16193
DI 10.1007/s11042-018-6948-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500020
DA 2024-07-18
ER

PT J
AU Saouli, A
   Babahenini, MC
   Medjram, S
AF Saouli, Abdelhak
   Babahenini, Mohamed Chaouki
   Medjram, Sofiane
TI Accurate, dense and shading-aware multi-view stereo reconstruction using
   metaheuritic optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view stereo (MVS); Depth maps; Swarm optimization;
   Photo-consistency; 3D reconstruction; Multimedia
ID SILHOUETTE; SHAPE
AB Among the modern means of 3D geometry creation that exist in the literature, there are the Multi-View Stereo (MVS) reconstruction methods that received much attention from the research community and the multimedia industry. In fact, several methods showed that it is possible to recover geometry only from images with reconstruction accuracies paralleling that of excessively expensive laser scanners. The majority of these methods perform on images such as online community photo collection and estimate the surface position with its orientation by minimizing a matching cost function defined over a small local region. However, these datasets not only they are large but also contain more challenging scenes setups with different photometric effects; therefore fine-grained details of an object's surface cannot be captured. This paper presents a robust multi-view stereo method based on metaheuristic optimization namely the Particle Swarm Optimization (PSO) in order to find the optimal depth, orientation, and surface roughness. To deal with the various shading and stereo mismatch problems caused by rough surfaces, shadows, and interreflections, we propose to use a robust matching/energy function which is a combination of two similarity measurements. Finally, our method computes individual depth maps that can be merged into compelling scene reconstructions. The proposed method is evaluated quantitatively using well-known Middlebury datasets and the obtained results show a high completeness score and comparable accuracy to those of the current top performing algorithms.
C1 [Saouli, Abdelhak; Babahenini, Mohamed Chaouki] Univ Mohamed Khider, LESIA, Dept Comp Sci, Biskra 07000, Algeria.
   [Medjram, Sofiane] Univ Claude Bernard Lyon 43, LIRIS, Villeurbanne, France.
C3 Universite Mohamed Khider Biskra; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon
RP Saouli, A (corresponding author), Univ Mohamed Khider, LESIA, Dept Comp Sci, Biskra 07000, Algeria.
EM saouli-abdelhak@hotmail.com; chaouki.babahenini@gmail.com;
   Sofiane.Medjram@univ-lyon2.fr
RI Saouli, Abdelhak/AAD-7773-2019; BABAHENINI, Mohamed Chaouki/F-1427-2017
OI BABAHENINI, Mohamed Chaouki/0000-0001-7972-8026; Saouli,
   Abdelhak/0000-0002-0002-1990
CR [Anonymous], BRIT MACH VIS C BMVC
   CHEN Wen-Chao Che Nzen, 2015, J INFORM SCI ENG
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183
   Furukawa Y, 2007, 2007 IEEE COMP SOC C
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Gallup David, 2007, 2007 IEEE COMP SOC C
   Gleirscher M, 2014, 2014 IEEE IWSPM 8TH INTERNATIONAL WORKSHOP ON SOFTWARE PRODUCT MANAGEMENT (IWSPM), P1, DOI 10.1109/IWSPM.2014.6891062
   Goesele M., 2006, COMP VIS PATT REC 20, P2402, DOI DOI 10.1109/CVPR.2006.199
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Harltey R., 2006, MULTIPLE VIEW GEOMET
   Hernández C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820
   Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Langguth F, 2016, LECT NOTES COMPUT SC, V9907, P469, DOI 10.1007/978-3-319-46487-9_29
   Li ZX, 2016, IEEE T IMAGE PROCESS, V25, P864, DOI 10.1109/TIP.2015.2507400
   Mei X, 2011, PROC CVPR IEEE, P1257
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Oren M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P763, DOI 10.1109/CVPR.1993.341163
   Oren M., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P239, DOI 10.1145/192161.192213
   Oren M., 1994, P 21 ANN C COMP GRAP, DOI DOI 10.1145/192161.192213
   Oxholm G, 2014, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2014.277
   Ranftl R, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P401, DOI 10.1109/IVS.2012.6232171
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   SCHLICK C, 1994, COMPUT GRAPH FORUM, V13, P121, DOI 10.1111/1467-8659.1320121
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Semerjian B, 2014, LECT NOTES COMPUT SC, V8694, P719, DOI 10.1007/978-3-319-10599-4_46
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Sinha SN, 2005, IEEE I CONF COMP VIS, P349
   Strecha C., 2008, 2008 IEEE COMP SOC C
   Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388
   Zhan YL, 2016, IEEE T CIRC SYST VID, V26, P1632, DOI 10.1109/TCSVT.2015.2473375
   Zhu ZL, 2015, EPL-EUROPHYS LETT, V109, DOI 10.1209/0295-5075/109/47003
   Zollhöfer M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766887
NR 38
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15053
EP 15077
DI 10.1007/s11042-018-6904-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700041
DA 2024-07-18
ER

PT J
AU Sayed, WS
   Tolba, MF
   Radwan, AG
   Abd-El-Hafiz, SK
AF Sayed, Wafaa S.
   Tolba, Mohammed F.
   Radwan, Ahmed G.
   Abd-El-Hafiz, Salwa K.
TI FPGA realization of a speech encryption system based on a generalized
   modified chaotic transition map and bit permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anti-log unit; Chaos; Encryption; FPGA; Generalized modified transition
   map; Log unit
ID SECURITY; IMPLEMENTATION
AB This paper proposes a generalized modified chaotic transition map with three independent parameters. A hardware speech encryption scheme utilizing this map along with a bit permutation network is presented. While the transition map's generalization introduces additional parameters, the modification enhances its chaotic properties and overcomes the finite range of the control parameter and dynamical degradation problems. The modification also presents a simplification for the hardware realization of the exponentiation operation in the map's equation because the modified output range allows conversion from the linear domain to the Logarithmic Number System (LNS). Mathematical analysis of the map is presented, where exact nonlinear expressions of the dependent parameters are derived and validated through simulations. To further simplify the hardware realization, the complicated nonlinear expressions are linearized and the introduced approximation error is quite acceptable. The encryption scheme is simulated using Xilinx ISE 14.7 and realized on Xilinx Nexys 4 Artix-7 FPGA with a throughput of 1.526 Gbit/sec. The security and efficiency of the hardware speech encryption scheme are validated and the performance is compared with recent works that provided experimental results on Pseudo-Random Number Generation (PRNG) and speech encryption.
C1 [Sayed, Wafaa S.; Radwan, Ahmed G.; Abd-El-Hafiz, Salwa K.] Cairo Univ, Dept Engn Math & Phys, Fac Engn, Giza 12613, Egypt.
   [Tolba, Mohammed F.; Radwan, Ahmed G.] Nile Univ, Nanoelect Integrated Syst Ctr, Cairo 12588, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Nile University
RP Sayed, WS (corresponding author), Cairo Univ, Dept Engn Math & Phys, Fac Engn, Giza 12613, Egypt.
EM wafaasayed@eng1.cu.edu.eg; m.farrag@nu.edu.eg; agradwan@ieee.org;
   salwa@computer.org
RI Sayed, Wafaa Saber/AAT-9268-2020; Radwan, Ahmed G./G-8908-2011
OI Radwan, Ahmed G./0000-0002-6119-8482; Tolba,
   Mohammed/0000-0002-6412-290X; Abd-El-Hafiz, Salwa/0000-0001-8407-0142;
   radwan, ahmed/0000-0001-6079-4138
FU Cairo University, Egypt [16-120]
FX This research was supported financially by Cairo University, Egypt,
   research project no. 16-120.
CR Abd-El-Hafiz S. K., 2015, Applied Mathematics & Information Sciences, V9, P3215
   AlAssaf N., 2003, J RES ENG APPL SCI, V2, P50
   Alligood K. A., 1996, Chaos: An Introduction to Dynamical Systems
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2013, FAR E J MATH SCI
   [Anonymous], 2000, MATH HDB SCI ENG DEF
   Azzaz MS, 2011, IEEE WRK SIG PRO SYS, P251, DOI 10.1109/SiPS.2011.6088984
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P2035, DOI 10.1016/j.cnsns.2012.12.018
   Barakat ML, 2013, ETRI J, V35, P448, DOI 10.4218/etrij.13.0112.0677
   George SN, 2015, MULTIMED TOOLS APPL, V74, P10393, DOI 10.1007/s11042-014-2172-2
   de la Fraga LG, 2017, NONLINEAR DYNAM, V90, P1661, DOI 10.1007/s11071-017-3755-z
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gutub A, 2003, 9 ANN GULF INT S
   Gutub A, 2004, INT COMP ENG C NEW T, P558
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Gutub AAA, 2011, COMM COM INF SC, V179, P104
   Hamdi M, 2017, MULTIMED TOOLS APPL, V76, P7105, DOI 10.1007/s11042-016-3377-3
   Hermassi H, 2017, MULTIMED TOOLS APPL, V76, P1177, DOI 10.1007/s11042-015-3030-6
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Ismail SM, 2017, AEU-INT J ELECTRON C, V80, P114, DOI 10.1016/j.aeue.2017.05.047
   KAK SC, 1977, AT&T TECH J, V56, P781, DOI 10.1002/j.1538-7305.1977.tb00539.x
   Kim H, 2006, IEEE J SOLID-ST CIRC, V41, P2373, DOI 10.1109/JSSC.2006.882887
   Klinefelter A, 2015, IEEE INT SYMP CIRC S, P2361, DOI 10.1109/ISCAS.2015.7169158
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Mitchell J.N., 1962, IRE Trans. Electron. Comput., P512, DOI DOI 10.1109/TEC.1962.5219391
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Pande A., 2013, TELECOMMUN SYST, P1
   Pedre S, 2016, J REAL-TIME IMAGE PR, V11, P349, DOI 10.1007/s11554-013-0353-2
   Piñeiro JA, 2004, IEEE T COMPUT, V53, P1085, DOI 10.1109/TC.2004.53
   Radwan AG, 2015, J ADV RES
   Radwan AG, 2014, IEEE I C ELECT CIRC, P283, DOI 10.1109/ICECS.2014.7049977
   Radwan AG, 2013, IEEE I C ELECT CIRC, P653, DOI 10.1109/ICECS.2013.6815499
   Sadr A, 2015, MULTIMED TOOLS APPL, V74, P9715, DOI 10.1007/s11042-014-2147-3
   Sayed WS, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741730004X
   Sayed WS, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P207, DOI 10.1109/ICENCO.2015.7416349
   Sayed WS, 2015, DISCRETE DYN NAT SOC, V2015, DOI 10.1155/2015/586783
   Sayed WS, 2017, Complexity, V2017
   Sheikh F, 2013, IEEE J SOLID-ST CIRC, V48, P128, DOI 10.1109/JSSC.2012.2222813
   Sheu LJ, 2011, NONLINEAR DYNAM, V65, P103, DOI 10.1007/s11071-010-9877-1
   Stouraitis T, 2001, IEEE CIRCUITS DEVICE, V17, P22, DOI 10.1109/101.950050
   Strogatz S., 2014, Studies in Nonlinearity
   Tolba MF, 2017, AEU-INT J ELECTRON C, V78, P162, DOI 10.1016/j.aeue.2017.04.028
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zeng L, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-257
   Zhao B., 2016, SIGNAL PROCESS, V7, P50
   Zhao H, 2014, SCI WORLD J, DOI 10.1155/2014/974735
   Zidan MA, 2012, INT J BIFURCAT CHAOS, V22, DOI 10.1142/S021812741250143X
NR 54
TC 24
Z9 24
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16097
EP 16127
DI 10.1007/s11042-018-6946-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500017
DA 2024-07-18
ER

PT J
AU Wu, HY
   Liu, JY
   Qiu, JL
   Zhang, XL
AF Wu, Huiyue
   Liu, Jiayi
   Qiu, Jiali
   Zhang, Xiaolong (Luke)
TI Seeking common ground while reserving differences in gesture elicitation
   studies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User-defined gestures; Elicitation study; Mouse gesture; Web navigation
ID USER; SYSTEM
AB Gesture elicitation studies have been frequently conducted in recent years for gesture design. However, most elicitation studies adopted the frequency ratio approach to assign top gestures derived from end-users to the corresponding target tasks, which may cause the results get caught in local minima, i.e., the gestures discovered in an elicitation study are not the best ones. In this paper, we propose a novel approach of seeking common ground while reserving differences in gesture elicitation research. To verify this point, we conducted a four-stage case study on the derivation of a user-defined mouse gesture vocabulary for web navigation and then provide new empirical evidences on our proposed method, including 1) gesture disagreement is a serious problem in elicitation studies, e.g., the chance for participants to produce the same mouse gesture for a given target task without any restriction is very low, below 0.26 on average; 2) offering a set of gesture candidates can improve consistency; and 3) benefited from the hindsight effect, some unique but highly teachable gestures produced in the elicitation study may also have a chance to be chosen as the top gestures. Finally, we discuss how these findings can be applied to inform all gesture-based interaction design.
C1 [Wu, Huiyue; Liu, Jiayi; Qiu, Jiali] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Guangdong, Peoples R China.
   [Wu, Huiyue] Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Xiaolong (Luke)] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA.
C3 Sun Yat Sen University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University; Pennsylvania State
   University - University Park
RP Wu, HY (corresponding author), Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Guangdong, Peoples R China.; Wu, HY (corresponding author), Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Guangdong, Peoples R China.
EM wuhuiyue@mail.sysu.edu.cn
RI ZHANG, XIAOLONG/IZQ-4553-2023
OI Zhang, Xiaolong/0000-0002-6828-4930; Wu, Huiyue/0000-0001-7027-518X
FU National Natural Science Foundation of China [61772564, 61202344]; China
   Scholarship Council (CSC)
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61772564, 61202344 and the funding offered by the
   China Scholarship Council (CSC)
CR Budiu R, 2018, MEMORY RECOGNITION R
   Chan E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3403, DOI 10.1145/2858036.2858589
   Chen Z, 2018, INT J HUM-COMPUT INT, V34, P238, DOI 10.1080/10447318.2017.1342943
   Choi E, 2014, APPL ERGON, V45, P1196, DOI 10.1016/j.apergo.2014.02.010
   Cockburn A, 2013, P SIGCHI C HUM FACT, P955, DOI [10.1145/2468356.2468527, DOI 10.1145/2468356.2468527, DOI 10.1145/2468356]
   Dulberg M, 1999, HUMAN COMPUTER INTER, P1
   Feng ZQ, 2013, PATTERN RECOGN, V46, P590, DOI 10.1016/j.patcog.2012.07.019
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Grijincu Daniela, 2014, P 9 ACM INT C INT TA, P25, DOI DOI 10.1145/2669485.2669511
   Hoff L, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P86, DOI 10.1145/2839462.2839472
   Kray C., 2010, Proc. of MobileHCI '10, P239, DOI DOI 10.1145/1851600.1851640
   Kühnel C, 2011, INT J HUM-COMPUT ST, V69, P693, DOI 10.1016/j.ijhcs.2011.04.005
   Kurdyukova E., 2012, Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces, IUI '12, New York, NY, USA, P93, DOI [10.1145/2166966.2166984, DOI 10.1145/2166966.2166984]
   Löcken A, 2012, MULTIMEDIA SYST, V18, P15, DOI 10.1007/s00530-011-0240-2
   Midgley L, 2006, P 12 INT C AUD DISPL, P187
   Morris M. R., 2010, P GRAPHICS INTERFACE, P261
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI [DOI 10.1145/2591689, 10.1145/2591689]
   Moyle Michael., 2003, Proceedings of the Fourth Australasian user interface conference on User interfaces 2003-Volume, V18, P39
   Nacenta MA, 2013, P ACM CHI C HUM FACT, P1099, DOI DOI 10.1145/2470654.2466142
   Nielsen J, 2018, 10 USABILITY HEURIST
   Nielsen M., 2004, Gesture-Based Communication in Human-Computer Interaction, P105
   Paschke JD, 2011, THESIS
   Rovelo G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4077, DOI 10.1145/2556288.2557113
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Valdes C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4107, DOI 10.1145/2556288.2557373
   Vatavu Radu-Daniel, 2012, P 10 EUR C INT TV VI, P45, DOI [10.1145/2325616.2325626, DOI 10.1145/2325616.2325626]
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wu HY, 2016, MULTIMED TOOLS APPL, V75, P733, DOI 10.1007/s11042-014-2323-5
   Yee W, 2009, LECT NOTES COMPUT SC, V5611, P291, DOI 10.1007/978-3-642-02577-8_32
   Zaiti IA, 2015, PERS UBIQUIT COMPUT, V19, P821, DOI 10.1007/s00779-015-0863-y
   서혜경, 2013, [Journal of the Korean Institute of Industrial Engineers, 대한산업공학회지], V39, P163, DOI 10.7232/JKIIE.2013.39.3.163
NR 33
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14989
EP 15010
DI 10.1007/s11042-018-6853-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700038
DA 2024-07-18
ER

PT J
AU El-Bakary, EM
   El-Shafai, W
   El-Rabaie, S
   Zahran, O
   Abd El-Samie, FE
AF El-Bakary, E. M.
   El-Shafai, W.
   El-Rabaie, S.
   Zahran, O.
   Abd El-Samie, F. E.
TI Efficient hybrid framework for transmission enhancement of composite 3D
   H.264 and H.265 compressed video frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D multi-view video; OFDM; DCT; Video compression; Chaotic interleaving
   and encryption; PAPR; Noise reduction
ID MULTIVIEW VIDEO
AB Three-Dimensional Multi-View Video (3D-MVV) transmission over wireless networks suffers from losses. Therefore, the robust performance of 3D-MVV transmission techniques over wireless channels has become a recent hot research issue due to the restricted resources and the presence of severe channel errors. The 3D-MVV is composed of multiple video stream shots by several cameras around a single object, simultaneously. So, it is an urgent task to achieve high compression ratios to meet future bandwidth constraints. Unfortunately, the highly-compressed 3D-MVV data becomes more sensitive and vulnerable to packet losses, especially in the case of heavy channel errors. Thus, in this paper, we propose the application of a chaotic Baker map interleaving technique with equalization for efficient transmission of composite 3D-MVV compressed frames over an Orthogonal Frequency Division Multiplexing (OFDM) wireless channel. Rayleigh fading and Additive White Gaussian Noise (AWGN) are considered in the real scenario of 3D-MVV transmission. Firstly, the 3D-MVV content is compressed exploiting the intra- and inter-prediction correlations between frames. After that, a composite frame of luminance is generated from each four consecutive frames using Discrete Cosine Transform (DCT), which represents a second level of compression. The resultant composite frame is converted to binary data format. Then, chaotic interleaving is applied on the binary information prior to the modulation process. This chaotic interleaving is used to mitigate the OFDM induced Peak-to-Average Power Ratio (PAPR) problem and to reduce the wireless channel effects on the transmitted bit streams. It also adds a degree of encryption to the transmitted 3D-MVV compressed frames. To evaluate the performance of the proposed hybrid technique, several simulation experiments on different 3D-MVV frames have been executed. The experimental results show that the received 3D-MVV frames have high average Peak Signal-to-Noise Ratio (PSNR) gains up to 4.25dB and a reduction of the average PAPR values by about 12dB with the proposed hybrid technique compared to the other traditional techniques.
C1 [El-Bakary, E. M.; El-Shafai, W.; El-Rabaie, S.; Zahran, O.; Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Bakary, EM (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM eman_elbakary449@yahoo.com; srabie1@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021; Sayed, Fathi/HRA-4752-2023
OI El-Shafai, Walid/0000-0001-7509-2120; Sayed, Fathi/0000-0001-8749-9518;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881; Zahran,
   Osama/0000-0001-5334-5908
CR Al-Kamali F. S., 2008, Progress In Electromagnetics Research B, V3, P255, DOI 10.2528/PIERB07121408
   Al-Kamali FS, 2009, DIGIT SIGNAL PROCESS, V19, P2, DOI 10.1016/j.dsp.2008.07.009
   Alfa A. S., 2014, WIR TEL S APR 2014 9, P1
   Aziz T, 2014, INT J EMERGING TECHN, V2, P667
   Bulzacchelli John F., 2015, IEEE Solid-State Circuits Magazine, V7, P23, DOI 10.1109/MSSC.2015.2475996
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Cho S, 2002, IEEE T CIRC SYST VID, V12, P157
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   El-Bakery EM, 2017, WIRELESS PERS COMMUN, V96, P1635, DOI 10.1007/s11277-017-4218-z
   El-Shafai, 2017, MULTIMED TOOLS APPL, V77, P1
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0064-5
   Eltholth AA, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON WIRELESS AND MOBILE, P172, DOI 10.1109/APWiMob.2014.6920306
   Fraunhofer Heinrich Hertz Institute, 2015, HIGH EFF VID COD HEV
   Hassan ES, 2013, J FRANKLIN I, V350, P770, DOI 10.1016/j.jfranklin.2013.01.007
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Jung SY, 2015, OPT EXPRESS, V23, P13889, DOI 10.1364/OE.23.013889
   Kuo C, 2012, APPL MATH INFORM SCI, V5, p16S
   Li S, 2001, PROGR CRYPTOLOGY IND, P316
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu YW, 2017, J VIS COMMUN IMAGE R, V46, P208, DOI 10.1016/j.jvcir.2017.04.005
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Pranavi P, 2017, IMPERIAL J INTERDISC, V3, P721
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Ramzan N, 2013, IEEE IMAGE PROC, P1885, DOI 10.1109/ICIP.2013.6738388
   Salim OH, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P4077
   Shrestha Suchitra, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P280, DOI 10.1109/ISSPA.2010.5605474
   Soliman NF, 2014, WIRELESS PERS COMMUN, V79, P2141, DOI 10.1007/s11277-014-1977-7
   Soliman NF, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P593, DOI 10.1109/ICCES.2009.5383063
   Tsai MF, 2011, COMPUT COMMUN, V34, P1125, DOI 10.1016/j.comcom.2010.02.001
   Xiang T, 2014, APPL SOFT COMPUT, V21, P159, DOI 10.1016/j.asoc.2014.03.009
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhang QW, 2017, MULTIDIM SYST SIGN P, V28, P1203, DOI 10.1007/s11045-016-0388-1
   Zhang QW, 2016, MULTIDIM SYST SIGN P, V27, P743, DOI 10.1007/s11045-014-0303-6
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 40
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11337
EP 11368
DI 10.1007/s11042-018-6464-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900012
DA 2024-07-18
ER

PT J
AU Matos, CEF
   Souza, JC
   Diniz, JOB
   Braz, G Jr
   de Paiva, AC
   de Almeida, JDS
   da Rocha, SV
   Silva, AC
AF Falcao Matos, Caio Eduardo
   Souza, Johnatan Carvalho
   Bandeira Diniz, Joao Otavio
   Braz Junior, Geraldo
   de Paiva, Anselmo Cardoso
   Sousa de Almeida, Joao Dallyson
   da Rocha, Simara Vieira
   Silva, Aristofanes Correa
TI Diagnosis of breast tissue in mammography images based local feature
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammography; Pattern recognition; Local features; Feature
   representation
ID CLASSIFICATION; CANCER; BAG
AB Breast cancer is one of the leading causes of death by cancer among women. The high mortality rates and the occurrence of this cancer worldwide show the importance of the investigation and development of means for the detection and early diagnosis of this disease. Computer-Aided Detection and Diagnosis systems have been developed to improve diagnostic accuracy by radiologists. This work proposes a method for discriminating patterns of malignancy and benignity of masses in digitized mammography images through the analysis of local features. The method comparatively applies the Scale-Invariant Feature Transform (SIFT), Speed Up Robust Feature (SURF), Oriented Fast and Rotated BRIEF (ORB) and Local Binary Pattern (LBP) descriptors for local feature extraction. These features are represented by a Bag of Features (BoF) model, applied to provide new representations of the data and to reduce its dimensionality. Finally, the features are used as input for the Support Vector Machine (SVM), Adaptive Boosting (Adaboost) and Random Forests (RF) classifiers to differentiate malignant and benign masses. The method obtained significant results, reaching 100% sensitivity, 99.65% accuracy and 99.24% specificity for benign and malignant mass classification.
C1 [Falcao Matos, Caio Eduardo; Souza, Johnatan Carvalho; Bandeira Diniz, Joao Otavio; Braz Junior, Geraldo; de Paiva, Anselmo Cardoso; Sousa de Almeida, Joao Dallyson; da Rocha, Simara Vieira; Silva, Aristofanes Correa] Univ Fed Maranhao, Comp Appl Grp, Sao Luis, Maranhao, Brazil.
C3 Universidade Federal do Maranhao
RP Matos, CEF (corresponding author), Univ Fed Maranhao, Comp Appl Grp, Sao Luis, Maranhao, Brazil.
EM caioefalcao@gmail.com; johnatancarvalho06@gmail.com; joao.obd@gmail.com;
   geraldo.braz@ufma.br; anselmo.paiva@ufma.br; joao.dallyson@ufma.br;
   simara.rocha@ufma.br; aristofanes.silva@ufma.br
RI Paiva, Anselmo/L-2358-2013; Braz, Geraldo/AAW-1827-2021; Bandeira,
   João/E-6498-2019
OI Paiva, Anselmo/0000-0003-4921-0626; Braz, Geraldo/0000-0003-3731-6431;
   Bandeira, João/0000-0003-3303-3346; Matos, Caio Eduardo
   Falcao/0000-0001-8470-1004; Almeida, Joao Dallyson Sousa de
   Almeida/0000-0001-7013-9700
FU CNPq; FAPEMA
FX The authors thanks CNPq and FAPEMA for the financial support.
CR Abbas Q, 2016, COMPUTERS, V5, DOI 10.3390/computers5030013
   Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2007, MIR
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Arevalo J, 2015, IEEE ENG MED BIO, P797, DOI 10.1109/EMBC.2015.7318482
   Avila S, 2013, THESIS U PIERRE M CU
   Ayed N.G.B., 2014, ASIAN J INF TECHNOL, V13, P477
   Azar AT, 2014, COMPUT METH PROG BIO, V113, P465, DOI 10.1016/j.cmpb.2013.11.004
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Braz G, 2009, COMPUT BIOL MED, V39, P1063, DOI 10.1016/j.compbiomed.2009.08.009
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brown Matthew., 2002, BMVC
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Campos LFA, 2005, LECT NOTES COMPUT SC, V3773, P460
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   da Rochaa SV, 2016, EXPERT SYST APPL, V66, P7, DOI 10.1016/j.eswa.2016.08.070
   Dhahbi S, 2015, COMPUT BIOL MED, V64, P79, DOI 10.1016/j.compbiomed.2015.06.012
   Don S, 2012, CYBERN INF TECHNOL, V12, P69, DOI 10.2478/cait-2012-0013
   Everitt B., 1998, The Cambridge Dictionary of Statistics
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Giger ML, 2000, COMPUT SCI ENG, V2, P39, DOI 10.1109/5992.877391
   Görgel P, 2013, COMPUT BIOL MED, V43, P765, DOI 10.1016/j.compbiomed.2013.03.008
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Haykin S., 1994, NEURAL NETWORKS COMP
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hussain A, 2014, APPL MATH INFORM SCI, V8, P355
   Kaur P., 2016, INT J ADV RES IDEAS, V2, P1
   Klein George, 2007, P1
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu XM, 2014, IEEE SYST J, V8, P910, DOI 10.1109/JSYST.2013.2286539
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu F., 2015, J INF HIDING MULTIME, V6, P708
   Martins L. D. O., 2006, 2006 9 BRAZILIAN S N, P24, DOI [10.1109/SBRN.2006.14, DOI 10.1109/SBRN.2006.14]
   Massich Joan, 2014, Breast Imaging. 12th International Workshop, IWDM 2014. Proceedings: LNCS 8539, P681, DOI 10.1007/978-3-319-07887-8_94
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Moayedi F, 2010, COMPUT BIOL MED, V40, P373, DOI 10.1016/j.compbiomed.2009.12.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Rijsbergen C. J. V., 1979, Information Retrieval
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rothacker L, 2013, PROC INT CONF DOC, P1305, DOI 10.1109/ICDAR.2013.264
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sun H, 2012, IEEE GEOSCI REMOTE S, V9, P109, DOI 10.1109/LGRS.2011.2161569
   Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Wajid SK, 2015, EXPERT SYST APPL, V42, P6990, DOI 10.1016/j.eswa.2015.04.057
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wang J., 2011, 6 INT C IM GRAPH ICI, P622, DOI DOI 10.1109/ICIG.2011.192
   Witkin AP, 1987, US Patent, Patent No. [4,658,372, 4658372]
   World health Organisation (WHO), 2014, WHO Position Paper on Mammography Screening
   Xie X, 2015, ALGORITHMS, V19, P21
   Xu S, 2010, IEEE GEOSCI REMOTE S, V7, P366, DOI 10.1109/LGRS.2009.2035644
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
NR 67
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12961
EP 12986
DI 10.1007/s11042-018-6390-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900014
DA 2024-07-18
ER

PT J
AU Jin, C
   Sun, QM
   Jin, SW
AF Jin, Cong
   Sun, Qing-Mei
   Jin, Shu-Wei
TI A hybrid automatic image annotation approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated image annotation; Visual attention mechanism; Label
   relationship; Conditional random fields
ID SALIENT REGION DETECTION; SUPPORT VECTOR MACHINE
AB Automated image annotation (AIA) is an important issue in computer vision and pattern recognition, and plays an extremely important role in retrieving large-scale images. In many image annotation approaches, different regions of the image are processed equally, which is inconsistent with the mechanism by which humans understand images. In order to improve the annotation performance of existing AIA approaches, a hybrid AIA approach based on visual attention mechanism (VAM) and the conditional random field (CRF) is proposed. First, since people pay more attention to the salient region of an image during the image recognition process, VAM is implemented for acquiring the salient and non salient regions of the image. Second, support vector machine (SVM) is used to annotate the salient region, and k nearest neighbor (kNN) voting algorithm is used to annotate the non salient regions. Finally, due to the existence of a certain relationship between any two annotation words (also called labels), CRF is calculated to obtain the final label set of each given image. The experimental results confirm that the proposed hybrid AIA approach has ideal annotation performance.
C1 [Jin, Cong; Sun, Qing-Mei] Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
   [Jin, Shu-Wei] Ecole Normale Super, Dept Phys, 24 Rue Lhomond, F-75231 Paris 5, France.
C3 Central China Normal University; Universite PSL; Ecole Normale
   Superieure (ENS)
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
EM jincong@mail.ccnu.edu.cn
CR Aksac A, 2017, PATTERN RECOGN, V66, P268, DOI 10.1016/j.patcog.2017.01.010
   Alham NK, 2011, COMPUT MATH APPL, V62, P2801, DOI 10.1016/j.camwa.2011.07.046
   [Anonymous], INT C INT SYST MOD S
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], TIP
   [Anonymous], 2000, GEN THEORY
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], APPL INTELL
   [Anonymous], 2018, ADV CIVIL ENG
   [Anonymous], INT J ELECT COMMUNIC
   [Anonymous], IMAGE
   [Anonymous], TIP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], BRITISH MACHINE VISI
   [Anonymous], INF SCI
   [Anonymous], RES
   [Anonymous], BIOINFORMATICS
   [Anonymous], 2011, THESIS
   [Anonymous], INT J ADV ENG TECHNO
   [Anonymous], TRANS
   Belaid S, 2016, ENERG CONVERS MANAGE, V118, P105, DOI 10.1016/j.enconman.2016.03.082
   Charte F, 2015, KNOWL-BASED SYST, V89, P385, DOI 10.1016/j.knosys.2015.07.019
   Chen A., 2013, ICML, P1274
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fan WT, 2013, PATTERN RECOGN, V46, P2754, DOI 10.1016/j.patcog.2013.03.026
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Ghosh Neha, 2018, Proceedings of International Conference on Recent Advancement on Computer and Communication. ICRAC 2017. Lecture Notes in Networks and Systems (LNNS 34), P305, DOI 10.1007/978-981-10-8198-9_32
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Ji P, 2017, NEUROCOMPUTING, V236, P48, DOI 10.1016/j.neucom.2016.09.108
   Jia C, 2016, NEUROCOMPUTING, V173, P406, DOI 10.1016/j.neucom.2015.03.122
   Jin C, 2018, J VIS COMMUN IMAGE R, V55, P720, DOI 10.1016/j.jvcir.2018.08.009
   Jin C, 2017, PROC SPIE, V10225, DOI 10.1117/12.2266104
   Jin C, 2015, ADV INTELL SYST COMP, V347, P29, DOI 10.1007/978-3-319-18476-0_4
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kuric E, 2015, COMPUT GRAPH-UK, V47, P1, DOI 10.1016/j.cag.2014.09.035
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu X, 2012, INT C PATT RECOG, P1253
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Loog M, 2014, PATTERN RECOGN LETT, V37, P24, DOI 10.1016/j.patrec.2013.03.004
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   McParlane Philip J., 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P133, DOI 10.1007/978-3-319-04114-8_12
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Qian ZM, 2016, NEUROCOMPUTING, V171, P1167, DOI 10.1016/j.neucom.2015.07.094
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Solomon C., 2010, Fundamentals of Digital Image Processing: A Practical Approach with Examples in Matlab
   Verma Y, 2017, INT J COMPUT VISION, V121, P126, DOI 10.1007/s11263-016-0927-0
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Zhou BL, 2014, ADV NEUR IN, V27
NR 58
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11815
EP 11834
DI 10.1007/s11042-018-6742-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900033
DA 2024-07-18
ER

PT J
AU Kannappan, S
   Liu, YH
   Tiddeman, B
AF Kannappan, Sivapriyaa
   Liu, Yonghuai
   Tiddeman, Bernie
TI Human consistency evaluation of static video summaries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Keyframe extraction; Performance evaluation;
   Consistency modelling; User consistency
ID SEGMENTATION; OPTIMIZATION
AB Automatic video summarization aims to provide brief representation of videos. Its evaluation is quite challenging, usually relying on comparison with user summaries. This study views it in a different perspective in terms of verifying the consistency of user summaries, as the outcome of video summarization is usually judged based on them. We focus on human consistency evaluation of static video summaries in which the user summaries are evaluated among themselves using the consistency modelling method we proposed recently. The purpose of such consistency evaluation is to check whether the users agree among themselves. The evaluation is performed on different publicly available datasets. Another contribution lies in the creation of static video summaries from the available video skims of the SumMe datatset. The results show that the level of agreement varies significantly between the users for the selection of key frames, which denotes the hidden challenge in automatic video summary evaluation. Moreover, the maximum agreement level of the users for a certain dataset, may indicate the best performance that the automatic video summarization techniques can achieve using that dataset.
C1 [Kannappan, Sivapriyaa; Liu, Yonghuai; Tiddeman, Bernie] Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales.
   [Liu, Yonghuai] Edge Hill Univ, Dept Comp Sci, St Helens Rd, Ormskirk L39 4QP, Lancs, England.
C3 Aberystwyth University; Edge Hill University
RP Kannappan, S (corresponding author), Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales.
EM sik2@aber.ac.uk; yyl@aber.ac.uk; bpt@aber.ac.uk
RI Tiddeman, Bernard/HSB-7114-2023; Liu, Yonghuai/ABF-3794-2020
OI , Sivapriyaa Kannappan/0000-0002-2619-358X; Tiddeman,
   Bernard/0000-0001-7570-1192
FU Aberystwyth University under the Departmental Overseas Scholarship (DOS)
FX The first author would like to thank for the award given by Aberystwyth
   University under the Departmental Overseas Scholarship (DOS) and partly
   funding by Object Matrix, Ltd on the project. The authors would express
   their gratitude to the associate editor and anonymous reviewers for
   their constructive comments that have improved the readability and
   quality of this paper.
CR [Anonymous], 2007, Multimedia retrieval
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Javed O., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, P532, DOI 10.1109/ICCV.2001.937671
   Kannappan Sivapriyaa, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P33, DOI 10.1007/978-3-319-50832-0_4
   Kannappan S, 2016, INT C PATT RECOG, P2240, DOI 10.1109/ICPR.2016.7899969
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   Lovstakken L, 2006, IEEE T ULTRASON FERR, V53, P1597, DOI 10.1109/TUFFC.2006.1678188
   Mahasseni B., 2017, IEEE C COMP VIS PATT, V1
   Mahmoud K. M., 2014, ARXIV14013590
   Mahmoud KM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P811, DOI 10.1109/ICCVW.2013.111
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Swanberg D., 1993, Proceedings of the SPIE - The International Society for Optical Engineering, V1908, P13, DOI 10.1117/12.143647
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   UCHIHASHI S, 1999, ACOUST SPEECH SIG PR, P3041
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, IEEE IJCNN, P1924, DOI 10.1109/IJCNN.2016.7727435
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yen K, 1996, INEFFECTIVENESS CORR
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 37
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12281
EP 12306
DI 10.1007/s11042-018-6772-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900054
DA 2024-07-18
ER

PT J
AU Gupta, N
   Jalal, AS
AF Gupta, Neeraj
   Jalal, Anand Singh
TI A robust model for salient text detection in natural scene images using
   MSER feature detector and Grabcut
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient text detection; Visual saliency models; Grabcut
ID ATTENTION
AB Visual attention models have been used to recognize the most prominent region in a natural scene. These regions are going to pull the human attention. The state-of-art models keep on under-predicting the significant image regions having text. These are specifically the regions with most noteworthy semantic significance in a natural scene and turn out to be useful for saliency-based applications like image classification and captioning. The text or character detection as a salient region in image remains a challenging research problem. Text contents within the scene convey vital information about the image. For example, signboard content conveys the important information for visually impaired person. In this paper, we have proposed a new model for salient text detection in a natural scene. In the proposed model, we integrate saliency model with the segmentation and text detection approach in a natural scene to generate the text saliency. The experimental outcomes in ROC curve and DET curves illustrate that the proposed model outperformed the state-of-art methods for detection of salient text content from a natural scene.
C1 [Gupta, Neeraj; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM neeraj.gupta@gla.ac.in; asjalal@gla.ac.in
RI Gupta, Neeraj/AAQ-6313-2021
OI Jalal, Anand/0000-0002-7469-6608; Gupta, Neeraj/0000-0002-3735-8044
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, IEEE T SIGNAL PROCES
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Gao RW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114539
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jalal AS, 2017, INT J IMAGE DATA FUS, P1
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Manke R, 2015, ELECTRON LETT, V51, P37, DOI 10.1049/el.2014.3334
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   RAHTU E, 2009, LECT NOTES COMPUT SC, V12, P1137
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   YIN XC, 2014, LECT NOTES COMPUT SC, V36, P5
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
NR 24
TC 15
Z9 15
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10821
EP 10835
DI 10.1007/s11042-018-6613-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400058
DA 2024-07-18
ER

PT J
AU Iguernaissi, R
   Merad, D
   Aziz, K
   Drap, P
AF Iguernaissi, Rabah
   Merad, Djamal
   Aziz, Kheireddine
   Drap, Pierre
TI People tracking in multi-camera systems: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Multi-camera tracking; Person re-identification; People tracking
ID PERSON REIDENTIFICATION; SPACE-TIME; RECOGNITION
AB Ubiquitousness of multiple cameras in surveillance systems is very beneficial for studying peoples behavior. The multiple views of the observed scene permit the management of dynamic occlusions and failures that may affect any sensor. The multi-camera tracking of objects is considered as the basic step in the design of intelligent surveillance applications. This thematic had been addressed in several researches. Various methods had been proposed to achieve an accurate tracking in the most challenging conditions as occlusions and lighting variations. These methods are addressed in two main research lines: the centralized and the distributed tracking approaches. In this paper, we propose an overview of the multi-camera tracking of objects which summarizes and classifies the most used existing methods.
C1 [Iguernaissi, Rabah; Merad, Djamal; Drap, Pierre] Aix Marseille Univ, CNRS, UMR 7296, LSIS, 163 Ave Luminy, F-13288 Marseille 9, France.
   [Aziz, Kheireddine] Toulon Univ, SeaTech Sch, Ave Univ,BP 20132, F-83957 La Garde, France.
C3 Centre National de la Recherche Scientifique (CNRS); Aix-Marseille
   Universite
RP Iguernaissi, R (corresponding author), Aix Marseille Univ, CNRS, UMR 7296, LSIS, 163 Ave Luminy, F-13288 Marseille 9, France.
EM rabah.iguernaissi@lsis.org
OI Merad, Djamal/0000-0001-9233-0020; iguernaissi,
   Rabah/0000-0002-1728-3532
CR Alahi A, 2010, COMPUT VIS IMAGE UND, V114, P624, DOI 10.1016/j.cviu.2010.01.004
   [Anonymous], 2008, ACM IEEE INT C DISTR
   [Anonymous], P EUR IT C GEN IT 18
   [Anonymous], 2008, 2008 2 ACMIEEE INT C, DOI DOI 10.1109/ICDSC.2008.4635689
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], 2004, CAVIAR CONTEXT AWARE
   [Anonymous], 2011, ACM WORKSH HUM GEST
   Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38
   Aziz Kheir-Eddine, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P303, DOI 10.1109/AVSS.2011.6027341
   Bai S, 2017, P IEEE C COMP VIS PA, V6, P7
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S, 2012, LECT NOTES COMPUT SC, V7574, P806, DOI 10.1007/978-3-642-33712-3_58
   Baltieri D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1817, DOI 10.1109/ICCVW.2011.6130469
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bhuvana V. P., 2016, J ADV SIGNAL PROCESS, V2016, P1, DOI [10.1186/s13634-016-0347-x, DOI 10.1186/S13634-016-0347-X]
   Bouma H, 2012, SPIE DEFENSE SECURIT
   Bredereck M., 2012, Proceedings of the 6th International Conference on Distributed Smart Cameras, P1
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen WH, 2014, IEEE IMAGE PROC, P2329, DOI 10.1109/ICIP.2014.7025472
   Chen Y, 2018, PERSON REIDENTIFICAT
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Colombo A., 2008, WORKSH MULT MULT SEN
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   Cosar S, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P407, DOI 10.1109/AVSS.2013.6636674
   del-Blanco C., 2008, P 2 ACM IEEE INT C D, P1
   Du W., 2006, PROC 9TH INT CONF IN, P1, DOI [10.1109/ICIF.2006.301712, DOI 10.1109/ICIF.2006.301712]
   Du W, 2007, LECT NOTES COMPUT SC, V4843, P365
   Eshel R, 2010, INT J COMPUT VISION, V88, P129, DOI 10.1007/s11263-009-0307-0
   Evans M, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P177, DOI 10.1109/AVSS.2013.6636636
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Guan L, 2010, INT J COMPUT VISION, V90, P283, DOI 10.1007/s11263-010-0341-y
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hofmann M, 2013, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2013.468
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Huang CC, 2012, IEEE T AUTOM SCI ENG, V9, P16, DOI 10.1109/TASE.2011.2163197
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jiang XY, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P343
   Kai Jungling, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P197, DOI 10.1109/AVSS.2011.6027319
   Kenk VS, 2015, IMAGE VISION COMPUT, V34, P11, DOI 10.1016/j.imavis.2014.11.002
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kroeger T, 2014, LECT NOTES COMPUT SC, V8753, P653, DOI 10.1007/978-3-319-11752-2_54
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Leal-Taixé L, 2012, PROC CVPR IEEE, P1987, DOI 10.1109/CVPR.2012.6247901
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Liem MC, 2014, COMPUT VIS IMAGE UND, V128, P36, DOI 10.1016/j.cviu.2014.06.003
   Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3
   Loy C.C., 2013, ICIP, V1, P5
   Martinel N, 2016, PATTERN RECOGN LETT, V71, P23, DOI 10.1016/j.patrec.2015.11.022
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Mazzon R, 2013, NEUROCOMPUTING, V100, P41, DOI 10.1016/j.neucom.2011.09.038
   Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014
   Medeiros H, 2008, IEEE J-STSP, V2, P448, DOI 10.1109/JSTSP.2008.2001310
   Nakajima C, 2003, PATTERN RECOGN, V36, P1997, DOI 10.1016/S0031-3203(03)00061-X
   Nie WZ, 2014, NEUROCOMPUTING, V139, P220, DOI 10.1016/j.neucom.2014.02.040
   Patino L, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P369, DOI 10.1109/AVSS.2014.6918696
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Quang M. H., 2013, Proc. International Conference on Machine Learning, P100
   Santos TT, 2011, PATTERN RECOGN LETT, V32, P47, DOI 10.1016/j.patrec.2010.05.016
   Schumann A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P193, DOI 10.1109/AVSS.2014.6918667
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005
   Taj M, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940281
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang HY, 2017, PATTERN RECOGN, V67, P340, DOI 10.1016/j.patcog.2017.01.033
   Wang JR, 2017, P IEEE VIRT REAL ANN, P335, DOI 10.1109/VR.2017.7892313
   Wang J, 2017, IEEE T CIRC SYST VID, V27, P513, DOI 10.1109/TCSVT.2016.2586851
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang Z, 2017, METRIC IEEE T CYBERN
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wen L, 2016, INT J COMPUT VISION, V122, P1
   Wen LY, 2017, INT J COMPUT VISION, V122, P313, DOI 10.1007/s11263-016-0943-0
   Yao J., 2008, WORKSH MULT MULT SEN
   Youlu W, 2013, THESIS
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zirui Zhang, 2013, Journal of Image and Graphics, V1, P76, DOI [10.12720/joig.1.2.76-79, DOI 10.12720/JOIG.1.2.76-79]
NR 88
TC 22
Z9 22
U1 6
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10773
EP 10793
DI 10.1007/s11042-018-6638-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400056
DA 2024-07-18
ER

PT J
AU Li, Y
   Wang, HX
AF Li, Yue
   Wang, Hong-Xia
TI Robust H.264/AVC video watermarking without intra distortion drift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Distortion drift; Robustness; H; 264; AVC
ID DATA HIDING ALGORITHM; SCHEME
AB A robust H.264/AVC video watermarking algorithm without intra distortion drift is proposed in this paper for the copyright protection of digital videos. The classic scheme prevented distortion from drifting by the classification of intra prediction modes, and different categories have different methods for modifying coefficient-pairs. Based on the reference pixels when 4x4 blocks of videos are encoded, the improved scheme proposed in this paper introduces a reclassification of intra prediction modes into avoiding distortion drift, which efficient enlarges the capacity of this kind of methods. Besides, the chosen principle of coefficient-pairs for watermarking is presented by theoretical and experimental analysis. By the means above, watermarked videos have controlled bit rate growth and guaranteed visual quality even if the capacity is enlarged. Then, pre-processing of watermarks reasonable reduce the bits needed to embed, which fixes the problem in classic scheme about limited capacity limits the size of watermarks. Meanwhile, spread-spectrum and Hamming code employed together not only promote robustness but also reduce computational complexity. Experimental results show that compared with the classic robust distortion drift-free methods, our algorithm maintains good visual performance with the enlarged capacity, and the strong robustness is kept without a huge increasement of bit rate.
C1 [Li, Yue] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.
   [Wang, Hong-Xia] Sichuan Univ, Coll Cybersecur, Chengdu 610065, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University
RP Wang, HX (corresponding author), Sichuan Univ, Coll Cybersecur, Chengdu 610065, Sichuan, Peoples R China.
EM liyue859000040@my.swjtu.edu.cn; hxwang@scu.edu.cn
RI Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China (NSFC) [U1536110]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under the grant No. U1536110.
CR Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Gaj S, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3009910
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Huo WJ, 2011, IEEE SIGNAL PROC LET, V18, P535, DOI 10.1109/LSP.2011.2162061
   ITU-T Recommendation, 2012, ADV VID COD GEN AUD
   Lin TJ, 2013, J SYST SOFTWARE, V86, P604, DOI 10.1016/j.jss.2012.10.922
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Liu YX, 2013, J SYST SOFTWARE, V86, P2174, DOI 10.1016/j.jss.2013.03.101
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Qiu G, 2004, INT C PATT RECOG, P865
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang WW, 2017, KSII T INTERNET INF, V11, P2741, DOI 10.3837/tiis.2017.05.024
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 19
TC 11
Z9 15
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8535
EP 8557
DI 10.1007/s11042-018-6942-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800036
DA 2024-07-18
ER

PT J
AU Sun, LN
   Li, WP
   Yasen, A
AF Sun, Li-na
   Li, Wei-ping
   Yasen, Aizezi
TI MTSW-SSTF: a wireless multimedia transmission scheme based on
   self-separation of time-frequency mode for shallow water
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless communication; Shallow water; Multimedia transmission; Self
   separation; Time-frequency mode
AB The random obstacles in the shallow sea environment, the irregular underwater pavement and the high quality requirements of multimedia transmission make the multimedia applications of shallow sea face the problems of high bit error rate, low transmission rate and low video quality. In order to solve these problems, this paper proposes a multimedia transmission mechanism and its architecture for wireless communication in shallow water based on time-frequency mode autonomous separation. Firstly, based on the complex and changeable seabed structure, the underwater biota movement track and the dynamic topology of end to end communication, a shallow sea wireless multimedia transmission system is constructed. Secondly, based on the performance of multimedia streaming in the time domain and frequency domain, a real-time multimedia transmission control mechanism for the time frequency separation of autonomous controlled multimedia signals from FS and TS is proposed. Finally, the simulation experiment and the field test results of shallow sea show that the proposed algorithm has superior performance in transmission rate, transmission efficiency, delivery rate and real-time performance.
C1 [Sun, Li-na] Henan Univ, Minsheng Coll, Kaifeng 475001, Henan, Peoples R China.
   [Li, Wei-ping] Railway Police Coll, Dept Image & Network Invest, Zhengzhou 450003, Henan, Peoples R China.
   [Yasen, Aizezi] Xinjiang Police Coll, Dept Informat Secur Engn, Urumqi 830013, Xinjiang, Peoples R China.
C3 Henan University; Railway Police College; Xinjiang Police College
RP Yasen, A (corresponding author), Xinjiang Police Coll, Dept Informat Secur Engn, Urumqi 830013, Xinjiang, Peoples R China.
EM 10260010@vip.henu.edu.cn; liweiping@rpc.edu.cn; yasinjan@sina.com
FU National Natural Science Foundation of China (NSFC) [61762086]; National
   natural science foundation [11671119]; Scientific and Technological
   Research Program of Henan Province [172102210111]
FX 1. The National Natural Science Foundation of China (NSFC)(No.
   61762086).; 2. National natural science foundation. No. 11671119.; 3.
   The Scientific and Technological Research Program of Henan Province. No.
   172102210111.
CR [Anonymous], C CONT METH TECHN OC
   [Anonymous], CHIN J ACOUST
   [Anonymous], J ACOUST SOC AM
   [Anonymous], ACOUST SOC AM J
   [Anonymous], ACOUST SOC AM J
   [Anonymous], INT S INT SIGN PROC
   [Anonymous], ACOUST SOC AM J
   [Anonymous], EURASIP J EMBED SYST
   [Anonymous], ACM INT C UND NETW S
   [Anonymous], ELECT POWER COMPON S
   [Anonymous], J ACOUST SOC AM
   [Anonymous], AC UND GEOSC S
   Bouvet PJ, 2017, OCEANS ABERDEEN C
   Mekkawy T, 2018, ELECTRON LETT, V54, DOI 10.1049/el.2017.3688
   Saranya K, 2016, 2016 INTERNATIONAL CONFERENCE ON ENERGY EFFICIENT TECHNOLOGIES FOR SUSTAINABILITY (ICEETS), P503, DOI 10.1109/ICEETS.2016.7583806
   Shao HY, 2017, INT J ROBUST NONLIN, V27, P1963, DOI 10.1002/rnc.3647
   Vayalamkuzhi P, 2016, J MICRO-NANOLITH MEM, V15, DOI 10.1117/1.JMM.15.2.023504
NR 17
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8827
EP 8839
DI 10.1007/s11042-018-6457-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800051
DA 2024-07-18
ER

PT J
AU Wu, YJ
   Zhu, YH
   Yang, Y
   Zhang, WM
   Yu, NH
AF Wu, Yaojun
   Zhu, Yonghe
   Yang, Yang
   Zhang, Weiming
   Yu, Nenghai
TI A no-reference quality assessment for contrast-distorted image based on
   improved learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference image quality assessment; Learning method;
   Contrast-distorted; Support vector regression; Grid search
ID ENHANCEMENT
AB No-reference image quality assessment (NR-IQA), which aims to predict image quality without accessing to reference images, is a fundamental and challenging problem in the field of image processing. Nevertheless, there are few researches about contrast-distorted images and results of the existing NR-IQA methods which cannot be in accordance with the subjective assessment results further. Therefore, an effective NR-IQA method for contrast-distorted image is proposed in this paper. Firstly, the proposed method extracts five features of all images from the database based on the natural scene statistics (NSS) model. Then the curve fitting method is subsequently represented to calculate values of natural image features. Finally, an improved Support Vector Regression (SVR) learning method based on grid search is proposed to establish the mapping between image feature values and the quality score of a test image. Experiments proved that the proposed method is effective when compared with other related state-of-the-art image quality assessment (IQA) methods based on three standard databases.
C1 [Wu, Yaojun; Zhu, Yonghe; Yang, Yang] Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Anhui, Peoples R China.
   [Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Yang, Y (corresponding author), Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Anhui, Peoples R China.
EM yaojun_wu@yeah.net; zyh_ahu@126.com; sky_yang@ahu.edu.cn;
   zhangwm@ustc.edu.cn; ynh@ustc.edu.cn
RI Wu, Yaojun/JUV-3069-2023
FU Natural Science Foundation of China [61502007, 61572452]; Natural
   Science Research Project of Anhui province [1608085MF125]; China
   Post-doctoral Science Foundation [58, 2015M582015]; Backbone Teacher
   Training Programof Anhui University; Doctoral Scientific Re-search
   Foundation of Anhui University [J01001319]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 61502007, 61572452, in part by the Natural Science
   Research Project of Anhui province under Grant 1608085MF125, in part by
   the NO. 58 China Post-doctoral Science Foundation under Grant
   2015M582015, in part by the Backbone Teacher Training Programof Anhui
   University, in part by the Doctoral Scientific Re-search Foundation of
   Anhui University under Grant J01001319.
CR Amiri SA, 2017, MULTIMED TOOLS APPL, P1
   [Anonymous], Categorical image quality (CSIQ) database
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Babu RV, 2007, SIGNAL PROCESS, V87, P1493, DOI 10.1016/j.sigpro.2006.12.014
   Chang DC, 1998, IEEE T MED IMAGING, V17, P518, DOI 10.1109/42.730397
   Chen C, 2011, P SPIE INT SOC OPT E, V7867, P1216
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liang LH, 2010, SIGNAL PROCESS-IMAGE, V25, P502, DOI 10.1016/j.image.2010.01.007
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944
   Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Omari M, 2015, MULTIMED TOOLS APPL, V74, P8685, DOI 10.1007/s11042-014-2353-z
   Oszust M, 2017, MULTIMED TOOLS APPL, P1
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Rezaie F., 2017, MULTIMED TOOLS APPL, V77, P1
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Shi Junsheng, 2007, Acta Optica Sinica, V27, P744
   Tolambiya A, IEEE INT C SYST MAN, V66, P359
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu XL, 2011, IEEE T IMAGE PROCESS, V20, P1262, DOI 10.1109/TIP.2010.2092438
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
   Zong XL, 1998, IEEE T MED IMAGING, V17, P532, DOI 10.1109/42.730398
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 38
TC 3
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10057
EP 10076
DI 10.1007/s11042-018-6524-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400026
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Jeong, HY
AF Joo, Hae-Jong
   Jeong, Hwa-Young
TI RETRACTED: A study on the control of smart device set-top box using
   image based reverse mirroring technology (Retracted article. See vol.
   82, pg. 14331, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Back Mirring; Service quality of experience and service quality; IPTV;
   STB; QoS; QoE
ID SYSTEM
AB To measure the quality of service of IPTV, the quality of service (QoS) is measured at the front end of the subscriber's STB. As is well known, QoS measures how reliably data are transmitted in a given network status. For example, the RTP packet header is scanned to analyze the packet loss, delay, jitter, etc. The IPTV services, however, send video data, including video and audio signals, and video data are sensitive to human sight and hearing. Back-mirroring technology is a function that enables the smart device to be utilized as a remote control device for interactive operation by wirelessly transmitting the screen of Android-based broadcasting devices (IPTV, smart TV, set-top box, etc.). In this paper, we suggest an advanced method and more diverse set of controls in order to process the signal from the set-top boxes or TV etc., suggesting that they are more convenient and more versatile. Using this solution, users will be able to use smart devices to increase user convenience and additional content markets by providing the same user convenience as smart devices, such as touch, drag, scaling, and scaling.
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
EM hjjoo@dongguk.edtu; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 2000, US REQ OBJ PERC VID
   [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], 1999, SUBJ VID QUA ASS MET
   Cho M-h, 2003, KICS
   Cho M-T, 2012, LNEE, V181, P591, DOI [10.1007/978-94-007-5075-3_72, DOI 10.1007/978-94-007-5075-3_72]
   Choi S, 2011, IFIP WIREL DAY
   Dai Q, 2010, IEEE INTERNET
   Dunham MH, 1999, P INT WORKSH DAT ENG, P14
   Ekman C, 2013, U. S. registered patent, Patent No. [2013-0279354, 20130279354]
   Joo H, 2013, LECT NOTES ELECT ENG
   Joo HJ, 2017, MULTIMED TOOLS APPL, V76, P19795, DOI 10.1007/s11042-016-3547-3
   Kim H, 2010, IEEE ICACT
   Lee J-h, 2010, E BUSINESS RES, V11
   Lee J-w, 2011, DESIGN RES, V24
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Maier G, 2010, LECT NOTES COMPUT SC, V6032, P161, DOI 10.1007/978-3-642-12334-4_17
   조대균, 2011, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V9, P109
   Portokalidis G, P 26 ANN COMP SEC AP, P347
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Richardson T., 1994, IEEE Personal Communications, V1, P6, DOI 10.1109/MPC.1994.311827
   Richardson T, 1995, P 9 ANN 10 TECHN C J
   Shabtai A, 2009, STATE OF THE ART REV
   Shmueli R, 2008, IEEE T BROADCAST, V54, P628, DOI 10.1109/TBC.2008.2001242
   Wood KR, 1997, COMPUTER, V30, P53, DOI 10.1109/2.566154
   Yoon TL, 2015, ISOKINET EXERC SCI, V23, P117, DOI 10.3233/IES-150572
   주해종, 2005, [The KIPS Transactions : Part D, 정보처리학회논문지D], V12, P521
NR 26
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5523
EP 5534
DI 10.1007/s11042-018-6910-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100025
OA Bronze
DA 2024-07-18
ER

PT J
AU Kim, IH
   Lim, DW
   Jung, JW
AF Kim, In-Hwan
   Lim, Dong-Woo
   Jung, Jin-Woo
TI Single-camera-based sand volume estimation of an excavator bucket
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sand volume estimation; Single camera; Image processing; Excavator
   bucket
AB For intelligent support of consruction site, it is needed to estimate the workload of excavator bucket. But, previous studies are not practical by the reason of non-real-time processing or implementation cost. In this paper, a novel method, which use only a single camera and image processing technique to estimate the workload of excavator bucket, is addressed based on the assumption of actual bucket size, uniformity of sand, and geometric model for the shape of excavator bucket and the shape of accumulated sand in the bucket. For the ease of analysis, the state of bucket was divided into three states, Under-Struck state, Struck state, and Heaped state, depending on the amount of sand accumulation. Specially, Heaped state was also divided into Sharply-Heaped state and Smoothly-Heaped state depending on the relative height of peak point of the sand pyramid in the view of photographed image. By finding the positions of bucket corner points, highest vertex of the sand pyramid and uppermost edge point of the sand region in photographed image, various geometric parameters are found by using mathematical modeling. Hereafter, the volume of sand in the bucket is estimated by using the ratio between the length of the actual bucket and the length of the bucket in the photographed image. Finally, the workload of the excavator bucket represented by the mass is obtained by multiplying the pre-defined density of sand. Experimental results show that the accuracy of the proposed method is 93.7% on average.
C1 [Kim, In-Hwan; Lim, Dong-Woo; Jung, Jin-Woo] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Dongguk University
RP Jung, JW (corresponding author), Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM jwjung@dongguk.edu
RI Lim, Darren Wan-Teck/V-8435-2019
OI Lim, Darren Wan-Teck/0000-0002-4655-0206
FU MIST (Ministry of Science and ICT), Korea [2016-0-00017]; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Education, Science and Technology [2015R1D1A1A09061368];
   Starting growth Technological RAMP;D program of SMBA [S2436536]; KIAT
   (Korea Institute for Advancement of Technology) - Korea Government
   (MOTIE: Ministry of Trade Industry and Energy) [N0001884]
FX This research was partially supported by the MIST (Ministry of Science
   and ICT), Korea, Under the national program for excellence in SW
   supervised by the IITP (Institute for Information & Communications
   Technology Promotion) (2016-0-00017), and partially supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (2015R1D1A1A09061368), and partially supported by the Starting growth
   Technological R&D program of SMBA [S2436536], and partially supported by
   the KIAT (Korea Institute for Advancement of Technology) grant funded by
   the Korea Government (MOTIE: Ministry of Trade Industry and Energy) (No.
   N0001884, HRD program for Embedded Software). And the authors would like
   to give special thanks to Mr. Hyun-Mo Yang for his assistance to the
   implementation of image processing algorithm for this research.
CR Ahn Seo-Hyun, 2016, [Journal of the Korean Society of Civil Engineers, 대한토목학회논문집(국문)], V36, P573, DOI 10.12652/Ksce.2016.36.3.0573
   FOJTIK D, 2016, P 2016 17 INT CARP, P194
   Jong Un Won, 2002, Journal of KISS: Computing Practices, V8, P562
   Jurman J., 2012, GEOD CARTOGR, V38, P157
   Suh Y-W, 2000, J KOR SOC SURVEYING, V18, P343
NR 5
TC 6
Z9 6
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5493
EP 5522
DI 10.1007/s11042-019-7225-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100024
DA 2024-07-18
ER

PT J
AU Olague, G
   Hernández, DE
   Llamas, P
   Clemente, E
   Briseño, JL
AF Olague, Gustavo
   Hernandez, Daniel E.
   Llamas, Paul
   Clemente, Eddie
   Briseno, Jose L.
TI Brain programming as a new strategy to create visual routines for object
   tracking: Towards automation of video tracking design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial dorsal stream; Deep genetic programming; Evolutionary
   computer vision; Visual tracking; Focus of attention; Deep learning
ID MOTION; RECOGNITION; ATTENTION; MODELS; CORTEX
AB This work describes the use of brain programming for automating the video tracking design process. The challenge is that of creating visual programs that learn to detect a toy dinosaur from a database while tested in a visual-tracking scenario. When planning an object tracking system, two sub-tasks need to be approached: detection of moving objects in each frame and correct association of detection to the same object over time. Visual attention is a skill performed by the brain whose functionality is to perceive salient visual features. The automatic design of visual attention programs through an optimization paradigm is applied to the detection-based tracking of objects in a video from a moving camera. A system based on the acquisition and integration steps of the natural dorsal stream was engineered to emulate its selectivity and goal-driven behavior useful to the task of tracking objects. This is considered a challenging problem since many difficulties can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid structures, object-to-object and object-to-scene occlusions, as well as camera motion, models, and parameters. Tracking relies on the quality of the detection process and automatically designing such stage could significantly improve tracking methods. Experimental results confirm the validity of our approach using three different kinds of robotic systems. Moreover, a comparison with the method of regions with convolutional neural networks is provided to illustrate the benefit of the approach.
C1 [Olague, Gustavo; Llamas, Paul; Briseno, Jose L.] CICESE, Appl Phys Div, Carretera Tijuana Ensenada 3918, Ensenada, Baja California, Mexico.
   [Hernandez, Daniel E.] TecNM Inst Tecnol Tijuana, Calzada Tecnol S-N, Tijuana 22414, BC, Mexico.
   [Clemente, Eddie] TecNM Inst Tecnol Ensenada, Blvd Tecnol 150, Ensenada 22780, Baja California, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada
RP Olague, G (corresponding author), CICESE, Appl Phys Div, Carretera Tijuana Ensenada 3918, Ensenada, Baja California, Mexico.
EM olague@cicese.mx
RI Olague, Gustavo/L-7795-2014; Clemente, Eddie/GWR-1377-2022
OI Olague, Gustavo/0000-0001-5773-9517; Clemente,
   Eddie/0000-0003-3195-9540; Hernandez Morales, Daniel
   Eduardo/0000-0003-2563-9129
FU CICESE [634-128]
FX This research was funded by CICESE through Project 634-128 -
   "Programacion cerebral aplicada al estudio del pensamiento y la vision".
   In addition, the authors acknowledge the valuable comments of the
   anonymous reviewers, the Editor of Multimedia Tools and Applications,
   and the International Editorial Board whose enthusiasm is gladly
   appreciated.
CR Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863
   Amazon Web Service, AM AI
   [Anonymous], 1980, COGNITIVE PSYCHOL
   [Anonymous], 2014, EVOLVE A BRIDGE PROB
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bensebaa A, 2018, VISUAL COMPUT, V34, P1109, DOI 10.1007/s00371-018-1520-z
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Chen SY, 2011, INT J ROBOT RES, V30, P1343, DOI 10.1177/0278364911410755
   Choudhury SK, 2018, MULTIMED TOOLS APPL, V77, P13075, DOI 10.1007/s11042-017-4933-1
   Clemente Eddie, 2012, Applications of Evolutionary Computation. Proceedings of EvoApplications 2012: EvoCOMNET, EvoCOMPLEX, EvoFIN, EvoGAMES, EvoHOT, EvoIASP, EvoNUM, EvoPAR, EvoRISK, EvoSTIM, and EvoSTOC, P315, DOI 10.1007/978-3-642-29178-4_32
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Dozal Leon, 2012, Applications of Evolutionary Computation. Proceedings of EvoApplications 2012: EvoCOMNET, EvoCOMPLEX, EvoFIN, EvoGAMES, EvoHOT, EvoIASP, EvoNUM, EvoPAR, EvoRISK, EvoSTIM, and EvoSTOC, P326, DOI 10.1007/978-3-642-29178-4_33
   Dozal L, 2014, COGN COMPUT, V6, P528, DOI 10.1007/s12559-014-9251-6
   Fan J, 2010, DISCRIMINATIVE SPATI, P480
   Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292
   FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Hernandez Daniel, 2012, Applications of Evolutionary Computation. Proceedings of EvoApplications 2012: EvoCOMNET, EvoCOMPLEX, EvoFIN, EvoGAMES, EvoHOT, EvoIASP, EvoNUM, EvoPAR, EvoRISK, EvoSTIM, and EvoSTOC, P336, DOI 10.1007/978-3-642-29178-4_34
   Hernandez Daniel E., 2018, Neural Computing and Applications, V30, P3007, DOI 10.1007/s00521-017-2873-3
   Hernández D, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1087
   Hernández DE, 2016, J COMPUT SCI-NETH, V17, P216, DOI 10.1016/j.jocs.2015.10.011
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   HUBEL DH, 1982, NATURE, V299, P515, DOI 10.1038/299515a0
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Kang BM, 2003, PROC CVPR IEEE, P267
   Kim K, 2011, OBJECT DETECTION TRA, P265
   Ko T, 2011, SURVEY BEHAV ANAL VI, P279
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BX, 2001, IEEE T IMAGE PROCESS, V10, P897, DOI 10.1109/83.923286
   Li ZD, 2013, PATTERN RECOGN, V46, P2187, DOI 10.1016/j.patcog.2013.01.020
   Ma L, 2010, VISUAL ATTENTION MOD, P483
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Mancas M, 2016, SPRINGER SERIES COGN, V10
   Nanda A, 2019, MULTIMED TOOLS APPL, V78, P3885, DOI 10.1007/s11042-017-4875-7
   Nanda AJ, 2017, IEEE ACCESS, V5, P6471, DOI 10.1109/ACCESS.2017.2686438
   Olague G, 2016, NAT COMPUT SER, P1, DOI 10.1007/978-3-662-43693-6
   Olague G, 2018, IEEE ACCESS, V6, P26254, DOI 10.1109/ACCESS.2018.2831633
   Osaka N, 2007, OBJECT RECOGNITION A
   Ouerhani N, 2003, MODEL DYNAMIC VISUAL, P702
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160
   RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z
   Reddy KR, 2015, INT CONF COMPUT INTE, P418, DOI 10.1109/CICN.2015.317
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Rout JK, 2017, MULTIMED TOOLS APPL, V76, P3187, DOI 10.1007/s11042-016-3819-y
   Schweitzer H, 2002, LECT NOTES COMPUT SC, V2353, P358
   Serby D, 2004, INT C PATT RECOG, P184, DOI 10.1109/ICPR.2004.1334091
   Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1
   Ungerleider Leslie G., 1994, Current Opinion in Neurobiology, V4, P157, DOI 10.1016/0959-4388(94)90066-3
   Vaswani N, 2003, PROC CVPR IEEE, P633
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Wolfe J.M., 2000, SEEING, P335, DOI DOI 10.1016/B978-012443760-9/50010-6
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zang Q, 2003, OBJECT CLASSIFICATIO, P198
   Zhao Q, 2017, COGN SCI TECHNOL, P1, DOI 10.1007/978-981-10-0213-7
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 67
TC 16
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5881
EP 5918
DI 10.1007/s11042-018-6634-9
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100043
DA 2024-07-18
ER

PT J
AU Srinivasan, A
   Gnanavel, VK
AF Srinivasan, A.
   Gnanavel, V. K.
TI Multiple feature set with feature selection for anomaly search in videos
   using hybrid classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Feature selection; Multiple features; Hybrid
   classification; GMM; SVM
AB An examination of abnormal activities in video scenes is a very difficult task in computer vision community. An efficient anomaly detection technique to detect anomalies in crowded scenes is presented in this paper. It uses Multiple Feature Set (MFS) to represent a piece of rectangular region of predefined size in a video frame called as patch with Hybrid Classification (HC) using Gaussian Mixture Model (GMM) and Support Vector Machine (SVM) classifiers for anomaly detection. The MFS contains a combination of the following types of features; gray intensity values, gradient edge features and texture energy map. The predominant features are selected from MFS by using a model of t-test feature selection method and are classified by HC model made up of GMM and SVM classifiers. The UCSD video clip database is used for performance analysis of MFS-HC system and compared with other approaches. Results show that MFS-HC provides better results than other approaches.
C1 [Srinivasan, A.; Gnanavel, V. K.] Anna Univ, Misrimal Navajee Munoth Jain Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Srinivasan, A (corresponding author), Anna Univ, Misrimal Navajee Munoth Jain Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM asrini30@gmail.com
RI Arulanandam, Srinivasan/AAF-5354-2021
OI Arulanandam, Srinivasan/0000-0001-9058-4473; V K,
   Gnanavel/0000-0002-3139-7288
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Benabbas Y, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/163682
   Bishop CM, 2006, PATTERN RECOGN, V1, P435
   Erasto P., 2001, THESIS
   Kim J, 2008, IEEE IJCNN, P2928, DOI 10.1109/IJCNN.2008.4634210
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Leyva R, 2014, IEEE INT WORKS INFOR, P209, DOI 10.1109/WIFS.2014.7084329
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Shreedarshan K, 2016, IEEE INT C CIRC CONT, P4
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Thida M, 2013, IEEE T CYBERNETICS, V43, P2147, DOI 10.1109/TCYB.2013.2242059
   Wei Z, 2003, P NATL ACAD SCI USA, V100, P4666
   Xiao T, 2015, LECT NOTES COMPUT SC, V9007, P66, DOI 10.1007/978-3-319-16814-2_5
   Xuan Mo, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1285, DOI 10.1109/ICASSP.2014.6853804
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
NR 18
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7713
EP 7725
DI 10.1007/s11042-018-6348-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700058
DA 2024-07-18
ER

PT J
AU Thakur, S
   Singh, AK
   Ghrera, SP
   Elhoseny, M
AF Thakur, Sriti
   Singh, Amit Kumar
   Ghrera, Satya Prakash
   Elhoseny, Mohamed
TI Multi-layer security of medical data through watermarking and chaotic
   encryption for tele-health applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DWT; DCT; SVD; Chaos; Robustness
ID MULTIPLE WATERMARKING; IMAGE WATERMARKING; ROBUST; SCHEME;
   AUTHENTICATION
AB In this paper, we present a robust and secure watermarking approach using transform domain techniques for tele-health applications. The patient report/identity is embedding into the host medical image for the purpose of authentication, annotation and identification. For better confidentiality, we apply the chaos based encryption algorithm on watermarked image in a less complex manner. Experimental results clearly indicated that the proposed technique is highly robust and sufficient secure for various forms of attacks without any significant distortions between watermarked and cover image. Further, the performance evaluation of our method is found better to existing state-of-the-art watermarking techniques under consideration. Furthermore, quality analysis of the watermarked image is estimated by subjective measure which is beneficial in quality driven healthcare industry.
C1 [Thakur, Sriti; Singh, Amit Kumar; Ghrera, Satya Prakash] JUIT, Dept CSE, Solan, HP, India.
   [Elhoseny, Mohamed] Mansoura Univ, Fac Comp & Informat, El Mansura, Egypt.
C3 Jaypee University of Information Technology; Egyptian Knowledge Bank
   (EKB); Mansoura University
RP Singh, AK (corresponding author), JUIT, Dept CSE, Solan, HP, India.
EM sritithakur19@gmail.com; amit_245singh@yahoo.com; sp.ghrera@juit.ac.in;
   mohamed_elhoseny@mans.edu.eg
RI Elhoseny, Mohamed/Q-5591-2017; Singh, Amit Kumar/D-1300-2015
OI Elhoseny, Mohamed/0000-0001-6347-8368; Singh, Amit
   Kumar/0000-0001-7359-2068
CR Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], IEEE INT S INT SIGN
   [Anonymous], 2014, INT J TELEMEDICINE A
   [Anonymous], 2013, IMAGE ENCRYPTION COM
   [Anonymous], 2006, REMOTE CARDIOLOGY CO
   [Anonymous], 2015, THESIS
   [Anonymous], 2014, 2014 10 INT C COMMUN
   [Anonymous], 2017, BOOK SERIES MULTIMED
   Bakthula R, 2018, MULTIMED TOOLS APPL, V77, P8375, DOI 10.1007/s11042-017-4738-2
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chauhan DS, 2017, MULTIMED TOOLS APPL, P1
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Giakoumaki Aggeliki L, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6328
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Kannammal A, 2014, INT J IMAG SYST TECH, V24, P111, DOI 10.1002/ima.22086
   Khan Mohammad Ibrahim, 2013, INT J COMPUTER SCI I, V10, P223
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P7563, DOI 10.1007/s11042-017-4507-2
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 40
TC 155
Z9 156
U1 2
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3457
EP 3470
DI 10.1007/s11042-018-6263-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600044
DA 2024-07-18
ER

PT J
AU Liu, AA
   Shao, Z
   Wong, YK
   Li, JN
   Su, YT
   Kankanhalli, M
AF Liu, An-An
   Shao, Zhuang
   Wong, Yongkang
   Li, Junnan
   Su, Yu-Ting
   Kankanhalli, Mohan
TI LSTM-based multi-label video event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concurrent event detections; Recurrent neural network
ID HISTOGRAMS; RECOGNITION; FLOW
AB Since large-scale surveillance videos always contain complex visual events, how to generate video descriptions effectively and efficiently without human supervision has become mandatory. To address this problem, we propose a novel architecture for jointly recognizing multiple events in a given surveillance video, motivated by the sequence to sequence network. The proposed architecture can predict what happens in a video directly without the preprocessing of object detection and tracking. We evaluate several variants of the proposed architecture with different visual features on a novel dataset perpared by our group. Moreover, we compute a wide range of quantitative metrics to evaluate this architecture. We further compare it to the popular Support Vector Machine-based visual event detection method. The comparison results suggest that the proposal method can outperform the traditional computer vision pipelines for visual event detection.
C1 [Liu, An-An; Shao, Zhuang; Su, Yu-Ting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Wong, Yongkang] Natl Univ Singapore, Smart Syst Inst, Singapore, Singapore.
   [Li, Junnan] Natl Univ Singapore, NUS Grad Sch Integrat Sci & Engn, Singapore, Singapore.
   [Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Tianjin University; National University of Singapore; National
   University of Singapore; National University of Singapore
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM anan0422@gmail.com
RI Shao, Zhuang/GYU-2414-2022; Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
FU National Natural Science Foundation of China [61772359, 61472275,
   61572356]; Tianjin Research Program of Application Foundation and
   Advanced Technology [15JCYBJC16200]; National Research Foundation, Prime
   Minister Office, Singapore under its International Research Centre in
   Singapore Funding Initiative
FX This work was supported in part by the National Natural Science
   Foundation of China (61772359, 61472275, 61572356), the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCYBJC16200), the National Research Foundation, Prime Minister
   Office, Singapore under its International Research Centre in Singapore
   Funding Initiative.
CR [Anonymous], ICIMCS
   [Anonymous], CORR
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Chenyou Fan, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P459, DOI 10.1007/978-3-319-46604-0_33
   Cho K., 2014, ARXIV14061078
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Fujiyoshi H, 2004, IEICE T INF SYST, VE87D, P113
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Gutchess D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P733, DOI 10.1109/ICCV.2001.937598
   He XN, 2017, IEEE T KNOWL DATA EN, V29, P57, DOI 10.1109/TKDE.2016.2611584
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li JN, 2016, IEEE INT SYM MULTIM, P222, DOI [10.1109/ISM.2016.0051, 10.1109/ISM.2016.16]
   Liu A, 2017, IEEE T CYBERN
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Pers J, 2010, PATTERN RECOGN LETT, V31, P1369, DOI 10.1016/j.patrec.2010.03.024
   Pritch Y, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P195, DOI 10.1109/AVSS.2009.53
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tu K, 2014, IEEE MULTIMEDIA, V21, P42, DOI 10.1109/MMUL.2014.29
   Venugopalan S., 2016, EMNLP, P1961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Yang Zhilin, 2016, Advances in Neural Information Processing Systems
   Yeung S, 2014, CVPR EG VIS WORKSH
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
NR 50
TC 26
Z9 29
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 677
EP 695
DI 10.1007/s11042-017-5532-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500038
DA 2024-07-18
ER

PT J
AU Wang, CB
   Xiao, H
   Wen, ST
AF Wang Chengbo
   Xiao Hui
   Wen, Shiting
TI SPSE a model of engineering multimedia learning and training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Engineering learning; SPSE; Design; Innovative thinking
AB Engineering learning has long been a topic of attention. The traditional engineering learning mode has its own rationality, which is not without merit. The PBL (Problem-Based Learning) model provides new ideas of engineering learning, yet it lacks the design elements, seldom takes into consideration the social attribute of engineering, and falls short of clear support to guide learners in problem-solving. This paper analyzes the properties and characteristics of various types of engineering learning modes, based on which the engineering learning is divided into 4 key nodes. Besides, it proposes a design-based scaffold-type engineering learning model SPSE (Scenario Prototype Scheme Evaluating), and explains SPSE from dimensions of engineering process, design and innovation. In order to improve the efficiency of SPSE engineering learning and training, a management platform software based on WEB and multimedia technology is designed. On the one hand, this software supports the communication and discussion between students and teachers. On the other hand, it supports the teacher to the student learning process monitoring and management. Finally, a successful case of SPSE teaching practice is used to further verify the rationality and effectiveness of engineering learning based on SPSE. Finally, a successful case of SPSE teaching practice is used to further verify the rationality and effectiveness of engineering learning based on SPSE.
C1 [Wang Chengbo; Xiao Hui; Wen, Shiting] Zhejiang Univ, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, CB (corresponding author), Zhejiang Univ, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
EM chengbo_wang@qq.com; xiaohui@nit.net.cn; wensht@foxmail.com
FU educational reform project of Zhejiang province of China; Humanities and
   Social Sciences Foundation of the Ministry of Education [16YJCZH112]
FX This study has been supported by the educational reform project of
   Zhejiang province of China with the project No.jg20160228, and the
   Humanities and Social Sciences Foundation of the Ministry of Education
   with grant No.16YJCZH112.
CR Achichaski T, SUCCESSFUL ED TRAIN, P220
   [Anonymous], 2012, INAPESCA Technical Report, Technology Branch in the North Pacific, P1
   [Anonymous], 2016, Project-based learning
   Barrows H. S., 1996, BRINGING PROBLEM BAS
   Billett S, 2016, EDUC TRAIN, V58, P613, DOI 10.1108/ET-01-2016-0001
   Crawley Edward F., 2009, REUNDERSTANDING ENG, P230
   Crosthwaite C, 2006, EDUC CHEM ENG, V1, P39, DOI 10.1205/ece.05002
   Dym CL, 2005, J ENG EDUC, V94, P103, DOI 10.1002/j.2168-9830.2005.tb00832.x
   Editor- in- chief, 2003, OXF COMP HIST MOD SC, P32
   Hill A. M., 2003, CANADIAN J SCI MATH, V3, P5, DOI DOI 10.1080/14926150309556548
   Hung W, 2011, ETR&D-EDUC TECH RES, V59, P529, DOI 10.1007/s11423-011-9198-1
   Jianmin G, 1999, GLOBAL ED, V5, P128
   Kolodner J. L., 1998, P INT C LEARNING SCI, V98, P16
   Levison, 2009, MODELS APPRENTICESHI
   Michem Karl, 2013, ENG PHILOS HIST PHIL, P5
   Schumpeter Joseph, 1997, THEORY EC DEV, P125
   Wood DF, 2003, BMJ-BRIT MED J, V326, P328, DOI 10.1136/bmj.326.7384.328
   Xiaodong Z, 2017, RES HIGHER ED ENG, V1, P17
   Yang Y, 2015, RES HIGHER ED ENG, V12, P24
   Yong Xiang L, LET INNOVATIVE DESIG
   Yu J, 2009, J ZHENGZHOU U AERONA, V28, P62
NR 21
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1149
EP 1164
DI 10.1007/s11042-018-6520-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500065
DA 2024-07-18
ER

PT J
AU Wei, HL
   Zhou, W
   Zhang, X
   Zhou, X
   Duan, ZM
AF Wei, Henglu
   Zhou, Wei
   Zhang, Xiu
   Zhou, Xin
   Duan, Zhemin
TI All zero block detection for HEVC based on the quantization level of the
   maximum transform coefficient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; All zero block; UQ; RDOQ; Maximum transform coefficient;
   Quantization level
ID DCT COEFFICIENTS; GENERAL-METHOD; EFFICIENCY; ALGORITHM; PREDICTION
AB Transform/quantization (T/Q) is one of the high complex modules in high efficiency video coding (HEVC). In this paper, all zero block (AZB) detection algorithm for HEVC is proposed to reduce the complexity of T/Q. The proposed AZB detection algorithm is based on the quantization level of the maximum transform coefficient, which is suitable for both uniform quantizer (UQ) and rate-distortion optimized quantizer (RDOQ). Experimental results show that 46% complexity of T/Q for UQ and 42% for RDOQ can be reduced with negligible loss of video quality and compression efficiency, outperforming the state-of-the-art methods.
C1 [Wei, Henglu; Zhou, Wei; Zhang, Xiu; Duan, Zhemin] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Zhou, Xin] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Wei, HL (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
EM weihenglu@yeah.net
RI 魏, 恒璐/JMR-2039-2023
FU National Natural Science Foundation of China [61602383, 61772424];
   Fundamental Natural Science Research Funds of Shaanxi Province
   [2018JQ6016, 2017JQ6019]; Innovation Foundation for Doctor Dissertation
   of Northwestern Polytechnical University [CX201716]
FX This work was supported in part by the National Natural Science
   Foundation of China (61602383 and 61772424), the Fundamental Natural
   Science Research Funds of Shaanxi Province (2018JQ6016 and 2017JQ6019),
   and the Innovation Foundation for Doctor Dissertation of Northwestern
   Polytechnical University (CX201716).
CR Bjontegaard G., 2001, SG16Q6 ITUT
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Bross F, 2012, JCTVCK1100
   Chen JH, 2006, SIGNAL PROCESS-IMAGE, V21, P562, DOI 10.1016/j.image.2006.03.007
   CHO NI, 1992, IEEE T SIGNAL PROCES, V40, P2166, DOI 10.1109/78.157217
   Fan HF, 2016, IEEE T MULTIMEDIA, V18, P537, DOI 10.1109/TMM.2016.2515365
   Ji XY, 2009, IEEE T CIRC SYST VID, V19, P1755, DOI 10.1109/TCSVT.2009.2026839
   Jung SW, 2010, IEEE T CIRC SYST VID, V20, P201, DOI 10.1109/TCSVT.2009.2031387
   JVT, 2013, H265 JVT ITUT
   Lee B, 2016, IEEE T MULTIMEDIA, V18, P1257, DOI 10.1109/TMM.2016.2557075
   Lee H, 2016, IEEE T CIRC SYST VID, V26, P107, DOI 10.1109/TCSVT.2015.2450151
   Lee K, 2013, IEEE J-STSP, V7, P1124, DOI 10.1109/JSTSP.2013.2272772
   Lee YM, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/524793
   Liu ZY, 2008, IEEE T CIRC SYST VID, V18, P620, DOI 10.1109/TCSVT.2008.918844
   Lv Z, 2014, ALL ZERO BLOCKS EARL
   McCann K., 2014, JCTVCR1002 ITUTISOIE
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ren J, 2008, P SOC PHOTO-OPT INS, V6811
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Sousa LA, 2000, ELECTRON LETT, V36, P306, DOI 10.1049/el:20000272
   Stankowski J, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P85, DOI 10.1109/PCS.2015.7170052
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P510, DOI 10.1109/TCSVT.2008.918553
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P728, DOI 10.1109/TMM.2007.893336
   Wang HL, 2014, J VIS COMMUN IMAGE R, V25, P1784, DOI 10.1016/j.jvcir.2014.08.007
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Wang H, 2014, P INT CONF BUS INTEL, P1, DOI 10.1109/BIFE.2013.1
   Xie ZG, 2007, IEEE T CIRC SYST VID, V17, P237, DOI 10.1109/TCSVT.2006.888812
   Yin HB, 2015, IEEE T CIRC SYST VID, V25, P1362, DOI 10.1109/TCSVT.2014.2380232
   Yin HB, 2018, SIGNAL PROCESS-IMAGE, V60, P79, DOI 10.1016/j.image.2017.09.004
   Zhou X, 1998, ELECTRON LETT, V34, P1839, DOI 10.1049/el:19981308
NR 31
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 363
EP 387
DI 10.1007/s11042-018-6529-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500019
DA 2024-07-18
ER

PT J
AU Xu, MX
   Zhu, ZF
   Zhao, Y
AF Xu, Meixiang
   Zhu, Zhenfeng
   Zhao, Yao
TI Towards learning a semantic-consistent subspace for cross-modal
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal; Semantic-correlation; Subspace learning; Multi-label
AB A great many of approaches have been developed for cross-modal retrieval, among which subspace learning based ones dominate the landscape. Concerning whether using the semantic label information or not, subspace learning based approaches can be categorized into two paradigms, unsupervised and supervised. However, for multi-label cross-modal retrieval, supervised approaches just simply exploit multi-label information towards a discriminative subspace, without considering the correlations between multiple labels shared by multi-modalities, which often leads to an unsatisfactory retrieval performance. To address this issue, in this paper we propose a general framework, which jointly incorporates semantic correlations into subspace learning for multi-label cross-modal retrieval. By introducing the HSIC-based regularization term, the correlation information among multiple labels can be not only leveraged but also the consistency between the modality similarity from each modality is well preserved. Besides, based on the semantic-consistency projection, the semantic gap between the low-level feature space of each modality and the shared high-level semantic space can be balanced by a mid-level consistent one, where multi-label cross-modal retrieval can be performed effectively and efficiently. To solve the optimization problem, an effective iterative algorithm is designed, along with its convergence analysis theoretically and experimentally. Experimental results on real-world datasets have shown the superiority of the proposed method over several existing cross-modal subspace learning methods.
C1 [Xu, Meixiang; Zhu, Zhenfeng; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
   [Xu, Meixiang; Zhu, Zhenfeng; Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhu, ZF (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.; Zhu, ZF (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM xumx0721@bjtu.edu.cn; zhfzhu@bjtu.edu.cn; yzhao@bjtu.edu.cn
FU National Natural Science Foundation of China [61572068, 61532005];
   National Key Research and Development of China [2016YFB0800404];
   Fundamental Research Funds for the Central Universities [2018JBZ001]
FX This work was jointly supported by National Natural Science Foundation
   of China (NO.61572068, NO.61532005), National Key Research and
   Development of China (NO.2016YFB0800404) and the Fundamental Research
   Funds for the Central Universities (No.2018JBZ001).
CR Akaho S, 2007, INT M PSYCH SOC IMPS
   [Anonymous], ICCV
   [Anonymous], TPAMI
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen X, 2011, IEEE INT C COMP VIS
   Chen Y, 2012, IEEE INT C IM PROC I
   Chua TS, 2009, ACM INT C IM VID
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Cui CR, 2017, J VIS COMMUN IMAGE R, V48, P367, DOI 10.1016/j.jvcir.2017.03.011
   Diethe T., 2008, NIPS WORKSH LEARN MU
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He R, 2015, IEEE T IMAGE PROCESS, V24, P5543, DOI 10.1109/TIP.2015.2466106
   Higham Nicholas John, 2002, Accuracy and Stability of Numerical Algorithms, V2nd, DOI [10.1137/1.9780898718027, DOI 10.1137/1.9780898718027]
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hwang SJ, 2010, P BRIT MACH VIS C BM
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Jiang SQ, 2014, MULTIMEDIA SYST, V20, P645, DOI 10.1007/s00530-012-0299-4
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kang F., 2006, CVPR, V2, P1719
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Liao R, 2014, ACM INT C WEB SEARCH
   Liu Y, 2006, P 31 AAAI C ART INT
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N, 2010, INT C MACH LEARN INT
   Rosipal R, 2003, PATTERN RECOGN, V36, P1961, DOI [10.1016/S0031-3203(03)00058-X, DOI 10.1016/S0031-3203(03)00058-X]
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shu X, 2015, ACM INT C MULT
   Song GL, 2017, IEEE T IMAGE PROCESS, V26, P4168, DOI 10.1109/TIP.2017.2713045
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Udupa R, 2010, HUMAN LANGUAGE TECHN
   Wang K, 2016, ARXIV160706215CSMM
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Wang Y, 2014, ACM INT C MULT
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Xu D, 2009, IEEE T IMAGE PROCESS, V18, P1671, DOI 10.1109/TIP.2009.2018015
   Yang JC, 2009, IEEE T IMAGE PROCESS, V18, P241, DOI 10.1109/TIP.2008.2009415
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang X, 2011, P 31 AAAI C ART INT
   Zhang Y, 2011, 14 INT C ART INT STA
   Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zheng Y, 2014, IEEE C COMP VIS PATT
   Zhu S, 2005, 28 ANN INT ACM SIG C
   Zhu ZF, 2016, INFORM SCIENCES, V332, P19, DOI 10.1016/j.ins.2015.11.007
   Zhuang Y, 2013, P 31 AAAI C ART INT
NR 55
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 389
EP 412
DI 10.1007/s11042-018-6578-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500020
DA 2024-07-18
ER

PT J
AU Ma, ZC
   Sun, ZX
AF Ma, Zichao
   Sun, Zhixin
TI Time-varying LSTM networks for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RNNs; CNNs; LSTMs; TV-LSTMs; Action recognition
AB We describe an architecture of Time-Varying Long Short-Term Memory recurrent neural networks (TV-LSTMs) for human action recognition. The main innovation of this architecture is the use of hybrid weights, shared weights and non-shared weights which we refer to as varying weights. The varying weights can enhance the ability of LSTMs to represent videos and other sequential data. We evaluate TV-LSTMs on UCF-11, HMDB-51, and UCF-101 human action datasets and achieve the top-1 accuracy of 99.64%, 57.52%, and 85.06% respectively. This model performs competitively against the models that use both RGB and other features, such as optical flows, improved Dense Trajectory, etc. In this paper, we also propose and analyze the methods of selecting varying weights.
C1 [Ma, Zichao] Nanjing Univ Posts & Telecommun, Nanjing, Jiangsu, Peoples R China.
   [Sun, Zhixin] Minist Educ, Key Lab Broadband Wireless Commun & Sensor Networ, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Ma, ZC (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing, Jiangsu, Peoples R China.
EM mazichao@njupt.edu.cn; sunzhixin@njupt.edu.cn
FU National Natural Science Foundation of China [61672299]
FX This work was supported by the National Natural Science Foundation of
   China (No.61672299). We would like to thank Songle Chen for his valuable
   advices.
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], P CVPR08
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2016, PROC ANN C NEURAL IN
   [Anonymous], 2015, 2015 IEEE C COMP VIS
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2007, ICCV
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, ARXIV151202595
   [Anonymous], 2015, P INT C MACH LEARN
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y., 2014, TECHNICAL REPORT
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   El Hihi S., 1995, Advances in Neural Information Processing Systems, V400, page, P409
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K., 2015, ARXIV150304069
   Hannun A, 2014, ARXIV14125567V2CSCL
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S., 1995, Long short term memory
   Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Lipton Z. C., 2015, ARXIV
   Otte Sebastian, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P1, DOI 10.1007/978-3-319-11179-7_1
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Sak H, 2014, INTERSPEECH, P338
   Sharma S., 2015, NEURAL INFORM PROCES
   Soomro K., 2012, ARXIV12120402CS
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I., 2013, TRAINING RECURRENT N
   Sutskever I, 2014, ADV NEUR IN, V27
   Venugopalan Subhashini, 2014, P 2015 C N AM CHAPT
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HW, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING MANAGEMENT, P124
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zaremba W., 2014, ARXIV
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
NR 50
TC 7
Z9 7
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32275
EP 32285
DI 10.1007/s11042-018-6260-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000034
DA 2024-07-18
ER

PT J
AU Zhou, NR
   Hou, WMX
   Wen, RH
   Zou, WP
AF Zhou, Nan Run
   Hou, Wei Ming Xia
   Wen, Ru Hong
   Zou, Wei Ping
TI Imperceptible digital watermarking scheme in multiple transform domains
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Transform domain; Watermark scrambling;
   Robustness; Imperceptibility
ID DISCRETE WAVELET TRANSFORM; ROBUST IMAGE WATERMARKING; DWT; DCT;
   ENCRYPTION; ALGORITHM
AB A novel imperceptible digital watermarking scheme in multiple transform domains is presented, where the cover image is dealt with by discrete wavelet transform (DWT), discrete cosine transform (DCT) and discrete fractional random transform (DFRNT), while the watermark image is scrambled by Arnold transform and logisticmap. First the watermark is scrambled by the Arnold transform, then the row and the column of the resulting watermark are scrambled by the Logistic map, respectively. In addition, four sub-band images are generated from the host image by the two-dimensional discrete wavelet transform. The low-frequency sub-band images are divided into 8 x 8 small matrices, and a coefficient matrix is produced by performing the discrete cosine transform on each matrix. An intermediate matrix with the same size as the watermark image is constructed by the intermediate frequency coefficients. Then the discrete fractional random transformation is performed on the intermediate frequency coefficient matrix and the scrambled watermark is embedded into the discrete fractional random transformation domain. Compared with the previous schemes, the proposed digital watermarking scheme has stronger imperceptibility and robustness.
C1 [Zhou, Nan Run; Hou, Wei Ming Xia] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Wen, Ru Hong] Yichun Univ, Coll Phys Sci & Technol, Yichun 336000, Peoples R China.
   [Zou, Wei Ping] Univ Poitiers, XLIM, CNRS, UMR 7252, Poitiers, France.
C3 Nanchang University; Yichun University; Universite de Poitiers; Centre
   National de la Recherche Scientifique (CNRS); CNRS - Institute for
   Engineering & Systems Sciences (INSIS)
RP Zhou, NR (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM nrzhou@ncu.edu.cn
RI Zhou, Nanrun/HGC-4650-2022
FU National Natural Science Foundation of China [61462061, 61561033]; China
   Scholarship Council [201606825042]; Department of Human Resources and
   Social security of Jiangxi Province; Major Academic Discipline and
   Technical Leader of Jiangxi Province [20162BCB22011]; Natural Science
   Foundation of Jiangxi Province [20171BAB202002]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61462061 and 61561033), the China Scholarship Council
   (Grant No. 201606825042), the Department of Human Resources and Social
   security of Jiangxi Province, the Major Academic Discipline and
   Technical Leader of Jiangxi Province (Grant No. 20162BCB22011), and the
   Natural Science Foundation of Jiangxi Province (Grant No.
   20171BAB202002).
CR Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Choudhary R, 2017, INT C COMM CONTR INT, P120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo Q, 2008, OPT ENG, V47, DOI 10.1117/1.2920339
   Halima NB, 2015, INT REV COMPUT SOFTW, V10, P643
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Liu ZJ, 2008, OPT COMMUN, V281, P1424, DOI 10.1016/j.optcom.2007.11.012
   Luo H, 2011, OPTIK, V122, P311, DOI 10.1016/j.ijleo.2009.12.018
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mastan Vali SK, 2015, INT C ELECT ELECT SI, P1
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Rajawat M, 2015, INT CONF COMM SYST, P638, DOI 10.1109/CSNT.2015.245
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P1, DOI [10.1007/s11042-015-3011-9, DOI 10.1007/S11042-015-3011-9]
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Tang LL, 2013, MULTIMED TOOLS APPL, V74, P1
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Wang B, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1034, DOI 10.1109/ICNIDC.2009.5360866
   Xie Y, 2016, CHIN CONT DECIS CONF, P4349, DOI 10.1109/CCDC.2016.7531749
   Ye X, 2015, INT C IM SIGN PROC, P323
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang CJ, 2008, NCM 2008 : 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 1, PROCEEDINGS, P329, DOI 10.1109/NCM.2008.121
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhou NR, 2010, OPT COMMUN, V283, P3037, DOI 10.1016/j.optcom.2010.03.064
NR 41
TC 42
Z9 42
U1 0
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30251
EP 30267
DI 10.1007/s11042-018-6128-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600005
DA 2024-07-18
ER

PT J
AU Cao, L
   Li, L
   Zheng, JF
   Fan, X
   Yin, F
   Shen, H
   Zhang, J
AF Cao, Liang
   Li, Long
   Zheng, Jifeng
   Fan, Xin
   Yin, Feng
   Shen, Hui
   Zhang, Jun
TI Multi-task neural networks for joint hippocampus segmentation and
   clinical score regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hippocampus segmentation; Clinical score regression; Brain disease
   diagnosis; Convolutional neural network
ID ALZHEIMERS-DISEASE DIAGNOSIS; CLASSIFICATION; IMAGES; ALGORITHM; STATE
AB Feature representations extracted from hippocampus in magnetic resonance (MR) images are widely used in computer-aided Alzheimer's disease (AD) diagnosis, and thus accurate segmentation for the hippocampus has been remaining an active research topic. Previous studies for hippocampus segmentation require either human annotation which is tedious and error-prone or pre-processing MR images via time-consuming non-linear registration. Although many automatic segmentation approaches have been proposed, their performance is often limited by the small size of hippocampus and complex confounding information around the hippocampus. In particular, human-engineered features extracted from segmented hippocampus regions (e.g., the volume of the hippocampus) are essential for brain disease diagnosis, while these features are independent of diagnosis models, leading to sub-optimal performance. To address these issues, we propose a multi-task deep learning (MDL) method for joint hippocampus segmentation and clinical score regression using MR images. The prominent advantages of our MDL method lie on that we don't need any time-consuming non-linear registration for pre-processing MR images, and features generated by MDL are consistent with subsequent diagnosis models. Specifically, we first align all MR images onto a standard template, followed by a patch extraction process to approximately locate hippocampus regions in the template space. Using image patches as input data, we develop a multi-task convolutional neural network (CNN) for joint hippocampus segmentation and clinical score regression. The proposed CNN network contains two subnetworks, including 1) a U-Net with a Dice-like loss function for hippocampus segmentation, and 2) a convolutional neural network with a mean squared loss function for clinical regression. Note that these two subnetworks share a part of network parameters, to exploit the inherent association between these two tasks. We evaluate the proposed method on 407 subjects with MRI data from baseline Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The experimental results suggest that our MDL method achieves promising results in both tasks of hippocampus segmentation and clinical score regression, compared with several state-of-the-art methods.
C1 [Cao, Liang; Li, Long; Yin, Feng; Shen, Hui] Taian Tumor Prevent & Treatment Hosp, Tai An 271000, Shandong, Peoples R China.
   [Zheng, Jifeng] Taian Matern & Child Care Hosp, Tai An 271000, Shandong, Peoples R China.
   [Fan, Xin] Taian Inst Sci & Technol Informat, Tai An 271000, Shandong, Peoples R China.
   [Zhang, Jun] Duke Univ, Dept Radiol, Durham, NC 27705 USA.
C3 Duke University
RP Zhang, J (corresponding author), Duke Univ, Dept Radiol, Durham, NC 27705 USA.
EM jun.zhang.2017@duke.edu
RI Zhang, Jun/L-3826-2017
FU National Natural Science Foundation of China [61703301, 61573023];
   University Science and Technology Project of Shandong Province
   [J17KA086]
FX This study was supported by National Natural Science Foundation of China
   (Nos. 61703301, 61573023) one more support grant and University Science
   and Technology Project of Shandong Province (No. J17KA086).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], NEUROIMAGE
   [Anonymous], MED IMAGE ANAL
   [Anonymous], IEEE T BIOMEDICAL EN
   [Anonymous], IEEE J BIOMEDICAL HL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Barnes J, 2007, NEUROBIOL AGING, V28, P1657, DOI 10.1016/j.neurobiolaging.2006.07.008
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cao X, 2016, INT C MEDICAL IMAGE, P1
   Carmichael OT, 2005, NEUROIMAGE, V27, P979, DOI 10.1016/j.neuroimage.2005.05.005
   Chincarini A, 2011, NEUROIMAGE, V58, P469, DOI 10.1016/j.neuroimage.2011.05.083
   Clark KA, 2006, NEUROIMAGE, V29, P185, DOI 10.1016/j.neuroimage.2005.07.035
   Coupé P, 2012, NEUROIMAGE, V59, P3736, DOI 10.1016/j.neuroimage.2011.10.080
   Coupé P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018
   Dagher A, 2001, BRAIN, V124, P1020, DOI 10.1093/brain/124.5.1020
   Dill V, 2015, NEUROINFORMATICS, V13, P133, DOI 10.1007/s12021-014-9243-4
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Hao YF, 2014, HUM BRAIN MAPP, V35, P2674, DOI 10.1002/hbm.22359
   Heckemann RA, 2006, NEUROIMAGE, V33, P115, DOI 10.1016/j.neuroimage.2006.05.061
   HYMAN BT, 1984, SCIENCE, V225, P1168, DOI 10.1126/science.6474172
   Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049
   JACK CR, 1992, NEUROLOGY, V42, P183, DOI 10.1212/WNL.42.1.183
   Jin KL, 2004, P NATL ACAD SCI USA, V101, P343, DOI 10.1073/pnas.2634794100
   Kwak K, 2013, MAGN RESON IMAGING, V31, P1190, DOI 10.1016/j.mri.2013.04.008
   Lian CF, 2016, MED IMAGE ANAL, V32, P257, DOI 10.1016/j.media.2016.05.007
   Lian CF, 2015, PATTERN RECOGN, V48, P2318, DOI 10.1016/j.patcog.2015.01.019
   Lindner C, 2013, IEEE T MED IMAGING, V32, P1462, DOI 10.1109/TMI.2013.2258030
   Liu MX, 2018, MED IMAGE ANAL, V43, P157, DOI 10.1016/j.media.2017.10.005
   Liu MX, 2017, MED IMAGE ANAL, V36, P123, DOI 10.1016/j.media.2016.11.002
   Liu MX, 2016, IEEE T MED IMAGING, V35, P1463, DOI 10.1109/TMI.2016.2515021
   Liu MX, 2016, IEEE T PATTERN ANAL, V38, P2335, DOI 10.1109/TPAMI.2015.2430325
   Liu MX, 2015, HUM BRAIN MAPP, V36, P1847, DOI 10.1002/hbm.22741
   Moodley K, 2015, HIPPOCAMPUS, V25, P939, DOI 10.1002/hipo.22417
   Pohl KM, 2007, IEEE T MED IMAGING, V26, P1201, DOI 10.1109/TMI.2007.901433
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Tulving E, 1998, HIPPOCAMPUS, V8, P198, DOI 10.1002/(SICI)1098-1063(1998)8:3<198::AID-HIPO2>3.0.CO;2-G
   Zarpalas Dimitrios, 2014, IEEE J Transl Eng Health Med, V2, P1800116, DOI 10.1109/JTEHM.2014.2297953
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhang J, 2016, IEEE T BIO-MED ENG, V63, P1820, DOI 10.1109/TBME.2015.2503421
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhu X., 2015, Medical image analysis
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu YY, 2017, LECT NOTES COMPUT SC, V10265, P158, DOI 10.1007/978-3-319-59050-9_13
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P264, DOI 10.1007/978-3-319-46720-7_31
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P106, DOI 10.1007/978-3-319-46720-7_13
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 50
TC 47
Z9 52
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29669
EP 29686
DI 10.1007/s11042-017-5581-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800027
DA 2024-07-18
ER

PT J
AU Chiang, PY
   Hung, SH
   Lai, YC
   Yao, CY
AF Chiang, Pei-Ying
   Hung, Shih-Hsuan
   Lai, Yu-Chi
   Yao, Chih-Yuan
TI Destination selection based on consensus-selected landmarks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Consensus-based publicity; Consensus-based optimal orientation;
   Hierarchical navigation; Destination searching
AB This study aims at enhancing the destination look-up experience based on the fact that humans can easily recognize and remember images and icons of a destination instead of texts and numbers. Thus, this paper propose an algorithm to display buildings in hierarchical publicity and optimize the location distribution and orientation of each buildings. In the usual, the general navigation GPS include a lot of redundant information, and the necessary information always being drowned. Aimed to this point, we build the hierarchical structure according to their consensus-based publicity and spacial relationship to each other. The publicity is approximated by considering transportation importance and consensus visibility which reflects public consideration on metro transportation, opinions on popularity and famousness respectively. In addition to this, consensus-based optimal orientation of icon is optimized for easy recognition according to public preference estimated by clustering the view of public web photos. For the system evaluation, we perform four user studies to verify the effect of recognition and destination searching, and we all get positive response from these user studies.
C1 [Chiang, Pei-Ying] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Hung, Shih-Hsuan; Lai, Yu-Chi; Yao, Chih-Yuan] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taipei University of Technology; National Taiwan University of
   Science & Technology
RP Chiang, PY (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM peiyingc@csie.ntut.edu.tw; kn810609@gmail.com; yu-chi@mail.ntust.edu.tw;
   cyuan.yao@csie.ntust.edu.tw
OI Lai, Yu-Chi/0000-0001-8578-3101
CR Beeharee AK, 2006, P 8 C HUM COMP INT M, P81
   Bulbul A, 2015, CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/2824840.2824860
   Corsini M, 2013, INT J COMPUT VISION, V102, P91, DOI 10.1007/s11263-012-0552-5
   Daniel M.P., 1998, KOGNITIONSWISSENSCHA, V7, P45, DOI [DOI 10.1007/BF03354963, 10.1007/bf03354963]
   Deng H, 2016, IEEE T VIS COMPUT GR, V22, P1862, DOI 10.1109/TVCG.2015.2469661
   Duckham M, 2010, J LOCAT BASED SERV, V4, P28, DOI 10.1080/17489721003785602
   Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782
   Giannopoulos I., 2015, P 17 INT C HUMAN COM, P337, DOI [10.1145/2785830.2785873, DOI 10.1145/2785830.2785873]
   Grabler F, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360699
   Hile H, 2009, LECT NOTES COMPUT SC, V5538, P59, DOI 10.1007/978-3-642-01516-8_6
   Kirk RE ., 1982, Experimental design
   Kopf J, 2010, ACM T GRAPHIC, V29
   Ledda P., 2005, ACM SIGGRAPH 2005
   Li YC, 2016, IEEE T INTELL TRANSP, V17, P1121, DOI 10.1109/TITS.2015.2497408
   Liu F, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2058
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Roman A., 2006, Euro- graphics Symposium on Rendering, P83
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Vincent L, 2007, COMPUTER, V40, P118, DOI 10.1109/MC.2007.442
   Wei-Chao Chen, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P1248, DOI 10.1109/ACSSC.2009.5469962
   Wither Jason., 2013, P 15 INT C HUMAN COM, P203, DOI DOI 10.1145/2493190.2493235
NR 22
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30011
EP 30033
DI 10.1007/s11042-018-5946-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800048
DA 2024-07-18
ER

PT J
AU Truong, MTN
   Pak, M
   Kim, S
AF Mai Thanh Nhat Truong
   Pak, Myeongsuk
   Kim, Sanghoon
TI Single object tracking using particle filter framework and
   saliency-based weighted color histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Particle filter; Color histogram; Saliency map
ID VISUAL TRACKING; ROBUST
AB Despite many years of research, object tracking remains a challenging problem, not only because of the variety of object appearances, but also because of the complexity of surrounding environments. In this research, we present an algorithm for single object tracking using a particle filter framework and color histograms. Particle filters are iterative algorithms that perform predictions in each iteration using particles, which are samples drawn from a statistical distribution. Color histograms are embedded in these particles, and the distances between histograms are used to measure likelihood between targets and observations. One downside of color histograms is that they ignore spatial information, which may produce tracking failure when objects appear that are similar in color. To overcome this disadvantage, we propose a saliency-based weighting scheme for histogram calculation. Given an image region, first its saliency map is generated. Next, its histogram is calculated based on the generated saliency map. Pixels located in salient regions have higher weights than those in others, which helps preserve the spatial information. Experimental results showed the efficiency of the proposed appearance model in object tracking under various conditions.
C1 [Mai Thanh Nhat Truong; Pak, Myeongsuk; Kim, Sanghoon] Hankyong Natl Univ, Dept Elect Elect & Control Engn, 327 Jungang Ro, Anseong, Gyeonggi Do, South Korea.
C3 Hankyong National University
RP Kim, S (corresponding author), Hankyong Natl Univ, Dept Elect Elect & Control Engn, 327 Jungang Ro, Anseong, Gyeonggi Do, South Korea.
EM kimsh@hknu.ac.kr
OI Mai, Truong/0000-0002-6448-7837
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2015R1D1A1A01057518]
FX This study was funded by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2015R1D1A1A01057518).
CR [Anonymous], 2015 IEEE 1 SMART CI
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2012, Bayesian Estimation and Tracking: A Practical Guide
   Barthélemy Q, 2015, IEEE T IMAGE PROCESS, V24, P3978, DOI 10.1109/TIP.2015.2458175
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bostanci E, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0040-3
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Lee Jeongick, 2015, [Journal of the Korea Convergence Society, 한국융합학회논문지], V6, P1, DOI 10.15207/JKCS.2015.6.4.001
   Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6
   Li TC, 2015, IEEE SIGNAL PROC MAG, V32, P70, DOI 10.1109/MSP.2014.2330626
   Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132
   Lin S, 2017, AUTON ROBOT, V41, P881, DOI 10.1007/s10514-016-9564-2
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Meshgi K, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P8, DOI 10.1109/AVSS.2016.7738027
   Nummiaro K., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P353
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pham Iq, 2014, 2014 IEEE/AIAA 33rd Digital Avionics Systems Conference (DASC), DOI 10.1109/DASC.2014.6979457
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sarif BAB, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0025-2
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Sidibé D, 2010, EUR SIGNAL PR CONF, P1776
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Su YY, 2014, PATTERN RECOGN, V47, P1826, DOI 10.1016/j.patcog.2013.11.028
   Sung Y, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0051-0
   Dinh TB, 2014, COMPUT VIS IMAGE UND, V119, P41, DOI 10.1016/j.cviu.2013.11.003
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoo S, 2014, J SIGNAL PROCESS SYS, V76, P19, DOI 10.1007/s11265-013-0803-x
   Yuan YR, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P388, DOI 10.1109/ICSPCC.2014.6986221
NR 35
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30067
EP 30088
DI 10.1007/s11042-018-6180-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800051
DA 2024-07-18
ER

PT J
AU Samaiya, D
   Gupta, KK
AF Samaiya, Devesh
   Gupta, Karunesh Kumar
TI Intelligent video surveillance for real time energy savings in smart
   buildings using HEVC compressed domain features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent video surveillance; HEVC; Video analytics; Smart buildings
ID BACKGROUND SUBTRACTION; OBJECTS
AB This work presents a unique approach to utilize the existing video surveillance infrastructure to optimize electricity consumption in large indoor spaces such as library reading halls, waiting rooms, indoor sports complex, large dormitories etc. The proposed method extracts features from the encoder loop of the digital video recorder (DVR) to analyze the foreground activity. High Efficiency Video Coding (HEVC) is chosen as the target video codec, as it is going to be the most widely deployed video codec in the future DVRs. The bit rate efficiency of HEVC is almost double in comparison to H.264/AVC for same video quality [17]. The proposed method utilizes only compressed domain parameters from video stream such as motion vectors clustering information, block partitioning modes etc., which allows to develop algorithms with relatively lower computational complexity and memory requirement than pixel based methods thus achieving real time performance.
C1 [Samaiya, Devesh; Gupta, Karunesh Kumar] Birla Inst Technol & Sci, Pilani 333031, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Samaiya, D (corresponding author), Birla Inst Technol & Sci, Pilani 333031, Rajasthan, India.
EM devesh.samaiya@pilani.bits-pilani.ac.in; kgupta@pilani.bits-pilani.ac.in
RI Gupta, Karunesh K./K-3538-2016
OI Gupta, Karunesh K./0000-0002-0003-4601
CR Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Chen YW, 2016, IEEE ACCESS, V4, P2529, DOI 10.1109/ACCESS.2016.2572121
   Dey B, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445631
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Huang TJ, 2014, IEEE J EM SEL TOP C, V4, P5, DOI 10.1109/JETCAS.2014.2298274
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Li H, 2014, IEEE INT CON MULTI
   Liang YL, 2015, INT CONF WIRE COMMUN
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Moriyama M, 2015, I S INTELL SIG PROC, P48, DOI 10.1109/ISPACS.2015.7432735
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Wang HZ, 2006, INT C PATT RECOG, P223
   Wang WQ, 2008, IEEE T CIRC SYST VID, V18, P670, DOI 10.1109/TCSVT.2008.918800
   Xu Y, 2016, CAAI T INT TECHN, V1
   Zhao L, 2017, IEEE T CIRC SYST VID
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 21
TC 7
Z9 7
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29059
EP 29076
DI 10.1007/s11042-018-6087-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500054
DA 2024-07-18
ER

PT J
AU Teoh, ABJ
   Cho, S
   Kim, J
AF Teoh, Andrew Beng Jin
   Cho, Sejung
   Kim, Jihyeon
TI Random permutation Maxout transform for cancellable facial template
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Template protection; Face recognition; Cancellable biometrics; Locality
   sensitive hashing
ID CANCELABLE BIOMETRICS
AB In this paper, we propose a salting based two-factor cancelable biometrics construct, dubbed Random Permutation Maxout (RPM) transform for facial template protection. The RPM transform is inspired from a member of rank-based Locality Sensitive Hashing (LSH), namely Winner Takes All hashing, which was devised for data retrieval. With externally generated user-specific parameters, RPM converts a continuous facial feature vector into a max ranked indices vector as cancellable template. Since the features magnitude of facial features have been transformed to the discrete index form, the resulting template is robust against noises and it is strongly concealed from the adversary learning on the original facial features. This lays a strong promise on non-invertibility requirement The LSH theory compliance RPM is shown minimal performance deterioration after transform. The experimental results render reasonable accuracy performance on benchmark AR and FERET datasets. We also perform several rigorous security, privacy, revocability and unlinkability analyses, which are required for cancellable biometrics techniques.
C1 [Teoh, Andrew Beng Jin; Cho, Sejung; Kim, Jihyeon] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
C3 Yonsei University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
EM bjteoh@yonsei.ac.kr; b10397@naver.com; kim_jihyeon@yonsei.ac.kr
RI Kim, Jihyeon/IQV-8555-2023; Teoh, Andrew Beng Jin/F-4422-2010
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B4011656]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (NO.
   2016R1A2B4011656).
CR [Anonymous], 2011, EEE T SYST MAN CYBER
   [Anonymous], 2011, ISO/IEC 24745:2011
   [Anonymous], AR FACE DATABASE CVC
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2016.2610969, DOI 10.1109/TPAMI.2016.2610969]
   [Anonymous], P SPIE
   [Anonymous], 1 IEEE INT C BIOM TH
   [Anonymous], P 17 INT C PATT REC
   [Anonymous], P 30 S THEOR COMP
   [Anonymous], 41 INT C AC SPEECH S
   [Anonymous], 2005, P 7 WORKSH MULT SEC
   [Anonymous], 2006 BIOM S SPEC SES
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2017, P 2017 INT C BIOM EG
   [Anonymous], P INT C COMP VIS IM
   Bartal Y, 2011, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P868
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DIACONIS P, 1977, J ROY STAT SOC B MET, V39, P262, DOI 10.1111/j.2517-6161.1977.tb01624.x
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Gomez-Barrero M, 2014, INT C PATT RECOG, P4483, DOI 10.1109/ICPR.2014.767
   Jain AK, 2007, NATURE, V449, P38, DOI 10.1038/449038a
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kang J, 2014, INFORM SCIENCES, V269, P1, DOI 10.1016/j.ins.2014.02.011
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Low CY, 2019, IEEE T CIRC SYST VID, V29, P115, DOI 10.1109/TCSVT.2017.2761829
   Maiorana E, 2010, IEEE T SYST MAN CY A, V40, P525, DOI 10.1109/TSMCA.2010.2041653
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Nakamurai I, 2015, EUR SIGNAL PR CONF, P2421, DOI 10.1109/EUSIPCO.2015.7362819
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Ntantogian C, 2015, COMPUT SECUR, V52, P17, DOI 10.1016/j.cose.2015.03.009
   Oh BS, 2012, PATTERN RECOGN, V45, P3288, DOI 10.1016/j.patcog.2012.02.027
   Pandey RK, 2015, INT CONF BIOMETR, P299, DOI 10.1109/ICB.2015.7139099
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Saito Y, 2016, JOINT INT CONF SOFT, P366, DOI [10.1109/SCIS&ISIS.2016.47, 10.1109/SCIS-ISIS.2016.0082]
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Teoh ABJ, 2007, LECT NOTES COMPUT SC, V4642, P435
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang YJ, 2011, IEEE T SYST MAN CY B, V41, P840, DOI 10.1109/TSMCB.2010.2098439
   Wang Y, 2010, IEEE T SYST MAN CY B, V40, P1280, DOI 10.1109/TSMCB.2009.2037131
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yagnik J, 2011, IEEE I CONF COMP VIS, P2431, DOI 10.1109/ICCV.2011.6126527
NR 52
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27733
EP 27759
DI 10.1007/s11042-018-5956-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500001
DA 2024-07-18
ER

PT J
AU Bhushan, V
   Kumar, V
AF Bhushan, Vishal
   Kumar, Vinay
TI Adaptive variable order polynomial based digital zoom of images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image zooming; Interpolation; Imaging systems
ID CUBIC CONVOLUTION INTERPOLATION
AB Digital zoom is widely used in daily life from zooming a captured image to navigating through live maps. The applications are simple but application domains benefit large number of users. This manuscript proposes a novel approach to escalate zoom limits by modifying the zoom tolerance bound of an image. The approach focuses on preserving original information and transfer it to zoomed image. Digital zoom is achieved by first representing the original image as a set mathematical model representing underlying statistical parameters. The sets in model are further analyzed to calculate set variance; which in turn is used for localizing fluctuations and generate polynomial for each set. These polynomial are then used for implementing variable order interpolation scheme. Experimental results confirm that the present technique outperforms existing techniques in terms of image quality measurement parameters. The discussed approach can be implemented on RGB or grayscale images equivalently.
C1 [Bhushan, Vishal; Kumar, Vinay] Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kumar, V (corresponding author), Thapar Univ, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM vinay.kumar@thapar.edu
RI Kumar, Vinay/AAB-8186-2019
OI Kumar, Vinay/0000-0001-9086-4782
CR [Anonymous], 18 IEEE INT S CONS E
   Caltech, 2016, COMP VIS
   Cha Y, 2007, IEEE T IMAGE PROCESS, V16, P1496, DOI 10.1109/TIP.2007.896645
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Giachetti A., 2008, PROCEED BR MACH VIS, V2008, p13.1
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim H, 2011, IEEE T IMAGE PROCESS, V20, P1895, DOI 10.1109/TIP.2011.2107523
   Lee SJ, 2016, IEEE T CONSUM ELECTR, V62, P159, DOI 10.1109/TCE.2016.7514715
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Mahajan SH, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P772, DOI 10.1109/ICCUBEA.2015.154
   Mikl┬u┬Es P., 2004, P 2 SIB HUNG JOINT S
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   Reichenbach SE, 2003, IEEE T IMAGE PROCESS, V12, P857, DOI 10.1109/TIP.2003.814248
   Russakoff DB, 2004, LECT NOTES COMPUT SC, V3023, P596
   Stoer J., 2013, INTRO NUMERICAL ANAL, V12
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wick DV, 2004, OPT ENG, V43, P8, DOI 10.1117/1.1633570
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhou D, 2012, IET IMAGE PROCESS, V6, P627, DOI 10.1049/iet-ipr.2011.0534
NR 23
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25131
EP 25148
DI 10.1007/s11042-018-5778-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400024
DA 2024-07-18
ER

PT J
AU Huang, PC
   Chang, CC
   Li, YH
AF Huang, Peng-Cheng
   Chang, Chin-Chen
   Li, Yung-Hui
TI Sudoku-based secret sharing approach with cheater prevention using QR
   code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Secret sharing; Cheater prevention; Sudoku
AB QR codes as public patent are widely used to acquire the information in various fields. However, the characteristic of its public readability hinders its usage for delivering private messages. To overcome this weakness, we propose a Sudoku-based secret sharing scheme to protect the privacy QR code message with the functionality of cheater prevention. The secret messages will be divided into several shadows and concealed to the QR code by replacing the QR code public message bits. And the private messages can be faithfully reproduced when all the involved participants cooperate. In our secret sharing scheme, the QR code public message still can be fully decoded publicly from the marked QR codes via a QR code reader, which helps to reduce uninvolved users' curiosity. Experiments show that the proposed scheme is feasible, with high security protection level, and resistant to common image post-processing attacks.
C1 [Huang, Peng-Cheng] Xiamen Univ Technol, Dept Comp Sci, 600 Ligong Rd, Xiamen 361024, Peoples R China.
   [Huang, Peng-Cheng; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Li, Yung-Hui] Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Zhongda Rd, Taoyuan 32001, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; National Central
   University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; Huang, Pengcheng/W-2238-2019; huang,
   peng/KBC-5715-2024
FU Foundation of Fujian Educational Committee of China [JAT160357]
FX This research was partially supported by the Foundation of Fujian
   Educational Committee of China (No. JAT160357).
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Bobmath, 2011, STRUCTURE QR CODE
   Chen W-Y, 2009, OPT ENG, V48
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Chuang Jun-Chou., 2010, International Journal of Image Processing (IJIP), V4, P468
   Denso-Wave Inc, 2000, QR COD STAND
   Dey S., 2012, INT J MODERN ED COMP, V4, P59, DOI [10.5815/ijmecs.2012.06.08, DOI 10.5815/IJMECS.2012.06.08]
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Li Li, 2011, J HANGZHOU DIANZI U, V31, P46
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   Rungraungsilp S., 2012, P INT C COMP COMM TE, P144
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sun M, 2007, NEW ZEAL J AGR RES, V50, P861, DOI 10.1080/00288230709510361
   Xing MH, 2015, ACSR ADV COMPUT, V16, P140
   Yung-Chen Chou, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P43, DOI 10.1109/IIHMSP.2010.18
   Zhi-Hui Wang, 2013, Journal of Electronic Science and Technology, V11, P44, DOI 10.3969/j.issn.1674-862X.2013.01.009
NR 16
TC 7
Z9 7
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25275
EP 25294
DI 10.1007/s11042-018-5784-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400030
DA 2024-07-18
ER

PT J
AU Karsh, RK
   Saikia, A
   Laskar, RH
AF Karsh, Ram Kumar
   Saikia, Arunav
   Laskar, Rabul Hussain
TI Image authentication based on robust image hashing with geometric
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust image hashing; Geometric transformation; Markov absorption
   probabilities; Image authentication; Tampering detection
ID RING PARTITION; MOMENTS; SCHEME; SECURE
AB Image authentication based on robust image hashing has been widely discussed with continuous improvements. However, most of the existing methods misjudge the images processed through the geometric transformation and small malicious operations. In this paper, we have proposed a geometric correction approach, which eliminates the influence of geometric transformation, including composite rotation-scaling-translation (RST). We have incorporated the local features with global features to construct hash. The local features are extracted from the salient regions, which have been obtained using Markov absorption probabilities. The global features include statistical feature distance. While being robust to content-preserving operations (including the composite RST) the hash is sensitive to the small malicious operations, and hence may be used for image authentication. The proposed image authentication is a two-phase system. First, the threshold, , based on only global feature segregates between different (also includes large area tampering) images and similar images or small tampered images. In the next phase, the similar image pairs are authenticated and the tampered regions are localized, based on local features. The receiver operating characteristics shows that the proposed image authentication system outperforms some state-of-the-art methods.
C1 [Karsh, Ram Kumar; Saikia, Arunav; Laskar, Rabul Hussain] Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Karsh, RK (corresponding author), Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
EM tnramkarsh@gmail.com
RI Laskar, Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Karsh,
   Ram/0000-0002-2341-341X
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2007, USC SIPI IM DAT
   [Anonymous], 2017, NITS IMAGE HASHING D
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Kantor ILV, 1989, HYPER COMPLEX NUMBER
   Karsh R. K., 2015, P TENCON 2015 IEEE R, P1
   Karsh RK, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0179-0
   Karsh RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3639-6
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu W, 2010, INT SOC OPTICS PHOTO
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Manish Mishra Manish Mishra, 2013, International Research Journal of Biological Sciences, V2, P1
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Ouyang JL, 2017, MULTIMED TOOLS APPL, V76, P2609, DOI 10.1007/s11042-015-3225-x
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 39
TC 29
Z9 29
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25409
EP 25429
DI 10.1007/s11042-018-5799-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400037
DA 2024-07-18
ER

PT J
AU Meng, B
   Liu, XJ
   Wang, XL
AF Meng, Bo
   Liu, XueJun
   Wang, Xiaolin
TI Human action recognition based on quaternion spatial-temporal
   convolutional neural network and LSTM in RGB videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Convolutional neural network; Quaternion; Long
   short-term memory network; Codebook
ID HISTOGRAMS
AB Convolutional neural networks (CNN) are the state-of-the-art method for action recognition in various kinds of datasets. However, most existing CNN models are based on lower-level handcrafted features from gray or RGB image sequences from small datasets, which are incapable of being generalized for application to various realistic scenarios. Therefore, we propose a new deep learning network for action recognition that integrates quaternion spatial-temporal convolutional neural network (QST-CNN) and Long Short-Term Memory network (LSTM), called QST-CNN-LSTM. Unlike a traditional CNN, the input for a QST-CNN utilizes a quaternion expression for an RGB image, and the values of the red, green, and blue channels are considered simultaneously as a whole in a spatial convolutional layer, avoiding the loss of spatial features. Because the raw images in video datasets are large and have background redundancy, we pre-extract key motion regions from RGB videos using an improved codebook algorithm. Furthermore, the QST-CNN is combined with LSTM for capturing the dependencies between different video clips. Experiments demonstrate that QST-CNN-LSTM is effective for improving recognition rates in the Weizmann, UCF sports, and UCF11 datasets.
C1 [Meng, Bo; Liu, XueJun; Wang, Xiaolin] Northeast Elect Power Univ, Sch Informat Engn, Jilin, Jilin, Peoples R China.
C3 Northeast Electric Power University
RP Liu, XJ (corresponding author), Northeast Elect Power Univ, Sch Informat Engn, Jilin, Jilin, Peoples R China.
EM liuxuejun_0828@163.com
RI wang, xiao/HGB-7081-2022; chen, xi/T-2067-2018; Meng, Bo/AAO-7303-2020;
   wang, xiao/HZI-9156-2023
OI wang, xiao/0000-0002-4088-3341; Meng, Bo/0000-0001-6894-4479; 
FU National Natural Science Foundation of China [61602108]; Jilin Science
   and Technology Innovation Developing Scheme [20166016]; Electric Power
   Intelligent Robot Collaborative Innovation Group
FX This work was supported by National Natural Science Foundation of China
   (61602108), Jilin Science and Technology Innovation Developing Scheme
   (20166016), and the Electric Power Intelligent Robot Collaborative
   Innovation Group.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2016, J NE DIANLI U
   [Anonymous], POWER ENERGY SOC GEN
   [Anonymous], 2016, APPL COMPUTER VISION, DOI DOI 10.1109/WACV.2016.7477589
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gutub A, 2017, MULTIMED TOOLS APPL, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hamilton W. R., 1969, Elements of Quaternions
   Hamilton W.R., 1969, ELEMENTS QUATERNIONS, V2
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hoai M, 2015, LECT NOTES COMPUT SC, V9007, P3, DOI 10.1007/978-3-319-16814-2_1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kim HJ, 2007, LECT NOTES COMPUT SC, V4492, P715
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Lan ZZ, 2016, IEEE COMPUT SOC CONF, P1196, DOI 10.1109/CVPRW.2016.152
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Ravanbakhsh Mahdyar, 2015, ABS151203980 CORR
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Salakhutdinov, 2015, ARXIV151104119
   Salih AA, 2016, PATTERN RECOGN LETT, V83, P32, DOI 10.1016/j.patrec.2016.05.032
   Sapienza M, 2014, ABS14057545 CORR
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tian YY, 2016, J NE ELECT POWER U, V5, P56
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang JX, 2016, ACSR ADV COMPUT, V41, P57
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362
   Wu Kun, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P419
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zeng R, 2016, NEUROCOMPUTING, V216, P416, DOI 10.1016/j.neucom.2016.08.006
   Zou CM, 2016, IEEE T IMAGE PROCESS, V25, P3287, DOI 10.1109/TIP.2016.2567077
NR 49
TC 37
Z9 37
U1 3
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26901
EP 26918
DI 10.1007/s11042-018-5893-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500030
DA 2024-07-18
ER

PT J
AU Merrad, A
   Saadi, S
AF Merrad, Ahmed
   Saadi, Slami
TI Blind speech watermarking using hybrid scheme based on DWT/DCT and
   sub-sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind; Speech watermarking; DCT; DWT; Sub-sampling; Attacks
ID AUDIO WATERMARKING; ALGORITHM
AB In this paper, a robust and blind speech watermarking technique is proposed using a combined scheme based on discrete cosine transform (DCT) and discrete wavelet transform (DWT) Algorithms within signal sub-sampling. To achieve good imperceptibility, hybridization is implemented against many attacks such as: re-quantization, cropping, echo, amplification and additive white Gaussian noise (AWGN). We profit from the advantages of correlation between two successive samples so that we used signal sub-sampling. Obtained results, compared successfully to recent researches, show the robustness of our proposed approach.
C1 [Merrad, Ahmed; Saadi, Slami] Ziane Achour Univ Djelfa UZAD, Fac Exact Sci & Comp, Lab Automat & Appl Ind Diagnost LAADI, BP3117, Djelfa, Algeria.
RP Saadi, S (corresponding author), Ziane Achour Univ Djelfa UZAD, Fac Exact Sci & Comp, Lab Automat & Appl Ind Diagnost LAADI, BP3117, Djelfa, Algeria.
EM saadisdz@gmail.com
RI slami, saadi/O-2435-2016
OI slami, saadi/0000-0001-8091-5232
CR Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Antony Sobin, 2012, INT J COMPUTER APPL, V52, P975
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Brannock Evelyn, 2008, WATERMARKING WAVELET
   Cai Yong-mei, 2013, Journal of Software, V8, P1801, DOI 10.4304/jsw.8.7.1801-1808
   Debnath Lokenath., 2002, WAVELET TRANSFORM TH, DOI 10.1007/978-1-4612-0097-0
   Deokar SM, 2015, INT C IND INSTR CONT
   Dhar PK, 2017, RADIOENGINEERING, V26, P552, DOI 10.13164/re.2017.0552
   Dhar Pranab Kumar, 2014, 8 INT C EL COMP ENG
   Elshazly AR, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P52, DOI 10.1109/JEC-ECC.2016.7518966
   Gupta M, 2013, INT J CORROS, V2013, DOI 10.1155/2013/582982
   Hemis M, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500204
   Kaur A, 2017, J INF SECUR APPL, V33, P1, DOI 10.1016/j.jisa.2016.12.003
   Khan MI, 2012, INT J COMPUT SCI INF, V4
   Lin Y, CHAM, DOI [10.1007/978-3-319-07974-5, DOI 10.1007/978-3-319-07974-5]
   Mehta Varun, 2015, INT J COMPUTER APPL, V123, P30
   Nair UR, 2016, INT C IEEE, P1
   Nosrati M., 2012, WORLD APPL PROGRAMMI, V2, P202
   Osman Mahmoud A., 2012, MECH ELECT TECHNOLOG, V229, P2784
   Pithiya Pravin M., 2013, INT J ENG RES DEV, V7, P104
   Tiwari A., 2012, J INFORM SECURITY, V3, P189, DOI DOI 10.4236/JIS.2012.33023
   Villanueva-Luna A.E., 2011, Engineering education and research using MATLAB
   Wang J, 2017, MULTIMED TOOLS APPL, V76, P14799, DOI 10.1007/s11042-016-4027-5
   Wang XK, 2014, MULTIMED TOOLS APPL, V71, P1157, DOI 10.1007/s11042-012-1259-x
   Xiang Shijun, 2007, CORR
   Yang HY, 2012, MULTIMED TOOLS APPL, V57, P453, DOI 10.1007/s11042-010-0644-6
   Zhao H, 2014, ELEKTRON ELEKTROTECH, V20, P75, DOI 10.5755/j01.eee.20.1.3948
NR 27
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27589
EP 27615
DI 10.1007/s11042-018-5939-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500060
DA 2024-07-18
ER

PT J
AU Yue, T
   Wang, HB
   Cheng, SD
AF Yue, Ting
   Wang, Hongbo
   Cheng, Shiduan
TI Learning from users: a data-driven method of QoE evaluation for Internet
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet video; QoE; Feature engineering; User behavior; Time series
   pattern mining; Ensemble method
ID QUALITY; BEHAVIOR
AB Improving quality of experience (QoE) is increasingly significant for Internet video content providers. The essential issue is how to evaluate QoE under the complex circumstance of Internet video. Based on the massive user data extracted from a large scale Video-on-Demand (VoD) provider, we present a data-driven, comprehensive and extendible study on the problems of QoE evaluation. The main works of this paper include obtaining QoE-associated features via feature engineering and building an evaluation model on features of different aspects for Internet video QoE. Firstly, for feature engineering, we propose to introduce pattern features of user viewing behaviors that interact with user-perceived video quality. A new method of frequent time series pattern mining is proposed to find typical patterns. We correlate user experience with user-perceived quality features and user behavior pattern features, and consider the impact of confounding factors by applying them as context features into modeling. Secondly, interdependency among features is challenging for QoE evaluation modeling. And the high dimension of feature vector should be considered. To address these challenges, we develop an ensemble method to model the interactions between features and their intricate relationships to user experience. Experiments demonstrate that our approach could achieve sound results in comparison with other related works.
C1 [Yue, Ting; Wang, Hongbo; Cheng, Shiduan] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wang, HB (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
EM yueting_aki@bupt.edu.cn; hbwang@bupt.edu.cn; chsd@bupt.edu.cn
CR Agarwal RC, 2002, ACM SIGKDD INT C KNO, P108
   Agboma F, 2012, TELECOMMUN SYST, V49, P85, DOI 10.1007/s11235-010-9355-6
   AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   Agrawal R., 1996, Advances in Knowledge Discovery and Data Mining, V12, P307, DOI DOI 10.1007/978-3-319-31750-2.
   [Anonymous], 2001, J UNIVERS COMPUT SCI
   [Anonymous], 2013, P 2013 C INT MEAS C, DOI [DOI 10.1145/2504730.2504748, 10.1145/2504730.2504748]
   Ayres J, 2002, P 8 ACM SIGKDD INT C, V8, P429, DOI DOI 10.1145/775047.775109
   Balachandran Athula, 2013, Performance Evaluation Review, V41, P379
   Balachandran A., 2013, Proceedings of the 2013 conference on Internet measurement conference, P43
   Balachandran A, 2013, ACM SIGCOMM COMP COM, V43, P339, DOI 10.1145/2534169.2486025
   Bayardo R. J.  Jr., 1998, SIGMOD Record, V27, P85, DOI 10.1145/276305.276313
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8
   Casas P, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P1609
   Chen L, 2014, COMPUT COMMUN, V46, P66, DOI 10.1016/j.comcom.2014.01.009
   Cheng H, 2007, PROC INT CONF DATA, P691
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Diewert E, 2005, REV INCOME WEALTH, P561
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Freudenthaler C, 2013, BAYESIAN FACTORIZATI
   Gopalakrishnan V., 2011, P 2011 ACM SIGCOMM C, P225, DOI DOI 10.1145/2068816.2068838
   Greenacre MJ, 2007, CORRES ANAL PRACTICE
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Han JW, 2000, SIGMOD RECORD, V29, P1
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Jana S, 2016, MULTIMED TOOLS APPL, V75, P7957, DOI 10.1007/s11042-015-2711-5
   Joumblatt D, 2013, IEEE INFOCOM SER, P235
   KLIR GJ, 1994, FUZZY SETS FUZZY LOG
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   Li ZK, 2012, ADV MATER RES-SWITZ, V427, P185, DOI 10.4028/www.scientific.net/AMR.427.185
   Mok R.K., 2011, PROC ACM SIGCOMM WOR, P31, DOI DOI 10.1145/2018602.2018611
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Mongy Sylvain, 2007, Proceedings of the International Conference on Data Mining. DMIN 2007, P99
   Ng A., 2016, MACHINE LEARNING COU
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Robitza W, 2016, 8 INT C QUAL MULT EX, P1, DOI DOI 10.1109/QOMEX.2016.7498926
   Shenoy P, 2000, SIGMOD RECORD, V29, P22, DOI 10.1145/335191.335376
   Shewhart W A, 2005, APPL LOGISTIC REGRES
   Sogaard J, 2017, MULTIMED TOOLS APPL, V76, P16727, DOI 10.1007/s11042-016-3948-3
   Song H.H., 2011, ACM SIGCOMM C INTERN, P195
   Trouleau W, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1215, DOI 10.1145/2939672.2939792
   Xiao ZJ, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417690
   Yue T, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1479, DOI 10.1109/FSKD.2016.7603395
   Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P283
   Zaki MJ, 2002, SIAM PROC S, P457
   Zhang DL, 2017, MULTIMED TOOLS APPL, V76, P7175, DOI 10.1007/s11042-016-3359-5
NR 48
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27269
EP 27300
DI 10.1007/s11042-018-5918-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500047
DA 2024-07-18
ER

PT J
AU Vranjes, M
   Rimac-Drlje, S
   Vranje, D
AF Vranjes, Mario
   Rimac-Drlje, Snjezana
   Vranjes, Denis
TI Foveation-based content adaptive root mean squared error for video
   quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FARMSE; Foveated vision; Human visual system; Spatio-temporal activity;
   Video quality assessment
ID HIGHLY PARALLEL FRAMEWORK; REFERENCE PSNR ESTIMATION; HEVC MOTION
   ESTIMATION; COMPRESSED VIDEO; STRUCTURAL SIMILARITY; MODEL; INTEGRATION;
   ATTENTION; REGIONS; NOISE
AB When the video is compressed and transmitted over heterogeneous networks, it is necessary to ensure the satisfying quality for the end user. Since human observers are the end users of video applications, it is very important that the human visual system (HVS) characteristics are taken into account during the video quality evaluation. This paper deals with video quality assessment (VQA) based on HVS characteristics and proposes a novel full-reference (FR) VQA metric called the Foveation-based content Adaptive Root Mean Squared Error (FARMSE). FARMSE uses several HVS characteristics that significantly influence perception of distortions in a video. Primarily these are foveated vision, reduction of the spatial acuity due to motions as well as spatial masking. Foveated vision is related to variable resolution of HVS across the viewing field, where the highest resolution is at the point of fixation. The point of fixation is projected onto the fovea - the area of retina with the highest density of photoreceptors. The part of image that falls on fovea is perceived by the highest acuity. whereas the spatial acuity decreases as the distance of the image part from the fovea increases. Spatial acuity further decreases if eyes cannot track moving objects. Both mentioned mechanisms influence contrast sensitivity of the HVS. Contrast sensitivity is frequency dependent and FARMSE uses Haar filters to utilize this dependence. Furthermore, spatial masking is implemented in each frequency channel. The FARMSE performance is compared to this of nine state-of-the-art VQA metrics on two different databases, LIVE and ECVQ. Additionally, the metrics are compared in terms of calculation complexity. The performed experiments show that FARMSE achieves high performance when predicting the quality of videos with different resolutions, degradation types and content types. FARMSE results outperform the results of most of the analyzed metrics, whereas they are comparable to these of the best publicly available metrics, including the well-known MOtion-based Video Integrity Evaluation (MOVIE) index. Besides that, FARMSE calculation complexity is significantly lower than that of the metrics comparable thereto in terms of prediction accuracy.
C1 [Vranjes, Mario; Rimac-Drlje, Snjezana; Vranjes, Denis] Univ Osijek, Fac Elect Engn Comp Sci & Informat Technol, Kneza Trpimira 2B, Osijek 31000, Croatia.
C3 University of JJ Strossmayer Osijek
RP Vranjes, M (corresponding author), Univ Osijek, Fac Elect Engn Comp Sci & Informat Technol, Kneza Trpimira 2B, Osijek 31000, Croatia.
EM mario.vranjes@ferit.hr; snjezana.rimac@ferit.hr; denis.vranjes@ferit.hr
RI Rimac-Drlje, Snjezana/ACP-5982-2022
OI Vranjes, Mario/0000-0003-3563-4735
FU J.J. Strossmayer University of Osijek [IZIP-2016]
FX This work was supported by the J.J. Strossmayer University of Osijek
   business fund through the internal competition for the research and
   artistic projects "IZIP-2016" (project title: "Providing of digital
   video signal based services in rural and rarely populated areas").
CR [Anonymous], 2010, SPIE P HUMAN VISION
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   [Anonymous], 2003, FIN REP VID QUAL EXP
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P4916, DOI 10.1109/TIP.2016.2598492
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   Bhat A, 2012, IEEE T CIRC SYST VID, V22, P165, DOI 10.1109/TCSVT.2011.2158465
   Birge B, 2012, PARTICLE SWARM OPTIM
   Boccignone G, 2008, IEEE T CIRC SYST VID, V18, P1727, DOI 10.1109/TCSVT.2008.2005798
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Breitmeyer BG, 2000, PERCEPT PSYCHOPHYS, V62, P1572, DOI 10.3758/BF03212157
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chandler DM, 2007, VSNR WAVELET BASED V
   Chen ZB, 2016, IEEE T CIRC SYST VID, V26, P1029, DOI 10.1109/TCSVT.2015.2441432
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Ciubotaru B, 2014, IEEE T BROADCAST, V60, P50, DOI 10.1109/TBC.2013.2290238
   Ciubotaru B, 2009, IEEE T BROADCAST, V55, P202, DOI 10.1109/TBC.2009.2020448
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   Eckert Michael P., 1993, P89
   Fei X, 2012, SIGNAL PROCESS-IMAGE, V27, P772, DOI 10.1016/j.image.2012.04.005
   Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Joskowicz J, 2013, IEEE T BROADCAST, V59, P569, DOI 10.1109/TBC.2013.2277951
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Lee B, 2013, IEEE T BROADCAST, V59, P20, DOI 10.1109/TBC.2012.2226533
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Li SN, 2012, IEEE T CIRC SYST VID, V22, P1100, DOI 10.1109/TCSVT.2012.2190473
   LISBERGER SG, 1981, J NEUROPHYSIOL, V46, P229, DOI 10.1152/jn.1981.46.2.229
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Ma L, 2012, IEEE T CIRC SYST VID, V22, P1441, DOI 10.1109/TCSVT.2012.2202049
   Masry MA, 2004, SIGNAL PROCESS-IMAGE, V19, P133, DOI 10.1016/j.image.2003.08.001
   McDonagh P, 2013, IEEE T BROADCAST, V59, P223, DOI 10.1109/TBC.2013.2255776
   Mittal A, 2011, P SOC PHOTO-OPT INS, V7685
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Murthy Adithya V., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P242, DOI 10.1109/QOMEX.2010.5516091
   Murthy AV, 2010, IVQUEST IMAGE VIDEO
   Na T, 2014, IEEE T CIRC SYST VID, V24, P320, DOI 10.1109/TCSVT.2013.2255425
   Narwaria M, 2012, IEEE T MULTIMEDIA, V14, P525, DOI 10.1109/TMM.2012.2190589
   Osberger W, 2001, PROC SPIE, V4299, P361, DOI 10.1117/12.429506
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Park J, 2013, IEEE T IMAGE PROCESS, V22, P610, DOI 10.1109/TIP.2012.2219551
   Pinson MH, 2014, IEEE T BROADCAST, V60, P637, DOI 10.1109/TBC.2014.2365260
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Recommendation ITU-T P.910, 1999, P910 ITUT
   Rimac-Drlje S., 2009, P 16 INT C SYST SIGN, P1
   Rimac-Drlje S, 2010, MULTIMED TOOLS APPL, V49, P425, DOI 10.1007/s11042-009-0442-1
   Rodríguez DZ, 2016, IEEE T BROADCAST, V62, P628, DOI 10.1109/TBC.2016.2570012
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Seyedebrahimi M, 2013, IEEE T CIRC SYST VID, V23, P2034, DOI 10.1109/TCSVT.2013.2270365
   Sogaard J, 2015, IEEE T CIRC SYST VID, V25, P1637, DOI 10.1109/TCSVT.2015.2397207
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Staelens N, 2013, IEEE T CIRC SYST VID, V23, P1322, DOI 10.1109/TCSVT.2013.2243052
   Sun XS, 2014, IEEE T IMAGE PROCESS, V23, P4649, DOI 10.1109/TIP.2014.2337758
   van der Linde I, 2009, SPATIAL VISION, V22, P161, DOI 10.1163/156856809787465636
   Vranjes M, 2012, THESIS
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   Vranjes M, 2012, ELMAR PROC, P13
   Wang Y, 2012, IEEE T CIRC SYST VID, V22, P989, DOI 10.1109/TCSVT.2012.2186745
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2001, P SOC PHOTO-OPT INS, V4472, P1
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yeh HH, 2013, IEEE T MULTIMEDIA, V15, P1944, DOI 10.1109/TMM.2013.2280250
   You JY, 2014, IEEE T IMAGE PROCESS, V23, P200, DOI 10.1109/TIP.2013.2287611
   You JY, 2010, IEEE INT CON MULTI, P914, DOI 10.1109/ICME.2010.5583037
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zhang F, 2016, IEEE T CIRC SYST VID, V26, P1017, DOI 10.1109/TCSVT.2015.2428551
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
   Zhu KF, 2015, IEEE T CIRC SYST VID, V25, P533, DOI 10.1109/TCSVT.2014.2363737
NR 87
TC 7
Z9 7
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21053
EP 21082
DI 10.1007/s11042-017-5544-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300033
DA 2024-07-18
ER

PT J
AU Wu, LS
   Liu, Z
   Song, HK
   Le Meur, O
AF Wu, Lishan
   Liu, Zhi
   Song, Hangke
   Le Meur, Olivier
TI RGBD co-saliency detection via multiple kernel boosting and fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-saliency detection; RGBD images; Multiple kernel boosting; Fusion
ID OBJECT DETECTION
AB RGBD co-saliency detection, which aims at extracting common salient objects from a group of RGBD images with the additional depth information, has become an emerging branch of saliency detection. In this regard, this paper proposes a novel framework via multiple kernel boosting (MKB) and co-saliency quality based fusion. First, on the basis of pre-segmented regions at multiple scales, the regional clustering by feature bagging is exploited to generate the base co-saliency maps. Then the clustering-based samples selection is performed to select the most similar regions with high saliency from different images in the image set. The selected samples are utilized to learn a MKB-based regressor, which is applied to all regions at multiple scales to generate the MKB-based co-saliency maps. Finally, to make full use of both MKB and clustering-based cosaliency maps, a co-saliency quality criterion is proposed for adaptive fusion to generate the final co-saliency maps. Experimental results on a public RGBD co-saliency detection dataset demonstrate that the proposed co-saliency model outperforms the state-of-the-art co-saliency models.
C1 [Wu, Lishan; Liu, Zhi; Song, Hangke] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wu, Lishan; Liu, Zhi; Song, Hangke] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Le Meur, Olivier] Univ Rennes 1, IRISA, F-35042 Rennes, France.
C3 Shanghai University; Shanghai University; Universite de Rennes
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM wlsxxrs@163.com; liuzhisjtu@163.com; hksong0209@163.com;
   olemeur@irisa.fr
RI LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301]; Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61771301, and by the Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning.
CR [Anonymous], 2003, Information Theory, Inference and Learning Algorithms, DOI 10.2277/0521642981
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bezdek JC, 2013, PATTERN RECOGN, P99
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho M, 2015, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2015.7298724
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   FU HZ, 2015, PROC CVPR IEEE, P4428, DOI DOI 10.1109/CVPR.2015
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jacobs D.E., 2010, ACM S USER INTERFACE, P219
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Song HK, 2016, INT CONF ACOUST SPEE, P1626, DOI 10.1109/ICASSP.2016.7471952
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wang ZX, 2013, IEEE I CONF COMP VIS, P393, DOI 10.1109/ICCV.2013.56
   Ye LW, 2015, IEEE SIGNAL PROC LET, V22, P2073, DOI 10.1109/LSP.2015.2458434
   Zhang D., 2016, ARXIV160407090
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
NR 33
TC 10
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21185
EP 21199
DI 10.1007/s11042-017-5576-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300038
DA 2024-07-18
ER

PT J
AU Wu, T
   Liu, Z
   Zhou, X
   Li, K
AF Wu, Tongbao
   Liu, Zhi
   Zhou, Xiaofei
   Li, Kai
TI Spatiotemporal salient object detection by integrating with objectness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Saliency; Objectness; Object probability map
ID PARALLEL FRAMEWORK; DETECTION MODEL; VIDEO; IMAGE; SEGMENTATION; TREE
AB This paper proposes a novel spatiotemporal salient object detection method by integrating saliency and objectness, for videos with complicated motion and complex scenes. The initial salient object detection result is first built upon both saliency map and objectness map. Afterwards, the region size of salient object is adjusted to obtain the frame-wise salient object detection result by iteratively updating the object probability map, which is the combination of saliency map and objectness map. Finally, in order to enhance the temporal coherence, the sequence-level refinement is performed to generate the final salient object detection result. Experimental results on public benchmark datasets demonstrate that the proposed method consistently outperforms the state-of-the-art salient object detection methods.
C1 [Wu, Tongbao; Liu, Zhi; Zhou, Xiaofei; Li, Kai] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wu, Tongbao; Liu, Zhi; Zhou, Xiaofei; Li, Kai] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM 15551253114@163.com; liuzhisjtu@163.com; zxforchid@outlook.com;
   kailee@shu.edu.cn
RI LIU, Zhi/D-4518-2012; Xiaofei, Zhou/AAE-8347-2020
OI LIU, Zhi/0000-0002-8428-1131; 
FU National Natural Science Foundation of China [61471230, 61601278];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61471230 and No. 61601278, and by the Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning.
CR [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], HDB COMPUTER VISION
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], P ACCV
   [Anonymous], 2014, COMPUT VISUAL MEDIA
   Bao L, 2016, MULTIMED TOOLS APPL, V75, P7761, DOI 10.1007/s11042-015-2692-4
   Bao L, 2015, MULTIMED TOOLS APPL, V74, P4045, DOI 10.1007/s11042-014-2043-x
   Chan A. B., 2007, P IEEE CVPR, P1
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Huang JW, 2009, IEEE INT CON MULTI, P1322, DOI 10.1109/ICME.2009.5202746
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li Junhao, 2015, Journal of Computer Applications, V35, P3560, DOI 10.11772/j.issn.1001-9081.2015.12.3560
   Li JH, 2015, SIGNAL PROCESS-IMAGE, V38, P100, DOI 10.1016/j.image.2015.04.014
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Lin RS, 2006, LECT NOTES COMPUT SC, V3952, P245
   Liu Ce, 2009, THESIS
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Luo Y, 2016, J VIS COMMUN IMAGE R, V38, P45, DOI 10.1016/j.jvcir.2016.02.001
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Tian YH, 2015, INT J COMPUT VISION, V111, P153, DOI 10.1007/s11263-014-0737-1
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Wu TB, 2016, PROC SPIE, V10033, DOI 10.1117/12.2244867
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Ye LL, 2016, PURE APPL GEOPHYS, V173, P321, DOI 10.1007/s00024-015-1202-y
   You XG, 2016, IEEE T IMAGE PROCESS, V25, P4782, DOI 10.1109/TIP.2016.2598653
   Yuan Z, 2012, IEEE T CIRC SYST VID, V22, P890, DOI 10.1109/TCSVT.2011.2181230
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 50
TC 5
Z9 6
U1 11
U2 117
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19481
EP 19498
DI 10.1007/s11042-017-5334-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500027
DA 2024-07-18
ER

PT J
AU Zou, XM
   Yang, J
   Zhang, JP
AF Zou Xiaomei
   Yang Jing
   Zhang Jianpei
TI Sentiment-based and hashtag-based Chinese online bursty event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Event detection; Hashtag; Text analysis; Social
   media
ID TWITTER
AB How to detect bursty events in data streams on social media is a hot research topic in natural language processing. However, current methods for extracting bursty events suffer from poor accuracy and low efficiency. Fortunately, sentiment analysis has been applied to event detection, which has improved the performance greatly. Inspired by this, this paper proposes a new model which utilizes sentiment analysis for Chinese bursty event detection. First, we build a sentiment co-occurrence graph offline and apply it to analyze microblog sentiment. Plutchik's emotion wheel is the base for the sentiment classification of the graph. Second, sentiment is used as features to detect bursts in microblog streams online. At last, we exploit regular expressions to extract hashtags in bursty periods and segment hashtags into keywords. By using mutual information and frequent patterns, we fetch words relevant to hashtags as keywords to form events. This approach can detect bursty events online while analyzing the sentiment of microblogs. The experimental results on a large real dataset show that our method can detect bursty events with higher accuracy in a shorter time than traditional methods.
C1 [Zou Xiaomei; Yang Jing; Zhang Jianpei] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Yang, J (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM zouxiaomeihy@163.com; yangjing@hrbeu.edu.cn; zhangjianpei@hrbeu.edu.cn
FU National Natural Science Foundation of China [61672179, 61370083,
   61402126]; Research Fund for the Doctoral Program of Higher Education of
   China [20122304110012]; Youth Science Foundation of Heilongjiang
   Province of China [QC2016083]; Heilongjiang postdoctoral Fund
   [LBH-Z14071]; China Scholarship Council
FX This paper is supported by (1) the National Natural Science Foundation
   of China under Grant nos. 61672179, 61370083 and 61402126, (2) Research
   Fund for the Doctoral Program of Higher Education of China under Grant
   nos. 20122304110012, (3) the Youth Science Foundation of Heilongjiang
   Province of China under Grant no. QC2016083, (4) Heilongjiang
   postdoctoral Fund no. LBH-Z14071. This paper is also supported by China
   Scholarship Council.
CR Adedoyin-Olowe M, 2016, EXPERT SYST APPL, V55, P351, DOI 10.1016/j.eswa.2016.02.028
   Anjaria M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0181-9
   [Anonymous], 2010, P 19 ACM INT C INF K
   [Anonymous], 2010, LREC 10
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Bisht S, 2014, LECT NOTES COMPUT SC, V8669, P394, DOI 10.1007/978-3-319-10840-7_48
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Bouras Christos, 2010, Proceedings of the Fifth International Conference on Internet and Web Applications and Services (ICIW 2010), P1, DOI 10.1109/ICIW.2010.8
   Cambria E, 2014, AAAI CONF ARTIF INTE, P1515
   Cui A., 2012, P 21 ACM INT C INFOR, P1794
   Cui AQ, 2011, LECT NOTES COMPUT SC, V7097, P238, DOI 10.1007/978-3-642-25631-8_22
   Fan J, 2016, NEURAL COMPUTING APP
   Fung G.P. C., 2005, VLDB, P181
   Fung GPC, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P300
   Goorha S., 2010, SIGKDD, P57, DOI [10.1145/1835804.1835815, DOI 10.1145/1835804.1835815]
   Guardia-Sebaoun E., 2013, P 10 C OP RES AR INF, P201
   Han JW, 2000, SIGMOD RECORD, V29, P1
   Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314
   Li H, 2015, SPR-CATAL, V27, P144, DOI 10.1039/9781782622697-00144
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang Ru-Ze, 2016, ARXIV160804581
   Liang RZ, 2016, ARXIV160406620
   Liu Q., 2002, Computational Linguistics and Chinese Language Processing, P59
   Lu TJ, 2015, INT CONF BIG DATA, P194, DOI 10.1109/35021BIGCOMP.2015.7072831
   Ortigosa-Hernández J, 2012, NEUROCOMPUTING, V92, P98, DOI 10.1016/j.neucom.2012.01.030
   Paltoglou G, 2015, J ASS INFORM SCI TEC
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Preotiuc-Pietro D., 2016, STUDYING TEMPORAL DY
   Qi He, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P207
   Read J, 2005, Proceedings of the ACL Student Research Workshop, ACLstudent'05, P43
   [申国伟 Shen Guowei], 2015, [计算机研究与发展, Journal of Computer Research and Development], V52, P512
   Snowsill T., 2010, 2010 2nd International Workshop on Cognitive Information Processing (CIP 2010), P405, DOI 10.1109/CIP.2010.5604085
   Stilo G, 2016, DATA MIN KNOWL DISC, V30, P372, DOI 10.1007/s10618-015-0412-3
   Sun JS, 2015, INFORM PROCESS MANAG, V51, P444, DOI 10.1016/j.ipm.2014.09.002
   Thelwall M, 2011, J AM SOC INF SCI TEC, V62, P406, DOI 10.1002/asi.21462
   Nguyen T, 2013, KNOWL INF SYST, V37, P279, DOI 10.1007/s10115-012-0494-9
   Wang X., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM'11, P1031
   Wang ZX, 2014, INT CONF CLOUD COMP, P917, DOI 10.1109/CloudCom.2014.69
   Wu QH, 2016, WORLD WIDE WEB, V19, P277, DOI 10.1007/s11280-015-0359-8
   Xiang-Ying Dai, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P3341, DOI 10.1109/ICMLC.2010.5580677
   Xie W, 2013, IEEE DATA MINING, P837, DOI 10.1109/ICDM.2013.86
   Yao JJ, 2012, WORLD WIDE WEB, V15, P171, DOI 10.1007/s11280-011-0136-2
   [张鲁民 Zhang Lumin], 2013, [计算机学报, Chinese Journal of Computers], V36, P1659
NR 44
TC 9
Z9 12
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21725
EP 21750
DI 10.1007/s11042-017-5531-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300061
DA 2024-07-18
ER

PT J
AU Boukhers, Z
   Shirahama, K
   Grzegorzek, M
AF Boukhers, Zeyd
   Shirahama, Kimiaki
   Grzegorzek, Marcin
TI Less restrictive camera odometry estimation from monocular camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera odometry; RJ-MCMC particle filtering; Trajectory extraction
ID TRACKING; ROBUST
AB This paper addresses the problem of estimating a camera motion from a non-calibrated monocular camera. Compared to existing methods that rely on restrictive assumptions, we propose a method which can estimate camera motion with much less restrictions by adopting new example-based techniques compensating the lack of information. Specifically, we estimate the focal length of the camera by referring to visually similar training images with which focal lengths are associated. For one step camera estimation, we refer to stationary points (landmark points) whose depths are estimated based on RGB-D candidates. In addition to landmark points, moving objects can be also used as an information source to estimate the camera motion. Therefore, our method simultaneously estimates the camera motion for a video, and the 3D trajectories of objects in this video by using Reversible Jump Markov Chain Monte Carlo (RJ-MCMC) particle filtering. Our method is evaluated on challenging datasets demonstrating its effectiveness and efficiency.
C1 [Boukhers, Zeyd; Shirahama, Kimiaki; Grzegorzek, Marcin] Univ Siegen, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
   [Grzegorzek, Marcin] Univ Econ Katowice, Fac Informat & Commun, Bogucicka 3, PL-40226 Katowice, Poland.
C3 Universitat Siegen; University of Economics in Katowice
RP Boukhers, Z (corresponding author), Univ Siegen, Res Grp Pattern Recognit, Hoelderlinstr 3, D-57076 Siegen, Germany.
EM zeyd.boukhers@uni-siegen.de; kimiaki.shirahama@uni-siegen.de;
   marcin.grzegorzek@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021; Boukhers, Zeyd/HZL-0733-2023
OI Boukhers, Zeyd/0000-0001-9778-9164; Grzegorzek,
   Marcin/0000-0003-4877-8287
CR [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.248
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], MONOCULAR MULTIVIEW
   [Anonymous], MULTIPLE TARGET TRAC
   [Anonymous], CORR
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Boukhers Z, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P83, DOI 10.1145/2671188.2749331
   Buczko M, 2016, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2016.7535429
   Cao LJ, 2015, SIGNAL PROCESS, V112, P154, DOI 10.1016/j.sigpro.2014.08.041
   Cvii I., 2015, 2015 European Conference on Mobile Robots (ECMR), P1
   Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183
   Ess A., 2008, IEEE Conf. on Computer Vision and Pattern Recognition, P1
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   García J, 2013, IEEE T SYST MAN CY-S, V43, P606, DOI 10.1109/TSMCA.2012.2220540
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Grigorescu SM, 2011, ROBOT AUTON SYST, V59, P899, DOI 10.1016/j.robot.2011.07.005
   Gutiérrez-Gómez D, 2015, IEEE INT CONF ROBOT, P83, DOI 10.1109/ICRA.2015.7138984
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Jafari OH, 2014, IEEE INT CONF ROBOT, P5636, DOI 10.1109/ICRA.2014.6907688
   Jaimez M, 2015, IEEE T ROBOT, V31, P809, DOI 10.1109/TRO.2015.2428512
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Karsch K., 2016, dense image correspondences for computer vision, P173
   Kerl C, 2015, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2015.261
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Liu R., 2008, IEEE C COMPUTER VISI, P1
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Micusík B, 2003, PROC CVPR IEEE, P485
   Mirabdollah M. Hossein, 2014, Pattern Recognition. 36th German Conference, GCPR 2014. Proceedings: LNCS 8753, P547, DOI 10.1007/978-3-319-11752-2_45
   Mirabdollah MH, 2015, LECT NOTES COMPUT SC, V9358, P297, DOI 10.1007/978-3-319-24947-6_24
   Morais E, 2014, PATTERN RECOGN LETT, V39, P21, DOI 10.1016/j.patrec.2013.09.007
   Nardi L, 2015, IEEE INT CONF ROBOT, P5783, DOI 10.1109/ICRA.2015.7140009
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Persson M, 2015, IEEE INT VEH SYM, P686, DOI 10.1109/IVS.2015.7225764
   Saisan P., 2005, CVPR Workshops 2005, P18
   Salas-Moreno RF, 2014, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2014.6948422
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Song SY, 2014, PROC CVPR IEEE, P1566, DOI 10.1109/CVPR.2014.203
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Wojek C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1993, DOI 10.1109/CVPR.2011.5995547
   Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486
   Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P265, DOI 10.1109/TMM.2015.2390044
   Zhou QY, 2015, PROC CVPR IEEE, P632, DOI 10.1109/CVPR.2015.7298662
NR 53
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16199
EP 16222
DI 10.1007/s11042-017-5195-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300010
DA 2024-07-18
ER

PT J
AU Fedila, M
   Bengherabi, M
   Amrouche, A
AF Fedila, M.
   Bengherabi, M.
   Amrouche, A.
TI Gammatone filterbank and symbiotic combination of amplitude and
   phase-based spectra for robust speaker verification under noisy
   conditions and compression artifacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gammatone filter-bank; Group-delay; Automatic speaker verification;
   GMM-UBM; G722.2
ID GROUP DELAY FEATURE; RECOGNITION
AB The main novelty of this work resides in incorporating a Gammatone filter-bank as a substitute of the Mel filter-bank in the extraction pipeline of the Product Spectrum PS. The proposed feature is dubbed the Gammatone Product-Spectrum Cepstral coefficients GPSCC. Experimental results are undertaken on TIMIT and noisy TIMIT corpora using the Gaussian Mixture Model with Universal Background Model (GMM-UBM) recognition algorithm. Performance evaluations indicate that GPSCC shows a drastic reduction in Equal Error Rates compared to other related features and this gain in performance is more pronounced at low signal to noise ratios. Also, our study demonstrates the merit of the Gammatone filter-bank in improving robustness to codec-degraded speech at different bit rates. Furthermore, the proposed GPSCC feature achieves the best verification performance under aggressive compression. Interestingly, at 6.60 kbps we observe that GPSCC achieves an absolute error reduction of 12% compared to the Mel Frequency Cepstral Coefficients (MFCC).
C1 [Fedila, M.; Amrouche, A.] USTHB, Fac Elect & Comp Sci, Algiers, Algeria.
   [Fedila, M.; Bengherabi, M.] Ctr Dev Technol Avancees, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Bengherabi, M (corresponding author), Ctr Dev Technol Avancees, Algiers, Algeria.
EM fedila_m@yahoo.fr; mbengherabi@cdta.dz
RI bengherabi, messaoud/AAZ-2734-2020
OI bengherabi, messaoud/0000-0001-8679-2093
CR Alsteris LD, 2007, DIGIT SIGNAL PROCESS, V17, P578, DOI 10.1016/j.dsp.2006.06.007
   [Anonymous], 2010, Int J Emerg Technol
   [Anonymous], 2004 IEEE INT C AC S
   [Anonymous], 2013, Msr identity toolbox
   Asbai N, 2015, INT J SPEECH TECHNOL, V18, P195, DOI 10.1007/s10772-014-9260-6
   Boulkenafet Z, 2013, 2013 INT C BIOSIG SP, P241
   Brümmer N, 2007, IEEE T AUDIO SPEECH, V15, P2072, DOI 10.1109/TASL.2007.902870
   Brummer N., FOCAL TOOLS FUSION C
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dimitriadis D, 2011, IEEE T AUDIO SPEECH, V19, P1504, DOI 10.1109/TASL.2010.2092766
   Fedila M., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1034, DOI 10.1109/ISSPA.2012.6310441
   Fedila M, 2015, INT CONF INTELL SYST, P347, DOI 10.1109/ISDA.2015.7489252
   Fernandez Gallardo L., 2016, HUMAN AUTOMATIC SPEA
   Gallardo L.F., 2014, SPEECH COMMUN, P1
   Gallardo LF, 2014, INTERSPEECH, P1115
   Gerkmann T, 2015, IEEE SIGNAL PROC MAG, V32, P55, DOI 10.1109/MSP.2014.2369251
   Gold B, 2011, AUDITORY SYSTEM FILT
   Hegde RM, 2007, IEEE T AUDIO SPEECH, V15, P190, DOI 10.1109/TASL.2006.876858
   Ireland D, 2015, BIOENGINEERING BIOTE, V3
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Kinnunen T, 2013, INT CONF ACOUST SPEE, P7229, DOI 10.1109/ICASSP.2013.6639066
   Kinnunen T, 2012, IEEE T AUDIO SPEECH, V20, P1990, DOI 10.1109/TASL.2012.2191960
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Li Z, 2015, MULTIMED TOOLS APPL, V75, P1
   Linguistic Data Consortium, 1990, CD111 NIST LING DAT
   Madikeri SR, 2015, INT J SPEECH TECHNOL, V18, P17, DOI 10.1007/s10772-014-9243-7
   Martin A., 1997, P EUR 97 RHOD GREEC, P1895
   McLaren M., 2013, P INTERSPEECH, P3698
   Meriem F, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P99, DOI 10.1109/SITIS.2014.111
   Mowlaee P, 2016, SPEECH COMMUN, V81, P1, DOI 10.1016/j.specom.2016.04.002
   Paliwal K. K., 2003, P 8 EUR C SPEECH COM
   Rajan P, 2013, INTERSPEECH, P2488
   Recommendation G, 2003, 722 2 WID COD SPEECH
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sebastian J, 2016, SPEECH COMMUN, V81, P42, DOI 10.1016/j.specom.2015.12.008
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vijayan K, 2016, SPEECH COMMUN, V81, P54, DOI 10.1016/j.specom.2016.02.005
   Xinhui Zhou, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P559, DOI 10.1109/ASRU.2011.6163888
   Ying L, 2006, PHASE UNWRAPPING WIL
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
NR 42
TC 7
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16721
EP 16739
DI 10.1007/s11042-017-5237-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300033
DA 2024-07-18
ER

PT J
AU Fernandez-Beltran, R
   Pla, F
AF Fernandez-Beltran, Ruben
   Pla, Filiberto
TI Prior-based probabilistic latent semantic analysis for multimedia
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information reduction; Topic models; Probabilistic latent semantic
   analysis; Content-based multimedia retrieval
ID BIG DATA; SCALE
AB Topic models have shown to be one of the most effective tools in Content-Based Multimedia Retrieval (CBMR). However, the high computational learning cost together with the huge expansion of multimedia collections limit the scalability of topic-based CBMR systems in real-life multimedia applications. The present work pursues a twofold objective. On the one hand, to study the effect of using clustering-based document reduction schemes over standard topic models pLSA (probabilistic Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation). On the other hand, to develop a pLSA-based extension oriented to integrate this reduction scheme within the own model in order to improve the CBMR effectiveness. The experimental part of the work includes three different multimedia databases, three ranking functions, four retrieval scenarios, three different numbers of topics and ten document reduction levels. Experiments revealed that standard topic models are highly sensitive to the document reduction level whereas the proposed model is able to provide a competitive advantage within the content-based retrieval field.
C1 [Fernandez-Beltran, Ruben; Pla, Filiberto] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12071, Spain.
C3 Universitat Jaume I
RP Fernandez-Beltran, R (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12071, Spain.
EM rufernan@uji.es
RI Fernandez-Beltran, Ruben/GLT-5907-2022; Fdz, Ruben/ABH-6669-2020; Pla,
   Filiberto/AAD-1208-2022
OI Fernandez-Beltran, Ruben/0000-0003-1374-8416; Pla,
   Filiberto/0000-0003-0054-3489
FU Spanish Ministry of Economy [ESP2013-48458-C4-3-P,
   ESP2016-79503-C2-2-P]; Generalitat Valenciana [PROMETEO-II/2014/062];
   Universitat Jaume I [P11B2014-09]
FX This work was supported by the Spanish Ministry of Economy under the
   projects ESP2013-48458-C4-3-P and ESP2016-79503-C2-2-P, by Generalitat
   Valenciana through project PROMETEO-II/2014/062, and by Universitat
   Jaume I through project P11B2014-09.
CR APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2006, ACM INT C MACH LEARN
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   ChengXiang Zhai, 2008, Foundations and Trends in Information Retrieval, V2, P137, DOI 10.1561/1500000008
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fahad A, 2014, IEEE T EMERG TOP COM, V2, P267, DOI 10.1109/TETC.2014.2330519
   Feng D, 2010, MULTIMEDIA INFORM RE
   Fernandez-Beltran R, 2016, PATTERN RECOGN, V51, P72, DOI 10.1016/j.patcog.2015.09.007
   Fernandez-Beltran R, 2015, IMAGE VISION COMPUT, V38, P1, DOI 10.1016/j.imavis.2015.02.003
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hu PF, 2014, PATTERN RECOGN, V47, P1138, DOI 10.1016/j.patcog.2013.06.010
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jiang YG, 2011, ACM INT C MULT RET
   Kakkonen T, 2008, EDUC TECHNOL SOC, V11, P275
   Khoat Than, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P490, DOI 10.1007/978-3-642-33460-3_37
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li AQ, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P891, DOI 10.1145/2623330.2623756
   Lienhart R, 2009, ACM INT C MULT RETR
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Rui YRY, 1997, RELEVANCE FEEDBACK A
   Saxena A, 2017, NEUROCOMPUTING, V267, P664, DOI 10.1016/j.neucom.2017.06.053
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sontag David, 2011, Advances in Neural Information Processing Systems, P1008
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Yi X, 2009, EUR C IR RES ADV INF
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   Zeng JB, 2015, MULTIMED TOOLS APPL, V74, P7859, DOI 10.1007/s11042-014-2029-8
   Zhou XH, 2007, IEEE T KNOWL DATA EN, V19, P1276, DOI 10.1109/TKDE.2007.1058
NR 40
TC 10
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16771
EP 16793
DI 10.1007/s11042-017-5247-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300035
DA 2024-07-18
ER

PT J
AU Li, HF
   Hu, L
   Chu, JF
   Chi, L
   Li, HT
AF Li, Huifeng
   Hu, Liang
   Chu, Jianfeng
   Chi, Ling
   Li, Hongtu
TI The maximum matching degree sifting algorithm for steganography
   pretreatment applied to IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things(IoT), image steganography; Carrier sifting; Embedding
   efficiency; Security
ID IMAGE; SECURITY; LOCATION; PRIVACY; SYSTEM
AB Similar to the Internet, the IoT also faces numerous information security issues. Because the multimedia sensors that form Wireless Multimedia Sensor Networks (WMSNs) inherently operate with large amounts of data with high redundancy, steganography appears to be a better way to ensure the security of information in this medium than does cryptography. Considering that computing power and energy resources are often limited in the IoT, it is more effective and feasible to use steganography to obtain the outcomes that people expect, including better concealment and security. Currently, some advanced steganalysis techniques can reliably detect embedded secret messages, To defend against such steganalysis techniques, most scholars in this field have focused on developing or improving advanced embedding algorithms. However, in this article, choosing a suitable carrier is also considered to be a good approach to improve resistance. Thus, this paper proposes the Maximum Matching Degree(MMD) sifting algorithm, which is based on the principle of "minimizing the effect of embedding" (here, we measure the effect of embedding by the number of modified bits) and can be applied to choose the best carrier by minimizing the number of bits that will be modified during embedding. This approach can be regarded as a steganography pretreatment. Moreover, it is easy to implement, which is also important in IoT situations. Using greyscale-images as carriers, we conducted experiments. The results demonstrated that the pretreatment method not only improves embedding efficiency and steganalysis resistance (to some common steganalysis techniques) but is also extremely versatile. This result has significant implications for steganography and broad implementation prospects.
C1 [Li, Huifeng; Hu, Liang; Chu, Jianfeng; Chi, Ling; Li, Hongtu] Jilin Univ, Qianjin St 2699, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University
RP Li, HT (corresponding author), Jilin Univ, Qianjin St 2699, Changchun 130012, Jilin, Peoples R China.
EM lihongtu@jlu.edu.cn
FU European Seventh Framework Program (FP7) [GA-2011-295222]; National
   Natural Science Foundation of China [61073009]; National Sci-Tech
   Support Plan of China [2014BAH02F03, 2014BAH02F00]; National Key RD Plan
   of China [2017YFA0604500]; Youth Science Foundation of Jilin Province of
   China [20160520011JH]; Youth Sci-Tech Innovation Leader and Team Project
   of Jilin Province of China [20170519017JH]
FX This work is funded by: European Seventh Framework Program (FP7) under
   Grant No. GA-2011-295222, and by National Natural Science Foundation of
   China under Grant No. 61073009, and by National Sci-Tech Support Plan of
   China under Grant No. 2014BAH02F03, and by National Key R&D Plan of
   China under Grant No. 2017YFA0604500, National Sci-Tech Support Plan of
   China under Grant No. 2014BAH02F00, and by Youth Science Foundation of
   Jilin Province of China under Grant No. 20160520011JH, and by Youth
   Sci-Tech Innovation Leader and Team Project of Jilin Province of China
   under GrantNo. 20170519017JH.
CR Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   [Anonymous], STEGANOGRAPHY DIGITA
   [Anonymous], JPEG STILL IMAGE DAT
   [Anonymous], 2016, IEEE T BIG DATA
   Atamli AW, 2014, 2014 INTERNATIONAL WORKSHOP ON SECURE INTERNET OF THINGS (SIOT), P35, DOI 10.1109/SIoT.2014.10
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Aydogdu I, 2015, INT J COMPUT MATH, V92, P1806, DOI 10.1080/00207160.2013.859854
   Bairagi AK, 2016, INF SECUR J, V25, P197, DOI 10.1080/19393555.2016.1206640
   Bhattasali T., 2013, LICRYPT LIGHTWEIGHT, P26
   Chang V, 2016, FUTURE GENER COMP SY, V57, P24, DOI 10.1016/j.future.2015.09.031
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gul G, 2010, IEEE T INF FOREN SEC, V5, P349, DOI 10.1109/TIFS.2010.2041826
   Harjito Bambang, 2010, 2010 4th IEEE International Conference on Digital Ecosystems and Technologies (DEST 2010), P640, DOI 10.1109/DEST.2010.5610580
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Huang Y., 2014, Proceedings of the 3rd International Symposium on Next-Generation Electronics, P1
   Jaheel HL, 2015, INT J SMART SENS INT, V8, P90
   Jiang N, 2015, INT J THEOR PHYS, V54, P1021, DOI 10.1007/s10773-014-2294-3
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Katagi M., 2008, Lightweight cryptography for the Internet of Things, P7
   Kim SR, 2018, J SUPERCOMPUT, V74, P4261, DOI 10.1007/s11227-016-1848-y
   Liu JF, 2015, DIGIT SIGNAL PROCESS, V38, P66, DOI 10.1016/j.dsp.2014.12.004
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Roman R, 2013, COMPUT NETW, V57, P2266, DOI 10.1016/j.comnet.2012.12.018
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Siwei Lyu, 2002, Information Hiding. 5th International Workshop, IH 2002. Revised Papers (Lecture Notes in Computer Science Vol.2578), P340
   Sun G, 2017, J NETW COMPUT APPL, V86, P34, DOI 10.1016/j.jnca.2016.11.024
   Tiwari N., 2010, International Journal of Computer Applications, V6, P1
   Touati L, 2014, 2014 International Conference on Advanced Networking Distributed Systems and Applications (INDS 2014), P64, DOI 10.1109/INDS.2014.19
   Turner Claude, 2009, 2009 International Conference on Innovations in Information Technology (IIT), P258, DOI 10.1109/IIT.2009.5413637
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   Wang ZW, 2017, J COMPUT SYST SCI, V89, P41, DOI 10.1016/j.jcss.2016.12.006
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yin JHJ, 2015, I C ARTIF INTELL, P310, DOI 10.1109/AIMS.2015.56
   Zeng Bohan, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1454, DOI 10.1109/GreenCom-iThings-CPSCom.2013.256
NR 40
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18203
EP 18221
DI 10.1007/s11042-017-5075-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900035
DA 2024-07-18
ER

PT J
AU Noura, H
   Chehab, A
   Sleem, L
   Noura, M
   Couturier, R
   Mansour, MM
AF Noura, Hassan
   Chehab, Ali
   Sleem, Lama
   Noura, Mohamad
   Couturier, Raphael
   Mansour, Mohammad M.
TI One round cipher algorithm for multimedia IoT devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Multimedia internet of things; Lightweight image
   encryption algorithm; Substitution; Permutation; Dynamic cryptographic
   primitives
ID IMAGE; AES; INTERNET; SCHEME; PERFORMANCE; CHAOS
AB With the exponential growth in Internet-of-Things (IoT) devices, security and privacy issues have emerged as critical challenges that can potentially compromise their successful deployment in many data-sensitive applications. Hence, there is a pressing need to address these challenges, given that IoT systems suffer from different limitations, and IoT devices are constrained in terms of energy and computational power, which renders them extremely vulnerable to attacks. Traditional cryptographic algorithms use a static structure that requires several rounds of computations, which leads to significant overhead in terms of execution time and computational resources. Moreover, the problem is compounded when dealing with multimedia contents, since the associated algorithms have stringent QoS requirements. In this paper, we propose a lightweight cipher algorithm based on a dynamic structure with a single round that consists of simple operations, and that targets multimedia IoT. In this algorithm, a dynamic key is generated and then used to build two robust substitution tables, a dynamic permutation table, and two pseudo-random matrices. This dynamic cipher structure minimizes the number of rounds to a single one, while maintaining a high level of randomness and security. Moreover, the proposed cipher scheme is flexible as the dimensions of the input matrix can be selected to match the devices' memory capacity. Extensive security tests demonstrated the robustness of the cipher against various kinds of attacks. The speed, simplicity and high-security level, in addition to low error propagation, make of this approach a good encryption candidate for multimedia IoT devices.
C1 [Noura, Hassan; Chehab, Ali; Mansour, Mohammad M.] Amer Univ Beirut, Dept Elect & Comp Engn, Beirut, Lebanon.
   [Sleem, Lama; Noura, Mohamad; Couturier, Raphael] UBFC, FEMTO ST Inst, Besancon, France.
C3 American University of Beirut; Universite de Franche-Comte; Centre
   National de la Recherche Scientifique (CNRS); Universite de Technologie
   de Belfort-Montbeliard (UTBM)
RP Couturier, R (corresponding author), UBFC, FEMTO ST Inst, Besancon, France.
EM hn49@aub.edu.lb; chehab@aub.edu.lb; lama.sleem@univ-fcomte.fr;
   mohamad.noura@univ-fcomte.fr; raphael.couturier@univ-fcomte.fr;
   mm14@aub.edu.lb
RI Mansour, Mohammad M/D-2809-2018; Noura, Hassan/U-8729-2018; Chehab,
   Ali/B-9392-2018; Couturier, Raphaël/C-1095-2013
OI Chehab, Ali/0000-0002-1939-2740; Couturier, Raphaël/0000-0003-1490-9592
FU Semaan Faculty of Engineering and Architecture at the American
   University of Beirut; Labex ACTION program [ANR-11-LABX-01-01]
FX This paper is partially supported with funds from the Semaan Faculty of
   Engineering and Architecture at the American University of Beirut and
   also from the Labex ACTION program (contract ANR-11-LABX-01-01).
CR ADAMS C, 1990, LECT NOTES COMPUT SC, V435, P612
   Adrianto D, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P777, DOI 10.1109/WF-IoT.2015.7389152
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   Amin R, 2017, MULTIMED TOOLS APPL, P1
   [Anonymous], 2016, RFID SECURITY LIGHTW
   [Anonymous], ARXIV170108371 CORR
   [Anonymous], NEW SUBSTITUTION PER
   [Anonymous], CLUSTER EUROPEAN RES
   [Anonymous], 2017, NISTIR8114
   [Anonymous], RC4 ENCRYPTION ALGOR
   [Anonymous], DIRECTOR NIST SPECIA
   [Anonymous], 2014, IACR CRYPTOLOGY EPRI
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2013, PROC INT S SECURITY
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, INT C CRYPT INF SEC
   [Anonymous], 2015, IACR CRYPTOLOGY EPRI
   [Anonymous], ARXIV09110482 CORR
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bernstein DJ, 2015, LECT NOTES COMPUT SC, V8895, P64, DOI 10.1007/978-3-319-16295-9_4
   Borghoff J, 2012, LECT NOTES COMPUT SC, V7658, P208, DOI 10.1007/978-3-642-34961-4_14
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Chandrasekaran V, 2017, MATH PROGRAM, V161, P1, DOI 10.1007/s10107-016-0998-2
   Cho JS, 2011, COMPUT COMMUN, V34, P391, DOI 10.1016/j.comcom.2010.02.029
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Evans-Pughe C, 2003, IEE REVIEW, V49, P28, DOI 10.1049/ir:20030303
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Gamal T.E., 1984, P WORKSH THEOR APPL, V196, P10, DOI DOI 10.1007/3-540-39568-7_2
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Granjal J, 2015, IEEE COMMUN SURV TUT, V17, P1294, DOI 10.1109/COMST.2015.2388550
   Gueron S, 2009, LECT NOTES COMPUT SC, V5665, P51, DOI 10.1007/978-3-642-03317-9_4
   Guo J, 2011, LECT NOTES COMPUT SC, V6917, P326, DOI 10.1007/978-3-642-23951-9_22
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jara AJ, 2013, IEEE J SEL AREA COMM, V31, P47, DOI 10.1109/JSAC.2013.SUP.0513005
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Moradi A, 2011, LECT NOTES COMPUT SC, V6632, P69, DOI 10.1007/978-3-642-20465-4_6
   Nithya R, 2016, PROC TECH, V25, P302, DOI 10.1016/j.protcy.2016.08.111
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   NYBERG K, 1995, J CRYPTOL, V8, P27, DOI 10.1007/BF00204800
   O'Melia S, 2010, IEEE T VLSI SYST, V18, P1505, DOI 10.1109/TVLSI.2009.2025171
   Osvik DA, 2010, LECT NOTES COMPUT SC, V6147, P75, DOI 10.1007/978-3-642-13858-4_5
   Paar C., 2009, UNDERSTANDING CRYPTO
   Raza S., 2009, Emerging Technologies Factory Automation (ETFA), P1
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Shibutani K, 2011, LECT NOTES COMPUT SC, V6917, P342, DOI 10.1007/978-3-642-23951-9_23
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Suzaki T., 2013, P INT C SEL ARE CRYP, V7707, P339
   Tillich S, 2006, LECT NOTES COMPUT SC, V4249, P270
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu WL, 2011, LECT NOTES COMPUT SC, V6715, P327, DOI 10.1007/978-3-642-21554-4_19
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang P., 2010, The 29th IEEE Conference on Computer Communications (INFOCOM 2010), P1
NR 59
TC 63
Z9 64
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18383
EP 18413
DI 10.1007/s11042-018-5660-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900042
DA 2024-07-18
ER

PT J
AU Rad, R
   Jamzad, M
AF Rad, Roya
   Jamzad, Mansour
TI A multi-view-group non-negative matrix factorization approach for
   automatic image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic imageannotation; AIA; Nonnegativematrixfactorization; NMF;
   Multi-view-group; Multi-label classification
ID SEPARATION; PARTS; MODEL
AB In automatic image annotation (AIA) different features describe images from different aspects or views. Part of information embedded in some views is common for all views, while other parts are individual and specific. In this paper, we present the Mvg-NMF approach, a multi-view-group non-negative matrix factorization (NMF) method for an AIA system which considers both common and individual factors. The NMF framework discovers a latent space by decomposing data into a set of non-negative basis vectors and coefficients. The views divided into homogeneous groups and latent spaces are extracted for each group. After mapping the test images into these spaces, a unified distance matrix is computed from the distance between images in all spaces. Then a search-based method is used to propagate tags from the nearest neighbors to test images. The evaluation on three datasets commonly used for image annotation showed that the Mvg-NMF is highly competitive with the recent state-of-the-art works.
C1 [Rad, Roya; Jamzad, Mansour] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Rad, R (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM raad@ce.sharif.edu; jamzad@sharif.edu
RI rad, roya/AAN-4434-2021
CR [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   Ballan L., 2014, P INT C MULTIMEDIA R, P73
   BenAbdallah Jaafar, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P128, DOI 10.1109/WI-IAT.2010.293
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Caicedo J C, 2012, P 2 ACM INT C MULT R, P1
   Caicedo JC, 2012, NEUROCOMPUTING, V76, P50, DOI 10.1016/j.neucom.2011.04.037
   Chen A., 2013, ICML, P1274
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Driesen J., 2012, THESIS
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Eweiwi A, 2013, LECT NOTES COMPUT SC, V8142, P61, DOI 10.1007/978-3-642-40602-7_7
   Grubinger M., 2007, ANAL EVALUATION VISU
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   Guan XH, 2009, J NETW COMPUT APPL, V32, P31, DOI 10.1016/j.jnca.2008.04.006
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Huang KJ, 2014, IEEE T SIGNAL PROCES, V62, P211, DOI 10.1109/TSP.2013.2285514
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Ke X, 2016, MULTIMED TOOLS APPL, V75, P12477, DOI 10.1007/s11042-014-2318-2
   Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lin C, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/239589
   Lin ZJ, 2015, MULTIMED TOOLS APPL, V74, P4091, DOI 10.1007/s11042-013-1811-3
   Liu J., 2013, P 2013 SIAM INT C DA, P252, DOI DOI 10.1137/1.9781611972832.28
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long XZ, 2014, MULTIMED TOOLS APPL, V72, P2679, DOI 10.1007/s11042-013-1572-z
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Mirzaei S, 2015, SIGNAL PROCESS, V115, P27, DOI 10.1016/j.sigpro.2015.03.006
   Moran S, 2014, INT J MULTIMED INF R, V3, P209, DOI 10.1007/s13735-014-0063-y
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Prajapati SJ, 2015, BRAIN, V4, P600
   Rad R, 2017, J VIS COMMUN IMAGE R, V46, P1, DOI 10.1016/j.jvcir.2017.03.005
   Rad R, 2015, IET COMPUT VIS, V9, P806, DOI 10.1049/iet-cvi.2014.0413
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wang D, 2013, SIGNAL PROCESS, V93, P1608, DOI 10.1016/j.sigpro.2012.07.015
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Xu C., 2013, Neural Computing and Applications, V23, P2031, DOI DOI 10.1007/S00521-013-1362-6
   Xu HJ, 2016, MULTIMED TOOLS APPL, V75, P6237, DOI 10.1007/s11042-015-2568-7
   Yang Y, 2015, J VIS COMMUN IMAGE R, V33, P368, DOI 10.1016/j.jvcir.2015.10.006
   Zar J.H., 1998, Encyclopedia of Biostatistics, V5, P4191
NR 45
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17109
EP 17129
DI 10.1007/s11042-017-5279-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300050
DA 2024-07-18
ER

PT J
AU Wang, T
   Qiao, MN
   Zhu, AC
   Niu, YD
   Li, C
   Snoussi, HC
AF Wang, Tian
   Qiao, Meina
   Zhu, Aichun
   Niu, Yida
   Li, Ce
   Snoussi, Hichem
TI Abnormal event detection via covariance matrix for optical flow based
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global abnormal event; Local abnormal event; Multi-RoI; Covariance
   matrix; Optical flow
ID ANOMALY DETECTION; LOCALIZATION; GRADIENTS; SUPPORT
AB Abnormal event detection is one of the most important objectives in security surveillance for public scenes. In this paper, a new high-performance algorithm based on spatio-temporal motion information is proposed to detect global abnormal events from the video stream as well as the local abnormal event. We firstly propose a feature descriptor to represent the movement by adopting the covariance matrix coding optical flow and the corresponding partial derivatives of multiple connective frames or the patches of the frames. The covariance matrix of multi-RoI (region of interest) which consists of frames or patches can represent the movement in high accuracy. For public surveillance video, the normal samples are abundant while there are few abnormal samples. Thus the one-class classification method is suitable for handling this problem inherently. The nonlinear one-class support vector machine based on a proposed kernel for Lie group element is applied to detect abnormal events by merely training the normal samples. The computational complexity and time performance of the proposed method is analyzed. The PETS, UMN and UCSD benchmark datasets are employed to verify the advantages of the proposed method for both global abnormal and local abnormal event detection. This method can be used for event detection for a surveillance video and outperforms the state-of-the-art algorithms. Thus it can be adopted to detect the abnormal event in the monitoring video.
C1 [Wang, Tian; Qiao, Meina; Niu, Yida] Beihang Univ, Sch Automat Sci & Elect Engn, Beihang, Peoples R China.
   [Zhu, Aichun] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Li, Ce] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou, Gansu, Peoples R China.
   [Snoussi, Hichem] Univ Technol Troyes, Inst Charles Delaunay, LM2S, UMR STMR 6279,CNRS, Troyes, France.
C3 Beihang University; Nanjing Tech University; Lanzhou University of
   Technology; Centre National de la Recherche Scientifique (CNRS);
   Universite de Technologie de Troyes
RP Zhu, AC (corresponding author), Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM wangtian@buaa.edu.cn; meinaqiao@buaa.edu.cn; aichun.zhu@njtech.edu.cn;
   2014niuyida@buaa.edu.cn; xjtulice@gmail.com; hichem.snoussi@utt.fr
RI Wang, Tianyi/A-1441-2016
FU National Natural Science Foundation of China [61503017, U1435220,
   61365003]; Aeronautical Science Foundation of China [2016ZC51022]; Gansu
   Province Basic Research Innovation Group Project [1506RJIA031];
   Fundamental Research Funds for the Central Universities
   [YWF-14-RSC-102]; ANR AutoFerm project; Platform CAPSEC - Region
   Champagne-Ardenne; FEDER
FX This work is partially supported by the National Natural Science
   Foundation of China (61503017, U1435220, 61365003), the Aeronautical
   Science Foundation of China (2016ZC51022), Gansu Province Basic Research
   Innovation Group Project (1506RJIA031), the Fundamental Research Funds
   for the Central Universities (YWF-14-RSC-102), the ANR AutoFerm project
   and the Platform CAPSEC funded by Region Champagne-Ardenne and FEDER.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P BR MACH VIS
   [Anonymous], 2003, LIE GROUPS LIE ALGEB
   [Anonymous], 1999, IEEE COMP SOC C COMP
   [Anonymous], 2010, UCSD AN DET DAT
   [Anonymous], AS C COMP VIS ACCV
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   [Anonymous], PERF EV TRACK SURV P
   [Anonymous], 2006, Unusual crowd activity dataset of university of minnesota
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV150502921
   [Anonymous], DEEP LEARNING FACE R
   Benezeth Y, 2011, PATTERN RECOGN LETT, V32, P423, DOI 10.1016/j.patrec.2010.10.008
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Burton A., 1978, THINKING PERSPECTIVE
   Canu S., 2005, Perception Systmes et Information
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cricri F, 2014, IEEE T MULTIMEDIA, V16, P917, DOI 10.1109/TMM.2014.2307552
   Cui P, 2012, IEEE T MULTIMEDIA, V14, P102, DOI 10.1109/TMM.2011.2176110
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ergezer H, 2016, LECT NOTES COMPUT SC, V9914, P728, DOI 10.1007/978-3-319-48881-3_51
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Harandi M, 2014, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2014.132
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hussein, 2013, INT JOINT C ART INT
   Jiménez-Hernández H, 2010, SENSORS-BASEL, V10, P7576, DOI 10.3390/s100807576
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kosmopoulos D, 2010, IEEE SIGNAL PROC MAG, V27, P34, DOI 10.1109/MSP.2010.937392
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu Y, 2016, IEEE T MULTIMEDIA, V18, P351, DOI 10.1109/TMM.2016.2514848
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mazloom M, 2016, IEEE T MULTIMEDIA, V18, P1378, DOI 10.1109/TMM.2016.2559947
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Orozco J, 2015, IMAGE VISION COMPUT, V42, P47, DOI 10.1016/j.imavis.2015.07.002
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Porikli Fatih., 2005, Proceedings of the third ACM international workshop on Video surveillance sensor networks, VSSN '05, P55, DOI DOI 10.1145/1099396.1099407
   Rosani A, 2015, IEEE T MULTIMEDIA, V17, P1359, DOI 10.1109/TMM.2015.2441003
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Utasi A, 2010, OPT ENG, V49, DOI 10.1117/1.3280284
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Wang F, 2014, IEEE T MULTIMEDIA, V16, P1303, DOI 10.1109/TMM.2014.2315780
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang T, 2013, SENSORS-BASEL, V13, P17130, DOI 10.3390/s131217130
   Warren DavidH., 2013, ELECT SPATIAL SENSIN, V99
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yinghuan Shi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3653, DOI 10.1109/ICPR.2010.891
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang XF, 2016, MULTIMED TOOLS APPL, V75, P8799, DOI 10.1007/s11042-015-3101-8
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 61
TC 33
Z9 33
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17375
EP 17395
DI 10.1007/s11042-017-5309-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300062
DA 2024-07-18
ER

PT J
AU Yin, ZX
   Niu, XJ
   Zhang, XP
   Tang, J
   Luo, B
AF Yin, Zhaoxia
   Niu, Xuejing
   Zhang, Xinpeng
   Tang, Jin
   Luo, Bin
TI Reversible data hiding in encrypted AMBTC images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal processing in encrypted domain (SPED); Privacy protection;
   Absolute moment block truncation coding (AMBTC); Reversible data hiding
   in encrypted images (RDH-EI)
AB Signal processing in the encrypted domain has attracted a lot of attention due to the requirement for content security and privacy protection. Reversible data hiding in encrypted images (RDH-EI) is also a hot topic. However, the majority of the published techniques are designed for uncompressed images rather than JPEG-, VQ- and BTC-compressed images. In this paper, for the first time, a RDH-EI method for AMBTC images is proposed. In the proposed method, the higher mean and lower mean of a triple in an AMBTC-compressed image are encrypted by using stream cipher at first. Then, additional data can be embedded into the redundant space by using prediction error histogram modification technique. Experimental results and analysis demonstrate that, with the marked cipher-image, legal receivers are able to extract embedded data exactly by using a data hiding key, decrypt it to recover an image very similar to the original one by using an image encryption key, or extract additional data and recover the original image error free with both keys. The proposed method is applicable to real-time transmission due to the simple implementation of the algorithm and low computational complexity.
C1 [Yin, Zhaoxia; Niu, Xuejing; Tang, Jin; Luo, Bin] Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Anhui, Peoples R China.
   [Yin, Zhaoxia; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 Anhui University; Shanghai University
RP Luo, B (corresponding author), Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Anhui, Peoples R China.
EM luobin_ahu@163.com
RI lu, bin/HPE-4790-2023; Yin, Zhaoxia/HRD-7425-2023
OI Yin, Zhaoxia/0000-0003-0387-4806
FU National Natural Science Foundation of China [61502009, 61525203,
   61472235, U1636206]; China Postdoctoral Science Foundation [2016
   M591650]; Shanghai Municipal Education Commission and Shanghai Education
   Development Foundation; Anhui Provincial Natural Science Foundation
   [1508085SQF216]; Key Program for Excellent Young Talents in Colleges and
   Universities of Anhui Province [gxyqZD2016011]; Undergraduates Training
   Foundation of Anhui University [J10118511269]
FX This research work is partly supported by the National Natural Science
   Foundation of China (61502009, 61525203, 61472235, U1636206), China
   Postdoctoral Science Foundation (2016 M591650), "Shu Guang" project
   supported by Shanghai Municipal Education Commission and Shanghai
   Education Development Foundation, Anhui Provincial Natural Science
   Foundation (1508085SQF216), Key Program for Excellent Young Talents in
   Colleges and Universities of Anhui Province (gxyqZD2016011) and
   Undergraduates Training Foundation of Anhui University (J10118511269).
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Fu Z., 2016, 2016 UKACC 11 INT C, P1
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P831, DOI 10.1109/ChinaSIP.2015.7230521
   Puech W, 2008, P SOC PHOTO-OPT INS, P6819
   Qian Z., 2016, IEEE T DEPENDABLE SE
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang ZC, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.050501
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yin ZX, 2016, INT CONF ACOUST SPEE, P2129, DOI 10.1109/ICASSP.2016.7472053
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2010, IEEE SIGNAL PROC LET, V17, P635, DOI 10.1109/LSP.2010.2049415
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 33
TC 22
Z9 24
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18067
EP 18083
DI 10.1007/s11042-017-4957-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900027
DA 2024-07-18
ER

PT J
AU Im, J
   Choi, M
   Lee, J
   Kim, CH
AF Im, Jaeho
   Choi, MyungJin
   Lee, Jung
   Kim, Chang-Hun
TI An optimized real time algorithm for window frost formation suited to
   mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Window frost; Ice formation; Mobile device
ID SIMULATION
AB We propose a real time simulation for window frost formation on mobile devices that uses both particles and grids. Previous ice formation methods made heavy demands on both memory and computational capacity because they were designed for a desktop environment. In this paper, a frost skeleton grows around a location touched by the user using particles, and the ice surfaces are constructed using a grid. Using a nonlattice random-walk technique, the frost skeleton grows freely and naturally. A hash grid technique is used to search efficiently for neighbor particles during the crystallization process. Finally, some 2.5D details are added to the ice skeleton by adjusting the height of the grid vertices around the skeleton. Experiments show that our method creates realistic frost in real time. Our method can be used to express ice formation effects in touch-based mobile device applications such as weather forecasts or games.
C1 [Im, Jaeho; Choi, MyungJin; Kim, Chang-Hun] Korea Univ, 407B Woojung Bldg,Anam Dong 5o Ga, Seoul 136713, South Korea.
   [Lee, Jung] Hallym Univ, 1303 Engn Bldg,1 Hallymdaehak Gil, Chunchon 24252, Gangwondo, South Korea.
C3 Korea University; Hallym University
RP Kim, CH (corresponding author), Korea Univ, 407B Woojung Bldg,Anam Dong 5o Ga, Seoul 136713, South Korea.
EM jaeholim@korea.ac.kr; chkim@korea.ac.kr
OI Choi, MyungJin/0000-0002-0389-3911
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF), - Ministry of Education, Science, ICT and Future
   Planning [NRF-2017R1A2B2005380]; Institute for Information &
   Communications Technology Promotion (IITP) grant - Korea government
   (MSIP) [2016-0-00285]; Korea Creative Content Agency(KOCCA) grant -
   Korea government(MCST) [2015-0-00060]; Business for Cooperative R&D
   between Industry, Academy, and Research Institute - P Korea Small and
   Medium Business Administration [C0443008]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF), funded by the Ministry
   of Education, Science, ICT and Future Planning (NRF-2017R1A2B2005380)
   and Institute for Information & Communications Technology Promotion
   (IITP) grant funded by the Korea government (MSIP; 2016-0-00285, High
   performance computing [HPC] based rendering solution development) and
   Korea Creative Content Agency(KOCCA) grant funded by the Korea
   government(MCST) (2015-0-00060, Developing the technology of open
   composable content editors for realistic media) and Business for
   Cooperative R&D between Industry, Academy, and Research Institute funded
   P Korea Small and Medium Business Administration (Grant C0443008).
CR CARTE AE, 1961, P PHYS SOC LOND, V77, P757, DOI 10.1088/0370-1328/77/3/327
   Gagnon J, 2011, VISUAL COMPUT, V27, P451, DOI 10.1007/s00371-011-0584-9
   GRINSTEIN G, 1986, DIRECTIONS CONDENSED, V1
   Im J, 2013, COMPUT GRAPH FORUM, V32, P371, DOI 10.1111/cgf.12057
   Ishikawa T, 2013, ACM SIGGRAPH 2013 PO, DOI 10.1145/2503385.2503400
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Kamal K. Raiyan, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P527, DOI 10.1109/ICCITECHN.2008.4803058
   Kharitonsky D., 1993, Visual Computer, V10, P88, DOI 10.1007/BF01901945
   KIM T, 2004, P 2004 ACM SIGGRAPH, P305, DOI DOI 10.1145/1028523.1028564
   Kim T., 2006, Proc 2006 ACM SIGGRAPH/Eurographics Symp Comp Anim, P167
   Madrazo C., 2009, The Journal of the Society for Art and Science, V8, P35
   Maréchal N, 2010, COMPUT GRAPH FORUM, V29, P449, DOI 10.1111/j.1467-8659.2009.01614.x
   MEAKIN P, 1983, PHYS REV A, V27, P604, DOI 10.1103/PhysRevA.27.604
   Miao YB, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P17, DOI 10.1145/2817675.2817676
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nishino T., 2012, SIGGRAPH ASIA 2012 T
   Reynolds DT, 2015, VISUAL COMPUT, V31, P689, DOI 10.1007/s00371-014-0995-5
   Seipel S, 2007, PROCEEDINGS OF THE NINTH IASTED INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND IMAGING, P60
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stanton M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601196
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   von Festenberg N, 2011, COMPUT GRAPH FORUM, V30, P1837, DOI 10.1111/j.1467-8659.2011.01904.x
   WITTEN TA, 1981, PHYS REV LETT, V47, P1400, DOI 10.1103/PhysRevLett.47.1400
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 24
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11807
EP 11821
DI 10.1007/s11042-017-4819-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100009
DA 2024-07-18
ER

PT J
AU Li, ZD
   Zhang, QL
   Duan, XD
   Wang, CR
   Shi, Y
AF Li, Zedong
   Zhang, Qingling
   Duan, Xiaodong
   Wang, Cunrui
   Shi, Yu
TI New semantic descriptor construction for facial expression recognition
   based on axiomatic fuzzy set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic descriptor; Axiomatic fuzzy set; Expression features; Semantic
   interpretation
ID LOGIC OPERATIONS; REPRESENTATIONS; FRAMEWORK; TREE
AB In this paper, we propose a new semantic descriptor based on axiomatic fuzzy set (AFS) to describe facial expressions. The new descriptor has two advantages: The first one is that it does not depend on priori-knowledge, when one uses it to construct semantic concepts. According to the distribution of feature data, one can quickly establish semantic concepts using the fuzzy membership degree. The second one is that the descriptor can describe complex features by implementing operation on semantic concepts. The developed descriptor can provide variations and relations of expression features. Finally, we implement our method on FEI and CK+ database, and make semantic interpretations for various expressions. Meanwhile, the performance is evaluated with the state-of-the-art methods such as C4.5, Bayes, Decision Table, Cart and Reduced error pruning tree.
C1 [Li, Zedong; Zhang, Qingling; Wang, Cunrui] Northeastern Univ, Inst Syst Sci, Shenyang, Liaoning, Peoples R China.
   [Duan, Xiaodong; Wang, Cunrui; Shi, Yu] Dalian Minzu Univ, Dalian Key Lab Digital Technol Natl Culture, Dalian, Liaoning, Peoples R China.
C3 Northeastern University - China; Dalian Minzu University
RP Duan, XD (corresponding author), Dalian Minzu Univ, Dalian Key Lab Digital Technol Natl Culture, Dalian, Liaoning, Peoples R China.
EM minzudigital@dlnu.edu.cn
RI Zhang, Qing/IZQ-5273-2023; Zhang, Qing/HTT-5047-2023; cunrui,
   wang/AAO-3589-2021
FU Natural Science Foundation of China [61370146, 61672132]; Liaoning
   Science & Technology of Liaoning Province of China [2013405003]
FX This work is supported by Natural Science Foundation of China (No.
   61370146, 61672132) and Liaoning Science & Technology of Liaoning
   Province of China (No. 2013405003).
CR An GY, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/390328
   Chakraborty A, 2009, IEEE T SYST MAN CY A, V39, P726, DOI 10.1109/TSMCA.2009.2014645
   Cheng SC, 2007, EXPERT SYST APPL, V33, P86, DOI 10.1016/j.eswa.2006.04.019
   Chew SW, 2012, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2012.6247973
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   De Marsico M, 2010, IEEE T SYST MAN CY A, V40, P121, DOI 10.1109/TSMCA.2009.2033031
   Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004
   Ekman P, 1978, FACIAL ACTION CODING
   Elomaa T, 2001, J ARTIF INTELL RES, V15, P163, DOI 10.1613/jair.816
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Hühn JC, 2009, IEEE T FUZZY SYST, V17, P138, DOI 10.1109/TFUZZ.2008.2005490
   Huysmans J, 2011, DECIS SUPPORT SYST, V51, P141, DOI 10.1016/j.dss.2010.12.003
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Lee SH, 2016, IEEE T AFFECT COMPUT, V7, P389, DOI 10.1109/TAFFC.2015.2496320
   Lee TS, 2006, COMPUT STAT DATA AN, V50, P1113, DOI 10.1016/j.csda.2004.11.006
   Li QL, 2016, PATTERN RECOGN, V60, P531, DOI 10.1016/j.patcog.2016.06.011
   Liang HR, 2016, IEEE T CYBERNETICS, V46, P890, DOI 10.1109/TCYB.2015.2417211
   Liu X, 2009, STUD FUZZ SOFT COMP, V244, P1, DOI 10.1007/978-3-642-00402-5
   Liu XD, 2005, IEEE T SYST MAN CY B, V35, P1013, DOI 10.1109/TSMCB.2005.847747
   Liu XD, 1998, FUZZY SET SYST, V95, P179, DOI 10.1016/S0165-0114(96)00298-9
   Liu XD, 1998, J MATH ANAL APPL, V217, P459
   Liu XD, 2007, INFORM SCIENCES, V177, P1027, DOI 10.1016/j.ins.2006.07.012
   Liu XD, 2007, INFORM SCIENCES, V177, P1007, DOI 10.1016/j.ins.2006.07.011
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mohammadi MR, 2016, IEEE T CYBERNETICS, V46, P817, DOI 10.1109/TCYB.2015.2416317
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Ramoni M, 2001, ARTIF INTELL, V125, P209, DOI 10.1016/S0004-3702(00)00085-0
   Ren Y, 2016, NEUROCOMPUTING, V171, P1462, DOI 10.1016/j.neucom.2015.07.096
   Rodríguez RM, 2013, INFORM SCIENCES, V241, P28, DOI 10.1016/j.ins.2013.04.006
   Sarkhel R, 2016, PATTERN RECOGN, V58, P172, DOI 10.1016/j.patcog.2016.04.010
   Siebers M, 2016, INFORM SCIENCES, V329, P866, DOI 10.1016/j.ins.2015.10.007
   Silva C, 2015, LECT NOTES ELECTR EN, V321, P365, DOI 10.1007/978-3-319-10380-8_35
   Tenorio E.Z., 2011, Proceedings of the X Simposio Brasileiro de Automacao Inteligente SBAI, P266
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang H, 2016, CHIN CONTR CONF, P3869, DOI 10.1109/ChiCC.2016.7553957
   Wang XC, 2014, APPL SOFT COMPUT, V24, P534, DOI 10.1016/j.asoc.2014.08.004
   Wang Z, 2016, NEUROCOMPUTING, V174, P756, DOI 10.1016/j.neucom.2015.09.083
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhang Z, 2015, KNOWL-BASED SYST, V84, P78, DOI 10.1016/j.knosys.2015.04.003
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao HT, 2008, IEEE T SYST MAN CY B, V38, P210, DOI 10.1109/TSMCB.2007.908870
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
NR 47
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11775
EP 11805
DI 10.1007/s11042-017-4818-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100008
DA 2024-07-18
ER

PT J
AU Yang, J
   Li, SB
AF Yang, Jie
   Li, Songbin
TI An efficient information hiding method based on motion vector space
   encoding for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Information hiding; Motion vector; Space encoding; Video coding
ID INTRA-PREDICTION MODES; VIDEO CODING HEVC; WATERMARKING; ALGORITHM
AB As the newest video coding standard, high efficiency video coding (HEVC) has great potential as a new information hiding carrier. This paper proposes an efficient information hiding method based on motion vector space encoding for HEVC encoding process. In this method, the mapping relationship between motion vector set and the points in the motion vector space is defined. The motion vector components from the N/2 prediction units (PUs) with smallest size in a coding tree unit (CTU) are selected as the secret information carriers. Each N secret bits are converted to a 2N + 1-ary number. By modifying at most one element in the set of N motion vector components, the mapping value of the set in the motion vector space can be equal to the 2N + 1-ary number. In this way, information hiding is realized. Since at most one element is changed and the N/2 PUs with smallest size are selected, this method contributes to excellent transparency of steganography and anti-steganalysis performance with high embedding efficiency. To the best of our knowledge, this is the first information hiding method based on motion vector for HEVC. Experimental results verify that the proposed method is practicable and has better performance than two typical embedding rules of information hiding based on motion vector.
C1 [Yang, Jie; Li, Songbin] Chinese Acad Sci, Inst Acoust, Beijing 100190, Peoples R China.
   [Yang, Jie; Li, Songbin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Li, SB (corresponding author), Chinese Acad Sci, Inst Acoust, Beijing 100190, Peoples R China.; Li, SB (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM yangjie13@mails.ucas.ac.cn; lisb@dsp.ac.cn
OI Yang, Jie/0000-0003-0503-6208
FU National Natural Science Foundation of China [U1636113]; Scientific
   Research Foundation Project of Haikou Laboratory, Institute of
   Acoustics, Chinese Academy of Sciences
FX This work is supported partly by National Natural Science Foundation of
   China under grant U1636113, and partly by the Scientific Research
   Foundation Project of Haikou Laboratory, Institute of Acoustics, Chinese
   Academy of Sciences.
CR ALI MA, 2011, P IEEE INT C CONS EL, P53
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], IEEE AS PAC SERV COM
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Dai YJ, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1845
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Gui Feng, 2011, Proceedings of the 2011 International Conference on Anti-Counterfeiting, Security and Identification (2011 ASID), P73, DOI 10.1109/ASID.2011.5967419
   Hongliu Zhu, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P487, DOI 10.1109/CISP.2010.5646792
   Hu Y, 2007, IEEE INT C MULT EXP, V2007, P1231
   Jia-Ji Wang, 2015, Journal of Software, V10, P213
   Jiaji W, 2014, SENSORS TRANSDUCERS, V177, P230
   Jiang B., 2015, J. Comput. Inf. Syst., V11, P2121
   Jordan F, 1997, M2281 ISOIEC JTCISC2
   Kapotas SK, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P373, DOI 10.1109/MMSP.2007.4412894
   Kapotas SK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P277, DOI 10.1109/ICME.2008.4607425
   Kapotas SK, 2009, J REAL-TIME IMAGE PR, V4, P33, DOI 10.1007/s11554-008-0100-2
   Li Y, 2010, INT CONF SIGN PROCES, P1833, DOI 10.1109/ICOSP.2010.5656918
   LIAO K, 2009, INT C MULT INF NETW, P578, DOI DOI 10.1109/MINES.2009.205
   Liu CH, 2008, IEEE INT SYMP CIRC S, P3025, DOI 10.1109/ISCAS.2008.4542095
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Mobasseri B.G., 2007, Proceedings of the SPIE security, steganography, and watermarking of multimedia contents VIII, V6505, P1
   Nasir M, 2012, FUTURE INFORM TECHNO, V179, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swaraja K., 2011, 2011 Annual IEEE India Conference, P1
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang JM, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, P233, DOI 10.1109/ISCID.2008.31
   Wang JJ, 2014, LARGE CAPACITY INFOR, P934
   Wu Guangyu, 2011, 3rd Int. workshop on search and mining user-generated contents (SMUC), P45, DOI DOI 10.1145/2065023.2065036
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xu DW, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P411, DOI 10.1109/WCINS.2010.5541810
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Xu JM, 2015, EUR RADIOL, V11, P1
   Yamadera S., 2010, 2010 2nd European Workshop on Visual Information Processing (EUVIP 2010), P210, DOI 10.1109/EUVIP.2010.5699112
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yao Guo, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P419, DOI 10.1109/ICITIS.2010.5689580
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Yi-Xiao Sun, 2017, International Journal of Innovative Computing and Applications, V8, P50
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang J, 2001, P 2003 INT C COMM TE, P1845
   Zhang XF, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-107
   Zou DK, 2010, IEEE INT CON MULTI, P117, DOI 10.1109/ICME.2010.5583550
NR 45
TC 50
Z9 56
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11979
EP 12001
DI 10.1007/s11042-017-4844-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100017
DA 2024-07-18
ER

PT J
AU Gan, ZH
   Chai, XL
   Yuan, K
   Lu, Y
AF Gan, Zhihua
   Chai, Xiuli
   Yuan, Ke
   Lu, Yang
TI A novel image encryption algorithm based on LFT based S-boxes and chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; S-box; Forward substitution process (FSP); Reverse
   substitution process (RSP); Sha 256; Chaos
ID PERMUTATION; SYSTEM; MAP
AB A novel and efficient image encryption algorithm based on the chaotic system and S-boxes is introduced in this paper, in which an original S-box is produced by linear fractional transformation (LFT) on Galois field of order 256, and then a set of S-boxes are obtained by performing zigzag confusion on the original S-box. The encryption architecture of forward substitution process (FSP) and reverse substitution process (RSP) is adopted. For each pixel of the plain image, a corresponding element in a certain S-box is chosen, and the choosing process of the S-box and element depends on two random numbers, the plain image pixel and the previous cipher pixel. Moreover, 2D-LASM is used to generate the random numbers, and its initial values and system parameter are computed by the SHA 256 hash of the plain image and the given values. Therefore, the proposed scheme has highly relationship with the original image and it can resist known-plaintext and chosen-plaintext attacks. Besides, correlated chaos and correlated substitution are used to improve the security level. Experiment results and security analyses demonstrate that the proposed image encryption algorithm is secure and efficient.
C1 [Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli; Yuan, Ke] Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
   [Lu, Yang] Henan Univ, Res Dept, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Pennsylvania Commonwealth System of
   Higher Education (PCSHE); University of Pittsburgh; Henan University
RP Chai, XL (corresponding author), Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.; Chai, XL (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA.
EM chaixiuli@henu.edu.cn
FU National Natural Science Foundation of China [41571417, U1604145];
   National Science Foundation of the United States [CNS-1253424,
   ECCS-1202225]; Science and Technology Foundation of Henan Province of
   China [152102210048]; Foundation and Frontier Project of Henan Province
   of China [162300410196]; China Postdoctoral Science Foundation
   [2016M602235]; Natural Science Foundation of Educational Committee of
   Henan Province of China [14A413015]; Research Foundation of Henan
   University [xxjc20140006]; Henan Postdoctoral Scientific Program
FX All the authors are deeply grateful to the editors for careful and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant No. 41571417 and U1604145), National Science
   Foundation of the United States (Grant No. CNS-1253424 and
   ECCS-1202225), Science and Technology Foundation of Henan Province of
   China (Grant No. 152102210048), Foundation and Frontier Project of Henan
   Province of China (Grant No. 162300410196), China Postdoctoral Science
   Foundation (Grant No. 2016M602235), Natural Science Foundation of
   Educational Committee of Henan Province of China (Grant No. 14A413015),
   the Research Foundation of Henan University (Grant No. xxjc20140006) and
   Henan Postdoctoral Scientific Program.
CR Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang HC, 2016, OPTIK, V127, P5950, DOI 10.1016/j.ijleo.2016.04.011
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Hussain I, 2013, NONLINEAR DYNAM, V72, P399, DOI 10.1007/s11071-012-0723-5
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Qin D., 2016, J INFORM HIDING MULT, V7, P938
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Suryanto Y, 2016, J INFORM HIDING MULT, V7, P697
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 41
TC 33
Z9 35
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8759
EP 8783
DI 10.1007/s11042-017-4772-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800044
DA 2024-07-18
ER

PT J
AU Liao, X
   Guo, SJ
   Yin, JJ
   Wang, H
   Li, X
   Sangaiah, AK
AF Liao, Xin
   Guo, Sujing
   Yin, Jiaojiao
   Wang, Huan
   Li, Xiong
   Sangaiah, Arun Kumar
TI New cubic reference table based image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Reference table; Cubic reference table; Pixel value
   differencing
AB Tradition reference table based (RTB) methods employ two pixels to conceal a secret digit according to a two-dimensional reference table. In this paper, x-dimensional reference table framework is defined, which can be regarded as generalization of the prior works. The available pixels to be embedded are limited in two-dimensional space, so the proposed methods extend the dimensional space of reference table. Theoretical analyses are given to justify the effectiveness of the proposed construction. Two novel RTB methods named CRT (cubic reference table) and CRT-PVD (cubic reference table and pixel value differencing) are presented. The former is independent of image contents while embedding, and the latter is depended on the discriminated image smoothness. Experimental results show that two proposed methods can achieve better performance compared with the prior works.
C1 [Liao, Xin; Guo, Sujing; Yin, Jiaojiao; Wang, Huan] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Liao, Xin] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Hunan University; Shenzhen University; Hunan University of Science &
   Technology; Vellore Institute of Technology (VIT); VIT Vellore
RP Li, X (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
EM lixiongzhq@163.com
RI Li, Xiong/K-7233-2012; Sangaiah, Arun Kumar/U-6785-2019; Liao,
   Xin/X-2736-2018; Liao, Xin/ITT-1021-2023
OI Li, Xiong/0000-0001-6619-554X; Sangaiah, Arun Kumar/0000-0002-0229-2460;
   Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61402162, 61370225,
   61472131, 61272546]; Hunan Provincial Natural Science Foundation of
   China [2017JJ3040]; Opening Project of Shanghai Key Laboratory of
   Integrated Administration Technologies for Information Security
   [AGK201605]; CCF-Venustech Research Fund, Specialized Research Fund for
   the Doctoral Program of Higher Education [20130161120004]; Science and
   Technology Key Projects of Hunan Province [2015TP1004, 2016JC2012]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61402162, 61370225, 61472131, 61272546), Hunan Provincial
   Natural Science Foundation of China (Grant No. 2017JJ3040), Opening
   Project of Shanghai Key Laboratory of Integrated Administration
   Technologies for Information Security (Grant No. AGK201605),
   CCF-Venustech Research Fund, Specialized Research Fund for the Doctoral
   Program of Higher Education (Grant No. 20130161120004), Science and
   Technology Key Projects of Hunan Province (Grant Nos. 2015TP1004,
   2016JC2012).
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Cai K, 2010, P IEEE INT C IM PROC, P26
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Felgenhauer B., 2006, Mathematical Spectrum, V39, P15
   Feng B., 2014, P INT WORKSH DIG WAT, P574
   Feng BW, 2015, MULTIMED TOOLS APPL, V74, P9623, DOI 10.1007/s11042-014-2140-x
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hong W, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P935, DOI 10.1109/IITA.2008.445
   Hong W, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P515, DOI 10.1109/ISISE.2008.153
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mao Q, 2015, IET IMAGE PROCESS, V9, P1073, DOI 10.1049/iet-ipr.2015.0065
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhan WZ, 2015, INT CONF COMPUT INTE, P1199, DOI 10.1109/CICN.2015.289
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhu XS, 2014, IEEE T MULTIMEDIA, V16, P1888, DOI 10.1109/TMM.2014.2340695
NR 31
TC 49
Z9 49
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10033
EP 10050
DI 10.1007/s11042-017-4946-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200044
DA 2024-07-18
ER

PT J
AU Loukhaoukha, K
   Refaey, A
   Zebbiche, K
   Shami, A
AF Loukhaoukha, Khaled
   Refaey, Ahmed
   Zebbiche, Khalil
   Shami, Abdallah
TI Efficient and secure cryptosystem for fingerprint images in wavelet
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Confusion; Diffusion; Rubik's cube; Fingerprint image
ID ENCRYPTION; SYSTEMS
AB In this paper, a fingerprint image encryption algorithm is proposed in order to enhance the protection of fingerprint-based systems against replay attacks. The proposed algorithm is consisting of permutation and diffusion operations in wavelet domain, whereas, one-level Lifting Wavelet Transform Integer-to-Integer is performed to the original fingerprint image. The approximation and detail sub-bands are then partitioned into blocks and permuted using a permutation key. It is noteworthy that, for each sub-band the Rubik's cube principle is applied. The encrypted image is constructed by ordering the encrypted sub-bands. Eventually, an experimental tests and security analysis were conducted on three fingerprint images attained through Fingerprint Verification Competition "FVC 2000" database. The obtained results confirm the effectiveness of the proposed encryption algorithm and clearly show the robustness against common attacks, for example differential and statistical attacks. In addition, it reveals the high security level achieved.
C1 [Loukhaoukha, Khaled; Zebbiche, Khalil] Res Dev Ctr, Algiers, Algeria.
   [Refaey, Ahmed] Manhattan Coll, Dept ECE, Riverdale, NY 10471 USA.
   [Loukhaoukha, Khaled] Laval Univ, Dept Elect & Comp Engn, Quebec City, PQ, Canada.
   [Zebbiche, Khalil] Queens Univ, Sch Elect Elect Engn & Comp Sci, Belfast, Antrim, North Ireland.
   [Refaey, Ahmed; Shami, Abdallah] Western Univ, Dept ECE, London, ON N6G 5B9, Canada.
C3 Manhattan College; Laval University; Queens University Belfast; Western
   University (University of Western Ontario)
RP Loukhaoukha, K (corresponding author), Res Dev Ctr, Algiers, Algeria.; Loukhaoukha, K (corresponding author), Laval Univ, Dept Elect & Comp Engn, Quebec City, PQ, Canada.
EM khaled.loukhaoukha.1@ulaval.ca
RI Loukhaoukha, Khaled/ABI-3136-2020; Shami, Abdallah/HTT-3720-2023
OI Loukhaoukha, Khaled/0000-0002-9000-4210; Shami,
   Abdallah/0000-0003-2887-0350; zebbiche, khalil/0000-0002-6926-8203
CR Abundiz-Perez F, 2016, FINGERPRINT IMAGE EN, V2016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2005, BIOMETRICS PERSONAL
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Delong Cui, 2010, Proceedings of the 2010 International Conference on Machine Vision and Human-Machine Interface (MVHI 2010), P168, DOI 10.1109/MVHI.2010.38
   Han FL, 2007, APPL MATH COMPUT, V185, P931, DOI 10.1016/j.amc.2006.07.030
   Khan MK, 2007, LECT NOTES ARTIF INT, V4682, P1141
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Wu C, 2007, THESIS U NEW YORK BU
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
NR 14
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9325
EP 9339
DI 10.1007/s11042-017-4938-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200009
DA 2024-07-18
ER

PT J
AU Vonikakis, V
   Kouskouridas, R
   Gasteratos, A
AF Vonikakis, Vassilios
   Kouskouridas, Rigas
   Gasteratos, Antonios
TI On the evaluation of illumination compensation algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination compensation; Image enhancement; Exposure correction;
   Comparison framework
ID REAL-TIME; RETINEX; IMAGES; IMPLEMENTATION; PERFORMANCE; FRAMEWORK;
   SCALE
AB This paper presents a comparison framework for algorithms that can diminish the effects of illumination in images. Its main objective is to reveal the positive and negative characteristics of such algorithms, allowing researchers to select the most appropriate one for their target application. The proposed framework utilizes artificial illumination degradations on real images, which are then processed by the tested algorithms. The results are evaluated by an ensemble of performance metrics, highlighting the various characteristics of the algorithms across a range of different image attributes. The proposed framework represents a useful tool for the selection of illumination compensation algorithms due to a) its quantitative nature, b) its multifaceted analysis and c) its easy reproducibility. The validity of the proposed framework is tested by applying it to the enhancement results of four illumination compensation algorithms, which are used as preprocessing in two classic computer vision applications. The improvements brought about by the algorithms are in accordance with the predictions of the proposed framework.
C1 [Vonikakis, Vassilios] Adv Digital Sci Ctr, 1 Fusionopolis Way,08-10 Connexis North Tower, Singapore 138632, Singapore.
   [Kouskouridas, Rigas] WIREWAX, 2-4 Whitfield St, London W1T 2RB, England.
   [Gasteratos, Antonios] Democritus Univ Thrace, Dept Prod, Management Engn, Vassilisis Sofias 12, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Vonikakis, V (corresponding author), Adv Digital Sci Ctr, 1 Fusionopolis Way,08-10 Connexis North Tower, Singapore 138632, Singapore.
EM bbonik@adsc.com.sg; rkouskou@gmail.com; agaster@pme.duth.gr
RI Gasteratos, Antonios/AAI-4740-2021; Gasteratos, Antonios/B-7796-2012
OI Gasteratos, Antonios/0000-0002-5421-0332; Kouskouridas,
   Rigas/0000-0002-4866-520X
FU Singapore's Agency for Science, Technology and Research (A*STAR)
FX This study is partially supported by the research grant for the
   Human-Centered Cyber-physical Systems Programme at the Advanced Digital
   Sciences Center from Singapore's Agency for Science, Technology and
   Research (A*STAR).
CR Aggarwal M, 2004, INT J COMPUT VISION, V58, P7, DOI 10.1023/B:VISI.0000016144.56397.1a
   [Anonymous], TOPOLOGICAL SLAM USI
   [Anonymous], 2012, PROC 20 ACM INT C MU
   [Anonymous], P 4 ALV VIS C, DOI DOI 10.5244/C.2.23
   [Anonymous], 2006, Proc. 14th Pacific Conf. on Comput. Graph. Appl
   [Anonymous], P NATL ACAD SCI US
   [Anonymous], THESIS STANFORD
   [Anonymous], QUANTIZATION TECHNIQ
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Battiato S, 2003, J ELECTRON IMAGING, V12, P459, DOI 10.1117/1.1580829
   Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Wanpeng P, 2008, PATTERN RECOGN LETT, V29, P192, DOI 10.1016/j.patrec.2007.09.012
   Ciocca G, 2003, J ELECTRON IMAGING, V12, P161, DOI 10.1117/1.1526844
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Finlayson G.D., 2002, ISTSID 10 COLOR IMAG, P73
   Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Han YX, 2014, MULTIMED TOOLS APPL, V72, P2619, DOI 10.1007/s11042-013-1521-x
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Iakovidou C, 2008, J REAL-TIME IMAGE PR, V3, P269, DOI 10.1007/s11554-008-0090-0
   Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kong TL, 2017, MULTIMED TOOLS APPL, V76, P14305, DOI 10.1007/s11042-016-3787-2
   Konstantinidis K, 2011, PATTERN ANAL APPL, V14, P251, DOI 10.1007/s10044-011-0217-y
   Kuang JT, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P315
   Kuo CM, 2016, MULTIMED TOOLS APPL, V75, P1177, DOI 10.1007/s11042-014-2363-x
   Kushwaha AKS, 2016, MULTIMED TOOLS APPL, V75, P16209, DOI 10.1007/s11042-015-2927-4
   Lai YR, 2017, MULTIMED TOOLS APPL, V76, P1585, DOI 10.1007/s11042-015-3147-7
   LAND EH, 1964, AM SCI, V52, P247
   Le HS, 2008, ELECTRON LETT, V44, P19, DOI 10.1049/el:20082182
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Lin GS, 2016, MULTIMED TOOLS APPL, V75, P9903, DOI 10.1007/s11042-015-2777-0
   Lin TL, 2016, MULTIMED TOOLS APPL, V75, P1899, DOI 10.1007/s11042-014-2379-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matsushita Y, 2004, IEEE T PATTERN ANAL, V26, P1336, DOI 10.1109/TPAMI.2004.86
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nalpantidis L, 2010, IMAGE VISION COMPUT, V28, P940, DOI 10.1016/j.imavis.2009.11.011
   Provenzi E, 2008, IEEE T PATTERN ANAL, V30, P1757, DOI 10.1109/TPAMI.2007.70827
   Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Rao YB, 2014, MULTIMED TOOLS APPL, V70, P2235, DOI 10.1007/s11042-012-1226-6
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Ruiz-Del-Solar J, 2008, PATTERN RECOGN LETT, V29, P1966, DOI 10.1016/j.patrec.2008.06.015
   Saponara S, 2007, J REAL-TIME IMAGE PR, V1, P267, DOI 10.1007/s11554-007-0027-z
   Sobol R, 2004, J ELECTRON IMAGING, V13, P65, DOI 10.1117/1.1636762
   Vonikakis V, 2008, IET IMAGE PROCESS, V2, P19, DOI 10.1049/iet-ipr:20070012
   Vonikakis V, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074024
   Vonikakis V, 2013, IEEE CONF IMAGING SY, P264, DOI 10.1109/IST.2013.6729703
   Xiong WH, 2009, IMAGE VISION COMPUT, V27, P178, DOI 10.1016/j.imavis.2007.11.012
   Yendrikhovskij SN, 1998, P SOC PHOTO-OPT INS, V3299, P274, DOI 10.1117/12.320117
   Yoshida A., 2005, Perceptual evaluation of tone mapping operators with real-world scenes, V5666, P192, DOI [10.1117/12.587782, DOI 10.1117/12.587782]
   Zhou SB, 2015, MULTIMED TOOLS APPL, V74, P6827, DOI 10.1007/s11042-014-1931-4
NR 57
TC 33
Z9 35
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9211
EP 9231
DI 10.1007/s11042-017-4783-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200002
DA 2024-07-18
ER

PT J
AU Wang, LH
   Hou, CP
   Qi, SM
   Jiang, LL
AF Wang, Laihua
   Hou, Chunping
   Qi, Sumin
   Jiang, Lanlan
TI Analysis of maximum tolerant depth distortion in view synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth-image-based rendering (DIBR); Multi-view plus depth (MVD); View
   synthesis distortion; Geometry distortion
ID VIDEO-PLUS-DEPTH; COMPRESSION; MODEL
AB In view synthesis, pixels in an original view are warped into a virtual view with depth-image-based rendering (DIBR). During the procedure of DIBR, distortions in depth map may lead to geometric errors in the synthesized view which will induce quality degradation of synthesized view. Therefore, how to efficiently preserve the fidelity of depth information is extremely important. In this paper, we explore and develop a maximum tolerable depth distortion (MTDD) model to examine the allowable depth distortion which will not introduce any texture distortion for a rendered virtual view and accordingly develop. Experimental results show that a virtual view can be synthesized without introducing any geometric changes if depth distortions follow the MTDD specified thresholds.
C1 [Wang, Laihua; Qi, Sumin; Jiang, Lanlan] Qufu Normal Univ, Sch Software, Jining 273165, Shandong, Peoples R China.
   [Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Qufu Normal University; Tianjin University
RP Wang, LH (corresponding author), Qufu Normal Univ, Sch Software, Jining 273165, Shandong, Peoples R China.
EM wlh@tju.edu.cn
FU National Natural Science Foundation of China [61471262, 61520106002,
   61601261]; Ph.D. Programs Foundation of Ministry of Education of China
   [20110032110029, 20130032110010]; Doctoral Fund of Natural Science
   Foundation of Shandong Province [2016ZRB01AIU]; Smart Future Fellowship
   - Queensland Government of Commonwealth Australia
FX This work is supported by the National Natural Science Foundation of
   China under Grants 61471262, 61520106002 and 61601261, and by Ph.D.
   Programs Foundation of Ministry of Education of China under Grants
   20110032110029 and 20130032110010, Doctoral Fund of Natural Science
   Foundation of Shandong Province under Grants 2016ZRB01AIU and a Smart
   Future Fellowship sponsored by the Queensland Government of Commonwealth
   Australia.
CR Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Daribo Ismael, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P413, DOI 10.1109/MMSP.2008.4665114
   Fang L, 2016, IEEE T IMAGE PROCESS, V25, P1961, DOI 10.1109/TIP.2016.2535345
   Fang L, 2014, IEEE T IMAGE PROCESS, V23, P185, DOI 10.1109/TIP.2013.2287608
   Hannuksela MM, 2013, IEEE T IMAGE PROCESS, V22, P3449, DOI 10.1109/TIP.2013.2269274
   Lei JJ, 2015, IEEE T CIRC SYST VID, V25, P275, DOI 10.1109/TCSVT.2014.2335471
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Loghman M, 2015, MULTIMED TOOLS APPL, V74, P1611, DOI 10.1007/s11042-013-1747-7
   Mateusz G, 2008, ISOIECJTC1SC29WG11M1
   McMillan Leonard, 1997, THESIS
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Sanchez Alfonso, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P578, DOI 10.1109/ACSSC.2009.5469898
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Xu XY, 2013, SIGNAL PROCESS-IMAGE, V28, P1023, DOI 10.1016/j.image.2013.04.003
   Yuan H, 2014, IEEE T CIRC SYST VID, V24, P443, DOI 10.1109/TCSVT.2013.2280071
   Zhang QW, 2011, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2011.6115620
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4879, DOI 10.1109/TIP.2014.2355715
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
NR 19
TC 5
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7909
EP 7927
DI 10.1007/s11042-017-4690-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800006
DA 2024-07-18
ER

PT J
AU Chen, TE
   Huang, TS
   Lin, WC
   Chuang, JH
AF Chen, Ta-En
   Huang, Tsung-Shian
   Lin, Wen-Chieh
   Chuang, Jung-Hong
TI Simulating painted appearance of BTF materials
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bidirectional texture function; Kubelka-Munk; Paint simulation
AB Bidirectional texture function (BTF) provides a realistic representation for real-world materials; however, the representation does not allow users to append additional rendering effects to the BTF data in a simple and effective way. In this paper, we present an approach for generating the painted appearance on a material that is represented by a BTF. We first convert a BTF into a physical representation composed of a height-field and a spatially varying bidirectional reflectance distribution function (SVBRDF). This representation allows us to simulate the appearance of paints on the surface of a material by computing the reflectance and the height field of the painted material. During rendering, we combine an existing BTF rendering approach and the modified material data to simulate the painted appearance of the BTF materials. Our experiments show that the proposed approach can simulate the painted appearance of a material while preserving the characteristic appearance of the original BTF. Our approach is mainly suitable for less specular BTF materials that allow depth reconstruction.
C1 [Chen, Ta-En; Huang, Tsung-Shian; Lin, Wen-Chieh; Chuang, Jung-Hong] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chuang, JH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM jhchuang@cs.nctu.edu.tw
CR Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Dorsey J., 2006, P ACM SIGGRAPH COURS, P2
   Duntley SQ, 1942, J OPT SOC AM, V32, P61, DOI 10.1364/JOSA.32.000061
   Filip J, 2009, IEEE T PATTERN ANAL, V31, P1921, DOI 10.1109/TPAMI.2008.246
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   Huang CG, 2013, COMPUT ANIMAT VIRT W, V24, P275, DOI 10.1002/cav.1523
   Kautz J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239504, 10.1145/1276377.1276443]
   Kortm G., 1969, REFLECTANCE SPECTROS, DOI DOI 10.1007/978-3-642-88071-1
   McAllister D. K., 2002, THESIS
   Menzel N, 2009, COMPUT GRAPH FORUM, V28, P2189, DOI 10.1111/j.1467-8659.2009.01432.x
   Müller G, 2003, VISION, MODELING, AND VISUALIZATION 2003, P271
   Philips-Invernizzi B, 2001, OPT ENG, V40, P1082, DOI 10.1117/1.1370387
   Rushmeier H., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P35
   Silberstein L, 1927, J OPT SOC AM REV SCI, V15, P125, DOI 10.1364/JOSA.15.000125
   Tatarchuk N., 2006, Proceedings of the 2006 symposium on Interactive 3D graphics and games, P63
   Volz H, 1962, BEITRAG PHANOMENOLOG, P98
   Volz H, 1964, P 7 FAT C, P194
   Zhou K, 2005, IEEE T VIS COMPUT GR, V11, P519, DOI 10.1109/TVCG.2005.78
NR 19
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7153
EP 7169
DI 10.1007/s11042-017-4626-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700033
DA 2024-07-18
ER

PT J
AU Tang, LJ
   Li, QH
   Li, LD
   Gu, K
   Qian, JS
AF Tang, Lijuan
   Li, Qiaohong
   Li, Leida
   Gu, Ke
   Qian, Jiansheng
TI Training-free referenceless camera image blur assessment via
   hypercomplex singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypercomplex; Singular value decomposition (SVD); No-reference (NR);
   Image quality assessment (IQA); Energy
ID SHARPNESS ASSESSMENT; QUALITY ASSESSMENT
AB Blur plays an important role in the perception of camera image quality. Generally, blur leads to attenuation of high frequency information and accordingly changes the image energy. Quaternion describes the color information as a whole. Recent researches in quaternion singular value decomposition show that the singular values and singular vectors of the quaternion can capture the distortion of color images, and thus we reasonably suppose that singular values can be utilized to evaluate the sharpness of camera images. Motivated by this, a novel training-free blind quality assessment method considering the integral color information and singular values of the distorted image is proposed to evaluate the sharpness of camera images. The blurred camera image is first converted to LAB color space and divided into blocks. Then pure quaternion is utilized to represent pixels of the blurred camera image and the energy of every block are obtained. Inspired by the human visual system appears to assess image sharpness based on the sharpest region of the image, the local sharpness normalized energy is defined as the sharpness score of the blurred camera image. Experimental results have demonstrated the effectiveness of the proposed metric compared with popular sharpness image quality metrics.
C1 [Tang, Lijuan; Li, Leida; Qian, Jiansheng] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Tang, Lijuan] Jiangsu Vocat Coll Business, Sch Elect & Informat, Nantong 226011, Peoples R China.
   [Li, Qiaohong; Gu, Ke] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 China University of Mining & Technology; Nanyang Technological
   University
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM nttlj@163.com; QLI013@e.ntu.edu.sg; lileida@cumt.edu.cn;
   gukesjtuee@gmail.com; qianzhangiqa@163.com
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022; Gu, Ke/AAJ-9684-2021
FU Fundamental Research Funds for the Central Universities [2015QNA66];
   National Natural Science Foundation of China [61379143]; Science and
   Technology Planning Project of Nantong [BK2014022]; Qing Lan Project
FX This work is supported by National Natural Science Foundation of China
   under Grant 61379143, the Fundamental Research Funds for the Central
   Universities under Grant 2015QNA66, Science and Technology Planning
   Project of Nantong under Grant BK2014022 and the Qing Lan Project.
CR [Anonymous], 9 INT S SIGN PROC IT
   [Anonymous], 2006, Patent No. [CN1897634 A, 1897634]
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Hamilton W. R., 1844, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, V25, P10, DOI [DOI 10.1080/14786444408644923, 10.1080/14786444408644923]
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Huang Y, 2016, MULTIMED TOOLS APPL, V75, P2769, DOI 10.1007/s11042-015-2620-7
   Kolaman A, 2012, IEEE T IMAGE PROCESS, V21, P1526, DOI 10.1109/TIP.2011.2181522
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2016, NEUROCOMPUTING, V177, P572, DOI 10.1016/j.neucom.2015.11.063
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Narwaria M, 2012, IEEE T IMAGE PROCESS, V21, P3364, DOI 10.1109/TIP.2012.2197010
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Qureshi MA, 2016, ELECTRON LETT, V52, DOI 10.1049/el.2016.1792
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sang QB, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108073
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Sangwine SJ, 2006, APPL MATH COMPUT, V182, P727, DOI 10.1016/j.amc.2006.04.032
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P25, DOI 10.1002/9780470175637.ch3
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Tang LJ, 2016, J VIS COMMUN IMAGE R, V40, P335, DOI 10.1016/j.jvcir.2016.07.007
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Y, 2016, IET IMAGE PROCESS, V10, P113, DOI 10.1049/iet-ipr.2014.0937
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang Y, 2013, J ELECT IMAG
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 51
TC 13
Z9 13
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5637
EP 5658
DI 10.1007/s11042-017-4477-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800023
DA 2024-07-18
ER

PT J
AU Vaidya, SP
   Mouli, PVSSRC
AF Vaidya, Prasanth S.
   Mouli, Chandra P. V. S. S. R.
TI Adaptive, robust and blind digital watermarking using Bhattacharyya
   distance and bit manipulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Color image watermarking; Bhattacharyya distance;
   Exponential function; Discrete Wavelet Transform (DWT); Adaptive
   watermarking
ID COLOR IMAGE WATERMARKING; SCHEME
AB Ownership identification and copyright protection are two major concerns for digital data. Digital watermarking provides the best solution for these issues. In order to preserve the copyright protection and identify the ownership of digital data, a robust blind watermarking method using Bhattacharyya distance and exponential function is proposed. The proposed method is adaptive since the embedding factor is calculated based on the gray scale pixel distribution of the host image. Insertion of watermark is done in two phases in which the first phase is carried out in wavelet domain, and the second phase in spatial domain. Similarly extraction of watermark is done in two phases. The proposed method is tested using standard benchmark color images and a binary watermark. The proposed method is analyzed with various image and signal processing attacks and compared with other methods. The results show that the proposed method has better performance than other methods.
C1 [Vaidya, Prasanth S.; Mouli, Chandra P. V. S. S. R.] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Mouli, PVSSRC (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM svprasanth.vaidya2014@vit.ac.in; chandramouli@vit.ac.in
RI sanivarapu, prasanth vaidya/Y-9058-2018; Pvssr, Chandra
   Mouli/L-1127-2019
OI sanivarapu, prasanth vaidya/0000-0002-8972-8860; Pvssr, Chandra
   Mouli/0000-0001-7909-9733
CR Abdallah HA, 2014, INFORM PROCESS MANAG, V50, P909, DOI 10.1016/j.ipm.2014.07.001
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Busch C, 1999, TECHNICAL REPORT
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Fazlali HamidReza, 2016, MULTIMED TOOLS APPL, P1
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P172, DOI 10.1016/j.aeue.2015.11.003
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   KHOTANZAD A, 1990, PATTERN RECOGN, V23, P961, DOI 10.1016/0031-3203(90)90105-T
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P920, DOI 10.1016/j.compeleceng.2014.01.006
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, OPTIK, V124, P3254, DOI 10.1016/j.ijleo.2012.10.005
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Suhail MA, 2003, INFORM SCIENCES, V151, P93, DOI 10.1016/S0020-0255(02)00291-8
   Sun R, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1592, DOI 10.1109/ICOSP.2002.1180102
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   Thanh T.M., 2015, MULTIMEDIA SYSTEMS, P1
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Yen E, 2010, EXPERT SYST APPL, V37, P4033, DOI 10.1016/j.eswa.2009.09.032
NR 25
TC 16
Z9 17
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5609
EP 5635
DI 10.1007/s11042-017-4476-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800022
DA 2024-07-18
ER

PT J
AU Al-Ayyoub, M
   AlZu'bi, S
   Jararweh, Y
   Shehab, MA
   Gupta, BB
AF Al-Ayyoub, Mahmoud
   AlZu'bi, Shadi
   Jararweh, Yaser
   Shehab, Mohammed A.
   Gupta, Brij B.
TI Accelerating 3D medical volume segmentation using GPUs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image processing; Fuzzy C-Means (FCM) algorithm; Parallel
   programming; 3D segmentation
ID COMPUTER-AIDED DIAGNOSIS; C-MEANS ALGORITHM; IMAGE SEGMENTATION; MRI;
   FCM; INFORMATION; LESIONS
AB Medical images have an undeniably integral role in the process of diagnosing and treating of a very large number of ailments. Processing such images (for different purposes) can significantly improve the efficiency and effectiveness of this process. The first step in many medical image processing applications is segmentation, which is used to extract the Region of Interest (ROI) from a given image. Due to its effectiveness, a very popular segmentation algorithm is the Fuzzy C-Means (FCM) algorithm. However, FCM takes a long processing time especially for 3D model. This problem can be solved by utilizing parallel programming using Graphics Processing Unit (GPU). In this paper, a hybrid parallel implementation of FCM for extracting volume object from medical DICOM files has been proposed. The proposed algorithm improves the performance 5x compared with the sequential version.
C1 [Al-Ayyoub, Mahmoud; Shehab, Mohammed A.] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
   [Al-Ayyoub, Mahmoud] Jordan Univ Sci & Technol, High Performance & Cloud Comp Res Lab, Irbid, Jordan.
   [Jararweh, Yaser] Jordan Univ Sci & Technol, Comp Sci, Irbid, Jordan.
   [AlZu'bi, Shadi] Zaytoonah Univ Jordan, Sch Sci & Informat Technol, Dept Comp Sci, Amman, Jordan.
   [Gupta, Brij B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology; Jordan University of Science & Technology; Al-Zaytoonah
   University of Jordan; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Al-Ayyoub, M (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.; Al-Ayyoub, M (corresponding author), Jordan Univ Sci & Technol, High Performance & Cloud Comp Res Lab, Irbid, Jordan.
EM maalshbool@just.edu.jo; smalzubi@zuj.edu.jo; yijararweh@just.edu.jo;
   mohammedshihab@daad-alumni.de; gupta.brij@gmail.com
RI Jararweh, Yaser/ABE-6543-2021; Jararweh, Yaser/JCO-2836-2023; Gupta,
   Brij B/E-9813-2011; AlZu'bi, Shadi/W-4507-2018
OI Gupta, Brij B/0000-0003-4929-4698; AlZu'bi, Shadi/0000-0003-4173-2323
FU Deanship of Research at the Jordan University of Science and Technology
   [20160081]
FX This work was supported in part by the Deanship of Research at the
   Jordan University of Science and Technology (Grant # 20160081).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Ayyoub Mahmoud, 2013, WSEAS Transactions on Information Science and Applications, V10, P261
   Al-Ayyoub Mahmoud, 2013, WSEAS Transactions on Computers, V12, P395
   Al-Ayyoub M, 2012, P 3 INT C INF COMM S, P23
   Al-Ayyoub M., 2016, INT J COMPUT SCI INF, V14, P10
   Al-Ayyoub M., 2013, JMPT, V4, P155
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Al-Darabsah K, 2013, 4 INT C INF COMM SYS
   Alawneh K, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P286, DOI 10.1109/IACS.2015.7103190
   Alomari RS, 2011, INT J COMPUT ASS RAD, V6, P119, DOI 10.1007/s11548-010-0487-7
   Alsmirat M, 2016, MULTIMEDIA IN PRESSS
   Althebyan Q, 2016, ANN TELECOMMUN, P1
   AlZubi S., 2011, IEEE INT S MEDICAL M, P619, DOI [DOI 10.1109/MEMEA.2011.5966667, 10.1109/MeMeA.2011.5966667]
   AlZubi S, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/136034
   [Anonymous], IS T SPIES S EL IM S
   [Anonymous], J SUPERCOMP IN PRESS
   [Anonymous], 1973, FUZZY RELATIVE ISODA
   [Anonymous], 2004, J LUNG CANC
   [Anonymous], 5 INT C MULT COMP SY
   [Anonymous], 2012, CUDA PROGRAMMING DEV
   Arnoldi E, 2010, EUR RADIOL, V20, P1160, DOI 10.1007/s00330-009-1644-7
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chan T, 2007, COMPUT MED IMAG GRAP, V31, P285, DOI 10.1016/j.compmedimag.2007.02.010
   Chen CH, 2010, ECS TRANSACTIONS, V28, P27, DOI 10.1149/1.3377096
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Chen WJ, 2006, ACAD RADIOL, V13, P63, DOI 10.1016/j.acra.2005.08.035
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902
   Fulkerson B., 2010, P 11 EUR C TRENDS TO, P350
   Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793
   Hall LO, 2011, IEEE T FUZZY SYST, V19, P792, DOI 10.1109/TFUZZ.2011.2143418
   Hore P, 2007, IEEE INT CONF FUZZY, P240
   Hwang C, 2007, IEEE T FUZZY SYST, V15, P107, DOI 10.1109/TFUZZ.2006.889763
   Jarrah M, 2016, MULTIMED TOOLS APPL, P1
   Klodt M, 2011, IEEE I CONF COMP VIS, P2236, DOI 10.1109/ICCV.2011.6126502
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779
   Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   McAuliffe MJ, 2001, COMP MED SY, P381
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Murugavalli S., 2006, BIME J, V6, P29
   Nakamoto T, 2014, COMPUTER AIDED DIAGN
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Oqaily A, 2014, 3 INT C INF ENG INF, P310
   Ortiz A, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/638563
   Pratx G, 2011, MED PHYS, V38, P2685, DOI 10.1118/1.3578605
   Qiu CY, 2013, PATTERN RECOGN LETT, V34, P1329, DOI 10.1016/j.patrec.2013.04.021
   Rahimi S, 2004, NAFIPS 2004: ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1AND 2, P234
   Rangayyan RM, 2007, J FRANKLIN I, V344, P312, DOI 10.1016/j.jfranklin.2006.09.003
   Rhee FCH, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P1926, DOI 10.1109/NAFIPS.2001.944361
   Rubio E., 2014, 2014 IEEE C NORBERT, P1
   Ryoo S, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P73, DOI 10.1145/1345206.1345220
   Shehab MA, 2015, P 6 INT C INF COMM S
   Ugarriza LG, 2009, IEEE T IMAGE PROCESS, V18, P2275, DOI 10.1109/TIP.2009.2025555
   Walters JP, 2009, INT PARALL DISTRIB P, P1010
   Wang JZ, 2008, COMPUT MED IMAG GRAP, V32, P685, DOI 10.1016/j.compmedimag.2008.08.004
   Wang L, 2014, APPL INTELL, V40, P143, DOI 10.1007/s10489-013-0450-8
   Winder J, 2005, J ORAL MAXIL SURG, V63, P1006, DOI 10.1016/j.joms.2005.03.016
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 67
TC 43
Z9 43
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4939
EP 4958
DI 10.1007/s11042-016-4218-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500048
DA 2024-07-18
ER

PT J
AU Sajjad, M
   Ullah, A
   Ahmad, J
   Abbas, N
   Rho, S
   Baik, SW
AF Sajjad, Muhammad
   Ullah, Amin
   Ahmad, Jamil
   Abbas, Naveed
   Rho, Seungmin
   Baik, Sung Wook
TI Integrating salient colors with rotational invariant texture features
   for image representation in retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Visual features; Salient colors; Texture
   features
ID LOCAL BINARY PATTERNS; FEATURE DESCRIPTOR; VISUAL-CORTEX; NEURAL BASIS;
   RECOGNITION; SEARCH
AB Content based image retrieval (CBIR) systems allow searching for visually similar images in large collections based on their contents. Visual contents are usually represented based on their properties like colors, shapes, and textures. In this paper, we propose to integrate two properties of images for constructing a discriminative and robust representation. Firstly, the input image is transformed into the HSV color space and then quantized into a limited number of representative colors. Secondly, texture features based on uniform patterns of rotated local binary patterns (RLBP) are extracted. The characteristics of color histogram populated from the quantized images and texture features are compared and analyzed for image representation. Consequently, the quantized color histogram and histogram of uniform patterns in RLBP are fused together to form a feature vector. Experimental evaluations with frequently used datasets show that the proposed method yields better results as compared to other state-of-the-art techniques.
C1 [Sajjad, Muhammad; Ullah, Amin; Abbas, Naveed] Islamia Coll, Dept Comp Sci, Digital Image Proc Lab, Peshawar, Pakistan.
   [Ullah, Amin; Ahmad, Jamil; Baik, Sung Wook] Sejong Univ, Coll Software & Convergence Technol, Intelligent Media Lab, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 University of Peshawar; Sejong University; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Coll Software & Convergence Technol, Intelligent Media Lab, Seoul, South Korea.
EM sbaik@sejong.ac.kr
RI Sajjad, Muhammad/L-5269-2016; Baik, Sung Wook/AAR-8236-2020; Rho,
   Seungmin/HTP-6683-2023; Abbas, Naveed/JAV-9478-2023; Ullah,
   Amin/AAH-5034-2020; Ullah, Amin/JPA-6034-2023; Ahmad, Jamil/G-6931-2015
OI Sajjad, Muhammad/0000-0001-5646-0338; Abbas, Naveed/0000-0003-1204-250X;
   Ullah, Amin/0000-0001-7538-2689; Ahmad, Jamil/0000-0001-8407-5971; Baik,
   Sung Wook/0000-0002-6678-7788
FU National Research Foundation of Korea (NRF) grant - Korea Government
   (MSIP) [2016R1A2B4011712]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIP) (No.
   2016R1A2B4011712).
CR Ahmad J, 2015, J REAL TIME IMAGE PR
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], NETW BAS INF SYST NB
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Boutell M, 2004, COMP VIS PATT REC WO
   Duan LY, 2013, AI MAG, V34, P67, DOI 10.1609/aimag.v34i2.2469
   Eimer M, 2014, TRENDS COGN SCI, V18, P526, DOI 10.1016/j.tics.2014.05.005
   Hoi SC, 2008, COMP VIS PATT REC 20
   Junling L, 2011, MECH SCI EL ENG COMP
   Kastner S, 2001, NEUROPSYCHOLOGIA, V39, P1263, DOI 10.1016/S0028-3932(01)00116-6
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   LIVINGSTONE MS, 1984, J NEUROSCI, V4, P309
   Maree R, 2007, P AS C COMP VIS
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   Sethi I. K., 2001, AEROSPACE DEFENSE SE
   Shao H., 2003, ZUBUD ZURICH BUILD I, P6
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Takala V, 2005, SCAND C IM AN
   Tang JY, 2007, IEEE T CIRC SYST VID, V17, P384, DOI 10.1109/TCSVT.2006.888941
   Vatamanu OA, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707396
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   YU YC, 2014, NCDR REP, V2014, P1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou JX, 2014, SPRINGER P MATH STAT, V86, P197, DOI 10.1007/978-3-662-43404-8_11
NR 30
TC 30
Z9 30
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4769
EP 4789
DI 10.1007/s11042-017-5010-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500039
DA 2024-07-18
ER

PT J
AU Yang, ZJ
   Wan, MH
   Zhan, TM
   Lai, ZH
   Luo, LM
   Huang, P
   Zhang, JC
AF Yang, Zhangjing
   Wan, Minghua
   Zhan, Tianming
   Lai, Zhihui
   Luo, Limin
   Huang, Pu
   Zhang, Jincheng
TI Unsupervised multi-manifold linear differential projection(UMLDP) for
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Multi-manifold; Unsupervised
   linear differential projection (ULDP)
ID FEATURE-EXTRACTION; ALGORITHM
AB A novel efficient algorithm called unsupervised multi-manifold linear differential projection(UMLDP) is proposed to overcome the drawbacks of existing unsupervised linear differential projection(ULDP) for face recognition. Firstly, the multi-manifold local neighborhood graph and the largest global variance is constructed respectively. Next, we calculate a low dimensional manifold embedded in high-dimensional space through the multi-objective optimization. This mapping can not only get the low-dimensional manifolds embedded in a high-dimensional space but also maintain the local and the global structural information effectively. Finally, experimental results validate the effectiveness of the proposed algorithm on the ORL, Yale and AR face databases.
C1 [Yang, Zhangjing; Luo, Limin] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210009, Peoples R China.
   [Yang, Zhangjing; Wan, Minghua; Zhan, Tianming; Zhang, Jincheng] Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.
   [Yang, Zhangjing; Wan, Minghua; Lai, Zhihui] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Yang, Zhangjing] Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Fujian, Peoples R China.
   [Huang, Pu] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Audit University; Shenzhen
   University; Nanjing University of Posts & Telecommunications
RP Yang, ZJ (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 210009, Peoples R China.; Yang, ZJ (corresponding author), Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.; Yang, ZJ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Yang, ZJ (corresponding author), Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Fujian, Peoples R China.
EM yzzjjj@126.com
RI Lai, Zhihui/R-1000-2019; zhang, jin/GXV-9154-2022; zhang,
   jin/IXD-9872-2023
OI Lai, Zhihui/0000-0002-4388-3080; 
FU National Natural Science Fund of China [61503195, 61462064, 61203243,
   61402231, 61603192, 61272077]; Natural Science Fund of Jiangsu Province
   [BK20161580]; University Natural Science Fund of JiangSu Province, China
   [15KJB520018, 16KJB520020, 12KJA63001]
FX This work is supported by the National Natural Science Fund of China
   (Grant Nos. 61503195, 61462064, 61203243,61402231, 61603192 and
   61272077), the Natural Science Fund of Jiangsu Province(Grant No.
   BK20161580), the University Natural Science Fund of JiangSu Province,
   China (Grant No. 15KJB520018, 16KJB520020 and 12KJA63001).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Lai ZH, 2016, IEEE T NEUR NET LEAR, V27, P723, DOI 10.1109/TNNLS.2015.2422994
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu ZH, 2016, J MED IMAG HEALTH IN, V6, P1218, DOI 10.1166/jmihi.2016.1901
   [马小虎 Ma Xiaohu], 2014, [自动化学报, Acta Automatica Sinica], V40, P73
   Nixon M, 2008, FEATURE EXTRACTION I, P385
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wan MH, 2011, NEURAL PROCESS LETT, V33, P267, DOI 10.1007/s11063-011-9177-x
   Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805
   Wankou Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P527, DOI 10.1109/ICPR.2010.134
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Xia JS, 2015, IEEE T GEOSCI REMOTE, V53, P2532, DOI 10.1109/TGRS.2014.2361618
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Yang X, 2009, OPT PRECIS ENG, V9, P33
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang PY, 2016, PATTERN RECOGN, V52, P249, DOI 10.1016/j.patcog.2015.09.024
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P873, DOI 10.1177/0037549716667834
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 33
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3795
EP 3811
DI 10.1007/s11042-016-4105-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600050
DA 2024-07-18
ER

PT J
AU Zhang, H
   Huang, Y
   Xu, X
   Zhu, ZQ
   Deng, CH
AF Zhang, Hong
   Huang, Yu
   Xu, Xin
   Zhu, Ziqi
   Deng, Chunhua
TI Latent semantic factorization for multimedia representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Posterior probability; Latent semantic factorization; Cross-modal
   retrieval
ID CROSS-MEDIA; SUBSPACE
AB Due to the rapid development of multimedia applications, cross-media semantics learning is becoming increasingly important nowadays. One of the most challenging issues for cross-media semantics understanding is how to mine semantic correlation between different modalities. Most traditional multimedia semantics analysis approaches are based on unimodal data cases and neglect the semantic consistency between different modalities. In this paper, we propose a novel multimedia representation learning framework via latent semantic factorization (LSF). First, the posterior probability under the learned classifiers is served as the latent semantic representation for different modalities. Moreover, we explore the semantic representation for a multimedia document, which consists of image and text, by latent semantic factorization. Besides, two projection matrices are learned to project images and text into a same semantic space which is more similar with the multimedia document. Experiments conducted on three real-world datasets for cross-media retrieval, demonstrate the effectiveness of our proposed approach, compared with state-of-the-art methods.
C1 [Zhang, Hong; Huang, Yu; Xu, Xin; Zhu, Ziqi; Deng, Chunhua] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Zhang, Hong; Huang, Yu; Xu, Xin; Zhu, Ziqi; Deng, Chunhua] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Hubei, Peoples R China.
EM zhanghong_wust@163.com
RI Xu, Xin/JRW-5800-2023
FU National Natural Science Foundation of China [61373109, 61602349]; Hubei
   Chengguang Talented Youth Development Foundation [2015B22]; Natural
   Science Foundation Hubei Province [ZRMS2016000155]; Science and
   technology research project of Hubei Provincial Department of Education
   [Q20161113]
FX This research is supported by the National Natural Science Foundation of
   China (No. 61373109, No. 61602349), the Hubei Chengguang Talented Youth
   Development Foundation (No. 2015B22), Natural Science Foundation Hubei
   Province (No. ZRMS2016000155) and Science and technology research
   project of Hubei Provincial Department of Education (No. Q20161113).
CR [Anonymous], JMLR P
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang JY, 2016, IEEE T PATTERN ANAL, V38, P1612, DOI 10.1109/TPAMI.2016.2519021
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Jiang A, 2015, COMPUT SCI, V1511, P1
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan ZZ, 2012, LECT NOTES COMPUT SC, V7131, P173
   Lei Huang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P276, DOI 10.1007/978-3-319-27671-7_23
   Li B, 2016, NEUROCOMPUTING, V188, P225, DOI 10.1016/j.neucom.2014.11.105
   Li B, 2015, NEUROCOMPUTING, V152, P121, DOI 10.1016/j.neucom.2014.11.012
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Rafailidis D, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P781, DOI 10.1145/2911451.2914710
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Singh A. P., 2008, P 14 ACM SIGKDD INT, P650
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tiezheng Nie, 2011, 2011 8th Web Information Systems and Applications Conference, P7, DOI 10.1109/WISA.2011.9
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang YF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P307, DOI 10.1145/2647868.2654901
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xue Z, 2014, INT J MULTIMED INF R, V3, P193, DOI 10.1007/s13735-014-0056-x
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang HY, 2015, 2015 12TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P169, DOI 10.1109/WISA.2015.49
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P9169, DOI 10.1007/s11042-016-3294-5
   Zhang H, 2016, NEUROCOMPUTING, V173, P93, DOI 10.1016/j.neucom.2015.07.104
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang H, 2012, NEUROCOMPUTING, V93, P100, DOI 10.1016/j.neucom.2012.03.007
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhuang Y., 2013, P 27 AAAI C ART INT, P1070
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 48
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3353
EP 3368
DI 10.1007/s11042-017-5135-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600025
DA 2024-07-18
ER

PT J
AU Zhu, FQ
   Kong, XW
   Wu, Q
   Fu, HY
   Li, M
AF Zhu, Fuqing
   Kong, Xiangwei
   Wu, Qun
   Fu, Haiyan
   Li, Ming
TI A loss combination based deep model for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Loss combination; Person re-identification
AB The Convolutional Neural Network (CNN) has significantly improved the state-of-the-art in person re-identification (re-ID). In the existing available identification CNN model, the softmax loss function is employed as the supervision signal to train the CNN model. However, the softmax loss only encourages the separability of the learned deep features between different identities. The distinguishing intra-class variations have not been considered during the training process of CNN model. In order to minimize the intra-class variations and then improve the discriminative ability of CNN model, this paper combines a new supervision signal with original softmax loss for person re-ID. Specifically, during the training process, a center of deep features is learned for each pedestrian identity and the deep features are subtracted from the corresponding identity centers, simultaneously. So that, the deep features of the same identity to the center will be pulled efficiently. With the combination of loss functions, the inter-class dispersion and intra-class aggregation can be constrained as much as possible. In this way, a more discriminative CNN model, which has two key learning objectives, can be learned to extract deep features for person re-ID task. We evaluate our method in two identification CNN models (i.e., CaffeNet and ResNet-50). It is encouraging to see that our method has a stable improvement compared with the baseline and yields a competitive performance to the state-of-the-art person re-ID methods on three important person re-ID benchmarks (i.e., Market-1501, CUHK03 and MARS).
C1 [Zhu, Fuqing; Kong, Xiangwei; Fu, Haiyan; Li, Ming] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Wu, Qun] Zhejiang Sci Tech Univ, Gen Design Inst, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wu, Qun] Zhejiang Univ, Taizhou Res Inst, Taizhou 318000, Peoples R China.
C3 Dalian University of Technology; Zhejiang Sci-Tech University; Zhejiang
   University
RP Kong, XW (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
EM fuqingzhu@mail.dlut.edu.cn; kongxw@dlut.edu.cn; wuq@zstu.edu.cn;
   fuhy@dlut.edu.cn; mli@dlut.edu.cn
RI Kong, Xiangwei/IWL-9350-2023
FU Foundation for Innovative Research Groups of the NSFC [71421001];
   National Natural Science Foundation of China [61502073]; Open Projects
   Program of National Laboratory of Pattern Recognition [201407349]
FX This work is supported by the Foundation for Innovative Research Groups
   of the NSFC (Grant no. 71421001), National Natural Science Foundation of
   China (Grant no. 61502073), and the Open Projects Program of National
   Laboratory of Pattern Recognition (No. 201407349).
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], ARXIV160402426
   [Anonymous], 2016, CORR
   [Anonymous], 2015, ARXIV151205300
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, ARXIV170307220
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2016, ARXIV
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, ARXIV170305693
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2007, P ICCV
   [Anonymous], 2016, ARXIV160604404
   [Anonymous], CORR
   [Anonymous], ARXIV160707216
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Davis J. V., 2007, ICML, P209
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Radford A., 2016, COMPUT SCI
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xiang ZJ, 2014, MULTIMED TOOLS APPL, V73, P91, DOI 10.1007/s11042-012-1286-7
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao YN, 2016, MULTIMED TOOLS APPL, V75, P4795, DOI 10.1007/s11042-015-2503-y
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 71
TC 11
Z9 12
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3049
EP 3069
DI 10.1007/s11042-017-5009-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600008
DA 2024-07-18
ER

PT J
AU Liu, HJ
   Kadir, A
   Sun, XB
   Li, YL
AF Liu, Hongjun
   Kadir, Abdurahman
   Sun, Xiaobo
   Li, Yanling
TI Chaos based adaptive double-image encryption scheme using hash function
   and S-boxes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double-image encryption; Autonomous ODE system; SHA-512; S-box; Post
   quantum cryptography
ID SYSTEM; MAP
AB Most current symmetric cryptographic algorithms (symmetric ciphers and hash functions) are considered to be relatively secure against attacks by quantum computers. Here we propose an adaptive color double-image encryption scheme based on autonomous ODE chaotic system and SHA-512. The double-image is diffused firstly by chaotic sequences with bitwise exclusive or operation, and an algorithm is designed to transform two 512-bit hash values into two S-Boxes, to substitute for the pixels of diffused double-image respectively. In each encryption process, the initial values of chaotic system are from random signal, they are true random numbers. Simulation results demonstrate that the scheme is suitable and effective for color double-image encryption.
C1 [Liu, Hongjun; Li, Yanling] Weifang Vocat Coll, Sch Informat Engn, Weifang 261061, Peoples R China.
   [Liu, Hongjun; Li, Yanling] Technol Res Ctr Weifang, Modern Logist Informat Engn, Weifang 261041, Peoples R China.
   [Kadir, Abdurahman] Xinjiang Univ Finance & Econ, Sch Comp Sci & Engn, Urumqi 830012, Peoples R China.
   [Sun, Xiaobo] Weifang Vocat Coll, Sci & Technol Dept, Weifang 261061, Peoples R China.
C3 Xinjiang University of Finance & Economics
RP Liu, HJ (corresponding author), Weifang Vocat Coll, Sch Informat Engn, Weifang 261061, Peoples R China.; Liu, HJ (corresponding author), Technol Res Ctr Weifang, Modern Logist Informat Engn, Weifang 261041, Peoples R China.
EM smithliu@126.com
RI li, yan/GTI-4638-2022; li, chunyuan/IQW-1618-2023
OI Liu, Hongjun/0000-0003-4991-6696
FU National Natural Science Foundation of China [61363082, 61662073];
   Natural Science Foundation of Shandong Province [ZR2015FM019]; Natural
   Science Foundation of Weifang [2014ZJ1060]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61363082, 61662073), the Natural Science Foundation of
   Shandong Province (No: ZR2015FM019), and the Natural Science Foundation
   of Weifang (No. 2014ZJ1060).
CR Bernstein DJ, 2015, LECT NOTES COMPUT SC, V9056, P368, DOI 10.1007/978-3-662-46800-5_15
   Bernstein DJ, 2010, LECT NOTES COMPUT SC, V6061, P73, DOI 10.1007/978-3-642-12929-2_6
   Cafagna D, 2012, NONLINEAR DYNAM, V70, P1185, DOI 10.1007/s11071-012-0522-z
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   De Feo L, 2014, J MATH CRYPTOL, V8, P209, DOI 10.1515/jmc-2012-0015
   Delfs C, 2013, ARXIV13107789
   Gondal MA, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0017-4
   Hussain I, 2014, OPT LASER TECHNOL, V61, P50, DOI 10.1016/j.optlastec.2014.01.018
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Liu GY, 2014, COMPUT BIOL MED, V45, P111, DOI 10.1016/j.compbiomed.2013.11.010
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu YJ, 2013, MATH COMPUT MODEL, V57, P2473, DOI 10.1016/j.mcm.2012.12.006
   NYBERG K, 1991, LECT NOTES COMPUT SC, V547, P378
   Radhakrishnan SV, 2013, COMPUT ELECTR ENG, V39, P1006, DOI 10.1016/j.compeleceng.2012.11.019
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Sui LS, 2014, OPT EXPRESS, V22, P10605, DOI 10.1364/OE.22.010605
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Wang Y, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501278
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu Y., 2014, DCT DOMAIN IMAGE ENC, V556, P5168
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou Y, 2015, NONLINEAR DYNAM, V80, P1661, DOI 10.1007/s11071-015-2069-2
NR 29
TC 40
Z9 40
U1 2
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1391
EP 1407
DI 10.1007/s11042-016-4288-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400057
DA 2024-07-18
ER

PT J
AU Nandhini, SA
   Radha, S
   Kishore, R
AF Nandhini, S. Aasha
   Radha, S.
   Kishore, R.
TI Efficient compressed sensing based object detection system for video
   surveillance application in WMSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed Sensing; Background subtraction; MMD-ATS; WVSN; Energy;
   Network lifetime
AB Limited memory, energy and bandwidth are the major constraints in wireless visual sensor network (WVSN). Video surveillance applications in WVSN attracts a lot of attention in recent years which requires high detection accuracy and increased network lifetime that can be achieved by reducing the energy consumption in the sensor nodes. Compressed sensing (CS) based background subtraction plays a significant role in video surveillance application for detecting the presence of anomaly with reduced complexity and energy. This paper presents a system based on CS for single and multi object detection that can detect the presence of an anomaly with higher detection accuracy and minimum energy. A novel and efficient mean measurement differencing approach with adaptive threshold strategy is proposed for detection of the objects with less number of measurements, thereby reducing transmission energy. The performance of the system is evaluated in terms of detection accuracy, transmission energy and network lifetime. Furthermore, the proposed approach is compared with the conventional background subtraction approach. The simulation results show that the proposed approach yields better detection accuracy with 90% reduction in samples compared to conventional approach.
C1 [Nandhini, S. Aasha; Radha, S.; Kishore, R.] SSN Coll Engn, Dept ECE, Kalavakkam, India.
C3 SSN College of Engineering
RP Nandhini, SA (corresponding author), SSN Coll Engn, Dept ECE, Kalavakkam, India.
EM aasha.nandhu@gmail.com; radhas@ssn.edu.in; kishorer@ssn.edu.in
RI Rajendiran, Kishore/AGJ-8384-2022; Nandhini, Aasha/HCI-1483-2022
OI Rajendiran, Kishore/0000-0002-0779-6035; 
CR Amiri M., 2010, Measurements of energy consumption and execution time of different operations on Tmote Sky sensor nodes
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Cao YQ, 2012, AASRI PROC, V1, P480, DOI 10.1016/j.aasri.2012.06.075
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Jiang H, 2013, ARXIV13021942, P201
   Kang B, 2015, EURASIP J ADV SIG PR, V1, P1
   Manimozhi S, 2015, IEEE INT C COMM SIGN
   Smitha H., 2012, INT J COMPUT SCI ISS, V9
   Sukumaran AN, 2015, COMPUT ELECTR ENG, V44, P51, DOI 10.1016/j.compeleceng.2015.02.008
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Warnell G, 2012, INT CONF ACOUST SPEE, P1477, DOI 10.1109/ICASSP.2012.6288170
   Ye Y, 2013, IEEE ACCESS, V1, P646, DOI 10.1109/ACCESS.2013.2282613
   Zhang YZ, 2012, PROCEDIA ENGINEER, V29, P2705, DOI 10.1016/j.proeng.2012.01.376
   Zheng Yi, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P270, DOI 10.1109/ISKE.2010.5680866
NR 14
TC 10
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1905
EP 1925
DI 10.1007/s11042-017-4345-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400020
DA 2024-07-18
ER

PT J
AU Voo, KHB
   Bong, DBL
AF Voo, Kenny H. B.
   Bong, David B. L.
TI Quality assessment of stereoscopic image by 3D structural similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structural similarity; Stereoscopic images; Image quality assessment
ID BLUR ASSESSMENT; INTEGRATION; MODEL
AB Objective image quality assessment is proposed with the intention to substitute human-rated subjective evaluation by using computational method. Several types of two dimensional (2D) image quality metrics were proposed in the last decade to evaluate the quality of 2D images. When three dimensional (3D) or stereoscopic imaging gradually become popular in different areas of application, new objective quality assessments for 3D images had also been proposed. In this paper, a new method for assessing 3D image quality is proposed. This method is an improvement of the popular 2D structural similarity (SSIM) method with the addition of depth information to measure similarity between distorted and reference 3D images. The proposed method was tested on benchmark 3D image databases to gauge its performance. Experiment results show that predicted quality scores, as calculated from the proposed algorithm, are highly correlated with the corresponding subjective scores from manual evaluation. The significance and effectiveness of the proposed method were also evaluated by comparing its performance to other state-of-the-art 3D quality metrics.
C1 [Voo, Kenny H. B.; Bong, David B. L.] Univ Malaysia Sarawak, Fac Engn, Kota Samarahan 94300, Malaysia.
C3 University of Malaysia Sarawak
RP Bong, DBL (corresponding author), Univ Malaysia Sarawak, Fac Engn, Kota Samarahan 94300, Malaysia.
EM kennyvoo1989@gmail.com; davidblbong@yahoo.com
RI Bong, David/I-8735-2016
OI Bong, David/0000-0002-9027-8422
FU Ministry of Education Malaysia [FRGS/TK03(01)/1063/2013(09)]
FX The authors would like to acknowledge Ministry of Education Malaysia,
   for the provision of research grant: FRGS/TK03(01)/1063/2013(09) and
   Faculty of Engineering, Universiti Malaysia Sarawak for the provision of
   research facilities.
CR Akhter R, 2010, PROC SPIE, V7524, DOI 10.1117/12.838775
   [Anonymous], 2009, CISP
   [Anonymous], 2010, P INT WORKSH VID PRO
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bong DBL, 2014, IEICE T INF SYST, VE97D, P1864, DOI 10.1587/transinf.E97.D.1864
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Bong DBL, 2014, SIGNAL PROCESS-IMAGE, V29, P699, DOI 10.1016/j.image.2014.03.003
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Gorley Paul, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6803, P680305, DOI 10.1117/12.763530
   Hewage C.T. E. R., 2010, Future Network MobileSummit 2010 Conference Proceedings, P1
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Howard I. P., 1995, Binocular Vision and Stereopsis, DOI [10.1093/acprof:oso/9780195084764.001.0001, DOI 10.1093/ACPROF:OSO/9780195084764.001.0001]
   Jiang QP, 2017, MULTIMED TOOLS APPL, V76, P9405, DOI 10.1007/s11042-016-3548-2
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu XA, 2015, MULTIMED TOOLS APPL, V74, P2803, DOI 10.1007/s11042-013-1698-z
   Liu YJ, 2016, J CHEM-NY, V2016, DOI 10.1155/2016/6903524
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Voo KHB, 2015, IEEE ICCE, P220, DOI 10.1109/ICCE-TW.2015.7216865
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang XM, 2011, J BIOMED BIOTECHNOL, P1, DOI 10.1155/2011/419343
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Yang JC, 2016, INFORM SCIENCES, V373, P251, DOI 10.1016/j.ins.2016.09.004
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P3810, DOI 10.1109/TIP.2015.2456414
   Zhongjie Zhu, 2009, WSEAS Transactions on Signal Processing, V5, P241
NR 37
TC 10
Z9 10
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2313
EP 2332
DI 10.1007/s11042-017-4361-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400036
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Bai, J
   Liu, B
   Wang, L
   Jiao, LC
AF Bai, Jing
   Liu, Bin
   Wang, Lei
   Jiao, Licheng
TI PolSAR image compression based on online sparse K-SVD dictionary
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Polarimetric synthetic aperture radar (PolSAR);
   Sparse dictionary learning; Sparse representation
ID HIERARCHICAL TREES; ALGORITHM; REPRESENTATION
AB we present a novel polarimetric synthetic aperture radar (PolSAR) image compression scheme. PolSAR data contains lots of similar redundancies in single-channel and massively correlation between polarimetric channels. So these features make it difficult to represent PolSAR data efficiently. In this paper, discrete cosine transform (DCT) is adopted to remove redundancies between polarimetric channels, simple but quite efficient in improving compressibility. Sparse K-singular value decomposition (K-SVD) dictionary learning algorithm is utilized to remove redundancies within each channel image. Double sparsity scheme will be able to achieve fast convergence and low representation error by using a small number of sparsity dictionary elements, which is beneficial for the task of PolSAR image compression. Experimental results demonstrate that both numerical evaluation indicators and visual effect of reconstructed images outperform other methods, such as SPIHT, JPEG2000, and offline method.
C1 [Bai, Jing; Liu, Bin; Jiao, Licheng] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Lei] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Shandong, Peoples R China.
C3 Xidian University; University of Jinan
RP Bai, J (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
EM baijing@mail.xidian.edu.cn; xd_liubin@stu.xidian.edu.cn;
   ise_wanglei@ujn.edu.cn; lchjiao@mail.xidian.edu.cn
RI xu, mingyu/KMX-9517-2024; Jiao, Licheng/JOZ-0842-2023; bai,
   jing/IUP-9367-2023
OI Jiao, Licheng/0000-0003-3354-9617; 
FU China Postdoctoral Science Foundation [2012 T50799]; International
   Postdoctoral Exchange Fellowship Program by Office of China Postdoctoral
   Council [20130026]; Open Research Fund of Key Laboratory of Spectral
   Imaging Technology by Chinese Academy of Sciences
FX This work is supported by the China Postdoctoral Science Foundation
   Special funded project (No. 2012 T50799), the International Postdoctoral
   Exchange Fellowship Program 2013 by the Office of China Postdoctoral
   Council (No. 20130026) and the Open Research Fund of Key Laboratory of
   Spectral Imaging Technology by Chinese Academy of Sciences.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Horev I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P592
   HWANG K, 1989, IEEE T COMPUT, V38, P47, DOI 10.1109/12.8729
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Skretting K, 2011, INT CONF ACOUST SPEE, P1517
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhan X, 2013, IEEE IMAGE PROC, P1665, DOI 10.1109/ICIP.2013.6738343
   Zhan X, 2013, IEEE GEOSCI REMOTE S, V10, P1090, DOI 10.1109/LGRS.2012.2230394
NR 13
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24859
EP 24870
DI 10.1007/s11042-017-4640-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300016
DA 2024-07-18
ER

PT J
AU Ding, IJ
   Shi, JY
AF Ding, Ing-Jr
   Shi, Jia-Yi
TI Hybridized estimations of support vector machine free parameters
   <i>C</i> and γ using a fuzzy learning strategy for microphone
   array-based speaker recognition in a Kinect sensor-deployed environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Support vector machine; Fuzzy scheme; SVM free
   parameter; TDOA; Microphone-array
AB The support vector machine (SVM) is a popular classification model for speaker verification. However, although SVM is suitable for classifying speakers, the uncertain values of the free parameters C and gamma of the SVM model have been a challenging technique problem. An improper value set provided for the free parameter pair (C, gamma) can cause dissatisfactory performance in the recognition accuracy of speaker verification. Moreover, the sound source localization information of the collected acoustic data has a large effect on the recognition performance of SVM speaker verification. In response, this study developed a sound source localization-driven fuzzy scheme to help determine the optimal value set of (C, gamma) for the establishment of an SVM model. Specifically, this scheme adopts the estimated information of time difference of arrival (TDOA) derived from the Kinect microphone array (containing both the angle and distance information of the acoustic data of the speaker), to optimally calculate the value set of the SVM free parameters C and gamma. It was demonstrated that speaker verification using the SVM with a properly estimated parameter pair (C, gamma) is more accurate than that with only an arbitrarily given value set for the parameter pair (C, gamma) on recognition rate.
C1 [Ding, Ing-Jr; Shi, Jia-Yi] Natl Formosa Univ, Dept Elect Engn, 64,Wunhua Rd, Huwei Township 632, Yunlin, Taiwan.
C3 National Formosa University
RP Ding, IJ (corresponding author), Natl Formosa Univ, Dept Elect Engn, 64,Wunhua Rd, Huwei Township 632, Yunlin, Taiwan.
EM ingjr@nfu.edu.tw
FU Ministry of Science and Technology (MOST) in Taiwan [MOST
   103-2221-E-150-046]
FX This research is partially supported by the Ministry of Science and
   Technology (MOST) in Taiwan under Grant MOST 103-2221-E-150-046.
CR Burges CristopherJ. C., 1998, DATA MIN KNOWL DISC
   Ding IJ, 2017, COMPUT ELECTR ENG, V62, P719, DOI 10.1016/j.compeleceng.2015.12.010
   Ding IJ, 2016, ENG COMPUTATION, V33, P2489, DOI 10.1108/EC-02-2016-0076
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P15537, DOI 10.1007/s11042-015-2505-9
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P9669, DOI 10.1007/s11042-015-2782-3
   Ding IJ, 2016, SENSOR MATER, V28, P463
   Ding IJ, 2016, COMPUT ELECTR ENG, V49, P173, DOI 10.1016/j.compeleceng.2015.03.032
   Ding IJ, 2015, APPL MATH MODEL, V39, P5769, DOI 10.1016/j.apm.2014.12.054
   Ding IJ, 2014, INT J ENG TECHNOL IN, V4, P38
   Ding IJ, 2013, T CAN SOC MECH ENG, V37, P467, DOI 10.1139/tcsme-2013-0036
   Ding J., 2016, P ENG TECHNOL INNO, V3, P25
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hsu C.-W., 2003, TECH REP, DOI [DOI 10.1177/02632760022050997, 10 . 1177 / 02632760022050997]
   Ing-Jr Ding, 2015, Applied Mechanics and Materials, V764-765, P891, DOI 10.4028/www.scientific.net/AMM.764-765.891
   Qian K., 2013, Int. J. of Smart Home, V7, P203
   Su Chuan-Jun, 2013, International Journal of Information and Education Technology, V3, P448, DOI DOI 10.7763/IJIET.2013.V3.316
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Tashev I, 2013, IEEE SIGNAL PROC MAG, V30, P129, DOI 10.1109/MSP.2013.2266959
   Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042
   Villarreal-Q. José A., 2011, Polibotánica, P1
   Wu J, 2013, INT CONF ACOUST SPEE, P2371, DOI 10.1109/ICASSP.2013.6638079
   Wu MR, 2009, IEEE T PATTERN ANAL, V31, P2088, DOI 10.1109/TPAMI.2009.24
   Xu MQ, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING AND 2008 INTERNATIONAL PACIFIC WORKSHOP ON WEB MINING AND WEB-BASED APPLICATION, P422, DOI 10.1109/ISIP.2008.124
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zimmermann H.-J., 2001, Fuzzy Set Theory-and Its Applications, V4th
NR 25
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25297
EP 25319
DI 10.1007/s11042-017-4499-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300042
DA 2024-07-18
ER

PT J
AU El-Bendary, MAM
AF El-Bendary, Mohsen A. M.
TI FEC merged with double security approach based on encrypted image
   steganography for different purpose in the presence of noise and
   different attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filtering attacks; Channel coding; Median filter; Encrypted LSB
   steganography; Image encryption; Metrics
AB In this research paper, robust and reliable encrypted steganography technique with the error control schemes is presented. It also, investigates the performance of this technique with existing different noises and attacks. The paper presents a powerful security algorithm through merging between the data hiding and encryption techniques. This security merging technique aims to improve and strengthen the image security through its transmission over a wireless channel. Error performance of the presented security algorithm is considered also, and the different error control schemes are utilized to encode the transmitted packets. The steganography conceals the data existence within a cover medium, while the encryption hides the data meaning by using specific algorithms. The chaos based encryption algorithms are considered efficient and secured image encryption algorithms. In this research work a confidential image is embedded into a cover image using the data hiding Least Significant Bit (LSB) Steganography technique and then the stego image is encrypted using two dimensional chaotic map encryption tool. The Logistic map and Chaotic Baker map encryption techniques are utilized for this purpose to produce a multi-level high secure algorithm for sensitive secret image transmission. The computer simulation experiments reveal that the chaotic Baker scenario resist the noise and attacks more than another scenario. The Median filter is utilized to enhance the extracted message quality in existence the Pepper-Salt noise. The encrypted stego signal performance is evaluated over the AWGN channel and different attacks. To improve the extraction of Logistic steganography, the FEC is employed for this purpose and to decrease the required SNR which permits the successfully embedded image extraction. These different error control techniques are utilized to improve the presented algorithm reliability over the wireless channels. There are several metrics are used to measure the extracted images quality such as the correlation coefficient, mean square error, and peak signal to noise ratio. Also, the number of lost packet is used as data loss attack and to evaluate the wireless link efficiency. Different image analyses and comparisons are verified to examine the suitability of proposed algorithms for securing a high sensitive image data through its transmission over wireless channel at different noise levels.
C1 [El-Bendary, Mohsen A. M.] Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Modern Sciences & Arts
   University (MSA)
RP El-Bendary, MAM (corresponding author), Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
EM engmohsen2004@yahoo.com
RI El-Bendary, Mohsen A. M./P-8567-2019
OI El-Bendary, Mohsen A. M./0000-0002-2425-4967
CR ABOUELFADL AA, 2014, LIFE SCI J, V11, P342
   Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   [Anonymous], 2013, IOSR J COMPUTER ENG, DOI DOI 10.9790/0661-1254954
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Choudhary K, 2012, GLOB SECUR STUD, V3
   El-Bendary MA, 2015, DEV SECURITY TOOLS W
   El-Bendary MAMM, INT J ELECT, V99, P1497
   El-Bendary MAMM, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-4
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Goel S., 2013, INT J COMPUTERS DIST, V3, P20
   Johnson N.F., 1998, IEEE Transactions on Image Processing., V31, P26, DOI [DOI 10.1109/MC.1998.4655281, 10.1109/MC.1998.4655281]
   Juneja M., 2009, INT C ADV REC TECHN
   Kamal AHM, 2013, INT J COMPUT TECHNOL, V4
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu JF, 2015, DIGIT SIGNAL PROCESS, V38, P66, DOI 10.1016/j.dsp.2014.12.004
   Mehta AM, 2008, 2 INT S ADV NETW TEL
   Ming C, 2006, INT C INT INF HID MU
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Nassar SS, 2016, WIRELESS PERS COMMUN, V216, P1
   Neeta D, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P173
   Owens M., 2002, A discussion of covert channels and steganography
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pareek NK, 2006, SCIENCEDIRECT IMAGE
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Raja KB, 2005, IEEE07803958830
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Silva AE, 2007, SPIE P MOBILE MULTIM, V6579, P3
   Soliman NF, 2014, WIRELESS PERS COMMUN, V79, P2141, DOI 10.1007/s11277-014-1977-7
   Srividya G, 2011, C COMM SIGN PROC, P266
   Udhayavene S, 2015, PROCEDIA COMPUT SCI, V54, P790, DOI 10.1016/j.procs.2015.06.093
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
NR 37
TC 17
Z9 18
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26463
EP 26501
DI 10.1007/s11042-016-4177-5
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500043
DA 2024-07-18
ER

PT J
AU Rashid, U
   Bhatti, MA
AF Rashid, Umer
   Bhatti, M. Afzal
TI A framework to explore results in multiple media information aggregated
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aggregated search; Architecture; Framework; Multimedia documents; Media
   objects; Results exploration; Search result space
ID MULTIMEDIA SEARCH; IMAGE RETRIEVAL; FEATURES; BEHAVIOR
AB On web information exists in the form of text, audio, image, and video objects often referred to multiple media objects. Vertical web search provides the search of multiple media information usually via keyword-based queries. The search results in different media formats usually presented in separate panels/tabs; integration is mostly non-blended. Therefore, results exploration via vertical web search engines require the selection of a source and scrolling of a linear ranked list of results. Relationships in the results presented in separate panels/tabs are mostly not considered. Search aggregations unify results from several vertical web sources via blended integration, but exploration still requires scrolling of a linear ranked list. Multimedia search frameworks provide the exploration of results in different media formats but more focused towards the retrieval issues. We proposed a multiple media information search framework to address issues, particularly in aggregated search. Our search framework provides a mechanism to explore results via non-linear ways. The search framework realized by suggesting a framework architecture design and instantiating a search tool. The effectiveness of blended integration and browsing is measured via precision and click through rate respectively. Search task support in results exploration mechanism measured via task-based evaluation. We also validated the conformance of various search/exploration attributes discussed in the state-of-the-art in our frameworks.
C1 [Rashid, Umer; Bhatti, M. Afzal] Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Rashid, U (corresponding author), Quaid I Azam Univ, Dept Comp Sci, Islamabad 45320, Pakistan.
EM umerrashid@qau.edu.pk; mabhatti@qau.edu.pk
RI Rashid, Umer/AAI-7228-2020
OI Rashid, Umer/0000-0002-3453-7979
CR [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], 2011, ISO/IEC/IEEE 42010:2011
   [Anonymous], ACM CIVR
   [Anonymous], P ACM WORKSH CONT AR
   [Anonymous], 2004, INT COMPUTER SCI SER
   [Anonymous], 2009, P 18 INT C WORLD WID
   Arguello Jaime, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P25, DOI 10.1007/978-3-319-16354-3_3
   Axenopoulos A., 2011, P 16 INT C 3D WEB TE, P51
   Axenopoulos Apostolos., 2012, The Future Internet, P130
   Bozzon A, 2010, LECT NOTES COMPUT SC, V5950, P135, DOI 10.1007/978-3-642-12310-8_8
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cechticky V, 2003, LECT NOTES COMPUT SC, V2830, P267
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chechik G., 2008, P 1 ACM INT C MULT I, P105, DOI DOI 10.1145/1460096.1460115
   Chen X, 2012, IEEE T MULTIMEDIA, V14, P3, DOI 10.1109/TMM.2011.2167223
   Chen YX, 2013, IEEE T KNOWL DATA EN, V25, P2257, DOI 10.1109/TKDE.2012.192
   Cheng WG, 2002, 2002 IEEE REGION 10 CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND POWER ENGINEERING, VOLS I-III, PROCEEDINGS, P586, DOI 10.1109/TENCON.2002.1181343
   Crnkovic I, 2011, IEEE T SOFTWARE ENG, V37, P593, DOI 10.1109/TSE.2010.83
   Daras Petros, 2011, International Journal of Multimedia Intelligence and Security, V2, P351, DOI 10.1504/IJMIS.2011.044765
   Dias R, 2015, MULTIMED TOOLS APPL, V74, P3691, DOI 10.1007/s11042-013-1794-0
   Golovchinsky G., 2012, Proceedings of the 4th information interaction in context symposium, P52, DOI DOI 10.1145/2362724.2362738
   Hakkoymaz V, 2010, MULTIMED TOOLS APPL, V47, P477, DOI 10.1007/s11042-009-0334-4
   Hanjalic A, 2012, INT J MULTIMED INF R, V1, P139, DOI 10.1007/s13735-012-0019-z
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   James N, 2011, SEM MULTIMED, P95
   Jiang W, 2012, INT J MULTIMED INF R, V1, P223, DOI 10.1007/s13735-012-0020-6
   Kalamaras I., 2013, J ELECT LETT COMPUTE, V12, P28
   Kaszkiel M, 2001, J AM SOC INF SCI TEC, V52, P344, DOI 10.1002/1532-2890(2000)9999:9999<::AID-ASI1075>3.0.CO;2-#
   Kiktova-Vozarikova E, 2015, MULTIMED TOOLS APPL, V74, P4213, DOI 10.1007/s11042-013-1529-2
   Kim J, 2009, J AM SOC INF SCI TEC, V60, P679, DOI 10.1002/asi.21035
   Kopliku, 2009, P 6 FRENCH C INF RET, P495
   Kopliku A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523817
   Lauer Claire, 2009, Computers and Composition, V26, P225, DOI 10.1016/j.compcom.2009.09.001
   Lazaridis M, 2013, SIGNAL PROCESS-IMAGE, V28, P351, DOI 10.1016/j.image.2012.04.001
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Li LS, 2011, MULTIMED TOOLS APPL, V54, P55, DOI 10.1007/s11042-010-0540-0
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Luo HZ, 2011, MULTIMED TOOLS APPL, V51, P625, DOI 10.1007/s11042-010-0639-3
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Mathias I, 2004, J SYST SOFTWARE, V73, P333, DOI 10.1016/j.jss.2003.10.029
   Mitrovic D, 2010, ADV COMPUT, V78, P71, DOI 10.1016/S0065-2458(10)78003-7
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Normark CJ, 2015, INT J HUM-COMPUT INT, V31, P731, DOI 10.1080/10447318.2015.1045240
   Özacar T, 2016, INFORM SYST, V56, P36, DOI 10.1016/j.is.2015.09.002
   Perry D. E., 1992, SIGSOFT Software Engineering Notes, V17, P40, DOI 10.1145/141874.141884
   Pinto-Caceres Sheila M., 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P335, DOI 10.1007/978-3-319-14445-0_29
   Rafailidis D, 2013, PATTERN RECOGN, V46, P3358, DOI 10.1016/j.patcog.2013.05.023
   Rashid U, 2016, INFORM SCIENCES, V370, P303, DOI 10.1016/j.ins.2016.07.072
   Rashid U, 2010, ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P129, DOI 10.1007/978-90-481-3660-5_22
   Rashid U, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1067, DOI 10.1109/ITNG.2009.8
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Richards M, 2015, Software Architecture Patterns
   Rigamonti M, 2007, LECT NOTES COMPUT SC, V4662, P102
   Rizzo G., 2012, P 2012 INT WORKSH SO, P15
   Schraefel M., 2005, Proceedings of the sixteenth ACM conference on Hypertext and hypermedia, P174
   Seifert C, 2014, IEEE INT CONF INF VI, P94, DOI 10.1109/IV.2014.49
   Shokouhi M, 2011, FOUND TRENDS INF RET, V5, P1, DOI 10.1561/1500000010
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.50
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Steiner T, 2012, P 21 INT C COMP WORL, P291
   Sushmita S, 2009, P WORKSH WEB SEARCH
   Sushmita S, 2012, COMMUNICATION
   Sushmita S, 2009, LECT NOTES COMPUT SC, V5721, P322, DOI 10.1007/978-3-642-03784-9_32
   Sushmita Shanu, 2010, P 19 ACM INT C INF K, P519
   Thanh-Huy Le, 2012, Database Systems for Advanced Applications. Proceedings of the 17th International Conference, DASFAA 2012, P33, DOI 10.1007/978-3-642-29038-1_5
   Tullis T.S., 2004, Usability professional association conference, V1, DOI 10.1.1.396.3677
   Vrochidis S, 2010, WORLD PAT INF, V32, P94, DOI 10.1016/j.wpi.2009.05.010
   White RW., 2009, SYNTHESIS LECT INFOR, DOI [10.2200/S00174ED1V01Y200901ICR003, DOI 10.2200/S00174ED1V01Y200901ICR003]
   Wilson TD, 1999, J DOC, V55, P249, DOI 10.1108/EUM0000000007145
   Yang J, 2001, LECT NOTES COMPUT SC, V2195, P482
   Yang J, 2002, P 11 INT C WORLD WID, P54, DOI DOI 10.1145/511446.511454
   Yang Y, 2010, PATTERN RECOGN, V43, P2927, DOI 10.1016/j.patcog.2010.02.015
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 75
TC 9
Z9 9
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25787
EP 25826
DI 10.1007/s11042-017-4769-8
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500015
DA 2024-07-18
ER

PT J
AU Suh, W
   Henclewood, D
   Guin, A
   Guensler, R
   Hunter, M
   Fujimoto, R
AF Suh, Wonho
   Henclewood, Dwayne
   Guin, Angshuman
   Guensler, Randall
   Hunter, Michael
   Fujimoto, Richard
TI Dynamic data driven transportation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data driven application systems; Real-time simulation; Transportation
   simulation; Distributed simulation
AB Congestion-induced delays and pollution in modern transportation systems remain formidable impediments to the sustainable growth of our cities. Next generation Intelligent Transportation Systems (ITS) will attack these problems by relying on extensive in-vehicle sensing, crowd-sourced data, ubiquitous computing, and communications to augment existing infrastructure-based deployments. Advances in wireless networking and mobile computing have made it possible to create dynamic, data driven application systems (DDDAS) that address many challenges in modern transportation systems. We outline a vision for future dynamic data-driven transportation systems, and focus on the effectiveness of an approach to real-time management based on online simulations. The online simulations are embedded in the traffic network where distributed simulators perform the modeling task individually but project the future states collectively. A real-time data driven arterial simulation methodology is proposed to assist such computations that are performed over a testbed in the midtown area of Atlanta, Georgia. Field results are presented that provide evidence to validate the proposed approach.
C1 [Suh, Wonho] Hanyang Univ, 55 Hanyangdaehak Ro, Ansan 15588, South Korea.
   [Henclewood, Dwayne] Booz Allen Hamilton, Boston, MA USA.
   [Guin, Angshuman; Guensler, Randall; Hunter, Michael] Georgia Inst Technol, Civil & Environm Engn, Atlanta, GA 30332 USA.
   [Fujimoto, Richard] Georgia Inst Technol, Computat Sci & Engn, Atlanta, GA 30332 USA.
C3 Hanyang University; Booz Allen Hamilton Holding Corporation; University
   System of Georgia; Georgia Institute of Technology; University System of
   Georgia; Georgia Institute of Technology
RP Suh, W (corresponding author), Hanyang Univ, 55 Hanyangdaehak Ro, Ansan 15588, South Korea.
EM wonhosuh@hanyang.ac.kr; henclewood_dwayne@bah.com;
   angshuman.guin@ce.gatech.edu; randall.guensler@ce.gatech.edu;
   michael.hunter@ce.gatech.edu; fujimoto@cc.gatech.edu
RI Guin, Angshuman/AAE-9224-2021; Guensler, Randall/L-4627-2019
OI Guin, Angshuman/0000-0001-6949-5126; Guensler,
   Randall/0000-0003-2204-7427
FU NSF [CNS-0540160]; AFOSR [FA9550-13-1-0100]; Transportation & Logistics
   Research Program [ID-97344];  [NRF-2014R1A1A2054793]; Directorate For
   Engineering; Div Of Electrical, Commun & Cyber Sys [1462503] Funding
   Source: National Science Foundation
FX The authors gratefully acknowledge supported for their DDDAS research
   under NSF grant CNS-0540160 and AFOSR grant FA9550-13-1-0100. Also,
   Wonho Suh's work was supported by NRF-2014R1A1A2054793 and
   Transportation & Logistics Research Program ID-97344.
CR Allen G, 2007, LECT NOTES COMPUT SC, V4487, P1034
   Bechler M, 2003, KIVS KURZBEITRAGE, P107
   Chaturvedi A, 2006, LECT NOTES COMPUT SC, V3993, P433
   Cortial J, 2007, LECT NOTES COMPUT SC, V4487, P1171
   Douglas CC, 2006, PROCEEDINGS OF THE 2006 WINTER SIMULATION CONFERENCE, VOLS 1-5, P2117, DOI 10.1109/WSC.2006.323011
   Farhat C, 2006, LECT NOTES COMPUT SC, V3993, P456
   Fujimoto R. M., 2007, PRINCIPLES ADV DISTR
   Kamrani F, 2007, IEEE ACM DIS SIM, P167, DOI 10.1109/DS-RT.2007.23
   Knight D, 2007, LECT NOTES COMPUT SC, V4487, P1189
   Low M.Y. H., 2005, P 4 INT JOINT C AUTO, P85
   Madey GR, 2007, LECT NOTES COMPUT SC, V4487, P1090
   Mandel J, 2005, LECT NOTES COMPUT SC, V3515, P632
   Mandel J., 2012, P INT C COMP SCI
   Morsink P, 2002, DESIGN APPL COMMUNIC
   Patra AK, 2012, P INT C COMP SCI
   Rahman A., 2004, 2004 International Workshop on Wireless Ad-Hoc Networks (IEEE Cat. No. 05EX789), P73
   Schrank D., 2015, Appendix A: Methodology for the 2015 urban mobility scorecard
   Suh W, 2014, SIMUL MODEL PRACT TH, V41, P1, DOI 10.1016/j.simpat.2013.11.002
   Tian J., 2002, TECHNICAL REPORT
   Werner J, 2004, USDOT OUTLINES NEW 7
   Wischhof L, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P6, DOI 10.1109/IVS.2003.1212873
   Wu H., 2004, P 1 ACM INT WORKSHOP, P47, DOI DOI 10.1145/1023875.1023884
   Ye T, 2008, IEEE ACM T NETWORK, V16, P777, DOI 10.1109/TNET.2008.2001729
NR 23
TC 7
Z9 7
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25253
EP 25269
DI 10.1007/s11042-016-4318-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300039
DA 2024-07-18
ER

PT J
AU Ding, Y
   Xu, Z
   Zhang, YB
   Sun, K
AF Ding, Yong
   Xu, Zheng
   Zhang, Yubin
   Sun, Ke
TI Fast lane detection based on bird's eye view and improved random sample
   consensus algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bird's eye view; Lane detection; Random sample consensus
AB In order to ensure the safety of drivers, Advanced Driving Assistance System (ADAS) has drawn more and more attention. The Lane Departure Warning system is one of the most important parts of ADAS. However, fast and stable lane marking detection is the precondition of it under complex background. In this paper, we proposed a new lane detection method through bird's eye view and improved RANSAC (Random Sample Consensus) algorithm based on the inspiration that extraction of road features from remote sensed images. According to the bird's eye view of the road image, we can recognize the line marking through Progressive Probabilistic Hough transform instead of lane detection. Then, the detected lines are grouped by a new distance-based weighting scheme and we can get the fields of candidate lanes. For each of the fields, lanes are refined through improved RANSAC algorithm and fitted by double models. Hence, the road orientation can be predicted by the curvature and straight line's slope. At last, our experimental results indicated that the lane detection algorithm has good robustness and real-time under various road environment.
C1 [Ding, Yong] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
   [Xu, Zheng] Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
   [Zhang, Yubin; Sun, Ke] Guilin Univ Elect Technol, Sch Math & Comp Sci, Guilin, Peoples R China.
C3 Guilin University of Electronic Technology; Ministry of Public Security
   (China); Guilin University of Electronic Technology
RP Xu, Z (corresponding author), Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
EM xuzheng@shu.edu.cn
RI Zhang, Yubin/GPP-7134-2022
OI Zhang, Yubin/0000-0002-9227-7394
FU Guangxi Natural Science Foundation [2014GXNSFCA118014]; Innovation of
   Guangxi Graduate Education [XJYC2012020]
FX This research has been funded by Guangxi Natural Science Foundation
   Project No. 2014GXNSFCA118014, Innovation of Guangxi Graduate Education
   No. XJYC2012020
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen QG, 2006, ICPASM 2005: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PROPERTIES AND APPLICATIONS OF DIELECTRIC MATERIALS, VOLS 1 AND 2, P510
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Collado Hilario C, 2005, IEEE INT VEH S GOLD, P7883
   Fan C, 2016, MULTIMED TOOLS APPL, V75, P12201, DOI 10.1007/s11042-015-3004-8
   Galamhos C, 1999, P COMPUTER VISION PA, P23
   Ge YQ, 2010, INT CONF COMP SCI, P134, DOI 10.1109/ICCSIT.2010.5563646
   Hsiao PY, 2006, 2006 I E 63 VEH TEC, V6, P2982
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Jung Gap Kuk, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1344, DOI 10.1109/ITSC.2010.5625121
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Lim KH, 2009, INT C INTEL HUM MACH, P351, DOI 10.1109/IHMSC.2009.211
   Massimo B, 1998, IMAGE VISION COMPUT, V16, P585
   Peden M, 2013, GLOBAL PLAN DECADE A, P1
   Richard OD, 1972, GRAPHICS IMAGE PROCE, V15, P11
   Ryosuke O, 2014, VLSI DES AUT TEST VL, V4, P1
   Sibel Y, 2013, ACM COMPUT SURV, V46, P1
   Son J, 2015, EXPERT SYST APPL, V42, P1816, DOI 10.1016/j.eswa.2014.10.024
   Sun T.-Y., 2006, IEEE INTELL TRANSP S, P1168, DOI DOI 10.1109/ITSC.2006.1707380
   Wang JG, 2010, EXPERT SYST APPL, V37, P113, DOI 10.1016/j.eswa.2009.05.026
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Weina Lu, 2008, 2008 Workshop on Knowledge Discovery and Data Mining (WKDD '08), P649, DOI 10.1109/WKDD.2008.119
   Xu Z, 2006, MULTIMED TOOLS APPL, V75, P12155
   Xu Z, 2016, CONCURR COMP-PRACT E, V28, P4038, DOI 10.1002/cpe.3780
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0553-0
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
NR 30
TC 20
Z9 24
U1 3
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22979
EP 22998
DI 10.1007/s11042-016-4184-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200056
DA 2024-07-18
ER

PT J
AU Ghahfarokhi, BS
   Moghim, N
   Eftekhari, S
AF Ghahfarokhi, Behrouz Shahgholi
   Moghim, Neda
   Eftekhari, Shayan
TI Reducing channel zapping time in live TV broadcasting over content
   centric networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information centric networking; TV broadcast; Channel zapping;
   In-network caching; Video quality
ID IPTV; DELAY
AB Channel zapping delay is a big challenge in delivering TV service over the Internet infrastructure. Previous research works have studied this delay, its components, and solutions to decrease it. Unfortunately, the best proposed solutions reduce the delay at the expense of increasing bandwidth usage or decreasing the received video quality. After channel switching, the Set Top Box (STB) or player application should buffer sufficient frames before starting to play the received video. However, the buffering process takes place at the playback rate and leads to a delay which is inversely related to the buffer duration. Regarding Information Centric Networking (ICN) paradigm, this paper introduces a new channel zapping protocol that aims to remove the synchronization and buffering delays while maintaining the bandwidth utilization and also the received video quality. The general idea of the proposed solution is to exploit the in-network caching feature of the ICN to retrieve the frames from the network at the network speed. Although the analyses show that the proposed zapping protocol eliminates the delay dependency to the buffer duration, network throughput becomes the bottleneck instead. So, novel solutions have been proposed to reduce the queuing delay as the main component of network delay. These solutions include two new caching algorithms, a new cache replacement algorithm, and applying scheduling methods to the forwarding queues. Simulation results show that increasing link rates, using the proposed caching and cache replacement algorithms, and applying an appropriate scheduling method will greatly reduce the zapping delay without sacrificing the bandwidth or video quality.
C1 [Ghahfarokhi, Behrouz Shahgholi; Moghim, Neda; Eftekhari, Shayan] Univ Isfahan, Fac Comp Engn, Dept Informat Technol Engn, Esfahan, Iran.
C3 University of Isfahan
RP Ghahfarokhi, BS (corresponding author), Univ Isfahan, Fac Comp Engn, Dept Informat Technol Engn, Esfahan, Iran.
EM shahgholi@eng.ui.ac.ir; n.moghim@eng.ui.ac.ir; eftekhari@eng.ui.ac.ir
RI Ghahfarokhi, Behrouz Shahgholi/AAI-5859-2020
OI Shahgholi Ghahfarokhi, Behrouz/0000-0001-9768-8793
CR Abdullahi I, 2015, J NETW COMPUT APPL, V56, P48, DOI 10.1016/j.jnca.2015.06.011
   Ahmad MZ, 2009, INT CONF EMERG TECHN, P466, DOI 10.1109/ICET.2009.5353126
   Amadeo M, 2013, COMPUT COMMUN, V36, P792, DOI 10.1016/j.comcom.2013.01.006
   [Anonymous], 2011, Proceedings of the ACM SIGCOMM workshop on Information-centric networking
   Ardissono L., 2004, USER MODELING RECOMM
   Arumaithurai M., 2014, Proceedings of the 1st ACM Conference on Information-Centric Networking, P107
   Begen A. C., 2009, 6 IEEE CONS COMM NET, P1
   Bejerano Y, 2009, IEEE INFOCOM SER, P1971, DOI 10.1109/INFCOM.2009.5062119
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   Ciancaglini V, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P982, DOI 10.1109/WAINA.2013.19
   Dannewitz C, 2013, COMPUT COMMUN, V36, P721, DOI 10.1016/j.comcom.2013.01.009
   Detti A, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3583, DOI 10.1109/PIMRC.2013.6666771
   Eftekhari S, 2015, P 7 IEEE INT C INF K, P1
   Fuchs H, 2008, IEEE INT SYM BROADB, P81
   Han B., 2013, IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), P375
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   Kim Y, 2008, IEEE INT SYM BROADB, P94
   Kooij R, 2006, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS AND NETWORKS, P155
   Koponen T, 2007, ACM SIGCOMM COMP COM, V37, P181, DOI 10.1145/1282427.1282402
   Kyryk M, 2012, P INT C MOD PROBL RA
   Lederer S, 2013, IEEE INT CONF COMM, P677, DOI 10.1109/ICCW.2013.6649319
   Lee J, 2007, LECT NOTES COMPUT SC, V4773, P235
   Lee S, 2011, IEEE T CONSUM ELECTR, V57, P1135, DOI 10.1109/TCE.2011.6018866
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Li ZH, 2011, PROBAB APPL SER, P1, DOI 10.1007/978-3-642-15004-3_1
   Liu YN, 2013, IEEE ICC, P3629, DOI 10.1109/ICC.2013.6655116
   Mandal SK, 2008, TECH REP
   Oh U, 2010, IEEE T CONSUM ELECTR, V56, P483, DOI 10.1109/TCE.2010.5505959
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Qiu TQ, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P430
   Rainer B, 2016, IEEE J SEL AREA COMM, V34, P1
   Ramos FMV, 2013, IEEE COMMUN MAG, V51, P128, DOI 10.1109/MCOM.2013.6576350
   Ramos FMV, 2011, SIGNAL PROCESS-IMAGE, V26, P400, DOI 10.1016/j.image.2011.03.005
   Ramos FMV, 2010, IEEE INT CON MULTI, P1327, DOI 10.1109/ICME.2010.5583279
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Sun WQ, 2008, IEEE T BROADCAST, V54, P419, DOI 10.1109/TBC.2008.2000281
   Tian XH, 2013, IEEE T PARALL DISTR, V24, P327, DOI 10.1109/TPDS.2012.94
   Xylomenos G, 2014, IEEE COMMUN SURV TUT, V16, P1024, DOI 10.1109/SURV.2013.070813.00063
NR 38
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23239
EP 23271
DI 10.1007/s11042-016-4037-3
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700006
DA 2024-07-18
ER

PT J
AU Albalawi, U
   Mohanty, SP
   Kougianos, E
AF Albalawi, Umar
   Mohanty, Saraju P.
   Kougianos, Elias
TI A new region aware invisible robust blind watermarking approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Blind watermarking; Invisible watermarking; Robust
   watermarking; DCT domain; DWT domain
AB The multimedia revolution has made a strong impact on our society. The explosive growth of Internet access to this digital information has generated new opportunities and challenges. The ease of editing and duplicating information in the digital domain has created copyright protection concerns for content providers. Various schemes to embed secondary data in digital media have been investigated to preserve copyright and to discourage unauthorized duplication. In order to achieve the required level of protection to digital information, digital watermarking is a viable solution. This paper proposes a novel invisible watermarking scheme: a Discrete Cosine Transform (DCT) domain based watermark embedding and blind extraction algorithm for copyright protection of color images. The proposed algorithm is optimized in terms of robustness, computational load, and quality of the image. Testing of the proposed watermarking scheme's robustness and security via different benchmarks as well as comparison with a DiscreteWavelet Transform (DWT) approach proves its resilience to digital attacks. The results show that the Peak Signal to Noise Ratio (PSNR) value obtained under no attack conditions in the proposed algorithm is above 41.81 dB, which is higher than most of the existing watermark algorithms. The results from the detector's response also show that the proposed algorithm has a better security performance than most of the existing algorithms. The architecture for hardware implementation of the proposed algorithm is also presented and the results from the architecture show a PSNR value of 44.37 dB. This verifies that the presented algorithm is more effective than existing algorithms such as image adaptive watermarking, image adaptive watermark creation, zerotree wavelet, and 9/7 biorthogonal wavelet lifting.
C1 [Albalawi, Umar; Mohanty, Saraju P.] Univ North Texas, Comp Sci & Engn, Denton, TX 76203 USA.
   [Kougianos, Elias] Univ North Texas, Engn Technol, Denton, TX 76203 USA.
C3 University of North Texas System; University of North Texas Denton;
   University of North Texas System; University of North Texas Denton
RP Mohanty, SP (corresponding author), Univ North Texas, Comp Sci & Engn, Denton, TX 76203 USA.
EM UmarAlbalawi@my.unt.edu; saraju.mohanty@unt.edu; elias.kougianos@unt.edu
RI Kougianos, Elias/AAU-7560-2020
OI Kougianos, Elias/0000-0002-1616-7628
CR Abdelhakim AM, 2016, IET IMAGE PROCESS, V10, P247, DOI 10.1049/iet-ipr.2015.0379
   [Anonymous], 2004, P 2004 WORKSHOP MULT
   [Anonymous], 2014, IND C INDICON 2014 A
   [Anonymous], THESIS
   Bansal N, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P40
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Chen L.G., 2007, VLSI DESIGN WAVELET
   Choi BC, 2005, 7TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P1085, DOI 10.1109/ICACT.2005.246147
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dhar N., 2010, PNAS Early Edition, P1
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Ghosh S, 2015, 2015 INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN, COMPUTER NETWORKS & AUTOMATED VERIFICATION (EDCAV), P72, DOI 10.1109/EDCAV.2015.7060542
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Iyer R, 2014, SADHANA-ACAD P ENG S, V39, P1357, DOI 10.1007/s12046-014-0288-8
   Kakkirala KR, 2014, 2014 IEEE 10TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2014), P58, DOI 10.1109/CSPA.2014.6805720
   Kaur A., 2012, International Journal of Engineering Research and DevelopmentISSN, V1, P49
   KHALFALLAH A, 2006, 2 INT C INF COMM TEC, P01145
   Lavoué G, 2007, COMPUT GRAPH-UK, V31, P480, DOI 10.1016/j.cag.2007.01.022
   Le NT, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P479, DOI 10.1109/ICOIN.2016.7427164
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lin YJ, 2005, IEEE DATA COMPR CONF, P113
   Liu XY, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1779
   Liu ZB, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P843
   Mohanty SP, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413865
   Mohanty SP, 2011, J SYST SOFTWARE, V84, P724, DOI 10.1016/j.jss.2010.12.012
   Mohanty SP, 2007, I SYMP CONSUM ELECTR, P42
   Munoz-Ramirez DO, 2015, P EUR WORKSH URB DAT, P1, DOI [10.1109/ICEEE.2015.7357955, DOI 10.2312/UDMV.20151341]
   Music J, 2015, 2015 4TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO), P315, DOI 10.1109/MECO.2015.7181932
   Pathak Y., 2014, P INT C ADV ENG TECH, P1
   Betancourth GP, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-7, P579, DOI 10.1109/ISIE.2006.295523
   PIPER A, 2005, P 7 WORKSH MULT SEC, P79, DOI DOI 10.1145/1073170.1073186
   Qiao XH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P63
   Safabakhsh R, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P671, DOI 10.1109/ITCC.2004.1286543
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Yen JC, 2006, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P474
   Zaboli S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1687, DOI 10.1109/ISIE.2007.4374858
   Zong TR, 2016, IEEE ACCESS, V4, P1689, DOI 10.1109/ACCESS.2016.2556723
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 49
TC 5
Z9 5
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21303
EP 21337
DI 10.1007/s11042-016-4063-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400045
DA 2024-07-18
ER

PT J
AU Bhartiya, G
   Jalal, AS
AF Bhartiya, Gunjan
   Jalal, Anand Singh
TI Forgery detection using feature-clustering in recompressed JPEG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recompression; Forgery detection; JPEG images
ID EXPOSING DIGITAL FORGERIES
AB JPEG images are widely used in a large range of applications. The properties of JPEG compression can be used for detection of forgery in digital images. The forgery in JPEG images requires the image to be resaved thereby, re-compression of image. Therefore, the traces of recompression can be identified in order to detect manipulation. In this paper, a method to detect forgery in JPEG image is presented and an algorithm is designed to classify the image blocks as forged or non-forged based on a particular feature present in multi-compressed JPEG images. The method performs better than the previous methods which use the probability based approach for detecting forgery in JPEG images.
C1 [Bhartiya, Gunjan; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM gunjan.bhartiya@gla.ac.in; anandsinghjalal@gmail.com
OI Jalal, Anand/0000-0002-7469-6608
CR Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   DeCarlo LT, 1997, PSYCHOL METHODS, V2, P292, DOI 10.1037/1082-989X.2.3.292
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Li W, 2008, P INT WORKSH LOC NON, P121
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Mahdian B, 2009, P 3 INT C IM CRIM DE, P12
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
NR 16
TC 11
Z9 12
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20799
EP 20814
DI 10.1007/s11042-016-3964-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400019
DA 2024-07-18
ER

PT J
AU Guo, C
   Yuan, QQ
   Lu, K
   Li, MC
   Fu, ZJ
AF Guo, Cheng
   Yuan, Qiongqiong
   Lu, Kun
   Li, Mingchu
   Fu, Zhangjie
TI (t, n) Threshold secret image sharing scheme with adversary structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversary structure; Secret image sharing; (t, n) threshold; Distortion
   free
ID SMALLER SHADOW IMAGES; STEGANOGRAPHY; AUTHENTICATION
AB Secret image sharing has been researched intensively, and it has emerged as an alternative to data hiding for protecting the security and privacy of important data. In the traditional (t, n) threshold secret image sharing schemes, any t or more shadow images can reconstruct the shared secret image. However, in real applications, (t, n) threshold access structures cannot meet all of the requirements, such as the adversary structure, which means that unauthorized groups of participants cannot reconstruct the shared secret. Thus, in (t, n) threshold secret sharing with adversary structure, t participants who want to reconstruct the secret cannot do so if they happen to belong to the defined adversary structure. This novel characteristic has the potential to work in many applications. However, the existing secret image sharing mechanisms cannot achieve the adversary structure. To solve this problem, we proposed a secret image sharing scheme that can achieve the adversary structure. In addition, our scheme also is a (t, n) threshold secret image sharing scheme. That is, t or more shadow images can be used to reconstruct the secret image, but some subsets that contain at least t shadow images among the adversary structures cannot reconstruct the secret image. The experimental results showed that the validity of our scheme is satisfactory.
C1 [Guo, Cheng; Yuan, Qiongqiong; Lu, Kun; Li, Mingchu] Dalian Univ Technol, Sch Software Technol, Dalian 116620, Peoples R China.
   [Guo, Cheng; Yuan, Qiongqiong; Lu, Kun; Li, Mingchu] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
   [Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Dalian University of Technology; Nanjing University of Information
   Science & Technology
RP Guo, C (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian 116620, Peoples R China.; Guo, C (corresponding author), Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
EM guocheng@dlut.edu.cn
OI Li, Mingchu/0000-0001-8280-2936; Guo, Cheng/0000-0001-7489-7381
FU National Science Foundation of China [61401060, 61501080, 61572095];
   general program of Liaoning Provincial Department of Education Science
   Research [L2014017]; Fundamental Research Funds for the Central
   Universities' [DUT16QY09]
FX This paper is supported by the National Science Foundation of China
   under grant No. 61401060, 61501080 and 61572095, the general program of
   Liaoning Provincial Department of Education Science Research under
   grants L2014017, and the Fundamental Research Funds for the Central
   Universities' under No. DUT16QY09.
CR BENALOH J, 1989, LECT NOTES COMPUTER, P213
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   CHANG CC, 1993, IEEE J SEL AREA COMM, V11, P725, DOI 10.1109/49.223873
   Guo C, 2015, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-2885-x, DOI 10.1007/S11042-015-2885-X]
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Guo YB, 2004, J COMPUT SCI TECH-CH, V19, P564, DOI 10.1007/BF02944759
   Ito M., 1987, PROC IEEE GLOB TELEC, P99
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Ma TH, 2015, IEICE T INF SYST, VE98D, P902, DOI 10.1587/transinf.2014EDP7283
   Naor M., 1995, P ADV CRYPT EUROCRYP, V950, P1
   Pang Liaojun, 2006, Journal of Computer Research and Development, V43, P33, DOI 10.1360/crad20060106
   Qin HW, 2009, INT J INF SECUR, V8, P379, DOI 10.1007/s10207-009-0085-2
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu S-J, 2008, P 25 WORKSH COMB MAT, P24
   Tan KJ, 1999, COMPUT COMMUN, V22, P755, DOI 10.1016/S0140-3664(99)00041-9
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Xia Z., 2016, MULTIMED TOOLS APPL, V75, P1
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhao DW, 2012, COMPUT MATH APPL, V64, P611, DOI 10.1016/j.camwa.2011.12.067
NR 30
TC 11
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21193
EP 21210
DI 10.1007/s11042-016-4065-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400039
DA 2024-07-18
ER

PT J
AU Kim, JM
   Choi, SB
AF Kim, Jin Min
   Choi, Suk Bong
TI An integrated application of Kano's model and AHP to Korean online open
   market services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online open market; Service quality; Kano model; AHP analysis; O2O
   commerce
ID WORD-OF-MOUTH; INFORMATION-SYSTEMS SUCCESS; MULTIPLE-ITEM SCALE;
   E-COMMERCE; SOCIAL COMMERCE; REPURCHASE INTENTION; CUSTOMER LOYALTY;
   FUZZY AHP; QUALITY; SATISFACTION
AB With the advancement in wireless and mobile technologies, online open markets decrease intermediate distribution margins and play the key intermediary role between sellers and consumers. While offline store sales remain stagnant, online open market sales have been growing steadily. We investigated the service quality of Korean online open market providers such as "Gmarket", "Auction", and "11st", based on an integrated application of Kano's model and the Analytic Hierarchy Process (AHP). The contributions of this study are as follows: (1) We conducted acritical review of previous literature to develop each analysis method. (2) We categorized the service quality factors of the Korean open market using Kano's model and identified the most important service quality factor by AHP analysis. (3) Then, we conducted a comparison between the results from the Kano model and AHP analysis. (4) Lastly, based on the results of the integrated application of both Kano model and AHP analysis, this study provided specific implications for improving the service quality of the online open market in Korea.
C1 [Kim, Jin Min; Choi, Suk Bong] Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong City 339700, South Korea.
C3 Korea University
RP Choi, SB (corresponding author), Korea Univ, Coll Business & Econ, 2511 Sejong Ro, Sejong City 339700, South Korea.
EM tristan1031@korea.ac.kr; sukchoi@korea.ac.kr
RI Kim, Jinmin/JXN-2852-2024
OI Kim, Jinmin/0000-0002-8881-365X
CR Alroaia Y, 2012, AFR J BUS MANAGE, V6, P7727
   Alroaia YV, 2011, J MOD ACCOUNT AUDIT, V7, P1097
   Amblee N, 2011, INT J ELECTRON COMM, V16, P91, DOI 10.2753/JEC1086-4415160205
   Anderson P, 2002, MIT SLOAN MANAGE REV, V43, P53
   Anderson RE, 2003, PSYCHOL MARKET, V20, P123, DOI 10.1002/mar.10063
   Badri MA, 2001, INT J PROD ECON, V72, P27, DOI 10.1016/S0925-5273(00)00077-3
   Barnes R.T., 2002, J ELECTRON COMMER RE, V3, P114, DOI DOI 10.1016/J.IM.2006.06.001
   Bauk SI, 2015, PROCD SOC BEHV, V191, P323, DOI 10.1016/j.sbspro.2015.04.393
   Bucklin RE, 2009, J INTERACT MARK, V23, P35, DOI 10.1016/j.intmar.2008.10.004
   Büyüközkan G, 2012, EXPERT SYST APPL, V39, P2341, DOI 10.1016/j.eswa.2011.08.061
   Büyüközkan G, 2011, EXPERT SYST APPL, V38, P9407, DOI 10.1016/j.eswa.2011.01.103
   Chow C.C., 2005, MANAG SERV QUAL, V15, P278, DOI DOI 10.1108/09604520510597827
   Collier JE, 2006, J SERV RES-US, V8, P260, DOI 10.1177/1094670505278867
   Cox J., 2001, MANAG SERV QUAL, V11, P121, DOI DOI 10.1108/09604520110387257
   Cristobal E., 2007, MANAG SERV QUAL, V17, P317, DOI [10.1108/09604520710744326, DOI 10.1108/09604520710744326]
   DeLone WH, 2004, INT J ELECTRON COMM, V9, P31, DOI 10.1080/10864415.2004.11044317
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   Doherty NF, 2015, J RETAIL CONSUM SERV, V27, P52, DOI 10.1016/j.jretconser.2015.07.002
   Fang YL, 2014, MIS QUART, V38, P407, DOI 10.25300/MISQ/2014/38.2.04
   Ghinea G, 2004, MULTIMED TOOLS APPL, V22, P187, DOI 10.1023/B:MTAP.0000011934.59111.b5
   Hajli N, 2014, INT J MARKET RES, V56, P673, DOI 10.2501/IJMR-2014-045
   Hemati M., 2011, MANAGEMENT SCI LETT, V1, P263
   Huang EY, 2015, ELECTRON COMMER R A, V14, P126, DOI 10.1016/j.elerap.2015.01.003
   Huang Z, 2013, ELECTRON COMMER R A, V12, P246, DOI 10.1016/j.elerap.2012.12.003
   Huiskonen J, 1998, INT J PROD ECON, V56-7, P253, DOI 10.1016/S0925-5273(97)00065-0
   Jeong HY, 2014, MULTIMED TOOLS APPL, V73, P887, DOI 10.1007/s11042-013-1445-5
   Jun Minjoon., 2001, INT J BANK MARK, V19, P276, DOI [DOI 10.1108/02652320110409825, 10.1108/02652320110409825, https://doi.org/10.1108/02652320110409825]
   Kahraman C, 2004, INT J PROD ECON, V87, P171, DOI 10.1016/S0925-5273(03)00099-9
   Kano N., 1984, J JPN SOC QUALITY CO J JAPANESE SOC QUALI, V41, P39
   Kassim N, 2010, ASIA PAC J MARKET LO, V22, P351, DOI 10.1108/13555851011062269
   Kazemi M, 2013, ADV RES EC MANAG SCI, V8, P11
   Keeney RL, 1999, MANAGE SCI, V45, P533, DOI 10.1287/mnsc.45.4.533
   Kim S, 2013, INT J INFORM MANAGE, V33, P318, DOI 10.1016/j.ijinfomgt.2012.11.006
   Korea On-Line Shopping Association, 2014, ONL SHOPP MARK OUTL
   Koufteros X, 2014, DECISION SCI, V45, P5, DOI 10.1111/deci.12056
   Kuo YF, 2004, TOTAL QUAL MANAG BUS, V15, P925, DOI 10.1080/14783360410001681854
   Lee GG, 2005, INT J RETAIL DISTRIB, V33, P161, DOI 10.1108/09590550510581485
   Lee Y, 2006, DECIS SUPPORT SYST, V42, P1383, DOI 10.1016/j.dss.2005.11.005
   Li YL, 2009, EXPERT SYST APPL, V36, P7045, DOI 10.1016/j.eswa.2008.08.036
   Lin HH, 2006, INFORM MANAGE-AMSTER, V43, P271, DOI 10.1016/j.im.2005.08.001
   Lu HP, 2010, INFORM MANAGE-AMSTER, V47, P150, DOI 10.1016/j.im.2010.01.003
   Lu YF, 2012, J ELECTRON COMMER RE, V13, P224
   Michaelidou N, 2011, IND MARKET MANAG, V40, P1153, DOI 10.1016/j.indmarman.2011.09.009
   Mikulic J, 2011, MANAG SERV QUAL, V21, P46, DOI 10.1108/09604521111100243
   Min S, 2005, J BUS RES, V58, P1030, DOI 10.1016/j.jbusres.2004.02.005
   Momani A., 2014, Engineering Management Research, V3, P68, DOI DOI 10.5539/EMR.V3N1P68
   Nilsson-Witell L, 2005, INT J SERV IND MANAG, V16, P152, DOI 10.1108/09564230510592289
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   Parasuraman A, 2005, J SERV RES-US, V7, P213, DOI 10.1177/1094670504271156
   Piercy N, 2014, J MARKET MANAG-UK, V30, P747, DOI 10.1080/0267257X.2013.839571
   Rotter P, 2012, MULTIMED TOOLS APPL, V60, P573, DOI 10.1007/s11042-011-0828-8
   Saaty T., 1980, The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation
   Santos J., 2003, MANAG SERV QUAL, V13, P233, DOI [DOI 10.1108/09604520310476490, 10.1108/09604520310476490]
   See-To EWK, 2014, COMPUT HUM BEHAV, V31, P182, DOI 10.1016/j.chb.2013.10.013
   Sobihah M., 2015, Mediterranean Journal of Social Sciences, V6, P260
   Srinivasan SS, 2002, J RETAILING, V78, P41, DOI 10.1016/S0022-4359(01)00065-3
   Tan K.C., 2001, MANAG SERV QUAL, V11, P418, DOI DOI 10.1108/EUM0000000006520
   Trusov M, 2009, J MARKETING, V73, P90, DOI 10.1509/jmkg.73.5.90
   Tsay AA, 2004, PROD OPER MANAG, V13, P93, DOI 10.1111/j.1937-5956.2004.tb00147.x
   Wang C, 2012, COMMUN ASSOC INF SYS, V31, P105
   Wen C, 2011, J COMPUT INFORM SYST, V52, P14
   Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4
   Wu YCJ, 2015, COMPUT HUM BEHAV, V51, P1395, DOI 10.1016/j.chb.2014.10.001
   [杨祖元 Yang Zuyuan], 2002, [重庆大学学报, Journal of Chongqing University], V25, P19
   Yen C.-H., 2008, MANAG SERV QUAL, V18, P127, DOI DOI 10.1108/09604520810859193
   Yoo B., 2001, Quarterly Journal of Electronic Commerce, V2, P31, DOI DOI 10.1007/978-3-319-11885-7_129
   Zeithaml V.A., 2002, MANAG SERV QUAL, V12, P135
   Zeithaml VA, 2002, J ACAD MARKET SCI, V30, P362, DOI 10.1177/009207002236911
   Zhang YX, 2011, INFORM MANAGE-AMSTER, V48, P192, DOI 10.1016/j.im.2011.05.003
NR 69
TC 8
Z9 9
U1 2
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19621
EP 19634
DI 10.1007/s11042-016-3323-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500018
DA 2024-07-18
ER

PT J
AU Yang, TH
   Yu, B
   Wang, HJ
   Li, JQ
   Lv, ZH
AF Yang, Tonghao
   Yu, Bin
   Wang, Hengjun
   Li, Junquan
   Lv, Zhihan
TI Cryptanalysis and improvement of Panda - public auditing for shared data
   in cloud and internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Cloud computing; Shared data; Privacy preserving;
   Public auditing; Internet of things
ID EFFICIENT USER REVOCATION
AB Cloud computing and internet of things have gained remarkable popularity by a wide spectrum of users recently. Despite of the convenience of cloud storage, security challenges have risen upon the fact that users do not physically possess their data any more. Thus, some auditing schemes are introduced to ensure integrity of the outsourced data. And among them Panda is a public auditing scheme for shared data with efficient and secure user revocation proposed by Wang et al. It argued that it could verify the integrity of shared data with storage correctness and public auditing. In this paper, we analyze this scheme and find some security drawbacks. Firstly, Panda cannot preserve shared data privacy in cloud storage. Furthermore, our analysis shows that Panda is vulnerable to integrity forgery attack, which can be performed by malicious cloud servers to forge a valid auditing proof against any auditing challenge even without correct data storage. Then we pinpoint that the primary cause of the insecurity is the linear combinations of sampled data blocks without random masking properly. Finally, we propose an improvement of Panda together with data privacy preserving and sound public auditing while incurring optimal communication and computation overhead.
C1 [Yang, Tonghao] Zhengzhou Inst Informat Sci & Technol, Informat Secur, Zhengzhou, Henan, Peoples R China.
   [Yu, Bin; Wang, Hengjun; Li, Junquan] Zhengzhou Inst Informat Sci & Technol, Zhengzhou, Henan, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Yang, TH (corresponding author), Zhengzhou Inst Informat Sci & Technol, Informat Secur, Zhengzhou, Henan, Peoples R China.; Lv, ZH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM youngtonghao@163.com; byu2009@163.com; wanghengjun@163.com;
   junquanli2014@163.com; webvr@vip.qq.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU school innovation foundation; doctorial foundation [2014JY170]
FX This work was supported by the school innovation foundation and the
   doctorial foundation under grant 2014JY170. We thank the anonymous
   reviewers for useful comments and suggestions.
CR Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Bian CY, 2015, IEEE INT WORKS LOCAL
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Boneh D, 2004, J CRYPTOL, V17, P297, DOI 10.1007/s00145-004-0314-9
   Che L., 2015, Smart Grid, IEEE Transactions on, VPP, P1
   Chen Z, 2016, MULTIMED TOOLS APPL
   Dang SP, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON ENVIRONMENT AND ELECTRICAL ENGINEERING (EEEIC), P323, DOI 10.1109/EEEIC.2014.6835887
   Gu W, 2016, MULTIMED TOOLS APPL
   Jiang D, 2015, J COMMUN NETW
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT ELECTR ENG, V37, P1106, DOI 10.1016/j.compeleceng.2011.06.009
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Juels A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P584
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu S, 2015, MULTIMED TOOLS APPL
   Lv Z, 2015, PERS UBIQUIT COMPUT
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Nan XF, 2010, IEEE INT C BIOINFORM, P520, DOI 10.1109/BIBM.2010.5706621
   Ou W, 2015, 2015 IE INT C SYST M
   Shacham H, 2008, LECT NOTES COMPUT SC, V5350, P90, DOI 10.1007/978-3-540-89255-7_7
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Tate Stephen R., 2013, P 3 ACM C DAT APPL S, P353, DOI DOI 10.1145/2435349.2435400
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang B, 2013, P IEEE ICC 13 BUD HU
   Wang B, 2013, 2013 IEEE INTERNATIONAL WORKSHOP ON ELECTROMAGNETICS (IWEM): APPLICATIONS AND STUDENT INNOVATION COMPETITION, P124, DOI 10.1109/iWEM.2013.6888788
   Wang BY, 2015, IEEE T SERV COMPUT, V8, P92, DOI 10.1109/TSC.2013.2295611
   Wang BY, 2013, IEEE INFOCOM SER, P2904
   Wang BY, 2014, IEEE T CLOUD COMPUT, V2, P43, DOI [10.1109/TCC.2014.2299807, 10.1109/CLOUD.2012.46]
   Wang K, 2015, P IEEE INT C CLUST C
   Wang K, 2015, CONCURRENCY COMPUTAT
   Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183
   Wang Y, 2015, P 27 INT C SCI STAT, V4
   Worku SG, 2014, COMPUT ELECTR ENG, V40, P1703, DOI 10.1016/j.compeleceng.2013.10.004
   Xu CX, 2012, COMM COM INF SC, V308, P422
   Yang J, 2016, MULTIMED TOOLS APPL
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Yang K, 2013, IEEE T PARALL DISTR, V24, P1717, DOI 10.1109/TPDS.2012.278
   Zhang S, 2014, IEEE IMAGE PROC, P2724, DOI 10.1109/ICIP.2014.7025551
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
   Zhang X, 2013, IEEE DECIS CONTR P, P6798, DOI 10.1109/CDC.2013.6760966
NR 43
TC 13
Z9 14
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19411
EP 19428
DI 10.1007/s11042-015-3139-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500005
DA 2024-07-18
ER

PT J
AU Jothi, JAA
   Rajam, VMA
AF Jothi, Angel Arul J.
   Rajam, Mary Anita, V
TI Automatic classification of thyroid histopathology images using
   multi-classifier system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer aided diagnosis (CAD); Multi-classifier systems;
   Histopathology; Thyroid; Classification; Segmentation
ID FOLLICULAR LESIONS; DIAGNOSIS SYSTEM; CARCINOMA; NODULES; BENIGN
AB A computer aided diagnosis system supports doctors by providing quantitative diagnostic clues from medical data. In this paper, we propose a computer aided diagnosis (CAD) system to automatically discriminate hematoxylin and eosin (H&E)-stained thyroid histopathology images either as normal thyroid (NT) images or as papillary thyroid carcinoma (PTC) images. The CAD system incorporates a multi-classifier system to maximize the diagnostic accuracy of classification. Thyroid histopathology images are provided as input to the CAD system. The input images are enhanced and the nuclei present in the images are segmented automatically. Shape and texture features are extracted from the segmented images. Classification of the features is studied using classifiers such as support vector machine (SVM), naive Bayes (NB), K-nearest neighbor (K-nn) and closest matching rule (CMR) either as stand alone classifiers or as combinations to form multi-classifier systems. The multi-classifier system which provides the best accuracy is found out experimentally. The CAD system thus formed can be used as a second opinion to assist pathologists.
C1 [Jothi, Angel Arul J.; Rajam, Mary Anita, V] Anna Univ, Coll Engn Guindy, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; College of Engineering Guindy
RP Rajam, VMA (corresponding author), Anna Univ, Coll Engn Guindy, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
EM jothi@cs.annauniv.edu; anitav@annauniv.edu
RI Rajam, Mary Anita/AAR-5031-2021; J, Angel Arul Jothi/AAE-3549-2020
OI J, Angel Arul Jothi/0000-0002-1773-8779
CR Al-Brahim N, 2006, ARCH PATHOL LAB MED, V130, P1057
   Belsare AD., 2012, Image Processing, V3, P23, DOI DOI 10.5121/SIPIJ.2012.3403
   Chen C, 2013, CYTOM PART A, V83A, P495, DOI 10.1002/cyto.a.22280
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   DASARATHY BV, 1991, PATTERN RECOGN LETT, V12, P497, DOI 10.1016/0167-8655(91)80014-2
   Daskalakis A, 2008, COMPUT BIOL MED, V38, P196, DOI 10.1016/j.compbiomed.2007.09.005
   Demir C, 2005, Technical report
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Gopinath B, 2015, TECHNOL CANCER RES T, V14, P653, DOI 10.7785/tcrt.2012.500430
   Gopinath B, 2010, PROCEDIA COMPUT SCI, V2, P265, DOI 10.1016/j.procs.2010.11.034
   Gopinath B, 2013, AUSTRALAS PHYS ENG S, V36, P219, DOI 10.1007/s13246-013-0199-8
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang H, 2014, PATTERN RECOGN LETT, V42, P115, DOI 10.1016/j.patrec.2014.02.008
   Huang PW, 2009, IEEE T MED IMAGING, V28, P1037, DOI 10.1109/TMI.2009.2012704
   Jothi AA, 2016, APPL SOFT COMPUT, V46, P652, DOI 10.1016/j.asoc.2016.02.030
   Jothi J, 2014, ADV INTELLIGENT SOFT, V325, P835
   Jothi JAA, 2017, ARTIF INTELL REV, V48, P31, DOI 10.1007/s10462-016-9494-6
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kulkarni RV, 2010, IEEE T SYST MAN CY C, V40, P663, DOI 10.1109/TSMCC.2010.2049649
   LiVolsi VA, 2011, MODERN PATHOL, V24, pS1, DOI 10.1038/modpathol.2010.129
   Lloyd RV, 2011, HEAD NECK PATHOL, V5, P51, DOI 10.1007/s12105-010-0236-9
   National Cancer Institute, 2016, NAT CANC I CANC TOP
   Norman J, 2015, INCIDENCE TYPES THYR
   Norman J, 2015, THYROID CANC SYMPTOM
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ozolek JA, 2014, MED IMAGE ANAL, V18, P772, DOI 10.1016/j.media.2014.04.004
   PAWLAK Z, 1995, COMMUN ACM, V38, P89, DOI 10.1145/219717.219791
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Scopa Chrisoula D, 2004, Hormones (Athens), V3, P100
   Sridhar S., 2011, Digital Image Processing'
   Wang W, 2010, CYTOM PART A, V77A, P485, DOI 10.1002/cyto.a.20853
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
NR 36
TC 10
Z9 11
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18711
EP 18730
DI 10.1007/s11042-017-4363-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800027
DA 2024-07-18
ER

PT J
AU Yi, Y
   Wang, HL
   Zhang, BW
AF Yi, Yun
   Wang, Hanli
   Zhang, Bowen
TI Learning correlations for human action recognition in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Late fusion; Learning correlations; Multiple
   features
ID ROBUST; REPRESENTATION; CLASSIFICATION; FUSION
AB Human action recognition in realistic videos is an important and challenging task. Recent studies demonstrate that multi-feature fusion can significantly improve the classification performance for human action recognition. Therefore, a number of researches utilize fusion strategies to combine multiple features and achieve promising results. Nevertheless, previous fusion strategies ignore the correlations of different action categories. To address this issue, we propose a novel multi-feature fusion framework, which utilizes the correlations of different action categories and multiple features. To describe human actions, this framework combines several classical features, which are extracted with deep convolutional neural networks and improved dense trajectories. Moreover, massive experiments are conducted on two challenging datasets to evaluate the effectiveness of our approach, and the proposed approach obtains the state-of-the-art classification accuracy of 68.1 % and 93.3 % on the HMDB51 and UCF101 datasets, respectively. Furthermore, the proposed approach achieves better performances than five classical fusion schemes, as the correlations are used to combine multiple features in this framework. To the best of our knowledge, this work is the first attempt to learn the correlations of different action categories for multi-feature fusion.
C1 [Yi, Yun; Wang, Hanli; Zhang, Bowen] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
   [Yi, Yun; Wang, Hanli; Zhang, Bowen] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
   [Yi, Yun] Gannan Normal Univ, Dept Math & Comp Sci, Ganzhou 341000, Peoples R China.
C3 Tongji University; Tongji University; Gannan Normal University
RP Wang, HL (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.; Wang, HL (corresponding author), Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
EM hanliwang@tongji.edu.cn
RI Wang, Hanli/G-5111-2014; Wang, Hanli/K-5717-2019; Yi, Yun/O-8432-2018
OI Wang, Hanli/0000-0002-9999-4871; Wang, Hanli/0000-0002-9999-4871; Yi,
   Yun/0000-0002-5644-8002
FU National Natural Science Foundation of China [61622115, 61472281];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning [GZ2015005]; Science and
   Technology Projects of education bureau of Jiangxi province of China
   [GJJ151001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61622115 and Grant 61472281, the Program
   for Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning (No. GZ2015005), and the Science and
   Technology Projects of education bureau of Jiangxi province of China
   (No. GJJ151001).
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2015, CORR
   [Anonymous], 2016, APPL COMPUTER VISION, DOI DOI 10.1109/WACV.2016.7477589
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   Ballan L, 2012, IEEE T MULTIMEDIA, V14, P1234, DOI 10.1109/TMM.2012.2191268
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen M, 2016, MULTIMED TOOLS APPL, V75, P10335, DOI 10.1007/s11042-015-3008-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hoai M., 2014, Asian Conference on Computer Vision, P3, DOI DOI 10.1007/978-3-319-16814-21
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai KT, 2015, IEEE T IMAGE PROCESS, V24, P2772, DOI 10.1109/TIP.2015.2423560
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587
   Li L, 2016, MULTIMEDIA IN PRESS
   Lin CJ, 2007, J MACH LEARN RES, V9, P561, DOI DOI 10.1145/1273496.1273567
   Liu C, 2016, MULTIMED TOOLS APPL, V75, P13023, DOI 10.1007/s11042-015-2550-4
   Ma TY, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P323, DOI 10.1109/ICCVW.2013.50
   Mironica I, 2016, MULTIMED TOOLS APPL, V75, P9045, DOI 10.1007/s11042-015-2819-7
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Vogt C. C., 1999, Information Retrieval, V1, P151, DOI 10.1023/A:1009980820262
   Wang H, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1175, DOI 10.1145/2733373.2806310
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wu D, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P945, DOI 10.1145/2647868.2654969
   Wu SL, 2009, INFORM PROCESS MANAG, V45, P413, DOI 10.1016/j.ipm.2009.02.003
   Xin Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1590, DOI 10.1109/ICPR.2010.393
   Xu HY, 2016, MULTIMED TOOLS APPL, V75, P5701, DOI 10.1007/s11042-015-2536-2
   Ye GN, 2012, PROC CVPR IEEE, P3021, DOI 10.1109/CVPR.2012.6248032
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 46
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18891
EP 18913
DI 10.1007/s11042-017-4416-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800035
DA 2024-07-18
ER

PT J
AU Shi, ZH
   Xu, BX
   Zheng, X
   Zhao, MH
AF Shi, Zhenghao
   Xu, Binxin
   Zheng, Xia
   Zhao, Minghua
TI A Chinese character structure preserved denoising method for Chinese
   tablet calligraphy document images based on KSVD dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dividing-frequency denoising; KSVD; Butterworth lowpass filter;
   Connected region; Ergodic method; Tablet image denoising
AB As an art form, Chinese ancient calligraphy tablet works occupy an important position in the heritage of Chinese culture. However, because of natural or man-made decay, there appear lots of noises in these ancient tablet works images, which have an important effect on the quality of the tablet images. To address this problem, a character structure preserved denoising method based on KSVD dictionary learning was proposed in this paper. This new proposed method consists of two major operations: dividing-frequency denoising and ant-like noises removal in binary image. At the stage of dividing-frequency denosing, the Butterworth low pass filter was employed to filter and extract low frequency part of the images firstly. Then, KSVD dictionary learning algorithm was used for smoothing the high frequency image and extracting image edges and the extracted edge images was then fused with the denoised low frequency part of the images. At the stage of ant-like noises removal, the fused image is converted into a binary one firstly. Then, the connected region method is employed to remove isolated ant-like noise; ergodic method is used to fill holes of strokes. Finally strokes thorn was eliminated by using the median filter. Experimental results demonstrate that the proposed method can effectively remove most image noise (including various block noise, linear noise and ant-like noise) and preserve characters better than existing methods.
C1 [Shi, Zhenghao; Xu, Binxin; Zhao, Minghua] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Zheng, Xia] Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
C3 Xi'an University of Technology; Zhejiang University
RP Shi, ZH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.; Zheng, X (corresponding author), Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou 310028, Zhejiang, Peoples R China.
EM ylshi@xaut.edu.cn; zhengxia@zju.edu.cn
FU National Natural Science Foundation of China [61202198, 61401355]; China
   Scholarship Council [201608610048]; Key Laboratory Foundation of Shaanxi
   Education Department, China [14JS072]; Nature Science Foundation of
   Science Department of PeiLin count at Xi'an [GX1619]
FX This work was supported in part by a grant from the National Natural
   Science Foundation of China (No. 61202198, No. 61401355), a grant from
   the China Scholarship Council (No. 201608610048), the Key Laboratory
   Foundation of Shaanxi Education Department, China (No. 14JS072), and the
   Nature Science Foundation of Science Department of PeiLin count at
   Xi'an(GX1619). The authors gratefully acknowledge the helpful comments
   and suggestions of the reviewers.
CR Aharon M, 2006, LINEAR ALGEBRA APPL, V416, P48, DOI 10.1016/j.laa.2005.06.035
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, IEEE T IMAGE PROCESS
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Butterworth S., 1930, EXP WIREL WIREL ENG, V7, P536
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Dabov K, 2007, SIGN PROC C 2007 EUR, P2080
   Dabov K, 2006, ELECT IMAGING, P354
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Guemri K, 2014, SOFT COMP PATT REC, P839
   Koga T, 2008, ELE COM ENG, P87
   Li H., 2015, NOVEL NONLOCAL MEANS
   LIN HM, 1988, IEEE T CIRCUITS SYST, V35, P675, DOI 10.1109/31.1805
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nguyen H T, 2010, INT C INF SCI SIGN P, P468
   Pati Y., 1995, C RECORD 27 ASILOMAR, V1, P1
   Shi ZH, 2016, MULTIMED TOOLS APPL, V75, P12245, DOI 10.1007/s11042-016-3421-3
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tukey J. M., 1971, EXPLORATORY DATA ANA
   Wang S Z, 2001, ICDAR 01, P271
   Zhang Jun-song, 2006, Journal of Zhejiang University (Science), V7, P1178, DOI 10.1631/jzus.2006.A1178
   Zheng X, 2016, MULTIMED TOOLS APPL, V75, P8719, DOI 10.1007/s11042-015-2788-x
NR 25
TC 12
Z9 13
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14921
EP 14936
DI 10.1007/s11042-016-4284-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400021
DA 2024-07-18
ER

PT J
AU Yan, XS
   Song, T
   Wu, QH
AF Yan, Xuesong
   Song, Tao
   Wu, Qinghua
TI An improved cultural algorithm and its application in image matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural algorithm; Isolation niche technology; Population; Image
   matching
ID ADAPTIVE DIFFERENTIAL EVOLUTION; OPTIMIZATION; NETWORKS
AB Cultural Algorithm (CA) are a class of computational models derived from observing the cultural evolution process in nature and is used to solve complex calculations of the new global optimization search algorithms. Aiming at the traditional cultural algorithm has poor precision and trap into local optimum of global optimization. In this paper, introduce the isolation niche technology into the traditional cultural algorithm. With improvements, the algorithm is less likely to trap in local optimum. According to the test of one set of benchmark function, the proposed algorithm has greater improvements than ordinal cultural algorithm in the aspects of convergence precision and stability. In this paper, introduce the proposed algorithm into the image matching problem, and the simulation test shows that the algorithm for image matching problem has made great effects in stability and convergence precision.
C1 [Yan, Xuesong] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
   [Song, Tao] China Univ Geosci, Ctr Network & Educ Technol, Wuhan 430074, Hubei, Peoples R China.
   [Wu, Qinghua] WuHan Inst Technol, Fac Comp Sci & Engn, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences; China University of Geosciences; Wuhan
   Institute of Technology
RP Wu, QH (corresponding author), WuHan Inst Technol, Fac Comp Sci & Engn, Wuhan 430074, Hubei, Peoples R China.
EM wuqinghua@sina.com
FU National Natural Science Foundation of China [41404076, 61402425,
   61501412, 61673354, 61672474]
FX This paper is supported by National Natural Science Foundation of China
   (No. 41404076, 61402425, 61501412, 61673354, 61672474).
CR Ali MZ, 2016, KNOWL-BASED SYST, V111, P73, DOI 10.1016/j.knosys.2016.08.005
   [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   [Anonymous], 1997, THESIS
   [Anonymous], 2019, THESIS DALIAN U TECH
   BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767
   Goldbeg D., 1989, GENETIC ALGORITHMS S
   Gong WY, 2015, IEEE T EVOLUT COMPUT, V19, P746, DOI 10.1109/TEVC.2015.2449293
   Gong WY, 2015, ENERGY, V86, P139, DOI 10.1016/j.energy.2015.03.117
   Gong WY, 2015, IEEE T CYBERNETICS, V45, P716, DOI 10.1109/TCYB.2014.2334692
   Gong WY, 2014, APPL SOFT COMPUT, V15, P149, DOI 10.1016/j.asoc.2013.11.005
   Gong WY, 2011, IEEE T SYST MAN CY B, V41, P397, DOI 10.1109/TSMCB.2010.2056367
   Haldar V, 2015, INT T ELECTR ENERGY, V25, P54, DOI 10.1002/etep.1820
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hu CY, 2015, AD HOC NETW, V35, P116, DOI 10.1016/j.adhoc.2015.07.011
   Jarraya SK, 2016, MULTIMED TOOLS APPL, V75, P10949, DOI 10.1007/s11042-015-2818-8
   Jia XB, 2016, MULTIMED TOOLS APPL, V75, P1099, DOI 10.1007/s11042-014-2359-6
   Li CH, 2015, INFORM SCIENCES, V296, P95, DOI 10.1016/j.ins.2014.10.062
   Lin Z, 2016, MULTIMED TOOLS APPL, V75, P2189, DOI 10.1007/s11042-014-2401-8
   Nam Y, 2016, MULTIMED TOOLS APPL, V75, P7003, DOI 10.1007/s11042-015-2625-2
   Nian FD, 2016, MULTIMED TOOLS APPL, V75, P2435, DOI 10.1007/s11042-015-2472-1
   Reynolds R.G., 1994, P 3 ANN C EVOLUTIONA, P131, DOI DOI 10.1142/9789814534116
   Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu Q., 2014, J. Chem. Pharmaceutical Res., V6, P271
   Xie SD, 2014, WIRELESS PERS COMMUN, V78, P231, DOI 10.1007/s11277-014-1748-5
   Yan L., 2000, SYST ENG J, V15, P86
   Yan X., 2015, METALL MIN IND, V7, P877
   Yan X, 2012, INT J COMPUT SCI ISS, V9, P11
   Yan X, 2013, INT J ADV COMPUTING, P122
   Yan X., 2015, SENSOR LETT, V13, P127
   Yan XS, 2012, J COMPUT INF TECHNOL, V2, P152
   Yan XS, 2016, J COMPUT METHODS SCI, V16, P379, DOI 10.3233/JCM-160625
   Yan XS, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416500130
   Yang M, 2015, IEEE T CYBERNETICS, V45, P302, DOI 10.1109/TCYB.2014.2339495
   Zadeh PM, 2016, IEEE C EVOL COMPUTAT, P4405, DOI 10.1109/CEC.2016.7744350
   Zadeh PM, 2015, PROCEDIA COMPUT SCI, V52, P342, DOI 10.1016/j.procs.2015.05.105
NR 36
TC 20
Z9 20
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14951
EP 14968
DI 10.1007/s11042-016-4313-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400023
DA 2024-07-18
ER

PT J
AU Lin, YD
   He, HJ
   Tai, HM
   Chen, F
   Yin, ZK
AF Lin, Yudong
   He, Hongjie
   Tai, Heng-Ming
   Chen, Fan
   Yin, Zhongke
TI Rotation and scale invariant target detection in optical remote sensing
   images based on pose-consistency voting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; Remote sensing; Target pose; Pose consistency and
   rotation-scale invariant
ID OBJECT DETECTION
AB Rotation and scaling are two problems that must be solved in remote sensing detection. Most current methods only focus on the rotation invariance. In this paper, a novel target detection method based on pose-consistency voting is proposed to solve both the rotation and scaling problems, and improve detection precision in complicated optical remote sensing images. The proposed method defines a target pose to describe the direction and the scale of the detected target related to the target template. To detect the target in a detection window, the estimation-voting strategy is used. In the estimation stage, a large set of possible poses for the target in the detection window are predicted by pairs of pose-related pixels. Each pair of pose-related pixels is obtained through a pixel matching method based on the radial- gradient angle (RGA). As to the voting stage, based on the pose consistency property, all possible target poses vote in the angle-scale space to generate a pose histogram. The maximum value of the pose histogram is defined as the detection score of current detection window, and the pose corresponding to this max value is considered as the pose the detected target. Experimental results demonstrate that the proposed method is rotation-scale invariant, and is robust to the interference of shadow and occlusion. The detection performance in the complicated background is better than other state-of-the-art detection methods.
C1 [Lin, Yudong; He, Hongjie; Chen, Fan] Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
   [Tai, Heng-Ming] Univ Tulsa, Dept Elect Engn, Tulsa, OK 74104 USA.
   [Yin, Zhongke] Beijing Inst Remote Sensing Informat, Beijing 100192, Peoples R China.
C3 Southwest Jiaotong University; University of Tulsa
RP He, HJ (corresponding author), Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
EM willianlam@126.com; hehojie@126.com; tai@utulsa.edu;
   Fchen@home.swjtu.edu.cn; yinzhongke@163.com
RI Lin, Yudong/KVB-0316-2024; Tai, Heng-Ming/A-9267-2009
OI Tai, Heng-Ming/0000-0002-0162-7492
FU National Natural Science Foundation of China, People's Republic of China
   [61373180, 61461047]; Technical Innovation Talent Project of Sichuan
   Province [2015042]
FX The research has been supported by the National Natural Science
   Foundation of China, People's Republic of China (61373180, 61461047),
   and the Technical Innovation Talent Project of Sichuan Province
   (2015042).
CR [Anonymous], 2011, P INT S IM DAT FUS A
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Cheng G, 2013, ISPRS J PHOTOGRAMM, V85, P32, DOI 10.1016/j.isprsjprs.2013.08.001
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Harris C., 1988, ALVEY VISION C, P147151
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Lei Z, 2012, IEEE T GEOSCI REMOTE, V50, P1206, DOI 10.1109/TGRS.2011.2166966
   Lin YD, 2015, IEEE GEOSCI REMOTE S, V12, P746, DOI 10.1109/LGRS.2014.2360887
   Liu L, 2014, OPTIK, V125, P5327, DOI 10.1016/j.ijleo.2014.06.062
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Nixon M, 2008, 5 FEATURE EXTRACTION, P228
   Papakostas GA, 2013, NEUROCOMPUTING, V99, P358, DOI 10.1016/j.neucom.2012.06.031
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sun H, 2012, IEEE GEOSCI REMOTE S, V9, P109, DOI 10.1109/LGRS.2011.2161569
   Wang LM, 2007, LECT NOTES COMPUT SC, V4843, P189
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang WC, 2014, IEEE GEOSCI REMOTE S, V11, P74, DOI 10.1109/LGRS.2013.2246538
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 25
TC 10
Z9 11
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14461
EP 14483
DI 10.1007/s11042-016-3857-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800034
DA 2024-07-18
ER

PT J
AU Boteanu, B
   Mironica, I
   Ionescu, B
AF Boteanu, Bogdan
   Mironica, Ionut
   Ionescu, Bogdan
TI Pseudo-relevance feedback diversification of social image retrieval
   results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social image search results diversification; Pseudo-relevance feedback;
   Hierarchical clustering; Image retrieval; MediaEval benchmarking
ID INFORMATION
AB In this paper we introduce a novel pseudo-relevance feedback (RF) perspective to social image search results diversification. Traditional RF techniques introduce the user in the processing loop by harvesting feedback about the relevance of the query results. This information is used for recomputing a better representation of the needed data. The novelty of our work is in exploiting the automatic generation of user feedback in a completely unsupervised diversification scenario, where positive and negative examples are used to generate better representations of visual classes in the data. First, user feedback is simulated automatically by selecting positive and negative examples from the initial query results. Then, an unsupervised hierarchical clustering is used to re-group images according to their content. Diversification is finally achieved with a re-ranking approach of the previously achieved clusters. Experimental validation on real-world data from Flickr shows the benefits of this approach achieving very promising results.
C1 [Boteanu, Bogdan; Mironica, Ionut; Ionescu, Bogdan] Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Boteanu, B (corresponding author), Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
EM bboteanu@alpha.imag.pub.ro; imironica@imag.pub.ro; bionescu@imag.pub.ro
RI Ionescu, Bogdan/IWU-7778-2023
FU Ministry of European Funds through the Financial Agreement [POSDRU
   187/1.5/S/155420 PROSCIENCE, ESF POSDRU/159/1.5/S/132395 InnoRESEARCH]
FX This work has been funded by the Ministry of European Funds through the
   Financial Agreement POSDRU 187/1.5/S/155420 PROSCIENCE, and by the ESF
   POSDRU/159/1.5/S/132395 InnoRESEARCH programme. We acknowledge also the
   MediaEval Benchmarking Initiative for Multimedia Evaluation
   (http://www.multimediaeval.org) for providing the data.
CR [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], 2007, 11 INT C COMPUTER VI
   [Anonymous], P MEDIAEVAL 2014WORK
   [Anonymous], 2014, MULT SYST C 2014
   [Anonymous], WORKING NOTES CROSS
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 2015, P 13 INT WORKSHOP CO
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], SIGIR WORKSH CROWD S
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], RESULT DIVERSIFICATI
   [Anonymous], TRECVID WORKSH
   [Anonymous], P 6 ACM C IM VID RET
   [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], P MEDIAEVAL 2015 WOR
   Cao Guihong, 2008, P SIGIR 2008, P243, DOI DOI 10.1145/1390334.1390377
   Cao LJ, 2012, IEEE IMAGE PROC, P2885, DOI 10.1109/ICIP.2012.6467502
   Carbonell JG, 1997, INT JOINT CONF ARTIF, P708
   Dang V, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/2348283.2348296
   Dang-Pham D., 2015, Investigating the formation of information security climate perceptions with social network analysis: A research proposal, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Denis F, 1998, LECT NOTES ARTIF INT, V1501, P112
   Pedronette DCG, 2014, MULTIMED TOOLS APPL, V69, P689, DOI 10.1007/s11042-012-1115-z
   Ionescu Bogdan, 2015, P 6 ACM MULT SYST C, P207
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   KING B, 1967, J AM STAT ASSOC, V62, P86, DOI 10.2307/2282912
   Ksibi A, 2014, INT J MULTIMED INF R, V3, P29, DOI 10.1007/s13735-013-0045-5
   Lestari Paramita M, 2010, MULTILINGUAL INFORM, V6242, P45, DOI [10.1007/978-3-642-15751-6-6, DOI 10.1007/978-3-642-15751-6-6]
   Liang S, 2008, PATTERN RECOGN LETT, V29, P1733, DOI 10.1016/j.patrec.2008.05.004
   Liu B, 2002, ICML
   Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346
   Ludwig O., 2009, P 12 INT IEEE C INTE, P1
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Priyatharshini R., 2013, Mobile Communication and Power Engineering, P17
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P921, DOI 10.1109/TMM.2013.2237896
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sneath P. H. A., NUMERICAL TAXONOMY
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381
   Sun A., 2009, Proc. SIGMM Workshop on Social Media, P19
   Taneva Bilyana., 2010, Proceedings of the third ACM international conference on Web search and data mining, P431
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Van Brummelen G., 2013, HEAVENLY MATH FORGOT
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Vee E, 2008, PROC INT CONF DATA, P228, DOI 10.1109/ICDE.2008.4497431
   Vieira MR, 2011, PROC INT CONF DATA, P1163, DOI 10.1109/ICDE.2011.5767846
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XY, 2013, ENG APPL ARTIF INTEL, V26, P368, DOI 10.1016/j.engappai.2012.05.008
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wu HC, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361686
   Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu J, 2007, INT CONF ACOUST SPEE, P965
   Zhu X., 2007, P HUM LANG TECHN C N, P97
NR 65
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11889
EP 11916
DI 10.1007/s11042-016-3678-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000041
DA 2024-07-18
ER

PT J
AU Ko, KR
   Chae, SH
   Moon, D
   Seo, CH
   Pan, SB
AF Ko, Kyeong-Ri
   Chae, Seung-Hoon
   Moon, Daesung
   Seo, Chang Ho
   Pan, Sung Bum
TI Four-joint motion data based posture classification for immersive
   postural correction system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Postural correction; Motion data analysis; Classification of posture
ID CAPTURE
AB In the modern age, it is important for people to maintain a good sitting posture because they spend long hours sitting. Posture correction treatment requires a great deal of time and expenses with continuous observation by a specialist. Therefore, there is a need for a system with which users can judge and correct their postures on their own. In this paper, we propose a four joint-based motion capture system for building immersive postural correction system. The system collects the subject's postures, and features are extracted from the collected data to build a database. The data in the DB are classified into normal and abnormal postures after posture learning using the K-means clustering algorithm. An experiment was performed to classify the posture from the joints' rotation angles and positions; the normal posture judgment reached a success rate of 99.79 %. This result suggests that the features of the four joints can be used to judge and help correct a user's posture through application to a spinal disease prevention system in the future.
C1 [Ko, Kyeong-Ri] Chosun Univ, Dept Control & Instrumentat Engn, 309 Pilmun Daero, Kwangju 501759, South Korea.
   [Chae, Seung-Hoon; Moon, Daesung] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea.
   [Seo, Chang Ho] Kongju Natl Univ, Dept Appl Math, Gongju Si 314701, Chungcheongnam, South Korea.
   [Pan, Sung Bum] Chosun Univ, Dept Elect Engn, 309 Pilmun Daero, Kwangju 501759, South Korea.
C3 Chosun University; Electronics & Telecommunications Research Institute -
   Korea (ETRI); Kongju National University; Chosun University
RP Pan, SB (corresponding author), Chosun Univ, Dept Elect Engn, 309 Pilmun Daero, Kwangju 501759, South Korea.
EM happymode4621@gmail.com; ssuguly@gmail.com; daesung@etri.re.kr;
   chseo@kongju.ac.kr; sbpan@chosun.ac.kr
OI Chae, Seung-Hoon/0000-0002-4115-1345; Ko, Kyeong-Ri/0000-0002-2436-7339
FU Ministry of Knowledge Economy (MKE), Rep. of Korea [10041059]; Basic
   Sciences Program through the National Research Foundation of Korea
   (NRF), Republic of Korea [2013-R1A1A2010382]
FX This work was supported by the Ministry of Knowledge Economy (MKE), Rep.
   of Korea, under the IT R&D program supervised by the KOREA Evaluation
   Institute of Industrial Technology (KEIT) (10041059). It was also
   supported by Basic Sciences Program through the National Research
   Foundation of Korea (NRF), Republic of Korea (2013-R1A1A2010382).
CR [Anonymous], J CONVERGENCE
   [Anonymous], J CONVERG
   Bunnell WP, 2005, CLIN ORTHOP RELAT R, P40, DOI 10.1097/01.blo.0000163242.92733.66
   Christou G, 2013, HUMAN CTR COMPUTING, V3, P1
   Duda RO, 2012, PATTERN CLASSIFICATI, P526
   Eberly D, 2008, TECH REP
   Furniss M., 1999, Motion capture
   Ko KR, 2015, IETE TECH REV, V32, P37, DOI 10.1080/02564602.2014.978397
   Lee MG, 2007, ETRI ELECT TELECOMMU, V22
   Lim M, 2013, J INF PROCESS SYST, V9, P489, DOI 10.3745/JIPS.2013.9.3.489
   MCCARTHY RE, 1987, CLIN ORTHOP RELAT R, P73
   Negrini S, 2011, SCOLIOSIS, V7, P2012
   Hai NCT, 2012, J INF PROCESS SYST, V8, P389, DOI 10.3745/JIPS.2012.8.3.389
   Nishanth KJ, 2013, J INF PROCESS SYST, V9, P633, DOI 10.3745/JIPS.2013.9.4.633
   Oh J, 2014, J CONVERG, V5, P21
   RENSHAW TS, 1988, CLIN ORTHOP RELAT R, P26
   Roetenberg D., 2006, THESIS U TWENTE ENSC
   Shin B., 2003, J KOREA CHUNA MANUAL, V4, P1
   Vanus J, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0035-0
   Yawn BP, 1999, JAMA-J AM MED ASSOC, V282, P1427, DOI 10.1001/jama.282.15.1427
   Zhu YH, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-15
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 22
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11235
EP 11249
DI 10.1007/s11042-016-3299-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000006
DA 2024-07-18
ER

PT J
AU Kasapakis, V
   Gavalas, D
AF Kasapakis, Vlasios
   Gavalas, Damianos
TI Occlusion handling in outdoors augmented reality games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pervasive games; Augmented reality; Occlusion; Field of view; Line of
   sight; Raycasting; OSM; Performance tests
ID TRACKING; OBJECTS
AB The use of augmented reality (AR) becomes increasingly common in mobile game development as a means of enhancing the players' view of the physical world through computer-generated graphical information. A situation often encountered in AR applications is the -partial or full- occlusion of virtual objects by physical artifacts; if not appropriately handled, the visualization of occluded objects often misleads users' perception. This paper introduces three alternative Geolocative Raycasting techniques aiming at assisting developers of outdoors AR games in generating a realistic field of view (FoV) for the players by integrating real time building recognition, so as to address the occlusion problem. Our geolocative raycasting methods have been applied in the location-based, AR game Order Elimination, which utilizes publicly and freely available building information to calculate the players FoV in real-time. The proposed algorithms are applicable to a variety of sensor-based AR applications and portable to any real setting, provided that sufficient topographical data exist. The three FoV determination methods have been tested with respect to several performance parameters demonstrating that real-time FoV rendering is feasible by modest mobile devices, even under stress conditions. A user evaluation study revealed that the consideration of buildings for determining the FoV in AR pervasive games can increase the quality of experience of players when compared with standard FoV generation methods.
C1 [Kasapakis, Vlasios; Gavalas, Damianos] Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece.
C3 University of Aegean
RP Kasapakis, V (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece.
EM v.kasapakis@aegean.gr
RI Gavalas, Damianos/F-1449-2010; Vlasis, Kasapakis/AAS-8169-2020
OI Kasapakis, Vlasios/0000-0002-4048-6047; Gavalas,
   Damianos/0000-0003-4208-8613
CR [Anonymous], FINAL CROSSMEDIA R 2
   Behzadan AH, 2010, COMPUT-AIDED CIV INF, V25, P3, DOI 10.1111/j.1467-8667.2009.00601.x
   Benford S., 2006, ACM Transactions on Computer-Human Interaction, V13, P100, DOI 10.1145/1143518.1143522
   Benford S, 2005, COMMUN ACM, V48, P54, DOI 10.1145/1047671.1047704
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Broll Wolfgang., 2006, Proceedings of 5th ACM SIGCOMM workshop on Network and system support for games, page, P28
   Capra M., 2005, 13th Annual ACM International Conference on Multimedia, P89, DOI 10.1145/1101149.1101163
   Cheok AD, 2006, IEEE PERVAS COMPUT, V5, P62, DOI 10.1109/MPRV.2006.25
   Ciepluch B, 2010, P 9 INT S SPAT ACC A, V337
   Clark A., 2011, 10th International Conference on Virtual Reality Continuum and Its Applications in Industry (VRCAI '11), P499
   Dey A, 2014, INT J HUM-COMPUT ST, V72, P704, DOI 10.1016/j.ijhcs.2014.04.001
   Fischer J, 2007, USING TIME OF FLIGHT, P109
   Gavalas D., 2015, P INT WORKSH NETW SY, P1
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hayashi K., 2005, P 2005 INT C AUGMENT, P180
   Herbst I., 2008, Proceedings of the 10th International Conference on Human Computer Interaction with Mobile Devices and Services, P235, DOI DOI 10.1145/1409240.1409266
   Hodson H, 2012, NEW SCI, V19
   Kasapakis V, 2015, J NETW COMPUT APPL, V55, P213, DOI 10.1016/j.jnca.2015.05.009
   Kasapakis V, 2015, PERS UBIQUIT COMPUT, V19, P523, DOI 10.1007/s00779-015-0846-z
   Kasapakis Vlasios., 2014, Proceedings of the 13th International Conference on Mobile and Ubiquitous Multimedia (MUM '14), P116
   Kim H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P169, DOI 10.1109/ISMAR.2003.1240700
   Lepetit V, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P137, DOI 10.1109/ISAR.2000.880937
   Livingston MA, 2011, VIRTUAL REAL-LONDON, V15, P175, DOI 10.1007/s10055-010-0179-1
   Ohta Y, 2002, PRESENCE-TELEOP VIRT, V11, P176, DOI 10.1162/105474602317396048
   Schroeder J., 2013, AndEngine for Android game development cookbook
   Shah M. M., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P372
   Thomas BH, 2012, COMPUT ENTERTAIN, V10, DOI 10.1145/2381876.2381879
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Tian Y, 2010, SENSORS-BASEL, V10, P2885, DOI 10.3390/s100402885
   Wetzel W., 2009, FINAL PROTOTYPE TIME
   Yang T, 2005, PROC CVPR IEEE, P970
   Zhu JJ, 2010, COMPUT ANIMAT VIRT W, V21, P509, DOI 10.1002/cav.326
NR 32
TC 8
Z9 9
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9829
EP 9854
DI 10.1007/s11042-016-3581-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300032
DA 2024-07-18
ER

PT J
AU Lu, Z
   Lin, YR
   Huang, XX
   Xiong, NX
   Fang, ZJ
AF Lu, Zhao
   Lin, Yu-Ru
   Huang, Xiaoxia
   Xiong, Naixue
   Fang, Zhijun
TI Visual topic discovering, tracking and summarization from social media
   streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic detection and tracking; Social media stream; K-partite graph;
   Multi-modality feature representation
ID SEGMENTATION; SERVICE; MODEL
C1 [Lu, Zhao; Huang, Xiaoxia] East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Dept Comp Sci & Technol, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
   [Lin, Yu-Ru] Univ Pittsburgh, Sch Informat Sci, 135 North Bellefield Ave, Pittsburgh, PA 15260 USA.
   [Xiong, Naixue] Southwestern Oklahoma State Univ, Dept Business & Comp Sci, 100 Campus Dr, Weatherford, OK 73096 USA.
   [Fang, Zhijun] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, 333 Longteng Rd, Shanghai 201620, Peoples R China.
C3 East China Normal University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); University of Pittsburgh; Shanghai University of
   Engineering Science
RP Lu, Z (corresponding author), East China Normal Univ, Shanghai Key Lab Multidimens Informat Proc, Dept Comp Sci & Technol, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
EM zlu@cs.ecnu.edu.cn; yurulin@pitt.edu
RI xiong, naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635
FU National Key Technology Support Program [2015BAH01F02]; Science and
   Technology Commission of Shanghai Municipality [16511102702,
   14DZ2260800]; Yu-Ru Lin's Lab at University of Pittsburgh; NSF [1423697,
   1634944]; CRDF; CIS; Division Of Behavioral and Cognitive Sci; Direct
   For Social, Behav & Economic Scie [1423697] Funding Source: National
   Science Foundation
FX This research was supported in part by National Key Technology Support
   Program (No. 2015BAH01F02), in part by Science and Technology Commission
   of Shanghai Municipality (No. 16511102702 and No. 14DZ2260800). The
   authors gratefully acknowledge the support of Yu-Ru Lin's Lab at
   University of Pittsburgh, supported in part by NSF grant #1423697,
   #1634944, and the CRDF and CIS. Any opinions, findings, and conclusions
   or recommendations expressed in this material do not necessarily reflect
   the views of the funding sources.
CR [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   CAO J, 2010, P ACM MULT C MM, P1639
   Cao J, 2015, NEUROCOMPUTING
   Cao J, 2011, IEEE T CIRC SYST VID, V21, P1835, DOI 10.1109/TCSVT.2011.2148470
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Guille A, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-015-0258-0
   Guorong Li, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P750, DOI 10.1007/978-3-319-03731-8_70
   Hao Tu, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P738, DOI 10.1109/CSSS.2012.189
   Li C., 2012, Cikm, P155, DOI DOI 10.1145/2396761.2396785
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu L., 2008, P 17 INT C WORLD WID, P1009
   Long B., 2006, SIGKDD, P317, DOI DOI 10.1145/1150402.1150439
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Ran L, 2014, FRONTIER FUTURE DEV, P603
   Shao J., 2010, P INT C MULT, P915
   Shao J, 2012, PATTERN RECOGN LETT, V33, P410, DOI 10.1016/j.patrec.2011.07.026
   Shi SK, 2012, INT J COMPUT INT SYS, V5, P735, DOI 10.1080/18756891.2012.718156
   Wang Z, 2015, IEEE T PARALL DISTR, V26, P775, DOI 10.1109/TPDS.2014.2314103
   Wanner F., 2014, COMPUTER GRAPHICS FO, V33
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Yun Zhai, 2005, 13th Annual ACM International Conference on Multimedia, P2, DOI 10.1145/1101149.1101152
   Zhang WG, 2015, NEUROCOMPUTING, V169, P169, DOI 10.1016/j.neucom.2015.02.083
   Zhang Y, 2013, LECT NOTES COMPUT SC, V7995, P1, DOI 10.1007/978-3-642-39479-9_1
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou XM, 2014, VLDB J, V23, P381, DOI 10.1007/s00778-013-0320-3
   Zhu TY, 2014, SCI WORLD J, DOI 10.1155/2014/360934
NR 29
TC 10
Z9 11
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10855
EP 10879
DI 10.1007/s11042-016-3877-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400031
DA 2024-07-18
ER

PT J
AU Alilou, VK
   Yaghmaee, F
AF Alilou, Vahid K.
   Yaghmaee, Farzin
TI Exemplar-based image inpainting using svd-based approximation matrix and
   multi-scale analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Image completion; Object removal; Singular value
   decomposition; Image pyramids
ID QUALITY ASSESSMENT; COMPLETION; DIFFUSION; ALGORITHM
AB Reconstruction of images by digital inpainting is an active field of research and such algorithms are, in fact, now widely used. In conventional methods, a texture synthesis algorithm is used for filling the unknown regions of the image. However, due to the lack of global analysis on the image, the result may contain undesirable artifacts especially when we have images with relatively large missing regions. Here we propose a new inpainting technique to overcome this limitation by using an approximation matrix. The basic idea is to first make an approximation matrix using singular value decomposition, and then reconstruct the target region by using this matrix. Approximation matrix here, is in fact a gray-scale copy of the original image in which the target region is approximated throughout the process of rank lowering. Experiments are performed on a variety of input images ranging from purely synthetic images to full-color photographs. The results demonstrate the effectiveness of the proposed approach.
C1 [Alilou, Vahid K.] Semnan Univ, Dept Comp Engn, Semnan, Iran.
   [Yaghmaee, Farzin] Semnan Univ, Fac Comp Engn, Semnan, Iran.
C3 Semnan University; Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Fac Comp Engn, Semnan, Iran.
EM alilou@semnan.ac.ir; f_yaghmaee@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021; K. Alilou, Vahid/AAQ-6281-2020
OI Yaghmaee, Farzin/0000-0001-7430-542X; K. Alilou,
   Vahid/0000-0002-9230-8277
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alilou VK, 2015, PATTERN RECOGN LETT, V62, P24, DOI 10.1016/j.patrec.2015.04.020
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], SINGULAR VALUE DECOM
   [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], INT SOC OPTICS PHOTO
   [Anonymous], KOKARAM IMAGE INPAIN
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Brigham E.O., 1988, The Fast Fourier Transform and Applications, V1
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Casaca W, 2014, PATTERN RECOGN LETT, V36, P36, DOI 10.1016/j.patrec.2013.08.023
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chan TF, 2006, J MATH IMAGING VIS, V26, P85, DOI 10.1007/s10851-006-6865-7
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Gepshtein S, 2013, IEEE T IMAGE PROCESS, V22, P2983, DOI 10.1109/TIP.2013.2237916
   GERBRANDS JJ, 1981, PATTERN RECOGN, V14, P375, DOI 10.1016/0031-3203(81)90082-0
   Ghorai M, 2015, LECT NOTES COMPUT SC, V9009, P63, DOI 10.1007/978-3-319-16631-5_5
   Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446
   Holtzman-Gazit M, 2006, LECT NOTES COMPUT SC, V4291, P648
   Huan XL, 2010, COMPUT VIS IMAGE UND, V114, P847, DOI 10.1016/j.cviu.2010.04.007
   Huang HF, 2012, COMM COM INF SC, V288, P666
   Jia JY, 2003, PROC CVPR IEEE, P643
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kawai N, 2009, LECT NOTES COMPUT SC, V5414, P271, DOI 10.1007/978-3-540-92957-4_24
   Koh M. S., 2009, IEEE INT WORKSHOP MU, P1
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   MOONEN M, 1992, SIAM J MATRIX ANAL A, V13, P1015, DOI 10.1137/0613061
   Padalkar Milind G., 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P61, DOI 10.1007/978-3-642-37484-5_6
   Pereira T, 2009, GRAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P39
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   STOLLNITZ E.J., 1996, WAVELETS COMPUTER GR
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Wang M., 2011, P ENG, V15, P3733
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Wu JY, 2006, INT C PATT RECOG, P810
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zheng CD, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-98
NR 51
TC 13
Z9 17
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7213
EP 7234
DI 10.1007/s11042-016-3366-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400049
DA 2024-07-18
ER

PT J
AU Nguyen, HL
   Jung, JE
AF Hoang Long Nguyen
   Jung, Jai E.
TI Statistical approach for figurative sentiment analysis on Social
   Networking Services: a case study on Twitter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Figurative sentiment analysis; Statistical approach; Content-based;
   Emotion pattern
ID IRONY
AB This paper presents a system that analyzes the sentiment of figurative language contained in short texts collected from Social Networking Services (SNS). This case study sources information from tweets on Twitter and calculates the polarity of the figurative language with three different categories (i.e., sarcastic, ironic, and metaphorical tweets). As in Medhat et al. (Ain Shams Eng J 5(4):1093-1113, 2014), Nguyen and Jung (Mob Netw Appl 20(4):475-486, 2015), many related works have used a lexical-based approach (e.g., dictionary and corpus), and machine learning-based approach (e.g., decision tree, rule discovery, and probabilistic methods) to extract sentiment in a given text. This statistical approach makes use of two main features: i) Content-based, and ii) Emotion Pattern-based. We believe that this combination offers a general method to solve the current problem and easily extends for analyzing other types of figurative languages. The proposed algorithm is evaluated by using Cosine similarity to conduct an experiment over a Data set that contains about 5,000 tweets. The results show that the FIS Model (Figurative language Identification using Statistical-based Model) works well with figurative tweets with a highest achievement of 0.7813.
C1 [Hoang Long Nguyen; Jung, Jai E.] Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Jung, JE (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
EM longnh238@gmail.com; j3ung@cau.ac.kr
RI Jung, Jason J./B-9622-2012; Nguyen, Hoang Long/K-6449-2019
OI Jung, Jason J./0000-0003-0050-7445; Nguyen, Hoang
   Long/0000-0002-8031-6341
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2014R1A2A2A05007154]; MSIP (Ministry of Science, ICT & Future
   Planning), Korea under ITRC (Information Technology Research Cetner)
   [NIPA-2014-H0301-14-1044]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP)
   (NRF-2014R1A2A2A05007154). Also, this research was supported by the MSIP
   (Ministry of Science, ICT & Future Planning), Korea, under the ITRC
   (Information Technology Research Cetner) support program
   (NIPA-2014-H0301-14-1044) supervised by the NIPA (National ICT Industry
   Promotion Agency).
CR Attardo S, 2000, J PRAGMATICS, V32, P793, DOI 10.1016/S0378-2166(99)00070-3
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Colston Herbert., 2001, Pragmatics Cognition, V8, P277
   Hao YF, 2010, MIND MACH, V20, P635, DOI 10.1007/s11023-010-9211-1
   Hong M, 2016, CYBERNET SYST, V47, P88, DOI 10.1080/01969722.2016.1128771
   Jung JJ, 2016, CONCURR COMP-PRACT E, V28, P1356, DOI 10.1002/cpe.3634
   Kaur Amandeep, 2013, Journal of Emerging Technologies in Web Intelligence, V5, P367, DOI 10.4304/jetwi.5.4.367-371
   KUMONNAKAMURA S, 1995, J EXP PSYCHOL GEN, V124, P3, DOI 10.1037/0096-3445.124.1.3
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Nguyen DT, 2015, MOBILE NETW APPL, V20, P475, DOI 10.1007/s11036-014-0557-0
   Long NH, 2015, CYBERNET SYST, V46, P69, DOI 10.1080/01969722.2015.1007737
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Reyes A, 2014, KNOWL INF SYST, V40, P595, DOI 10.1007/s10115-013-0652-8
   Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x
   Reyes A, 2012, DECIS SUPPORT SYST, V53, P754, DOI 10.1016/j.dss.2012.05.027
   Reyes A, 2012, DATA KNOWL ENG, V74, P1, DOI 10.1016/j.datak.2012.02.005
   Shutova Ekaterina., 2010, P 23 INT C COMP LING, P1002
   Veale T., 2007, AAAI, V2007, P1471
   Veale T., 1992, Computational Intelligence, V8, P494, DOI [DOI 10.1111/J.1467-8640, 10.1111/j.1467-8640.1992.tb00377.x, DOI 10.1111/J.1467-8640.1992.TB00377.X]
   Veale T, 2012, P 26 INT C ASS ADV A
NR 20
TC 14
Z9 15
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8901
EP 8914
DI 10.1007/s11042-016-3525-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800056
DA 2024-07-18
ER

PT J
AU Liu, JW
   Gu, YL
   Kamijo, S
AF Liu, Jingwen
   Gu, Yanlei
   Kamijo, Shunsuke
TI Customer behavior classification using surveillance camera for marketing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance camera; Customer behavior; Orientation estimation; Arm
   action classification
ID RECOGNITION; TRACKING; MOTION
AB The analysis of customer behavior from surveillance camera is one of the most important open topics for marketing. Traditionally, retailers use the records of cash registers or credit cards to analyze the buying behaviors of customers. However, this information cannot reveal the behaviors of customer when he or she shows interest on the front of the merchandise shelf but does not buy. Those behaviors can be recorded and analyzed by the surveillance camera. We propose a system to classify different customer behaviors on the front of shelf: no interest, viewing, turning body to shelf, touching, picking and returning to shelf and picking and putting into basket, which show customer's increasing interest to products. In the proposed system, head orientation, body orientation, and arm action, the multiple cues are integrated for the customer behavior recognition. The proposed system discretizes the head and body orientation of customer into 8 directions to estimate whether the customer is looking or turning to the merchandise shelf. Semi-Supervised Learning method is applied to optimize the training dataset and to generate the accurate classifier. In addition, the temporal constraint and the human physical model constraint are considered in joint body and head orientation estimation. As for the arm action recognition, a novel Combined Hand Feature (CHF), which includes hand trajectory, tracking status and the relative position between hand and shopping basket, is proposed to classify different arm actions. The hand tracking is done by an improved particle filter. The CHF is classified by Dynamic Bayesian Network (DBN) to output different types of arm actions. A series of experiments demonstrate effectiveness of the proposed technologies and the performance to the developed system.
C1 [Liu, Jingwen] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Gu, Yanlei; Kamijo, Shunsuke] Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo
RP Liu, JW (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
EM ljwqq0@kmj.iis.u-tokyo.ac.jp; guyanlei@kmj.iis.u-tokyo.ac.jp;
   kamijo@iis.u-tokyo.ac.jp
RI jingwen, liu/B-5167-2014; Gu, Yanlei/GSJ-3642-2022
CR [Anonymous], 2010, WORLD AUT C
   [Anonymous], DEWS2007
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Cheng Chen, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P5, DOI 10.1109/AVSS.2011.6027284
   Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elmezain M, 2009, IEEE IMAGE PROC, P3577, DOI 10.1109/ICIP.2009.5414322
   Feng Chen, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P34, DOI 10.1109/VSMM.2010.5665970
   Gandhi T, 2008, IEEE INT VEH SYM, P795
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Gu YL, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1266, DOI 10.1109/ITSC.2014.6957861
   Haritaoglu I, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P127, DOI 10.1109/ACV.2002.1182169
   Haritaoglu I, 2001, PROC CVPR IEEE, P431
   Haritaoglu I, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P175, DOI 10.1109/MOTION.2002.1182231
   Trinh H, 2011, INT CONF ACOUST SPEE, P1337
   Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153
   Lao WL, 2009, IEEE T CONSUM ELECTR, V55, P591, DOI 10.1109/TCE.2009.5174427
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Leykin A, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P417, DOI 10.1109/AVSS.2007.4425347
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Migniot C, 2013, LECT NOTES COMPUT SC, V8047, P482, DOI 10.1007/978-3-642-40261-6_58
   Murphy KevinP., 1994, DYNAMIC BAYESIAN NET
   Niebles J. C., 2007, COMPUTER VISION PATT, P1
   Popa M., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2512, DOI 10.1109/ICSMC.2010.5641928
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schulz Andreas, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P51, DOI 10.1007/978-3-642-23123-0_6
   Schulz A, 2012, IEEE INT C INTELL TR, P1771, DOI 10.1109/ITSC.2012.6338829
   Senior AW, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P423, DOI 10.1109/AVSS.2007.4425348
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Stan Carmen E., 2008, 2008 3rd International Multi-Conference on Computing in the Global Information Thechnology (ICCGI 2008), P7, DOI 10.1109/ICCGI.2008.23
   Watanabe Tomoki, 2010, Information and Media Technologies, V5, P659
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Yano S, 2016, INT J INTELL TRANSP, V14, P75, DOI 10.1007/s13177-014-0103-2
   Yao J, 2007, COMPUTER VISION PATT, P1
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 39
TC 20
Z9 20
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6595
EP 6622
DI 10.1007/s11042-016-3342-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400023
DA 2024-07-18
ER

PT J
AU Mousse, MA
   Motamed, C
   Ezin, EC
AF Mousse, Mikael A.
   Motamed, Cina
   Ezin, Eugene C.
TI People counting via multiple views using a fast information fusion
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual surveillance; People counting; Homography; Data association;
   Tracking; Overlapping cameras
ID TRACKING; CAMERAS
AB Real-time estimates of a crowd size is a central task in civilian surveillance. In this paper we present a novel system counting people in a crowd scene with overlapping cameras. This system fuses all single view foreground information to localize each person present on the scene. The purpose of our fusion strategy is to use the foreground pixels of each single views to improve real-time objects association between each camera of the network. The foreground pixels are obtained by using an algorithm based on codebook. In this work, we aggregate the resulting silhouettes over cameras network, and compute a planar homography projection of each camera's visual hull into ground plane. The visual hull is obtained by finding the convex hull of the foreground pixels. After the projection into the ground plane, we fuse the obtained polygons by using the geometric properties of the scene and on the quality of each camera detection. We also suggest a region-based approach tracking strategy which keeps track of people movements and of their identities along time, also enabling tolerance to occasional misdetections. This tracking strategy is implemented on the result of the views fusion and allows to estimate the crowd size dependently on each frame. Assessment of experiments using public datasets proposed for the evaluation of counting people system demonstrates the performance of our fusion approach. These results prove that the fusion strategy can run in real-time and is efficient for making data association. We also prove that the combination of our fusion approach and the proposed tracking improve the people counting.
C1 [Mousse, Mikael A.; Motamed, Cina] Univ Littoral Cote dOpale, EA 4491, LISIC, Lab Informat Signal & Image Cote Opale, F-62228 Calais, France.
   [Mousse, Mikael A.; Ezin, Eugene C.] Univ Abomey Calavi, Inst Math & Sci Phys, Unite Rech Informat & Sci Appl, Abomey Calavi, Benin.
C3 Universite du Littoral-Cote-d'Opale; Institute of Mathematical Sciences
   & Physics IMPS; University of Abomey Calavi
RP Mousse, MA (corresponding author), Univ Littoral Cote dOpale, EA 4491, LISIC, Lab Informat Signal & Image Cote Opale, F-62228 Calais, France.; Mousse, MA (corresponding author), Univ Abomey Calavi, Inst Math & Sci Phys, Unite Rech Informat & Sci Appl, Abomey Calavi, Benin.
EM mousse@lisic.univ-littoral.fr; motamed@lisic.univ-littoral.fr;
   eugene.ezin@imsp-uac.org
RI Mousse, Mikael A./AAO-6421-2021
OI Mousse, Mikael A./0000-0002-3326-6396
FU Association AS2V and Fondation Jacques De Rette, France
FX This work is partially funded by the Association AS2V and Fondation
   Jacques De Rette, France. Authors are grateful to the Service de
   Cooperation et d'Action Culturelle de l'Ambassade de France au Benin. We
   also appreciate the valuable comments provided by the anonymous
   reviewers as these have improved the manuscript immensely.
CR Albiol A, 2001, IEEE T INTELL TRANSP, V2, P204, DOI 10.1109/6979.969366
   Ferreira JCA, 2009, IEEE INTL CONF IND I, P25, DOI 10.1109/INDIN.2009.5191765
   [Anonymous], PERF EV TRACK SURV P
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   Cai Q, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P356, DOI 10.1109/ICCV.1998.710743
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Conte D., 2010, EURASIP Journal on Advances in Signal Processing, V5, P1
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Duin RPW, 2000, LECT NOTES COMPUT SC, V1857, P16
   Englebienne G, 2010, P 22 BEN C ART INT
   Eshel R., 2008, IEEE C COMPUT VIS PA, P1
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Fu HY, 2014, MULTIMED TOOLS APPL, V73, P273, DOI 10.1007/s11042-013-1608-4
   Ge WN, 2010, LECT NOTES COMPUT SC, V6315, P324
   Giacinto G, 2000, LECT NOTES COMPUT SC, V1876, P87
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Hashemzadeh M, 2014, MULTIMED TOOLS APPL, V72, P453, DOI 10.1007/s11042-013-1367-2
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Kang BM, 2003, PROC CVPR IEEE, P267
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Kim J, 1997, PROC INT CONF DOC, P459, DOI 10.1109/ICDAR.1997.620539
   Kim JW, 2002, ROBUST REAL TIME PEO
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Kuncheva LI, 2000, INT C PATT RECOG, P168, DOI 10.1109/ICPR.2000.906041
   Ma HD, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089107
   Maddalena L, 2014, PATTERN RECOGN LETT, V36, P125, DOI 10.1016/j.patrec.2013.10.006
   Ming Xu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3593, DOI 10.1109/ICIP.2011.6116494
   Motamed C, 2006, IMAGE VISION COMPUT, V24, P1192, DOI 10.1016/j.imavis.2005.06.005
   Mousse MA, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P119, DOI 10.1109/SITIS.2014.55
   Subburaman VB, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P470, DOI 10.1109/AVSS.2012.87
   Sutherland I. E., 1974, Computing Surveys, V6, P1, DOI 10.1145/356625.356626
   van Oosterhout T, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P620
   Wren C, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P51, DOI 10.1109/AFGR.1996.557243
   Xu M, 2005, IEE P-VIS IMAGE SIGN, V152, P232, DOI 10.1049/ip-vis:20041257
   Yahiaoui T, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3455989
   Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122
   Zhu QY, 2010, INT CONF COMPUT AUTO, P81, DOI 10.1109/ICCAE.2010.5451996
NR 41
TC 13
Z9 14
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6801
EP 6819
DI 10.1007/s11042-016-3352-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400032
DA 2024-07-18
ER

PT J
AU Shakoor, MH
   Tajeripour, F
AF Shakoor, Mohammad Hossein
   Tajeripour, Farshad
TI Noise robust and rotation invariant entropy features for texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local entropy; Variance; Local binary pattern; Texture classification;
   Noise resistance
ID LOCAL BINARY PATTERNS; SCALE
AB In this paper, a new formula is proposed that uses local entropy for texture feature extraction. This new method is similar to entropy; however, it calculates the local entropy of each local patch of textures. Entropy (ENT) is an attribute that measures the randomness of gray-level distribution of image. Entropy extracts dissimilarity of each local patch. In this paper, local entropy is compared to Local Binary Pattern (LBP) and local variance (VAR). All of these descriptors are rotation invariant and are used for extracting the features from each local neighborhood of textures. In spite of low accuracy of VAR and LBP the performance of ENT does not decrease significantly for noisy textures. In other words, ENT is more robust to noise than VAR and LBP. Implementations on Outex, UIUC, CUReT and MeasTex datasets show that entropy is more accurate than variance and LBP. Similar to VAR and LBP, ENT can be combined with other descriptors to improve the performance of classification. For almost all datasets that are used in implementation part, LBP/ENT is more accurate than LBP/ VAR for normal and noisy textures. Also the ENT accuracy outperforms the accuracy of VAR and LBP and most of the advanced noise robust LBP versions for low Signal to Noise Ratio (SNR) values (SNR < 10). ENT feature is a continuous value so it is necessary to quantize to discrete value for histogram. The quantization and train step of ENT is the same as VAR.
C1 [Shakoor, Mohammad Hossein; Tajeripour, Farshad] Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
C3 Shiraz University
RP Shakoor, MH (corresponding author), Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
EM mhshakoor@shirazu.ac.ir; tajeri@shirazu.ac.ir
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen Timo., 2007, Proceedings of the Finnish Signal Processing Symposium, FINSIG, P1
   [Anonymous], 2007, Computer Vision
   [Anonymous], 2012, IEEE C COMP VIS PATT
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Desir C, 2012, COMPUT MED IMAG GRAP, V36, P264, DOI 10.1016/j.compmedimag.2011.11.001
   Fathi A, 2012, PATTERN RECOGN LETT
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Haralick RM, 1979, IEEE T SYST MAN CYBE
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   Huang Y., 2006, P BRIT MACH VIS C, P901
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leutenegger, 2011, BRISK BINARY ROBUST
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Mir AH, 1995, IEEE ENG MED BIOL MA, V14
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1997, ACTA U OULUENSIS C, V105
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Smith G, 1998, UNIV QLD
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2003, PROC CVPR IEEE, P691
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xu Y., 2005, P INT C COMP VIS PAT, P1932
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 48
TC 18
Z9 18
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8031
EP 8066
DI 10.1007/s11042-016-3455-6
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800020
DA 2024-07-18
ER

PT J
AU Asteriadis, S
   Daras, P
AF Asteriadis, Stylianos
   Daras, Petros
TI Landmark-based multimodal human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectral clustering; Human action recognition; Multimodal fusion
ID HUMAN MOTION; SEQUENCES; VIDEO
AB Human activity recognition has received a lot of attention recently, mainly thanks to the advancements in sensing technologies and systems' increasing computational power. However, complexity in human movements, sensing devices' noise and person-specific characteristics impose challenges that still remain to be overcome. In the proposed work, a novel, multi-modal human action recognition method is presented for handling the aforementioned issues. Each action is represented by a basis vector and spectral analysis is performed on an affinity matrix of new action feature vectors. Using modality-dependent kernel regressors for computing the affinity matrix, complexity is reduced and robust low-dimensional representations are achieved. The proposed scheme supports online adaptivity of modalities, in a dynamic fashion, according to their automatically inferred reliability. Evaluation on three publicly available datasets demonstrates the potential of the approach.
C1 [Asteriadis, Stylianos] Maastricht Univ, Dept Data Sci & Knowledge Engn, Postbus 616, NL-6200 MD Maastricht, Netherlands.
   [Daras, Petros] Inst Informat Technol, Ctr Res Technol Hellas, 1st km Thermi Panorama, Thessaloniki 57001, Greece.
C3 Maastricht University; Centre for Research & Technology Hellas
RP Asteriadis, S (corresponding author), Maastricht Univ, Dept Data Sci & Knowledge Engn, Postbus 616, NL-6200 MD Maastricht, Netherlands.
EM stelios.asteriadis@maastrichtuniversity.nl; daras@iti.gr
RI Daras, Petros/F-5284-2012; Asteriadis, Stylianos/O-2140-2016
OI Daras, Petros/0000-0003-3814-6710; Asteriadis,
   Stylianos/0000-0002-4298-6870
FU EU [690090]
FX This work has been partly funded by the EU Horizon 2020 Framework
   Programme under grant agreement no. 690090 (ICT4Life project).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2013, Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG), 2013 Fourth National Conference on
   Asteriadis S., 2013, Proceedings of the 6th International Conference on Computer Vision / Computer Graphics Collaboration Techniques and Applications. MIRAGE '13, P3, DOI DOI 10.1145/2466715.2466727
   Asteriadis S, 2008, LECT NOTES COMPUT SC, V5163, P927, DOI 10.1007/978-3-540-87536-9_95
   Asteriadis S, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769569
   Caridakis G, 2007, INT FED INFO PROC, P375
   Chen C, 3D ACTION RECOGNITIO
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen X., 2011, P 25 AAAI C ART INT, P313
   Delachaux B, 2013, LECT NOTES COMPUT SC, V7903, P216
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   He WH, 2012, EURASIP J ADV SIG PR, DOI [10.1186/1687-6180-2012-108, 10.1155/2012/615476]
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kapsouras I, 2014, J VIS COMMUN IMAGE R, V25, P1432, DOI 10.1016/j.jvcir.2014.04.007
   Ke Y, 2007, 7 INT WORKSH VIS SUR
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Kumari S., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P239, DOI 10.1109/NCVPRIPG.2011.58
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu CY, 2013, INT CONF MACH LEARN, P381, DOI 10.1109/ICMLC.2013.6890498
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Nandakumar K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P475, DOI 10.1145/2522848.2532593
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Shen C, 2015, ARXIV150201368
   Song Y, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P27
   Stork J. A., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P509, DOI 10.1109/ROMAN.2012.6343802
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   von Luxburg U, 2007, STAT COMPUT
   Wang XY, 2012, INT C PATT RECOG, P3553
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Zappi P., 2008, ACTIVITY RECOGNITION
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
NR 36
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4505
EP 4521
DI 10.1007/s11042-016-3945-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200064
DA 2024-07-18
ER

PT J
AU Buzzi, MC
   Buzzi, M
   Leporini, B
   Trujillo, A
AF Buzzi, Maria Claudia
   Buzzi, Marina
   Leporini, Barbara
   Trujillo, Amaury
TI Analyzing visually impaired people's touch gestures on smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessibility; Visually impairment; Touch gestures; Mobile devices;
   Multimodal interfaces
ID USER-INTERFACE; RECOGNITION; BLIND
AB We present an analysis of how visually impaired people perform gestures on touch-screen smartphones and report their preferences, explaining the procedure and technical implementation that we followed to collect gesture samples. To that end, we recruited 36 visually impaired participants and divided them into two main groups of low-vision and blind people respectively. We then examined their touch-based gesture preferences in terms of number of strokes, multi-touch, and shape angle, as well as their execution in geometric, kinematic and relative terms. For this purpose, we developed a wireless system to simultaneously record sample gestures from several participants, with the possibility of monitoring the capture process. Our results are consistent with previous research regarding the preference of visually impaired users for simple gestures: with one finger, a single stroke, and in one or two cardinal directions. Of the two groups of participants, blind people are less consistent with multi-stroke gestures. In addition, they are more likely than low-vision people to go outside the bounds of the display in the absence of its physical delimitation of, especially with multi-touch gestures. In the case of more complex gestures, rounded shapes are greatly preferred to angular ones, especially by blind people, who have difficulty performing straight gestures with steep or right angles. Based on these results and on previous related research, we offer suggestions to improve gesture accessibility of handheld touchscreen devices.
C1 [Buzzi, Maria Claudia; Buzzi, Marina; Trujillo, Amaury] IIT CNR, V Moruzzi 1, I-56124 Pisa, Italy.
   [Leporini, Barbara] ISTI CNR, V Moruzzi 1, I-56124 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Informatica e
   Telematica (IIT-CNR); Consiglio Nazionale delle Ricerche (CNR); Istituto
   di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Buzzi, MC (corresponding author), IIT CNR, V Moruzzi 1, I-56124 Pisa, Italy.
EM claudia.buzzi@iit.cnr.it
RI Buzzi, Maria Claudia/A-3286-2016; Buzzi, Marina/A-3038-2013; Trujillo,
   Amaury/Q-3946-2018; Leporini, Barbara/V-4626-2017
OI Buzzi, Maria Claudia/0000-0001-7818-0601; Buzzi,
   Marina/0000-0003-1725-9433; Leporini, Barbara/0000-0003-2469-9648
CR Albinsson P.A., 2003, Proceedings of CHI 2003, P105, DOI [DOI 10.1145/642611.642631, 10.1145/642611.642631]
   [Anonymous], 2014, Proceedings of the 16th International Conference on Multimodal Interaction, DOI DOI 10.1145/2663204.2663273
   [Anonymous], PROBLEM M RANKINGS
   Anthony L., 2012, P GRAPHICS INTERFACE, P117
   Anthony L, 2013, P GRAPH INT 2013 REG
   Anthony L., 2010, Proc. of Graphics Interface 2010, P245
   Anthony Lisa., 2012, P 2012 ACM INT C INT
   Azenkot S, 2013, 15 INT ACM SIGACCESS
   Bayus BL, 1997, J MARKETING RES, V34, P50, DOI 10.2307/3152064
   BENYON D, 1993, HUM FAC INF, V10, P149
   Bragdon A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P403
   Buzzi M.C., 2014, Proceedings of the 16th International ACM SIGACCESS Conference on Computers; Accessibility. ASSETS'14. Rochester, P131, DOI [10.1145/2661334.2661354, DOI 10.1145/2661334.2661354]
   Buzzi Maria Claudia., 2015, Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter, P94, DOI DOI 10.1145/2808435.2808448
   Charland A, 2011, COMMUN ACM, V54, P49, DOI 10.1145/1941487.1941504
   Findlater Leah, 2013, P SIGCHI C HUM FACT
   GOLDBERG D, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P80
   Guerreiro T, 2008, 15 EUR C COGN ERG
   Heo S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2597, DOI 10.1145/2556288.2557234
   Kammer D., 2010, ITS'10, P49
   Kane Shaun K., 2008, Proceedings of the 10th international ACM SIGACCESS confer- ence on Computers and accessibility, Assets '08, P73, DOI DOI 10.1145/1414471.1414487
   Kane SK, 2013, 15 INT ACM SIGACCESS
   Kane SK, 2011, SIGCHI C
   Kristensson P., 2004, P 17 ANN ACM S USER, P43, DOI DOI 10.1145/1029632.1029640
   Lettner F, 2012, P 11 INT C MOB UB MU, P49
   LI Y, 2010, P SIGCHI C HUM FACT, P2169
   Long A. C.  Jr., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P360, DOI 10.1145/332040.332458
   Luthra V, 2015, LECT NOTES COMPUT SC, V9176, P25, DOI 10.1007/978-3-319-20681-3_3
   MacKenzie IS, 1997, PROC GRAPH INTERF, P129
   McGookin D, 2008, 5 NORD C HUM COMP IN
   Moore DA, 1999, ORGAN BEHAV HUM DEC, V78, P146, DOI 10.1006/obhd.1999.2828
   Morris John, 2014, Inclusive designing: Joining usability, accessibility, and inclusion, P69
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI [DOI 10.1145/2591689, 10.1145/2591689]
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   Oh U, 2013, 15 INT ACM SIGACCESS
   Oh Uran., 2013, P SIGCHI C HUMAN FAC, P1129, DOI DOI 10.1145/2470654.2466145
   Oliveira J, 2011, 13 INT ACM SIGACCESS
   Oviatt S, 2000, HUM-COMPUT INTERACT, V15, P263, DOI 10.1207/S15327051HCI1504_1
   PITTMAN JA, 1991, P SIGCHI C HUM FACT, P271
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Plimmer B, 2008, SIGCHI C
   Postma A, 2007, PERCEPTION, V36, P1253, DOI 10.1068/p5441
   Rivera J., 2014, GARTNER SAYS SALES S
   Rodrigues A, 2015, P ASSETS 15
   Romano M, 2015, LECT NOTES COMPUT SC, V9296, P38, DOI 10.1007/978-3-319-22701-6_3
   Rubine D, 1991, P 18 ANN C COMP GRAP
   Ruiz J., 2011, P SIGCHI C HUM FACT
   Sandnes FE, 2012, UNIVERSAL ACCESS INF, V11, P421, DOI 10.1007/s10209-011-0258-4
   Schmidt M, 2009, LECT NOTES COMPUT SC, V5615, P574, DOI 10.1007/978-3-642-02710-9_64
   Sears A, 2011, P SIGCHI C HUM FACT
   Sezgin T.M., 2005, Proceedings of International Conference on Intelligent User Interfaces (IUI 2005), P281, DOI DOI 10.1145/1040830.1040899
   Spano Lucio Davide, 2012, Human-Centered Software Engineering. Proceedings of the 4th International Conference, HCSE 2012, P34, DOI 10.1007/978-3-642-34347-6_3
   Vatavu R-D, 2014, P 16 INT C MULT INT
   Vatavu R-D, 2013, P SIGCHI C HUM FACT
   Vatavu R-D, 2013, 15 ACM INT C MULT IN
   Vatavu RD, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P273
   Vidal Sylvie., 2010, P 6 NORDIC C HUMAN C, P809
   Walker G, 2012, J SOC INF DISPLAY, V20, P413, DOI 10.1002/jsid.100
   Westerman W., 2001, P HUMAN FACTORS ERGO, V1, P632, DOI DOI 10.1177/154193120104500612
   Willems D, 2009, PATTERN RECOGN, V42, P3303, DOI 10.1016/j.patcog.2009.01.030
   Wobbrock J.O., 2005, P CHI 05 HUM FACT CO, P1869, DOI [DOI 10.1145/1056808.1057043, 10.1145/1056808.1057043]
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Xu S, 2015, LECT NOTES COMPUT SC, V9176, P161, DOI 10.1007/978-3-319-20681-3_15
   Zhong Yu, 2014, P 11 WEB ALL C W4A 1, P1
NR 63
TC 33
Z9 37
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5141
EP 5169
DI 10.1007/s11042-016-3594-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500021
DA 2024-07-18
ER

PT J
AU Chen, X
   Li, LF
   Xiang, XD
AF Chen, Xin
   Li, Longfei
   Xiang, Xudong
TI Ant colony learning method for joint MCS and resource block allocation
   in LTE Femtocell downlink for multimedia applications with QoS
   guarantees
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Femtocell; Modulation and coding scheme; Resource block; QoS guarantees
ID POWER ALLOCATION; SUBCHANNEL
AB With the emergence of bandwidth-intensive online mobile multimedia applications in wireless networks, in order to make mobile users enjoy better Quality of Service (QoS) under the conditions of limited resources, efficient radio spectrum resource allocation schemes are always desirable. This paper addresses the problem of joint Resource Block (RB) allocation and Modulation-and-Coding Scheme (MCS) selection in LTE femtocell DownLink (DL) for mobile multimedia applications. We first formulate the problem as an Integer Linear Program (ILP) whose objective is to minimize the number of allocated RBs of a closed femtocell, while guaranteeing minimum throughput for each user. In view of the NP-hardness of the ILP, we then propose an intelligent optimization learning algorithm called ACO-HM algorithm with reduced polynomial time complexity. The Ant Colony Optimization (ACO) learning algorithm exhibits better performance in machine learning and supports parallel search for the RB allocation, while the Harmonic Mean (HM) method is to select a more appropriate MCS than the MINimum/MAXimum MCS selection schemes (MIN/MAX). Simulation results show that compared with the ACO-MIN algorithm and the ACO-MAX algorithm, the proposed ACO-HM learning algorithm achieves better performance with fewer RBs and better QoS guarantees.
C1 [Chen, Xin; Li, Longfei] Beijing Informat Sci & Technol Univ, Comp Sch, Beijing 100101, Peoples R China.
   [Xiang, Xudong] Univ Sci & Technol Beijing, Dept Comp Sci & Technol, Beijing 100083, Peoples R China.
C3 Beijing Information Science & Technology University; University of
   Science & Technology Beijing
RP Chen, X (corresponding author), Beijing Informat Sci & Technol Univ, Comp Sch, Beijing 100101, Peoples R China.
EM chenxin@mail.tsinghua.edu.cn; longfei.li.stu@gmail.com;
   x.xiang.cn@ieee.org
RI li, long/HOF-6990-2023; Xiang, Xiaodong/Q-7727-2018
FU National Natural Science Foundation of China (NSFC) [61370065]; National
   Science & Technology Pillar Program [2015BAK12B00]; Project of
   Construction of Innovative Teams and Teacher Career Development for
   Universities and Colleges Under Beijing Municipality [IDHT20130519]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant No. 61370065, and the National Science &
   Technology Pillar Program(2015BAK12B00), and the Project of Construction
   of Innovative Teams and Teacher Career Development for Universities and
   Colleges Under Beijing Municipality (IDHT20130519). A part of this paper
   [22] has been previously published in GAMENETS 2014.
CR Ahmadi H., 2010, IEEE Wireless Communications and Networking Conf. (WCNC), P1
   Ahmadi H., 2011, ENV EL ENG EEEIC 201, P1
   Ahn JK, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/340717
   Alexiou A., 2011, IFIP Wireless Days (WD), P1, DOI DOI 10.1109/WD.2010.5657749
   Andrews JG, 2012, IEEE J SEL AREA COMM, V30, P497, DOI 10.1109/JSAC.2012.120401
   [Anonymous], P SPRING SUP
   [Anonymous], P IEEE VTC FALL
   [Anonymous], EPRINT ARXIV
   [Anonymous], 2012, P IEEE MILCOM ORL FL
   [Anonymous], 2013, 2013 IEEE INT C ADV, DOI DOI 10.1109/ANTS.2013.6802850
   [Anonymous], TS25468 3GPP
   [Anonymous], 2013, PLAY ME SOMETHING QU
   [Anonymous], TS25469 3GPP
   [Anonymous], TS25467 3GPP
   Baig AR, 2012, NEURAL COMPUT APPL, V21, P219, DOI 10.1007/s00521-010-0490-5
   Bochrini S., 2013, 6th Joint IFIP Wireless and Mobile Networking Conference (WMNC), P1
   Dorigo M., 2010, COMPUTATIONAL INTELL, V1, P28, DOI DOI 10.1109/MCI.2006.329691
   Fan JM, 2011, 2011 INTERNATIONAL CONFERENCE ON COMPUTER, ELECTRICAL, AND SYSTEMS SCIENCES, AND ENGINEERING (CESSE 2011), P100
   Francis J, 2013, IEEE GLOB COMM CONF, P3703, DOI 10.1109/GLOCOM.2013.6831649
   Kim J, 2010, IEEE T VEH TECHNOL, V59, P4340, DOI 10.1109/TVT.2010.2070816
   Kim RY, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5277460
   Ksairi N, 2010, IEEE T SIGNAL PROCES, V58, P720, DOI 10.1109/TSP.2009.2033301
   Lai WS, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P3364
   Li L, 2014, CHANDOS INF PROF SER, P1
   Li Z, 2012, IEEE WCNC, P1212, DOI 10.1109/WCNC.2012.6213962
   Lin CP, 2013, MULTIMED TOOLS APPL, V67, P641, DOI 10.1007/s11042-012-1041-0
   López-Pérez D, 2013, IEEE ACM T NETWORK, V21, P1145, DOI 10.1109/TNET.2012.2218124
   Malik S, 2014, P ANN HICSS, P5114, DOI 10.1109/HICSS.2014.629
   Marshoud Hanaa, 2012, 2012 IEEE 8th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob 2012), P474, DOI 10.1109/WiMOB.2012.6379115
   Mhiri F., 2011, 2011 The 10th IFIP Annual Mediterranean Ad Hoc Networking Workshop (Med-Hoc-Net 2011), P45, DOI 10.1109/Med-Hoc-Net.2011.5970492
   Fajardo JO, 2014, MULTIMED TOOLS APPL, V70, P311, DOI 10.1007/s11042-011-0825-y
   Pedemonte M, 2011, APPL SOFT COMPUT, V11, P5181, DOI 10.1016/j.asoc.2011.05.042
   Siddavaatam R, 2013, P SPRINGERWIRELESS P, P1
   Song H, 2011, IEEE T COMMUN, V59, P603, DOI 10.1109/TCOMM.2011.011811.100056
   Wang YZ, 2012, INT J INF SECUR, V11, P41, DOI 10.1007/s10207-011-0148-z
   Zhang HJ, 2012, IEEE GLOB COMM CONF, P4572, DOI 10.1109/GLOCOM.2012.6503839
   Zhang JM, 2011, WIRELESS PERS COMMUN, V57, P501, DOI 10.1007/s11277-009-9858-1
   Zhu HL, 2012, IEEE T COMMUN, V60, P499, DOI 10.1109/TCOMM.2011.112811.110036
NR 38
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4035
EP 4054
DI 10.1007/s11042-015-2991-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200040
DA 2024-07-18
ER

PT J
AU Jin, R
   Kim, J
AF Jin, Ruichen
   Kim, Jongweon
TI Tracking feature extraction techniques with improved SIFT for video
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature detection; Tracking; Video feature; SIFT; Identification;
   Torrent
AB This paper presents a method for tracking of object movements and detecting of feature to identify video content using improved Scale-Invariant Feature Transform (SIFT). SIFT can robustly identify objects even among clutter and under partial occlusion, because the SIFT feature descriptor is invariant to uniform scaling, orientation, and also partially invariant to affine distortion and illumination changes. Even if the video drops frames or attacked, our method can extract the features. In our method we detect the video features from tracking the object's movement and make a dataset with feature sequences to identify video. In contrast to the existing tracking techniques, our method recognized reliable object coordinate. The developed algorithm will be an essential part of a completely tracking and identification system. To evaluate the performance of the proposed approach, we was experimenting with several genres of video. Compare with the original SIFT algorithm, we reducing up to 5 % in processing time was achieved for matching. Also appoint the position of the object area in tracking method make the proposed method automatic, fast and effective.
C1 [Jin, Ruichen] Sangmyung Univ, Dept Copyright Protect, Seoul, South Korea.
   [Kim, Jongweon] Sangmyung Univ, Dept Contents & Copyright, Seoul, South Korea.
C3 Sangmyung University; Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Dept Contents & Copyright, Seoul, South Korea.
EM kimyejin0602@gmail.com; jwkim@smu.ac.kr
RI Kim, Jongweon/AAO-2221-2020
OI Kim, Jongweon/0000-0002-8916-6431
FU Ministry of Culture, Sports and Tourism (MCST); Korea Copyright
   Commission
FX This research project was supported by the Ministry of Culture, Sports
   and Tourism (MCST) and the Korea Copyright Commission in 2014.
CR [Anonymous], 2006, P 9 EUR C COMP VIS M
   Ce L, 2011, IEEE T PATTERN ANAL, V33
   Chapelle O, 2006, SEMISURPERVISED LEAR
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jin R, 2012, COMM COM INF SC, V342, P39
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Ke Y., 2004, P 2004 IEEE COMP SOC
   Kim J, 2010, SIGNAL PROCESS-IMAGE, V25, P559, DOI 10.1016/j.image.2010.07.004
   Lee Y., 2011, COMMUN COMPUT PHYS, V263
   Li D, 2012, APPL MATH INFORM SCI, V6, p513S
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Zdennek K, TRACKING LEARNING DE
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 14
TC 7
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5927
EP 5936
DI 10.1007/s11042-015-2694-2
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500056
DA 2024-07-18
ER

PT J
AU Wang, JC
   Wang, CY
   Chin, YH
   Liu, YT
   Chen, ET
   Chang, PC
AF Wang, Jia-Ching
   Wang, Chien-Yao
   Chin, Yu-Hao
   Liu, Yu-Ting
   Chen, En-Ting
   Chang, Pao-Chi
TI Spectral-temporal receptive fields and MFCC balanced feature extraction
   for robust speaker recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE STRF; Speaker recognition; Feature extraction; Speaker authentication
ID SPEECH
AB This paper proposes a speaker recognition system using acoustic features that are based on spectral-temporal receptive fields (STRFs). The STRF is derived from physiological models of the mammalian auditory system in the spectral-temporal domain. With the STRF, a signal is expressed by rate (in Hz) and scale (in cycles/octaves). The rate and scale are used to specify the temporal response and spectral response, respectively. This paper uses the proposed STRF based feature to perform speaker recognition. First, the energy of each scale is calculated using the STRF representation. A logarithmic operation is then applied to the scale energies. Finally, a discrete cosine transform is utilized to the generation of the proposed STRF feature. This paper also presents a feature set that combines the proposed STRF feature with conventional Mel frequency cepstral coefficients (MFCCs). The support vector machines (SVMs) are adopted to be the speaker classifiers. To evaluate the performance of the proposed speaker recognition system, experiments on 36-speaker recognition were conducted. Comparing with the MFCC baseline, the proposed feature set increases the speaker recognition rates by 3.85 % and 18.49 % on clean and noisy speeches, respectively. The experiments results demonstrate the effectiveness of adopting STRF based feature in speaker recognition.
C1 [Wang, Jia-Ching; Wang, Chien-Yao; Chin, Yu-Hao] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
   [Liu, Yu-Ting; Chen, En-Ting; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, Jhongli, Taiwan.
C3 National Central University; National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli, Taiwan.
EM pcchang@ce.ncu.edu.tw
CR [Anonymous], 2011, ACM T INTELLIGENT SY
   Anthony L, 2015, RSR2015 DATABASE TEX
   Anthony L, 2013, PHONETICALLY CONSTRA
   Campbell W., 2006, IEEE SIGNAL PROCESSI
   Campbell WM, 2006, COMPUTER SPEECH LANG
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chi TS, 2012, J ACOUST SOC AM, V131, pEL368, DOI 10.1121/1.3697534
   Childers D, 1998, IEEE SIGNAL PROC MAG, V15, P24, DOI 10.1109/79.671130
   Desai S, 2010, IEEE T AUDIO SPEECH, V18, P954, DOI 10.1109/TASL.2010.2047683
   Didier M, 2001, ODYSSEY 2001
   Ding IR, 2013, MULTIMEDIA TOOLS APP
   Douglas AR, 1995, IEEE T SPEECH AUDIO
   Hatch Andrew O., 2006, 2006 ICSLP
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Khan SA, 2015, 2015 8 INT C ADV PAT
   Kuan TW, 2012, IEEE T VLSI SYST, V20, P673, DOI 10.1109/TVLSI.2011.2107533
   Kuruvachan KG, 2014, INT C POW SIGN CONTR
   Lukas B, 2007, IEEE T AUDIO SPEECH
   Srinivas V, 2013, INT J SIGNAL PROCESS, V6, P193, DOI DOI 10.14257/IJSIP.2013.6.6.18
   Stafylakis T, 2013, TEXT DEPENDENT SPEAK
   TUZUN OB, 1994, 7TH MEDITERRANEAN ELECTROTECHNICAL CONFERENCE, VOLS 1-3, P65, DOI 10.1109/MELCON.1994.381143
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang JC, 2002, INTEGRATION, V32, P111, DOI 10.1016/S0167-9260(02)00045-7
   Wang JC, 2014, ASIA PACIFIC SIGNAL
   Wang JC, 2007, IEEE COMPUT INTELL M, V2, P52, DOI 10.1109/MCI.2007.353420
   Wang JC, 2015, IEEE T AUTOM SCI ENG, V12, P1191, DOI 10.1109/TASE.2015.2467311
   Wang JC, 2015, IEEE T AUTOM SCI ENG, V12, P1235, DOI 10.1109/TASE.2015.2470119
   Wang JC, 2015, IEEE T VLSI SYST, V23, P1355, DOI 10.1109/TVLSI.2014.2335112
   Woojay J., 2008, IEEE T AUDIO SPEECH, V15, P1802
   Yun L, 2014, IEEE INT C AC SPEECH
   Zhe J, 2013, 2013 9 INT C NAT COM
NR 31
TC 9
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4055
EP 4068
DI 10.1007/s11042-016-3335-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200041
DA 2024-07-18
ER

PT J
AU Bogatinov, D
   Lameski, P
   Trajkovik, V
   Trendova, KM
AF Bogatinov, Dimitar
   Lameski, Petre
   Trajkovik, Vladimir
   Trendova, Katerina Mitkovska
TI Firearms training simulator based on low cost motion tracking sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microsoft Kinect; Simulator; Training; Sensors
ID MICROSOFT KINECT
AB This paper gives an overview of new low cost firearms simulator based on a motion-tracking sensor - Microsoft Kinect that provides aiming results that are highly correlated with real live results. This simulator uses Microsoft Kinect SDK based application that utilizes the input from the embedded Kinect sensors to calculate the aiming point at the screen, recognizes the user's gestures and the audio inputs, and emulates commands in a simulation based on those inputs. We have created three test modules that are using different calibration points and mathematical frameworks to accurately transform the gunshot targeting point in proper pixel coordinate. The initial experiments with the proposed firearms simulator show that the results that are accomplished by humans using the simulator and the results accomplished in the real live firearms shooting have a high correlation coefficient of 0.82. This shows that the proposed simulator can be used in firearms training and is a good alternative to the existing expensive simulators available on the market.
C1 [Bogatinov, Dimitar; Trendova, Katerina Mitkovska] Mil Acad Gen Mihailo Apostolski, Skopje 1000, North Macedonia.
   [Lameski, Petre; Trajkovik, Vladimir] Fac Comp Sci & Engn, Str Rugjer Boshkovikj 16, Skopje 1000, North Macedonia.
RP Bogatinov, D (corresponding author), Mil Acad Gen Mihailo Apostolski, Skopje 1000, North Macedonia.
EM dimitar.bogatinov@ugd.edu.mk; petre.lameski@finki.ukim.mk;
   vladimir.trajkovik@finki.ukim.mk; katerina.trendova@ugd.edu.mk
RI Trajkovik, Vladimir/K-9758-2019; Lameski, Petre/P-8389-2014
OI Bogatinov, dimitar/0000-0001-6263-543X; Trajkovik,
   Vladimir/0000-0001-8103-8059
CR [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], ADV COMPUTER CONTROL
   [Anonymous], FUTURE INFORM TECHNO
   [Anonymous], INT IND TRAIN SIM ED
   [Anonymous], SENSORS
   [Anonymous], P 18 AUSTR C COMP HU
   [Anonymous], ADV INTELL SYST COMP
   [Anonymous], ENCY STAT SCI
   [Anonymous], READINGS COMPUTER VI
   [Anonymous], INT IND TRAIN SIM ED
   [Anonymous], INT J INF ELECT ENG
   [Anonymous], INTRO KINECT
   [Anonymous], 32 ANN ACM C HUM FAC
   [Anonymous], GERONTECHNOLOGY
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], 1989, ABS PROJECTION ALGOR
   [Anonymous], THEORY APPL NUMER AN
   [Anonymous], 5 INT C PERV TECHN R
   [Anonymous], ENCY RES DESIGN
   [Anonymous], IEEE VIRT REAL C
   Craciun EG, 2013, ADV ELECTR COMPUT EN, V13, P47, DOI 10.4316/AECE.2013.01008
   Gonzalez-Jorge H, 2013, MEASUREMENT, V46, P1800, DOI 10.1016/j.measurement.2013.01.011
   Kim H, 2014, SCI WORLD J, DOI 10.1155/2014/683045
   Molina J.P., 2013, S ESPA OL ENTRETENIM, P119
   WEI GQ, 1994, IEEE T PATTERN ANAL, V16, P469, DOI 10.1109/34.291450
   Yeo H. S., 2013, MULTIMED TOOLS APPL, P1
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 29
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1403
EP 1418
DI 10.1007/s11042-015-3118-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000061
DA 2024-07-18
ER

PT J
AU Sridhar, S
   Sathishkumar, R
   Sudha, GF
AF Sridhar, Srividhya
   Sathishkumar, R.
   Sudha, Gnanou Florence
TI Adaptive halftoned visual cryptography with improved quality and
   security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Halftoning; Adaptive halftoning; Polynomial image
   secret sharing
ID SHARING METHOD; SECRETS
AB Visual Cryptography Scheme (VCS) is a cryptographic technique which can hide image based secrets. Even though VCS has the major advantage that the decoding can be done with the help of Human Visual System (HVS), yet it does not provide sufficient reconstruction quality. Hence, Two in One Image Secret Sharing Scheme (TiOISSS) is used which provides two decoding phases. However, the existing TiOISSS method has several limitations. In this work, a Modified TiOISSS is proposed in which an adaptive threshold is used for halftoning, which changes depending on the nature of the pixels present in image. By this, the quality of reconstructed secret image is improved in the first decoding stage compared to the existing scheme. In addition, the security is also enhanced by pixel and bit level permutation with a 64 bit key and embedding the key in Gray VCS shadows. To verify the authenticity of the image, a secret message is also embedded in the shadows. Security analysis shows that the Modified TiOISSS is robust to Brute Force and Man-in-Middle attacks.
C1 [Sridhar, Srividhya; Sudha, Gnanou Florence] Pondicherry Engn Coll, Dept Elect & Commun, Pondicherry, India.
   [Sathishkumar, R.] Perunthalaivar Kamarajar Inst Engn & Technol, Dept Elect & Commun, Pondicherry, India.
C3 Pondicherry Engineering College
RP Sudha, GF (corresponding author), Pondicherry Engn Coll, Dept Elect & Commun, Pondicherry, India.
EM srividhya2207@gmail.com; sathish.pkiet@gmail.com; gfsudha@pec.edu
RI Sudha, Gnanou Florence/GLU-3814-2022; SRIDHAR, SRIVIDHYA/AAH-6420-2020
OI Sudha, Gnanou Florence/0000-0002-5471-3255; 
CR Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Arya KV, 2014, P 9 INT C IND INF SY
   Askari N, 2013, P 26 ANN IEEE CAN C
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Lee CC, 2014, J VISUAL LANG COMPUT, V25, P243, DOI 10.1016/j.jvlc.2013.11.001
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin C-C, 2002, J PATTERN RECOGNIT L, V24, P349
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu Feng, 2014, T DATA HIDING MULTIM, V9, P1, DOI DOI 10.1371/J0URNAL.P0NE.0110272
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2013, PERS UBIQUIT COMPUT, V17, P843, DOI 10.1007/s00779-012-0535-0
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 21
TC 10
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 815
EP 834
DI 10.1007/s11042-015-3066-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000035
DA 2024-07-18
ER

PT J
AU Tsai, YW
   Cheng, FC
   Ruan, SJ
AF Tsai, Yu-Wen
   Cheng, Fan-Chieh
   Ruan, Shanq-Jang
TI An efficient dynamic window size selection method for 2-D histogram
   construction in contextual and variational contrast enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Integral histogram; Histogram equalization; 2D
   histogram
ID INTEGRAL HISTOGRAM; EQUALIZATION
AB Contrast enhancement is usually applied to those images captured in poor lighting conditions for improving the visual quality. Using interpixel contextual information, a 2-D histogram based contrast enhancement (CE) was proposed to improve image contrast and preserve more details as well. In order to maintain the balance between contrast enhancement and detail preservation, the window size of a 2-D histogram-based contrast enhancement should be adjustable based on the original image contrast and details. In addition, the computation intensive 2-D histogram based CE should be accelerated for real-time applications. Thus, we propose an efficient dynamic window size 2-D histogram construction algorithm in this paper. The proposed algorithm divides the input image into sub-blocks and assigns them appropriate window sizes, which depend upon the standard deviation and the number of distinct intensity values of each individual sub-block. Furthermore, the integral histogram is employed to be able to compute the dynamic range 2-D histogram in constant time while fluctuant window size is adopted dynamically. Experimental results demonstrate the efficacy and efficiency of the proposed algorithm.
C1 [Tsai, Yu-Wen; Cheng, Fan-Chieh; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Tsai, YW (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 106, Taiwan.
EM m10002124@mail.ntust.edu.tw
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Agaian S, 2007, IEEE T IMAGE PROCESS, V16
   [Anonymous], 1992, Digital Image Processing
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng FC, 2010, IEICE T INF SYST, VE93D, P1773, DOI 10.1587/transinf.E93.D.1773
   Ginesu G, 2004, IEEE T IND ELECTRON, V51, P480, DOI 10.1109/TIE.2004.825286
   Kim DH, 2009, MULTIDIM SYST SIGN P, V20, P81, DOI 10.1007/s11045-008-0049-0
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Leung CC, 2005, PATTERN RECOGN LETT, V26, P769, DOI 10.1016/j.patrec.2004.09.032
   Panetta K, 2008, IEEE T SYST MAN CY B, V38
   Peng YT, 2013, IEEE IMAGE PROC, P891, DOI 10.1109/ICIP.2013.6738184
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Sundaram M, 2011, APPL SOFT COMPUT, V11, P5809, DOI 10.1016/j.asoc.2011.05.003
   Tsai YW, 2012, IEEE INT SYMP CIRC S, P2769, DOI 10.1109/ISCAS.2012.6271883
   Xie XD, 2005, PATTERN RECOGN, V38, P221, DOI 10.1016/j.patcog.2004.07.002
   Zhu H, 1999, COMPUT VIS IMAGE UND, V73, P281, DOI 10.1006/cviu.1998.0723
NR 18
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1121
EP 1137
DI 10.1007/s11042-015-3082-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000049
DA 2024-07-18
ER

PT J
AU Wan, MH
   Yang, GW
   Gai, S
   Yang, ZJ
AF Wan, Minghua
   Yang, Guowei
   Gai, Shan
   Yang, Zhangjing
TI Two-dimensional discriminant locality preserving projections (2DDLPP)
   and its application to feature extraction via fuzzy set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2DDLPP; Fuzzy set theory; Feature extraction; FKNN; Membership degree
ID DIMENSIONALITY REDUCTION; FACE; RECOGNITION
AB This paper presents a new method for image feature extraction, namely, the fuzzy 2D discriminant locality preserving projections (F2DDLPP) based on the 2D discriminant locality preserving projections (2DDLPP) and fuzzy set theory. Firstly, we calculate the membership degree matrix by fuzzy k-nearest neighbor (FKNN), then we incorporate the membership degree matrix into the definition of the intra-class scatter matrix and inter-class scatter matrix, respectively. Secondly, we can get the fuzzy intra-class scatter matrix and fuzzy inter-class scatter matrix, respectively. The FKNN is implemented to achieve the distribution information of original samples, and this information is utilized to redefine corresponding scatter matrices. So, F2DDLPP can extract discriminative features from overlapping (outlier) samples which is different to the conventional 2DDLPP. Finally, Experiments on the Yale, ORL face databases, USPS database and PolyU palmprint database are demonstrated to verify the effectiveness of the proposed algorithm.
C1 [Wan, Minghua; Yang, Guowei; Gai, Shan; Yang, Zhangjing] Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.
   [Wan, Minghua] Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
   [Wan, Minghua] Nanjing Xiaozhuang Univ, Key Lab Trusted Cloud Comp & Big Data Anal, Nanjing 211171, Jiangsu, Peoples R China.
C3 Nanjing Audit University; Nanjing University of Science & Technology;
   Nanjing Xiaozhuang University
RP Wan, MH (corresponding author), Nanjing Audit Univ, Sch Technol, Nanjing 211815, Jiangsu, Peoples R China.; Wan, MH (corresponding author), Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.; Wan, MH (corresponding author), Nanjing Xiaozhuang Univ, Key Lab Trusted Cloud Comp & Big Data Anal, Nanjing 211171, Jiangsu, Peoples R China.
EM wmh36@sina.com
RI Yang, Jacky/HKE-6819-2023
FU National Science Foundation of China [61462064, 61203243, 61272077,
   61202319, 61403188, 61563037]; China Postdoctoral Science Foundation
   [2014 T70453, 2013 M530223]; Jiangsu Provincial Postdoctoral Science
   Foundation [1301095C]; Key Laboratory of Intelligent Perception and
   Systems for High-Dimensional Information (Nanjing University of Science
   and Technology), Ministry of Education [30920140122006]; University
   Natural Science Fund of JiangSu Province, China [15KJB520018]
FX This work is partially supported by the National Science Foundation of
   China under grant no. 61462064, 61203243, 61272077, 61202319, 61403188,
   61563037, the China Postdoctoral Science Foundation under grant No. 2014
   T70453, 2013 M530223 and Jiangsu Provincial Postdoctoral Science
   Foundation under grant No. 1301095C, the Key Laboratory of Intelligent
   Perception and Systems for High-Dimensional Information (Nanjing
   University of Science and Technology), Ministry of Education (Grant No.
   30920140122006), the University Natural Science Fund of JiangSu
   Province, China (Grant No. 15KJB520018).
CR [Anonymous], CVPR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bezdek J., 1999, FUZZY MODELS ALGORIT
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chen SB, 2007, NEUROCOMPUTING, V70, P912, DOI 10.1016/j.neucom.2006.10.032
   Chowdhury S, 2011, APPL SOFT COMPUT, V11, P4282, DOI 10.1016/j.asoc.2010.12.002
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   He XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P385, DOI 10.1109/ICCV.2003.1238370
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Jing XY, 2006, PATTERN RECOGN, V39, P707, DOI 10.1016/j.patcog.2005.10.020
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Kw K. C., 2005, PATTERN RECOGN, V38, P1717
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Niu B, 2008, PATTERN RECOGN, V41, P3237, DOI 10.1016/j.patcog.2007.12.001
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wan M, 2011, IET COMPUT VIS, V5, P301, DOI 10.1049/iet-cvi.2011.0028
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wan MH, 2012, MACH VISION APPL, V23, P985, DOI 10.1007/s00138-011-0365-5
   Wan MH, 2009, NEUROCOMPUTING, V73, P197, DOI 10.1016/j.neucom.2009.07.015
   Wang R, 2015, IEEE T CYBERNETICS, V45, P1108, DOI 10.1109/TCYB.2014.2341575
   Xiong HL, 2005, PATTERN RECOGN, V38, P1121, DOI 10.1016/j.patcog.2004.12.003
   Xu Y, 2009, NEUROCOMPUTING, V73, P245, DOI 10.1016/j.neucom.2009.09.010
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2002, PATTERN RECOGN, V35, P1997, DOI 10.1016/S0031-3203(02)00040-7
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhi RC, 2014, IEICE T INF SYST, VE97D, P2434, DOI 10.1587/transinf.2013EDP7422
   Zhou X, 2015, NEUROCOMPUTING
NR 38
TC 30
Z9 30
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 355
EP 371
DI 10.1007/s11042-015-3057-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000016
DA 2024-07-18
ER

PT J
AU Xu, J
   Chang, ZG
   Fan, JL
   Zhao, XQ
   Wu, XM
   Wang, YZ
   Zhang, XD
AF Xu, Jian
   Chang, Zhiguo
   Fan, Jiulun
   Zhao, Xiaoqiang
   Wu, Xiaomin
   Wang, Yanzi
   Zhang, Xiaodan
TI Super-resolution via adaptive combination of color channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image up-scaling; Super-resolution; Total variation regularization;
   Iterative back projection
ID SINGLE-IMAGE SUPERRESOLUTION; INTERPOLATION; RECONSTRUCTION; RESOLUTION
AB Super-resolution (SR) is a technology to reconstruct a clear high-resolution image with plausible details according to one or a group of observed low- resolution images. However, many existing methods require the help of "tools", which results in high time and memory costs for training and storing these "tools". This paper proposes an SR method that can be executed without these training "tools". This method comprises two stages: color channel adaptive combination and regularization. In the first stage, color channel adaptive combination assembles the textures captured by different color channels into the luminance component. This strategy is helpful in effectively utilizing the luminance information of different light bands. In the second stage, an improved total variation (TV) regularization method is proposed to suppress artifacts and sharpen edges. The TV regularization adds a new item in the iteration formula to enable the edges to be similar to the desired high-resolution image. Next, iterative back projection is used to fit the high-resolution image to the observed low-resolution image. The experimental results demonstrate that the proposed algorithm is superior to many existing learning-based methods and has low time cost.
C1 [Xu, Jian; Fan, Jiulun; Zhao, Xiaoqiang; Wu, Xiaomin; Wang, Yanzi; Zhang, Xiaodan] Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
   [Xu, Jian] Xi An Jiao Tong Univ, Image Proc & Recognit Ctr, Xian 710049, Peoples R China.
   [Xu, Jian] Crime Scene Invest Unit Shannxi Prov, Lab Image Proc, Xian 710121, Peoples R China.
   [Chang, Zhiguo] Changan Univ, Sch Informat Engn, Xian 710064, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an Jiaotong
   University; Chang'an University
RP Xu, J (corresponding author), Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.; Xu, J (corresponding author), Xi An Jiao Tong Univ, Image Proc & Recognit Ctr, Xian 710049, Peoples R China.; Xu, J (corresponding author), Crime Scene Invest Unit Shannxi Prov, Lab Image Proc, Xian 710121, Peoples R China.
EM xujian_paper@126.com
RI Fan, Jiulun/AAG-4371-2020; Zhang, Xiaodan/GQR-0608-2022
OI Zhang, Xiaodan/0000-0001-8192-0666; Fan, Jiulun/0000-0002-7553-204X
FU National Science Foundation of China [61340040, 61202183, 61102095,
   61201194]; Science and Technology Plan in Shannxi Province of China
   [2016KJXX-47]
FX This work was supported by the National Science Foundation of China
   (Grant no. 61340040, 61202183, 61102095, 61201194) and the Science and
   Technology Plan in Shannxi Province of China (No.2016KJXX-47).
CR [Anonymous], 1952, Opticks: Or A Treatise of the Reflections, Refractions, Inflections and Colors of Light
   BERNSTEIN R, 1976, IBM J RES DEV, V20, P40, DOI 10.1147/rd.201.0040
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   Chen XX, 2014, SIGNAL PROCESS, V94, P6, DOI 10.1016/j.sigpro.2013.06.016
   Trinh DH, 2014, IEEE T IMAGE PROCESS, V23, P1882, DOI 10.1109/TIP.2014.2308422
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gunturk BK, 2002, IEEE SIGNAL PROC LET, V9, P170, DOI 10.1109/LSP.2002.800503
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Melin P, 2014, IEEE T FUZZY SYST, V22, P1515, DOI 10.1109/TFUZZ.2013.2297159
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Purkait P, 2014, IEEE T IMAGE PROCESS, V23, P2277, DOI 10.1109/TIP.2014.2312289
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Song HH, 2015, IEEE T GEOSCI REMOTE, V53, P1195, DOI 10.1109/TGRS.2014.2335818
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Vedadi F, 2014, IEEE T IMAGE PROCESS, V23, P424, DOI 10.1109/TIP.2013.2290586
   Wang JJ, 2010, PATTERN RECOGN LETT, V31, P1, DOI 10.1016/j.patrec.2009.09.004
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zeng X, 2012, IEEE SIGNAL PROC LET, V19, P195, DOI 10.1109/LSP.2012.2186961
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhou L, 2014, MULTIMED TOOLS APPL, V71, P1879, DOI 10.1007/s11042-012-1311-x
NR 42
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1553
EP 1584
DI 10.1007/s11042-015-3124-1
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000068
DA 2024-07-18
ER

PT J
AU Gutiérrez, S
   García, S
AF Gutierrez, Salvador
   Garcia, Salvador
TI Landmark-based music recognition system optimisation using genetic
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recognition; Genetic algorithms; Audio fingerprinting; Parameter
   optimisation
ID INFORMATION-RETRIEVAL; FOURIER-TRANSFORM; AUDIO; ROBUST
AB Audio fingerprinting allows us to label an unidentified music fragment within a previously generated database. The use of spectral landmarks aims to obtain a robustness that lets a certain level of noise be present in the audio query. This group of audio identification algorithms holds several configuration parameters whose values are usually chosen based upon the researcher's knowledge, previous published experimentation or just trial and error methods. In this paper we describe the whole optimisation process of a Landmark-based Music Recognition System using genetic algorithms. We define the actual structure of the algorithm as a chromosome by transforming its high relevant parameters into various genes and building up an appropriate fitness evaluation method. The optimised output parameters are used to set up a complete system that is compared with a non-optimised one by designing an unbiased evaluation model.
C1 [Gutierrez, Salvador; Garcia, Salvador] Univ La Rioja, Inst Ciencias & Vino, CSIC, Apartado Postal 1042, Logrono 26080, Spain.
   [Gutierrez, Salvador] Crta Burgos Km 6, Logrono 26007, Spain.
   [Garcia, Salvador] Univ Granada, Dept Comp Sci & Articial Intelligence, CITIC UGR Res Ctr Informat & Commun Technol, ETSII, Calle Periodista Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
   [Garcia, Salvador] King Abdulaziz Univ, Dept Informat Syst, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); Universidad de
   La Rioja; University of Granada; King Abdulaziz University
RP García, S (corresponding author), Univ La Rioja, Inst Ciencias & Vino, CSIC, Apartado Postal 1042, Logrono 26080, Spain.
EM salvador.gutierrez@unirioja.com; salvagl@decsai.ugr.es
RI García, Salvador/N-3624-2013; Gutiérrez, Salvador/GLV-0302-2022
OI García, Salvador/0000-0003-4494-7565; Gutierrez,
   Salvador/0000-0002-8205-9772
FU  [TIN2014-57251-P]
FX This work is supported by the research project TIN2014-57251-P. The
   authors are very grateful to the anonymous reviewers for their valuable
   suggestions and comments to improve the quality of this paper.
CR ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   [Anonymous], 2005, P INT C MUS INF RETR
   [Anonymous], 2010, P ACM MM
   Apelblat A., 2012, Laplace transforms and their applications
   Bellettini Carlo, 2010, Journal of Communications, V5, P409, DOI 10.4304/jcm.5.5.409-424
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Cao BQ, 2013, CHINA COMMUN, V10, P77, DOI 10.1109/CC.2013.6723881
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Cordón O, 2006, IMAGE VISION COMPUT, V24, P525, DOI 10.1016/j.imavis.2006.02.002
   Deng J, 2011, IET INT C SMART SUST, P27
   DUHAMEL P, 1990, SIGNAL PROCESS, V19, P259, DOI 10.1016/0165-1684(90)90158-U
   Dupraz E, 2010, INT CONF ACOUST SPEE, P281, DOI 10.1109/ICASSP.2010.5495944
   Eiben A. E., 2015, INTRO EVOLUTIONARY C
   Ellis Dan., 2009, ROBUST LANDMARK BASE
   ESHELMAN L.J., 1992, Real-coded genetic algorithms and interval-schemata, P187
   Eshelman L.J., 1991, Foundations of genetic algorithms, V1, P265, DOI DOI 10.1016/B978-0-08-050684-5.50020-3
   Filipiak Patryk, 2012, Artificial Intelligence: Methodology, Systems, and Applications. Proceedings of the 15th International Conference (AIMSA 2012), P305, DOI 10.1007/978-3-642-33185-5_34
   Herrera F, 2003, INT J INTELL SYST, V18, P309, DOI 10.1002/int.10091
   Jiang W, 2012, 2012 C HD AS PAC SIG
   Jijun Deng, 2011, IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011), P93, DOI 10.1049/cp.2011.0854
   Kamaladas MD, 2013, INT C SIGN PROC IM P, P1
   Ke Y, 2005, PROC CVPR IEEE, P597
   Klapuri A, 2006, SIGNAL PROCESSING ME
   Lee IH, 2014, MULTIMED TOOLS APPL, V71, P247, DOI 10.1007/s11042-013-1433-9
   Levy M, 2009, IEEE T MULTIMEDIA, V11, P383, DOI 10.1109/TMM.2009.2012913
   Li ZY, 2013, INT J PHOTOENERGY, V2013, DOI 10.1155/2013/670315
   Liu JX, 2011, COMM COM INF SC, V234, P360
   Liu Y, 2009, IEEE SIGNAL PROC LET, V16, P525, DOI 10.1109/LSP.2009.2016837
   Malekesmaeili M, 2012, IEEE INT WORKSH MULT, P136, DOI 10.1109/MMSP.2012.6343429
   Marín J, 2012, SOFT COMPUT, V16, P331, DOI 10.1007/s00500-011-0745-9
   Mendoza M, 2014, LECT NOTES ARTIF INT, V8856, P125, DOI 10.1007/978-3-319-13647-9_14
   Mohsenfar SM, 2013, MULTIMED TOOLS APPL, V74, P1
   Nesmachnow S, 2012, COMPUT INTELL-US, V28, P131, DOI 10.1111/j.1467-8640.2012.00410.x
   Ramalingam A, 2006, IEEE T INF FOREN SEC, V1, P457, DOI 10.1109/TIFS.2006.885036
   Seo JS, 2005, INT CONF ACOUST SPEE, P213
   Sethares W. A., 2005, Tuning, Timbre, Spectrum, Scale
   Sinitsyn A, 2006, I SYMP CONSUM ELECTR, P622
   Son W, 2010, IEEE T CONSUM ELECTR, V56, P156, DOI 10.1109/TCE.2010.5439139
   Suyoto ISH, 2008, IEEE T AUDIO SPEECH, V16, P372, DOI 10.1109/TASL.2007.911644
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tsai T-H, 2014, MULTIMED TOOLS APPL, P1
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vaseghi S., 2007, MULTIMEDIA SIGNAL PR
   Wang A. L.-C., 2004, SPIE P, V5307, P582
   Wang A, 2006, COMMUN ACM, V49, P44, DOI 10.1145/1145287.1145312
   Wang Q, 2012, INT J DIGITAL CONTEN, V6, P361
   Wong GY, 2014, IEEE INT FUZZY SYST, P1248, DOI 10.1109/FUZZ-IEEE.2014.6891771
   Xueqian Pan, 2011, IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011), P351, DOI 10.1049/cp.2011.0907
NR 49
TC 4
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16905
EP 16922
DI 10.1007/s11042-015-2963-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600009
DA 2024-07-18
ER

PT J
AU Su, KX
   Chen, J
   Wang, WX
   Su, LC
AF Su, Kaixiong
   Chen, Jian
   Wang, Weixing
   Su, Lichao
TI Reconstruction algorithm for block-based compressed sensing based on
   mixed variational inequality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed variational inequality; Image reconstruction; Block-based
   compressed sensing; Alternating direction method
AB Block compressed sensing based on mixed variational inequality (BCS-MVI) is proposed to improve the performance of current reconstruction algorithms for block-based compressed sensing. In the measurement phase, an image is sampled block by block. In the recovery period, BCS-MVI takes the sparse regularization of the natural image as prior knowledge and approaches the target function within the entire image through the modified augmented Lagrange method (ALM) and alternating direction method (ADM) of multipliers. Moreover, for the reconstruction problem including two regularization terms, an adaptive weight (-AW) strategy based on the gray entropy of the initialized image is studied. BCS-MVI achieves an average PSNR gain of 0.5-2.0 dB and an SSIM gain of 0.02-0.05 over previous block-based compressed sensing methods, and the reconstructing time only slightly fluctuates with the sampling rate. The algorithm is suitable for applications in multimedia data processing with fixed transmission delays.
C1 [Su, Kaixiong; Chen, Jian; Wang, Weixing] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou, Peoples R China.
   [Su, Lichao] Xiamen Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
C3 Fuzhou University; Xiamen University
RP Chen, J (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou, Peoples R China.
EM chenjian-fzu@163.com
OI , Jian/0000-0001-7556-3121
FU National Natural Science Foundation of China [61170147, 61471124];
   Natural Science Foundation of Fujian Province [2013 J01234, 2014 J01234,
   2015 J01251]
FX The paper is supported by the National Natural Science Foundation of
   China (No. 61170147 and 61471124), and the Natural Science Foundation of
   Fujian Province (No. 2013 J01234, 2014 J01234 and 2015 J01251). The
   wonderful lectures and patient help of Prof. Peng Zheng in the College
   of Mathematics and Computer Science at Fuzhou University is greatly
   appreciated, as are the wonderful lectures and scholarly communications
   from Prof. He Bing-sheng and Mrs. Tao Ming at Nanjing University.
CR [Anonymous], P PICT COD S PCS BEI
   [Anonymous], 2008, P EUSIPCO 2008 LAUS
   BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Foucart S, 2013, MATH INSTRUCTION COM
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Goldfarb D, 2005, SIAM J SCI COMPUT, V27, P622, DOI 10.1137/040608982
   Gu GY, 2014, COMPUT OPTIM APPL, V59, P135, DOI 10.1007/s10589-013-9616-x
   Han H, 2015, J MATH IMAGING VIS, V51, P161, DOI 10.1007/s10851-014-0516-1
   He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936
   He BS, 2012, COMPUT OPTIM APPL, V51, P681, DOI 10.1007/s10589-010-9373-z
   He BS, 2012, COMPUT OPTIM APPL, V51, P649, DOI 10.1007/s10589-010-9372-0
   Li C., 2011, Compressive sensing for 3D data processing tasks: applications, models, and algorithms
   Li CB, 2009, EFFCIENT ALGORITHM T
   Mun S, 2009, P INT C IMAG PROC IC
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Stankovic V, 2008, P C IM SIGN PROC CIS
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   [王蓉芳 Wang Rongfang], 2013, [电子学报, Acta Electronica Sinica], V41, P1506
   Xiao YH, 2012, J MATH IMAGING VIS, V44, P114, DOI 10.1007/s10851-011-0314-y
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   Zhang HC, 2004, SIAM J OPTIMIZ, V14, P1043, DOI 10.1137/S1052623403428208
   Zheng Hai-bo, 2013, Journal of China Universities of Posts and Telecommunications, V20, P97, DOI 10.1016/S1005-8885(13)60056-4
NR 29
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16417
EP 16438
DI 10.1007/s11042-015-2975-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700068
DA 2024-07-18
ER

PT J
AU Zare, S
   Rahbar, AG
AF Zare, Sajjad
   Rahbar, Akbar Ghaffarpour
TI Program-driven approach to reduce latency during surfing periods in IPTV
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Channel switching; Surfing period; Program-driven
ID CHANNEL; SCHEME; TIME
AB Nowadays, using delay sensitive services such as IPTV is rapidly growing. Unlike traditional TV that supports a limited number of channels due to the fixed radio frequency bandwidth, IPTV can support hundreds of channels through IP networks. However, finding a desired IPTV channel among hundreds of channels is a difficult and time consuming issue. To solve this problem, we propose two novel methods to reduce channel surfing period. The first method is channel number-based and is called the Program-Driven Channel Switching (PDCS) method. The second method is popularity-based and is called the Program-Driven with Weight (PDW) method. It is noted that the number of channel switches has a main effect on the channel surfing period. Our proposed methods are based on programs; i.e., program-driven methods. In these methods, instead of choosing channels, users select their desired programs by which they can reach the desired channels that play the programs. Note that a user likes to watch his/her desired program independent of the channel number. Simulation results show that the proposed methods can reduce the number of channel switches; thus reducing the latency for channel surfing period.
C1 [Zare, Sajjad] Payame Noor Univ, Dept Informat Technol Engn, Tehran, Iran.
   [Rahbar, Akbar Ghaffarpour] Sahand Univ Technol, Comp Networks Res Lab, Sahand New Town, Tabriz, Iran.
C3 Payame Noor University; Sahand University of Technology
RP Zare, S (corresponding author), Payame Noor Univ, Dept Informat Technol Engn, Tehran, Iran.; Rahbar, AG (corresponding author), Sahand Univ Technol, Comp Networks Res Lab, Sahand New Town, Tabriz, Iran.
EM sajjad.zare@pnu.ac.ir; akbar_rahbar92@yahoo.com
RI zare, sajjad/AAF-9796-2022; zare, sajjad/AFK-2526-2022
OI zare, sajjad/0000-0002-6539-8510; zare, sajjad/0000-0002-6539-8510;
   Ghaffarpour Rahbar, Akbar/0000-0002-0902-379X
FU Payame Noor University (PNU), Iran
FX This research was financially supported by Payame Noor University (PNU),
   Iran.
CR Azgin A, 2013, IEEE T BROADCAST, V59, P471, DOI 10.1109/TBC.2013.2265773
   Bejerano Y, 2009, IEEE INFOCOM SER, P1971, DOI 10.1109/INFCOM.2009.5062119
   Beyragh AA, 2014, MULTIMED TOOLS APPL, V72, P1049, DOI 10.1007/s11042-013-1414-z
   Boyce JM, 2005, IEEE ICCE, P1
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   Degrande N, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4473090
   Jennehag U, 2007, IEEE T BROADCAST, V53, P69, DOI 10.1109/TBC.2006.887167
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Lee E, 2014, IEEE T CONSUM ELECTR, V60, P124, DOI 10.1109/TCE.2014.6780934
   Lee E, 2009, IEEE T CONSUM ELECTR, V55, P1945, DOI 10.1109/TCE.2009.5373754
   Lee J, 2007, LECT NOTES COMPUT SC, V4773, P235
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Manjunath L, 2013, INT J ENG RES APPL I, V3, P1331
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Zare S, 2014, J NETW COMPUT APPL, V37, P240, DOI 10.1016/j.jnca.2013.02.012
   Zare S, 2012, J NETW COMPUT APPL, V35, P459, DOI 10.1016/j.jnca.2011.09.008
NR 16
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16059
EP 16071
DI 10.1007/s11042-015-2913-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700053
DA 2024-07-18
ER

PT J
AU Cheng, H
   Zhang, XP
   Yu, J
AF Cheng, Hang
   Zhang, Xinpeng
   Yu, Jiang
TI AC-coefficient histogram-based retrieval for encrypted JPEG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image encryption; JPEG image; Histogram
ID SEARCH
AB This paper proposes a novel retrieval scheme for encrypted JPEG images. With this scheme, the DC and AC coefficients of JPEG images are encrypted using a stream cipher and scrambling encryption, respectively. Then, the encrypted images are transmitted to and stored in a server, which can also provide retrieval service. When receiving an encrypted query image, the server without any knowledge of the plaintext content may acquire statistically its AC coefficients histogram. By calculating the distances between the histograms of encrypted query image and database image, the server may output the encrypted images closest to the query image to the authorized user.
C1 [Cheng, Hang; Zhang, Xinpeng; Yu, Jiang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Cheng, Hang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Peoples R China.
C3 Shanghai University; Fuzhou University
RP Cheng, H (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.; Cheng, H (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Peoples R China.
EM hcheng@shu.edu.cn; xzhang@shu.edu.cn; sxyj1981@shu.edu.cn
FU National Natural Science Foundation of China [61472235, 61373151,
   61272043, 61202367]; Research Fund for the Doctoral Program of Higher
   Education of China [20113108110010]; Program for Professor of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning, and Shanghai Pujiang Program [13PJ1403200]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61472235, 61373151, 61272043 and 61202367, the
   Research Fund for the Doctoral Program of Higher Education of China
   under Grant 20113108110010, the Program for Professor of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning, and Shanghai Pujiang Program under Grant 13PJ1403200.
CR [Anonymous], 2013, INT C FIN CRYPT DAT
   [Anonymous], 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587388
   [Anonymous], IS T SPIE ELECT IMAG
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Curtmola Reza, 2006, P 13 ACM C COMP COMM, DOI DOI 10.1145/1180405.1180417
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Fanti G, 2013, IEEE SIGNAL PROC MAG, V30, P53, DOI 10.1109/MSP.2012.2229783
   Goh E.-J., 2003, Rep. 2003/216
   Li J, 2010, 2010 2ND INTERNATIONAL CONFERENCE ON E-BUSINESS AND INFORMATION SYSTEM SECURITY (EBISS 2010), P1
   Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Qian ZX, 2015, J VIS COMMUN IMAGE R, V26, P9, DOI 10.1016/j.jvcir.2014.10.008
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Ra M.-R., 2013, P USENIX S NETW SYST, P515
   Shi E, 2007, P IEEE S SECUR PRIV, P350, DOI 10.1109/SP.2007.29
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Sudharsanan S, 2005, IEEE T CONSUM ELECTR, V51, P1204
   Wang C, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.34
   Wang C, 2012, IEEE INFOCOM SER, P451, DOI 10.1109/INFCOM.2012.6195784
   Zhang XP, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P446, DOI 10.1109/ChinaSIP.2014.6889282
NR 21
TC 24
Z9 25
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13791
EP 13803
DI 10.1007/s11042-015-2741-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800042
DA 2024-07-18
ER

PT J
AU Ke, CH
   Lin, KW
   Huang, CA
   Chen, YS
   Park, SO
AF Ke, Chih-Heng
   Lin, Kawuu W.
   Huang, Chih-Ang
   Chen, Yeong-Sheng
   Park, Sang Oh
TI Cross-layer quality enhancement scheme for video transmission over
   multi-hop wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-hop wireless networks; Video transmission; MPEG; TTL
AB Wireless networks have a varying channel quality and a limited bandwidth. Therefore, ensuring a satisfactory video quality over wireless networks is extremely challenging. Most existing studies for enhancing the received video quality over wireless networks consider only single-hop transmission environments. Consequently, when applied to multi-hop wireless networks, such as wireless mesh networks, VANETs or wireless sensor networks, the video quality is typically rather poor. Accordingly, this study proposes a cross-layer mechanism for improving the video transmission quality in multi-hop wireless networks. The proposed scheme considers both the video frame type and the output interface queue length at the intermediate nodes while determining the drop probability during the packet forwarding process. Besides, in the event of transmission failures, the number of retransmission attempts is varied adaptively in accordance with the network conditions and the relative priority of the corresponding frame. Furthermore, the forwarding probability at each node is increased in accordance with the number of hops previously traversed by the packet. Thus, the proposed scheme improves video delivery quality by means of providing unequal protection for frames of different importance. The NS2 simulation results show that the average PSNR results obtained with the proposed scheme have significant improvements compared to that obtained with the traditional IEEE 802.11 mechanism, thereby confirming the effectiveness of the proposed scheme.
C1 [Ke, Chih-Heng] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen, Taiwan.
   [Lin, Kawuu W.; Huang, Chih-Ang] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
   [Chen, Yeong-Sheng] Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
   [Park, Sang Oh] Korea Inst Sci & Technol Informat, Global Sci Expt Data Hub Ctr, Seoul, South Korea.
C3 National Kaohsiung University of Science & Technology; National Taipei
   University of Education; Korea Institute of Science & Technology
   Information (KISTI)
RP Chen, YS (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM smallko@gmail.com; linwc@cc.kuas.edu.tw; chihangh@gmail.com;
   yschen@tea.ntue.edu.tw; sopark3@gmail.com
CR Ahvar E, 2014, SCI WORLD J, DOI 10.1155/2014/359897
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   Akyildiz IF, 2005, IEEE COMMUN MAG, V43, pS23, DOI 10.1109/MCOM.2005.1509968
   [Anonymous], 802111999 IEEE
   [Anonymous], J SCI TECHNOL RES
   [Anonymous], CONS EL ICCE 2010 IN
   [Anonymous], NS 2 NETW SIM SOFTW
   [Anonymous], IEEE 56 VTC
   [Anonymous], P ICN COLM FRANC
   Avokh A, 2013, SCI WORLD J, DOI 10.1155/2013/794549
   Chen M, 2008, IEEE VTS VEH TECHNOL, P2873
   Crow BP, 1997, IEEE COMMUN MAG, V35, P116, DOI 10.1109/35.620533
   Hartenstein H, 2008, IEEE COMMUN MAG, V46, P164, DOI 10.1109/MCOM.2008.4539481
   Jiang H, 2009, IEEE SENS J, V9, P1511, DOI 10.1109/JSEN.2009.2022878
   Karimi E, 2011, I C WIREL COMM NETW
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Nguyen LT, 2007, LECT NOTES COMPUT SC, V4864, P326
   Rasheed A, 2014, SCI WORLD J, DOI 10.1155/2014/403918
   Xu SG, 2001, IEEE COMMUN MAG, V39, P130, DOI 10.1109/35.925681
NR 20
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14849
EP 14865
DI 10.1007/s11042-015-2720-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500050
DA 2024-07-18
ER

PT J
AU Kim, JS
   Kwak, J
AF Kim, Jun-Sub
   Kwak, Jin
TI Design of USIM-based secure user authentication scheme in a mobile
   office environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; USIM; Mobile; Formal verification; Security
AB In order to spread the scale of the mobile device market rapidly, mobile office applications have been introduced that can be process office work anytime, anywhere. However, the mobile office is vulnerable to several security threats that can occur over wireless networks, which can result in illegal enterprise information access and disclosure because of the openness and portability of the mobile device. Therefore, the mobile office environment must prevent unauthorized service and resource access, and a user authentication scheme is needed to mitigate the potential security vulnerabilities. In this paper, we propose a USIM-based secure user authentication scheme for a mobile office environment. The proposed scheme uses the USIM to securely share secret information for authentication between the mobile user and the server, and the mobile device can perform re-authentication to the server through the re-authentication phase in the event of handover. Moreover, the proposed authentication scheme is specified using Casper and is verified the security using the CasperFDR and FDR tool.
C1 [Kim, Jun-Sub] Sungkyunkwan Univ, IT Convergence Res Inst, Suwon 440746, Gyeonggi Do, South Korea.
   [Kwak, Jin] Ajou Univ, Dept Informat & Comp Engn, Suwon 443749, Gyeonggi Do, South Korea.
C3 Sungkyunkwan University (SKKU); Ajou University
RP Kwak, J (corresponding author), Ajou Univ, Dept Informat & Comp Engn, Suwon 443749, Gyeonggi Do, South Korea.
EM jskim.isaa@gmail.com; security@ajou.ac.kr
OI Kwak, Jin/0000-0001-6931-2705
FU ICT R&D program of MSIP/IITP, Republic of Korea [13-912-06-003]
FX This work was supported by the ICT R&D program of MSIP/IITP, Republic of
   Korea. [13-912-06-003, Development of Mobile S/W Security Testing Tools
   for Detecting New Vulnerabilities of Android]
CR *FORM SYST LTD, 1999, FDR2 US MAN
   HOARE CAR, 1985, COMMUNICATIONG SEQUE
   Jhee E-W, 2011, 2015 SPRING C KIPS, P982
   Jiang Y, 2010, 2010 INT C MULT INF, P795
   Korea Communications Commission, 2012, INF SEC RUL INTR OP
   Lee J, 2013, GRID PERVASIVE COMPU, V7681, P860
   Lee JD, 2013, INF TECHNOLCONVERGEN, V253, P495
   Lowe G, 1997, P IEEE CSFW, P18, DOI 10.1109/CSFW.1997.596779
   Ministry of Science, 2013, ICT FUT PLANN
   Tian H, 2010, 2010 INT C INF SCI M, P166
   Yim Sunjip, 2014, Asia Pacific Journal of Information Systems, V24, P115, DOI 10.14329/apjis.2014.24.2.115
   Yoon S, 2013, INT SECUR FOCUS, P69
   Yoon S, 2013, RES NOTES INF SCI, V4, P567
   Zhiyu Y, 2009, 2009 1 INT WORKSH ED, P495
NR 14
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14541
EP 14556
DI 10.1007/s11042-015-2869-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500032
DA 2024-07-18
ER

PT J
AU Li, C
   Feng, ZY
   Xu, C
AF Li, Chao
   Feng, Zhiyong
   Xu, Chao
TI Error-correcting output codes for multi-label emotion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Multi-modal; Error-correcting Output Code; EEG
   signals; Physiological signals
ID RECOGNITION
AB Multi-modal affective data such as EEG and physiological signals is increasingly utilized to analyze of human emotional states. Due to the noise existed in collected affective data, however, the performance of emotion recognition is still not satisfied. In fact, the issue of emotion recognition can be regarded as channel coding, which focuses on reliable communication through noise channels. Using affective data and its label, the redundant codeword would be generated to correct signals noise and recover emotional label information. Therefore, we utilize multi-label output codes method to improve accuracy and robustness of multi-dimensional emotion recognition by training a redundant codeword model, which is the idea of error-correcting output codes. The experiment results on DEAP dataset show that the multi-label output codes method outperforms other traditional machine learning or pattern recognition methods for the prediction of emotional multi-labels.
C1 [Li, Chao] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Feng, Zhiyong; Xu, Chao] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Xu, C (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
EM xuchao@tju.edu.cn
RI Gulliver, Aaron/K-7925-2012
FU National Natural Science Foundation of China [61304262]
FX This work was partially supported by the National Natural Science
   Foundation of China (no. 61304262).
CR AlZoubi O, 2012, IEEE T AFFECT COMPUT, V3, P298, DOI 10.1109/T-AFFC.2012.4
   Calvo RA, 2009, LECT NOTES ARTIF INT, V5866, P62, DOI 10.1007/978-3-642-10439-8_7
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chao Li, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P208, DOI 10.1109/SMARTCOMP.2014.7043860
   Costello DJ, 2007, P IEEE, V95, P1150, DOI 10.1109/JPROC.2007.895188
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P, 1989, WILEY HDB PSYCHOPHYS, P143
   Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hsu Daniel J, 2009, Proc. of Neural Information Processing Systems, P772
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kandemir M, 2014, NEUROCOMPUTING, V139, P97, DOI 10.1016/j.neucom.2014.02.057
   Kang Li, 2013, 2013 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P305, DOI 10.1109/BIBM.2013.6732507
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolodyazhniy V, 2011, PSYCHOPHYSIOLOGY, V48, P908, DOI 10.1111/j.1469-8986.2010.01170.x
   Li C, 2016, NEUROCOMPUTING, V178, P103, DOI 10.1016/j.neucom.2015.07.112
   Li X, 2015, SIGIR2015 WORKSHOP N
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Nasoz F, 2010, INFORM SCIENCES, V180, P3817, DOI 10.1016/j.ins.2010.06.034
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Tai F, 2012, NEURAL COMPUT, V24, P2508, DOI 10.1162/NECO_a_00320
   Übeyli ED, 2007, DIGIT SIGNAL PROCESS, V17, P675, DOI 10.1016/j.dsp.2006.11.009
   Wagner J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P941
   Xu C, 2016, FUTURE GENER COMP SY, V54, P507, DOI 10.1016/j.future.2015.02.008
   Xu C, 2015, PATTERN RECOGN, V48, P3917, DOI 10.1016/j.patcog.2015.06.004
   Zhang XJ, 2016, PATTERN RECOGN, V54, P190, DOI 10.1016/j.patcog.2015.12.014
   Zhang XJ, 2016, NEUROCOMPUTING, V182, P36, DOI 10.1016/j.neucom.2015.12.009
   Zhang Yi, 2011, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, P873
NR 36
TC 1
Z9 1
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14399
EP 14416
DI 10.1007/s11042-016-3608-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500023
DA 2024-07-18
ER

PT J
AU Jin, Y
   Cao, JW
   Wang, YZ
   Zhi, RC
AF Jin, Yi
   Cao, Jiuwen
   Wang, Yizhi
   Zhi, Ruicong
TI Ensemble based extreme learning machine for cross-modality face matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Neural network; Cross-modality matching;
   Feature learning; Canonical correlation analysis
ID DISCRIMINANT-ANALYSIS; SPECTRAL REGRESSION; RECOGNITION
AB Extreme learning machine (ELM) is one of the most important and efficient machine learning algorithms for pattern classification due to its fast learning speed. In this paper, we propose a new ensemble based ELM approach for cross-modality face matching. Different to traditional face recognition methods, the proposed approach integrates the voting-base extreme learning machine (V-ELM) with a novel feature learning based face descriptor. Firstly, the discriminant feature learning is proposed to learn the cross-modality feature representation. Then, we used common subspace learning based method to reduce the obtained cross-modality features. Finally, Voting ELM is utilized as the classifier to improve the recognition accuracy and to speed up the feature learning process. Experiments conducted on two different heterogeneous face recognition scenarios demonstrate the effectiveness of our proposed approach.
C1 [Jin, Yi; Wang, Yizhi] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Cao, Jiuwen] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zhi, Ruicong] China Natl Inst Standardizat, Beijing 100191, Peoples R China.
C3 Beijing Jiaotong University; Hangzhou Dianzi University; China National
   Institute of Standardization
RP Jin, Y (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM yjin@bjtu.edu.cn; jwcao@hdu.edu.cn; yzwang@bjtu.edu.cn;
   zhirc_research@hotmail.com
RI cao, jiuwen/C-9547-2009
OI Jin, Yi/0000-0001-8408-3816
FU fundamental research funds for the central universities [K14JB00230];
   National Natural Science Foundation of China [61403024, 31201358,
   61100141]
FX This work was supported by the fundamental research funds for the
   central universities (K14JB00230) and the National Natural Science
   Foundation of China (No. 61403024, 31201358, 61100141).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2002, Matrices: Theory and Applications
   [Anonymous], QUANTITATIVE SOCIOLO
   Cao J, 2014, BIOMED RES INT, P2014
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Fung G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P77, DOI 10.1145/502512.502527
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang LK, 2012, INT C PATT RECOG, P1683
   Huang XS, 2013, IEEE T IMAGE PROCESS, V22, P353, DOI 10.1109/TIP.2012.2215617
   Kasun Liyanaarachchi Lekamalage Chamara, 2013, IEEE INTELLIGENT SYS
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Lei Z, 2012, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2012.6247967
   Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860
   Li AN, 2011, IEEE I CONF COMP VIS, P1060, DOI 10.1109/ICCV.2011.6126352
   Li Stan Z., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204149
   Li ZF, 2014, IEEE T IMAGE PROCESS, V23, P2436, DOI 10.1109/TIP.2014.2315920
   Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Long XZ, 2014, MULTIMED TOOLS APPL, V72, P2679, DOI 10.1007/s11042-013-1572-z
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HJ, 2014, NEUROCOMPUTING, V128, P22, DOI 10.1016/j.neucom.2013.02.052
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Yang D, 2014, LECT NOTES COMPUT SC, V8588, P213, DOI 10.1007/978-3-319-09333-8_23
   Yi D, 2014, ARXIV14061247
   Zhai JH, 2012, SOFT COMPUT, V16, P1493, DOI 10.1007/s00500-012-0824-6
   Zhang P, 2015, P ADAPTATION LEARNIN, V3, P237
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
   Zong WW, 2011, LECT NOTES ARTIF INT, V6752, P263, DOI 10.1007/978-3-642-21538-4_26
   Zong WW, 2011, NEUROCOMPUTING, V74, P2541, DOI 10.1016/j.neucom.2010.12.041
NR 47
TC 10
Z9 10
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11831
EP 11846
DI 10.1007/s11042-015-2650-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200014
DA 2024-07-18
ER

PT J
AU Ranasinghe, N
   Lee, KY
   Suthokumar, G
   Do, EYL
AF Ranasinghe, Nimesha
   Lee, Kuan-Yi
   Suthokumar, Gajan
   Do, Ellen Yi-Luen
TI Virtual ingredients for food and beverages to create immersive taste
   experiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Taste; Gustation; Taste media; Multimodal interaction; Perceptual
   immersion; Taste interfaces
ID PERCEPTION; SYSTEM; SMELL
AB This paper presents a new technology that overlays virtual taste sensations on food and beverages while eating and drinking. This additional layer of taste sensation enables modifying the existing taste sensations (flavors) of food and beverages virtually. To achieve this technology, we primarily use weak and controlled electrical pulses on the tip of the tongue (while eating and drinking). The ability of this technology to simulate primary taste sensations such as salty, sour, and bitter has made us able to merge it into everyday eating and drinking utensils such as the spoon and beverage bottle, thus to augment the taste sensations of food and beverages. In addition to electrical pulses, we change the color of the beverage using an RGB Light Emitting Diode (LED). Two prototype systems produced with this technology, Spoon+ and Bottle+ are explained in this paper. First, we present a comprehensive technical description of these utensils. Then, we detailed a user experiment conducted to study the effectiveness of our approach. Through these two prototype systems, we discuss the impact of this technology to create immersive taste experiences when consuming food and beverages. With focus on new features and improvements of several limitations of the existing systems, we present our future vision that enables merging of this technology into more appliances thus making a platform for creating virtual food and beverage ingredients.
C1 [Ranasinghe, Nimesha; Lee, Kuan-Yi; Suthokumar, Gajan; Do, Ellen Yi-Luen] Natl Univ Singapore, Keio NUS CUTE Ctr, Singapore, Singapore.
C3 National University of Singapore
RP Ranasinghe, N (corresponding author), Natl Univ Singapore, Keio NUS CUTE Ctr, Singapore, Singapore.
EM nimesha@nus.edu.sg; kuanyi22@gmail.com; gajan004@gmail.com;
   ellendo@acm.org
RI Do, Ellen Yi-Luen/B-3621-2009
OI Do, Ellen Yi-Luen/0000-0002-9948-6375; Ranasinghe,
   Nimesha/0000-0003-3962-8084
FU National Research Foundation, Prime Minister's Office, Singapore under
   its International Research Centre @ Singapore Funding Initiative
FX This research is supported by the National Research Foundation, Prime
   Minister's Office, Singapore under its International Research Centre @
   Singapore Funding Initiative and administered by the Interactive and
   Digital Media Programme Office.
CR Auvray M, 2008, CONSCIOUS COGN, V17, P1016, DOI 10.1016/j.concog.2007.06.005
   Beyreuther K, 2007, EUR J CLIN NUTR, V61, P304, DOI 10.1038/sj.ejcn.1602526
   Boyce JM, 2006, POSTGRAD MED J, V82, P239, DOI 10.1136/pgmj.2005.039453
   Buck L.B., 2000, Principles of Neural Science
   COWART BJ, 1981, PSYCHOL BULL, V90, P43, DOI 10.1037/0033-2909.90.1.43
   Cruz A, 2000, NATURE, V403, P889, DOI 10.1038/35002581
   DePuy V, 2005, COUNTERBALANCING, P418, DOI [10.1002/0470013192.bsa145, DOI 10.1002/0470013192.BSA145]
   Dobrin R. J., 1984, US Patent, Patent No. [4,464,293, 4464293]
   Drewnowski A, 2001, DRUG METAB DISPOS, V29, P535
   Eisenstein M, 2010, NATURE, V468, pS18, DOI 10.1038/468S18a
   Firestein S, 2001, NATURE, V413, P211, DOI 10.1038/35093026
   FRANK RA, 1989, CHEM SENSES, V14, P371, DOI 10.1093/chemse/14.3.371
   Grabenhorst F, 2008, EUR J NEUROSCI, V27, P723, DOI 10.1111/j.1460-9568.2008.06033.x
   Harrar V., 2013, FLAVOUR, V2, P1
   KRUT LH, 1961, BRIT MED J, V1, P384, DOI 10.1136/bmj.1.5223.384
   Kundu PK, 2011, IEEE T INSTRUM MEAS, V60, P1959, DOI 10.1109/TIM.2011.2115410
   Lackovic I, 2007, IFMBE PROC, V17, P154
   Lansdown Alan B G, 2006, Curr Probl Dermatol, V33, P17
   Lawless HT, 2005, CHEM SENSES, V30, P185, DOI 10.1093/chemse/bji014
   Lindemann B, 2001, NATURE, V413, P219, DOI 10.1038/35093032
   Matsunami H, 2000, NATURE, V404, P601, DOI 10.1038/35007072
   MEISELMAN HL, 1967, PERCEPT PSYCHOPHYS, V2, P496, DOI 10.3758/BF03210253
   Nagata M, 2006, EXP ANIM TOKYO, V55, P109, DOI 10.1538/expanim.55.109
   Nakamura Hiromi., 2011, Proceedings of the 2Nd Augmented Human International Conference, V34, P1, DOI [DOI 10.1145/1959826.1959860, 10.1145/1959826.1959860]
   Narumi T., 2010, Proceedings of the 1st Augmented Human International Conference, P1, DOI 10.1145/1785455.1785473
   Palit M, 2010, IEEE T INSTRUM MEAS, V59, P2230, DOI 10.1109/TIM.2009.2032883
   Ranasinghe N., 2014, Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction, P133, DOI [DOI 10.1145/2540930, DOI 10.1145/2540930.2540939, 10.1145/2540930.2540939]
   Ranasinghe N., 2014, Proceedings of the 2nd ACM International Workshop on Immersive Media Experiences, P7, DOI [10.1145/2660579, DOI 10.1145/2660579]
   Ranasinghe N., 2013, Proceedings of the 2013 ACM International Workshop on Immersive Media Experiences, P29, DOI DOI 10.1145/2512142.2512148
   Ranasinghe N, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P409
   Ranasinghe N, 2012, IEEE INT SYM WRBL CO, P80, DOI 10.1109/ISWC.2012.16
   Ratner BD, 2009, Biomedical Engineering e-Mega Reference, P377
   ROBINSON JO, 1970, BRIT J PSYCHOL, V61, P375, DOI 10.1111/j.2044-8295.1970.tb01254.x
   Shepherd GM, 2006, NATURE, V444, P316, DOI 10.1038/nature05405
   Silverthorn DU, 2009, HUMAN PHYSL INTEGRAT, P354
   Small DM, 2005, EXP BRAIN RES, V166, P345, DOI 10.1007/s00221-005-2376-9
   Sorensen LB, 2003, INT J OBESITY, V27, P1152, DOI 10.1038/sj.ijo.0802391
   SPIELMAN AI, 1990, J DENT RES, V69, P838, DOI 10.1177/00220345900690030101
   Tortora G. J., 2008, Principles of Anatomy and Physiology
   Vega C, 2008, TRENDS FOOD SCI TECH, V19, P372, DOI 10.1016/j.tifs.2008.01.006
NR 40
TC 19
Z9 19
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12291
EP 12309
DI 10.1007/s11042-015-3162-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700002
DA 2024-07-18
ER

PT J
AU Shin, J
   An, G
   Park, JS
   Baek, SJ
   Lee, K
AF Shin, Jongkyu
   An, Gwangseok
   Park, Joon-Sang
   Baek, Seung Jun
   Lee, Kyogu
TI Application of precise indoor position tracking to immersive virtual
   reality with translational movement support
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Virtual reality; Immersive media experience; Real-time
   position tracking; Ultrasound
ID LOCALIZATION; CAPTURE
AB In this study, we propose an application for immersive virtual reality experiences, which integrates three-dimensional (3D) head-mounted displays (HMDs) with a precise indoor position tracking algorithm based on ultrasound. Our method provides a natural virtual reality experience with interaction by precisely matching the physical movements in the real world with those in the virtual environment, unlike other methods that require external input devices to move around in the virtual environment. Users can move within the assigned indoor space while carrying a wireless client device with the HMD, without the risk of colliding with obstacles or structures. The system is designed to provide the accurate 3D X, Y, and Z coordinate values of translational movements in real-time as well as the pitch, roll, and yaw values of rotational movements supported by the HMD, resulting in the six degrees of freedom required by immersive virtual reality. In addition, the system utilizes ultrasonic transducers in a grid format, which makes it simple to expand the position tracking coverage area, and supports simultaneous tracking of multiple users. Through experiments and a user study we show that the system obtains the accurate position of the moving objects and delivers a highly immersive virtual reality experience.
C1 [Shin, Jongkyu; An, Gwangseok; Lee, Kyogu] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, 1 Gwanak Ro, Seoul 151742, South Korea.
   [Park, Joon-Sang] Hongik Univ, Dept Comp Engn, 94 Wausan Ro, Seoul 121791, South Korea.
   [Baek, Seung Jun] Korea Univ, Dept Comp & Commun Engn, Coll Informat & Commun, Seoul 136701, South Korea.
C3 Seoul National University (SNU); Hongik University; Korea University
RP Lee, K (corresponding author), Seoul Natl Univ, Grad Sch Convergence Sci & Technol, 1 Gwanak Ro, Seoul 151742, South Korea.
EM jqshin@snu.ac.kr; angoang@snu.ac.kr; jsp@hongik.ac.kr;
   sjbaek@korea.ac.kr; kglee@snu.ac.kr
OI Shin, Jongkyu/0000-0002-4638-9192
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [IITP-2015-H8501-15-1016]
FX This research was partly supported by the MSIP (Ministry of Science, ICT
   and Future Planning), Korea, under the ITRC (Information Technology
   Research Center) support program (IITP-2015-H8501-15-1016) supervised by
   the IITP (Institute for Information & Communications Technology
   Promotion).
CR [Anonymous], 2014, CHI 14 EXTENDED ABST, DOI [DOI 10.1145/2559206.2574827, 10.1145/2559206.2574827]
   [Anonymous], INFOCOM 2000 19 ANN
   Bhatnagar DK, 1993, TR93010 U N CAR, P1
   Chow Yang-Wai., 2009, Int'l. Journal of Recent Trends in Engineering and Technology, V1, P527
   Cruz O., 2011, 2011 21st International Conference on Electrical Communications and Computers (CONIELECOMP 2011), P271, DOI 10.1109/CONIELECOMP.2011.5749373
   FALCONER DD, 1995, IEEE COMMUN MAG, V33, P50, DOI 10.1109/35.339881
   Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2480
   Frauenberger C., 2003, PROC 9 INT C AUDITOR, P1
   Fukuju Y, 2003, WSTFES 2003: IEEE WORKSHOP ON SOFTWARE TECHNOLOGIES FOR FUTURE EMBEDDED SYSTEMS, PROCEEDINGS, P53, DOI 10.1109/WSTFES.2003.1201360
   Gardner W, 1999, 3D AUDIO ACOUSTIC EN, P1
   Hale K.S., 2014, Handbook of virtual environments: Design, implementation, and applications
   Haverinen J, 2009, ROBOT AUTON SYST, V57, P1028, DOI 10.1016/j.robot.2009.07.018
   Hazas M., 2002, UbiComp 2002: Ubiquitous Computing. 4th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2498), P264
   Hightower J, 2001, COMPUTER, V34, P57, DOI 10.1109/2.940014
   Hodgson E, 2015, BEHAV RES METHODS, V47, P296, DOI 10.3758/s13428-014-0463-1
   Jr JL, 2000, ACM SIGCHI B, V32
   Jung Y, 2014, JUST ROAD EARTH EXHI
   Katzourin M, 2006, IEEE COMPUT GRAPH, V26, P15, DOI 10.1109/MCG.2006.137
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Mautz R., 2012, THESIS, DOI [10.3929/ethz-a-007313554, DOI 10.3929/ETHZ-A-007313554]
   Mokka S, 2003, P 2 INT C ENT COMP, V1, P3
   Priyantha N. B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P32, DOI 10.1145/345910.345917
   Satyavolu S, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P149, DOI 10.1109/VR.2012.6180925
   Shin J, 2014, P 2 ACM INT WORKSH I, P23, DOI [10.1145/2660579.2660582, DOI 10.1145/2660579.2660582]
   Uddin M., 2013, P 19 ANN INT C MOB C, P223
   Vorderer P., 2004, Mec spatial presence questionnaire
   Ward A, 1997, IEEE PERS COMMUN, V4, P42, DOI 10.1109/98.626982
   Yuan QL, 2011, IEEE INT CONF ROBOT, P848, DOI 10.1109/ICRA.2011.5979872
   Yuan QL, 2013, IEEE T ROBOT, V29, P806, DOI 10.1109/TRO.2013.2248535
NR 29
TC 13
Z9 13
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12331
EP 12350
DI 10.1007/s11042-016-3520-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700004
DA 2024-07-18
ER

PT J
AU Wang, H
   Ren, MW
   Yang, JY
AF Wang, Huan
   Ren, Mingwu
   Yang, Jingyu
TI Capitalizing on the boundary ratio prior for road detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road detection; Boundary ratio prior; Illumination invariance space
ID SEGMENTATION; SUPERPIXELS
AB Most of the color based road detection methods use a lower-center region as a "safe" road reference to construct appearance models for the road. However, its utility critically relies on the pose of vehicles. In case of involving non-road pixels, color models trained by using samples from this region often yield erroneous results. To address this problem, we propose a novel color-based road detection method based on a boundary ratio prior, with which we are able to infer the confidence of a certain image region belonging to the road class. Specifically, the boundary ratio prior is defined as the ratio of the length of the coincident boundary of this region and the image bottom to that of the region boundary itself. The calculation of this prior model is realized by a graph based geodesic distance measure. Moreover, the conventional illumination invariance space is integrated to calculate the distance metric of two neighboring nodes in the graph in order to make our approach robust to shadows. Experiments on multiple datasets demonstrate that the proposed approach is efficient and more robust than the existing methods based on the lower-center region prior.
C1 [Wang, Huan; Ren, Mingwu; Yang, Jingyu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Wang, H (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM wanghuanphd@njust.edu.cn; renmingwu@njust.edu.cn; yangjy@njust.edu.cn
RI Yang, Jingyu/I-3476-2019
OI Yang, Jingyu/0000-0003-2729-9519
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alvarez JM, 2014, IEEE T INTELL TRANSP, V15, P1168, DOI 10.1109/TITS.2013.2295427
   Alvarez JM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P594, DOI 10.1109/ICCVW.2013.82
   Alvarez JM, 2013, IEEE INT VEH SYM, P423, DOI 10.1109/IVS.2013.6629505
   Alvarez JM, 2013, IEEE T INTELL TRANSP, V14, P459, DOI 10.1109/TITS.2012.2221088
   Alvarez JM, 2012, LECT NOTES COMPUT SC, V7585, P635, DOI 10.1007/978-3-642-33885-4_70
   Alvarez JM, 2012, LECT NOTES COMPUT SC, V7578, P376, DOI 10.1007/978-3-642-33786-4_28
   Alvarez JM, 2011, IEEE T INTELL TRANSP, V12, P184, DOI 10.1109/TITS.2010.2076349
   Alvarez JM, 2010, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2010.5540228
   Alvarez Jose M, 2014, ARXIV14123506
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Dahlkamp Hendrik, 2006, ROBOTICS SCI SYSTEMS
   Darms M, 2010, IEEE INT VEH SYM, P609, DOI 10.1109/IVS.2010.5548011
   Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582
   Fritsch J, 2013, IEEE INT C INTELL TR, P1693, DOI 10.1109/ITSC.2013.6728473
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Guo CZ, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P37, DOI 10.1109/IVS.2012.6232149
   Guo CZ, 2010, IEEE INT VEH SYM, P361, DOI 10.1109/IVS.2010.5548107
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   He Z, 2013, IEEE IMAGE PROC, P2757, DOI 10.1109/ICIP.2013.6738568
   JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Lookingbill A, 2007, INT J COMPUT VISION, V74, P287, DOI 10.1007/s11263-006-0024-x
   Lu KY, 2014, IEEE INT CONF ROBOT, P517, DOI 10.1109/ICRA.2014.6906904
   Rotaru C, 2008, J REAL-TIME IMAGE PR, V3, P311, DOI 10.1007/s11554-008-0078-9
   Siogkas GK, 2013, IEEE T INTELL TRANSP, V14, P527, DOI 10.1109/TITS.2012.2223686
   Wang B, 2014, IEEE INT VEH SYM, P31, DOI 10.1109/IVS.2014.6856619
   Wang H, 2014, IEEE ANN INT CONF CY, P152, DOI 10.1109/CYBER.2014.6917452
   Wang Y, 2008, IEEE T INTELL TRANSP, V9, P570, DOI 10.1109/TITS.2008.2006733
   Yuan J, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1644, DOI 10.1109/ITSC.2014.6957929
   Zhang G, 2009, IEEE INT VEH SYM, P556, DOI 10.1109/IVS.2009.5164338
   Zhou SY, 2010, IEEE INT C INT ROBOT, P1183, DOI 10.1109/IROS.2010.5650300
   Zhou SY, 2010, IEEE INT VEH SYM, P256, DOI 10.1109/IVS.2010.5548086
NR 34
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11999
EP 12019
DI 10.1007/s11042-016-3280-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200024
DA 2024-07-18
ER

PT J
AU Liu, L
   Chang, CC
   Wang, AH
AF Liu, Li
   Chang, Chin-Chen
   Wang, Anhong
TI Reversible data hiding scheme based on histogram shifting of
   <i>n</i>-bit planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; n-bit planes; BPTI; Histogram shifting
ID IMAGES
AB In this paper, a reversible data hiding scheme is proposed based on histogram shifting of n-bit planes (nBPs). This scheme extracts nBPs from an 8-bit plane for each pixel to generate the bit plane truncation image (BPTI), and then block division is used in the BPTI. These operations can make the peak point of the block histogram more concentrated and improve the probability of the zero point in the block histogram. The histogram shifting method was used to embed secret bits into the peak point in each block. Note that this block was not utilized to embed secret bits if the zero point of a certain block did not exist, thus, there was no overflow or underflow in our scheme when the histogram was shifted. Our proposed scheme achieved higher hiding capacity than previous histogram-based schemes, and its visual quality was very satisfactory. The experimental results validated the expected merits of the proposed scheme.
C1 [Liu, Li; Wang, Anhong] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
C3 Taiyuan University of Science & Technology; Feng Chia University; Asia
   University Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.; Chang, CC (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU NNFSC [61272262]; Shanxi NSF [2012011014-3]; YSTRF of TYUST [20123004]
FX This work was supported in part by NNFSC (No.61272262), Shanxi NSF
   (No.2012011014-3), YSTRF of TYUST (No.20123004).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], MULTIMED TOOL APPL
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kuo WC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P365, DOI 10.1109/CISP.2008.730
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhao P, 2015, J INFORM HIDING MULT, V1, P163
NR 21
TC 18
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11311
EP 11326
DI 10.1007/s11042-015-2855-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900022
DA 2024-07-18
ER

PT J
AU Long, W
   Chen, XG
   Yang, J
AF Long, Wei
   Chen, Xiaogang
   Yang, Jie
TI Adaptive bound-constrained image deblurring with learned ringing
   suppression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deblurring; Blind deconvolution; Image restoration; Ringing
   suppression
ID BLIND DECONVOLUTION; RESTORATION
AB Image deblurring is an important task for digital cameras. This paper introduces spatial-variant upper and lower bound constraints to regularize Total Variation blind deconvolution. The local upper and lower bound constraints are computed based on the local structure of the observed image. We demonstrate that the proposed spatial-variant constraints can be useful in PSF estimation and image blind deconvolution. Secondly, as other traditional deblurring techniques, the TV blind deconvolution can also produce ringing artifacts. This paper study the GMM-based method to learn the ringing patch distributions. The learned distribution function is then incorporated into the deblurring objective function to suppress the ringing artifacts. Experiments demonstrated the efficacy of the proposed method.
C1 [Long, Wei; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
   [Chen, Xiaogang] Univ Shanghai Sci & Technol, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; University of Shanghai for Science &
   Technology
RP Long, W (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM canoexp@sjtu.edu.cn; xg.chen@live.com; jieyang@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023
CR Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2009, 2009 IEEE International Conference on Computational Photography, DOI 10.1109/ICCPHOT.2009.5559014
   [Anonymous], 2010, ACM T GRAPHICS TOG
   Babacan SD, 2009, IEEE T IMAGE PROCESS, V18, P12, DOI 10.1109/TIP.2008.2007354
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Cai JF, 2009, PROC CVPR IEEE, P1566, DOI 10.1109/CVPRW.2009.5206711
   Chan TF, 2005, INT J IMAG SYST TECH, V15, P92, DOI 10.1002/ima.20041
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chartrand R, 2010, INT CONF ACOUST SPEE, P766, DOI 10.1109/ICASSP.2010.5494993
   Chen J, 2008, LECT NOTES COMPUT SC, V5018, P1, DOI 10.1007/978-3-540-79723-4_1
   Chen XG, 2011, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2011.5995568
   Chen XG, 2010, OPT ENG, V49, DOI 10.1117/1.3505868
   Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   He L, 2005, INT J IMAG SYST TECH, V15, P74, DOI 10.1002/ima.20040
   Hirsch M, 2010, PROC CVPR IEEE, P607, DOI 10.1109/CVPR.2010.5540158
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2009, ACM T GRAPHICS SIGGR
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Money JH, 2008, IMAGE VISION COMPUT, V26, P302, DOI 10.1016/j.imavis.2007.06.005
   Rahmani P, 2008, LECT NOTES COMPUT SC, V5259, P410, DOI 10.1007/978-3-540-88458-3_37
   Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Tai YW, 2013, IEEE T PATTERN ANAL, V35, P2498, DOI 10.1109/TPAMI.2013.40
   Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   You YL, 1999, IEEE T IMAGE PROCESS, V8, P396, DOI 10.1109/83.748894
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhuo SJ, 2010, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2010.5539941
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 45
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11327
EP 11346
DI 10.1007/s11042-015-2856-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900023
DA 2024-07-18
ER

PT J
AU Kim, S
   Dey, AK
AF Kim, SeungJun
   Dey, Anind K.
TI Augmenting human senses to improve the user experience in cars: applying
   augmented reality and haptics approaches to reduce cognitive distances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Automotive user interfaces; Multisensory
   interaction; Sensory augmentation systems
ID LOAD THEORY; PERFORMANCE; INFORMATION; MODEL
AB Augmenting people's senses with computational support can improve the ability to perceive information and perform tasks. However, the impact of such augmentation may fluctuate according to user context, thereby impacting the quality of a user experience. In this paper, we present two systems that assess the in-situ effects of augmenting senses using Augmented Reality and Haptic technologies. We demonstrate that sensory augmentation systems can improve performance when users are multitasking; however, a hybrid assessment, including eye tracking and psycho-physiological measurement, reveals that the benefits and costs of such systems can differ depending on the demographics of a population with different cognitive capabilities. For elder adults, sensory augmentation improved perception for responding to local incidents in the physical space, but a richer intervention using sensory augmentation (visual, auditory, and haptic) strains cognitive load. For younger adults, additional modes for providing sensory information increased attentiveness for performing tasks, but can lead to overloading of already used sensory channels. Thus, sensory augmentation was more advantageous for improving global awareness for situated physical space, rather than responding to local incidents.
C1 [Kim, SeungJun; Dey, Anind K.] Carnegie Mellon Univ, Human Comp Interact Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Kim, S (corresponding author), Carnegie Mellon Univ, Human Comp Interact Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM sjunikim@cs.cmu.edu; anind@cs.cmu.edu
RI dey, anind/B-1312-2008
OI Kim, SeungJun/0000-0003-0470-2483
FU General Motors; Carnegie Mellon University's Technologies for Safe and
   Efficient Transportation; National USDOT University Transportation
   Center for Safety (T-SET UTC) - US Department of Transportation
FX This project is funded in part by General Motors, Carnegie Mellon
   University's Technologies for Safe and Efficient Transportation, The
   National USDOT University Transportation Center for Safety (T-SET UTC)
   which is sponsored by the US Department of Transportation.
CR Anderson JR, 2002, COGNITIVE SCI, V26, P85, DOI 10.1207/s15516709cog2601_3
   [Anonymous], P INT C ADV LEARN TE
   Canham M, 2010, LEARN INSTR, V20, P155, DOI 10.1016/j.learninstruc.2009.02.014
   Carton A., 2013, Augmented Human International Conference, P58, DOI [10.1145/2459236.2459247., DOI 10.1145/2459236.2459247]
   Cegarra J, 2008, BEHAV RES METHODS, V40, P988, DOI 10.3758/BRM.40.4.988
   CHANDLER P, 1992, BRIT J EDUC PSYCHOL, V62, P233, DOI 10.1111/j.2044-8279.1992.tb01017.x
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Chang W, 2011, INT J HUM-COMPUT INT, V27, P1119, DOI 10.1080/10447318.2011.555321
   Clive-smith M, 2013, MED EV C WEAR TECHN
   Collins CC, 1985, Electronic Spatial Sensing for the Blind, P35
   Conati C, 2009, USER MODEL USER-ADAP, V19, P267, DOI 10.1007/s11257-009-9062-8
   Cook AM, 1982, THERAPEUTIC MED DEVI, P152
   Coyne JT, 2009, LECT NOTES ARTIF INT, V5638, P469, DOI 10.1007/978-3-642-02812-0_55
   D'Mello S, 2012, INT J HUM-COMPUT ST, V70, P377, DOI 10.1016/j.ijhcs.2012.01.004
   De Waard D., 1996, The Measurement of Drivers Mental Workload
   FISK AD, 1987, CURR PSYCHOL RES REV, V5, P315
   Goldberg J. H., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P51, DOI 10.1145/507072.507082
   Haapalainen E, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P301
   HART S G, 1988, P139
   Iqbal S. T., 2004, CHI 04 HUM FACT COMP, P1477, DOI [10.1145/985921.986094, DOI 10.1145/985921.986094]
   Javal E, 1879, ESSAI PHYSL LECT ANN
   Kaczmarek K. A., 1995, CRC HDB BIOMEDICAL E, P2100
   Kahneman D., 1973, Attention and effort
   Kalyuga S, 2007, EDUC PSYCHOL REV, V19, P509, DOI 10.1007/s10648-007-9054-3
   Kalyuga S, 2012, EDUC PSYCHOL REV, V24, P313, DOI 10.1007/s10648-012-9195-x
   Kern D, 2009, LECT NOTES COMPUT SC, V5538, P42, DOI 10.1007/978-3-642-01516-8_5
   Kim Seung Jun, 2014, C HUMAN FACTORS COMP, P1867, DOI [10.1145/2559206.2581248, DOI 10.1145/2559206.2581248]
   Kim S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P493
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Klauer SG, 2014, NEW ENGL J MED, V370, P54, DOI 10.1056/NEJMsa1204142
   Kramer AF, 1991, Multiple Task Performance, DOI DOI 10.1201/9781003069447-14/PHYSIOLOGICAL-METRICS-MENTAL-WORKLOAD-REVIEW-RECENT-PROGRESS-ARTHUR-KRAMER
   Larson R., 2014, New directions for methodology of social & behavioral science, P21, DOI [DOI 10.1007/978-94-017-9088-8_2, 10.1007/978-94-017-9088-82, DOI 10.1007/978-94-017-9088-82]
   Mauri M, 2010, IEEE ENG MED BIO, P3563, DOI 10.1109/IEMBS.2010.5627465
   Mercier J., 2012, Neuroeducation, V1, P5
   Mital A, 1999, INT J IND ENG-THEORY, V6, P190
   Narzt W., 2006, Universal Access in the Information Society, V4, P177, DOI 10.1007/s10209-005-0017-5
   Paas F, 2004, INSTR SCI, V32, P1, DOI 10.1023/B:TRUC.0000021806.17516.d0
   PAAS FGWC, 1994, J EDUC PSYCHOL, V86, P122, DOI 10.1037/0022-0663.86.1.122
   Poole A, 2005, BCS CONF SERIES, P363, DOI 10.1007/1-84628-062-1_23
   POSNER MI, 1971, PSYCHOL REV, V78, P391, DOI 10.1037/h0031333
   Salvucci DD, 2001, INT J HUM-COMPUT ST, V55, P85, DOI 10.1006/ijhc.2001.0472
   Salvucci DD, 1999, CMUCS99131
   Schiessl M., 2003, MMI Interaktiv, V6
   Setz C, 2010, IEEE T INF TECHNOL B, V14, P410, DOI 10.1109/TITB.2009.2036164
   SeungJun Kim, 2012, Pervasive Computing. Proceedings of the 10th International Conference, Pervasive 2012, P179, DOI 10.1007/978-3-642-31205-2_12
   Simon A.H., 1971, COMPUTERS COMMUNICAT, P37
   Sottilare R.A., 2013, Design recommendations for intelligent tutoring systems: Volume 1-learner modeling, V1
   Sungjae Hwang, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P660, DOI 10.1109/PERCOMW.2010.5470517
   Wickens C. D., MULTIPLE TASK PERFOR, P3
   Wickens C.D., 1984, Varieties of Attention, P63
   Wickens CD, 1981, EPL813ONR813 U ILL
   Yarbus A. L., 1967, Eye Movements and Vision
NR 52
TC 25
Z9 26
U1 5
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9587
EP 9607
DI 10.1007/s11042-015-2712-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500005
DA 2024-07-18
ER

PT J
AU Liu, Y
   Tong, XJ
   Ma, J
AF Liu, Yang
   Tong, Xiaojun
   Ma, Jing
TI Image encryption algorithm based on hyper-chaotic system and dynamic
   S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Hyper-chaotic system; S-box; Linear feedback shift
   registers
ID LENGTH
AB Chaos based image encryption algorithm is a research hotspot in multimedia security area. In this paper, a hyper-chaos based image encryption algorithm is proposed. Firstly, a new hyper-chaotic system is constructed and its dynamic characteristics are analyzed. The proposed hyper-chaotic system has bigger Lyapunov exponent than many classical hyper-chaotic systems. Then this system is used to generate key-streams to permute and substitute the image pixels. In the encryption algorithm, a dynamic S-box is constructed to get good confusion effect. This S-box is based on the inverse operation in the algebraic structure Z (257). Moreover, this inverse operation is embedded into an affine transformation to complicate the algebraic expression of the S-box and improve its security. The analysis results show that the proposed algorithm performs well.
C1 [Liu, Yang; Tong, Xiaojun] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Ma, Jing] Sci & Technol Informat Assurance Lab, Beijing 100072, Peoples R China.
C3 Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM liuyang@hitwh.edu.cn; tong_xiaojun@163.com
FU National Natural Science Foundation of China [60973162]; Natural Science
   Foundation of Shandong Province of China [ZR2014FM026, ZR2009GM037];
   Science and Technology of Shandong Province, China [2013GGX10129,
   2010GGX10132, 2012GGX10110]; Soft Science of Shandong Province, China
   [2012RKA10009]; National Cryptology Development Foundation of China
   [MMJJ201301006]; Foundation of Science and Technology on Information
   Assurance Laboratory [KJ-14-005]; Engineering Technology and Research
   Center of Weihai Information Security
FX This work was supported by the National Natural Science Foundation of
   China (60973162), the Natural Science Foundation of Shandong Province of
   China (ZR2014FM026, ZR2009GM037), the Science and Technology of Shandong
   Province, China (2013GGX10129, 2010GGX10132, 2012GGX10110), the Soft
   Science of Shandong Province, China (2012RKA10009), the National
   Cryptology Development Foundation of China (MMJJ201301006), the
   Foundation of Science and Technology on Information Assurance Laboratory
   (No. KJ-14-005) and the Engineering Technology and Research Center of
   Weihai Information Security.
CR Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Cai GL, 2007, ACTA PHYS SIN-CH ED, V56, P6230, DOI 10.7498/aps.56.6230
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   KAM JB, 1979, IEEE T COMPUT, V28, P747, DOI 10.1109/TC.1979.1675242
   Katz J, 2008, INTRO MODERN CRYPTOG, P234
   Li S. J., 2001, LECT NOTES COMPUTER, V2247, P316
   Liao XF, 2009, THEORY APPL CHAOTIC, P50
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Lin QZ, 2013, J SYST SOFTWARE, V86, P1384, DOI 10.1016/j.jss.2013.01.012
   Liu Ming-hua, 2010, Journal of Applied Sciences, V28, P406, DOI 10.3969/j.issn.0255-8297.2010.04.013
   Liu SB, 2009, J COMPUT, V4, P1091
   Liu Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1548, DOI 10.1016/j.image.2013.07.009
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   MILNOR J, 1985, COMMUN MATH PHYS, V99, P177, DOI 10.1007/BF01212280
   Qi GY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/5/050507
   [邱劲 Qiu Jing], 2012, [计算机科学, Computer Science], V39, P44
   Sang T, 1998, ELECTRON LETT, V34, P873, DOI 10.1049/el:19980680
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Tong XJ, 2012, J SYST SOFTWARE, V85, P850, DOI 10.1016/j.jss.2011.10.051
   Tong XJ, 2010, SCI CHINA INFORM SCI, V53, P191, DOI 10.1007/s11432-010-0010-3
   Wang JZ, 2006, CHINESE PHYS, V15, P1216, DOI 10.1088/1009-1963/15/6/015
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu XJ, 2014, COMMUN NONLINEAR SCI, V19, P1884, DOI 10.1016/j.cnsns.2013.10.025
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 26
TC 53
Z9 53
U1 3
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7739
EP 7759
DI 10.1007/s11042-015-2691-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600014
DA 2024-07-18
ER

PT J
AU Harb, SME
   Isa, NAM
   Salamah, S
AF Harb, Suheir M. Elbayoumi
   Isa, Nor Ashidi Mat
   Salamah, Samy
TI New adaptive interpolation scheme for image upscaling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Geometric regularity; Geometric duality; Intensity
   distance
ID SUPERRESOLUTION; ALGORITHM
AB Preserving edge structures and image details simultaneously is considered the main challenge for image interpolation techniques that produce high-resolution images from their low-resolution counterparts. Two variants of a new adaptive interpolation scheme are proposed in this paper. In the proposed scheme for better interpolation of natural images, a new estimation mechanism that utilizes discontinuities in blocks around missing pixels is devised to discriminate strong edges. Strong edge pixels are obtained by using amended error linear interpolation and cubic convolution interpolation. Adaptive interpolation weights determined by inverse intensity distances in local windows are used to produce non-strong edge pixels based on local image structure. The proposed amended linear interpolation and cubic convolution interpolation exhibited approximately comparable performances. Simulation results on different types of images, including natural, texture, and cartoon images, demonstrate that, compared with other state-of-the-art algorithms, the proposed algorithm can generate better visual quality of the magnified images with higher peak signal-to-noise ratio (PSNR), structural similarity (SSIM), feature similarity (FSIM) index, and reasonable execution time.
C1 [Harb, Suheir M. Elbayoumi; Isa, Nor Ashidi Mat] Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
   [Salamah, Samy] Palestine Tech Coll, Dept Comp, Gaza, Israel.
C3 Universiti Sains Malaysia
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
EM suheirma@gmail.com; ashidi@usm.my; samy_ptc@yahoo.com
RI Salamah, Samy A. M./ABF-5807-2020; Mat Isa, Nor Ashidi/I-7826-2017
OI Mat Isa, Nor Ashidi/0000-0002-2675-4914
FU Research University Grant for Individual (RUI), Universiti Sains
   Malaysia, Malaysia
FX This study was partially supported by the Research University Grant for
   Individual (RUI), Universiti Sains Malaysia, Malaysia titled
   "Development of an intelligent auto-Immune Diseases Diagnostic System by
   classification of Hep_2 Immunofluorescence Patterns".
CR Amanatiadis A, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/10/104015
   [Anonymous], FREE PHOT
   [Anonymous], COMP COMM NETW ICCCN
   [Anonymous], COMP VIS 2009 IEE 12
   [Anonymous], IM AN SIGN PROC IASP
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], TEST IM
   [Anonymous], TEST IM
   [Anonymous], INT J COMPUT SCI ENG
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   Biancardi A, 2002, PATTERN RECOGN, V35, P677, DOI 10.1016/S0031-3203(01)00034-6
   Cha Y, 2007, IEEE T IMAGE PROCESS, V16, P1496, DOI 10.1109/TIP.2007.896645
   Chen HY, 2010, SIGNAL PROCESS, V90, P1676, DOI 10.1016/j.sigpro.2009.11.019
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Han JW, 2010, IEEE T CONSUM ELECTR, V56, P175, DOI 10.1109/TCE.2010.5439142
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jing MG, 2013, OPT COMMUN, V286, P111, DOI 10.1016/j.optcom.2012.09.011
   Jurio A, 2011, IEEE T IMAGE PROCESS, V20, P3112, DOI 10.1109/TIP.2011.2158227
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee YJ, 2010, IEEE T IMAGE PROCESS, V19, P2682, DOI 10.1109/TIP.2010.2050108
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lu GY, 2008, COMPUT GEOSCI-UK, V34, P1044, DOI 10.1016/j.cageo.2007.07.010
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Sajjad M, 2012, MULTIMEDIA TOOLS APP, P1
   Shi GM, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3327934
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wittman T., 2005, Mathematical techniques for image interpolation
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yun Y, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.4.040503
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhou D, 2012, IET IMAGE PROCESS, V6, P627, DOI 10.1049/iet-ipr.2011.0534
NR 38
TC 1
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7293
EP 7325
DI 10.1007/s11042-015-2647-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400028
DA 2024-07-18
ER

PT J
AU Yang, J
   Sha, WEI
   Chao, HY
   Jin, Z
AF Yang, Jun
   Sha, Wei E. I.
   Chao, Hongyang
   Jin, Zhu
TI High-quality image restoration from partial mixed adaptive-random
   measurements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data acquisition; Mixed adaptive-random sampling; Total variation;
   Compressive sensing
ID SIGNAL RECOVERY; RECONSTRUCTION; MINIMIZATION; ALGORITHM; PURSUIT
AB A novel framework to construct an efficient sensing (measurement) matrix, called mixed adaptive-random (MAR) matrix, is introduced for directly acquiring a compressed image representation. The mixed sampling (sensing) procedure hybridizes adaptive edge measurements extracted from a low-resolution image with uniform random measurements predefined for the high-resolution image to be recovered. The mixed sensing matrix seamlessly captures important information of an image, and meanwhile approximately satisfies the restricted isometry property. To recover the high-resolution image from MAR measurements, the total variation algorithm based on the compressive sensing theory is employed for solving the Lagrangian regularization problem. Both peak signal-to-noise ratio and structural similarity results demonstrate the MAR sensing framework shows much better recovery performance than the completely random sensing one. The work is particularly helpful for high-performance and lost-cost data acquisition.
C1 [Yang, Jun; Jin, Zhu] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sha, Wei E. I.] Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
   [Chao, Hongyang] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; University of Hong Kong; Sun Yat Sen University
RP Sha, WEI (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.; Chao, HY (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM juneryoung@gmail.com; wsha@eee.hku.hk; isschhy@mail.sysu.edu.cn;
   zjin.sysu@gmail.com
RI Sha, Wei E. I./G-4955-2010
OI Sha, Wei E. I./0000-0002-7431-8121
FU China NSF [61173081, 61201122]; Guangdong Natural Science Foundation,
   China [S2011020001215]
FX Dr. Sha acknowledges Ms. Qing Ye to motivate the compressive sensing
   work. We also would like to acknowledge the support of China NSF under
   Grant 61173081 and 61201122; and Guangdong Natural Science Foundation,
   China, under Grant S2011020001215.
CR ALLINEY S, 1994, IEEE T SIGNAL PROCES, V42, P618, DOI 10.1109/78.277854
   [Anonymous], 1997, ALGORITHMS IMAGE PRO
   [Anonymous], 2009, ARXIV09061487
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Hager W. W., 2006, Pacific J. Optimization, V2, P35
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Li P., 2006, P ACM SIGKDD INT C K, P287
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Needell D, 2013, SIAM J IMAGING SCI, V6, P1035, DOI 10.1137/120868281
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Romberg Justin, 2007, 2007 2nd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, P137, DOI 10.1109/CAMSAP.2007.4497984
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488
   Zhang J., 2011, PowerTech, 2011 IEEE Trondheim, P1
NR 26
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6189
EP 6205
DI 10.1007/s11042-015-2566-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700008
DA 2024-07-18
ER

PT J
AU Said, J
   Hiary, H
AF Said, Jamal
   Hiary, Hazem
TI Watermark location via back-lighting modelling and verso registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paper watermark; Image registration; Back-lighting; Recto and verso
   removal
AB We consider the location of paper watermarks in documents that present problems such as variable paper thickness, stain and other damage. Earlier work has shown success in exploiting a computational model of backlit image acquisition - here we enhance this approach by incorporating knowledge of surface verso features. Robustly removing recto features using established techniques, we present a registration approach that permits similarly robust removal of verso, leaving only features attributable to watermark, folds, chain lines and inconsistencies of paper manufacture. Experimental results illustrate the success of the approach.
C1 [Said, Jamal; Hiary, Hazem] Univ Jordan, Amman 11942, Jordan.
C3 University of Jordan
RP Hiary, H (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM hazemh@ju.edu.jo
RI Hiary, Hazem/C-8358-2015
OI Hiary, Hazem/0000-0002-0306-5294
CR Ash N., 1982, BOOK PAPER GROUP ANN, VVolume 1
   Bianco G, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P131, DOI 10.1109/VSMM.2009.25
   Biermann C, 1996, HDB PULPING PAPERMAK, P171
   Boyle RD, 2009, INT J DOC ANAL RECOG, V12, P33, DOI 10.1007/s10032-009-0080-1
   Bridgman C.F., 1958, STUD CONSERV, V3, P175, DOI [10.1179/sic.1958.025, DOI 10.1179/SIC.1958.025]
   Bridgman CF, 1965, STUD CONSERV, V10, P8
   Edge D, 2001, COMPUT MUSICOL, V12, P261
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Goshtasby AA, 2005, 2-D AND 3-D IMAGE REGISTRATION FOR MEDICAL, REMOTE SENSING, AND INDUSTRIAL APPLICATIONS, P1
   Gravell TL, 1990, DU PONT MAG, V84, P4
   Haupt W., 1981, RESTAURO, V87, P38
   Heawood Edward., 1950, Watermarks Mainly of the 17th and 18th Centuries
   Hiary H, 2008, THESIS U LEEDS
   Hiary H, NG K DIGITISED ARABI
   Hiary H, 2007, INT J DIGIT LIBRARIE, V6, P351, DOI 10.1007/s00799-007-0008-7
   Hunter D., 1978, Papermaking: the history and technique of an ancient craft
   Jie Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1176, DOI 10.1109/ICDAR.2009.126
   Lewis J.P., 1995, Vision, Interface, V95, P120
   Moschini D, 2000, PUZZLES PAPER CONCEP, P187
   Neuheuser H. P., 2005, ABI-Technik, V25, P266, DOI 10.1515/ABITECH.2005.25.4.266
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Schoonover D., 1987, ESSAYS PAPER ANAL, P154
   Sharma G, 2001, IEEE T IMAGE PROCESS, V10, P736, DOI 10.1109/83.918567
   Small CA, 2000, PUZZLES PAPER CONCEP, P169
   Stevenson Allan., 1951, Studies in Bibliography, V4, P57
   STEWART D, 1995, J IMAGING SCI TECHN, V39, P261
   TOMIMASU H, 1991, TAPPI J, V74, P165
   Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V7, P17, DOI 10.1007/s10032-004-0121-8
   Tonazzini A, 2004, LECT NOTES COMPUT SC, V3212, P241
   Tonazzini Anna, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P546, DOI 10.1109/ICDAR.2009.131
   Tonazzini A, 2007, INT J DOC ANAL RECOG, V10, P17, DOI 10.1007/s10032-006-0015-z
   Van Aken J, 2003, STUD CONSERV, V48, P103, DOI 10.1179/sic.2003.48.2.103
   Wang J, 2010, INT CONF COMP SCI, P274, DOI 10.1109/ICCSIT.2010.5565027
   Wang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P69, DOI 10.1109/DAS.2008.60
   Wolberg G, 2000, IEEE IMAGE PROC, P493, DOI 10.1109/ICIP.2000.901003
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5673
EP 5688
DI 10.1007/s11042-015-2532-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600015
DA 2024-07-18
ER

PT J
AU Banitalebi-Dehkordi, A
   Pourazad, MT
   Nasiopoulos, P
AF Banitalebi-Dehkordi, Amin
   Pourazad, Mahsa T.
   Nasiopoulos, Panos
TI An efficient human visual system based quality metric for 3D video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3DTV; Stereoscopic video; Depth map; Cyclopean view; Quality of
   experience; 3D video quality metric
ID HEVC
AB Stereoscopic video technologies have been introduced to the consumer market in the past few years. A key factor in designing a 3D system is to understand how different visual cues and distortions affect the perceptual quality of stereoscopic video. The ultimate way to assess 3D video quality is through subjective tests. However, subjective evaluation is time consuming, expensive, and in some cases not possible. The other solution is developing objective quality metrics, which attempt to model the Human Visual System (HVS) in order to assess perceptual quality. Although several 2D quality metrics have been proposed for still images and videos, in the case of 3D efforts are only at the initial stages. In this paper, we propose a new full-reference quality metric for 3D content. Our method mimics HVS by fusing information of both the left and right views to construct the cyclopean view, as well as taking to account the sensitivity of HVS to contrast and the disparity of the views. In addition, a temporal pooling strategy is utilized to address the effect of temporal variations of the quality in the video. Performance evaluations showed that our 3D quality metric quantifies quality degradation caused by several representative types of distortions very accurately, with Pearson correlation coefficient of 90.8 %, a competitive performance compared to the state-of-the-art 3D quality metrics.
C1 [Banitalebi-Dehkordi, Amin; Pourazad, Mahsa T.; Nasiopoulos, Panos] Univ British Columbia, ICICS, Vancouver, BC V5Z 1M9, Canada.
   [Pourazad, Mahsa T.] TELUS Commun Inc, Vancouver, BC, Canada.
   [Banitalebi-Dehkordi, Amin; Nasiopoulos, Panos] Univ British Columbia, Dept Elect Engn, Vancouver, BC, Canada.
C3 University of British Columbia; University of British Columbia
RP Banitalebi-Dehkordi, A (corresponding author), Univ British Columbia, ICICS, Vancouver, BC V5Z 1M9, Canada.; Banitalebi-Dehkordi, A (corresponding author), Univ British Columbia, Dept Elect Engn, Vancouver, BC, Canada.
EM dehkordi@ece.ubc.ca; pourazad@icics.ubc.ca; panos@ece.ubc.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [STPGP 447339-13]; Institute for Computing Information and Cognitive
   Systems (ICICS) at UBC
FX This work was partly supported by Natural Sciences and Engineering
   Research Council of Canada (NSERC) under Grant STPGP 447339-13 and the
   Institute for Computing Information and Cognitive Systems (ICICS) at
   UBC.
CR [Anonymous], EL IM S 2009 SAN JOS
   [Anonymous], 2010, P 5 INT WORKSH VID P
   [Anonymous], 5 INT WORKSH VID PRO
   [Anonymous], 2011, 96 MPEG M GEN
   [Anonymous], 2010, VIEW SYNTH REF SOFTW
   [Anonymous], 46 ANN AS C SIGN SYS
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2006, THESIS EINDHOVEN U T
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2011, JTC1SC29WG11 ISOIEC
   [Anonymous], 2006, P 2 INT WORKSH VID P
   Banitalebi-Dehkordi A., 2013, INT 3DTV C VIS DEPTH
   Banitalebi-Dehkordi A, 2014, INT C IM PROC ICIP
   Banitalebi-Dehkordi A, 2013, JTC1SC29WG11 ISOIEC, VM27745
   Banitalebi-Dehkordi A, 2013, 38 INT C AC SPEECH S
   Banitalebi-Dehkordi A, 2013, 11 IEEE IVMSP WORKSH
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Boev A, 2010, MOBILE STEREOSCOPIC
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Chen M., 2013, IEEE T IMAGE PROCESS, V22
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen W, 2012, SPIE C STER DISPL AP
   Coria L, 2012, 3DTV CON TRUE VISION
   Coria LE, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P755, DOI 10.1109/ICCE.2011.5722846
   Ha K, 2010, 18 INT C IM PROC ICI
   Hamberg R, 1999, SMPTE J, V108, P802, DOI 10.5594/J04337
   Hanhart P, 2012, INT WORK QUAL MULTIM, P236, DOI 10.1109/QoMEX.2012.6263854
   Huynh-Thu Q, 2010, IEEE IMAGE PROC, P4025, DOI 10.1109/ICIP.2010.5650571
   Irwin D.E., 1992, Eye movements and visual cognition: Scene perception and reading, P146, DOI [10.1007/978-1-4612-2852-3_9, DOI 10.1007/978-1-4612-2852-3_9]
   Jin L., NOVEL STEREO VIDEO Q
   Jin L., 2011, 19 EUR SIGN PROC C E
   Jin LN, 2011, IEEE IMAGE PROC
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Lee K, 2010, IEEE 17 INT IM PROC
   Park J, 2011, IEEE IMAGE PROC
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Rimac-Drlje S, 2009, BROADBAND MULTIMEDIA
   Ryu S., 2014, IEEE T CIRCUITS SYST, V24
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sobel I, 2014, WORLD WIDE WEB, V1505
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tanimoto M, 2009, ISOIECJTC1SC29WG11MP
   Wang JJ, 2013, IEEE T IMAGE PROCESS, V22, P3690, DOI 10.1109/TIP.2013.2268977
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xu D, 2012, J SOC INF DISPLAY, V20, P397, DOI 10.1002/jsid.99
   Zicong Mai, 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P1, DOI 10.1109/ICCE-Berlin.2012.6336477
NR 50
TC 15
Z9 15
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4187
EP 4215
DI 10.1007/s11042-015-2466-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, X
   Jin, LH
   Song, EM
   He, Z
AF Li, Xiang
   Jin, Lianghai
   Song, Enmin
   He, Zeng
TI An integrated similarity metric for graph-based color image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph-based method; Image segmentation; Similarity metrics; Quaternion
ID FEATURE-SPACE; MEAN SHIFT; QUATERNION; TEXTURE; SUPERPIXELS; REGIONS
AB Graph-based method has become one of the major trends in image segmentation. In this paper, we focus on how to build the affinity matrix which is one of the key issues in graph-based color image segmentation. Four different metrics are integrated in order to build an effective affinity matrix for segmentation. First, the quaternion-based color distance is utilized to measure color differences between color pixels and the oversegmented regions (superpixels), which is more accurate than the commonly used Euclidean distance. In order to describe the superpixels well, especially for texture images, we combine the mean and the variance information to represent the superpixels. Then the image boundary information is used to merge the oversegmented regions to preserve the image edge and reduce the computational complexity. An object for recognition may be cut into nonadjacent sub-parts by clutter or shadows, the affinities between adjacent and nonadjacent superpixels are computed in our study. This feature of affinity is not considered in other methods which only consider the similarity of adjacent regions. Experimental results on the Berkeley segmentation dataset (BSDS) and Weizmann segmentation evaluation datasets demonstrate the superiority of the proposed approach compared with some existing popular image segmentation methods.
C1 [Li, Xiang; Jin, Lianghai; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Li, Xiang; Jin, Lianghai; Song, Enmin] Minist Image Proc & Intelligent Cont, Key Lab Educ, Wuhan 430074, Peoples R China.
   [He, Zeng] Huazhong Univ Sci & Technol, Sch Civil Engn & Mech, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Jin, LH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM lianghaijin@gmail.com
RI li, xiang/P-1588-2015
OI He, Zeng/0000-0002-5170-5970
FU National Natural Science Foundation of China [61370181, 61075010,
   61370179]; National Key Technology Research and Development Program of
   China [2012BAI23B07]
FX The authors would like to thank the anonymous reviewers for their
   insightful suggestions, and Dr. Chih-Cheng Hung for his valuable
   comments and suggestions. This work was supported by the National
   Natural Science Foundation of China (Grant Nos. 61370181, 61075010 and
   61370179), and National Key Technology Research and Development Program
   of China (Grant No. 2012BAI23B07).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383017
   [Anonymous], 2008, CVPR
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Cai CH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P816, DOI 10.1109/ICIP.2000.899834
   Collins MD, 2012, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2012.6247859
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Jahne B., 2002, DIGITAL IMAGE PROCES
   Jin LH, 2013, IEEE T CIRC SYST VID, V23, P741, DOI 10.1109/TCSVT.2012.2207272
   Jin LH, 2012, PATTERN RECOGN, V45, P4300, DOI 10.1016/j.patcog.2012.06.003
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Makrogiannis S, 2005, IEEE T SYST MAN CY B, V35, P44, DOI 10.1109/TSMCB.2004.837756
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0
   Nguyen HT, 2000, IEEE T IMAGE PROCESS, V9, P137, DOI 10.1109/83.817605
   Pei SC, 1997, IEEE T COMMUN, V45, P583, DOI 10.1109/26.592558
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Tilton JC, 2012, IEEE T GEOSCI REMOTE, V50, P4454, DOI 10.1109/TGRS.2012.2190079
   Tilton JC, 1998, INT GEOSCI REMOTE SE, P1766, DOI 10.1109/IGARSS.1998.703645
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang C, 2014, IEEE T MULTIMEDIA, V16, P903, DOI 10.1109/TMM.2014.2306393
   Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Xia T, 2009, NEUROCOMPUTING, V72, P3203, DOI 10.1016/j.neucom.2009.03.012
   Zhang XC, 2011, PATTERN RECOGN LETT, V32, P352, DOI 10.1016/j.patrec.2010.09.014
   Zhu SY, 1999, OPT ENG, V38, P612, DOI 10.1117/1.602105
NR 44
TC 3
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 2969
EP 2987
DI 10.1007/s11042-014-2416-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600003
DA 2024-07-18
ER

PT J
AU Paluri, S
   Kambhatla, KKR
   Bailey, BA
   Cosman, PC
   Matyjas, JD
   Kumar, S
AF Paluri, Seethal
   Kambhatla, Kashyap K. R.
   Bailey, Barbara A.
   Cosman, Pamela C.
   Matyjas, John D.
   Kumar, Sunil
TI A low complexity model for predicting slice loss distortion for
   prioritizing H.264/AVC video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Video coding; CMSE prediction; Slice prioritization; Slice
   loss; Unequal Error Protection (UEP); Slice discard
ID PACKET-LOSS VISIBILITY; QUALITY ESTIMATION; ALGORITHMS; STREAMS
AB The cumulative mean squared error (CMSE) is a widely used measure of distortion introduced by a slice loss. We propose a low-complexity and low-delay generalized linear model for predicting CMSE contributed by the loss of individual H.264/AVC encoded video slices. We train the model over a video database by using a combination of video factors that are extracted during the encoding of the current frame, without using any data from future frames in the group of pictures (GOP). We then analyze the accuracy of the CMSE prediction model using cross-validation and correlation coefficients. We prioritize the slices within a GOP based on their predicted CMSE values. The performance of our model is evaluated by applying unequal error protection, using rate compatible punctured convolutional codes, to the prioritized slices over noisy channels. We also demonstrate an application of our slice prioritization by implementing a slice discard scheme, where the slices are dropped from the router when the network experiences congestion. The simulation results show that (i) the slice CMSE prediction model performs well for varying GOP structures, GOP lengths, and encoding bit rates, and (ii) the peak signal-to-noise ratio and video quality metric performance of an unequal error protection algorithm using slices prioritized by the predicted CMSE is similar to that of the measured CMSE values for different videos and channel signal-to-noise. We also extend the GOP-level slice prioritization to frame-level slice prioritization and show its performance over noisy channels.
C1 [Paluri, Seethal] San Diego State Univ, Computat Sci Res Ctr, San Diego, CA 92182 USA.
   [Kambhatla, Kashyap K. R.; Kumar, Sunil] San Diego State Univ, Elect & Comp Engn, San Diego, CA 92182 USA.
   [Kambhatla, Kashyap K. R.] Univ Calif San Diego, San Diego, CA 92103 USA.
   [Bailey, Barbara A.] San Diego State Univ, Dept Math & Stat, San Diego, CA 92182 USA.
   [Cosman, Pamela C.] Univ Calif San Diego, Elect & Comp Engn, San Diego, CA 92103 USA.
   [Matyjas, John D.] Air Force Res Lab, Rome, NY USA.
C3 California State University System; San Diego State University;
   California State University System; San Diego State University;
   University of California System; University of California San Diego;
   California State University System; San Diego State University;
   University of California System; University of California San Diego;
   United States Department of Defense; United States Air Force; US Air
   Force Research Laboratory
RP Paluri, S (corresponding author), San Diego State Univ, Computat Sci Res Ctr, San Diego, CA 92182 USA.
EM spaluri@mail.sdsu.edu; kkambhat@ucsd.edu; bbailey@mail.sdsu.edu;
   pcosman@ucsd.edu; john.matyjas@us.af.mil; skumar@mail.sdsu.edu
RI Kumar, Sunil/AAT-4942-2020
OI Kumar, Sunil/0000-0001-9957-5661; Cosman, Pamela/0000-0002-4012-0176
FU U.S. Air Force Research Laboratory [FA8750-08-1-0078, FA8750-11-1-0048];
   Division Of Mathematical Sciences; Direct For Mathematical & Physical
   Scien [1107046] Funding Source: National Science Foundation
FX Approved for Public Release; Distribution Unlimited: 88ABW-2014-5103,
   4th November 2014. This research was partially supported by awards from
   the U.S. Air Force Research Laboratory under contract #FA8750-08-1-0078
   and FA8750-11-1-0048. Opinions, interpretations and conclusions are
   those of the authors and are not necessarily endorsed by the United
   States Government.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   ANDERSON TW, 1954, J AM STAT ASSOC, V49, P765, DOI 10.2307/2281537
   [Anonymous], INT PACK VID WORKSH
   [Anonymous], ICME
   [Anonymous], 2014, P IEEE INT C MULT EX
   [Anonymous], GEN LINEAR MODELS
   [Anonymous], IEEE COMPUTER COMMUN
   [Anonymous], P INT PACK VID WORKS
   [Anonymous], 2007, IEEE INT C IMAGE PRO
   [Anonymous], 2016, MODEL SELECTION MULT, DOI 10.1016/j.ecolmodel.2003.11.004
   [Anonymous], J QUAL TECHNOL
   Babich F, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324290
   Baccaglini E, 2008, IEEE SIGNAL PROC LET, V15, P581, DOI 10.1109/LSP.2008.2001565
   Bandyopadhyay SK, 2006, IEEE SARNOFF SYMPOS, P97
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L., 2001, Mach. Learn., V45, P5
   Chakareski J, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P763, DOI 10.1109/ICME.2005.1521535
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chakareski J, 2005, IEEE T CIRC SYST VID, V15, P1257, DOI 10.1109/TCSVT.2005.854227
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Chen WT, 2008, IEEE WCNC, P3133
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   De Vito F, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P141, DOI 10.1109/ICME.2002.1035738
   Hemami SS, 2010, SIGNAL PROCESS-IMAGE, V25, P469, DOI 10.1016/j.image.2010.05.009
   ICHIDA K, 1979, COMPUTING, V23, P85, DOI 10.1007/BF02252616
   Kambhatla KKR, 2012, IEEE IMAGE PROC, P1649, DOI 10.1109/ICIP.2012.6467193
   Kambhatla KKR, 2012, IEEE T MULTIMEDIA, V14, P1480, DOI 10.1109/TMM.2012.2196508
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kumar S, 2006, J VIS COMMUN IMAGE R, V17, P183, DOI 10.1016/j.jvcir.2005.12.002
   Li F, 2009, IEEE T CIRC SYST VID, V19, P1908, DOI 10.1109/TCSVT.2009.2031457
   Li ZC, 2009, IEEE T CIRC SYST VID, V19, P917, DOI 10.1109/TCSVT.2009.2022806
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Liu H, 2012, COMPUT COMMUN, V35, P151, DOI 10.1016/j.comcom.2011.08.006
   Masala E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P345
   Miguel V, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P211, DOI 10.1109/ICCE.2011.5722545
   Paluri S, 2012, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2012.6466953
   Pérez P, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P315, DOI 10.1109/ICCE.2011.5722602
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Schier M, 2012, IEEE T MULTIMEDIA, V14, P415, DOI 10.1109/TMM.2011.2178235
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shen YS, 2006, IEEE T IMAGE PROCESS, V15, P273, DOI 10.1109/TIP.2005.860598
   Srinivasan SK, 2010, IEEE T BROADCAST, V56, P281, DOI 10.1109/TBC.2010.2049610
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Talari A, 2009, IEEE MILIT COMMUN C, P1608
   Venables W., 2010, Modern Applied Statistics with S (Statistics and Computing)
   Wang Y, 2006, IEEE T CIRC SYST VID, V16, P716, DOI 10.1109/TCSVT.2006.875203
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu ZY, 2006, IEEE INT SYMP CIRC S, P4463
   Zhang F, 2014, J VIS COMMUN IMAGE R, V25, P542, DOI 10.1016/j.jvcir.2013.11.011
   Zhang PY, 2009, IEEE WCNC, P1, DOI 10.1109/PLASMA.2009.5227420
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang WZ, 2009, IEEE T CONSUM ELECTR, V55, P1982, DOI 10.1109/TCE.2009.5373759
NR 53
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 961
EP 985
DI 10.1007/s11042-014-2334-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yu, LY
   Han, Q
   Niu, XM
AF Yu, Liyang
   Han, Qi
   Niu, Xiamu
TI Feature point-based copy-move forgery detection: covering the
   non-textured areas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-Move Detection; MROGH Descriptor; Hue Histogram; Feature matching;
   Feature fusion
ID DUPLICATION FORGERY
AB Detection of copy-move forgery has recently attracted much attention. During the past decade, two categories of methods, namely block-based and feature point-based methods, gradually developed. Compared with block-based methods, feature point-based methods exhibit remarkable performance with respect to robustness and computational cost. However, the feature point-based methods are still incomplete especially in terms of forgeries involving small smooth regions. In this paper, we solve this problem by cautiously supplementing redundant feature points and feature fusion. We propose two-stage feature detection to obtain better feature coverage and enhance the matching performance by combining the MROGH and HH descriptor. We evaluated our method on two representative datasets. We use precision, recall and F (1) score to quantitatively evaluate the performance. Experimental results confirm the efficacy of our work.
C1 [Yu, Liyang; Han, Qi; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Heilongjiang, Peoples R China.
   [Yu, Liyang] Mudanjiang Normal Univ, Dept Comp Sci & Technol, Mudanjiang, Peoples R China.
C3 Harbin Institute of Technology; Mudanjiang Normal University
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Heilongjiang, Peoples R China.
EM liyang.yu.81@gmail.com; qi.han@hit.edu.cn
FU National Natural Science Foundation of China [61100187, 61361166006];
   China Postdoctoral Science Foundation [2011M500666]
FX The authors would like to thank Yuenan Li and Irene Amerini for sharing
   their copy-move forgery detection code. We also thank Mahmoud Emam and
   all the anonymous reviewers for their helpful comments and suggestions.
   Additionally, this work is supported by the National Natural Science
   Foundation of China (61100187 and 61361166006) and the China
   Postdoctoral Science Foundation (2011M500666).
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Brown M, 2005, PROC CVPR IEEE, P510
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gkalelis N, 2014, P INT C MULT RETR, V25
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu AC, 2004, TECHNICAL REPORT TR2
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Scherp A, 2014, MULTIMED TOOLS APPL, V70, P7, DOI 10.1007/s11042-013-1427-7
   Shivakumar B.L., 2011, International Journal of Computer Science Issues (IJCSI), V8
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
NR 27
TC 43
Z9 44
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1159
EP 1176
DI 10.1007/s11042-014-2362-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700021
DA 2024-07-18
ER

PT J
AU Li, CL
   Zhang, AH
   Liu, ZF
   Liao, L
   Huang, D
AF Li, Chunlei
   Zhang, Aihua
   Liu, Zhoufeng
   Liao, Liang
   Huang, Di
TI Semi-fragile self-recoverable watermarking algorithm based on wavelet
   group quantization and double authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-fragile; Self-recoverable; Tamper detection; Group quantization;
   Double authentication ring
ID IMAGE TAMPER DETECTION; SCHEME
AB Semi-fragile self-recoverable watermarking algorithms are important to meet various requirements such as security, robustness, localization, and image recovery. However, current approaches are not adequate for this importance. Thus, we propose a novel semi-fragile and self-recoverable watermarking algorithm based on a group quantization and double authentication method. In the proposed algorithm, a target image is first split into 16 x16 image blocks. For each image block, a five-bit authentication watermark is generated from the first-order statistical moment of the block and then is embedded into the mid-frequency band of another image block by a novel group-based wavelet quantization method. With the generated watermarks, image security is enhanced by randomly permuting coefficients among a group and image robustness is improved by embedding the watermark in the largest coefficient inside a sub-group by significant difference parity quantization. The proposed double authentication ring structure effectively improves the image localization accuracy. Recovered image is a better approximate to the original image. Experimental comparisons of ours with other algorithms shows the effectiveness of the proposed self-recoverable and semi-fragile watermarking algorithm.
C1 [Li, Chunlei; Zhang, Aihua; Liu, Zhoufeng; Liao, Liang] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.
   [Huang, Di] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Dev Environm, Beijing 10091, Peoples R China.
C3 Zhongyuan University of Technology; Beihang University
RP Huang, D (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Dev Environm, Beijing 10091, Peoples R China.
EM dhuang@buaa.edu.cn
RI Huang, Di/JBJ-3541-2023
OI Huang, Di/0000-0001-7877-7301
FU National Natural Science Foundation of China [61202499, 60902063,
   61152004]; Specialized Research Fund for the Doctoral Program of Higher
   Education [20121102120016]; State Key Laboratory of Software Development
   Environment [SKLSDE-2013ZX-31]; Henan provincial key science and
   technology research [142102210578, 132300410163, 142300410042]; LIA
   2MCSI lab; Fundamental Research Funds for Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61202499, No. 60902063, No. 61152004), the
   Specialized Research Fund for the Doctoral Program of Higher Education
   (No. 20121102120016); the research program of State Key Laboratory of
   Software Development Environment (SKLSDE-2013ZX-31); the project of
   Henan provincial key science and technology research (No. 142102210578,
   No. 132300410163, No. 142300410042); the joint grant by the LIA 2MCSI
   lab between the group of Ecoles Centrales and Beihang University; and
   the Fundamental Research Funds for the Central Universities.
CR [Anonymous], MAKING BUSINESS CASE
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Chunlei Li, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P327, DOI 10.1007/978-3-642-34778-8_30
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   FRIDRICH J, 1999, CONTENT SECURITY DAT
   He HJ, 2008, IHW, P137
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Ho ATS, 2008, IEEE T INF FOREN SEC, V3, P567, DOI 10.1109/TIFS.2008.926994
   Holliman M, 2010, IEEE T IMAGE PROCESS, V3, P432
   Hung KL, 2001, OPT ENG, V40, P1950, DOI 10.1117/1.1391435
   Kim KS, 2011, COMPUT VIS IMAGE UND, V115, P1308, DOI 10.1016/j.cviu.2011.05.001
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Li CT, 2007, J ELECTRON IMAGING, V16, P134
   Li GB, 2009, INT C COMP SUPP COOP, P107, DOI 10.1109/CSCWD.2009.4968043
   Li KF, 2001, P INT C COMM COMP SI
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu H, 2010, EUR J ANAESTH, V27, P740, DOI 10.1097/EJA.0b013e328337bb56
   Liu HM, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P229, DOI 10.1109/ICME.2008.4607413
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   MeenakshiDevi P., 2009, Journal of Computer Sciences, V5, P831, DOI 10.3844/jcssp.2009.831.837
   Mendoza-Noriega JA, 2010, MIDWEST SYMP CIRCUIT, P612, DOI 10.1109/MWSCAS.2010.5548902
   Peng ZN, 2008, CHAOS SOLITON FRACT, V36, P946, DOI 10.1016/j.chaos.2006.07.015
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Solorio SB, 2011, SIGNAL PROCESS, V91, P728, DOI DOI 10.1016/J.SIGPRO.2010.07.019
   Stinson D. R., 2018, Cryptography Theory and Practice
   Tsai MJ, 2008, OPT ENG, V47, DOI 10.1117/1.2947580
   Wang JW, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2954129
   Watson A.B., 1993, Proc. AIAA Computing in Aerospace, V9, P286
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Yu M, 2007, SCI CHINA SER F, V50, P491, DOI 10.1007/s11432-007-0024-7
   Zhang JS, 2004, J CHINA I COMMUN, V25, P98
   ZHANG JS, 2004, P IEEE ICME 04
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 43
TC 21
Z9 21
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10581
EP 10604
DI 10.1007/s11042-014-2188-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700020
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
AF Weng, Shaowei
   Pan, Jeng-Shyang
TI Adaptive reversible data hiding based on a local smoothness estimator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Adaptive embedding technique; The local
   smoothness estimator; Multi-step embedding strategy
ID GENERALIZED INTEGER TRANSFORM; HISTOGRAM-MODIFICATION; DIFFERENCE
   EXPANSION; IMAGE WATERMARKING; PREDICTION ERRORS
AB A novel reversible watermarking (RW) scheme based on a local smoothness estimator and multi-step embedding strategy is proposed in this paper. All the pixels are divided into four equal parts. Correspondingly, the watermark embedding process is separated into four independent steps. Thus each step is performed to embed watermark information into its corresponding image part. In each step, for each to-be-embedded pixel, a local smoothness estimator defined as the variance of its total neighbors is presented to estimate its local smoothness. An obvious advantage of introducing this estimator is that it can determine those pixels in smooth regions accurately. In fact, accurate determination means the decrease in embedding distortion. At the low embedding rate (ER), modifications induced by difference expansion (DE) are done only to those pixels located in smooth regions. Hence, the proposed method can obtain high embedding capacity while maintaining good visual quality. With ER gradually increased, adaptive embedding is employed. In adaptive embedding, for one to-be-embedded pixel, 1 or 2 bits are adaptively embedded according to the strength of relationship among all the pixels surrounding it. The experimental results demonstrate that the proposed method is effective.
C1 [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Harbin Inst Technol, Grad Sch, Shenzhen, Peoples R China.
C3 Guangdong University of Technology; Harbin Institute of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61272498, 61001179]; New Star of Pearl
   River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (No. 61201393,
   No. 61272498, No. 61001179), New Star of Pearl River on Science and
   Technology of Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2013, J INF HIDING MULTIM
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP, V2002
   Hong W., 2010, EURASIP J ADV SIGNAL
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Marin O, 2014, J INFORM HIDING MULT, V5, P451
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2010, P ICIP
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xuan GR, 2004, P IWDW, V5, P23
NR 35
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10657
EP 10678
DI 10.1007/s11042-014-2197-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700023
DA 2024-07-18
ER

PT J
AU Karri, S
   Sur, A
AF Karri, Swathi
   Sur, Arijit
TI Steganographic algorithm based on randomization of DCT kernel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Cover image; Stego image; DCT; Parametric
   DCT; Calibration attack
ID STEGANALYSIS
AB Calibration attack is one of the most important attacks specially on JPEG domain steganography. Prediction of cover image statistics from its stego image is an important requirement in calibration based attacks. Domain separation techniques are used as a counter measures against such attacks because they make the cover image prediction process rather difficult. Most of the algorithms in the past are based on randomization of embedding locations. In this paper, we propose a new domain separation technique which is based on randomization of DCT kernel matrix. A comprehensive set of experiments are done to validate that the proposed domain separation scheme performs better than the related existing schemes.
C1 [Karri, Swathi; Sur, Arijit] IIT Guwahati, Dept CSE, Gauhati, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sur, A (corresponding author), IIT Guwahati, Dept CSE, Gauhati, Assam, India.
EM karri@iitg.ernet.in; arijit@iitg.ernet.in
RI Sur, Arijit/AAB-4216-2020
OI Sur, Arijit/0000-0002-9038-8138
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2011, P SPIE, V7880
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2008, P SPIE SECURITY STEG, V6819
   [Anonymous], P SPIE
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Chandrakanth B, P ICVGIP 12 8 IND C
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Eggers J, 2002, P SPIE SECURITY WATE, V4675
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fridrich Jessica., 2007, STATISTICALLY UNDETE, P3
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Jain AnilK., 1989, Fundamentals of Digital Image Processing, P150
   Kodovsky J, P SPIE, P313
   Liu Q, P 13 ACM MULT WORKSH, P77
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Pevny T, P SPIE ELECT IMAGING, P313
   Pevny T, IEEE T INFO FORENSIC, V5, P215
   Provos N., 2001, Proceedings of the 10th conference on USENIX Security Symposium, P24
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Solanki K., 2005, P IEEE INT C IM PROC, P1118
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Sur Arijit, 2012, Transactions on Data Hiding and Multimedia Security VII: LNCS 7110, P82, DOI 10.1007/978-3-642-28693-3_6
   Upham D., STEGANOGRAPHIC ALGOR
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 27
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9207
EP 9230
DI 10.1007/s11042-014-2077-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200007
DA 2024-07-18
ER

PT J
AU Kono, S
   Rutkowski, TM
AF Kono, Shota
   Rutkowski, Tomasz M.
TI Tactile-force brain-computer interface paradigm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tactile media interface; Brain-computer interface; Brain somatosensory
   evoked response; Brainwave signal processing and classification
AB This study explores the extent to which a neurotechnology multimedia application utilizing tactile-force stimulus delivered to the hand holding a force-feedback joystick can serve as a platform for a brain-computer interface (BCI). We present a successful application of an extended multimedia paradigm beyond the classic vision and auditory based approaches. The four pressure directions are used to evoke tactile brain potential responses, thus defining a tactile-force brain computer interface (tfBCI). We present brainwave electroencephalogram (EEG) signal processing and classification procedures leading to successful online interfacing results. Experiment results with seven advanced and five naive users performing online BCI experiments provide a validation of the hand location tfBCI paradigm, while the feasibility of the concept is substantiated by noteworthy information-transfer rates.
C1 [Kono, Shota; Rutkowski, Tomasz M.] Univ Tsukuba, TARA, Life Sci Ctr, Tsukuba, Ibaraki 3058577, Japan.
   [Rutkowski, Tomasz M.] RIKEN Brain Sci Inst, Wako, Saitama 3510198, Japan.
C3 University of Tsukuba; RIKEN
RP Rutkowski, TM (corresponding author), Univ Tsukuba, TARA, Life Sci Ctr, Tennodai 1-1-1, Tsukuba, Ibaraki 3058577, Japan.
EM tomek@bci-lab.info
RI Rutkowski, Tomasz Maciej/D-2445-2015; Rutkowski, Tomasz/AAO-7976-2020
OI Rutkowski, Tomasz Maciej/0000-0002-4259-4121; 
FU Ministry of Internal Affairs and Communications in Japan [121803027]
FX This research was supported in part by the Strategic Information and
   Communications R&D Promotion Program, no. 121803027, of The Ministry of
   Internal Affairs and Communications in Japan.
CR [Anonymous], 2012, BRAIN COMPUTER INTER
   Brouwer AM, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00019
   Jurcak V, 2007, NEUROIMAGE, V34, P1600, DOI 10.1016/j.neuroimage.2006.09.024
   Kaufmann T, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00129
   Kono S, 2014, THESIS
   Kono S, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P812, DOI 10.1109/SITIS.2013.132
   Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007
   Mori Hiromu, 2013, Haptic and Audio Interaction Design. 8th International Workshop (HAID 2013). Revised Selected Papers: LNCS 7989, P50, DOI 10.1007/978-3-642-41068-0_6
   Mori H., 2013, P 5 INT BRAIN COMP I
   Müller-Putz GR, 2006, IEEE T NEUR SYS REH, V14, P30, DOI 10.1109/TNSRE.2005.863842
   Plum F., 1966, The diagnosis of stupor and coma
   Rutkowski TM, 2009, P INT WORKSH INT WOR, P5
   Rutkowski TM, 2015, J NEUROSCI METH, V244, P45, DOI 10.1016/j.jneumeth.2014.04.010
   Schalk G, 2010, PRACTICAL GUIDE TO BRAIN-COMPUTER INTERFACING WITH BCI2000, P1, DOI 10.1007/978-1-84996-092-2
   van der Waal M, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/045002
   Wischenbart M, 2010, FORCEFEEDBACK JOYSTI
NR 16
TC 4
Z9 4
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8655
EP 8667
DI 10.1007/s11042-014-2351-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600026
DA 2024-07-18
ER

PT J
AU Oh, AR
   Nixon, MS
AF Oh, Ah-Reum
   Nixon, Mark S.
TI Extending the image ray transform for shape detection and extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Feature extraction; Shape extraction; Histogram pattern
   analysis; Image ray transform
ID HIGH-LEVEL
AB A conventional approach to image analysis is to separately perform feature extraction at a low level (such as edge detection) and follow this with high level feature extraction to determine structure (e.g. by collecting edge points) using the Hough transform. The original image Ray Transform (IRT) demonstrated capability to extract structures at a low level. Here we extend the IRT to add shape specificity that makes it select specific shapes rather than just edges; the new capability is achieved by addition of a single parameter that controls which shape is selected by the extended IRT. The extended approach can then perform low-and high-level feature extraction simultaneously. We show how the IRT process can be extended to focus on chosen shapes such as lines and circles. Histogram patterns, which are an extension to this new capability, can describe extracted features showing that the extracted patterns are robust to change in orientation, position and scale. We confirm the new capability by using conventional methods for exact shape location, such as the Hough transform. We analyse performance with images from the Caltech-256 dataset and show that the new approach can indeed select chosen shapes. Further research will aim to capitalise on the new extraction ability to extend descriptive capability.
C1 [Oh, Ah-Reum; Nixon, Mark S.] Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England.
C3 University of Southampton
RP Oh, AR (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England.
EM aro1g11@ecs.soton.ac.uk; msn@ecs.soton.ac.uk
RI Nixon, Mark S/F-7406-2014; Oh, Ah Reum/AAO-9733-2021
OI Nixon, Mark/0000-0002-9174-5934
CR Beucher S, 1979, P INT WORKSH IM PROC
   Cummings AH, 2010, P IEEE BTAS
   Cummings AH, 2011, PATTERN RECOGN LETT, V32, P2053, DOI 10.1016/j.patrec.2011.08.020
   Direkoglu C, 2011, PATTERN RECOGN LETT, V32, P270, DOI 10.1016/j.patrec.2010.08.012
   Griffin Greg., 2006, Caltech-256 object category dataset
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Hurley DJ, 2002, IMAGE VISION COMPUT, V20, P311, DOI 10.1016/S0262-8856(02)00003-3
   Madabhushi A, 2003, IEEE T MED IMAGING, V22, P155, DOI 10.1109/TMI.2002.808364
   Maragos P, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P587, DOI 10.1016/B978-012119792-6/50098-X
   Oh AR, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P100, DOI 10.1109/SITIS.2013.27
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
NR 13
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8597
EP 8612
DI 10.1007/s11042-014-2348-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600023
DA 2024-07-18
ER

PT J
AU Xiao, D
   Deng, MM
   Zhu, XY
AF Xiao, Di
   Deng, Mimi
   Zhu, Xinyi
TI A reversible image authentication scheme based on compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Compressive sensing; Reversible watermarking;
   Zero-watermarking
ID WATERMARKING
AB In order to satisfy the requirement of reversible authentication as well as tamper localization and recovery, a reversible image authentication scheme based on compressive sensing (CS) is proposed. Double watermarks are employed, including a short one (perception Hash) for image integrity authentication and a long one for tamper localization and recovery. First, we embed the short watermark into the image in a reversible way. The embedding method is based on histogram modification of discrete Haar wavelet coefficients which is proposed in this paper. Then the long watermark, which is generated by CS sampling on the transformation coefficients of the non-overlapping image blocks, is registered to intellectual property rights (IRP) database for saving in a zero-watermarking way. At the authentication side, the receiver recovers the image after extracting the short watermark, and compares the Hash values generated from the recovered image with the short watermark for authentication. If the authentication is successful, the image can be completely restored to the original state in a reversible way; if the authentication fails, by utilizing the long watermark in the IRP database and CS reconstruction, it can achieve tamper localization and recovery. Meanwhile, experimental results show that the watermarked image has good imperceptibility. The proposed scheme is with good potential to be adopted for reversible image authentication.
C1 [Xiao, Di; Deng, Mimi; Zhu, Xinyi] Chongqing Univ, Coll Comp Sci, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI Zhu, Xinyi/HSG-4784-2023
OI Zhu, Xinyi/0000-0002-1421-5593
FU Natural Science Foundation Project of CQ CSTC [2011jjjq40001]; Chongqing
   Key Laboratory of Emergency Communications [CQKLEC, 20140504]
FX The work was funded by the Natural Science Foundation Project of CQ CSTC
   (Grant No. 2011jjjq40001) and supported by the open research fund of
   Chongqing Key Laboratory of Emergency Communications (Grant No. CQKLEC,
   20140504).
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chang CC, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P506, DOI 10.1109/EUC.2008.20
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2000, IEEE IMAGE PROC, P446, DOI 10.1109/ICIP.2000.900991
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gu QL, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P95, DOI 10.1109/CISP.2008.323
   Li CL, 2013, MULTIMED TOOLS APPL, V64, P757, DOI 10.1007/s11042-011-0974-z
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tzung-Her Chen, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P13, DOI 10.1109/IIHMSP.2010.11
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Yuan H, 2006, IEEE T IMAGE PROCESS, V15, P3189, DOI 10.1109/TIP.2006.877310
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   [赵春晖 Zhao Chunhui], 2012, [自动化学报, Acta Automatica Sinica], V38, P609
   Zhong X, 2007, IEEE 2007 INTERNATIONAL SYMPOSIUM ON MICROWAVE, ANTENNA, PROPAGATION AND EMC TECHNOLOGIES FOR WIRELESS COMMUNICATIONS, VOLS I AND II, P1227
NR 25
TC 18
Z9 20
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7729
EP 7752
DI 10.1007/s11042-014-2017-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200015
DA 2024-07-18
ER

PT J
AU Yang, WC
   Chen, LH
AF Yang, Wen-Chao
   Chen, Ling-Hwei
TI Reversible DCT-based data hiding in stereo images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo images; Data hiding; Quantized DCT coefficients
AB Stereo images captured from a pair of CCDs simultaneously are widely used to create the illusion of 3D depth. Each pair of stereo images has many similar block pairs. In this paper, a novel reversible data hiding method is proposed to embed secret data in these similar block pairs. To increase the embedding capacity, each 3-bit secret data is first converted to a pair of integers. Then, similar block pairs are found based on the lower frequency DCT-quantized coefficients. Each converted integer is embedded via the difference of a pair of middle frequency DCT-quantized coefficients from these similar block pairs. It is worth mentioning that the proposed method is reversible, but the existing data hiding methods for stereo images are irreversible. Experimental results show that the proposed method is undetectable under Chi-square analysis, and it provides high embedding capacity while maintaining acceptable quality of stereo images higher than 30 dB. The experimental results also show that the proposed method outperforms Chang et al.'s method and Lin and Shiu's method in embedding capacity and image quality.
C1 [Yang, Wen-Chao; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM wchy@debut.cis.nctu.edu.tw; lhchen@cc.nctu.edu.tw
CR Bai NY, 1998, P 8 NAT C INF SEC MA, P245
   Campisi P, 2008, J ELECTRON IMAGING, V17
   Chang CC, 2007, INF SCI, V141, P123
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Katzenbeisser S., 2000, INFORM HIDING TECHNI, P3
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Luo T, 2013, MULTIMEDIA TOOLS APP
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Rengarajaswamy C, 2013, P ICEVENT, P1
   Shrikalaa M, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P686
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wong K., 2010, International Symposium on Communications, Control, and Signal Processing, P1, DOI DOI 10.1109/ISCCSP.2010.5463307
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 17
TC 14
Z9 15
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7181
EP 7193
DI 10.1007/s11042-014-1958-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800027
DA 2024-07-18
ER

PT J
AU Oh, S
   Hahn, M
   Kim, J
AF Oh, Seungwon
   Hahn, Minsoo
   Kim, Jinsul
TI Dynamic EKF-based SLAM for autonomous mobile convergence platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SLAM; Mobile robot; Dynamic; EKF; SURF
ID SIMULTANEOUS LOCALIZATION; ROBOTS; CAMERA
AB This paper presents a new Simultaneous Localization and Mapping (SLAM) framework for solving the problem of SLAM in dynamic environments. The landmark location change causes the error of robot pose estimation and landmark mapping. In this paper, we propose the Dynamic Extended Kalman Filter (EKF) SLAM based on the independence of the dynamic landmarks. The proposed framework decomposes the SLAM problem into a traditional SLAM problem for the static landmarks and individual SLAM problems for the dynamic landmarks. Therefore, in the dynamic environments, it is able to minimize the error caused by the dynamic landmarks and reduce the uncertainty in the robot pose and the landmark locations. In order to validate the proposed approach, we implement an indoor mobile robot platform with a Red Green Blue - Depth (RGB-D) sensor and utilize Speeded Up Robust Features (SURF) algorithm to extract appearance-based features. The simulation and experimental results show the validity and robustness of the Dynamic EKF SLAM in indoor environments including the dynamic landmarks.
C1 [Oh, Seungwon; Hahn, Minsoo] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
   [Kim, Jinsul] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju 500757, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Chonnam
   National University
RP Hahn, M (corresponding author), Korea Adv Inst Sci & Technol, 335 Gwahak Ro, Taejon 305701, South Korea.
EM swoh@kaist.ac.kr; mshahn@ee.kaist.ac.kr; jsworld@jnu.ac.kr
RI Hahn, Minsoo/C-1746-2011
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program; MSIP (Ministry of Science, ICT & Future Planning), Korea, under
   the ITRC (Information Technology Research Center) support program
   [NIPA-2013-H0301-13-3005]
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program and also supported
   partially by the MSIP (Ministry of Science, ICT & Future Planning),
   Korea, under the ITRC (Information Technology Research Center) support
   program (NIPA-2013-H0301-13-3005) supervised by the NIPA (National IT
   Industry Promotion Agency).
CR [Anonymous], 1990, Autonomous Robot Vehicles, DOI 10.1007/978-1-4613-8997-2{}14
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bibby C, 2010, IEEE INT CONF ROBOT, P257, DOI 10.1109/ROBOT.2010.5509262
   Chung SY, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1594, DOI 10.1109/IROS.2008.4650945
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616
   Ganganath N., 2012, 2012 IEEE International Conference on Emerging Signal Processing Applications, P91, DOI 10.1109/ESPA.2012.6152453
   Hähnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816
   Hochdorfer S, 2010, IEEE INT C INT ROBOT, P3981, DOI 10.1109/IROS.2010.5651229
   Howarth B, 2010, IEEE INT C INT ROBOT, P1539, DOI 10.1109/IROS.2010.5648844
   Kuen-Han Lin, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3975, DOI 10.1109/IROS.2010.5649653
   Lee SJ, 2010, ROBOTICA, V28, P97, DOI 10.1017/S026357470900561X
   Lee TK, 2011, IEEE INT C INT ROBOT, P841, DOI 10.1109/IROS.2011.6048539
   May S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P790, DOI 10.1109/iros.2006.281670
   Montemerlo M., 2003, P INT JOINT C ARTIFI, P1151, DOI [10.5555/1630659.1630824, DOI 10.5555/1630659.1630824]
   Montemerlo M, 2002, P AAAI
   Murillo AC, 2007, IEEE INT CONF ROBOT, P3901, DOI 10.1109/ROBOT.2007.364077
   Murphy K., 1999, ADV NEURAL INFORM PR
   Pirker K, 2011, IEEE INT C INT ROBOT, P3990, DOI 10.1109/IROS.2011.6048253
   Rogers John G.  III, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P2077, DOI 10.1109/IROS.2010.5652091
   Siegwart R, 2004, INTRO AUTONOMOUS MOB, P250
   Takezawa S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1866
   Thrun S, 2005, PROBABILISTIC ROBOTI, P191
   Wang CC, 2003, IEEE INT CONF ROBOT, P842
   Wangsiripitak Somkiat, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P375, DOI 10.1109/ROBOT.2009.5152290
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799
   Zhang ZY, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P1651, DOI 10.1109/WCICA.2008.4593166
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 31
TC 7
Z9 8
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6413
EP 6430
DI 10.1007/s11042-014-2093-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700020
DA 2024-07-18
ER

PT J
AU Tu, H
   Kumar, N
   Kim, J
   Seo, J
AF Tu, Hang
   Kumar, Neeraj
   Kim, Jongsung
   Seo, Jungtaek
TI A strongly secure pairing-free certificateless authenticated key
   agreement protocol suitable for smart media and mobile environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Certificateless cryptography; Authenticated key agreement; Provable
   security; Bilinear pairings; Elliptic curve
AB The authenticated key agreement (AKA) protocol is an important cryptographic mechanism, which allows two users to establish a session key for future communication. Recently, the certificateless public key cryptography received wide attention since it could solve the certificate management problem in the traditional public key cryptography and solve the key escrow problem in the identity-based public key cryptography. In this paper, we present a strongly secure certificateless authenticated key agreement (CLAKA) protocol without pairing suitable for smart media and mobile environments, which is provably secure in the extended Canetti-Krawczyk (eCK) model and is secure as long as each party has at least one uncompromised secret. Compared with previous CLAKA protocols, our protocol has advantages over them in security or efficiency.
C1 [Tu, Hang] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
   [Kumar, Neeraj] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kim, Jongsung] Kookmin Univ, Dept Math, Seoul, South Korea.
   [Kim, Jongsung] Kookmin Univ, Dept Financial Informat Secur, Plus Future Financial Informat Secur Specialist E, Seoul, South Korea.
   [Seo, Jungtaek] NSRI, Taejon, South Korea.
C3 Wuhan University; Thapar Institute of Engineering & Technology; Kookmin
   University; Kookmin University
RP Kim, J (corresponding author), Kookmin Univ, Dept Math, Seoul, South Korea.
EM neeraj.kumar@thapar.edu; jongsung.k@gmail.com; seojt@ensec.re.kr
RI Kumar, Neeraj/J-4123-2017; Kumar, Neeraj/L-3500-2016
OI Kumar, Neeraj/0000-0002-3020-3947; Seo, Jung Taek/0000-0003-0971-8548
FU Basic Science Research Program - National Research Foundation of Korea
   (NRF) funded by the Ministry of Education [2013R1A1A2059864]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (grant number 2013R1A1A2059864).
CR Al-Riyami SS, 2003, LECT NOTES COMPUT SC, V2894, P452
   [Anonymous], 1993, P 13 ANN INT CRYPT C
   [Anonymous], J INFORM COMPUTATION
   [Anonymous], 2011, P 6 ACM S INF COMP C, DOI DOI 10.1145/1966913.1966924
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   Bellare M., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, P57, DOI 10.1145/225058.225084
   Canetti R, 2001, LECT NOTES COMPUT SC, V2045, P453
   Cao XF, 2010, INFORM SCIENCES, V180, P2895, DOI 10.1016/j.ins.2010.04.002
   Chen L, 2007, INT J INF SECUR, V6, P213, DOI 10.1007/s10207-006-0011-9
   He DB, 2012, COMPUT MATH APPL, V64, P1914, DOI 10.1016/j.camwa.2012.03.044
   He DB, 2011, MATH COMPUT MODEL, V54, P3143, DOI 10.1016/j.mcm.2011.08.004
   He DB, 2012, INT J COMMUN SYST, V25, P221, DOI 10.1002/dac.1265
   Hou MB, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 1, P412, DOI 10.1109/ICCSIT.2009.5234917
   LaMacchia B, 2007, LECT NOTES COMPUT SC, V4784, P1
   Lippold G, 2009, LECT NOTES COMPUT SC, V5671, P206, DOI 10.1007/978-3-642-03298-1_14
   Mandt TK, 2007, LECT NOTES COMPUT SC, V4435, P37
   Manman Geng, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P208, DOI 10.1109/CIS.2009.152
   Ni L, 2011, COMPUT ELECTR ENG, V37, P205, DOI 10.1016/j.compeleceng.2011.03.001
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Shao Zu-Hua, 2005, Wuhan University Journal of Natural Sciences, V10, P267, DOI 10.1007/BF02828666
   Shi Yijuan, 2007, Wuhan University Journal of Natural Sciences, V12, P71, DOI 10.1007/s11859-006-0194-y
   Swanson C, 2008, THESIS U WATERLOO
   Zhang L, 2010, INFORM SCIENCES, V180, P1020, DOI 10.1016/j.ins.2009.11.036
NR 23
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6365
EP 6377
DI 10.1007/s11042-015-2470-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700016
DA 2024-07-18
ER

PT J
AU Akiyama, Y
   Oore, S
   Watters, C
AF Akiyama, Yasushi
   Oore, Sageev
   Watters, Carolyn
TI Framework for constructing task-space to support novice multimedia
   authoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interface designs; Multimedia interfaces; Multimedia authoring;
   Multimedia authoring as problem-solving tasks
ID CREATIVITY
AB Despite the growing demand of complex multimedia contents and the evolution of the authoring tools, many home computer users face significant obstacles in an attempt to familiarize themselves with multimedia authoring tasks. Many authoring tools have evolved to accommodate advanced skills typically performed by professionals and to introduce new authoring styles that are only possible with digital tools. As a result, interface designs of such tools have become more complicated and are often intimidating to novices thus preventing them from undertaking even the initial task. For users with little knowledge in multimedia authoring, one of the challenging issues is generating mental representation of the task that they are trying to perform. Being unable to construct proper task-spaces often results in a poor action plan, leading to an inefficient or undesirable outcome. We investigate and propose a new framework for constructing and presenting task-spaces with which users can interact in order to explore rather complex task-spaces during multimedia authoring tasks. The framework is grounded in the cognitive models originally developed in the context of planning and problem-solving tasks. We then illustrate how the proposed framework might be used in practical examples and suggest possible modifications or new features for existing authoring tools. The proposed framework was evaluated in the user studies.
C1 [Akiyama, Yasushi; Watters, Carolyn] Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada.
   [Oore, Sageev] St Marys Univ, Dept Math & Comp Sci, Halifax, NS B3H 3C3, Canada.
C3 Dalhousie University; Saint Marys University - Canada
RP Akiyama, Y (corresponding author), Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada.
EM yasushi@cs.dal.ca; watters@cs.dal.ca; sageev@cs.smu.ca
OI Oore, Sageev/0000-0002-8130-3569
FU NSERC; CFI
FX This research is funded with the support of NSERC and CFI. The authors
   would like to thank Derek Reilly for his invaluable feedback, and also
   the anonymous reviewers for their very helpful comments that improved
   the quality of the manuscript significantly.
CR Akiyama Y, 2014, J MULTIMED THEORY AP, V2, P11
   Akiyama Y, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P735
   ANZAI Y, 1984, COGNITIVE SCI, V8, P221, DOI 10.1016/S0364-0213(84)80002-6
   BARRETT A, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1117
   Berlage, 1994, ACM T COMPUT-HUM INT, V1, P269
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Cox R., 1995, Journal of Artificial Intelligence in Education, V6, P239
   Davies SP, 2005, COGNITIVE PSYCHOL PL
   Davis M, 2003, IEEE MULTIMEDIA, V10, P54, DOI 10.1109/MMUL.2003.1195161
   Duignan M, 2004, LECT NOTES COMPUT SC, V3101, P111
   Ecker D., 1963, Journal of Aesthetic Education and Art Criticism, V21, P283
   Foote J., 2002, P ACM MULTIMEDIA 200, P553, DOI DOI 10.1145/641007.641119
   GICK ML, 1986, EDUC PSYCHOL-US, V21, P99, DOI 10.1207/s15326985ep2101&2_6
   Guindon R., 1990, Human-Computer Interaction, V5, P305, DOI 10.1207/s15327051hci0502&3_6
   HAYES-ROTH B, 1979, Cognitive Science, V3, P275, DOI 10.1207/s15516709cog0304_1
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hick WE, 1952, Q J EXP PSYCHOL, V4, P11, DOI 10.1080/17470215208416600
   Hoc J.M., 1988, COGNITIVE PSYCHOL PL
   Iqbal ST, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P677
   JEFFRIES R, 1980, COGNITIVE SKILLS THE, P255
   Johnson H, 2006, INT J HUM-COMPUT ST, V64, P998, DOI 10.1016/j.ijhcs.2006.06.001
   Losh S, 2010, GUNDO PLUGIN FOR VIM
   Makedon F., 1994, Educational Multimedia and Hypermedia, 1994. Proceedings of ED-MEDIA 94, P38
   McFarland MC, 1988, PAPERS 25 YEARS ELEC, P602
   NEWELL A, 1958, PSYCHOL REV, V65, P151, DOI 10.1037/h0048495
   Newell A., 1972, HUMAN PROBLEM SOLVIN, V104
   Norman Don, 2013, The design of everyday things
   Ormerod TC, 2005, CURR ISS THINK REASO, P53
   Osburn HK, 2006, CREATIVITY RES J, V18, P173, DOI 10.1207/s15326934crj1802_4
   Patalano AL, 1997, COGNITIVE PSYCHOL, V34, P1, DOI 10.1006/cogp.1997.0655
   Pu P, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P145, DOI 10.1109/INFVIS.2000.885103
   SACERDOTI ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5
   Salyucci DD, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P89
   Scott SD, 2006, 50 ANN M HUM FACT ER, P16
   SEAGO A, 2004, 200420 OP U
   Shneiderman B, 2009, ENGINEERING THE USER INTERFACE: FROM RESEARCH TO PRACTICE, P1, DOI 10.1007/978-1-84800-136-7_1
   Simon Herbert A, 1978, Handbook of Learning and Cognitive Processes, V5, P271, DOI DOI 10.4324/9781315770314
   Turner G, 2003, OZCHI AS PAC COMP HU, P44
   Ward G, 2005, CURR ISS THINK REASO, P1
   Ware C., 2004, MORGAN KAUFMANN SERI, V2nd
   Xian-Sheng Hua, 2005, 13th Annual ACM International Conference on Multimedia, P792
   Yamamoto Y, 2005, INT J HUM-COMPUT ST, V63, P513, DOI 10.1016/j.ijhcs.2005.04.023
   Zhang JJ, 1997, COGNITIVE SCI, V21, P179
NR 43
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 6111
EP 6147
DI 10.1007/s11042-014-1911-8
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100036
DA 2024-07-18
ER

PT J
AU Kopaczewski, K
   Szczodrak, M
   Czyzewski, A
   Krawczyk, H
AF Kopaczewski, K.
   Szczodrak, M.
   Czyzewski, A.
   Krawczyk, H.
TI A method for counting people attending large public events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd; People counting; Crowd behavior
ID TRACKING; SYSTEM
AB The algorithm for people counting in crowded scenes, based on the idea of virtual gate which uses optical flow method is presented. The concept and practical application of the developed algorithm under real conditions is depicted. The aim of the work is to estimate the number of people passing through entrances of a large sport hall. The most challenging problem was the unpredicted behavior of people while entering the building. The examined flow of people fluctuated between individual persons and dense crowd. A series of experiments during sport and entertainment events was made. The results of the experiments show a high efficiency of the elaborated algorithm.
C1 [Kopaczewski, K.; Szczodrak, M.; Czyzewski, A.] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, PL-80233 Gdansk, Poland.
   [Krawczyk, H.] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Comp Architecture Dept, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology; Fahrenheit
   Universities; Gdansk University of Technology
RP Szczodrak, M (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, Ul Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM kkop@sound.eti.pg.gda.pl; szczodry@sound.eti.pg.gda.pl;
   andcz@sound.eti.pg.gda.pl
RI Krawczyk, Henryk/G-9508-2017; Krawczyk, Henryk/AAD-3430-2022; Czyzewski,
   Andrzej/JXN-0946-2024
OI Krawczyk, Henryk/0000-0003-0436-6264; Krawczyk,
   Henryk/0000-0003-0436-6264; Czyzewski, Andrzej/0000-0001-9159-8658
FU European regional development fund; Polish State budget; 
   [POIG.02.03.03-00-008/08]
FX Research funded within the project No. POIG.02.03.03-00-008/08, entitled
   "MAYDAY EURO 2012-the supercomputer platform of context-depended
   analysis of multimedia data streams for identifying specified objects or
   safety threads". The project is subsidized by the European regional
   development fund and by the Polish State budget.
CR Albiol A, 2001, IEEE T INTELL TRANSP, V2, P204, DOI 10.1109/6979.969366
   Albiol A, 2009, IEEE IMAGE PROC, P2569, DOI 10.1109/ICIP.2009.5414002
   [Anonymous], P 5 INT C SOFTW DAT
   [Anonymous], FAILURE RESPONSIBILI
   [Anonymous], 2012, P ASM INT MECH ENG
   Bozzoli M, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P506, DOI 10.1109/ICIAP.2007.4362828
   Cui JS, 2007, COMPUT VIS IMAGE UND, V106, P300, DOI 10.1016/j.cviu.2006.07.015
   Czyzewski A, 2008, STUD COMP INTELL, V142, P75
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Mathews E, 2009, EURASIP J EMBED SYST, DOI 10.1155/2009/352172
   Szczuko P, 2014, MULTIMED TOOLS APPL, V68, P177, DOI 10.1007/s11042-012-1147-4
   Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122
NR 15
TC 12
Z9 12
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4289
EP 4301
DI 10.1007/s11042-013-1628-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600007
OA hybrid
DA 2024-07-18
ER

PT J
AU Yoon, SM
   Yoon, GJ
   Schreck, T
AF Yoon, Sang Min
   Yoon, Gang-Joon
   Schreck, Tobias
TI User-drawn sketch-based 3D object retrievalusing sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Sketch-based querying; Gradient descriptor; Sparse
   coding
ID ROBUST UNCERTAINTY PRINCIPLES; SIGNAL RECOVERY; BENCHMARK
AB 3D object retrieval from user-drawn (sketch) queries is one of the important research issues in the areas of pattern recognition and computer graphics for simulation, visualization, and Computer Aided Design. The performance of any content-based 3D object retrieval system crucially depends on the availability of effective descriptors and similarity measures for this kind of data. We present a sketch-based approach for improving 3D object retrieval effectiveness by optimizing the representation of one particular type of features (oriented gradients) using a sparse coding approach. We perform experiments, the results of which show that the retrieval quality improves over alternative features and codings. Based our findings, the coding can be proposed for sketch-based 3D object retrieval systems relying on oriented gradient features.
C1 [Yoon, Sang Min] Kookmin Univ, Sch Comp Sci, Seoul, South Korea.
   [Yoon, Gang-Joon] Ewha W Univ, Dept Math, Seoul, South Korea.
   [Schreck, Tobias] Univ Konstanz, Comp & Informat Sci, Constance, Germany.
C3 Kookmin University; Ewha Womans University; University of Konstanz
RP Yoon, SM (corresponding author), Kookmin Univ, Sch Comp Sci, Seoul, South Korea.
EM sangmin.yoon@gmail.com; gangjoon@gmail.com;
   Tobias.Schreck@uni-konstanz.de
RI Yoon, Gangjoon/GZM-8532-2022
OI Schreck, Tobias/0000-0003-0778-8665
FU Korea Meteorological Administration Research and Development Program
   under Grant Weather Information Service Engine(WISE) project
   [153-3100-3133-302-350]; National Research Foundation of Korea(NRF) -
   Korea government(MEST) [2013024792]
FX S.M. Yoon was funded by the Korea Meteorological Administration Research
   and Development Program under Grant Weather Information Service
   Engine(WISE) project, 153-3100-3133-302-350. G.-J. Yoon was supported by
   the National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MEST) (No. 2013024792).
CR [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], 2013, P EUR WORKSH 3D OBJ, DOI DOI 10.2312/3DOR/3DOR13/049-056
   [Anonymous], 2013, EUR WORKSH 3D OBJ RE
   [Anonymous], ACM SIGGRAPH
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Bozas K, 2012, LECT NOTES COMPUT SC, V7431, P210, DOI 10.1007/978-3-642-33179-4_21
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Bustos B, 2012, MULTIMED TOOLS APPL, V58, P81, DOI 10.1007/s11042-010-0689-6
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Dutagaci H., 2011, Proceedings of the 4th Eurographics Conference on 3D Object Retrieval, 3DOR'11, P57
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gregor K., 2010, P INT C MACH LEARN I
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   LEE J, 2008, EUROGRAPHICS WORKSH
   LI B., 2012, EurographicsWorkshop on 3D Object Retrieval, P109
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Wright JL, 2009, IEEE INT C EMERG
   Yoon SM, 2012, ELECTRON LETT, V48, P493, DOI 10.1049/el.2012.0170
   Yoon SM, 2011, ELECTRON LETT, V47, P1181, DOI 10.1049/el.2011.2158
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 45
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4707
EP 4722
DI 10.1007/s11042-013-1831-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400012
DA 2024-07-18
ER

PT J
AU Kim, C
AF Kim, Chulyun
TI Theoretical analysis of constructing wavelet synopsis on partitioned
   data sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet; MapReduce; Data mining; Cloud computing; Big data
AB Currently, the size of data becomes much larger and the distributed data processing is getting very important to manage the huge size of data. The MapReduce well known as Google's data processing environment is the most popular distributed platform with good scalability and fault tolerance. Many traditional algorithms in the single machine environment are being adopted to the MapReduce platform. In this paper we analyze a novel algorithm to generate wavelet synopses on the distributed MapReduce framework. Wavelet synopsis is one of the most popular dimensionality reduction methods and has been studied in various areas such as query optimization, approximate query answering, feature selection, etc. In the proposed algorithm, the wavelet synopsis can be calculated by a single MapReduce phase, and, by minimizing the amount of data communicated through the network of the distributed MapReduce platform, all computations are processed within almost linear time complexity. We theoretically study the properties of constructing wavelet synopsis on partitioned data sets and the correctness of the proposed algorithm.
C1 Gachon Univ, Dept Software Design & Management, Songnam, South Korea.
C3 Gachon University
RP Kim, C (corresponding author), Gachon Univ, Dept Software Design & Management, Songnam, South Korea.
EM cykim@gachon.ac.kr
FU Gachon University [GCU-2011-R077]
FX This work was supported by the Gachon University research fund of 2011.
   (GCU-2011-R077).
CR Cao P, 2004, P PODC C
   CHAKRABARTI K, 2000, P VLDB C
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Ghemawat S., 2004, P OSDI C
   Gilbert AC, 2001, P VLDB C
   GUHA S, 2004, P VLDB C
   Guha S, 2006, P SODA C
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Jestes J, 2011, PROC VLDB ENDOW, V5, P109, DOI 10.14778/2078324.2078327
   Jiang J, 2006, MULTIMED TOOLS APPL, V29, P93, DOI 10.1007/s11042-006-0001-y
   Karras P, 2007, P ICDE C
   Kim C, 2012, J KIISE DATABASES, V39, P346
   Li Z, 2012, MULTIMED TOOLS APPL, V56, P419, DOI 10.1007/s11042-010-0594-z
   MATIAS Y, 1998, P ACM SIGMOD C
   Mattias Y, 2000, P VLDB C
   Natsev A, 1999, P ACM SIGMOD C
   Omidyeganeh M, 2013, MULTIMED TOOLS APPL, V65, P441, DOI 10.1007/s11042-012-1012-5
   Tsai MJ, 2011, MULTIMED TOOLS APPL, V52, P385, DOI 10.1007/s11042-009-0422-5
   VITTER JS, 1999, P ACM SIGMOD C
   Vitter JS, 1998, P CIKM C
NR 20
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2417
EP 2432
DI 10.1007/s11042-014-1908-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200015
DA 2024-07-18
ER

PT J
AU Yus, R
   Ilarri, S
   Mena, E
AF Yus, Roberto
   Ilarri, Sergio
   Mena, Eduardo
TI Real-time selection of video streams for live TV broadcasting based on
   Query-by-Example using a 3D model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query by example; Camera shot similarity computation; User interfaces to
   manage 3D scenes
ID IMAGE RETRIEVAL; RELEVANCE FEEDBACK; SEARCH
AB The emergence of low-cost cameras with nearly professional features in the consumer market represents a new important source of video information. For example, using an increasing number of these cameras in live TV broadcastings enables obtaining varied contents without affecting the production costs. However, searching for interesting shots (e.g., a certain view of a specific car in a race) among many video sources in real-time can be difficult for a Technical Director (TD). So, TDs require a mechanism to easily and precisely represent the kind of shot they want to obtain abstracting them from the need to be aware of all the views provided by the cameras. In this paper we present our proposal to help a TD to visually define, using an interface for the definition of 3D scenes, an interesting sample view of one or more objects in the scenario. We recreate the views of the cameras in a 3D engine and apply 3D geometric computations on their virtual view, instead of analyzing the real images they provide, to enable an efficient and precise real-time selection. Specifically, our system computes a similarity measure to rank the candidate cameras. Moreover, we present a prototype of the system and an experimental evaluation that shows the interest of our proposal.
C1 [Yus, Roberto; Ilarri, Sergio; Mena, Eduardo] Univ Zaragoza, IIS Dept, Zaragoza 50018, Spain.
C3 University of Zaragoza
RP Yus, R (corresponding author), Univ Zaragoza, IIS Dept, Maria de Luna 1, Zaragoza 50018, Spain.
EM ryus@unizar.es; silarri@unizar.es; emena@unizar.es
RI Yus, Roberto/AAO-4477-2020; Mena Nieto, Eduardo/F-7459-2016; ILARRI,
   SERGIO/L-6311-2014
OI Yus, Roberto/0000-0002-9311-954X; Mena Nieto,
   Eduardo/0000-0002-7462-0080; ILARRI, SERGIO/0000-0002-7073-219X
FU CICYT [TIN2010-21387-C02-02]; DGA-FSE
FX This research work has been supported by the CICYT project
   TIN2010-21387-C02-02 and DGA-FSE. We would also like to thank the
   anonymous reviewers for their useful comments.
CR Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Assfalg J, 2002, IEEE T VIS COMPUT GR, V8, P305, DOI 10.1109/TVCG.2002.1044517
   Cheng E, 2009, IEEE T IMAGE PROCESS, V18, P1350, DOI 10.1109/TIP.2009.2017128
   Chmielewski J, 2012, MULTIMED TOOLS APPL
   Choi K, 2009, INT WORKSH ADV IM TE
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Erozel G, 2008, INFORM SCIENCES, V178, P2534, DOI 10.1016/j.ins.2008.02.001
   Fagin R, 2003, SIAM PROC S, P28
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Ilarri S, 2012, MOB INF SYST, V8, P17, DOI 10.1155/2012/386472
   Ilarri S, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1670679.1670682
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Li B, 2013, MULTIMED TOOLS APPL, V65, P363, DOI 10.1007/s11042-012-1009-0
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280
   McCown F, 2007, ACM-IEEE J CONF DIG, P309, DOI 10.1145/1255175.1255237
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Morrison D, 2012, MULTIMED TOOLS APPL
   Pedronette DCG, 2012, MULTIMED TOOLS APPL
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shi ZP, 2012, MULTIMED TOOLS APPL, V61, P263, DOI 10.1007/s11042-011-0836-8
   Shirahama K., 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P829, DOI 10.1109/ICIG.2011.158
   Shirahama K, 2010, 12 INT WORKSH MULT M, P5
   Shirahatti NV, 2005, PROC CVPR IEEE, P955
   Thomee B, 2010, THESIS LEIDEN U GERM
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Trillo R, 2011, INFORM SYST, V36, P117, DOI 10.1016/j.is.2010.06.008
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   Wang XY, 2012, MULTIMED TOOLS APPL
   Yus R, 2011, 19 ACM INT C MULT MM, P1005
   Zloof MosheM., 1975, Proceedings of the AFIPS National Computer Conference, Anaheim, CA, P431, DOI DOI 10.1147/SJ.164.0324
NR 37
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2659
EP 2685
DI 10.1007/s11042-013-1550-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300006
DA 2024-07-18
ER

PT J
AU Chen, J
   Chen, YZ
   Qin, D
   Kuo, YH
AF Chen, Jian
   Chen, Yunzheng
   Qin, Dong
   Kuo, Yonghong
TI An elastic net-based hybrid hypothesis method for compressed video
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Distributed video coding; Elastic net; Hypothesis
   prediction; Wireless multimedia sensor networks
ID SIGNAL RECOVERY; RECONSTRUCTION; REGULARIZATION; SHRINKAGE; SELECTION
AB Compressed Sensing, an emerging framework for signal processing, can be used in image and video application, especially when available resources at the transmitter side are limited, such as Wireless Multimedia Sensor Networks. For a low-cost and low-power demand, we consider the plain compressive sampling and low sampling rates and propose a Compressed Video Sensing scheme. As a result, most burden of video processing can be shifted to the decoder which employs a hybrid hypothesis prediction method in reconstruction. The Elastic net-based multi-hypothesis mode, one part of the prediction method, combines the multi-hypothesis prediction and the elastic net regression together. And in the process of decoding, either this mode or the single-hypothesis one is implemented based on the threshold which is selected from [1e-11, 1). Both of the prediction modes are carried out in the measurement domain and a residual reconstruction as the final step is executed to accomplish the recovery. According to the performance presented by the simulation results, the proposed multi-hypothesis mode provides a better reconstruction quality than the other multi-hypothesis ones and the proposed scheme outperforms the observed state-of-the-art schemes for compressed-sensing video reconstruction at low sampling rates.
C1 [Chen, Jian; Chen, Yunzheng; Kuo, Yonghong] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
   [Qin, Dong] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Chen, J (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM jianchen@mail.xidian.edu.cn
RI Qin, Dong/E-1434-2011; KUO, Yong-Hong/M-9078-2015
OI Qin, Dong/0000-0001-5206-5912; 
FU National Science Foundation China [60972072]; 111 Project of China
   [B08038]
FX The authors would like to thank Dr. Eric W. Tramel for the helpful
   discussion on the MH-BCS-SPL method. This work was supported by the
   National Science Foundation China under grant 60972072 and the 111
   Project of China (B08038).
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2010, UCLA CAM Report
   Asif MS, 2011, DUK WORKSH
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gamper U, 2008, MAGN RESON MED, V59, P365, DOI 10.1002/mrm.21477
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Kyrillidis A, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P185, DOI 10.1109/SSP.2012.6319655
   Liu Y, 2013, IEEE T CIRC SYST VID, V23, P438, DOI 10.1109/TCSVT.2012.2207269
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Prades-Nebot J., 2009, 2009 Picture Coding Symposium, PCS 2009, P1, DOI DOI 10.1109/PCS.2009.5167431
   Sjostrand K., 2012, Spasm: A matlab toolbox for sparse statistical modeling
   Stankovic Vladimir., 2008, Proc. of the European Signal Processing Conf.(EUSIPCO), P2
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Tramel EW, 2012, THESIS MISSISSIPPI S
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tzagkarakis G, 2012, P INT C COMP VIS THE, P24
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4108, DOI 10.1109/TSP.2010.2048105
   Vaswani N, 2008, IEEE IMAGE PROC, P893, DOI 10.1109/ICIP.2008.4711899
   Wakin M. B., 2006, P PICT COD S
   Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577
   Waters A. E., 2011, NEURAL INFORM PROCES, P1089
   Wei Lu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2689, DOI 10.1109/ICIP.2011.6116222
   Wen ZW, 2010, SIAM J SCI COMPUT, V32, P1832, DOI 10.1137/090747695
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735
   Zou H, 2009, ANN STAT, V37, P1733, DOI 10.1214/08-AOS625
NR 43
TC 30
Z9 41
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2085
EP 2108
DI 10.1007/s11042-013-1743-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500018
DA 2024-07-18
ER

PT J
AU Gai, S
   Luo, LM
AF Gai, Shan
   Luo, Limin
TI Image denoising using normal inverse gaussian model in quaternion
   wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion wavelet transform; Normal inverse Gaussian density; Maximum
   posterior estimator; Image denoising
ID SEGMENTATION; TRANSFORM; SPARSE
AB This paper proposes a novel image denoising algorithm that can more effectively remove Gaussian white noise. The proposed algorithm is based on a design of a Maximum Posteriori Estimator (MAP) combined with a Quaternion Wavelet Transform (QWT) that utilizes the Normal Inverse Gaussian (NIG) Probability Density Function (PDF). The QWT is a near shift-invariant whose coefficients include one magnitude and three phase values. An NIG PDF which is specified by four real-value parameters is capable of modeling the heavy-tailed QWT coefficients, and describing the intra-scale dependency between the QWT coefficients. The NIG PDF is applied as a prior probability distribution, to model the coefficients by utilizing the Bayesian estimation technique. Additionally, a simple and fast method is given to estimate the parameters of the NIG PDF from the neighboring QWT coefficients. Experimental results show that the proposed method outperforms other existing denoising methods in terms of the PSNR, the structural similarity, and the edge preservation. It is clear that the proposed method can remove Gaussian white noise more effectively.
C1 [Gai, Shan; Luo, Limin] Southeast Univ, Sch Comp Sci & Engn, Nanjing 211102, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Gai, S (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 211102, Jiangsu, Peoples R China.
EM gaishan886@163.com; luo.list@seu.edu.cn
FU National Natural Science Foundation of China [61202319, 61272077,
   61203243, 61162002]; Natural Science Foundation of Jiangxi
   [20114BAB201034, 20122BAB211025]; China Postdoctoral Science Foundation
   [2013 M530223, 2013 M530224]; Department of Education of Jiangxi
   [GJJ13481]
FX This work is partially supported by National Natural Science Foundation
   of China (61202319, 61272077, 61203243, 61162002); Natural Science
   Foundation of Jiangxi (20114BAB201034, 20122BAB211025); China
   Postdoctoral Science Foundation under grant No.(2013 M530223, 2013
   M530224); Department of Education of Jiangxi (GJJ13481).
CR Balster EJ, 2005, IEEE T IMAGE PROCESS, V14, P2024, DOI 10.1109/TIP.2005.859385
   BarndorffNielsen OE, 1997, SCAND J STAT, V24, P1, DOI 10.1111/1467-9469.00045
   Bayro-Corrochano E, 2006, J MATH IMAGING VIS, V24, P19, DOI 10.1007/s10851-005-3605-3
   Bayro-Corrochano E, 2005, NUMER ALGORITHMS, V39, P35, DOI 10.1007/s11075-004-3619-8
   Bharath AA, 2005, IEEE T IMAGE PROCESS, V14, P948, DOI 10.1109/TIP.2005.849295
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Bulow T., 1997, Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings, P148, DOI 10.1007/BFb0017865
   Chan WL, 2008, IEEE T IMAGE PROCESS, V17, P1069, DOI 10.1109/TIP.2008.924282
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chappelier V, 2006, IEEE T IMAGE PROCESS, V15, P2892, DOI 10.1109/TIP.2006.877526
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   Chen SF, 2013, PATTERN RECOGN, V46, P976, DOI 10.1016/j.patcog.2012.08.014
   Cour T, 2005, PROC CVPR IEEE, P1124
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Derrode S, 2007, PATTERN RECOGN, V40, P1135, DOI 10.1016/j.patcog.2006.04.032
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Feng CC, 1996, SIGNAL PROCESS, V54, P23, DOI 10.1016/0165-1684(96)00091-6
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Gupta S, 2005, IEE P-VIS IMAGE SIGN, V152, P129, DOI 10.1049/ip-vis:20050975
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hui W, 2006, IEEE IMAGE PROC, P745, DOI 10.1109/ICIP.2006.312504
   Hyvärinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Lefkimmiatis S, 2009, IEEE T IMAGE PROCESS, V18, P1724, DOI 10.1109/TIP.2009.2022008
   Li YF, 2013, PATTERN RECOGN, V46, P681, DOI 10.1016/j.patcog.2012.09.021
   Lian QF, 2011, APPL ANAL, V90, P1299, DOI 10.1080/00036811.2010.490524
   Luisier F, 2008, IEEE T IMAGE PROCESS, V17, P482, DOI 10.1109/TIP.2008.919370
   Miller M, 2008, IEEE T IMAGE PROCESS, V17, P1500, DOI 10.1109/TIP.2008.926146
   Mor E, 2005, IMAGE VISION COMPUT, V23, P1150, DOI 10.1016/j.imavis.2005.07.011
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   Naouai M, 2011, LECT NOTES COMPUT SC, V6669, P452
   Nasir R, 2012, PATTERN RECOGN, V45, P2938
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Rajpoot N, 2012, PATTERN RECOGN, V45, P2938, DOI 10.1016/j.patcog.2012.01.023
   Rakvongthai Y, 2010, IEEE T SIGNAL PROCES, V58, P3545, DOI 10.1109/TSP.2010.2046698
   Raphan M, 2008, IEEE T IMAGE PROCESS, V17, P1342, DOI 10.1109/TIP.2008.925392
   Richard C, 2007, IEEE TRANSAUDIO SPEE, V15, P918
   Ruikar SD, 2011, INT J ADV COMPUT SC, V2, P49
   Sangwine SJ, 1998, ELECTRON LETT, V34, P969, DOI 10.1049/el:19980697
   Sathyabama B, 2011, PATTERN ANAL APPL, V18, P1
   Soulard R, 2011, PATTERN RECOGN LETT, V32, P1669, DOI 10.1016/j.patrec.2011.06.028
   Sumetphong C, 2012, PATTERN RECOGN LETT, V33, P2270, DOI 10.1016/j.patrec.2012.08.021
   Yang SY, 2010, PATTERN RECOGN LETT, V31, P1894, DOI 10.1016/j.patrec.2009.12.016
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang YT, 2012, PATTERN RECOGN, V45, P2743, DOI 10.1016/j.patcog.2012.01.015
NR 47
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1107
EP 1124
DI 10.1007/s11042-013-1812-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400021
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Noh, Z
   Sunar, MS
AF Kolivand, Hoshang
   Noh, Zakiah
   Sunar, Mohd Shahrizal
TI A quadratic spline approximation using detail multi-layer for soft
   shadow generation in augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Shadow generation; Soft shadows; Reflective sphere;
   Environment map
ID VIRTUAL OBJECTS; TIME
AB Implementation of shadows is crucial to enhancement of images in AR environments. Without shadows, virtual objects would look floating over the scene resulting in unrealistic rendering of AR environments. Casting hard shadows would provide only spatial information while soft shadows help improve realism of AR environments. Several algorithms have been proposed to render realistic shadows which often incurred high computational costs. Little attention has been directed towards the balanced trade-off between shadow quality and computational costs. In this study, two approaches are proposed: Quadratic Spline Interpolation (QSI) to soften the outline of the shadow and Detail Multi-Layer (DML) technique to optimize the volume of computations for the generation of soft shadows based on real light sources. QSI estimates boarder hard shadow samples while DML involves three main phases: real light sources estimation, soft shadow production and reduction of the complexity of 3-Dimensional objects' shadows. To be more precise, a reflective hemisphere is used to capture real light and to create an environment map. The Median Cut algorithm is implemented to locate the direction of real light sources on the environment map. Subsequently, the original hard shadows are retrieved and a sample of multilayer hard shadows is produced where each layer has its unique size and colour. These layers overlap to produce soft shadows based on the real light sources' directions. Finally, the Level of Details (LOD) algorithm is implemented to increase the efficiency of soft shadows by decreasing the complexity of vertex transformations. The proposed technique is tested using three samples of multilayer hard shadows with varying numbers of light sources generated from the Median Cut algorithm. The experimental results show that the proposed technique successfully produces realistic soft shadows at low computational costs.
C1 [Kolivand, Hoshang; Noh, Zakiah; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Fac Comp Sci & Informat Syst, Dept Comp Graph & Multimedia, UTM ViCubelab, Skudai Johor 81310, Malaysia.
C3 Universiti Teknologi Malaysia
RP Kolivand, H (corresponding author), Univ Teknol Malaysia, Fac Comp Sci & Informat Syst, Dept Comp Graph & Multimedia, UTM ViCubelab, Skudai Johor 81310, Malaysia.
EM shahinkey@yahoo.com
RI Sunar, Mohd Shahrizal/AFQ-7366-2022; Kolivand, Hoshang/F-4736-2011;
   Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Kolivand,
   Hoshang/0000-0001-5460-5679
FU FRGS grant at the UTM VicubeLab, Department of Computer Graphics and
   Multimedia, Faculty of Computing, Universiti Teknologi Malaysia
   [J13000.7282.4F085]
FX This research was supported by Vot. J13000.7282.4F085 FRGS grant at the
   UTM VicubeLab, Department of Computer Graphics and Multimedia, Faculty
   of Computing, Universiti Teknologi Malaysia.
CR Agusanto K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208, DOI 10.1109/ISMAR.2003.1240704
   Aittala M, 2010, VISUAL COMPUT, V26, P669, DOI 10.1007/s00371-010-0501-7
   Annen T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360633
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   de Castro T. K., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P36, DOI 10.1109/SVR.2012.9
   Debevec P, 2005, INT C COMP GRAPH INT
   Dimitrov R., 2007, Cascaded shadow maps
   Gibson S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P219
   Gibson S, 2000, SPRING COMP SCI, P365
   Haller M., 2004, ACM International Conference on Virtual Reality Continuum and its Applications in Industry, P189, DOI [10.1145/1044588.1044627, DOI 10.1145/1044588.1044627]
   Haller M., 2003, Proceedings of the ACM symposium on Virtual reality software and technology, P56, DOI DOI 10.1145/1008653.1008665
   Hartmann W, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P44, DOI 10.1109/ART.2003.1320426
   Hasenfratz JM, 2003, COMPUT GRAPH FORUM, V22, P753, DOI 10.1111/j.1467-8659.2003.00722.x
   Hensley J, 2005, COMPUT GRAPH FORUM, V24, P547, DOI 10.1111/j.1467-8659.2005.00880.x
   Herf Michael., 1996, ACM SIGGRAPH 96 Visual Proceedings: The art and interdisciplinary programs of SIGGRAPH '96, SIGGRAPH '96, P145
   Hu B, 2005, CAST SHADOWS AUGMENT
   Hughes CE, 2004, INT IND TRAIN SIM ED, V2004
   Jacobs K, 2005, P GRAPH INT VANC CAN
   Jensen B, 2009, SIMPLIFYING REAL TIM
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Kanbara M, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P279, DOI 10.1109/ISMAR.2002.1115112
   Kolivand H, 2011, INT J COMPUTER SCI I, V8, P80
   Kolivand H, 2012, TELKOMNIKA, V10, P171
   Kolivand H, 2014, MULTIMED TOOLS APPL, V72, P2143, DOI 10.1007/s11042-013-1494-9
   Kolivand H, 2013, IETE TECH REV, V30, P38, DOI 10.4103/0256-4602.107338
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Lensing P, 2012, INT SYM MIX AUGMENT, P109, DOI 10.1109/ISMAR.2012.6402547
   Madsen C, 2003, P 6 ANN INT WORKSH P
   Madsen C, 2008, PROBE LESS AUGMENTED
   Madsen CB, 2007, GRAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL GM/R, P252
   Naemura T., 2002, T VIRTUAL REALITY SO, V7, P227
   Nakano G, 2008, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2008.4637352
   Poupyrev I, 2002, COMPUTER, V35, P44, DOI 10.1109/2.989929
   Sato I, 1999, IEEE T VIS COMPUT GR, V5, P1, DOI 10.1109/2945.764865
   Sood R, 2012, PROANDROID AUGMENTED, P159
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Yan F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P771, DOI 10.1109/CISP.2008.87
   Yeoh RC, 2009, INT SYM MIX AUGMENT, P223, DOI 10.1109/ISMAR.2009.5336453
NR 40
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1225
EP 1245
DI 10.1007/s11042-013-1630-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200008
DA 2024-07-18
ER

PT J
AU De Marsico, M
   Nappi, M
   Riccio, D
AF De Marsico, Maria
   Nappi, Michele
   Riccio, Daniel
TI ES-RU: an entropy based rule to select representative templates in face
   surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Video surveillance; Face indexing; Entropy
ID RECOGNITION
AB ES-RU is a system for video sequence indexing. Video frames are annotated according to the identities of appearing subjects. The system architecture is designed by distributing the different processing steps across dedicated modules. These modules interact with each other to accomplish the final task. Such modularity is also designed to allow a high system flexibility, because it is possible to independently substitute each component with a different one performing the same task using a different method. As an example, face detection is presently performed by Viola-Jones algorithm, but the corresponding module might be substituted by one exploiting neural networks or support vector machines (which are actually more computationally demanding). In detail, ES-RU implements both face location and analysis, and an algorithm to select the most representative templates for the selected identities. The novelty of the algorithm for template analysis and selection relies on the proposed use of the concept of entropy. This concept is the base of most techniques that exploit relative entropy to estimate the degree of uniqueness which is assured by a biometric trait, when processed by a Feature Extraction Technique (FET). In this paper, entropy is introduced as a tool to evaluate the contribution of each sample in guaranteeing a suitable diversification of the templates that make up the gallery of a relevant subject. Video-surveillance activities cause to gather a huge amount of templates to be used for tracking and re-identifying subjects. However, most of these templates are not informative enough to be useful. The aim of our approach is to provide an effective technique to keep only the most "representative" of them, i.e. those that provide a sufficient level of diversification. This allows faster processing (less comparisons) and better results (it is possible to recognize a subject under different conditions). ES-RU was tested on six video clips and on a subset of the SCFace database to assess its performances.
C1 [De Marsico, Maria] Univ Roma La Sapienza, I-00198 Rome, Italy.
   [Nappi, Michele; Riccio, Daniel] Univ Salerno, I-84084 Fisciano, Italy.
C3 Sapienza University Rome; University of Salerno
RP Riccio, D (corresponding author), Univ Salerno, Via Ponte Don Melillo, I-84084 Fisciano, Italy.
EM demarsico@di.uniroma1.it; mnappi@unisa.it; driccio@unisa.it
RI Riccio, Daniel/JGM-4522-2023; Nappi, Michele/X-3089-2019; De Marsico,
   Maria/K-6684-2015
OI De Marsico, Maria/0000-0002-1391-8502; Riccio,
   Daniel/0000-0002-5844-0602; Nappi, Michele/0000-0002-2517-2867
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Becker B, 2009, IEEE INT C AUT FAC G
   Bhatnagar J., 2007, Proc. of the IEEE Conference on Computer Vision and Pattern Recognition CVPR, P1
   Bhatnagar J, 2009, PATTERN RECOGN, V42, P1803, DOI 10.1016/j.patcog.2008.10.004
   Bhatnagar JR, 2010, IETE TECH REV, V27, P273, DOI 10.4103/0256-4602.64599
   Choi JY, 2010, IEEE T CONSUM ELECTR, V56, P147, DOI 10.1109/TCE.2010.5439138
   Cover T. M., 1991, ELEMENTS INFORM THEO
   De Marsico M, 2011, P INT ACM WORKSH MUL
   De Marsico M, 2010, IEEE IMAGE PROC, P1597, DOI 10.1109/ICIP.2010.5650758
   Doretto G, 2011, J AMBIENT INTELL HUM, P1
   Fischer M, 2011, MULTIMED TOOLS APPL, V55, P83, DOI 10.1007/s11042-010-0603-2
   Gallager R. G., 1968, INFORM THEORY RELIAB
   Golic JD, 2008, IEEE T INFORM THEORY, V54, P2026, DOI 10.1109/TIT.2008.920211
   Gomez-Laberge C, 2006, CAN CON EL COMP EN, P1029
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jassim AJ, 2010, P WORKSH PATT REC IT
   MAGGIO E, 2007, P IEEE INT C AC SPEE
   Martinel N, 2012, ELECTRON LETT, V48, P765, DOI 10.1049/el.2012.1607
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Schmid NA, 2004, IEEE T SIGNAL PROCES, V52, P3036, DOI 10.1109/TSP.2004.833863
   Torres L, 2002, PATTERN RECOGN, V35, P615, DOI 10.1016/S0031-3203(01)00064-4
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 23
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 109
EP 128
DI 10.1007/s11042-012-1279-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700006
DA 2024-07-18
ER

PT J
AU Horng, SJ
   Rosiyadi, D
   Fan, PZ
   Wang, X
   Khan, MK
AF Horng, Shi-Jinn
   Rosiyadi, Didi
   Fan, Pingzhi
   Wang, Xian
   Khan, Muhammad Khurram
TI An adaptive watermarking scheme for e-government document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive; Watermarking; Luminance masking; Human visual system;
   E-government
ID COPYRIGHT PROTECTION
AB This paper proposes an adaptive watermarking scheme for e-government document images. The adaptive scheme combines the discrete cosine transform (DCT) and the singular value decomposition (SVD) using luminance masking. As a core of masking model in the human visual system (HVS), luminance masking is implemented to improve noise sensitivity. Genetic algorithm (GA), subsequently, is employed for the optimization of the scaling factor of the masking. Involving a number of steps, the scheme proposed through this study begins by calculating the mask of the host image using luminance masking. It is then continued by transforming the mask on each area into all frequencies domain. The watermark image, following this, is embedded by modifying the singular values of DCT-transformed host image with singular values of mask coefficient of host image and the control parameter of DCT-transformed watermark image using Genetic Algorithm (GA). The use of both the singular values and the control parameter respectively, in this case, is not only to improve the sensitivity of the watermark performance but also to avoid the false positive problem. The watermark image, afterwards, is extracted from the distorted images. The experiment results show the improved adaptive performance of the proposed scheme is in resistant to several types of attacks in comparison with the previous schemes; the adaptive performance refers to the adaptive parameter of the luminance masking functioned to improve the performance or robustness of an image from any attacks.
C1 [Fan, Pingzhi; Wang, Xian] Southwest Jiaotong Univ, Inst Mobile Commun, Chengdu 610031, Peoples R China.
   [Horng, Shi-Jinn; Rosiyadi, Didi] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
   [Rosiyadi, Didi] Indonesian Inst Sci LIPI, Res Ctr Informat, Jakarta, Indonesia.
C3 Southwest Jiaotong University; National Taiwan University of Science &
   Technology; King Saud University; National Research & Innovation Agency
   of Indonesia (BRIN); Indonesian Institute of Sciences (LIPI)
RP Horng, SJ (corresponding author), 43,Sec 4,Kee Lung Rd, Taipei 106, Taiwan.
EM horngsj@yahoo.com.tw; rosiyadi@informatika.lipi.go.id;
   pingzhifan@gmail.com; drwangxian@gmail.com; mkhurram@ksu.edu.sa
RI Nusa, Nuhammad/JXY-5819-2024; KHAN, MUHAMMAD KHURRAM/E-4836-2014;
   rosiyadi, didi/AAG-9137-2021; Khan, Muhammad/IXN-8470-2023; Horng,
   Shi-Jinn/GVU-0488-2022
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; 
FU National Science Council [NSC-99-2916-I-011-002-A1]; 111 Project
   [111-2-14]; One Hundred Person Project, Sichuan Province
FX This work was supported in part by the National Science Council under
   contract number NSC-99-2916-I-011-002-A1, and it was also partially
   supported by the 111 Project under the grant No. 111-2-14 and One
   Hundred Person Project 2012, Sichuan Province.
CR Aslantas V., 2007, IEEE INT S INT SIGN, P1
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Belkacem S, 2007, IEEE I C ELECT CIRC, P330, DOI 10.1109/ICECS.2007.4510997
   Benhocine A., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P9
   Carballeira P., 2012, P 3DTV C TRUE VIS CA, P1
   Coello Coello CA, 2001, P GEN EV COMP C
   Cui LH, 2011, IEEE T IMAGE PROCESS, V20, P1047, DOI 10.1109/TIP.2010.2079551
   Deljavan Amiri M., 2010, P IEEE INF THEOR WOR, P1
   Hamed M, 2010, P INT C INN INF TECH, P6
   He Xu, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P408, DOI 10.1109/ICICTA.2011.386
   Himanshu H., 2011, 3 INT C EM TRENDS EN, P146
   Hoi-Yu Tong H, 1997, THESIS U TORONTO
   Huang C-H, 2000, P SPIE, V3971
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Kang XG, 2008, IEEE T MULTIMEDIA, V10, P953, DOI 10.1109/TMM.2008.2001361
   Kumar Sharma D, 2007, DIGITAL WATERMARKING, P182
   Kuo SS, 2002, IEEE T IMAGE PROCESS, V11, P509, DOI 10.1109/TIP.2002.1006398
   Lai CC, 2009, INT J INNOV COMPUT I, V5, P1867
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Lim SB, 2010, HUMAN VISUAL SYSTEM
   Ma XH, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1063, DOI 10.1109/ICALIP.2008.4590092
   Mairgiotis AK, 2008, IEEE T INF FOREN SEC, V3, P29, DOI 10.1109/TIFS.2007.916290
   Naiss I, 2013, IEEE T INFORM THEORY, V59, P760, DOI 10.1109/TIT.2012.2222345
   Pappas TN, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P939, DOI 10.1016/B978-012119792-6/50118-2
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Si H.Y., Maintaining information security in E-government through steganology
   Sing K, 2011, EDGE DETECTOR
   Verma A, 2009, EUROCON 2009: INTERNATIONAL IEEE CONFERENCE DEVOTED TO THE 150 ANNIVERSARY OF ALEXANDER S. POPOV, VOLS 1- 4, PROCEEDINGS, P1374, DOI 10.1109/EURCON.2009.5167819
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang JJ, 2008, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL II, P359, DOI 10.1109/ICIII.2008.15
   White GB, 2007, HICSS 2007 40 ANN HA, P97
   Xiaoyuan Zhang, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P580
   Xue SJ, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P731, DOI 10.1109/FSKD.2007.133
   Yixin Yan, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P377, DOI 10.1109/IST.2009.5071669
   Zhao F, 2009, 2 INT C IM SIGN PROC, P1
   Zhu SM, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P668, DOI 10.1109/KAM.2008.78
NR 38
TC 60
Z9 61
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3085
EP 3103
DI 10.1007/s11042-013-1579-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300043
DA 2024-07-18
ER

PT J
AU Guo, ZB
   Li, ZT
   Tu, H
   Liu, SY
AF Guo, Zhengbiao
   Li, Zhitang
   Tu, Hao
   Liu, Shuyu
TI A novel P2P IPTV system for IPv4/v6 networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPv4/v6 network; Peer-to-peer; IPTV; Live video streaming
ID PEER
AB As IPv4 address pool has been completely depleted and the transition from IPv4 to IPv6 has become a trend, P2P video streaming through IPv4/v6 hybrid network is now needed, for equipments with different types of IP addresses widely exist on the Internet. Traditionally, large-scale commercial P2P-IPTV systems have been deployed in IPv4 networks. However, these systems do not support equipments with IPv6 addresses and cannot work in IPv4/v6 hybrid networks. To overcome this problem, we propose a novel dual-stack-based architecture to distribute contents to different networks. The core element of the system is the dual-stack tracker which makes all equipments with IP address interconnect with each other and form a hybrid network. Meanwhile, equipments with IPv4/v6 addresses act as bridges, which distribute contents to IPv4 and IPv6 networks. The paper focuses on how to make all equipments with different types of IP addresses work in one system, analyzing the architecture and performance results related to the use of IPv6 bandwidth. This system has been deployed and broadcasted the 2010 FIFA World Cup South Africa with 755 kbps video stream, and our results demonstrate the feasibility of video over IPv4/v6 hybrid network for a representative application.
C1 [Guo, Zhengbiao; Li, Zhitang; Tu, Hao; Liu, Shuyu] Huazhong Univ Sci & Technol, Network Ctr, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, ZT (corresponding author), Huazhong Univ Sci & Technol, Network Ctr, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM zhengbiaoguo@gmail.com; leeying@hust.edu.cn; tuhao@hust.edu.cn;
   shuyu@hust.edu.cn
FU CNSTSP [2008BAH37B08]; NSF of China [61272407]; NSF of Hubei Province
   [2010CDB02306]; CNGI [CNGI-122]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments, which helped them to improve the manuscript
   significantly. They also thank the editor Ms. Angie Malanday for her
   efforts in revising the paper, and Da Xie for her helpful work. This
   work was supported by the CNSTSP [2008BAH37B08], NSF of China
   [61272407], NSF of Hubei Province [2010CDB02306] and CNGI[CNGI-122].
CR Arnaud J, 2011, MULTIMED TOOLS APPL, V55, P333, DOI 10.1007/s11042-010-0576-1
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   DEERING SE, 1990, ACM T COMPUT SYST, V8, P85, DOI 10.1145/78952.78953
   Ganesh AJ, 2003, IEEE T COMPUT, V52, P139, DOI 10.1109/TC.2003.1176982
   Hei X, 2006, INT WORLD WID WEB C
   Hei X, 2007, IEEE J SEL AREAS COM
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Huang Y., 2008, ACM SIGCOMM COMPUTER
   Jung S, 2008, MULTIMED TOOLS APPL, V37, P263, DOI 10.1007/s11042-007-0159-y
   Kontothanassis L, 2004, P IEEE, V92, P1408, DOI 10.1109/JPROC.2004.832956
   Li B, 2007, IEEE J SEL AREAS COM, V25
   Lin CT., 2012, MULTIMED TOOLS APPL, P1
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Palau CE, 2011, MULTIMED TOOLS APPL, V53, P591, DOI 10.1007/s11042-010-0516-0
   Vu L., 2006, UIUCDCSR2006275
   Vu L, 2007, MEASUREMENT LARGE SC
   Vu L, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1865106.1865115
   Wang WD, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P390, DOI 10.1109/ICBNMT.2011.6155963
   Xie H, 2008, P SIGCOMM AUG
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
NR 20
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 967
EP 986
DI 10.1007/s11042-013-1477-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800044
DA 2024-07-18
ER

PT J
AU Sheng, B
   Meng, WL
   Sun, HQ
   Wu, W
   Wu, EH
AF Sheng, Bin
   Meng, Weiliang
   Sun, Hanqiu
   Wu, Wen
   Wu, Enhua
TI Perception-motivated multiresolution rendering on sole-cube maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiresolution rendering; Sole-cube maps; GPU processing; Mesh
   refinement
ID PARAMETRIZATION
AB This paper presents a novel GPU-based multiresolution rendering on sole-cube maps (SCMs), which is a variant of geometry images built upon spherical parameterization. Given spherical parametrization of a manifold mesh, the sphere domain is gnomonically projected to a closed cube, which constitutes the 6-chart sole-cube maps. A quadtree structure of SCMs and normal map atlas are then constructed by using the regular re-sampling. Then, by packing the quadtree nodes into the SCMs texture atlas, a new parallel multiresolution rendering is processed on the latest GPU in two rendering passes: the multiresolution node selection in fragment shader; the triangulation in vertex shader followed by the node culling operation in geometry shader. The proposed approach generates adaptive mesh surfaces dynamically, and can be fully implemented in GPU parallelization. The proposed scheme alleviates the computing load of multiresolution mesh refinement on CPU, and our GPU-based multiresolution rendering is demonstrated with a variety of examples. Our user study confirmed that the visual quality of the SCMs multiresolution rendering, in comparison with the meshes/geometry images rendering, is also highly efficient especially for complex models in large-scale virtual environment.
C1 [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Eng, Shanghai 200030, Peoples R China.
   [Sheng, Bin] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Meng, Weiliang] Chinese Acad Sci, Inst Automat, LIAMA, NLPR, Beijing, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Wen; Wu, Enhua] Univ Macau, Macau, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of
   Software, CAS; Chinese Academy of Sciences; Institute of Automation,
   CAS; Chinese University of Hong Kong; University of Macau; Chinese
   Academy of Sciences; Institute of Software, CAS
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Eng, Shanghai 200030, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
FU National Basic Research Project of China [2011CB302203]; National
   Natural Science Foundation of China [61202154, 61133009, 61202324,
   61271431]; RGC [416311]; UGC [2050485, 2050454]; Open Projects Program
   of National Laboratory of Pattern Recognition; Open Project Program of
   the State Key Lab of CAD&CG, Zhejiang University [A1206]
FX We would like to thank the anonymous reviewers for their valuable
   comments. This work is supported by the National Basic Research Project
   of China (No. 2011CB302203), and the National Natural Science Foundation
   of China (No. 61202154,61133009,61202324,61271431), RGC research grant
   (ref. 416311), UGC direct grant for research (no. 2050485, 2050454).
   This work is also partially supported by the Open Projects Program of
   National Laboratory of Pattern Recognition, and the Open Project Program
   of the State Key Lab of CAD&CG (Grant No. A1206), Zhejiang University.
CR Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   [Anonymous], 2007, P ACM SIGGRAPH S INT
   [Anonymous], 2004, THESIS SAARLAND U
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Bolz J., 2003, EVALUATION SUBDIVISI
   Boubekeur T, 2008, COMPUT GRAPH FORUM, V27, P102, DOI 10.1111/j.1467-8659.2007.01040.x
   Boubekeur T., 2005, HWWS 05, P99, DOI DOI 10.1145/1071866.1071882
   Carr N., 2006, P EUROGRAPHICSSIGGRA, P181
   Carr NA, 2002, ACM T GRAPHIC, V21, P106, DOI 10.1145/508357.508360
   Dachsbacher C, 2003, ACM T GRAPHIC, V22, P657, DOI 10.1145/882262.882321
   Engelhardt T, 2008, P VIS MOD VIS 2008
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Gu X., 2003, P 2003 EUROGRAPHICSA, P127
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Heidrich W, 1998, P ACM SIGGRAPH EUROG
   Hernandez B., 2006, PROC GRAPHITE 2006, P157, DOI DOI 10.1145/1174429.1174454)
   Hu L., 2009, P 2009 S INTERACTIVE, P169
   Hu LA, 2010, IEEE T VIS COMPUT GR, V16, P718, DOI 10.1109/TVCG.2009.101
   Ji JF, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P108
   Kalaiah A, 2003, IEEE T VIS COMPUT GR, V9, P30, DOI 10.1109/TVCG.2003.1175095
   KARLSSON F, 2004, THESIS CHALMERS U TE
   Kobbelt LP, 1999, COMPUT GRAPH FORUM, V18, pC119, DOI 10.1111/1467-8659.00333
   Lin JC, 2008, LECT NOTES COMPUT SC, V4975, P3
   Losasso F., 2003, Symposium on Geometry Processing, P138
   Luebke D., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P199, DOI 10.1145/258734.258847
   Luebke D., 1997, VIEW DEPENDENT SIMPL
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Purnomo B., 2004, PROC S GEOM, P67
   Sander P. V., 2003, Symposium on Geometry Processing, P146
   Schroder P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P161, DOI 10.1145/218380.218439
   Segal M., 2004, OPENGL GRAPHICS SYST
   Shiue LJ, 2005, ACM T GRAPHIC, V24, P1010, DOI 10.1145/1073204.1073304
   Smolic A, 2004, IEEE T CIRC SYST VID, V14, P348, DOI 10.1109/TCSVT.2004.823395
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743, DOI DOI 10.1112/PLMS/S3-13.1.743
   Von Herzen B., 1987, SIGGRAPH 87, P103
   Wan L, 2007, IEEE T VIS COMPUT GR, V13, P720, DOI 10.1109/TVCG.2007.1020
   Wang HY, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P397
   Wang Hongyu., 2007, ACM SOLID PHYS MODEL, P241
   Xia J., 2011, S INTERACTIVE 3D GRA, P151
NR 44
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 231
EP 252
DI 10.1007/s11042-012-1335-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800012
DA 2024-07-18
ER

PT J
AU Hong, J
   Kang, JS
   Price, ME
AF Hong, Jie
   Kang, Jinsheng
   Price, Michael E.
TI Extraction of bodily features for gait recognition and gait
   attractiveness evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait analysis; Gait features; Gait signatures; Gait attractiveness;
   Principal component analysis; Walking
ID WALKING; PATTERNS; CHILDREN; MOTION; SEX
AB Although there has been much previous research on which bodily features are most important in gait analysis, the questions of which features should be extracted from gait, and why these features in particular should be extracted, have not been convincingly answered. The primary goal of the study reported here was to take an analytical approach to answering these questions, in the context of identifying the features that are most important for gait recognition and gait attractiveness evaluation. Using precise 3D gait motion data obtained from motion capture, we analyzed the relative motions from different body segments to a root marker (located on the lower back) of 30 males by the fixed root method, and compared them with the original motions without fixing root. Some particular features were obtained by principal component analysis (PCA). The left lower arm, lower legs and hips were identified as important features for gait recognition. For gait attractiveness evaluation, the lower legs were recognized as important features.
C1 [Hong, Jie; Kang, Jinsheng] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
   [Price, Michael E.] Brunel Univ, Dept Psychol, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University; Brunel University
RP Kang, JS (corresponding author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
EM jinsheng.kang@brunel.ac.uk
OI Price, Michael/0000-0002-2572-4326
FU Dorothy Hodgkin Postgraduate Award; HEFCE SRIF2 project [BRUN 07/033]
FX We thank the Dorothy Hodgkin Postgraduate Award to Jie Hong and HEFCE
   SRIF2 project BRUN 07/033 funding for motion capture system.
CR Arantes M, 2011, MULTIMED TOOLS APPL, V55, P655, DOI 10.1007/s11042-010-0587-y
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Barton JG, 1997, GAIT POSTURE, V5, P28, DOI 10.1016/S0966-6362(96)01070-3
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   Bruijn SM, 2010, J EXP BIOL, V213, P3945, DOI 10.1242/jeb.045112
   Carriero A, 2009, GAIT POSTURE, V29, P71, DOI 10.1016/j.gaitpost.2008.06.011
   Cho CW, 2009, EXPERT SYST APPL, V36, P7033, DOI 10.1016/j.eswa.2008.08.076
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   CUTTING JE, 1978, J EXP PSYCHOL HUMAN, V4, P357, DOI 10.1037/0096-1523.4.3.357
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Das S. R., 2006, Journal of Multimedia, V1
   Davies A.P. C., 2008, Foundations of evolutionary psychology: Ideas, issues and applications, V3rd, P261
   Foster JP, 2003, PATTERN RECOGN LETT, V24, P2489, DOI 10.1016/S0167-8655(03)00094-1
   Huang PS, 1999, IEE P-VIS IMAGE SIGN, V146, P93, DOI 10.1049/ip-vis:19990187
   Ibrahim RK, 2008, IEEE ENG MED BIO, P3852, DOI 10.1109/IEMBS.2008.4650050
   Jahoda Marie., 1933, ARBEITSLOSEN MARIENT
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Johnson KL, 2005, PSYCHOL SCI, V16, P890, DOI 10.1111/j.1467-9280.2005.01633.x
   Khandoker AH, 2007, IEEE T NEUR SYS REH, V15, P587, DOI 10.1109/TNSRE.2007.906961
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Li X., 2007, IEEE INT C SYST MAN, P3881
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Menant JC, 2009, GAIT POSTURE, V30, P65, DOI 10.1016/j.gaitpost.2009.03.003
   Menant JC, 2009, GAIT POSTURE, V29, P392, DOI 10.1016/j.gaitpost.2008.10.057
   Muniz AMS, 2009, GAIT POSTURE, V29, P31, DOI 10.1016/j.gaitpost.2008.05.015
   Nixon MS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P139, DOI 10.1109/AFGR.2004.1301521
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Reid SM, 2010, GAIT POSTURE, V31, P197, DOI 10.1016/j.gaitpost.2009.10.005
   Roislien J, 2009, GAIT POSTURE, V30, P441, DOI 10.1016/j.gaitpost.2009.07.002
   Rosengren KS, 2009, GAIT POSTURE, V29, P225, DOI 10.1016/j.gaitpost.2008.08.005
   Schmitt A, 1995, ETHOL SOCIOBIOL, V16, P451, DOI 10.1016/0162-3095(95)00070-4
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Vrieling AH, 2008, GAIT POSTURE, V28, P235, DOI 10.1016/j.gaitpost.2007.12.006
   Wang Kai., 2009, 2009 P 18 INT C COMP, P1
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Yoo JH, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P35, DOI 10.1109/IAI.2002.999885
NR 38
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1999
EP 2013
DI 10.1007/s11042-012-1319-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000046
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Li, Z
   Yap, KH
AF Li, Zhen
   Yap, Kim-Hui
TI Beyond Bag-of-Words: combining generative and discriminative models for
   scene categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene categorization; Bag-of-Words; Generative model; Discriminative
   model; Scalability
ID CLASSIFICATION; FEATURES
AB This paper proposes an efficient framework for scene categorization by combining generative model and discriminative model. A state-of-the-art approach for scene categorization is the Bag-of-Words (BoW) framework. However, there exist many categories in scenes. Generally when a new category is considered, the codebook in BoW framework needs to be re-generated, which will involve exhaustive computation. In view of this, this paper tries to address the issue by designing a new framework with good scalability. When an additional category is considered, much lower computational cost is needed while the resulting image signatures are still discriminative. The image signatures for training discriminative model are carefully designed based on the generative model. The soft relevance value of the extracted image signatures are estimated by image signature space modeling and are incorporated in Fuzzy Support Vector Machine (FSVM). The effectiveness of the proposed method is validated on UIUC Scene-15 dataset and NTU-25 dataset, and it is shown to outperform other state-of-the-art approaches for scene categorization.
C1 [Li, Zhen; Yap, Kim-Hui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Li, Z (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM lizh0019@ntu.edu.sg; EKHYap@ntu.edu.sg
OI Yap, Kim-Hui/0000-0003-1933-4986
FU Agency for Science, Technology and Research (A*STAR), Singapore under
   SERC [062 130 0055]
FX This work is supported by Agency for Science, Technology and Research
   (A*STAR), Singapore under SERC Grant 062 130 0055. Thank Dr. J. C. van
   Gemert for kindly providing the source code of UNC in [15]. Thank the
   anonymous reviewers for providing the valuable suggestions that
   significantly improve the quality of the paper.
CR [Anonymous], 2004, WORKSH STAT LEARN CO
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Deselaers T, 2010, PATTERN RECOGN, V43, P2476, DOI 10.1016/j.patcog.2010.02.002
   Dorko G., 2005, RR5497 INRIA
   JIANG YG, 2007, ACM INT C IM VID RET
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Li Z, 2011, INT CONF ACOUST SPEE, P965
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Yu ZW, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1913, DOI 10.1109/ICME.2006.262930
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 17
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1033
EP 1050
DI 10.1007/s11042-012-1245-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000004
DA 2024-07-18
ER

PT J
AU Paul, A
   Rho, S
   Bharnitharan, K
AF Paul, Anand
   Rho, Seungmin
   Bharnitharan, K.
TI Interactive scheduling for mobile multimedia service in M2M environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel processing; Video processing; Dynamic scheduling; Ubiquitous
   environment; M2M
ID MOTION ESTIMATION
AB Computational load of motion estimation in advanced video coding (AVC) standard is significantly high and its more true for HDTV sequences. In this paper, video processing algorithm is mapped onto a learning method to improve machine to machine (M2M) architecture, namely, the parallel reconfigurable computing (PRC) architecture, which consists of multiple units, First, we construct a directed acyclic graph (DAG) to represent the video coding algorithms comprising motion estimation. In the future trillions of devices are connected (M2M) together to provide services and that time power management would be a challenge. Computation aware scheme for different machine is reduced by dynamically scheduling usage of multi-core processing environment for video sequence depending up complexity of the video. And different video coding algorithm is selected depending upon the nature of the video. Simulation results show the effectiveness of the proposed method.
C1 [Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Taegu, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
   [Bharnitharan, K.] Feng Chia Univ, Dept Elect Engn, Taichung 40724, Taiwan.
C3 Kyungpook National University; Sungkyul University; Feng Chia University
RP Rho, S (corresponding author), Sungkyul Univ, Dept Multimedia, Anyang Si, South Korea.
EM paul.editor@gmail.com; smrho@sungkyul.edu
RI Rho, Seungmin/HTP-6683-2023; Paul, Anand/V-6724-2017
OI Paul, Anand/0000-0002-0737-2021; Paul, Anand/0000-0003-3115-2325
FU Kyungpook National University Research Fund; URP-CEST [Undergraduate
   Research Program - Center for Embedded Software Technology], Kyungpook
   National University, Korea
FX This research is support by Kyungpook National University Research Fund
   2012. This work was partially supported by URP-CEST 2013 [Undergraduate
   Research Program - Center for Embedded Software Technology], Kyungpook
   National University, Korea.
CR [Anonymous], PROBABILITY STAT ENG
   Benini L, 1999, IEEE T COMPUT AID D, V18, P813, DOI 10.1109/43.766730
   Chen L. -F., 2004, IEEE CIRC SYST C ISC, P937
   Chen YK, 2012, ASIA S PACIF DES AUT, P383, DOI 10.1109/ASPDAC.2012.6164978
   Chung EY, 1999, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION 1999, PROCEEDINGS, P77, DOI 10.1109/DATE.1999.761100
   Draft ITU- T Recommendation and Final Draft International Standard of Joint Video Specification, 2003, ITU T REC F IN PRESS
   Kortuem Gerd, 2010, IEEE Internet Computing, V14, P44, DOI 10.1109/MIC.2009.143
   Lu Y-H, 2001, COMP SYSTEM LEVEL PO
   LU YH, 2000, DESIGN AUTOMATION TE, P20
   Maestre R, 2001, J SYST ARCHITECT, V47, P277, DOI 10.1016/S1383-7621(00)00050-3
   Paul A, 2011, IET IMAGE PROCESS, V5, P323, DOI 10.1049/iet-ipr.2009.0256
   Paul A, 2013, ACM T EMBED COMPUT S, V12
   Paul A, 2013, IETE TECH REV
   Paul A, 2013, IETE TECH REV, V30, P24, DOI 10.4103/0256-4602.107336
   Paul A, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2331147.2331149
   Qiu Q, 1999, DES AUT C
   Schmit H, 2002, PROCEEDINGS OF THE IEEE 2002 CUSTOM INTEGRATED CIRCUITS CONFERENCE, P63, DOI 10.1109/CICC.2002.1012767
   Singh H, 2000, DES AUT CON, P573, DOI 10.1145/337292.337583
   Stallings William., 2003, Computer organization and architecture: designing for performance
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Tai PL, 2003, IEEE T CIRC SYST VID, V13, P901, DOI 10.1109/TCSVT.2003.816510
   Vissers KA, 2003, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, PROCEEDINGS, P396
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 23
TC 17
Z9 17
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 235
EP 246
DI 10.1007/s11042-013-1490-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700013
DA 2024-07-18
ER

PT J
AU Gaber, SMA
   Sumari, P
AF Gaber, Suliman Mohamed Ahmed
   Sumari, Putra
TI Predictive and content-aware load balancing algorithm for peer-service
   area based IPTV networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; VoD; Peer-service area architecture; Content Distribution Network;
   Load balancing algorithm; Request distribution; Content replication
   scheme
ID REPLICATION; CLUSTER
AB Load balancing is a crucial factor in IPTV delivery networks. Load balancing aims at utilizing the resources efficiently, maximizing the throughput, and minimizing the request rejection rate. The peer-service area is the recent architecture for IPTV delivery networks that overcomes the flaws of the previous architectures. However, it still suffers from the load imbalance problem. This paper investigates the load imbalance problem, and tries to augment the peer-service area architecture to overcome this problem. To achieve the load balancing over the proposed architecture, we suggest a new load-balancing algorithm that considers both the expected and the current load of both contents and servers. The proposed load-balancing algorithm consists of two stages. The first stage is the contents replication according to their expected load, while the second stage is the content-aware request distribution. To test the effectiveness of the proposed algorithm, we have compared it with both the traditional Round Robin algorithm and Cho algorithm. The experimental results depict that the proposed algorithm outperforms the two other algorithms in terms of load balance, throughput, and request rejection rate.
C1 [Gaber, Suliman Mohamed Ahmed; Sumari, Putra] Univ Sains Malaysia, Sch Comp Sci, Multimedia Res Grp, P Penang 11800, Malaysia.
C3 Universiti Sains Malaysia
RP Gaber, SMA (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Multimedia Res Grp, P Penang 11800, Malaysia.
EM smfati@yahoo.com
RI Fati, Suliman Mohamed/W-9547-2018; Sumari, Putra/I-1070-2016
OI Sumari, Putra/0000-0002-2644-6428
CR Borzemski L, 2008, LECT NOTES ARTIF INT, V5178, P117, DOI 10.1007/978-3-540-85565-1_15
   Casalicchio E., 2002, Cluster Computing, V5, P65, DOI 10.1023/A:1012796706047
   Cherkasova L, 2000, 8TH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P492, DOI 10.1109/MASCOT.2000.876576
   Cho DH, 2008, J SYST ARCHITECT, V54, P335, DOI 10.1016/j.sysarc.2007.08.001
   Dakshayini M, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL IV, PROCEEDINGS, P162, DOI 10.1109/ICCIMA.2007.170
   DAN A, 1995, MULTIMEDIA SYST, V3, P93, DOI 10.1007/BF01542861
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Gupta R, 2011, MARKET RES REPORTS R
   Guruprasad HS, 2008, IJCSS, V5, P13
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Huang CD, 2005, REAL TIM SYST SYMP P, P50
   Huang YF, 2004, INFORM SCIENCES, V164, P113, DOI 10.1016/j.ins.2003.10.005
   Jacqui C, 2007, REPORT ONE 3 TV WATC
   Kursten L, 2011, GLOBAL IPTV MARKET R
   Li MF, 2010, COMPUT COMMUN, V33, P83, DOI 10.1016/j.comcom.2009.08.003
   Mathias W, 2007, IEEE T CIRCUITS SYST, V17, P1771
   MRG Inc, 2010, SEM IPTV GLOB FOR RE
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P47, DOI 10.1109/MCOM.2008.4689207
   Organization for Economics Development (OECD), 2007, DSTIICCPCISP20072FIN
   Pai VS, 1998, ACM SIGPLAN NOTICES, V33, P205, DOI 10.1145/291006.291048
   Passarella A, 2012, COMPUT COMMUN, V35, P1, DOI 10.1016/j.comcom.2011.10.005
   Pathan M, 2008, CDNS STATE ARTS INSI
   Qiu TQ, 2009, PERF E R SI, V37, P275
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sharifian S, 2008, FUTURE GENER COMP SY, V24, P775, DOI 10.1016/j.future.2008.03.005
   Sharifian S, 2011, APPL SOFT COMPUT, V11, P970, DOI 10.1016/j.asoc.2010.01.017
   Shicong Meng, 2010, 2010 IEEE International Conference on Web Services (ICWS), P179, DOI 10.1109/ICWS.2010.26
   Soumen K, 2012, IJAIS, V1, P2249
   Tay YC, 2000, IEEE T KNOWL DATA EN, V12, P410, DOI 10.1109/69.846293
   Van der Auwera G, 2009, IEEE T BROADCAST, V55, P541, DOI 10.1109/TBC.2009.2027399
   Vinay A, 2011, P INT C ICWET, P344
   ZHOU X, 2002, P INT C IPDPS, P127
   Zhou XB, 2007, J NETW COMPUT APPL, V30, P515, DOI 10.1016/j.jnca.2006.03.001
NR 33
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1987
EP 2010
DI 10.1007/s11042-012-1209-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500027
DA 2024-07-18
ER

PT J
AU Nightingale, J
   Wang, Q
   Grecos, C
AF Nightingale, James
   Wang, Qi
   Grecos, Christos
TI Empirical evaluation of H.264/SVC streaming in resource-constrained
   multihomed mobile networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/SVC; Scalable video streaming; Mobile networks; Multihoming;
   Mobile multimedia; Performance evaluation
ID SCALABLE VIDEO; BANDWIDTH AGGREGATION; TRANSMISSION; EXTENSION
AB Nomadic users of streamed multimedia content in mobile networks are often faced with resource-constrained network paths that suffer from low bandwidth. Streaming high-quality video in such a challenging scenario demands a set of highly adaptive schemes, which have not been sufficiently explored in particular for the emerging H.264 Scalable Video Coding (H.264/SVC) standard. In this paper, we empirically investigate the performance of streaming H.264/SVC scalable video streams to users in multihomed mobile networks containing multiple available transmission paths. Previous work has demonstrated the feasibility of aggregating bandwidth of multiple paths to deliver video streams when no single, sufficiently high bandwidth path is available. We focus on evaluating the enhanced performance of multipath bandwidth-aggregation streaming by exploiting a quality-layers based, H.264/SVC-specific packet prioritisation scheme for quality-aware multipath packet scheduling and selective packet dropping in case of bandwidth shortage even after aggregation. Additionally, we explore a base-layer rate control scheme for H.264/SVC delivery in ultra-low bandwidth environments. Through extensive experimentation on a realistic hardware-based testbed, we obtain a comprehensive and insightful understanding of the behaviour of H.264/SVC streams when transmitted across multiple paths in mobile networks. We quantify the improvements offered by the use of H.264/SVC-specific packet prioritisation schemes compared with an existing generic scalable video prioritisation scheme, and the benefits by the use of base-layer rate control in ultra-low bandwidth situations. The performance of the multipath streaming schemes is further compared with that of an ideal single high bandwidth path. We also identify the remaining challenges that must be overcome if such streaming schemes are to offer performance close to that of the ideal single high bandwidth path.
C1 [Nightingale, James; Wang, Qi; Grecos, Christos] Univ West Scotland, Audio Visual Commun & Networks Grp AVCN, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland.
C3 University of West Scotland
RP Wang, Q (corresponding author), Univ West Scotland, Audio Visual Commun & Networks Grp AVCN, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland.
EM Qi.Wang@uws.ac.uk
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   Chebrolu K, 2006, IEEE T MOBILE COMPUT, V5, P388, DOI 10.1109/TMC.2006.1599407
   Chebrolu K, 2004, P 2004 IEEE INT C CO
   Cicalò S, 2012, SIGNAL PROCESS-IMAGE, V27, P800, DOI 10.1016/j.image.2012.01.005
   Devarapalli V., 2005, 3963 RFC
   Fernandez JC, 2009, IEEE T MULTIMEDIA, V11, P1082, DOI 10.1109/TMM.2009.2026086
   Jurca D, 2007, IEEE T MULTIMEDIA, V9, P629, DOI 10.1109/TMM.2006.888017
   Leontaris A, 2007, ISOIECJTC1SC29WG11
   Li KG, 2003, ISOIECJTC1SC29WG11
   Maani E, 2010, IEEE T CIRC SYST VID, V20, P407, DOI 10.1109/TCSVT.2009.2035846
   Nightingale James, 2011, Performance Evaluation Review, V39, P29, DOI 10.1145/2034832.2034838
   Nightingale J, 2010, IEEE T CONSUM ELECTR, V56, P2161, DOI 10.1109/TCE.2010.5681086
   Nur G, 2014, MULTIMED TOOLS APPL, V70, P689, DOI 10.1007/s11042-012-1120-2
   Reichel J., 2007, JOINT SCALABLE VIDEO
   Sanchez Y, 2012, SIGNAL PROCESS-IMAGE, V27, P329, DOI 10.1016/j.image.2011.10.002
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Tsai MF, 2010, IET COMMUN, V4, P937, DOI 10.1049/iet-com.2009.0661
   Wang Q, 2009, WIRELESS PERS COMMUN, V48, P113, DOI 10.1007/s11277-007-9424-7
   Wenger S, 2011, 6090 RFC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 21
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2011
EP 2035
DI 10.1007/s11042-012-1219-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500028
DA 2024-07-18
ER

PT J
AU Seiller, N
   Williem
   Singhal, N
   Park, IK
AF Seiller, Nicolas
   Williem
   Singhal, Nitin
   Park, In Kyu
TI Object oriented framework for real-time image processing on GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPGPU; Computer vision; Image/video processing; Object-oriented; Design
   patterns
AB General purpose computation on graphics processing unit (GPGPU) provides a significant gain in terms of the processing time compared with CPU. Images are particularly good subjects for massive parallel implementations on GPU. Thus, the processing time can be improved for computer vision and image/video processing algorithms. However, GPGPU has a fairly complex integration process in a framework and they evolve very rapidly. In this paper, we present a framework that provides all the desired primitives related to GPGPU-based image processing algorithms, which makes it easy and straightforward for the user to exploit. The proposed framework is object-oriented, and it utilizes design patterns. The user can benefit from all the advantages of object-oriented programming, such as code reusability/extensibility, flexibility, information hiding, and complexity hiding. This makes it possible to rapidly integrate new technologies and functionality as they appear.
C1 [Seiller, Nicolas] SmartCo, F-75008 Paris, France.
   [Singhal, Nitin] GE Global Res, Biomed Signal Anal Lab, Bangalore 560066, Karnataka, India.
   [Williem; Park, In Kyu] Inha Univ, Sch Informat & Commun Engn, Inchon 402751, South Korea.
C3 General Electric; Inha University
RP Park, IK (corresponding author), Inha Univ, Sch Informat & Commun Engn, Inchon 402751, South Korea.
EM ns.seiller@gmail.com; williem_060689@hotmail.com;
   nitin.singhal@ieee.org; pik@inha.ac.kr
RI Williem, Williem/O-6205-2019; Park, In Kyu/B-5967-2013
OI Williem, Williem/0000-0002-2763-7883; 
FU Ministry of Knowledge Economy (MKE, Korea) [10041664]
FX This work was supported by the Industrial Strategic Technology
   Development Program (10041664, The Development of Fusion Processor based
   on Multi-Shader GPU) funded by the Ministry of Knowledge Economy (MKE,
   Korea).
CR Allusse Yannick., 2008, Proceedings of the 16th ACM international conference on Multimedia, P1089
   Babenko P, 2008, J REAL-TIME IMAGE PR, V3, P255, DOI 10.1007/s11554-008-0085-x
   Bradski G., 2008, LEARNING OPENCV
   Chang JY, 2011, COMPUT VIS IMAGE UND, V115, P620, DOI 10.1016/j.cviu.2010.11.017
   Fung J., 2005, 13th Annual ACM International Conference on Multimedia, P849, DOI 10.1145/1101149.1101334
   Gamma Erich., 1994, DESIGN PATTERNS
   Hou QM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360618
   Hwu W.-m, 2016, Programming Massively Parallel Processors: A Hands-On Approach
   Jansen T, 2007, THESIS TU MUNICH
   Kuck R, 2009, LECT NOTES COMPUT SC, V5875, P1019, DOI 10.1007/978-3-642-10331-5_95
   McCool M, 2004, ACM T GRAPHIC, V23, P787, DOI 10.1145/1015706.1015801
   Membarth R, 2011, HPPC 2011, P28
   NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0
   Nguyen V, 2007, P INT ANN FOR COCOMO, P1
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Park IK, 2011, IEEE T PARALL DISTR, V22, P91, DOI 10.1109/TPDS.2010.115
   Raspe M, 2009, THESIS U KOBLENZ LAN
   Rost R.J., 2006, OpenGL Shading Language, V2nd
NR 18
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2347
EP 2368
DI 10.1007/s11042-013-1440-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500044
DA 2024-07-18
ER

PT J
AU Xu, PF
   Yao, HX
   Ji, RR
   Liu, XM
   Sun, XS
AF Xu, Pengfei
   Yao, Hongxun
   Ji, Rongrong
   Liu, Xian-Ming
   Sun, Xiaoshuai
TI Where should I stand? Learning based human position recommendation for
   mobile photographing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photographing recommendation; Knowledge learning; 3D model
   reconstruction; Landmark recognition
ID IMAGE QUALITY ASSESSMENT; PHOTO
AB In this paper, we study the problem of human position recommendation in mobile photographing and propose a learning-based method to summarize the photographing knowledge from massive social images to improve the robustness and effectiveness. In contrast to existing photographing guide methods, we focus on turning to the collaborative web data source and learning the distribution of human position. To overcome the challenges in landmark image alignment and the relative human position projection, we propose a 3D reconstruction-based method to align the background region and human region into a uniform coordinate system. Finally, a camera-view sensitive human position recommendation strategy is carried out. A dataset containing 30,000 photos of ten landmark scenes is collected from Flickr, and a group of experiments are conducted comparing both our alternatives and various other baseline methods. Moreover, an application is developed on mobile phones to implement the real-time photographing recommendation. The experimental results show that our proposed framework achieves promising results, which demonstrate the robustness and effectiveness of our approach.
C1 [Xu, Pengfei; Yao, Hongxun; Ji, Rongrong; Liu, Xian-Ming; Sun, Xiaoshuai] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
EM pengfeixu.hit@gmail.com; H.yao@hit.edu.cn; rrji@hit.edu.cn;
   xmliu@hit.edu.cn; xssun@hit.edu.cn
FU National Science Foundation of China [61071180, 61133003]
FX This work was supported in part by the National Science Foundation of
   China (No. 61071180 & No. 61133003).
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], COMPLETE GUIDE LIGHT
   [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], 2010, ACM MULTIMEDIA
   ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271
   Bhattacharya S., 2010, P 18 ACM INT C MULTI, P271
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chen H, 2012, J INFORM HIDING MULT, V3, P66
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Goodale Mark, 2007, PHOTOGRAPHERS EYE CO, P1
   Hartley R., 2003, Multiple View Geometry in Computer Vision, V2
   Ji R., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P573
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Joshi D, 2012, MULTIMED TOOLS APPL, V56, P131, DOI 10.1007/s11042-010-0553-8
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kretzschmar H, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2902, DOI 10.1109/IROS.2008.4650855
   Li X, 2002, IEEE IMAGE PROC, P449
   Li X, 2008, P ECCV, V8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Robertson D., 2004, BRITICH MACHINE VISI, P819
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sun X, 2009, ACM MM, V1658
   Tong HG, 2004, LECT NOTES COMPUT SC, V3331, P198
   Tong HH, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P247
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yeh T, 2004, PROC CVPR IEEE, P76
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Yu F.X., 2011, Proceedings_of_the_19th_ACM_International_Conference_on_Multimedia, MM'11, P3
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
NR 38
TC 9
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 3
EP 29
DI 10.1007/s11042-012-1343-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200002
DA 2024-07-18
ER

PT J
AU Kim, SH
   Chung, KY
AF Kim, Sung-Ho
   Chung, Kyung-Yong
TI 3D simulator for stability analysis of finite slope causing plane
   activity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finite slope; Plane activity; Factor of safety; Stability analysis; 3D
   simulator
AB This paper describes the development of a 3D simulator that enables a user to analyze the stability of a finite slope causing plane activity among a range of slopes comprised of a finite slope and infinite slope. Until now, there has been considerable theory and research into slope stability. Nevertheless, few systems can be confirmed directly by simulating the stability analysis of a slope, such as landslides. In other words, virtual experiments, such as the analysis of the slope, cannot be performed due to the absence of a system. For that reason, in this study, a 3D simulator was developed for stability analysis of a finite slope causing plane activity from the landslide phenomena that actually occurred or had very high probability. The Nvidia PhysX, which is utilized to develop computer games and simulators, was used to develop a 3D simulator with physical features. In addition, OpenGL was used to provide a three-dimensional visual effect from the simulator. In this paper, the values of each variable were determined to confirm whether landslides can occur easily when the factor of safety (F-s) was within a certain range in the 3D simulator. The 3D simulator developed in this paper was found to be quite useful because it can verify visually whether landslides occur easily in different environments and conditions.
C1 [Kim, Sung-Ho; Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
EM kimsh1204@sangji.ac.kr; dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea; Ministry of Education, Science and Technology [2012-0004478]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology (No. 2012-0004478).
CR Brideau MA, 2011, LANDSLIDES, V8, P139, DOI 10.1007/s10346-010-0242-8
   Chao F, 2010, INF SCI ENG ICISE 2, P6899
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Leynaud D, 2010, MAR GEOL, V269, P89, DOI 10.1016/j.margeo.2009.12.002
   Michalowski RL, 2010, J GEOTECH GEOENVIRON, V136, P583, DOI 10.1061/(ASCE)GT.1943-5606.0000251
   Nian TK, 2011, APPL MECH MATER, V90-93, P676, DOI 10.4028/www.scientific.net/AMM.90-93.676
   Peng WX, 2011, APPL MECH MATER, V90-93, P255, DOI 10.4028/www.scientific.net/AMM.90-93.255
   Sasahara Katsuo, 2010, Journal of the Japan Landslide Society, V47, P35, DOI 10.3313/jls.47.155
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Stianson JR, 2011, CAN GEOTECH J, V48, P891, DOI 10.1139/T11-006
   Wang FW, 2010, PHYS CHEM EARTH, V35, P149, DOI 10.1016/j.pce.2009.07.006
   Yang B, 2012, ADV MATER RES-SWITZ, V378-379, P489, DOI 10.4028/www.scientific.net/AMR.378-379.489
NR 12
TC 41
Z9 41
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 455
EP 463
DI 10.1007/s11042-013-1356-5
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400017
DA 2024-07-18
ER

PT J
AU Hsu, FH
   Wu, MH
   Wang, SJ
AF Hsu, Fu-Hau
   Wu, Min-Hao
   Wang, Shiuh-Jeng
TI Reversible data hiding using side-match predictions on steganographic
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Reversible data hiding; Side match; Prediction;
   Histogram
ID DIFFERENCE EXPANSION
AB Information hiding is an important method to achieve multi-media security. Recently, many researchers have paid attention to the reversible data hiding scheme, which can completely recover original multi-media files after the embedded data are extracted. In this paper, a side-match approach is proposed to achieve more capacity in histogram-based reversible data hiding for grayscale images. The histogram is created by exploiting the difference in all the values between pixels and their predictedive values. Experimental results show that our method is capable of providing a great embedding capacity without causing noticeable distortion. In one-level hiding, where it has the best capacity, our method conserves image qualities larger than 48 dB. Furthermore, in multilevel hiding, a rotation strategy is proposed to further improve image qualities. Experimental results show that our method performs better than other existing methods in multilevel hiding cases.
C1 [Hsu, Fu-Hau; Wu, Min-Hao] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 320, Taiwan.
   [Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Tao Yuan 333, Taiwan.
C3 National Central University
RP Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Tao Yuan 333, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU National Science Council of the Republic of China [NSC
   98-2221-E-015-001-MY3, NSC 100-2221-E-015 -001 -MY2, NSC
   99-2918-I-015-001]
FX This research was partially supported by the National Science Council of
   the Republic of China under the Grants NSC 98-2221-E-015-001-MY3, NSC
   100-2221-E-015 -001 -MY2, and NSC 99-2918-I-015-001. We are also
   indebted to Prof. C. H. Yang for the discussions in the revised version
   toward a better quality presentation.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Hong W, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P292, DOI 10.1109/IITA.Workshops.2008.119
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Jiang J, 2000, IEE P-VIS IMAGE SIGN, V147, P575, DOI 10.1049/ip-vis:20000767
   Jin HL, 2007, IEICE T FUND ELECTR, VE90A, P771, DOI 10.1093/ietfec/e90-a.4.771
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xianting Zeng, 2009, Journal of Multimedia, V4, P145
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
NR 24
TC 12
Z9 13
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 571
EP 591
DI 10.1007/s11042-012-1047-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900003
DA 2024-07-18
ER

PT J
AU Yu, HF
AF Yu, Hsiang-Fu
TI Improvement of the client-centric approach for broadcasting popular
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic broadcast; Near video-on-demand (VOD); Waiting time; Multimedia
   communications
ID ON-DEMAND APPLICATIONS; SERVICE; SCHEME; NETWORKS; MEDIA
AB Periodic broadcast is a cost-effective solution for large-scale distribution of popular videos. Regardless of the number of video requests, this strategy guarantees constant worst service latency to all clients. An essential periodic broadcast method is the client-centric approach (CCA), which allows clients to use smaller receiving bandwidth to download broadcast data. An enhanced version, namely CCA+, was proposed to yield a shorter waiting time. This work further improves CCA+ by leveraging client bandwidth for more efficient video broadcast. The new scheme reduces the broadcast latency by as much as 39 % when compared to CCA+ and 78 % when compared to CCA. We prove the applicability of this new scheme and provide an analytical evaluation to demonstrate the performance advantage, as compared with particular schemes.
C1 Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@tea.ntue.edu.tw
FU National Science Council, Taiwan [NSC 100-2221-E-152-005]
FX The work was financially supported by National Science Council, Taiwan
   under a research grant number NSC 100-2221-E-152-005.
CR [Anonymous], J INFORM HIDING MULT
   Cai Y, 2001, J APPL SYSTEMS STUDI, V2
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Frossard P, 2008, P IEEE, V96, P39, DOI 10.1109/JPROC.2007.909876
   Gao LX, 2002, MULTIMEDIA SYST, V8, P284, DOI 10.1007/s005300100049
   Hua KA, 1997, ACM SIGCOMM
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Lou J, 2010, IDING MULTIMEDIA SIG, V1, P132
   Natarajan A, 2009, MULTIMED TOOLS APPL, V43, P179, DOI 10.1007/s11042-009-0263-2
   Shiang HP, 2009, IEEE T VEH TECHNOL, V58, P941, DOI 10.1109/TVT.2008.925308
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Yu HF, 2008, IEEE T BROADCAST, V54, P304, DOI 10.1109/TBC.2008.915761
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
NR 17
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 629
EP 639
DI 10.1007/s11042-012-1062-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900006
DA 2024-07-18
ER

PT J
AU Yan, B
   Guo, YJ
AF Yan, Bin
   Guo, Yin-Jing
TI Speech authentication by semi-fragile speech watermarking utilizing
   analysis by synthesis and spectral distortion optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech authentication; Fragile watermark; Analysis by Synthesis (AbS);
   Bit allocation; Spectral distortion
ID DIGITAL WATERMARKING; SECURITY IMPROVEMENT; ALGORITHM
AB This paper proposes an improved semi-fragile speech watermarking scheme by quantization of linear prediction (LP) parameters, i.e., the inverse sine (IS) parameters. The spectral distortion due to watermark embedding is controlled to meet the 'transparency' criterion in speech coding. A modified bit allocation algorithm combined with watermarking is developed to determine the quantization step so that the 'transparency' requirement is satisfied. Due to the statistical nature, the LP coefficients estimated from the watermarked speech signal are different from the watermarked LP coefficients even in the absence of attacks. This effect is the cause of increase in decoding error and minimum authentication length. To tackle this problem, an Analysis by Synthesis (AbS) scheme is developed to reduce the difference between the estimated LP coefficients and the watermarked ones. The watermark detection threshold and minimum authentication length are then derived according to the probability of error and the signal to noise ratio (SNR) requirements. Experimental results show that the proposed AbS based method can effectively reduce the difference between the watermarked IS parameter and the extracted IS parameter when there is no attacks. In addition, the modified bit allocation algorithm can automatically find the appropriate quantization step used in the odd-even modulation so that the transparency requirement is satisfied.
C1 [Yan, Bin; Guo, Yin-Jing] Shandong Univ Sci & Technol, Dept Commun Engn, Sch Informat & Elect Engn, Qingdao 266510, Shandong, Peoples R China.
C3 Shandong University of Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Dept Commun Engn, Sch Informat & Elect Engn, Qingdao 266510, Shandong, Peoples R China.
EM yanbinhit@hotmail.com
RI Yan, Bin/Y-7642-2019
OI Yan, Bin/0000-0003-2929-464X
FU research project of "SUST Spring Bud" [2009AZZ155]; National Natural
   Science Foundation of China (NSFC) [61071087]
FX This work is supported by research project of "SUST Spring Bud" under
   the grant number: 2009AZZ155. The work of the second author is also
   supported by the project of National Natural Science Foundation of China
   (NSFC) under project grant number: 61071087. The authors would like to
   thank the anonymous reviewers for their constructive comments and
   suggestions. We are indebted to the reviewers for their valuable time
   spent on the manuscript of this paper. The first author would like to
   thank Prof. Zhe-Ming Lu, Prof. Sheng-He Sun, Prof. Jeng-Shyang Pan and
   Prof. Xia-Mu Niu for their guidance and help in developing the basic
   algorithm upon which the extension in this paper is built.
CR [Anonymous], 1993, Discrete Time Processing of Speech Signals
   [Anonymous], APPL SIGNAL PROCESSI
   [Anonymous], 1997, P 5 EUR C SPEECH COM
   [Anonymous], 2002, Discrete-Time Speech Signal Processing: Principles and Practice
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   Barni J., 2004, WATERMARKING SYSTEMS
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Cheng Q, 2001, INT CONF ACOUST SPEE, P1337, DOI 10.1109/ICASSP.2001.941175
   Cheng Q., 2005, United States Patent, Patent No. [US6892175B1, 6892175]
   Chu W.C., 2003, SPEECH CODING ALGORI
   Ciloglu T, 2003, INT C MULT EXP, V2, P1017
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   Deng ZY, 2007, LECT NOTES COMPUT SC, V4810, P429
   Faundez-Zanuy M, 2006, SPEECH COMMUN, V48, P1608, DOI 10.1016/j.specom.2006.06.010
   Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P3027, DOI 10.1016/j.patcog.2007.02.016
   Faundez-Zanuy M, 2010, J FORENSIC SCI, V55, P1080, DOI 10.1111/j.1556-4029.2010.01395.x
   Faundez-Zanuy M, 2010, LECT NOTES ARTIF INT, V5933, P84, DOI 10.1007/978-3-642-11509-7_11
   Fei C, 2006, THESIS U TORONTO
   Geiser B, 2008, INT CONF ACOUST SPEE, P4005, DOI 10.1109/ICASSP.2008.4518532
   GURIJALA A, 2002, P INT C SPOK LANG PR
   Hagmuller Martin, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1653
   Harjito Bambang, 2010, 2010 4th IEEE International Conference on Digital Ecosystems and Technologies (DEST 2010), P640, DOI 10.1109/DEST.2010.5610580
   Hatada M, 2002, PROC SPIE, V4861, P258, DOI 10.1117/12.455620
   Hofbauer K, 2009, IEEE T AUDIO SPEECH, V17, P1624, DOI 10.1109/TASL.2009.2021543
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Kay S. M., 1988, Modern Spectral Estimation: Theory and Application
   Konrad H, 2005, 4 EUR INN RES WORKSH
   KUNDUR D, 1999, THESIS U TORONTO
   Lacy J, 1998, INT CONF ACOUST SPEE, P3725, DOI 10.1109/ICASSP.1998.679693
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu CH, 2004, 2004 47TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, CONFERENCE PROCEEDINGS, P165
   Liu JX, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P75, DOI 10.1109/IAS.2009.60
   Lu ZM, 2005, IEICE T INF SYST, VE88D, P330, DOI 10.1093/ietisy/E88-D.2.330
   Ma L, 2007, LECT NOTES COMPUT SC, V4681, P1305
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   Ramamurthy K.N., 2010, MATLAB Software for the Code Excited Linear Prediction Algorithm: The Federal Standard-1016
   Ruiz FJ, 2000, INT CONF ACOUST SPEE, P1499, DOI 10.1109/ICASSP.2000.861923
   Sakaguchi S, 2000, INT CONF ACOUST SPEE, P917
   Saraswathi S., 2010, INT J INF TECHNOL, V16, P34
   Singh J, 2009, INF SECUR J, V18, P99, DOI 10.1080/19393550902791424
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   Unoki AM, 2011, J INFORM HIDING MULT, V2, P337
   Wu CP, 2002, INT CONF ACOUST SPEE, P3305
   Yan B, 2005, LECT NOTES ARTIF INT, V3683, P497
NR 46
TC 16
Z9 17
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 383
EP 405
DI 10.1007/s11042-011-0861-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800004
DA 2024-07-18
ER

PT J
AU Granda, JC
   Nuño, P
   Suárez, FJ
   Pérez, MA
AF Granda, Juan C.
   Nuno, Pelayo
   Suarez, Francisco J.
   Perez, Maria A.
TI E-pSyLon: a synchronous e-learning platform for staff training in large
   corporations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synchronous e-learning; E-training; Staff training; Educational
   multimedia tools
ID DISTANCE; SYSTEM; MULTICAST; TOOLS; MBONE
AB Synchronous e-learning is becoming increasingly popular as a tool for developing human resource training plans in large corporations. A synchronous e-training platform has been designed and implemented to explore the possibilities of synchronous e-training in a large corporation. The client tool is used by learners and instructors to collaborate in real-time during e-training activities. It is based on standard protocols also used in voice over IP, which makes it inter-operable with other software and hardware devices. The functionalities offered by the client tool have been chosen based on those provided by commercial tools, but focusing on the specific characteristics of users and network conditions of corporate environments. This facilitates highly interactive synchronous e-training activities. Multimedia configuration of activities is flexible, so participants with different network link capabilities can join activities. The e-training platform has been tested in real e-training activities in ArcelorMittal Spain. The opinions of the users reflect an enhanced learning experience when using the client tool.
C1 [Granda, Juan C.; Nuno, Pelayo; Suarez, Francisco J.] Univ Oviedo, Dept Informat, Gijon 33204, Spain.
   [Perez, Maria A.] La Toba ArcelorMittal Training Ctr, Aviles, Spain.
C3 University of Oviedo; ArcelorMittal
RP Granda, JC (corresponding author), Univ Oviedo, Dept Informat, Campus Viesques, Gijon 33204, Spain.
EM jcgranda@uniovi.es; nunopelayo@uniovi.es; fjsuarez@uniovi.es;
   Maria-Aranzazu.Perez@arcelormittal.com
RI Nuño, Pelayo/KIL-6014-2024; Suarez Alonso, Francisco Jose/G-7308-2014;
   Granda-Candas, Juan Carlos/K-8599-2014
OI Nuño, Pelayo/0000-0002-8599-3077; Suarez Alonso, Francisco
   Jose/0000-0001-5572-6229; Granda-Candas, Juan Carlos/0000-0001-8214-6019
FU ArcelorMittal [CN-06-038]; University of Oviedo-Banco de Santander
   [UNOV-10-BECDOC-S]; Spanish National Plan of Research, Development and
   Innovation [TIN2008-06045-C02, TIN2011-24903]
FX This work was partially funded by ArcelorMittal under contract number
   CN-06-038. Financial support (grant: UNOV-10-BECDOC-S) given by the
   University of Oviedo-Banco de Santander is acknowledged. This work was
   partially funded by the Spanish National Plan of Research, Development
   and Innovation under the projects TIN2008-06045-C02 and TIN2011-24903.
CR ALAVI M, 1994, MIS QUART, V18, P159, DOI 10.2307/249763
   Almeroth KC, 2000, IEEE NETWORK, V14, P10, DOI 10.1109/65.819167
   [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   [Anonymous], 4 ASHE ERIC G WASH U
   Barnes M, 2008, 5239 RFC INT ENG TAS
   Bijlani K, 2010, P 2 INT C ED TECHN C, pV2219
   Bolot JC, 1996, IEEE INFOCOM SER, P232, DOI 10.1109/INFCOM.1996.497898
   Boulos MNK, 2005, TELEMED J E-HEALTH, V11, P583, DOI 10.1089/tmj.2005.11.583
   Bouras C., 2002, Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications PDPTA, P1158
   Camarillo G, 2006, 4582 RFC INT ENG TAS
   Casner S, 1992, CONNEXIONS, V6, P10
   Chassie K, 2002, IEEE POTENTIALS, V21, P33, DOI 10.1109/MP.2002.1033664
   Civanlar M, 2000, 2862 RFC INT ENG TAS
   Deshpande S. G., 2001, IEEE Transactions on Multimedia, V3, P432, DOI 10.1109/6046.966115
   Di Lecce V, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P255, DOI 10.1109/VECIMS.2009.5068904
   El Saddik A, 2008, MULTIMED TOOLS APPL, V39, P353, DOI 10.1007/s11042-007-0165-0
   El Saddik A, 2007, MULTIMED TOOLS APPL, V33, P217, DOI 10.1007/s11042-006-0057-8
   Emswiler T, 1995, THESIS NAVAL POSTGRA
   Floyd S, 1997, IEEE ACM T NETWORK, V5, P784, DOI 10.1109/90.650139
   Fortino G, 2001, EUROMICRO CONF PROC, P336, DOI 10.1109/EURMIC.2001.952473
   Fung A, 2005, P 6 INT WORK C INF T, P47
   Garcia DF, 2007, INT J EDUC INF TECH, V1, P95
   Granda JC, 2008, VIS 2008: INTERNATIONAL CONFERENCE VISUALISATION, PROCEEDINGS, P70, DOI 10.1109/VIS.2008.16
   Granda JC, 2010, COMPUT COMMUN, V33, P1752, DOI 10.1016/j.comcom.2010.02.020
   Hellstrom G, 2005, 4103 RFC INT ENG TAS
   Higuchi Y, 2006, LECT NOTES ARTIF INT, V4252, P1027
   Isaacs E.A., 1994, Multimedia systems, V2, P63, DOI [DOI 10.1007/BF01274181, 10.1007/bf01274181]
   Isenhour P., 2000, J ED TECHNOLOGY SOC, V3, P74
   ITU-T, 1998, MULT STILL IM ANN PR
   ITU-T, 1998, PROT MULT APPL TEXT
   Jacobson V, 1993, VISUAL AUDIO TOOL
   Latchman H, 2001, IEEE T EDUC, V44, P208, DOI 10.1109/13.925861
   Latchman HA, 1999, IEEE T EDUC, V42, P247, DOI 10.1109/13.804528
   Ludlow BL, 1996, RURAL GOALS 2000 BUI
   Malpani R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P155, DOI 10.1145/266180.266356
   Marjanovic O, 1999, J COMPUT ASSIST LEAR, V15, P129, DOI 10.1046/j.1365-2729.1999.152085.x
   MCCANNE S, 1995, P ACM MULT 95 SAN FR, P511
   Nuno P., 2010, Proceedings of the Fifth International Conference on Systems and Networks Communications (ICSNC 2010), P213, DOI 10.1109/ICSNC.2010.40
   Pahud M, 2008, CONFERENCEXP RES PLA
   Papert S., 1991, SITUATING CONSTRUCTI
   Paxson V, 1999, IEEE ACM T NETWORK, V7, P277, DOI 10.1109/90.779192
   Premchaiswadi Wichian, 2010, 2010 IEEE Education Engineering 2010 - The Future of Global Learning Engineering Education (EDUCON 2010), P1531, DOI 10.1109/EDUCON.2010.5492344
   Schooler E., 2002, 3261 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Snow C, 2005, IEEE T EDUC, V48, P705, DOI 10.1109/TE.2005.854577
   Ullrich C, 2010, IEEE T LEARN TECHNOL, V3, P6, DOI 10.1109/TLT.2009.54
   Weller M, 2007, COMPUT EDUC, V49, P148, DOI 10.1016/j.compedu.2005.04.015
   Yang ZK, 2007, COMPUT EDUC, V48, P171, DOI 10.1016/j.compedu.2004.12.007
   Zhao X, 2006, PRODUCTIVITY RES, P200
   Zhao X, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P102
NR 50
TC 11
Z9 14
U1 0
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 431
EP 463
DI 10.1007/s11042-012-1061-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300005
DA 2024-07-18
ER

PT J
AU Tang, HB
   Liu, XS
AF Tang, Hongbin
   Liu, Xinsong
TI Cryptanalysis of Arshad et al.'s ECC-based mutual authentication scheme
   for session initiation protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Password guessing attack; Session initiation protocol; Elliptic curve
   cryptography; Authentication; Protocol; Cryptography
AB Session Initiation Protocol (SIP) has been widely used in the current Internet protocols such as Hyper Text Transport Protocol (HTTP) and Simple Mail Transport Protocol (SMTP). However, the original SIP authentication scheme was insecure and many researchers tried to propose schemes to overcome the flaws. In the year 2011, Arshad et al. proposed a SIP authentication protocol using elliptic curve cryptography (ECC), but their scheme suffered from off-line password guessing attack along with password change pitfalls. To conquer the mentioned weakness, we proposed an ECC-based authentication scheme for SIP. Our scheme only needs to compute four elliptic curve scale multiplications and two hash-to-point operations, and maintains high efficiency. The analysis of security of the ECC-based protocol shows that our scheme is suitable for the applications with higher security requirement.
C1 [Tang, Hongbin; Liu, Xinsong] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Tang, HB (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
EM tanghongbin@uestc.edu.cn
CR [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], SIP SECURIT IN PRESS
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], RFC3261 IETF
   [Anonymous], STAND EFF CRYPT SEC
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Chen TH, 2010, COMM COM INF SC, V119, P46
   DENNING DE, 1981, COMMUN ACM, V24, P533, DOI 10.1145/358722.358740
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Eun-Jun Yoon, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P334, DOI 10.1109/NSS.2010.101
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Lin CL, 2003, COMPUT SECUR, V22, P68, DOI 10.1016/S0167-4048(03)00114-7
   Liu F, 2011, LECT NOTES COMPUT SC, V7025, P134, DOI 10.1007/978-3-642-24712-5_11
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Yoon EJ, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P642, DOI 10.1109/NISS.2009.137
   Yoon EJ, 2009, CISIS: 2009 INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, VOLS 1 AND 2, P549, DOI 10.1109/CISIS.2009.93
NR 23
TC 27
Z9 27
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 321
EP 333
DI 10.1007/s11042-012-1001-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600001
DA 2024-07-18
ER

PT J
AU Hästbacka, D
   Kuikka, S
AF Hastbacka, David
   Kuikka, Seppo
TI Semantics enhanced engineering and model reasoning for control
   application development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Control application engineering; Semantically enriched models; Software
   models; Semantic web; Owl; Rules; Reasoning
ID UML CLASS DIAGRAMS; ONTOLOGY; OWL; ARCHITECTURE; INDUSTRY; GAP
AB Development of advanced systems requires new methods to improve quality and efficiency of engineering processes, and to assist management of complex models encompassing different engineering disciplines. Methods such as model-driven development and domain-specific modeling facilitate development from this perspective but reduce interoperability and other prospects of rationalizing processes, on the other hand. An approach applying Web Ontology Language (OWL) semantics and reasoning to models is presented with examples to support industrial control application engineering. Using the methods, generalized classifications are inferred from instance models and combined with generic engineering knowledge maintained in ontologies. Reasoning allows identifying assemblies and structures outside the scope of traditional modeling to detect specific structures, flaws and error-prone designs. The semantic descriptions of models allow linking of other engineering related information to support engineering tasks during design. The results indicate that OWL semantics and reasoning can be used as a supplement enhancing typical development practices.
C1 [Hastbacka, David; Kuikka, Seppo] Tampere Univ Technol, Dept Automat Sci & Engn, FIN-33101 Tampere, Finland.
C3 Tampere University
RP Hästbacka, D (corresponding author), Tampere Univ Technol, Dept Automat Sci & Engn, POB 692, FIN-33101 Tampere, Finland.
EM david.hastbacka@tut.fi; seppo.kuikka@tut.fi
RI Kuikka, Seppo/G-4262-2014; Hästbacka, David/AAX-2308-2021
OI Hästbacka, David/0000-0001-8442-1248; Kuikka, Seppo/0000-0003-0781-4341
CR Albert M, 2011, DATA KNOWL ENG, V70, P365, DOI 10.1016/j.datak.2011.01.003
   [Anonymous], INT WORKSH SEM WEB E
   Bennicke M, 2010, LECT NOTES COMPUT SC, V5765, P274, DOI 10.1007/978-3-642-17322-6_13
   Berardi D, 2005, ARTIF INTELL, V168, P70, DOI 10.1016/j.artint.2005.05.003
   Breslin JG, 2010, COMPUT IND, V61, P729, DOI 10.1016/j.compind.2010.05.002
   Cranefield S, 2007, INT J HUM-COMPUT ST, V65, P595, DOI 10.1016/j.ijhcs.2007.03.001
   Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001
   Hästbacka D, 2012, LECT NOTES ARTIF INT, V7267, P647, DOI 10.1007/978-3-642-29347-4_75
   Hastbacka D, 2011, INFORMATION VALUE MANAGEMENT, FUTURE TRENDS OF MODEL-DRIVEN DEVELOPMENT, RECENT TRENDS IN SOA BASED INFORMATION SYSTEMS AND MODELLING AND SIMULATION, VERIFICATION AND VALIDATION OF ENTERPRISE INFORMATION SYSTEMS, P13
   Hästbacka D, 2011, J SYST SOFTWARE, V84, P1100, DOI 10.1016/j.jss.2011.01.063
   Henderson-Sellers B, 2011, J SYST SOFTWARE, V84, P301, DOI 10.1016/j.jss.2010.10.025
   Horrocks I, 2005, J WEB SEMANT, V3, P23, DOI 10.1016/j.websem.2005.05.003
   Hsieh SH, 2011, ADV ENG INFORM, V25, P288, DOI 10.1016/j.aei.2010.08.004
   Jung JJ, 2012, INFORM SCIENCES, V182, P30, DOI 10.1016/j.ins.2010.08.042
   Kaneiwa K, 2010, THEOR COMPUT SCI, V411, P301, DOI 10.1016/j.tcs.2009.04.030
   Knorr M, 2011, ARTIF INTELL, V175, P1528, DOI 10.1016/j.artint.2011.01.007
   Knublauch H., 2011, SPIN-Overview and Motivation. W3C Member Submission
   López C, 2012, SCI COMPUT PROGRAM, V77, P66, DOI 10.1016/j.scico.2010.06.009
   Mokos K, 2010, 2010 36 EUROMICRO C, P47, DOI [10.1109/SEAA.2010.60, DOI 10.1109/SEAA.2010.60]
   Pahl Claus, 2007, INFORM SOFTWARE TECH, V49, P838, DOI 10.1016/j.infsof.2006.09.007
   Parreiras FS, 2010, DATA KNOWL ENG, V69, P1194, DOI 10.1016/j.datak.2010.07.009
   Ritala T, 2007, IEEE INTL CONF IND I, P885, DOI 10.1109/INDIN.2007.4384890
   Robles K, 2012, INFORM SOFTWARE TECH, V54, P72, DOI 10.1016/j.infsof.2011.07.003
   Savioja P, 2007, LECT NOTES ARTIF INT, V4562, P174
   Serral E, 2010, PERVASIVE MOB COMPUT, V6, P254, DOI 10.1016/j.pmcj.2009.07.006
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Vepsalainen T, 2009, 7 NORD WORKSH MOD DR, P315
NR 27
TC 10
Z9 10
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 47
EP 62
DI 10.1007/s11042-012-1134-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800004
DA 2024-07-18
ER

PT J
AU Choi, YH
   Tak, YS
   Rho, S
   Hwang, E
AF Choi, Young-Hwan
   Tak, Yoon-Sik
   Rho, Seungmin
   Hwang, Eenjun
TI Skin feature extraction and processing model for statistical skin age
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin age; Skin surface analysis; SVM classification; Skin feature
   extraction
ID SURFACE; TOPOGRAPHY
AB The convergence of information and medical technologies has resulted in the emergence and active development of the ubiquitous healthcare (U-Healthcare) industry. The U-healthcare industry provides telepathology and anytime-anywhere wellness services. The main purpose of these wellness services is to provide health information to improve the quality of life. Human skin is an organ that can be easily examined without expensive devices. In addition, there has recently been rapidly increasing interest in skin care products, resulting in a concomitant increase in their consumption. In this paper, we propose a new scheme for a self-diagnostic application that can estimate the actual age of the skin on the basis of the features on a skin image. In accordance with dermatologists' suggestions, we examined the length, width, depth, and other cell features of skin wrinkles to evaluate skin age. Using our highly developed image processing method, we could glean detailed information from the surface of the skin. Our scheme uses the extracted information as features to train a support vector machine (SVM) and evaluates the age of a subject's skin. Evaluation of our proposed scheme showed that it was more than 90% accurate in the analysis of the skin age of three different parts of the body: the face, neck, and hands. Therefore, we believe our model can be used as a standard or as a scale to measure the degree of damage or the aging process of the skin. This scheme is implemented into our Self-Diagnostic Total Skin Care system, and the information obtained from this system can be utilized in various areas of medicine.
C1 [Choi, Young-Hwan; Tak, Yoon-Sik; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Baekseok Univ, Informat & Commun Div, Cheonan, South Korea.
   [Choi, Young-Hwan] Korea Univ, Sch Elect Engn, Fac Elect Engn, Seoul, South Korea.
C3 Korea University; Baekseok University; Korea University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM ehwang04@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2011-0026448]; MKE (Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program [NIPA-2012- C1090-1201-0008]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2011-0026448) and the MKE
   (Ministry of Knowledge Economy), Korea, under the ITRC (Information
   Technology Research Center) support program supervised by the NIPA
   (National IT Industry Promotion Agency) (NIPA-2012- C1090-1201-0008).
CR Akazaki S, 2002, BRIT J DERMATOL, V147, P689, DOI 10.1046/j.1365-2133.2002.04874.x
   Beucher S, 1979, PROCPROC INT INT WOR
   Boyer G, 2009, SKIN RES TECHNOL, V15, P55, DOI 10.1111/j.1600-0846.2008.00324.x
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Choi Y, 2008, P INT C UB INF TECHN
   Edwards C, 2003, PHOTODERMATOL PHOTO, V19, P169, DOI 10.1034/j.1600-0781.2003.00042.x
   Fischer TW, 1999, SKIN PHARMACOL APPL, V12, P1, DOI 10.1159/000029840
   Fujimura T., 2007, International Journal of Cosmetic Science, V29, P423, DOI 10.1111/j.1468-2494.2007.00399.x
   Hatzis J, 2004, MICRON, V35, P201, DOI 10.1016/j.micron.2003.11.007
   Hayashi J, 2003, LECT NOTES ARTIF INT, V2774, P863
   Hayashi J Jun-Ichiro, 2002, INT C PATT REC, V1
   Iliev D, 1997, EXP DERMATOL, V6, P157, DOI 10.1111/j.1600-0625.1997.tb00199.x
   Kim K, 2009, P INT C MULT EXP
   Lagarde JM, 2005, SKIN RES TECHNOL, V11, P110, DOI 10.1111/j.1600-0846.2005.00096.x
   Lagarde JM, 2001, SKIN RES TECHNOL, V7, P112, DOI 10.1034/j.1600-0846.2001.70210.x
   Lévêque JL, 2003, SKIN RES TECHNOL, V9, P343, DOI 10.1034/j.1600-0846.2003.00043.x
   Nita D, 1998, Skin Res Technol, V4, P121, DOI 10.1111/j.1600-0846.1998.tb00096.x
   Purba MB, 2001, AGE AGEING, V30, P227, DOI 10.1093/ageing/30.3.227
   Tanaka H, 2008, SKIN RES TECHNOL, V14, P192, DOI 10.1111/j.1600-0846.2007.00278.x
   Zou YB, 2009, SKIN RES TECHNOL, V15, P399, DOI 10.1111/j.1600-0846.2009.00377.x
NR 20
TC 15
Z9 15
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 227
EP 247
DI 10.1007/s11042-011-0987-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200002
DA 2024-07-18
ER

PT J
AU Lee, H
   Seo, S
   Ryoo, S
   Ahn, K
   Yoon, K
AF Lee, Hochang
   Seo, Sanghyun
   Ryoo, Seungtaek
   Ahn, Keejoo
   Yoon, Kyunghyun
TI A multi-level depiction method for painterly rendering based on visual
   perception cue
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Painting technique; Image saliency
AB Increasing the level of detail (LOD) in brushstrokes within areas of interest improved the realism of painterly rendering. Using a modified quad-tree, we segmented an image into areas with similar levels of saliency; each of these segments was then used to control the brush strokes during rendering. We could also simulate real oil painting steps based on saliency information. Our method runs in a reasonable fine and produces results that are visually appealing and competitive with previous techniques.
C1 [Lee, Hochang; Ahn, Keejoo; Yoon, Kyunghyun] Chung Ang Univ, Seoul 156756, South Korea.
   [Seo, Sanghyun] Univ Lyon 1, CNRS, LIRIS, F-69365 Lyon, France.
   [Ryoo, Seungtaek] Hansin Univ, Osan, South Korea.
   [Yoon, Kyunghyun] Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University; Centre National de la Recherche Scientifique
   (CNRS); Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1; Chung Ang University
RP Yoon, K (corresponding author), Chung Ang Univ, 221 Heuksuk Dong, Seoul 156756, South Korea.
EM hclee0126@cglab.cau.ac.kr; shseo75@gmail.com; stryoo@hs.ac.kr;
   kjahn@cglab.cau.ac.kr; khyoon@cau.ac.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Chung-Ang University
FX This research was supported by the Chung-Ang University Research
   Scholarship Grants in 2011.
CR Barry R., 2006, P SIGGRAPH 06 SKETCH, P99
   Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Collomosse JP, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P122, DOI 10.1109/EGUK.2002.1011281
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Halim Z., 2011, INT J INF TECHNOL CO, V1, P92
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P47, DOI 10.1109/CGI.2001.934657
   Hertzmann A., 2002, NPAR, P91, DOI 10.1145/508530.508546
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Karna AK, 2010, J CONVERGENCE, V1, P65
   Kovács L, 2006, WSCG 2006: FULL PAPERS PROCEEDINGS, P141
   Lee H., 2003, P ICCSA, P317
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Lee S., 2006, Proc. NPAR '06, P97, DOI DOI 10.1145/1124728.1124745
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Santella A, 2002, 3 NPAR 02, P75
   Seo S. H., 2009, P COMP AESTH, P9
   SHASHUA A, 1988, IEEE T PATTERN ANAL, V7, P90
   Surendran D., 2011, International Journal of Information Technology, Communications and Convergence, V1, P159, DOI 10.1504/IJITCC.2011.039283
   Treavett S MF., 1997, Proc. 15th Eurographics UK Conference, P201
   van de Weijer J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1520
   Zeki S., 1999, Inner Vision: An Exploration of Art and the Brain
NR 33
TC 5
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 277
EP 292
DI 10.1007/s11042-012-1036-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200004
DA 2024-07-18
ER

PT J
AU Kang, D
   Seo, S
   Ryoo, S
   Yoon, K
AF Kang, Dongwann
   Seo, Sanghyun
   Ryoo, Seungtaek
   Yoon, Kyunghyun
TI A study on stackable mosaic generation for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photomosaic; Smartphone; Database; Best match search
AB With the growing use of mobile devices such as smartphones, tablet PCs, and digital cameras, photography has become an integral part of everyday life. In particular, mobile devices with cameras allow us to easily capture and modify photographs that can be shared via social networks. In this paper, we introduce a mobile device application for converting photographs into photomosaic images. In general, high-quality photomosaics require large databases. However, mobile devices have limited resources; hence it is difficult for such devices to support photomosaics. We propose a method that produces a photomosaic effect using a database that consists of rotatable images. We also propose a solution to the performance issue based on a best match search.
C1 [Kang, Dongwann; Yoon, Kyunghyun] Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
   [Seo, Sanghyun] Univ Lyon 1, F-69622 Villeurbanne, France.
   [Ryoo, Seungtaek] Han Shin Univ, Sch Comp Engn, Osan Si, Gyeonggi Do, South Korea.
C3 Chung Ang University; Universite Claude Bernard Lyon 1
RP Yoon, K (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
EM khyoon@cau.ac.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU National Research Foundation of Korea(NRF); Korea government(MEST)
   [20100018445]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MEST) (No. 20100018445).
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   Blasi Gd, 2006, SMART IDEAS PHOTOMOS, P267
   Blasi Gd, 2005, P IASTED VIIP2005
   Blasi Gd, 2005, P ACM WSCG2005
   Di Blasi G, 2005, VISUAL COMPUT, V21, P373, DOI 10.1007/s00371-005-0292-4
   Dominguez-Sal D, 2011, IJITCC, V1, P41
   Elber G, 2003, VISUAL COMPUT, V19, P67, DOI 10.1007/s00371-002-0175-x
   Finkelstein A., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P11, DOI 10.1007/BFb0053259
   Halim Z., 2011, INT J INF TECHNOL CO, V1, P92
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Kang D, 2011, IEICE T INF SYST, VE94D, P2036, DOI 10.1587/transinf.E94.D.2036
   Kim J, 2002, ACM T GRAPHIC, V21, P657
   Liang WY, 2011, JOC, V1, P93
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Orchard J., 2008, P 6 INT S NONPH AN R, P79, DOI DOI 10.1145/1377980.1377997
   Park JW, 2006, LECT NOTES COMPUTER, V4035
   Pyshkin E, 2011, JOC, V1, P1
   Silvers R., 1997, Photomosaics
   Tran N, 1999, P 1999 ACM S APPL CO, P105, DOI [10.1145/298151.298213, DOI 10.1145/298151.298213]
NR 19
TC 15
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 145
EP 159
DI 10.1007/s11042-012-1065-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400010
DA 2024-07-18
ER

PT J
AU Huber, J
   Ding, Y
AF Huber, Jochen
   Ding, Yun
TI Adapting web pages using graph partitioning algorithms for user-centric
   multi-device web browsing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-device web browsing; Web page partitioning; Partitioning
   algorithms; Web page annotation; Mobile and ubiquitous multimedia
AB In the era of ubiquitous computing, applications are emerging to benefit from using devices of different users and different capabilities together. This paper focuses on user-centric web browsing using multiple devices, where content of a web page is partitioned, adapted and allocated to devices in the vicinity. We contribute two novel web page partitioning algorithms. They differ from existing approaches by allowing for both, automatic and semi-automatic partitioning. On the one hand, this provides good automatic, web page independent results by utilizing sophisticated structural pre-and postprocessing of the web page. On the other hand, these results can be improved by considering additional semantic information provided through user-generated web page annotations. We further present a performance evaluation of our algorithms. Moreover, we contribute the results of a user study. These clearly show that (1) our algorithms provide good automatic results and (2) the application of user-centric, annotation-based semantic information leads to a significantly higher user satisfaction.
C1 [Huber, Jochen] Tech Univ Darmstadt, D-64289 Darmstadt, Germany.
   [Ding, Yun] RIB Software AG, Singapore 038989, Singapore.
C3 Technical University of Darmstadt
RP Huber, J (corresponding author), Tech Univ Darmstadt, Hsch Str 10, D-64289 Darmstadt, Germany.
EM jochen.huber@acm.org; yun.ding@ribitwo.com
CR Ailon N., 2005, P 37 ANN ACM S THEOR, P684, DOI [DOI 10.1145/1060590.1060692, 10.1145/1060590.1060692]
   Alapetite A, 2010, PERS UBIQUIT COMPUT, V14, P45, DOI 10.1007/s00779-009-0228-5
   Amershi S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1647
   [Anonymous], P ACM INT C INT TABL
   Atterer R, 2007, P 11 INT C HUM COMP
   Bouchet J, 2004, P INT C MULT INT ICM
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cai D, 2003, LECT NOTES COMPUT SC, V2642, P406
   Chakrabarti D., 2008, INT C WORLD WIDE WEB, P377
   COLES A, 2003, P 12 INT C WORLD WID, P718
   Dahlhaus E., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P241, DOI 10.1145/129712.129736
   Ding Y, 2008, P 7 INT ACM C MOB UB, P8
   Fiduccia C. M., 1988, PAPERS 25 YEARS ELEC, P241
   Florins M, 2004, P 9 INT C INT US INT
   Greenberg S., 1999, Personal Technologies, V3, P54, DOI 10.1007/BF01305320
   Han R., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P221, DOI 10.1145/358916.358993
   Hattori G., 2007, PROC 16 INT C WORLD, P361, DOI DOI 10.1145/1242572.1242622
   Johanson B., 2002, IEEE Pervasive Computing, V1, P67, DOI 10.1109/MPRV.2002.1012339
   Johanson B., 2001, Proceedings of the 3rd International Conference on Ubiquitous Computing (Atlanta, Georgia, USA, September 30 - October 02, 2001), V2201, P346
   Kane SK, 2009, LECT NOTES COMPUT SC, V5726, P722, DOI 10.1007/978-3-642-03655-2_79
   Kleinberg J, 2002, J ACM, V49, P616, DOI 10.1145/585265.585268
   Maekawa T, 2005, P 16 INT WORKSH DAT
   Maekawa T, 2006, PERCOM 2006: FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P22
   Magerkurth C, 2002, P WORKSH COLL INT WA
   Myers BA, 2001, COMMUN ACM, V44, P34, DOI 10.1145/384150.384159
   Raghunath M, 2003, COMPUTER, V36, P56, DOI 10.1109/MC.2003.1231195
   Wiltse H, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1781
NR 27
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 209
EP 231
DI 10.1007/s11042-011-0980-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800010
DA 2024-07-18
ER

PT J
AU Neto, A
   Freitas, L
   Cerqueira, E
   Aguiar, R
   Gomes, D
AF Neto, Augusto
   Freitas, Leandro
   Cerqueira, Eduardo
   Aguiar, Rui
   Gomes, Danielo
TI QoS-RRC: an overprovisioning-centric and load balance-aided solution for
   future internet QoS-oriented routing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Future internet; QoS routing; QoE; Over-provisioning; Multimedia
AB The concepts and designs of 4WARD project for the Future Internet involve a clean-slate architecture with various networking innovations, including a new connectivity paradigm called Generic Path (GP). In GP architecture, several facilities are designed to efficiently support complex value-added applications and services with assured Quality of Service (QoS). The GP mainly makes transparent the underlying network structure and heterogeneity, and any entities, regardless of their purpose (technology, location or architectural layer) communicate with each other in a single way via a common interface. In addition, cooperation with network-layer provisioning mechanisms is required to map data paths that are compliant with session-demanded resources (QoS requirements - minimum bandwidth and maximum delay/loss experience) in appropriate GPs. In contrast, robust and scalable QoS-provisioning facilities are urgently required as a support for efficient GP allocations. To address this need, this paper introduces the QoS-Routing and Resource Control (QoS-RRC), a set of GP-compliant facilities to meet the requirements mentioned above. QoS-RRC complements GP architecture with QoS-oriented routing, with the aid of load balancing to select paths that comply with session-demands while keeping residual bandwidth to increase user experience. To address scalability issues, QoS-RRC operates on the basis of an overprovisioning-centric approach to achieve cost-effectiveness in terms of state storage, signaling load and network operations. An initial QoS-RRC performance evaluation was carried out in Network Simulator v.2 (NS-2), which showed that there had been drastic improvements in the flow delay experience and bandwidth use among a range of relevant state-of-the-art solutions. Moreover, the impact of QoS-RRC on the user experience (compared to current IP QoS and routing standards) has been evaluated, by analyzing the main objective and subjective Quality of Experience (QoE) metrics, namely Peak Signal to Noise Ratio (PSNR), The Structural Similarity Index (SSIM), Video Quality Metric (VQM) and Mean Opinion Score (MOS).
C1 [Neto, Augusto; Gomes, Danielo] Fed Univ Ceara UFC, Dept Teleinformat Engn DETI, Grp Comp Networks Software Engn & Syst GREat, BR-60755640 Fortaleza, Ceara, Brazil.
   [Freitas, Leandro] Univ Fed Goias, Inst Informat, BR-74001970 Goiania, Go, Brazil.
   [Cerqueira, Eduardo] Fed Univ Para, GERCOM EngComp PPGCC PPGEE, BR-66075110 Belem, Para, Brazil.
   [Neto, Augusto; Aguiar, Rui] Univ Aveiro, Inst Telecommun, P-3810193 Aveiro, Portugal.
C3 Universidade Federal do Ceara; Universidade Federal de Goias;
   Universidade Federal do Para; Instituto de Telecomunicacoes;
   Universidade de Aveiro
RP Neto, A (corresponding author), Fed Univ Ceara UFC, Dept Teleinformat Engn DETI, Grp Comp Networks Software Engn & Syst GREat, Campus Pici,Bloco 725, BR-60755640 Fortaleza, Ceara, Brazil.
EM augusto.deti@ufc.br; leandroaf@inf.ufg.br; cerqueira@ufpa.br;
   ruilaa@ua.pt; danielo@ufc.br
RI Venâncio Neto, Augusto José/O-3065-2015; Gomes, Diogo/E-9376-2010; G.
   Gomes, Danielo/H-9499-2012; Gomes, Diogo/AAB-8850-2020; Gomes, Danielo
   G./T-8389-2019; Aguiar, Rui L/B-5452-2009; Cerqueira,
   Eduardo/HPC-8703-2023
OI Venâncio Neto, Augusto José/0000-0002-9936-3770; Gomes,
   Diogo/0000-0002-5848-2802; G. Gomes, Danielo/0000-0002-8285-4629; Gomes,
   Diogo/0000-0002-5848-2802; Gomes, Danielo G./0000-0002-8285-4629;
   Aguiar, Rui L/0000-0003-0107-6253; Cerqueira,
   Eduardo/0000-0003-2162-6523
FU CNPq; REDE-TIC; FAPESPA
FX CNPq, REDE-TIC and FAPESPA supported Eduardo Cerqueira. CNPq also
   supported Augusto Neto.
CR [Anonymous], 1982, COMBINATORIAL OPTIMI
   [Anonymous], 2001, G1010 ITUT
   Apostopoulos G, P INFOCOM 99 NEW YOR, P199
   Braden R, 1998, 2309 IETF RFC
   Brades R, 1997, 4094 IETF RFC
   Correia LM, 2011, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-90-481-9346-2
   Figueiredo S, 2009, P 1 INT ICST C MOB N
   Gomes DG, 2007, COMPUT COMMUN, V30, P2236, DOI 10.1016/j.comcom.2007.05.005
   Kannan G, 2000, ADAPTIVE SELECTIVE F
   Manner J., 2005, 4094 IETF RFC
   Mu Mu, 2009, International Journal of Internet Protocol Technology, V4, P54, DOI 10.1504/IJIPT.2009.024170
   Neto A, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.453
   Neto A, 2009, European Patent Office, Patent No. [EP 2037636A1, 2037636]
   Neto A, 2009, European Patent Office, Patent No. [EP 2031796A1, 2031796]
   Neto A, 2008, 11 IFIP IEEE INT C M
   Porwal R, 2005, ADAPTIVE SELECTIVE F
   Rekhter Y, 2006, 4271 IERF RFC
NR 17
TC 2
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 721
EP 746
DI 10.1007/s11042-011-0931-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700011
DA 2024-07-18
ER

PT J
AU Jeong, HY
   Hong, BH
   Shrestha, B
   Cho, S
AF Jeong, Hwa-Young
   Hong, Bong-Hwa
   Shrestha, Bhanu
   Cho, Seongsoo
TI English course E-learning system based on relative item difficulty using
   web component composition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-learning system; SCORM; Item analysis; Web component; Relative item
   difficulty
ID EXPERIENCE
AB Many researches about e-learning system have been applied item difficulty to increase learning effectiveness. And development environment was changed the internet based learning media contents into the more various technology such as component, web 2.0, service oriented development and so on. Especially, service-oriented development is one of new trend in web based system and has become mainstream in software development. In the development, web components aims at providing support to service-oriented technique by enabling automatic discovery, composition, invocation and interoperation of the services. In this paper, we aimed the implementation of English e-learning system including the item guessing parameter and considering the relative correction of item difficulty. In the system, a learner was given to choose the learning step by the relative difficulty. In order to process and combine, all the learning contents are based on Sharable Content Object Reference Model (SCORM) with Learning Management System (LMS). Also, each learning contents are belong to Sharable Content Objects (SCOs).
C1 [Shrestha, Bhanu; Cho, Seongsoo] Kwangwoon Univ, Dept Elect Engn, Seoul 139701, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Dept Gen Educ, Seoul 130701, South Korea.
   [Hong, Bong-Hwa] Kyunghee Cyber Univ, Dept Informat Commun, Seoul 130701, South Korea.
C3 Kwangwoon University; Kyung Hee University
RP Cho, S (corresponding author), Kwangwoon Univ, Dept Elect Engn, Seoul 139701, South Korea.
EM hyjeong@khu.ac.kr; bhhong@khcu.ac.kr; bnu@kw.ac.kr; css@kw.ac.kr
RI Shrestha, Bhanu/ABB-8066-2021
OI Shrestha, Bhanu/0000-0002-2557-8699; Jeong,
   Hwa-Young/0000-0002-5017-934X
CR *ADV DISTR LEARN I, 2001, ADV DISTR LEARN SHAR
   Barr A, 2006, BULL TECH COMM LEARN, V8, P3
   Battle S, 2002, OMG WEB SERV WORKSH
   Benyon D, 1997, INT J HUM-COMPUT ST, V47, P197, DOI 10.1006/ijhc.1997.0126
   Birnbaum A., 1968, SOME LATENT TRAIT MO
   Chen CM, 2008, COMPUT EDUC, V51, P787, DOI 10.1016/j.compedu.2007.08.004
   Chen LH, 2010, COMPUT EDUC, V54, P1028, DOI 10.1016/j.compedu.2009.10.008
   David FD, 2006, IEEE COMPUTER SOC, P8
   Fei Yui-Ku, 2004, P 2004 IEEE INT C SE
   Frank Baker B, 2001, ERIC CLEARINGHOUSE A
   Iribarne L, 2004, COLOMBIAN J COMPUT, V5
   Jeong HY, 2006, LECT NOTES COMPUT SC, V4270, P318
   Liu YC, 2004, P IEEE INT C ADV LEA
   Mackenzie Gord, 2004, SCORM 2004 PRIMER MO
   Ozkan S, 2009, COMPUT EDUC, V53, P1285, DOI 10.1016/j.compedu.2009.06.011
   Perrin KM, 2000, ONLINE J DISTANCE LE, V13
   STAR Early Literacy and Item Difficulty, 2002, STAR EARLY LITERACY, P103
   Verbert K, 2005, P WORLD C ED MULT HY
   Windsor JA, 2008, AM J SURG, V195, P837, DOI 10.1016/j.amjsurg.2007.09.034
   Zeramdin K, 2004, 5 INT C INF TECHN BA
NR 20
TC 6
Z9 6
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 225
EP 241
DI 10.1007/s11042-010-0708-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000014
DA 2024-07-18
ER

PT J
AU Chiang, CC
   Wu, JW
   Lee, GC
AF Chiang, Cheng-Chieh
   Wu, Jia-Wei
   Lee, Greg C.
TI Probabilistic semantic component descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Probabilistic latent semantic analysis; Visual words; Semantic gap;
   Hidden concepts
ID IMAGE RETRIEVAL
AB This paper proposes the probabilistic semantic component descriptor (PSCD) for automatically extracting semantic information in a set of images. The basic idea of the PSCD is first to identify what kinds of hidden semantic concepts associated with regions in a set of images and then to construct an image-based descriptor by integrating hidden concepts of regions in an image. First, low-level features of regions in images are quantized into a set of visual words. Visual words for representing region features and high-level concepts hidden in images are linked together using the unsupervised method probabilistic latent semantic analysis. The linkage of visual words and images is built on the entire set of images, and hence a set of hidden concepts to describe each of the regions is extracted. Next, regions with unreliable concepts are eliminated, and then a PSCD for each image is constructed by propagating the probabilities of hidden concepts in the remaining regions of an image. We also present quantitative experiments to demonstrate the performance of our proposed PSCD.
C1 [Wu, Jia-Wei; Lee, Greg C.] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chiang, Cheng-Chieh] Takming Univ Sci & Technol, Dept Informat Technol, Taipei, Taiwan.
C3 National Taiwan Normal University; Takming University Science &
   Technology
RP Lee, GC (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM kevin@csie.ntnu.edu.tw; g696470148@csie.ntnu.edu.tw;
   leeg@csie.ntnu.edu.tw
FU National Science Council, Taiwan [NSC 98-2631-S-003-003]; Ministry of
   Economic Affairs, Taiwan [99-EC-17-A-02-S1-032]
FX This work was in part supported by National Science Council, Taiwan,
   under Grant No. NSC 98-2631-S-003-003 and by Ministry of Economic
   Affairs, Taiwan, under Grant No. 99-EC-17-A-02-S1-032.
CR [Anonymous], P WORKSH GEN MOD BAS
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2005, P INT C COMP VIS
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Duygulu P., 2002, P ECCV
   HOFMANN T, 1999, P ACM SIGIR
   Lavrenko V., 2001, P ACM SIGIR
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu D, 2006, P WORKSH PATCH CONJ
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mori Y., 1999, MISRM
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Rabinovich A., 2007, P INT C COMP VIS
   Schreer O, 2010, MULTIMED TOOLS APPL, V48, P23, DOI 10.1007/s11042-009-0375-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J, 2003, P INT C MULT EXP
   Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0
NR 24
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 629
EP 643
DI 10.1007/s11042-011-0726-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000011
DA 2024-07-18
ER

PT J
AU Kumar, P
   Roy, S
   Mittal, A
AF Kumar, Praveen
   Roy, Sujoy
   Mittal, Ankush
TI OS-Guard: on-site signature based framework for multimedia surveillance
   data management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed surveillance systems; Multimedia mining; Reservoir sampling;
   Feature extraction; Selection
ID EVENT DETECTION; RECOGNITION
AB This paper presents OS-Guard(On-Site Guard), a novel on-site signature based framework for multimedia surveillance data management. One of the major concerns in widespread deployment of multimedia surveillance systems is the enormous amount of data collected from multiple media streams that need to be communicated, observed and stored for crime alerts and forensic analysis. This necessitates investigating efficient data management techniques to solve this problem. This work aims to tackle this problem, motivated by the following observation, more data does not mean more information. OS-Guard is a novel framework that attempts to collect informative data and filter out non-informative data on-site, thus taking a step towards solving the data management problem. In the framework, both audio and video cues are utilized by extracting features from the incoming data stream and the resultant real valued feature data is binarized for efficient storage and processing. A feature selection process based on association rule mining selects discriminant features. A short representative sample of the whole database is generated using a novel reservoir sampling algorithm that is stored onsite and used with an support vector machine to classify an important event. Initial experiments for a Bank ATM monitoring scenario demonstrates promising results.
C1 [Kumar, Praveen] Gokaraju Rangaraju Inst Engn Coll, Hyderabad, Andhra Pradesh, India.
   [Roy, Sujoy] Inst Infocomm Res, Singapore 138632, Singapore.
   [Mittal, Ankush] Coll Engn, Roorkee, Uttar Pradesh, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; Agency for
   Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm
   Research (I2R)
RP Kumar, P (corresponding author), Gokaraju Rangaraju Inst Engn Coll, Hyderabad, Andhra Pradesh, India.
EM praveen.kverma@gmail.com; sujoy@i2r.a-star.edu.sg;
   Dr.ankush.mittal@gmail.com
RI Kumar, Praveen/AAA-8584-2022
OI Kumar, Praveen/0000-0003-4820-3088
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Ali W, 2010, 7 IEEE INT C ADV VID, P555
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boiman O, 2005, P IEEE INT C COMP VI, P1985
   Borgelt C., 2010, Apriori - Association Rule Induction / Frequent Item Set Mining
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen M, 2006, IEEE SIGNAL PROC MAG, V23, P38, DOI 10.1109/MSP.2006.1621447
   COLLINS RT, 2000, CMURITR0012 CARN MEL
   Cowling M, 2003, PATTERN RECOGN LETT, V24, P2895, DOI 10.1016/S0167-8655(03)00147-8
   Fayolle J, 1998, IEEE T SIGNAL PROCES, V46, P1174, DOI 10.1109/78.668571
   Ganchev T., 2005, 10th International Conference on Speech and Computer (SPECOM 2005), V1, P191
   Gonzalez R, 2007, P 9 BIENN C AUSTR PA, P61, DOI DOI 10.1109/DICTA.2007.4426776
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kieran Declan, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P97, DOI 10.1109/AVSS.2010.57
   Leo M, 2004, LECT NOTES COMPUT SC, V3332, P1019
   Marple SL., 1987, Digital spectral analysis with applications
   Mittal A, 2003, MULTIMED TOOLS APPL, V20, P135, DOI 10.1023/A:1023627404478
   Niu W, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1144
   Oh J. H., 2002, P 3 INT WORKSH MULT, P1
   Radhakrishnan R, 2005, IEEE WORK APPL SIG, P158, DOI 10.1109/ASPAA.2005.1540194
   Spackman K.A., 1989, P 6 INT WORKSH MACH, P160, DOI DOI 10.1016/B978-1-55860-036-2.50047-3
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stringa E, 2000, IEEE T IMAGE PROCESS, V9, P69, DOI 10.1109/83.817599
   Tax DMJ, 2003, 2003 IEEE XIII WORKSHOP ON NEURAL NETWORKS FOR SIGNAL PROCESSING - NNSP'03, P499, DOI 10.1109/NNSP.2003.1318049
   Tziakos I., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P519, DOI 10.1109/AVSS.2010.70
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Wijesekera D., 2000, P INT WORKSH MULT DA, P98
   Xiong Z, 2003, COMP MFCC MPEG 7 AUD, P397
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 32
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 363
EP 382
DI 10.1007/s11042-010-0693-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800017
DA 2024-07-18
ER

PT J
AU Pogorelc, B
   Vatavu, RD
   Lugmayr, A
   Stockleben, B
   Risse, T
   Kaario, J
   Lomonaco, EC
   Gams, M
AF Pogorelc, Bogdan
   Vatavu, Radu-Daniel
   Lugmayr, Artur
   Stockleben, Bjoern
   Risse, Thomas
   Kaario, Juha
   Lomonaco, Estefania Constanza
   Gams, Matjaz
TI Semantic ambient media: From ambient advertising to ambient-assisted
   living
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient media; Ubiquitous media; Pervasive computation; Ubiquitous
   computation; Ambient computation; Artificial intelligence; Machine
   learning; Data mining; Context awareness; Semantics; Ambient-assisted
   living; Art
AB The term ambient media was in its beginning used only for ambient advertising. Nowadays it denotes the media environment and the communication of information in ubiquitous and pervasive environments. With the addition of intelligence, the new field of semantic ambient media was established. In recent years, the field of semantic ambient media has spread its span from only a few sub-areas, such as ambient advertising, to new ones, such as ambient-assisted living (AAL) and health-monitoring media, significantly supported by intelligence. The study presented in this paper provides an advanced introduction to the field of semantic ambient media including the solutions for threat issues and illustration of success stories of the field. It conducts a survey of the related work and presents a thorough discussion of it. The related work is grouped according to the coverage of the principles of semantic ambient media. Based on the state-of-the-art research, the future possibilities of the field are demonstrated, especially for the ambient-assisted living, audio-visual rendering of media objects, user design principles and the society impact of the field. The paper provides ideas for impacting ambient media and directions and questions for further research. It also discusses the potential of the combination of several research studies.
C1 [Pogorelc, Bogdan; Gams, Matjaz] Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana, Slovenia.
   [Pogorelc, Bogdan; Gams, Matjaz] Spica Int Doo, Ljubljana, Slovenia.
   [Vatavu, Radu-Daniel] Univ Stefan Cel Mare Suceava, Res Ctr Comp Sci, Suceava, Romania.
   [Lugmayr, Artur] Tampere Univ Technol, EMMi Lab, Dept Business Informat Management & Logist, EMMi Entertainment & Media Prod Management, FIN-33101 Tampere, Finland.
   [Stockleben, Bjoern] Univ Appl Sci Magdeburg, Magdeburg, Germany.
   [Risse, Thomas] L3S Res Ctr, Hannover, Germany.
   [Kaario, Juha] Varaani Works Oy, Business Dev, Tampere, Finland.
   [Lomonaco, Estefania Constanza] Univ Nova Gorica, Grad Sch, Nova Gorica, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute;
   Stefan cel Mare University of Suceava; Tampere University; Leibniz
   University Hannover; University of Nova Gorica
RP Pogorelc, B (corresponding author), Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana, Slovenia.
EM bogdan.pogorelc@ijs.si; vatavu@eed.usv.ro; lartur@acm.org;
   bjoern.stockleben@gmx.de; risse@l3s.de; Juha.kaario@varaani.com;
   estefanialomonaco@gmail.com; matjaz.gams@ijs.si
RI Vatavu, Radu-Daniel/AAA-3282-2022; Lugmayr, Artur/AAY-7738-2020;
   Lugmayr, Artur/G-4357-2014; Vatavu, Radu-Daniel/F-1820-2017
OI Lugmayr, Artur/0000-0001-6994-4470; Vatavu,
   Radu-Daniel/0000-0002-7631-6445; Risse, Thomas/0000-0001-6248-1709
FU European Union; European Social Fund; CHIRON; ARTEMIS [2009-1-100228];
   project "Progress and development through post-doctoral research and
   innovation in engineering and applied sciences- PRiDE
   [POSDRU/89/1.5/S/57083]; European Social Fund through Sectorial
   Operational Program Human Resources
FX This work was partly financed by the European Union, European Social
   Fund, and partly by the CHIRON project (Cyclic and person-centric Health
   management: Integrated appRoach for hOme, mobile and clinical
   eNvironments), co-funded by the ARTEMIS Joint Undertaking (grant
   agreement # 2009-1-100228) and by national authorities. Radu-Daniel
   Vatavu acknowledges support from the project "Progress and development
   through post-doctoral research and innovation in engineering and applied
   sciences- PRiDE - Contract no. POSDRU/89/1.5/S/57083", project co-funded
   from European Social Fund through Sectorial Operational Program Human
   Resources 2007-2013.
CR Ambient assisted living, 2011, AMB ASS LIV
   [Anonymous], 2008, Being Human: Human-Computer Interaction in the year 2020
   Augusto JC, 2010, HANDBOOK OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS, P3, DOI 10.1007/978-0-387-93808-0_1
   Baik S, 2012, MULTIMED TOOLS APPL, V58, P427, DOI 10.1007/s11042-010-0686-9
   Barnes J, 1999, ADMAP, V34, P46
   Chang Angela, 2001, CHI'01 extended abstracts on Human factors in computing systems, P313, DOI DOI 10.1145/634067.634252
   Chung Hyemin., 2006, Proceeding of CHI '06 Extended Abstracts on Human Factors in Computing Systems-CHI EA '06, P375, DOI [10.1145/1125451.1125532, DOI 10.1145/1125451.1125532]
   Codognet P, 2012, MULTIMED TOOLS APPL, V58, P355, DOI 10.1007/s11042-010-0666-0
   Dietz P., 2009, TEI '09 Proceedings of the 3rd International Conference on Tangible and Embedded Interaction, P249, DOI [10.1145/1517664.1517717, DOI 10.1145/1517664.1517717]
   Dovgan E, 2011, ZDR VESTN, V80, P824
   Forster F, 2009, P AMI, P177
   Gilroy SW, 2009, P AMI, P189
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Kononenko I, 2007, TEXTBOOK
   Li AX, 2009, P AMI, P165
   Lugmayr A, 2008, P MM, P1143
   Lugmayr A, 2009, P AMI, P161
   Lugmayr A, 2007, ADJ P EUROITV 2007
   Lugmayr A, 2009, P AMI, P197
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P385, DOI 10.1007/s11042-010-0671-3
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P331, DOI 10.1007/s11042-009-0283-y
   Lugmayr A, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, P516, DOI 10.1109/ISPA.2008.141
   Mujacic S, 2012, MULTIMED TOOLS APPL, V58, P435, DOI 10.1007/s11042-010-0665-1
   Norman D.A., 2007, EMOTIONAL DESIGN WHY
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Scherp A, 2012, MULTIMED TOOLS APPL, V58, P293, DOI 10.1007/s11042-010-0667-z
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V58, P371, DOI 10.1007/s11042-010-0674-0
NR 28
TC 17
Z9 18
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 399
EP 425
DI 10.1007/s11042-011-0917-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500007
DA 2024-07-18
ER

PT J
AU Yang, CK
   Tsai, CY
AF Yang, Chuan-Kai
   Tsai, Ching-Yang
TI Fast architecture prototyping through 3D collage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D collage; Automatic alignment; Mesh segmentation
ID TEXTURE SYNTHESIS; MESH COMPOSITION; MODELS
AB In this paper, we propose a new framework for architecture prototyping via the concept of 3D collage, that is, a combination of geometrically transformed components segmented from multiple source architectures. In short, our proposed framework makes its contribution by featuring three desired functionalities as follows. First, during the construction process, two components can be snapped together through the most matched faces. Second, deformation can be performed arbitrarily on any face of the resulting mesh. Third, the assignment of color and texture attributes on the resulting mesh is intuitively and flexibly done in a user-friendly manner. By enjoying a simpler user interface, our system strikes a good balance between efficiency and expressiveness, thus making it particularly appropriate for the purpose of rapid architecture prototyping. Results are shown to demonstrate that our framework is not only good at simulating a wide variety of existing architectures, but also capable of creating even avant-garde architectural styles.
C1 [Yang, Chuan-Kai; Tsai, Ching-Yang] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM ckyang@cs.ntust.edu.tw
CR [Anonymous], THEORY COMPUTING SYS
   [Anonymous], SIGGRAPH 86
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cabral M, 2009, COMPUT GRAPH FORUM, V28, P469, DOI 10.1111/j.1467-8659.2009.01386.x
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Ehrig H., 1999, HDB GRAPH GRAMMARS C
   Foley J.D., 1990, Computer graphics: Principles and practice
   Funkhouser T, 2004, SIGGRAPH 2004
   Huang X., 2007, PROC SPM 07, P35
   Jin XG, 2006, VISUAL COMPUT, V22, P266, DOI 10.1007/s00371-006-0004-8
   Lin JC, 2008, IEEE T VIS COMPUT GR, V14, P653, DOI 10.1109/TVCG.2007.70632
   Lipp M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360701
   Merrell P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409111
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Paul M, 2007, I3D 2007
   Piegl L, 1995, NURB BOOK
   Sharf A, 2006, VISUAL COMPUT, V22, P835, DOI 10.1007/s00371-006-0068-5
   Sipser M., 1996, Introduction to the Theory of Computation, V1
   Stiny G., 1975, Pictorial and Formal Aspects of Shape and Shape Grammars, Interdisciplinary Systems Research
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wonka P, 2003, ACM T GRAPHIC, V22, P669, DOI 10.1145/882262.882324
   Xiao JX, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409114
NR 28
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 527
EP 547
DI 10.1007/s11042-010-0654-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900004
DA 2024-07-18
ER

PT J
AU Bhat, V
   Sengupta, I
   Das, A
AF Bhat K, Vivekananda
   Sengupta, Indranil
   Das, Abhijit
TI An audio watermarking scheme using singular value decomposition and
   dither-modulation quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Dither-modulation (DM); Quantization index
   modulation (QIM); Singular value decomposition (SVD)
ID TIME-SCALE MODIFICATION; ROBUST
AB Quantization index modulation is one of the best methods for performing blind watermarking, due to its simplicity and good rate-distortion-robustness trade-offs. In this paper, a new audio watermarking algorithm based on singular value decomposition and dither-modulation quantization is presented. The watermark is embedded using dither-modulation quantization of the singular values of the blocks of the host audio signal. The watermark can be blindly extracted without the knowledge of the original audio signal. Subjective and objective tests confirm high imperceptibility achieved by the proposed scheme. Moreover, the scheme is quite robust against attacks including additive white Gaussian noise, MP3 compression, resampling, low-pass filtering, requantization, cropping, echo addition and denoising. The watermark data payload of the algorithm is 196 bps. Performance analysis of the proposed scheme shows low error probability rates.
C1 [Bhat K, Vivekananda; Sengupta, Indranil; Das, Abhijit] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Bhat, V (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM vbk@cse.iitkgp.ernet.in; isg@cse.iitkgp.ernet.in;
   abhij@cse.iitkgp.ernet.in
RI bhat, vivekanand/R-9967-2019; Das, Abhijit/H-1974-2013
OI bhat, vivekanand/0000-0003-3411-9221; 
CR [Anonymous], 2000, Digital Watermarking
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Christian N, 1998, P 105 AES CONV
   Chang CY, 2006, IEEE SYS MAN CYBERN, P1214, DOI 10.1109/ICSMC.2006.384880
   Cox IJ., 2007, DIGITAL WATERMARKING
   Cvejic N., 2007, INFORM SCI REFERENCE
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   KEILER F, 2006, P 120 AES CONV
   Lerch A., 2002, ZPLANE DEV EAQUAL EV
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Wang RD, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2393
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
NR 18
TC 67
Z9 71
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 369
EP 383
DI 10.1007/s11042-010-0515-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000008
DA 2024-07-18
ER

PT J
AU Seo, D
   Jung, I
AF Seo, Dongmahn
   Jung, Inbum
TI Network-adaptive autonomic transcoding algorithm for seamless streaming
   media service of mobile clients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transcoding; Mobile client; Wireless; Network adaptive QoS; Streaming;
   Bit-rate
AB As a result of improvements in wireless communication technologies, a multimedia data streaming service can now be provided for mobile clients. Since mobile devices have low computing power and work on a low network bandwidth, a transcoding technology is needed to adapt the original streaming media for mobile environments. However, wireless networks have variable bandwidths depending on the movement of clients and the communication distance from Access Point (AP). These characteristics make it hard to support stable Quality of Service (QoS) streams for mobile clients. In this paper, a target transcoding bit-rate decision algorithm is proposed to provide stable QoS streams for mobile clients. In our experiments, the proposed algorithm provides seamless streaming media services based on the network adaptive bit rate control and reduces transmission failure.
C1 [Seo, Dongmahn; Jung, Inbum] Kangwon Natl Univ, Dept Comp Engn, Chunchon, Gangwon, South Korea.
C3 Kangwon National University
RP Jung, I (corresponding author), Kangwon Natl Univ, Dept Comp Engn, Chunchon, Gangwon, South Korea.
EM sarum@kangwon.ac.kr; ibjung@kangwon.ac.kr
RI An, Ke/JPX-5153-2023; Seo, Dongmahn/E-7438-2017
OI An, Ke/0009-0008-3642-8881; Seo, Dongmahn/0000-0002-1069-4232
FU Korean Government (MOEHRD) [KRF-2008-D00424(I00901)]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MOEHRD, Basic Research Promotion Fund)
   (KRF-2008-D00424(I00901)).
CR BHRADVAJ H, 1998, P INT C REL DISTR SY, P118
   Chakareski J, 2007, IEEE COMMUN MAG, V45, P77, DOI 10.1109/MCOM.2007.284541
   Chandra S., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P961, DOI 10.1109/INFCOM.2000.832271
   Cho S, 2003, LECT NOTES COMPUT SC, V2662, P171
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   DU DHC, 1999, P IEEE INT C MULT CO, P191
   FENG WC, 2000, P 20 INT C DISTR COM, P201
   FOROUZAN BA, 2001, DATA COMMUNICATIONS
   HU N, 2002, CMUCS02116
   Hu NN, 2003, IEEE J SEL AREA COMM, V21, P879, DOI 10.1109/JSAC.2003.814505
   Kohler E, 2006, ACM SIGCOMM COMP COM, V36, P27, DOI 10.1145/1151659.1159918
   Kurose J.F., 2004, COMPUTER NETWORKING, V3rd
   Padhye J., 1999, NOSSDAV99
   Roy S, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P408
   Seo D, 2007, J SYST ARCHITECT, V53, P39, DOI 10.1016/j.sysarc.2006.07.003
   Seo D, 2006, LECT NOTES COMPUT SC, V3983, P1156
   SITARAM D., 2000, Multimedia servers: applications, environments, and design
   Vetro A, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P607, DOI 10.1109/CCECE.2001.933753
   WEE S, 2003, P IEEE ICME, P5
NR 19
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 897
EP 912
DI 10.1007/s11042-009-0421-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100003
DA 2024-07-18
ER

PT J
AU Marques, O
   Barenholtz, E
   Charvillat, V
AF Marques, Oge
   Barenholtz, Elan
   Charvillat, Vincent
TI Context modeling in computer vision: techniques, implications, and
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Object recognition; Objects in context; Context
   modeling
ID GLOBAL FEATURES; SPATIAL CONTEXT; OBJECT; SCENE; REPRESENTATION;
   RECOGNITION; RETRIEVAL; ATTENTION; FOREST; SHAPE
AB In recent years there has been a surge of interest in context modeling for numerous applications in computer vision. The basic motivation behind these diverse efforts is generally the same-attempting to enhance current image analysis technologies by incorporating information from outside the target object, including scene analysis as well as metadata. However, many different approaches and applications have been proposed, leading to a somewhat inchoate literature that can be difficult to navigate. The current paper provides a 'roadmap' of this new research, including a discussion of the basic motivation behind context-modeling, an overview of the most representative techniques, and a discussion of specific applications in which contextual modeling has been incorporated. This review is intended to introduce researchers in computer vision and image analysis to this increasingly important field as well as provide a reference for those who may wish to incorporate context modeling in their own work.
C1 [Marques, Oge; Barenholtz, Elan] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
   [Charvillat, Vincent] ENSEEIHT, F-31000 Toulouse, France.
C3 State University System of Florida; Florida Atlantic University;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de
   Toulouse; Institut National Polytechnique de Toulouse
RP Marques, O (corresponding author), Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM omarques@fau.edu; elan.barenholtz@fau.edu;
   vincent.charvillat@enseeiht.fr
RI Marques, Oge/I-4933-2014
OI Marques, Oge/0000-0003-4321-2719
FU Division Of Behavioral and Cognitive Sci; Direct For Social, Behav &
   Economic Scie [0958615] Funding Source: National Science Foundation
CR Alvarez GA, 2008, PSYCHOL SCI, V19, P392, DOI 10.1111/j.1467-9280.2008.02098.x
   Amores J, 2005, PATTERN RECOGN LETT, V26, P1720, DOI 10.1016/j.patrec.2004.12.007
   Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   [Anonymous], P W JOINT COMP C IEE
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2005, 2005 IEEE COMP SOC C, DOI [10.1109/CVPR.2005.470, DOI 10.1109/CVPR.2005.470]
   [Anonymous], PERCEPT PSYCHOPHYS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2008.4587799, DOI 10.1109/CVPR.2008.4587799]
   [Anonymous], 1973, IJCAI
   [Anonymous], RADIUS IMAGE UNDERST
   [Anonymous], COMP VIS PATT REC PR
   [Anonymous], 2010, ECCV
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], J EXP PSYCHOL HUM PE
   Ariely D, 2001, PSYCHOL SCI, V12, P157, DOI 10.1111/1467-9280.00327
   Auckland ME, 2007, PSYCHON B REV, V14, P332, DOI 10.3758/BF03194073
   Bar M, 2003, NEURON, V38, P347, DOI 10.1016/S0896-6273(03)00167-3
   Bar M, 1996, PERCEPTION, V25, P343, DOI 10.1068/p250343
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Barenholtz E., 2009, J VISION, V9, P800, DOI [DOI 10.1167/9.8.800, 10.1167/9.8.800]
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   BIEDERMAN I, 1974, J EXP PSYCHOL, V103, P597, DOI 10.1037/h0037158
   Brockmole JR, 2006, J EXP PSYCHOL LEARN, V32, P699, DOI 10.1037/0278-7393.32.4.699
   Brockmole JR, 2008, Q J EXP PSYCHOL, V61, P1886, DOI 10.1080/17470210701781155
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Chong SC, 2005, VISION RES, V45, P891, DOI 10.1016/j.visres.2004.10.004
   Chong SC, 2005, PERCEPT PSYCHOPHYS, V67, P1, DOI 10.3758/BF03195009
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Chun MM, 1999, PSYCHOL SCI, V10, P360, DOI 10.1111/1467-9280.00168
   Cox D, 2004, SCIENCE, V304, P115, DOI 10.1126/science.1093110
   Davenport JL, 2004, PSYCHOL SCI, V15, P559, DOI 10.1111/j.0956-7976.2004.00719.x
   DEGRAEF P, 1992, CAN J PSYCHOL, V46, P489, DOI 10.1037/h0084324
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Endo N, 2005, PSYCHON B REV, V12, P880, DOI 10.3758/BF03196780
   Epstein R, 1999, NEURON, V23, P115, DOI 10.1016/S0896-6273(00)80758-8
   Epstein R, 1998, NATURE, V392, P598, DOI 10.1038/33402
   Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Fink M., 2003, Advances in neural information processing systems
   Fischler M., 1989, Proc. DARPA Image Understanding Workshop, P774
   Forsyth DavidA., 1996, Finding pictures of objects in large collections of images
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Goujon A, 2007, VIS COGN, V15, P257, DOI 10.1080/13506280600677744
   Goujon A, 2009, J EXP PSYCHOL HUMAN, V35, P50, DOI 10.1037/0096-1523.35.1.50
   Greene MR, 2009, COGNITIVE PSYCHOL, V58, P137, DOI 10.1016/j.cogpsych.2008.06.001
   Gronau N, 2008, J COGNITIVE NEUROSCI, V20, P371, DOI 10.1162/jocn.2008.20.3.371
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Henderson JM, 1999, ANNU REV PSYCHOL, V50, P243, DOI 10.1146/annurev.psych.50.1.243
   HOCK HS, 1974, PERCEPT PSYCHOPHYS, V16, P4, DOI 10.3758/BF03203242
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hoiem D., 2008, Proceedings of CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587587
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hollingworth A, 1998, J EXP PSYCHOL GEN, V127, P398, DOI 10.1037/0096-3445.127.4.398
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Joshi D., 2008, P INT C CONTENT BASE, P37
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kumar MP, 2005, PROC CVPR IEEE, P18
   Kumar S, 2005, IEEE I CONF COMP VIS, P1284
   Kunar MA, 2007, J EXP PSYCHOL HUMAN, V33, P816, DOI 10.1037/0096-1523.33.4.816
   Luo J., 2008, ACM International Conference on Multimedia, P1071, DOI DOI 10.1145/1459359.1459574MULTIMEDIA-MM'PLACE
   Marr D., 1982, Vision
   MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   O'Hare N, 2006, LECT NOTES COMPUT SC, V4071, P529
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Opelt Andreas., 2006, IEEE COMPUTER SOC C, V1, P3
   PALMER SE, 1975, MEM COGNITION, V3, P519, DOI 10.3758/BF03197524
   Peissig JJ, 2007, ANNU REV PSYCHOL, V58, P75, DOI 10.1146/annurev.psych.58.102904.190114
   Perko R, 2010, COMPUT VIS IMAGE UND, V114, P700, DOI 10.1016/j.cviu.2010.03.005
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POTTER MC, 1976, J EXP PSYCHOL-HUM L, V2, P509, DOI 10.1037/0278-7393.2.5.509
   POTTER MC, 1975, NATURE, V253, P437, DOI 10.1038/253437a0
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Rabinovich A, 2009, PROC CVPR IEEE, P913
   Rieger JW, 2008, J EXP PSYCHOL HUMAN, V34, P56, DOI 10.1037/0096-1523.34.1.56
   Russell B., 2007, Annu. Conf. Neural Inform. Process. Syst. NIPS, P1241
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   SCHYNS PG, 1994, PSYCHOL SCI, V5, P195, DOI 10.1111/j.1467-9280.1994.tb00500.x
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stein A, 2007, IEEE I CONF COMP VIS, P110
   Strat T., 1990, Proc. DARPA Image Understanding Workshop, P456
   Strat T. M., 1989, Conference Record. Twenty-Third Asilomar Conference on Signals, Systems ands Computers (IEEE Cat. No.89-CH2836-5), P532
   Strat T.M., 1993, DARPA, V93, P217
   Strat T.M., 1992, Natural Object Recognition
   STRAT TM, 1991, IEEE T PATTERN ANAL, V13, P1050, DOI 10.1109/34.99238
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   Torralba A, 2010, COMMUN ACM, V53, P107, DOI 10.1145/1666420.1666446
   Torralba A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P763, DOI 10.1109/ICCV.2001.937604
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Torralba Antonio., 2004, ADV NEURAL INFORM PR, P1401
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang Y.H., 2008, ACM International Conference on Multimedia (MM), P199
   Yang Y, 2010, PROC CVPR IEEE, P3113, DOI 10.1109/CVPR.2010.5540070
   YANTIS S, 1990, J EXP PSYCHOL HUMAN, V16, P121, DOI 10.1037/0096-1523.16.1.121
   YANTIS S, 1993, J EXP PSYCHOL HUMAN, V19, P676, DOI 10.1037/0096-1523.19.3.676
   Zheng WS, 2009, IEEE I CONF COMP VIS, P932, DOI 10.1109/ICCV.2009.5459344
NR 128
TC 22
Z9 27
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 303
EP 339
DI 10.1007/s11042-010-0631-y
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800012
DA 2024-07-18
ER

PT J
AU Ntalianis, KS
   Doulamis, AD
   Tsapatsoulis, N
   Doulamis, N
AF Ntalianis, Klimis S.
   Doulamis, Anastasios D.
   Tsapatsoulis, Nicolas
   Doulamis, Nikolaos
TI Human action annotation, modeling and analysis based on implicit user
   interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action analysis; User transparent interaction; Human object
   detection; Action modeling; Video annotation
ID CONCEPT ONTOLOGY; IMAGE; RETRIEVAL
AB This paper proposes an integrated framework for analyzing human actions in video streams. Despite most current approaches that are just based on automatic spatiotemporal analysis of sequences, the proposed method introduces the implicit user-in-the-loop concept for dynamically mining semantics and annotating video streams. This work sets a new and ambitious goal: to recognize, model and properly use "average user's" selections, preferences and perception, for dynamically extracting content semantics. The proposed approach is expected to add significant value to hundreds of billions of non-annotated or inadequately annotated video streams existing in the Web, file servers, databases etc. Furthermore expert annotators can gain important knowledge relevant to user preferences, selections, styles of searching and perception.
C1 [Ntalianis, Klimis S.; Doulamis, Nikolaos] Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece.
   [Doulamis, Anastasios D.] Tech Univ Crete, Dept Prod Engn & Management, Khania 73100, Greece.
   [Tsapatsoulis, Nicolas] Cyprus Univ Technol, Dept Commun & Internet Studies, CY-3603 Limassol, Cyprus.
C3 National Technical University of Athens; Technical University of Crete;
   Cyprus University of Technology
RP Ntalianis, KS (corresponding author), Natl Tech Univ Athens, Dept Elect & Comp Engn, 9 Heroon Polytech Str, GR-15773 Athens, Greece.
EM kntal@image.ntua.gr; adoulam@cs.ntua.gr; nicolas.tsapatsoulis@cut.ac.cy;
   ndoulam@cs.ntua.gr
RI TSAPATSOULIS, NICOLAS/E-4146-2016; Cataldi, Antonio/AAM-7411-2021;
   Doulamis, Anastasios/AAL-5972-2021
OI TSAPATSOULIS, NICOLAS/0000-0002-6739-8602; 
FU Research Promotion Foundation (RPF) of the Republic of Cyprus
FX This research was performed in the framework of the PSIFIORIKSI project
   (Audiovisual Content Digitisation and Multimedia Metadata Extraction,
   Authoring and Storing based on MPEG-7), funded by the Research Promotion
   Foundation (RPF) of the Republic of Cyprus.
CR [Anonymous], 5 INT S COMM SYST NE
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   Bagdanov AD, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P713, DOI 10.1109/ICSC.2007.30
   Bertini M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1429
   BHATTACHARYA A, 2005, P 5 IEEE INT C DAT M
   *COMSCORES, COMSCORES QSEARCH 2
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Doulamis AD, 2000, IEEE T CONSUM ELECTR, V46, P758, DOI 10.1109/30.883444
   Doulamis AD, 2000, IEEE T NEURAL NETWOR, V11, P137, DOI 10.1109/72.822517
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Fan J, 2007, IEEE T MULTIMEDIA, V9, P939, DOI 10.1109/TMM.2007.900143
   GAO S, 2006, P IEEE INT C AC SPEE, V2, pR2
   Harit G, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P211, DOI 10.1109/WI.2006.183
   Haykin S., 1994, NEURAL NETWORKS COMP
   Haykin S.O., 1996, Adaptive Filter Theory, V4th
   Jansen BJ, 2000, INFORM PROCESS MANAG, V36, P207, DOI 10.1016/S0306-4573(99)00056-4
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Kolda T. G., 2008, P 8 IEEE INT C DAT M
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   NESVADBA J, 2007, 8 IEEE INT WORKSH IM
   Petridis K, 2004, P 2004 EUR WORKSH IN, P33
   PETRIDIS S, 2006, P 1 INT C SEM DIG ME
   Rapantzikos K, 2007, IET IMAGE PROCESS, V1, P237, DOI 10.1049/iet-ipr:20060040
   RAPANTZIKOS K, 2005, P 2005 INT C IM P, V2, P1298
   SCHULDT C, 2004, P ICPR 04 CAMBR UK
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stevenson K, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1195
   Tsapatsoulis N, 2001, PATTERN ANAL APPL, V4, P93, DOI 10.1007/PL00014577
   Tsapatsoulis N, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P92, DOI 10.1109/SMAP.2007.49
   Tseng VS, 2008, IEEE T MULTIMEDIA, V10, P260, DOI 10.1109/TMM.2007.911832
   VASILESCU MAO, 2004, P ACM SIGGRAPH 2004, P334
   Xu BW, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P329, DOI 10.1109/CW.2004.24
   SEO WEEKLY ARTICLE
NR 38
TC 10
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 199
EP 225
DI 10.1007/s11042-009-0369-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900010
DA 2024-07-18
ER

PT J
AU Roth, D
   Koller-Meier, E
   Van Gool, L
AF Roth, Daniel
   Koller-Meier, Esther
   Van Gool, Luc
TI Multi-object tracking evaluated on sparse events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking; Event detection; Performance evaluation; Real-time
ID MOTION; SURVEILLANCE
AB This article presents a visual object tracking method and applies an event-based performance evaluation metric for assessment. The proposed monocular object tracker is able to detect and track multiple object classes in non-controlled environments. The tracking framework uses Bayesian per-pixel classification to segment an image into foreground and background objects, based on observations of object appearances and motions in real-time. Furthermore, a performance evaluation method is presented and applied to different state-of-the-art trackers based on successful detections of semantically high level events. These events are extracted automatically from the different trackers an their varying types of low level tracking results. Then, a general new event metric is used to compare our tracking method with the other tracking methods against ground truth of multiple public datasets.
C1 [Roth, Daniel; Koller-Meier, Esther; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Roth, D (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.
EM droth@vision.ee.ethz.ch; ebmeier@vision.ee.ethz.ch;
   vangool@vision.ee.ethz.ch
FU Swiss SNF NCCR [IM2]; EU [FP6-027110]
FX The authors gratefully acknowledge support by the Swiss SNF NCCR project
   IM2 and EU project HERMES (FP6-027110). Furthermore, we would like to
   thank Prof. Dr. Thomas Moeslund from the University of Aalborg, Denmark
   and Dr. Jordi Gonzalez from the CVC Center in Barcelona, Spain for their
   tracking results and valuable input.
CR AGUILERA J, 2005, IEEE INT WORKSH VS P, P293
   BASHIR F, 2006, IEEE INT WORKSH PETS, V5, P7
   Comaniciu D., 2000, CVPR
   DUIZER P, 2007, THESIS AALBORG U DEN
   GONZLEZ J, 2007, COMPUTATIONAL VISION
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Lanz O, 2006, IEEE T PATTERN ANAL, V28, P1436, DOI 10.1109/TPAMI.2006.177
   LEIBE B, 2007, INT C COMP VIS ICCV
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K., 2004, A Boosted Particle Filter
   ROTH D, 2008, IEEE WORKSH MOT VID
   ROTH D, 2005, MOTION, P78
   ROWE D, 2006, LECT NOTES COMPUT SC, P505
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   WU B, 2006, CVPR, P951
   YOUNG D, 2005, P 2 JOINT IEEE INT W, P15
   ZHAO T, 2005, COMPUTER VISION PATT, P976
   CENTRAL PEDESTRIAN C
   ETISEO VIDEO UNDERST
NR 23
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 29
EP 47
DI 10.1007/s11042-009-0365-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900003
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, HY
   Schaefer, G
   Liu, TW
   Lin, FQ
AF Zhou, Huiyu
   Schaefer, Gerald
   Liu, Tangwei
   Lin, Faquan
TI Segmentation of optic disc in retinal images using an improved gradient
   vector flow algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal image analysis; Optic disc; Segmentation; Gradient vector flow
ID VESSEL SEGMENTATION
AB Image segmentation plays an important role in the analysis of retinal images as the extraction of the optic disk provides important cues for accurate diagnosis of various retinopathic diseases. In recent years, gradient vector flow (GVF) based algorithms have been used successfully to successfully segment a variety of medical imagery. However, due to the compromise of internal and external energy forces within the resulting partial differential equations, these methods can lead to less accurate segmentation results in certain cases. In this paper, we propose the use of a new mean shift-based GVF segmentation algorithm that drives the internal/external energies towards the correct direction. The proposed method incorporates a mean shift operation within the standard GVF cost function to arrive at a more accurate segmentation. Experimental results on a large dataset of retinal images demonstrate that the presented method optimally detects the border of the optic disc.
C1 [Zhou, Huiyu] Queens Univ Belfast, Inst Elect Commun & Informat Technol, Belfast BT3 9DT, Antrim, North Ireland.
   [Schaefer, Gerald] Univ Loughborough, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.
   [Liu, Tangwei; Lin, Faquan] Guangxi Univ Tradit Chinese Med, Nanning 530027, Peoples R China.
C3 Queens University Belfast; Loughborough University; Guangxi University
   of Chinese Medicine
RP Zhou, HY (corresponding author), Queens Univ Belfast, Inst Elect Commun & Informat Technol, Belfast BT3 9DT, Antrim, North Ireland.
EM H.Zhou@ecit.qub.ac.uk; G.Schaefer@ieee.org
RI Zhou, Huiyu/O-2692-2014
OI Zhou, Huiyu/0000-0003-1634-9840
CR ABDELGHAFAR R, 2004, MED IM UND AN C
   [Anonymous], 1998, 4 IEEE WORKSH APPL C
   Balasubramanian S., 2007, IAPR C MACH VIS APPL, P281
   Barrett S F, 2001, Biomed Sci Instrum, V37, P81
   BISWAS P, 2002, P 3 IND C COMP VIS G
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   HERZOG A, 2005, IEEE WORKSH APPL COM, V1, P263
   Ikram MK, 2002, OPHTHALMOLOGY, V109, P486, DOI 10.1016/S0161-6420(01)00983-6
   Infeld DA, 1998, POSTGRAD MED J, V74, P129, DOI 10.1136/pgmj.74.869.129
   Kande GB, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P535
   Li CM, 2005, PROC CVPR IEEE, P162
   Li HQ, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P837, DOI 10.1109/ICIP.2001.958624
   Liu TW, 2008, PATTERN RECOGN LETT, V29, P90, DOI 10.1016/j.patrec.2007.08.015
   Mahfouz AE, 2009, LECT NOTES COMPUT SC, V5762, P985, DOI 10.1007/978-3-642-04271-3_119
   Mayer-Base A., 2004, Pattern Recognition for Medical Imagining
   Mendels F., 1999, P IRISH MACHINE VISI, P103
   Osareh A, 2002, INT C PATT RECOG, P743, DOI 10.1109/ICPR.2002.1044865
   Pallawala PMDS, 2004, LECT NOTES COMPUT SC, V3022, P139
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001
   RIGO W, 2002, COMPUTER GRAPHICS IM, P18
   RIORDANEVA P, 2007, VAUGHAN ASBURYS GENN
   Siddalingaswamy PC, 2009, IFMBE PROC, V23, P277
   Sinthanayothin C, 2008, J BIOMED SCI ENG, V2, P90
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   TERHAAR F, 2005, THESIS UTRECHT U NET
   Tobin KW, 2007, IEEE T MED IMAGING, V26, P1729, DOI 10.1109/TMI.2007.902801
   Wang J, 2004, LECT NOTES COMPUT SC, V3022, P238
   WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Xu J, 2007, PATTERN RECOGN, V40, P2063, DOI 10.1016/j.patcog.2006.10.015
   Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004
   Zhou HY, 2005, INT CONF ACOUST SPEE, P749
   Zhu GP, 2006, OPT ENG, V45, DOI 10.1117/1.2333566
NR 37
TC 18
Z9 20
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 447
EP 462
DI 10.1007/s11042-009-0443-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800004
DA 2024-07-18
ER

PT J
AU Bergsträsser, S
   Hildebrandt, T
   Rensing, C
   Steinmetz, R
AF Bergstraesser, Sonja
   Hildebrandt, Tomas
   Rensing, Christoph
   Steinmetz, Ralf
TI Virtual context based services for multiplayer online games to
   facilitate community participation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual context based services; Networked gaming; User support;
   Middleware
AB In the future of Massively Multiuser Online Gaming new improvements and innovations are needed. With demands of gamers for support and involvement, increasing new approaches are required in order to enhance community participation and increase the gaming experience. Using the concept of Virtual Context Based Services we have developed a novel approach to solve these challenges. Our concept enables information exchange game and genre independent by using the VCBS middleware. With the eXtensible game description language (xgdl) we propose a standardized way to describe the virtual context of a gamer. VCBS is an interface between games and other internet applications, which involves game communities and supports gamers.
C1 [Bergstraesser, Sonja; Hildebrandt, Tomas; Rensing, Christoph; Steinmetz, Ralf] Tech Univ Darmstadt, KOM Multimedia Commun Lab, D-64283 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Bergsträsser, S (corresponding author), Tech Univ Darmstadt, KOM Multimedia Commun Lab, Merckstr 25, D-64283 Darmstadt, Germany.
EM sonja.bergstraesser@KOM.tu-darmstadt.de;
   tomas.hildebrandt@KOM.tu-darmstadt.de;
   christoph.rensing@KOM.tu-darmstadt.de;
   ralf.steinmetz@KOM.tu-darmstadt.de
RI Rensing, Christopher/D-3947-2011; Steinmetz, Patrick R. H./AAD-4093-2022
OI Rensing, Christopher/0000-0002-5012-7953; Steinmetz,
   Ralf/0000-0002-6839-9359; Rensing, Christoph/0000-0002-1287-216X
CR [Anonymous], 1994, 1994 1 WORKSH MOB CO, DOI DOI 10.1109/WMCSA.1994.16
   [Anonymous], P SIGCHI C HUM FACT
   Bergstrasser S., 2007, P 6 ACM SIGCOMM WORK, P111, DOI DOI 10.1145/1326257.1326277
   BERGSTRASSER S, 2009, 16 ITG GI FACHT KOMM
   Chambers Rachel., 2005, Human Rights Brief, V13, P14
   GOERTZ M, 2004, INT C COMP COMM NETW, P272
   GOERTZ M, 2005, THESIS TU DARMSTADT
   *GUILD, WIK GUID ARENANETS C
   HILDEBRANDT T, 2008, NETGAMES 2008, P111
   LI K, 2004, P 14 INT WORKSH NETW
   *LITTLEBIGPLANET, MED MOL SON COMP ENT
   MOSCHGATH ML, 2005, THESIS TU DARMSTADT
   SCHMITT J, 2008, EXTENSIBLE FRAMEWORK
   SINGH A, 2004, P 3 ACM SIGCOMM WORK
   *SPOR, MAX EL ARTS
   STRAIN J, 2007, GAM CONV DEV C GCDC
   *TEAMSPEAK, TEAMSPEAK SYST TEAMS
   *XCHAR, WOW MEETS REAL LIF
   THOTTBOT WORLD WARCR
NR 19
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
BP 347
EP 367
DI 10.1007/s11042-009-0293-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900015
DA 2024-07-18
ER

PT J
AU Wang, XW
   Sun, J
   Xie, R
   Yu, SY
   Zhang, WJ
AF Wang, Xiangwen
   Sun, Jun
   Xie, Rong
   Yu, Songyu
   Zhang, Wenjun
TI An improved block size selection method based on macroblock movement
   characteristic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video encoder; Mode decision; Variable block size selection; MB movement
   characteristic; Image edge direction
ID MOTION ESTIMATION
AB The H.264 video compression standard supports seven variable block sizes ranging from 4 x 4 to 16 x 16 for one Macro Block (MB) with 16 x 16 size to conduct motion estimation (ME) and compensation. This new feature achieves significant coding gain at the cost of huge computation complexity. Dozens of fast mode decision algorithms with fast block size selection have been proposed to reduce complexity. In this paper, we propose an improved fast block size selection method based on MB movement characteristic. The Motion Vector (MV) and block residual are employed to analyze the movement characteristic of one MB novelly. Then the movement characteristic is used to decide whether and how to merge or split the MB for encoding. Experimental results show that this method speeds up mode decision procedure dramatically with negligible compression performance degradation.
C1 [Wang, Xiangwen] Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou 310018, Peoples R China.
   [Sun, Jun; Xie, Rong; Yu, Songyu; Zhang, Wenjun] Shanghai Jiao Tong Univ, Shanghai Key Lab Digital Media Proc & Transmiss, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
C3 Hangzhou Dianzi University; Shanghai Jiao Tong University
RP Wang, XW (corresponding author), Hangzhou Dianzi Univ, Coll Commun Engn, Xiasha Pk, Hangzhou 310018, Peoples R China.
EM wxw21st@gmail.com; Sunjun@sjtu.edu.cn; xierong@sjtu.edu.cn;
   syyu@cdtv.org.cn; wjzhang@cdtv.org.cn
RI Zhang, Wenjun/GNH-2095-2022; Yu, Song/JMR-3167-2023
OI Zhang, Wenjun/0000-0002-5282-3725; 
FU  [CNGI-04-15-2A]
FX This work is supported by CNGI-04-15-2A. CHINA. The authors thank the
   anonymous reviewers for invaluable comments.
CR ANDY CY, 2004, IEEE ICASSP
   [Anonymous], H 264 AVC REFERENCE
   CHAN MH, 1990, IEE PROC-I, V137, P205, DOI 10.1049/ip-i-2.1990.0029
   CHEN Z, 2002, 6 JVT F017 M AW ISL
   *JVT ITU T ISO IEC, 2005, H264 JVT ITUT ISOIEC
   Kucukgoz M, 2004, P SOC PHOTO-OPT INS, V5308, P932, DOI 10.1117/12.522040
   Rhee I, 2000, IEEE T CIRC SYST VID, V10, P42, DOI 10.1109/76.825857
   SEFERIDIS VE, 1994, IEEE T COMMUN, V42, P1277, DOI 10.1109/TCOMM.1994.580237
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   TU YK, 2003, MULTIMEDIA EXPO 2003, V2, P789
   Wang HF, 2007, MULTIMED TOOLS APPL, V34, P221, DOI 10.1007/s11042-006-0091-6
   Wang XW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P372
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Zhou Z, 2004, IEEE IMAGE PROC, P789
   ZHOU Z, 2004, ISCAS2004
NR 16
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2009
VL 43
IS 2
BP 131
EP 143
DI 10.1007/s11042-009-0260-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 430WI
UT WOS:000265021100002
DA 2024-07-18
ER

PT J
AU Sofokleous, AA
   Angelides, MC
AF Sofokleous, Anastasis A.
   Angelides, Marios C.
TI DCAF: An MPEG-21 Dynamic Content Adaptation Framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content adaptation; Genetic Algorithms; Pareto optimality; MPEG-21
ID MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS; MULTIMEDIA ADAPTATION
AB Universal Multimedia Access aims at providing a gratifying end user-experience by either adapting the content, be it static or dynamic, to suit the usage environment or adapting the usage environment, be it client- or server-centric, to suit content. This paper presents our MPEG-21 Dynamic Content Adaptation Framework, acronym DCAF, which uses a fusion of Genetic Algorithms and Strength Pareto Optimality to adapt content in order to suit the usage environment.
C1 [Sofokleous, Anastasis A.; Angelides, Marios C.] Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Angelides, MC (corresponding author), Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
EM anastasis.sofokleous@bcs.org; marios.angelides@bcs.org
CR Angelides M, 2006, LECT NOTES COMPUT SC, V4132, P55
   Angelides MC, 2005, LECT NOTES COMPUT SC, V3823, P556
   Bellard F., 2006, FFMPEG MULTIMEDIA SY
   Böszörményi L, 2003, SIGNAL PROCESS-IMAGE, V18, P749, DOI 10.1016/S0923-5965(03)00062-6
   DAN A, 1995, MULTIMEDIA SYST, V3, P93, DOI 10.1007/BF01542861
   Devillers S, 2005, IEEE T MULTIMEDIA, V7, P463, DOI 10.1109/TMM.2005.846794
   Di Cagno G, 2006, SIGNAL PROCESS-IMAGE, V21, P200, DOI 10.1016/j.image.2005.09.005
   Feng N, 2004, IEEE T COMMUN, V52, P1547, DOI 10.1109/TCOMM.2004.833191
   HEIJMANS H, 2006, MASCOT ADAPTIVE MORP
   Huang J, 2006, MULTIMEDIA SYST, V11, P513, DOI 10.1007/s00530-006-0036-y
   HUTTER A, 2005, P ICIP GEN IT SEP, P716
   *ISO IEC, 2100072004 ISOIEC 7
   Jannach D, 2006, APPL INTELL, V24, P109, DOI 10.1007/s10489-006-6933-0
   Jannach D, 2007, J NETW COMPUT APPL, V30, P958, DOI 10.1016/j.jnca.2005.12.007
   KASUTANI E, 2004, 0422 ITS
   Lei ZJ, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P913, DOI 10.1109/CCECE.2001.933563
   LUCAS C., 2006, PRACTICAL MULTIOBJEC
   MAO ZM, 2001, P 11 INT WORKSH NETW, P107
   Mehra P, 2005, IEEE T MULTIMEDIA, V7, P740, DOI 10.1109/TMM.2005.846783
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Mukherjee D, 2003, PROC SPIE, V5018, P148, DOI 10.1117/12.478426
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Panis G, 2003, SIGNAL PROCESS-IMAGE, V18, P721, DOI 10.1016/S0923-5965(03)00061-4
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   Ranganathan P, 2006, COMPUTER, V39, P31, DOI 10.1109/MC.2006.89
   RONG L, 2004, P 1 IEEE CONS COMM N, P436
   Sofokleous AA, 2006, J MOBILE MULTIMEDIA, V2, P112
   Sofokleous AA, 2006, J MOBILE MULTIMEDIA, V2, P297
   Steiger O, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P45
   Sun H, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P536
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TELLER PJ, 2003, ACM SIGOPS OPER SYST, V40, P83
   Timmerer C, 2005, IEEE MULTIMEDIA, V12, P74, DOI 10.1109/MMUL.2005.7
   Tunali ET, 2005, MULTIMED TOOLS APPL, V27, P431, DOI 10.1007/s11042-005-4090-9
   Tusch R, 2003, LECT NOTES COMPUT SC, V2789, P78
   TUSCH R, 2004, COMPUTER SCI INFORMA, V1, P49
   van Beek P, 2003, IEEE SIGNAL PROC MAG, V20, P40, DOI 10.1109/MSP.2003.1184338
   Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125, DOI 10.1162/106365600568158
   Veeravalli B, 2006, MULTIMED TOOLS APPL, V28, P89, DOI 10.1007/s11042-006-5116-7
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   VETRO A, 2006, MPEG 21 BOOK, P282
   Weiser M., 1994, Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (OSDI), P13
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
NR 45
TC 19
Z9 22
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 151
EP 182
DI 10.1007/s11042-008-0198-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200001
DA 2024-07-18
ER

PT J
AU Gardikis, G
   Xilouris, G
   Skianis, C
   Kourtis, A
AF Gardikis, Georgios
   Xilouris, Georgios
   Skianis, Charalabos
   Kourtis, Anastasios
TI Broadband multimedia on the move with DVB-H
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DVB-H; cellular/broadcast convergence; IP datacasting
AB DVB-H is the newly standardized extension to DVB-T, aiming at the provision of IP datacasting (IPDC) services to mobile terminals. This tutorial paper outlines the structure of an interactive DVB-H platform and presents in brief the technical advances of the new specification. It also discusses some interesting scenarios of interactive and non-interactive services which can be directly deployed with the use of the DVB-H technology either as a stand-alone broadcast network or as a complement to existing cellular (2G/3G/WLAN) infrastructures.
C1 [Gardikis, Georgios; Xilouris, Georgios; Skianis, Charalabos] Univ Aegean, Dept Informat & Commun Syst Engn, GR-83200 Karlovassi, Samos, Greece.
   [Kourtis, Anastasios] Demokritos Natl Ctr Sci Res, Inst Informat & Telecommun, GR-15310 Athens, Greece.
C3 University of Aegean; National Centre of Scientific Research
   "Demokritos"
RP Gardikis, G (corresponding author), Univ Aegean, Dept Informat & Commun Syst Engn, GR-83200 Karlovassi, Samos, Greece.
EM gardikis@iit.demokritos.gr; xilouris@iit.demokritos.gr;
   cskianis@aegean.gr; kourtis@iit.demokritos.gr
RI Xylouris, Georgios/AAU-9159-2021
OI Xylouris, Georgios/0000-0003-2695-4534; Kourtis,
   Anastasios/0000-0003-3047-4568
CR COSMOS J, 2003, P DTV WORKSH CONFTEL, P5
   *DVB H, 2005, A097 DVB
   *DVB H, 2005, A098 DVB
   *DVB PROJ OFF, 2006, DVB H GLOB MOB TV
   *ETSI EN, 2004, 302 304 ETSI EN
   *ETSI TR, 2005, 102 401 ETSI TR
   Faria G, 2006, P IEEE, V94, P194, DOI 10.1109/JPROC.2005.861011
   GARDIKIS G, 2005, P 3 C HET NETW HETNE
   KORNFELD M, 2005, 301 EBU
   Rauch C, 2001, P EUR PERS MOB COMM
   STARE E, 1998, P INT BROAD CONV IBC, P473
   STARE E, 2002, HYBRID RECEPTION 2 K
   Wu YY, 2000, IEEE T BROADCAST, V46, P101, DOI 10.1109/11.868925
   Xu L., 2000, P 25 ANN C LOC COMP
NR 14
TC 7
Z9 7
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 133
EP 144
DI 10.1007/s11042-006-0084-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600008
DA 2024-07-18
ER

PT J
AU Eidenberger, H
AF Eidenberger, Horst
TI Evaluation of content-based image descriptors by statistical methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE evaluation; statistical data analysis; feature design; visual
   information retrieval; MPEG-7
ID RETRIEVAL
AB Evaluation of visual information retrieval systems is usually performed by executing test queries and computing recall- and precision-like measures based on predefined media collections and ground truth information. This process is complex and time consuming. For the evaluation of feature transformations (transformation of visual media objects to feature vectors) it would be desirable to have simpler methods available as well. In this paper we introduce a supplementary evaluation procedure for features that is founded on statistical data analysis. A second novelty is that we make use of the existing visual MPEG-7 descriptors to judge the characteristics of feature transformations. The proposed procedure is divided into four steps: (1) feature extraction, (2) merging with MPEG-7 data and normalisation, (3) statistical data analysis and (4) visualisation and interpretation. Three types of statistical methods are used for evaluation: (1) univariate description (moments, etc.), (2) identification of similarities between feature elements (e.g. cluster analysis) and (3) identification of dependencies between variables (e.g. factor analysis). Statistical analysis provides beneficial insights into the structure of features that can be exploited for feature redesign. Application and advantages of the proposed approach are shown in a number of toy examples.
C1 Vienna Univ Technol, Inst Software Technol & Interact Syst, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Eidenberger, H (corresponding author), Vienna Univ Technol, Inst Software Technol & Interact Syst, Favoritenstr 9-11, A-1040 Vienna, Austria.
EM eidenberger@ims.tuwien.ac.at
CR [Anonymous], 1999, Visual Information Retrieval
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   BREITENEDER C, 1999, P IEEE INT WORKSH MU, P91
   Chan FY, 2001, J TELEMED TELECARE, V7, P7, DOI 10.1258/1357633011937290
   Cowan G., 1998, Statistical Data Analysis
   Edwards JD, 2003, PROC SPIE, V5150, P467, DOI 10.1117/12.503044
   Eidenberger H, 2004, MULTIMEDIA SYST, V10, P84, DOI 10.1007/s00530-004-0141-8
   Eidenberger H, 2004, PROC SPIE, V5307, P145
   Eidenberger H, 2003, P SOC PHOTO-OPT INS, V5150, P476, DOI 10.1117/12.503064
   Eidenberger H, 2003, J VISUAL LANG COMPUT, V14, P443, DOI 10.1016/S1045-926X(03)00035-1
   Fuhr N, 2001, COMPUT IMAGING VIS, V22, P191
   Izquierdo E, 2003, DIGITAL MEDIA: PROCESSING MULTIMEDIA INTERACTIVE SERVICES, P519, DOI 10.1142/9789812704337_0094
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KOIKKALAINEN P, 1990, P INT JOINT C NEUR N, V2, P279
   LEW MS, 2003, PRINCIPLES VISUAL IN
   Loehlin J. C., 2001, LATENT VARIABLE MODE
   Manjunath B.S., 2002, INTRO MPEG 7
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Marques O., 2002, CONTENT BASED IMAGE
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Smeaton AlanF., 2004, MULTIMEDIA '04: Proceedings of the 12th annual ACM international conference on Multimedia, P652
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Vesanto J., 1999, P MATLAB DSP C, P35
NR 25
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2007
VL 35
IS 3
BP 241
EP 258
DI 10.1007/s11042-007-0106-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 228XS
UT WOS:000250766500001
DA 2024-07-18
ER

PT J
AU Shen, HT
   Zhou, XF
AF Shen, Heng Tao
   Zhou, Xiaofang
TI Capture local information in shape representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image retrieval; shape representation; local; component distance
   distribution function
AB Research in content-based image retrieval has been around for over a decade. While the research community has successfully exploited content features such as color and texture, finding an effective shape representation and measure remains a challenging task. The shape feature is particularly crucial for the success of content-based systems as it carries meaningful semantics of the objects of interest and fits more naturally into humans' perception of similarity. In this paper, we present our approach to use the shape feature for image retrieval. First, we introduce an effective image decomposition method called Crawling Window (CW) to distinguish the outline of each object in the image. Second, to represent each individual shape, we propose a novel representation model called component Distance Distribution Function and its measure. Traditionally, an object is represented by a set of points on the shape's contour. Our idea is to first compute the distance between each point and the center of the object. The distance values for all points form a signal, which we call Distance Distribution Function (DDF). Each DDF is then divided into component DDFs (cDDF) by taking local signal information into account. Finally, a transformation technique is employed to generate the feature vector for each cDDF. All vectors from the cDDFs in circular order construct the final shape representation. The model is invariant to position, scaling, rotation and starting point. The similarity measure model based on the new representation is also introduced. Our extensive experiments show that our models are more effective than the existing representation model, both in the shape and the image level.
C1 Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
C3 University of Queensland
RP Shen, HT (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
EM shenht@itee.uq.edu.au; zxf@itee.uq.edu.au
RI Zhou, Xiaofang/C-6169-2013; Zhou, Xiangfeng/KDO-8724-2024; Shen, Heng
   Tao/ABD-5331-2021
OI Zhou, Xiaofang/0000-0001-6343-1455; 
CR ADAMEK T, 2003, 5 ACM SIGMM INT WORK, P138
   [Anonymous], 1986, COMPUTATIONAL APPROA, DOI DOI 10.1109/TPAMI.1986.4767851
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BOUET M, 1999, ACM MULTIMEDIA
   JACOBS CE, 1995, SIG GRAPH
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   SMITH JR, 1997, THESIS COLUMBIA U
   Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 12
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 157
EP 174
DI 10.1007/s11042-006-0061-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000003
DA 2024-07-18
ER

PT J
AU Guo, HQ
   Ngoh, LH
   Wong, WC
   Tan, JG
AF Guo, H. Q.
   Ngoh, L. H.
   Wong, W. C.
   Tan, J. G.
TI Comparison of in-network versus Staggered Multicast video distribution
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video-in-network; optical network; Staggered Multicast; concurrent
   stream number; startup latency
ID STORAGE; ISSUES
AB This paper proposes a new video distribution service: Video-In-Network (VIN). In VIN, videos are continuously circulating in an optical network where they can be easily retrieved by VIN Nodes. A mathematical model of the VIN system was derived and used to explore the performance of VIN in terms of the maximum number of concurrent video streams which can be supported by the system. We then compared VIN with Staggered Multicast. We found that VIN has a number of advantages over Staggered Multicast. First, VIN is more scalable in terms of the number of streams/channels. Second, the startup latency of VIN is shorter than that of Staggered Multicast. Third, Staggered Multicast is a near-VOD system and the video clients usually have no specific channels to the server to request for video. In the VIN system, the video clients can request the VIN Node for particular videos for multicast or unicast on demand.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
   ASTAR, Inst Infocomm Res, Singapore 119613, Singapore.
C3 National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Guo, HQ (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM guohq@i2r.a-star.edu.sg; lhn@i2r.a-star.edu.sg; lwong@i2r.a-star.edu.sg;
   tjg@i2r.a-star.edu.sg
RI TAN, Jianguo/K-4219-2017; Guo, Huaqun/HLQ-0619-2023
OI Wong, Lawrence/0000-0001-6581-234X; Guo, Huaqun/0000-0001-6753-6537
CR Acharya S, 1995, IEEE PERS COMMUN, V2, P50, DOI 10.1109/98.475988
   ACHARYA S, 1995, P ACM SIGMOD C SAN J
   Bertsekas D., 1992, DATA NETWORK, VSecond
   Brackett JW, 1998, IEEE MULTIMEDIA, V5, P72, DOI 10.1109/93.713308
   Carrera E. V., 1999, Parallel and Distributed Processing. 11th IPPS/SPDP'99 Workshops Held in Conjunction with the 13th International Parallel Processing Symposium and 10th Symposium on Parallel and Distributed Processing. Proceedings, P859
   Carrera EV, 2000, APPL OPTICS, V39, P6663, DOI 10.1364/AO.39.006663
   CARRERA EV, 1999, P 6 INT C PAR INT FO, P452
   CHLAMTAC IA, 1996, IEEE J SEL AREAS COM, V14
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   DONG L, 2003, SPRINGERVERLAG LECT
   DONG L, 2003, P 2003 INT S PERF EV, P622
   Dong LG, 2003, PARALLEL AND DISTRIBUTED COMPUTING SYSTEMS, PROCEEDINGS, P187
   Fei ZM, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P949, DOI 10.1109/MMCS.1999.778617
   Feng W. C., 1997, BUFFERING TECHNIQUES
   GAO L, 1998, P NOSSDAV 98
   Gao LX, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P203
   GEMELL DJ, 1995, IEEE COMPUTER MA MAY, P40
   GUO HQ, 2003, P 5 INT C ADV COMM T, P457
   Haskin RL, 1996, DIGEST OF PAPERS: COMPCON SPRING 96, FORTY-FIRST IEEE COMPUTER SOCIETY INTERNATIONAL CONFERENCE - INTELLECTUAL LEVERAGE, P226, DOI 10.1109/CMPCON.1996.501773
   HILL M, 2001, SCI LUCENT TECHNOLOG
   KUNII TL, 1995, MULTIMEDIA SYST, V3, P298, DOI 10.1007/BF01832145
   Langenhorst R, 1996, J LIGHTWAVE TECHNOL, V14, P324, DOI 10.1109/50.485589
   LAURSEN A, 1995, COMPCON '95 - TECHNOLOGIES FOR THE INFORMATION SUPERHIGHWAY, DIGEST OF PAPERS, P203
   Lee YB, 1996, IEEE INFOCOM SER, P27, DOI 10.1109/INFCOM.1996.497874
   Li VOK, 1997, P IEEE, V85, P1063, DOI 10.1109/5.611116
   Mourad AN, 1996, MULTIMEDIA SYST, V4, P70, DOI 10.1007/s005300050013
   SPOONER J, 2000, ZDNET NEWS US
   SPRING J, 1993, ELECT LETT, V29
   *WDM, 2001, LIGHT READ
   XU L, 2001, P ACM MULT
   CANARIES WAVELENGTH
   2001, GILDER TECHNOLOGY RE
   TELECOMMAGAZINE
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 373
EP 394
DI 10.1007/s11042-006-7719-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000006
DA 2024-07-18
ER

PT J
AU Dong, JY
   He, C
   Zheng, YF
   Ewing, RL
AF Dong, JY
   He, C
   Zheng, YF
   Ewing, RL
TI AVP: A highly efficient transport protocol for low bit rate multimedia
   communications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RTP/RTCP; video streaming; synchronization; end-to-end delay; QoS
AB Utilization of Internet communications in distance learning, distributed simulation, and distributed work groups involves multimedia transmission of animation, voice and video clips. Highly compressed audio-video data protocols are required for efficient Internet multimedia communications. Addressing this requirement, a new transport protocol called Audio-Video Protocol (AVP) for highly efficient multimedia communications on the Internet is presented. While providing similar real-time delivery functions as Real-Time Transport Protocol (RTP) and Real-Time Control Protocol (RTCP), AVP adopts a novel audio-based synchronization scheme. This synchronization scheme has two advantages. One is the overhead reduction through eliminating the timestamp in each transmitted data packet. The other is the packet rate reduction by putting multiple audio frames or mixed audio-video frames in a single AVP packet. As a result, the end-to-end media unit delay is reduced while achieving implicit synchronization. Furthermore, AVP provides adaptive quality of service (QoS) by the prioritized packetization scheme. Simulation results are presented to verify the advantages of the AVP protocol.
C1 Ohio State Univ, Dept Elect Engn, Columbus, OH 43210 USA.
   AFRL, IFTA, Informat Directorate, Wright Patterson AFB, OH 45433 USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Defense; United States Air Force; US Air Force Research
   Laboratory
RP Dong, JY (corresponding author), Ohio State Univ, Dept Elect Engn, Columbus, OH 43210 USA.
EM jdong2@calstatela.edu; hec@ee.eng.ohio-state.edu;
   zheng@ee.eng.ohio-state.edu
CR [Anonymous], 1995, 138182 ISOIEC
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   Busse I, 1996, COMPUT COMMUN, V19, P49, DOI 10.1016/0140-3664(95)01038-6
   CASH G, 1998, 2343 RFC INT ENG TAS
   Casner S. L., 1999, 2508 RFC INT ENG TAS
   CLARK D, 1990, P ACM SIGC 90
   DONG J, 2002, IN PRESS P SPIE AER
   FIELDING R, 1997, 2068 RFC INT ENG TAS
   Handley M., 1999, 2736 RFC INT ENG TAS
   HUITEMA C, 1998, IPV6 NEXT GENERATION
   Kantarci A, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1021, DOI 10.1109/ICME.2000.871533
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   KOSSENTINI F, 1998, TMN 8 H 263 PLUS ENC
   Levy IK, 2001, IEEE T IMAGE PROCESS, V10, P470, DOI 10.1109/83.908536
   MCCANNE S, UCB LBNL NETWORK SIM
   Mills D., 1992, RFC1305 IETF
   Palacharla S, 1997, P INT COMP SOFTW APP, P376, DOI 10.1109/CMPSAC.1997.625003
   PAUL B, 1999, P IEEE MULT SIGN PRO, P59
   SCHULZRINNE H, 1995, 1889 RFC INT ENG TAS
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   STEINMETZ R, 1993, 439310 IBM EUR NETW
   Talley T, 1996, CONF LOCAL COMPUT NE, P374, DOI 10.1109/LCN.1996.558166
   Tham JY, 1998, IEEE J SEL AREA COMM, V16, P12, DOI 10.1109/49.650917
NR 23
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 187
EP 216
DI 10.1007/s11042-005-5605-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000002
DA 2024-07-18
ER

PT J
AU Magaña, E
   Aracil, J
   Villadangos, J
AF Magaña, E
   Aracil, J
   Villadangos, J
TI Packet video broadcasting with general-purpose operating systems in an
   Ethernet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE packet video broadcasting; general-purpose video servers; Ethernet
AB Video transmission with general-purpose PCs poses a number of requirements that radically differ from those of high-end dedicated video servers. We analyze the scenario of an Ethernet local area network in which a number of PCs are transmitting video streams, while other TCP/IP applications are also running concurrently. Our findings show that since the operating system clock resolution cannot cope with the transmission timing requirements the following holds: if the video transmission is performed with exact timing accuracy to maintain a constant rate then CPU load grows to 100%, thus blocking the PC for other user applications; on the other hand, if transmission is performed in a bursty manner, i.e. with sleep system calls, then CPU load decreases dramatically but the increased burstiness of the video stream has a negative impact on network performance ( for example, capture effect in the Ethernet). Furthermore, the impact of video transmission over the rest of TCP/IP applications running on the same network depends heavily on the packet size. We provide an integrated analysis of operating system and network parameters to achieve video broadcasting while preserving timing requirements and minimizing the impact on other applications.
C1 Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   Univ Publ Navarra, Dept Automat & Computac, Pamplona, Spain.
C3 University of California System; University of California Berkeley;
   Universidad Publica de Navarra
RP Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
EM emagana@eecs.berkeley.edu; javier.aracil@unavarra.es; jesusv@unavarra.es
RI Villadangos, Jesus/AFW-4492-2022; Magana, Eduardo/I-2648-2015
OI Villadangos, Jesus/0000-0002-7341-9529; Magana,
   Eduardo/0000-0002-6851-3414
CR BOLOT J, 1997, ACM COMPUTER COMMUNI
   DALGIC I, 1994, P IEEE INFOCOM 94 TO
   Goodheart B., 1994, The Magic Garden Explained: The Internals of UNIX System V Release 4: an Open Systems Design
   GRINGERI S, 1998, IEEE NETWORK
   GUOTA S, 1994, P GLOBECOM 94 SAN FR
   MELIKSETIN D, 2000, IEEE T MULTIMEDIA, V2
   MOLLE M, 1998, J TELECOMMUNICATIONS, V9
   NI J, 1996, IEE P COMMUNICATIONS, V143
   POSTEL J, 1983, STD0020RFC862
   Ramakrishnan K. K., 1994, Proceedings. 19th Conference on Local Computer Networks (Cat. No.94TH8004), P228, DOI 10.1109/LCN.1994.386597
   VIDALLER L, 1994, P DELTA TEL C 94 DUS
   WHETTEN B, 1994, P IEEE LOCAL COMPUTE
NR 12
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2004
VL 24
IS 1
BP 5
EP 28
DI 10.1023/B:MTAP.0000033981.34629.37
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 834ZA
UT WOS:000222448200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bertino, E
   Elmagarmid, AK
   Hacid, MS
AF Bertino, E
   Elmagarmid, AK
   Hacid, MS
TI A logical approach to quality of service specification in video
   databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of Service; multimedia presentations; video databases; QoS
   parameters; QoS specification; QoS mapping; constraint-based query
   languages; constraint satisfaction; constraint optimization; reactive
   systems
AB Quality of Service (QoS) is defined as a set of perceivable attributes expressed in a user-friendly language with parameters that may be objective or subjective. Objective parameters are those related to a particular service and are measurable and verifiable. Subjective parameters are those based on the opinions of the end-users. We believe that quality of service should become an integral part of multimedia database systems and users should be able to query by requiring a quality of service from the system. The specification and enforcement of QoS presents an interesting challenge in multimedia systems development. A deal of effort has been done on QoS specification and control at the system and the network levels, but less work has been done at the application/user level. In this paper, we propose a language, in the style of constraint database languages, for formal specification of QoS constraints. The satisfaction by the system of the user quality requirements can be viewed as a constraint satisfaction problem, and the negotiation can be viewed as constraint optimization. We believe this paper represents a first step towards the development of a database framework for quality of service management in video databases. The contribution of this paper lies in providing a logical framework for specifying and enforcing quality of service in video databases. To our knowledge, this work is the first from a database perspective on quality of service management.
C1 Univ Milan, Dipartimento Sci Informaz, I-20135 Milan, Italy.
   Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   Univ Lyon 1, UFR Informat, F-69622 Villeurbanne, France.
C3 University of Milan; Purdue University System; Purdue University;
   Universite Claude Bernard Lyon 1
RP Univ Milan, Dipartimento Sci Informaz, Via Comelico 39-41, I-20135 Milan, Italy.
EM bertino@dsi.unimi.it; ake@cs.purdue.edu; mshacid@bat710.univ-lyon1.fr
CR [Anonymous], 1992, The Z Notation
   [Anonymous], P 14 ANN ACM S PRINC
   BHARGAVA B, 2002, MULTIMEDIA TOOLS APP, V17
   BOLOGNESI T, 1988, COMPUTER NETWORKS IS, V14
   BROWN A, 1993, LECT NOTES ARTIF INT, V689, P362
   COHEN J, 1990, COMMUN ACM, V33, P52, DOI 10.1145/79204.79209
   Daneshmand MF, 1997, INTELLIGENT INFORMATION SYSTEMS, (IIS'97) PROCEEDINGS, P466, DOI 10.1109/IIS.1997.645343
   Ehrich HD, 1998, SPRING INT SER ENG C, P167
   Ferrari D., 1992, Journal of High Speed Networks, V1, P79
   FISHER S, 1995, P IEEE INT C MULT NE, P132
   GOVINDARAJAN K, 1996, P 23 ACM SIGPLAN SIG, P91
   GOVINDARAJAN K, 1997, THESIS SUNY BUFFALO
   GOVINDARAJAN K, 1995, P 12 INT C LOG PROGR, P731
   Hampapur A., 1998, MULTIMEDIA DATA MANA, P245
   KANELLAKIS PC, 1995, J COMPUT SYST SCI, V51, P26, DOI 10.1006/jcss.1995.1051
   KIM KW, 1997, P 5 IFIP INT WORKSH
   KNOCHE H, 1997, P 5 IFIP INT WORKSH, P347
   LAKAS A, 1996, P 4 INT WORKSH QUAL
   Lee JW, 1999, ADV OCCUP ERGO SAF, V3, P385
   LENSTRA J, 1977, ANN DISCRETE MATH, V1
   LI W, 1996, P 1 ACM INT C DIG LI, P19
   MAIER D, 1993, LECT NOTES ARTIF INT, V730, P1
   MYERS KL, 1994, ARTIF INTELL, V67, P329, DOI 10.1016/0004-3702(94)90056-6
   NAHRSTEDT K, 1995, COMPUTER, V28, P52, DOI 10.1109/2.384118
   NEEDHAM R, 1992, LNCS, V712, P32
   STAEHLI R, 1995, MULTIMEDIA SYST, V3, P251, DOI 10.1007/BF01832141
   STEINMETZ R, 1995, IEEE MULTIMEDIA, V2, P68, DOI 10.1109/93.368605
   VanHentenryck P, 1996, ACM COMPUT SURV, V28, P701, DOI 10.1145/242223.242279
   Venkatasubramanian N, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P371, DOI 10.1145/266180.266389
   WALPOLE J, 1999, DATABASE SEMANTICS S
   WIELMAKER JAN, 2000, SWI PROLOG 3 3 REFER
   WILSON M, 1993, J LOGIC PROGRAM, V16, P277, DOI 10.1016/0743-1066(93)90046-J
   Wu CH, 1997, PROMS-MMNET '97: IEEE CONFERENCE ON PROTOCOLS FOR MULTIMEDIA SYSTEMS - MULTIMEDIA NETWORKING, PROCEEDINGS, P64, DOI 10.1109/PRMNET.1997.638881
   Zhang A, 1997, IEEE INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES - ADL'97 - PROCEEDINGS, P102, DOI 10.1109/ADL.1997.601205
   Zhang AD, 1996, P SOC PHOTO-OPT INS, V2670, P228, DOI 10.1117/12.234799
   ZHAO W, 1987, J SYSTEMS SOFTWARE, V7
   [No title captured]
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2004
VL 23
IS 2
BP 75
EP 101
DI 10.1023/B:MTAP.0000026842.02622.6c
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 818LV
UT WOS:000221247500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, T
   Suganthan, PN
AF Lu, T
   Suganthan, PN
TI An accumulation algorithm for video shot boundary detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video shot detection; retrieval; gradual transitions
AB In this paper, an accumulation algorithm for video shot detection is introduced. The algorithm considers the properties of gradual transition. In a gradual transition, there is only a small difference between consecutive frames. The algorithm remembers the differences between consecutive frames and accumulates them. When the accumulation difference exceeds a threshold, an occurrence of shot transition is declared. Our main contributions are to introduce a frame C that remembers the changes from the beginning of a shot and detect the different types of boundaries (cut, fade, dissolve) at one process. We tested our algorithm with clips extracted from MPEG VCDs. The algorithm showed a good performance in detecting the gradual transitions as well as the abrupt cuts and has the ability to identify different types of boundaries.
C1 Nanyang Technol Univ, Sch EEE, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch EEE, BLK S2, Singapore 639798, Singapore.
EM tong.lu@ntlworld.com; epnsugan@ntu.edu.sg
RI Suganthan, Ponnuthurai Nagaratnam/A-5023-2011
OI Suganthan, Ponnuthurai Nagaratnam/0000-0003-0901-5105
CR [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Arman F., 1993, Proceedings ACM Multimedia 93, P267, DOI 10.1145/166266.166297
   Ford RM, 2000, MULTIMEDIA SYST, V8, P37, DOI 10.1007/s005300050003
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Gong YH, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P850, DOI 10.1109/MMCS.1999.779312
   Hampapur A., 1994, Proceedings ACM Multimedia '94, P357, DOI 10.1145/192593.192699
   HANJALIC A, 1997, P IS T SPIE STOR RET, V3022
   JAIN R, 1995, MACHINE VISION, P406
   Lupatini G, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P34, DOI 10.1109/RIDE.1998.658276
   Meng J., 1995, P SPIE, V2419
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   NAKAJIMA Y, 1994, IEICE T INF SYST, VE77D, P1355
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Rui Y, 1999, MULTIMEDIA SYST, V7, P359, DOI 10.1007/s005300050138
   Sethi I. K., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P329, DOI 10.1117/12.205299
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   UEDA H, 1991, P CHI NEW ORL
   YEO BL, 1995, IEEE T CIRCUITS SYST, V5
   ZABHI R, 1995, P ACM MULT, P198
   Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227
   ZHONG D, 1999, IEEE T CIRCUITS SYST, V9
NR 23
TC 8
Z9 14
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2004
VL 22
IS 1
BP 89
EP 106
DI 10.1023/B:MTAP.0000008661.37331.c7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 754MK
UT WOS:000187320800005
DA 2024-07-18
ER

PT J
AU Ding, JW
   Huang, YM
AF Ding, JW
   Huang, YM
TI Resource-based striping: An efficient striping strategy for video
   servers using heterogeneous disk-subsystems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia storage; Video-On-Demand; video server; data striping;
   heterogeneous disk-subsystems
ID LOAD
AB In building a large-scale video server, it is highly desirable to use heterogeneous disk-subsystems for the following reasons. First, existing disks may fail, especially in an environment with a large number of disks, enforcing the use of new disks. Second, for a scalable server, to cope with the increasing demand of customers, new disks may be needed to increase the server's storage capacity and throughput. With rapid advances in the performance of disks, the newly added disks generally have a higher data transfer rate and a larger storage capacity than the disks originally in the system. In this paper, we propose a novel striping scheme, termed as resource-based striping (RBS), for video servers built on heterogeneous disks. RBS combines the techniques of wide striping and narrow striping so that it can obtain the optimal stripe allocation and efficiently utilize both the I/O bandwidth and storage capacity of all disks. RBS is suitable for applications whose files are not updated frequently, such as course-on-demand and movie-on-demand. We examine the performance of RBS via simulation experiments. Our results show that RBS greatly outperforms the conventional striping schemes proposed for video servers with heterogeneous or homogeneous disks, in terms of the number of simultaneous streams supported and the number of files that can be stored.
C1 Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
EM jwding@mail2000.com.tw; raymond@mail.ncku.edu.tw
RI Huang, Yueh-Min/B-4563-2009; Ding, Jen-Wen/B-4860-2009
CR ANDERSON ER, 1992, ENVIRON CLAIM J, V4, P311
   [Anonymous], 1994, Operations Research-Applications and Algorithms
   [Anonymous], 1997, Linear Programming 1: Introduction
   Chang E, 1996, IEEE MULTIMEDIA, V3, P56, DOI 10.1109/93.556461
   Chang E, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P496
   CHEN S, 1997, P INT ALG ARCH PAR, P437
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   DAN A, 1995, MULTIMEDIA SYST, V3, P93, DOI 10.1007/BF01542861
   DAN A, 1995, P IEEE COMPCON SAN F, P217
   DENGLER J, 1996, P EUR WORKSH INT DIS, P245
   Flynn R, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P590, DOI 10.1109/MMCS.1996.535027
   Flynn RJ, 1998, IBM J RES DEV, V42, P165, DOI 10.1147/rd.422.0165
   FREEMAN R, 1996, COMPUTER TECHNOLOGY, V16
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   GHANDEHARIZADEH S, 1995, SIGMETRICS PERFORMAN, V23, P37
   Griwodz C, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P349, DOI 10.1145/266180.266386
   Grochowski E., 1996, IEEE Transactions on Magnetics, V32, P1850, DOI 10.1109/20.492876
   GROCHOWSKI E, 1997, DISK DRIVE PRICE DEC
   Huang YM, 1999, VLDB J, V8, P44, DOI 10.1007/s007780050073
   KATEVENIS M, 1991, IEEE J SEL AREA COMM, V9, P1265, DOI 10.1109/49.105173
   Lee CI, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P132, DOI 10.1109/PDIS.1996.568675
   Lee JYB, 1998, IEEE MULTIMEDIA, V5, P20, DOI 10.1109/93.682522
   Lie PWK, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P52, DOI 10.1109/RIDE.1998.658278
   Ozden B, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P580, DOI 10.1109/MMCS.1996.535026
   Reddy A. L. N., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P256, DOI 10.1109/MMCS.1995.484931
   ROOHOLAMINI R, 1995, IEEE MULTIMEDIA, V2, P39, DOI 10.1109/93.368600
   RUEMMLER C, 1994, COMPUTER, V27, P17, DOI 10.1109/2.268881
   Serpanos DN, 1998, IEEE T CIRC SYST VID, V8, P13, DOI 10.1109/76.660824
   Tewari R., 1998, P SPIE ACM C MULT CO, P191
   Vin H. M., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P158, DOI 10.1109/MMCS.1995.484920
   Vin H. M., 1994, Proceedings ACM Multimedia '94, P33, DOI 10.1145/192593.192616
   WANG YT, 1994, P IEEE ICC 94, P1032
   Wang YW, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P102, DOI 10.1109/MMCS.1997.609580
   Wolf JL, 1997, MULTIMEDIA SYST, V5, P358, DOI 10.1007/s005300050067
   Wu MY, 1996, FRONTIERS '96 - THE SIXTH SYMPOSIUM ON FRONTIERS OF MASSIVELY PARALLEL COMPUTING, PROCEEDINGS, P126, DOI 10.1109/FMPC.1996.558069
   YU PS, 1992, P 3 INT WORKSH NETW
   Zimmermann R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P227, DOI 10.1145/266180.266374
NR 37
TC 6
Z9 14
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2003
VL 19
IS 1
BP 29
EP 51
DI 10.1023/A:1021164829330
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 617QH
UT WOS:000179372000002
DA 2024-07-18
ER

PT J
AU Sabitha, C
   Eluri, S
AF Sabitha, Ch.
   Eluri, Suneetha
TI Restoration of dehaze and defog image using novel cross entropy-based
   deep learning neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intensity-based Dynamic Fuzzy Histogram Equalization (IDFHE); Dark
   Channel Prior (DCP); Transmission map; Cross Entropy-based Deep Learning
   Neural Network (CE-DLNN); Modified Structure Transference Filtering
   (MST)
ID VISIBILITY RESTORATION; TRANSMISSION MAP; SINGLE IMAGE
AB Computer vision applications require high-quality images with a lot of information. Images captured in poor weather conditions such as fog or haze can affect the visibility of the images, which can lead to negative interferences. Fog/haze removal is a technique that can improve image quality and restore the true details of the objects. Currently, the image dehazing methods, which focus primarily on enhancing the overall contrast of the image, fail to deliver quality results because the light source distribution is not specified, or the cost functions are not suited to mathematical constraints. This paper proposes an efficient restoration approach based on a Cross Entropy-Based Deep Learning Neural Network (CE-DLNN). Initially, the input images are pre-processed by using the Intensity-based Dynamic Fuzzy Histogram Equalization (IDFHE) method. Then, the Dark Channel Prior (DCP) of the enhanced image is estimated, and the corresponding transmission map. Then the important features are extracted and applied as input to the CE-DLNN, which gives clear haze/fog images. From the classified output, the haze/fog images are applied for the Modified Structure Transference Filtering (MST) to reconstruct the dehaze/defog images. Then, the effectiveness of the proposed system is illustrated. The proposed method achieved a classification accuracy of 97.08%. In comparison with the existing methods, the proposed method has attained better results.
C1 [Sabitha, Ch.] Koneru Lakshmaiah Educ Fdn KLEF, Dept Comp Sci & Engn, Vijayawada, Andhra Pradesh, India.
   [Eluri, Suneetha] Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Jawaharlal Nehru Technological University - Kakinada
RP Sabitha, C (corresponding author), Koneru Lakshmaiah Educ Fdn KLEF, Dept Comp Sci & Engn, Vijayawada, Andhra Pradesh, India.
EM sabithakiran.ch@gmail.com
RI ch, Sabitha/KBA-5774-2024
CR Aiswarya Menon N, 2020, P 4 INT C COMP METH
   Anan S, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030285
   Banerjee S, 2020, IEEE REG 10 S 5 7 JU
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Du J., 2020, Smart multimedia. ICSM 2019. Lecture notes in computer science, DOI [10.1007/978-3-030-54407-2_28, DOI 10.1007/978-3-030-54407-2_28]
   Feiniu Yuan Yu., 2020, Comput Vis Image Underst, V194, P1
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hassan H, 2021, J REAL-TIME IMAGE PR, V18, P1555, DOI 10.1007/s11554-020-00953-4
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Ju MY, 2019, IEEE T CIRC SYST VID, V29, P2349, DOI 10.1109/TCSVT.2018.2869594
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Ju MY, 2017, VISUAL COMPUT, V33, P1613, DOI 10.1007/s00371-016-1305-1
   Kuanar S, 2022, VISUAL COMPUT, V38, P1121, DOI 10.1007/s00371-021-02071-z
   Kumar R, 2019, IEEE T VLSI SYST, V27, P2693, DOI 10.1109/TVLSI.2019.2932033
   Kumari A, 2021, IEEE ACCESS, V9, P48131, DOI 10.1109/ACCESS.2021.3068446
   Thanh LT, 2019, ASIA-PAC CONF COMMUN, P36, DOI [10.1109/APCC47188.2019.9026457, 10.1109/apcc47188.2019.9026457]
   Li B., 2015, J Latex Class Files, V14, P1
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu W, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.001
   Ma RQ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7938060
   Rao RV, 2023, VISUAL COMPUT, V39, P1797, DOI 10.1007/s00371-022-02446-w
   Rao RV, 2021, MULTIMED TOOLS APPL, V80, P11815, DOI 10.1007/s11042-020-10415-5
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz S, 2022, CMC-COMPUT MATER CON, V70, P1, DOI 10.32604/cmc.2022.018268
   Sabir A, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0493-9
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Singh D, 2020, MULTIMED TOOLS APPL, V79, P34771, DOI 10.1007/s11042-019-08286-6
   Tang G, 2019, P IEEE INT C BIG DAT, P154
   Tufail Z, 2019, IET IMAGE PROCESS, V13, P1161, DOI 10.1049/iet-ipr.2018.6485
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Yousaf RM, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9721503
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Yue BX, 2019, FRONT INFORM TECH EL, V20, P1109, DOI 10.1631/FITEE.1700148
   Zhu ZQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163104
NR 41
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-17835-z
EA DEC 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB6G7
UT WOS:001129606100002
DA 2024-07-18
ER

PT J
AU Tang, XX
   He, L
AF Tang, Xuxiang
   He, Lei
TI A pioneer study on laboratory safety WSN with improved adaptive
   segmentation clustering multi-hop protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lab Safety; Wireless Sensor Network; Abnormal Data Preprocessing;
   Adaptive Segmentation Clustering Multi-hop; Data Integration
ID ENERGY EFFICIENCY; MANAGEMENT; SYSTEM
AB An adaptive segmentation clustering multi-hop protocol targeting at lab safety monitoring WSN is studied in this paper. The protocol consists of two perspectives, namely abnormal data preprocessing and WSN parameter optimization. Abnormal data preprocessing contains transient abnormal data analysis, fault data preprocessing and data validity judgment. This study seeks to find an optimal scheme to reduce the system energy consumption that can extend the life cycle of network system through balancing other system indicators by optimizing adaptive parameters (e.g. hop count, hop distance, etc.). According to the structural characteristics of lab safety monitoring, the space structure based on multiple labs is studied and the structure of multiple isolated sub units (e.g. fire zones, isolation gates, etc.) is set. Correspondingly, the transmission scheme of equal interval multi-hops is introduced based on the structural design of sub units. The design facilitates the effective isolation of hidden dangers in the protection zones so as to protect the safety of the whole lab.
C1 [Tang, Xuxiang] Zhejiang Gongshang Univ, Sch Business Adm, MBA Sch, Hangzhou 310018, Peoples R China.
   [Tang, Xuxiang; He, Lei] Zhejiang Gongshang Univ, Lab & Asset Management Off, Hangzhou 310018, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University
RP Tang, XX (corresponding author), Zhejiang Gongshang Univ, Sch Business Adm, MBA Sch, Hangzhou 310018, Peoples R China.; Tang, XX (corresponding author), Zhejiang Gongshang Univ, Lab & Asset Management Off, Hangzhou 310018, Peoples R China.
EM txx@zjgsu.edu.can
FU The "Digital +" Subject Funding Project of Zhejiang Gongshang University
   (2022); Graduate Education Reform Project of Zhejiang Gongshang
   University [YJG2018230]
FX This work is financially supported by "Digital +" Subject Funding
   Project of Zhejiang Gongshang University (2022); Graduate Education
   Reform Project of Zhejiang Gongshang University (No. YJG2018230).
CR Amit Singh A., 2020, Ad Hoc Networks, V107, P1
   Behera TM, 2020, IEEE INTERNET THINGS, V7, P710, DOI 10.1109/JIOT.2019.2940988
   Daoqu G., 2022, Int J Semantic Web Inform Syst (IJSWIS), V18, P1
   David E., 2014, Heart Rhythm, V11, P9, DOI [10.1016/j.hrthm.2014.03.042, DOI 10.1016/J.HRTHM.2014.03.042]
   del Arco ND, 2020, J HEALTHC QUAL RES, V35, P291, DOI 10.1016/j.jhqr.2019.12.002
   Dowlatshahi MB, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107473
   Gherbi C, 2016, ENERGY, V114, P647, DOI 10.1016/j.energy.2016.08.012
   Gopika D, 2020, Mater Today Proceed, DOI [10.1016/j.matpr.2020.10.137, DOI 10.1016/J.MATPR.2020.10.137]
   Khan A., 2022, Secur Pri Preserv IoT 5G Networks: Tech Challenges New Direct, V95, P225, DOI [10.1007/978-3-030-85428-7_10, DOI 10.1007/978-3-030-85428-7_10]
   Lestari F, 2019, J CHEM HEALTH SAF, V26, P14, DOI 10.1016/j.jchas.2018.12.006
   Marques G, 2019, PROCEDIA COMPUT SCI, V155, P487, DOI 10.1016/j.procs.2019.08.068
   Meghana GR., 2022, Int J Semantic Web Inform Syst (IJSWIS), V18, P1
   Mehta D, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100406
   Moorthi, 2020, COMPUT COMMUN, V149, P90, DOI 10.1016/j.comcom.2019.10.006
   Muduli L, 2018, J NETW COMPUT APPL, V106, P48, DOI 10.1016/j.jnca.2017.12.022
   Rebaudo F, 2019, METHODSX, V6, P2127, DOI 10.1016/j.mex.2019.09.013
   Rosset V, 2017, EXPERT SYST APPL, V78, P89, DOI 10.1016/j.eswa.2017.02.008
   Rouissi N, 2017, PROCEDIA COMPUT SCI, V112, P1429, DOI 10.1016/j.procs.2017.08.103
   SudeepTanwar KT., 2018, Proc Comput Sci, V132, P1154, DOI [10.1016/j.procs.2018.05.030, DOI 10.1016/J.PROCS.2018.05.030]
   Vinitha A., 2019, J King Saud Univ-Comput Inform Sci, V21, P359
   Yadav Amrendra Singh, 2020, Procedia Computer Science, V171, P887, DOI 10.1016/j.procs.2020.04.096
   Zahoor A., 2022, Int J Semantic Web Inform Syst (IJSWIS), V18, P1
NR 22
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17871-9
EA DEC 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000005
DA 2024-07-18
ER

PT J
AU Yang, ZZ
   Zheng, YX
   Shao, J
   Yang, YP
AF Yang, Zhenzhen
   Zheng, Yixin
   Shao, Jing
   Yang, Yongpeng
TI Improved YOLOv4 based on dilated coordinate attention for object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE YOLOv4; Dilated convolution; Multi-scale training; Coordinate attention;
   Object detection
AB Classical YOLOv4 object detector transcends some famous object detectors in speed and accuracy. However, despite its superior performance, it still has some limitations such as the insufficient for extracting the feature. Therefore, we propose an improved YOLOv4 method for object detection in this paper. Specifically, we introduce a dilated coordinate attention module for improving the accuracy of object detection, which combine the dilated convolutional neural network with coordinate attention. At the same time, the multi-scale training strategy is also introduced to enhance the performance of object detection via using the training data with different scales. Experiments on PASCAL VOC2007 and VOC2012 datasets demonstrate that our proposed improved YOLOv4 object detector is superior to other state of the art object detection detector. Specially, its performance is better than the traditional YOLOv4, which is 1.84% and 1.91% higher on the mean average precision (mAP) for the two datasets, respectively.
C1 [Yang, Zhenzhen; Zheng, Yixin; Shao, Jing; Yang, Yongpeng] Nanjing Univ Posts & Telecommun, Minist Educ, Broadband Wireless Commun & Sensor Network Technol, Key Lab, Nanjing 210023, Peoples R China.
   [Yang, Zhenzhen] Nanjing Univ Posts & Telecommun, Coll Sci, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing Vocational College of Information
   Technology
RP Yang, ZZ; Yang, YP (corresponding author), Nanjing Univ Posts & Telecommun, Minist Educ, Broadband Wireless Commun & Sensor Network Technol, Key Lab, Nanjing 210023, Peoples R China.; Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Coll Sci, Nanjing 210023, Peoples R China.; Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
EM yangzz@njupt.edu.cn; yangyp@njcit.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Ashwani K, 2015, Int J Eng Sci Res Technol, P1
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Burger W., 2022, Digital Image Processing: An Algorithmic Introduction, P709, DOI DOI 10.1007/978-3-031-05744-1_25
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chopra J, 2016, ICITEE2, P84
   Dai JF, 2016, ADV NEUR IN, V29
   Dewi C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060889
   Diwan T, 2023, MULTIMED TOOLS APPL, V82, P9243, DOI 10.1007/s11042-022-13644-y
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hosseini-Fard E, 2022, J PETROL SCI ENG, V209, DOI 10.1016/j.petrol.2021.109971
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kumar A., 2015, Int. J. Res. Electron. Commun. Technol., V3, P1
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Kumar A, 2006, INT J COMPUT ASS RAD, V1, P14
   Li GQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3080402
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanjay R., 2012, Int J Future Comput Commun, P366, DOI DOI 10.7763/IJFCC.2012.V1.97
   Simonyan K., 2014, CORR
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian DX, 2022, IEEE T INTELL TRANSP, V23, P4099, DOI 10.1109/TITS.2020.3041278
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang Y, 2021, IEEE T IND INFORM, V17, P7423, DOI 10.1109/TII.2021.3056554
   Zhou WJ, 2022, NEUROCOMPUTING, V490, P347, DOI 10.1016/j.neucom.2021.11.100
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 42
TC 0
Z9 0
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 18
PY 2023
DI 10.1007/s11042-023-17817-1
EA DEC 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CO5S9
UT WOS:001126208400005
DA 2024-07-18
ER

PT J
AU Faghihi, A
   Fathollahi, M
   Rajabi, R
AF Faghihi, Amir
   Fathollahi, Mohammadreza
   Rajabi, Roozbeh
TI Diagnosis of skin cancer using VGG16 and VGG19 based transfer learning
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Melanoma; Dropout; Overfitting; Convolutional neural networks; K-fold;
   Transfer learning
AB Today, skin cancer is considered one of the most dangerous and common cancers in the world, demanding special attention. Skin cancer can be developed in different types, including melanoma, actinic keratosis, basal cell carcinoma, squamous cell carcinoma, and Merkel cell carcinoma. Among them, melanoma is considered to be more unpredictable. However, melanoma cancer can be diagnosed at early stages, which increases the possibility of successful treatment. Automatic classification of skin lesions is a challenging task due to diverse forms and grades of the disease, which demands the implementation of novel methods. Deep convolutional neural networks (CNNs) have shown an excellent potential for data and image classification. In this article, we examine the problem of skin lesion classification using CNN techniques. Remarkably, we present that prominent classification accuracy of lesion detection can be achieved through proper design and application of transfer learning framework on pre-trained neural networks. This can be accomplished without the need for data augmentation techniques; specifically, we merged the core architectures of VGG16 and VGG19, which were pretrained on a generic dataset, into a modified AlexNet network. We then fine-tuned this combined architecture using a subject-specific dataset consisting of dermatology images. The convolutional neural network was trained using 2541 images. In particular, dropout was employed to mitigate overfitting. Finally, we assessed the model's performance by applying the K-fold cross validation method. The proposed model improved classification accuracy with an increase of 3% (from 94.2% to 98.18%) compared to other methods.
C1 [Faghihi, Amir; Fathollahi, Mohammadreza; Rajabi, Roozbeh] Qom Univ Technol, Fac Elect & Comp Engn, Khodakaram Blvd 3718146645, Qom, Iran.
   [Rajabi, Roozbeh] Univ Genoa, DITEN Dept, Via All Opera Pia 11, I-16145 Genoa, GE, Italy.
C3 University of Genoa
RP Fathollahi, M; Rajabi, R (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Khodakaram Blvd 3718146645, Qom, Iran.; Rajabi, R (corresponding author), Univ Genoa, DITEN Dept, Via All Opera Pia 11, I-16145 Genoa, GE, Italy.
EM faghihi.a@qut.ac.ir; fathollahi@qut.ac.ir; rajabi@qut.ac.ir
OI Rajabi, Roozbeh/0000-0002-4098-4820
CR Alahmadi MD, 2022, IEEE ACCESS, V10, P122560, DOI 10.1109/ACCESS.2022.3224005
   Alzubaidi L, 2021, CANCERS, V13, DOI 10.3390/cancers13071590
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Brindha PG., 2020, J Crit Rev, V7, P640, DOI DOI 10.31838/JCR.07.11.117
   Cokun M., 2017, Eur. J. Tech. (EJT), V7, P165, DOI [DOI 10.23884/EJT.2017.7.2.11, 10.23884/ejt.2017.7.2.11]
   Fahad NM, 2023, 2023 INT C EL COMP C, P1, DOI [10.1109/ECCE57851.2023.10101527, DOI 10.1109/ECCE57851.2023.10101527]
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Hassan E, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23125393
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   Hinton G. E., 2012, arXiv
   Hoefler T, 2021, J MACH LEARN RES, V23
   Jain S, 2015, PROCEDIA COMPUT SCI, V48, P735, DOI 10.1016/j.procs.2015.04.209
   Jayalakshmi GS, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI 10.1109/iccids.2019.8862143
   Lafraxo S, 2022, MULTIMED TOOLS APPL, V81, P16021, DOI 10.1007/s11042-022-12521-y
   Mahdavi F, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349620
   Mijwil MM, 2021, MULTIMED TOOLS APPL, V80, P26255, DOI 10.1007/s11042-021-10952-7
   Nawaz M, 2021, MULTIMED TOOLS APPL, V80, P28953, DOI 10.1007/s11042-021-11120-7
   Pham TC, 2020, 2020 INT C MULT AN P, P1, DOI [DOI 10.1109/MAPR49794.2020.9237778, 10.1109/MAPR49794.2020.9237778]
   Rafi TH, 2021, 2021 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P198, DOI 10.1109/CIBCB49929.2021.9562888
   Rasel MA, 2022, IEEE ACCESS, V10, P83398, DOI 10.1109/ACCESS.2022.3196911
   Rotemberg V, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00815-z
   Sonsare PM, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111446
   Wu HB, 2015, NEURAL NETWORKS, V71, P1, DOI 10.1016/j.neunet.2015.07.007
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Zandi MS, 2022, MULTIMED TOOLS APPL, V81, P15841, DOI 10.1007/s11042-022-12023-x
   Zhang TW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3119875
NR 27
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17735-2
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L5
UT WOS:001155145700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nazif, H
   Nassr, M
   Al-Khafaji, HMR
   Navimipour, NJ
   Unal, M
AF Nazif, Habibeh
   Nassr, Mohammad
   Al-Khafaji, Hamza Mohammed Ridha
   Navimipour, Nima Jafari
   Unal, Mehmet
TI A cloud service composition method using a fuzzy-based particle swarm
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Service composition; Cloud computing; Particle swarm optimization; Fuzzy
ID LEVEL BIT ALLOCATION; HIGH-DELAY APPLICATIONS; VIDEO-RATE CONTROLLER;
   QUALITY; HEVC; MODEL
AB In today's dynamic business landscape, organizations heavily rely on cloud computing to leverage the power of virtualization and resource sharing. Service composition plays a vital role in cloud computing, combining multiple cloud services to fulfill complex user requests. Service composition in cloud computing presents several challenges. These include service heterogeneity, dynamic service availability, QoS (Quality of Service) constraints, and scalability issues. Traditional approaches often struggle to handle these challenges efficiently, leading to suboptimal resource utilization and poor service performance. This work presents a fuzzy-based strategy for composing cloud services to overcome these obstacles. The fact that service composition is NP-hard has prompted the use of a range of metaheuristic algorithms in numerous papers. Therefore, Particle Swarm Optimization (PSO) has been applied in this paper to solve the problem. Implementing a fuzzy-based PSO for service composition requires defining the fuzzy membership functions and rules based on the specific service domain. Once the fuzzy logic components are established, they can be integrated into the PSO algorithm. The simulation results have shown the high efficiency of the proposed method in decreasing the latency, cost, and response time.
C1 [Nazif, Habibeh] Payame Noor Univ, Dept Math, Tehran, Iran.
   [Nassr, Mohammad] Tartous Univ, Commun Technol Engn Dept, Tartus, Syria.
   [Nassr, Mohammad] Gulf Univ Sci & Technol, Dept Math & Nat Sci, Mishref Campus, Mubarak Al Abdullah, Kuwait.
   [Al-Khafaji, Hamza Mohammed Ridha] Al Mustaqbal Univ, Coll Engn & Technol, Biomed Engn Dept, Hillah 51001, Babil, Iraq.
   [Navimipour, Nima Jafari] Kadir Has Univ, Fac Engn & Nat Sci, Dept Comp Engn, Istanbul, Turkiye.
   [Navimipour, Nima Jafari] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu 64002, Taiwan.
   [Unal, Mehmet] Nisantasi Univ, Dept Comp Engn, Istanbul, Turkiye.
C3 Payame Noor University; Tartous University; Al-Mustaqbal University
   College; Kadir Has University; National Yunlin University Science &
   Technology; Istanbul Nisantasi University
RP Navimipour, NJ (corresponding author), Kadir Has Univ, Fac Engn & Nat Sci, Dept Comp Engn, Istanbul, Turkiye.; Navimipour, NJ (corresponding author), Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu 64002, Taiwan.
EM h_nazif@pnu.ac.ir; mohammadnasr@tartous-univ.edu.sy;
   hamza.alkhafaji@uomus.edu.iq; nima.navimipour@khas.edu.tr;
   mehmet.unal@nisantasi.edu.tr
RI Unal, Mehmet/W-2804-2018; Al-Khafaji, Hamza Mohammed Ridha/D-6335-2019
OI Unal, Mehmet/0000-0003-1243-153X; Al-Khafaji, Hamza Mohammed
   Ridha/0000-0003-3620-581X
CR Ahmad I, 2022, MULTIMED TOOLS APPL, V81, P34919, DOI 10.1007/s11042-021-11249-5
   Bossen F, 2020, 20 M TEL
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Busoniu L, 2010, AUTOM CONTROL ENG SE, P1, DOI 10.1201/9781439821091-f
   Cao B, 2020, IEEE T IND INFORM, V16, P3597, DOI 10.1109/TII.2019.2952565
   Chen ZZ, 2019, IEEE T IMAGE PROCESS, V28, P4541, DOI 10.1109/TIP.2019.2911180
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Fang MY, 2020, IEEE SIGNAL PROC LET, V27, P520, DOI 10.1109/LSP.2020.2976578
   Fani D, 2018, IEEE T CIRC SYST VID, V28, P1379, DOI 10.1109/TCSVT.2017.2669214
   Fani D, 2016, SIGNAL IMAGE VIDEO P, V10, P1183, DOI 10.1007/s11760-016-0875-8
   Francois E, 2020, IEEE T CIRC SYST VID, V30, P1253, DOI 10.1109/TCSVT.2019.2945169
   Gao W, 2017, IEEE T IMAGE PROCESS, V26, P6074, DOI 10.1109/TIP.2017.2745099
   Guo HW, 2020, IEEE T BROADCAST, V66, P113, DOI 10.1109/TBC.2019.2917402
   Hamidouche W, 2022, IEEE CONSUM ELECTR M, V11, P10, DOI 10.1109/MCE.2022.3144545
   Harshalatha Y, 2021, MULTIMED TOOLS APPL, V80, P25897, DOI 10.1007/s11042-021-10922-z
   Hou YH, 2015, SIGNAL IMAGE VIDEO P, V9, P875, DOI 10.1007/s11760-013-0518-2
   Hyun MH, 2020, IEEE ACCESS, V8, P227255, DOI 10.1109/ACCESS.2020.3046043
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Kamran R, 2016, J INTELL FUZZY SYST, V30, P1367, DOI 10.3233/IFS-152050
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li L, 2020, IEEE T IMAGE PROCESS, V29, P6237, DOI 10.1109/TIP.2020.2989576
   Li L, 2020, IEEE J-STSP, V14, P130, DOI 10.1109/JSTSP.2019.2963154
   Li Q, 2021, SIGNAL IMAGE VIDEO P, V15, P1873, DOI 10.1007/s11760-021-01937-y
   Li Y, 2018, JVETK0390
   Li Y, 2021, IEEE T BROADCAST, V67, P500, DOI 10.1109/TBC.2021.3068871
   Lim W, 2020, SIGNAL IMAGE VIDEO P, V14, P887, DOI 10.1007/s11760-019-01620-3
   Liu D, 2020, IEEE T CIRC SYST VID, V30, P1267, DOI 10.1109/TCSVT.2019.2945057
   Liu FY, 2021, IEEE T IMAGE PROCESS, V30, P4706, DOI 10.1109/TIP.2021.3072225
   Mallikarachchi T, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070120
   Marzuki I, 2020, IEEE ACCESS, V8, P165670, DOI 10.1109/ACCESS.2020.3022408
   Nakhaei A, 2021, MULTIMED TOOLS APPL, V80, P7023, DOI 10.1007/s11042-020-09710-y
   Nien YC, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103242
   Peng ZJ, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116256
   Raufmehr F, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116317
   Raufmehr F, 2021, J REAL-TIME IMAGE PR, V18, P751, DOI 10.1007/s11554-020-01018-2
   Raufmehr F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043013
   Ross T. J., 2004, FUZZY LOGIC ENG APPL
   Sainio J, 2022, IEEE T CONSUM ELECTR, V68, P387, DOI 10.1109/TCE.2022.3194596
   Seo CW, 2013, IEEE T IMAGE PROCESS, V22, P2442, DOI 10.1109/TIP.2013.2251647
   Shang M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18042101
   Shojaei M, 2020, MULTIMED TOOLS APPL, V79, P13753, DOI 10.1007/s11042-019-08563-4
   Sun XB, 2020, NEUROCOMPUTING, V411, P393, DOI 10.1016/j.neucom.2020.06.003
   Sun Y, 2021, MULTIMED TOOLS APPL, V80, P28761, DOI 10.1007/s11042-021-11055-z
   Nguyen T, 2021, IEEE T CIRC SYST VID, V31, P3801, DOI 10.1109/TCSVT.2021.3074312
   Ultra Video Group (UVG), Data Set
   vcgit hhi fraunhofer de, H.266/VVC Reference Software VTM
   Wang P, 2019, MULTIMED TOOLS APPL, V78, P23733, DOI 10.1007/s11042-019-7680-7
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang SQ, 2017, IEEE T CIRC SYST VID, V27, P2189, DOI 10.1109/TCSVT.2016.2580398
   Yan T, 2020, IEEE ACCESS, V8, P24549, DOI 10.1109/ACCESS.2020.2970063
   Yang Y, 2019, J VIS COMMUN IMAGE R, V60, P328, DOI 10.1016/j.jvcir.2019.02.031
   Ye Y, 2020, IEEE T CIRC SYST VID, V30, P1241, DOI 10.1109/TCSVT.2019.2953827
   Yuan H, 2021, IEEE T CONSUM ELECTR, V67, P97, DOI 10.1109/TCE.2021.3065636
   Zhang M, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115964
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2013, PICT COD SYMP, P353, DOI 10.1109/PCS.2013.6737756
   Zhang ZW, 2017, IEEE ACCESS, V5, P13677, DOI 10.1109/ACCESS.2017.2676125
   Zhao ZM, 2021, MULTIMED TOOLS APPL, V80, P345, DOI 10.1007/s11042-020-09721-9
   Zhou GQ, 2021, IEEE ACCESS, V9, P27140, DOI 10.1109/ACCESS.2021.3057719
   Zhou ML, 2021, IEEE T MULTIMEDIA, V23, P1106, DOI 10.1109/TMM.2020.2992968
   Zhou ML, 2020, IEEE T IMAGE PROCESS, V29, P7603, DOI 10.1109/TIP.2020.3004714
   Zupancic I, 2017, IEEE J-STSP, V11, P167, DOI 10.1109/JSTSP.2016.2634458
NR 63
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17719-2
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800008
DA 2024-07-18
ER

PT J
AU Wang, L
   Pu, YF
   Liu, PL
   Hao, Y
AF Wang, Li
   Pu, Yi-Fei
   Liu, Paul
   Hao, Yin
TI Multiscale hybrid method for speckle reduction of medical ultrasound
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ultrasound image; Speckle reduction; Multi-scale hybrid method;
   Fractional order filter; Guided filter; Directional filter
ID ANISOTROPIC DIFFUSION; ENHANCEMENT; ALGORITHM
AB This paper presents a multi-scale hybrid method for speckle reduction in ultrasound (US) images. Speckle is removed by guided filtering, directional filtering, and fractional order filtering on the coarse to fine resolution images of a wavelet pyramid. For the directional filter, the eigen-analysis of each pixel is firstly carried out to obtain its structural features, and then it is classified into edges for filtering. Speckle noise, corresponding to the homogeneous anatomical regions, is then alleviated by the guided filter. Thereby, the algorithm reduces speckle noise while enhancing edge sharpness regardless of the size of the edges. In the synthetic images, the proposed method showed statistically significant improvements in peak signal-to-noise ratio(PSNR), structural similarity(SSIM), feature similarity index(FSIM) index and Mean Squared Error(MSE) compared with other speckle reduction methods, e.g., the squeeze boxes (SBF) filter, optimal Bayesian NLM (OBNLM) filter, speckle reducing anisotropic diffusion filter (SRAD), nonlocal low-rank framework (NLLRF) and multi-scale attention-guided neural network (MSANN). Similarly, our method outperformed the other methods in terms of mainly metrics. All the clinical images that were denoised using the six speckle reduction methods were reviewed by four radiologists for evaluation based on each radiologist's diagnostic preferences. All the radiologists showed a significant preference for the liver images and arotid artery images obtained using our methods in terms of effectively suppresses speckle noise while preserving the structural details. For the kidney and thyroid images, our method showed similar improvement over other methods. The experimental results show that this method has better performance than other state-of-the-art medical ultrasonic image speckle removal methods.
C1 [Wang, Li; Pu, Yi-Fei; Hao, Yin] Sichuan Univ, Coll Comp Sci, Chengdu 610064, Sichuan, Peoples R China.
   [Liu, Paul] Stork Healthcare, Chengdu 610064, Sichuan, Peoples R China.
C3 Sichuan University
RP Pu, YF (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610064, Sichuan, Peoples R China.
EM wang_86_li@foxmail.com; puyifei_007@163.com; paulsliu@gmail.com;
   yinhao@scu.edu.cn
FU Natural Science Foundation of China
FX We thank Saset Healthcare Inc. for providing real ultrasound image data
   and engineers Chen Jueli and Shi Youling for helping to collect real
   ultrasound images. We thank all the cited authors in this article for
   their source code and Peter Tay for providing the source code of SBF
   filter. We thank all the anonymous judges for their valuable comments on
   this article.
CR Abd-Elmoniem KZ, 2002, IEEE T BIO-MED ENG, V49, P997, DOI 10.1109/TBME.2002.1028423
   Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   Andria G, 2012, MEASUREMENT, V45, P1792, DOI 10.1016/j.measurement.2012.04.005
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cardoso FM, 2012, ULTRASOUND MED BIOL, V38, DOI 10.1016/j.ultrasmedbio.2012.03.014
   Choi H, 2019, J X-RAY SCI TECHNOL, V27, P885, DOI 10.3233/XST-190515
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Ding F, 2015, DIGIT SIGNAL PROCESS, V37, P100, DOI 10.1016/j.dsp.2014.10.005
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Flores WG, 2014, ULTRASOUND MED BIOL, V40, P2609, DOI 10.1016/j.ultrasmedbio.2014.06.005
   Guo YJ, 2023, PROCEEDINGS OF 2023 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION TECHNOLOGY, ICIIT 2023, P1, DOI [10.1145/3591569.3591570, 10.1109/ICASSP49357.2023.10095621, 10.1109/TAI.2023.3235342]
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huh J, 2022, INT CONF ACOUST SPEE, P1206, DOI 10.1109/ICASSP43922.2022.9747401
   Ilesanmi AE, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102396
   Kim YS, 2005, PROC SPIE, V5747, P1085, DOI 10.1117/12.595129
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   Lan YC, 2020, IEEE ACCESS, V8, P195327, DOI 10.1109/ACCESS.2020.3034230
   Lee H, 2022, IEEE T ULTRASON FERR, V69, P2638, DOI 10.1109/TUFFC.2022.3193640
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li PC, 2002, IEEE T ULTRASON FERR, V49, P39, DOI 10.1109/58.981382
   Liang JL, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P697, DOI 10.1109/CISP.2015.7407967
   LOVE ER, 1971, J LOND MATH SOC, V3, P241, DOI 10.1112/jlms/s2-3.2.241
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   ODONNELL M, 1988, IEEE T ULTRASON FERR, V35, P470, DOI 10.1109/58.4184
   Opretzka J, 2011, IEEE T ULTRASON FERR, V58, P1355, DOI 10.1109/TUFFC.2011.1955
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2006, CURR MED IMAGING, V2, P247, DOI 10.2174/157340506776930665
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Rahimizadeh N, 2021, MULTIMED TOOLS APPL, V80, P9231, DOI 10.1007/s11042-020-10051-z
   Rossikhin YA., 1997, Appl. Mech. Rev., V50, P15, DOI DOI 10.1115/1.3101682
   Sharif SMA, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122192
   Sonka M, 1995, IEEE T MED IMAGING, V14, P719, DOI 10.1109/42.476113
   Sudeep PV, 2016, BIOMED SIGNAL PROCES, V28, P1, DOI 10.1016/j.bspc.2016.03.001
   Sudeep PV, 2015, BIOMED SIGNAL PROCES, V20, P125, DOI 10.1016/j.bspc.2015.04.015
   Sun D, 2014, SIGNAL PROCESS, V100, P132, DOI 10.1016/j.sigpro.2014.01.022
   Tay PC, 2010, IEEE T IMAGE PROCESS, V19, P1847, DOI 10.1109/TIP.2010.2044962
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TRAHEY GE, 1986, ULTRASONIC IMAGING, V8, P151, DOI 10.1016/0161-7346(86)90006-4
   Vegas-Sanchez-Ferrero G, 2010, INT C MED IM COMP CO, DOI [10.1007/978-3-642-15705-9_63, DOI 10.1007/978-3-642-15705-9_63]
   Wang Y, 2021, IEEE SIGNAL PROC LET, V28, P424, DOI 10.1109/LSP.2021.3057544
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang J, 2016, NEUROCOMPUTING, V195, P88, DOI 10.1016/j.neucom.2015.05.140
   Yoon C, 2013, BIOMED SIGNAL PROCES, V8, P876, DOI 10.1016/j.bspc.2013.08.007
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao HQ, 2016, ELECTRON LETT, V52, P712, DOI 10.1049/el.2015.3550
   Zhu L, 2017, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2017.60
NR 52
TC 1
Z9 1
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17335-0
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300006
DA 2024-07-18
ER

PT J
AU Premkumar, N
   Santhosh, R
AF Premkumar, N.
   Santhosh, R.
TI Pelican optimization algorithm with blockchain for secure load balancing
   in fog computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fog computing; Blockchain technology; Cloud computing; Secure
   authentication; Load balancing; Edge data centers
AB Rapid advancements in innovation, the Internet of Things (IoT), and edge computing have provided room for companies, government agencies, well-being administrations, and organizations to offer their kind of assistance through the cloud. Operating these cloud administrations requires monetary and computational assets to acquire and protect information from vindictive elements and to handle the multitude of information these administrations generate through nervous and IoT gadgets. Scalability, system availability, network transmission, and load relocation are some of the issues with the parallel file system. In the literature, few works are reviewed for obtaining load balancing but it does not consider the secure authentication phase in fog computing. Secure authentication and load balancing are critical challenges in a fog computing environment. In this paper, we develop Adaptive Load Balancing and Secure Authentication (ALBSA) for managing load balancing schemes and secure authentication schemes in fog computing. Normally, the Edge Data Centres (EDC) are utilized to set up as a distributed system and it is located among the data source and cloud datacentre. So, the proposed ALBSA is utilized to enable efficient authentication and workload management (load balancing). The proposed method is a combination of Blockchain technology and the Pelican Optimization Algorithm (POA). Based on resource utilization and response time, efficient load balancing is achieved. Additionally, this paper develops a blockchain-based authentication system that utilizes the characteristics and advantages of blockchain and smart contracts to authenticate users securely. The implemented system uses the email address, username, Ethereum address, password, and data from a biometric reader to register and authenticate users. The proposed methodology is implemented and evaluated based on performance metrics. To justify the efficiency of the proposed technique, it is contrasted with the traditional techniques. The proposed method is achieved, Encryption time is 4.2ms, the waiting time is 0.28ms and the decryption time is 10.21ms.
C1 [Premkumar, N.; Santhosh, R.] Karpagam Acad Higher Educ, Fac Engn, Dept Comp Sci & Engn, Coimbatore, Tamilnadu, India.
C3 Karpagam Academy of Higher Education (KAHE)
RP Premkumar, N (corresponding author), Karpagam Acad Higher Educ, Fac Engn, Dept Comp Sci & Engn, Coimbatore, Tamilnadu, India.
EM send2premkumar@gmail.com; santhoshrd@gmail.com
CR Abd Elaziz M, 2021, FUTURE GENER COMP SY, V124, P142, DOI 10.1016/j.future.2021.05.026
   Baburao D, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02143-5
   Baburao D, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-01970-w
   Hussein MK, 2020, IEEE ACCESS, V8, P37191, DOI 10.1109/ACCESS.2020.2975741
   Kashani MH, 2023, IEEE T SERV COMPUT, V16, P1505, DOI 10.1109/TSC.2022.3174475
   Kashyap V, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7183
   Kaur M, 2022, WIRELESS PERS COMMUN, V125, P3549, DOI 10.1007/s11277-022-09724-9
   Kaur M, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09584-w
   Kaur M, 2021, J SUPERCOMPUT, V77, P9202, DOI 10.1007/s11227-020-03600-8
   Kaur N, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6432
   Kishor Amit., 2021, Wirel Pers Commun, P1
   Liu YH, 2021, CLUSTER COMPUT, V24, P1331, DOI 10.1007/s10586-020-03190-3
   Ngabo D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172110
   Nguyen TA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186253
   Razaq MM, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/4218696
   Singh SP, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100766
   Singh SP, 2022, CLUSTER COMPUT, V25, P3325, DOI 10.1007/s10586-022-03554-x
   Singh SP, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5913
   Singh SP, 2021, IETE J RES, V67, P603, DOI 10.1080/03772063.2021.1874840
   Sulimani H., 2021, Procedia Computer Science, V191, P93, DOI [10.1016/j.procs.2021.07.015, DOI 10.1016/J.PROCS.2021.07.015]
   Tripathy Subhranshu Sekhar, 2022, Advances in Communication, Devices and Networking: Proceedings of ICCDN 2020. Lecture Notes in Electrical Engineering (776), P277, DOI 10.1007/978-981-16-2911-2_30
   Trojovsky P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030855
   Tuerxun W, 2022, MACHINES, V10, DOI 10.3390/machines10050407
   Umoren O, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103956
   Wang HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245538
   Wu D, 2020, IEEE INTERNET THINGS, V7, P6603, DOI 10.1109/JIOT.2020.2974231
NR 26
TC 2
Z9 2
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 18
PY 2023
DI 10.1007/s11042-023-17632-8
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y5JY5
UT WOS:001105630500003
DA 2024-07-18
ER

PT J
AU Alzahir, S
   Islam, W
AF Alzahir, Saif
   Islam, Wahedul
TI Blind image-variant based authentication method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image-variant; Image authentication; Image watermarking; QR-codes;
   DICOM; Singular value decomposition
ID WATERMARKING SCHEME; MULTI-WATERMARKING; DWT; ROBUST
AB There is a plethora of image authentication techniques in the literature. Almost all of these methods use either a form of watermarking or data hiding techniques to embed data directly in the original image or its decomposed sub-bands. Recently, new multiple watermarking methods have emerged to tackle more robust forgery challenges where a single watermark fails or insufficient. Most of these methods are directed towards medical images for obvious reasons. This paper presents a new precise blind image-variant authentication method. This method initiates a new direction for research on image authentication as it does not embed any sort of data in the original image or its decomposed sub-band(s) but rather produces an image-variant via manipulating some statistics of the original image. These variations represent two sequences which were infused in two QR-codes that enabled the variation process. We tested this method against image processing attacks including JPEG compression, resizing, and Gaussian-noise using images from several databases including the USC - SIPI, McGill Calibrated Color Image, DICOM medical image. Also, we compared this method performance with results from seven 7 published methods and found that our method scored higher performance results for robustness and imperceptibility and it regenerated the variation secret sequences with 100% accuracy in each case. Furthermore, this method capacity is large enough to prevent data-overflow.
C1 [Alzahir, Saif] Concordia Univ, ECE Dept, 1455 Maisonneuve Blvd, Montreal, PQ H3G 1M8, Canada.
   [Islam, Wahedul] UNBC, Comp Sci Dept, Prince George, BC, Canada.
C3 Concordia University - Canada; University of British Columbia;
   University of Northern British Columbia
RP Alzahir, S (corresponding author), Concordia Univ, ECE Dept, 1455 Maisonneuve Blvd, Montreal, PQ H3G 1M8, Canada.
EM saifalzahir@gmail.com; islamm@unbc.ca
CR Al Zahir S, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P723, DOI 10.1109/ICCE.2011.5722830
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   alZahir S, 2018, CAN CON EL COMP EN
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], DIGITAL IMAGING COMM
   [Anonymous], Rec. ITU-R BT.601-4
   [Anonymous], QR Codes
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Boussif M, 2020, MED BIOL ENG COMPUT, V58, P2905, DOI 10.1007/s11517-020-02269-8
   Cheddad A., 2010, Digital Image Steganography: Survey and Analysis of current methods, P727
   Chou CH, 2006, P 2006 INT C INT INF
   Daren H, 2001, IEEE INT C MULT EXP, P429
   Dharwadkar N. V., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P489, DOI 10.1109/ICCSP.2011.5739368
   Dugad R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P419, DOI 10.1109/ICIP.1998.723406
   Elbasi E, 2006, IS T SPIES 18 ANN S
   Elbasi E., 2006, J ISTANBUL COMMERCIA, V5, P119
   Feng G, 2008, P SOC PHOTO-OPT INS, V6623, pK6231, DOI 10.1117/12.791517
   Ganic E., 2004, MM SEC 04 SEPT 20 21, DOI [10.1145/1022431.1022461, DOI 10.1145/1022431.1022461]
   Islam MW, 2012, VIS IMAGING IMAGE PR, P3
   Lee MH, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1592
   Lee W, 2005, LECT NOTES COMPUT SC, V3528, P254
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Meerwald P, 2009, IEEE T MULTIMEDIA, V11, P1037, DOI 10.1109/TMM.2009.2021793
   Rakhmawati L, 2020, Int J Intell Eng Syst, V13
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Yin CQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2607, DOI 10.1109/ICAL.2007.4339020
   Yuan XC, 2018, SIGNAL PROCESS, V149, P103, DOI 10.1016/j.sigpro.2018.03.007
   Zear A, 2016, J Intell Syst
   Zhang R, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1591206
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   US
NR 35
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17547-4
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300009
DA 2024-07-18
ER

PT J
AU Sharma, D
   Chandra, P
AF Sharma, Deepak
   Chandra, Pravin
TI An empirical analysis of software fault proneness using factor analysis
   with regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bugs; Faults Prediction; Latent variables; Factor Analysis with
   Regression Analysis
ID OBJECT-ORIENTED CLASSES; SENSITIVITY-ANALYSIS; PREDICTION; METRICS;
   RELIABILITY; CLASSIFICATION; VALIDATION; MODELS; TIME; COMPLEXITY
AB The fault prediction process becomes essential in the early stages of Software Development Life Cycle, so as to be able to generate various modules that can thereafter help detect faulty modules and classes. Further, this procedure will facilitate identification of modules that require a high level of refactoring during the maintenance stage. Hence, the current research proposes a mechanism to recognise faults and to explore the usability of Factor Analysis with Regression (FAWR) which can help ameliorate the system performance remarkably. To direct this study, two research questions (RQ) are defined- how can integration of techniques to enhance the development of fault prediction model, and evaluation of the suggested technique to overcome the limitations of the older methods. In order to answer these RQs, FAWR techniques are applied. The quality of the technique is then tested through two experiments. Results reveal that FAWR is the better performing method in terms of its prediction capability compared to the two methods used individually. For example, values for different performance metrics such as accuracy, precision, recall and F1 score reported by FAWR technique are 89.34%, 88.73%, 88.49 % and 88.61 %, respectively. The current study has practical implications as the models constructed to estimate the proneness of faults surpass the standard regression models. The factorization method used shall be able to classify any module based on its fault proneness. The more efficient and reliable software thus produced will have better outcomes for the users for basic and applied research purposes.
C1 [Sharma, Deepak] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Delhi 110078, India.
   [Chandra, Pravin] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect 16 C, New Delhi 110078, India.
C3 GGS Indraprastha University; GGS Indraprastha University
RP Sharma, D (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Delhi 110078, India.
EM deepak.usict.9000501@ipu.ac.in; chandra.pravin@gmail.com
OI Sharma, Deepak/0000-0002-3494-8401
FU The authors are indebted to the anonymous reviewers for their valuable
   comments which has brought clarity to the paper.
FX The authors are indebted to the anonymous reviewers for their valuable
   comments which has brought clarity to the paper.
CR Aggarwal K. K., 2009, Software Process: Improvement and Practice, V14, P39, DOI 10.1002/spip.389
   Aiken L S., 2012, Handbook of Psychology, VSecond, P511, DOI DOI 10.1002/9781118133880.HOP202018
   Al Dallal J, 2018, ARAB J SCI ENG, V43, P7153, DOI 10.1007/s13369-017-3012-2
   Al Dallal J, 2014, EMPIR SOFTW ENG, V19, P775, DOI 10.1007/s10664-012-9239-3
   Al Dallal J, 2013, INFORM SOFTWARE TECH, V55, P2028, DOI 10.1016/j.infsof.2013.07.005
   Al Dallal J, 2012, INFORM SOFTWARE TECH, V54, P396, DOI 10.1016/j.infsof.2011.11.007
   Al Dallal J, 2011, INFORM SOFTWARE TECH, V53, P914, DOI 10.1016/j.infsof.2011.03.004
   Arar ÖF, 2015, APPL SOFT COMPUT, V33, P263, DOI 10.1016/j.asoc.2015.04.045
   Basili VR, 1996, IEEE T SOFTWARE ENG, V22, P751, DOI 10.1109/32.544352
   Binkley AB, 1998, PROC INT CONF SOFTW, P452, DOI 10.1109/ICSE.1998.671604
   Briand L. C., 2001, Empirical Software Engineering, V6, P11, DOI 10.1023/A:1009815306478
   BRIAND LC, 1993, IEEE T SOFTWARE ENG, V19, P1028, DOI 10.1109/32.256851
   BROWNE MW, 1969, PSYCHOMETRIKA, V34, P375, DOI 10.1007/BF02289365
   Cang L, 2004, J ENVIRON SCI-CHINA, V16, P371
   Catal C, 2009, EXPERT SYST APPL, V36, P7346, DOI 10.1016/j.eswa.2008.10.027
   Challagulla VUB, 2005, WORDS 2005: 10TH IEEE INTERNATIONAL WORKSHOP ON OBJECT-ORIENTED REAL-TIME DEPENDABLE, PROCEEDINGS, P263, DOI 10.1109/WORDS.2005.32
   Chandrasekaran M, 2010, INT J ADV MANUF TECH, V46, P445, DOI 10.1007/s00170-009-2104-x
   Chatterjee S, 2017, NEURAL COMPUT APPL, V28, pS1221, DOI 10.1007/s00521-016-2437-y
   Chatterjee S, 2016, ARAB J SCI ENG, V41, P5009, DOI 10.1007/s13369-016-2189-0
   Chatterjee S, 2016, SOFT COMPUT, V20, P4023, DOI 10.1007/s00500-015-1738-x
   Chatterjee S, 2015, QUAL RELIAB ENG INT, V31, P1517, DOI 10.1002/qre.1687
   Chaturvedi DK, 2008, STUD COMPUT INTELL, V103, P1, DOI 10.1007/978-3-540-77481-5
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Chiang MC, 2021, IEEE T RELIAB, V70, P13, DOI 10.1109/TR.2020.2968884
   CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895
   Cohen J., 2013, APPL MULTIPLE REGRES
   Cohen W. W., 1997, 14 INT C MACH LEARN, P66
   Colanzi TE, 2020, INFORM SOFTWARE TECH, V127, DOI 10.1016/j.infsof.2020.106372
   Dagpinar M, 2003, 10TH WORKING CONFERENCE ON REVERSE ENGINEERING, PROCEEDINGS, P155, DOI 10.1109/WCRE.2003.1287246
   de Almeida MA, 1999, Lecture Notes in Computer Science, V1609, DOI [10.1007/BFb0095145, DOI 10.1007/BFB0095145]
   Dejaeger K, 2013, IEEE T SOFTWARE ENG, V39, P237, DOI 10.1109/TSE.2012.20
   Dhanajayan RCG, 2017, SOFT COMPUT, V21, P403, DOI 10.1007/s00500-016-2316-6
   Di Nucci D, 2018, IEEE T SOFTWARE ENG, V44, P5, DOI 10.1109/TSE.2017.2659747
   Eivazpour Z, 2019, IN THE 7 INT C CONT, P299
   Erturk E, 2016, APPL SOFT COMPUT, V49, P1020, DOI 10.1016/j.asoc.2016.08.025
   Erturk E, 2015, EXPERT SYST APPL, V42, P1872, DOI 10.1016/j.eswa.2014.10.025
   Evett M., 1998, Genetic Programming 1998. Proceedings of the Third Annual Conference, P60
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   GOEL AL, 1979, IEEE T RELIAB, V28, P206, DOI 10.1109/TR.1979.5220566
   Goyal R, 2017, J KING SAUD UNIV-COM, V29, P93, DOI 10.1016/j.jksuci.2014.12.008
   Goyal R, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-627
   Goyal S, 2022, MULTIMED TOOLS APPL, V81, P37033, DOI 10.1007/s11042-021-11488-6
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Gyimóthy T, 2005, IEEE T SOFTWARE ENG, V31, P897, DOI 10.1109/TSE.2005.112
   HARMAN GH, 1967, J PHILOS, V64, P75, DOI 10.2307/2023773
   Hassan AE, 2009, PROC INT CONF SOFTW, P78, DOI 10.1109/ICSE.2009.5070510
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   Huang CY, 2005, IEEE T RELIAB, V54, P592, DOI 10.1109/TR.2005.858099
   Jabangwe R, 2015, EMPIR SOFTW ENG, V20, P640, DOI 10.1007/s10664-013-9291-7
   Kapur PK, 2011, IEEE T RELIAB, V60, P331, DOI 10.1109/TR.2010.2103590
   KARNAVAS WJ, 1993, IEEE T SYST MAN CYB, V23, P488, DOI 10.1109/21.229461
   Khoshgoftaar TM, 2005, INTELL DATA ANAL, V9, P347, DOI 10.3233/IDA-2005-9403
   Khoshgoftaar TM, 2004, EMPIR SOFTW ENG, V9, P229, DOI 10.1023/B:EMSE.0000027781.18360.9b
   Khoshgoftaar TM, 1997, IEEE T NEURAL NETWOR, V8, P902, DOI 10.1109/72.595888
   Killick R, 2014, J STAT SOFTW, V58, P1
   Kitchenham BA, 2001, IEEE T SOFTWARE ENG, V27, P788, DOI 10.1109/32.950316
   Koru AG, 2005, IEEE SOFTWARE, V22, P23, DOI 10.1109/MS.2005.149
   Kosker Y, 2009, EXPERT SYST APPL, V36, P10000, DOI 10.1016/j.eswa.2008.12.066
   Kumari S, 2021, COMPUT COMMUN, V178, P161, DOI 10.1016/j.comcom.2021.07.023
   Kuszaj S, 1999, J PROTEIN CHEM, V18, P147, DOI 10.1023/A:1020615703727
   LANUBILE F, 1995, SEKE '95, PROCEEDINGS, P312
   LAWLEY DN, 1973, BIOMETRIKA, V60, P331, DOI 10.2307/2334544
   Liang Yin, 1999, Proceedings 10th International Symposium on Software Reliability Engineering (Cat. No.PR00443), P6, DOI 10.1109/ISSRE.1999.809305
   Lo JH, 2005, J SYST SOFTWARE, V76, P3, DOI 10.1016/j.jss.2004.06.025
   Mahabal Anil S., 2004, P1
   Malviya S, 2022, Trans Asian Low-Resour Lang Inf Process
   Menzies T., 2004, P WORKSH PRED SOFTW, P1
   Mockus A, 2000, BELL LABS TECH J, V5, P169, DOI 10.1002/bltj.2229
   Mohanty Ramakanta, 2010, International Journal of Information and Decision Sciences, V2, P233, DOI 10.1504/IJIDS.2010.033450
   Ohlsson N, 1998, SOFTWARE QUAL J, V7, P51, DOI 10.1023/A:1008844909795
   Olague HM, 2007, IEEE T SOFTWARE ENG, V33, P402, DOI 10.1109/TSE.2007.1015.
   Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49
   Panichella A, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1077, DOI 10.1145/2908812.2908938
   Pillai K, 1997, IEEE T SOFTWARE ENG, V23, P485, DOI 10.1109/32.624305
   Porter A. A., 1990, Journal of Systems and Software, V12, P209, DOI 10.1016/0164-1212(90)90041-J
   Ramani RG, 2012, 2012 IEEE INT C COMP, P1, DOI [10.1109/ICCIC.2012.6510294, DOI 10.1109/ICCIC.2012.6510294]
   Rathore SS, 2017, SOFT COMPUT, V21, P7417, DOI 10.1007/s00500-016-2284-x
   Riquelme J., 2008, Actas de los Talleres de las Jornadas de Ingenieria del Software y Bases de Datos, V2, P67
   Runkler T. A., 2012, DATA ANAL, DOI [10.1007/978-3-8348-2589-6, DOI 10.1007/978-3-8348-2589-6]
   Sarkar S., 2015, SSRG INT J COMPUT SC, V2, P18, DOI DOI 10.14445/23488387/IJCSE-V2I8P104
   Saxena P., 2011, Int. J. Comput. Appl., V22, P41, DOI 10.5120/2600-3626
   SCHMITT N, 1977, PSYCHOL BULL, V84, P751, DOI 10.1037/0033-2909.84.4.751
   Schneidewind N. F., 1975, SIGPLAN Notices, V10, P337, DOI 10.1145/390016.808456
   Sharma Deepak, 2019, International Journal of Information Technology, V11, P37, DOI 10.1007/s41870-018-0211-3
   Sharma D., 2020, Int J Computat Syst Eng, V6, P14, DOI [10.1504/IJCSYSE.2020.109110, DOI 10.1504/IJCSYSE.2020.109110]
   Sharma D., 2018, Smart Computing and Informatics, P541
   Sharma D, 2020, J INTERDISCIP MATH, V23, P11, DOI 10.1080/09720502.2020.1721641
   Sharma D, 2019, INT J SYST ASSUR ENG, V10, P1453, DOI 10.1007/s13198-019-00896-5
   Sharma D, 2018, PROCEEDINGS OF THE 2018 SECOND WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4), P193, DOI 10.1109/WorldS4.2018.8611559
   Sharma D, 2017, ADV INTELL SYST COMP, V547, P220, DOI 10.1007/978-981-10-3325-4_22
   Shatnawi R, 2008, J SYST SOFTWARE, V81, P1868, DOI 10.1016/j.jss.2007.12.794
   Singh SK, 2017, MULTIMED TOOLS APPL, V76, P18771, DOI 10.1007/s11042-017-4419-1
   Singh Y, 2010, SOFTWARE QUAL J, V18, P3, DOI 10.1007/s11219-009-9079-6
   Staron M, 2018, INFORM SOFTWARE TECH, V98, P117, DOI 10.1016/j.infsof.2018.03.001
   Subramanyam R, 2003, IEEE T SOFTWARE ENG, V29, P297, DOI 10.1109/TSE.2003.1191795
   Turhan B, 2009, EMPIR SOFTW ENG, V14, P540, DOI 10.1007/s10664-008-9103-7
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang J, 2022, MULTIMED TOOLS APPL, V81, P41611, DOI 10.1007/s11042-021-11007-7
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   WHITELY SE, 1981, J EDUC MEAS, V18, P67, DOI 10.1111/j.1745-3984.1981.tb00843.x
   Xie M, 2007, QUAL RELIAB ENG INT, V23, P459, DOI 10.1002/qre.827
   Xie M., 1992, Proceedings. Third International Symposium on Software Reliability Engineering (Cat. No.92TH0486-1), P184, DOI 10.1109/ISSRE.1992.285846
   YAMADA S, 1983, IEEE T RELIAB, V32, P475, DOI 10.1109/TR.1983.5221735
   YAMADA S, 1992, INT J SYST SCI, V23, P2241, DOI 10.1080/00207729208949452
   ZADEH LA, 1994, IEEE SOFTWARE, V11, P48, DOI 10.1109/52.329401
NR 105
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17518-9
EA NOV 2023
PG 57
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakraborty, D
   Rudrapal, D
   Bhattacharya, B
AF Chakraborty, Debatosh
   Rudrapal, Dwijen
   Bhattacharya, Baby
TI A multimodal sentiment analysis approach for tweets by comprehending
   co-relations between information modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Multimodal sentiment analysis; Machine learning;
   Social media text
ID FUSION; CLASSIFICATION; RECOGNITION; LANGUAGE; CONTEXT
AB With the popularity of smart devices and online social media platforms, people are expressing their views in various modalities like text, images, and audio. Thus, recent research in sentiment analysis is no more limited to one modality of information only, rather it compiles all the available modalities to predict more correct sentiment. Multimodal sentiment analysis (MSA) is the process of extracting sentiment from various modalities such as text, images, and audio. Existing research works predict the sentiment of individual modalities independently and these predictions leverage the final sentiment. This paper presents an MSA approach for obtaining the final sentiment of an image-text tweet using multimodal decision-level fusion by incorporating features of individual modalities and inter-modal semantic relations. A dataset is prepared from an existing benchmark MSA dataset by annotating the final sentiment to tweets as a whole after assessing all the modalities. The proposed approach is experimented on this dataset and compared with state-of-the-art MSA methods. The in-depth analysis of the comparison results shows that the proposed approach outperforms existing methods in terms of accuracy, and F1-score.
C1 [Chakraborty, Debatosh; Bhattacharya, Baby] NIT Agartala, Dept Math, Agartala, India.
   [Rudrapal, Dwijen] NIT Agartala, Dept CSE, Agartala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; National Institute of Technology (NIT System);
   National Institute of Technology Agartala
RP Rudrapal, D (corresponding author), NIT Agartala, Dept CSE, Agartala, India.
EM debatosh.info01@gmail.com; dwijen.rudrapal@gmail.com;
   babybhatt75@gmail.com
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   AlexWang Amanpreet Singh, 2019, ICLR
   Barbieri F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1644
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cai GY, 2015, LECT NOTES ARTIF INT, V9362, P159, DOI 10.1007/978-3-319-25207-0_14
   Caschera MC, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6040028
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Cheema GS, 2021, MMPT '21: PROCEEDINGS OF THE 2021 WORKSHOP ON MULTI-MODAL PRE-TRAINING FOR MULTIMEDIA UNDERSTANDING, P37, DOI 10.1145/3463945.3469058
   Chen T., 2014, ARXIV14108586, DOI DOI 10.48550/ARXIV.1410.8586
   Chen T, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P367, DOI 10.1145/2647868.2654935
   Das R, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3586075
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   El-Sappagh S, 2021, FUTURE GENER COMP SY, V115, P680, DOI 10.1016/j.future.2020.10.005
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gandhi A, 2021, 2021 IEEE PUN SECT I, P1, DOI [10.1109/PuneCon52575.2021.9686504, DOI 10.1109/PUNECON52575.2021.9686504]
   Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025
   Gkoumas D, 2021, INFORM FUSION, V66, P184, DOI 10.1016/j.inffus.2020.09.005
   Goel A, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P257, DOI 10.1109/NGCT.2016.7877424
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huddar MG, 2020, INT J MULTIMED INF R, V9, P103, DOI 10.1007/s13735-019-00185-8
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Jiang T, 2020, LECT NOTES ARTIF INT, V12085, P785, DOI 10.1007/978-3-030-47436-2_59
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kaur R, 2022, Multimodal Sentiment Analysis: A Survey and Comparison, P1846, DOI [10.4018/978-1-6684-6303-1.ch098, DOI 10.4018/978-1-6684-6303-1.CH098]
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Li JH, 2021, ADV NEUR IN, V34
   Li JN, 2022, PR MACH LEARN RES
   Liao WX, 2022, APPL INTELL, V52, P11184, DOI 10.1007/s10489-021-02936-9
   Liao WX, 2021, APPL INTELL, V51, P3522, DOI 10.1007/s10489-020-01964-1
   Ligthart A, 2021, ARTIF INTELL REV, V54, P4997, DOI 10.1007/s10462-021-09973-3
   Liu MF, 2017, COMPUT VIS IMAGE UND, V163, P58, DOI 10.1016/j.cviu.2017.04.012
   Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692
   Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Miaschi A, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P110
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Niu T., 2016, MULTIMEDIA MODELING, P15, DOI [DOI 10.1007/978-3-319-27674-82, 10.1007/978-3-319-27674-8_2]
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Riaz S, 2019, CLUSTER COMPUT, V22, pS7149, DOI 10.1007/s10586-017-1077-z
   Rogers S., 2014, Twitter
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Sanagar S, 2020, IEEE ACCESS, V8, P118050, DOI 10.1109/ACCESS.2020.3005242
   Sebastiani F., 2006, P 5 INT C LANG RES E, P417, DOI DOI 10.1155/2015/715730
   Setiawan E, 2021, International Journal of Intelligent Engineering and Systems, V14, P521
   She DY, 2020, IEEE T MULTIMEDIA, V22, P1358, DOI 10.1109/TMM.2019.2939744
   Tai KS, 2015, Arxiv, DOI arXiv:1503.00075
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wang M., 2014, P INT C INT MULT COM, P76, DOI [10.1145/2632856.2632912, DOI 10.1145/2632856.2632912]
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Wu YY, 2020, DECIS SUPPORT SYST, V132, DOI 10.1016/j.dss.2020.113280
   Xi DH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102687
   Xiao Y, 2022, IEEE T INTELL TRANSP, V23, P537, DOI 10.1109/TITS.2020.3013234
   Xu J, 2019, KNOWL-BASED SYST, V178, P61, DOI 10.1016/j.knosys.2019.04.018
   Xu N, 2018, ACM/SIGIR PROCEEDINGS 2018, P929, DOI 10.1145/3209978.3210093
   Xu N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2399, DOI 10.1145/3132847.3133142
   Xu N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P152, DOI 10.1109/ISI.2017.8004895
   Yan XD, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2015), P594, DOI 10.1109/BWCCA.2015.32
   Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266
   Yang T, 2016, CHIN CONTR CONF, P7042, DOI 10.1109/ChiCC.2016.7554468
   Yang XC, 2021, IEEE T MULTIMEDIA, V23, P4014, DOI 10.1109/TMM.2020.3035277
   You QZ, 2017, AAAI CONF ARTIF INTE, P231
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu YH, 2016, ALGORITHMS, V9, DOI 10.3390/a9020041
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao ZY, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102097
NR 81
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17569-y
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200020
DA 2024-07-18
ER

PT J
AU Zhuohang, S
AF Zhuohang, Shi
TI Dynamic convolution-based image dehazing network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image dehazing; Dynamic convolution; Normalization; Transformer
AB Convolutional neural networks use a convolutional kernel with static weights for processing non-uniform haze or dense fog, which may lead to redundancy of network parameters. To address the structural limitations of convolution, dynamic convolution has been proposed and received wide attention; however, its direct application to image dehazing tasks still suffers from parameter redundancy, simple structure, and lack of information exchange in different dimensions. To solve these problems, a novel dynamic convolution-based image dehazing network DyStd-Net is proposed, which uses a novel dynamic convolution TDyConv, which uses the Transformer mechanism to dynamically adjust the weights of the output channel dimension and spatial dimension of the convolution kernel according to the input, giving the convolution a larger perceptual field and better nonlinear representation. In addition, a standard deviation normalization scheme StdNorm for the dynamic convolution kernel weights is explored to accelerate the dynamic convolution training. DyStd-Net adopts a U-Net-like structure and combines dynamic convolution with depth-separable convolution, making full use of image features of different dimensions to recover fog-free images. A combination of smoothed L1 loss, SSIM loss, and Perceptual Loss is used in the training process for parameter optimization. Tests on synthetic and real fogging datasets show that DyStd-Net achieves higher PSNR and SSIM metrics and provides better subjective perception compared with mainstream dehazing algorithms.
C1 [Zhuohang, Shi] Chengdu Univ Technol, Sch Comp & Network Secur, Oxford Brookes Inst, Chengdu 610059, Sichuan, Peoples R China.
C3 Chengdu University of Technology
RP Zhuohang, S (corresponding author), Chengdu Univ Technol, Sch Comp & Network Secur, Oxford Brookes Inst, Chengdu 610059, Sichuan, Peoples R China.
EM 763821768@qq.com
FU Chengdu University of Technology campus-level science and technology
   project final results [CX2022-215]; Chengdu University of Technology
   Yibin campus professional development fee project [22100-000039]
FX 2022 Chengdu University of Technology campus-level science and
   technology project final results (CX2022-215); Chengdu University of
   Technology Yibin campus professional development fee project
   (22100-000039)
CR Almalawi A, 2022, CHEMOSPHERE, V303, DOI 10.1016/j.chemosphere.2022.134960
   Ancuti CO, 2021, IEEE COMPUT SOC CONF, P627, DOI 10.1109/CVPRW53098.2021.00074
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   [Anonymous], 1952, VISION ATMOSPHERE
   [Anonymous], 2016, P ADV NEUR INF PROC
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li C., 2021, INT C LEARNING REPRE
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santurkar S, 2018, ADV NEUR IN, V31
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Yang B, 2019, ADV NEUR IN, V32
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
NR 30
TC 0
Z9 0
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17408-0
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200013
DA 2024-07-18
ER

PT J
AU Sapna, S
   Sandhya, S
   Acharya, V
   Ravi, V
AF Sapna, S.
   Sandhya, S.
   Acharya, Vasundhara
   Ravi, Vinayakumar
TI Apple foliar leaf disease detection through improved capsule neural
   network architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Apple leaf disease; Deep learning; Capsule Network; Convolutional neural
   network
AB Apple Scab and Apple Rust are the major classes of apple leaf diseases that gravely affect the apple yield. Seeking an automatic, less expensive, fast yet precise method to detect plant diseases is crucial. Traditional approaches to detect plant diseases using computer vision involve complex and labor-intensive methodologies that rely on image enhancement methods and hand-engineered features. The deep convolutional neural network models are highly favourable in performing image classification with many target classes without involving the arduous phase of feature engineering. In this paper, we utilized the Capsule Neural Network (CapsNet) architecture and modified the network structure by adding additional convolution layers to enhance the model's learning capacity to classify the apple diseases into apple rust, apple scab, healthy, and multiple diseases on the same leaf. Model training was performed on a dataset of images that reflected complex growing conditions observed in the real world. The ability of the model to learn was improved by enhancing the images. Experimentation was conducted on the Kaggle Plant Pathology 2020 - FGVC7 dataset. Experimental study demonstrated a recognition accuracy of 91.37% on the test set, with an overall improvement of 3.67% in accuracy when compared to the research work utilizing the same dataset in literature. Therefore, the proposed method effectively achieves Apple foliar leaf disease detection and surpasses existing state-of-the-art techniques applied to the same dataset. "(Dataset Link: https://www.kaggle.com/c/plant-pathology-2020-fgvc7/data)"
C1 [Sapna, S.] Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA.
   [Sandhya, S.] Nitte Univ, NMAM Inst Technol, Dept Informat Sci & Engn, Nitte, India.
   [Acharya, Vasundhara] Manipal Acad Higher Educ MAHE, Manipal Inst Technol MIT, Manipal, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
C3 Michigan State University; NITTE (Deemed to be University); NMAM
   Institute of Technology; Manipal Academy of Higher Education (MAHE);
   Prince Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM sapnasad@msu.edu; sandhyasadananda03@gmail.com; vravi@pmu.edu.sa
RI Sapna, S/HTP-0969-2023; Ravi, Vinayakumar/L-4202-2018
OI Sapna, S/0000-0001-5773-5583; Ravi, Vinayakumar/0000-0001-6873-6469
CR Amara J., 2017, DATENBANKSYSTEME BUS
   Ayu H. R., 2021, Journal of Physics: Conference Series, V1751, DOI 10.1088/1742-6596/1751/1/012072
   Baranwal S, 2019, P INT C SUST COMP SC
   Bhatia GS, 2020, LECT NOTE DATA ENG, V44, P408, DOI 10.1007/978-3-030-37051-0_47
   Bi CK, 2022, MOBILE NETW APPL, V27, P172, DOI 10.1007/s11036-020-01640-1
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Dalianis, 2018, CLIN TEXT MINING, DOI DOI 10.1007/978-3-319-78503-5_6
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Gabbouj M, 1998, P 9 EUROPEAN SIGNAL
   Gupta S, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/4710842
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Rongjie, 2020, CSSE '20: Proceedings of the 3rd International Conference on Computer Science and Software Engineering, P58, DOI 10.1145/3403746.3403905
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal A, 2020, Advances in biomedical engineering and technology, P199
   Jakjoud F., 2019, P 4 INT C BIG DAT IN
   Jearanaiwongkul W, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION TECHNOLOGY (IAIT2018), DOI 10.1145/3291280.3291786
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li LH, 2019, P 3 INT C VISION IMA, P1
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu L, 2019, P 2019 INT C VID SIG, P49
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Oyewola DO, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.352
   Park H, 2017, I C INF COMM TECH CO, P129
   Patidar S., 2020, MACHINE LEARNING IMA, V1240, P278, DOI 10.1007/978- 981-15- 6315-7_23
   Patil B.V., 2021, Evolutionary Computing and Mobile Sustainable Networks, P875
   Petrellis N., 2017, P 21 PAN HELL C INF, P1
   Rehman ZU, 2021, IET IMAGE PROCESS, V15, P2157, DOI 10.1049/ipr2.12183
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Subetha T., 2021, Mater. Today Proc, DOI DOI 10.1016/J.MATPR.2020.11.993
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thapa R, 2020, APPL PLANT SCI, V8, DOI 10.1002/aps3.11390
   Trivedi Jay, 2020, Emerging technology trends in electronics, communication and networking, P267, DOI DOI 10.1007/978-981-15-7219-7_23
   Wan H, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P5, DOI 10.1145/3380688.3380697
   Wozniak M, 2018, NEURAL NETWORKS, V98, P16, DOI 10.1016/j.neunet.2017.10.009
   Xu C., 2023, Convolutional Neural Networks and Deep Learning For Crop Improvement and Production, V16648714, P182
   Yu HJ, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.2.020507
NR 41
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17463-7
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500001
DA 2024-07-18
ER

PT J
AU Sujithra, BS
   Jerome, SA
AF Sujithra, B. S.
   Jerome, S. Albert
TI Identification of glaucoma in fundus images utilizing gray wolf
   optimization with deep convolutional neural network-based resnet50 model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bilateral with Unsharp Filter; Glaucoma detection; Gray Wolf
   Optimization with deep convolutional neural network classifier;
   Hysteresis thresholding with morphological post segmentation process;
   ResNet-50
ID OPTIC DISC; VESSELS
AB The main objective of this research is to explore and predict the potentiality of the image analysis model for early detection and diagnosis of glaucoma for assessing ocular pathologies. The proposed Computer-Aided Diagnosis system can assist the ophthalmologist in diagnosing ocular diseases by providing a second opinion as a human expert's decision. The database images are acquired from the various public datasets available on the website and in the clinical. After that, these images are collected to perform the preprocessing techniques, which improve the quality of the image in their appearance and experimental results. Next, image segmentation is performed for blood vessel segmentation from the fundus retinal image. Then the segmented output is fed Gray Wolf Optimization with a deep convolutional neural network-based ResNet50 model. Ultimately, the Fundus images are classified by utilizing a Gray Wolf Optimization with deep convolutional neural network-based ResNet50 model-based transfer learning classifier. A different benchmark dataset and a private dataset are used to validate the performance of the proposed algorithm. The efficacy of the proposed system is evaluated by different performance measures like accuracy, sensitivity, and specificity. The results show the improvement of diagnosis in the proposed method compared to other methods.
C1 [Sujithra, B. S.] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, TamilNadu, India.
RP Sujithra, BS (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
EM sujithrasaran2023@gmail.com; albertjerome@niuniv.com
RI JEROME, S ALBERT/AAJ-5555-2021; B S, Sujithra/KRQ-7428-2024
OI JEROME, S ALBERT/0009-0008-0155-8053; B S, Sujithra/0000-0002-6841-6251
FU The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of the freely-accessible public ORIGA, SCES, and
   SINDI database. Then we would like to acknowl; Noorul Islam Center for
   Higher Education
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of the freely-accessible public ORIGA, SCES, and
   SINDI database. Then we would like to acknowledge Dr. Somervell Memorial
   C.S.I. Medical College & Hospital, Kerala, India for providing the
   in-house clinical data. Finally, we would like to thank the anonymous
   reviewers for helping to organize this text.
CR Ali MAS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111763
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Barros DMS, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-00767-2
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Brown J.M., 2021, State of the Art in Neural Networks and their Applications, P219
   Burton MJ, 2021, LANCET GLOB HEALTH, V9, pE489, DOI 10.1016/S2214-109X(20)30488-5
   Cao X., 2021, ANN EYE SCI, V6, P27, DOI [10.21037/aes-2020-lt, DOI 10.21037/AES-2020-LT]
   Carvalho NRD, 2021, NEUROCOMPUTING, V438, P72, DOI 10.1016/j.neucom.2020.07.146
   Chai YD, 2018, KNOWL-BASED SYST, V161, P147, DOI 10.1016/j.knosys.2018.07.043
   Chaudhary PK, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102237
   ConduracheAP AachT, 2005, P 9 IAPR C MACH VIS, P269
   Dinç B, 2023, WIRELESS PERS COMMUN, V129, P2727, DOI 10.1007/s11277-023-10255-0
   Forrest SL, 2023, GLOB HEALTH-SCI PRAC, V11, DOI 10.9745/GHSP-D-22-00091
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Gang L, 2002, IEEE T BIO-MED ENG, V49, P168, DOI 10.1109/10.979356
   Girard F, 2019, ARTIF INTELL MED, V94, P96, DOI 10.1016/j.artmed.2019.02.004
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   Hasan MK, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.102001
   Imtiaz R, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107036
   Incir R, 2024, MULTIMED TOOLS APPL, V83, P12185, DOI 10.1007/s11042-023-15754-7
   Jena PK, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010025
   Jero S, 2021, IEEE REAL TIME, P1, DOI 10.1109/RTAS52030.2021.00009
   Juneja M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108009
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Khalil T, 2021, INT J IMAG SYST TECH, V31, P1155, DOI 10.1002/ima.22541
   Lin MQ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17753-4
   Medeiros FA, 2021, OPHTHALMOLOGY, V128, P383, DOI 10.1016/j.ophtha.2020.07.045
   Morales S, 2013, IEEE T MED IMAGING, V32, P786, DOI 10.1109/TMI.2013.2238244
   Pascolini D, 2012, BRIT J OPHTHALMOL, V96, P614, DOI 10.1136/bjophthalmol-2011-300539
   Rani KV, 2022, IETE J RES, V68, P1485, DOI 10.1080/03772063.2019.1654935
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P4571, DOI 10.1007/s11760-023-02693-x
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P3873, DOI 10.1007/s11760-023-02616-w
   Rani KV, 2021, J AMB INTEL HUM COMP, V12, P7667, DOI 10.1007/s12652-020-02485-y
   Rasti R, 2018, IEEE T MED IMAGING, V37, P1024, DOI 10.1109/TMI.2017.2780115
   Rodrigues LC, 2017, BIOMED SIGNAL PROCES, V36, P39, DOI 10.1016/j.bspc.2017.03.014
   Saba T, 2018, MICROSC RES TECHNIQ, V81, P1105, DOI 10.1002/jemt.23094
   Sallow AB, 2019, Acad J Nawroz Univ, V8, P67, DOI [10.25007/ajnu.v8n3a398, DOI 10.25007/AJNU.V8N3A398]
   Sau Paresh Chandra, 2021, Proceedings of International Conference on Big Data, Machine Learning and their Applications. ICBMA 2019. Lecture Notes in Networks and Systems (LNNS 150), P85, DOI 10.1007/978-981-15-8377-3_8
   Senjam SS, 2020, J FAM MED PRIM CARE, V9, P2200, DOI 10.4103/jfmpc.jfmpc_111_20
   Shabbir A, 2021, MATH BIOSCI ENG, V18, P2033, DOI 10.3934/mbe.2021106
   Shibata N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33013-w
   Shoukat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101738
   Sudhan MB, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/1601354
   Sujithra BS, 2024, SIGNAL IMAGE VIDEO P, V18, P465, DOI 10.1007/s11760-023-02751-4
   Tang Michael Chi Seng, 2020, 2020 11th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0728, DOI 10.1109/IEMCON51383.2020.9284931
   Rani KV, 2020, IET IMAGE PROCESS, V14, P3355, DOI 10.1049/iet-ipr.2020.0407
   Zedan MJM, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13132180
   Zhang L, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106328
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
NR 49
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17506-z
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900004
DA 2024-07-18
ER

PT J
AU Gupta, M
   Rajnish, K
   Bhattacharjee, V
AF Gupta, Mansi
   Rajnish, Kumar
   Bhattacharjee, Vandana
TI Software fault prediction with imbalanced datasets using SMOTE-Tomek
   sampling technique and Genetic Algorithm models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; SMOTE-Tomek; Tomek; Mutual information;
   Genetic algorithm and software fault prediction
AB Over the years, there has been a considerable discussion regarding machine learning (ML) techniques to forecast software faults. It can be challenging to choose a suitable machine learning technique for fault prediction modelling because of variations in the prediction performance of machine learning techniques for software systems. The evaluation of previously presented software fault prediction (SFP) approaches revealed that single machine learning-based models that did not deliver the best accuracy and F1-Score in any context, emphasizing the need to use multiple techniques, such as sampling and selection, in addition to the application of machine learning models. In order to address this issue, we present and discuss a method for predicting software faults that rely on choosing the most suitable machine learning and deep learning techniques from a pool of accurate and competitive learning techniques in order to construct a fault prediction model. The presented approach chooses the best features using Mutual Information feature selection technique. Using a hybrid sampling (SMOTE-Tomek) techniques, the issue of class imbalance (CI) is addressed. Then finally a Genetic Algorithm based machine learning (GA-DT) and a deep learning model (ANN-DT) are developed for the purpose for predicting faults in a software. For empirical evaluation, Eclipse version dataset (2.0, 2.1, and 3.0) is considered. Precision, recall, accuracy, and f1-Score are the performance metrics we used to evaluate the effectiveness of the proposed approach. The results demonstrated that the proposed approach (GA-DT and ANN-DT) effectively predicted the software's faults with ANN-DT providing best accuracies for all the three versions of Eclipse dataset.
C1 [Gupta, Mansi; Rajnish, Kumar; Bhattacharjee, Vandana] Birla Inst Technol, Mesra, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Gupta, M (corresponding author), Birla Inst Technol, Mesra, Ranchi, India.
EM lncs@springer.com
RI Rajnish, Kumar -/JAX-2106-2023; Gupta, Mansi/KHY-2402-2024; Gupta,
   Mansi/KHY-2433-2024; Bhattacharjee, Vandana/IZP-5454-2023
OI Gupta, Mansi/0000-0003-3090-1216; Gupta, Mansi/0000-0003-3090-1216;
   BHATTACHARJEE, VANDANA/0000-0002-0680-2691
CR Abid A, 2021, ARTIF INTELL REV, V54, P3639, DOI 10.1007/s10462-020-09934-2
   Alsghaier H, 2021, SOFTWARE PRACT EXPER, V51, P1121, DOI 10.1002/spe.2941
   Arora R, 2022, VIETNAM J COMPUT SCI, V09, P261, DOI 10.1142/S2196888822500142
   Bal PR, 2018, ICSOFT, P354
   Balogun AO, 2020, LECT NOTES COMPUT SC, V12254, P615, DOI 10.1007/978-3-030-58817-5_45
   Balogun AO, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020179
   Bennin KE, 2019, EMPIR SOFTW ENG, V24, P602, DOI 10.1007/s10664-018-9633-6
   Charte F, 2015, NEUROCOMPUTING, V163, P3, DOI 10.1016/j.neucom.2014.08.091
   Elahi E, 2021, INT BHURBAN C APPL S, P506, DOI 10.1109/IBCAST51254.2021.9393182
   Goel L, 2019, INT J PARALLEL EMERG, DOI 10.1080/17445760.2019.1650039
   Goyal S, 2022, ARTIF INTELL REV, V55, P2023, DOI 10.1007/s10462-021-10044-w
   Guoqiang X., 2021, Int J Performabil Eng, V17, P123, DOI [10.23940/ijpe.21.01.p12.123134, DOI 10.23940/IJPE.21.01.P12.123134]
   Gupta M., 2021, Scientific Programm, P1
   Gupta M, 2020, Lecture Notes in Electrical Engineering, P561
   Hamdia KM, 2021, NEURAL COMPUT APPL, V33, P1923, DOI 10.1007/s00521-020-05035-x
   Huang YG, 2011, INT CONF CLOUD COMPU, P34
   Jonathan B., 2020, 2020 IEEE INT C IND
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Khanna M, 2021, INT J GRID HIGH PERF, V13, P70, DOI 10.4018/IJGHPC.2021040105
   Khuat TT, 2019, Int J Elect Comput Eng, V9, P3241, DOI [10.11591/ijece.v9i4.pp3241-3246, DOI 10.11591/IJECE.V9I4.PP3241-3246]
   Khuat TT, 2020, SN Comput Sci, V1
   Kramer O., 2017, Genetic Algorithm Essentials, V679, DOI 10.1007/978-3-319-52156-5
   Kumar R, 2022, IEEE T RELIAB, V71, P911, DOI 10.1109/TR.2022.3151125
   Laradji IH, 2015, INFORM SOFTWARE TECH, V58, P388, DOI 10.1016/j.infsof.2014.07.005
   Le TMH., 2015, Int J Electric Comput Eng (IJECE), V5, P1164, DOI [10.11591/ijece.v5i5.pp1164-1173, DOI 10.11591/IJECE.V5I5.PP1164-1173]
   Mahmood Y, 2022, SOFTWARE PRACT EXPER, V52, P39, DOI 10.1002/spe.3009
   Malhotra R, 2019, NEUROCOMPUTING, V343, P120, DOI 10.1016/j.neucom.2018.04.090
   Mangla M, 2022, INNOV SYST SOFTW ENG, V18, P301, DOI 10.1007/s11334-021-00390-x
   Nagpal A, 2014, IEEE INT ADV COMPUT, P45, DOI 10.1109/IAdCC.2014.6779292
   Palak, 2022, Computational Intelligence in Software Modeling, P163
   Pandey SK, 2021, 2021 8TH INTERNATIONAL CONFERENCE ON SMART COMPUTING AND COMMUNICATIONS (ICSCC), P58, DOI 10.1109/ICSCC51209.2021.9528170
   Pandey SK, 2021, SOFT COMPUT, V25, P13465, DOI 10.1007/s00500-021-06096-3
   Pelayo L, 2007, NAFIPS 2007 - 2007 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P69, DOI 10.1109/NAFIPS.2007.383813
   Raji ID, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031186
   Rathore SS, 2021, APPL INTELL, V51, P8945, DOI 10.1007/s10489-021-02346-x
   Rathore SS, 2022, IEEE T RELIAB, V71, P747, DOI 10.1109/TR.2022.3158949
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   sklearn-genetic-opt.readthedocs, About us
   Sohail A., 2021, Annals of Data Science, P1
   Sohan MF, 2019, 2019 INT C EL COMP C
   Stanczyk U, 2014, Feature Selection for Data and Pattern Recognition, Part of the Studies in Computational Intelligence book series, V584
   Swana EF, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093246
   Tabassum Mujahid., 2014, International Journal of Digital Information and Wireless Communications (IJDIWC), V4, P124, DOI [DOI 10.17781/P001091, 10.17781/p001091]
   Tomar D, 2016, APPL COMPUT INTELL S, V2016, DOI 10.1155/2016/7658207
   Zheng JM, 2021, IEEE ACCESS, V9, P86855, DOI 10.1109/ACCESS.2021.3072682
NR 47
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-16788-7
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300017
DA 2024-07-18
ER

PT J
AU Kakarla, P
   Vimala, C
   Hemachandra, S
AF Kakarla, Praveena
   Vimala, C.
   Hemachandra, S.
TI An automatic multi-class lung disease classification using deep learning
   based bidirectional long short term memory with spiking neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-class lung disease classification; Chest X-ray; Bidirectional long
   short term memory; Spiking neural network; Tent chaotic archerfish
   algorithm
AB Lung disease (LD) is a dreadful disease that affects numerous people in various ways; hence, it is considered the foremost reason for death around the globe. To reduce LDs, affording earlier treatment is highly required. However, learning lung features and finding abnormalities are highly complex due to the lack of enhanced diagnosing techniques. Hence, this article introduces a novel hybridized deep learning (DL) scheme for automatically classifying LDs with improved accuracy. The proposed study undergoes three major stages: pre-processing, feature extraction, and LD classification. Initially, the pre-processing stage reduces the noises from the inputs using an improved Diffusion-based unsharp masking filtering and crispening (ID-UMFC) scheme, where the image quality is improved. Then, to reduce the complexity problems, an Extended Two-Dimensional Wavelet Transform (E-2DWT) technique is proposed in the feature extraction stage to extract useful features efficiently. Finally, the Deep Bidirectional Long short-term Term Memory-Spiking Neural Network (DBLSTM-SNN) based DL technique is introduced to classify multiple classes of LDs accurately. The proposed method is implemented in Python, and a publicly available chest X-ray 14 dataset is utilized in this study. The various performance measures such as accuracy, precision, false discovery rate (FDR), time complexity, kappa and positive predictive value (PPV) are analyzed. In addition, statistical analysis is also studied and compared with different existing studies. The proposed method obtains an overall accuracy of 99.7%, precision of 98.9%, kappa of 98.2%, FDR of 1.05%, PPV of 98.9% and time complexity of 64.4 s.
C1 [Kakarla, Praveena] SRM Inst Sci & Technol, Coll Engn & Technol, Dept Telecommun Engn, Chennai 603203, India.
   [Vimala, C.] SRM Inst Sci & Technol, Coll Engn & Technol, Dept Telecommun Engn, Chennai 603203, India.
   [Hemachandra, S.] Mohan Babu Univ, EEE, Chandragiri 517102, Andhra Pradesh, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Kakarla, P (corresponding author), SRM Inst Sci & Technol, Coll Engn & Technol, Dept Telecommun Engn, Chennai 603203, India.
EM pk8112@srmist.edu.in
RI K, Praveena/FAE-8976-2022
OI K, Praveena/0000-0001-8044-5648
CR Agarwal V., 2022, 2022 INT C SCI TECHN, P1, DOI [10.1109/ICOSTECH54296.2022.9828806, DOI 10.1109/ICOSTECH54296.2022.9828806]
   Alshmrani GMM, 2023, ALEX ENG J, V64, P923, DOI 10.1016/j.aej.2022.10.053
   Balamurugan KS, 2022, Improving the performance of diagnosing chronic obstructive lung disease using outlier detection with decision tree algorithm, DOI [10.21203/rs.3.rs-2072803/v2, DOI 10.21203/RS.3.RS-2072803/V2]
   Bharati Subrato, 2020, Inform Med Unlocked, V20, P100391, DOI 10.1016/j.imu.2020.100391
   Bratt A, 2022, CHEST, V162, P815, DOI [10.1016/j.chest.2021.03.044, 10.1016/j.chest.2022.03.044]
   Demir F, 2019, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0091-3
   Dong CJ, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105003
   El-Askary NS, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116489
   Farhan AMQ, 2023, MULTIMED TOOLS APPL, V82, P38561, DOI 10.1007/s11042-023-15047-z
   Fernando Chamodi, 2022, 2022 2nd International Conference on Advanced Research in Computing (ICARC), P165, DOI 10.1109/ICARC54489.2022.9753811
   Gite S, 2023, NEURAL COMPUT APPL, V35, P22839, DOI 10.1007/s00521-021-06719-8
   Harinath reddy C., 2022, Second International Conference on Image Processing and Capsule Networks: ICIPCN 2021. Lecture Notes in Networks and Systems (300), P462, DOI 10.1007/978-3-030-84760-9_40
   Ijaz Aneeqa, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2021.100832
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Karaddi SH, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118650
   Kim S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040915
   Kumar A, 2022, P I MECH ENG H, V236, P12, DOI 10.1177/09544119211039317
   Nillmani, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030652
   Rajagopal R, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104197
   Ravi V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12966
   Shamrat FJM, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106646
   Shamrat FMJM, 2022, J PERS MED, V12, DOI 10.3390/jpm12050680
   Shanbehzadeh M, 2022, J EDUC HEALTH PROMOT, V11, DOI 10.4103/jehp.jehp_387_21
   Shankar K, 2021, COMPLEX INTELL SYST, V7, P1277, DOI 10.1007/s40747-020-00216-6
   Soni M, 2022, INT J SWARM INTELL R, V13, DOI 10.4018/IJSIR.287544
   Souid A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062751
   Sulochana CH, 2022, P I MECH ENG H, V236, P1492, DOI 10.1177/09544119221113722
   Zebin T, 2021, APPL INTELL, V51, P1010, DOI 10.1007/s10489-020-01867-1
NR 28
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17371-w
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300006
DA 2024-07-18
ER

PT J
AU Vijayalakshmi, V
   Kumar, DM
   Kumar, SCP
   Veeramani, S
AF Vijayalakshmi, V.
   Kumar, D. Mahesh
   Kumar, S. C. Prasanna
   Veeramani, S.
TI Soil salinity prediction based on hybrid classifier: study on Bellary
   and Chamarajanagar district in Karnataka
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Soil salinization; Proposed PCA; Deep Belief Network; Optimized Bi-LSTM;
   SU-BSO Algorithm
ID GROWTH
AB Soil salinization is one of the most frequent environmental concerns that contribute to the degradation of agricultural land, particularly in arid and semi-arid regions. The correct methods must be developed by farm owners and decision-makers in order to reduce soil erosion and increase crop output. For this, accurate spatial forecasting and soil salinity modeling in agricultural areas are needed. The accurate consideration of environmental elements under the scale effects, which have received less attention in prior research, is essential for digital soil mapping. The goal of this research is to create a special technique for predicting soil salinity. Preprocessing is done on the sentinel image input first. The next step is to determine the spectral channels, salinity index, and vegetation index. The development of transformation-based features also takes advantage of enhanced PCA. The suggested hybrid classifier uses "Deep Belief Network (DBN) and Bidirectional Long Short Term Memory (Bi-LSTM)" to predict salinity while accounting for these variables. The final forecast result is determined by the increased score level fusion. To improve the precision and accuracy of the prediction, Self Upgraded BSO (SU-BSO) calibrates the weights of the Bi-LSTM and DBN. The MSE values of the suggested technique are lower than those of other conventional methods like CNN, DBN, SVM, BI-LSTM, MLP-FFA, and MLSR metrics, achieving lower values of 0.13, 0.07, 0.03, 0.05, 0.09, and 0.094%, respectively. Finally, numerous measurements are employed to demonstrate the value of the selected approach.
C1 [Vijayalakshmi, V.] Visvesvaraya Technol Univ, JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru 560060, India.
   [Kumar, D. Mahesh] Visvesvaraya Technol Univ, JSS Acad Tech Educ, Dept Elect & Commun Engn, Belagavi 590018, India.
   [Kumar, S. C. Prasanna] Visvesvaraya Technol Univ, RV Coll Engn, Dept Elect & Instrumentat Engn, Belagavi 590018, India.
   [Veeramani, S.] Periyar Tiger Conservat Fdn, Kerala Forests & Wildlife Dept, GIS Cell Ecol & Conservat Biol Wing, Periyar Tiger Reserve, Thekkady 685503, Kerala, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University; Visvesvaraya Technological University
RP Vijayalakshmi, V (corresponding author), Visvesvaraya Technol Univ, JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru 560060, India.
EM vijayalakshmiv7288@gmail.com
RI V, Vijayalakshmi/AAC-5165-2022
CR Adil K., 2021, Biosyst Eng21, V209, P200
   Akhter N, 2021, ENVIRON POLLUT, V286, DOI 10.1016/j.envpol.2021.117316
   Barman A, 2021, J ENVIRON MANAGE, V296, DOI 10.1016/j.jenvman.2021.113243
   Nguyen BT, 2020, APPL SOIL ECOL, V152, DOI 10.1016/j.apsoil.2020.103531
   Boudibi S, 2021, ACTA GEOCHIM, V40, P390, DOI 10.1007/s11631-020-00444-0
   Chen QL, 2021, NEURAL COMPUT APPL, V33, P877, DOI 10.1007/s00521-020-05262-2
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Emran M, 2020, GEODERMA, V366, DOI 10.1016/j.geoderma.2020.114257
   Gharaibeh MA, 2021, CATENA, V205, DOI 10.1016/j.catena.2021.105466
   Gunarathne V, 2020, BIOCHAR, V2, P107, DOI 10.1007/s42773-020-00036-4
   Gupta BB, 2018, SOFT COMPUT, V22, P7679, DOI 10.1007/s00500-018-3575-1
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Imran M, 2021, ECOTOX ENVIRON SAFE, V224, DOI 10.1016/j.ecoenv.2021.112692
   Jia J, 2020, SCI TOTAL ENVIRON, V742, DOI 10.1016/j.scitotenv.2020.140124
   Li Z, 2019, CHINESE GEOGR SCI, V29, P784, DOI 10.1007/s11769-019-1071-x
   Mahajan G, 2020, ENVIRON SCI POLLUT R, V27, P26221, DOI 10.1007/s11356-020-09010-w
   Mahajan GR, 2021, CATENA, V198, DOI 10.1016/j.catena.2020.105041
   Nabiollahi K, 2021, GEODERMA, V385, DOI 10.1016/j.geoderma.2020.114858
   Pankaj U, 2020, PEDOSPHERE, V30, P671, DOI 10.1016/S1002-0160(20)60029-7
   Pankaj U, 2019, INDIAN J MICROBIOL, V59, P137, DOI 10.1007/s12088-018-00776-9
   Pouladi N, 2019, ENVIRON EARTH SCI, V78, DOI 10.1007/s12665-019-8159-6
   Andrade GRP, 2020, GEODERMA, V371, DOI 10.1016/j.geoderma.2020.114380
   Shah SHH, 2021, J ENVIRON MANAGE, V280, DOI 10.1016/j.jenvman.2020.111678
   Taghadosi MM, 2019, EUR J REMOTE SENS, V52, P138, DOI 10.1080/22797254.2019.1571870
   Wang TT, 2020, FILOMAT, V34, P5121, DOI 10.2298/FIL2015121W
   Wei Y, 2021, CATENA, V196, DOI 10.1016/j.catena.2020.104939
   Xiao D, 2021, MICROCHEM J, V165, DOI 10.1016/j.microc.2021.106182
   Xiao L, 2020, AGR ECOSYST ENVIRON, V303, DOI 10.1016/j.agee.2020.107124
   Zhang LH, 2019, ATMOS ENVIRON, V204, P78, DOI 10.1016/j.atmosenv.2019.02.024
   Zhang ZP, 2021, GEODERMA, V382, DOI 10.1016/j.geoderma.2020.114729
   Zhou XL, 2020, NEUROCOMPUTING, V390, P217, DOI 10.1016/j.neucom.2019.04.099
   Zuo WG, 2021, ENVIRON SCI POLLUT R, V28, P7476, DOI 10.1007/s11356-020-11115-1
NR 32
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-16652-8
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WJ9
UT WOS:001086868500001
DA 2024-07-18
ER

PT J
AU Guo, XX
   Li, X
   Lin, QF
   Li, GY
   Hu, XY
   Che, ST
AF Guo, Xiaoxin
   Li, Xiang
   Lin, Qifeng
   Li, Guangyu
   Hu, Xiaoying
   Che, Songtian
TI Controllable fundus image generation based on conditional generative
   adversarial networks with mask guidance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial network; Retinal images; Image generation; Mask
   guidance
ID DEEP
AB Fundus image generation can serve training data diversity as well as clinical and medical education. To solve the problem of the controllability and flexibility of fundus image generation with multiple lesion features, we propose a controllable fundus image generation model (CFIGGAN) based on conditional generative adversarial networks (GAN) for medical data augmentation. The least square loss and the perceptual loss term are added to the final loss to make the generated images more realistic, and the spectral normalization is used as the normalization method of the discriminator to make the training process more stable. In the two-stage training of the model, the vascular tree image concatenates the real and generated images as positive and negative samples to train the model. CFIGGAN can generate diseased fundus images by using the annotations of vascular tree, field of vision(FOV), DR-related lesions as input and controlling the morphology of four types of lesions. Qualitative experimental evaluation shows that the fundus images generated by our model are clear and realistic and close to the real image data distribution. Quantitative experimental evaluation shows that the combination of the spectral norm and the perceptual loss can improve visual observation and quantitative indices, and data augmentation by image generation can further increase the classification accuracy. More importantly, CFIGGAN achieve the controllability of fundus image generation corresponding to DR-related lesions, and the proposed method can be extended to medical images generation of other diseases for broader prospects.
C1 [Guo, Xiaoxin; Li, Xiang; Li, Guangyu] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Guo, Xiaoxin; Li, Xiang; Li, Guangyu] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Lin, Qifeng] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Hu, Xiaoying] Jilin Univ, Ophthalmol Dept, Bethune Hosp 1, Changchun 130021, Peoples R China.
   [Che, Songtian] Jilin Univ, Ophthalmol Dept, Bethune Hosp 2, Changchun 130041, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University;
   Jilin University
RP Guo, XX (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Guo, XX (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM guoxx@mail.jlu.edu.cn
RI Hu, Xiaoying/ACC-8682-2022
FU This work was supported by the National Natural Science Foundation of
   China under Grant 82071995, the Key Research And Development Program of
   Jilin Province under Grant 20220201141GX and the Natural Science
   Foundation of Jilin Province under Grant 20200201 [82071995]; National
   Natural Science Foundation of China [20220201141GX]; Key Research And
   Development Program of Jilin Province [20200201292JC]; Natural Science
   Foundation of Jilin Province
FX This work was supported by the National Natural Science Foundation of
   China under Grant 82071995, the Key Research And Development Program of
   Jilin Province under Grant 20220201141GX and the Natural Science
   Foundation of Jilin Province under Grant 20200201292JC.
CR Altaf F, 2019, IEEE ACCESS, V7, P99540, DOI 10.1109/ACCESS.2019.2929365
   Bermudez C, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293515
   Bińkowski M, 2021, Arxiv, DOI [arXiv:1801.01401, DOI 10.48550/ARXIV.1801.01401]
   Burlina PM, 2019, JAMA OPHTHALMOL, V137, P258, DOI 10.1001/jamaophthalmol.2018.6156
   Chartsias Agisilaos, 2017, Simulation and Synthesis in Medical Imaging. Second International Workshop, SASHIMI 2017. Held in Conjunction with MICCAI 2017. Proceedings: LNCS 10557, P3, DOI 10.1007/978-3-319-68127-6_1
   Chuquicusma MJM, 2018, I S BIOMED IMAGING, P240, DOI 10.1109/ISBI.2018.8363564
   Costa P, 2017, Arxiv, DOI arXiv:1701.08974
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Deshmukh A, 2019, I S BIOMED IMAGING, P583, DOI [10.1109/isbi.2019.8759414, 10.1109/ISBI.2019.8759414]
   Dhariwal P, 2021, ADV NEUR IN, V34
   Diaz-Pinto A, 2019, IEEE T MED IMAGING, V38, P2211, DOI 10.1109/TMI.2019.2903434
   Fiorini S, 2014, MIUA, P7, DOI DOI 10.1016/J.PROCS.2016.07.010
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guan JW, 2019, Arxiv, DOI arXiv:1903.11821
   Hensel M, 2017, ADV NEUR IN, V30
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin DK, 2018, LECT NOTES COMPUT SC, V11071, P732, DOI 10.1007/978-3-030-00934-2_81
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Lin K, 2017, ADV NEUR IN, V30
   Mahapatra Dwarikanath, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P382, DOI 10.1007/978-3-319-66179-7_44
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Maspero M, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada6d
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Mogren O, 2016, Arxiv, DOI arXiv:1611.09904
   Mok TCW, 2019, LECT NOTES COMPUT SC, V11383, P70, DOI 10.1007/978-3-030-11723-8_7
   Niu YH, 2022, IEEE J BIOMED HEALTH, V26, P44, DOI 10.1109/JBHI.2021.3110593
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Ring M, 2019, COMPUT SECUR, V82, P156, DOI 10.1016/j.cose.2018.12.012
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh N.K., 2021, Health Informatics: A Computational Perspective in Healthcare, P77
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Guibas JT, 2018, Arxiv, DOI arXiv:1709.01872
   Thukral R, 2020, 2020 IEEE INT STUD C, P1, DOI [10.1109/SCEECS48394.2020.154https://ieeexplore.ieee.org/abstract/document/9086961, DOI 10.1109/SCEECS48394.2020.154HTTPS://IEEEXPLORE.IEEE.ORG/ABSTRACT/DOCUMENT/9086961]
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang XF, 2019, LECT NOTES COMPUT SC, V11764, P423, DOI 10.1007/978-3-030-32239-7_47
   Wang XT, 2018, Arxiv, DOI [arXiv:1809.00219, DOI 10.48550/ARXIV.1809.00219]
   Yang HR, 2018, LECT NOTES COMPUT SC, V11045, P174, DOI 10.1007/978-3-030-00889-5_20
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu ZK, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0682-x
   Zhao H, 2018, MED IMAGE ANAL, V49, P14, DOI 10.1016/j.media.2018.07.001
   Zhou Y, 2019, LECT NOTES COMPUT SC, V11764, P505, DOI 10.1007/978-3-030-32239-7_56
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang JT, 2019, Arxiv, DOI [arXiv:1810.07810, DOI 10.48550/ARXIV.1810.07810]
NR 51
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17280-y
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100009
DA 2024-07-18
ER

PT J
AU Cai, C
   Zhou, GX
   Lu, C
AF Cai, Chuang
   Zhou, Guoxiong
   Lu, Chao
TI Citrus surface defect identification based on PCS-2D-Otsu and
   CGWO-DT-SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE PDE; PCS; Threshold segmentation; 2D-Otsu; CGWO; DT-SVM
ID AUTOMATIC DETECTION; SYSTEM; VISION; FRUITS
AB Aiming at the problems of poor image quality, susceptibility to interference from the external environment and difficulties in recognition due to high similarity between real defects and fruit stalks in citrus surface defect recognition, we proposed a citrus surface defect recognition method based on a combination of PCSA-2D-Otsu and CGWO-DT-SVM. Firstly, a partial differential equations (PDE) based variational model is used to denoise the captured citrus images, which reduces the blurring of the images while retaining the edge details and important texture information. Then, a 2D-Otsu threshold segmentation algorithm optimized by the plant cell swarm algorithm (PCSA) is used to segment the citrus surface defects and extract the image features to separate the citrus from the background, making full use of the relevant information and reducing the influence of complex backgrounds. Finally, the images are input to the chaos gray wolf optimizer (CGWO) algorithm optimized DT-SVM classifier for true defects and fruit stalks to identify the citrus into healthy and defective classes. We selected 2000 collected citrus images for the experiments and the application results showed an overall recognition accuracy of 96.71%. To verify the feasibility and effectiveness of the proposed model, we compared it with advanced deep learning methods and machine learning methods, among others. The experimental results show that the method is more accurate and less time consuming for the recognition of citrus surface defects, and can be effective for the recognition of citrus surface defects. It provides a solution and reference for the application of machine vision methods in the accurate and rapid diagnosis of fruit surface defects.
C1 [Cai, Chuang; Zhou, Guoxiong; Lu, Chao] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Hunan, Peoples R China.
EM caichuang0815@163.com; t20060599@csuft.edu.cn; 1244414754@qq.com
CR Abdellah H., 2014, IOSR Journal of Engineering, V4, P69, DOI DOI 10.9790/3021-041246977
   Alshamlan Hala M., 2016, International Journal of Machine Learning and Computing, V6, P184, DOI 10.18178/ijmlc.2016.6.3.596
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Azizah LM, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P242, DOI 10.1109/ICCSCE.2017.8284412
   Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Bhargava A, 2020, FOOD ANAL METHOD, V13, P751, DOI 10.1007/s12161-019-01690-6
   Blasco J, 2007, J FOOD ENG, V83, P384, DOI 10.1016/j.jfoodeng.2007.03.027
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chithra P L, 2017, Int J Adv Res Comput Sci, V8, DOI [10.26483/ijarcs.v8i8.4735, DOI 10.26483/IJARCS.V8I8.4735]
   Cubero S, 2016, FOOD BIOPROCESS TECH, V9, P1623, DOI 10.1007/s11947-016-1767-1
   Huang CL, 2008, APPL SOFT COMPUT, V8, P1381, DOI 10.1016/j.asoc.2007.10.007
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WQ, 2015, J FOOD ENG, V146, P62, DOI 10.1016/j.jfoodeng.2014.09.002
   Jianrong C., 2005, Trans CSAM, V36, P61
   Khoje S., 2013, Int J Eng Technol, V5, P3251, DOI DOI 10.1016/J.POSTHARVBIO.2013.02.016
   Kukreja Vinay, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P97, DOI 10.1109/ICOSEC49089.2020.9215359
   Li JB, 2013, POSTHARVEST BIOL TEC, V82, P59, DOI 10.1016/j.postharvbio.2013.02.016
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu J, 2015, 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), P1543, DOI 10.1109/FSKD.2015.7382174
   Ravi T, 2016, SMART INNOV SYST TEC, V43, P163, DOI 10.1007/978-81-322-2538-6_17
   Rezaei H, 2018, STUD COMPUT INTELL, V720, P81, DOI 10.1007/978-981-10-5221-7_9
   Al-amri SS, 2010, Arxiv, DOI [arXiv:1005.4020, DOI 10.48550/ARXIV.1005.4020]
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Sivakami K., 2015, International Journal of Scientific Engineering and Applied Science (IJSEAS), V1, P418
   Tan AJ, 2021, MULTIMED TOOLS APPL, V80, P9109, DOI 10.1007/s11042-020-10036-y
   Targ S., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.08029
   Thendral R, 2017, CURR SCI INDIA, V112, P1704, DOI 10.18520/cs/v112/i08/1704-1711
   Wang CL, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11081500
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Alom MZ, 2018, Arxiv, DOI arXiv:1803.01164
   Zhang BH, 2015, J FOOD ENG, V146, P143, DOI 10.1016/j.jfoodeng.2014.08.024
NR 31
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17341-2
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000007
DA 2024-07-18
ER

PT J
AU Kiliçarslan, S
   Dönmez, E
AF Kilicarslan, Serhat
   Donmez, Emrah
TI Improved multi-layer hybrid adaptive particle swarm optimization based
   artificial bee colony for optimizing feature selection and
   classification of microarray data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Feature selection; Microarray; Adaptive particle swarm optimization;
   Artificial bee algorithm; Classification
ID GENE SELECTION
AB Early diagnosis of cancer allows for easy follow-up of patients' treatment processes. The utilization of microarray gene technology has become increasingly prevalent in the detection of cancer. However, the limited success of classical data mining methods can be attributed to the absence of a linear relationship among the data in microarray datasets. Artificial intelligence-based classification methods are employed to address classification challenges in datasets with a high number of attributes, due to the following reasons: This study presents a novel approach that combines adaptive particle swarm optimization (PSO) with the artificial bee colony (ABC) algorithm to effectively classify microarray datasets. Firstly, Chi2 and ANOVA F-test feature selection algorithms are applied to the microarray datasets to prevent the model from getting stuck in the local optimum. Thus, the most defining features in the dataset are selected, and the dimension is reduced. For classification success increases, we have selected optimal features with the proposed hybrid adaptive ABC + PSO, gray wolf algorithm (GWO), PSO, and ABC algorithms on the new dataset obtained. The last step is performed to classify using a support vector machine (SVM), an artificial neural network (ANN), and a nearest-neighbor (k-NN) algorithm. In the study, eight microarray datasets liver, lung, renal, pancreatic, prostate, breast, colorectal, and brain tumors were used.
C1 [Kilicarslan, Serhat; Donmez, Emrah] Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Dept Software Engn, TR-10200 Balikesir, Turkiye.
C3 Bandirma Onyedi Eylul University
RP Kiliçarslan, S (corresponding author), Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Dept Software Engn, TR-10200 Balikesir, Turkiye.
EM skilicarslan@bandirma.edu.tr; emrahdonmez@bandirma.edu.tr
RI Dönmez, Emrah/W-2891-2017; KILIÇARSLAN, Serhat/AHB-3775-2022
OI Dönmez, Emrah/0000-0003-3345-8344; KILIÇARSLAN,
   Serhat/0000-0001-9483-4425
FU Bandirma Onyedi Eylul University Scientific Research Projects
   Coordination Unit [BAP-22-1003-004]
FX This research article was supported by Bandirma Onyedi Eylul University
   Scientific Research Projects Coordination Unit with the code
   "BAP-22-1003-004".
CR Abd-elnaby Muhammed, 2022, Digital Transformation Technology: Proceedings of ITAF 2020. Lecture Notes in Networks and Systems (224), P547, DOI 10.1007/978-981-16-2275-5_36
   Adem K, 2020, PHYSICA A, V551, DOI 10.1016/j.physa.2020.124591
   Alanni R, 2019, BMC MED GENOMICS, V12, DOI 10.1186/s12920-018-0447-6
   Alrefai N, 2022, NEURAL COMPUT APPL, V34, P13513, DOI 10.1007/s00521-022-07147-y
   Atay Y., 2021, Gazi Univ J Sci Part C: Des Technol, V9, P811
   Aziz RM, 2022, MED BIOL ENG COMPUT, V60, P1627, DOI 10.1007/s11517-022-02555-7
   Berber O., 2016, Kahramanmaras Sutcu Imam Universitesi Muhendislik Bilimleri Dergisi, V19, P165
   Bhui N, 2020, 2020 11 INT C COMP C, P1
   Bolón-Canedo V, 2019, INFORM FUSION, V52, P1, DOI 10.1016/j.inffus.2018.11.008
   Dashtban M, 2018, GENOMICS, V110, P10, DOI 10.1016/j.ygeno.2017.07.010
   Díaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3
   Eberhart RC, 2000, IEEE C EVOL COMPUTAT, P84, DOI 10.1109/CEC.2000.870279
   Feltes BC, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.586602
   Grisci BI, 2021, INFORM SCIENCES, V559, P111, DOI 10.1016/j.ins.2021.01.052
   Grisci BI, 2019, J BIOMED INFORM, V89, P122, DOI 10.1016/j.jbi.2018.11.013
   Guckiran K., 2019, Suleyman Demirel Universitesi Fen Bilimleri Enstitusu Dergisi, V23, P126, DOI 10.19113/sdufenbed.453462
   Gumaei A, 2021, HEALTH INFORM J, V27, DOI 10.1177/1460458221989402
   Hancer E, 2018, INFORM SCIENCES, V422, P462, DOI 10.1016/j.ins.2017.09.028
   Jinthanasatian P, 2017, 2017 IEEE S SER COMP, P1
   Jowkar GH, 2016, COMPUT BIOL CHEM, V64, P263, DOI 10.1016/j.compbiolchem.2016.07.004
   Kang CZ, 2019, J THEOR BIOL, V463, P77, DOI 10.1016/j.jtbi.2018.12.010
   Kapukaya O., 2019, Kahramanmaras Sutcu Imam Universitesi Muhendislik Bilimleri Dergisi, V22, P257, DOI [10.17780/ksujes.655044, DOI 10.17780/KSUJES.655044]
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kilicarslan S., 2019, Duzce Universitesi Bilim ve Teknoloji Dergisi, V7, P769, DOI [10.29130, DOI 10.29130/DUBITED.464092]
   Kilicarslan S, 2020, MED HYPOTHESES, V137, DOI 10.1016/j.mehy.2020.109577
   Kiran MS, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114817
   Kisengeu Susan Mumbi, 2021, Heliyon, V7, pe08138, DOI 10.1016/j.heliyon.2021.e08138
   Kokanali D., 2019, Jinekoloji-Obstetrik ve Neonatoloji Tip Dergisi, V16, P97
   Kumar M, 2015, PROCEDIA COMPUT SCI, V57, P727, DOI 10.1016/j.procs.2015.07.463
   Kundu R, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105349
   Liao Q, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P76, DOI 10.1109/SPAC.2017.8304254
   Ludwig SA, 2015, 2015 IEEE INT C FUZZ, P1
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Medjahed SA, 2017, APPL SOFT COMPUT, V51, P39, DOI 10.1016/j.asoc.2016.12.010
   Ozcan T, 2020, CLUSTER COMPUT, V23, P2847, DOI 10.1007/s10586-020-03050-0
   Pandey AC, 2020, J AMB INTEL HUM COMP, V11, P719, DOI 10.1007/s12652-019-01330-1
   Patel Sachin, 2021, 2021 2nd International Conference on Smart Electronics and Communication (ICOSEC), P1174, DOI 10.1109/ICOSEC51865.2021.9591854
   Peng YH, 2010, J BIOMED INFORM, V43, P15, DOI 10.1016/j.jbi.2009.07.008
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Salem H, 2017, APPL SOFT COMPUT, V50, P124, DOI 10.1016/j.asoc.2016.11.026
   Segal E, 2003, BIOINFORMATICS, V19, pi264, DOI 10.1093/bioinformatics/btg1037
   Sharma A, 2019, COMPUT METH PROG BIO, V178, P219, DOI 10.1016/j.cmpb.2019.06.029
   Shekar BH, 2020, ADV INTELL SYST, V1024, P227, DOI 10.1007/978-981-32-9291-8_19
   Song XF, 2020, IEEE T EVOLUT COMPUT, V24, P882, DOI 10.1109/TEVC.2020.2968743
   Khuat TT, 2018, J INTELL SYST, V27, P489, DOI 10.1515/jisys-2016-0294
   Tuncez IH., 2021, PHOENIX MED J, V3, P69, DOI [10.38175/phnx.922780, DOI 10.38175/PHNX.922780]
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Wang YD, 2019, APPL MATH MODEL, V71, P286, DOI 10.1016/j.apm.2019.01.044
   Yildiz O, 2012, Gazi Universitesi Muhendislik Mimarlik Fakultesi Dergisi, V27
   Zhang Y, 2020, INFORM SCIENCES, V507, P67, DOI 10.1016/j.ins.2019.08.040
   Zivkovic M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051711
NR 52
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17234-4
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000004
DA 2024-07-18
ER

PT J
AU Siddiqui, HUR
   Zafar, K
   Saleem, AA
   Sehar, R
   Rustam, F
   Dudley, S
   Ashraf, I
AF Siddiqui, Hafeez Ur Rehman
   Zafar, Kainat
   Saleem, Adil Ali
   Sehar, Rukhshanda
   Rustam, Furqan
   Dudley, Sandra
   Ashraf, Imran
TI Artificial intelligence-based myocardial infarction diagnosis: a
   comprehensive review of modern techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Myocardial infarction; Coronary artery disease; Noninvasive imaging
   techniques; Automated computer-aided diagnostic systems; Artificial
   intelligence
ID AUTOMATED DETECTION; ECG SIGNALS; LOCALIZATION; NETWORK; ENERGY
AB Myocardial infarction (MI), commonly known as a heart attack, is a serious medical condition that can lead to congestive heart failure and even death. Prompt diagnosis and early intervention are essential for improving a patient's survival chances. Electrocardiography (ECG) is the most commonly used diagnostic method for MI, but other noninvasive imaging techniques and clinical parameters are also used. However, manual interpretation of these methods can result in potential inconsistencies among different observers. To address this issue, automated computer-aided diagnostic systems that utilize artificial intelligence (AI) have been developed. These systems use both machine learning (ML) and deep learning (DL) models to discriminate between MI and normal signals or subjects. In this review paper, we survey the current state-of-the-art methods in ML and DL-based MI detection approaches that are published from 2015 to the present. This review highlights the advantages and limitations of different AI-based approaches and provides insights into future directions for research in this field. The ultimate goal of these efforts is to improve the accuracy and efficiency of MI diagnosis and contribute to more efficient and timely diagnosis of MI patients.
C1 [Siddiqui, Hafeez Ur Rehman; Zafar, Kainat; Saleem, Adil Ali; Sehar, Rukhshanda] Khwaja Fareed Univ Engn & Informat Technol, Inst Comp Sci, Abu Dhabi Rd, Rahim Yar Khan 64200, Punjab, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04 V1W8, Ireland.
   [Dudley, Sandra] London South Bank Univ, Bioengn Res Ctr, Sch Engn, 103 Borough Rd, London SE1 0AA, England.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; University College Dublin; London South Bank University;
   Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM hafeez@kfueit.edu.pk; kainat.zafar96@gmail.com; adilalisaleem@gmail.com;
   rukhshandasehar08@gmail.com; Furqan.rustam@ucdconnect.ie;
   dudleyms@lsbu.ac.uk; imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020; Sehar, Rukhshanda/JJD-1093-2023; SALEEM,
   ADIL Ali/AAL-1968-2021
OI Rustam, Furqan/0000-0001-8403-1047; Sehar,
   Rukhshanda/0000-0002-7654-6048; SALEEM, ADIL Ali/0000-0003-2468-8471;
   Ashraf, Imran/0000-0002-8271-6496
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2017, INFORM SCIENCES, V377, P17, DOI 10.1016/j.ins.2016.10.013
   Acharya UR, 2016, KNOWL-BASED SYST, V99, P146, DOI 10.1016/j.knosys.2016.01.040
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Alharthi AS, 2019, IEEE SENS J, V19, P9575, DOI 10.1109/JSEN.2019.2928777
   Attallah O, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104273
   Banerjee S., 2012, Int. J. Electr. Electron. Comput. Eng., V1, P88
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Bousseljot R, 1995, Nutzung der ekg-signaldatenbank cardiodat der ptb uiber das internet
   Braunwald E, 2012, EUR HEART J-ACUTE CA, V1, P9, DOI 10.1177/2048872612438026
   Canto JG, 2000, JAMA-J AM MED ASSOC, V283, P3223, DOI 10.1001/jama.283.24.3223
   Creemers EEJM, 2001, CIRC RES, V89, P201, DOI 10.1161/hh1501.094396
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Degerli A, 2021, IEEE ACCESS, V9, P34442, DOI 10.1109/ACCESS.2021.3059595
   Diker Aykut, 2018, SIGNAL PROCESSING CO
   Faizal ASM, 2023, MED BIOL ENG COMPUT, V61, P2527, DOI 10.1007/s11517-023-02841-y
   Feng K, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091879
   Fu LD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041020
   Garland J, 2021, AM J FOREN MED PATH, V42, P230, DOI 10.1097/PAF.0000000000000672
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guo YH, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105791
   Gupta A., 2021, P IFMBE, V80, P341, DOI [10.1007/978-3-030-64610-3_40, DOI 10.1007/978-3-030-64610-340]
   Hammad M, 2021, INFORM SCIENCES, V571, P580, DOI 10.1016/j.ins.2021.05.035
   Hammad M, 2022, MULTIMEDIA SYST, V28, P1373, DOI 10.1007/s00530-020-00728-8
   Han C, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105138
   Han C, 2019, COMPUT METH PROG BIO, V175, P9, DOI 10.1016/j.cmpb.2019.03.012
   HANKINS GDV, 1985, OBSTET GYNECOL, V65, P139
   Hellermann JP, 2002, AM J MED, V113, P324, DOI 10.1016/S0002-9343(02)01185-3
   Iyengar Nikhil, 1996, American Journal of Physiology, V271, pR1078
   Jahmunah V, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104457
   Jayachandran ES, 2010, J MED SYST, V34, P985, DOI 10.1007/s10916-009-9314-5
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kayikcioglu I, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106621
   Kim YC, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105150
   Kumar M, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19090488
   Lalande A, 2020, DATA, V5, DOI 10.3390/data5040089
   Lewandrowski Kent, 2002, Am J Clin Pathol, V118 Suppl, pS93
   Lin ZC, 2020, SIGNAL IMAGE VIDEO P, V14, P857, DOI 10.1007/s11760-019-01617-y
   Liu B, 2015, COMPUT BIOL MED, V61, P178, DOI 10.1016/j.compbiomed.2014.08.010
   Liu WH, 2020, IEEE J BIOMED HEALTH, V24, P503, DOI 10.1109/JBHI.2019.2910082
   Liu WH, 2018, IEEE J BIOMED HEALTH, V22, P1434, DOI 10.1109/JBHI.2017.2771768
   Mofrad FB, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119261
   Reasat T, 2017, IEEE REG 10 HUMANIT, P718, DOI 10.1109/R10-HTC.2017.8289058
   Reed GW, 2017, LANCET, V389, P197, DOI 10.1016/S0140-6736(16)30677-8
   Ribeiro JM, 2022, TRENDS CARDIOVAS MED, V32, P153, DOI 10.1016/j.tcm.2021.02.002
   Sandoval Y, 2019, J AM COLL CARDIOL, V73, P1846, DOI 10.1016/j.jacc.2019.02.018
   Scheffler K, 2003, EUR RADIOL, V13, P2409, DOI 10.1007/s00330-003-1957-x
   Sharma LN, 2015, IEEE T BIO-MED ENG, V62, P1827, DOI 10.1109/TBME.2015.2405134
   Tripathy RK, 2019, IEEE SENS J, V19, P4509, DOI 10.1109/JSEN.2019.2896308
   Valizadeh G, 2023, EXPERT SYST APPL, V228, DOI 10.1016/j.eswa.2023.120368
   Valizadeh G, 2021, MED BIOL ENG COMPUT, V59, P1261, DOI 10.1007/s11517-021-02372-4
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
   Zhang G, 2019, IEEE ACCESS, V7, P171570, DOI 10.1109/ACCESS.2019.2955555
   Zhang JS, 2019, IEEE ACCESS, V7, P70634, DOI 10.1109/ACCESS.2019.2919068
NR 55
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17246-0
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100007
DA 2024-07-18
ER

PT J
AU Tripathi, MK
   Shivendra
AF Tripathi, Mukesh Kumar
   Shivendra
TI Neutrosophic approach based intelligent system for automatic mango
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mango Detection; Neutroscopic logic set; Geometric Mean based Local
   Binary Pattern; Segmentation; Deep Learning
AB Due to its deliciousness, flavoring, and nutritional value, mango is considered one of the most common fruits among the generations. Mango growth occurs numerous times a year. In India, mangoes are abundantly harvested in the summer months, and traders ship them to a variety of markets. In this scenario, the Indian markets need the automatic identification and recognition of mango species, which also ensures their quality. Moreover, the mango species identification also focuses on structure, geometry, and texture as well. Advanced technologies comprise its efficiency in automatic recognition, however often fail due to the intra-class heterogeneity among millions of mango species worldwide. Deep Convolutional Neural Networks (CNN) are employed in this study to more precisely identify the mango species. The collected input mango image is initially pre-processed using basic functions like noise reduction and scaling. The image is then converted to the neutrosophic domain, and the defined neutrosophic set is divided using the Improved Fuzzy C-Means Clustering (IFCM) algorithm. The Geometric Mean based Local Binary Pattern (GM-LBP) and Local Vector Pattern (LVP) features are extracted as part of the feature extraction process. To differentiate the mango species, a Convolutional Neural Network (CNN) model is applied at the end. In order to confirm the efficacy of various measures, a comparison of the suggested (Convolutional Neural Network with an Improved Texture feature set (CNN + ITF)) with previous works is made.
C1 [Tripathi, Mukesh Kumar] Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Shivendra] DK Coll Dumraon, Dept Comp Applicat, Buxar, Bihar, India.
C3 Vardhaman College of Engineering
RP Tripathi, MK (corresponding author), Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM mukeshtripathi016@gmail.com
CR Anurekha D, 2020, MULTIMED TOOLS APPL, V79, P4169, DOI 10.1007/s11042-019-07784-x
   Ardepolla JA, 2019, P 6 INT C BIOINFORMA
   Behera SK, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01865-8
   Belizón M, 2018, J CO2 UTIL, V25, P56, DOI 10.1016/j.jcou.2018.03.005
   Blanes C, 2015, FOOD BIOPROCESS TECH, V8, P1914, DOI 10.1007/s11947-015-1548-2
   Cheng HD, 2011, NEW MATH NAT COMPUT, V7, P155, DOI 10.1142/S1793005711001858
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Gabriëls SHEJ, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111206
   Gurubelli Y, 2020, Texture and Colour Gradient Features for Grade analysis of Pomegranate and Mango Fruits using kernel-SVM Classifiers, P122, DOI [10.1109/ICACCS48705.2020.9074221, DOI 10.1109/ICACCS48705.2020.9074221]
   Gururaj N., 2019, Int J Innov Technol Exploring Eng (IJITEE), V9, P3567, DOI [10.35940/ijitee.B7387.129219, DOI 10.35940/IJITEE.B7387.129219]
   Jadhav T, 2019, MULTIMED TOOLS APPL, V78, P1613, DOI 10.1007/s11042-018-6271-3
   Kumari N, 2021, MULTIMED TOOLS APPL, V80, P4943, DOI 10.1007/s11042-020-09747-z
   Mazlan MM, 2020, CYTA-J FOOD, V18, P417, DOI 10.1080/19476337.2020.1767693
   Mohammad MB, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P512, DOI 10.1109/ComPE49325.2020.9200114
   Momin M. A., 2017, Information Processing in Agriculture, V4, P150, DOI 10.1016/j.inpa.2017.03.003
   Mon T, 2020, BIOSYST ENG, V198, P338, DOI 10.1016/j.biosystemseng.2020.08.021
   Naik S, 2019, P INT C SUSTAINABLE
   Naik S, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS & INNOVATION IN ICT (ICEI), P15, DOI 10.1109/ETIICT.2017.7977003
   Nambi VE, 2015, SCI HORTIC-AMSTERDAM, V193, P90, DOI 10.1016/j.scienta.2015.05.031
   Nandi CS, 2016, IEEE SENS J, V16, P6387, DOI 10.1109/JSEN.2016.2580221
   Pise D., 2018, 2018 INT C SMART CIT, P1, DOI DOI 10.1109/ICSCET.2018.8537342
   Ren AF, 2020, IEEE SENS J, V20, P2075, DOI 10.1109/JSEN.2019.2949528
   Sa'ad FSA, 2015, COMPUT ELECTRON AGR, V115, P51, DOI 10.1016/j.compag.2015.05.006
   Shiroma Yasushi, 2019, 2019 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS), P117, DOI 10.1109/ICIIBMS46890.2019.8991514
   Shukla A, 2020, FOOD CHEM, V316, DOI 10.1016/j.foodchem.2020.126354
   Xiao B, 2019, IEEE T CIRC SYST VID, V29, P2796, DOI 10.1109/TCSVT.2018.2869841
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17037-7
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500004
DA 2024-07-18
ER

PT J
AU Kapre, BS
   Rajurkar, AM
   Guru, DS
AF Kapre, B. S.
   Rajurkar, A. M.
   Guru, D. S.
TI The blind robust video watermarking scheme in video surveillance context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE M-CLD; TTBD; Multiple watermarks; Embedding; Extraction; DWT; SVD;
   Entropy
ID ALGORITHM
AB Video surveillance systems are now commonly deployed in both public and private settings globally. Use of watermarking in the surveillance systems is emerging as one of the alternative to cryptography for ensuring video authenticity and integrity. In this paper, we propose a novel video watermarking approach designed to protect the ownership of surveillance system videos. The proposed scheme utilizes various algorithms to achieve effective watermark embedding and enhances security levels also. The process begins by detecting video shots using the Modified Color Layout Descriptor (M-CLD) approach, which reduces false detection rates caused by noise, illumination changes, object motions, and camera operations. The entropy value of each frame within a shot is calculated, and the frame with the maximum entropy is selected as the key-frame. Entropy serves as a statistical measure to assess randomness and classify frames. To increase security, the proposed scheme employs a multi-watermark embedding approach. Three binary watermarks are generated from a grayscale image using the Two Threshold Binary Decomposition (TTBB) algorithm. A Watermark Embedding Code (WEC) is generated based on the entropy values of each key-frame, and a secure watermark selection algorithm is introduced to choose the appropriate watermark for each key-frame. The selected watermark is then embedded into the key-frame using Singular Value Decomposition (SVD) and Discrete Wavelet Transform (DWT) techniques, ensuring good perceptual quality. Experimental results demonstrate that the proposed scheme achieves high visual imperceptibility, improved performance in terms of normalized correlation, and low bit error rate. A comparative analysis with existing schemes reveals the superior robustness, enhanced imperceptibility, and reduced computational time of the proposed approach.
C1 [Kapre, B. S.; Rajurkar, A. M.; Guru, D. S.] MGMs Coll Engn, Dept Comp Sci & Engn, Nanded, India.
RP Kapre, BS (corresponding author), MGMs Coll Engn, Dept Comp Sci & Engn, Nanded, India.
EM kapre_bs@mgmcen.ac.in; rajurkar_am@mgmcen.ac.in; dsguruji@yahoo.com
OI Kapre, Bhagyashri/0000-0001-5490-7810
CR Amiri MD, 2019, MULTIMEDIA SYST, V25, P273, DOI 10.1007/s00530-019-00604-0
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Boreiry M, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P73, DOI 10.1109/RIOS.2017.7956446
   Chang YC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P287, DOI 10.1109/IS3C.2016.82
   Farfoura M, 2016, MULTIMED TOOLS APPL, V75, P7465, DOI 10.1007/s11042-015-2672-8
   Hammami A, 2021, MULTIMED TOOLS APPL, V80, P7479, DOI 10.1007/s11042-020-09982-4
   Joshi AM, 2016, MULTIMED TOOLS APPL, V75, P3121, DOI 10.1007/s11042-014-2426-z
   Kalker T, 1999, PROC SPIE, V3657, P103, DOI 10.1117/12.344661
   Kaur G, 2019, MULTIMED TOOLS APPL, V78, P21245, DOI 10.1007/s11042-019-7456-0
   Kirovski D, 2002, ACM INT C MULT, P372
   Li C, 2020, Wirel Commun Mob Comput, P11
   Li L, 2018, LECT NOTES COMPUT SC, V11066, P160, DOI 10.1007/978-3-030-00015-8_14
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Preda RO, 2011, UNIV POLIT BUCHAR S, V73, P93
   Priya GGL, 2012, COMM COM INF SC, V283, P421
   Priya P., 2014, Int J Res EngTechnol, V4, P630
   Sadi KA, 2017, INT J ELECTRON, V104, P673, DOI 10.1080/00207217.2016.1242163
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   Sathya SPA, 2020, IET IMAGE PROCESS, V14, P366, DOI 10.1049/iet-ipr.2019.0341
   Sharma C, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5536170
   Shukla D, 2018, J INTELL SYST, V27, P47, DOI 10.1515/jisys-2017-0039
   Singh R, 2022, COMPLEX INTELL SYST, V8, P1047, DOI 10.1007/s40747-021-00569-6
   Sujatha C. N., 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P621, DOI 10.1007/978-981-13-1742-2_62
   Swaraja K, 2019, INT C INT COMP COMM, P379
   Tyagi S, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P379, DOI 10.1109/ICETEESES.2016.7581413
   Yassin NI., 2012, IJCSI inter J ComprSci, V9, P296
   Yu XY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101891
   Zebbiche K, 2006, AHS 2006: FIRST NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P451
NR 30
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-16620-2
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600016
DA 2024-07-18
ER

PT J
AU Chowdhury, R
   Chakraborty, T
   Purkait, S
   Saha, B
AF Chowdhury, Ratul
   Chakraborty, Tamal
   Purkait, Shankhadeep
   Saha, Banani
TI SE<SUP>2</SUP>CURA - design and implementation of a robust ensemble
   learning based 2-tier intrusion detection system for real time traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Two-tier intrusion detection system (SE(2)CURA); CICIDS-2017 dataset;
   Ensemble learning; Real-time test-bed implementation; VoIP application
ID COGNITIVE RADIO NETWORK
AB Network Intrusion Detection System (NIDS) design faces enormous challenges under growing security vulnerabilities and innovative malicious attacks capable of bypassing conventional signature-based detection techniques. On the other hand, excessive analysis of network flows may prove detrimental to the underlying applications, especially when dealing with real-time services. Focusing on such challenges, this paper introduces "SE(2)CURA" - a novel two-tier NIDS system that maintains a perfect trade-off between network security and application-level Quality of Service (QoS). Specifically, the proposed system develops an optimal feature-set and subsequently deploys a binary classification in the first tier for coarse-grain packet filtering, followed by multiclass classification in the second tier, which is aimed at the fine-grain analysis of the blocked packets. The novelty of this system is established by its capability to accurately analyze and classify the malicious flows while bypassing the regular traffic flows without hampering the overall QoS. Experimental results reveal that the model achieves above 99% detection accuracy for CICIDS2017 dataset and outperforms other state-of-art methods with respect to different performance indicators. Comparative performance evaluation further justifies the performance superiority of the proposed system in terms of accuracy as well as execution time. Finally, the applicability of SE(2)CURA model is established by implementing the proposed framework to preserve the security of VoIP applications in the emerging Cognitive Radio Networks(CRN) through a robust and generic hardware-based test-bed design and execution of the SE(2)CURACURA model, that strongly validates the practical feasibility of the proposed methodology.
C1 [Chowdhury, Ratul; Chakraborty, Tamal] Future Inst Engn & Management, Kolkata, West Bengal, India.
   [Purkait, Shankhadeep] Univ Calcutta, New Alipore Coll, Kolkata, West Bengal, India.
   [Saha, Banani] Univ Calcutta, Kolkata, West Bengal, India.
C3 University of Calcutta; University of Calcutta
RP Chowdhury, R (corresponding author), Future Inst Engn & Management, Kolkata, West Bengal, India.
EM ratul.cse87@gmail.com; tamalchakraborty29@gmail.com;
   purkait144@gmail.com; bsaha_29@yahoo.com
CR Abdulhammed R, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030322
   Adeniyi AE, 2023, MULTIMED TOOLS APPL, V82, P20537, DOI 10.1007/s11042-023-14338-9
   Agrawal S., 2021, (2021) Temporal weighted averaging for asynchronous federated intrusion detection systems
   Aksu D, 2018, 2018 INTERNATIONAL CONGRESS ON BIG DATA, DEEP LEARNING AND FIGHTING CYBER TERRORISM (IBIGDELFT), P77, DOI 10.1109/IBIGDELFT.2018.8625370
   Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   Arunraj N. S., 2017, Anwendungen Konzepte Wirtschaftsinformatik, V6, P10
   Bansal A., 2018, International Conference on Advances in Computing and Data Sciences, P372, DOI DOI 10.1007/978-981
   Bentéjac C, 2021, ARTIF INTELL REV, V54, P1937, DOI 10.1007/s10462-020-09896-5
   Bhattacharya S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020219
   Bisong E., 2019, Building Machine Learning and Deep Learning Models on Google Cloud Platform
   Chakraborty T., 2019, VoIP Technology: Applications and Challenges, DOI [10.1007/978-3-319-95594-0, DOI 10.1007/978-3-319-95594-0]
   Chakraborty T, 2016, IEEE SYST J, V10, P370, DOI 10.1109/JSYST.2014.2382607
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chowdhury R, 2022, MULTIMED TOOLS APPL, V81, P41225, DOI 10.1007/s11042-022-12330-3
   Dey S, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Enache AC, 2014, 2014 IEEE 9TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P153, DOI 10.1109/SACI.2014.6840052
   Gharib A, 2016, 2016 INT C INFORM SC, P1
   Hlavacek D, 2014, COMPUT NETW, V75, P414, DOI 10.1016/j.comnet.2014.10.001
   Khan L, 2007, VLDB J, V16, P507, DOI 10.1007/s00778-006-0002-5
   Krishnaveni S, 2020, ADV INTELL SYST COMP, V1056, P723, DOI 10.1007/978-981-15-0199-9_62
   Kumar M, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P629, DOI 10.1109/ICCT.2012.6511281
   Liao X, 2013, IEICE T FUND ELECTR, VE96A, P2731, DOI 10.1587/transfun.E96.A.2731
   Liao X, 2013, IEICE T FUND ELECTR, VE96A, P2039, DOI 10.1587/transfun.E96.A.2039
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Lin WH, 2020, LECT NOTE DATA ENG, V41, P173, DOI 10.1007/978-3-030-34986-8_12
   Mahfouz A, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12110180
   Marir N, 2018, IEEE ACCESS, V6, P59657, DOI 10.1109/ACCESS.2018.2875045
   Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210
   Moustafa N, 2019, IEEE INTERNET THINGS, V6, P4815, DOI 10.1109/JIOT.2018.2871719
   Mukherjee S, 2012, PROC TECH, V4, P119, DOI 10.1016/j.protcy.2012.05.017
   Nikhitha M., 2019, Int J Recent Technol Eng, V8, P2258
   Orebaugh Angela, 2006, Wireshark & Ethereal Network Protocol Analyzer Toolkit
   Papavassiliou S, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12010007
   Pathak A., 2020, International Journal of Engineering Research Technology, V9, P376, DOI [DOI 10.17577/IJERTV9IS050303, 10.17577/ijertv9is050303]
   Phutane MT., 2015, J Comput Eng Technol, V6, P09
   Rahayuningsih PA., 2020, J Phys: Conference Series, V1641
   Singh Panwar S, 2019, INT C ADV ENG SCI MA
   Soltani M, 2022, INT J INF SECUR, V21, P547, DOI 10.1007/s10207-021-00567-2
   Suri S., 2010, International Journal of Innovative Technology and Exploring Engineering, V1, P63
   Thirimanne SP., 2022, SN Computer Science, V3, P1, DOI DOI 10.1007/S42979-022-01031-1
   Ustebay S, 2018, 2018 INTERNATIONAL CONGRESS ON BIG DATA, DEEP LEARNING AND FIGHTING CYBER TERRORISM (IBIGDELFT), P71, DOI 10.1109/IBIGDELFT.2018.8625318
   Dorogush AV, 2018, Arxiv, DOI arXiv:1810.11363
   Watson G., 2018, A comparison of header and deep packet features when detecting network intrusions
   Yulianto A, 2019, J PHYS CONF SER, V1192, DOI 10.1088/1742-6596/1192/1/012018
   Zhang CJ, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170312
NR 45
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16876-8
EA OCT 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900016
DA 2024-07-18
ER

PT J
AU Li, HS
   Chen, JY
   Huang, HF
AF Li, Hai-Sheng
   Chen, Jingyin
   Huang, Huafeng
TI QR code arbitrary style transfer algorithm based on style matching layer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE QR code; Image style transfer; Deep learning; Convolutional neural
   network
AB A single style transfer model can realize the Quick Response (QR) code beautification task. However, the number of styles in the single-style transfer model is limited, and the training must be carried out in advance to expand to new styles, which requires a lot of training time and memory. Therefore, the flexibility of the model needs to be further improved. The current mainstream arbitrary style transfer algorithm solves the flexibility problem and can complete the transfer task of any style after one training. Unfortunately, the existing arbitrary style transfer algorithms have issues such as heavy computational burden, distorted content, and blurred details, which are unsuitable for QR code beautification tasks. This paper proposes an arbitrary style conversion algorithm based on a style-matching layer to solve the above problems. Our algorithm obtains the style information using a small convolutional neural network and then transmits the second-order statistics of style images through a linear matrix multiplication to achieve arbitrary style transfer. Simulation results show that the proposed algorithm can efficiently complete the general style transfer task and has a higher visual quality and testing speed than the existing arbitrary style transfer models. Meanwhile, the algorithm can flexibly combine multi-level style features to complete the QR code style beautification task. Furthermore, there is a great affinity between the image generated by the proposed algorithm and the original image without distorted content and fuzzy details. Therefore, the generated style beautified QR code has high visual quality and recognition.
C1 [Li, Hai-Sheng; Chen, Jingyin; Huang, Huafeng] Guangxi Normal Univ, Sch Elect & Informat Engn, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Li, HS (corresponding author), Guangxi Normal Univ, Sch Elect & Informat Engn, Guilin 541004, Guangxi, Peoples R China.
EM lhs_ecjtu@126.com
FU the Science and Technology Project of Guangxi [2020GXNSFDA238023];
   Science and Technology Project of Guangxi [61762012]; National Natural
   Science Foundation of China
FX This work is supported by the Science and Technology Project of Guangxi
   under Grant No. 2020GXNSFDA238023, the National Natural Science
   Foundation of China under Grant no. 61762012. In addition, Rongrong Yuan
   and Wenya Yang participated in writing the revised manuscript.
CR Chauhan S, 2021, DATA SCI DATA ANALYT
   Chauhan S, 2021, IEEE 2 INT C ELECT P, P1
   DENSO WAVE INCORPORATED, About us
   Dumoulin V, 2017, Arxiv, DOI [arXiv:1610.07629, DOI 10.48550/ARXIV.1610.07629]
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Ghiasi G, 2017, Arxiv, DOI arXiv:1705.06830
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li HS, 2020, MULTIMED TOOLS APPL, V79, P33839, DOI 10.1007/s11042-019-08555-4
   Li YJ, 2018, LECT NOTES COMPUT SC, V11207, P468, DOI 10.1007/978-3-030-01219-9_28
   Li YJ, 2017, ADV NEUR IN, V30
   Li YJ, 2017, PROC CVPR IEEE, P266, DOI 10.1109/CVPR.2017.36
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Ning-zhong, 2011, Acta Electronica Sinica, V39, P2459
   Nichol K, 2016, Painter by numbers, P5264
   Risser E, 2017, Arxiv, DOI arXiv:1701.08893
   Shen FL, 2018, PROC CVPR IEEE, P8061, DOI 10.1109/CVPR.2018.00841
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Tu Chang-He, 2005, Chinese Journal of Computers, V28, P965
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Ulyanov D, 2016, arXiv, DOI 10.48550/ARXIV.1603.03417
   Wang X, 2017, PROC CVPR IEEE, P7178, DOI 10.1109/CVPR.2017.759
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   You FC, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012027
NR 30
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17231-7
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900009
DA 2024-07-18
ER

PT J
AU Joshi, I
   Prakash, T
   Kumar, R
   Dantcheva, A
   Roy, SD
   Kalra, PK
AF Joshi, Indu
   Prakash, Tushar
   Kumar, Rohit
   Dantcheva, Antitza
   Roy, Sumantra Dutta
   Kalra, Prem Kumar
TI Unsupervised domain alignment of fingerprint denoising models using
   pseudo annotations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fingerprint enhancement; Unsupervised domain adaptation;
   Self-supervision; Latent fingerprints
ID IMAGE-ENHANCEMENT; ORIENTATION; ALGORITHM
AB State-of-the-art fingerprint recognition systems perform far from satisfactory on noisy fingerprints. A fingerprint denoising algorithm is designed to eliminate noise from the input fingerprint and output a fingerprint image with improved clarity of ridges and valleys. To alleviate the unavailability of annotated data to train the fingerprint denoising model, state-of-the-art fingerprint denoising models generate synthetically distorted fingerprints and train the fingerprint denoising model on the synthetic data. However, a visible domain shift exists between synthetic training data and the real-world test data. Subsequently, state-of-the-art fingerprint denoising models suffer from poor generalization. To counter this drawback of state-of-the-art, this research proposes to align the synthetic and real fingerprint domains. Experiments conducted on publicly available rural Indian fingerprint demonstrate that after the proposed domain alignment, equal error rate improves from 7.30 to 6.10 on Bozorth matcher and 5.96 to 5.31 on minutiae cylinder code (MCC) matcher. Similar improved fingerprint recognition results are obtained for IIITD-MOLF and private rural fingerprints database as well.
C1 [Joshi, Indu; Dantcheva, Antitza] INRIA Sophia Antipolis, Valbonne, France.
   [Joshi, Indu; Roy, Sumantra Dutta; Kalra, Prem Kumar] Indian Inst Technol, Delhi, India.
   [Prakash, Tushar; Kumar, Rohit] Delhi Technol Univ, Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; Delhi Technological University
RP Joshi, I (corresponding author), INRIA Sophia Antipolis, Valbonne, France.; Joshi, I (corresponding author), Indian Inst Technol, Delhi, India.
EM indu.joshi@inria.fr
OI Prakash, Tushar/0009-0003-4691-3526
FU The authors acknowledge the support of the HPC services of Inria Sophia
   Antipolis and IIT Delhi for the computational infrastructure. The
   authors sincerely thank Prof. Phalguni Gupta from IIT Kanpur and Prof.
   Kamlesh Tiwari from BITS Pilani for sharing the; IIT Delhi
FX The authors acknowledge the support of the HPC services of Inria Sophia
   Antipolis and IIT Delhi for the computational infrastructure. The
   authors sincerely thank Prof. Phalguni Gupta from IIT Kanpur and Prof.
   Kamlesh Tiwari from BITS Pilani for sharing the private rural Indian
   fingerprint used in this research. The authors acknowledge Naman Mukund
   from Tekie for his technical guidance.
CR Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Cao K, 2015, INT CONF BIOMETR, P349, DOI 10.1109/ICB.2015.7139060
   Cappelli R, 2011, IEEE T PATTERN ANAL, V33, P1051, DOI 10.1109/TPAMI.2010.228
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chaidee W, 2018, INT CONF BIOMETR, P23, DOI 10.1109/ICB2018.2018.00015
   Chen CJ, 2016, INT CONF BIOMETR
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Gidaris S., 2018, P 6 INT C LEARNING R
   Gottschlich C, 2012, IEEE T IMAGE PROCESS, V21, P2220, DOI 10.1109/TIP.2011.2170696
   Gupta R, 2020, INFORM SCIENCES, V530, P201, DOI 10.1016/j.ins.2020.01.031
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Horapong K, 2021, IEEE ACCESS, V9, P96288, DOI 10.1109/ACCESS.2021.3093879
   Hsieh CT, 2003, PATTERN RECOGN, V36, P303, DOI 10.1016/S0031-3203(02)00032-8
   Jirachaweng S, 2007, LECT NOTES COMPUT SC, V4642, P96
   Joshi I, 2021, INT JOINT C NEUR NET, P1
   Joshi I, 2021, AI DEEP LEARNING BIO, P51
   Joshi I., 2021, Advanced Deep Learning Techniques for Fingerprint Preprocessing
   Joshi I, 2021, Digital image enhancement and reconstruction
   Joshi I, 2022, IEEE Sensors Letters
   Joshi I, 2022, Arxiv, DOI [arXiv:2208.09191, DOI 10.1109/TPAMI.2024.3362821, DOI 10.48550/ARXIV.2208.09191]
   Joshi I, 2022, MULTIMED TOOLS APPL, V81, P35349, DOI 10.1007/s11042-021-11863-3
   Joshi I, 2021, IEEE WINT C APPL COM, P60, DOI 10.1109/WACVW52041.2021.00011
   Joshi I, 2019, IEEE WINT CONF APPL, P895, DOI 10.1109/WACV.2019.00100
   Karabulut D, 2020, MULTIMED TOOLS APPL, V79, P18569, DOI 10.1007/s11042-020-08750-8
   Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Li YB, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108405
   Liu SX, 2017, PATTERN RECOGN, V67, P164, DOI 10.1016/j.patcog.2017.02.012
   Liu YC, 2018, PROC CVPR IEEE, P8867, DOI 10.1109/CVPR.2018.00924
   Long M, 2017, Conditional adversarial domain adaptation, P1647
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   NIST, NBISNIST Biometric Image Software
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Puri C, 2010, LECT NOTES COMPUT SC, V6005, P55
   Qian P, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987279
   Qu ZS, 2018, LECT NOTES COMPUT SC, V11141, P436, DOI 10.1007/978-3-030-01424-7_43
   Rama RK, 2011, P IEEE INT JOINT C B, P1
   Sahasrabudhe M, 2014, P IAPR ACM SPONS IND, P1
   Sankaran A, 2015, IEEE ACCESS, V3, P653, DOI 10.1109/ACCESS.2015.2428631
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Schuch P, 2016, INT CONF IMAG PROC
   Schuch P, 2018, IET BIOMETRICS, V7, P102, DOI 10.1049/iet-bmt.2016.0088
   Sharma RP, 2019, IMAGE VISION COMPUT, V83-84, P1, DOI 10.1016/j.imavis.2019.02.006
   Singh K, 2015, NEUROCOMPUTING, V167, P418, DOI 10.1016/j.neucom.2015.04.053
   Svoboda J, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P429, DOI 10.1109/BTAS.2017.8272727
   Tiwari K, 2014, LECT NOTES COMPUT SC, V8833, P199, DOI 10.1007/978-3-319-12484-1_22
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng E, 2014, Arxiv, DOI [arXiv:1412.3474, 10.48550/arXiv.1412.3474, DOI 10.48550/ARXIV.1412.3474]
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vatsa M, 2010, P INT WORKSH EM TECH, P1
   Volpi R, 2018, PROC CVPR IEEE, P5495, DOI 10.1109/CVPR.2018.00576
   Wang W, 2008, PATTERN RECOGN LETT, V29, P301, DOI 10.1016/j.patrec.2007.10.004
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3400066
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P955, DOI 10.1109/TPAMI.2013.184
   Zhang WC, 2021, IEEE T PATTERN ANAL, V43, P2047, DOI 10.1109/TPAMI.2019.2962476
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 66
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-15513-8
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500020
DA 2024-07-18
ER

PT J
AU Lobato-Camacho, FJ
   López, JC
   Vargas, JP
AF Lobato-Camacho, Francisco Jose
   Lopez, Juan Carlos
   Vargas, Juan Pedro
TI Virtual reality evaluation of the spatial learning strategies in gamers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality learning; Virtual reality evaluation; Spatial memory;
   Water maze
ID VIDEO GAMES; PERFORMANCE; MEMORY; NAVIGATION; ADHD; HIPPOCAMPUS;
   ACQUISITION; VALIDATION; TASK
AB Psychological memory tests have traditionally relied on paper-based methods. However, the emergence of virtual reality tools, including adaptations of animal lab tests, has opened up new possibilities for evaluating and enhancing attention and memory processes. The impact of virtual environments on spatial memory remains a topic of ongoing debate. To contribute to this discussion, we conducted a comprehensive study with two primary objectives. Firstly, we aimed to develop a virtual reality tool that could effectively assess search strategies in gamers within virtual environments. To achieve this, we designed a virtual water maze inspired by those used in animal research. Secondly, we conducted a cross-sectional study involving participants to analyze how spatial memory strategies evolve in a virtual environment with increasing gaming experience. The results revealed that participants with more gaming experience exhibited faster and more precise learning in the virtual water maze, along with improved search strategies. Additionally, our study allowed for the evaluation of our software and enabled us to track changes in the efficacy of learning strategies. Overall, this study emphasizes the potential of virtual environments for both evaluation and cognitive stimulation purposes.
C1 [Lobato-Camacho, Francisco Jose; Lopez, Juan Carlos; Vargas, Juan Pedro] Univ Seville, Fac Psicol, Dept Psicol Expt, Calle Camilo Jose Cela S-N, Seville 41018, Spain.
C3 University of Sevilla
RP Lobato-Camacho, FJ (corresponding author), Univ Seville, Fac Psicol, Dept Psicol Expt, Calle Camilo Jose Cela S-N, Seville 41018, Spain.
EM fralobcam@alum.us.es
RI Lopez, Juan C/H-6028-2015; Vargas, Juan Pedro/H-6950-2015
OI Vargas, Juan Pedro/0000-0002-4358-5737; Lobato-Camacho, Francisco
   Jose/0000-0001-9538-1771; Lopez-Garcia, Juan-Carlos/0000-0001-8106-5006
FU Universidad de Sevilla/CBUA; Gobierno de Espana; Ministerio de Ciencia e
   Innovacion [PID2019-110739GB-I00]
FX Funding for open access publishing: Universidad de Sevilla/CBUA This
   research was funded by Gobierno de Espana. Ministerio de Ciencia e
   Innovacion: PID2019-110739GB-I00/AEI/10.13039/501100011033.
CR Adams R, 2009, CHILD NEUROPSYCHOL, V15, P120, DOI 10.1080/09297040802169077
   Alvarez JA, 2006, NEUROPSYCHOL REV, V16, P17, DOI 10.1007/s11065-006-9002-x
   Anand KS, 2012, ANN INDIAN ACAD NEUR, V15, P239, DOI 10.4103/0972-2327.104323
   Artigas A.A., 2005, Int. J. Comp. Psychol., V18, P224, DOI [10.46867/IJCP.2005.18.03.03, DOI 10.46867/IJCP.2005.18.03.03]
   Astur RS, 2002, BEHAV BRAIN RES, V132, P77, DOI 10.1016/S0166-4328(01)00399-0
   Baram TZ, 2019, LEARN MEMORY, V26, P206, DOI 10.1101/lm.049239.118
   Butler O, 2020, J PSYCHIATR NEUROSCI, V45, P279, DOI 10.1503/jpn.190027
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Cimadevilla JM, 2011, J NEUROSCI METH, V196, P45, DOI 10.1016/j.jneumeth.2010.12.026
   Clemenson GD, 2020, BEHAV BRAIN RES, V390, DOI 10.1016/j.bbr.2020.112667
   Clemenson GD, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00057
   Clemenson GD, 2015, J NEUROSCI, V35, P16116, DOI 10.1523/JNEUROSCI.2580-15.2015
   COLLADO J. C, 2018, SECTOR VIDEOJUEGOS E
   Commins S, 2020, BEHAV RES METHODS, V52, P1189, DOI 10.3758/s13428-019-01310-5
   Daugherty AM, 2017, NEUROIMAGE, V146, P492, DOI 10.1016/j.neuroimage.2016.09.044
   Dupret D, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001959
   EICHENBAUM H, 1990, J NEUROSCI, V10, P3531
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Garthe A, 2016, HIPPOCAMPUS, V26, P261, DOI 10.1002/hipo.22520
   Garthe A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00063
   Gaunet F, 1996, PERCEPTION, V25, P967, DOI 10.1068/p250967
   Gómez Y, 2020, BRAIN RES BULL, V164, P29, DOI 10.1016/j.brainresbull.2020.08.007
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Green CS, 2006, COGNITION, V101, P217, DOI 10.1016/j.cognition.2005.10.004
   Hsu WY, 2023, ANN PHYS REHABIL MED, V66, DOI 10.1016/j.rehab.2022.101677
   Jiménez-Soto A, 2022, ACTA PSYCHOL, V224, DOI 10.1016/j.actpsy.2022.103528
   Kallai J, 2005, BEHAV BRAIN RES, V159, P187, DOI 10.1016/j.bbr.2004.10.015
   Kapadia M, 2016, NEUROSCI BIOBEHAV R, V68, P195, DOI 10.1016/j.neubiorev.2016.05.016
   Kessels RPC, 2001, BRAIN RES REV, V35, P295, DOI 10.1016/S0165-0173(01)00058-3
   Kühn S, 2014, MOL PSYCHIATR, V19, P265, DOI 10.1038/mp.2013.120
   Lau Chloe, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020019
   Levy LJ, 2005, BEHAV NEUROSCI, V119, P853, DOI 10.1037/0735-7044.119.4.853
   Liu YX, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.197467
   López JC, 2003, NEUROSCI LETT, V341, P197, DOI 10.1016/S0304-3940(03)00186-1
   Machado ML, 2019, J NEUROSCI METH, V327, DOI 10.1016/j.jneumeth.2019.108388
   Maggio MG, 2019, J NATL MED ASSOC, V111, P457, DOI 10.1016/j.jnma.2019.01.003
   Maggio MG, 2019, J NEUROSCI NURS, V51, P101, DOI 10.1097/JNN.0000000000000423
   Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597
   MORRIS R, 1984, J NEUROSCI METH, V11, P47, DOI 10.1016/0165-0270(84)90007-4
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Newcombe NS, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.186460
   Oing Theodore, 2018, JMIR Serious Games, V6, pe10965, DOI 10.2196/10965
   Ouellet É, 2018, J NEUROSCI METH, V303, P126, DOI 10.1016/j.jneumeth.2018.03.010
   Parsons TD, 2007, CHILD NEUROPSYCHOL, V13, P363, DOI 10.1080/13825580600943473
   Vargas JP, 2009, BRAIN RES BULL, V79, P436, DOI 10.1016/j.brainresbull.2009.05.008
   Peñuelas-Calvo I, 2022, EUR CHILD ADOLES PSY, V31, P5, DOI 10.1007/s00787-020-01557-w
   Rand D, 2009, NEUROPSYCHOL REHABIL, V19, P583, DOI 10.1080/09602010802469074
   Rinderknecht MD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209839
   Schenk S, 2017, BEHAV BRAIN RES, V335, P208, DOI 10.1016/j.bbr.2017.08.027
   Schoenfeld R, 2017, NEUROBIOL LEARN MEM, V139, P117, DOI 10.1016/j.nlm.2016.12.022
   SEMENOV LV, 1989, BEHAV NEURAL BIOL, V51, P346, DOI 10.1016/S0163-1047(89)90987-4
   Serrano-Barroso A, 2022, CHILDREN-BASEL, V9, DOI 10.3390/children9111652
   Serrano-Barroso A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093221
   Spence I, 2010, REV GEN PSYCHOL, V14, P92, DOI 10.1037/a0019491
   Thornberry C, 2021, REV NEUROSCIENCE, V32, P887, DOI 10.1515/revneuro-2020-0149
   Thurley K, 2022, FRONT SYST NEUROSCI, V16, DOI 10.3389/fnsys.2022.896251
   Tong T, 2016, JMIR SERIOUS GAMES, V4, pE7, DOI 10.2196/games.5006
   Vargas JP, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00206
   Woollett K, 2011, CURR BIOL, V21, P2109, DOI 10.1016/j.cub.2011.11.018
   Woolley DG, 2010, BEHAV BRAIN RES, V208, P408, DOI 10.1016/j.bbr.2009.12.019
NR 61
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17177-w
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Rayachoti, E
   Gundabatini, SG
   Vedantham, R
AF Rayachoti, Eswaraiah
   Gundabatini, Sanjay Gandhi
   Vedantham, Ramachandran
TI Recurrent Residual Puzzle based Encoder Decoder Network (R2-PED) model
   for retinal vessel segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retinal vessel segmentation; Pre-processing; Feature extraction;
   Segmentation and residual puzzle-based encoder decoder network model
   (R2PED)
AB The retina is considered the most important part of the eye, containing numerous light, cone, rod and nerve cells. The retina collects and categorizes information from visual data and transmits it to the brain via the optic nerve. In retinal images, manual blood vessel classifications have huge restrictions. It takes a long time and is prone to human errors, especially when dealing with twisted blood vessels and many retinal images to analyze. As a result, an effective technique is required for extracting and segmenting the required features of retinal blood vessels. Therefore, a new supervised deep learning-based model is proposed for an effective vessel segmentation process. The proposed model undergoes two stages: pre-processing and segmentation. In this work, a new recurrent residual puzzle-based encoder decoder network model (R2PED) is proposed for the segmentation of retinal vessels from Optical coherence tomography (OCT) images. This model preserves the edge information using a recurrent residual connection between the encoder and decoder modules. Also, it contains a self-attention approach for describing the complex contextual dependences across local feature depictions. The proposed approach uses three OCT datasets to analyze the vessel segmentation performance. The simulation results show that the proposed R2PED network model outdoes the existing models by achieving the Jaccard indexes of 85.78, 89.63, and 87.34 on OCTA-SS, OCTA-6 M, and OCTA-3 M datasets.
C1 [Rayachoti, Eswaraiah] VIT AP Univ, SCOPE, Amaravati 522237, Andhra Pradesh, India.
   [Gundabatini, Sanjay Gandhi; Vedantham, Ramachandran] Vasireddy Venkatadri Inst Technol, Dept Comp Sci & Engn, Namburu 522508, AP, India.
C3 VIT-AP University
RP Rayachoti, E (corresponding author), VIT AP Univ, SCOPE, Amaravati 522237, Andhra Pradesh, India.
EM eswaraiah.rayachoti@vitap.ac.in
RI Ramachandran, Vedantham/E-7627-2016
OI Ramachandran, Vedantham/0000-0002-3857-8145
CR Aguirre-Ramos H, 2018, APPL MATH COMPUT, V339, P568, DOI 10.1016/j.amc.2018.07.057
   BahadarKhan K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158996
   Bhuiyan A, 2021, medRxiv
   Lipton ZC, 2015, Arxiv, DOI [arXiv:1506.00019, DOI 10.48550/ARXIV.1506.00019]
   Chatterjee Sayan, 2021, Journal of Physics: Conference Series, V1717, DOI 10.1088/1742-6596/1717/1/012008
   Chen CH, 2021, IEEE ACCESS, V9, P111985, DOI 10.1109/ACCESS.2021.3102176
   Corazza P, 2021, EXPERT REV MOL DIAGN, V21, P109, DOI 10.1080/14737159.2020.1865806
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Erwin, 2022, INT J COMPUT INTELL, V21, DOI 10.1142/S1469026822500043
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gao X., 2017, P IEEE INT C COMM, P1
   Giarratano Y, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.13.5
   He K., 2016, PROC IEEE C COMPUT V
   Hu DW, 2021, LECT NOTES COMPUT SC, V12901, P514, DOI 10.1007/978-3-030-87193-2_49
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Imran A, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2935912
   Jiang Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091112
   Li M, 2018, FED CONF COMPUT SCI, P117, DOI 10.15439/2018F127
   Li MC, 2020, Arxiv, DOI arXiv:2012.07261
   Lian S, 2021, IEEE ACM T COMPUT BI, V18, P852, DOI 10.1109/TCBB.2019.2917188
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu XM, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104604
   Liu YF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3133956
   Manan MA, 2022, arXiv
   Mou L, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101874
   Mou L, 2019, LECT NOTES COMPUT SC, V11764, P721, DOI 10.1007/978-3-030-32239-7_80
   Naveed K, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11010114
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Srinidhi CL, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0719-2
   Tan X, 2023, COMPUT METH PROG BIO, V233, DOI 10.1016/j.cmpb.2023.107454
   Uysal E, 2021, MULTIMED TOOLS APPL, V80, P3505, DOI 10.1007/s11042-020-09372-w
   Wang Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3181062
   Xiancheng W, 2018, PROCEDIA COMPUTER SC, P8
   Xu ZY, 2021, BRIT J OPHTHALMOL, V105, P561, DOI 10.1136/bjophthalmol-2020-315817
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Ye YW, 2022, IEEE J BIOMED HEALTH, V26, P4551, DOI 10.1109/JBHI.2022.3182471
   Zeidabadi F.A., 2022, Int J Intell Eng Syst, V15, P273
   Zhuang J, 2019, P ACM TUR CEL C CHIN, P1
NR 39
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16765-0
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500018
DA 2024-07-18
ER

PT J
AU Obeidat, I
   Mughaid, A
   AlZu'bi, S
   AL-Arjan, A
   AL-Amrat, R
   AL-Ajmi, R
   AL-Hayajneh, R
   Abuhaija, B
   Abualigah, L
AF Obeidat, Ibrahim
   Mughaid, Ala
   AlZu'bi, Shadi
   AL-Arjan, Ahmed
   AL-Amrat, Rula
   AL-Ajmi, Rathaa
   AL-Hayajneh, Razan
   Abuhaija, Belal
   Abualigah, Laith
TI A novel secure cryptography model for data transmission based on Rotor64
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Rotor64; Cryptography; Data transmission; Cyber Security; Authintication
AB In recent years, there have been many Security vulnerabilities that threaten user security, these threats have led to the finding of user files, so the use of the Internet has become unlimited, and the number of digital network devices has increased,Therefore, maintaining the confidentiality and integrity of information has become an urgent necessity to preserve user information, due to the increase in hackers and intruders, and the innovation of modern methods of penetration every day. Data cryptography has proven to be a secure way to protect a user's data. Many current cryptography algorithms are considered weak regarding data transmission over the Internet, so newly updated algorithms are in high demand. In this paper, we proposed to develop the ancient rotor machine depending on the base64 codding technique, in which we replaced the alphabets of the ancient rotor machine with the alphabets of base64 that contain 64 characters. Furthermore, we proposed a key exchange based on One-time password OTP code via SMS, OTP is mechanism for logging on to a network using unique password that can only be used once, to overcome the static password method that is least secure, and used it to generate the subkeys for rotor machines based on hash and random permutation techniques. MD5 algorithm function is used to authenticate the original message, Finally, we experimented with these techniques of secure sending e-mails by encrypting the contents of them with the proposed technique. However, the proposed security technique got promising results.
C1 [Obeidat, Ibrahim; Mughaid, Ala; AL-Arjan, Ahmed; AL-Amrat, Rula; AL-Ajmi, Rathaa; AL-Hayajneh, Razan] Hashemite Univ, Fac Prince Al Hussein Bin Abdallah II Informat Tec, Dept Informat Technol, POB 330127, Zarqa 13133, Jordan.
   [AlZu'bi, Shadi] Al Zaytoonah Univ Jordan, Fac Sci & IT, Amman, Jordan.
   [Abuhaija, Belal] Wenzhou Kean Univ, Dept Comp Sci, Wenzhou, Peoples R China.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Hashemite University; Al-Zaytoonah University of Jordan; Wenzhou-Kean
   University; Lebanese American University; Al-Ahliyya Amman University;
   Middle East University
RP Abuhaija, B (corresponding author), Wenzhou Kean Univ, Dept Comp Sci, Wenzhou, Peoples R China.; Abualigah, L (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM imsobeidat@hu.edu.jo; smalzubi@zuj.edu.jo; babuhaij@kean.edu;
   Aligah.2020@gmail.com
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Abualigah Laith, 2023, Pervasive Knowledge and Collective Intelligence on Web and Social Media: First EAI International Conference, PerSOM 2022, Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (494), P96, DOI 10.1007/978-3-031-31469-8_7
   Alia MohammadAhmad., 2010, EUR J SCI RES, V40, P223
   Arshad A, 2023, Decis Anal J
   Bauer FL, 1999, CRYPTOLOGIA, V23, P206, DOI 10.1080/0161-119991887847
   Bauer FL., 1997, Decrypted Secrets; Methods and Maxims of Cryptology, DOI [10.1007/978-3-662-03452-1, DOI 10.1007/978-3-662-03452-1]
   Bauer FL, 2007, The history of information security, P381
   Christensen C, 2010, Cryptologia, V35, P97
   Deepakumara J, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P919, DOI 10.1109/CCECE.2001.933564
   Gupta S., 2014, Int J Comput Appl, V104, P14
   Kaushal R., 2020, IJICTDC, V5, P28
   Khodadadi N, 2023, IEEE Access
   Kore A, 2022, WIREL NETW, V28, P287, DOI 10.1007/s11276-021-02850-5
   Kumar A, 2020, Arxiv, DOI arXiv:2011.01803
   Liu QX, 2023, ARTIF INTELL REV, V56, P159, DOI 10.1007/s10462-023-10498-0
   Mangla C, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/3426811
   Mughaid A, 2023, Int J Data Netw Sci, V7, P757
   Mughaid A, 2023, MULTIMED TOOLS APPL, V82, P13973, DOI 10.1007/s11042-022-13914-9
   Mughaid A, 2022, SOFT COMPUT, V26, P5577, DOI 10.1007/s00500-022-07080-1
   Pandya D., 2015, International Journal of Computer Applications, V131, P28, DOI DOI 10.5120/IJCA2015907390
   Prasanalakshmi B, 2022, J SUPERCOMPUT, V78, P361, DOI 10.1007/s11227-021-03861-x
   Rehman AU, 2020, IEEE ACCESS, V8, P172275, DOI 10.1109/ACCESS.2020.3024994
   Shahbazi Z, 2021, PROCESSES, V9, DOI 10.3390/pr9010092
   Sharma A, 2013, Arxiv, DOI arXiv:1302.4510
   Silambarasan S., 2022, International Journal of Computer Networks and Applications, P316, DOI 10.22247/ijcna/2022/212557
   Thirumalai C, 2016, Int J Pharm Technol, V8, P21797
   Zhang Y, 2020, NANO TODAY, V33, DOI 10.1016/j.nantod.2020.100871
NR 26
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16889-3
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300006
DA 2024-07-18
ER

PT J
AU Shirley, CP
   Raja, JIJ
   Sonia, SVE
   Titus, I
AF Shirley, C. P.
   Raja, J. Immanuel John
   Sonia, S. V. Evangelin
   Titus, I.
TI Recognition and monitoring of gas leakage using infrared imaging
   technique with machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gas leakage; Artificial intelligence; Infrared imaging techniques;
   Machine learning; Image processing
AB Gas leakage in the domestic sector leads to numerous dangerous hazards. The earlier prediction is one of the safety measures to prevent various consequences. The proposed system helps in the earlier detection of gas leakage using artificial intelligence techniques. This involves machine learning with infrared imaging techniques. Machine learning is the process of teaching machines to do tasks automatically by analysing and testing data. The obtained data are processed using image processing techniques. The image processing technique is used to extract information from the images involving various stages such as image enhancement and image analysis. The initial data are obtained in the form of images using infrared imaging techniques. It is the technique that utilizes the infrared portion of the electromagnetic spectrum to obtain the desired images. The obtained images are processed to obtain clear images in the dataset. The data is then tested and taught using machine learning evolving optimization techniques on the data. This helps in the accurate detection of gas leakage. To compare, the individual models' test accuracy ranged from 99.8% (based on Gas Sensor data using Random Forest) with the training accuracy of 99.8%. Experimental results demonstrate its ability to automatically detect and display gas leaks in high quality by establishing a background model, segmenting the gas-leak zone with motion characteristics, and rendering the gas-leak region in colour using grayscale mapping.
C1 [Shirley, C. P.; Raja, J. Immanuel John; Sonia, S. V. Evangelin; Titus, I.] Karunya Inst Technol & Sci, Coimbatore, India.
C3 Karunya Institute of Technology & Sciences
RP Sonia, SVE (corresponding author), Karunya Inst Technol & Sci, Coimbatore, India.
EM evangelinsonia.vs@gmail.com
OI C P, SHIRLEY/0000-0002-8263-0238; Jebadurai, Immanuel
   Johnaja/0000-0002-8548-3333
CR Adabi S., 2019, IEEE Trans Indust Electron, V66, P1093
   Amiri MJ., 2020, IEEE Trans Instrum Meas, V69, P4351, DOI [10.1109/TIM.2019.2948584, DOI 10.1109/TIM.2019.2948584]
   Cao Y., 2016, IEEE Trans Indust Electron, V63, P3847
   Chen C., 2021, 2021 IEEE 16 INT C A, P331
   Chen K., 2019, IEEE Access., V7, P7317
   Cheung KCK., 2014, IEEE Sensors J., V14, P2138
   Gurreri GA., 2013, IEEE Trans Indust Electron, V60, P2447
   Kumar R, 2018, 2018 IEEE INT C EL E, P760, DOI [10.1109/ICEECCOT.2018.8720695, DOI 10.1109/ICEECCOT.2018.8720695]
   Lee SW, 2020, Sensors (Basel), V20, P5832
   Li M, 2020, 2020 IEEE 6 INT C CO, P2302
   Liu Y., 2016, IEEE Trans Instrum Meas, V65, P2225
   Marsico MA., 2015, IEEE Trans Indust Electron, V62, P3839
   Mirjalili SM, 2015, 2015 IEEE INT C IND, P932, DOI [10.1109/IEEM.2015.7385806, DOI 10.1109/IEEM.2015.7385806]
   Rahimi A., 2017, IEEE Trans Ind Electron., V64, P3336, DOI [10.1109/TIE.2016.2622163, DOI 10.1109/TIE.2016.2622163]
   Shahriari M, 2019, 2019 IEEE 9 ANN COMP, P0682, DOI [10.1109/CCWC.2019.8666586, DOI 10.1109/CCWC.2019.8666586]
   Sun H, 2018, 2018 IEEE INT C ROB, P1
   Sun H., 2018, IEEE Access, V6, P23934
   Tian Y., 2018, IEEE Access., V6, P66147
   Wang X., 2020, 2020 INT C COMP INF, P109
   Wang Y., 2019, 2019 IEEE 4 INT C IN, P557
   Xie Y., 2020, IEEE Access., V8, P50631
   Zhang H, 2019, 2019 IEEE 5 INT C CO, P1728
   Zhang T., 2017, IEEE Sensors J., V17, P6017
   Zhang XT, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3120796
   Zhang YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3011777
   Zheng J., 2021, 2021 IEEE INT C POW, P232
   Zhou L., 2019, 2019 IEEE 14 INT C C, P1036
   Zhou Y., 2020, IEEE Access, V8, P199146
NR 28
TC 2
Z9 2
U1 11
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17131-w
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600017
DA 2024-07-18
ER

PT J
AU Ali, M
   Yin, BQ
   Bilal, H
   Kumar, A
   Shaikh, AM
   Rohra, A
AF Ali, Munawar
   Yin, Baoqun
   Bilal, Hazrat
   Kumar, Aakash
   Shaikh, Ali Muhammad
   Rohra, Avinash
TI Advanced efficient strategy for detection of dark objects based on
   spiking network with multi-box detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Object detection; Spiking neural network; Convolutional
   layer; Single shot multi-box detector (SSD); VGG-16
ID YOLO
AB Several deep learning algorithms have shown amazing performance for existing object detection tasks, but recognizing darker objects is the largest challenge. Moreover, those techniques struggled to detect or had a slow recognition rate, resulting in significant performance losses. As a result, an improved and accurate detection approach is required to address the above difficulty. The whole study proposes a combination of spiked and normal convolution layers as an energy-efficient and reliable object detector model. The proposed model is split into two sections. The first section is developed as a feature extractor, which utilizes pre-trained VGG16, and the second section of the proposal structure is the combination of spiked and normal Convolutional layers to detect the bounding boxes of images. We drew a pre-trained model for classifying detected objects. With state of the art Python libraries, spike layers can be trained efficiently. The proposed spike convolutional object detector (SCOD) has been evaluated on VOC and Ex-Dark datasets. SCOD reached 66.01% and 41.25% mAP for detecting 20 different objects in the VOC-12 and 12 objects in the Ex-Dark dataset. SCOD uses 14 Giga FLOPS for its forward path calculations. Experimental results indicated superior performance compared to Tiny YOLO, Spike YOLO, YOLO-LITE, Tinier YOLO and Center of loc + Xception based on mAP for the VOC dataset.
C1 [Ali, Munawar; Yin, Baoqun; Bilal, Hazrat; Kumar, Aakash; Shaikh, Ali Muhammad; Rohra, Avinash] Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ali, M (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China.
EM alimunawar@mail.ustc.edu.cn
RI Bilal, Hazrat/HTP-2363-2023
OI Bilal, Hazrat/0000-0002-7328-3705
FU This work was supported in part by the National Natural Science
   Foundation of China under Grant 62133013 and in part by the Chinese
   Association for Artificial Intelligence (CAAI)-Huawei Mind Spore Open
   Fund. [62133013]; National Natural Science Foundation of China; Chinese
   Association for Artificial Intelligence (CAAI)-Huawei Mind Spore Open
   Fund
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62133013 and in part by the Chinese
   Association for Artificial Intelligence (CAAI)-Huawei Mind Spore Open
   Fund.
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Ahmad T, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8403262
   Ali MH, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14375-4
   Barbhuiya AA, 2021, MULTIMED TOOLS APPL, V80, P3051, DOI 10.1007/s11042-020-09829-y
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen XL, 2017, Arxiv, DOI arXiv:1702.02138
   Dong BW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2856, DOI 10.1109/ICCV48922.2021.00287
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959
   Gavrilescu R, 2018, INT CONF EXPO ELECTR, P165, DOI 10.1109/ICEPE.2018.8559776
   Gerstner W, 2002, Spiking Neuron Models: An Introduction, P494
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Horak K, 2019, PROC SPIE, V11179, DOI 10.1117/12.2539806
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Ibrahem H, 2021, IEEE ACCESS, V9, P38742, DOI 10.1109/ACCESS.2021.3064372
   Jensen MB, 2017, IEEE COMPUT SOC CONF, P882, DOI 10.1109/CVPRW.2017.122
   Kahlon GS, 2023, MULTIMED TOOLS APPL, V82, P34589, DOI 10.1007/s11042-023-15019-3
   Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Lee C, 2019, IEEE T COGN DEV SYST, V11, P384, DOI 10.1109/TCDS.2018.2833071
   Li Yongquan, 2022, 2022 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)., P264, DOI 10.1109/ICCCBDA55098.2022.9778892
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2023, MULTIMED TOOLS APPL, V82, P21673, DOI 10.1007/s11042-023-14646-0
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Macías-Macías M, 2023, MULTIMED TOOLS APPL, V82, P21657, DOI 10.1007/s11042-023-14668-8
   Mahendru M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P734, DOI 10.1109/Confluence51648.2021.9377064
   Msonda P, 2020, TRAIT SIGNAL, V37, P1075, DOI 10.18280/ts.370620
   Panda P, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00653
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Rauber Jonas, 2020, Journal of Open Source Software, V5, P2607, DOI DOI 10.21105/JOSS.02607
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shafiee MJ, 2017, arXiv
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P1687, DOI 10.1016/j.jksuci.2019.09.012
   Shetty S, 2016, Arxiv, DOI arXiv:1607.03785
   Tammina S, 2019, Int. J. Sci. Res. Publ, V9, P143, DOI DOI 10.29322/IJSRP.9.10.2019.P9420
   Tang P, 2021, IEEE WINT CONF APPL, P2290, DOI 10.1109/WACV48630.2021.00234
   Tsung-Y, 2017, P IEEE C COMP VIS PA, P2117, DOI [10.48550/arXiv.1612.03144, DOI 10.48550/ARXIV.1612.03144]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu ZZ, 2022, IEEE T NEUR NET LEAR, V33, P6249, DOI 10.1109/TNNLS.2021.3073016
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang HW, 2018, PROCEEDINGS OF 2018 IEEE 7TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS), P170, DOI 10.1109/DDCLS.2018.8516094
   Zhang S, 2023, MULTIMED TOOLS APPL, V82, P26063, DOI 10.1007/s11042-023-14342-z
   Zhang S, 2020, CHINESE J ELECTRON, V29, P132, DOI 10.1049/cje.2019.11.002
   Zimmer R, 2019, Arxiv, DOI arXiv:1911.10124
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 51
TC 44
Z9 43
U1 32
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16852-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000020
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Yan, M
   Hu, YL
   Zhang, HK
AF Yan, Ming
   Hu, Yueli
   Zhang, Haikun
TI Progressive meaningful visual cryptography for secure communication of
   grayscale medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meaningful shares; Medical images; Single grayscale secret; Triggered
   error; Visual Cryptography
ID SOCIAL NETWORKS
AB In the digital era, data transmission plays a crucial role, encompassing various forms such as text, images, and videos. Industries such as banking, medical, marketing, social media, and business applications heavily rely on images for communication with customers and others. However, this increased reliance on digital communication has attracted Cyber Attackers (CAs), individuals or entities that exploit network weaknesses and disturb data integrity, leading to vulnerabilities in data transmission. The healthcare industry, in particular, has faced significant costs due to data breaches, as indicated by the Cost of a Data Breach Report 2021. Securing such data during communication is a key challenge. Visual Cryptography (VC) emerges as a powerful solution for secure image transfer. VC's share generation module encrypts the image and divides it into multiple shares, which are then communicated to recipients. Individual shares do not disclose classified information. At the destination, the shares are digitally or physically stacked to reconstruct the original image without the need for complex mathematical operations or additional hardware. Key constraints in VC include the security of share images, the quality of the reconstructed image, pixel expansion issues, and computational complexity. Despite the significance of VC, existing research papers often focus on specific types of schemes, leaving gaps in comprehensive comparisons and coverage of the state-of-the-art. To address this, we propose a new Progressive Meaningful Visual Cryptography (PMVC) method in this paper for transferring secret images by triggering an error instance. The proposed method generates meaningful shares and ensures the quality of the reconstructed image, achieving a peak signal-to-noise ratio (PSNR) of up to 37 dB without pixel expansion issues. Additionally, the proposed method works on (n, n) VC schemes and supports grayscale secret images.
C1 [Yan, Ming; Hu, Yueli; Zhang, Haikun] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
C3 Shanghai University
RP Hu, YL (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
EM Yan_ming22@outlook.com; Yuelihu.rnd@gmail.com; Haikun_Zzhang@outlook.com
RI yan, ming/KDP-1369-2024; Hu, Yue/HGE-1673-2022
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blesswin AJ, 2022, WIRELESS PERS COMMUN, V122, P3085, DOI 10.1007/s11277-021-09041-7
   Blesswin AJ, 2020, MULTIMED TOOLS APPL, V79, P17057, DOI 10.1007/s11042-019-7535-2
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Dehkordi MH, 2015, WIRELESS PERS COMMUN, V82, P1749, DOI 10.1007/s11277-015-2310-9
   Dehkordi MH, 2016, WIRELESS PERS COMMUN, V91, P1459, DOI 10.1007/s11277-016-3539-7
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Fu ZX, 2018, IEEE ACCESS, V6, P59567, DOI 10.1109/ACCESS.2018.2874527
   Guo YS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041321
   Huang BY, 2020, MULTIMED TOOLS APPL, V79, P7705, DOI 10.1007/s11042-019-08436-w
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Mary GS, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab2faa
   Mhala NC, 2018, IET IMAGE PROCESS, V12, P422, DOI 10.1049/iet-ipr.2017.0759
   Mudia HM, 2016, PROCEDIA COMPUT SCI, V78, P632, DOI 10.1016/j.procs.2016.02.110
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Mary GS, 2022, WIRELESS PERS COMMUN, V125, P1695, DOI 10.1007/s11277-022-09628-8
   Mary GS, 2020, MULTIMED TOOLS APPL, V79, P10363, DOI 10.1007/s11042-019-7202-7
   Sridhar S, 2017, MULTIMED TOOLS APPL, V76, P815, DOI 10.1007/s11042-015-3066-7
   Verheul E.R., 1997, DESIGN CODE CRYPTOGR, V2, P179, DOI [10.1023/A:1008280705142, DOI 10.1023/A:1008280705142]
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang SJ, 2011, WIRELESS PERS COMMUN, V56, P173, DOI 10.1007/s11277-009-9875-0
   Wu X, 2022, IEEE T CIRC SYST VID
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33639
EP 33652
DI 10.1007/s11042-023-16960-z
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100005
DA 2024-07-18
ER

PT J
AU Wang, XY
   Leng, ZY
AF Wang, Xingyuan
   Leng, Ziyu
TI Image encryption algorithm based on face recognition, facial features
   recognition and bitonic sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy image encryption; Facial features recognition; Chaotic system;
   Fisher-Yeats algorithm; Hash function
ID MAP
AB Traditional scrambling algorithms frequently rely on static and fixed scrambling modes, which lack the involvement of chaotic sequences during the scrambling phase. This results in poor randomness in the scrambling process and can leave key information, such as facial features in images, inadequately protected. In the event that such sensitive information is stolen, it could lead to significant trouble. To mitigate these issues, this paper presents an image encryption algorithm that incorporates face recognition and bitonic sequence techniques. The algorithm utilizes the SHA-512 (Secure Hash Algorithm) for key generation and the Chen system for generating chaotic sequences during the encryption process. Initially, the algorithm identifies the face and facial features within the image via face recognition and facial feature recognition technologies. A row-column scrambling algorithm, designed based on the characteristics of the bitonic sequence, is then implemented to scramble the facial features while the Zigzag algorithm is used to break the row-column correlation. With respect to the overall image scrambling, the Fisher Yeats scrambling algorithm is employed, and the entire image is uniformly diffused. Through simulation experiments and security tests, the proposed algorithm has shown better performance than other methods in terms of NPCR and UACI testing studies, resulting in outcomes closer to the ideal values of 99.6094% and 33.4635%, respectively. Other experimental data also demonstrates performance that is near ideal, and the decrypted images show good visual quality against various attacks. Overall, the proposed algorithm exhibits strong robustness.
C1 [Wang, Xingyuan; Leng, Ziyu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Dalian Maritime University; Guangxi Normal University
RP Wang, XY; Leng, ZY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM xywang@dlmu.edu.cn; lengziyu0402@163.com
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS20-M-02]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Alexan W, 2023, FRACTAL FRACT, V7, DOI 10.3390/fractalfract7040287
   Chai XL, 2023, IEEE INTERNET THINGS, V10, P7380, DOI 10.1109/JIOT.2022.3228781
   Chai XL, 2022, NONLINEAR DYNAM, V108, P2671, DOI 10.1007/s11071-022-07328-3
   Chen BJ, 2022, IEEE T CIRC SYST VID, V32, P3527, DOI 10.1109/TCSVT.2021.3116679
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Kitio GJ, 2023, BRAZ J PHYS, V53, DOI 10.1007/s13538-023-01268-y
   Jin B, 2022, IEEE SENS J, V22, P21780, DOI 10.1109/JSEN.2022.3197235
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Kumari P, 2023, WIRELESS PERS COMMUN, V130, P2261, DOI 10.1007/s11277-023-10382-8
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Li XJ, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107074
   Lin HR, 2022, IEEE T IND INFORM, V18, P8839, DOI 10.1109/TII.2022.3155599
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Mao N, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01294-8
   Peters H, 2011, CONCURR COMP-PRACT E, V23, P681, DOI 10.1002/cpe.1686
   Pourasad Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030341
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Sha YW, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501863
   Silva-García VM, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030599
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Song W, 2023, MATH COMPUT SIMULAT, V204, P71, DOI 10.1016/j.matcom.2022.07.029
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XQ, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421500218
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421500036
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu YR, 2023, IEEE T IND INFORM, V19, P2089, DOI 10.1109/TII.2022.3194590
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan DW, 2023, EUR PHYS J PLUS, V138, DOI 10.1140/epjp/s13360-023-03904-7
   Yan SH, 2023, MATH COMPUT SIMULAT, V206, P391, DOI 10.1016/j.matcom.2022.11.016
   Ye Guodong, 2022, Alexandria Engineering Journal, V61, P6785, DOI 10.1016/j.aej.2021.12.023
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P474, DOI 10.1109/TPAMI.2020.3011426
NR 44
TC 0
Z9 0
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31603
EP 31627
DI 10.1007/s11042-023-16787-8
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200012
DA 2024-07-18
ER

PT J
AU Liao, PH
   Chu, WL
AF Liao, Pei-Hung
   Chu, William
TI Exploring the impact of an instructional web-based healthcare app for
   relieving back pain from spinal compression fractures: an observational
   study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web app; Health instructions; Compression fracture; Back pain; Quality
   of life
ID PERCUTANEOUS VERTEBROPLASTY; MANAGEMENT; KYPHOPLASTY; DIAGNOSIS;
   FRAILTY; SCHEME
AB With the expected rise of patients with osteoporosis-induced fractures, it has become increasingly urgent to design and use specialized health education materials to ease pain and improve bodily functions. This study designed web-based app for pain relief instructions for women with spinal compression fractures. An observational study was conducted at an educational hospital in northern Taiwan between October 2018 and September 2019. Using random assignment based on their presentation order, we divided patients into an experimental (n = 87) and control (n = 84) group. The experimental and control groups received web app healthcare instructions for relieving back pain and regular nursing care instructions, respectively. Taiwanese versions of the Brief Pain Inventory and 36-Item Short Form Health Survey were used to collect data. We collected patients' pain rating data the day before, one month after, and three months after providing them with the instructions. Pain intensity differed significantly between the two groups, and it interacted with time. Pain impact did not significantly differ between groups; however, it interacted with time. Relieving back pain is a primary concern for those affected by it. This study presents a consistent, easy-to-use instructional healthcare web-based app that may provide knowledge of pain relief and reduce mobility impairments.
C1 [Liao, Pei-Hung; Chu, William] Natl Taipei Univ Nursing & Hlth Sci, Sch Nursing, Taipei, Taiwan.
   [Chu, William] Natl Taipei Univ Nursing & Hlth Sci, Cheng Hsin Gen Hosp, Sch Nursing, Dept Orthoped, 45, Cheng Hsin St, Taipei 112, Taiwan.
C3 National Taipei University of Nursing & Health Science (NTUNHS);
   National Taipei University of Nursing & Health Science (NTUNHS); Cheng
   Hsin General Hospital
RP Chu, WL (corresponding author), Natl Taipei Univ Nursing & Hlth Sci, Sch Nursing, Taipei, Taiwan.; Chu, WL (corresponding author), Natl Taipei Univ Nursing & Hlth Sci, Cheng Hsin Gen Hosp, Sch Nursing, Dept Orthoped, 45, Cheng Hsin St, Taipei 112, Taiwan.
EM healthai95@gmail.com
CR Amoretti N, 2018, EUR J RADIOL, V104, P38, DOI 10.1016/j.ejrad.2018.04.010
   Balkarli H, 2015, INT J CLIN EXP MED, V8, P16287
   Ballane G, 2017, OSTEOPOROSIS INT, V28, P1531, DOI 10.1007/s00198-017-3909-3
   Bandeira PM, 2021, SCAND J PAIN, V21, P426, DOI 10.1515/sjpain-2021-0006
   Buchbinder R, 2018, COCHRANE DB SYST REV, DOI [10.1002/14651858.CD006349.pub3, 10.1002/14651858.CD006349.pub4]
   Byun Ji-Hye, 2017, J Bone Metab, V24, P37
   Chen YC, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000014317
   Ching WY, 2014, J Hosp Bimon, V47, P25
   Chu W, 2013, INJURY, V44, P813, DOI 10.1016/j.injury.2012.10.017
   Dwivedi RK, 2021, INT J CLOUD APPL COM, V11, P52, DOI 10.4018/IJCAC.2021010103
   Feng L, 2018, BMC MUSCULOSKEL DIS, V19, DOI 10.1186/s12891-018-2123-6
   Fillingim RB, 2017, PAIN, V158, pS11, DOI 10.1097/j.pain.0000000000000775
   Fisher C, 2016, J NEUROSURG-SPINE, V25, P535, DOI 10.3171/2016.1.SPINE151261
   Gambacciani M, 2014, PANMINERVA MED, V56, P115
   Gao WX, 2023, ORTHOP SURG, V15, P961, DOI 10.1111/os.13655
   Garg Bhavuk, 2017, J Clin Orthop Trauma, V8, P131, DOI 10.1016/j.jcot.2017.02.001
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Ger LP, 1999, J PAIN SYMPTOM MANAG, V18, P316, DOI 10.1016/S0885-3924(99)00087-1
   Gibbs JC, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008618.pub3
   Halilaj E, 2018, J BIOMECH, V81, P1, DOI 10.1016/j.jbiomech.2018.09.009
   Huang ZF, 2019, PAIN PHYSICIAN, V22, P63
   Jafari J, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-013282
   Jun M, 2020, RES SQUARE, DOI [10.21203/rs.3.rs-17452/v1, DOI 10.21203/RS.3.RS-17452/V1]
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Kaushik Shweta, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.297107
   Kong M, 2019, CLIN INTERV AGING, V14, P1693, DOI 10.2147/CIA.S224663
   Lin SJ, 2022, J ORTHOP SURG RES, V17, DOI 10.1186/s13018-022-03087-4
   Liu HY, 2017, Clin Med, V80, P507
   Lu J.F., 2002, TAIWAN J PUBLIC HLTH, V22, P501
   Ma YY, 2020, BONE, V131, DOI 10.1016/j.bone.2019.115154
   McCarthy J, 2016, AM FAM PHYSICIAN, V94, P44
   Partridge JSL, 2012, AGE AGEING, V41, P142, DOI 10.1093/ageing/afr182
   Phinyomark A, 2018, J MED BIOL ENG, V38, P244, DOI 10.1007/s40846-017-0297-2
   Rizzo M, 2022, ORTHOP REV, V14, DOI 10.52965/001c.38562
   Stanghelle B, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1268-y
   Traeger A, 2017, CAN MED ASSOC J, V189, pE1386, DOI 10.1503/cmaj.170527
   Vambheim SM, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07837
   Wang BJ., 2016, J GERONTECHNOL SERVI, V4, P483
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang JN, 2019, ARCH OSTEOPOROS, V14, DOI 10.1007/s11657-019-0563-8
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33295
EP 33311
DI 10.1007/s11042-023-16801-z
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500008
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, YY
   Chen, C
   Lin, HW
   Li, Z
AF Liu, Yuan-yuan
   Chen, Chong
   Lin, Hong-wei
   Li, Zhu
TI A new camera model identification method based on color correction
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color correction matrix; Deep learning; PRNU; Image compression;
   Ensemble classifier
AB This paper focuses on source camera model identification technology in the field of digital image forensics. The research goal is to identify the source camera model, and researchers generally use the algorithm design of convolutional neural networks combined with noise residuals. However, traditional features such as noise residuals are easily polluted by noise and compression, which substantially affects the classification accuracy of source camera model identification algorithms for traditional features. Based on existing source camera model identification methods, this paper proposes the use of color correction features as the basic features of source camera model identification for the first time and proposes a new algorithm for source camera model identification based on image color correction features. A convolutional neural network is utilized to extract image color correction features and identify and classify source camera models. This paper has carried out experimental verification on a large-scale dataset, and the source camera model recognition accuracy of the proposed method in this paper can reach 97.23%; the recognition accuracy under compression conditions has reached 91.28%. The experimental results show that the image color correction feature is better than the source camera model in terms of recognition and has great research and application potential in the field of recognition. Additionally, the proposed algorithm is highly robust even after image compression and pollution, outperforming other methods under both original image conditions and compressed image conditions.
C1 [Liu, Yuan-yuan; Chen, Chong; Lin, Hong-wei; Li, Zhu] Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
C3 Hangzhou Dianzi University
RP Li, Z (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
EM lz1126@hdu.edu.cn
RI liu, yuanyuan/HSG-8372-2023; liu, yuanyuan/GWZ-5838-2022
OI Li, Zhu/0000-0001-6373-5846
CR Bayar B., 2017, ELECT IMAGING, DOI DOI 10.2352/ISSN.2470-1173.2017.7.MWSF-328
   Bernacki J, 2020, FORENS SCI INT-DIGIT, V34, DOI 10.1016/j.fsidi.2020.300983
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Cai TT, 2019, IEEE SYS MAN CYBERN, P3518, DOI 10.1109/SMC.2019.8914375
   Chen C, 2021, MULTIMED TOOLS APPL, V80, P11365, DOI 10.1007/s11042-020-09011-4
   Deng ZH, 2011, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2011.6126225
   Galdi C, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P648, DOI 10.5220/0007403706480655
   Gupta B, 2018, DIGIT INVEST, V24, P121, DOI 10.1016/j.diin.2018.02.003
   Hadwiger Benjamin, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P500, DOI 10.1007/978-3-030-68780-9_40
   Han ZH, 2020, IEEE ACCESS, V8, P25914, DOI 10.1109/ACCESS.2020.2971423
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Lee SH, 2008, IEEE T CONSUM ELECTR, V54, P268, DOI 10.1109/TCE.2008.4560085
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lorch B, 2021, IEEE SIGNAL PROC LET, V28, P912, DOI 10.1109/LSP.2021.3070206
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mantiuk R, 2009, COMPUT GRAPH FORUM, V28, P193, DOI 10.1111/j.1467-8659.2009.01358.x
   Rafi AM, 2021, NEURAL COMPUT APPL, V33, P3655, DOI 10.1007/s00521-020-05220-y
   Rao Q, 2017, IEEE SIGNAL PROC LET, V24, P809, DOI 10.1109/LSP.2017.2681426
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Roy A, 2017, IEEE COMPUT SOC CONF, P1848, DOI 10.1109/CVPRW.2017.231
   Sameer VU, 2020, MULTIMED TOOLS APPL, V79, P28079, DOI 10.1007/s11042-020-09106-y
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Tomioka Y, 2013, IEEE T INF FOREN SEC, V8, P1986, DOI 10.1109/TIFS.2013.2284761
   Tuama A, 2016, IEEE INT WORKS INFOR
   Uchida M, 2020, INT CONF AWARE SCI, DOI 10.1109/ICAST51195.2020.9319471
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   Wang B, 2021, MULTIMED TOOLS APPL, V80, P29719, DOI 10.1007/s11042-021-11201-7
   Wang B, 2020, FORENSIC SCI INT, V307, DOI 10.1016/j.forsciint.2019.110109
   Wang B, 2019, MULTIMED TOOLS APPL, V78, P8397, DOI 10.1007/s11042-018-6835-2
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
NR 31
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29179
EP 29195
DI 10.1007/s11042-023-16693-z
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063370800005
DA 2024-07-18
ER

PT J
AU Uikey, A
   Bedi, AK
   Choudhary, P
   Ooi, WT
   Saini, M
AF Uikey, Akash
   Bedi, Anterpreet Kaur
   Choudhary, Priyankar
   Ooi, Wei Tsang
   Saini, Mukesh
TI A highly robust deep learning technique for overlap detection using
   audio fingerprinting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio matching; Fingerprinting; Deep learning; Overlap detection;
   Synchronisation
ID CHAOS; ALGORITHM; MAP; NETWORK; INTERNET; SYSTEM; MODEL
AB Due to the proliferation of video-based applications, there is a high demand for automated systems to support various video-based tasks that are free from human intervention, i.e., manual tagging. In this paper, we present a novel approach for detecting the presence of overlap between two videos by exploiting their corresponding audio signals, which is a crucial preprocessing step for audio, and further video alignment and synchronisation. Several existing approaches have limitations related to timestamps, overlapping regions, and the length of video clips. For the proposed work, we target the challenging scenario consisting of simultaneously recorded videos in an unconstrained manner by multiple users attending performance events. xOur work is an attempt towards developing a robust framework that not only considers noisy components present in the audio but is also free from the limitations mentioned above. We compare our framework with several other existing approaches. Our proposed framework outperforms other approaches by an average of 13.71% in terms of accuracy.
C1 [Uikey, Akash; Choudhary, Priyankar; Saini, Mukesh] Indian Inst Technol, Dept Comp Sci & Engn, Roopnagar 140001, Punjab, India.
   [Bedi, Anterpreet Kaur] Thapar Inst Engn & Technol, Elect & Instrumentat Engn Dept, Patiala 147004, Punjab, India.
   [Ooi, Wei Tsang] Natl Univ Singapore, Dept Comp Sci, Singapore 119077, Singapore.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Ropar; Thapar Institute of Engineering & Technology;
   National University of Singapore
RP Bedi, AK (corresponding author), Thapar Inst Engn & Technol, Elect & Instrumentat Engn Dept, Patiala 147004, Punjab, India.
EM 2020aim1004@iitrpr.ac.in; anterpreet.bedi@thapar.edu;
   2017csz0011@iitrpr.ac.in; ooiwt@comp.nus.edu.sg; mukesh@iitrpr.ac.in
RI Yeraliyeva, Bakhyt/ABJ-7322-2022; Saini, Mukesh/J-5139-2016; Choudhary,
   Priyankar/GPP-6965-2022
OI Yeraliyeva, Bakhyt/0000-0002-8680-7694; Bedi, Anterpreet
   Kaur/0000-0001-6064-5925
CR Bullock L, 2020, INT CONF ACOUST SPEE, P7114, DOI [10.1109/ICASSP40776.2020.9053096, 10.1109/icassp40776.2020.9053096]
   Burloiu G, 2014, 2014 11 INT S EL TEL, P1
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Covell M, 2007, INT CONF ACOUST SPEE, P237
   Dannenberg RB, 2006, COMMUN ACM, V49, P38, DOI 10.1145/1145287.1145311
   Diego F, 2011, IEEE T IMAGE PROCESS, V20, P1858, DOI 10.1109/TIP.2010.2095873
   Duan ZY, 2011, INT CONF ACOUST SPEE, P197
   Ewert S, 2009, INT CONF ACOUST SPEE, P1869, DOI 10.1109/ICASSP.2009.4959972
   Gasser MGM, 2013, Automatic alignment of music performances with structural differences
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Joder C, 2013, IEEE T AUDIO SPEECH, V21, P2118, DOI 10.1109/TASL.2013.2266794
   Joder C, 2011, IEEE T AUDIO SPEECH, V19, P2385, DOI 10.1109/TASL.2011.2134092
   Ke Y, 2005, PROC CVPR IEEE, P597
   Montecchio N, 2011, INT CONF ACOUST SPEE, P193
   Muller M., 2021, Journal of Open Source Software, V6, P3434, DOI DOI 10.21105/JOSS.03434
   Muller M., 2006, P 6 INT C MUSIC INFO, P192
   Prätzlich T, 2016, INT CONF ACOUST SPEE, P569, DOI 10.1109/ICASSP.2016.7471739
   Saini M, 2013, P 4 ACM MULT SYST C, P108
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Six J, 2014, 15 INT SOC MUS INF R
   Tralie C, 2020, Arxiv, DOI arXiv:2008.02734
   Trigeorgis G, 2018, IEEE T PATTERN ANAL, V40, P1128, DOI 10.1109/TPAMI.2017.2710047
   Wang A.L., 2003, P ISMIR 2003 4 INT C, P7
   Wang SY, 2016, IEEE-ACM T AUDIO SPE, V24, P2132, DOI 10.1109/TASLP.2016.2598318
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29119
EP 29137
DI 10.1007/s11042-023-16713-y
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063374600003
DA 2024-07-18
ER

PT J
AU Lin, H
   Zhao, GH
   Song, SY
   Wu, W
   Jiang, W
AF Lin, Hao
   Zhao, Gaohua
   Song, Shouyou
   Wu, Wei
   Jiang, Wei
TI A new lightweight public key encryption with equality test for cloud
   storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Public key encryption; Cloud storage; Equality test; Ciphertext size;
   Data sharing
ID IDENTITY-BASED ENCRYPTION; EFFICIENT; SCHEME; AUTHORIZATION; CIPHERTEXTS
AB Public key encryption with equality test (PKEET) can test if two ciphertexts generated from different public keys contain the same message without decryption. In the application of cloud storage, PKEET could be used to search on encrypted data. Currently, there have been many researches about security, efficiency, and function of PKEET. After analyzing the ciphertext sizes in the existing proposals, we find that the ciphertext sizes in PKEET schemes are usually large. In this case, it will bring storage burden for the cloud server. To address the problem, in this paper, we introduce a new notion of lightweight public key encryption with equality test (L-PKEET). Then we present a concrete construction of L-PKEET. Furthermore, we demonstrate that L-PKEET can reduce ciphertext sizes efficiently. In terms of the computation cost and ciphertext size, we compare L-PKEET with related schemes which also achieve four kinds of authorization. The comparison results show that L-PKEET is more efficient in terms of encryption, decryption, and test algorithms. Regarding the adversaries with/without trapdoor, we theoretically prove that L-PKEET can meet OW-CCA security and IND-CCA security, respectively.
C1 [Lin, Hao; Zhao, Gaohua; Song, Shouyou; Wu, Wei; Jiang, Wei] Chinese Acad Cyberspace Studies, Beijing 100010, Peoples R China.
RP Zhao, GH; Jiang, W (corresponding author), Chinese Acad Cyberspace Studies, Beijing 100010, Peoples R China.
EM zhaogaohua@cac.gov.cn; jw@bjut.edu.cn
FU National Key R&D Program of China [2021YFB3101300, 2021YFB3101302,
   2021YFB3101305]; Major Programs of the National Social Science
   Foundation of China [22ZD147]
FX This work is supported by National Key R&D Program of China (Grant Nos.
   2021YFB3101300, 2021YFB3101302, 2021YFB3101305), and Major Programs of
   the National Social Science Foundation of China(Grant No. 22&ZD147).
CR Abdalla M, 2008, J CRYPTOL, V21, P350, DOI 10.1007/s00145-007-9006-6
   Akinyele JA, 2013, J CRYPTOGR ENG, V3, P111, DOI 10.1007/s13389-013-0057-3
   Al-Zubaidie M, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15010152
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Murillo-Escobar MA, 2023, MULTIMED TOOLS APPL, V82, P23373, DOI 10.1007/s11042-022-14092-4
   [Anonymous], INT J APPL CRYPTOGRA
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Caruccio L, 2020, IEEE ACCESS, V8, P205034, DOI 10.1109/ACCESS.2020.3036916
   Cui YZ, 2019, COMPUT J, V62, P1166, DOI 10.1093/comjnl/bxz036
   Deng XT, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4605685
   Desiato D., 2018, P 26 IT S ADV DAT SY
   Duong DH, 2022, THEOR COMPUT SCI, V905, P31, DOI 10.1016/j.tcs.2021.12.013
   Duong DH, 2019, LECT NOTES COMPUT SC, V11821, P19, DOI 10.1007/978-3-030-31919-9_2
   Duong DH, 2019, LECT NOTES COMPUT SC, V11547, P138, DOI 10.1007/978-3-030-21548-4_8
   Huang KB, 2014, LECT NOTES COMPUT SC, V8792, P550, DOI 10.1007/978-3-319-11698-3_45
   Lee HT, 2020, INFORM SCIENCES, V516, P89, DOI 10.1016/j.ins.2019.12.023
   Lee HT, 2016, COMPUT J, V59, P1689, DOI 10.1093/comjnl/bxw033
   Li HB, 2019, IEEE ACCESS, V7, P25409, DOI 10.1109/ACCESS.2019.2899680
   Li WC, 2022, IEEE T INTELL TRANSP, V23, P20187, DOI 10.1109/TITS.2022.3174716
   Lin H, 2022, IEEE SYST J, V16, P1460, DOI 10.1109/JSYST.2021.3106701
   Lin H, 2021, COMPUT J, V64, P1226, DOI 10.1093/comjnl/bxaa144
   Lin XJ, 2021, COMPUT COMMUN, V170, P190, DOI 10.1016/j.comcom.2021.02.006
   Ling YH, 2020, INFORM SCIENCES, V510, P16, DOI 10.1016/j.ins.2019.09.025
   Ling YH, 2019, LECT NOTES COMPUT SC, V11547, P39, DOI 10.1007/978-3-030-21548-4_3
   Ma S, 2016, INFORM SCIENCES, V328, P389, DOI 10.1016/j.ins.2015.08.053
   Ma S, 2015, COMPUT J, V58, P986, DOI 10.1093/comjnl/bxu026
   Ma S, 2015, IEEE T INF FOREN SEC, V10, P458, DOI 10.1109/TIFS.2014.2378592
   Qu HP, 2018, INFORM SCIENCES, V462, P76, DOI 10.1016/j.ins.2018.06.025
   Roy PS, 2022, THEOR COMPUT SCI, V929, P124, DOI 10.1016/j.tcs.2022.06.034
   Shen J, 2020, IEEE T SUST COMPUT, V5, P161, DOI 10.1109/TSUSC.2017.2781232
   Shen J, 2019, IEEE T DEPEND SECURE, V16, P996, DOI 10.1109/TDSC.2017.2725953
   Shen XY, 2022, INFORM SCIENCES, V605, P202, DOI 10.1016/j.ins.2022.05.001
   Shen XY, 2020, IEEE ACCESS, V8, P75463, DOI 10.1109/ACCESS.2020.2988732
   Shor PW, 1997, SIAM J COMPUT, V26, P1484, DOI 10.1137/S0036144598347011
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Susilo Willy, 2022, IEEE Transactions on Cloud Computing, V10, P1476, DOI 10.1109/TCC.2020.2990201
   Tang Q, 2012, SECUR COMMUN NETW, V5, P1351, DOI 10.1002/sec.418
   Tang Q, 2011, LECT NOTES COMPUT SC, V6812, P389, DOI 10.1007/978-3-642-22497-3_25
   Wang Q, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775741
   Wang YH, 2020, IEEE ACCESS, V8, P32891, DOI 10.1109/ACCESS.2020.2973459
   Wang YJ, 2020, INFORM SCIENCES, V522, P80, DOI 10.1016/j.ins.2020.02.064
   Wang YJ, 2019, INFORM SCIENCES, V490, P146, DOI 10.1016/j.ins.2019.03.039
   Wang YJ, 2017, INFORM SCIENCES, V414, P289, DOI 10.1016/j.ins.2017.06.008
   Wu LB, 2018, IEEE T SUST COMPUT, V3, P44, DOI 10.1109/TSUSC.2017.2734110
   Wu LB, 2017, FUTURE GENER COMP SY, V73, P22, DOI 10.1016/j.future.2017.03.007
   Wu T, 2017, LECT NOTES COMPUT SC, V10342, P168, DOI 10.1007/978-3-319-60055-0_9
   Yang GM, 2010, LECT NOTES COMPUT SC, V5985, P119, DOI 10.1007/978-3-642-11925-5_9
   Yu Y, 2020, IEEE J SEL AREA COMM, V38, P1242, DOI 10.1109/JSAC.2020.2986620
   Yu Y, 2020, IEEE T EMERG TOP COM, V8, P377, DOI 10.1109/TETC.2017.2759329
   Zhao M, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/4462134
   Zhao Z, 2022, IEEE INTERNET THINGS, V9, P22595, DOI 10.1109/JIOT.2022.3181582
   Zhou ZJ., 2022, INT J NETW SECUR, V24, P841
   Zhu HJ, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717715605
NR 54
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28947
EP 28968
DI 10.1007/s11042-023-16540-1
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001062311100004
DA 2024-07-18
ER

PT J
AU Phatnani, KS
   Patil, HA
AF Phatnani, Kirtana Sunil
   Patil, Hemant A.
TI Modeling musical expectancy via reinforcement learning and directed
   graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reinforcement learning; Music structure; Pitch; Note directed graphs;
   Music cognition
AB Algorithms strive to capture the intricacies of our complex world, but translating qualitative aspects into quantifiable data poses a significant challenge. In our paper, we embark on a journey to unveil the hidden structure of music by exploring the interplay between our predictions and the sequence of musical events. Our ultimate goal is to gain insights into how certainty fluctuates throughout a musical piece using a three-fold approach: a listening test, reinforcement learning (RL), and graph construction. Through this approach, we seek to understand how musical expectancy affects physiological measurements, visualize the graphical structure of a composition, and analyze the accuracy of prediction accuracy across 15 musical pieces. We conducted a listening test using western classical music on 50 subjects, monitoring changes in blood pressure, heart rate, and oxygen saturation in response to different segments of the music. We also assessed the accuracy of the RL agent in predicting notes and pitches individually and simultaneously. Our findings reveal that the average accuracy of the RL agent in note and pitch prediction is 64.17% and 22.48%, respectively, while the accuracy for simultaneous prediction is 73.84%. These results give us a glimpse into the minimum level of certainty present across any composition. To further analyze the accuracy of the RL agent, we propose novel directed graphs in our paper. Our analysis shows that the variance of the edge distributions in the graph is inversely proportional to the accuracy of the RL agent. Through this comprehensive study, we hope to shed light on the enigmatic nature of music and pave the way for future research in this fascinating field.
C1 [Phatnani, Kirtana Sunil] Fractal Analyt, Fractal Cerebral, Level 7,Commerz 2I nt Business Pk,Western Express, Mumbai 400063, Maharashtra, India.
   [Patil, Hemant A.] Dhirubhai Ambani Inst Informat & Commun Technol, Speech Res Lab, Reliance Cross Rd, Gandhinagar 382007, Gujarat, India.
C3 Dhirubhai Ambani Institute of Information & Communication Technology
RP Phatnani, KS (corresponding author), Fractal Analyt, Fractal Cerebral, Level 7,Commerz 2I nt Business Pk,Western Express, Mumbai 400063, Maharashtra, India.; Patil, HA (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Speech Res Lab, Reliance Cross Rd, Gandhinagar 382007, Gujarat, India.
EM kirtana.phatnani@fractal.ai; hemant_patil@daiict.ac.in
CR Aldridge D., 1994, COMPLEMENT THER MED, V2, P204, DOI [DOI 10.1016/0965-2299(94)90021-3, 10.1016/0965-2299(94)90021-3]
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   [Anonymous], 1990, The Analysis and Cognition of Basic Melodic Structures: the Implication-realization Model
   [Anonymous], 2011, Handbook of music and emotion: Theory, research, applications
   Barabási AL, 2003, SCI AM, V288, P60, DOI 10.1038/scientificamerican0503-60
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   BHARUCHA JJ, 1986, J EXP PSYCHOL HUMAN, V12, P403, DOI 10.1037/0096-1523.12.4.403
   Bigand E, 1999, J EXP PSYCHOL HUMAN, V25, P184, DOI 10.1037/0096-1523.25.1.184
   Bunt L.Stige., 2014, Music therapy: An art beyond words, V2nd
   BuongiornoNardelli M, 2019, arXiv
   Caldarelli G., 2012, NETWORKS VERY SHORT, DOI [10.1093/actrade/9780199588077.001.0001, DOI 10.1093/ACTRADE/9780199588077.001.0001]
   CASTELLANO MA, 1984, J EXP PSYCHOL GEN, V113, P394, DOI 10.1037/0096-3445.113.3.394
   Dabney W, 2020, NATURE, V577, P671, DOI 10.1038/s41586-019-1924-6
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Duda RO., 2012, Pattern classificatio
   Ferreri L, 2019, P NATL ACAD SCI USA, V116, P3793, DOI 10.1073/pnas.1811878116
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Fora T, 2011, Dopamine jackpot! sapolsky on the science of pleasure
   Freytag G., 1908, Freytag's technique of the drama: an exposition of dramatic composition and art
   Gebauer L., 2012, PSYCHOMUSICOLOGY MUS, V22, P152, DOI DOI 10.1037/A0031126
   Gold C, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004381.pub2
   Gormezano I., 1966, Classical conditioning. Exp Methods Instrument Psychol, V1, P385
   Grossman E, 2001, J HUM HYPERTENS, V15, P263, DOI 10.1038/sj.jhh.1001147
   Hall J. E., 2016, GUYTON HALL TXB MED
   Huron D., 2008, Sweet anticipation: Music and the psychology of expectation
   Jones MR, 2002, PSYCHOL SCI, V13, P313, DOI 10.1111/1467-9280.00458
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   KRUMHANSL CL, 1983, MUSIC PERCEPT, V1, P28
   Krumhansl CL, 2000, PSYCHOL BULL, V126, P159, DOI 10.1037/0033-2909.126.1.159
   Lauridsen MM, 2013, METAB BRAIN DIS, V28, P231, DOI 10.1007/s11011-012-9373-z
   Lin SH, 2008, INT CONF BIOMED, P344, DOI 10.1109/BMEI.2008.305
   Loomba Rohit S, 2012, Indian Heart J, V64, P309, DOI 10.1016/S0019-4832(12)60094-7
   McPherson T, 2019, J MUSIC THER, V56, P240, DOI 10.1093/jmt/thz007
   Meyer L.B., 1956, Emotion and meaning in music
   Milne AJ, 2017, J MATH MUSIC, V11, P101, DOI 10.1080/17459737.2017.1395915
   Mitterschiffthaler MT, 2007, HUM BRAIN MAPP, V28, P1150, DOI 10.1002/hbm.20337
   Mott FW, 1919, BRIT MED J, V1919, P424
   Newman M. E. J., 2018, Networks: An Introduction, DOI [DOI 10.1093/ACPROF:OSO/9780199206650.001.0001, 10.1093/acprof:oso/9780199206650.001.0001]
   Phatnani KS, 2022, MULTIMED TOOLS APPL, V81, P22247, DOI 10.1007/s11042-021-11430-w
   Phatnani KS, 2020, ASIAPAC SIGN INFO PR, P353
   Rudovic O, 2017, FRONT ROBOT AI, V4, P1, DOI 10.3389/frobt.2017.00036
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Schellenberg EG, 1996, COGNITION, V58, P75, DOI 10.1016/0010-0277(95)00665-6
   Schultz W, 1999, NEWS PHYSIOL SCI, V14, P249
   SERAFINE ML, 1984, MUSIC QUART, V70, P218
   Situmorang DDB, 2020, ADDICT DISORD TREAT, V19, P252, DOI 10.1097/ADT.0000000000000224
   Staddon JER, 2003, ANNU REV PSYCHOL, V54, P115, DOI 10.1146/annurev.psych.54.101601.145124
   Strang G., 1982, Linear algebra and its applications
   Sun LJ, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.578112
   Sutoo D, 2004, BRAIN RES, V1016, P255, DOI 10.1016/j.brainres.2004.05.018
   Sutton RS, 1998, Introduction to reinforcement learning, V135
   Szalavitz M., 2016, UNBROKEN BRAIN REVOL
   THOMPSON RF, 1966, PSYCHOL REV, V73, P16, DOI 10.1037/h0022681
   World M, 2020, midiworld.com
   Yokoyama K, 2002, IEEE T BIO-MED ENG, V49, P729, DOI 10.1109/TBME.2002.1010857
   Yust J, 2020, J MATH MUSIC, V14, P170, DOI 10.1080/17459737.2020.1725667
NR 58
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28523
EP 28547
DI 10.1007/s11042-023-16497-1
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000002
DA 2024-07-18
ER

PT J
AU Li, M
   Liu, DM
   Liu, CS
   Chang, FL
   Wang, WQ
   Wang, B
AF Li, Min
   Liu, Dongmei
   Liu, Chunsheng
   Chang, Faliang
   Wang, Wenqian
   Wang, Bin
TI ACF-net: appearance-guided content filter network for video captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video captioning; Content filter; Linguistic information; Temporal
   semantic aggregation
AB Video captioning refers to the automatic generation of natural language sentences for a given video. There are two open problems for this task: how to effectively combine the multimodal features to better represent video content, and how to effectively extract useful features from complex visual and linguistic information to generate more detailed descriptions. Considering these two difficulties together, we propose a video captioning method named ACF-Net: Appearance-guided Content Filter Network, utilizing appearance information as a Content Filter to guide the network to aware discrimination information from both motion information and object information. Specifically, we propose a new multimodal fusion method to alleviate the problem of insufficient video information fusion. Distinguished with previous feature fusion methods that directly concatenate features, our fusion mechanism fuses relevant content information through content filters to form unified multimodal features. Moreover, a hierarchical decoder with temporal semantic aggregation is proposed, which can dynamically aggregate visual and linguistic features while generating corresponding words, focusing on the most relevant temporal and semantic information. Extensive experiments are conducted on two benchmark datasets, including MSVD and MSR-VTT, which demonstrate the effectiveness of our proposed method.
C1 [Li, Min; Liu, Chunsheng; Chang, Faliang; Wang, Wenqian; Wang, Bin] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Li, Min] Chinese Acad Sci, Aerosp Informat Res Inst Qilu, Aerosp Informat Res Inst, Shandong Key Lab Low Altitude Airspace Surveillanc, Jinan 250100, Peoples R China.
   [Liu, Dongmei] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
C3 Shandong University; Chinese Academy of Sciences; Aerospace Information
   Research Institute, CAS; Shandong Normal University
RP Liu, CS; Chang, FL (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM 202014774@mail.sdu.edu.cn; dmliu531@126.com; liuchunsheng@sdu.edu.cn;
   flchang@sdu.edu.cn; wqwang@mail.sdu.edu.cn; cvwangb@mail.sdu.edu.cn
FU National Natural Science Foundation of China [U22A2058, 62176138,
   62176136]; National Key Ramp;D Program of China [2018YFB1305300];
   Shandong Provincial Key Research and Development Program (Major
   Scientific and Technological Innovation Project) [2020CXGC010207,
   2019JZZY010130]
FX This work was supported by the National Natural Science Foundation of
   China (NO.U22A2058, 62176138, 62176136), National Key R&D Program of
   China (NO.2018YFB1305300), Shandong Provincial Key Research and
   Development Program (Major Scientific and Technological Innovation
   Project)(NO.2020CXGC010207, 2019JZZY010130).
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2023, IEEE T MULTIMEDIA
   Bai Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3556, DOI 10.1145/3474085.3475519
   Barbu A, 2012, ARXIV
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen, 2015, ARXIV
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen HR, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.475767
   Chen SX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1523, DOI 10.1109/ICCV48922.2021.00157
   Chen SX, 2019, AAAI CONF ARTIF INTE, P8191
   Deng JC, 2022, IEEE T CIRC SYST VID, V32, P880, DOI 10.1109/TCSVT.2021.3063423
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Foo, 2022, ARXIV
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gu X, 2023, PROC CVPR IEEE, P18941, DOI 10.1109/CVPR52729.2023.01816
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Hu W., 2023, MICROBIAL BIOPROCESS, P1
   Jin T, 2019, ARXIV
   Lee JY, 2019, MULTIMED TOOLS APPL, V78, p31,793
   Li L, 2022, IEEE T IMAGE PROCESS, V31, P2726, DOI 10.1109/TIP.2022.3158546
   Li T, EUR C COMP VIS, P386
   Li T, P IEEE CVF C COMP VI, p16,266
   Li T., 2021, P IEEE CVF INT C COM
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Lu JS, 2016, ADV NEUR IN, V29
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Perez-Martin J, 2021, IEEE WINT CONF APPL, P3038, DOI 10.1109/WACV48630.2021.00308
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao Z, 2023, TEXTUAL CONTEXT AWAR, P1, DOI DOI 10.1109/TMM.2023.3241517
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Singh A, 2022, MULTIMED TOOLS APPL, V81, p17,989
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan G, 2020, ARXIV
   Thomason J., 2014, COLING, P1218
   Tianjiao Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P420, DOI 10.1007/978-3-030-58621-8_25
   Tran K, 2016, IEEE COMPUT SOC CONF, P434, DOI 10.1109/CVPRW.2016.61
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2014, ARXIV
   Venugopalan S, 2016, ARXIV
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2019, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2019.00273
   Wang B, 2023, INT J PROD RES, V61, P4934, DOI [10.1080/00207543.2022.2025944, 10.1109/IECON49645.2022.9968912]
   Wang SW, 2020, MULTIMED TOOLS APPL, V79, P2013, DOI 10.1007/s11042-019-08209-5
   Wang W., 2023, IEEE Transactions on Image Processing
   Wang WQ, 2023, IEEE T MULTIMEDIA, V25, P1061, DOI 10.1109/TMM.2021.3137745
   Wang WQ, 2021, NEUROCOMPUTING, V433, P37, DOI 10.1016/j.neucom.2020.12.025
   Wu B, 2023, IEEE T SYST MAN CY-S, V53, P4039, DOI 10.1109/TSMC.2023.3242308
   Wu BF, 2022, IEEE T CIRC SYST VID, V32, P6753, DOI 10.1109/TCSVT.2022.3169894
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yuan JW, 2018, IEEE C EVOL COMPUTAT, P63, DOI [10.1109/INTMAG.2018.8508389, 10.1109/CEC.2018.8477649]
   Zhang JC, 2019, PROC CVPR IEEE, P8319, DOI 10.1109/CVPR.2019.00852
   Ziqi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13275, DOI 10.1109/CVPR42600.2020.01329
NR 63
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31103
EP 31122
DI 10.1007/s11042-023-16580-7
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300003
DA 2024-07-18
ER

PT J
AU Bajpai, S
   Kidwai, NR
AF Bajpai, Shrish
   Kidwai, Naimur Rahman
TI Fractional wavelet filter based low memory coding for hyperspectral
   image sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral coding; Low memory hyperspectral image sensors; Coding
   memory; Coding gain; Set partitioned algorithm
ID COMPRESSION; ARCHITECTURE; ALGORITHMS
AB In the present study, a novel low memory coding algorithm for lossless image compression of hyperspectral images is proposed. The hyperspectral images are volumetric images that pose a challenge to the sensor memory. The contemporary transform-based compression algorithms exhibit remarkably efficient performance on the coding gain, complexity, and memory in comparison to other algorithms for lossy compression. The traditional 3D-DWT requires large memory for computation of wavelet coefficients of transform image. The fractional wavelet filter is a low memory solution to calculate the wavelet coefficients of the hyperspectral image. The 2D-ZM-SPECK is employed as a coding algorithm which is applied over HS image frame by frame basis. The simulation results indicate that the proposed compression algorithm has low memory requirements and high coding gain with less computational complexity. On observing the simulation results of the proposed compression algorithm, it is noticeable that the proposed coder is fast enough due to requiring low memory and hence proving its candidature in the implementation of a resource-constrained hyperspectral image sensor.
C1 [Bajpai, Shrish; Kidwai, Naimur Rahman] Integral Univ, Fac Engn & Informat Technol, Elect & Commun Engn Dept, Lucknow, Uttar Pradesh, India.
C3 Integral University
RP Bajpai, S (corresponding author), Integral Univ, Fac Engn & Informat Technol, Elect & Commun Engn Dept, Lucknow, Uttar Pradesh, India.
EM shrishbajpai@gmail.com
OI Bajpai, Shrish/0000-0001-5598-1940
FU Integral University, Lucknow, Uttar Pradesh, India
   [IU/R&D/2022-MCN0001387]
FX We are sincerely thankful to the anonymous reviewers for their critical
   comments and suggestions to improve the quality of the paper. The
   authors would like to gratefully acknowledge the support of the Integral
   University, Lucknow, Uttar Pradesh, India and Manuscript Communication
   Number for this manuscript is IU/R&D/2022-MCN0001387.
CR Achard V, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13051020
   Altamimi A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010263
   Bairagi V. K., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P135, DOI 10.1007/s40031-013-0049-9
   Baisantry M, 2021, J INDIAN SOC REMOTE, V49, P843, DOI 10.1007/s12524-020-01262-w
   Bajpai S., 2019, INT J INNOVATIVE TEC, V8, P64
   Bajpai S., 2019, INDONESIAN J ELECT E, V15, P1001, DOI [10.11591/ijeecs.v15.i2.pp1001-1008, DOI 10.11591/IJEECS.V15.I2.PP1001-1008]
   Bajpai S, 2023, WIRELESS PERS COMMUN, V131, P805, DOI 10.1007/s11277-023-10455-8
   Bajpai S, 2023, MULTIMED TOOLS APPL, V82, P31233, DOI 10.1007/s11042-023-14738-x
   Bajpai S, 2023, J ELECTR COMPUT ENG, V2023, DOI 10.1155/2023/8961271
   Bajpai S, 2022, MULTIMED TOOLS APPL, V81, P33205, DOI 10.1007/s11042-022-13057-x
   Bajpai S, 2022, MULTIMED TOOLS APPL, V81, P841, DOI 10.1007/s11042-021-11456-0
   Bajpai S, 2019, MULTIMED TOOLS APPL, V78, P27193, DOI 10.1007/s11042-019-07797-6
   Bajpai S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P97, DOI 10.1109/MSPCT.2017.8363982
   Bano N., 2017, Adv Wireless Mobile Commun, V10, P871
   Báscones D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060907
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, V12, P2915, DOI 10.1007/s12652-020-02449-2
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Bilgin A, 2000, APPL OPTICS, V39, P1799, DOI 10.1364/AO.39.001799
   Boettcher JB, 2007, INT GEOSCI REMOTE SE, P1033, DOI 10.1109/IGARSS.2007.4422977
   Chandra H, 2023, 2023 INT C POW INSTR, P1, DOI [10.1109/PIECON56912.2023.10085841, DOI 10.1109/PIECON56912.2023.10085841]
   Chandra H, 2022, 2022 5TH INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), DOI 10.1109/IMPACT55510.2022.10029076
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Das A, 2010, IEEE T CIRC SYST VID, V20, P286, DOI 10.1109/TCSVT.2009.2031551
   Das S, 2021, IET IMAGE PROCESS, V15, P964, DOI 10.1049/ipr2.12077
   Datta A, 2017, IEEE GEOSCI REMOTE S, V14, P82, DOI 10.1109/LGRS.2016.2628078
   Dmitriev EV, 2018, OPTOELECTRON INSTRUM, V54, P213, DOI 10.3103/S8756699018030019
   Dua Y, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116255
   Dua Y, 2021, J PARALLEL DISTR COM, V150, P60, DOI 10.1016/j.jpdc.2020.12.004
   Dua Y, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.9.090902
   Gnutti A, 2021, MULTIDIM SYST SIGN P, V32, P791, DOI 10.1007/s11045-020-00753-w
   Hou Y, 2007, PROC SPIE, V6790, DOI 10.1117/12.750975
   Hou Y, 2008, 2008 INTERNATIONAL WORKSHOP ON EARTH OBSERVATION AND REMOTE SENSING APPLICATIONS, P106
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kumar RS, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101862
   Lee S, 2005, P 2005 IEEE INT GEOS, P1, DOI [10.1109/IGARSS.2005.1526118, DOI 10.1109/IGARSS.2005.1526118]
   Licciardi GA, 2020, DATA HANDL SCI TECHN, V32, P55, DOI 10.1016/B978-0-444-63977-6.00004-3
   Mishra MK, 2019, CURR SCI INDIA, V116, P1089, DOI 10.18520/cs/v116/i7/1089-1100
   Mitran T, 2021, J INDIAN SOC REMOTE, V49, P2611, DOI 10.1007/s12524-021-01415-5
   Mohan BK, 2015, CURR SCI INDIA, V108, P833
   Mohanty BK, 2011, IEEE T SIGNAL PROCES, V59, P5605, DOI 10.1109/TSP.2011.2162510
   Nagendran R, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S021969131941008X
   Ngadiran R., 2010, IEEE INT C COMP COMM, P1, DOI [10.1109/ICCCE.2010.5556843, DOI 10.1109/ICCCE.2010.5556843]
   Oliver J, 2008, IEEE T CIRC SYST VID, V18, P237, DOI 10.1109/TCSVT.2007.913962
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Pradhan MK, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172799
   Ramakrishnan D, 2015, CURR SCI INDIA, V108, P879
   Rein S, 2011, IEEE COMMUN SURV TUT, V13, P291, DOI 10.1109/SURV.2011.100110.00059
   Sahoo RN, 2015, CURR SCI INDIA, V108, P848
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Sharma D, 2020, IETE TECH REV, V37, P36, DOI 10.1080/02564602.2018.1557569
   Sharma D, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.076102
   Sneha, 2022, MULTIMED TOOLS APPL, V81, P44141, DOI 10.1007/s11042-022-13235-x
   Sneha, 2022, ADV INTELL SYST COMP, V1420, P69, DOI 10.1007/978-981-16-9573-5_5
   Song MY, 2022, LECT NOTES COMPUT SC, V13679, P481, DOI 10.1007/978-3-031-19800-7_28
   Srinivasarao BKN, 2016, 2016 INTERNATIONAL SYMPOSIUM ON VLSI DESIGN, AUTOMATION AND TEST (VLSI-DAT)
   Sudha VK, 2013, J SCI IND RES INDIA, V72, P735
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Tang XL, 2004, IEEE IMAGE PROC, P3283
   Tausif M, 2023, MULTIDIM SYST SIGN P, V34, P657, DOI 10.1007/s11045-023-00878-8
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Valsesia D, 2017, IEEE GEOSCI REMOTE S, V14, P394, DOI 10.1109/LGRS.2016.2644726
   Verma B, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106581
   Wang L, 2010, ELECTRON LETT, V46, P1601, DOI 10.1049/el.2010.1788
   Weeks M., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P57, DOI 10.1109/ISCAS.1998.698757
   Yang CH, 2007, IEICE T FUND ELECTR, VE90A, P1062, DOI 10.1093/ietfec/e90-a.5.1062
   Yoon J, 2022, BIOCHIP J, V16, P1, DOI 10.1007/s13206-021-00041-0
   Zabalza J, 2023, IEEE SENS J, V23, P452, DOI 10.1109/JSEN.2022.3221680
   Zabalza J, 2018, J FRANKLIN I, V355, P1733, DOI 10.1016/j.jfranklin.2017.05.020
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2012, IEEE IMAGE PROC, P1057, DOI 10.1109/ICIP.2012.6467045
   Zikiou N, 2020, VISUAL COMPUT, V36, P1473, DOI 10.1007/s00371-019-01753-z
NR 72
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26281
EP 26306
DI 10.1007/s11042-023-16528-x
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700005
DA 2024-07-18
ER

PT J
AU Hu, YJ
   Zhang, QY
   Zhang, QW
   Ba, YJ
AF Hu, Yingjie
   Zhang, Qiuyu
   Zhang, Qiwen
   Ba, Yujiao
TI An intelligent homomorphic audio signal encryption algorithm for secure
   interacting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio encryption; Homomorphic encryption; Decimal integers; Adaptive
   encryption; Ciphertext calculation
ID IMPLEMENTATION
AB The present encryption algorithm has high computational complexity for the large data volume as audio and usually focuses on one audio format. Furthermore, the data in the cloud cannot be modified before decrypting, which means the interaction between the encrypted audio and the users is difficult. To address the above problems, a new homomorphic audio signal encryption algorithm has been developed for secure processing and interaction in the cloud. The original audio signal is encrypted without converting to binary to reduce the computational complexity. Adaptive parameters were generated to deal with varied audio formats and attributes. The users can choose the appropriate encryption level to balance the security and complexity. Meanwhile, this scheme supports additive and multiplicative homomorphism to perform some operations (e.g., volume adjustment and audio editing) correctly with the encrypted data. Security analysis and experiments show that the proposed algorithm has better encryption performance, stronger sensitivity to key, higher efficiency, less data expansion, and could be against attacks from statistical analysis. Overall, the proposed algorithm is secure and efficient to satisfy requirements for interaction with encrypted audio files in the cloud.
C1 [Hu, Yingjie; Zhang, Qiuyu; Zhang, Qiwen; Ba, Yujiao] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou, Gansu, Peoples R China.
EM zhangqylz@163.com
FU National Natural Science Foundation of China [61862041]
FX AcknowledgmentsThis work is supported by the National Natural Science
   Foundation of China (No. 61862041).
CR Alaya B, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100235
   Chindris MC, 2020, INT C INF TECHN COMM, P198, DOI [10.1007/978-3-030-69255-1_13, DOI 10.1007/978-3-030-69255-1_13]
   Elsafty AH, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153347
   Farsana FJ, 2020, ADV MATH PHYS, V2020, DOI 10.1155/2020/8050934
   Farsana FJ, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P2197, DOI 10.1109/ICCSP.2017.8286804
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P31517, DOI 10.1007/s11042-018-6426-2
   Hashemi S, 2021, INT J SPEECH TECHNOL, V24, P651, DOI 10.1007/s10772-021-09821-3
   Imran OA, 2020, PROCEDIA COMPUT SCI, V167, P1028, DOI 10.1016/j.procs.2020.03.402
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   Kalpana M, 2019, MULTIMED TOOLS APPL, V78, P5969, DOI 10.1007/s11042-018-6373-y
   Kaur G, 2021, MULTIMED TOOLS APPL, V80, P10927, DOI 10.1007/s11042-020-10223-x
   Khoirom MS, 2021, WIRELESS PERS COMMUN, V117, P809, DOI 10.1007/s11277-020-07897-9
   Mishra A, 2023, HOMOMORPHIC ENCRYPTI
   Sathiyamurthi P, 2022, MULTIMED TOOLS APPL, V81, P6331, DOI 10.1007/s11042-021-11757-4
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Sayed, 2018, 2018 7 INT C MOD CIR, P1, DOI [10.1109/MOCAST.2018.8376621, DOI 10.1109/MOCAST.2018.8376621]
   Sayed WS, 2018, INT C MICROELECTRON, P92, DOI 10.1109/ICM.2018.8704022
   Shi CH, 2019, KSII T INTERNET INF, V13, P2588, DOI 10.3837/tiis.2019.05.020
   Slimani D, 2018, PROCEDIA COMPUT SCI, V128, P79, DOI 10.1016/j.procs.2018.03.011
   Thaine P, 2019, INTERSPEECH, P3715, DOI 10.21437/Interspeech.2019-1136
   Tolba MF, 2020, INTEGRATION, V72, P163, DOI 10.1016/j.vlsi.2020.02.003
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Yan XY, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8832341
   Zhang QY., 2022, INT J NETW SECUR, V24, P1042, DOI [10.6633/IJNS.20221124(6).09, DOI 10.6633/IJNS.20221124(6).09]
   Zhang SX, 2019, INT CONF ACOUST SPEE, P5691, DOI [10.1109/icassp.2019.8683721, 10.1109/ICASSP.2019.8683721]
   Zuber Martin, 2020, Information and Communications Security. 22nd International Conference, ICICS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12282), P403, DOI 10.1007/978-3-030-61078-4_23
NR 28
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25675
EP 25693
DI 10.1007/s11042-023-16493-5
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600004
DA 2024-07-18
ER

PT J
AU Chen, XL
   Chen, YP
   Yin, GJ
   He, HY
AF Chen, Xuelong
   Chen, Yiping
   Yin, Guojie
   He, Hanyue
TI Dynamic evolution of information diffusion networks of news agencies in
   emergencies: a case study of microblogs of urban fire disasters on Sina
   Weibo
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media platform; Information diffusion network; Topological
   structure; Dynamic evolution; News agency; Emergency
ID SOCIAL MEDIA; PROPAGATION; TWITTER; MODEL; TWEETS
AB Critical to information diffusion, influential news agencies can publicize emergencies on social media platforms, not only helping to guide public opinion and enhance the public's situational awareness and responsiveness to emergencies, but also reducing social panic, rumor propagation, and negative public opinions during emergencies. To study diffusion patterns of emergency information, postings and repostings about 11 urban fire disasters on 35 original microblogs posted by the two most influential news agencies were collected and analyzed by exploring the law of dynamic information diffusion and the evolution of the topology structure during peak diffusion. Results showed that the topological structures of the information diffusion networks (IDN) of news agencies comprise superstar, N-star, galaxy, ring, and comprehensive structures, characterized by topological structure and numerical characteristics such as reposting rate. In the dynamic evolution of IDN, the comprehensive structure has the best information diffusion and control, and thus serves to optimize the timely and effective management of emergency information on social media platforms. The out-degrees of the most dominant hub node in this structure achieved 2000, which is nearly 5-10 times that of the other structures. This work fills the gap in the combination of dynamical topological and statistical characteristics evolution by analyzing the topological evolution and statistical characteristics of networks. The findings of this study can be applicable to similar disasters and social media platforms.
C1 [Chen, Xuelong; Chen, Yiping; Yin, Guojie; He, Hanyue] Dalian Univ Technol, Sch Econ & Management, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Chen, XL (corresponding author), Dalian Univ Technol, Sch Econ & Management, Dalian, Peoples R China.
EM chenxl_dg@dlut.edu.cn
RI ZHENG, YI/KAM-6536-2024
FU National Natural Science Foundation of China [71974025]; National Key
   Ramp;D Program of China [2021YFC3300201]; Dalian Science and Technology
   Innovation Project [2022JJ12GX012]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant number: 71974025), the National Key R&D
   Program of China (Grant number: 2021YFC3300201) and the Dalian Science
   and Technology Innovation Project (Grant number: 2022JJ12GX012). We
   would like to thank the reviewers for their valuable and constructive
   comments on improving the paper and Editage (www.editage.com) for
   English language editing. We would also like to thank Xiaoyan Su for her
   critical support in data acquisition.
CR Ahsan M, 2021, INNOVATIONS COMPUTAT, P430, DOI [10.1007/978-981-15-6067-5_48, DOI 10.1007/978-981-15-6067-5_48]
   Alvarez-Hamelin JI, 2005, ARXIV
   Antoniades D, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P361, DOI 10.1109/SITIS.2014.68
   Bastos M, 2018, SOC NETWORKS, V52, P282, DOI 10.1016/j.socnet.2017.09.006
   Chen AY, 2020, CHINESE PHYS B, V29, DOI 10.1088/1674-1056/ab9c0a
   Chen C, 2017, LECT NOTES COMPUT SC, V10569, P165, DOI 10.1007/978-3-319-68783-4_12
   Chen JP, 2017, NEURAL NETWORKS, V96, P11, DOI 10.1016/j.neunet.2017.08.006
   Chen R, 2013, MIS QUART, V37, P125
   Cheng XX, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11195330
   Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527
   Ertem Z, 2016, SOC NETWORKS, V46, P1, DOI 10.1016/j.socnet.2016.01.001
   Fabrega J, 2013, INFORMATION, V4, P171, DOI 10.3390/info4020171
   Fan C, 2021, J COMPUT-MEDIAT COMM, V26, P108, DOI 10.1093/jcmc/zmaa020
   Foroozani A, 2019, EXPERT SYST APPL, V134, P249, DOI 10.1016/j.eswa.2019.05.047
   Goel A, 2015, LECT NOTES COMPUT SC, V9479, P119, DOI 10.1007/978-3-319-26784-5_10
   Grassi R, 2015, QUAL QUANT, V49, P1597, DOI 10.1007/s11135-014-0070-3
   Gu J., 2020, INFORM SCIENCES, V38, P78
   Huang JM, 2014, SCI REP-UK, V4, DOI 10.1038/srep05334
   Huang XM, 2014, IEEE IJCNN, P1401, DOI 10.1109/IJCNN.2014.6889910
   Itzkovitz S, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.026127
   Li LF, 2018, INT J INFORM MANAGE, V38, P34, DOI 10.1016/j.ijinfomgt.2017.08.008
   Li SCS, 2017, TELEMAT INFORM, V34, P261, DOI 10.1016/j.tele.2016.07.003
   [林燕霞 Lin Yanxia], 2020, [中国管理科学, Chinese Journal of Management Science], V28, P212
   Ling C., 2019, INFORM SCIENTIST, V37, P145
   Liu XY, 2019, IEEE T COMPUT SOC SY, V6, P8, DOI 10.1109/TCSS.2018.2885127
   Liu YJ., 2016, MANAGE REV, DOI [10.14120/j.cnki.cn11-5057/f.2016.03.021, DOI 10.14120/j.cnki.cn11-5057/f.2016.03.021]
   Luna S, 2018, INT J DISAST RISK RE, V28, P565, DOI 10.1016/j.ijdrr.2018.01.006
   Luo FX, 2016, APPL GEOGR, V70, P11, DOI 10.1016/j.apgeog.2016.03.001
   Luo GX, 2016, J UNIVERS COMPUT SCI, V22, P360
   Ming-kui Huo., 2019, INFORM SCIENCES, V31, P98
   Morales AJ, 2014, SOC NETWORKS, V39, P1, DOI 10.1016/j.socnet.2014.03.007
   Muchnik L, 2013, SCI REP-UK, V3, DOI 10.1038/srep01783
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Pentina I, 2014, COMPUT HUM BEHAV, V35, P211, DOI 10.1016/j.chb.2014.02.045
   Rattanaritnont Geerajit., 2012, Proceedings of the 2nd Temporal Web Analytics Workshop (TempWeb'12), P1
   Ribeiro B, 2012, IEEE INFOCOM SER, P1692, DOI 10.1109/INFCOM.2012.6195540
   Safarnejad L, 2020, AM J PUBLIC HEALTH, V110, pS340, DOI 10.2105/AJPH.2020.305854
   Said A, 2018, APPL SOFT COMPUT, V63, P59, DOI 10.1016/j.asoc.2017.11.014
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Si MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76162-7
   Takahashi B, 2015, COMPUT HUM BEHAV, V50, P392, DOI 10.1016/j.chb.2015.04.020
   Tan Xuehan, 2017, Journal of the China Society for Scientific and Technical Information, V36, P297
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   Wang BR, 2017, NAT HAZARDS, V89, P161, DOI 10.1007/s11069-017-2960-x
   Wang C., 2019, J INT, V38, P123
   Wang ZY, 2016, NAT HAZARDS, V83, P523, DOI 10.1007/s11069-016-2329-6
   Weng L, 2013, SCI REP-UK, V3, DOI [10.1038/srep02304, 10.1038/srep02522]
   Wu B, 2015, INT J INFORM MANAGE, V35, P702, DOI 10.1016/j.ijinfomgt.2015.07.003
   [阳长征 Yang Changzheng], 2021, [情报学报, Journal of the China Society for Scientific and Technical Information], V40, P448
   Yao L., 2020, LIBR INFORM SERV, V64, P123
   Yin FL, 2020, MATH BIOSCI ENG, V17, P2676, DOI 10.3934/mbe.2020146
   Zhang L, 2021, ELECTRON LIBR, V39, P732, DOI 10.1108/EL-12-2020-0329
   Zhang L, 2020, INF DISCOV DELIV, V48, P151, DOI 10.1108/IDD-10-2019-0074
   Zhao Xun., 2013, SEMANTIC WEB WEB SCI, P55, DOI [10.1007/978-1-4614-6880-6_5, DOI 10.1007/978-1-4614-6880-6_5]
   Zhou XK, 2021, IEEE T NETW SCI ENG, V8, P894, DOI 10.1109/TNSE.2021.3064952
NR 55
TC 0
Z9 0
U1 15
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25287
EP 25319
DI 10.1007/s11042-023-16498-0
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050545200001
DA 2024-07-18
ER

PT J
AU Zhang, P
   Zheng, JS
   Gao, LH
   Li, P
   Long, HW
   Liu, HB
   Li, DL
AF Zhang, Pan
   Zheng, Jishu
   Gao, Lihong
   Li, Ping
   Long, Hanwei
   Liu, Hongbo
   Li, Daoliang
TI A novel detection model and platform for dead juvenile fish from the
   perspective of multi-task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dead fish; Detection; Attention; Lightweight; Monitoring platform
AB The cultivation stage of juvenile fish is the starting point of the whole cultivation process. In this stage, the vitality of juvenile fish is weak and they are extremely vulnerable to environmental stress and death. Therefore, there is an urgent need for an automated method to replace the aquaculture personnel to achieve the growth monitoring of juvenile fish in the cultivation stage. However, the dead juvenile fish are generally small, and there are interference signals with high similarity to the color of the dead fish, such as reflection and foam, on the water surface of the aquaculture area. To solve this problem, this study constructs dead fish detection model from two perspectives of improving model accuracy and realizing model lightweight. First, the dead fish detection data set is constructed using visual technology. Secondly, the Efficient Channel Attention module (ECA) is used to strengthen the feature auxiliary branch of YOLOv4 backbone feature extraction network output (E-YOLOv4), the E-YOLOv4 dead fish detection model is constructed (mAP = 96.91%, model-size = 244 M). In addition, this study replaced YOLOv4's cross stage partial network (CSPDarkNet53) with Densenet169 (D-YOLOv4), the D-YOLOv4 dead fish detection model is constructed (mAP = 95.93%, model-size = 84.7 M). The results show that E-YOLOV4 and D-YOLOV4 are superior to YOLOV4 in model effect and model-size. Finally, Python+PyQt5 is used to build a dead fish monitoring platform, and the above model is deployed on the platform to achieve real-time monitoring of dead fish in the breeding process. The dead fish monitoring platform established in this study can not only assist the aquaculture personnel in daily aquaculture supervision, but also assist the water quality sensor to jointly monitor the safety of the growth environment of juvenile fish. The platform is simple in design and has certain practical application value.
C1 [Zhang, Pan; Li, Daoliang] China Agr Univ, Natl Innovat Ctr Digital Fishery, Beijing, Peoples R China.
   [Zhang, Pan; Li, Daoliang] China Agr Univ, Key Lab Smart Farming Technol Aquat Anim & Livesto, Minist Agr & Rural Affairs, Beijing 100083, Peoples R China.
   [Zhang, Pan; Li, Daoliang] China Agr Univ, Beijing Engn & Technol Res Ctr Internet Things Agr, Beijing 100083, Peoples R China.
   [Zhang, Pan; Li, Daoliang] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Zheng, Jishu; Gao, Lihong; Li, Ping; Long, Hanwei; Liu, Hongbo] Chongqing Acad Agr Sci, Chongqing 400000, Peoples R China.
C3 China Agricultural University; China Agricultural University; Ministry
   of Agriculture & Rural Affairs; China Agricultural University; China
   Agricultural University; Chongqing Academy of Agricultural Sciences
RP Li, DL (corresponding author), China Agr Univ, Natl Innovat Ctr Digital Fishery, Beijing, Peoples R China.; Li, DL (corresponding author), China Agr Univ, Key Lab Smart Farming Technol Aquat Anim & Livesto, Minist Agr & Rural Affairs, Beijing 100083, Peoples R China.; Li, DL (corresponding author), China Agr Univ, Beijing Engn & Technol Res Ctr Internet Things Agr, Beijing 100083, Peoples R China.; Li, DL (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
EM dliangl@cau.edu.cn
RI Gao, Lihong/JHV-1214-2023
FU talent cultivation and development support plan team construction funds
   [2018QC188]; National Natural Science Foundation of China [62076244]
FX The authors would like to thank the editor and reviewers for their
   valuable input, time, and suggestions to improve the quality of the
   manuscript. This work was supported by the talent cultivation and
   development support plan team construction funds - national innovation
   team leading professor class A, Study on mechanism and method of rapid
   detection of trace toxic nitrogen in aquaculture water based on SERS
   light pole [Grant No.2018QC188] and the National Natural Science
   Foundation of China "Study on characteristics recognition and behavior
   analysis of swimming fish feeding population based on machine vision",
   Yantai Industrial Leading Talent Project, National Marine Ranch
   Information Platform Design [Grant No.62076244].
CR Anas O., 2020, Procedia Computer Science, V175, P141, DOI [10.1016/j.procs.2020.07.023, DOI 10.1016/J.PROCS.2020.07.023]
   Beyan C, 2013, IEEE IMAGE PROC, P1476, DOI 10.1109/ICIP.2013.6738303
   Chen J, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION ENGINEERING (ICECE 2019), P438, DOI [10.1109/icece48499.2019.9058567, 10.1109/ICECE48499.2019.9058567]
   Cheng SH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091179
   Goldstein ED, 2020, MAR BIOL, V167, DOI 10.1007/s00227-019-3627-9
   Hu J, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115051
   Hu ZH, 2022, PROCEEDINGS OF 2022 THE 6TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, ICMLSC 20222, P92, DOI 10.1145/3523150.3523165
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jalal A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101088
   Konovalov Dmitry A., 2019, 2019 International Joint Conference on Neural Networks (IJCNN). Proceedings, DOI 10.1109/IJCNN.2019.8851907
   Li DL, 2020, J WORLD AQUACULT SOC, V51, P808, DOI 10.1111/jwas.12736
   Li X, 2015, OCEANS 2015 MTS IEEE, P1
   Li X, 2022, COMPUT ELECTRON AGR, V203, DOI 10.1016/j.compag.2022.107435
   Li X, 2016, OCEANS-IEEE
   Li X, 2017, OCEANS-IEEE
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Matic-Skoko S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78181-w
   Qian ZM, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1138-y
   Redmon J., 2018, P IEEE C COMP VIS PA
   Salman A, 2020, ICES J MAR SCI, V77, P1295, DOI 10.1093/icesjms/fsz025
   Salman A, 2019, ECOL INFORM, V51, P44, DOI 10.1016/j.ecoinf.2019.02.011
   Scoulding B, 2022, ICES J MAR SCI, V79, P2204, DOI 10.1093/icesjms/fsac166
   Sung M, 2017, OCEANS-IEEE
   Thida M, 2009, P 11 IAPR C MACH VIS, P278
   Wang C., 2020, COMPUT VIS PATTERN R
   Wang C, 2021, INTELLIGENT FISH FAR
   Wang Chien-Yao, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang H, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106512
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wenwei Xu, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P313, DOI 10.1109/CSCI46756.2018.00067
   Xu WK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164425
   Yang L, 2021, ARCH COMPUT METHOD E, V28, P2785, DOI 10.1007/s11831-020-09486-2
   Yu GY, 2020, CHIN AUTOM CONGR, P1973, DOI 10.1109/CAC51589.2020.9326648
   Zhang P, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2022.106714
   Zhao SL, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107098
NR 35
TC 0
Z9 0
U1 12
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16370-1
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600006
DA 2024-07-18
ER

PT J
AU Zhao, J
   Chen, MY
AF Zhao, Jing
   Chen, Mingyue
TI FP-GCN: fine pseudo-label driven iterative GCN to learning
   discriminative fusion features for unsupervised person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Unsupervised person re-identification; Graph convolutional network;
   Pseudo-labels; Discriminative feature learning; Label noise; Multimodal
   fusion feature
ID SELF-SIMILARITY; ENSEMBLE
AB Unsupervised person re-identification (RE-ID) has attracted increasing attention recently due to its low costs and high application values. Currently, most of the unsupervised RE-ID approaches attempt to explore discriminative visual features based on unlabeled samples, which suffer from the label noise problem. To alleviate this problem, this paper first proposes to leverage both visual and spatial information for unsupervised person RE-ID, with a feasible assumption that the same identity has similar neighbors across different cameras. Technically, we devise an iterative Graph Convolutional Network (GCN) to alternately improve the quality of pseudo-labels and multimodal fusion features. What is more, our modal is trained based on three novel pseudo-label classes (pseudo-positive, visually similar, and pseudo-negative) instead of two to better learn discriminative features. Extensive experiments on two representative datasets (Market-1501 and DukeMTMC-reID) demonstrate the effectiveness of our approach, with 1%-2% mAP improvements as compared to the advanced approaches.
C1 [Zhao, Jing] Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Chen, Mingyue] Hunan Univ, Changsha, Hunan, Peoples R China.
C3 Nanjing University of Science & Technology; Hunan University
RP Zhao, J (corresponding author), Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM 13331088368@njust.edu.cn
FU National Natural Science Foundation of China [62272157]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62272157.
CR Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   [Anonymous], 2017, Advances in Neural Information Processing Systems
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cho Y, 2022, PROC CVPR IEEE, P7298, DOI 10.1109/CVPR52688.2022.00716
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Goodfellow I. J., 2014, ARXIV
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Han J, 2022, IEEE C AAAI
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Li YY, 2021, IEEE T IMAGE PROCESS, V30, P7952, DOI 10.1109/TIP.2021.3112039
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin X., 2021, arXiv
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu C, 2020, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR42600.2020.00692
   Ma AJ, 2015, LECT NOTES COMPUT SC, V9007, P397, DOI 10.1007/978-3-319-16814-2_26
   Marcheggiani D, 2018, 2018 C N AM CHAPTER
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Narasimhan M, 2018, ADV NEUR IN, V31
   Norcliffe-Brown W, 2018, Advances in Neural Information Processing Systems
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen F, 2020, Arxiv, DOI arXiv:2005.14684
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Battaglia PW, 2018, Arxiv, DOI [arXiv:1806.01261, DOI 10.48550/ARXIV.1806.01261, 10.48550/arXiv.1806.01261]
   Wang D, 2020, IEEECVF C COMPUTER V
   Wang D, 2020, IEEE C COMPUTER VISI
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang ML, 2021, AAAI CONF ARTIF INTE, V35, P2764
   Wang P., 2022, IEEE Transactions on Multimedia
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu L, 2022, IEEE T IMAGE PROCESS, V31, P4803, DOI 10.1109/TIP.2022.3186746
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xuan SY, 2021, PROC CVPR IEEE, P11921, DOI 10.1109/CVPR46437.2021.01175
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yang FX, 2020, IEEE T MULTIMEDIA, V22, P2444, DOI 10.1109/TMM.2019.2957928
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yuan J, 2022, IEEE T IMAGE PROCESS, V31, P1723, DOI 10.1109/TIP.2022.3145158
   Yuan J, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107131
   Zhang X, 2021, PROC CVPR IEEE, P3435, DOI 10.1109/CVPR46437.2021.00344
   Zhang XY, 2022, PROC CVPR IEEE, P7359, DOI 10.1109/CVPR52688.2022.00722
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao JD, 2022, PATTERN RECOGN
   Zheng K, 2021, IEEE C AAAI
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Y, 2021, IEEE CVF INT C COMP
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou J, 2021, Arxiv, DOI [arXiv:1812.08434, DOI 10.1016/J.AIOPEN.2021.01.001]
   Zhu YC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P646, DOI 10.1145/3394171.3413607
NR 71
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-15344-7
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600009
DA 2024-07-18
ER

PT J
AU Abedi, A
   Khan, SS
AF Abedi, Ali
   Khan, Shehroz S.
TI Affect-driven ordinal engagement measurement from video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Engagement measurement; Engagement detection; Affect states; Temporal
   convolutional network; Ordinal classification
AB User engagement is crucial for the successful completion of education and intervention programs. Automatic measurement of user engagement can provide valuable insights for instructors to personalize the delivery of the program and achieve program objectives. This paper presents a novel approach to automatically measuring users' engagement in virtual learning programs from their videos. The proposed approach utilizes affect states, continuous values of valence and arousal, along with a new latent affective feature vector and behavioral features extracted from consecutive video frames. Deep-learning sequential models are trained and validated on the extracted features for video-based engagement measurement. Since engagement is an ordinal variable, ordinal versions of the models are also developed to address the problem of engagement level measurement as an ordinal classification problem. The proposed approach was evaluated on two publicly available video-based engagement measurement datasets, Dataset for Affective States in E-Environments (DAiSEE) and Emotion recognition in the Wild-Engagement prediction in the Wild (EmotiW-EW), containing videos of students in virtual learning programs. The experiments demonstrated a state-of-the-art engagement level classification accuracy of 67.4% on the DAiSEE dataset and a regression mean squared error of 0.0508 on the EmotiW-EW dataset. The ablation study demonstrated that incorporating affect states and ordinality of engagement significantly improved engagement measurement.
C1 [Abedi, Ali; Khan, Shehroz S.] Univ Hlth Network, KITE Res Inst, Toronto Rehabil Inst, 190 Elizabeth St, Toronto, ON M5G 2C4, Canada.
C3 University of Toronto; University Health Network Toronto; Toronto
   Rehabilitation Institute
RP Abedi, A (corresponding author), Univ Hlth Network, KITE Res Inst, Toronto Rehabil Inst, 190 Elizabeth St, Toronto, ON M5G 2C4, Canada.
EM ali.abedi@uhn.ca; shehroz.khan@uhn.ca
RI Khan, Shehroz/O-2706-2014
OI Khan, Shehroz/0000-0002-1195-4999
CR Abedi A, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P151, DOI 10.1109/CRV52889.2021.00028
   Ai XS, 2022, Arxiv, DOI arXiv:2208.07216
   Altuwairqi K, 2021, J KING SAUD UNIV-COM, V33, P99, DOI 10.1016/j.jksuci.2018.12.008
   Aslan S., 2017, EDUC TECHNOL, V57, P53
   Bai SJ, 2018, Arxiv, DOI [arXiv:1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Belle A, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/528781
   Booth BM, 2017, INT CONF AFFECT, P470, DOI 10.1109/ACII.2017.8273641
   Broughton SH, 2010, J EDUC RES, V103, P407, DOI 10.1080/00220670903383101
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cardoso JS, 2011, INT J PATTERN RECOGN, V25, P1173, DOI 10.1142/S0218001411009093
   Chen X., 2019, IEEE T AFFECT COMPUT
   Copur O, 2022, LECT NOTES COMPUT SC, V13233, P411, DOI 10.1007/978-3-031-06433-3_35
   D'Mello S, 2017, EDUC PSYCHOL-US, V52, P104, DOI 10.1080/00461520.2017.1281747
   Delgado K, 2021, IEEE INT CONF COMP V, P3621, DOI 10.1109/ICCVW54120.2021.00405
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Dhall Abhinav, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P784, DOI 10.1145/3382507.3417973
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Doherty K, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234149
   Fedotov D., 2018, P WORKSH MOD COGN PR, P1
   Geng L, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P442, DOI [10.1109/ssci44817.2019.9002713, 10.1109/SSCI44817.2019.9002713]
   Gupta A, 2022, Arxiv, DOI arXiv:1609.01885
   Hu Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168007
   Huang T, 2019, IEEE INT CONF ELECTR, P338, DOI [10.1109/ICEIEC.2019.8784559, 10.1109/iceiec.2019.8784559]
   Jianming Wu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P777, DOI 10.1145/3382507.3417959
   Rivas JJ, 2022, IEEE T AFFECT COMPUT, V13, P1183, DOI 10.1109/TAFFC.2021.3055790
   Kaur A., 2018, P 2018 DIG IM COMP T, P1
   Khan SS, 2022, Arxiv, DOI arXiv:2208.04548
   Khosla P., 2020, ADV NEURAL INF PROCE, V33, P18661
   Kook L, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108263
   Liao JC, 2021, APPL INTELL, V51, P6609, DOI 10.1007/s10489-020-02139-8
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, DOI 10.48550/ARXIV.1906.08172]
   Matamala-Gomez M, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00354
   Mehta NK, 2022, APPL INTELL, V52, P13803, DOI 10.1007/s10489-022-03200-4
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Mukhtar K, 2020, PAK J MED SCI, V36, pS27, DOI 10.12669/pjms.36.COVID19-S4.2785
   Niu XS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P599, DOI 10.1145/3242969.3264982
   Nuara A, 2022, J NEUROL, V269, P627, DOI 10.1007/s00415-021-10397-w
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pekrun R, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P259, DOI 10.1007/978-1-4614-2018-7_12
   Ranti C, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64999-x
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salam H, 2022, Arxiv, DOI arXiv:2209.15370
   Sinatra GM, 2015, EDUC PSYCHOL-US, V50, P1, DOI 10.1080/00461520.2014.1002924
   Sumer O., 2021, IEEE Transactions on Affective Computing
   Thomas C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P604, DOI 10.1145/3242969.3264984
   Toisoul A, 2021, NAT MACH INTELL, V3, P42, DOI 10.1038/s42256-020-00280-0
   Venton BJ, 2021, ANAL BIOANAL CHEM, V413, P1507, DOI 10.1007/s00216-021-03159-0
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Woolf B, 2009, INT J LEARN TECHNOL, V4, P129, DOI 10.1504/IJLT.2009.028804
   Xiaoyang Ma, 2021, International Journal of Information and Education Technology, V11, P107, DOI 10.18178/ijiet.2021.11.3.1497
   Zhang H, 2019, IEEE INT CONF ELECTR, P342, DOI [10.1109/iceiec.2019.8784507, 10.1109/ICEIEC.2019.8784507]
NR 55
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16345-2
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100004
DA 2024-07-18
ER

PT J
AU Huang, CM
   Yang, KJ
AF Huang, Chung-Ming
   Yang, Kai-Jiun
TI Adaptive sliding window-based video downloading for 1-to-k cooperative
   SVC streaming using the multi-access edge computing (MEC) architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Scalable video coding (SVC); 1-to-k cooperative video streaming;
   Multicast video streaming; Multi-access edge computing (MEC); Adaptive
   forward error correction (FEC); Quality adaptation; Credit-based header
   re-selection
ID SCALABLE VIDEO; SOCIAL-AWARE; ADAPTATION
AB This work proposed the 1-to-k cooperative SVC adaptive streaming method for a group of users based on the Multi-access Edge Computing (MEC) architecture. In the proposed method, a group member's handheld device is selected as the Header Handheld Device (H-HD), which is in charge of downloading the video content from the MEC Server and then multicasting the downloaded video content to other group members' Receiver Handheld Devices (R-HDs). The video bit rate that can be adopted in the next transmission cycle is derived using the proposed adaptive Forward Error Correction (FEC) scheme with the estimated bandwidth. To have the smooth streaming, the Currently Downloading Segment Section (CDSS) mechanism was proposed such that the segments inside CDSS can be downloaded in a downloading cycle, i.e., in a time period. CDSS is a sliding window, which can be moved forwardly and whose size can be dynamically adjusted depending on the networking situation, the video playout situation and the buffering situation. A credit scheme was proposed to select the one that has the minimum credit to become the H-HD in next downloading round to balance all handheld devices' power consumption. Based on the performance evaluation results, the proposed SVC streaming method can have (i) 28.3% higher video quality, which is in terms of the average number of playout video layers and (ii) 52.16% improvement of Quality Of Experience (QOE), which is in terms of the frequency of quality switching, comparing with the target SVC video streaming method; the proposed credit-based H-HD's re-selection control scheme can have the more even power consumption among all group members' handheld devices and thus can extend the group's streaming service time.
C1 [Huang, Chung-Ming; Yang, Kai-Jiun] Natl Chen Kung Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Tainan, Taiwan.
C3 National Cheng Kung University
RP Huang, CM (corresponding author), Natl Chen Kung Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Tainan, Taiwan.
EM hungcm@locust.csie.ncku.edu.tw; yangkj@locust.csie.ncku.edu.tw
RI Yang, Kaijie/HJP-4591-2023
FU Ministry Of Science and Technology (MOST), Taiwan [MOST
   1082221-E-006-100-MY3]
FX This work was supported by the Ministry Of Science and Technology
   (MOST), Taiwan (R.O.C.) under the grant number MOST
   108-2221-E-006-100-MY3.
CR [Anonymous], 2017, JSVM JOINT SCALABLE
   Bilal K, 2018, COMPUT NETW, V130, P94, DOI 10.1016/j.comnet.2017.10.002
   Elgabli A, 2019, IEEE T CIRC SYST VID, V29, P2833, DOI 10.1109/TCSVT.2018.2870715
   Elgabli A, 2019, IEEE ACM T NETWORK, V27, P1138, DOI 10.1109/TNET.2019.2911523
   Huo YK, 2015, IEEE COMMUN SURV TUT, V17, P1166, DOI 10.1109/COMST.2015.2392378
   Hwang J, 2016, SIGNAL PROCESS-IMAGE, V47, P242, DOI 10.1016/j.image.2016.06.013
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Kuo WH, 2015, IEEE T CIRC SYST VID, V25, P812, DOI 10.1109/TCSVT.2014.2363741
   Liu CY, 2021, CHINA COMMUN, V18, P200, DOI 10.23919/JCC.2021.02.013
   Sun HF, 2007, WIREL COMMUN MOB COM, V7, P159, DOI 10.1002/wcm.471
   Ticao Zhang, 2019, IEEE Networking Letters, V1, P63, DOI 10.1109/LNET.2019.2911972
   Ullah S, 2020, IEEE ACCESS, V8, P48060, DOI 10.1109/ACCESS.2020.2978544
   Wei-Yu Chen, 2020, 2020 International Conference on Computing, Networking and Communications (ICNC), P796, DOI 10.1109/ICNC47757.2020.9049706
   Wu D, 2017, IEEE T MULTIMEDIA, V19, P2571, DOI 10.1109/TMM.2017.2700621
   Wu F, 2020, IEEE CONF COMPUT, P97, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162662
   Yang LX, 2018, IEEE ACCESS, V6, P36092, DOI 10.1109/ACCESS.2018.2849204
   Yang SR, 2019, IEEE T VEH TECHNOL, V68, P1888, DOI 10.1109/TVT.2018.2889196
   Yuan Z, 2019, INT WIREL COMMUN, P656
NR 18
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-15460-4
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100001
DA 2024-07-18
ER

PT J
AU Zheng, AY
   Zeng, XJ
   Song, PP
   Mi, Y
   He, ZB
AF Zheng, Anyi
   Zeng, Xiangjin
   Song, Pengpeng
   Mi, Yong
   He, Zhibo
TI Face super resolution based on attention upsampling and gradient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face super-resolution; Convolutional neural network; Upsampling with
   attention; Gradient information
ID IMAGE SUPERRESOLUTION; HALLUCINATION; INFORMATION
AB Face Super-Resolution(SR) is a specific domain SR task, which is to reconstruct low-resolution(LR) face images. Recently, many face super-resolution methods based on deep neural networks have sprung up, yet many methods ignore the gradient information of the face image, which is related closely to the restoration of image detail features. At the same time, many super-resolution methods directly use linear interpolation or pixel shuffle and several convolution layers to up-sample the feature maps, caussing some irrelevant pixels will make subsequent detail reconstruction difficult. Considering these issues, in this paper, we propose a face super-resolution method guided by the gradient structure. In particular, we designed a sub-network to generate gradient information from low-resolution images and up-sample the gradient as additional information for the entire network. Unlike other methods based on prior information, such as facial landmarks, facial parsing, face alignment, the gradient information is generated from low-resolution images. At the same time, relying on pixel shuffle, we also designed a novel upsampling module based on channel attention and pixel attention. The results of the experiment show that our network can achieve the sota on several public datasets on PSNR, SSIM, and VIF. The visual result also proves the feasibility and advancement of our network in restoring the detailed structure.
C1 [Zheng, Anyi; Zeng, Xiangjin; Song, Pengpeng; Mi, Yong; He, Zhibo] Wuhan Inst Technol, Sch Comp Sci & Engn, Sch Artificial Intelligence, Guanggu 1st Rd 206, Wuhan 430205, Hubei, Peoples R China.
C3 Wuhan Institute of Technology
RP Zeng, XJ (corresponding author), Wuhan Inst Technol, Sch Comp Sci & Engn, Sch Artificial Intelligence, Guanggu 1st Rd 206, Wuhan 430205, Hubei, Peoples R China.
EM zay3355285479@163.com; xjzeng21@163.com; 1170552818@qq.com;
   2532740174@qq.com; 794729728@qq.com
FU National Natural Science Foundation of China [61502355]; Hubei Three
   Gorges Laboratory Innovation Fund [SC215001]
FX 1.National Natural Science Foundation of China (61502355) 2. Hubei Three
   Gorges Laboratory Innovation Fund (SC215001)
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Berthelot D, 2017, Arxiv, DOI arXiv:1703.10717
   Bin H, 2017, Arxiv, DOI arXiv:1707.00737
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen XZ, 2020, NEUROCOMPUTING, V376, P119, DOI 10.1016/j.neucom.2019.09.079
   Chen Y, 2020, J ADV MODEL EARTH SY, P1, DOI DOI 10.1029/2019MS001719
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Chen ZB, 2021, IEEE T CYBERNETICS, V51, P451, DOI 10.1109/TCYB.2018.2889791
   Chen ZM, 2017, Arxiv, DOI arXiv:1705.02438
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dou H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1891, DOI 10.1145/3394171.3413590
   Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181
   Feng ZX, 2016, INT C PATT RECOG, P3276, DOI 10.1109/ICPR.2016.7900140
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   Guo J, 2018, LECT NOTES COMPUT SC, V11165, P190, DOI 10.1007/978-3-030-00767-6_18
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Han Z, 2018, 2018 IEEE INT C MULT, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu X, 2019, PATTERN RECOGN, V94, P110, DOI 10.1016/j.patcog.2019.05.027
   Huang HB, 2019, INT J COMPUT VISION, V127, P763, DOI 10.1007/s11263-019-01154-8
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Indradi SD, 2019, 2019 7 INT C INFORM, P1
   Jiang K, 2022, IEEE T NEUR NET LEAR, V33, P378, DOI 10.1109/TNNLS.2020.3027849
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Kalarot R, 2020, IEEE WINT CONF APPL, P359, DOI [10.1109/wacv45572.2020.9093399, 10.1109/WACV45572.2020.9093399]
   Nguyen K, 2018, PATTERN RECOGN, V78, P23, DOI 10.1016/j.patcog.2018.01.002
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ko W.J., 2016, 2016 IEEE INT C MULT, P1
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu QM, 2020, IEEE ACCESS, V8, P4110, DOI 10.1109/ACCESS.2019.2962790
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Lu T, 2019, IEEE ACCESS, V7, P81266, DOI 10.1109/ACCESS.2019.2923023
   Luo YK, 2020, INT CONF INFO SCI, P145, DOI 10.1109/ICIST49303.2020.9202156
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Majdabadi MM, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Song YB, 2017, Arxiv, DOI arXiv:1708.00223
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Tuzel O, 2016, Arxiv, DOI arXiv:1603.07235
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xiaoyu Zheng, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P114, DOI 10.1007/978-3-030-31723-2_10
   Xu XY, 2017, IEEE I CONF COMP VIS, P251, DOI 10.1109/ICCV.2017.36
   Xu YJ, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2019), P807, DOI 10.1109/ICMCCE48743.2019.00185
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yang LB, 2020, Arxiv, DOI arXiv:2010.05508
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yang X, 2018, LECT NOTES COMPUT SC, V11165, P441, DOI 10.1007/978-3-030-00767-6_41
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang Y., 2020, Pushing the limits of semi-supervised learning for automatic speech recognition
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871
   Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37
NR 71
TC 1
Z9 1
U1 8
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-15502-x
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900011
DA 2024-07-18
ER

PT J
AU Karatay, B
   Bestepe, D
   Sailunaz, K
   Özyer, T
   Alhajj, R
AF Karatay, Busra
   Bestepe, Deniz
   Sailunaz, Kashfia
   oezyer, Tansel
   Alhajj, Reda
TI CNN-Transformer based emotion classification from facial expressions and
   body gestures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Body gesture; CNN; Emotion classification; Emotion detection; Gaussian
   mixture model; LSTM; Transformer
ID RECOGNITION; MODEL; DATABASES; DEEP
AB Classifying the correct emotion from different data sources such as text, images, videos, and speech has been an inspiring research area for researchers from various disciplines. Automatic emotion detection from videos and images is one of the most challenging tasks that have been analyzed using supervised and unsupervised machine learning methods. Deep learning has been also employed where the model has been trained by facial and body features using pose and landmark detectors and trackers. In this paper, facial and body features extracted by the OpenPose tool have been used for detecting basic 6, 7 and 9 emotions from videos and images by a novel deep neural network framework which combines the Gaussian mixture model with CNN, LSTM and Transformer to generate the CNN-LSTM model and CNN-Transformer model with and without Gaussian centers. The experiments which were conducted using two benchmark datasets, namely FABO and CK+, showed that the proposed transformer model with 9 and 12 Gaussian centers with video generation approach was able to achieve close to 100% classification accuracy for the FABO dataset which outperforms the other DNN frameworks for emotion detection. It reported over 90% accuracy for most combinations of features for both datasets leading to a comparable framework for video emotion classification.
C1 [Karatay, Busra] Yapi Kredi Teknol, R&D & Special Projects Dept, Istanbul, Turkiye.
   [Bestepe, Deniz; Alhajj, Reda] Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.
   [Sailunaz, Kashfia; Alhajj, Reda] Istanbul Medipol Univ, Dept Comp Engn, Istanbul, Turkiye.
   [oezyer, Tansel] Ankara Medipol Univ, Dept Comp Engn, Ankara, Turkiye.
   [Alhajj, Reda] Univ Southern Denmark, Dept Heath Informat, Odense, Denmark.
C3 Yapi Kredi Bank; University of Calgary; Istanbul Medipol University;
   Ankara Medipol University; University of Southern Denmark
RP Alhajj, R (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB, Canada.; Alhajj, R (corresponding author), Istanbul Medipol Univ, Dept Comp Engn, Istanbul, Turkiye.; Alhajj, R (corresponding author), Univ Southern Denmark, Dept Heath Informat, Odense, Denmark.
EM rsalhajj@gmail.com
CR Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Alswaidan N, 2020, KNOWL INF SYST, V62, P2937, DOI 10.1007/s10115-020-01449-0
   [Anonymous], 2010, INTRO GENEVA MULTIMO, DOI 10.1037/a0025827
   Banziger T., 2010, Blueprint for affective computing: A sourcebook, P271, DOI DOI 10.1037/A0025827
   Barros Pablo, 2020, SN Comput Sci, V1, P321, DOI 10.1007/s42979-020-00325-6
   Barros P, 2015, NEURAL NETWORKS, V72, P140, DOI 10.1016/j.neunet.2015.09.009
   Behoora I, 2015, DESIGN STUD, V39, P100, DOI 10.1016/j.destud.2015.04.003
   Borod J., 2000, The Neuropsychology of Emotion (Affective Science)
   Bota PJ, 2019, IEEE ACCESS, V7, P140990, DOI 10.1109/ACCESS.2019.2944001
   Broad C.D., 1954, Journal of Aesthetics and Art Criticism, P203, DOI [DOI 10.2307/425913, 10.2307/425913, DOI 10.1111/1540_6245.JAAC13.2.0203]
   Calvo RA, 2013, COMPUT INTELL-US, V29, P527, DOI 10.1111/j.1467-8640.2012.00456.x
   CAMRAS L, 1980, AM J PSYCHOL, V93, P751, DOI 10.2307/1422394
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Chen L. F., 2007, Taiwanese Facial Expression Image Database
   Darwin C., 1872, P374
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   interactivearchitecture.org, IAL ADM DET HUM FAC
   Islam MR, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0046-0
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   LeDoux JE., 1984, COGNITION EMOTION, P357
   Li S., 2020, IEEE T AFFECT COMPUT
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Lövheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ly Son Thai, 2019, International Journal of Contents, V15, P59, DOI 10.5392/IJoC.2019.15.4.059
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mungra D, 2020, MULTIMED TOOLS APPL, V79, P2285, DOI 10.1007/s11042-019-08397-0
   Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6
   Nonis F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183904
   Oatley K., 1987, Cogn Emot, V1, P29, DOI DOI 10.1080/02699938708408362
   Ortony A., 1988, COGNITIVE STRUCTURE
   Poria S, 2019, IEEE ACCESS, V7, P100943, DOI 10.1109/ACCESS.2019.2929050
   PS S., 2017, Int. J. Control. Theory Appl, V10, P651
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2
   Santamaria-Granados L, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13010002
   Santhoshkumar R., 2019, Procedia Computer Science, V152, P158, DOI 10.1016/j.procs.2019.05.038
   Sapinski T, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070646
   Scherer K., 2000, Neuropsychology of Emotion, V137, P137
   Seng JKP, 2019, IEEE ACCESS, V7, P90982, DOI 10.1109/ACCESS.2019.2926751
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037//0022-3514.52.6.1061
   Sun X, 2019, COGN COMPUT, V11, P587, DOI 10.1007/s12559-019-09654-y
   Wang SM, 2020, IEEE ACCESS, V8, P124928, DOI 10.1109/ACCESS.2020.3007956
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xie BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144913
   Yang D, 2018, PROCEDIA COMPUT SCI, V125, P2, DOI 10.1016/j.procs.2017.12.003
   Yu ZB, 2018, NEUROCOMPUTING, V317, P50, DOI 10.1016/j.neucom.2018.07.028
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 55
TC 2
Z9 2
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-16342-5
EA AUG 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100002
DA 2024-07-18
ER

PT J
AU Hazman, C
   Guezzaz, A
   Benkirane, S
   Azrour, M
AF Hazman, Chaimae
   Guezzaz, Azidine
   Benkirane, Said
   Azrour, Mourade
TI Toward an intrusion detection model for IoT-based smart environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IoT security; Smart environments; IDS; Machine learning; Ensemble
   learning
ID DETECTION SYSTEM; INTERNET; THINGS; HYBRID; FRAMEWORK; SELECTION
AB Nowadays, modern Internet of Things (IoT) applications are enabling smart cities across the world. They provide remote device monitoring, management, and control, and even the extraction of new perspectives and actionable data from massive amounts of real-time data. A high degree of information technology integration and extensive utilization of resources are two biggest features of smart cities. Due to the obvious increasing amount and mobility of such distributed interconnected objects, attackers are becoming increasingly interested in them. Hence, a set of approaches have been developed to improve IoT Security. Intrusion detection systems (IDS) have previously gotten a lot of attention in the research field and industry. Therefore, several intrusion detection systems (IDSs) relies on approaches of machine learning (ML) and deep learning (DL) have been suggested to detect malicious intrusions. This study describes a revolutionary intrusion detection methodology for IoT-based smart environments that uses Ensemble Learning. The approach typically presented an optimum anomaly detection model which is based on AdaBoost and the Boruta feature selection technique based on the Xgboost algorithm. Furthermore, the suggested model metrics have been evaluated utilizing the NSL-KDD and BoT-IoT datasets. When compared to existing IDS, the results demonstrate that the proposed method produces excellent performance metrics in high accuracy (ACC), recall, and F1-score. It gives 99.9% on record detection and computation time.
C1 [Hazman, Chaimae; Guezzaz, Azidine; Benkirane, Said] Cadi Ayyad Univ, Technol Higher Sch Essaouira, Marrekech, Morocco.
   [Azrour, Mourade] Moulay Ismail Univ Meknes, Fac Sci & Tech, IDMS team, Meknes, Morocco.
C3 Cadi Ayyad University of Marrakech; Moulay Ismail University of Meknes
RP Hazman, C (corresponding author), Cadi Ayyad Univ, Technol Higher Sch Essaouira, Marrekech, Morocco.
EM a.guzzaz@gmail.com
CR Ahmad T, 2021, SUSTAIN CITIES SOC, V68, DOI 10.1016/j.scs.2021.102783
   Al-kasassbeh Mouhammd, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1230), P391, DOI 10.1007/978-3-030-52243-8_28
   Alanazi M, 2022, CMC-COMPUT MATER CON, V72, P261, DOI 10.32604/cmc.2022.024496
   Alazzam H, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113249
   Amouri A, 2018, 2018 IEEE 19TH WIRELESS AND MICROWAVE TECHNOLOGY CONFERENCE (WAMICON)
   Bostani H, 2017, COMPUT COMMUN, V98, P52, DOI 10.1016/j.comcom.2016.12.001
   Çavusoglu Ü, 2019, APPL INTELL, V49, P2735, DOI 10.1007/s10489-018-01408-x
   Chanal PM, 2020, SECURITY PRIVACY IOT
   Chatfield AT, 2019, GOV INFORM Q, V36, P346, DOI 10.1016/j.giq.2018.09.007
   Chourabi H., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P2289, DOI 10.1109/HICSS.2012.615
   Cover Thomas M, 1999, Elements of information theory
   Douiba M, 2022, J RELIABL INTELL ENV
   Douiba M, 2023, J SUPERCOMPUT, V79, P3392, DOI 10.1007/s11227-022-04783-y
   Elsaeidy A, 2019, J NETW COMPUT APPL, V135, P76, DOI 10.1016/j.jnca.2019.02.026
   Garcia-Font V, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040771
   Ge MM, 2021, COMPUT NETW, V186, DOI 10.1016/j.comnet.2020.107784
   Ghazali A., 2015, ACAD J SCI, V4, P199
   Giffinger R., 2007, SMART CITIES RANKING
   Gu J, 2020, COMPUT SECUR
   Gu J, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2020.102158
   Guezzaz A., 2019, International Journal of Network Security, V21, P438
   Guezzaz A, 2021, SECUR COMMUN NETW, V2021
   Guezzaz A, 2021, BIG DATA MIN ANAL, V4, P18, DOI 10.26599/BDMA.2020.9020019
   Guezzaz A, 2016, INT J ADV COMPUT SC, V7, P207
   HASTIE T., The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Hodo E, 2016, COMPUTERS COMMUNICAT, P1
   Irshad A, 2020, IEEE T IND APPL, V56, P4425, DOI 10.1109/TIA.2020.2966160
   Jabbar MA, 2017, PROCEDIA COMPUT SCI, V115, P226, DOI 10.1016/j.procs.2017.09.129
   Jan SU, 2019, IEEE ACCESS, V7, P42450, DOI 10.1109/ACCESS.2019.2907965
   Jeong H, 2021, VEH COMMUN, V31, DOI 10.1016/j.vehcom.2021.100349
   Jin DZ, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101984
   Kevric J, NEURAL COMPUT APPL, V28
   Khan M.A., 2021, 2 INT C ADV COMP INF
   Khraisat A, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0038-7
   King J, 2016, INFORM-J COMPUT INFO, V40, P133
   Koroniotis K., FUTURE
   Koroniotis N, 2020, FUTURE GENER COMP SY, V110, P91, DOI 10.1016/j.future.2020.03.042
   Krishnaveni S, 2020, ADV INTELL SYST COMP, V1056, P723, DOI 10.1007/978-981-15-0199-9_62
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Li LJ, 2018, IEEE ACCESS, V6, P12060, DOI 10.1109/ACCESS.2017.2787719
   Liao HJ, 2013, J NETW COMPUT APPL, V36, P16, DOI 10.1016/j.jnca.2012.09.004
   Liu LQ, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1128-z
   Mohy-Eddine M, 2023, J COMPUT VIROL HACKI, V19, P469, DOI 10.1007/s11416-022-00456-9
   Nakano S, 2021, CITIES, V115, DOI 10.1016/j.cities.2021.103244
   Nivaashini M, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, POWER AND COMMUNICATION TECHNOLOGIES (GUCON), P44, DOI 10.1109/GUCON.2018.8674952
   Pham N T, 2018, P AUSTR COMP SCI WEE, P1
   Pham NT, 2019, P AUSTRALASIAN COMPU, V2, P1
   Prabavathy S, 2018, J COMMUN NETW-S KOR, V20, P291, DOI 10.1109/JCN.2018.000041
   Primartha R, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE)
   Revathi S., 2013, INT J ENG RES TECHNO, V2, P1848
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Singh A, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102353
   Sommer R, 2010, P IEEE S SECUR PRIV, P305, DOI 10.1109/SP.2010.25
   Tait K.-A., IEEE INT C ADV TECHN
   Tama B.A., 2017, Neural Computing and Applications, P1
   Tavallaee M., 2009, P 2009 IEEE S COMPUT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Thaseen S., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P294, DOI 10.1109/ICPRIME.2013.6496489
   Wang WM, 2021, J SYST ARCHITECT, V118, DOI 10.1016/j.sysarc.2021.102215
   Yao HP, 2019, IEEE NETWORK, V33, P75, DOI 10.1109/MNET.001.1800479
NR 59
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16436-0
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000011
DA 2024-07-18
ER

PT J
AU Padminivalli, VSJRK
   Rao, MVPCS
   Narne, NSR
AF Padminivalli, V. S. J. R. K.
   Rao, M. V. P. Chandra Sekhara
   Narne, Naga Sai Ram
TI Sentiment based emotion classification in unstructured textual data
   using dual stage deep model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Emotion classification; Pre-processing; Latent
   semantic analysis; Chaotic artificial hummingbird algorithm; Dual-stage
   deep model; Convolutional gated attention recurrent unit
AB Classification of sentiments is an essential task in Natural Language Processing (NLP) domain. The powerful sentiment classification helps determine user opinions in product reviews or social networks. However, comprehending hidden opinions, sentiments, and emotions in emails, tweets, reviews, and comments is a challenge and equally crucial for social media monitoring, brand monitoring, customer services, and market research. Also, unstructured data in social media remains a major issue, and a proficient technique to deal with this issue remains a research gap. Therefore, this work presents an automated sentiment polarity and emotion classification in unstructured textual data using dual stage deep learning framework. Initially, pre-processing is performed to remove the noises and promote the quality of input data using stop words removal, Parts-Of-Speech (POS) tagging and duplicates removal. Then, the most discriminative features are extracted in the feature extraction stage, and the optimal set of features is selected to minimize the large feature dimensionality. Finally, the selected features are provided to the Dual-stage Deep Model to classify sentiments and emotions. The proposed classification stage classifies the sentiment and emotions from the given input data. The proposed work used three datasets for simulation analysis, and each dataset's performance is determined. Using Twitter Sentiment Dataset, the proposed model obtains an accuracy of 99.80%, F1-measure of 99.667%, specificity of 99.85% and kappa value of 99.52%, IMDB Movie Reviews attains an accuracy of 99.75%, F1-measure of 99.47%, specificity of 99.75% and kappa value of 98.99% and Yelp Reviews Dataset attains accuracy of 99.83%, F1-measure of 99.6%, specificity of 99.83% and kappa value of 99.32%. The obtained results reveal the effectiveness of a proposed study.
C1 [Padminivalli, V. S. J. R. K.] Acharya Nagarjuna Univ, Dr YSR ANU Coll Engn & Technol, Dept Comp Sci & Engn, Guntur 522510, Andhra Pradesh, India.
   [Rao, M. V. P. Chandra Sekhara] RVR & JC Coll Engn, Dept CSBS, Chowdavaram 522019, Andhra Pradesh, India.
   [Narne, Naga Sai Ram] Northwest Missouri State Univ, 800 Univ Dr, Maryville, MO USA.
C3 Acharya Nagarjuna University; RVR & JC College of Engineering
RP Padminivalli, VSJRK (corresponding author), Acharya Nagarjuna Univ, Dr YSR ANU Coll Engn & Technol, Dept Comp Sci & Engn, Guntur 522510, Andhra Pradesh, India.
EM srivallivasantham@gmail.com
RI PADMINIVALLI, S J R K/ADK-8684-2022; Rao, M.V.P. Chandra
   Sekhara/ABH-6843-2020
OI PADMINIVALLI, S J R K/0000-0001-8338-6268; Rao, M.V.P. Chandra
   Sekhara/0000-0002-6676-0454
CR Acheampong FA, 2020, ENG REP, V2, DOI 10.1002/eng2.12189
   Ahire Vijaya, 2022, Applied Information Processing Systems: Proceedings of ICCET 2021. Advances in Intelligent Systems and Computing (1354), P83, DOI 10.1007/978-981-16-2008-9_8
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Almeida J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156827
   Balahur A., 2013, P 4 WORKSHOP COMPUTA, P120
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Chen LC, 2020, SOFT COMPUT, V24, P8187, DOI 10.1007/s00500-019-04402-8
   D'Souza RS, 2021, MAYO CLIN PROC, V96, P2218, DOI 10.1016/j.mayocp.2021.02.010
   Du YP, 2019, IEEE ACCESS, V7, P39321, DOI 10.1109/ACCESS.2019.2906398
   Ghosh Debraj, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P39, DOI 10.1007/978-981-13-7403-6_5
   Gorodnichenko Y, 2021, EUR ECON REV, V136, DOI 10.1016/j.euroecorev.2021.103772
   Guo CH, 2018, J SYST SCI SYST ENG, V27, P542, DOI 10.1007/s11518-018-5388-2
   Huddar MG, 2021, INT J INTERACT MULTI, V6, P112, DOI 10.9781/ijimai.2020.07.004
   Jabreel M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061123
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Karthik E, 2022, NEURAL PROCESS LETT, V54, P4123, DOI 10.1007/s11063-022-10797-7
   Mao XL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071334
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pathak AR, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107440
   Singh C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083709
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Sudhir P., 2021, Glob. Transit. Proc, V2, P205, DOI [10.1016/j.gltp.2021.08.004, DOI 10.1016/J.GLTP.2021.08.004]
   Taj S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673428
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4
   Zad S, 2021, 2021 IEEE WORLD AI IOT CONGRESS (AIIOT), P255, DOI [10.1109/AIIoT52608.2021.9454192, 10.1109/AIIOT52608.2021.9454192]
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
NR 27
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16314-9
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400010
DA 2024-07-18
ER

PT J
AU Trivedi, A
   Pandey, M
   Ramesh, G
   Chhabra, R
AF Trivedi, Abha
   Pandey, Mayank
   Ramesh, G.
   Chhabra, Rohan
TI An agent based modeling approach to evaluate crowd movement strategies
   and density at bathing areas during Kumbh Mela-2019
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kumbh Mela; Kumbh Mela site; Movement schemes; Bathing procedure; Agent
   based modeling and simulation; AnyLogic
ID SOCIAL FORCE MODEL; EVACUATION; SIMULATION; BEHAVIOR; SAFETY
AB Kumbh-Mela of Prayagraj, India, a festival of faith and belief, is one of the many significant gathering events worldwide. Pilgrims arrive from different places to take a holy bath at the confluence point of 3-rivers the Ganges, Yamuna, and Sarasvati. The police department is assigned a major role of handling and managing the dense traffic of pilgrims in this event to avoid unwanted situations. The primary surveillance points are the intersecting junctions and bathing zones. In addition, the authorities make crowd movement plans with different route diversion schemes and sets bathing time intervals to maintain crowd density at the Kumbh Mela site. Significantly, we must test these crowd management plans for a realistic assessment of population count, density maintenance, and time management. In this paper, we have created a model utilizing a micro-modeling agent-based approach that incorporates the virtual environment of the site. We have used AnyLogic, a ABMS tool, to incorporate social forces and stochastic behavior among the synthetic agents. The model simulates different crowd movement plans according to real behavioral scenarios. In the simulation, we have considered the whole bathing procedure as a halt time in the area. We have utilized our model to evaluate the time consumed by the pilgrims to reach "Ghat". Also, to count the number of pilgrims that took a bath in 12 hours on different time intervals set for bathing. The significance of performing these evaluations is to assess the effect on density at the site during the whole arrival, bathing, and departure process.
C1 [Trivedi, Abha; Pandey, Mayank; Chhabra, Rohan] Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj, Uttar Pradesh, India.
   [Ramesh, G.] Indian Inst Management Bangalore IIMB, Master Management Studies Publ Policy, Bengaluru, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Indian Institute of Management (IIM System);
   Indian Institute of Management Bangalore
RP Trivedi, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj, Uttar Pradesh, India.
EM abhatrivedidas@gmail.com
FU Kumbh Mela police authorities, Prayagraj
FX Ms. Abha Trivedi (Research Scholar, GIS Cell, Motilal Nehru National
   Institute of Technology Allahabad, Prayagraj) received a partial
   financial support from Kumbh Mela police authorities, Prayagraj. Dr.
   Mayank Pandey (Associate Professor, Computer Science, and Engineering
   Department, Motilal Nehru National Institute of Technology Allahabad,
   Prayagraj) declares no conflicts of interest. The remaining authors have
   no conflicts of interest to declare
CR Al-Kodmany K, 2011, J ARCHIT PLAN RES, V28, P28
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Antonini G, 2005, DISCRETE CHOICE MODE, DOI [10.5075/epfl-thesis-3382, DOI 10.5075/EPFL-THESIS-3382]
   Luna-Ramirez WA, 2018, COMPUTERS, V7, DOI 10.3390/computers7020024
   Axelrod R, 2006, HANDB ECON, V13, P1565
   Bonabeau E, 2002, P NATL ACAD SCI USA, V99, P7280, DOI 10.1073/pnas.082080899
   Cai H., 2014, International Journal of Disaster Resilience in the Built Environment, V5, P362, DOI [10.1108/IJDRBE-06-2012-0014, DOI 10.1108/IJDRBE-06-2012-0014]
   Chen M, 2007, J URBAN PLAN DEV, V133, P30, DOI 10.1061/(ASCE)0733-9488(2007)133:1(30)
   Chen X, 2008, J OPER RES SOC, V59, P25, DOI 10.1057/palgrave.jors.2602321
   Company A, 2018, AN 8 3 UN
   Curtis S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P128, DOI 10.1109/ICCVW.2011.6130234
   Curtis S, 2013, THESIS U N CAROLINA, DOI [10.17615/zbcj-xa48, DOI 10.17615/ZBCJ-XA48]
   Daamen W, 2003, TRANSPORT RES REC, P20, DOI 10.3141/1828-03
   Daamen W, 2012, TRANSPORT RES REC, P69, DOI 10.3141/2316-08
   Dridi M., 2015, Open J. Model. Simul. (OJMSi), V3, P81, DOI DOI 10.4236/OJMSI.2015.33009
   Fruin J.J., 1971, HIGHWAY RES RECORD, V355, P1
   FRUIN JJ, 1993, ENGINEERING FOR CROWD SAFETY, P99
   Gulhare S, 2018, COLLECT DYN, V3, P1, DOI DOI 10.17815/CD.2018.16
   Haghighati R., 2013, JURNAL MEKANIKAL, V36, P2
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P21
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D., 2012, Social Self-Organization: Agent-Based Simulations and Experiments To Study Emergent Social Behavior, P25, DOI [DOI 10.1007/978-3-642-24004-1_2, 10.1007/978-3-642-24004-12, DOI 10.1007/978-3-642-24004-12]
   Helbing D, 2012, EPJ DATA SCI, V1, DOI 10.1140/epjds7
   Ijaz K., 2015, 17 UKSIMAMSS INT C M, P111, DOI [10.1109/UKSim.2015.46, DOI 10.5555/2867552.2868182]
   Illiyas FT, 2013, INT J DISAST RISK RE, V5, P10, DOI 10.1016/j.ijdrr.2013.09.003
   Ilyas Q., 2013, Undefined, V3, P199
   Jha M, 2004, TRANSPORT RES REC, P40
   Johansson F, 2013, MICROSCOPIC MODELING, DOI [10.3384/lic.diva-101085, DOI 10.3384/LIC.DIVA-101085]
   Kasthala S, 2015, 2 WORLD C DIS MAN VI
   KELLEY HH, 1965, J EXP SOC PSYCHOL, V1, P20, DOI 10.1016/0022-1031(65)90035-1
   Kolli S, 2013, P AAMAS, P1203
   Kountouriotis V, 2014, PATTERN RECOGN LETT, V44, P30, DOI 10.1016/j.patrec.2013.10.024
   Lakoba TI, 2005, SIMUL-T SOC MOD SIM, V81, P339, DOI 10.1177/0037549705052772
   Le Bon Gustav, 1895, The crowd: a study of the popular mind, V2nd
   Lee S, 2009, P 2009 INFORMS SIM S, P96
   Macal CM, 2005, PROCEEDINGS OF THE 2005 WINTER SIMULATION CONFERENCE, VOLS 1-4, P2, DOI 10.1109/WSC.2005.1574234
   Mahmood I, 2017, SIGSIM-PADS'17: PROCEEDINGS OF THE 2017 ACM SIGSIM CONFERENCE ON PRINCIPLES OF ADVANCED DISCRETE SIMULATION, P231, DOI 10.1145/3064911.3064924
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Mao Y, 2020, MULTIMED TOOLS APPL, V79, P3077, DOI 10.1007/s11042-018-6069-3
   McPhail C., 2017, MYTH MADDING CROWD, DOI [10.4324/9781315133270, DOI 10.4324/9781315133270]
   Mulyana WW, 2010, P INT C COMP COMM EN, P1, DOI DOI 10.1109/ICCCE.2010.5556818
   Namoun A., 2018, J THEOR APPL INF TEC, V96, P6665
   Premkamal PK, 2020, INT J CLOUD APPL COM, V10, P28, DOI 10.4018/IJCAC.2020010103
   Railsback S. F., 2019, AGENT BASED INDIVIDU
   Rastogi R, 2011, J TRANSP ENG, V137, P687, DOI 10.1061/(ASCE)TE.1943-5436.0000251
   Santos G., 2004, A critical review of emergency evacuation simulation models
   Schadschneider A., 2009, Encyclopedia of complexity and systems science, P3142, DOI [DOI 10.1007/978-0-387-30440-3_187, 10.1007/978-0-387-30440-3_187]
   Shi X., 2015, Proceedings of CICTP, P1081, DOI [10.1061/9780784479292.101, DOI 10.1061/9780784479292.101]
   Shi XM, 2016, ACCIDENT ANAL PREV, V95, P405, DOI 10.1016/j.aap.2015.10.009
   Shiwakoti N, 2016, 38 AUSTR TRANSP RES, V16-18, P1
   Smith ER, 2007, PERS SOC PSYCHOL REV, V11, P87, DOI 10.1177/1088868306294789
   Still GK, 2014, INTRODUCTION TO CROWD SCIENCE, P1, DOI 10.1201/b17097
   Sumam MI, 2013, AGENT BASED EVACUATI, V4
   Trivedi A, 2020, AUTON AGENT MULTI-AG, V34, DOI 10.1007/s10458-020-09454-x
   Vizzari G, 2015, J INTELL TRANSPORT S, V19, P32, DOI 10.1080/15472450.2013.856718
   Vizzari G, 2013, COMPLEX ADAPT SYST M, V1, DOI 10.1186/2194-3206-1-7
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang P, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1605.05146
   Wen KC., 2013, URBAN PLANNING DESIG, V1, P59
   Xi H., 2011, Human-in-the-Loop Simulations, P69, DOI [DOI 10.1007/978-0-85729-883-6_4, 10.1007/978-0-85729-883-6_4]
   Xinni Wang, 2013, International Journal of Digital Content Technology and its Applications, V7, P503, DOI 10.4156/jdcta.vol7.issue8.56
   Yadav P, 2019, TRAFFIC PLAN MANUAL
   Yi S, 2015, IEEE I CONF COMP VIS, P3137, DOI 10.1109/ICCV.2015.359
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zafar M., 2016, Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media, P12, DOI [10.1145/3007120.3007143, DOI 10.1145/3007120.3007143]
   Zou N, 2005, TRANSPORT RES REC, P138, DOI 10.3141/1922-18
NR 68
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18739
EP 18777
DI 10.1007/s11042-023-16267-z
EA JUL 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900004
DA 2024-07-18
ER

PT J
AU Banu, SA
   Al-Alawi, AI
   Padmaa, M
   Priya, PS
   Thanikaiselvan, V
   Amirtharajan, R
AF Banu, S. Aashiq
   Al-Alawi, Adel Ismail
   Padmaa, M.
   Priya, P. Shanmuga
   Thanikaiselvan, V.
   Amirtharajan, Rengarajan
TI Healthcare with datacare-a triangular DNA security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA; DICOM; Chaotic attractors
ID IMAGE; CHAOS; MAP
AB One of the fastest-growing industries in recent years has been e-Healthcare. Many cyberattacks and threats against patient confidentiality exist in electronic health records (EHRs). To shield EHRs from data breaches and to secure the data with integrity, DNA subsequences, SHA-256, and Hyper Chaotic Multi Attractors Chen System (HCMACS) are proposed for effective medical image encryption. A combined HCMACS produces a pseudorandom key sequence to strengthen its resiliency. The two significant advantages of the proposed technique are integrity and robustness, where the secret keys are susceptible to initial states determined by the original image's hash value. Furthermore, the encrypted image is uploaded to a cloud-based service where an authorised user can retrieve the original data. Finally the digital medical images have confidentiality, integrity and availability (CIA). The outcomes of the DNA-based cryptosystem for medical images are validated with several analyses and are efficiently defended against statistical, differential, and chosen-plaintext attacks.
C1 [Banu, S. Aashiq] Koneru Lakshmaiah Educ Fdn, Dept CSE, Hyderabad 500075, Telangana, India.
   [Al-Alawi, Adel Ismail] Univ Bahrain, Coll Business Adm, Dept Management & Mkt, Zallaq, Bahrain.
   [Padmaa, M.] Saranathan Coll Engn, Dept ECE, Thiruchirapalli 620012, India.
   [Priya, P. Shanmuga] Rajalakshmi Engn Coll, Dept Elect & Commun Engn, Chennai 602105, India.
   [Thanikaiselvan, V.] Vellore Inst Technol VIT, Sch Elect Engn, Vellore 632014, India.
   [Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   University of Bahrain; Rajalakshmi Engineering College; Vellore
   Institute of Technology (VIT); VIT Vellore; Shanmugha Arts, Science,
   Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Thanikaiselvan,
   V/0000-0003-2418-5217; , Dr. Aashiq Banu/0000-0002-7708-0307
FU Department of Science amp; Technology, New Delhi
   [SR/FST/ET-I/2018/221(C)]
FX The authors thank the Department of Computer Science Engineering at
   Koneru Lakshmaiah Education Foundation, Hyderabad. Also,& nbsp;thank the
   Department of Science & Technology, New Delhi, for the FIST funding
   (SR/FST/ET-I/2018/221(C)), the Intrusion Detection Lab at the School of
   Electrical & Electronics Engineering, SASTRA Deemed University, for
   providing infrastructural support to carry out this research work.
CR Banu SA, 2021, FRONT INFORM TECH EL, V22, P940, DOI 10.1631/FITEE.2000071
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   [Anonymous], COST DATA BREACH STU
   [Anonymous], 2020, IT SECURITY NEWS ET
   Anthony B, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01596-5
   Aparna H, 2021, J INF SECUR APPL, V63, DOI 10.1016/j.jisa.2021.102972
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dua M, 2020, J AMB INTEL HUM COMP, V11, P3771, DOI 10.1007/s12652-019-01580-z
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   IBM Security, 2020, Cost of a data breach report
   Kalsi S, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0851-z
   Kumar V, 2022, J KING SAUD UNIV-COM, V34, P6453, DOI 10.1016/j.jksuci.2022.01.015
   Lakshmi C, 2021, NEURAL COMPUT APPL, V33, P6671, DOI 10.1007/s00521-020-05447-9
   Li JY, 2022, OPT LASER TECHNOL, V152, DOI 10.1016/j.optlastec.2022.108127
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Lone MA, 2022, OPTIK, V260, DOI 10.1016/j.ijleo.2022.168880
   Mahalingam H, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11081769
   Mahalingam H, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11020457
   Microsoft, UW DEM 1 FULL AUT DN
   Raj V, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01278-8
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Ravichandran D, 2023, WIRELESS PERS COMMUN, V129, P703, DOI 10.1007/s11277-022-10152-y
   Ren HP, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500766
   Rodrigues JJPC, 2018, IEEE ACCESS, V6, P13129, DOI 10.1109/ACCESS.2017.2789329
   Sridevi A, 2022, MULTIMED TOOLS APPL, V81, P16987, DOI 10.1007/s11042-022-12471-5
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Wang WT, 2023, QUANTUM INF PROCESS, V22, DOI 10.1007/s11128-022-03823-z
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Ye GD, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117709
   zettaset, WHY HEALTHC DAT PROT
   Zhang FF, 2021, IEEE MULTIMEDIA, V28, P96, DOI 10.1109/MMUL.2021.3080579
   Zhang YZ, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105542
   Zhao CF, 2020, NONLINEAR DYNAM, V100, P679, DOI 10.1007/s11071-020-05526-5
   Zhao JF, 2023, INFORMATION, V14, DOI 10.3390/info14030150
NR 42
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21153
EP 21170
DI 10.1007/s11042-023-16303-y
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900013
DA 2024-07-18
ER

PT J
AU Zeng, W
   Ma, LM
   Zhang, Y
AF Zeng, Wei
   Ma, Limin
   Zhang, Yu
TI Analysis and classification of gait patterns in osteoarthritic and
   asymptomatic knees using phase space reconstruction, intrinsic
   time-scale decomposition and neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knee Osteoarthritis (OA); Intrinsic Time-Scale Decomposition (ITD);
   Phase Space Reconstruction (PSR); Nonlinear gait dynamics; Neural
   networks
ID FAULT-DIAGNOSIS; MOTOR CONTROL; WALKING; VARIABILITY; PERFORMANCE;
   KINEMATICS; SENSORS; SYSTEM; REPRESENTATION; INDIVIDUALS
AB Artificial intelligence (AI) has gained significant traction in medical applications. This study focuses on knee joint diseases, specifically osteoarthritis (OA) and rheumatoid arthritis, which often lead to pathological gait patterns in patients due to pain and mobility issues. The proposed technique put forth in this research aims to classify gait patterns in kinematic data of osteoarthritic and asymptomatic (AS) knees. Our approach utilizes Phase Space Reconstruction (PSR), Intrinsic Time-Scale Decomposition (ITD), and neural networks to extract features. Knee kinematic data, including translations and rotations, are analyzed using ITD to obtain dominant proper rotation components (PRCs) capturing most of the energy from the signals. The phase space of PRCs is then reconstructed, revealing nonlinear gait dynamics. By employing three-dimensional PSR and Euclidean distance, we extract features that capture the distinctive dynamics of osteoarthritic and AS knee gait patterns. Utilizing neural networks, we model and classify the gait system dynamics. Experimental evaluation on 22 knee OA patients and 28 age-matched AS control individuals demonstrates the effectiveness of our method in distinguishing between the two groups' gait patterns, achieving superior classification accuracies of 92% and 96%, respectively. These results suggest that our approach holds promise for aiding the identification of knee OA in clinical practice, leading to improved quality outcomes. By enabling accurate identification of knee OA in clinical practice, the proposed method has the potential to contribute to improved patient outcomes, such as timely interventions, personalized treatment plans, and enhanced monitoring of disease progression. This, in turn, can lead to better management of knee OA and improved quality outcomes for patients.
C1 [Zeng, Wei] Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Ma, Limin; Zhang, Yu] Guangdong Prov Peoples Hosp, Dept Orthoped, Guangzhou 510080, Peoples R China.
C3 Longyan University; Guangdong Academy of Medical Sciences & Guangdong
   General Hospital
RP Zeng, W (corresponding author), Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.; Ma, LM (corresponding author), Guangdong Prov Peoples Hosp, Dept Orthoped, Guangzhou 510080, Peoples R China.
EM zw0597@126.com; malimin_7@163.com
FU Natural Science Foundation of Fujian Province [2022J011146]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Fujian Province (Grant no. 2022J011146).
CR Alkjaer T, 2015, GAIT POSTURE, V42, P479, DOI 10.1016/j.gaitpost.2015.07.063
   ALTMAN R, 1986, ARTHRITIS RHEUM-US, V29, P1039, DOI 10.1002/art.1780290816
   Ameli S, 2017, PATTERN RECOGN, V63, P246, DOI 10.1016/j.patcog.2016.08.002
   An XL, 2012, J VIB CONTROL, V18, P240, DOI 10.1177/1077546311403185
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Azar AT, 2014, NEURAL COMPUT APPL, V24, P1163, DOI 10.1007/s00521-012-1324-4
   Befrui N, 2018, MED BIOL ENG COMPUT, V56, P1499, DOI 10.1007/s11517-018-1785-4
   Blanco FJ, 2012, NAT REV RHEUMATOL, V8, P130, DOI 10.1038/nrrheum.2012.11
   Boashash B, 2015, PATTERN RECOGN, V48, P616, DOI 10.1016/j.patcog.2014.08.016
   Brooks S, 2002, ANN ROY COLL SURG, V84, P265, DOI 10.1308/003588402320439711
   Cao P, 2018, PATTERN RECOGN, V79, P195, DOI 10.1016/j.patcog.2018.01.028
   Chan Sophal, 2022, International Journal of Computers and Applications, V44, P571, DOI 10.1080/1206212X.2020.1838145
   Chen BJ, 2011, MEAS SCI TECHNOL, V22, DOI 10.1088/0957-0233/22/5/055704
   Chen HC, 2014, IEEE T BIO-MED ENG, V61, P171, DOI 10.1109/TBME.2013.2278780
   Chen MY, 2014, BIOMED SIGNAL PROCES, V11, P10, DOI 10.1016/j.bspc.2014.02.002
   Debi R, 2017, ORTHOP TRAUMATOL-SUR, V103, P603, DOI 10.1016/j.otsr.2017.02.006
   Duan JM, 2017, PATTERN RECOGN, V72, P158, DOI 10.1016/j.patcog.2017.07.004
   Esrafilian A, 2013, RHEUMATOL INT, V33, P1753, DOI 10.1007/s00296-012-2639-2
   Farrell JA, 1998, IEEE T NEURAL NETWOR, V9, P1008, DOI 10.1109/72.712182
   Feng ZP, 2016, MECH SYST SIGNAL PR, V72-73, P223, DOI 10.1016/j.ymssp.2015.11.024
   Frei MG, 2007, P R SOC A, V463, P321, DOI 10.1098/rspa.2006.1761
   Gustafson JA, 2015, CLIN BIOMECH, V30, P475, DOI 10.1016/j.clinbiomech.2015.03.007
   Hada S, 2017, ARTHRITIS RES THER, V19, DOI 10.1186/s13075-017-1411-0
   Halim HNA., 2022, J HUM CENTERED TECHN, V1, P33, DOI [10.11113/humentech.v1n2.19, DOI 10.11113/HUMENTECH.V1N2.19]
   Huang BQ, 2013, J COMPUT APPL MATH, V240, P174, DOI 10.1016/j.cam.2012.07.012
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Iijima H, 2019, J BIOMECH, V87, P127, DOI 10.1016/j.jbiomech.2019.02.027
   Jia J, 2017, BIOMED SIGNAL PROCES, V38, P148, DOI 10.1016/j.bspc.2017.05.015
   Karg M, 2015, IEEE T NEUR SYS REH, V23, P319, DOI 10.1109/TNSRE.2014.2362862
   KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494
   Kobsar D, 2019, GAIT POSTURE, V72, P82, DOI 10.1016/j.gaitpost.2019.05.020
   Kobsar D, 2016, J BIOMECH, V49, P3977, DOI 10.1016/j.jbiomech.2016.11.047
   Kotti M, 2017, MED ENG PHYS, V43, P19, DOI 10.1016/j.medengphy.2017.02.004
   Kour N, 2021, ARCH COMPUT METHOD E, V28, P345, DOI 10.1007/s11831-019-09379-z
   Kubkaddi S., 2017, IJSEAT, V5, P259
   Kwon SB, 2019, OSTEOARTHR CARTILAGE, V27, P1755, DOI 10.1016/j.joca.2019.07.014
   Kwon S. B., 2020, IEEE Access, V8, DOI [10.1109/ACCESS.2020.3006335, DOI 10.1109/ACCESS.2020.3006335]
   Lee SH, 2014, COMPUT METH PROG BIO, V116, P10, DOI 10.1016/j.cmpb.2014.04.012
   Li YB, 2015, MECH MACH THEORY, V94, P9, DOI 10.1016/j.mechmachtheory.2015.08.001
   Lundberg HJ, 2012, J BIOMECH, V45, P990, DOI 10.1016/j.jbiomech.2012.01.015
   Martinez-Hernandez U, 2018, NEURAL NETWORKS, V102, P107, DOI 10.1016/j.neunet.2018.02.017
   McCarthy I, 2013, BMC MUSCULOSKEL DIS, V14, DOI 10.1186/1471-2474-14-169
   Merigó JM, 2011, EXPERT SYST APPL, V38, P7603, DOI 10.1016/j.eswa.2010.12.103
   Mezghani N, 2008, IEEE T BIO-MED ENG, V55, P1230, DOI 10.1109/TBME.2007.905388
   Michael S, 2005, APPL NONLINEAR TIME, V52
   Middleton A, 2015, J AGING PHYS ACTIV, V23, P314, DOI 10.1123/japa.2013-0236
   Mills K, 2013, ARTHRIT CARE RES, V65, P1643, DOI 10.1002/acr.22015
   Orellana JN, 2018, BIOMED SIGNAL PROCES, V39, P431, DOI 10.1016/j.bspc.2017.08.017
   Ornetti P, 2010, JOINT BONE SPINE, V77, P421, DOI 10.1016/j.jbspin.2009.12.009
   Park C, 2011, NEUROCOMPUTING, V74, P867, DOI 10.1016/j.neucom.2010.07.030
   Park HJ, 2013, EUR J RADIOL, V82, P112, DOI 10.1016/j.ejrad.2012.02.023
   Peixoto JG, 2019, AGING CLIN EXP RES, V31, P67, DOI 10.1007/s40520-018-0942-9
   Petersen ET, 2022, OSTEOARTHR CARTILAGE, V30, P249, DOI 10.1016/j.joca.2021.10.011
   Pfeiffer SJ, 2021, OSTEOARTHR CARTILAGE, V29, pS187
   Phinyomark A, 2018, J MED BIOL ENG, V38, P244, DOI 10.1007/s40846-017-0297-2
   Procházka A, 2015, NEURAL COMPUT APPL, V26, P1621, DOI 10.1007/s00521-015-1827-x
   Riad R, 2018, COMPUT ELECTR ENG, V68, P181, DOI 10.1016/j.compeleceng.2018.04.004
   Segal NA, 2015, PHYSICIAN SPORTSMED, V43, P213, DOI 10.1080/00913847.2015.1074854
   Sen Köktas N, 2010, PATTERN RECOGN LETT, V31, P898, DOI 10.1016/j.patrec.2010.01.003
   Sharma S, 2021, BIOELECTRONICS MED D, P187
   Som A, 2016, IEEE ENG MED BIO, P3096, DOI 10.1109/EMBC.2016.7591384
   Srivastava S., 2021, CONCEPTS REAL TIME A
   Tadano S, 2016, J BIOMECH, V49, P684, DOI 10.1016/j.jbiomech.2016.01.017
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Tanimoto K, 2017, GAIT POSTURE, V57, P236, DOI 10.1016/j.gaitpost.2017.06.017
   Tarnita D, 2017, P ROMANIAN ACAD A, V18, P353
   Tawy GF, 2018, GAIT POSTURE, V59, P272, DOI 10.1016/j.gaitpost.2017.08.015
   Turcot K, 2008, IEEE T BIO-MED ENG, V55, P1415, DOI 10.1109/TBME.2007.912428
   van Egmond N, 2017, KNEE SURG SPORT TR A, V25, P2904, DOI 10.1007/s00167-016-4045-x
   Venkataraman V, 2016, IEEE T PATTERN ANAL, V38, P2531, DOI 10.1109/TPAMI.2016.2533388
   Wang C, 2006, IEEE T NEURAL NETWOR, V17, P130, DOI 10.1109/TNN.2005.860843
   Wang C., 2009, Deterministic learning theory for identification, recognition, and control
   Wang C, 2007, IEEE T NEURAL NETWOR, V18, P617, DOI 10.1109/TNN.2006.889496
   Wang C, 2009, INT J BIFURCAT CHAOS, V19, P1307, DOI 10.1142/S0218127409023640
   Wong DWC, 2020, CLIN BIOMECH, V72, P37, DOI 10.1016/j.clinbiomech.2019.11.023
   Xing ZQ, 2017, J MECH SCI TECHNOL, V31, P545, DOI 10.1007/s12206-017-0107-3
   Xu BB, 2013, IEEE ENG MED BIO, P3274, DOI 10.1109/EMBC.2013.6610240
   Yang JH, 2020, ANN REHABIL MED-ARM, V44, P415, DOI 10.5535/arm.20071
   Yousef R, 2022, MULTIMEDIA SYST, V28, P881, DOI 10.1007/s00530-021-00884-5
   Zhang Y, 2015, GAIT POSTURE, V41, P763, DOI 10.1016/j.gaitpost.2015.01.020
   Zhou DG, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00411-5
NR 82
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21107
EP 21131
DI 10.1007/s11042-023-16322-9
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900003
DA 2024-07-18
ER

PT J
AU Yadav, AK
   Ranvijay
   Yadav, RS
   Maurya, AK
AF Yadav, Avaneesh Kumar
   Ranvijay, Rama Shankar
   Yadav, Rama Shankar
   Maurya, Ashish Kumar
TI Graph-based extractive text summarization based on single document
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text summarization; Extractive text summarization; Lemmatization;
   Textual graph; ROUGE
AB Day by day, the amount of online and offline text data is growing tremendously from various sources like legal documents, medical documents, news articles, etc. Manual text summarization of large documents is unfeasible and costly because it takes much time and requires more effort. As a consequence, various graph-based text summarization techniques have been designed which provide thoroughly and well-prepared summaries of documents. The problems issues that exist in these techniques are redundancy of data, loss of information and readability. To overcome these problems, we have proposed a textual graph-based extractive text summarization technique called TGETS, for extracting essential information from a single document. In the proposed approach, a graph's node is denoted as group of sentences in the document and an edge of the graph is represented as an association between two sentences. The summary generation is based on the sum of sentence weight and the average weight of the textual graph. The performance of proposed approach is evaluated on the BBC news articles dataset through the ROUGE-metric (R-1 and R-2). The proposed approach in the range of 100-200 words length summary offers better scores of 19.88%, 38.76%, and 30.73% for R-1 under precision, recall and F-1-score with respect to the existing PageRank (PR) method. Similarly, for R-2, the proposed approach exceeds by 32%, 26.99%, and 29.01% for precision, recall, and F-1-score with respect to existing PageRank (PR) method.
C1 [Yadav, Avaneesh Kumar; Ranvijay, Rama Shankar; Yadav, Rama Shankar; Maurya, Ashish Kumar] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Yadav, AK (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
EM avaneesh17@mnnit.ac.in; ranvijay@mnnit.ac.in; rsy@mnnit.ac.in;
   ashishmaurya@mnnit.ac.in
CR Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Alami N, 2021, MULTIMED TOOLS APPL, V80, P19567, DOI 10.1007/s11042-021-10613-9
   [Anonymous], 2015, P 2015 C EMP METH NA
   Awan MN, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101116
   Azadani MN, 2018, J BIOMED INFORM, V84, P42, DOI 10.1016/j.jbi.2018.06.005
   Bahloul B, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12476
   Belwal RC, 2021, J AMB INTEL HUM COMP, V12, P8975, DOI 10.1007/s12652-020-02591-x
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Canhasi E, 2014, EXPERT SYST APPL, V41, P535, DOI 10.1016/j.eswa.2013.07.079
   Chen YN, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P940
   Demange M, 2022, THEOR COMPUT SCI, V914, P47, DOI 10.1016/j.tcs.2022.02.012
   El-Kassas WS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102264
   Elbarougy R, 2020, EGYPT INFORM J, V21, P73, DOI 10.1016/j.eij.2019.11.001
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fang CJ, 2017, EXPERT SYST APPL, V72, P189, DOI 10.1016/j.eswa.2016.12.021
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Gambhir M, 2022, MULTIMED TOOLS APPL, V81, P20829, DOI 10.1007/s11042-022-12729-y
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gupta VK, 2012, 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT HUMAN COMPUTER INTERACTION (IHCI 2012)
   Hachey B, 2005, P DOC UND C DUC VANC
   Jaradat YA, 2016, INT CONF INFORM COMM, P85, DOI 10.1109/IACS.2016.7476091
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Knor M, 2022, DISCRETE APPL MATH, V319, P454, DOI 10.1016/j.dam.2021.02.020
   Korenius T., 2004, P 13 ACM INT C INF K, P625, DOI [DOI 10.1145/1031171.1031285, 10.1145/1031171.1031285]
   Krahmer Emiel., 2008, P ANN M ASS COMPUTAT, P193, DOI DOI 10.3115/1557690.1557745
   Lloret E, 2012, ARTIF INTELL REV, V37, P1, DOI 10.1007/s10462-011-9216-z
   Mahalleh Elham Rahimzadeh, 2022, International Journal of Information Technology, P2963, DOI 10.1007/s41870-022-01049-x
   Mallick C, 2019, ADV INTELL SYST, V758, P137, DOI 10.1007/978-981-13-0514-6_14
   Medelyan O., 2007, P 45 ANN M ACL STUDE, P85
   Miao LH, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102123
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Mihalcea R, 2005, COMP VOL P C INCL PO
   Moawad IF, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES'2012), P132, DOI 10.1109/ICCES.2012.6408498
   Moratanch N, 2023, MULTIMED TOOLS APPL, V82, P4569, DOI 10.1007/s11042-022-13299-9
   Mutlu B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102359
   Nallapati R, 2016, PREPRINT
   Nandhini K, 2013, EGYPT INFORM J, V14, P195, DOI 10.1016/j.eij.2013.09.001
   Nasar Z, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102088
   Plisson Jol., 2004, Proceedings of IS, Vvolume 3, P83
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Roul RK, 2021, SOFT COMPUT, V25, P1113, DOI 10.1007/s00500-020-05207-w
   Sahoo D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P873, DOI 10.1109/CCAA.2016.7813838
   Salton G, 1997, INFORM PROCESS MANAG, V33, P193, DOI 10.1016/S0306-4573(96)00062-3
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Srivastava AK, 2021, MULTIMED TOOLS APPL, V80, P11273, DOI 10.1007/s11042-020-10176-1
   Srivastava R, 2022, KNOWL-BASED SYST, V246, DOI 10.1016/j.knosys.2022.108636
   Steinberger J, 2009, LECT NOTES ARTIF INT, V5729, P77, DOI 10.1007/978-3-642-04208-9_14
   Tomer M, 2022, J KING SAUD UNIV-COM, V34, P6057, DOI 10.1016/j.jksuci.2021.04.004
   Uçkan T, 2020, EGYPT INFORM J, V21, P145, DOI 10.1016/j.eij.2019.12.002
   Vaissnave V, 2023, MULTIMED TOOLS APPL, V82, P17175, DOI 10.1007/s11042-022-14171-6
   Wang D., 2020, PREPRINT
   Xia T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10145011
   Yadav A. K., 2021, Ingenierie des Systemes d'Information, V26
   Yadav AK, 2016, INDIAN J SCI TECHNOL, V9, DOI [10.17485/ijst/2016/v9i44/105143, DOI 10.17485/ijst/2016/v9i44/105143]
   Yadav AK, 2023, MULTIMED TOOLS APPL, V82, P29135, DOI 10.1007/s11042-023-14613-9
NR 55
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18987
EP 19013
DI 10.1007/s11042-023-16199-8
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900002
DA 2024-07-18
ER

PT J
AU Kumari, N
   Bhatia, R
AF Kumari, Naveen
   Bhatia, Rekha
TI Saliency map and deep learning based efficient facial emotion
   recognition technique for facial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Contrast-limited adaptive histogram equalization; Generative adversarial
   network (GAN); Saliency map; Bilateral filter; Deep convolutional neural
   network
ID EXPRESSION RECOGNITION
AB Detecting and recognizing facial emotions from human facial movements is one of the most important research area in human-computer interaction. In this paper, a saliency map and deep learning-based facial emotion recognition technique for facial images is proposed. The proposed model, contrast-limited adaptive histogram equalization (CLAHE), generative adversarial network (GAN), saliency map, and bilateral filter are used for data pre-processing. A deep convolutional neural network is trained using the Nadam optimizer to recognize facial emotion. After this, the proposed technique is tested on the JAFFE, CK+, and FER+ benchmark datasets. The maximum accuracies achieved with the proposed technique are 97.7%, 99.9%, and 84.2% for the JAFFE, CK+, and FER+ datasets, respectively.
C1 [Kumari, Naveen; Bhatia, Rekha] Punjabi Univ, Dept Comp Sci & Engn, Patiala, India.
C3 Punjabi University
RP Kumari, N (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala, India.
EM naveen_rcitm@pbi.ac.in; rb@pbi.ac.in
RI Kumari, Naveen/GPX-1688-2022
OI Kumari, Naveen/0000-0003-4231-0050
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Barsoum E., 2016, Training Deep Networks for Facial Expression Recognition with Crowd-Sourced Label Distribution
   Basu A, 2015, ANNU IEEE IND CONF
   Bhardwaj T., 2022, Artificial Intelligence in Healthcare, P133, DOI [10.1007/978-981-16-6265-29, DOI 10.1007/978-981-16-6265-29, 10.1007/978-981-16-6265-2_9, DOI 10.1007/978-981-16-6265-2_9]
   Bhaskar S, 2023, MULTIMED TOOLS APPL, V82, P5455, DOI 10.1007/s11042-022-12796-1
   Chen LF, 2018, INFORM SCIENCES, V428, P49, DOI 10.1016/j.ins.2017.10.044
   Cheng S, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420560030
   Choi DY, 2020, IEEE ACCESS, V8, P121549, DOI 10.1109/ACCESS.2020.3006958
   Deng J, 2019, IEEE ACCESS, V7, P9848, DOI 10.1109/ACCESS.2019.2891668
   Dharanya V, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103110
   Dozat T., 2016, INCORPORATING NESTER
   Fei ZX, 2020, NEUROCOMPUTING, V388, P212, DOI 10.1016/j.neucom.2020.01.034
   Furlong LS, 2021, J AFFECT DISORDERS, V279, P518, DOI 10.1016/j.jad.2020.10.038
   Gan YL, 2019, PATTERN RECOGN LETT, V125, P105, DOI 10.1016/j.patrec.2019.04.002
   Gonog L, 2019, C IND ELECT APPL, P505, DOI [10.1109/ICIEA.2019.8833686, 10.1109/iciea.2019.8833686]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hajarolasvadi N, 2020, IET IMAGE PROCESS, V14, P3536, DOI 10.1049/iet-ipr.2019.1566
   Hanafi WNW, 2021, INT J INNOV SUSTAIN, V15, P126, DOI 10.1504/IJISD.2021.111553
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Iyer A, 2023, MULTIMED TOOLS APPL, V82, P4883, DOI 10.1007/s11042-022-12310-7
   Jumani SZ., 2019, INDIAN J SCI TECHNOL, V12, P1, DOI [10.17485/ijst/2019/v12i24/145, DOI 10.17485/ijst/2019/v12i24/145093, 10.17485/ijst/2019/v12i24/145093]
   Khattak A, 2022, MULTIMED TOOLS APPL, V81, P1649, DOI 10.1007/s11042-021-11298-w
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Kingma D. P., 2014, arXiv
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Kumari N., 2020, DECISION ANALYTICS A, P157, DOI [10.1007/978-981-15-3643-4_11, DOI 10.1007/978-981-15-3643-4_11]
   Kumari N, 2023, INT J SYST ASSUR ENG, V14, P1421, DOI 10.1007/s13198-023-01945-w
   Kumari N, 2022, SOFT COMPUT, V26, P7817, DOI 10.1007/s00500-022-06804-7
   Kumari N, 2021, INT J INTELL ENG INF, V9, P59, DOI 10.1504/IJIEI.2021.116088
   Lakshmi D, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103834
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database
   [马玉环 Ma Yuhuan], 2020, [重庆邮电大学学报. 自然科学版, Journal of Chongqing University of Posts and Telecommunications. Natural Science Edition], V32, P874
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Muhammad G, 2021, IEEE INTERNET THINGS, V8, P16894, DOI 10.1109/JIOT.2021.3058587
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Staff AI, 2022, EUR CHILD ADOLES PSY, V31, P715, DOI 10.1007/s00787-020-01709-y
   Sun Z, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109157
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang JH, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/2689029
   Wang LL., 2018, PROGR LASER OPTOELEC, V55, P204
   Wang WX, 2019, Arxiv, DOI arXiv:1907.10838
   Wei QL, 2021, IEEE ACCESS, V9, P76224, DOI 10.1109/ACCESS.2021.3082694
   Xinyue Zhu, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P349, DOI 10.1007/978-3-319-93040-4_28
   [徐琳琳 Xu Linlin], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P227
   Zhang M, 2009, THESIS, DOI [10.31390/gradschool_theses.1912, DOI 10.31390/GRADSCHOOL_THESES.1912]
   Zhang ZL, 2020, NEUROCOMPUTING, V409, P341, DOI 10.1016/j.neucom.2020.05.081
NR 55
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 18
PY 2023
DI 10.1007/s11042-023-16220-0
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8MO0
UT WOS:001032703400006
DA 2024-07-18
ER

PT J
AU Duan, JW
   Xie, F
   Huang, NY
   Luo, ND
   Guan, ZY
   Zhao, W
   Gao, G
AF Duan, Junwei
   Xie, Fei
   Huang, Ningyuan
   Luo, Ningdi
   Guan, Ziyu
   Zhao, Wei
   Gao, Gang
TI An EEG abnormality detection algorithm based on graphic attention
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram; Graph attention network; Long short-term memory
ID SIGNALS
AB The incidence of brain diseases has increased yearly, threatening human life and health seriously. The Electroencephalogram (EEG) has been playing an important role in clinical practice for diagnosing brain diseases. However, due to the interference of noise and the limitations of manual observation, experts need to spend a lot of time and energy on EEG interpretation, and also is affected by subjective factors, which is prone to misjudgment. Therefore, the establishment of EEG-assisted diagnosis system is of great significance for the clinical diagnosis of brain diseases. With the application of artificial intelligence in EEG auxiliary system, researchers have proposed a series of EEG automatic analysis and anomaly detection algorithms based on deep learning. However, the existing algorithms still have some shortcomings such as inadequate extraction of potential spatio-temporal features in EEG signals. In this paper, the method based on GATs-LSTM is proposed. The comparative analysis of the final experiment shows that, It has demonstrated superior performance on the benchmark dataset with sensitive and specificity as 99.21%, 99.73% and 94.15%, 95.67%. The proposed work shows great results on the benchmark datasets and a big potential for clinics as a support system with medical experts monitoring the patients.
C1 [Duan, Junwei; Huang, Ningyuan; Guan, Ziyu] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
   [Xie, Fei] Xidian Univ, Frontier Cross Res Inst, Xian, Peoples R China.
   [Xie, Fei] Xijing Univ, Key Lab Human Machine Integrat & Control Technol I, Xian 710123, Peoples R China.
   [Luo, Ningdi] Shanghai Jiao Tong Univ, Ruijin Hosp, Inst Neurol, Sch Med,Dept Neurol, Shanghai, Peoples R China.
   [Zhao, Wei] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
   [Gao, Gang] Shanghai Yiran Hlth Consulting Co Ltd, Shanghai, Peoples R China.
C3 Northwest University Xi'an; Xidian University; Xijing University;
   Shanghai Jiao Tong University; Xidian University
RP Guan, ZY (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
EM ziyuguan@nwu.edu.cn
FU National Natural Science Foundation of China [61973250, 82150301,
   61973249, 62002271, 61902296, 62073218, 62133012, 62273232, 62273231,
   62003279, 61936006, 62073255]; Innovation Capability Support Program of
   Shaanxi [2021TD-05]; Key Research and Development Program of Shaanxi
   [2020ZDLGY04-07, 2021ZDLGY02-06, 2021GY-077]; Young science and
   technology nova of Shaanxi Province [2022KJXX-73, 2023KJXX-136];
   National Defense Science and Technology Key Laboratory Fund Project
   [2022YFB4300700, XXJS202242]; National Key R amp; D program of China
   [2022KXJ-169]; Shaanxi Association for Science and Technology Young
   Talent Lifting Program; Qinchuangyuan Scientist + Engineer; 
   [6142101210202];  [2021QCYRC4-49]
FX This work was partially supported by National Natural Science Foundation
   of China under grant agreements Nos. 61973250, 82150301, 61973249,
   62002271, 61902296, 62073218, 62133012, 62273232, 62273231, 62003279,
   61936006, and 62073255. The Innovation Capability Support Program of
   Shaanxi under Grant 2021TD-05. The Key Research and Development Program
   of Shaanxi under Grant 2020ZDLGY04-07, 2021ZDLGY02-06 and 2021GY-077,
   Young science and technology nova of Shaanxi Province: 2022KJXX-73,
   2023KJXX-136. Qin Chuangyuan project 2021QCYRC4-49, National Defense
   Science and Technology Key Laboratory Fund Project No. 6142101210202,
   Qinchuangyuan Scientist + Engineer No. 2022KXJ-169, National Key R & D
   program of China (No. 2022YFB4300700), Shaanxi Association for Science
   and Technology Young Talent Lifting Program (No.XXJS202242).
CR Acharya UR, 2009, J MECH MED BIOL, V9, P539, DOI 10.1142/S0219519409003152
   Alickovic E, 2018, BIOMED SIGNAL PROCES, V39, P94, DOI 10.1016/j.bspc.2017.07.022
   Bhattacharya A, 2022, INT J NEURAL SYST, V32, DOI 10.1142/S0129065721500581
   Chen XY, 2020, FUTURE GENER COMP SY, V109, P188, DOI 10.1016/j.future.2020.03.019
   Ein Shoka Athar A, 2021, Brain Inform, V8, P1, DOI 10.1186/s40708-021-00123-7
   Gao ZK, 2021, COGN NEURODYNAMICS, V15, P369, DOI 10.1007/s11571-020-09626-1
   Gong YZ, 2020, ANAL QUALITY LIFE IT
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hui X, 2020, ACTA PHYS SIN-CH ED
   Jiao ZC, 2018, PATTERN RECOGN, V76, P582, DOI 10.1016/j.patcog.2017.12.002
   Kalatzis I, 2004, COMPUT METH PROG BIO, V75, P11, DOI 10.1016/j.cmpb.2003.09.003
   Knopman DS, 2021, NAT REV DIS PRIMERS, V7, DOI 10.1038/s41572-021-00269-y
   Kumar JS, 2012, PROCEDIA ENGINEER, V38, P2525, DOI 10.1016/j.proeng.2012.06.298
   Lodder SS, 2013, CLIN NEUROPHYSIOL, V124, P228, DOI 10.1016/j.clinph.2012.07.007
   Lun X, 2020, ARXIV
   Maiorana E, 2020, NEUROCOMPUTING, V410, P374, DOI 10.1016/j.neucom.2020.06.009
   Milosavljevic A, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9010024
   MuMing P, 2019, B CHIN ACAD SCI, V34
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Narayanan SJ., 2020, DEEP LEARNING ALGORI, P263, DOI [10.1007/978-3-030-31760-7_9, DOI 10.1007/978-3-030-31760-7_9]
   Nsugbe E, 2021, IET CYBER-SYST ROBOT, V3, P77, DOI 10.1049/csy2.12009
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Sanei S, 2013, EEG Signal Processing
   Shoeb A.H., 2010, P 27 INT C MACH LEAR
   Shoeibi A, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113788
   Singh K, 2022, COMPLEX INTELL SYST, V8, P2405, DOI 10.1007/s40747-021-00627-z
   Spivak D I, 2022, ARXIV
   Xu MY, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107390
   Yao X., 2019, IEEE Trans Biomed Eng, V9, P31, DOI [10.48550/arXiv.1906.02745, DOI 10.48550/ARXIV.1906.02745]
   Zhang DL, 2020, IEEE T CYBERNETICS, V50, P3033, DOI 10.1109/TCYB.2019.2905157
   Zhao XF, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103338
NR 31
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17941
EP 17960
DI 10.1007/s11042-023-16280-2
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100008
DA 2024-07-18
ER

PT J
AU Liu, JJ
   Feng, ML
   Gu, DZ
   Zeng, XY
   Liu, WQ
   Xiu, XC
AF Liu, Jingjing
   Feng, Manlong
   Gu, Dongzhou
   Zeng, Xiaoyang
   Liu, Wanquan
   Xiu, Xianchao
TI Moving object detection in gigapixel-level videos using manifold sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gigapixel-level videos; Manifold sparse representation (MSR); Moving
   object detection; Optimization algorithm
AB Moving object detection (MOD) is one of the most important and challenging tasks in analyzing videos. Recently, emerging gigapixel-level videos have attracted considerable attention due to its large field of view and high spatial resolution. So far, there is not much research on moving object detection in the field of gigapixel-level videos. To detect moving objects in gigapixel-level videos, we propose a novel manifold sparse representation (MSR) method for detecting moving objects in gigapixel-level videos. The innovation of this method lies in introducing sparse representation to promote global structure and utilizing manifold learning to retain the local structure of moving objects. Then, to solve the explicit solutions of this problem, an efficient optimization scheme based on the manifold alternating direction method of multipliers (MADMM) is developed. Finally, the extensive experiments on three challenging benchmark MOD datasets, three samples from the gigapixel-level PANDA dataset (gigaPixel-level humAN-centric viDeo dAtaset), and one real wide area video dataset are executed to demonstrate the superiority of the proposed MSR. In particular, the detection performance on PANDA is improved by an average of 5%, which suggests that the proposed method is promising for gigapixel-level videos.
C1 [Liu, Jingjing; Feng, Manlong] Shanghai Univ, Sch Microelect, Shanghai Key Lab Chips & Syst Intelligent Connecte, Shanghai, Peoples R China.
   [Gu, Dongzhou; Xiu, Xianchao] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
   [Zeng, Xiaoyang] Fudan Univ, Sch Microelect, State Key Lab Integrated Chips & Syst, Shanghai, Peoples R China.
   [Liu, Wanquan] Sun Yat sen Univ, Sch Intelligent Syst Engn, Guangzhou, Peoples R China.
C3 Shanghai University; Shanghai University; Fudan University; Sun Yat Sen
   University
RP Xiu, XC (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
EM jjliu@shu.edu.cn; emxlight22@shu.edu.cn; gduz678@shu.edu.cn;
   xyzeng@fudan.edu.cn; liuwq63@mail.sysu.edu.cn; xcxiu@shu.edu.cn
RI li, rui/JVM-8999-2024; chen, huan/KEC-2019-2024; zheng,
   yan/JKJ-3632-2023; Yang, Mei/JNS-2225-2023; Li, Fan/KBB-8931-2024; feng,
   feng/KBR-1814-2024; Chen, Xiao/KBD-1464-2024; wang, xi/JNT-5162-2023;
   xiao, wei/KCK-6954-2024; ZHENG, YI/KAM-6536-2024; yang,
   zhou/KBB-6972-2024; LI, LI/KCJ-5600-2024; fang, yu/KCK-2014-2024; LI,
   YUN/JTV-7108-2023; LI, LIXIN/KFS-0074-2024; guo, ppdop/KAL-9865-2024;
   Zhang, Bo/JVD-9890-2024; Li, Xinyue/JVN-4601-2024; liu,
   feng/KCL-0778-2024; Zhang, yuxuan/JXM-9935-2024; Liu, qi/JZT-5038-2024;
   yang, kun/JGM-4169-2023; Li, Kun/JLL-6505-2023; wang,
   wang/JQW-3034-2023; Lin, Lin/JTU-1595-2023; Wang, Xintong/JJE-1189-2023;
   zhang, hao/JOJ-7093-2023; Jing, Jing/JSK-6237-2023; chen,
   gang/JRX-1197-2023; Chen, Chao/JHS-6563-2023; yang,
   yunfeng/KHT-9566-2024; Liu, yuqing/KEI-3260-2024; li,
   mengyang/JWO-9551-2024; zhang, can/KHC-5357-2024; qin,
   cheng/KHC-3344-2024; Liu, Zhe/KEJ-5299-2024; yang, le/KFB-5420-2024; Li,
   Jiawei/JOJ-9277-2023; Wang, Zejun/KBB-8454-2024
OI Li, Kun/0000-0002-3638-2974; Xiu, Xianchao/0000-0002-3374-7413
FU National Natural Science Foundation of China [62204044, 12001019]; State
   Key Laboratory of ASIC and System [2021KF009]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 62204044 and Grant 12001019, and
   in part by the State Key Laboratory of ASIC and System under Grant
   2021KF009.
CR Belkin M, 2002, ADV NEUR IN, V14, P585
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Brunton SL, 2022, DATA DRIVEN SCI ENG, DOI [10.1080/00107514.2019.1665103, DOI 10.1080/00107514.2019.1665103]
   Camplani M, 2017, LECT NOTES COMPUT SC, V10590, P219, DOI 10.1007/978-3-319-70742-6_21
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Chen YK, 2023, IEEE T PATTERN ANAL, V45, P2367, DOI 10.1109/TPAMI.2022.3166905
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Ding J, 2022, IEEE T PATTERN ANAL, V44, P7778, DOI 10.1109/TPAMI.2021.3117983
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289
   Jenatton R, 2011, J MACH LEARN RES, V12, P2297
   JIA K, 2012, EUR C COMP VIS ECCV, P331
   Liu JJ, 2021, NEUROCOMPUTING, V458, P112, DOI 10.1016/j.neucom.2021.06.008
   Liu JJ, 2019, IEEE ACCESS, V7, P112939, DOI 10.1109/ACCESS.2019.2935235
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Sobral A, 2016, HANDBOOK OF ROBUST LOW-RANK AND SPARSE MATRIX DECOMPOSITION: APPLICATIONS IN IMAGE AND VIDEO PROCESSING
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wang XY, 2020, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR42600.2020.00333
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang YM, 2020, NEUROCOMPUTING, V388, P202, DOI 10.1016/j.neucom.2020.01.039
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099
   Xu YC, 2021, IEEE T PATTERN ANAL, V43, P1452, DOI [10.1109/TGRS.2020.3026387, 10.1109/TPAMI.2020.2974745]
   Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840
   Yang LL, 2017, IEEE J-STSP, V11, P1072, DOI 10.1109/JSTSP.2017.2743683
   Yuan X, 2017, 2017 IEEE INT C COMP, P1, DOI [10.1109/ICCPHOT.2017.7951481, DOI 10.1109/ICCPHOT.2017.7951481]
   Zhang JP, 2022, IEEE T PATTERN ANAL, V44, P5185, DOI 10.1109/TPAMI.2021.3066696
   Zhang JP, 2020, IEEE T GEOSCI REMOTE, V58, P2659, DOI 10.1109/TGRS.2019.2953181
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 42
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18381
EP 18405
DI 10.1007/s11042-023-15860-6
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100005
DA 2024-07-18
ER

PT J
AU Lyko, T
   Broadbent, M
   Race, N
   Nilsson, M
   Farrow, P
   Appleby, S
AF Lyko, Tomasz
   Broadbent, Matthew
   Race, Nicholas
   Nilsson, Mike
   Farrow, Paul
   Appleby, Steve
TI Improving quality of experience in adaptive low latency live streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CMAF; DASH; ABR algorithm; Live streaming; Low latency; Quality of
   Experience; Video quality assessment; Database
ID SUBJECTIVE QUALITY
AB HTTP Adaptive Streaming (HAS), the most prominent technology for streaming video over the Internet, suffers from high end-to-end latency when compared to conventional broadcast methods. This latency is caused by the content being delivered as segments rather than as a continuous stream, requiring the client to buffer significant amounts of data to provide resilience to variations in network throughput and enable continuous playout of content without stalling. The client uses an Adaptive Bitrate (ABR) algorithm to select the quality at which to request each segment to trade-off video quality with the avoidance of stalling to improve the Quality of Experience (QoE). The speed at which the ABR algorithm responds to changes in network conditions influences the amount of data that needs to be buffered, and hence to achieve low latency the ABR needs to respond quickly. Llama (Lyko et al. 28) is a new low latency ABR algorithm that we have previously proposed and assessed against four on-demand ABR algorithms. In this article, we report an evaluation of Llama that demonstrates its suitability for low latency streaming and compares its performance against three state-of-the-art low latency ABR algorithms across multiple QoE metrics and in various network scenarios. Additionally, we report an extensive subjective test to assess the impact of variations in video quality on QoE, where the variations are derived from ABR behaviour observed in the evaluation, using short segments and scenarios. We publish our subjective testing results in full and make our throughput traces available to the research community.
C1 [Lyko, Tomasz; Race, Nicholas] Univ Lancaster, Sch Comp & Commun, Lancaster, England.
   [Broadbent, Matthew] Edinburgh Napier Univ, Sch Comp, Edinburgh, Scotland.
   [Nilsson, Mike; Farrow, Paul; Appleby, Steve] British Telecommun PLC, Appl Res, Martlesham, England.
C3 Lancaster University; Edinburgh Napier University; British Telecom (BT)
RP Lyko, T (corresponding author), Univ Lancaster, Sch Comp & Commun, Lancaster, England.
EM t.lyko@lancaster.ac.uk; m.broadbent@napier.ac.uk;
   n.race@lancaster.ac.uk; mike.nilsson@bt.com; paul.farrow@bt.com;
   steve.appleby@bt.com
OI Race, Nicholas/0000-0002-6870-8078; Lyko, Tomasz/0000-0003-3876-4316;
   Broadbent, Matthew/0000-0002-7029-6893
FU UK Engineering and Physical Sciences Research Council (EPSRC); British
   Telecom (BT)
FX This work was supported by the UK Engineering and Physical Sciences
   Research Council (EPSRC) and British Telecom (BT).
CR Allan B., 2019, SMPTE MOTION IMAG J, V128, P1, DOI [10.5594/JMI.2019.2910704, DOI 10.5594/JMI.2019.2910704]
   [Anonymous], 2019, INFORM TECHNOLOGY DY
   [Anonymous], 2022, ABR THROUGHPUT TRACE
   [Anonymous], 2021, SIMULATION MODEL LIV
   [Anonymous], 2022, LLAMA QOE DATABASE
   [Anonymous], 2022, ENCODED CONTENT INPU
   Bampis CG, 2017, ARXIV
   Bampis CG, 2018, ARXIV
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Bentaleb A, 2022, IEEE T MULTIMEDIA, V24, P2300, DOI 10.1109/TMM.2021.3079288
   Bentaleb A, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P7, DOI 10.1145/3304112.3325611
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Cisco V, 2018, 1 CISC V
   Duanmu ZF, 2018, IEEE T IMAGE PROCESS, V27, P6135, DOI 10.1109/TIP.2018.2855403
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   El Essaili A, 2018, IEEE INT SYM BROADB
   Eswara N, 2018, IEEE T CIRC SYST VID, V28, P3236, DOI 10.1109/TCSVT.2017.2742601
   Garcia-Valls M., 2015, Proceedings of the 14th International Workshop on Adaptive and Re ective Middleware - ARM 2015, P1, DOI DOI 10.1109/QOMEX.2015.7148123
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Gutterman C, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P327, DOI 10.1145/3339825.3397044
   Hughes K, 2017, 2300019 ISOIEC
   Tran HTT, 2016, 2016 IEEE SIXTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P423, DOI 10.1109/CCE.2016.7562674
   ITU R.I.-R.B., 2012, 500 13 METH SUBJ ASS
   Karagkioules T, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P315, DOI 10.1145/3339825.3397042
   Lohmar T., 2011, IEEE INT S WORLD WIR, P1, DOI DOI 10.1109/WOWMOM.2011.5986186
   Lyko T, 2020, IEEE INT SYM MULTIM, P113, DOI 10.1109/ISM.2020.00027
   Lyko T, 2020, NOSSDAV '20: PROCEEDINGS OF THE 2020 WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P21, DOI 10.1145/3386290.3396932
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Ott H, 2017, WNS3'17: PROCEEDINGS OF THE WORKSHOP ON NS-3, P95, DOI 10.1145/3067665.3067675
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   parksassociates, 61 LIV VIEW WATCH SP
   Recommendation I., 1999, 910 REC I STAND SECT
   Robitza W., 2017, 2017 9 INT C QUAL MU, P1, DOI DOI 10.1109/QOMEX.2017.7965689
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Rodríguez DZ, 2016, IEEE T BROADCAST, V62, P628, DOI 10.1109/TBC.2016.2570012
   Shuai Y, 2018, 2018 15 IEEE ANN CON, P1, DOI [10.1109/CCNC.2018.8319262, DOI 10.1109/CCNC.2018.8319262]
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Tavakoli S, 2016, IEEE J SEL AREA COMM, V34, P2141, DOI 10.1109/JSAC.2016.2577361
   Tran HTT, 2016, IEEE GLOBE WORK
   Viola R, 2019, 2019 IEEE INT S BROA, P1
   Wang F, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-1044-3
   Yamagishi K, 2017, IEEE T MULTIMEDIA, V19, P1545, DOI 10.1109/TMM.2017.2669859
   Zambelli A., 2009, MICROSOFT CORPORATIO, V3, P40
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15957
EP 15983
DI 10.1007/s11042-023-15895-9
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200012
OA hybrid
DA 2024-07-18
ER

PT J
AU Su, XP
   Duan, JW
   Ren, J
   Li, YH
   Danner, M
   Rätsch, M
   Peng, JY
AF Su, Xueping
   Duan, Jiawei
   Ren, Jie
   Li, Yunhong
   Danner, Michael
   Ratsch, Matthias
   Peng, Jinye
TI Personalized clothing recommendation fusing the 4-season color system
   and users' biological characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized clothing recommendation; 4-season color system; Deep
   transfer learning; Ensemble learning
ID HUMAN AGE ESTIMATION; GABOR FEATURE; FACE; CLASSIFICATION; MODEL
AB In clothing e-commerce, the challenge of optimally recommending clothing that suits a user's unique characteristics remains a pressing issue. Many platforms simply recommend best-selling or popular clothing, without taking into account important attributes like user's face color, pupil color, face shape, age, etc. To solve this problem, this paper proposes a personalized clothing recommendation algorithm that incorporates the established 4-Season Color System and user-specific biological characteristics. Firstly, the attributes and colors of clothing are classified by Fnet network, that can learn disjoint label combinations and mitigate the issue of excessive labels. Secondly, on the basis of the 4-Season Color System, the user's face color model is trained by combined MobileNetV3_DTL, which ensures the model's generalization and improves the training speed. Thirdly, user's face shape and age are divided into different categories by an Inception network. Finally, according to the users' face color, age, face shape and other information, personalized clothing is recommended in a coarse-to-fine manner. Experiments on five datasets demonstrate that the algorithm proposed in this paper achieves state-of-the-art results.
C1 [Su, Xueping; Peng, Jinye] Northwest Univ China, Coll Informat & Technol, Xian, Peoples R China.
   [Su, Xueping; Duan, Jiawei; Ren, Jie; Li, Yunhong] Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
   [Danner, Michael; Ratsch, Matthias] Reutlingen Univ, Dept Engn, Interact & Mobile Robot & Artificial Intelligence, Reutlingen, Germany.
C3 Northwest University Xi'an; Xi'an Polytechnic University
RP Su, XP (corresponding author), Northwest Univ China, Coll Informat & Technol, Xian, Peoples R China.; Su, XP (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM yifeichongtian1201@163.com
RI Yun, Wang/KHM-3009-2024; Qi, Ling/KHE-3068-2024; zhang,
   xiaoyu/KEJ-0657-2024; Yuan, Ye/KBC-9835-2024; xu, liu/KCL-1154-2024;
   zhang, jiahao/KEE-9357-2024; wang, wenjing/KEH-0575-2024; Lu,
   Yi/KEJ-2560-2024
OI Yuan, Ye/0009-0008-1640-7047; 
FU National Natural Science Foundation of China [61902301]; Shaanxi
   Provincial Science and Technology Department [2022JZ-35]; Shaanxi
   Natural Science Basic Research Project [2022JM-394, 2022JQ-711]; Shaanxi
   Provincial Education Department [22JS019]; Xi'an Science and Technology
   Bureau Science and Technology Innovation Leading Project [21XJZZ0020,
   21XJZZ0022]; Science and Technology Guidance Program of China National
   Textile And Apparel Council [2020100]
FX This work is supported by the National Natural Science Foundation of
   China (grant no. 61902301), the Natural Science Basic Research Key
   Program funded by Shaanxi Provincial Science and Technology
   Department(2022JZ-35), Shaanxi Natural Science Basic Research Project
   (grant no. 2022JM-394, 2022JQ-711), the Key Scientific Research Program
   funded by the Shaanxi Provincial Education Department (grant no.
   22JS019), and Xi'an Science and Technology Bureau Science and Technology
   Innovation Leading Project (grant no. 21XJZZ0020 and 21XJZZ0022), and &
   nbsp;Science and Technology Guidance Program of China National Textile
   And Apparel Council (2020100).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alzahrani T., 2019, 2019 INT C INT SYST, P1
   [Anonymous], 2013, Int J Res Eng Technol (IJRET)
   Bansode N., 2016, Int J Comput Sci Issue (IJCSI), V13, P24, DOI DOI 10.20943/IJCSI-201602-2431
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Chen YT, 2021, LECT NOTES ARTIF INT, V12817, P323, DOI 10.1007/978-3-030-82153-1_27
   Deng QQ, 2018, INT C DIGITAL HOME, P219, DOI 10.1109/ICDH.2018.00046
   Duong CN, 2016, PROC CVPR IEEE, P5772, DOI 10.1109/CVPR.2016.622
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Gu SD, 2017, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND INFORMATION PROCESSING (ICCIP 2017), P185, DOI 10.1145/3162957.3162982
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Hassan Khaled Rahman, 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/3/032039
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jackson C, 1985, COLOR ME BEAUTIFUL D, P15
   Lin YM, 2020, IEEE T KNOWL DATA EN, V32, P912, DOI [10.1109/TKDE.2019.2898191, 10.1063/1.5138067]
   Lin YS, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P77, DOI 10.1145/3366423.3380096
   Lin ZQ, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9915-8
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Pasupa K, 2019, EXPERT SYST APPL, V120, P14, DOI 10.1016/j.eswa.2018.11.011
   Standley T., 2020, INT C MACHINE LEARNI, P9120, DOI DOI 10.48550/ARXIV.1905.07553
   Su XP, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/7954393
   Sunhem W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P390, DOI 10.1109/ICACI.2016.7449857
   Tio AE, 2019, ARXIV
   Twigg J., 2009, DRESS NARRATION LIFE
   Wen YJ, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351302
   Xu DN, 2020, IEEE T NEUR NET LEAR, V31, P2409, DOI 10.1109/TNNLS.2019.2945133
   Yaman D, 2018, I W BIOMETRIC FORENS
   Yaman D, 2019, IEEE COMPUT SOC CONF, P2414, DOI 10.1109/CVPRW.2019.00296
   Yan S., 2008, Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587405
   Yanqiu Xu, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2588, DOI 10.1109/CISP.2010.5648207
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhuang XD, 2008, INT C PATT RECOG, P3543
   Zou XX, 2019, IEEE COMPUT SOC CONF, P296, DOI 10.1109/CVPRW.2019.00039
NR 35
TC 0
Z9 0
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12597
EP 12625
DI 10.1007/s11042-023-16014-4
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700002
DA 2024-07-18
ER

PT J
AU Elmaci, M
   Toprak, AN
   Aslantas, V
AF Elmaci, Mehmet
   Toprak, Ahmet Nusret
   Aslantas, Veysel
TI Detection of background forgery using a two-stream convolutional neural
   network architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE image forgery detection; image forensics; image splicing detection;
   background forgery; deep learning
ID IMAGE; FEATURES
AB In this paper, a novel two-stream convolutional neural network (CNN) method is proposed to determine whether or not the background of an image is replaced with that of another image. Although removing or changing the background of an image is one of the most common image forgery techniques, to the best of our knowledge, this is the first passive image forgery detection (IFD) method in the literature that directly addresses such forgery. The proposed background forgery detection network (BFDNET) consists of two identical DenseNet-based feature extractors and a CNN-based classifier. The method first divides the given image into the foreground containing people in the image and background regions using the Mask R-CNN model in the preprocessing phase. Then, the features from the foreground and background regions are extracted using feature extractors. At last, the feature pair of the regions are combined and classified using a CNN-based classification network to determine if the background of the input image is changed. While conducting this study, the findings of some ablation experiments are used to determine the structure of the model and some important strategies. In addition, the proposed method is compared with nine state-of-the-art image splicing detection (ISD) methods using a novel dataset in the experiments. Experiments demonstrate that the proposed method achieves an accuracy of 95.5% in detecting background forgeries. The proposed method can improve the accuracy by over 14% compared to prior works.
C1 [Elmaci, Mehmet; Toprak, Ahmet Nusret; Aslantas, Veysel] Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkiye.
C3 Erciyes University
RP Elmaci, M (corresponding author), Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkiye.
EM mehmetelmaci@erciyes.edu.tr; antoprak@erciyes.edu.tr;
   aslantas@erciyes.edu.tr
OI Toprak, Ahmet Nusret/0000-0003-4841-9508; ELMACI,
   Mehmet/0000-0002-6707-9994
FU Erciyes University Scientific Research Projects Coordination Unit
   [FDK-2021-11218]
FX This work was supported by the Erciyes University Scientific Research
   Projects Coordination Unit under the Grant No. FDK-2021-11218.
CR Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   AISegment, 2022, MATT HUM DAT
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   Bjorck N., 2018, Adv. Neural Inf. Process. Syst, V31, P1
   Chen BC, 2019, IEEE WINT CONF APPL, P73, DOI 10.1109/WACVW.2019.00019
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Elmaci M, 2021, 2021 9 INT S DIG FOR, P1
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gloe T, 2012, IEEE INT WORKS INFOR, P139, DOI 10.1109/WIFS.2012.6412639
   Goljan M, 2018, ELECT IMAGING, V2018, P1
   Goljan M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2078399
   Gou HM, 2007, IEEE IMAGE PROC, P2893
   Gul E, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118730
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P28
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Hussien Nadheer Younus, 2020, International Journal of Sociotechnology and Knowledge Development, V12, P31, DOI 10.4018/IJSKD.2020040102
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Kirchner M, 2010, MEDIA FORENSICS SECU, V7541, P383
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mayer O, 2020, IEEE J-STSP, V14, P1049, DOI 10.1109/JSTSP.2020.3001516
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   Mazumdar A, 2019, IEEE IMAGE PROC, P116, DOI [10.1109/icip.2019.8802969, 10.1109/ICIP.2019.8802969]
   Meena Kunj Bihari, 2021, Journal of Physics: Conference Series, V1714, DOI 10.1088/1742-6596/1714/1/012038
   Pan X, 2012, INT CONF E BUS ENG, P17, DOI 10.1109/ICEBE.2012.13
   Pan ZG, 2021, MULTIMEDIA SYST, V27, P353, DOI 10.1007/s00530-021-00756-y
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Ren S., 2015, Advances in Neural Information Processing Systems, V28, P1
   Salim MZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010136
   Salim MZ, 2021, INT C ADV ENG ARCH S, P210
   Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Supervise.ly, 2022, FILT SEGM PERS DAT
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang W, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-1
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuang PY, 2021, IEEE T INF FOREN SEC, V16, P2986, DOI 10.1109/TIFS.2021.3070444
   Zhuo L, 2022, IEEE T INF FOREN SEC, V17, P819, DOI 10.1109/TIFS.2022.3152362
NR 50
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 10
PY 2023
DI 10.1007/s11042-023-16097-z
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L9TC3
UT WOS:001026613700004
DA 2024-07-18
ER

PT J
AU Liu, X
   Nie, JH
AF Liu, Xiao
   Nie, Jianhui
TI Unsupervised bas-relief generation with feature transferring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Bas-relief; Deep-learning; Unsupervised; Feature transfer
ID ACCURACY
AB The generation of relief based on 3D models has always been a research hotspot in computer graphics. The challenge of bas-relief generation lies in the need to maintain details and eliminate height jumps while significantly compressing height. Traditional algorithms are computationally complex. The latest methods based on deep learning bring new ideas to the problem but are rely on supervised training, which requires a large number of samples to be constructed manually. In this paper, an unsupervised bas relief generation method is proposed. In the method, the normal image of the model is modified by a style-transfer neural network firstly, and then it is reconstructed by Convolution Neural Network (CNN). Our method takes the orthogonal relationship between the normal vector and the local points as the optimization goal, thus avoiding the process of constructing "ground truth". At the same time, by adding normal vector continuity constraints to the style-transfer network and the reconstruction network, the high jump in the original model is effectively eliminated, and the detailed features are well maintained. Experiments show that this method is simple and efficient, and can generate a series of pleasant stylized relief models with rich details and good saturation.
C1 [Liu, Xiao; Nie, Jianhui] Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Nie, JH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Nanjing, Peoples R China.
EM njh19@njupt.edu.cn
FU NSFC [61802204]
FX AcknowledgementsWe would like to thank all the reviewers for their
   valuable comments. This work is supported by NSFC (No. 61802204).
CR Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Fernandes FE Jr, 2019, SWARM EVOL COMPUT, V49, P62, DOI 10.1016/j.swevo.2019.05.010
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Ji ZP, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102928
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Kerber J, 2012, COMPUT GRAPH FORUM, V31, P2363, DOI 10.1111/j.1467-8659.2012.03185.x
   Kerber J., 2007, P 23 SPRING C COMP G, P101, DOI DOI 10.1145/2614348.2614363
   Kerber J, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P148, DOI 10.1109/SMI.2009.5170176
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Li Bo, 2011, Computer Integrated Manufacturing Systems, V17, P946
   Nie JH, 2021, GRAPH MODELS, V113, DOI 10.1016/j.gmod.2021.101096
   Sch?ller C., 2014, ACM T GRAPHIC, V36, P1
   Song WH, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P211, DOI 10.1109/SMI.2007.9
   Sun XF, 2009, IEEE T VIS COMPUT GR, V15, P642, DOI 10.1109/TVCG.2009.21
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P1651, DOI 10.1109/TVCG.2018.2818146
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yang ZJ, 2022, IEEE T VIS COMPUT GR, V28, P4558, DOI 10.1109/TVCG.2021.3092877
   Zhang Y-W, 2022, IEEE T VIS COMPUT GR
   Zhang YW, 2020, IEEE T VIS COMPUT GR, V26, P2659, DOI 10.1109/TVCG.2019.2892439
   Zhang YW, 2021, COMPUT GRAPH FORUM, V40, P288, DOI 10.1111/cgf.14273
   Zhang YW, 2020, VISUAL COMPUT, V36, P2241, DOI 10.1007/s00371-020-01917-2
   Zhang YW, 2016, COMPUT GRAPH FORUM, V35, P311, DOI 10.1111/cgf.13028
   Zhang YW, 2015, IEEE T VIS COMPUT GR, V21, P328, DOI 10.1109/TVCG.2014.2377773
   Zhang YW, 2013, GRAPH MODELS, V75, P2, DOI 10.1016/j.gmod.2012.10.003
NR 31
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13181
EP 13195
DI 10.1007/s11042-023-16111-4
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700002
DA 2024-07-18
ER

PT J
AU Moghaddam, RM
   Aghazadeh, N
AF Moghaddam, Reza Mousavi
   Aghazadeh, Nasser
TI Lung Parenchyma Segmentation from CT Images with a Fully Automatic
   Method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung Parenchyma Segmentation; Juxtapleural Nodule; Chest CT Slice
ID PROBABILISTIC ATLAS; COMPUTED-TOMOGRAPHY; U-NET; NODULES; ALGORITHM;
   MODEL
AB For the last three years, the world has been facing an infectious disease that primarily affects the human breathing organ. The disease has caused many deaths worldwide so far and has imposed high economic costs on all countries. Therefore, attention to computer-aided detection/diagnosis (CAD) systems to help diagnose and treat diseases related to the human respiratory system should be given more attention so that countries' health systems can treat patients in epidemics. Considering the importance of CAD systems, we proposed a two-step automatic algorithm. In the first step, we obtain the primary boundary of the lobes in CT lung scan images with the help of some conventional image processing tools. In the second stage, we obtained a more precise boundary of the lung lobes by correcting the unusual dimples and valleys (which are sometimes caused by the presence of juxtapleural nodules). This proposed method has low implementation time. Given that a precise boundary of the pulmonary lobes is essential in the more accurate diagnosis of lung-related diseases, an attempt has been made to ensure that the final segmentation of the lung parenchyma has an acceptable score in terms of evaluation criteria so that the proposed algorithm can be used in the diagnosis procedure.
C1 [Moghaddam, Reza Mousavi; Aghazadeh, Nasser] Azarbaijan Shahid Madani Univ, Dept Appl Math, Image Proc Lab, Tabriz, Iran.
   [Aghazadeh, Nasser] Izmir Inst Technol, Dept Math, Izmir, Turkiye.
C3 Azarbaijan Shahid Madani University; Izmir Institute of Technology
RP Aghazadeh, N (corresponding author), Azarbaijan Shahid Madani Univ, Dept Appl Math, Image Proc Lab, Tabriz, Iran.; Aghazadeh, N (corresponding author), Izmir Inst Technol, Dept Math, Izmir, Turkiye.
EM r.mousavi@azaruniv.ac.ir; aghazadeh@azaruniv.ac.ir
RI Aghazadeh, Nasser/Q-6551-2019
OI Aghazadeh, Nasser/0000-0003-2705-8942
CR Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   Akram T, 2021, PATTERN ANAL APPL, V24, P951, DOI 10.1007/s10044-020-00950-0
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Ashok M, 2023, J COMPUT BIOL, V30, P346, DOI 10.1089/cmb.2022.0248
   Campadelli P., 2009, ELECT LETT COMPUTER, V8, P1
   Campadelli P, 2010, ARTIF INTELL MED, V50, P3, DOI 10.1016/j.artmed.2010.04.010
   Carmo Diedre, 2022, Yearb Med Inform, V31, P277, DOI 10.1055/s-0042-1742517
   Chen B, 2019, APPL MATH MODEL, V65, P120, DOI 10.1016/j.apm.2018.08.009
   Chondro P, 2018, NEUROCOMPUTING, V275, P1002, DOI 10.1016/j.neucom.2017.09.053
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   de Carvalho AS, 2017, J DIGIT IMAGING, V30, P812, DOI 10.1007/s10278-017-9973-6
   Dharmalingham V, 2020, MULTIMED TOOLS APPL, V79, P10003, DOI 10.1007/s11042-019-07854-0
   Dhou K, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101613
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   Gill G, 2016, COMPUT BIOL MED, V76, P143, DOI 10.1016/j.compbiomed.2016.06.022
   Gonzalez R.C., 2018, Digital Image Processing
   Guhan B, 2022, BIOMED ENG-APP BAS C, V34, DOI 10.4015/S1016237222500028
   Hofmanninger J, 2020, EUR RADIOL EXP, V4, DOI 10.1186/s41747-020-00173-2
   Khanna A, 2020, BIOCYBERN BIOMED ENG, V40, P1314, DOI 10.1016/j.bbe.2020.07.007
   Khanna D, 2022, J SCLERODERMA RELAT, V7, P168, DOI 10.1177/23971983211064463
   Kumar SP, 2020, IETE J RES, V66, P370, DOI 10.1080/03772063.2018.1494519
   Liu CX, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102032
   Mekali V, 2021, INT J HEALTHC INF SY, V16, P87, DOI 10.4018/IJHISI.20210401.oa5
   Müller D, 2022, BMC RES NOTES, V15, DOI 10.1186/s13104-022-06096-y
   Mukherjee J, 2020, BIOCYBERN BIOMED ENG, V40, P1036, DOI 10.1016/j.bbe.2020.03.006
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Ohno Y, 2021, EUR J RADIOL, V134, DOI 10.1016/j.ejrad.2020.109410
   Osadebey M, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-021-00640-1
   Ren H, 2020, QUANT IMAG MED SURG, V10, P233, DOI 10.21037/qims.2019.12.02
   Shi CF, 2017, MED IMAGE ANAL, V38, P30, DOI 10.1016/j.media.2017.02.008
   Shi CF, 2016, PATTERN RECOGN, V50, P88, DOI 10.1016/j.patcog.2015.09.001
   Shukla S, 2022, MULTIMED TOOLS APPL, V81, P26483, DOI 10.1007/s11042-022-12185-8
   Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020
   Soltani-Nabipour J, 2020, NUCL ENG TECHNOL, V52, P2313, DOI 10.1016/j.net.2020.03.011
   Thawani R, 2018, LUNG CANCER, V115, P34, DOI 10.1016/j.lungcan.2017.10.015
   Wang JK, 2016, INT J COMPUT ASS RAD, V11, P817, DOI 10.1007/s11548-015-1332-9
   Wang Y., 2022, 2022 5 INT C ADV EL, P651, DOI [10.1109/AEMCSE55572.2022.00132, DOI 10.1109/AEMCSE55572.2022.00132]
   Xiao XJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050832
   Xie XZ, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.663514
NR 40
TC 2
Z9 2
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14235
EP 14257
DI 10.1007/s11042-023-16040-2
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800003
DA 2024-07-18
ER

PT J
AU Bao, ZJ
   Xue, R
   Hu, JY
   Liu, Y
AF Bao, Zhenjie
   Xue, Ru
   Hu, Jingyun
   Liu, Yue
TI Color image encryption based on lite dense-ResNet and bit-XOR diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Lite dense-ResNet; Bit-XOR diffusion; Deep
   learning
ID SCHEME
AB Images contain a wealth of information and are frequently targeted by malicious attackers when transmitted over public networks. Fortunately, image encryption prevents confidential information from being acquired by illegal attackers. Deep learning-based image encryption is a relatively new research area, but recently proposed methods have not achieved satisfactory levels of generalization, security, and efficiency. To address these limitations, we employ a lite dense residual network (Dense-ResNet) to rearrange image pixels, thereby reducing the computation amounts. In addition, we design a weight-adjustable loss function model, which combines the encryption loss function, decryption loss function, and total variational loss function. And then we adopt bit-XOR diffusion to further encrypt the intermedia ciphertext image obtained by the encryption network. We trained and tested encryption and decryption neural networks in a dataset of no fixed category images. Experiments declare our method can complete the image encryption/ decryption tasks in various scenarios. Additionally, the proposed approach exhibits broad generalization abilities with high encryption and decryption quality aided by the decryption total variation loss function. Compared to recently proposed deep learning-based image encryption approaches, our method demonstrates faster processing times for both image encryption and decryption, with at least a 2.7% and 7.5% increase in efficiency, respectively. Furthermore, our method improves decryption performance by at least 1.0% and 0.5% in Peak signal-to-ratio (PSNR) as well as structural similarity (SSIM) indicators while maintaining a high level of security. What is more, our method enhances traceability of data loss or noise attacks since such attacks leave a noticeable trail on decrypted images produced by our method.
C1 [Bao, Zhenjie; Xue, Ru; Hu, Jingyun; Liu, Yue] Xizang Minzu Univ, Sch Informat Engn, Xianyang, Shaanxi, Peoples R China.
C3 Xizang Minzu University
RP Xue, R (corresponding author), Xizang Minzu Univ, Sch Informat Engn, Xianyang, Shaanxi, Peoples R China.
EM rxue@xzmu.edu.cn
FU Major Programs Incubation Plan of Xizang Minzu University [22MDZ03]
FX AcknowledgmentsThis study is supported by the Major Programs Incubation
   Plan of Xizang Minzu University "Research on multi-biometric
   characteristic image encryption method based on deep learning" under
   Grant 22MDZ03.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bao ZJ, 2021, APPL OPTICS, V60, P5320, DOI 10.1364/AO.428203
   Bao ZJ, 2021, MULTIMED TOOLS APPL, V80, P28265, DOI 10.1007/s11042-021-11043-3
   Barik RC, 2020, IET IMAGE PROCESS, V14, P2457, DOI 10.1049/iet-ipr.2019.0527
   Berkeley Computer Vision Group, 2014, CONT DET IM SEGM RES
   Chakraborty R, 2021, J AMB INTEL HUM COMP, V12, P7793, DOI 10.1007/s12652-020-02506-w
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen W, 2020, ACTA PHYS SIN-CH ED, V69, DOI 10.7498/aps.69.20201019
   Das S, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4716
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Fang PF, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6691547
   Guo Y, 2020, IEEE ACCESS, V8, P9896, DOI 10.1109/ACCESS.2019.2963717
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kang Y, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/ac0815
   Kingma D. P., 2014, arXiv
   Kumar P, 2022, IEEE PHOTONIC TECH L, V34, P521, DOI 10.1109/LPT.2022.3169011
   [李锦青 Li Jinqing], 2021, [吉林大学学报. 工学版, Journal of Jilin University. Engineering and Technology Edition], V51, P1060
   Li SX, 2021, SYST SCI CONTROL ENG, V9, P141, DOI 10.1080/21642583.2020.1852624
   Liu DY, 2021, INFORM SCIENCES, V545, P118, DOI 10.1016/j.ins.2020.07.073
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Luan GY, 2021, OPT APPL, V51, P121, DOI 10.37190/oa210110
   Maniyath SR, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103134
   Qian XL, 2021, IEEE ACCESS, V9, P61334, DOI 10.1109/ACCESS.2021.3073514
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Ulyanov Dmitry, 2016, arXiv
   Wang C, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108536
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yu H, 2022, J OPTICS-UK, V24, DOI 10.1088/2040-8986/ac4873
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   [张云鹏 ZHANG Yunpeng], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P463
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   [周辉 Zhou Hui], 2021, [中国图象图形学报, Journal of Image and Graphics], V26, P1081
   Zhou S, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110225
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 43
TC 1
Z9 1
U1 11
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12819
EP 12848
DI 10.1007/s11042-023-16073-7
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020195700004
DA 2024-07-18
ER

PT J
AU Li, XD
   Yin, KL
   Shen, SY
   Xia, HF
AF Li, Xiangdong
   Yin, Kailin
   Shen, Siyang
   Xia, Hanfei
TI Conducting individualised hand therapy evaluation with around-device
   hand movements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand therapy evaluation; Hand movement; Around-device interaction;
   Mobile phone device
ID CARPAL-TUNNEL-SYNDROME; DESIGN; REHABILITATION; SCALE; GAMES
AB Office workers often resort to therapeutic systems to address muscular and nerve disorders caused by poor gestures and extraordinary workloads. These systems deliver effective treatment with a playable experience. However, the therapeutic evaluation still heavily relies on occupational therapists' diagnose, which is time-consuming and subjective. This highlights the necessity for a system that adheres to standard treatment protocols and enables individualised therapeutic evaluations. In this study, we proposed a hand therapy system based on around-device hand movements with a capacitive-sensing mobile phone case to realise instant yet approximate hand therapy evaluation. Moreover, we conducted empirical studies to investigate the usability and acceptability of this system and its potential influence on office workers' willingness to take hand therapy exercises during working hours. The results showed that this instant yet approximate evaluation system can significantly improve the workers' hand therapy frequencies during working intervals. Furthermore, it can quantitatively measure and report on individual therapy performances, helping office workers understand their therapy outcomes and promoting their willingness to take therapeutic hand exercises. Our results introduce a new perspective for designing mobile systems for well-being.
C1 [Li, Xiangdong; Yin, Kailin; Shen, Siyang; Xia, Hanfei] Zhejiang Univ, Coll Comp Sci & Technol, 38 Zheda Rd, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Yin, KL (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, 38 Zheda Rd, Hangzhou, Peoples R China.
EM klyin@zju.edu.cn
RI Yin, Kailin/JNS-1286-2023
OI Yin, Kailin/0000-0002-6389-9821
FU project of Zhejiang provincial key Ramp;D program [2022C03103]; national
   natural science foundation of China [61972346]; major research plan of
   the national natural science foundation of China [92148205]
FX This research work is co-supported by the project of Zhejiang provincial
   key R & D program (ref no 2022C03103), national natural science
   foundation of China (ref no 61972346), and the major research plan of
   the national natural science foundation of China (ref no 92148205).
CR Algar L, 2014, J HAND THER, V27, P254, DOI 10.1016/j.jht.2013.12.009
   Appelboom G, 2014, ARCH PUBLIC HEALTH, V72, DOI 10.1186/2049-3258-72-28
   Beatty AL, 2013, J AM HEART ASSOC, V2, DOI 10.1161/JAHA.113.000568
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cambo SA, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3595, DOI 10.1145/3025453.3026021
   Case LE., 2015, MUSCULAR DYSTROPHY C, P73, DOI [10.1007/978-3-319-17362-7_8, DOI 10.1007/978-3-319-17362-7_8]
   Cheng JY, 2016, PERVASIVE MOB COMPUT, V30, P97, DOI 10.1016/j.pmcj.2016.01.007
   Chien-Yen Chang, 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P159, DOI 10.4108/icst.pervasivehealth.2012.248714
   Cooke ME., 2017, CARPAL TUNNEL SYNDRO, P7, DOI [10.1007/978-3-319-57010-5_2, DOI 10.1007/978-3-319-57010-5_2]
   Daponte P, 2013, MEASUREMENT, V46, P3291, DOI 10.1016/j.measurement.2013.05.006
   Giannini F, 2002, CLIN NEUROPHYSIOL, V113, P71, DOI 10.1016/S1388-2457(01)00704-0
   Goyal S, 2013, QJM-INT J MED, V106, P1067, DOI 10.1093/qjmed/hct203
   Graves LEF, 2010, J PHYS ACT HEALTH, V7, P393, DOI 10.1123/jpah.7.3.393
   Grosse-Puppendahl T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3293, DOI 10.1145/3025453.3025808
   Henkemans OAB, 2017, INT J HUM-COMPUT ST, V106, P63, DOI 10.1016/j.ijhcs.2017.06.001
   Jarus T, 2000, AM J OCCUP THER, V54, P176, DOI 10.5014/ajot.54.2.176
   Kisner C, 2017, THERAPEUTIC EXERCISE, P19
   Kjeken I, 2011, ARTHRIT CARE RES, V63, P834, DOI 10.1002/acr.20427
   Kranz M, 2013, PERVASIVE MOB COMPUT, V9, P203, DOI 10.1016/j.pmcj.2012.06.002
   Laflamme S, 2012, STRUCT CONTROL HLTH, V19, P70, DOI 10.1002/stc.426
   Laflamme S, 2013, J ENG MECH, V139, P879, DOI 10.1061/(ASCE)EM.1943-7889.0000530
   Le HuyViet., 2016, P 2016 CHI C EXTENDE, P2576
   Le HV, 2017, P 2017 CHI C EXT ABS
   Lee H., 2013, CHI 13 EXTENDED ABST, P2257, DOI [10.1145/2468356.2468747, DOI 10.1145/2468356.2468747]
   Lohse K, 2013, J NEUROL PHYS THER, V37, P166, DOI 10.1097/NPT.0000000000000017
   Meijer HA, 2018, ARCH PHYS MED REHAB, V99, P1890, DOI 10.1016/j.apmr.2017.10.018
   Miyamoto H, 2014, RADIOLOGY, V270, P481, DOI 10.1148/radiol.13122901
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Music J, 2016, HUM-COMPUT INTERACT, V31, P420, DOI 10.1080/07370024.2015.1071195
   Nielsen Jackob., 1993, Usability Engineering, P1
   O'Brien HL, 2013, INFORM PROCESS MANAG, V49, P1092, DOI 10.1016/j.ipm.2012.08.005
   Palmer M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189801
   Pereira Margarida F, 2020, J Biomed Inform, V111, P103584, DOI 10.1016/j.jbi.2020.103584
   Pourahmadi MR, 2017, J ANAT, V230, P484, DOI 10.1111/joa.12568
   Qi BZ, 2016, MOBICOM'16: PROCEEDINGS OF THE 22ND ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P441, DOI 10.1145/2973750.2985268
   Reid S, 2019, J HAND THER, V32, P110, DOI 10.1016/j.jht.2018.03.003
   Sato Munehiko., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI '12, P483, DOI 10.1145/2207676.2207743
   Short N, 2017, J HAND THER, V30, P106, DOI 10.1016/j.jht.2016.03.014
   Takata SC, 2019, J HAND THER, V32, P1, DOI 10.1016/j.jht.2017.05.018
   Torres A, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0550-1
   Torres A, 2015, LECT NOTES COMPUT SC, V9456, P148, DOI 10.1007/978-3-319-26508-7_15
   Valdes K, 2020, J HAND THER, V33, P229, DOI 10.1016/j.jht.2019.10.003
   Valdes K, 2010, J HAND THER, V23, P334, DOI 10.1016/j.jht.2010.05.001
   van Dantzig S, 2013, PERS UBIQUIT COMPUT, V17, P1237, DOI 10.1007/s00779-012-0588-0
   Wainwright SF, 2011, PHYS THER, V91, P87, DOI 10.2522/ptj.20100161
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 46
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12687
EP 12704
DI 10.1007/s11042-023-16099-x
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020279100002
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Liu, XC
   Chen, Y
   Xie, LY
   Wang, HB
   Salem, O
AF Zhang, Yifei
   Liu, Xinchen
   Chen, Yan
   Xie, Linyao
   Wang, Hongbo
   Salem, Osman
TI SPSO-Pruner: a network pruning method on YOLOv5 for fewer categories
   scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few classes; Network pruning; YOLOv5; PSO; Loss optimization
AB In recent years, object detection methods based on deep learning have developed rapidly, but we have found that comparing with public datasets, the categories of objects to be recognized in most practical scenarios are relatively small. In such scenarios, we proposed a network pruning method inspired by the PSO algorithm, named SPSO-Pruner to improve the detection accuracy and speed, while reducing the model parameters. To better fit the application scenarios, we used the up-to-date one stage detector - YOLOv5 to adapt to the real-time requirements. Comparing with regular network prune method such as slimming prune, our SPSO-pruner can reach better accuracy with less than 50% parameters. Besides, we proposed an optimization method for confidence Loss of YOLOv5 which can balance the Precision and Recall of our model, the F1 of our method is 4% higher than the baseline model.
C1 [Zhang, Yifei; Liu, Xinchen; Chen, Yan; Xie, Linyao; Wang, Hongbo] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Salem, Osman] Univ Paris Cite, Ctr Borelli UMR 9010, F-75006 Paris, France.
C3 Beijing University of Posts & Telecommunications; Universite Paris Cite
RP Wang, HB (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM hbwang@bupt.edu.cn
RI Li, Xintong/KHD-6915-2024; chen, huan/KEC-2019-2024; yi,
   cheng/KHC-5004-2024; Chen, Yukun/KGK-4521-2024; Liu,
   Xinchen/AAA-3951-2021; li, fang/KDO-8841-2024; Zhang,
   Xiaoyu/JXR-6386-2024; Zhang, yuxuan/JXM-9935-2024; Chen,
   Jin/KBQ-0163-2024; WEI, ZHEN/KHU-7176-2024; li, yuanfang/KHV-1697-2024;
   Wang, Yifan/KDO-8319-2024; cheng, qian/KFB-6227-2024
OI Liu, Xinchen/0000-0003-4931-8821; Chen, Jin/0009-0005-5844-635X; 
FU National Natural Science Foundation of China (CN) [61002011]
FX National Natural Science Foundation of China (CN) (61002011).
CR Ashraf AH, 2022, CMC-COMPUT MATER CON, V70, P2761, DOI 10.32604/cmc.2022.018785
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du C, 2016, PROCEEDINGS OF 2016 16TH INTERNATIONAL CONFERENCE ON GROUND PENETRATING RADAR (GPR)
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   [胡建秀 Hu Jianxiu], 2007, [计算机研究与发展, Journal of Computer Research and Development], V44, P1825, DOI 10.1360/crad20071103
   Jianxiu, 2015, ELECTORNIC TECHNOL S, V1, P182
   Jocher G, 2021, ZENODO, V11
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Murthy CB, 2021, CMC-COMPUT MATER CON, V69, P3015, DOI 10.32604/cmc.2021.018781
   Murugan SP, 2022, CMC-COMPUT MATER CON, V70, P181, DOI 10.32604/cmc.2022.016152
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sakthivel B, 2022, COMPUT SYST SCI ENG, V42, P397, DOI 10.32604/csse.2022.021637
   Tanaka Hidenori, 2020, ARXIV
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wang Y.M., 2020, J. Artificial Intell. (English), V2, P113, DOI 10.32604/jai.2020.010137
   Zhang SN, 2020, 2020 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND HUMAN-COMPUTER INTERACTION (ICHCI 2020), P367, DOI 10.1109/ICHCI51889.2020.00084
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531
NR 31
TC 0
Z9 0
U1 8
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11493
EP 11506
DI 10.1007/s11042-023-16038-w
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100013
DA 2024-07-18
ER

PT J
AU Pradhan, A
   Yajnik, A
AF Pradhan, Ashish
   Yajnik, Archit
TI Parts-of-speech tagging of Nepali texts with Bidirectional LSTM,
   Conditional Random Fields and HMM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parts-of-speech (POS) tagging; Long short term memory (LSTM);
   Conditional random fields (CRF); hidden markov model (HMM);
   Bidirectional long short term memory (Bi-LSTM)
AB Parts-of-Speech (POS) Tagging is one of the fundamental and pre-processing steps for Natural Language Processing (NLP) tasks such as Text Summarization, Name Entity Recognition, Dependency Parsing or Parsing in general, Classification, Sentiment analysis, Machine translation and Information Extraction systems etc. Various state-of-art models have been implemented for the POS tagging of many natural languages. However from our literature survey, it is established that the problem has not been addressed rigorously for Nepali language and no comprehensive comparative studies have been presented. It is an under-resourced and highly inflectional language, therefore encodes information like gender, person, number, mood, and aspect within their word forms. Precise disambiguation of these inflected words is critical in Nepali text analysis. In this paper, POS tagging using Hidden Markov Model (HMM), Conditional Random Fields (CRF) and Long Short Term Memory (LSTM) is presented for the language. Furthermore, a comprehensive comparative study of the three models is also presented. Experiments shows that CRF based technique outperforms HMM model, further deep neural network based technique like LSTM outperforms CRF in terms of accuracy, which scores an accuracy of 99.6%. This study demonstrate that deep learning based models are exceptional at disambiguating rich morphological information encoded by Nepali words.
C1 [Pradhan, Ashish; Yajnik, Archit] Sikkim Manipal Inst Technol, Dept Math, Sikkim 737136, India.
C3 Sikkim Manipal Institute of Technology; Sikkim Manipal University
RP Pradhan, A (corresponding author), Sikkim Manipal Inst Technol, Dept Math, Sikkim 737136, India.
EM asiispradhan@gmail.com; archit.yajnik@gmail.com
FU Department of Science and Technology, Government of India under the
   "Cognitive Science Research Initiative (CSRI)" [SR/CSRI/- 28/2015]; TMA
   Pai University (Sikkim Manipal University)
FX We would like to acknowledge and express our sincere gratitude to the
   "Department of Science and Technology, Government of India", for
   sponsoring the project entitled "Study and develop a natural language
   parser for Nepali language", "reference no. SR/CSRI/- 28/2015(G)" under
   the "Cognitive Science Research Initiative (CSRI)" to carry out this
   work. We also acknowledge the "TMA Pai University (Sikkim Manipal
   University)" research grant for supporting this work.
CR Acharya J., 1991, DESCRIPTIVE GRAMMAR
   Akhil K. K., 2020, International Journal of Information Technology, V12, P741, DOI 10.1007/s41870-020-00491-z
   Alhasan A, 2018, PROCEDIA COMPUT SCI, V142, P158, DOI 10.1016/j.procs.2018.10.471
   [Anonymous], 2015, PART OF SPEECH TAGGI
   [Anonymous], 2019, BUREAU INDIAN STANDA
   [Anonymous], 2019, INDIAN LANGUAGE TECH
   Aziz TA, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1502, DOI 10.1109/ICACCI.2015.7275825
   Bal KB, 2004, STRUCTURE NEPALI GRA
   Behera P, 2016, WILDRE 3
   Besharati Sara, 2021, Iran Journal of Computer Science, V4, P35, DOI DOI 10.1007/S42044-020-00063-1
   Boonkwan P, 2017, P INT C COMP SCI APP, P184
   Brants T., 2000, arXiv
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Carneiro HCC, 2015, NEURAL NETWORKS, V66, P11, DOI 10.1016/j.neunet.2015.02.012
   CUTTING D, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P133
   Das BR, 2015, PROCEDIA COMPUT SCI, V48, P507, DOI 10.1016/j.procs.2015.04.127
   Denis P, 2012, LANG RESOUR EVAL, V46, P721, DOI 10.1007/s10579-012-9193-0
   Divyapushpalakshmi M, 2021, INT J SPEECH TECHNOL, V24, P329, DOI 10.1007/s10772-021-09801-7
   Ekbal, 2008, Advances in Natural Language Processing and Applications, Research in Computing Science (RCS) Journal, V33, P67
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jayan JP., 2011, COMPUT ENG INTELL SY, V2, P68
   Jolly SK., 2020, INTELL COMPUT ENG, P107
   Junaida M, 2021, 2 INT C NETWORKS ADV, P243
   Kabir MF, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P26, DOI 10.1109/ICIEV.2016.7760098
   Kempe A., 1993, PROBABILISTIC TAGGER
   Khan W, 2019, LANG RESOUR EVAL, V53, P331, DOI 10.1007/s10579-018-9439-6
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   MacKinlay A, 2005, THESIS U OF MELBOURN
   Màrquez L, 2000, MACH LEARN, V39, P59, DOI 10.1023/A:1007673816718
   Mukherjee S., 2013, Atlas of shear zone structures in meso-scale, P1, DOI [10.1109/PESMG.2013.6672434, DOI 10.1109/PESMG.2013.6672434]
   Nambiar Sindhya K., 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P957, DOI 10.1109/ICSSIT46314.2019.8987786
   Narayan R., 2014, INT J ADV TECHNOLOGY, V5, P137
   Bach NX, 2018, COMPUT SPEECH LANG, V50, P1, DOI 10.1016/j.csl.2017.12.004
   Pakray P, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), P3, DOI 10.1109/MICAI.2015.7
   Pallavi ASP, 2014, P NAT C IND LANG COM
   Pammi S.C., 2007, P WORKSH SHALL PARS, P33
   Pandian SL, 2009, LECT NOTES ARTIF INT, V5459, P11, DOI 10.1007/978-3-642-00831-3_2
   Patel C, 2008, P IJCNLP 08 WORKSH N
   Paul A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), P149, DOI 10.1109/ISACC.2015.7377332
   Phuong LH, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P103, DOI 10.1109/RIVF.2013.6719875
   Plank B, 2016, ARXIV
   Pota M, 2019, KNOWL-BASED SYST, V164, P309, DOI 10.1016/j.knosys.2018.11.003
   Pradhan Ashish, 2021, ISEEIE 2021: 2021 International Symposium on Electrical, Electronics and Information Engineering, P249, DOI 10.1145/3459104.3459146
   Sakiba Shadikun Nahar, 2021, Artificial Intelligence Techniques for Advanced Computing Applications. Proceedings of ICACT 2020. Lecture Notes in Networks and Systems (LNNS 130), P67, DOI 10.1007/978-981-15-5329-5_8
   Sarkar K., 2013, P INT C FRONTIERS IN, V199, P205, DOI [10.1007/978-3-642-35314, DOI 10.1007/978-3-642-35314]
   Schmid H., 1994, ARXIV
   Shahi TB, 2013, INT J COMPUT APPL T, V70
   Shamsi F, 2020, P 8 INT C TEXTUAL DA
   Shim Kwangseob, 2011, [Korean Journal of Cognitive Science, 인지과학], V22, P327
   Shrivastava M, 2008, INT C NLP ICON08 PUN
   Shu XB, 2022, IEEE T PATTERN ANAL, V44, P3300, DOI 10.1109/TPAMI.2021.3050918
   Shu XB, 2021, IEEE T NEUR NET LEAR, V32, P663, DOI 10.1109/TNNLS.2020.2978942
   Shu XB, 2021, IEEE T PATTERN ANAL, V43, P1110, DOI 10.1109/TPAMI.2019.2942030
   Singh J, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1554, DOI 10.1109/ICACCI.2013.6637411
   Surasvadi N., 2017, 2017 10th International Conference on Ubimedia Computing and Workshops (Ubi-Media), P1, DOI [DOI 10.1109/I2C2.2017.8321833, 10.1109/UMEDIA.2017, DOI 10.1109/UMEDIA.2017]
   Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603
   Tiwary U.S., 2008, Natural language Processing and Information Retrieval
   VanHalteren H, 1998, ARXIV
   Yajnik A., 2017, WORLD ACAD SCI ENG T, V11, P76
   Yajnik A., 2018, INT J NATURAL LANGUA, V7, P13, DOI [10.5121/ijnlc.2018.7302, DOI 10.5121/IJNLC.2018.7302]
   Yuwana RS, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P204, DOI 10.1109/IC3INA.2018.8629531
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao L, 2020, PATTERN RECOGN LETT, V138, P163, DOI 10.1016/j.patrec.2020.07.017
NR 64
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9893
EP 9909
DI 10.1007/s11042-023-15679-1
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900016
DA 2024-07-18
ER

PT J
AU Avci, D
   Sert, E
   Özyurt, F
   Avci, E
AF Avci, Derya
   Sert, Eser
   Ozyurt, Fatih
   Avci, Engin
TI MFIF-DWT-CNN: Multi-focus image fusion based on discrete wavelet
   transform with deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-Focus Image Fusion; Discrete Wavelet Transform; Deep Convolutional
   Neural Network
ID SPATIAL-FREQUENCY; PERFORMANCE; ALGORITHM; FUZZY
AB A new fusion method based on Multi-Focus Image Fusion Based on Discrete Wavelet Transform with Deep Convolutional Neural Network (MFIF-DWT-CNN) is presented to reduce spatial artifacts and blurring effects in edge details and increase the robustness of multifocal image fusion. The main purpose of the MFIF-DWT-CNN approach is to create a new merged image by collecting the required features from the main image. With the MFIF-DWT-CNN approach, information focused on individual images is combined into a single image, resulting in a clearer image. Within the scope of MFIF-DWT-CNN approach, DWT is applied to the image pairs and the obtained images are then given to the CNN architecture. The MFIF-DWT-CNN approach was developed in this study to reduce spatial artifacts and blurring effects in edge details and to increase the robustness of multifocal image fusion. In order to evaluate our proposed MFIF-DWT-CNN method, QMI, QG, QYi QCB evaluations were made on the public data set. From the experimental results, it is seen that the proposed method gives better results in the relevant metrics than the other methods. This demonstrated the effectiveness of the proposed method.
C1 [Avci, Derya] Firat Univ, Dept Comp Technol, Elazig, Turkiye.
   [Sert, Eser] Malatya Turgut Ozal Univ, Dept Comp Engn, Malatya, Turkiye.
   [Ozyurt, Fatih; Avci, Engin] Firat Univ, Dept Software Engn, Elazig, Turkiye.
C3 Firat University; Malatya Turgut Ozal University; Firat University
RP Avci, D (corresponding author), Firat Univ, Dept Comp Technol, Elazig, Turkiye.
EM davci@firat.edu.tr
RI Avcı, Derya/W-2243-2018; Özyurt, Fatih/W-4385-2018; SERT,
   ESER/AAK-1852-2020
OI Avcı, Derya/0000-0002-5204-0501; Özyurt, Fatih/0000-0002-8154-6691; 
FU Firat University Scientific Research Projects Coordination Unit (FUEBAP)
   [ADEP.23.21]
FX This work is supported by Firat University Scientific Research Projects
   Coordination Unit (FUEBAP) with project & nbsp;number ADEP.23.21.
CR Adu JH, 2012, J MOD OPTIC, V59, P1355, DOI 10.1080/09500340.2012.714802
   Agarap A. F., 2018, ARXIV
   Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Amin-Naji M, 2020, J AMB INTEL HUM COMP, V11, P1749, DOI 10.1007/s12652-019-01199-0
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Amin-Naji M, 2017, IRAN CONF MACH, P45, DOI 10.1109/IranianMVIP.2017.8342367
   Anish A, 2012, INT J ADV RES COMPUT, V1
   Aslantas Veysel, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P492, DOI 10.1109/SIU.2009.5136440
   Aymaz S, 2019, INFORM FUSION, V45, P113, DOI 10.1016/j.inffus.2018.01.015
   Balasubramaniam P, 2014, INFORM FUSION, V20, P21, DOI 10.1016/j.inffus.2013.10.011
   Bhat S, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107307
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712
   Chen WB, 2019, J INTELL SYST, V28, P505, DOI 10.1515/jisys-2017-0078
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   De I, 2006, IMAGE VISION COMPUT, V24, P1278, DOI 10.1016/j.imavis.2006.04.005
   Deighan AJ, 1997, GEOPHYSICS, V62, P1896, DOI 10.1190/1.1444290
   Diwakar M, 2020, MATER TODAY-PROC
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Gogu LB, 2021, MATER TODAY-PROC
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Goudarzi AR, 2012, EARTH SCI RES J, V16, P31
   Guo LQ, 2012, OPT EXPRESS, V20, P18846, DOI 10.1364/OE.20.018846
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   Han ZZ, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104888
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Hua KL, 2014, J VIS COMMUN IMAGE R, V25, P951, DOI 10.1016/j.jvcir.2014.02.009
   inik O., 2017, Gaziosmanpasa Journal of Scientific Research, V6, P85
   Jiang Q, 2017, IEEE ACCESS, V5, P20286, DOI 10.1109/ACCESS.2017.2758644
   Jinju J, 2019, ENG SCI TECHNOL, V22, P715, DOI 10.1016/j.jestch.2019.01.004
   Karlik B., 2011, INT J ARTIF INTELL E, V1, P111, DOI DOI 10.1088/1742-6596/1237/2/022030
   Kaur G, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1420, DOI 10.1109/ICEEOT.2016.7754918
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Li YY, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070522
   Liu YP, 2014, SIGNAL PROCESS, V97, P9, DOI 10.1016/j.sigpro.2013.10.010
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2017, J VIS COMMUN IMAGE R, V45, P46, DOI 10.1016/j.jvcir.2017.02.006
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Meng FJ, 2017, COMPUT ELECTR ENG, V62, P375, DOI 10.1016/j.compeleceng.2016.09.019
   Miao QG, 2011, CHIN OPT LETT, V9, DOI 10.3788/COL201109.041001
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Ozyurt F, 2020, J SUPERCOMPUT, V76, P8413, DOI 10.1007/s11227-019-03106-y
   Ozyurt F, 2020, SOFT COMPUT, V24, P8163, DOI 10.1007/s00500-019-04383-8
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Qiang Zhang, 2007, 2007 IEEE International Conference on Control and Automation, ICCA 2007, P3239, DOI 10.1109/ICCA.2007.4376961
   Ramakrishnan V., 2020, SN Comput. Sci, V1, P326, DOI [10.1007/s42979-020-00343-4, DOI 10.1007/S42979-020-00343-4]
   Saeedi J, 2009, LECT NOTES COMPUT SC, V5856, P970, DOI 10.1007/978-3-642-10268-4_113
   Saeedi J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P420, DOI 10.1109/ICICISYS.2009.5357648
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Varga D, 2020, SIGNAL IMAGE VIDEO P, V14, P1265, DOI 10.1007/s11760-020-01664-w
   Varga D, 2017, EUR SIGNAL PR CONF, P1559, DOI 10.23919/EUSIPCO.2017.8081471
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wan T, 2009, IEEE T MULTIMEDIA, V11, P624, DOI 10.1109/TMM.2009.2017640
   Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253
   Wang Q., 2016, JOIG, V21, P1295, DOI 10.11834/jig.20161004
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Xia XH, 2018, SIGNAL PROCESS, V153, P71, DOI 10.1016/j.sigpro.2018.07.004
   Xu KP, 2018, KSII T INTERNET INF, V12, P2253, DOI 10.3837/tiis.2018.05.019
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang Y, 2017, IEEE ACCESS, V5, P6989, DOI [10.1109/ACCESS.2017.26961I9, 10.1109/ACCESS.2017.2696119]
   Yang Y, 2011, PROCEDIA ENGINEER, V24, P177, DOI 10.1016/j.proeng.2011.11.2622
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 80
TC 1
Z9 1
U1 12
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10951
EP 10968
DI 10.1007/s11042-023-16074-6
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800005
DA 2024-07-18
ER

PT J
AU Saini, A
   Singh, D
   Alvarez, M
AF Saini, Aradhya
   Singh, Dharmendra
   Alvarez, Mauricio
TI FishTwoMask R-CNN: Two-stage Mask R-CNN approach for detection of
   fishplates in high-altitude railroad track drone images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Instance segmentation; Drone images; Fishplate instances; Railroad
   track; Faster R-CNN; Mask R-CNN; YOLOv5
AB Maintenance of railroad track safety is of utmost importance as derailment accidents cause significant loss to life and property. Inspection of railroad tracks and their components is necessary in order to ensure security and well-being of goods as well as humans. Fishplate is an essential component in the railroad track environment hence, periodic maintenance of fishplates is an imperative goal. In this paper, we propose a method for detection and segmentation of fishplate instances in high-altitude drone images (DI) for a closer-view and consequent inspection of fishplate instances. For this purpose, a novel two-stage Mask R-CNN-based framework termed as FishTwoMask R-CNN is proposed. A new fine-tuning strategy has been developed for the purpose of improving the detections in the second stage (Stage 2) which includes a training trick of modifying the loss weights for Stage 2 training. In the first stage (Stage 1), we detect fishplate instances, which are then cropped and fed as input to Stage 2, along with Stage 1 dataset. The Stage 2 network is then trained through a modified weighted loss and produces final detections for segmentation and further inspection. The"layers" hyper-parameter is assigned as "heads" for Stage 1 and updated to "4 + " for Stage 2. Also, the critical analysis of Mask R-CNN hyper-parameters has been carried out during both the stages which has lead to an improved detection precision rate of 97% in Stage 2 as opposed to 47% in Stage 1. We evaluate our proposed approach on five different test image scenarios in order to view fishplate instance detection results. There has been statistical evaluation on out-of-distribution test images also in order to compute the metrics values. The comparative results have been evaluated using metrics of precision, recall, and F1-score on Mask R-CNN Stage 1 and Stage 2 along with Faster R-CNN and YOLOv5 methods. It is inferred that the proposed approach achieves appreciable metrics values and thus can be gathered suitable for fishplate instance segmentation in drone images.
C1 [Saini, Aradhya; Singh, Dharmendra] Indian Inst Technol, Dept Elect & Commun Engn, Roorkee, Uttarakhand, India.
   [Saini, Aradhya; Singh, Dharmendra] RailTel IIT Roorkee Ctr Excellence Telecommun, Roorkee, Uttarakhand, India.
   [Alvarez, Mauricio] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; University of Sheffield
RP Singh, D (corresponding author), Indian Inst Technol, Dept Elect & Commun Engn, Roorkee, Uttarakhand, India.; Singh, D (corresponding author), RailTel IIT Roorkee Ctr Excellence Telecommun, Roorkee, Uttarakhand, India.
EM dharmfec@gmail.com
CR Bharath B, 2017, INT CONF COMPUT POW, P43, DOI 10.1109/ICCPEIC.2017.8290336
   Bhat S, 2021, SMART RAILWAY TRACK
   Buggy SJ, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/5/055201
   Chen Z, 2022, MEASUREMENT
   Du C, 2020, SENSOR ACTUAT A-PHYS, V303, DOI 10.1016/j.sna.2019.111728
   Gao M, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814019891570
   Gavai G., 2019, ELECT IMAGING, V2019, P360
   Güçlü E, 2022, 2022 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATIONS (DASA), P1416, DOI 10.1109/DASA54658.2022.9765117
   Guo F, 2021, TRANSPORT RES REC, V2675, P655, DOI 10.1177/03611981211019034
   Guo F, 2021, COMPUT-AIDED CIV INF, V36, P362, DOI 10.1111/mice.12625
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hodge VJ, 2015, IEEE T INTELL TRANSP, V16, P1088, DOI 10.1109/TITS.2014.2366512
   Kafetzis D, 2020, INT CONF UNMAN AIRCR, P1491, DOI [10.1109/ICUAS48674.2020.9213928, 10.1109/icuas48674.2020.9213928]
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Liu JH, 2020, INT J SOFTW ENG KNOW, V30, P941, DOI 10.1142/S0218194020400136
   Madheswari K, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2826, DOI 10.1109/TENCON.2016.7848558
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Nayan MMR, 2020, PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P310, DOI 10.1109/ICECE51571.2020.9393036
   Rampriya RS, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2021.2018184
   Ravichandran A, 2017, INT CONF COMPUT POW, P68, DOI 10.1109/ICCPEIC.2017.8290341
   Saini A, 2022, INT GEOSCI REMOTE SE, P4891, DOI 10.1109/IGARSS46834.2022.9883490
   Saini A, 2021, PATTERN ANAL APPL, V24, P1549, DOI 10.1007/s10044-021-00994-w
   Saini A, 2020, INT GEOSCI REMOTE SE, P2237, DOI 10.1109/IGARSS39084.2020.9323630
   Saini A, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P33, DOI 10.1109/ISIVC.2018.8709170
   Singh PP, 2015, J INDIAN SOC REMOTE, V43, P851, DOI 10.1007/s12524-014-0435-z
   Singh PP, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083526
   Sumit SS., 2020, J PHYS C SER, V1529
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Waleed A, 2017, GITHUB REPOSITORY
   Wu YP, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2022.101819
   Yilmazer M, 2022, 2022 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATIONS (DASA), P1363, DOI 10.1109/DASA54658.2022.9765024
   Zheng DY, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/2565500
NR 33
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10367
EP 10392
DI 10.1007/s11042-023-15924-7
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600004
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Xia, L
   Zhao, JQ
   Yao, R
   Liu, B
AF Zhou, Yong
   Xia, Lei
   Zhao, Jiaqi
   Yao, Rui
   Liu, Bing
TI Efficient convolutional neural networks and network compression methods
   for object detection: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Efficient convolutional neural network; Object detection; Review; Deep
   learning; Computer vision
ID REMOTE-SENSING IMAGES; VEHICLE DETECTION; TARGET DETECTION;
   CLASSIFICATION
AB Object detection is one of the most basic and important research tasks in the field of computer vision. The general trend in object detection has been to design large and over-parameterized models, which can achieve excellent performance. However, this comes at the expense of low speed, heavy computation and large amount of memory overhead, also makes object detection models more difficult to be applied on mobiles and embedded devices which have limited hardware resources and need real-time feedback. So there has been rising interest in building portable and efficient networks for object detection in the recent literature. The main contributions of this review include the following aspects. As far as we know, there are few reviews on efficient object detection CNNs. We systematically summarize the methods, models and evaluation metrics of efficient CNNs for object detection in recent years. We summarize and introduce some commonly used datasets for object detection. Finally, we point out some possible research directions and inspire some useful suggestions for the future work of efficient convolutional neural network.
C1 [Zhou, Yong; Xia, Lei; Zhao, Jiaqi; Yao, Rui; Liu, Bing] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
   [Zhou, Yong; Xia, Lei; Zhao, Jiaqi; Yao, Rui; Liu, Bing] Minstry Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou 221116, Peoples R China.
   [Zhao, Jiaqi] China Univ Min & Technol, Innovat Res Ctr Disaster Intelligent Prevent & Eme, Xuzhou, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Zhao, JQ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.; Zhao, JQ (corresponding author), Minstry Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou 221116, Peoples R China.; Zhao, JQ (corresponding author), China Univ Min & Technol, Innovat Res Ctr Disaster Intelligent Prevent & Eme, Xuzhou, Peoples R China.
EM yzhou@cumt.edu.cn; ts19170021a31@cumt.edu.cn; jiaqizhao@cumt.edu.cn;
   ruiyao@cumt.edu.cn; liubing@cumt.edu.cn
FU National Natural Science Foundation of China [62272461, 62172417,
   62276266]; Natural Science Foundation of Jiangsu Province [BK20201346];
   "Double First-Class" Project of China University of Mining and
   Technology for Independent Innovation and Social Service [2022ZZCX06];
   Six Talent Peaks Project in Jiangsu Province [2015-DZXX-010,
   2018-XYDXX-044]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (No. 62272461, 62172417, 62276266), and the Natural
   Science Foundation of Jiangsu Province (No. BK20201346), the "Double
   First-Class" Project of China University of Mining and Technology for
   Independent Innovation and Social Service under Grant 2022ZZCX06, the
   Six Talent Peaks Project in Jiangsu Province (No. 2015-DZXX-010,
   2018-XYDXX-044).
CR Agarwal S., 2018, ARXIV
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   [Anonymous], 2016, ARXIV
   [Anonymous], 2016, ICML
   Ba LJ, 2014, ADV NEUR IN, V27
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Cai, 2019, INT C LEARNING REPRE
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen GB, 2017, ADV NEUR IN, V30
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LJ, 2018, ADV NEUR IN, V31
   Chen YK, 2019, ADV NEUR IN, V32
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Cheng Yu, 2017, ARXIV
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chu X, 2019, ARXIV
   Courbariaux M., 2016, ARXIV
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dai J, 2015, ARXIV
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Charette R, 2009, IEEE INT VEH SYM, P358, DOI 10.1109/IVS.2009.5164304
   Dean J., 2015, NIPS DEEP LEARNING R
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Dong XY, 2019, IEEE I CONF COMP VIS, P3680, DOI 10.1109/ICCV.2019.00378
   Du YL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1610
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fan Y, 2016, 2016 IEEE C COMPUTER
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PF, 2012, RIGID TEMPLATES GRAM
   Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584
   Frankle J., 2019, ARXIV
   Gale T., 2019, ARXIV
   Gao M, 2017, COMPUTER VISION PATT
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gerards MET, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400700
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Ghodrati A, 2015, ARXIV
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R. B., 2011, Advances in Neural Information Processing Systems, P442
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Guo Y, 2016, ARXIV
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han K, 2019, ARXIV
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Han  S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hanson SJ., 1989, COMP BIASES MINIMAL, P177
   Hariharan B, 2014, ARXIV
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hassibi B., 1993, P ADV NEUR INF PROC, P164
   Haussler D, 2001, CONVOLUTION KERNELS
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hendrycks D., 2016, ARXIV
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hong S, 2016, COMPUTER VISION PATT
   Houben S, 2013, IEEE IJCNN
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hsu C-H, 2018, ARXIV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang J., ARXIV
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M., 2014, ARXIV
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jiang B, 2018, ARXIV
   Jin X, 2016, ARXIV
   Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kokkinos I, 2012, LECT NOTES COMPUT SC, V7585, P41, DOI 10.1007/978-3-642-33885-4_5
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam D, 2018, ARXIV
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Leather H, 2009, INT SYM CODE GENER, P81, DOI 10.1109/CGO.2009.21
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li B, 2020, ARXIV
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li QQ, 2017, PROC CVPR IEEE, P7341, DOI 10.1109/CVPR.2017.776
   Li YZ, 2017, ADV NEUR IN, V30
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Lin T., 2016, arXiv
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin XF, 2017, ADV NEUR IN, V30
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2017, ARXIV
   Liu S, 2020, ARXIV
   Liu S, 2019, ARXIV
   Liu S, 2022, IEEE INTERNET THINGS
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z., 2019, ICLR
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2014, ARXIV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Luo JH, 2020, ARXIV
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Maji S, 2008, PROC CVPR IEEE, P2245
   Mathieu M, 2013, ARXIV
   Mehrara H, 2009, INT C COMP ELEC ENG, P408, DOI 10.1109/ICCEE.2009.144
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Mukkamala MC, 2017, PR MACH LEARN RES, V70
   Nada H, 2018, INT CONF BIOMETR THE
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Noh H, 2015, ARXIV
   Oksuz K, 2018, LECT NOTES COMPUT SC, V11211, P521, DOI 10.1007/978-3-030-01234-2_31
   Ouyang W, 2017, ARXIV
   Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Parmar N, 2018, PR MACH LEARN RES, V80
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Pratt H, 2017, LECT NOTES ARTIF INT, V10534, P786, DOI 10.1007/978-3-319-71249-9_47
   Ramachandran P., 2017, ARXIV
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, ARXIV
   Rippel O, 2015, ARXIV
   Romero A, 2014, ARXIV
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghi M.A., 2013, Advances in Neural Information Processing Systems (NIPS)
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simard PY, 1999, ADV NEUR IN, V11, P571
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M., 2019, arXiv
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tung F, 2020, IEEE T PATTERN ANAL, V42, P568, DOI 10.1109/TPAMI.2018.2886192
   Tzelepis G, 2019, COMPUTER VISION PATT
   VAILLANT R, 1994, IEE P-VIS IMAGE SIGN, V141, P245, DOI 10.1049/ip-vis:19941301
   Vanhoucke V., 2011, DEEP LEARN UNS FEAT, DOI DOI 10.1109/TED.2016.2545412
   Vasilache N., 2014, Fast convolutional nets with fbfft: A GPU performance evaluation
   Vedaldi A, 2012, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2012.6247943
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang K, 2018, ARXIV
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Watanabe Tomoki, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P39, DOI 10.2197/ipsjtcva.2.39
   Wen W, 2016, ARXIV
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xia G, 2017, COMPUTER VISION PATT
   Yang J, 2015, NUMERICAL ANAL
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yu G., 2021, arXiv
   Zeiler M.D., 2013, arXiv
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S, 2017, ARXIV
   Zhang T, 2017, ARXIV
   Zhang X, 2017, ARXIV
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhang XD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070755
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao Q., 2018, Annals of Statistics
   Zheng M, 2020, ARXIV
   Zheng Z, 2019, ARXIV
   Zhonghe Zhou, 2021, 2021 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC), P709, DOI 10.1109/YAC53711.2021.9486540
   Zhou X., 2019, arXiv
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zhu X., 2020, arXiv
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zhuang L, 2017, COMPUTER VISION PATT
   Zoph B., 2016, INT C LEARN REPR
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou Z, 2019, ARXIV
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 219
TC 2
Z9 2
U1 12
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10167
EP 10209
DI 10.1007/s11042-023-15608-2
EA JUN 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400006
DA 2024-07-18
ER

PT J
AU Gong, X
   Luo, B
AF Gong, Xun
   Luo, Bin
TI Video-based person re-identification with scene and person attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Person attributes; Occlusion; Video-based ReID
ID NETWORK
AB Person re-identification (Re-ID) is an essential computer vision task retrieving a person of interest across multiple non-overlapping cameras. In recent years, video-based person Re-ID research has become more and more popular. Compared with image-based person Re-ID, it can obtain more feature information from multiple frames such as temporal information. However, video-based person Re-ID still faces challenges such as occlusion, multiple people and target changes. Given the above issues, a network integrating person attributes feature and scene attributes feature with person feature is proposed to assist person Re-ID. In our method, the feature of person attributes and scene attributes is re-weighted, making it possible to make full use of the person attribute feature when it is difficult to extract the feature of the person in some problematic cases. Moreover, a strip pooling operation is applied to the person Re-ID network. The horizontal and vertical contextual information is extracted separately through the strip pooling operation, leading to an increased receptive field and improved the person Re-ID accuracy. Extensive experiments on MARS and DukeMTMC-VID datasets show that the proposed methods achieve competitive results with state-of-art methods.
C1 [Gong, Xun; Luo, Bin] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Gong, X (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu, Sichuan, Peoples R China.
EM xgong@swjtu.edu.cn
RI Liu, Yiwei/JUF-2477-2023; peng, jin/JRW-4493-2023; LEI,
   LEI/JTS-4675-2023; Yao, Chen/JVD-6226-2023; lei, lei/JSL-3106-2023;
   Wang, yl/JNR-4963-2023; chen, xu/JNT-3068-2023; Wang, Zhuo/JVO-1874-2024
OI Gong, Xun/0000-0002-1494-0955
FU National Natural Science Foundation of China [61876158]; Fundamental
   Research Funds for the Central Universities [2682021ZTPY030]
FX AcknowledgementsThis work is partly supported by the National Natural
   Science Foundation of China (No.61876158) and the Fundamental Research
   Funds for the Central Universities(2682021ZTPY030).
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Aich A, 2021, ARXIV
   Chen ZT, 2020, PROC INT SYMP SOFTW, P426, DOI 10.1109/ISSRE5003.2020.00047
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Fu Y, 2018, ARXIV
   Gao J., 2018, arXiv
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Layne R, 2012, PERSON RE IDENTIFICA, V2
   Li AN, 2015, IEEE T CIRC SYST VID, V25, P869, DOI 10.1109/TCSVT.2014.2352552
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu C-T, 2019, SPATIALLY TEMPORALLY, P08
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Oliveira I, 2009, OBJECT REIDENTIFICAT, V12
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Song WR, 2019, IEEE ACCESS, V7, P8508, DOI 10.1109/ACCESS.2019.2890836
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xu BQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P673, DOI 10.1145/3394171.3414056
   Yan C, 2022, IEEE T MULTIMEDIA, V24, P1665, DOI 10.1109/TMM.2021.3069562
   Yan Y, 2017, PERSON RE IDENTIFICA, V01
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhiyuan Chen, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P209, DOI 10.1007/978-3-030-31723-2_18
NR 37
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8117
EP 8128
DI 10.1007/s11042-023-15719-w
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400004
DA 2024-07-18
ER

PT J
AU Xiao, BJ
   Nguyen, M
   Yan, WQ
AF Xiao, Bingjie
   Nguyen, Minh
   Yan, Wei Qi
TI Apple ripeness identification from digital images using transformers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLO; Transformer; Object detection
AB We describe a non-destructive test of apple ripeness using digital images of multiple types of apples. In this paper, fruit images are treated as data samples, artificial intelligence models are employed to implement the classification of fruits and the identification of maturity levels. In order to obtain the ripeness classifications of fruits, we make use of deep learning models to conduct our experiments; we evaluate the test results of our proposed models. In order to ensure the accuracy of our experimental results, we created our own dataset, and obtained the best accuracy of fruit classification by comparing Transformer model and YOLO model in deep learning, thereby attaining the best accuracy of fruit maturity recognition. At the same time, we also combined YOLO model with attention module and gave the fast object detection by using the improved YOLO model.
C1 [Xiao, Bingjie; Nguyen, Minh; Yan, Wei Qi] Auckland Univ Technol, Auckland, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland, New Zealand.
EM dcsyanwq@gmail.com
RI Nguyen, Minh/KLD-0648-2024
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Abozeid A, 2022, COMPUTATIONAL INTELL
   Agushinta R.D., 2017, 2017 IEEE 3 INT C EN, P1, DOI [10.1109/ICETSS.2017.8324146, DOI 10.1109/ICETSS.2017.8324146]
   Ahmad T, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8403262
   Alkalouti HN, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P718, DOI 10.1109/IEMTRONICS52119.2021.9422600
   Arivazhagan S., 2010, J. Emerg. Trends Comput. Inf. Sci, V1, P90
   Arkin Ershat, 2021, 2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML), P99, DOI 10.1109/PRML52754.2021.9520732
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Choudhury A., 2021, AGR INFORMATICS AUTO, DOI [10.1002/9781119769231, DOI 10.1002/9781119769231]
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Dou Q., 2021, Int. Core J. Eng, V7, P167
   Fu Y., 2022, SN Comput. Sci, V3, P264, DOI [10.1007/s42979-022-01152-7, DOI 10.1007/S42979-022-01152-7]
   Glorot X., 2011, P 28 INT C INT C MAC, P513
   Han X, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (IEEE ICWS 2019), P383, DOI 10.1109/ICWS.2019.00068
   Hendria WF, 2021, ICT EXPRESS
   Jiménez A, 1999, PATTERN RECOGN, V32, P1719, DOI 10.1016/S0031-3203(98)00170-8
   Kabir MH, 2022, TOXIN REV, V41, P860, DOI 10.1080/15569543.2021.1952436
   Kim S, 2021, IEEE ACCESS, V9, P20828, DOI 10.1109/ACCESS.2021.3054879
   Kousik N, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114064
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Mauri A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020532
   Mekhalfi M, 2021, IEEE GEOSCI REMOTE S
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Nguyen M., 2022, Lecture Notes in Computer Science, V13836, P48, DOI [10.1007/978-3-031-25825-1_4, DOI 10.1007/978-3-031-25825-1_4]
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Qi J, 2022, PACIFIC RIM S IMAGE
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Tang YF, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2020), P1865, DOI 10.1109/ICMCCE51767.2020.00409
   Tang ZY, 2021, APPL INTELL, V51, P9066, DOI 10.1007/s10489-021-02373-8
   Tsai MF, 2021, J SUPERCOMPUT, V77, P6676, DOI 10.1007/s11227-020-03525-2
   Unal H.B., 2020, P 2020 INNOVATIONS I, DOI [10.1109/ASYU50717.2020.9259881, DOI 10.1109/ASYU50717.2020.9259881]
   Wang XQ, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110302
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Xiao B., 2019, APPLE RIPENESS IDENT
   Xiao B., 2021, Commun. Comput. Inf. Sci, P53, DOI [10.1007/978-3-030-72073-5_5, DOI 10.1007/978-3-030-72073-5_5]
   Zhang XS, 2022, IEEE T PATTERN ANAL, V44, P3096, DOI 10.1109/TPAMI.2021.3050494
   Zhao K, 2021, INT S GEOM VIS ISGV
NR 37
TC 4
Z9 5
U1 24
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7811
EP 7825
DI 10.1007/s11042-023-15938-1
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, SH
AF Zhang, Shaohua
TI ParaViewWeb architecture method of power security emergency drill
   platform based on VR technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VR technology; Power safety; Emergency drill platform; Paraview web
   architecture; 3D scene; Message distribution
AB In order to improve the proficiency and response ability of emergency command and rescue personnel at all levels on emergency responsibilities and processes, and reduce casualties and property losses caused by emergencies, a ParaViewWeb architecture method of power security emergency drill platform based on VR technology is proposed to improve the actual completion of the drill. Using the scalability of ParaViewWeb architecture, a power security emergency drill platform based on VR technology is built. In the platform, the self-learning algorithm for power safety emergency drills based on big data and deep learning is used to manage power data. Based on the processed data, three-dimensional scenes, mathematical models and pre-plan reasoning are established through VR technology, and gesture recognition algorithms are used to realize man-machine interaction; according to the 3D drill scenario based on VR technology, the message distribution mechanism, emergency drill mechanism and drill execution mechanism in the emergency drill platform is built to complete the power security emergency drill. The experimental results show that this method has high accuracy in character gesture recognition, can increase the purpose of message transmission, reduce the overhead waste and unnecessary transmission hopes of information transmission, and save the time of message transmission; the actual completion of the drill is very close to the expected completion, and the integrity of the emergency drill is high.
C1 [Zhang, Shaohua] Wuhan Univ Technol, Sch Management, Wuhan 430070, Peoples R China.
   [Zhang, Shaohua] State Grid Ningxia Elect Power Co Ltd, Yinchuan 750001, Peoples R China.
C3 Wuhan University of Technology
RP Zhang, SH (corresponding author), Wuhan Univ Technol, Sch Management, Wuhan 430070, Peoples R China.; Zhang, SH (corresponding author), State Grid Ningxia Elect Power Co Ltd, Yinchuan 750001, Peoples R China.
EM zhangjiu17047@163.com
RI Zhang, Shaohua/ABD-9226-2020
CR Ajibodu FA., 2020, AM J ENG RES, V9, P106
   Akulichev VO., 2021, SAFETY RELIABILITY P, V13, P248, DOI [10.24223/1999-5555-2020-13-4-248-256, DOI 10.24223/1999-5555-2020-13-4-248-256]
   Baker S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102105
   Bazyar J, 2020, PREHOSP DISASTER MED, V35, P305, DOI 10.1017/S1049023X20000291
   Burlov Vyacheslav, 2021, E3S Web of Conferences, V274, DOI 10.1051/e3sconf/202127410004
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   da Silva JR, 2019, INT J DIGIT LIBRARIE, V20, P185, DOI 10.1007/s00799-018-0238-x
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Jian CF, 2019, IET IMAGE PROCESS, V13, P991, DOI 10.1049/iet-ipr.2018.5959
   Kondratiuk SS., 2019, ARTIF INTELL, V24, P107
   Lee J, 2021, INFORM SYST, V97, DOI 10.1016/j.is.2020.101686
   [刘玉杰 Liu Yujie], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P104
   Mai W. X., 2020, Journal of Biomedical Science and Engineering, V13, P66, DOI DOI 10.4236/JBISE.2020.135006
   Mohammadpourfard M, 2019, IET GENER TRANSM DIS, V13, P1441, DOI 10.1049/iet-gtd.2018.6801
   Pavlic J, 2022, J RES INTERACT MARK, V16, P551, DOI 10.1108/JRIM-02-2021-0041
   Polyukhovich Maxim, 2019, E3S Web of Conferences, V140, DOI 10.1051/e3sconf/201914008006
   Shalkevich L.V., 2020, J GRODNO STATE MEDIC, V18, P716, DOI [10.25298/2221-8785-2020-18-6-716-721, DOI 10.25298/2221-8785-2020-18-6-716-721]
   Yang Z. J., 2019, Computer Simulation, V36, P432, DOI [10.3969/j.issn.1006-9348.2019.04.090, DOI 10.3969/J.ISSN.1006-9348.2019.04.090]
   Yim MYC, 2019, J BUS RES, V100, P581, DOI 10.1016/j.jbusres.2018.10.041
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
   Zhou ZH, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9801-4
   Zhu S., 2019, HUNAN ELECT POWER, V39, P5
NR 22
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6447
EP 6467
DI 10.1007/s11042-023-15934-5
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003483000002
DA 2024-07-18
ER

PT J
AU Huang, LC
   Wang, ZW
   Fu, XB
AF Huang, Lincai
   Wang, Zhiwen
   Fu, Xiaobiao
TI Pedestrian detection using RetinaNet with multi-branch structure and
   double pooling attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE pedestrian detection; RetinaNet; multi-branch construction; double
   pooling attention mechanism
ID NETWORK
AB Pedestrian detection technology, combined with techniques such as pedestrian tracking and behavior analysis, can be widely applied in fields closely related to people's lives such as traffic, security, and machine interaction. However, the multi-scale changes of pedestrians have always been a challenge for pedestrian detection. Aiming at the shortcomings of the traditional RetinaNet algorithm in multi-scale pedestrian detection, such as false detection, missed detection, and low detection accuracy, an improved RetinaNet algorithm is proposed to enhance the detection ability of the network model. This paper mainly makes innovations in the following two aspects. Firstly, in order to obtain more semantic information, we use a multi-branch structure to expand the network and extract the characteristics of different receptive fields at different depths. Secondly, in order to make the model pay more attention to the important information of pedestrian features, double pooling attention mechanism module is embedded in the prediction head of the model to enhance the correlation of feature information between channels, suppress unimportant information, and improve the detection accuracy of the model. Experiments were conducted on different datasets such as the COCO dataset, and the results showed that compared with the traditional RetinaNet model, the model proposed in this paper has improved in various evaluation indicators and has good performance, which can meet the needs of pedestrian detection.
C1 [Huang, Lincai; Fu, Xiaobiao] Guangxi Univ Sci & Technol, Sch Automat, Liuzhou 545000, Guangxi, Peoples R China.
   [Wang, Zhiwen] Guangxi Univ Sci & Technol, Sch Comp Sci & Technol, Liu Zhou 545000, Guangxi, Peoples R China.
C3 Guangxi University of Science & Technology; Guangxi University of
   Science & Technology
RP Wang, ZW (corresponding author), Guangxi Univ Sci & Technol, Sch Comp Sci & Technol, Liu Zhou 545000, Guangxi, Peoples R China.
EM wzw69@126.com
RI wang, jun/JPY-3635-2023; zhang, wen/JXN-0191-2024; Han,
   Yang/JVN-5921-2024; liu, xiao/JLL-2119-2023; Li, Lei/JPE-6543-2023;
   Yang, Fan/JMA-9594-2023; wang, yi/JYO-8193-2024; zhang,
   xiang/JJD-7003-2023; Liu, Jingyi/JWP-6326-2024; Liu, qi/JZT-5038-2024;
   Li, Yan/JRW-0176-2023; Zhang, Bo/JVD-9890-2024; WANG,
   YING/JLM-9219-2023; Wang, Yue/JRY-8962-2023; Wang, Jing/JRW-1512-2023;
   Zhang, Yuan/JUF-7293-2023; LI, YUN/JTV-7108-2023; wang,
   zhiwen/JDV-9990-2023; Zhang, Yanyan/JFA-9161-2023; zhang,
   yan/JGL-8022-2023; Wang, Han/JJF-2614-2023; Zhang, Jinfan/JPK-7588-2023;
   li, rui/JVM-8999-2024; Wen, Jing/KCL-6614-2024; yang, liu/JXX-5043-2024;
   liu, yang/JMB-9083-2023; li, Li/JPA-0218-2023; Yang, Fan/JVO-8611-2024;
   wang, xiaoqiang/JMT-2783-2023; Yang, Min/JPY-3791-2023; Zhang,
   Jun/JPK-7723-2023; chen, yan/JRY-4645-2023; WANG, JIAXUAN/JMP-8599-2023;
   wang, KiKi/JFZ-3334-2023; Li, Wei/JLL-4365-2023; Li, Yan/JUU-5189-2023;
   wen, liang/JNR-7720-2023; XIE, WANYING/JNR-9259-2023; Zhang,
   Lijun/JEZ-7925-2023
OI Wang, Yue/0000-0001-8673-6358; wang, zhiwen/0000-0003-2309-7282
FU National Natural Science Foundation of China [6192007, 61866004,
   FEDOP2022A06, 2018GXNSFDA294001, 2018GXNSFDA281009]; Key projects of
   Guangxi Natural Science Foundation [202210594038, 202210594041]; Guangxi
   Key Laboratory of Big Data in Finance and Economics [MIMS19-04]; 2020
   Guangxi Education Department Degree and Postgraduate Education Reform
   Project [gxkjdx201504]; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining Security [202210594036]; 2015 Innovation Team Project
   of Guangxi University of Science and Technology [202210594037]; College
   Students' Innovative Entrepreneurial Training [62266009, 61462008,
   202110594133, 202110594134];  [61751213];  [20210121210028]
FX This work was funded by the National Natural Science Foundation of
   China, grant number 6192007, 62266009,61462008, 61751213, 61866004; the
   Key projects of Guangxi Natural Science Foundation, grant number
   2018GXNSFDA294001,2018GXNSFDA281009; Guangxi Key Laboratory of Big Data
   in Finance and Economics, Grant No. FEDOP2022A06; 2020 Guangxi Education
   Department Degree and Postgraduate Education Reform Project, grant
   number 20210121210028; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining & Security, grant number MIMS19-04; 2015 Innovation
   Team Project of Guangxi University of Science and Technology, grant
   number gxkjdx201504; College Students' Innovative Entrepreneurial
   Training, grant number 202210594036, 202210594037,
   202210594038,202210594041,202110594133,202110594134.
CR Brazil G, 2019, PROC CVPR IEEE, P7224, DOI 10.1109/CVPR.2019.00740
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao JW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133646
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Du KX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197594
   Flores-Calero M, 2019, IEEE LAT AM T, V17, P1552, DOI [10.1109/tla.2019.8931190, 10.1109/TLA.2019.8931190]
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Gawande U, 2022, APPL INTELL, V52, P10398, DOI 10.1007/s10489-021-03073-z
   Ge Z, 2021, NEUROCOMPUTING, V462, P272, DOI 10.1016/j.neucom.2021.07.094
   He Y, 2023, MULTIMED SYSTEM, P1
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Hsu WY, 2021, IEEE ACCESS, V9, P110063, DOI 10.1109/ACCESS.2021.3102600
   Ji QG, 2018, IET IMAGE PROCESS, V12, P133, DOI 10.1049/iet-ipr.2016.0044
   Jiang QY, 2022, IEEE ACCESS, V10, P53797, DOI 10.1109/ACCESS.2022.3175303
   Kumar K, 2020, MULTIMED TOOLS APPL, V79, P21389, DOI 10.1007/s11042-020-08864-z
   Lei Han, 2021, 2021 International Conference on Big Data Analysis and Computer Science (BDACS), P1, DOI 10.1109/BDACS53596.2021.00008
   Li GY, 2020, SENSOR MATER, V32, P1997, DOI 10.18494/SAM.2020.2787
   Li GF, 2020, IEEE T IND ELECTRON, V67, P8889, DOI 10.1109/TIE.2019.2945295
   Li ML, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25020381
   Li QM, 2021, INFORM SCIENCES, V550, P1, DOI 10.1016/j.ins.2020.10.049
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lv HH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155903
   Ma J, 2021, J REAL-TIME IMAGE PR, V18, P1965, DOI 10.1007/s11554-021-01074-2
   Mihçioglu ME, 2019, TRAFFIC INJ PREV, V20, P619, DOI 10.1080/15389588.2019.1624731
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Nataprawira J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072536
   Pei DS, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103178
   Qiu J, 2020, ELECTRON LETT, V56, P706, DOI 10.1049/el.2020.0850
   Qiu ML, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14143498
   Ramirez I, 2020, NEURAL COMPUT APPL, V32, P13203, DOI 10.1007/s00521-018-3390-8
   Ren J, 2021, J ELECTR ENG TECHNOL, V16, P1151, DOI 10.1007/s42835-021-00673-0
   Shao X, 1820, SENSORS-BASEL, V21
   Sun C, 2022, PATTERN ANAL APPL, V25, P853, DOI 10.1007/s10044-022-01076-1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Wang MJ, 2021, IET INTELL TRANSP SY, V15, P837, DOI 10.1049/itr2.12066
   Wang ZW, 2022, MULTIMED TOOLS APPL, V81, P39655, DOI 10.1007/s11042-022-13058-w
   Wei Li, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1052, DOI 10.1109/IAEAC50856.2021.9390896
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao F, 2020, MULTIMED TOOLS APPL, V79, P14593, DOI 10.1007/s11042-018-7143-6
   Xiao YQ, 2021, IET IMAGE PROCESS, V15, P286, DOI 10.1049/ipr2.12042
   Xie H, 2019, APPL INTELL, V49, P1200, DOI 10.1007/s10489-018-1326-8
   Xue P, 2023, IET COMPUT VIS, V17, P13, DOI 10.1049/cvi2.12125
   Xue YJ, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103906
   Zhang C, 2019, MULTIMED TOOLS APPL, V78, P1719, DOI 10.1007/s11042-018-6240-x
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang Q, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073587
   Zhang XW, 2020, IEEE ACCESS, V8, P94429, DOI 10.1109/ACCESS.2020.2995321
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhou HZ, 2021, FUTURE GENER COMP SY, V125, P604, DOI 10.1016/j.future.2021.06.016
NR 51
TC 5
Z9 5
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15862-4
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000006
DA 2024-07-18
ER

PT J
AU Hong, X
   Zhang, LW
   Yu, XY
   Xie, W
   Xie, YM
AF Hong, Xing
   Zhang, Langwen
   Yu, Xiaoyuan
   Xie, Wei
   Xie, Yumin
TI MBA-Net: multi-branch attention network for occluded person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person Re-identification; Occlusion; Feature refinement; Attention
   mechanism
AB Occluded person re-identification (ReID) aims to retrieve the same pedestrian from partially occluded pedestrian images across non-overlapping cameras. Current state-of-the-art methods generally use auxiliary models to obtain non-occluded regions, which not only result in more complex models, but also cannot effectively handle the more generalized ReID task. To this end, a Multi-Branch Attention Network (MBA-Net) is proposed to achieve multi-level refinement of features through an end-to-end multi-branch framework with attention mechanisms. Specifically, we first achieve preliminary feature refinement through a backbone network with a non-local attention mechanism. Then, a two-level multi-branch architecture in MBA-Net is proposed with two-level features refinement to obtain aware local discriminative features from the self-attention branch, non-occluded local complementary features from the cross-attention branch, and global features from the global branch. Finally, we can obtain retrieval features that are robust to occlusion by concatenating all the above features. Experimental results show that our MBA-Net achieves state-of-the-art performance on an occluded person ReID dataset Occluded-Duke and simultaneously achieves competitive performance on two general person ReID datasets Market-1501 and DukeMTMC-ReID.
C1 [Hong, Xing; Zhang, Langwen; Xie, Wei; Xie, Yumin] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Langwen; Xie, Wei] South China Univ Technol, Key Lab Autonomous Syst & Networked Control, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Langwen; Xie, Wei] South China Univ Technol, Guangdong Prov Key Lab Tech & Equipment Macromol A, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Langwen; Xie, Wei] South China Univ Technol, Unmanned Aerial Vehicle Syst Engn Technol Res Ctr, Guangzhou, Guangdong, Peoples R China.
   [Yu, Xiaoyuan] South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; South China University of Technology; South China University
   of Technology; South China Normal University
RP Hong, X (corresponding author), South China Univ Technol, Sch Automat Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM auhongxing@mail.scut.edu.cn; aulwzhang@scut.edu.cn;
   xiaoyuanyu@scnu.edu.cn; weixie@scut.edu.cn; au_ymxie@mail.scut.edu.cn
RI xie, jing/KDO-9486-2024; YANG, DAN/KCL-5217-2024; CAO,
   ying/KFA-2972-2024
OI Hong, Xing/0000-0002-1873-0269
FU National Natural Science Foundation of China [61803161]; Natural Science
   Foundation of Guangdong Province [2023A1515030119, 2022A1515011887,
   2022A1515110119]; Science and Technology Plan Project of Jiangmen
   [2020030103080008999]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 61803161; in part by the Natural
   Science Foundation of Guangdong Province under Grant 2023A1515030119,
   Grant 2022A1515011887 and Grant 2022A1515110119; in part by the Science
   and Technology Plan Project of Jiangmen under Grant 2020030103080008999.
CR [Anonymous], 2019, ADV NEUR IN
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen WB, 2022, MULTIMED TOOLS APPL, V81, P4649, DOI 10.1007/s11042-020-10494-4
   Chen Y, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104587
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   He LX, 2020, Arxiv, DOI arXiv:2006.02631
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Jin HY, 2022, IEEE T CIRC SYST VID, V32, P2170, DOI 10.1109/TCSVT.2021.3088446
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ren XN, 2022, LECT NOTES COMPUT SC, V13141, P325, DOI 10.1007/978-3-030-98358-1_26
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shi YX, 2022, NEUROCOMPUTING, V486, P237, DOI 10.1016/j.neucom.2021.11.038
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang HX, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104186
   Wang LB, 2022, APPL INTELL, V52, P7407, DOI 10.1007/s10489-021-02820-6
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu WY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107424
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P32079, DOI 10.1007/s11042-020-09569-z
   Xu YJ, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106554
   Yang J, 2022, NEURAL COMPUT APPL, V34, P8241, DOI 10.1007/s00521-022-06903-4
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou QQ, 2020, IEEE T IMAGE PROCESS, V29, P7578, DOI 10.1109/TIP.2020.3004267
   Zou GF, 2021, MULTIMED TOOLS APPL, V80, P26855, DOI 10.1007/s11042-021-10953-6
NR 49
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15312-1
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400006
DA 2024-07-18
ER

PT J
AU Kumar, M
   Biswas, M
AF Kumar, Manoj
   Biswas, Mantosh
TI Abnormal human activity detection by convolutional recurrent neural
   network using fuzzy logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abnormal human activity; Fuzzy logic; Transfer learning; Deep learning
ID ACTION RECOGNITION; ANOMALY DETECTION; SURVEILLANCE; FRAMEWORK;
   FEATURES; BAG
AB In automated video surveillance applications, detecting abnormal human activity is incredibly difficult to classify them. The automatic detection of aberrant human activity in a surveillance system was resolved in our proposed work. The videos are first turned into frames, and keyframes from a batch of frames are extracted using fuzzy logic. Secondly, the features are retrieved from the keyframes using a pre-train convolutional neural network (CNN) through transfer learning. Finally, to recognize anomalous activity from video, the collected features are loaded into a Long-Short Term Memory (LSTM) based recurrent network. Two benchmark datasets were used to evaluate the proposed methodology: the UCF50 and the UCF-crime, with our model achieving 95.04% and 49.04% accuracy, respectively. Using the same data set, the experimental findings are compared to conventional detection approaches which suggest that our proposed model outperforms the other approaches that were compared.
C1 [Kumar, Manoj] JSS Acad Tech Educ, Noida, UP, India.
   [Kumar, Manoj] Natl Inst Technol, Kurukshetra, Haryana, India.
   [Biswas, Mantosh] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Kumar, M (corresponding author), JSS Acad Tech Educ, Noida, UP, India.; Kumar, M (corresponding author), Natl Inst Technol, Kurukshetra, Haryana, India.
EM manojkumar@jssaten.ac.in
RI KUMAR, MANOJ/ADH-0406-2022
OI KUMAR, MANOJ/0000-0001-5259-4208
CR Asad M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103047
   Biswas S, 2018, IEEE WINT CONF APPL, P1615, DOI 10.1109/WACV.2018.00180
   Chandrakala S, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116168
   Crispim CF Jr, 2016, IEEE T PATTERN ANAL, V38, P1598, DOI 10.1109/TPAMI.2016.2537323
   Cui XC, 2022, ALEX ENG J, V61, P2899, DOI 10.1016/j.aej.2021.08.020
   Hassan E, 2021, PATTERN RECOGN LETT, V151, P200, DOI 10.1016/j.patrec.2021.08.017
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hou JY, 2018, IEEE T MULTIMEDIA, V20, P1537, DOI 10.1109/TMM.2017.2771462
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Hussain T, 2021, IEEE INTERNET THINGS, V8, P9634, DOI 10.1109/JIOT.2020.3027483
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kuehne H, 2020, IEEE T PATTERN ANAL, V42, P765, DOI 10.1109/TPAMI.2018.2884469
   Kumar M, 2021, Solid State Technology, V64, P6489
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li WH, 2018, IEEE ACCESS, V6, P44211, DOI 10.1109/ACCESS.2018.2863943
   Lin ZH, 2021, AUTOMAT CONSTR, V124, DOI 10.1016/j.autcon.2021.103572
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Mehboob F, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P188, DOI 10.1109/SAI.2016.7555981
   Muhammad K, 2021, FUTURE GENER COMP SY, V125, P820, DOI 10.1016/j.future.2021.06.045
   Muhammad K, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444693
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Özyer T, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106995
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P549, DOI 10.1109/TCSVT.2019.2894161
   Sekma M, 2015, PATTERN RECOGN LETT, V65, P37, DOI 10.1016/j.patrec.2015.06.029
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh Dushyant Kumar, 2020, Procedia Computer Science, V171, P350, DOI 10.1016/j.procs.2020.04.036
   Singh D, 2021, FUTURE GENER COMP SY, V125, P687, DOI 10.1016/j.future.2021.07.015
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun L, 2020, IEEE IMAGE PROC, P2121, DOI 10.1109/ICIP40778.2020.9191072
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Ullah A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207595
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Ullah A, 2019, IEEE T IND ELECTRON, V66, P9692, DOI 10.1109/TIE.2018.2881943
   Ullah W, 2022, FUTURE GENER COMP SY, V129, P286, DOI 10.1016/j.future.2021.10.033
   Ullah W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082811
   Uzzaman M.S., 2022, SSRN Electronic Journal, DOI [10.2139/ssrn.4173741, DOI 10.2139/SSRN.4173741]
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Xin M, 2016, NEUROCOMPUTING, V178, P87, DOI 10.1016/j.neucom.2015.09.112
   Yahaya SW, 2021, PATTERN RECOGN LETT, V145, P200, DOI 10.1016/j.patrec.2021.02.006
   Yuan SH, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2021.102221
   Zhang R., 2017, Applications and Techniques in Information Security, P157
   Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhu Y, 2019, Arxiv, DOI arXiv:1907.10211
NR 48
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15904-x
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400001
DA 2024-07-18
ER

PT J
AU Kacem, A
   Zbiss, K
   Watta, P
   Mohammadi, A
AF Kacem, Amal
   Zbiss, Khalil
   Watta, Paul
   Mohammadi, Alireza
TI Wave space sonification of the folding pathways of protein molecules
   modeled as hyper-redundant robotic mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sonification; Protein folding; Hyper-redundant robots; Wave Space
   Sonification (WSS)
ID KINEMATICS; MANIPULATORS; MUSIC
AB Investigation of the folding pathways of protein molecules plays a key role in studying diseases such as Alzheimer's and designing viral drugs at the molecular level. Despite recent advances in visualization techniques, effective sonification (i.e., non-speech auditory representation) of large datasets associated with protein folding pathways is still an open question. This paper investigates the problem of sonification of protein folding pathway datasets by using the wave space sonification (WSS) framework due to Hermann (2018). In particular, this paper utilizes the powerful WSS framework to develop a sonification methodology for the dihedral angle folding trajectories of protein molecules, which are modeled as hyper-redundant robotic mechanisms with many rigid nano-linkages. As an example, the developed sonification methodology is applied to a protein molecule backbone chain with a dihedral angle space of dimension 82, where a canonical wave space function based on a sum-of-sinusoids with conformation-dependent frequencies and a sample-based wave space function based on Mozart's Alla Turca are utilized for sonification of the folding trajectories of this peptide chain.
C1 [Kacem, Amal; Zbiss, Khalil; Watta, Paul; Mohammadi, Alireza] Univ Michigan Dearborn, Dept Elect & Comp Engn, 4901 Evergreen Rd, Dearborn, MI 48128 USA.
C3 University of Michigan System; University of Michigan Dearborn
RP Mohammadi, A (corresponding author), Univ Michigan Dearborn, Dept Elect & Comp Engn, 4901 Evergreen Rd, Dearborn, MI 48128 USA.
EM akacem@umich.edu; kzbiss@umich.edu; watta@umich.edu; amohmmad@umich.edu
OI Mohammadi, Alireza/0000-0002-1089-3872
FU National Science Foundation (NSF) [CMMI-2153744]
FX AcknowledgmentsThis work is supported by the National Science Foundation
   (NSF) through the award number CMMI-2153744.
CR ADOLF DB, 1991, MACROMOLECULES, V24, P5834, DOI 10.1021/ma00021a018
   Alvarado C, 2003, PROTEIN ENG, V16, P717, DOI 10.1093/protein/gzg092
   [Anonymous], 2012, Psychology of science: Implicit and explicit processes
   Arkun Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029628
   Arkun Y, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013275
   Barrass S, 1999, MULTIMEDIA SYST, V7, P23, DOI 10.1007/s005300050108
   Behandish M, 2013, ASME INT DES ENG TEC, V55850, P02
   Bergasa-Caceres F, 2020, J PHYS CHEM B, V124, P8201, DOI 10.1021/acs.jpcb.0c03716
   Bremner P, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.904720
   Bresin R, 2021, WORKSH SOUND HUM ROB
   Cabral JP, 2019, APPL ERGON, V78, P224, DOI 10.1016/j.apergo.2019.02.008
   Chorsi M T, 2020, INT S ADV ROB KIN, P41
   Delatour T, 2000, COMPUT MUSIC J, V24, P48, DOI 10.1162/014892600559335
   Dunn J, 1999, LEONARDO, V32, P25, DOI 10.1162/002409499552966
   Errede S., 2017, Lecture notes on acoustical physics of music]
   Feng Z, 2020, ANNU REV CONTROL, V49, P113, DOI 10.1016/j.arcontrol.2020.02.002
   Ferina J, 2019, J MOL BIOL, V431, P1540, DOI 10.1016/j.jmb.2019.02.026
   Finkelstein A.V., 2016, Protein Physics: A Course of Lectures, DOI DOI 10.1016/C2015-0-04816-X
   Franjou SL, 2021, NANO FUTURES, V5, DOI 10.1088/2399-1984/abcf1b
   Franjou SL, 2019, EXPERT REV PROTEOMIC, V16, P875, DOI 10.1080/14789450.2019.1697236
   Frid E., 2018, Proceedings of the International Computer Music Conference 2018 : Daegu, South Korea, International Computer Music Conference Proceedings, P53
   Frid E, 2022, INT J SOC ROBOT, V14, P357, DOI 10.1007/s12369-021-00788-4
   Fryman Jeff., 2012, ROBOTIK 2012; 7th German Conference on Robotics, P1
   Haspel N, 2010, BMC STRUCT BIOL, V10, DOI 10.1186/1472-6807-10-S1-S1
   Henderson T, 2019, 22 INT C DIGITAL AUD
   Hermann T., 2011, The sonification handbook
   Hermann T., 1999, Advances in intelligent computing and multimedia systems
   Hermann T., 2008, P 14 INT C AUDITORY
   Hermann T, 2018, P 24 INT C AUD DISPL
   Hermann T., 2005, ACM T APPL PERCEPT T, V2, P559, DOI [10.1145/1101530.1101557, DOI 10.1145/1101530.1101557]
   Hu ZH, 2021, ACTA ASTRONAUT, V185, P102, DOI 10.1016/j.actaastro.2021.04.018
   Jones BA, 2006, IEEE T ROBOT, V22, P43, DOI 10.1109/TRO.2005.861458
   Kalonaris S, 2021, P 26 INT C AUDITORY
   Kazerounian K, 2005, J MECH DESIGN, V127, P712, DOI 10.1115/1.1867502
   Kazerounian K, 2005, J MECH DESIGN, V127, P699, DOI 10.1115/1.1867956
   Lazzarini V., 2016, CSOUND SOUND MUSIC C, DOI [10.1007/978-3-319-45370-5, DOI 10.1007/978-3-319-45370-5]
   Lemkul J. A., 2018, LIVING J COMPUT MOL, V1, DOI 10.33011/livecoms.1.1.5068
   Madden C, 2009, INT J ROBOT RES, V28, P450, DOI 10.1177/0278364908098092
   Menon MS, 2017, J MECH ROBOT, V9, DOI 10.1115/1.4036571
   Michael E, 2022, CURR OPIN STRUC BIOL, V72, P46, DOI 10.1016/j.sbi.2021.07.011
   Mochiyama H, 1999, INT J ROBOT RES, V18, P584, DOI 10.1177/02783649922066411
   Mohammadi A, 2022, IEEE CONTR SYST LETT, V6, P2755, DOI 10.1109/LCSYS.2022.3176433
   Mohammadi A, 2022, IEEE CONTR SYST LETT, V6, P373, DOI 10.1109/LCSYS.2021.3076869
   Mozart W A, 1783, PIANO SONATA 11 MAJO
   Mundrane C, 2022, INT S ADV ROB KIN, P257
   Neuhoff J G, 2000, P 6 INT C AUD DISPL
   Nown T H, 2022, IEEE REV BIOMED ENG
   Qin Z, 2019, EXTREME MECH LETT, V29, DOI 10.1016/j.eml.2019.100460
   Schwenk M, 2014, IEEE ROMAN, P161, DOI 10.1109/ROMAN.2014.6926247
   Shahbazi Z, 2010, J MECH ROBOT, V2, DOI 10.1115/1.4001088
   Shoemaker BA, 1997, P NATL ACAD SCI USA, V94, P777, DOI 10.1073/pnas.94.3.777
   Subramanian R, 2007, MECH MACH THEORY, V42, P903, DOI 10.1016/j.mechmachtheory.2006.09.010
   Tavousi P., 2015, ASME J NANOTECHNOL E, V6, P3
   Tavousi P, 2016, THESIS U CONNECTICUT
   Teodoro ML, 2001, IEEE INT CONF ROBOT, P960, DOI 10.1109/ROBOT.2001.932674
   Thuruthel TG, 2018, SOFT ROBOT, V5, P149, DOI 10.1089/soro.2017.0007
   Triantafyllidis E, 2020, IEEE ACCESS, V8, P78213, DOI 10.1109/ACCESS.2020.2990080
   Trivedi Deepak, 2008, Applied Bionics and Biomechanics, V5, P99, DOI 10.1080/11762320802557865
   Yu CH, 2020, APL BIOENG, V4, DOI 10.1063/1.5133026
   Yu CH, 2019, ACS NANO, V13, P7471, DOI 10.1021/acsnano.9b02180
   Zbiss K, 2022, IEEE ACCESS, V10, P9950, DOI 10.1109/ACCESS.2022.3144631
   Zhang BJ, 2022, IEEE ROBOT AUTOM LET, V7, P10566, DOI 10.1109/LRA.2022.3193228
   Zhao YJ, 2018, J BIONIC ENG, V15, P397, DOI 10.1007/s42235-018-0030-z
NR 63
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15385-y
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700005
DA 2024-07-18
ER

PT J
AU Mallik, A
   Kumar, S
AF Mallik, Abhishek
   Kumar, Sanjay
TI Word2Vec and LSTM based deep learning technique for context-free fake
   news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Complex networks; Fake news detection; Long short-term memory (LSTM);
   Neural network; Online social networks
AB Nowadays, social media and virtual networking hubs like Twitter, Facebook have become an integral part of our daily lives. The recent boom in multimedia technology and increased internet access has led us into a hyper-connected global world. But these networks are often observed as the conduit for propagating fake news, which may cause a severe problem to a healthy social environment and destroy the harmony between the users. This calls for a proper segregation tool to classify various news articles as real or fake. Numerous research has been done on this topic, including the use of Artificial Intelligence (AI). In this work, we propose a deep learning based hybrid framework utilizing Word2Vec embedding and LSTM for fake news detection. As part of our approach, we generate Word2Vec embedding for obtaining vector representations of the news excerpts. The Word2Vec embeddings assist in generating context-free and data agnostic feature vectors for our news articles. The stacked LSTM layers process the extracted feature vectors to obtain the topic-relevant salient features for the news articles. This is followed by two fully connected dense layers for classifying whether the news excerpt under consideration is real or fake. We also perform hyperparameter tuning for achieving a better performance of our model. The proposed model is context-free and independent of datasets as well as topics for fake news detection. We compare the proposed method's performance with some traditional Machine Learning baseline models, deep learning models, the pre-trained Bidirectional Encoder Representations from Transformers (BERT) via transfer learning, and some recently proposed state-of-the-art models. These models are tested on four datasets belonging to different domains for both training and testing purposes. Our proposed technique outperforms other well-known methods based on various performance metrics through intensive experimentation.
C1 [Mallik, Abhishek; Kumar, Sanjay] Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, New Delhi 110042, India.
C3 Delhi Technological University
RP Kumar, S (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, New Delhi 110042, India.
EM abhishekmallik265@gmail.com; sanjay.kumar@dtu.ac.in
OI Kumar, Dr. Sanjay/0000-0002-8951-5996
CR Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Almeida TA, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P259
   Anand S, 2022, MULTIMED TOOLS APPL, V81, P38593, DOI 10.1007/s11042-022-12854-8
   Brasoveanu AMP, 2021, NEURAL PROCESS LETT, V53, P3055, DOI 10.1007/s11063-020-10365-x
   Brooks HZ, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.023041
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128193
   Del Vicario M, 2019, ACM T WEB, V13, DOI 10.1145/3316809
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ghanem Bilal, 2018, Proceedings of the First Workshop on Fact Extraction and VERification (FEVER), P66
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hai Z., 2016, P C EMP METH NAT LAN, P1817, DOI [10.18653/v1/D16-1187, DOI 10.18653/V1/D16-1187]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Hunan SL, 2021, T ASIAN LOW RESOURCE
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kumar S, 2022, EXPERT SYST APPL
   Kumar S. Malviya, 2022, Transactions on Asian and Low-Resource Language Information Processing
   Kumar S, 2021, J INTELL INF SYST, V57, P51, DOI 10.1007/s10844-020-00625-6
   Kumar S, 2018, Arxiv, DOI [arXiv:1804.08559, 10.48550/arXiv.1804.08559]
   Liu S, 2021, MOBILE NETW APPL, V26, P1891, DOI 10.1007/s11036-020-01725-x
   Long Yunfei., 2017, Fake news detection through multi-perspective speaker profiles
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mihalcea Rada, 2009, P ACL IJCNLP 2009 C, P309, DOI [10.3115/1667583.1667679, DOI 10.3115/1667583.1667679]
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   OBrien Nicole, 2018, The language of fake news: Opening the black-box of deep learning-based detectors
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Singh V. K., 2017, INT C SOCIAL COMPUTI, P1, DOI [10.13140/RG.2.2.16825.67687, DOI 10.13140/RG.2.2.16825.67687]
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Spohr Dominic, 2017, Business Information Review, V34, P150, DOI 10.1177/0266382117722446
   Tacchini E, 2017, Arxiv, DOI arXiv:1704.07506
   Thota A, 2018, SMU Data Sci Rev, V1
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P517, DOI 10.1145/3184558.3188722
   Wallace B., 2015, ARXIV
   Wang S, 2022, IEEE INTERNET THINGS, V9, P7128, DOI 10.1109/JIOT.2021.3077600
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wang WY, 2017, Arxiv, DOI arXiv:1705.00648
   Yang Y, 2022, Arxiv, DOI arXiv:1806.00749
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 47
TC 2
Z9 2
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15364-3
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OO5
UT WOS:000995776100003
DA 2024-07-18
ER

PT J
AU Jemshi, KM
   Sreelekha, G
   Sathidevi, PS
   Mohanachandran, P
   Vinekar, A
AF Jemshi, K. M.
   Sreelekha, G.
   Sathidevi, P. S.
   Mohanachandran, Poornima
   Vinekar, Anand
TI Plus disease classification in Retinopathy of Prematurity using
   transform based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retinopathy of Prematurity; Plus disease; Feature extraction;
   Classification; Artificial neural network
ID COMPUTER-AIDED DIAGNOSIS; INTERNATIONAL CLASSIFICATION; INTER-EXPERT;
   QUANTIFICATION; IMAGES
AB Retinopathy of prematurity (ROP) is a leading cause of childhood blindness affecting the retina of low birth weight preterm infants. Plus disease in ROP characterised by abnormal tortuosity and dilation of posterior retinal blood vessels, is a benchmark that identifies treatment-requiring ROP cases. A Plus disease classifier with zero false negatives is a major requirement of an ROP screening system. In this paper, an efficient Artificial Neural Network (ANN) architecture with an optimal feature set is proposed which meets the above requirement. A total of 178 images with 81(45%) Plus and 97 (55%) No Plus are used for the analysis. A feature set derived from transform domain representation of retinal funds images is used along with the existing vascular features in the proposed work. Wavelet and Curvelet transforms are considered for deriving the additional feature set in the experimental analysis. The feature set containing Curvelet transform energy coefficient along with the vascular features gave an Accuracy of 96% and Specificity of 93% with 100% Sensitivity.
C1 [Jemshi, K. M.; Sreelekha, G.; Sathidevi, P. S.] Natl Inst Technol, Calicut, Kerala, India.
   [Mohanachandran, Poornima] EkLakshya Acad LLP, Hubli, India.
   [Vinekar, Anand] Narayana Nethralaya PG Inst Ophthalmol, Bangalore, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Jemshi, KM (corresponding author), Natl Inst Technol, Calicut, Kerala, India.
EM jemshi.km@gmail.com; lekha@nitc.ac.in; sathi@nitc.ac.in;
   poornima.mohanachandran@gmail.com; anandvinekar@yahoo.com
RI Mohanachandran, Poornima/IZD-6771-2023
OI Mohanachandran, Poornima/0000-0003-1825-4757; K M,
   JEMSHI/0000-0001-5189-9800
CR AlZubi S, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/136034
   Ataer-Cansizoglu E, 2015, METHOD INFORM MED, V54, P93, DOI 10.3414/ME13-01-0081
   Ataer-Cansizoglu E, 2015, TRANSL VIS SCI TECHN, V4, DOI 10.1167/tvst.4.6.5
   Attallah O, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020359
   BahadarKhan K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158996
   Bhuiyan MN, 2019, BIG DATA ANAL INTELL, P59
   Brown JM, 2018, JAMA OPHTHALMOL, V136, P803, DOI 10.1001/jamaophthalmol.2018.1934
   Byra M, 2018, INT J COMPUT ASS RAD, V13, P1895, DOI 10.1007/s11548-018-1843-2
   Chiang Michael F, 2007, Trans Am Ophthalmol Soc, V105, P73
   Chiang Michael F, 2021, Ophthalmology, V128, pe51, DOI 10.1016/j.ophtha.2021.05.031
   Erguzel TT, 2015, CLIN EEG NEUROSCI, V46, P321, DOI 10.1177/1550059414523764
   Fekri-Ershad S, 2021, MULTIMED TOOLS APPL, V80, P12103, DOI 10.1007/s11042-020-10321-w
   Ferreira João Elias Vidueira, 2016, Educ. quím, V27, P209, DOI 10.1016/j.eq.2016.04.007
   Gole GA, 2005, ARCH OPHTHALMOL-CHIC, V123, P991, DOI 10.1001/archopht.123.7.991
   Gopal Lingam, 1995, Indian Journal of Ophthalmology, V43, P59
   Gschliesser A, 2015, AM J OPHTHALMOL, V160, P553, DOI 10.1016/j.ajo.2015.05.016
   Hu JJ, 2019, IEEE T MED IMAGING, V38, P269, DOI 10.1109/TMI.2018.2863562
   Huang YP, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091444
   Huang YP., 2022, FRONT PEDIATR, V10, P11
   Jemshi KM, 2018, INT J COMPUT ASS RAD, V13, P1369, DOI 10.1007/s11548-018-1795-6
   Jero SE, 2015, BIOMED SIGNAL PROCES, V22, P161, DOI 10.1016/j.bspc.2015.07.004
   Jomier J, 2003, LECT NOTES COMPUT SC, V2879, P620
   Kiely AE, 2010, ARCH OPHTHALMOL-CHIC, V128, P847, DOI 10.1001/archophthalmol.2010.133
   Lei BY, 2021, MULTIMED TOOLS APPL, V80, P36341, DOI 10.1007/s11042-021-11208-0
   Mao JB, 2020, ACTA OPHTHALMOL, V98, pE339, DOI 10.1111/aos.14264
   Mills MD, 2007, ARCH OPHTHALMOL-CHIC, V125, P1276, DOI 10.1001/archopht.125.9.1276
   Nisha KL, 2019, COMPUT MED IMAG GRAP, V74, P72, DOI 10.1016/j.compmedimag.2019.04.003
   Oloumi F, 2015, COMPUT BIOL MED, V66, P316, DOI 10.1016/j.compbiomed.2015.09.009
   Pour Elias Khalili, 2017, Korean J Ophthalmol, V31, P524, DOI 10.3341/kjo.2015.0143
   Rajashekar D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163923
   Rani P., 2016, Int. J. Control Theory Appl, V9, P451
   Rani P, 2016, INT J BIOMED ENG TEC, V22, P338, DOI 10.1504/IJBET.2016.10002009
   Repka MX, 2011, ARCH OPHTHALMOL-CHIC, V129, P1175, DOI 10.1001/archophthalmol.2011.229
   Samant A., 2017, INT J SCI RES NETW S, V5, P9
   Schmitt A, 2014, REMOTE SENS-BASEL, V6, P2435, DOI 10.3390/rs6032435
   Shafiei F, 2020, TRAIT SIGNAL, V37, P1029, DOI 10.18280/ts.370615
   Tan LZ, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.23
   Shahriar MT, 2020, Arxiv, DOI arXiv:2011.06928
   Thangaraj S, 2018, IET IMAGE PROCESS, V12, P669, DOI 10.1049/iet-ipr.2017.0284
   Vinekar A, 2017, INDIAN J OPHTHALMOL, V65, P390, DOI 10.4103/ijo.IJO_211_17
   Vinekar A, 2011, J INDIAN BUS RES, V3, P98, DOI 10.1108/17554191111132215
   Vyas R, 2019, OPTIK, V185, P859, DOI 10.1016/j.ijleo.2019.04.015
   Wallace DK, 2003, J AAPOS, V7, P126, DOI 10.1067/S1091-8531(02)00015-0
   Wang JY, 2018, EBIOMEDICINE, V35, P361, DOI 10.1016/j.ebiom.2018.08.033
   Worrall DE, 2016, LECT NOTES COMPUT SC, V10008, P68, DOI 10.1007/978-3-319-46976-8_8
   Yadav P., 2018, INT J STAT APPL MATH, V3, P266
   Yavuz Z, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4897258
   Yildiz V, 2021, I S BIOMED IMAGING, P353, DOI 10.1109/ISBI48211.2021.9433881
   Yildiz VM, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.10
   Zhang DS., 2019, FUNDAMENTALS IMAGE D, V2019, P35, DOI [DOI 10.1007/978-3-030-17989-2_3, 10.1007/978-3-030-12281-2_5]
   Zhang RG, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115843
NR 51
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15430-w
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000002
DA 2024-07-18
ER

PT J
AU Kanimozhi, A
   Vimala, N
AF Kanimozhi, A.
   Vimala, N.
TI y Adaptive Weighted Support Vector Machine classification method for
   privacy preserving in cloud over big data using hadoop framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Big data; Cloud computing; Data security; Encryption; Privacy;
   Decryption; Clustering and classification
ID SECURITY
AB Data security is one of the most critical parts of big data investigation. The cloud system applications deal with sensitive information, such as personal, business, or medical records. Threats to this type of data could endanger the cloud systems that store it. On the other hand, traditional security solutions are incapable of safeguarding huge data migration. An effective privacy-preserving system is used to handle the creation of large amounts of data and the security elements of that data throughout the cloud. The information in a cloud-based dataset is initially clustered and balanced using the hadoop framework. The process of clustering is accomplished by Density Peak Weighted Fuzzy C-means Clustering (DPWFCM) algorithm and processed by hadoop framework, which is then encrypted and classified by Enhanced Word Auto Key Encryption (WAKE) and Adaptive Weighted Support Vector Machine with Continuous scatter search (CSS) Optimization Algorithm classifier called as (AWSVM-CSS) technique respectively. The process of encryption and decryption is accomplished in the form of hybrid scheme. The experimental observation of the proposed approach is highly effective in terms of encryption and classification.
C1 [Kanimozhi, A.; Vimala, N.] LRG Govt Arts Coll Women, Dept Comp Sci, Tirupur, India.
RP Kanimozhi, A (corresponding author), LRG Govt Arts Coll Women, Dept Comp Sci, Tirupur, India.
EM akanimozhi986@gmail.com
CR Abd Elminaam DiaaSalama., 2010, IJ NETWORK SECURITY, V10, P216
   Almorsy M., 2016, ARXIV
   Chandra Mayank Arya, 2021, International Journal of Information Technology, V13, P1, DOI 10.1007/s41870-017-0080-1
   Del Rosal Edni., 2017, Journal of Circuits and Systems, V8, P237, DOI DOI 10.4236/CS.2017.89016
   Ding JJ, 2018, SOFT COMPUT, V22, P2777, DOI 10.1007/s00500-017-2748-7
   George Amalarethinam DI, 2019, SURVEY SECURITY CHAL
   Gontumukkala SST, 2021, 2021 12 INT C COMP C, P01
   Gordon A, 2016, IEEE CLOUD COMPUT, V3, P82, DOI 10.1109/MCC.2016.21
   Hassan H, 2017, J INF COMMUN TECHNOL, V16, P21
   Hentschel R, 2018, J CLOUD COMPUT-ADV S, V7, DOI 10.1186/s13677-018-0107-6
   Hou J, 2016, INT C PATT RECOG, P468, DOI 10.1109/ICPR.2016.7899678
   Huang SH, 2021, J INTELL MANUF, V32, P1845, DOI 10.1007/s10845-020-01690-y
   Jiang LX, 2019, IEEE T KNOWL DATA EN, V31, P201, DOI 10.1109/TKDE.2018.2836440
   Jimenez JM, 2019, IEEE NETWORK, V33, P106, DOI 10.1109/MNET.2018.1300246
   Kalra M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5588486
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Khan MA, 2016, J NETW COMPUT APPL, V71, P11, DOI 10.1016/j.jnca.2016.05.010
   Li K, 2017, NEUROCOMPUTING, V259, P55, DOI 10.1016/j.neucom.2016.08.131
   Lu CC, 2002, IEEE INT CONF ASAP, P277, DOI 10.1109/ASAP.2002.1030726
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Nurdiyanto H, 2018, J PHYS CONF SER, V1028, DOI 10.1088/1742-6596/1028/1/012053
   Ramachandra G, 2017, PROCEDIA COMPUT SCI, V110, P465, DOI 10.1016/j.procs.2017.06.124
   Raut Rakesh D., 2017, Journal of High Technology Management Research, V28, P125, DOI 10.1016/j.hitech.2017.10.004
   Razzaghi T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155119
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   Tariq MI, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/6535834
   Tharini J, 2022, Computational Intelligence and Data Sciences, V1st, P195
   Tharini VJ., 2020, Incorporating the Internet of Things in healthcare applications and wearable devices, P1
   Vijayarani S, 2019, INT J ENG ADV TECHNO, V8
   Walczak S, 2018, ENCYCLOPEDIA OF INFORMATION SCIENCE AND TECHNOLOGY, 4TH EDITION, P120, DOI 10.4018/978-1-5225-2255-3.ch011
NR 30
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15825-9
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400012
DA 2024-07-18
ER

PT J
AU Pattanayak, A
   Acharya, A
   Panda, NR
AF Pattanayak, Abanikanta
   Acharya, Aditya
   Panda, Nihar Ranjan
TI Dark image enhancement using adaptive piece-wise sigmoid gamma
   correction (APSGC) in presence of optical sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE dark image enhancement; sigmoid; piecewise; adaptive gamma correction
AB Various classical enhancement methods may potentially enhance only the darker regions of an image in presence of illuminating sources. However, they distort and saturate the brighter regions consequently resulting in loss of original information and degradation of image quality. In addition, fringes and shading artefacts are produced around the optical sources as an outcome of image enhancement. Hence, it is desired to develop a more versatile enhancement algorithm which not only enhance the dark regions of an image but also preserves the information content of bright regions without much distortion. To overcome such problems, an adaptive piece-wise non-linear gamma correction technique is proposed here. The proposed algorithm employs piece-wise modified-sigmoidal functions which are derived from the image histogram so as to make it highly adaptive, nonlinear and versatile. The simulation results show that the proposed method gives better performance than most of the existing techniques in-terms-of objective and subjective measures.
C1 [Pattanayak, Abanikanta] Biju Patnaik Univ Technol, Rourkela, Odisha, India.
   [Acharya, Aditya; Panda, Nihar Ranjan] Silicon Inst Technol, Bhubaneswar, India.
C3 Silicon Institute of Technology
RP Pattanayak, A (corresponding author), Biju Patnaik Univ Technol, Rourkela, Odisha, India.
EM abanigiet@gmail.com; aditya@silicon.ac.in; nihar.panda@silicon.ac.in
OI Pattanayak, Abanikanta/0009-0004-3905-7941
CR Abdani SR, 2015, 2015 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P53, DOI 10.1109/ELECSYM.2015.7380813
   Acharya A, 2021, MULTIMED TOOLS APPL, V80, P5577, DOI 10.1007/s11042-020-09947-7
   Acharya A, 2020, INT CONF ADVAN COMPU, P110, DOI [10.1109/ICACCS48705.2020.9074386, 10.1109/icaccs48705.2020.9074386]
   Adhikari G, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Agarwal TK, 2014, IEEE STUDENT TECHNOL, P247, DOI 10.1109/TechSym.2014.6808055
   Akter N, 2019, IEEE PHOTON CONF, DOI 10.1109/ipcon.2019.8908502
   Alizadeh M., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1544, DOI 10.1109/IranianCEE.2012.6292604
   Arriaga-Garcia EF, 2014, INT CONF ELECTR COMM, P28, DOI 10.1109/CONIELECOMP.2014.6808563
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Cheolkon Jung, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457796
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Gautam C, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P175, DOI 10.1109/IIC.2015.7150733
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Huang LH, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P189, DOI 10.1109/CISP-BMEI.2016.7852706
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kaur R., 2016, PROC C EMERG DEVICES, P155, DOI DOI 10.1109/ICEDSS.2016.7587782
   Li Y, 2015, INT CONF INSTR MEAS, P1858, DOI [10.1109/IMCCC.2015.395, 10.1109/INFOCOM.2015.7218568]
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P614, DOI 10.1109/ICISC.2018.8398873
   Shen C-T., 2008, 2008 IEEE INT S CONS, P1
   Shi Y, 2010, 2010 6 INT C WIRELES, P1, DOI [10.1109/WICOM.2010.5601002, DOI 10.1109/WICOM.2010.5601002]
   Shi YH, 2007, IEEE IMAGE PROC, P529
   Shimoyama S, 2009, IEEE IMAGE PROC, P3153, DOI 10.1109/ICIP.2009.5414418
   Shukla KN, 2017, Int. J. Eng. Appl. Comput. Sci, V2, P232
   Singh H, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P431, DOI 10.1109/SPIN.2017.8049988
   Singh H, 2019, IEEE ACCESS, V7, P37192, DOI 10.1109/ACCESS.2019.2901292
   Singh H, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1299, DOI 10.1109/ICCSP.2017.8286592
   Srinivas K, 2020, IET IMAGE PROCESS, V14, P668, DOI 10.1049/iet-ipr.2019.0781
   Süsstrunk S, 2004, PROC SPIE, V5304, P118, DOI 10.1117/12.537804
   Tiwari M, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Yang KF, 2019, IEEE T CIRC SYST VID, V29, P640, DOI 10.1109/TCSVT.2018.2810212
   Yu WY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030845
   Zhang Dongni., 2012, Con- sumer Electronics (ISCE), 2012 IEEE 16th International Symposium on, P1, DOI DOI 10.1109/ISCE.2012.6241687
NR 35
TC 2
Z9 2
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15615-3
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600008
DA 2024-07-18
ER

PT J
AU Thaipisutikul, T
   Chen, YN
AF Thaipisutikul, Tipajin
   Chen, Ying-Nong
TI An improved deep sequential model for context-aware POI recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Sequential behavior; Context awareness; User preference;
   Next POI recommendation
AB Nowadays, Location-based social networks (LSBNs) have been pervasive in our everyday lives since mobile users can share their experiences on point-of-interest (POIs) with friends anytime at hand. Currently, the recurrent neural network methods (RNN) have shown promising results for the next POI prediction task. However, they fail to incorporate important spatial-temporal contextual factors into the model learning process to distill the relevant long-term user preferences to the current user preference. Besides, traditional RNN-based models could only capture the consecutive check-ins relationship, which can obscure the complex motivations behind users' decisions in real-world scenarios. Therefore, in this paper, we propose An Improved Deep Sequential Model for Context-Aware POI Recommendation (SCR) for the next POI recommendation. Specifically, we model the user's short-term preference by a self multi-head attentive aggregation layer to capture the relationship of non-consecutive POIs under complex situations and aggregate all POI representations into a user's fine-grained short-term preference. Also, we model the users' long-term preferences by newly proposed three context-aware layers to discover the relevant past sessions on the current sessions based on temporal and spatial contexts. Finally, both users' short-and-long-term preferences are collaboratively fused for the final next POI prediction in a unified framework. The experimental results on two widely public POI datasets reveal the substantial enhancement of our proposed method over several state-of-the-art baselines from all evaluation metrics. Also, through the case study, we demonstrate the model's capability in delivering the interpretable recommendation results to the LSBN users.
C1 [Thaipisutikul, Tipajin] Mahidol Univ, Fac Informat & Commun Technol, Nakhon Pathom, Thailand.
   [Chen, Ying-Nong] Natl Cent Univ, Ctr Space & Remote Sensing Res, Taoyuan City, Taiwan.
   [Chen, Ying-Nong] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan City, Taiwan.
C3 Mahidol University; National Central University; National Central
   University
RP Thaipisutikul, T (corresponding author), Mahidol Univ, Fac Informat & Commun Technol, Nakhon Pathom, Thailand.
EM tipajin.tha@mahidol.ac.th; yingnong1218@csrsr.ncu.edu.tw
OI Thaipisutikul, Tipajin/0000-0002-2538-1108
FU Faculty of Information and Communication Technology and Mahidol AI
   Center, Mahidol University, Thailand
FX This research project was supported by the Faculty of Information and
   Communication Technology and Mahidol AI Center, Mahidol University,
   Thailand.
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Belhadi A, 2022, INT J PROD RES, V60, P4487, DOI 10.1080/00207543.2021.1950935
   Belhadi A, 2020, ACM TRANS MANAG INF, V11, DOI 10.1145/3399631
   Chen YC, 2022, IEEE T CYBERNETICS, V52, P2453, DOI 10.1109/TCYB.2020.3000733
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Djenouri Y, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3425867
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Faruqui C., 2014, P 14 C EUR CHAPT ASS, P462, DOI [10.3115/v1/E14-1049, DOI 10.3115/V1/E14-1049]
   Feng J, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1459, DOI 10.1145/3178876.3186058
   Feng S, 2020, P 43 INT ACM SIGIR C, DOI [10.1145/3397271.3401049, DOI 10.1145/3397271.3401049]
   Halder S, 2021, LECT NOTES ARTIF INT, V12713, P510, DOI 10.1007/978-3-030-75765-6_41
   He RN, 2016, IEEE DATA MINING, P191, DOI [10.1109/ICDM.2016.88, 10.1109/ICDM.2016.0030]
   Hidasi B, 2016, Arxiv, DOI arXiv:1511.06939
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang LW, 2021, IEEE T SERV COMPUT, V14, P1585, DOI 10.1109/TSC.2019.2918310
   Li J, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1419, DOI 10.1145/3132847.3132926
   Li M, 2021, IEEE ACCESS, V9, P35997, DOI 10.1109/ACCESS.2021.3061502
   Li Z, 2018, P 24 ACM SIGKDD INT, DOI [10.1145/3219819.3220014, DOI 10.1145/3219819.3220014]
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Lin JCW, 2020, NEUROCOMPUTING, V403, P431, DOI 10.1016/j.neucom.2020.04.102
   Liu Q, 2016, AAAI CONF ARTIF INTE, P194
   Liu Q, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1831, DOI 10.1145/3219819.3219950
   Liu X, 2022, NEUROCOMPUTING, V467, P454, DOI 10.1016/j.neucom.2021.09.056
   Miao H, 2022, MULTIMED TOOLS APPL, V81, P12029, DOI 10.1007/s11042-020-10492-6
   Qiao JJ, 2021, INT J MACH LEARN CYB, V12, P2591, DOI 10.1007/s13042-021-01343-3
   Quadrana M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P130, DOI 10.1145/3109859.3109896
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Shao YN, 2021, PATTERN RECOGN LETT, V145, P157, DOI 10.1016/j.patrec.2021.02.008
   Sun K, 2020, AAAI CONF ARTIF INTE, V34, P214
   Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656
   Thaipisutikul T, 2021, NEURAL COMPUT APPL, V33, P11067, DOI 10.1007/s00521-020-05640-w
   Thaipisutikul T, 2020, IND MANAGE DATA SYST, V120, P1901, DOI 10.1108/IMDS-04-2020-0207
   Wang DJ, 2021, WORLD WIDE WEB, V24, P2161, DOI 10.1007/s11280-021-00961-9
   Wang HL, 2021, INFORM SCIENCES, V547, P482, DOI 10.1016/j.ins.2020.08.088
   Wang QY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P906, DOI 10.1145/3366423.3380170
   Yao D, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2411, DOI 10.1145/3132847.3133056
   Yin MH, 2021, MULTIMED TOOLS APPL, V80, P36215, DOI 10.1007/s11042-021-11407-9
   Ying HC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3926
   Yu DJ, 2021, MULTIMED TOOLS APPL, V80, P1487, DOI 10.1007/s11042-020-09746-0
   Zhang L, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3551
   Zhu Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3602
NR 44
TC 0
Z9 0
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15540-5
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800002
DA 2024-07-18
ER

PT J
AU Xu, J
   Tian, WJ
   Lv, GY
   Fan, YY
AF Xu, Jia
   Tian, Weijian
   Lv, Guoyun
   Fan, Yangyu
TI Spatiotemporal fusion personality prediction based on visual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual Information; Personality Prediction; Spatiotemporal Fusion
ID TRAITS
AB The previous studies have demonstrated that the use of deep learning algorithms can make personality prediction based on two-dimensional image information, and the emergence of video provides more possibilities for exploring personality prediction. Compared to image-based personality prediction, using video can provide more information than static images. But videos contain hundreds of frames, not all of which are useful, and processing these images requires a lot of computation. This paper proposes to apply video analysis algorithms to the task of personality prediction and propose the use of LSTM to fuse image feature information. The best prediction effect is confirmed by experiments when the fusion frame number is 16 frames. This paper is based on 3D-ConvNet to build an end-to-end video analysis network and solve the network over fitting problem by pre-training and data augmentation. Experiments show that the accuracy of character prediction can be improved by using 3D-ConvNet to fuse the spatio-temporal information of videos.
C1 [Xu, Jia; Tian, Weijian; Lv, Guoyun; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Xu, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM xujiajia_2008@163.com
FU National Natural Science Foundation of China [61402371]; Shaanxi
   Provincial Science and Technology Innovation Project Plan
   [2013SZS15-K02]; Shaanxi Provincial Key Scientific Research Project
   [2020zdlgy04-09]
FX This work was funded by the National Natural Science Foundation of China
   (61402371), the Shaanxi Provincial Science and Technology Innovation
   Project Plan(2013SZS15-K02), and the Shaanxi Provincial Key Scientific
   Research Project (2020zdlgy04-09)
CR [Anonymous], 2016, EFFICIENT 2 STREAM M
   Attrapadung N, 2021, ADAM PRIVATE SECURE
   Brooks J, 2011, PACKAGING NEWS, P3
   Cao XQ, 2015, IEEE T FUZZY SYST, V23, P1581, DOI 10.1109/TFUZZ.2014.2370678
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Hara K, 2018, CAN SPATIOTEMPORAL 3
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Joo J, 2015, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2015.423
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Lin QH, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102430
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Mohammadi G, 2012, IEEE T AFFECT COMPUT, V3, P273, DOI 10.1109/T-AFFC.2012.5
   Nguyen LS, 2016, IEEE T MULTIMEDIA, V18, P1422, DOI 10.1109/TMM.2016.2557058
   Ponce-López V, 2016, LECT NOTES COMPUT SC, V9915, P400, DOI 10.1007/978-3-319-49409-8_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sammeta V, ACOUSTICS RECOGNITIO
   SCHMID W, 1975, INVENT MATH, V30, P47, DOI 10.1007/BF01389847
   Wang S, 2022, IEEE INTERNET THINGS, V9, P7128, DOI 10.1109/JIOT.2021.3077600
   Wei XS, 2018, IEEE T AFFECT COMPUT, V9, P303, DOI 10.1109/TAFFC.2017.2762299
   Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452
   Xu J, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/5581984
   Xu J, 2021, IEEE ACCESS, V9, P76822, DOI 10.1109/ACCESS.2021.3076989
   Xu J, 2018, LECT NOTES COMPUT SC, V11068, P611, DOI 10.1007/978-3-030-00021-9_54
   Yan S, 2014, SOME EXAMPLES CALTEC
   Yu Z, 2019, AAAI CONF ARTIF INTE, P9127
   Zha S., 2015, P BRIT MACH VIS C BM
   Zhang Wenxuan, 2022, 2022 International Conference on Machine Learning and Knowledge Engineering (MLKE), P177, DOI 10.1109/MLKE55170.2022.00041
NR 28
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44227
EP 44244
DI 10.1007/s11042-023-15537-0
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979963000003
DA 2024-07-18
ER

PT J
AU Xue, J
   Wu, W
   Cheng, QK
AF Xue, Jing
   Wu, Wen
   Cheng, Qingkai
TI Intelligent invigilator system based on target detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EfficientDet; Intelligent invigilation; Abnormal behavior detection;
   Audio analysis; Centroid tracking
AB Affected by the COVID-19 epidemic, the final examinations at many universities and the recruitment interviews of enterprises were forced to be transferred to online remote video invigilation, which undoubtedly improves the space and possibility of cheating. To solve these problems, this paper proposes an intelligent invigilation system based on the EfficientDet target detection network model combined with a centroid tracking algorithm. Experiments show that cheating behavior detection model proposed in this paper has good detection, tracking and recognition effects in remote testing scenarios. Taking the EfficientDet network as the detection target, the average detection accuracy of the network is 81%. Experiments with real online test videos show that the cheating behavior detection accuracy can reach 83.1%. In addition, to compensate for the shortage of image detection, we also design an audio detection module to carry out auxiliary detection and forensics. The audio detection module is used to continuously detect the environmental sound of the examination room, save suspicious sounds and provide evidence for judging cheating behavior.
C1 [Xue, Jing; Wu, Wen; Cheng, Qingkai] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Xue, J (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
EM xuejing@njupt.edu.cn
OI Xue, Jing/0000-0001-9259-4325
FU Instructional Reform Item of Nanjing University of Posts and
   Telecommunications [JG00421JX75]; Innovative Research Group Project of
   the National Natural Science Foundation of China [61906098]
FX AcknowledgmentThis work is supported by Instructional Reform Item of
   Nanjing University of Posts and Telecommunications (Grant No.
   JG00421JX75) and Innovative Research Group Project of the National
   Natural Science Foundation of China (Grand No. 61906098).The authors
   would like to appreciate all anonymous reviewers for their insightful
   comments and constructive suggestions to polish this paper in high
   quality. (Haowei Zhang collected and processed the data; Haowei Zhang
   and Wen Wu performed the experiments and conducted the analyses; All
   authors agree with the above contribution details.)
CR Chakraborty R., 2021, J AMBIENT INT HUMAN, V12, P1
   Deepa R, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING & COMMUNICATION ENGINEERING (ICACCE-2019), DOI 10.1109/icacce46606.2019.9079965
   Ding M, 2017, RES INTELLIGENT MONI
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gopal R, 2021, EDUC INF TECHNOL, V26, P6923, DOI 10.1007/s10639-021-10523-1
   Li C., 2019, TECHNOL INNOV APPL, V18, P8
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu H, 2020, IEEE 7 INT C DAT SCI
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Makarewicz R, 2016, APPL ACOUST, V111, P116, DOI 10.1016/j.apacoust.2016.04.016
   Manana M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT AND INNOVATIVE COMPUTING APPLICATIONS (ICONIC), P416
   Morera A, 2020, IMAGE SENSORS SYST A
   Morin L, 2020, J ELASTICITY, V138, P221, DOI 10.1007/s10659-019-09741-z
   Rahman Z, 2020, IEEE REGION 10 SYMP, P916, DOI [10.1109/tensymp50017.2020.9230463, 10.1109/TENSYMP50017.2020.9230463]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Weber M, 2020, IEEE INT VEH SYM, P1423, DOI 10.1109/IV47402.2020.9304830
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   YANAGISAWA H, 2018, STUDY OBJECT DETECTI, DOI DOI 10.1109/IWAIT.2018.8369633
   Yin LW., 2020, INT THINGS TECHNOL, V10, P3
   Zhao J, 2022, MULTIMED TOOLS APPL, V81, P343, DOI 10.1007/s11042-021-11429-3
NR 21
TC 0
Z9 0
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44673
EP 44695
DI 10.1007/s11042-023-15474-y
EA APR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978477000002
PM 37362652
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Ding, JH
   Yu, JY
AF Zhang, Yuhong
   Ding, Jianhao
   Yu, Jieyue
TI Art image inpainting via embedding multiple attention dilated
   convolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Art image inpainting; Hybrid dilated convolution; Coordination attention
AB Image inpainting seeks a semantically consistent way to recover the damaged image while taking into account its unmasked content. It is a crucial task for multiple practical applications like object removal and art image editing. Recently deep neural networks have achieved promising performance for filling large missing regions in image inpainting tasks. However, the existing methods often generate content with distorted structures and blurry textures when encountering artistic images. To address these problems, we propose an art image inpainting method via embedding multiple attention dilated convolutions (MADC). Four dilated convolution blocks with dilation ratios of 1, 3, 5, and 7 are aggregated to obtain dense multi-scale contextual information. Then, we use the coordination attention layer to capture long-range spatial dependencies while preserving precise location information in order to enhance the feature representation of interest. By explicitly using the surrounding image features as references, we insert the MADC modules into the encoder network to facilitate the recovery of large portions in incomplete images. We also employ a discriminator with local and global branches to ensure local-global content consistency. Experiments on the art image dataset show that our method performs favorably against state-of-the-art in generating sharper more coherent and visually plausible inpainting results.
C1 [Zhang, Yuhong; Ding, Jianhao; Yu, Jieyue] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Ding, JH (corresponding author), Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Peoples R China.
EM djh@hdu.edu.cn
FU Zhejiang Province Basic Public Welfare Research Program Project
   [LGG20F020002]
FX Supported by Zhejiang Province Basic Public Welfare Research Program
   Project (LGG20F020002).
CR Alilou VK, 2017, MULTIMED TOOLS APPL, V76, P7213, DOI 10.1007/s11042-016-3366-6
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Fang YC, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115664
   Hongyu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P725, DOI 10.1007/978-3-030-58536-5_43
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hui Z, 2020, P EUROPEAN C COMPUTE, DOI [10.48550/arXiv.2002.02609, DOI 10.48550/ARXIV.2002.02609]
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li JY, 2019, IEEE I CONF COMP VIS, P5961, DOI 10.1109/ICCV.2019.00606
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu XY, 2023, MULTIMED TOOLS APPL, V82, P3433, DOI 10.1007/s11042-022-12635-3
   Lugmayr A, 2022, PROC CVPR IEEE, P11451, DOI 10.1109/CVPR52688.2022.01117
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng JL, 2021, PROC CVPR IEEE, P10770, DOI 10.1109/CVPR46437.2021.01063
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Sagong MC., 2020, IEEE CVF C COMP VIS, P11360
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Wang Y, 2018, ADV NEUR IN, V31
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Xue A, 2021, IEEE WINT CONF APPL, P3862, DOI 10.1109/WACV48630.2021.00391
   Yang J, 2020, AAAI CONF ARTIF INTE, V34, P12605
   Yi Zili, 2020, P IEEE CVF C COMP VI, P7505
   Yu J, 2018, IEEECVF INT C COMPUT, P4471
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu ZL, 2022, CRIT REV FOOD SCI, V62, P905, DOI [10.1080/10408398.2020.1830262, 10.1007/978-3-030-58529-7_1]
   Zhang DY, 2018, MULTIMED TOOLS APPL, V77, P11823, DOI 10.1007/s11042-017-4829-0
NR 31
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 19
PY 2023
DI 10.1007/s11042-023-15285-1
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E1PC7
UT WOS:000973330100001
DA 2024-07-18
ER

PT J
AU Altun, I
   Altun, S
   Alkan, A
AF Altun, Idiris
   Altun, Sinan
   Alkan, Ahmet
TI LSS-UNET: Lumbar spinal stenosis semantic segmentation using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-Net; Lumbar spinal stenosis; Semantic segmentation
AB The most important information to be noted about LSS not a hernia. While a hernia occurs with a rupture in the disc, LSS occurs as a result of calcification due to deformation of the bone in the following years. In addition, the correct interpretation and diagnosis of biomedical images requires serious expertise, making the diagnosis of LSS difficult. Looking at the literature, the U-Net method can perform semantic segmentation with high success. In recent years, it has been seen in the literature that the success of the classical U-Net has increased when the architecture of different deep learning methods has been applied. In order to segment the LSS region, semantic segmentation was performed on lumbar spine MR images with 3 different deep learning methods. The success of these methods was calculated by Dice and IoU scores. The highest segmentation success among 1560 images was obtained in the ResUNet model with 0.93 DICE score. LSS treatment, which negatively affects human life, is very important because of the difficulty of interpreting MR images and the confusion of LSS with lumbar hernia. Today, expert decision support systems have become essential for correct diagnosis, which is the most important feature of starting a treatment/surgical operation. Especially the high success of classification/segmentation obtained by deep learning methods has also been demonstrated in LSS segmentation, which is the subject of our study.
C1 [Altun, Idiris] Kahramanmaras Sutcuu Imam Univ, Dept Neurosurg, Kahramanmaras, Turkiye.
   [Altun, Sinan; Alkan, Ahmet] Kahramanmaras Sutcu Imam Univ, Dept Elect & Elect Engn, Kahramanmaras, Turkiye.
C3 Kahramanmaras Sutcu Imam University
RP Altun, S (corresponding author), Kahramanmaras Sutcu Imam Univ, Dept Elect & Elect Engn, Kahramanmaras, Turkiye.
EM s.altun@yaani.com
RI Altun, Sinan/IAM-5049-2023; altun, idiris/A-6095-2016
OI Altun, Sinan/0000-0002-2356-0460; altun, idiris/0000-0003-4263-766X
FU TUBITAK [122E042]
FX This study was funded by the TUBITAK (Project no:122E042) project
   entitled Lumbar Spinal Narrow Channel Analysis with Deep Learning Based
   Decision Support Systems
CR Al-Kafri AS, 2019, IEEE ACCESS, V7, P43487, DOI 10.1109/ACCESS.2019.2908002
   Das D, 2022, MULTIMED TOOLS APPL, V81, P21471, DOI 10.1007/s11042-022-11913-4
   Deer T, 2019, PAIN MED, V20, pS32, DOI 10.1093/pm/pnz161
   Dong N, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106311
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   Ghosh S, 2021, PHYS ENG SCI MED, V44, P703, DOI 10.1007/s13246-021-01019-w
   Gong H, 2022, ARTIF INTELL MED, V124, DOI 10.1016/j.artmed.2022.102243
   Huber FA, 2019, EUR J RADIOL, V114, P45, DOI 10.1016/j.ejrad.2019.02.023
   Jensen RK, 2019, PHYS REV X, V181
   Li HX, 2021, NEURAL COMPUT APPL, V33, P11589, DOI 10.1007/s00521-021-05856-4
   Liu WC, 2022, WORLD NEUROSURG, V162, pE553, DOI 10.1016/j.wneu.2022.03.060
   Lu J, 2018, MLHC
   Lu SY, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05625
   Macfarlane GJ, 1999, PAIN, V80, P113, DOI 10.1016/S0304-3959(98)00209-7
   Miron C, 2022, MULTIMED TOOLS APPL, V81, P14961, DOI 10.1007/s11042-022-12212-8
   Rana A, 2022, MULTIMED TOOLS APPL, V81, P18129, DOI 10.1007/s11042-022-12214-6
   Rehman HU, 2022, MULTIMED TOOLS APPL, V81, P25765, DOI 10.1007/s11042-022-12460-8
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shehab LH., 2021, J KING SAUD U ENG SC, V33, P404, DOI [DOI 10.1016/J.JKSUES.2020.06.001, 10.1016/j.jksues.2020.06.001]
   Zhang Z, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105395
NR 21
TC 2
Z9 2
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41287
EP 41305
DI 10.1007/s11042-023-15205-3
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967980300009
DA 2024-07-18
ER

PT J
AU Pinard, C
   Manzanera, A
AF Pinard, Clement
   Manzanera, Antoine
TI Does it work outside this benchmark? Introducing the rigid depth
   constructor tool Depth validation dataset construction in rigid scenes
   for the masses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular depth estimation; Validation dataset construction; Depth
   evaluation metrics
ID REGISTRATION
AB A new framework called Rigid Depth Constructor (RDC) is proposed, allowing a user to create his own dataset for the validation of depth map estimation algorithms in the context of autonomous navigation. Compared to the existing tools that rely on high quality fixed Lidar sensor, RDC is usable in low-cost setups requiring only a camera and any (e.g. handheld, or UAV-carried) Lidar sensor, which implies more flexible - and much faster - scene scan. Furthermore, unlike photogrammetry tools that use sparse RGB views, it can be applied to smooth videos while remaining computationally tractable. The framework includes a test suite to get insightful information from the evaluated algorithm. As examples, validation videos made from UAV footage are provided to evaluate two depth prediction algorithms initially tested on in-car driving video datasets, which shows that the drone context is dramatically different. This supports the need to benchmark depth estimation algorithms on a dataset that fits one's particular context, which often means creating a brand new one. An open source implementation accompanies the paper, designed to be as user-friendly as possible, to make depth dataset creation possible even for small teams. The key contributions are the following: (1) a complete, open-source and almost fully automatic software application for creating validation datasets with densely annotated depth, adaptable to a wide variety of image, video and range data; (2) selection tools to adapt the dataset to specific validation needs, and conversion tools to other dataset formats; (3) as use case examples, two new real datasets, outdoor and indoor, readily usable in UAV navigation context are provided, and used as test sets in the evaluation of two depth prediction algorithms, using a collection of comprehensive (e.g. distribution based) metrics.
C1 [Pinard, Clement; Manzanera, Antoine] Inst Polytech Paris, ENSTA Paris, U2IS, 828 Blvd Marechaux, F-91762 Palaiseau, France.
C3 Institut Polytechnique de Paris; ENSTA Paris
RP Manzanera, A (corresponding author), Inst Polytech Paris, ENSTA Paris, U2IS, 828 Blvd Marechaux, F-91762 Palaiseau, France.
EM clement.pinard@ensta-paris.fr; antoine.manzanera@ensta-paris.fr
FU Parrot9 company
FX Acquisitions for the Manoir dataset were made in collaboration with
   AIRD'ECO-Drone8 company, thanks to the financial support of Parrot9
   company. Acquisitions for the University hall dataset were made entirely
   by Clement Pinard, thanks to the equipment and training provided by
   Geomesure10 company.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bian JW, 2019, ADV NEUR IN, V32
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chen YH, 2019, IEEE I CONF COMP VIS, P7062, DOI 10.1109/ICCV.2019.00716
   Clement P, 2019, THESIS U PARIS SACLA
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eigen D, 2014, ADV NEUR IN, V27
   Fragkiadaki Aikaterini, 2017, ARXIV
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Gollob C, 2020, DATA, V5, DOI 10.3390/data5040103
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jonas U, 2017, INT C 3D VIS 3DV
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kraus K., 2011, PHOTOGRAMMETRY GEOME, V2nd
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Labatut P, 2009, DATA COMPUT GRAPH FO
   Lee J, 2019, PR MACH LEARN RES, V97
   Li H, 2020, C ROBOT LEARNING COR
   Li Hanhan, 2021, P C ROB LEARN, P1908
   Lopez Brett T., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5759, DOI 10.1109/ICRA.2017.7989677
   Matteo P, 2020, IEEE CVF C COMP VIS
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nalpantidis L, 2009, LECT NOTES ARTIF INT, V5928, P195, DOI 10.1007/978-3-642-10817-4_19
   Pinard C, 2017, ISPRS ANN PHOTO REM, V4-2, P67, DOI 10.5194/isprs-annals-IV-2-W3-67-2017
   Pinard C, 2018, P EUR C COMP VIS ECC
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Schilling H, 2020, IN PRESS
   Schonberger J. L., 2016, P AS C COMP VIS
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   van Dijk T, 2019, IEEE I CONF COMP VIS, P2183, DOI 10.1109/ICCV.2019.00227
   Vasiljevic I., 2019, DIODE: A dense indoor and outdoor DEpth dataset
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhou KY, 2021, APPL OPTICS, V60, P8188, DOI 10.1364/AO.432534
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 49
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41641
EP 41667
DI 10.1007/s11042-023-14743-0
EA APR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900016
DA 2024-07-18
ER

PT J
AU Hamida, S
   Cherradi, B
   El Gannour, O
   Raihani, A
   Ouajji, H
AF Hamida, Soufiane
   Cherradi, Bouchaib
   El Gannour, Oussama
   Raihani, Abdelhadi
   Ouajji, Hassan
TI Cursive Arabic handwritten word recognition system using majority voting
   and k-NN for feature descriptor selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-nearest neighbor's algorithm (k-NN); Gabor filter; Handwritten Arabic
   words recognition; HOG; Machine learning
ID TEXTURE CLASSIFICATION; COMBINATION; CLASSIFIERS
AB Handwriting text recognition for computer systems has been the subject of more and more research. Recognition of Arabic handwritten text is always an ongoing challenge, mainly due to the similarity between its letters and various writing styles. However, the problem of cursive handwriting recognition remains laborious due to the complexity of the Arabic handwriting morphology. This paper proposes a new efficient-based image processing approach that combines three image descriptors, the Oriented Gradient Histogram, the Gabor filter, and the Local Binary Pattern method for the features extraction phase. To prepare the training and testing datasets, we applied a series of preprocessing techniques on 100 classes selected from the handwritten Arabic database IFN/ENIT. Then, we trained the k-nearest neighbor algorithm (k-NN) to generate the best model for each feature extraction descriptor. The best k-NN model is used to classify Arabic handwritten images according to their classes. The model's performance evaluation uses the main common metrics, namely accuracy, sensitivity, specificity, and precision. Based on the performance evaluation results of the three k-NN generated models, the Majority-voting algorithm is used to combine the prediction results. A high recognition rate of up to 99.88% is achieved, far exceeding the already state-of-the-art results on the IFN/ENIT dataset. The obtained results highlight the reliability of the final model generated for recognizing handwritten Arabic words.
C1 [Hamida, Soufiane; Cherradi, Bouchaib; El Gannour, Oussama; Raihani, Abdelhadi; Ouajji, Hassan] Hassan II Univ Casablanca, Elect Engn & Intelligent Syst EEIS Lab, ENSET Mohammedia, Mohammadia, Morocco.
   [Hamida, Soufiane] SUPMTI Rabat, GENIUS Lab, Rabat, Morocco.
   [Cherradi, Bouchaib] CRMEF Casablanca Settat, STIE Team, Prov Sect Jadida, El Jadida 24000, Settat, Morocco.
C3 Hassan II University of Casablanca
RP Cherradi, B (corresponding author), Hassan II Univ Casablanca, Elect Engn & Intelligent Syst EEIS Lab, ENSET Mohammedia, Mohammadia, Morocco.; Cherradi, B (corresponding author), CRMEF Casablanca Settat, STIE Team, Prov Sect Jadida, El Jadida 24000, Settat, Morocco.
EM bouchaib.cherradi@gmail.com
RI bouchaib, cherradi/J-2572-2016; EL GANNOUR, Oussama/AGZ-7257-2022; EL
   GANNOUR, OUSSAMA/IAR-0349-2023; RAIHANI, Abdelhadi/GOP-3473-2022
OI bouchaib, cherradi/0000-0002-2016-8682; EL GANNOUR,
   Oussama/0000-0003-2536-9528; EL GANNOUR, OUSSAMA/0000-0003-2536-9528;
   RAIHANI, Abdelhadi/0000-0002-6295-274X
CR AL-Saffar A, 2018, IJET (UAE), V7, P344, DOI [10.14419/ijet.v7i3.20.19271, DOI 10.14419/IJET.V7I3.20.19271]
   Al-wajih E, 2021, MULTIMED TOOLS APPL, V80, P24399, DOI 10.1007/s11042-021-10762-x
   Alalshekmubarak A, 2012, LECT NOTES COMPUT SC, V7664, P85, DOI 10.1007/978-3-642-34481-7_11
   AlKhateeb JH, 2015, PROCEDIA COMPUT SCI, V65, P556, DOI 10.1016/j.procs.2015.09.130
   Almodfer R, 2017, LECT NOTES COMPUT SC, V10614, P260, DOI 10.1007/978-3-319-68612-7_30
   Alrobah N, 2021, IEEE ACCESS, V9, P87058, DOI 10.1109/ACCESS.2021.3087647
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Alyahya H., 2020, TIPCV, V6, P68, DOI 10.19101/TIPCV.2020.618051
   Amara Marwa, 2020, Hybrid Intelligent Systems. 18th International Conference on Hybrid Intelligent Systems (HIS 2018). Advances in Intelligent Systems and Computing (AISC 923), P570, DOI 10.1007/978-3-030-14347-3_56
   [Anonymous], 2012, GUIDE OCR ARABIC SCR
   Armi L., 2019, ARXIV
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   BOLAND PJ, 1989, STATISTICIAN, V38, P181, DOI 10.2307/2348873
   Bouressace H, 2019, LECT NOTES ARTIF INT, V11697, P127, DOI 10.1007/978-3-030-27947-9_11
   Cao SX, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0487-7
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Sousa IP, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.167
   Neto AFD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217711
   El Abed Haikal, 2007, 2007 9th International Symposium on Signal Processing and Its Applications (ISSPA), DOI 10.1109/ISSPA.2007.4555529
   Furnkranz J., 2011, ENCY MACHINE LEARNIN, P683, DOI [10.1007/978-0-387-30164-8_550, DOI 10.1007/978-0-387-30164-8_550]
   Ghadhban HQ, 2020, ADV INTELL SYST COMP, V978, P358, DOI 10.1007/978-3-030-36056-6_34
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   Hamida S., 2020, P 2020 IEEE 2 INT C, P1, DOI DOI 10.1109/ICECOCS50124.2020.9314373
   Hamida S, 2021, 2021 INT C ADV TECHN, P1, DOI [10.1109/ICOTEN52080.2021.9493438, DOI 10.1109/ICOTEN52080.2021.9493438]
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Khalifa M, 2011, COMM COM INF SC, V143, P163
   Khan S, 2019, J GRID COMPUT, V17, P239, DOI 10.1007/s10723-018-9459-x
   Kim CM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196904
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V4985, P598
   Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102
   Maalej R, 2020, MULTIMED TOOLS APPL, V79, P17969, DOI 10.1007/s11042-020-08740-w
   Mohamad RAH, 2009, IEEE T PATTERN ANAL, V31, P1165, DOI 10.1109/TPAMI.2008.136
   Mohammad K, 2021, MULTIMED TOOLS APPL, V80, P2177, DOI 10.1007/s11042-020-09737-1
   Mouhcine Rabi, 2018, Journal of Electrical Systems and Information Technology, V5, P245, DOI 10.1016/j.jesit.2017.02.001
   Nemouchi Soulef, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P562, DOI 10.1007/978-3-642-31254-0_64
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Ramdan J, 2013, PROC TECH, V11, P580, DOI 10.1016/j.protcy.2013.12.231
   Saddami K, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02613
   Saeed K, 2010, INT J AP MAT COM-POL, V20, P317, DOI 10.2478/v10006-010-0024-4
   Sahlol Ahmed T., 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P264, DOI 10.1007/978-3-319-11656-3_24
   Su CT, 2006, EXPERT SYST APPL, V31, P531, DOI 10.1016/j.eswa.2005.09.082
   Tulyakov S, 2008, STUD COMPUT INTELL, V90, P361
   Wang ZB, 2020, ARTIF INTELL REV, V53, P5637, DOI 10.1007/s10462-020-09830-9
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Zoizou A, 2020, J KING SAUD UNIV-COM, V32, P576, DOI 10.1016/j.jksuci.2018.07.003
NR 51
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40657
EP 40681
DI 10.1007/s11042-023-15167-6
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100002
DA 2024-07-18
ER

PT J
AU Jalali, M
   Zahedi, M
   Basiri, A
AF Jalali, Maryam
   Zahedi, Morteza
   Basiri, Abdolali
TI Deterministic solution of algebraic equations in sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algebraic approaches to semantics; Applications and expert knowledge
   intensive systems; Sentiment analysis; Text mining; Text processing;
   Tikhonov regularization
ID FEATURE-SELECTION; ALGORITHM; LEXICON
AB Text mining methods usually use statistical information to solve text and language-independent procedures. Text mining methods such as polarity detection based on stochastic patterns and rules need many samples to train. On the other hand, deterministic and non-probabilistic methods are easy to solve and faster than other methods but are not efficient in NLP data. In this article, a fast and efficient deterministic method for solving the problems is proposed. In the proposed method firstly we transform text and labels into a set of equations. In the second step, a mathematical solution of ill-posed equations known as Tikhonov regularization was used as a deterministic and non-probabilistic way including additional assumptions, such as smoothness of solution to assign a weight that can reflect the semantic information of each sentimental word. We confirmed the efficiency of the proposed method in the SemEval-2013 competition, ESWC Database and Taboada database as three different cases. We observed improvement of our method over negative polarity due to our proposed mathematical step. Moreover, we demonstrated the effectiveness of our proposed method over the most common and traditional machine learning, stochastic and fuzzy methods.
C1 [Jalali, Maryam; Zahedi, Morteza] Shahrood Univ Technol, Fac Comp & IT Engn, Shahrood, Iran.
   [Basiri, Abdolali] Univ Damghan, Fac Math & Comp Sci, Damghan, Iran.
C3 Shahrood University of Technology
RP Zahedi, M (corresponding author), Shahrood Univ Technol, Fac Comp & IT Engn, Shahrood, Iran.
EM maryamjalali@shahroodut.ac.ir; zahedi@shahroodut.ac.ir; basiri@du.ac.ir
CR Abdi A, 2018, EXPERT SYST APPL, V109, P66, DOI 10.1016/j.eswa.2018.05.010
   Abdullah NA, 2019, IEEE ACCESS, V7, P144957, DOI 10.1109/ACCESS.2019.2945340
   Al-Twairesh N, 2019, IEEE ACCESS, V7, P84122, DOI 10.1109/ACCESS.2019.2924314
   Amini I., 2019, P 10 WORKSHOP COMPUT, P81
   [Anonymous], 1999, Tech. Rep. C-1
   Araque O, 2019, KNOWL-BASED SYST, V165, P346, DOI 10.1016/j.knosys.2018.12.005
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Blankers M, 2019, INT J DRUG POLICY, V64, P34, DOI 10.1016/j.drugpo.2018.11.016
   Borshchev N. O., 2020, Russian Engineering Research, V40, P593, DOI 10.3103/S1068798X20070059
   Brooke J, 2009, THESIS DEP LINGUISTI
   BROWN DE, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P406
   Buccini A, 2020, J COMPUT APPL MATH, V373, DOI 10.1016/j.cam.2019.05.024
   Bulirsch R., 2002, Introduction to Numerical Analysis
   Carbonell J.G., 1979, Subjective Understanding: Computer Models of Belief Systems
   Chatterjee N, 2020, ALGO INTELL SY, P237, DOI 10.1007/978-981-15-1216-2_9
   Dai A.M., 2015, ARXIV
   DANGI D, 2022, CMC-COMPUT MATER CON, P1
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   de Vries G, 2020, SOC ISS POLICY REV, V14, P244, DOI 10.1111/sipr.12061
   Delibasis K, 2010, PATTERN RECOGN, V43, P4011, DOI 10.1016/j.patcog.2010.06.009
   Deng D, 2019, IEEE-ACM T AUDIO SPE, V27, P1777, DOI 10.1109/TASLP.2019.2933326
   Devlin J., 2018, BERT PRE TRAINING DE
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Di Rosa E, 2016, SEMANTIC WEB EVALUAT, P95
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   Fu XH, 2018, IEEE ACCESS, V6, P71884, DOI 10.1109/ACCESS.2018.2878425
   Gao Y, 2019, IEEE ACCESS, V7, P168548, DOI 10.1109/ACCESS.2019.2954590
   Haddadi GA, 2011, CAN J REMOTE SENS, V37, P27
   Hogenboom A, 2013, MULTIMED TOOLS APPL, V64, P27, DOI 10.1007/s11042-012-1122-0
   Iqbal F, 2019, IEEE ACCESS, V7, P14637, DOI 10.1109/ACCESS.2019.2892852
   Jazyah YH., 2018, J COMPUT SCI, V14, P804, DOI [10.3844/jcssp.2018.804.818, DOI 10.3844/JCSSP.2018.804.818]
   Kim Suin., 2013, AAAI, P526, DOI DOI 10.1609/AAAI.V27I1.8700
   Kiritchenko S, 2017, ARXIV
   Kumar A, 2020, MULTIMED TOOLS APPL, V79, P15349, DOI 10.1007/s11042-019-7346-5
   Lu CH, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0097-y
   Maghsoudi Y, 2013, IEEE J-STARS, V6, P1531, DOI 10.1109/JSTARS.2013.2259219
   Mahmoudi A, 2021, ARXIV
   Mihaylova T, 2019, ARXIV
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nemati S, 2009, EXPERT SYST APPL, V36, P12086, DOI 10.1016/j.eswa.2009.04.023
   Nemes L, 2021, J INFORM TELECOMMUN, V5, P1, DOI 10.1080/24751839.2020.1790793
   Ngo VTT, 2020, THESIS RICE U
   Osorio J, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207039
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Petrucci G, 2016, SEMANTIC WEB EVALUAT, P126, DOI DOI 10.1007/978-3-319-46565-4
   Phang J, 2018, ARXIV
   Priyadarshini I, 2022, MULTIMED TOOLS APPL, V81, P27009, DOI 10.1007/s11042-021-11004-w
   Qiao G, 2020, INVERSE PROBL SCI EN, P1, DOI DOI 10.1080/17415977.2020.1817916
   Qiu QJ, 2020, EARTH SPACE SCI, V7, DOI 10.1029/2019EA000993
   Qureshi SA, 2020, IEEE COMPUT INTELL M, V15, P47, DOI 10.1109/MCI.2020.2998234
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Raju KV, 2020, ADV INTELL SYST, V1045, P807, DOI 10.1007/978-981-15-0029-9_63
   RAY A, 2020, BEHAV INF TECHNOL, P1
   Ruseti Stefan, 2020, Fourth International Congress on Information and Communication Technology. ICICT 2019. Advances in Intelligent Systems and Computing (AISC 1041), P323, DOI 10.1007/978-981-15-0637-6_27
   Sánchez-Núñez P, 2020, IEEE ACCESS, V8, P134563, DOI 10.1109/ACCESS.2020.3009482
   Santos TMR, 2020, INVERSE PROBL SCI EN, V28, P1513, DOI 10.1080/17415977.2020.1732957
   Sharma R., 2020, arXiv
   Snyder B., 2007, proceedings of the Joint Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies, P300
   Stoer J., 1980, INTRO NUMERICAL ANAL
   Stone P. J., 1966, GEN INQUIRER COMPUTE
   Sygkounas E., 2016, SEMANTIC WEB EVALUAT, P108
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Taboada Maite., 2004, P AAAI SPRING S EXPL, P158
   Tang GJ, 2020, VIETNAM J MATH, V48, P221, DOI 10.1007/s10013-019-00362-6
   Tewari Anand Shanker, 2015, Information Science and Applications, P1021, DOI 10.1007/978-3-662-46578-3_122
   Upadhyaya B, 2019, 2019 IEEE VTS ASIA PACIFIC WIRELESS COMMUNICATIONS SYMPOSIUM (APWCS 2019), DOI 10.1109/vts-apwcs.2019.8851633
   Vinodhini G., 2014, CSI Transactions on ICT, V2, P169
   Xu GX, 2019, IEEE ACCESS, V7, P43749, DOI 10.1109/ACCESS.2019.2907772
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Yang F, 2020, J COMPUT APPL MATH, V380, DOI 10.1016/j.cam.2020.112998
   Yang QJ, 2019, IEEE INTELL SYST, V34, P43, DOI 10.1109/MIS.2019.2899142
   Ye QF, 2019, IEEE SYS MAN CYBERN, P372, DOI 10.1109/SMC.2019.8913898
   Yi JH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2003.1250949
   You L, 2020, FUTURE GENER COMP SY, V102, P163, DOI 10.1016/j.future.2019.07.044
   Yu LC, 2018, IEEE-ACM T AUDIO SPE, V26, P671, DOI 10.1109/TASLP.2017.2788182
   Yurtalan G, 2019, TURK J ELECTR ENG CO, V27, P1325, DOI 10.3906/elk-1803-92
   Zargari H, J INTELL FUZZY SYST, P1
   Zhao YY, 2016, MULTIMED TOOLS APPL, V75, P8843, DOI 10.1007/s11042-014-2184-y
   Zhou JT, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149057
   Zoph B., 2016, INT C LEARN REPR
NR 82
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35457
EP 35474
DI 10.1007/s11042-023-15140-3
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000960423600002
PM 37362725
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Saranya, P
   Pranati, R
   Patro, SS
AF Saranya, P.
   Pranati, R.
   Patro, Sneha Shruti
TI Detection and classification of red lesions from retinal images for
   diabetic retinopathy detection using deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Red lesions; Microaneurysms; Haemorrhages; CNN;
   UNet
ID MICROANEURYSM DETECTION; FRAMEWORK
AB Diabetic retinopathy (DR) is an eye disease caused by retinal damage induced by the long-term illness of diabetes mellitus. In the early stages, DR may show no symptoms or only minor vision difficulties, but it can eventually result in vision loss if not treated early. Manual diagnosis of Diabetic retinopathy requires many physical tests like visual acuity, pupil dilation, and tonometry. But the issue with these tests is that they consume more time, cost, and effort, therefore affecting patients. Also, it is challenging to identify the disease through these tests during the earlier stage of the disease due to its tiny structure. Since the current system is highly dependent on the resources available and time-consuming, better alternatives are being sought. The proposed work aims to develop an automated model for detecting the early stage of DR detection based on red lesions present in the retinal images. The pre-processing is carried out to remove the noise present, improve local contrast levels in the image, and is further subjected to UNet architecture for the semantic segmentation of red lesions. Advanced Convolutional Layer Architecture in U-Net was used to support pixel-level class labeling, which is much needed in medical segmentation. The segmented images obtained from the red lesion detection were then used as the input to feed the convolution neural network to train and classify the input images to their corresponding severity classes. Four publicly available datasets, IDRiD, DIARETDB1, MESSIDOR, and STARE, were used in the proposed model to evaluate its performance. On working with the IDRID dataset, the specificity and sensitivity of the proposed Red Lesion detection system were observed as 99% and 89%, respectively, with an accuracy of 95.65%. The specificity, sensitivity, and accuracy obtained for the Diabetic retinopathy severity classification system were 93.8%, 92.3%, and 94%, respectively, on working with the MESSIDOR dataset.
C1 [Saranya, P.; Pranati, R.; Patro, Sneha Shruti] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Saranya, P (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 603203, Tamil Nadu, India.
EM saranyap@srmist.edu.in
RI P, Saranya/ABY-7095-2022
OI P, Saranya/0000-0003-2333-6968
FU The authors would like to thank the SRM Institute of Science and
   Technology, Department of CSE for providing an excellent atmosphere for
   researching on this topic.
FX The authors would like to thank the SRM Institute of Science and
   Technology, Department of CSE for providing an excellent atmosphere for
   researching on this topic.
CR Agarwal S, 2023, MULTIMED TOOLS APPL, V82, P17321, DOI 10.1007/s11042-022-13837-5
   [Anonymous], 2019, UNDERSTANDING SEMANT
   Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126
   Brownlee J., 2019, How to accelerate learning of deep neural networks with batch normalization
   Chetoui M, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.4.044503
   Choong KH, 2022, MULTIMED TOOLS APPL, V81, P31161, DOI 10.1007/s11042-021-11808-w
   Dayana AM, 2022, MULTIMED TOOLS APPL, V81, P20611, DOI 10.1007/s11042-022-12492-0
   de la Torre J, 2020, NEUROCOMPUTING, V396, P465, DOI 10.1016/j.neucom.2018.07.102
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Fan XN, 2019, CHIN CONT DECIS CONF, P5661, DOI [10.1109/CCDC.2019.8833280, 10.1109/ccdc.2019.8833280]
   González-Gonzalo C, 2020, ACTA OPHTHALMOL, V98, P368, DOI 10.1111/aos.14306
   Guo S, 2019, NEUROCOMPUTING, V349, P52, DOI 10.1016/j.neucom.2019.04.019
   Hoover A, 2003, Structured Analysis of the Retina
   Islam M., 2017, J Biomed Sci Eng, V10, P86, DOI DOI 10.4236/JBISE.2017.105B010
   Joshi S, 2020, EUR J OPHTHALMOL, V30, P1135, DOI 10.1177/1120672119843021
   Kalviainen R., 2007, the diaretdb1 diabetic retinopathy database and evaluation protocol
   Kind A., 2019, Computer Analysis of Images and Patterns. CAIP 2019. Lecture notes in computer science
   Kumar S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P359, DOI 10.1109/SPIN.2018.8474264
   Latha D, 2022, MULTIMED TOOLS APPL, V81, P26143, DOI 10.1007/s11042-022-12667-9
   Lavado Diego M., 2022, 2022 E-Health and Bioengineering Conference (EHB), P1, DOI 10.1109/EHB55594.2022.9991526
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Prabha S., 2022, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2325/1/012043
   Rakhlin A., 2017, bioRxiv
   Romero-Oraá R, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040417
   Roychowdhury S, 2014, IEEE J BIOMED HEALTH, V18, P1717, DOI 10.1109/JBHI.2013.2294635
   Sahoo R., 2019, Int J Comput Appl, V182, P46
   Sakaguchi A., 2019, Proceedings of the 2019 9th International Conference on Biomedical Engineering and Technology, P190
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Serener A, 2020, TURK J ELECTR ENG CO, V28, P664, DOI 10.3906/elk-1902-131
   Shaukat N, 2022, J PERS MED, V12, DOI 10.3390/jpm12091454
   Staff B. M., 2018, Diabetic retinopathy Retrieved from Mayo Clinic
   Wang Z., 2017, Medical Image Computing and Computer Assisted Intervention (MICCAI)
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zhang L, 2009, IEEE T INF TECHNOL B, V13, P528, DOI 10.1109/TITB.2008.2007201
   Zhang YR, 2016, J STAT MECH-THEORY E, P1, DOI 10.1088/1742-5468/2016/11/113207
   Zhu CZ, 2019, J COMPUT SCI TECH-CH, V34, P1307, DOI 10.1007/s11390-019-1977-x
NR 37
TC 22
Z9 22
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39327
EP 39347
DI 10.1007/s11042-023-15045-1
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Yadav, NK
AF Yadav, Naresh Kumar
TI Optimizing TCSC configuration via genetic algorithm for ATC enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mutation; ATC; GADMP; TCSC; Optimization
ID FACTS DEVICES; POWER-SYSTEM; OPTIMIZATION; PLACEMENT; SSSC
AB Flexible AC transmission systems (FACTS) are a viable way to improve power system performance because of the rapid advancement of power electronic technology. Improvement of dynamic and transient stability, voltage control, voltage stability improvement, power factor correction, enhancement of `power profile, an increase in the transmission line's power transfer capabilities, and loss alleviation are all FACTS device applications in power system networks. But, optimal placement and sizing of the FACTS devices may cause the system to attain the objective at a reasonable cost. Hence, to find out the optimal location and compensation level of the FACTS device, an improved version of the Genetic algorithm (GA) had been introduced in the preceding version of this paper. Genetic Algorithm with Dual Mutation Probability (GADMP) was the term given to the improved version of GA since it included dual probabilities for the mutation operator. To ensure a fair comparison between the algorithms on FACTS localization and sizing, this paper subjects the GADMP and Traditional GA (TGA) to rigorous experimental investigation. Simulation experiments have been performed using three benchmark bus systems, IEEE 24 RTS, IEEE 30, and IEEE 57 to verify the performance of the adopted scheme.
C1 [Yadav, Naresh Kumar] Deenbandhu Chhotu Ram Univ Sci & Technol, Fac Engn & Technol, Dept Elect Engn, Sonepat, Haryana, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology
RP Yadav, NK (corresponding author), Deenbandhu Chhotu Ram Univ Sci & Technol, Fac Engn & Technol, Dept Elect Engn, Sonepat, Haryana, India.
EM nareshyadhavdr@gmail.com
CR Abasi M., 2021, Journal of Operation and Automation in Power Engineering, V9, P213, DOI 10.22098/joape.2021.7774.1551
   Abd Elazim SM, 2016, INT J ELEC POWER, V82, P161, DOI 10.1016/j.ijepes.2016.02.023
   Abd-Elazim SM, 2016, INT J ELEC POWER, V80, P240, DOI 10.1016/j.ijepes.2016.01.023
   Adewolu BO, 2020, INT J ENG RES AFR, V49, P104, DOI 10.4028/www.scientific.net/JERA.49.104
   Bamigbade Abdullateef T., 2020, 2020 IEEE PES IAS PO
   Barua P, 2018, 2018 4 INT C EL ENG
   do Nascimento S, 2017, ENRGY PROCED, V107, P60, DOI 10.1016/j.egypro.2016.12.129
   Durkovic V, 2020, INT J ELEC POWER, V115, DOI 10.1016/j.ijepes.2019.105497
   Ejebe GC, 1998, IEEE T POWER SYST, V13, P1521, DOI 10.1109/59.736300
   Gautam A, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON RECENT DEVELOPMENTS IN CONTROL, AUTOMATION & POWER ENGINEERING (RDCAPE), P313, DOI [10.1109/RDCAPE47089.2019.8979016, 10.1109/rdcape47089.2019.8979016]
   Goldberg D. E., 1999, GENETIC ALGORITHMS S
   Gomis-Bellmunt O, 2020, IEEE T POWER DELIVER, V35, P2, DOI 10.1109/TPWRD.2019.2939588
   Guirguis M, 2018, IEEE CONF COMM NETW
   Gupta D, 2021, ENERGIES, V14, DOI 10.3390/en14040869
   Ibraheem, 2011, INT J COMP ELECT ENG, V3, P343, DOI [10.7763/IJCEE.2011.V3.338, DOI 10.7763/IJCEE.2011.V3.338]
   Karmakar N, 2020, IET GENER TRANSM DIS, V14, P6294, DOI 10.1049/iet-gtd.2020.1356
   Kumar H., 2019, J COMPUTATIONAL MECH, V2, P38, DOI [10.46253/jcmps.v2i2.a5, DOI 10.46253/JCMPS.V2I2.A5]
   Li BH, 2000, INT J ELEC POWER, V22, P43, DOI 10.1016/S0142-0615(99)00037-X
   Li WT, 2014, IET MICROW ANTENNA P, V8, P287, DOI 10.1049/iet-map.2013.0240
   Lokesh Kumar R., 2019, J COMPUT MECH POWER, V2, P1, DOI [10.46253/jcmps.v2i3.a1, DOI 10.46253/JCMPS.V2I3.A1]
   Long W., 2020, FLEXIBLE AC TRANSMIS, P3, DOI [10.1007/978-3-030-35386-5_1, DOI 10.1007/978-3-030-35386-5_1]
   Luburic Z, 2019, INT J ELEC POWER, V104, P311, DOI 10.1016/j.ijepes.2018.07.013
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   Nadeem M, 2020, ENERGIES, V13, DOI 10.3390/en13030753
   Pandiyan M. Karuppasamy, 2021, IOP Conference Series: Materials Science and Engineering, V1055, DOI 10.1088/1757-899X/1055/1/012146
   Panichella A, 2015, IEEE T SOFTWARE ENG, V41, P358, DOI 10.1109/TSE.2014.2364175
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Sadiq AA, 2020, IET GENER TRANSM DIS, V14, P4866, DOI 10.1049/iet-gtd.2020.0886
   Said A., 2020, J COMPUT MECH POWER, V3, P33, DOI DOI 10.46253/JCMPS.V3I2.A5
   Salkuti SR., 2018, INT J ELECT ENG INF, V10, P526
   Shahgholian G., 2020, NASHRIYYAH I MUHANDI, V75, P271
   Sheng H, 2014, IEEE T POWER SYST, V29, P1365, DOI 10.1109/TPWRS.2013.2289917
   Siddique A, 2018, C IND ELECT APPL, P893, DOI 10.1109/ICIEA.2018.8397839
   Singh RP, 2015, INT J ELEC POWER, V64, P1185, DOI 10.1016/j.ijepes.2014.09.005
   Singh S, 2021, MATER TODAY-PROC, V34, P787, DOI 10.1016/j.matpr.2020.05.161
   Tapre PC, 2021, J COMPUT MECH POWER, V4
   Nguyen TT, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072813
   Vaithilingam C, 2013, INT J ELEC POWER, V47, P387, DOI 10.1016/j.ijepes.2012.10.054
   Wang FJ, 2014, IEEE-ASME T MECH, V19, P916, DOI 10.1109/TMECH.2013.2260555
   Yadav N, 2015, P 6 INT C ADV COMP C
   Zuo XQ, 2015, IEEE T INTELL TRANSP, V16, P1030, DOI 10.1109/TITS.2014.2352599
NR 42
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38715
EP 38741
DI 10.1007/s11042-023-15043-3
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956328600001
DA 2024-07-18
ER

PT J
AU Bushara, AR
   Kumar, RSV
   Kumar, SS
AF Bushara, A. R.
   Kumar, R. S. Vinod
   Kumar, S. S.
TI LCD-Capsule Network for the Detection and Classification of Lung Cancer
   on Computed Tomography Images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Capsule network; Deep learning; Convolutional neural network; Computed
   tomography; Lung cancer
ID CT; SEGMENTATION; DIAGNOSIS; FEATURES; NODULES
AB Lung cancer is the second most prominent cancer in men and women, and it is also the leading cause of cancer-related mortality.If lung cancer is diagnosed early, when it is minuscule and has not spread, it is preferable to be adequately treated. A non-invasive low-dose Computed Tomography (CT) scan can detect abnormal patches in the lungs that could be cancerous. It is proposed that machine learning and pattern classification be used to identify and categorize lung cancer from CT scans. Pattern classification algorithms like deep learning can categorize input data into various classes based on the input's characteristic features. A novel deep learning framework formulated by the encapsulation of a Convolutional Neural Network (CNN) and a Capsule Neural Network (CapsNet) called LCD-CapsNet, leveraging the capabilities of these networks to minimize vast amounts of data and achieve spatial invariance for lung cancer detection and classification using CT images is proposed. The primary objective of the proposed method is to create algorithms that would classify and examine images from a dataset to determine whether or not a patient had or posed a danger of developing lung cancer. The Lung Image Database Consortium (LIDC) datasets are utilized to assess this deep learning model, from which 4335 images were collected for the training and testing pipeline. The results demonstrated that LCD-CapsNet outperforms CapsNet, with an average Precision of 95 %, Recall of 94.5 %, F1-Score 94.5 %, Specificity 99.07 %, Area Under the Curve of 0.989, and Accuracy 94 % of benign and malignant data.
C1 [Bushara, A. R.; Kumar, R. S. Vinod] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari 629180, Tamil Nadu, India.
   [Kumar, S. S.] Noorul Islam Ctr Higher Educ, Dept Elect & Instrumentat Engn, Kanyakumari 629180, Tamil Nadu, India.
RP Bushara, AR (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari 629180, Tamil Nadu, India.
EM bushara.ar@gmail.com; vinodkumar@niuniv.com; kumarss@niuniv.com
RI S S, Kumar/D-6066-2014; Kumar, R.S. Vinod/AAT-3266-2020; A R,
   BUSHARA/HKF-5469-2023
OI S S, Kumar/0000-0002-7988-2768; Kumar, R.S. Vinod/0000-0001-9727-8110; A
   R, BUSHARA/0000-0001-5849-3416
FU National Cancer Institute; National Institutes of Health
FX The authors acknowledge the National Cancer Institute and the National
   Institutes of Health for their contributions to the development of the
   LIDC/IDRI database, which is free and open to the public. There was no
   specific grant awarded for this study by any government, commercial, or
   nonprofit organization.
CR Abubeker KM, 2022, FRONT SUSTAIN CITIES, V4, DOI 10.3389/frsc.2022.1063067
   Adebisi OA, 2022, INTELL HEALTHCARE, P19, DOI DOI 10.1007/978-981-16-8150-9_2
   Adu K, 2021, INT J IMAG SYST TECH, V31, P2075, DOI 10.1002/ima.22569
   Afshar P, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107942
   Afshar P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64824-5
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   AL-Huseiny M.S., 2021, Indonesian Journal of Electrical Engineering and Computer Science, V22, P1078, DOI DOI 10.11591/IJEECS.V22.I2.PP1078-1086
   Al-Yasriy Hamdalla F., 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/2/022035
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2014, International Journal of Com
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Avanzo M, 2020, STRAHLENTHER ONKOL, V196, P879, DOI 10.1007/s00066-020-01625-9
   Aydin N, 2021, CURR MED IMAGING, V17, P1137, DOI 10.2174/1573405617666210204210500
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bushara AR, 2022, ELCVIA Electron. Lett. Comput. Vis. Image Anal, V21, DOI [10.5565/rev/elcvia.1490, DOI 10.5565/REV/ELCVIA.1490]
   Causey JL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27569-w
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   El-Askary NS, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND INFORMATION ENGINEERING (ICSIE 2019), P248, DOI 10.1145/3328833.3328872
   Ghani T, 2021, PATTERN RECOGN LETT, V152, P56, DOI 10.1016/j.patrec.2021.09.001
   Guo ZQ, 2021, INT J IMAG SYST TECH, V31, P1954, DOI 10.1002/ima.22608
   Huidrom R, 2022, MULTIMED TOOLS APPL, V81, P32661, DOI 10.1007/s11042-022-12722-5
   Jain S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1599537
   K m Abubeker, 2022, 2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1, DOI 10.1109/ICRITO56286.2022.9964842
   Kalaivani N., 2020, IOP Conference Series: Materials Science and Engineering, V994, DOI 10.1088/1757-899X/994/1/012026
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Koresh HJD, 2021, PATTERN RECOGN LETT, V143, P104, DOI 10.1016/j.patrec.2021.01.005
   Kumar MP, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01654-9
   Lennartz S, 2021, CANCER IMAGING, V21, DOI 10.1186/s40644-020-00374-3
   Makaju S, 2018, PROCEDIA COMPUT SCI, V125, P107, DOI 10.1016/j.procs.2017.12.016
   Manju BR, 2021, IOP C SERIES MAT SCI, V1012, DOI [10.1088/1757-899X/1012/1/012034, DOI 10.1088/1757-899X/1012/1/012034]
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071
   Mobiny A, 2021, IEEE T MED IMAGING, V40, P2869, DOI 10.1109/TMI.2021.3051089
   Naqi SM, 2019, MULTIMED TOOLS APPL, V78, P26287, DOI 10.1007/s11042-019-07819-3
   Nasser I.M., 2019, INT J ENG INF SYST, V3, P17
   Nithila EE, 2019, BIOMED SIGNAL PROCES, V47, P57, DOI 10.1016/j.bspc.2018.08.008
   Nithila EE, 2017, ENG SCI TECHNOL, V20, P1192, DOI 10.1016/j.jestch.2016.12.006
   Nithila EE, 2016, ALEX ENG J, V55, P2583, DOI 10.1016/j.aej.2016.06.002
   Nithila EE, 2016, INT J BIOMED ENG TEC, V21, P311, DOI 10.1504/IJBET.2016.078334
   Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862
   Polat H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050940
   Ramana K, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.886739
   Sabour S, 2017, ADV NEUR IN, V30
   Salama WM, 2022, MULTIMED TOOLS APPL, V81, P32705, DOI 10.1007/s11042-022-13005-9
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau A.O., 2021, INFORM MED UNLOCKED, V23, P100511, DOI [10.1016/j.imu.2021.100511, DOI 10.1016/J.IMU.2021.100511]
   Saleh AY., 2021, Int J Adv Intell Informatics, V7, P151
   Shafi I, 2022, CANCERS, V14, DOI 10.3390/cancers14215457
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Song QZ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8314740
   Sori WJ, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9050-z
   Tang B, 2019, IEEE ACCESS, V7, P26022, DOI 10.1109/ACCESS.2019.2901049
   Thakur SK, 2020, CANCER METAST REV, V39, P989, DOI 10.1007/s10555-020-09901-x
   Wu PP, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8975078
   Yu H, 2020, IEEE ACCESS, V8, P86400, DOI 10.1109/ACCESS.2020.2992645
   Yu H, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04234-0
NR 57
TC 11
Z9 11
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 23
PY 2023
DI 10.1007/s11042-023-14893-1
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A5CE8
UT WOS:000955293100013
DA 2024-07-18
ER

PT J
AU Ge, SL
   Xia, ZH
   Fei, JW
   Tong, Y
   Weng, J
   Li, M
AF Ge, Sulong
   Xia, Zhihua
   Fei, Jianwei
   Tong, Yao
   Weng, Jian
   Li, Ming
TI A robust document image watermarking scheme using deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark; Document image; Noise layer; Deep neural network
ID COPYRIGHT PROTECTION; MARKING
AB Watermarking is an important copyright protection technology which generally embeds the identity information into the carrier imperceptibly. Then the identity can be extracted to prove the copyright from the watermarked carrier even after suffering various attacks. Most of the existing watermarking technologies take the nature images as carriers. Different from the natural images, document images are not so rich in color and texture, and thus have less redundant information to carry watermarks. This paper proposes an end-to-end document image watermarking scheme using the deep neural network. Specifically, an encoder and a decoder are designed to embed and extract the watermark. A noise layer is added to simulate the various attacks that could be encountered in reality, such as the Cropout, Dropout, Gaussian blur, Gaussian noise, Resize, and JPEG Compression. A text-sensitive loss function is designed to limit the embedding modification on characters. An embedding strength adjustment strategy is proposed to improve the quality of watermarked image with little loss of extraction accuracy. Experimental results show that the proposed document image watermarking technology outperforms three state-of-the-art methods in terms of the robustness and image quality.
C1 [Ge, Sulong; Xia, Zhihua; Fei, Jianwei] Nanjing Univ Informat Sci & Technol, Sch Comp, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.
   [Ge, Sulong; Xia, Zhihua; Fei, Jianwei] Minist Educ, Engn Res Ctr Digital Forens, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.
   [Xia, Zhihua; Weng, Jian; Li, Ming] Jinan Univ, Coll Cyber Secur, 601 Huangpu Rd West, Guangzhou 510632, Guangdong, Peoples R China.
   [Tong, Yao] Guangzhou Fongwell Data Ltd Co, 371-1 Wushan Rd, Guangzhou 510510, Guangdong, Peoples R China.
C3 Nanjing University of Information Science & Technology; Jinan University
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.; Xia, ZH (corresponding author), Minist Educ, Engn Res Ctr Digital Forens, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.; Xia, ZH (corresponding author), Jinan Univ, Coll Cyber Secur, 601 Huangpu Rd West, Guangzhou 510632, Guangdong, Peoples R China.
EM 13512983683@163.com; xia_zhihua@163.com; fjw826244895@163.com;
   melody@fongwell.com; cryptjweng@gmail.com; limjnu@gmail.com
RI Fei, Jianwei/HJB-2007-2022; Xia, Zhihua/C-8581-2011; Tong,
   Yao/KPY-1291-2024
OI Fei, Jianwei/0000-0002-1243-3909; Weng, Jian/0000-0003-4067-8230
FU National Key Research and Development Plan of China [2022YFB3103100,
   2020YFB1005600]; Guangdong Basic and Applied Basic Research Foundation
   [2019B1515120010]; National Natural Science Foundation of China
   [62122032, 62172233, 62102189, U1936118, 61932011, 61931004, 61825203,
   U1736203, 61732021]; Major Program of Guangdong Basic and Applied
   Research Project [2019B030302008]; Six Peak Talent project of Jiangsu
   Province [R2016L13]; Qinglan Project of Jiangsu Province; "333" project
   of Jiangsu Province; National Joint Engineering Research Center for
   Network Security Detection and Protection Technology; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD)
   fund; Collaborative Innovation Center of Atmospheric Environment and
   Equipment Technology (CICAEET) fund, China; Ministry of Education of
   Korea
FX This work is supported in part by the National Key Research and
   Development Plan of China under Grant number 2022YFB3103100,
   2020YFB1005600, in part by Guangdong Basic and Applied Basic Research
   Foundation under Grant number 2019B1515120010, in part by the National
   Natural Science Foundation of China under grant numbers 62122032,
   62172233, 62102189, U1936118, 61932011, 61931004, 61825203, U1736203,
   and 61732021, in part by the Major Program of Guangdong Basic and
   Applied Research Project under Grant 2019B030302008, in part by Six Peak
   Talent project of Jiangsu Province (R2016L13), Qinglan Project of
   Jiangsu Province, and "333" project of Jiangsu Province, in part by the
   National Joint Engineering Research Center for Network Security
   Detection and Protection Technology, in part by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD)
   fund, in part by the Collaborative Innovation Center of Atmospheric
   Environment and Equipment Technology (CICAEET) fund, China. Zhihua Xia
   is supported by BK21+ program from the Ministry of Education of Korea.
CR Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Al-Haj A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), P441, DOI 10.1109/INFOMAN.2017.7950424
   Amano T., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P91, DOI 10.1109/ICDAR.1999.791732
   [Anonymous], 2021, IEEE IET ELECT LIB
   [Anonymous], 2021, CHINA NATL KNOWLEDGE
   Barouqa H, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2021), P102, DOI 10.1109/ICIM52229.2021.9417146
   BRASSIL J, 1994, IEEE INFOCOM SER, P1278, DOI 10.1109/INFCOM.1994.337544
   Brassil JT, 1999, P IEEE, V87, P1181, DOI 10.1109/5.771071
   Chetan KR, 2015, J INF SECUR APPL, V24-25, P13, DOI 10.1016/j.jisa.2015.07.002
   Cox IJ., 2007, DIGITAL WATERMARKING
   Loc CV, 2018, INT C PATT RECOG, P1091, DOI 10.1109/ICPR.2018.8546035
   Fang H, 2020, IEEE T CIRC SYST VID, V30, P4075, DOI 10.1109/TCSVT.2019.2953720
   Guan ZY, 2023, IEEE T PATTERN ANAL, V45, P372, DOI 10.1109/TPAMI.2022.3141725
   Huang D, 2001, IEEE T CIRC SYST VID, V11, P1237, DOI 10.1109/76.974678
   Jing JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4713, DOI 10.1109/ICCV48922.2021.00469
   Kamaruddin NS, 2018, IEEE ACCESS, V6, P8011, DOI 10.1109/ACCESS.2018.2796585
   Kim YW, 2004, PATTERN RECOGN LETT, V25, P1243, DOI 10.1016/j.patrec.2004.04.002
   Kim YW, 2003, PROC INT CONF DOC, P775
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2016, IEEE INT SEMICONDUCT
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Lu HP, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P300
   Luo XY, 2021, IEEE DATA COMPR CONF, P354, DOI 10.1109/DCC50243.2021.00049
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Dang QB, 2019, PROC INT CONF DOC, P1, DOI 10.1109/ICDARW.2019.70133
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shin Richard, 2017, NIPS 2017 WORKSH MAC, V1
   Sun X, 2012, RADIOENGINEERING, V21
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiyang Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13545, DOI 10.1109/CVPR42600.2020.01356
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhong X, 2021, IEEE T MULTIMEDIA, V23, P1951, DOI 10.1109/TMM.2020.3006415
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 35
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38589
EP 38612
DI 10.1007/s11042-023-15048-y
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000955293100009
DA 2024-07-18
ER

PT J
AU Li, SG
   Dou, Q
   Yu, ZX
AF Li, Shugang
   Dou, Qian
   Yu, Zhaoxu
TI The influence mechanism of quasi-site creativity stimulation on
   consumers' impulse buying in e-commerce live streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Divergence; Social presence; Need for cognition; Impulse buying;
   E-commerce live streaming
ID SOCIAL NETWORKING SITES; CONTINUANCE INTENTION; PURCHASE INTENTION;
   USERS CONTINUANCE; PERCEIVED VALUE; NEED; BEHAVIOR; DETERMINANTS;
   COGNITION; QUALITY
AB The creativity of live streaming video can affect consumers' value perception and emotion, thus stimulating their impulse buying. However, few studies consider the impact of video creativity combined with social presence on live streaming effect, and the difference in personal characteristics of consumers is also ignored. Therefore, based on the stimulus-organism-response (SOR) theory, this study constructs an influence mechanism model of live streaming consumers' impulse buying under the stimulation of quasi-site creativity. In the proposed model, quasi-site creativity stimulation is composed of divergence and social presence, which can trigger consumers' continuous viewing intention and impulse buying intention by arousing consumers' sense of gain, i.e., perceived value and positive affect. At the same time, we also consider the moderating effect of personal characteristic, need for cognition (NFC), on the relationship between quasi-site creativity stimulation and sense of gain. Structural equation modeling was employed to analysis the research model of this study. The results show that divergence and social presence are the key stimulus factors of consumers' continuous viewing intention and impulse buying intention, which can both arouse consumers' intermediate reaction of perceived value and positive affect. Furthermore, consumer's NFC plays a negative moderating role in the relationship between divergence or social presence and perceived value. Based on the findings of this study, it is suggested that live streaming managers improve the design of live streaming programs and provide strong quasi-site creativity stimulation to increase the viewing and transaction volume of live streaming, and design various quasi-site creativity live streaming programs for consumers with different NFC levels, so as to develop a broader potential market.
C1 [Li, Shugang; Dou, Qian] Shanghai Univ, Sch Management, Shanghai, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Dou, Q (corresponding author), Shanghai Univ, Sch Management, Shanghai, Peoples R China.
EM westside_li@163.com; futupzj@163.com; yyzx@ecust.edu.cn
OI Yu, Zhaoxu/0000-0002-2375-0213
FU National Natural Science Foundation of China [71871135, 72271155]
FX FundingThis work was supported by the National Natural Science
   Foundation of China [Grant number 71871135, 72271155].
CR Anantharaman R, 2023, J STRATEG MARK, V31, P1199, DOI 10.1080/0965254X.2022.2070526
   [Anonymous], 2004, MARKETING THEOR, DOI DOI 10.1177/1470593104044086
   Bagozzi R.P., 1992, HUM RELAT, V45, P660
   BAGOZZI RP, 1991, ADMIN SCI QUART, V36, P421, DOI 10.2307/2393203
   Beatty SE, 1998, J RETAILING, V74, P169, DOI 10.1016/S0022-4359(99)80092-X
   CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116
   CACIOPPO JT, 1984, J PERS ASSESS, V48, P306, DOI 10.1207/s15327752jpa4803_13
   Cacioppo JT, 1996, PSYCHOL BULL, V119, P197, DOI 10.1037/0033-2909.119.2.197
   Chan TKH, 2017, INFORM MANAGE-AMSTER, V54, P204, DOI 10.1016/j.im.2016.06.001
   Chen JM, 2016, J ACAD MARKET SCI, V44, P334, DOI 10.1007/s11747-014-0414-5
   Chen S. C., 2003, Information Technology & Management, V4, P303, DOI 10.1023/A:1022962631249
   China Internet Network Information Center, 2021, 47 CHIN STAT REP INT
   CLOPTON S.W., 2001, J CONSUMER BEHAV, V1, P124, DOI [10.1002/cb.60, DOI 10.1002/CB.60]
   Cohen J., 1988, STAT POWER ANAL BEHA
   Dahlén M, 2008, J ADVERTISING RES, V48, P392, DOI 10.2501/S002184990808046X
   Dong Y, 2015, J APPL PSYCHOL, V100, P1364, DOI 10.1037/a0038969
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gao P, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.870635
   Gefen D, 2004, OMEGA-INT J MANAGE S, V32, P407, DOI 10.1016/j.omega.2004.01.006
   Gefen D, 2000, Communications of the Association for Information Systems, V4, P7, DOI [10.1016/j.emj.2021.07.010, DOI 10.1016/J.EMJ.2021.07.010, DOI 10.17705/1CAIS.00407]
   George JM, 1996, J APPL PSYCHOL, V81, P318, DOI 10.1037/0021-9010.81.3.318
   HOLBROOK MB, 1982, J CONSUM RES, V9, P132, DOI 10.1086/208906
   Hsu MH, 2015, INT J INFORM MANAGE, V35, P45, DOI 10.1016/j.ijinfomgt.2014.09.002
   Hu M, 2017, COMPUT HUM BEHAV, V75, P594, DOI 10.1016/j.chb.2017.06.006
   iiMedia R., 2021, ANN RES REP CHIN ONL
   Kang YS, 2009, COMPUT HUM BEHAV, V25, P111, DOI 10.1016/j.chb.2008.07.009
   Kardes FR, 2004, J CONSUM RES, V31, P368, DOI 10.1086/422115
   Kaynar O, 2008, COMPUT HUM BEHAV, V24, P361, DOI 10.1016/j.chb.2007.01.033
   KEAVENEY SM, 1995, J MARKETING, V59, P71, DOI 10.2307/1252074
   Lee CH, 2021, INFORMATION, V12, DOI 10.3390/info12060241
   Lee YY, 2022, HUM BEHAV EMERG TECH, V2022, DOI 10.1155/2022/2767735
   Lele Kang, 2014, HCI in Business. First International Conference, HCIB 2014. Held as Part of HCI International 2014. Proceedings: LNCS 8527, P504, DOI 10.1007/978-3-319-07293-7_49
   Li H, 2011, DECIS SUPPORT SYST, V51, P434, DOI 10.1016/j.dss.2011.01.017
   Li MW, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19074378
   Lin H, 2014, INFORM MANAGE-AMSTER, V51, P595, DOI 10.1016/j.im.2014.03.010
   Lu BJ, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103509
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   Ou CX, 2014, MIS QUART, V38, P209, DOI 10.25300/MISQ/2014/38.1.10
   Parboteeah DV, 2009, INFORM SYST RES, V20, P60, DOI 10.1287/isre.1070.0157
   Podsakoff PM, 2003, J APPL PSYCHOL, V88, P879, DOI 10.1037/0021-9010.88.5.879
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Qian TYZ, 2022, SPORT MANAG REV, V25, P59, DOI 10.1080/14413523.2021.1930700
   Rauwers F, 2018, INT J ADVERT, V37, P749, DOI 10.1080/02650487.2018.1480167
   Richard MO, 2016, J BUS RES, V69, P541, DOI 10.1016/j.jbusres.2015.05.010
   Rosengren S., 2015, J MARK COMMUN, V21, P20, DOI DOI 10.1080/13527266.2014.970825
   Sarilgan AE, 2021, EUR J TOUR RES, V30, P3014
   Serrano-Malebrán J, 2021, MULTIMED TOOLS APPL, V80, P36509, DOI 10.1007/s11042-021-11303-2
   Sheinin DA, 2011, J ADVERTISING, V40, P5, DOI 10.2753/JOA0091-3367400301
   Shen KN, 2012, INTERNET RES, V22, P396, DOI 10.1108/10662241211250962
   Singh S, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114241
   Smith RE, 2007, MARKET SCI, V26, P819, DOI 10.1287/mksc.1070.0272
   STERN H, 1962, J MARKETING, V26, P59, DOI 10.2307/1248439
   Strobel A, 2017, PERS INDIV DIFFER, V117, P42, DOI 10.1016/j.paid.2017.05.023
   Su QL, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12093783
   Sun Y, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100886
   Sweeney JC, 2001, J RETAILING, V77, P203, DOI 10.1016/S0022-4359(01)00041-0
   Taobangdan TL, 2021, STREAM 2021 TAOB LIV
   Till BD, 2005, J ADVERTISING, V34, P47, DOI 10.1080/00913367.2005.10639201
   Verhagen T, 2011, INFORM MANAGE-AMSTER, V48, P320, DOI 10.1016/j.im.2011.08.001
   Wang HQ, 2022, INT J MOB COMMUN, V20, P462, DOI 10.1504/IJMC.2022.123819
   WEINBERG P, 1982, J BUS RES, V10, P43, DOI 10.1016/0148-2963(82)90016-9
   Woodruff RB, 1997, J ACAD MARKET SCI, V25, P139, DOI 10.1007/BF02894350
   Wu IL, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2020.102099
   Xiang L, 2016, INT J INFORM MANAGE, V36, P333, DOI 10.1016/j.ijinfomgt.2015.11.002
   Yang XJ, 2009, MARKET SCI, V28, P935, DOI 10.1287/mksc.1080.0460
   Yin FS, 2015, TECHNOL FORECAST SOC, V99, P267, DOI 10.1016/j.techfore.2015.07.019
   ZEITHAML VA, 1988, J MARKETING, V52, P2, DOI 10.2307/1251446
   Zhang HP, 2012, ELECTRON MARK, V22, P143, DOI 10.1007/s12525-012-0097-z
   Zhang ML, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107052
   Zhao XS, 2010, J CONSUM RES, V37, P197, DOI 10.1086/651257
   Zheng XB, 2019, INT J INFORM MANAGE, V48, P151, DOI 10.1016/j.ijinfomgt.2019.02.010
   Zheng YM, 2013, DECIS SUPPORT SYST, V56, P513, DOI 10.1016/j.dss.2012.11.008
NR 73
TC 2
Z9 2
U1 27
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 22
PY 2023
DI 10.1007/s11042-023-15101-w
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XB0
UT WOS:000954481800006
DA 2024-07-18
ER

PT J
AU Chavan, S
   Choubey, N
AF Chavan, Sachin
   Choubey, Nitin
TI An automated diabetic retinopathy of severity grade classification using
   transfer learning and fine-tuning for fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy (DR); Retinal fundus images; Classification;
   Segmentation; Transfer learning (TL); Fine tuning (FT)
ID ARCHITECTURE
AB Diabetes mellitus Retinopathy (DR) has recently become a major health problem, and its complications are also increasing worldwide. Early diagnosis of DR is essential to determine the significance of several features from fundus images for detection and classification in many Computer-Aided Diagnosis (CAD) applications. However, existing methods suffer from high dimensional features, small training datasets, misclassification, and high training loss, which leads to a complex grading system. Aiming at these concerns, this paper presents a Frame-wise Severity Scale Classification Model (FSSCM) using Transfer Learning enabled EfficientNet B3 and Fine Tuning enabled ResNet 101, namely, TL-EN3 and FT-RN 101, to classify the severity of disease level of retinal fundus images. Initially, the preprocessing and augmentation processes are performed to bring out the clear view features of the raw fundus images. Then the segmentation phase constrains the whole region using the Chan-Vese algorithm. Twelve features are extracted and fed into the learning network for training purposes. The proposed work utilizes the TL-EN3 model to capture high-resolution patterns with high accuracy and integrates FT-RN 101 models to maintain a balance between efficiency and accuracy with fewer parameters. Experimental analysis is conducted with different metrics such as kappa coefficient (K-score), classification accuracy (CA), precision (P), recall (R), F1-measure (F1), and False Positive Rate (FPR) on three publically available datasets such as Kaggle, Messidor-1, and Messidor-2 datasets. Furthermore, some performance graphs are plotted for visualizing the architecture performance, including training loss, validation loss, training accuracy, and validation accuracy. The performance of the proposed FSSCM approach obtains high estimation values of 0.981 0.985 0.983, 0.98 0.986 0.984, and 0.98 0.985 0.98 in terms of P, R, and F1 on three datasets, respectively. Also, it achieves high estimation results of 99.02 0.993, 98.1 0.97, and 98.3 0.98 in terms of CA and K-score for three datasets, respectively. With a high training accuracy and a low level of training loss, the proposed method gets better severity level classification results than other models.
C1 [Chavan, Sachin; Choubey, Nitin] Mukesh Patel Sch Technol Management & Engn, SVKMS NMIMS, Shirpur, Maharashtra, India.
C3 SVKM's NMIMS (Deemed to be University)
RP Chavan, S (corresponding author), Mukesh Patel Sch Technol Management & Engn, SVKMS NMIMS, Shirpur, Maharashtra, India.
EM phd.sachinchavan@gmail.com
RI Choubey, Nitin/AAI-2112-2020
OI Choubey, Nitin/0000-0002-7117-0555
CR adcis, MESSIDOR DATASET
   adcis, MESSIDOR 2 DATASET
   Alzami Farrikh, 2019, 2019 International Seminar on Application for Technology of Information and Communication (iSemantic). Proceedings, P272, DOI 10.1109/ISEMANTIC.2019.8884217
   Bhatkar AP, 2015, 2015 IEEE International Symposium on Nanoelectronic and Information Systems, P331, DOI 10.1109/iNIS.2015.30
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Cho NH, 2018, DIABETES RES CLIN PR, V138, P271, DOI 10.1016/j.diabres.2018.02.023
   Costa P, 2018, IEEE ACCESS, V6, P18747, DOI 10.1109/ACCESS.2018.2816003
   Cui XD, 2018, Arxiv, DOI arXiv:1810.06773
   Daniel K, 2018, KAGGLE DATASET
   Das S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102600
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   Gayathri S, 2021, PHYS ENG SCI MED, V44, P639, DOI 10.1007/s13246-021-01012-3
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Gayathri S, 2020, PHYS ENG SCI MED, V43, P927, DOI 10.1007/s13246-020-00890-3
   Gayathri S, 2020, IEEE ACCESS, V8, P57497, DOI 10.1109/ACCESS.2020.2979753
   Gupta Ankita, 2018, Procedia Computer Science, V132, P1432, DOI 10.1016/j.procs.2018.05.074
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hussain M., 2018, ADV INTELL SYST
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Islam M., 2017, J Biomed Sci Eng, V10, P86, DOI DOI 10.4236/JBISE.2017.105B010
   Islam MM, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105320
   Jebaseeli TJ, 2019, OPTIK, V199, DOI 10.1016/j.ijleo.2019.163328
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062021
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam Carson, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P147
   Li F, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.4
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Memari N, 2019, J MED BIOL ENG, V39, P713, DOI 10.1007/s40846-018-0454-2
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Nair M., 2019, INT J ENG ADV TECHNO, V8, P51
   Narasimhan K., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P964, DOI 10.1109/ICCEET.2012.6203804
   Qiao LF, 2020, IEEE ACCESS, V8, P104292, DOI 10.1109/ACCESS.2020.2993937
   Qomariah DUN, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P152, DOI [10.1109/ICTS.2019.8850940, 10.1109/icts.2019.8850940]
   Rahman Ziaur, 2019, International Journal of Computers and Applications, V41, P207, DOI 10.1080/1206212X.2017.1422358
   Riaz H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010024
   Roychowdhury A, 2018, LECT NOTES ELECTR EN, V475, P168, DOI 10.1007/978-981-10-8240-5_19
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Seewoodhary Mahesh, 2021, Nurs Stand, V36, P71, DOI 10.7748/ns.2021.e11696
   Selvathi D, AUTOMATED DETECTION
   Shankar K, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2568-8
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Targ S., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.08029
   Vijayan T., 2020, Microprocess. Microsyst, P103353, DOI [10.3390/s22145103, DOI 10.1016/J.MICPRO.2020.103353, 10.1016/j.micpro.2020.103353]
   Wu Z, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101936
   Zaaboub N., 2020, 2020 5 INT C ADV TEC, P1
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zimmet P, 2016, NAT REV ENDOCRINOL, V12, P616, DOI 10.1038/nrendo.2016.105
NR 51
TC 6
Z9 6
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-15135-0
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900006
DA 2024-07-18
ER

PT J
AU Hematkhah, H
   Kavian, Y
   Namjoo, E
AF Hematkhah, Hooman
   Kavian, Yousef
   Namjoo, Ehsan
TI PoCH: automatic HDL code generator tool for Polar channel coding
   decoders in multimedia communication systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic code generator; Polar coding; VHDL; Tools; Hardware
   implementation; Python; Multimedia communication systems
AB Polar codes are a class of block codes which are widely used in communication networks. Polar codes have been utilized in the fifth generation of enhanced mobile broadband systems (5G) due to their performance in error correction and also their low instinct complexity in implementation. However when they come in very large blocks, their efficient implementation in reasonable time is challenging. The automatic code generator (ACG) tools are useful and essential in these cases, when the design process should be error prone and time consuming. This paper presents an error prone and fast ACG tool to generate the VHDL description code at gate level for Polar decoders in multimedia communication systems according to user adjusted parameters including code-length, code-rate and quantization width, called PoCH tool. The PoCH constructs the Polar decoder using the design SNR and Bhattacharyya parameters which are set by the user, or are provided by a file consisting of the frozen bits location. The PoCH can generate the Polar decoder for four famous algorithms including SC, SSC, Fast-SSC and Fast-SSC + BiREP algorithms. To validate the performance of the PoCH tool, the block counts is presented for each generated code for various code-length, code-rate and Bhattacharyya parameters. Finally, the time consumed by the tool to generate Polar channel decoders for each algorithm is compared.
C1 [Hematkhah, Hooman; Kavian, Yousef; Namjoo, Ehsan] Shahid Chamran Univ Ahvaz, Fac Engn, Ahvaz, Iran.
C3 Shahid Chamran University of Ahvaz
RP Kavian, Y (corresponding author), Shahid Chamran Univ Ahvaz, Fac Engn, Ahvaz, Iran.
EM y.s.kavian@scu.ac.ir
OI Hematkhah, Hooman/0000-0001-9294-9931
FU Shahid Chamran University of Ahvaz [SCU.EE99.256]
FX AcknowledgementsThis work was supported by Shahid Chamran University of
   Ahvaz under Grant Number SCU.EE99.256.
CR [Anonymous], 2017, Cisco Visual Networking Index: Forecast and Trends
   Arikan E., 2011, IEEE COMMUN LETT, V15, P860, DOI [10.1109/LCOMM.2011.061611.110862, DOI 10.1109/LCOMM.2011.061611.110862]
   Arikan E, 2009, IEEE T INFORM THEORY, V55, P3051, DOI 10.1109/TIT.2009.2021379
   Balakrishna S, 2020, INT J INTERACT MULTI, V6, P56, DOI 10.9781/ijimai.2020.03.001
   Balatsoukas Stimming A K, 2016, THESIS EPFL
   Bioglio V, 2021, IEEE COMMUN SURV TUT, V23, P29, DOI 10.1109/COMST.2020.2967127
   Chandramouleeshwaran S, 2023, INT PSYCHOGERIATR, DOI 10.1017/S1041610223000844
   Chen K, 2013, IEEE T COMMUN, V61, P3100, DOI 10.1109/TCOMM.2013.070213.120789
   Condo C, 2020, IEEE T SIGNAL PROCES, V68, P2004, DOI 10.1109/TSP.2020.2981766
   Doan N, 2022, IEEE ACCESS, V10, P5568, DOI 10.1109/ACCESS.2021.3140151
   Egilmez ZBK, 2020, IEEE COMMUN SURV TUT, V22, P96, DOI 10.1109/COMST.2019.2960746
   Feng BW, 2020, SCI CHINA TECHNOL SC, V63, P1371, DOI 10.1007/s11431-020-1630-2
   Giard P., 2016, Ph.D.dissertation
   Giard P, 2018, IEEE WIREL COMMUNN, P73, DOI 10.1109/WCNCW.2018.8369026
   Giard P, 2018, J SIGNAL PROCESS SYS, V90, P675, DOI 10.1007/s11265-016-1173-y
   Gupta A, 2021, INT J INTERACT MULTI, V6, P156, DOI 10.9781/ijimai.2021.03.004
   Hamdan M.K., 2017, 2017 International Conference on ReConFigurable Computing and FPGAs (ReConFig), P1
   Hashemi SA, 2019, IEEE T SIGNAL PROCES, V67, P5689, DOI 10.1109/TSP.2019.2944738
   Iscan O, 2019, IEEE ACCESS, V7, P22579, DOI 10.1109/ACCESS.2019.2898103
   Jing Zeng, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P580, DOI 10.1109/ISVLSI.2019.00109
   Kirchner Aljoscha, 2018, 2018 Forum on Specification & Design Languages (FDL), P5, DOI 10.1109/FDL.2018.8524051
   Kumar S, 2020, INT J INTERACT MULTI, V6, P107, DOI 10.9781/ijimai.2020.01.003
   Leroux C, 2013, IEEE T SIGNAL PROCES, V61, P289, DOI 10.1109/TSP.2012.2223693
   Li SB, 2018, IEEE COMMUN LETT, V22, P2439, DOI 10.1109/LCOMM.2018.2875437
   Li ZS, 2020, IEEE ACCESS, V8, P3772, DOI 10.1109/ACCESS.2019.2958482
   Lin J, 2016, IEEE T VLSI SYST, V24, P2378, DOI 10.1109/TVLSI.2015.2499777
   Mahmood OF., 2021, INT RES J MODERNIZAT, V3, P55
   McEliece R, 2003, THEORY INFORM CODING
   Möller K, 2017, IEEE T COMPUT AID D, V36, P927, DOI 10.1109/TCAD.2016.2614775
   Oliveira RM, 2021, IEEE ACCESS, V9, P41902, DOI 10.1109/ACCESS.2021.3065816
   Özkan MA, 2020, IEEE T COMPUT AID D, V39, P3202, DOI 10.1109/TCAD.2020.3012172
   Pinto-Santos F, 2021, ACTA ASTRONAUT, V1472
   Polyanskiy Y., 2010, Channel coding: non-asymptotic fundamental limits
   Säily M, 2020, IEEE T BROADCAST, V66, P404, DOI 10.1109/TBC.2020.2985906
   Sasoglu E, 2014, IEEE INT SYMP INFO, P1456, DOI 10.1109/ISIT.2014.6875074
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shariat M, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/5264012
   Su Z, 2022, IEEE T COMPUT AID D, V41, P49, DOI 10.1109/TCAD.2021.3055487
   Szczesny S, 2018, IEEE T COMPUT AID D, V37, P915, DOI 10.1109/TCAD.2017.2740295
   Takamaeda-Yamazaki S., 2015, INT S APPL REC COMP
   Trost A, 2019, 2019 8 MEDITERRANEAN, P1
   Xu Y, 2021, ICMLCA 2021 2 INT C, P1
   Zhang X, 2018, IEEE J SEL AREA COMM, V36, P2787, DOI 10.1109/JSAC.2018.2871327
NR 43
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 20
PY 2023
DI 10.1007/s11042-023-14507-w
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PJ6
UT WOS:000984224700007
DA 2024-07-18
ER

PT J
AU Tariq, J
   Javed, M
   Ayub, B
   Armghan, A
   Ijaz, A
   Alenezi, F
   Rahman, H
   Zulfiqar, A
AF Tariq, Junaid
   Javed, Mubashar
   Ayub, Bushra
   Armghan, Ammar
   Ijaz, Amir
   Alenezi, Fayadh
   Rahman, Hameedur
   Zulfiqar, Adil
TI Nature inspired algorithm based fast intra mode decision in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bat algorithm; Firefly algorithm; Intra mode; Fast algorithm
ID PREDICTION
AB To efficiently handle the complex region, the intra modes are increased from 9 to 35 in High Efficiency Video Coding (HEVC). As a result, the encoding time is increased and makes HEVC unfit for real time applications. This article applies the firefly algorithm (FFA) in HEVC to perform fast intra mode selection. Firstly, the intra modes of HEVC are mapped to the fireflies in FFA. Secondly, a novel, fast, and efficient objective function is formulated to efficiently handle the current problem of HEVC. Results show that 32.48% of the encoding time of HEVC is reduced. Moreover, it saved 20% more time than the existing work that applied FFA for intra mode decision.
C1 [Tariq, Junaid] Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
   [Javed, Mubashar] Natl Univ Modern Languages, Dept Math, Rawalpindi, Pakistan.
   [Ayub, Bushra; Ijaz, Amir] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
   [Armghan, Ammar; Alenezi, Fayadh] Jouf Univ, Coll Engn, Dept Elect Engn, Sakaka, Saudi Arabia.
   [Rahman, Hameedur] Air Univ, Dept Creat Technol, Islamabad, Pakistan.
   [Zulfiqar, Adil] Natl Univ Comp & Emerging Sci, Dept Elect Engn, Chiniot Faisalabad Campus, Faisalabad, Pakistan.
C3 NITEC University; Al Jouf University; Air University Islamabad
RP Tariq, J (corresponding author), Natl Univ Modern Languages, Dept Comp Sci, Rawalpindi, Pakistan.
EM jtariq2-c@my.cityu.edu.hk; mubashar.javed@numl.edu.pk;
   bushra.ayub6@gmail.com; aarmghan@ju.edu.sa; amir.ijaz@hitecuni.edu.pk;
   fshenezi@ju.edu.sa; rhameedur@mail.au.edu.pk; adil.zulfiqar@nu.edu.pk
RI Rahman, Hameedur/AAK-6179-2021; Armghan, Ammar/ABA-9560-2021; Rahman,
   Hameedur/HSE-8425-2023; Rahman, Hameedur/GPW-6712-2022
OI Rahman, Hameedur/0000-0001-8892-9911; Armghan,
   Ammar/0000-0002-9062-7493; 
CR Armghan A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151839
   Arora S, 2013, CONTROL COMPUTING CO, P2013
   Bjotegaard G., 2001, VCEGM33
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Chao CF, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/343217
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Khan HUR, 2019, ARAB J SCI ENG, V44, P2151, DOI 10.1007/s13369-018-3367-z
   Kumar B.S. Sunil., 2016, ALEX ENG J
   Sullivan JG, HIGH EFFICIENCY VIDE
   TARIQ J, 2019, MULTIMED TOOLS APPL, V78, P1, DOI DOI 10.1007/S11042-018-6670-5
   Tariq J, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103594
   Tariq J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10090985
   Tariq J, 2021, MULTIMED TOOLS APPL, V80, P21449, DOI 10.1007/s11042-021-10677-7
   Tariq J, 2020, MULTIMED TOOLS APPL, V79, P20299, DOI 10.1007/s11042-020-08915-5
   Tariq J, 2021, CIRC SYST SIGNAL PR, V40, P418, DOI 10.1007/s00034-020-01482-y
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Yang, 2008, NATURE INSPIRED META, P242
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang J, 2020, P 2020 IEEE 4 INFORM, V1, P2020
   Yang X-S, 2023, FIREFLY ALGORITHM FF
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
NR 26
TC 4
Z9 4
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29789
EP 29804
DI 10.1007/s11042-023-14999-6
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950429600007
DA 2024-07-18
ER

PT J
AU Dharminder, D
   Dadsena, PK
   Mishra, D
AF Dharminder, Dharminder
   Dadsena, Pradeep Kumar
   Mishra, Dheerendra
TI Construction of system friendly attribute based fully distributed access
   control architecture for e-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical data storage; Bilinear pairing; Access control matrix; Data
   security; Data privacy; Attribute based access control; e-healthcare
ID ENCRYPTION; SECURE
AB The adoption of telemedicine has improved health care quality and its reachability to remote patients. There are substantial contributions towards the implementation of secure communication of medical records such as digital images, documents, videos, etc. However, less attention is paid to efficiency, privacy-preserving communication, and access control. Moreover, existing constructions have either failed to support distributed revocation or the symmetric encryption approach, which requires ensuring encryption of arbitrary length messages. As scalability and flexibility in the delegation of keys and revocation of mobile users are very fundamental issues in attribute-based access control and its application to e-healthcare, we propose a new cryptographic concept called attribute-based fully distributed access control architecture that supports fine-grained access control, data protection, data validity, and efficient data search in the context of an electronic personal health record system. The proposed design supports the symmetric key approach to encrypt/decrypt the data. The proposed design is secure and efficient, and it also provides a fully distributed access control on the stored data at a central authority with a revocation facility. It provides access to the user, doctor, and health department according to the set of attributes/ credentials shown by them. It benefits in key delegation and revocation of the user, which will help to improve the robustness of e-healthcare systems.
C1 [Dharminder, Dharminder] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci & Engn, Chennai 601103, India.
   [Dadsena, Pradeep Kumar] Govt Engn Coll, Dept Math, Jagdalpur 494001, India.
   [Mishra, Dheerendra] Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal 462003, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Chennai; National
   Institute of Technology (NIT System); Maulana Azad National Institute of
   Technology Bhopal
RP Mishra, D (corresponding author), Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal 462003, India.
EM dheerendra.m@gmail.com
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397
CR Al-Zubaidie M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16091490
   Ali M, 2020, THEOR COMPUT SCI, V815, P25, DOI 10.1016/j.tcs.2020.02.030
   Anjum A, 2018, COMPUT SECUR, V72, P196, DOI 10.1016/j.cose.2017.09.014
   Bello SA, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103441
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Bhatt S, 2021, IEEE ACCESS, V9, P107200, DOI 10.1109/ACCESS.2021.3101218
   Bobba R, 2009, LECT NOTES COMPUT SC, V5789, P587, DOI 10.1007/978-3-642-04444-1_36
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Deng H, 2014, INFORM SCIENCES, V275, P370, DOI 10.1016/j.ins.2014.01.035
   Gajanayake R., 2014, ELECT J HLTH INFORM, V8, pe151
   Gao S, 2020, IEEE T VEH TECHNOL, V69, P5784, DOI 10.1109/TVT.2020.2967099
   Gentry C, 2002, LECT NOTES COMPUT SC, V2501, P548, DOI 10.1007/3-540-36178-2_34
   Goyal V., 2006, P 13 ACM C COMP COMM, P89, DOI DOI 10.1145/1180405.1180418
   Hu V.C., 2013, NIST special publication, V800, P1
   Hu V C, 2006, 7316 NAT I STAND TEC, P20899
   Huang QL, 2017, FUTURE GENER COMP SY, V72, P239, DOI 10.1016/j.future.2016.09.021
   Jung TH, 2013, IEEE INFOCOM SER, P2625
   Khan S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010336
   Lewko A, 2010, LECT NOTES COMPUT SC, V6110, P62, DOI 10.1007/978-3-642-13190-5_4
   Li J, 2011, MOBILE NETW APPL, V16, P553, DOI 10.1007/s11036-010-0233-y
   Li Q, 2016, COMPUT SECUR, V59, P45, DOI 10.1016/j.cose.2016.02.002
   Liu Q, 2014, INFORM SCIENCES, V258, P355, DOI 10.1016/j.ins.2012.09.034
   Rana S, 2021, MULTIMED TOOLS APPL, V80, P25255, DOI 10.1007/s11042-021-10813-3
   Rana S, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01564-z
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sangeetha D, 2022, MULTIMED TOOLS APPL, V81, P22065, DOI 10.1007/s11042-021-10817-z
   ShuLan Wang, 2015, Applied Mechanics and Materials, V701-702, P911, DOI 10.4028/www.scientific.net/AMM.701-702.911
   Singh AK, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3422816
   Tian Youliang, 2019, Journal of Communications, V40, P101
   Wan ZG, 2012, IEEE T INF FOREN SEC, V7, P743, DOI 10.1109/TIFS.2011.2172209
   Wang GJ, 2011, COMPUT SECUR, V30, P320, DOI 10.1016/j.cose.2011.05.006
   Wang SL, 2016, IEEE T INF FOREN SEC, V11, P1265, DOI 10.1109/TIFS.2016.2523941
   Waters B, 2005, LECT NOTES COMPUT SC, V3494, P114
   Wu AX, 2019, ANN TELECOMMUN, V74, P401, DOI 10.1007/s12243-018-00699-y
   Ximeng Liu, 2014, International Journal of Network Security, V16, P437
   Zhang YH, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3398036
   Zhang YH, 2018, IEEE INTERNET THINGS, V5, P2130, DOI 10.1109/JIOT.2018.2825289
NR 37
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26937
EP 26953
DI 10.1007/s11042-023-14836-w
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945313000007
DA 2024-07-18
ER

PT J
AU Dwivedi, N
   Singh, DK
   Kushwaha, DS
AF Dwivedi, Neelam
   Singh, Dushyant Kumar
   Kushwaha, Dharmender Singh
TI A novel approach for suspicious activity detection with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Suspicious activity; Video surveillance; Convolutional neural network;
   Inception V3; Long short-term memory
ID REAL-TIME DETECTION; NEURAL-NETWORK; RECOGNITION; BEHAVIOR
AB Suspicious human activities like fighting, shooting, fire have got serious security concern in public places because of a steep surge in these types of cases all around. CCTV cameras are generally installed at public places like malls, railway stations; but evidences suggest that only availability of these cameras are not very effective unless the video feeds are constantly monitored. Therefore, we intend to build an automated and intelligent video surveillance system to detect the suspicious human activities, followed by an alert generation. In this article, we propose a deep neural network-based solution to identify suspicious human activities. Here, the deep Inception V3 model extracts the salient discriminative activity-specific features from video streams. Furthermore, we feed these features into a recurrent neural network, namely Long Short Term Memory (LSTM) network, which is used to develop a temporal relation between features extracted from consecutive frames in order to distinguish suspicious human activities accurately. Added to it, the proposed system is evaluated for diverse data by collecting activities from eleven benchmark databases: KTH action database, WEIZMANN database, JHMDB database, HMDB database, UCF-Crime database, UCF101 database, MIVIA database, UCF database, FIRESENSE database, VISILAB database, and SHAKEFIVE2 database. The proposed approach achieved a recognition rate of 98.87%, showing significant improvement as compared to the state-of-the-art (SOTA) methods.
C1 [Dwivedi, Neelam; Singh, Dushyant Kumar; Kushwaha, Dharmender Singh] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Dwivedi, N (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj, India.
EM neelamdw@gmail.com; dushyant@mnnit.ac.in; dsk@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Ainsworth T., 2002, Security Oz, V19, P18
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 2020, 2 BIKE SNATCH GOLD C
   [Anonymous], 2014, DOES VIDEO SURVEILLA
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Carletti V, 2013, LECT NOTES COMPUT SC, V8158, P436, DOI 10.1007/978-3-642-41190-8_47
   Dimitropoulos K, 2015, IEEE T CIRC SYST VID, V25, P339, DOI 10.1109/TCSVT.2014.2339592
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elhamod M, 2013, IEEE T INTELL TRANSP, V14, P688, DOI 10.1109/TITS.2012.2228640
   Fan YX, 2017, NEUROCOMPUTING, V260, P43, DOI 10.1016/j.neucom.2017.02.082
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Foucher S, 2011, PROC SPIE, V8056, DOI 10.1117/12.884402
   Gholamrezaii M, 2021, MULTIMED TOOLS APPL, V80, P19361, DOI 10.1007/s11042-020-10435-1
   Gouaillier V, 2009, CRIM TECH DEFENCE SE, P456
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kapoor S, 2021, NEWS BUST 0309
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar KPS, 2020, MULTIMED TOOLS APPL, V79, P3543, DOI 10.1007/s11042-018-6034-1
   Kushwaha A, 2021, INT J IMAGE GRAPH
   Ladjailia A, 2020, NEURAL COMPUT APPL, V32, P16387, DOI 10.1007/s00521-018-3951-x
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Mysore P., 2005, AAAI, V5, P1541
   Nogueira TDC, 2020, MULTIMED TOOLS APPL, V79, P30615, DOI 10.1007/s11042-020-09539-5
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   Pu SL, 2017, PROCEDIA COMPUT SCI, V111, P154, DOI 10.1016/j.procs.2017.06.022
   Rashwan HA, 2020, MULTIMED TOOLS APPL, V79, P34141, DOI 10.1007/s11042-020-09194-w
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Serrano I., 2013, MediaEval
   Sharif MH, 2012, PATTERN RECOGN, V45, P2543, DOI 10.1016/j.patcog.2011.11.023
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tam NN, 2017, PROC 8 INT S INF COM, P370
   Tarassenko L, 2000, INT J SYST SCI, V31, P1427, DOI 10.1080/00207720050197802
   Tripathi V, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/502737
   van Gemeren C, 2016, LECT NOTES COMPUT SC, V9997, P116, DOI 10.1007/978-3-319-46843-3_8
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Velastin SA, 2006, TRANSPORT RES C-EMER, V14, P96, DOI 10.1016/j.trc.2006.05.006
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wiliem A, 2012, COMPUT VIS IMAGE UND, V116, P194, DOI 10.1016/j.cviu.2011.10.001
   Yuan XF, 2020, IEEE T IND INFORM, V16, P3168, DOI [10.1109/TII.2019.2902129, 10.1002/er.4607]
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 48
TC 4
Z9 4
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32397
EP 32420
DI 10.1007/s11042-023-14445-7
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943966200004
DA 2024-07-18
ER

PT J
AU Solanki, R
   Kumar, D
AF Solanki, Rinki
   Kumar, Dhirendra
TI Probabilistic intuitionistic fuzzy c-means algorithm with spatial
   constraint for human brain MRI segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intuitionistic fuzzy c-mean algorithm; Clustering; Magnetic resonance
   imaging; Image segmentation; Unsupervised machine learning
ID MEANS CLUSTERING-ALGORITHM; IMAGE SEGMENTATION; NEIGHBORHOOD ATTRACTION;
   LOCAL INFORMATION; NEURAL-NETWORK; MEMBERSHIP; EVOLUTIONARY; FUZZINESS;
   NEGATION
AB Segmentation of brain MRI images becomes a challenging task due to spatially distributed noise and uncertainty present between boundaries of soft tissues. In this work, we have presented intuitionistic fuzzy set theory based probabilistic intuitionistic fuzzy c-means with spatial neighborhood information method for MRI image segmentation. We have investigated two well known negation functions namely, Sugeno's negation function and Yager's negation function for representing the image in terms of intuitionistic fuzzy sets. The proposed approach takes leverage of intuitionistic fuzzy set theory to address vagueness and uncertainty present in the data. The spatial neighborhood information term in the segmentation process is included to dampen the effect of noise. The segmentation performance of the proposed method is evaluated in terms of average segmentation accuracy and Dice score. Further, the comparison of the proposed method with other similar state-of-art methods is carried out on two publicly available brain MRI dataset which shows the significant improvements in segmentation performance in terms of average segmentation accuracy and Dice score. The proposed approach achieves on average 91% average segmentation accuracy in the presence of noise and intensity inhomogeneity on BrainWeb simulated dataset, which outperformed the state-of-art methods.
C1 [Solanki, Rinki] Times Internet, Gurugram, India.
   [Kumar, Dhirendra] Delhi Technol Univ, Dept Appl Math, Delhi 110042, India.
C3 Delhi Technological University
RP Kumar, D (corresponding author), Delhi Technol Univ, Dept Appl Math, Delhi 110042, India.
EM rinkisolanki21@gmail.com; dhirendrakumar@dtu.ac.in
OI Kumar, Dhirendra/0000-0002-8902-5022
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Balafar MA, 2008, 2008 IEEE CONFERENCE ON INNOVATIVE TECHNOLOGIES IN INTELLIGENT SYSTEMS AND INDUSTRIAL APPLICATIONS, P66, DOI 10.1109/CITISIA.2008.4607337
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bezdek J. C., 1978, Fuzzy Sets and Systems, V1, P111, DOI 10.1016/0165-0114(78)90012-X
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   BRANDT ME, 1994, COMPUT MED IMAG GRAP, V18, P25, DOI 10.1016/0895-6111(94)90058-2
   Cabezas M, 2011, COMPUT METH PROG BIO, V104, pE158, DOI 10.1016/j.cmpb.2011.07.015
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Chintalapudi KK, 1998, 1998 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AT THE IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE - PROCEEDINGS, VOL 1-2, P1458, DOI 10.1109/FUZZY.1998.686334
   Cocosco C.A., 1997, NeuroImage
   Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dubey YK, 2016, BIOCYBERN BIOMED ENG, V36, P413, DOI 10.1016/j.bbe.2016.01.001
   Elazab A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/485495
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guo FF, 2016, IET IMAGE PROCESS, V10, P272, DOI 10.1049/iet-ipr.2015.0236
   HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang CW, 2015, SOFT COMPUT, V19, P459, DOI 10.1007/s00500-014-1264-2
   Hylton Nola, 2006, Magn Reson Imaging Clin N Am, V14, P383, DOI 10.1016/j.mric.2006.09.001
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5259, P764, DOI 10.1007/978-3-540-88458-3_69
   Iancu I, 2014, PATTERN RECOGN LETT, V42, P128, DOI 10.1016/j.patrec.2014.02.010
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Ji ZX, 2012, COMPUT METH PROG BIO, V108, P644, DOI 10.1016/j.cmpb.2011.10.010
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar D, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902984
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Liew AWC, 2005, IEEE T FUZZY SYST, V13, P444, DOI 10.1109/TFUZZ.2004.841748
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Lin KP, 2014, IEEE T FUZZY SYST, V22, P1074, DOI 10.1109/TFUZZ.2013.2280141
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lohani QMD, 2018, IEEE T FUZZY SYST, V26, P3715, DOI 10.1109/TFUZZ.2018.2848245
   Ma L, 2007, PATTERN RECOGN, V40, P3005, DOI 10.1016/j.patcog.2007.02.005
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Murofushi T, 2000, STUD FUZZ SOFT COMP, V40, P3
   Pelekis Nikos, 2008, International Journal of Business Intelligence and Data Mining, V3, P45, DOI 10.1504/IJBIDM.2008.017975
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pham DL, 2001, COMPUT VIS IMAGE UND, V84, P285, DOI 10.1006/cviu.2001.0951
   Selvaraj H., 2007, IC-MED, V1, P21, DOI DOI 10.1080/1931308X.2007.10644134
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Singh C, 2019, EXPERT SYST APPL, V118, P625, DOI 10.1016/j.eswa.2018.10.023
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Szmidt E, 2000, FUZZY SET SYST, V114, P505, DOI 10.1016/S0165-0114(98)00244-9
   Tolias YA, 1998, IEEE T SYST MAN CY A, V28, P359, DOI 10.1109/3468.668967
   Varshney Ayush K., 2020, 2020 IEEE INT C FUZZ, P1
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Wang C, 2021, IEEE-CAA J AUTOMATIC, V8, P876, DOI 10.1109/JAS.2020.1003420
   Wang ZY, 2007, IEEE T GEOSCI REMOTE, V45, P3055, DOI 10.1109/TGRS.2007.896283
   Xu ZS, 2010, J SYST ENG ELECTRON, V21, P580, DOI 10.3969/j.issn.1004-4132.2010.04.009
   YAGER RR, 1979, INT J GEN SYST, V5, P221, DOI 10.1080/03081077908547452
   YAGER RR, 1980, INFORM CONTROL, V44, P236, DOI 10.1016/S0019-9958(80)90156-4
   Zhang YX, 2019, IEEE T FUZZY SYST, V27, P185, DOI 10.1109/TFUZZ.2018.2883033
   Zhao F, 2013, DIGIT SIGNAL PROCESS, V23, P184, DOI 10.1016/j.dsp.2012.09.016
   Zhou HY, 2008, IEEE ENG MED BIO, P3091, DOI 10.1109/IEMBS.2008.4649857
   Zhu L, 2009, IEEE T SYST MAN CY B, V39, P578, DOI 10.1109/TSMCB.2008.2004818
NR 62
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33663
EP 33692
DI 10.1007/s11042-023-14512-z
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000016
DA 2024-07-18
ER

PT J
AU Zhang, LN
   Dai, HD
AF Zhang, Lina
   Dai, Haidong
TI Motion trajectory tracking of athletes with improved depth
   information-based KCF tracking method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background segmentation threshold; Depth distribution features;
   Kernerlized correlation filter; Universal background eliminator
AB In this paper, a computer vision-based technique is proposed to track the motion trajectories of athletes to improve sport performance and deliver reliable physical data analysis. The moving target in the video was obtained through the Universal Background Eliminator (ViBe) moving target detection algorithm, and fused with the associated depth information based on the Kernerlized Correlation Filter (KCF) tracking algorithm. In order to better identify partly occluded objects, the depth information of the moving target and background segmentation threshold were acquired based on the depth distribution features within the original video tracking range. Meanwhile, the number of negative samples in the training sample set was reduced to prevent the model shifting problem caused by the background and obstacles. Experiments have been conducted on the dance trajectories of gymnasts as well as the motion trajectories of batting arms of badminton players. The results prove that the proposed algorithm can reduce the trajectory prediction error and improve the operating efficiency.
C1 [Zhang, Lina; Dai, Haidong] Zhejiang Coll Secur Technol, Zhejiang, Peoples R China.
RP Zhang, LN (corresponding author), Zhejiang Coll Secur Technol, Zhejiang, Peoples R China.
EM zhanglinazj@126.com
CR Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Cheng SW, 2023, APPL OPTICS, V62, P933, DOI 10.1364/AO.479307
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   [姜文涛 Jiang Wentao], 2016, [计算机学报, Chinese Journal of Computers], V39, P1334
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li SE, 2018, MECH SYST SIGNAL PR, V98, P173, DOI 10.1016/j.ymssp.2017.04.041
   Li ZH., 2018, COMPUT SIMUL, V42, P69
   [李兆波 Li Zhaobo], 2018, [工程设计学报, Chinese Journal of Engineering Design], V25, P338
   Liu L, 2023, IEEE T CYBERNETICS, V53, P4015, DOI 10.1109/TCYB.2022.3225106
   Lu SY, 2023, CMES-COMP MODEL ENG, V136, P363, DOI 10.32604/cmes.2023.025217
   Martins P, 2012, EUROPEAN C COMPUTER
   Meng QX, 2022, IEEE T NEUR NET LEAR, V33, P3814, DOI 10.1109/TNNLS.2021.3054611
   Meng X, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2020.106699
   Min C, 2023, MECH MACH THEORY, V181, DOI 10.1016/j.mechmachtheory.2022.105185
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Sokhandan A, 2018, COMPUT VIS IMAGE UND
   Talha M, 2014, IEEE SENS J, V14, P159, DOI 10.1109/JSEN.2013.2271561
   Wang FW, 2022, IEEE SENS J, V22, P19046, DOI 10.1109/JSEN.2022.3201015
   Wang S, 2023, IET IMAGE PROCESS, V17, P157, DOI 10.1049/ipr2.12624
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   XU S, 2022, IEEE T INSTRUM MEAS, V1
   Yan LY, 2023, ALEX ENG J, V63, P307, DOI 10.1016/j.aej.2022.08.003
   Yang Pengsheng, 2016, Computer Engineering and Applications, V52, P71, DOI 10.3778/j.issn.1002-8331.1403-0219
   Yu Naigong, 2016, Journal of Beijing University of Technology, V42, P361, DOI 10.11936/bjutxb2015060061
   [余烨 Yu Ye], 2014, [仪器仪表学报, Chinese Journal of Scientific Instrument], V35, P924
   Zhang B, 2014, DIGIT SIGNAL PROCESS, V27, P107, DOI 10.1016/j.dsp.2014.01.007
   Zong CJ, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107685
NR 29
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26481
EP 26493
DI 10.1007/s11042-023-14929-6
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943970200005
DA 2024-07-18
ER

PT J
AU Sarkar, A
AF Sarkar, Arindam
TI Neural coordination through spider monkey optimization-guided weight
   synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spider Monkey Optimization (SMO); Neural synchronization; Hash Function;
   Session Key
AB This paper proposes a Spider Monkey-based neural weight optimization approach for quicker neural synchronization. To exchange the session key across a public channel, two Artificial Neural Networks (ANNs) are synchronized through reciprocating learning. The most crucial feature of ANN coordination is evaluating how effectively sender and receiver's ANNs coordinate without the other's weights. Traditional algorithms have a latency in assessing coordination, which endangers neuronal coordination's confidentiality. This research proposes a collaborative learning technique for analyzing the total synchronization of ANNs efficiently and decisively. The frequency at which the two ANNs got the same outcome in previous iterations determines synchronization. The hash is being used to evaluate if all ANNs are better aligned when a certain threshold is met. The presented technique uses the hash value of the synaptic weights to achieve complete synchronization among two communicating parties. This approach offers a number of benefits, namely (1) the usage of a Spider Monkey-based PRNG optimization to obtain the optimal weight vector. (2) The suggested method, in contrast to earlier methodologies, allows two communicating entities to discover complete collaboration more rapidly. (3) The probability of success is lowered geometrically. (4) The proposed TLTPM coordination periods are significantly quicker than the present CVTPM, VVTPM, and TPM-FPGA approaches. The suggested method improves the security of the neural key exchange protocol. The proposed approach is tested, and the findings reveal that it outperforms similar techniques currently in use.
C1 [Sarkar, Arindam] Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Belur Math, Howrah 711202, West Bengal, India.
RP Sarkar, A (corresponding author), Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Belur Math, Howrah 711202, West Bengal, India.
EM arindam.vb@gmail.com
OI Sarkar, Arindam/0000-0002-4951-4729
CR Abdalrdha Z. K., 2019, INT J SCI RES SCI EN, P230, DOI [10.32628/ijsrset196550, DOI 10.32628/IJSRSET196550]
   [Anonymous], 2006, NEURAL SYNCHRONIZATI
   Chourasia S., 2019, COMPUSOFT, V8, P3140, DOI DOI 10.1155/2021/6680782
   Dolecki M, 2015, LECT NOTES COMPUT SC, V9339, P451, DOI 10.1007/978-3-319-24369-6_37
   Dong T, 2020, IEEE T NEUR NET LEAR, V31, P4999, DOI 10.1109/TNNLS.2019.2955165
   Gao J, 2021, IEEE T IND INFORM, V17, P971, DOI 10.1109/TII.2019.2947432
   Hadke P.P., 2016, FUTUR TRENDS RES INN, P1, DOI DOI 10.1109/STARTUP.2016.7583925
   Jeong S, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6680782
   Jo M., 2020, IEEE T IND INF, DOI [10.1109/TII.2020.3011849, DOI 10.1109/TII.2020.3011849]
   Kanter I, 2002, EUROPHYS LETT, V57, P141, DOI 10.1209/epl/i2002-00552-9
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Liu P, 2019, IEEE T NEUR NET LEAR, V30, P2358, DOI 10.1109/TNNLS.2018.2884620
   Lu YL, 2020, IEEE T IND INFORM, V16, P4177, DOI 10.1109/TII.2019.2942190
   Makkar A, 2021, IEEE T IND INFORM, V17, P903, DOI 10.1109/TII.2020.2968927
   Mehic M., 2020, Reversible Computation:Extending Horizons of Computing, P222
   Niemiec M, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2296-4
   Niemiec M, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P191
   NIST, 2020, NIST STAT TEST
   Pal S. K., 2019, International Journal of Computer Network and Information Security, V11, P45, DOI [10.5815/ijcnis.2019.10.06, DOI 10.5815/IJCNIS.2019.10.06]
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Protic D., 2016, Vojnotehnicki glasnik/Military Technical Courier, V64, P483, DOI DOI 10.5937/VOJTEHG64-8877
   Rosen-Zvi M, 2002, J PHYS A-MATH GEN, V35, pL707, DOI 10.1088/0305-4470/35/47/104
   Ruttor A, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.036121
   Ruttor A, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.056104
   Dorokhin ÉS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8214681
   Sarkar A., 2019, INT J ARTIF INTELL, V8, P44, DOI DOI 10.11591/IJEECS.V14.I1.PP169-177
   Sarkar A., 2012, INT J COMPUT SCI ENG, V3, P267
   Sarkar A, 2021, NEURAL PROCESS LETT, V53, P1355, DOI 10.1007/s11063-021-10443-8
   Shacham LN, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066137
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Shishniashvili E., 2020, INT J SIMUL SYST SCI, V21, P371, DOI [10.5013/ijssst.a.21.02.37, DOI 10.5013/IJSSST.A.21.02.37]
   Teodoro AAM, 2022, WIRELESS PERS COMMUN, V127, P1085, DOI 10.1007/s11277-021-08566-1
NR 33
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33577
EP 33606
DI 10.1007/s11042-023-14443-9
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943638900008
DA 2024-07-18
ER

PT J
AU Gayal, BS
   Patil, SR
AF Gayal, Baliram Sambhaji
   Patil, Sandip Raosaheb
TI Detection and localization of anomalies in video surveillance using
   novel optimization based deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Surveillance; Object tracking; Deep-convolutional
   neural network; Optimization
AB Nowadays, the demand for the surveillance applications is increased in order to guarantee the safety and security of the people/society. Due to the rapid growth in surveillance, human intervention is required to process the human behaviors in monitoring the anomaly attempts. Hence, this research proposes an automatic anomaly detection model for monitoring the anomalies from the surveillance videos. Accordingly, hierarchical-based social hunting optimization tuned Deep-convolutional neural network (HiS- Deep CNN) is proposed for video anomaly detection for which the object detection and tracking are the done initially. The detection improvement of the classifier is based on the training algorithm, hierarchical social hunting optimization (HiS) algorithm, which is designed based on the hybrid characteristics inherited from timber wolf and Ateles geoffrogis search agents. Moreover, the hierarchical social hunting strategy tracking of the video object is done using the features of Minimum output sum of squared error tracking algorithm (MOSSE) and Simple moving average based algorithm (SMA). The effectiveness of the hierarchical-based social hunting tuned Deep-convolutional neural network anomaly detection model is analyzed concerning the indices, such as sensitivity, accuracy, specificity, and Multiple Object Tracking Precision, which is 96.62%, 96.56%, 96.14%, and 0.994, respectively.
C1 [Gayal, Baliram Sambhaji] JSPMs Rajarshi Shahu Coll Engn, Dept Elect & Telecommun Engn, Pune 411033, India.
   [Patil, Sandip Raosaheb] Bharati Vidyapeeths Coll Engn Women, Dept Elect & Telecommun Engn, Pune 411043, India.
RP Gayal, BS (corresponding author), JSPMs Rajarshi Shahu Coll Engn, Dept Elect & Telecommun Engn, Pune 411033, India.
EM ram.gayal@gmail.com; srpatil44@gmail.com
RI Gayal, Baliram Sambhaji/HMV-6914-2023
CR Aberkane S, 2022, INFORM-INT J COMPUT, V46
   Ata-Ur-Rehman, 2021, IEEE ACCESS, V9, P19457, DOI 10.1109/ACCESS.2021.3054040
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Cheng KW, 2016, MULTIMED TOOLS APPL, V75, P15101, DOI 10.1007/s11042-015-2453-4
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Deshpande K, 2022, ARXIV
   Duman E, 2019, IEEE ACCESS, V7, P183914, DOI 10.1109/ACCESS.2019.2960654
   edu.hk, AVENUE DATASET
   ELHarrouss O., 2015, 2015 IEEE ACS 12 INT, P1
   github.io, SHANGHAITECH CAMPUS
   Guha P, 2006, P 3 INT C VIS INF EN, DOI [10.1049/CP:20060572, DOI 10.1049/CP:20060572]
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hui XF, 2012, INT C MANAGE SCI ENG, P1393, DOI 10.1109/ICMSE.2012.6414356
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Liu S, 2021, COMPLEX INTELL SYST, V7, P1895, DOI 10.1007/s40747-020-00161-4
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Muhammad K, 2020, IEEE INTERNET THINGS, V7, P4455, DOI 10.1109/JIOT.2019.2950469
   Murugesan M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103303
   Pawar K, 2022, IET BIOMETRICS, V11, P289, DOI 10.1049/bme2.12064
   Qi X, RETRAINING GENERATIV
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Tu P, 2008, LECT NOTES COMPUT SC, V5305, P691, DOI 10.1007/978-3-540-88693-8_51
   ucsd.edu, UCSD ANOMALY DETECTI
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Wang ZG, 2020, PATTERN RECOGN LETT, V140, P88, DOI 10.1016/j.patrec.2020.09.019
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   Yu BS, 2017, IEEE T SYST MAN CY-S, V47, P704, DOI 10.1109/TSMC.2016.2638048
   Yunzuo Z, 2019, 2019 IEEE INT C SIGN, P1
   Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou FQ, 2020, NEURAL PROCESS LETT, V52, P961, DOI 10.1007/s11063-019-10113-w
NR 37
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28895
EP 28915
DI 10.1007/s11042-023-14917-w
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941913300003
DA 2024-07-18
ER

PT J
AU Sivaraman, R
   Padmaa, M
   Sridevi, A
   Raj, V
   Manikandan, V
   Siva, J
   Bhogi, T
   Rengarajan, A
AF Sivaraman, R.
   Padmaa, M.
   Sridevi, A.
   Raj, Vinoth
   Manikandan, V.
   Siva, Janakiraman
   Bhogi, Tarunraj
   Rengarajan, Amirtharajan
TI Pullikolam assisted medical image watermarking on reconfigurable
   hardware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pullikolam; FPGA; Watermarking; Perceptual transparency
ID ROBUST; INFORMATION
AB This paper proposes that Pullikolam influenced medical image watermarking on Field Programmable Gate Array (FPGA). This watermarking scheme undergoes three successive operations: Look Up Table (LUT) formation for Pullikolam, Pixel localisation and Least Significant Bit (LSB) substitution. Additionally, this data hiding strategy employs on-chip embedded memory to store the data. This proposed architecture has been designed using Verilog HDL and implemented on Altera Cyclone IV E EP4CE115F29C7 FPGA. This watermarking scheme is consumed 3269 Logic Elements (LEs) which is 3% of the available LEs. Also, it requires only 5.24 mS to perform watermarking on 256 x 256 medical images. This work has achieved an average Mean Square Error (MSE) of < 5, and Normalized Cross-Correlation (NCC) is close to an ideal which is evidence of the robustness of the algorithm. Further, near-zero perceptual transparency has been attained through the Structural Similarity Index Matrix (SSIM) and histogram analyses that confirm the strength of the scheme.
C1 [Sivaraman, R.; Rengarajan, Amirtharajan] SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, India.
   [Padmaa, M.] Saranathan Coll Engn, Dept ECE, Thiruchirapalli 620012, India.
   [Sridevi, A.; Raj, Vinoth; Manikandan, V.; Siva, Janakiraman] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Raj, Vinoth] Velammal Inst Technol, ECE, Panchetti 601204, India.
   [Manikandan, V.] Kalasalingam Acad Res & Educ, CSE, Krishnankoil 626126, India.
   [Bhogi, Tarunraj] CoreEL Technol, Bengaluru 560034, Karnataka, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Kalasalingam Academy of Research & Education
RP Rengarajan, A (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; R, Sivaraman/ABB-1397-2020;
   Ramachandran, Vinoth Raj/HCI-6235-2022; Veerappan,
   Manikandan/HNS-8576-2023
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; R,
   Sivaraman/0000-0001-5989-4422; Ramachandran, Vinoth
   Raj/0000-0001-6441-0402; Veerappan, Manikandan/0000-0001-8501-5743;
   Rethinam, Sivaraman/0000-0001-9292-8524
FU Department of Science & Technology, New Delhi [SR/FST/ET-I/2018/221(C)]
FX The authors thank the Department of Science & Technology, New Delhi, for
   the FIST funding (SR/FST/ET-I/2018/221(C). Furthermore, the authors
   sincerely thank Dr R. Sundararaman (Former Senior Assistant Professor,
   School of EEE, SASTRA Deemed University) for his valuable suggestions
   and support. The authors also wish to thank the Intrusion Detection Lab
   at the School of Electrical & Electronics Engineering, SASTRA Deemed
   University, for providing infrastructural support to carry out this
   research work.
CR Banu SA, 2021, FRONT INFORM TECH EL, V22, P940, DOI 10.1631/FITEE.2000071
   Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Chowdhury Sarah N., 2020, 2020 Conference on Lasers and Electro-Optics (CLEO). Proceedings
   Darwish M.M., 2020, Multimedia security using chaotic maps: principles and methodologies, P137
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fengming Qin, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12240), P179, DOI 10.1007/978-3-030-57881-7_16
   Hammad I, 2010, IEEE EMBED SYST LETT, V2, P67, DOI 10.1109/LES.2010.2052401
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Liu J, 2020, IEEE ACCESS, V8, P93939, DOI 10.1109/ACCESS.2020.2995015
   Liu Y, 2020, ARTIF INTELL, P637
   Meloni P, 2010, IEEE EMBED SYST LETT, V2, P5, DOI 10.1109/LES.2010.2044365
   Nambakhsh MS, 2011, COMPUT METH PROG BIO, V104, P418, DOI 10.1016/j.cmpb.2010.08.016
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Sankaran KS, 2019, 2019 INT C COMM SIGN, P0568
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sharma A, 2015, PROCEDIA COMPUT SCI, V70, P778, DOI 10.1016/j.procs.2015.10.117
   Singh P, 2022, IEEE ACCESS, V10, P8974, DOI 10.1109/ACCESS.2022.3143801
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Zhang XR, 2020, CMC-COMPUT MATER CON, V64, P1435, DOI 10.32604/cmc.2020.011359
NR 26
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21193
EP 21203
DI 10.1007/s11042-023-14725-2
EA FEB 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000940729500006
DA 2024-07-18
ER

PT J
AU Chan, CT
   Huang, SH
   Choy, PP
AF Chan, Chak-Tong
   Huang, Szu-Hao
   Choy, Patrick Puiyui
TI Poisoning attacks on face authentication systems by using the generative
   deformation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Adversarial attack; Poisoning attack; Computer
   vision; Image deformation; Information security
AB Various studies have revealed the vulnerabilities of machine learning algorithms. For example, a hacker can poison a deep learning facial recognition system by impersonating an administrator and obtaining confidential information. According to studies, poisoning attacks are typically implemented based on the optimization conditions of the machine learning algorithm. However, neural networks, because of their complexity, are typically unsuited for these attacks. Although several poisoning strategies have been developed against deep facial recognition systems, poor image qualities and unrealistic assumptions remain the drawbacks of these strategies. Therefore, we proposed a black-box poisoning attack strategy against facial recognition systems, which works by injecting abnormal data generated by using elastic transformation to deform the facial components. We demonstrated the performance of the proposed strategy using the VGGFace2 data set to attack various facial extractors. The proposed strategy outperformed its counterparts in the literature. The contributions of the study lie in 1) providing a novel method of attack against a nonoverfitting facial recognition system with fewer injections, 2) applying a new image transformation technique to compose malicious samples, and 3) formulating a method that leaves no trace of modification to the human eye.
C1 [Chan, Chak-Tong] Natl Yang Ming Chiao Tung Univ, Inst Informat Management, 1001 Univ Rd, Hsinchu 300, Taiwan.
   [Huang, Szu-Hao; Choy, Patrick Puiyui] Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Huang, SH (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM szuhaohuang@nycu.edu.tw
OI Huang, Szu-Hao/0000-0002-4073-0652
FU Ministry of Science and Technology, Taiwan [MOST 110-2221-E-A49-101,
   MOST 110-2622-8-009-014-TM1]; Financial Technology (FinTech) Innovation
   Research Center, National Yang Ming Chiao Tung University
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Contract MOST 110-2221-E-A49-101 and Contract
   MOST 110-2622-8-009-014-TM1; and in part by the Financial Technology
   (FinTech) Innovation Research Center, National Yang Ming Chiao Tung
   University.
CR Aghakhani H, 2021, 2021 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2021), P159, DOI 10.1109/EuroSP51992.2021.00021
   Alfeld S., 2016, AAAI CONF ARTIF INTE, VVolume 30
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio S, 2016, ARXIV
   Biggio B., 2012, ARXIV
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Dubrofsky E., 2009, Ph.D. Thesis
   Goodfellow I. J., 2014, ARXIV
   Gu TY, 2019, IEEE ACCESS, V7, P47230, DOI 10.1109/ACCESS.2019.2909068
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jain A. K., 2011, HDB FACE RECOGNITION
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Liu YS, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23254
   Munoz-Gonzalez L., 2017, PROC 10 ACMWORKSHOP, P27, DOI 10.1145/3128572.3140451
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Rahimi Ali, 2007, ADV NEURAL INFORM PR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shafahi A, 2018, ADV NEUR IN, V31
   Simard PY, 2003, PROC INT CONF DOC, P958
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xiong W, 2017, IEEE-ACM T AUDIO SPE, V25, P2410, DOI 10.1109/TASLP.2017.2756440
   Yan SC, 2005, PROC CVPR IEEE, P830
   Yang C, 2017, ARXIV
   Zhang YH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2989, DOI 10.1145/3394486.3403349
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao MC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3945
   Zhong YY, 2021, IEEE T INF FOREN SEC, V16, P1452, DOI 10.1109/TIFS.2020.3036801
   Zhu C, 2019, PR MACH LEARN RES, V97
NR 36
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29457
EP 29476
DI 10.1007/s11042-023-14695-5
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000939106100003
DA 2024-07-18
ER

PT J
AU Hemdan, EE
   Essa, YM
   Shouman, M
   El-Sayed, AN
   Moustafa, AN
AF Hemdan, Ezz El-Din
   Essa, Youssef M. M.
   Shouman, Marwa
   El-Sayed, Ayman N.
   Moustafa, Abdullah N.
TI An efficient IoT based smart water quality monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Water quality; Machine learning; Internet of things; Time series
   forecasting; Facebook prophet; LSTM
AB Globally, water resources play a vital role regards to environment and health. Accurate forecasting of water quality is the key to enhancing water management. To identify the water quality effects and provide an automated water quality monitoring and testing system that can support in guaranteeing the safety of the water around the world. Therefore, This paper presents an IoT-based water quality system along with an efficient prediction method based on machine learning techniques to forecast at scale the water quality for competent decision support making in IoT-based smart water quality and monitoring systems in the context of smart cities. This water quality monitoring and testing system use the Internet of Things and forecasting-based machine learning algorithms. Forecasting is an indispensable task in the data prediction journey which can help the water provider entities to plan better, set goals, and detect abnormal events. Therefore, this work describes an experimental work to forecast at scale the water quality and proposes the measurement of the Water Quality Index (WQI) for drinking water and labels the dataset with WQI values. Likewise, it provides a comparative study between LSTM and Facebook prophet in the era of water quality which can help the data providers and business analysts to make better decisions based on forecasting water quality data. The result shows that the Facebook prophet performs better in terms of accuracy, performance, and resource utilization.
C1 [Hemdan, Ezz El-Din; Shouman, Marwa; El-Sayed, Ayman N.; Moustafa, Abdullah N.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [Essa, Youssef M. M.] Bayer, Principle Data & Knowledge, Berlin, Germany.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Bayer AG
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM ezzvip@yahoo.com; youessfessa@gmail.com; marwashouman834@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg; abdalla.moustafa@ejust.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X
FU ITAC [CFP178]
FX This work is a part of the project "Smart Spout: A Water Quality System
   based on Big Data Analytics and Internet of Things in the Context of
   Smart City Initiatives in Egypt" funded by ITAC under grant ID "CFP178".
   Also, this work contains data supplied by Natural Environment Research.
CR Abbasimehr H, 2022, J AMB INTEL HUM COMP, V13, P673, DOI 10.1007/s12652-020-02761-x
   Aldhyani THH, 2020, APPL BIONICS BIOMECH, V2020, DOI 10.1155/2020/6659314
   Ali M, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P108, DOI 10.1109/ICDIM.2013.6694009
   [Anonymous], 2021, OPEN GOVT LICENCE V3
   [Anonymous], 2021, LONDON ENGLAND UK WE
   [Anonymous], 2020, CONTINUOUS MEASUREME
   Atlam HF, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100220
   Ebenstein A, 2012, REV ECON STAT, V94, P186, DOI 10.1162/REST_a_00150
   El-Din HE, 2017, STUD BIG DATA, V25, P109, DOI 10.1007/978-3-319-53472-5_5
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   García-Alba J, 2019, WATER RES, V150, P283, DOI 10.1016/j.watres.2018.11.063
   Hemdan E. E. D., 2020, Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications
   Hemdan EE-D, 2001, 2021 INT C ELECT ENG
   Hou JW, 2014, J CENT SOUTH UNIV, V21, P1051, DOI 10.1007/s11771-014-2036-y
   Huang PS, 2019, J MARINE SYST, V199, DOI 10.1016/j.jmarsys.2019.103218
   Khaleeq H., 2016, Network Protocols and Algorithms, V8, P1, DOI [10.5296/npa.v8i3.9719, DOI 10.5296/NPA.V8I3.9719]
   Khan Rijwan, 2021, Comput Intell Neurosci, V2021, P5942574, DOI 10.1155/2021/5942574
   Khan R, 2022, WORLD J ENG, V19, P204, DOI 10.1108/WJE-05-2021-0269
   Kumar A, 2020, DEEP LEARNING TECHNI, P211, DOI [DOI 10.1007/978-3-030-33966-111, DOI 10.1007/978-3-030-33966-1_11]
   Lee S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15071322
   Li C, 2009, 2009 1 INT C INFORM
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Liu YS, 2003, PROG PHYS GEOG, V27, P24, DOI 10.1191/0309133303pp357ra
   Lobato TC, 2015, J HYDROL, V522, P674, DOI 10.1016/j.jhydrol.2015.01.021
   Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9
   Maroli AA, 2021, CLEAN TECHNOL ENVIR, V23, P271, DOI 10.1007/s10098-020-01975-z
   National Institute For Research In Tuberculosis Formerly Tuberculosis Research Centre Icmr-Nirt Chennai, 2020, Indian J Tuberc, V67, pS7, DOI 10.1016/j.ijtb.2020.12.001
   Peng ZL, 2019, SCI TOTAL ENVIRON, V687, P218, DOI 10.1016/j.scitotenv.2019.06.067
   Pontoh Resa Septiani, 2021, Journal of Physics: Conference Series, V1776, DOI 10.1088/1742-6596/1776/1/012057
   Rabee A. M., 2011, Journal of Water Resource and Protection, V3, P262, DOI 10.4236/jwarp.2011.34033
   Rezk NG, 2021, MULTIMED TOOLS APPL, V80, P773, DOI 10.1007/s11042-020-09740-6
   Sakizadeh M, 2016, MODEL EARTH SYST ENV, V2, DOI 10.1007/s40808-015-0063-9
   Shafi Uferah, 2018, 2018 15th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT (HONET-ICT), P92, DOI 10.1109/HONET.2018.8551341
   Sheppard D, 2001, IGARSS 2001 SCANNING, V3
   Srivastava P., 2018, Int. J. Adv. Res. Comput. Sci. Softw. Eng, V8, P17, DOI [DOI 10.23956/IJARCSSE.V8I6.711, 10.23956/ijarcsse.v8i6.711]
   Swain A, 2008, CONFLICT PEACE S ASI
   TOHARUDIN T, 2020, COMMUN STAT-SIMUL C, P1
   Valdivia-Garcia M, 2016, SCI REP-UK, V6, DOI 10.1038/srep35027
   Wechmongkhonkon S., 2012, WORLD ACAD SCI ENG T, V6, P574
   Xiang YR, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P900, DOI 10.1109/WKDD.2009.217
   Yan J, 2019, APPL SCI-BASEL, V9, P9
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhong Y, 2014, ABSTR APPL ANAL, V2014
NR 43
TC 3
Z9 3
U1 18
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28827
EP 28851
DI 10.1007/s11042-023-14504-z
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000939106800008
DA 2024-07-18
ER

PT J
AU Han, F
   Jiang, SK
   Wu, JM
   Xu, BL
   Zhao, J
   Shen, FR
AF Han, Feng
   Jiang, Shaokui
   Wu, Jianmin
   Xu, Baile
   Zhao, Jian
   Shen, Furao
TI Real-time object tracking in the wild with Siamese network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time object tracking; Siamese network; Squeeze-and-excitation
   network; Regression localization
AB Single object tracking (SOT) is one of the most important tasks in computer vision. With the development of deep neural networks and the release for a series of large scale datasets for single object tracking, Siamese networks have been proposed and perform better than most of the traditional methods. However, recent Siamese networks are getting slower to obtain better performance as they become deeper. Most of those networks could only meet the needs of real-time object tracking in ideal environments. In order to achieve a better balance between efficiency and accuracy, we propose a simpler Siamese network for single object tracking, which runs fast in poor hardware configurations while remaining an acceptable accuracy. The proposed method consists of three parts: sample generation, SE-Siamese and regression localization. In the sample generation stage, template patch and detection patch are cropped from the selected video frames in a new way. The SE-Siamese subnetwork adopts Siamese network and Squeeze-and-Excitation (SE) network as the feature extractor which is an effective way of speeding up the training phase. The regression localization network aims to compute the location of the tracked object in a more efficient way without losing much precision. To validate the effectiveness of the proposed approach, we conduct extensive experiments on several challenging tracking benchmark datasets, including VOT2015, VOT2016, VOT2017 and OTB-100. The experimental results show that our approach displays significant speed improvements compared to several strong baseline trackers (19.5 FPS to 44.4 FPS).
C1 [Han, Feng; Jiang, Shaokui; Wu, Jianmin; Xu, Baile; Shen, Furao] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
   [Han, Feng; Jiang, Shaokui; Wu, Jianmin; Xu, Baile] Nanjing Univ, Dept Comp Sci & Technol, Nanjing 210023, Peoples R China.
   [Zhao, Jian] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Peoples R China.
   [Shen, Furao] Nanjing Univ, Sch Artificial Intelligence, Nanjing 210023, Peoples R China.
C3 Nanjing University; Nanjing University; Nanjing University; Nanjing
   University
RP Shen, FR (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.; Shen, FR (corresponding author), Nanjing Univ, Sch Artificial Intelligence, Nanjing 210023, Peoples R China.
EM frshen@nju.edu.cn
RI han, feng/KBB-3356-2024; Xu, Baile/AAE-7944-2019
OI Xu, Baile/0000-0001-6349-7999; Shen, Furao/0000-0002-7285-326X
FU National Natural Science Foundation of China [62276127]
FX AcknowledgementsThis work is supported by the National Natural Science
   Foundation of China under Grant Nos. (62276127).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bai S, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102759
   Benenson Rodrigo, 2008, International Journal of Vehicle Autonomous Systems, V6, P4, DOI 10.1504/IJVAS.2008.016486
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Beymer D., 1999, IEEE Frame Rate Workshop, P1
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dosovitskiy Alexey, 2021, ICLR
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CH, 2021, VISUAL COMPUT, V37, P587, DOI 10.1007/s00371-020-01825-5
   Li Y., 2019, ARXIV
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Nam H, 2016, ARXIV
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2020, IEEE ACCESS, V8, P8834, DOI 10.1109/ACCESS.2020.2964838
   Ong P, 2022, VISUAL COMPUT, V38, P939, DOI 10.1007/s00371-021-02060-2
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2014, PR MACH LEARN RES, V32, P1107
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yang CJ, 2005, IEEE I CONF COMP VIS, P212
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang WC, 2021, VISUAL COMPUT, V37, P881, DOI 10.1007/s00371-020-01839-z
   Zhu G, 2015, ARXIV
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 55
TC 1
Z9 1
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24327
EP 24343
DI 10.1007/s11042-023-14519-6
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000934222700005
DA 2024-07-18
ER

PT J
AU Yen, AZ
   Fu, MH
   Ang, WH
   Chu, TT
   Tsai, SH
   Huang, HH
   Chen, HH
AF Yen, An-Zi
   Fu, Min-Huan
   Ang, Wei-Hong
   Chu, Tai-Te
   Tsai, Ssu-Hao
   Huang, Hen-Hsen
   Chen, Hsin-Hsi
TI Visual lifelog retrieval: humans and machines interpretation on
   first-person images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifelog; Visual lifelog retrieval; Interactive system
AB People usually forget the details of life experiences and encounter situations where they require to recall their past experiences. Therefore, lifelog retrieval turns out to be an emerging task in the AI community. Nowadays, people can record their life experiences by capturing images through wearable devices, writing blog posts, and so on. These personal big data stored in digital format can be considered lifelogs for retrieval. In this work, we focus on constructing a visual lifelog retrieval system that is able to efficiently find related images given the input textual queries. The core challenge of visual lifelog retrieval with textual queries comes from the semantic gap between visual and textual data. In this work, we propose LifeConcept, an interactive lifelog search system that is aimed at not only accelerating the retrieval process but also fetching more precise results. To reduce the semantic gap, we incorporate visual and textual concepts from images into our system utilizing pre-trained textual embeddings. Moreover, we propose a concept recommendation method enabling users to set up the related conditions for their requirements efficiently and search the desired images with appropriate query terms based on the suggestion. Experimental results show that textual concepts from images detected by CV models improve the retrieval results. We further employ annotators to label captions of images for investigating the difference between model-generated captions and human-labeled captions. The human-annotated dataset is released to facilitate future study of visual lifelog retrieval. Four research questions are discussed to explore the characteristic of models and humans interpreting the first-person images captured by wearable cameras. The impacts of model-generated captions and human-labeled captions in terms of visual lifelog retrieval are also included.
C1 [Yen, An-Zi] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 30010, Taiwan.
   [Fu, Min-Huan; Ang, Wei-Hong; Chu, Tai-Te; Tsai, Ssu-Hao; Chen, Hsin-Hsi] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, 1 Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
   [Huang, Hen-Hsen] Acad Sinica, Inst Informat Sci, 128 Acad Rd, Taipei 115, Taiwan.
C3 National Yang Ming Chiao Tung University; National Taiwan University;
   Academia Sinica - Taiwan
RP Chen, HH (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, 1 Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
EM azyen@nycu.edu.tw; mhfu@nlg.csie.ntu.edu.tw; wfhong@nlg.csie.ntu.edu.tw;
   tdjhu@nlg.csie.ntu.edu.tw; b08902026@ntu.edu.tw;
   hhhuang@iis.sinica.edu.tw; hhchen@ntu.edu.tw
FU National Science and Technology Council, Taiwan [MOST
   110-2221-E-002-128-MY3, MOST 110-2634-F-002-050-]
FX AcknowledgementsThis research was partially supported by National
   Science and Technology Council, Taiwan, under grants MOST
   110-2221-E-002-128-MY3 and MOST 110-2634-F-002-050-.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bolaños M, 2015, IEEE INT CONF MULTI
   Bolaños M, 2017, IEEE T HUM-MACH SYST, V47, P77, DOI 10.1109/THMS.2016.2616296
   Bradski G, 2000, DR DOBBS J, V25, P120
   Chang CC, 2019, LSC '19 - PROCEEDINGS OF THE ACM WORKSHOP ON LIFELONG SEARCH CHALLENGE, P41, DOI 10.1145/3326460.3329163
   Chu TH, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P398, DOI 10.1145/3350546.3352555
   Collell G, 2017, AAAI CONF ARTIF INTE, P4378
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doherty AR, 2011, COMPUT HUM BEHAV, V27, P1948, DOI 10.1016/j.chb.2011.05.002
   Fan C, 2018, J VIS COMMUN IMAGE R, V55, P40, DOI 10.1016/j.jvcir.2018.05.008
   Fu M-H, 2019, P 14 NTCIR C EVALUAT, P61
   Gurrin C., 2019, NTCIR 14, P14
   Gurrin Cathal, 2021, PROC INT C MULTIMEDI
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jiayu Li, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P29, DOI 10.1145/3379172.3391720
   Karthikeyan T, 2014, INT J ENG-IRAN, P3
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Lim J-H, 2017, VISUALIZING PERSONAL
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Maekawa T, 2013, INT CONF PER COMP, P405, DOI 10.4108/icst.pervasivehealth.2013.252128
   Min-Huan Fu, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P450, DOI 10.1145/3372278.3390700
   Nakashima K, 2020, ROBOMECH J, V7, DOI 10.1186/s40648-020-00181-2
   Le NK, 2019, LSC '19 - PROCEEDINGS OF THE ACM WORKSHOP ON LIFELONG SEARCH CHALLENGE, P1, DOI 10.1145/3326460.3329155
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Poleg Y, 2014, PROC CVPR IEEE, P2537, DOI 10.1109/CVPR.2014.325
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tai-Te Chu, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P51, DOI 10.1145/3379172.3391723
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang P, 2012, INT J MULTIMED INF R, V1, P87, DOI 10.1007/s13735-012-0010-8
   Woodberry E, 2015, MEMORY, V23, P340, DOI 10.1080/09658211.2014.886703
   Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19
   Yen A-Z, 2021, 35 AAAI C ARTIFICIAL
   Yen An-Zi, 2021, P 2021 INT C MULT RE, DOI DOI 10.1145/3460426.3463607
   Zhang T., 2020, INT C LEARNING REPRE
NR 40
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 FEB 16
PY 2023
DI 10.1007/s11042-023-14344-x
EA FEB 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9H0QP
UT WOS:000938546700001
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Pratihar, S
   Chatterji, S
   Basu, A
AF Ghosh, Sagarika
   Pratihar, Sanjoy
   Chatterji, Sanjay
   Basu, Anupam
TI Matching of hand-drawn flowchart, pseudocode, and english description
   using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand-drawn flowchart; Pseudocode; Text description; S-DistilBERT;
   Ruleset; Embedding; Transfer learning; Similarity matching
ID OPTIMAL POLYGONAL-APPROXIMATION; DOMINANT POINTS; ALGORITHM
AB An algorithm plays an important role when solving a problem. It is challenging to comprehend for computer novices or machines. Therefore, a textual explanation is provided to illustrate the algorithm. To understand an algorithm, a method needs to be devised to find or generate the corresponding text description and vice versa. This paper matches an algorithm in a variety of forms, such as pseudocode and hand-drawn flowchart, with the illustrative text written in English to facilitate a thorough understanding of the algorithm. The experiment includes a proposed set of rules for generating pseudocode from a hand-drawn flowchart and a proposed S-DistilBERT-based transfer learning method to determine the similarity match score between multiple forms of algorithm and text description. Basic block and line identification, as well as OCR-ization, are used to characterize the hand-drawn flowcharts. The experimental result show that we can generate the equivalent pseudocode in 85% cases, and our fine-tuned S-DistilBERT model can accommodate the matching text for the existing pseudocode with 75.59% and the generated pseudocode with 74.57% accuracy. We also find the appropriate description from an algorithm in the top five matches in 30 out of 50 cases. The rules are found to be adequate for non-recursive flowcharts.
C1 [Ghosh, Sagarika; Pratihar, Sanjoy; Chatterji, Sanjay] Indian Inst Informat Technol Kalyani, Comp Sci & Engn, Kalyani 741235, West Bengal, India.
   [Ghosh, Sagarika] Univ Engn & Management Jaipur, Comp Sci & Engn, Jaipur 303807, Rajasthan, India.
   [Basu, Anupam] Natl Inst Technol Durgapur, Comp Sci & Engn, Durgapur 713209, West Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Ghosh, S (corresponding author), Indian Inst Informat Technol Kalyani, Comp Sci & Engn, Kalyani 741235, West Bengal, India.; Ghosh, S (corresponding author), Univ Engn & Management Jaipur, Comp Sci & Engn, Jaipur 303807, Rajasthan, India.
EM sagarika.ghosh304@gmail.com; sanjoy@iiitkalyani.ac.in;
   sanjayc@iiitkalyani.ac.in; anupambas@gmail.com
RI Pratihar, Sanjoy/K-8029-2017; Basu, Anupam/K-1838-2014
OI Basu, Anupam/0000-0002-0608-9267
CR Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi JA, 2020, J INTELL FUZZY SYST, V39, P1021, DOI 10.3233/JIFS-191933
   [Anonymous], 2021, PEACE TEXT SCANNER
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Cer D., 2018, ARXIV
   Chakraborty S, 2020, IEEE REGION 10 S TEN, DOI [10.1109/TENSYMP50017.2020.9231033https://doi.org/10.1109/TENSYMP50017.2020.9231033, DOI 10.1109/TENSYMP50017.2020.9231033HTTPS://DOI.ORG/10.1109/TENSYMP50017.2020.9231033]
   Chen X, 2014, ARXIV
   Cho K., 2014, ARXIV14061078
   Chung KL, 2008, J VIS COMMUN IMAGE R, V19, P219, DOI 10.1016/j.jvcir.2008.01.004
   Climer S, 2003, PATTERN RECOGN LETT, V24, P2291, DOI 10.1016/S0167-8655(03)00055-2
   Devlin J., 2018, BERT PRE TRAINING DE
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Gomaa WH., 2013, international journal of Computer Applications, V68, P13, DOI 10.5120/11638-7118
   Liu HR, 2008, INT J COMPUT VISION, V80, P104, DOI 10.1007/s11263-008-0131-y
   Loshchilov I., 2019, arXiv
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Melkman A, 1988, P COMPUTATIONAL MORP, P87
   Miyao H, 2012, INT CONF FRONT HAND, P83, DOI 10.1109/ICFHR.2012.250
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   Mutinda FW, 2021, METHOD INFORM MED, V60, pE56, DOI 10.1055/s-0041-1731390
   Neumann R, 2002, PATTERN RECOGN, V35, P1447, DOI 10.1016/S0031-3203(01)00145-5
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pontes L E, 2018, ASS COMPUTATIONAL LI, V1
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Rematska, 2021, DEEP UNDERSTANDING T, V30, DOI [10.1142/S0218213021500160https://doi.org/10.1142/S0218213021500160, DOI 10.1142/S0218213021500160HTTPS://DOI.ORG/10.1142/S0218213021500160]
   Sanh V., 2020, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Venugopalan S, 2014, ARXIV
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Wang CC, 2017, INT J DOC ANAL RECOG, V20, P123, DOI 10.1007/s10032-017-0284-8
   Westermann H, 2021, LECT NOTES COMPUT SC, V12758, P269, DOI 10.1007/978-3-030-79942-7_18
   Yin PY, 2004, J VIS COMMUN IMAGE R, V15, P241, DOI 10.1016/j.jvcir.2003.12.001
   Yin PY, 2003, PATTERN RECOGN, V36, P1783, DOI 10.1016/S0031-3203(02)00321-7
   Yuan Z., 2008, NOVEL PEN BASED FLOW, DOI [10.1007/978-3-540-89962-4_6, DOI 10.1007/978-3-540-89962-4_6]
   Yun XL, 2022, IEEE T MULTIMEDIA, V24, P2580, DOI 10.1109/TMM.2021.3087000
   Zwillinger D., 2000, CRC STANDARD PROBABI, P372
NR 39
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 27027
EP 27055
DI 10.1007/s11042-023-14346-9
EA FEB 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000924075600002
DA 2024-07-18
ER

PT J
AU Mumtaz, A
   Sargano, AB
   Habib, Z
AF Mumtaz, Aqib
   Sargano, Allah Bux
   Habib, Zulfiqar
TI Robust learning for real-world anomalies in surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-world anomalies; Anomaly detection; Surveillance videos; Deep
   learning; Inflated inception network; Dynamic frame-skipping
ID EVENT DETECTION; DEEP NETWORK; LOCALIZATION
AB Anomaly detection has significant importance for developing autonomous surveillance systems. Real-world anomalous events are far more complex and harder to capture due to diverse human behaviors and a wide range of anomaly types. A key factor in defining activity is the temporal length or duration of the activity. The time period required for an anomalous activity to be completely understandable and meaningful depends on the nature and speed of the event. Some events are as fast to be captured within a few frames; however, some activities are slow and may require several thousands of video frames to define an activity. Deep learning architectures have a limited input temporal sequence length and suffer from learning very long sequences. There is a need to re-investigate the problem from the frame sequences perspective to better define an activity in the limited temporal length. In this research work, our contribution is two-fold. Firstly, a novel strategy of dynamic frame-skipping is proposed for producing meaningful temporal sequences for model learning. Secondly, a new deep learning model based on the Inflated Inception network (I3D) is proposed for learning spatial and temporal information from video frames. In order to evaluate the performance of the proposed model, experiments are performed on one of the most challenging real-world anomalies UCF-Crime dataset. The results confirm that the proposed model is robust and significantly outperforms state-of-the-art methods in terms of accuracy. In addition to this, the proposed model has achieved the highest F1 score for fast and slow activities, such as explosions, road accidents, robbery, and stealing, and the AUC score of 0.837.
C1 [Mumtaz, Aqib; Sargano, Allah Bux; Habib, Zulfiqar] COMSATS Univ Islamabad, Dept Comp Sci, Lahore 54000, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Sargano, AB; Habib, Z (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore 54000, Pakistan.
EM allahbux@cuilahore.edu.pk; drzhabib@cuilahore.edu.pk
RI Sargana, AllahBux/AFO-1591-2022; Habib, Zulfiqar/B-6355-2013
OI Sargana, AllahBux/0000-0003-2024-2843; Habib,
   Zulfiqar/0000-0001-9758-9162; Mumtaz, Aqib/0000-0002-1760-6346
FU PDE-GIR project; European Union [778035]; Marie Curie Actions (MSCA)
   [778035] Funding Source: Marie Curie Actions (MSCA)
FX This research is supported by the PDE-GIR project, which has received
   funding from the European Union's Horizon 2020 research and innovation
   program under the Marie Sklodowska-Curie grant agreement No 778035.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Bai S., 2019, P CVPR WORKSH, P117
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chalapathy R, 2019, LECT NOTES ARTIF INT, V11051, P173, DOI 10.1007/978-3-030-10925-7_11
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Chidananda K., 2022, Information and Communication Technology for Competitive Strategies (ICTCS 2020): ICT: Applications and Social Interfaces. Lecture Notes in Networks and Systems (191), P791, DOI 10.1007/978-981-16-0739-4_75
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Chong YS, 2015, ARXIV
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dhole H, 2019, INT CONF COMPUT
   Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He CK, 2018, MULTIMED TOOLS APPL, V77, P29573, DOI 10.1007/s11042-017-5255-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kay W., 2017, CORR ABS170506950
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu Y, 2022, IEEE T CIRCUITS-II, V69, P2498, DOI 10.1109/TCSII.2022.3161049
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Maqsood R, 2021, MULTIMED TOOLS APPL, V80, P18693, DOI 10.1007/s11042-021-10570-3
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mumtaz A, 2020, FAST LEARNING DEEP M
   Mumtaz A, 2018, 2018 2ND EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (EECS 2018), P558, DOI 10.1109/EECS.2018.00109
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Ramachandra B, 2022, IEEE T PATTERN ANAL, V44, P2293, DOI 10.1109/TPAMI.2020.3040591
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Sargano AB, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010110
   Sargano AB, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6100309
   Sebe N., 2015, P BRIT MACH VIS C 20
   Shahnaz A, 2019, IEEE ACCESS, V7, P147782, DOI 10.1109/ACCESS.2019.2946373
   Shao J, 2016, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR.2016.606
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Tian Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4955, DOI 10.1109/ICCV48922.2021.00493
   Ullah H, 2014, LECT NOTES COMPUT SC, V8749, P62, DOI 10.1007/978-3-319-11839-0_6
   Ullah W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082811
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang G., 2019, P CVPR WORKSH, P382
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   [袁非牛 Yuan Feiniu], 2019, [计算机学报, Chinese Journal of Computers], V42, P203
   Zhao B, 2011, PROC CVPR IEEE
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu S., 2020, ARXIV
   Zhu Y., 2019, 30 BR MACH VIS C 201
   Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722
NR 72
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20303
EP 20322
DI 10.1007/s11042-023-14425-x
EA JAN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000923421800001
DA 2024-07-18
ER

PT J
AU Li, YS
   Ding, HW
   Hu, P
   Yang, ZJ
   Wang, GB
AF Li, Yushan
   Ding, Hongwei
   Hu, Peng
   Yang, Zhijun
   Wang, Guanbo
TI Real-time detection algorithm for non-motorized vehicles based on D-YOLO
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Non-motorized vehicles detection; Dilated convolution; Deep separable
   convolution; Coordinate attention; Spatial pyramid pooling
ID FEATURES
AB In complex traffic scenarios, it is crucial to develop a rapid and precise real-time detection system for non-motorized vehicles to ensure safe driving. D-YOLO is a lightweight real-time detection technique for non-motorized vehicles based on an enhanced version of YOLOv4-tiny. Typically, the computing capabilities of mobile devices are constrained, therefore we begin by reducing the number of model parameters. Then, we add dilated convolution and depthwise separable convolution into the network's Cross Stage Partial Connection (CSPNet) in order to produce the DCSPNet with improved performance. Coordinate Attention(CA) is implemented to enhance the network's capability to extract effective features. In the neck network of the model by introducing a spatial pyramid set (SPP) to enhance the feature representation of non-motorized vehicles in the feature layer. Finally, we test this proposed model on dataset, the experimental results show that D-YOLO has a model size of only 6.7MB, which is 16.5MB smaller than YOLOv4-tiny. The detection speed of D-YOLO is about 25% faster than that of YOLOv4-tiny, D-YOLO has approximately 58% fewer model parameters than YOLOv4-tiny, D-YOLO has a mAP of 70.36%, which is 2.01% higher than YOLOv4-tiny. It can be shown that D-YOLO ensures both accuracy and real-time performance to satisfies the demand of real-time detection of non-motorized vehicles in intelligent traffic scenarios.
C1 [Li, Yushan; Ding, Hongwei; Yang, Zhijun; Wang, Guanbo] Yunnan Univ, Sch Informat, Kunming 650500, Yunnan, Peoples R China.
   [Li, Yushan; Ding, Hongwei; Yang, Zhijun; Wang, Guanbo] Yunnan Univ, Key Lab Internet Things Technol & Applicat Yunnan, Kunming 650500, Yunnan, Peoples R China.
   [Hu, Peng] Yunnan Youbei Commun Technol Co, Kunming 650500, Yunnan, Peoples R China.
C3 Yunnan University; Yunnan University
RP Ding, HW (corresponding author), Yunnan Univ, Sch Informat, Kunming 650500, Yunnan, Peoples R China.; Ding, HW (corresponding author), Yunnan Univ, Key Lab Internet Things Technol & Applicat Yunnan, Kunming 650500, Yunnan, Peoples R China.
EM myssgxka@163.com
RI Li, Yushan/HKE-5889-2023
OI Guanbo, Wang/0000-0001-8210-8805
FU National Natural Science Foundation of China [61461053, 61461054]
FX AcknowledgementsThis study was supported in part by grants from The
   National Natural Science Foundation of China, Grant/Award Numbers:
   61461053, 61461054.
CR Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Aslam N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1071, DOI 10.1109/ICCSP.2017.8286540
   Avenash R, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P413, DOI 10.5220/0007469604130420
   Bar-Cohen Y, 2006, BIOINSPIR BIOMIM, V1, pP1, DOI 10.1088/1748-3182/1/1/P01
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YP, 2018, ADV NEUR IN, V31
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gholami A, 2018, IEEE COMPUT SOC CONF, P1719, DOI 10.1109/CVPRW.2018.00215
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, ADV NEUR IN, V31
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YM, 2018, Arxiv, DOI [arXiv:1805.11394, 10.48550/arXiv.1805.11394]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZC, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3067470
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li GF, 2020, IEEE T IND ELECTRON, V67, P8889, DOI 10.1109/TIE.2019.2945295
   Li X, 2022, IEEE T CIRC SYST VID, V32, P1792, DOI 10.1109/TCSVT.2021.3082635
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin MB, 2020, Arxiv, DOI arXiv:2001.08565
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma XL, 2020, AAAI CONF ARTIF INTE, V34, P5117
   Misra D, 2021, IEEE WINT CONF APPL, P3138, DOI 10.1109/WACV48630.2021.00318
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Peng CL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107498
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Srinivas S, 2017, IEEE COMPUT SOC CONF, P455, DOI 10.1109/CVPRW.2017.61
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stollenga MF, 2014, ADV NEUR IN, V27
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang F, 2016, Arxiv, DOI arXiv:1601.06823
   Wang GB, 2022, IET COMPUT VIS, V16, P126, DOI 10.1049/cvi2.12072
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yu JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093263
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang TY, 2018, Arxiv, DOI arXiv:1802.05747
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao X, 2019, DETECTION TRACKING, V7
NR 69
TC 0
Z9 0
U1 20
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 25
PY 2023
DI 10.1007/s11042-023-14385-2
EA JAN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8G8VR
UT WOS:000920621000002
DA 2024-07-18
ER

PT J
AU Ali, MH
   Jaber, MM
   Daniel, JA
   Vignesh, CC
   Meenakshisundaram, I
   Kumar, BS
   Punitha, P
AF Ali, Mohammed Hasan
   Jaber, Mustafa Musa
   Alfred Daniel, J.
   Vignesh, C. Chandru
   Meenakshisundaram, Iyapparaja
   Kumar, B. Santhosh
   Punitha, P.
TI Autonomous vehicles decision-making enhancement using self-determination
   theory and mixed-precision neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous Vehicles; Decision-Making; Mixed-Precision Neural Networks;
   Neural Networks; Self-Determination Theory
ID ARTIFICIAL-INTELLIGENCE; OPTIMIZATION; NAVIGATION
AB The safe human-level decision-making for expressing the autonomous vehicles and the estimation of the eco vehicles has been proposed for the motion control for the driving behavior. For efficient decision-making, the sensor-based tracking of the autonomous machine for blockchain is to be done. The sensor-based history recording management has to propose, and storing the vehicle's traveling history must be managed. For security reasons, the blockchain is done. Self-determination theory and energy-efficient mixed-precision neural networks are used in autonomous vehicles' decision-making, and this technique is used in making moral decisions. The self-determination theory is used in creating the vehicles traveling steps using the innovative signal delivery system of the autonomous vehicles. The energy-efficient mixed-precision neural networks are used in managing the problem that travels the signal to the vehicles using the mixed-precision neural networks. The vehicle network has been made more efficient for storing the data of the mixed precision value and its neural network from autonomous vehicles. Here 80% of the precision value is raised compared to the previous days. In previous days, 20% of the precision has been calculated in autonomous vehicles. Comparing this, 60% of the precision value has been raised in traveling history. According to these variations, 40%-50% of autonomous vehicles' data transmission that delivers the neural network has been proposed. By improving autonomous vehicles, the efficiency of mixed precision neural networks is the decision-making for efficient precision.
C1 [Ali, Mohammed Hasan] Imam Jaafar Al Sadiq Univ, Fac Informat Technol, Comp Tech Engn Dept, Baghdad, Iraq.
   [Jaber, Mustafa Musa] Al Turath Univ Coll, Dept Med instruments Engn Tech, Baghdad 10021, Iraq.
   [Alfred Daniel, J.] Karpagam Acad Higher Educ, Coimbatore, India.
   [Vignesh, C. Chandru] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Meenakshisundaram, Iyapparaja] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, India.
   [Kumar, B. Santhosh] Guru Nanak Inst Technol, Dept Comp Sci & Engin, Hyderabad, Telangana, India.
   [Punitha, P.] SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, India.
C3 Imam Jaa'far al-Sadiq University; Karpagam Academy of Higher Education
   (KAHE); Vellore Institute of Technology (VIT); VIT Vellore; Vellore
   Institute of Technology (VIT); VIT Vellore; SNS College of Technology
RP Daniel, JA (corresponding author), Karpagam Acad Higher Educ, Coimbatore, India.
EM 85.alfred@gmail.com
RI Daniel, Alfred/O-1875-2017; Balan, Dr Santhosh Kumar/N-3734-2016
OI Daniel, Alfred/0000-0003-0602-3425; Balan, Dr Santhosh
   Kumar/0000-0003-1929-7337; , P.Punitha/0000-0003-0727-7072; Chinnappan,
   Dr Chandru Vignesh/0000-0001-5513-846X
CR Anvari M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31942-9
   Aubin CA, 2022, NATURE, V602, P393, DOI 10.1038/s41586-021-04138-2
   Bagga P, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101877
   Bartolozzi C, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28487-2
   Bellemare MG, 2020, NATURE, V588, P77, DOI 10.1038/s41586-020-2939-8
   Chai F, 2020, NAT REV EARTH ENV, V1, P315, DOI 10.1038/s43017-020-0053-y
   Chakraborty I, 2020, NAT MACH INTELL, V2, P43, DOI 10.1038/s42256-019-0134-0
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Daniel A, 2020, IET INTELL TRANSP SY, V14, P1410, DOI 10.1049/iet-its.2019.0784
   Ding YK, 2020, NAT ELECTRON, V3, P514, DOI 10.1038/s41928-020-00476-7
   Floreano D, 2015, NATURE, V521, P460, DOI 10.1038/nature14542
   Gagné M, 2022, NAT REV PSYCHOL, V1, P378, DOI 10.1038/s44159-022-00056-w
   Grillot F, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00598-3
   Jayachandran M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96769-8
   Kaack LH, 2022, NAT CLIM CHANGE, V12, P518, DOI 10.1038/s41558-022-01377-7
   Kattenborn T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53797-9
   Lakkam S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47747-8
   Lechner M, 2020, NAT MACH INTELL, V2, P642, DOI 10.1038/s42256-020-00237-3
   Li J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92904-7
   Li YJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90221-7
   Lu L, 2021, NAT MACH INTELL, V3, P218, DOI 10.1038/s42256-021-00302-5
   Man DP, 2023, IEEE CONSUM ELECTR M, V12, P109, DOI 10.1109/MCE.2021.3137790
   Mansour RF, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17043-z
   Martínez-González JU, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04037-6
   Marwah GPK, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14255-1
   Milford M, 2020, NAT MACH INTELL, V2, P661, DOI 10.1038/s42256-020-00245-3
   Olaverri-Monreal C, 2020, NAT ELECTRON, V3, P292, DOI 10.1038/s41928-020-0434-8
   Orr I, 2021, NAT MACH INTELL, V3, DOI 10.1038/s42256-020-00288-6
   Pedretti G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05480-0
   Priyan M. K., 2019, International Journal of Advanced Intelligence Paradigms, V12, P98
   Qian C, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30377-6
   Ramkumar MP, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108037
   Riboni A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12509-6
   Rodrigues SP, 2021, NAT PHOTONICS, V15, P66, DOI 10.1038/s41566-020-00736-0
   Salmela L, 2021, NAT MACH INTELL, V3, P344, DOI 10.1038/s42256-021-00297-z
   Sasaki M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81546-4
   Schuman CD, 2022, NAT COMPUT SCI, V2, P10, DOI 10.1038/s43588-021-00184-y
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shi BH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14355-y
   Shi WX, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00809-5
   Shin JH, 2022, NPJ FLEX ELECTRON, V6, DOI 10.1038/s41528-022-00164-w
   Singh PK, 2021, Arxiv, DOI arXiv:2112.14078
   Song QY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14737-2
   Taddeo M, 2019, NAT MACH INTELL, V1, P557, DOI 10.1038/s42256-019-0109-1
   Tang XF, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09156-2
   Tian DX, 2016, SCI REP-UK, V6, DOI 10.1038/srep23048
   Vazirani AA, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0211-0
   Wang LL, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14438-w
   Wang W, 2021, EUR J REMOTE SENS, V54, P65, DOI 10.1080/22797254.2020.1755998
   Wang Z, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29856-7
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Woods W, 2019, NAT MACH INTELL, V1, P508, DOI 10.1038/s42256-019-0104-6
   Wu C., 2021, 2017 IEEE INT C PROG, V18, piii, DOI 10.23919/JCC.2021.9495349
   Wurman PR, 2022, NATURE, V602, P223, DOI 10.1038/s41586-021-04357-7
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Xue JW, 2022, NAT MACH INTELL, V4, P246, DOI 10.1038/s42256-022-00462-y
   Zacharaki A, 2019, P 2019 1 INT C SOC A, P1, DOI [DOI 10.1109/SA47457.2019.8938044, 10.1109/SA47457.2019.8938044]
   Zador AM, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11786-6
   Zhang DH, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22696-x
   Zhou ZL, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08931-6
   Zhuo M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01638-z
NR 61
TC 9
Z9 9
U1 10
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 21
PY 2023
DI 10.1007/s11042-023-14375-4
EA JAN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8S1OV
UT WOS:000928356500001
DA 2024-07-18
ER

PT J
AU Dhaka, P
   Nagpal, B
AF Dhaka, Priyanka
   Nagpal, Bharti
TI WoM-based deep BiLSTM: smart disease prediction model using WoM-based
   deep BiLSTM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep BiLSTM; WoM optimization; Heart disease prediction; ECC based
   Diffi-Huffman algorithm
ID SYSTEM; CLOUD; ARCHITECTURE
AB Diagnosis of cardiovascular disease has been significant due to the increased number of people affected by cardiovascular diseases. Though various methods were developed in classifying the diseases and ensuring the privacy for secure data transfer, most of the existing methods suffer from accurate decision making. Hence, this research tends to introduce a well-suited disease prediction model with the help of an improved deep Bidirectional Long Short Term Memory (Deep BiLSTM). The hyper-parameters related to the optimized deep BiLSTM classifier are tuned by the proposed optimization named Whale-on-Marine optimization (WoM) algorithm. The research-based on the developed deep BiLSTM classifier for heart disease utilizes the Elliptic Curve Cryptography (ECC) dependent Diffi-Huffman algorithm to ensure secure data transmission in the network. The effective decision making and secure data transfer are performed using the WoM-based deep BiLSTM classifier, where the WoM optimization reflects the characteristics of marine and Whale to determine the space between the prey and the predators, which improves the exploitation integration and exploitation tendencies. The performance metrics reveal that the proposed optimization based on deep BiLSTM effectively predicts heart diseases. The optimized deep BiLSTM classifier achieves a sensitivity of 97.93%, specificity of 97.52%, F-Measure of 97.658% and accuracy of 97.53% for the training percentage in Statlog, Cleveland, and Hungary database.
C1 [Dhaka, Priyanka] Guru Gobind Singh Indraprastha Univ, USICT, Maharaja Surajmal Inst, Delhi, India.
   [Nagpal, Bharti] Netaji Subhash Univ Technol NSUT, Comp Sci & Engn, East Campus AIACT & R, Delhi, India.
C3 GGS Indraprastha University; Maharaja Surajmal Institute of Technology;
   Netaji Subhas University of Technology
RP Dhaka, P (corresponding author), Guru Gobind Singh Indraprastha Univ, USICT, Maharaja Surajmal Inst, Delhi, India.
EM priyankadhaka744@gmail.com
CR Aieshwarya B., 2017, International Journal on Emerging Trends in Technology, V1, P8274
   Albahri AS, 2021, HEALTH TECHNOL-GER, V11, P1013, DOI 10.1007/s12553-021-00579-x
   Amin MS, 2019, TELEMAT INFORM, V36, P82, DOI 10.1016/j.tele.2018.11.007
   [Anonymous], KAGGLE DATASET HEART
   Basheer S, 2021, SOFT COMPUT, V25, P12145, DOI 10.1007/s00500-021-05865-4
   Devi VA, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6132
   Durairaj M., 2015, Int. J. Sci. Technol. Res, V4, P235
   Gavhane Aditi, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1275, DOI 10.1109/ICECA.2018.8474922
   Gupta PK, 2017, MULTIMED TOOLS APPL, V76, P18489, DOI 10.1007/s11042-016-4050-6
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang MJ, 2007, EXPERT SYST APPL, V32, P856, DOI 10.1016/j.eswa.2006.01.038
   Ishaq A, 2021, IEEE ACCESS, V9, P39707, DOI 10.1109/ACCESS.2021.3064084
   Jabeen F, 2019, PEER PEER NETW APPL, V12, P1263, DOI 10.1007/s12083-019-00733-3
   Jangra M., 2017, COMMUNICATION COMPUT, P177
   Jangra M, 2023, COMPLEX INTELL SYST, V9, P2685, DOI 10.1007/s40747-021-00371-4
   Khan MA, 2020, IEEE ACCESS, V8, P34717, DOI 10.1109/ACCESS.2020.2974687
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Kwon JM, 2018, J AM HEART ASSOC, V7, DOI 10.1161/JAHA.118.008678
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Nayeemuddin Z., 2019, International Journal of Recent Technology and Engineering (IJRTE), V8, P1
   Ordonez C, 2006, IEEE T INF TECHNOL B, V10, P334, DOI 10.1109/TITB.2006.864475
   Patil A. B. C., 2017, International Journal of Advanced Research in Computer and Communication Engineering, V6, P24
   Rani Pooja, 2021, Journal of Reliable Intelligent Environments, V7, P263, DOI 10.1007/s40860-021-00133-6
   Rao SN, 2018, INDIAN HEART J, V70, P533, DOI 10.1016/j.ihj.2017.11.022
   Rustam F, 2022, MULTIMED TOOLS APPL, V81, P31929, DOI 10.1007/s11042-022-12897-x
   Safa M, 2021, MATER TODAY
   Sarmah SS, 2020, IEEE ACCESS, V8, P135784, DOI 10.1109/ACCESS.2020.3007561
   Satyender, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12897
   Verma P, 2018, J AMB INTEL HUM COMP, V9, P1293, DOI 10.1007/s12652-017-0520-6
NR 30
TC 6
Z9 6
U1 11
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25061
EP 25082
DI 10.1007/s11042-023-14336-x
EA JAN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000917963300001
DA 2024-07-18
ER

PT J
AU Sultan, B
   ArifWani, M
AF Sultan, Bisma
   ArifWani, M.
TI A new framework for analyzing color models with generative adversarial
   networks for improved steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; GAN-based steganography; Color models in steganography;
   Deep learning in steganography
ID STEGANALYSIS
AB Steganography algorithms are designed by human experts and use rule-based methods to hide the secret data inside a cover medium. Recently, this process has been automated by using Generative Adversarial Networks. However, Generative Adversarial Networks based steganography has certain limitations. These algorithms may not generate steganographic images that are real enough to fool the intruder. Security of steganography degrades as embedding capacity is increased. A new framework for improved steganography based on deep learning is proposed in this paper. The new framework uses color models with Generative Adversarial Networks. Popular color models such as HSV, YCrCb, YDbDr, CIE-XYZ, YIQ, HED, and YUV are analyzed. The proposed framework helps to identify the best color model with Generative Adversarial Networks based steganography. The quality of steganographic images is assessed with three metrics: capacity, security, and invisibility. Extensive experimentation has been carried out with the CelebA dataset which has more than 200 K samples to assess the effectiveness of the proposed framework. The results show that compared with the RGB and other color models, the CIE-XYZ model produces the best results with Generative Adversarial Networks for steganography.The results further show that the proposed framework improves the security of steganography even when the embedding capacity is increased.
C1 [Sultan, Bisma] Univ Kashmir, Postgrad Dept Comp Sci, Hazaratal, Srinagar 190006, India.
   [ArifWani, M.] Univ Kashmir, Postgrad Dept Comp Sci, Hazaratbal, Srinagar 190006, India.
C3 University of Kashmir; University of Kashmir
RP Sultan, B (corresponding author), Univ Kashmir, Postgrad Dept Comp Sci, Hazaratal, Srinagar 190006, India.
EM bismasultan4@gmail.com
CR Bachrach M, 2013, MULTIMEDIA SECURITY: WATERMARKING, STEGANOGRAPHY, AND FORENSICS, P201
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Hayes J, 2017, ADV NEUR IN, V30
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P40993, DOI 10.1007/s11042-022-13001-z
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P35733, DOI 10.1007/s11042-021-11126-1
   Ker AD, 2013, 1 IH MMSEC WOR
   Lerch-Hostalot D, 2016, ENG APPL ARTIF INTEL, V50, P45, DOI 10.1016/j.engappai.2015.12.013
   Liu Ming-ming, 2018, Journal of Applied Sciences - Electronics and Information Engineering, V36, P371, DOI 10.3969/j.issn.0255-8297.2018.02.015
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Ma S, 2019, MULTIMED TOOLS APPL, V78, P32503, DOI 10.1007/s11042-019-07994-3
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Radford A, 2016, 4 INT C LEARN REPRES, P276
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi HC, 2019, LECT NOTES COMPUT SC, V11537, P31, DOI 10.1007/978-3-030-22741-8_3
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Sultan Bisma, 2022, 2022 9th International Conference on Computing for Sustainable Global Development (INDIACom), P454, DOI 10.23919/INDIACom54597.2022.9763273
   Swain G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang Z, 2018, SSTEGAN SELF LEARNI, V1302
   Wani MA, ADV DEEP LEARNIN, P149
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Yang JY, 2018, AER ADV ENG RES, V127, P1
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102910
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
   Zhang Z, 2020, TSINGHUA SCI TECHNOL, V25, P516, DOI 10.26599/TST.2019.9010027
NR 39
TC 1
Z9 1
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19577
EP 19590
DI 10.1007/s11042-023-14348-7
EA JAN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000911268400002
DA 2024-07-18
ER

PT J
AU Zhang, L
   Chang, MH
   Chen, R
AF Zhang, Lei
   Chang, Minhui
   Chen, Rui
TI Image inpainting based on sparse representation using self-similar joint
   sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Sparse representation; Self-similar; Joint sparse
   coding
ID ALGORITHM; REMOVAL
AB In order to improve the sparse coding ability of over-complete dictionary and take advantage of the similarity between damaged pixels and their neighbors, we propose an inpainting method based on sparse representation using self-similar joint sparse coding. First, we perform singular value decomposition on the gradient vector of the image patches, and then divide the image patches into three categories: smooth patches, edge patches and texture patches according to the relationship between the primary direction and the secondary direction. Second, we use the KSVD method to train these three types of image patches respectively, and obtain three over-complete dictionaries that adapt to different local features. Third, we define a non-local self-similar matching function and use it to search for the most similar image patch to the current patch in the target region, and then use the similar patch and the current patch for joint sparse coding. Finally, we use the calculated sparse coding and the corresponding over-complete dictionary to reconstruct the current patch. A series of experimental results show that the self-similar joint sparse coding we proposed can not only improve the restoration effect of sparse representation methods to a certain extent, but also has good adaptability and can be combined with other sparse representation methods to improve their restoration effect.
C1 [Zhang, Lei; Chang, Minhui] Yuncheng Univ, Sch Math & Informat Technol, Yuncheng 044000, Peoples R China.
   [Chen, Rui] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450001, Peoples R China.
C3 Yuncheng University; Zhengzhou University of Light Industry
RP Zhang, L (corresponding author), Yuncheng Univ, Sch Math & Informat Technol, Yuncheng 044000, Peoples R China.
EM zhanglei@ycu.edu.cn
FU National Natural Science Foundation of China [61703363]; Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi Province [2020 L0572]; Scientific Research Project of Yuncheng
   University [XK-2018034, CY-2019025, YQ-2020021]; Industrial Science and
   Technology Research Project of Henan Province [202102210387,
   212102210418]; Natural Science Foundation Project of Henan Province
   [222300420582]
FX The research is supported in part by National Natural Science Foundation
   of China (Grant: 61703363), in part by Scientific and Technological
   Innovation Programs of Higher Education Institutions in Shanxi Province
   (Grant: 2020 L0572), in part by Scientific Research Project of Yuncheng
   University (Grant: XK-2018034, CY-2019025, YQ-2020021), in part by the
   Industrial Science and Technology Research Project of Henan Province
   (Grant: 202102210387, 212102210418), in part by the Natural Science
   Foundation Project of Henan Province (Grant: 222300420582).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bai H, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103426
   Barba-J L, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103096
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chen YX, 2022, J ASTHMA, V59, P890, DOI 10.1080/02770903.2021.1892752
   Cheng KY, 2021, CHINESE J ELECTRON, V30, P1103, DOI 10.1049/cje.2021.08.006
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dong XH, 2019, IEEE T IND ELECTRON, V66, P4777, DOI 10.1109/TIE.2018.2866043
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Gapon N, 2021, PROC SPIE, V11785, DOI 10.1117/12.2594476
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jam J, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103147
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P29303, DOI 10.1007/s11042-018-5959-8
   Kaur Amreen, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P778, DOI 10.1109/ICIRCA48905.2020.9182917
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Kumar BVR, 2019, COMPUT APPL MATH, V38, DOI 10.1007/s40314-019-0768-x
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li RJ, 2020, IEEE ACCESS, V8, P60515, DOI 10.1109/ACCESS.2020.2983107
   [李月龙 Li Yuelong], 2021, [计算机学报, Chinese Journal of Computers], V44, P2295
   Liu HS, 2021, IEEE PHOTONICS J, V13, DOI [10.1109/JPHOT.2021.3056574, 10.1109/jphot.2021.3056574]
   Mirza M, 2014, COMPUT THERM SCI, p2672?2680
   Mullah HU, 2020, IET IMAGE PROCESS, V14, P2833, DOI 10.1049/iet-ipr.2019.0714
   Newson A, 2017, IMAGE PROCESS ON LIN, V7, P373, DOI 10.5201/ipol.2017.189
   Özkaya U, 2021, GEOMATIK, V6, P61, DOI 10.29128/geomatik.678354
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sreelakshmy IJ, 2021, J INF KNOWL MANAG, V20, DOI 10.1142/S0219649221500398
   Sun M, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105868
   Torrado-Carvajal A, 2021, ANN BIOMED ENG, V49, P345, DOI 10.1007/s10439-020-02556-3
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yao F, 2019, CLUSTER COMPUT, V22, P13683, DOI 10.1007/s10586-018-2068-4
   Zhang L, 2020, IEEE ACCESS, V8, P94357, DOI 10.1109/ACCESS.2020.2995700
NR 35
TC 1
Z9 2
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20215
EP 20231
DI 10.1007/s11042-023-14337-w
EA JAN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000911268400001
DA 2024-07-18
ER

PT J
AU Zhu, CY
   Zhao, WH
   Lian, H
AF Zhu, Chunyang
   Zhao, Weihua
   Lian, Heng
TI Image recognition and classification with HOG based on nonlinear support
   tensor machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CANDECOMP/PARAFAC decomposition; Histogram of oriented gradient; Support
   tensor machine; Polynomial splines
ID REGRESSION
AB Spatial structure information is very important in image analysis algorithms. Traditional machine learning methods based on vectorization strategies often ignore the spatial information of the original data, resulting in low image recognition and classification accuracy. Different from the vector representation, the tensor representation can preserve spatial structure information in still images. Histogram of oriented gradient (HOG) is a feature descriptor that generates histograms by calculating the gradient amplitude and direction of the local area of the image. This paper proposes a new support tensor machine learning method based on tensor space, where the HOG method in the form of tensors is used to extract the features of the image data. Borrowing the broadcasting idea, we investigate a flexible and concise nonparametric tensor model to capture the nonlinear spatial information in HOG tensor. By the polynomial spline approximation to nonparametric functions and low-rank CP decomposition, a new spline support tensor classification algorithm is studied with the alternating iterative approach under the framework of original support vector machine. The experimental result shows the superior performance of the proposed model compared with the existing methods.
C1 [Zhu, Chunyang; Zhao, Weihua] Nantong Univ, Sch Sci, Nantong 226019, Jiangsu, Peoples R China.
   [Lian, Heng] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
C3 Nantong University; City University of Hong Kong
RP Zhao, WH (corresponding author), Nantong Univ, Sch Sci, Nantong 226019, Jiangsu, Peoples R China.
EM zhaowhstat@163.com
FU National Social Science Fund; National Natural Science Fund [22BTJ025]; 
   [11871411]
FX This work was supported in part by the National Social Science Fund
   (22BTJ025) and in part by the National Natural Science Fund (11871411).
CR CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chen C, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108337
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dang YJ, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2004-9
   Hao ZF, 2013, IEEE T IMAGE PROCESS, V22, P2911, DOI 10.1109/TIP.2013.2253485
   Harshman R.A., 1970, UCLA Working Papers in Phonetics, V16, P84, DOI DOI 10.1134/S0036023613040165
   He LF, 2017, PROC CVPR IEEE, P6846, DOI 10.1109/CVPR.2017.724
   He Lifang, 2014, Proc SIAM Int Conf Data Min, V2014, P127
   Jia XK, 2018, 2018 IEEE/ACIS 16TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATION (SERA), P79, DOI 10.1109/SERA.2018.8477214
   Jing L., 2013, OP ITS APPL ENG TECH, P1
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I
   Kolda T. G., 2006, Multilinear operators for higher-order decompositions, DOI 10.2172/923081
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kossaifi J, 2020, J MACH LEARN RES, V21
   Liu JJ, 2020, IEEE T GEOSCI REMOTE, V58, P1244, DOI 10.1109/TGRS.2019.2944989
   Liu YF, 2011, J AM STAT ASSOC, V106, P166, DOI 10.1198/jasa.2011.tm10319
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Ma G., 2016, Proceedings_of_the_2016_ SIAM_International_Conference_on_Data_Mining, P819, DOI DOI 10.1137/1.9781611974348.92
   MOCKS J, 1988, IEEE T BIO-MED ENG, V35, P482, DOI 10.1109/10.2119
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Reyes J, 2020, ARXIV
   Schölkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27
   Signoretto M, 2011, NEURAL NETWORKS, V24, P861, DOI 10.1016/j.neunet.2011.05.011
   Tao DC, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P450
   Vo T, 2015, NEUROCOMPUTING, V165, P38, DOI 10.1016/j.neucom.2014.06.093
   Wang BX, 2019, TECHNOMETRICS, V61, P396, DOI 10.1080/00401706.2018.1529629
   Wang BX, 2016, J COMPUT GRAPH STAT, V25, P826, DOI 10.1080/10618600.2015.1049700
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Zhang JG, 2018, MULTIMED TOOLS APPL, V77, P29213, DOI 10.1007/s11042-018-5916-6
   Zhang JG, 2016, J VIS COMMUN IMAGE R, V41, P260, DOI 10.1016/j.jvcir.2016.10.006
   Zhang JG, 2016, MULTIMEDIA SYST, V22, P343, DOI 10.1007/s00530-015-0464-7
   Zhao QB, 2013, INT CONF ACOUST SPEE, P3577, DOI 10.1109/ICASSP.2013.6638324
   Zhao XB, 2017, J INTELL FUZZY SYST, V33, P2145, DOI 10.3233/JIFS-162245
   Zheng L, 2020, TRANSPORTMETRICA B, V8, P182, DOI 10.1080/21680566.2020.1732247
   Zhou Y, 2020, arXiv
NR 39
TC 1
Z9 1
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20119
EP 20138
DI 10.1007/s11042-022-14320-x
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000903837100001
DA 2024-07-18
ER

PT J
AU Mebtouche, NE
   Baha, N
AF Mebtouche, Naoual El-Djouher
   Baha, Nadia
TI Robust UAV detection based on saliency cues and magnified features on
   thermal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAV detection; Thermal images; Saliency; Magnifier; Deep neural network
ID VISION-BASED DETECTION; FUSION; TRACKING
AB Recent advances in the development of unmanned aerial vehicles (UAV), also known as drones, raised serious security concerns in critical locations. It is, therefore, necessary to design robust systems that can detect drones in any situation. In this paper, we present a novel approach for robust and accurate drone detection in different lighting conditions from thermal images based on deep learning. The main contributions of this paper consist of: First, the introduction of a thermal saliency map as a new feature to adapt deep learning models to learn features from thermal sources. Second, the introduction of a novel module called Magnifying Small Objects (MSO) as a guide for the deep Neural network to improve the detection and localization of small drones, for robust drone detection. Third, a new data augmentation strategy is proposed to generate novel drone images from different sources. Comprehensive experiments are conducted on University of Southern California (USC) thermal UAV dataset and Drone Detection Dataset. A comparative evaluation of the obtained results with state-of-the-art methods is presented. The experimental results show the robustness and high precision of our approach for drone detection.
C1 [Mebtouche, Naoual El-Djouher; Baha, Nadia] Univ Sci & Technol Houari Boumedienne, Comp Sci Dept, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Mebtouche, NE (corresponding author), Univ Sci & Technol Houari Boumedienne, Comp Sci Dept, Algiers, Algeria.
EM nmebtouche@usthb.dz; nbahatouzene@usthb.dz
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Aker C, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2017.8078539
   Andrasi P, 2017, TRANSP RES PROC, V28, P183, DOI 10.1016/j.trpro.2017.12.184
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Carrio A, 2017, J INTELL ROBOT SYST, V88, P583, DOI 10.1007/s10846-017-0529-2
   Castellano Giovanna, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12538), P588, DOI 10.1007/978-3-030-66823-5_35
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Coluccia A, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/AVSS.2019.8909876
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Diwakar M, 2021, MATER TODAY-PROC, V37, P3411, DOI 10.1016/j.matpr.2020.09.278
   Dumitrescu C, 2020, ADV INTELL SYST, V1050, P129, DOI 10.1007/978-3-030-30440-9_13
   Ganti SR, 2016, INT CONF UNMAN AIRCR, P1254, DOI 10.1109/ICUAS.2016.7502513
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Gökçe F, 2015, SENSORS-BASEL, V15, P23805, DOI 10.3390/s150923805
   Grana C, 2010, IEEE T IMAGE PROCESS, V19, P1596, DOI 10.1109/TIP.2010.2044963
   Herrmann C, 2018, PROC SPIE, V10643, DOI 10.1117/12.2304400
   Hommes A, 2016, PROC SPIE, V9997, DOI 10.1117/12.2242180
   Jindal M, 2021, MATER TODAY-PROC, V37, P2952, DOI 10.1016/j.matpr.2020.08.704
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Liu H., 2018, IOP Conference Series: Materials Science and Engineering, V322
   Mebtouche NED, 2022, ADV INTELL SYST COMP, V1418, P529, DOI 10.1007/978-3-030-90639-9_43
   Mejias L, 2010, IEEE INT C INT ROBOT, P87, DOI 10.1109/IROS.2010.5651028
   Park J, 2017, INT C CONTR AUTOMAT, P696, DOI 10.23919/ICCAS.2017.8204318
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Ruder S., 2016, ARXIV
   Saqib M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/AVSS.2017.8078541
   Schumann A, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Seidaliyeva U, 2020, 2020 FOURTH IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2020), P465, DOI 10.1109/IRC.2020.00088
   Seidaliyeva U, 2020, 2020 FOURTH IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2020), P490, DOI 10.1109/IRC.2020.00093
   Seidaliyeva U, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143856
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Svanström F, 2021, INT C PATT RECOG, P7265, DOI 10.1109/ICPR48806.2021.9413241
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Ünel FÖ, 2019, IEEE COMPUT SOC CONF, P582, DOI 10.1109/CVPRW.2019.00084
   Unlu Eren, 2019, IPSJ Transactions on Computer Vision and Applications, V11, DOI 10.1186/s41074-019-0059-x
   Unlu E., 2018, Electron. Imaging, V2018, p128
   UNLU E, 2017, 14 IEEE INT C ADV VI, P1
   Wang Y, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2018.30
   Wu M., 2018, Machine Learning and Intelligent Communications, P22, DOI DOI 10.1007/978-3-030-00557-3_3
   Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 44
TC 1
Z9 1
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20039
EP 20058
DI 10.1007/s11042-022-14271-3
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000896363400003
DA 2024-07-18
ER

PT J
AU Marullo, G
   Tanzi, L
   Piazzolla, P
   Vezzetti, E
AF Marullo, Giorgia
   Tanzi, Leonardo
   Piazzolla, Pietro
   Vezzetti, Enrico
TI 6D object position estimation from 2D images: a literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer vision; 6D position estimation; Deep learning; RGB Input
ID POSE ESTIMATION; NETWORK
AB The 6D pose estimation of an object from an image is a central problem in many domains of Computer Vision (CV) and researchers have struggled with this issue for several years. Traditional pose estimation methods (1) leveraged on geometrical approaches, exploiting manually annotated local features, or (2) relied on 2D object representations from different points of view and their comparisons with the original image. The two methods mentioned above are also known as Feature-based and Template-based, respectively. With the diffusion of Deep Learning (DL), new Learning-based strategies have been introduced to achieve the 6D pose estimation, improving traditional methods by involving Convolutional Neural Networks (CNN). This review analyzed techniques belonging to different research fields and classified them into three main categories: Template-based methods, Feature-based methods, and Learning-Based methods. In recent years, the research mainly focused on Learning-based methods, which allow the training of a neural network tailored for a specific task. For this reason, most of the analyzed methods belong to this category, and they have been in turn classified into three sub-categories: Bounding box prediction and Perspective-n-Point (PnP) algorithm-based methods, Classification-based methods, and Regression-based methods. This review aims to provide a general overview of the latest 6D pose recovery methods to underline the pros and cons and highlight the best-performing techniques for each group. The main goal is to supply the readers with helpful guidelines for the implementation of performing applications even under challenging circumstances such as auto-occlusions, symmetries, occlusions between multiple objects, and bad lighting conditions.
C1 [Marullo, Giorgia; Tanzi, Leonardo; Piazzolla, Pietro; Vezzetti, Enrico] Polytech Univ Turin, Dept Management Prod & Design Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Vezzetti, E (corresponding author), Polytech Univ Turin, Dept Management Prod & Design Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM enrico.vezzetti@polito.it
RI Piazzolla, Pietro/I-5441-2016
OI Piazzolla, Pietro/0000-0003-2288-8410; VEZZETTI,
   Enrico/0000-0001-8910-7020; Marullo, Giorgia/0000-0002-2359-4409; Tanzi,
   Leonardo/0000-0002-8813-6388
FU Politecnico di Torino within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Torino within the
   CRUI-CARE Agreement.
CR Cao Z, 2016, IEEE INT CONF ROBOT, P2441, DOI 10.1109/ICRA.2016.7487396
   Capellen C, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P162, DOI 10.5220/0008990901620172
   Chen C., 2019, ARXIV
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Corona E, 2018, IEEE INT C INT ROBOT, P7215, DOI 10.1109/IROS.2018.8594282
   Dabbour A, 2020, COMPUT SCI-AGH, V21, P97, DOI 10.7494/csci.2020.21.1.3426
   Do T.-T., 2018, ARXIV
   Hara K, 2017, ARXIV
   Hu YL, 2021, PROC CVPR IEEE, P15865, DOI 10.1109/CVPR46437.2021.01561
   Hu YL, 2020, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR42600.2020.00300
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Josifovski J, 2018, IEEE INT C INT ROBOT, P6269, DOI 10.1109/IROS.2018.8594379
   Kastner L, 2020, MARKERLESS DEEP LEAR, DOI [10.1109/UR49135.2020.9144789, DOI 10.1109/UR49135.2020.9144789]
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Konishi Y, 2016, LECT NOTES COMPUT SC, V9905, P398, DOI 10.1007/978-3-319-46448-0_24
   Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214
   Kundu JN, 2019, LECT NOTES COMPUT SC, V11131, P298, DOI 10.1007/978-3-030-11015-4_23
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li Z., 2020, ARXIV
   Li ZG, 2019, IEEE I CONF COMP VIS, P7677, DOI 10.1109/ICCV.2019.00777
   Liu FC, 2019, NEUROCOMPUTING, V337, P15, DOI 10.1016/j.neucom.2018.12.061
   Liu J.Z, 2019, ARXIV
   Liu J, 2020, IEEE SENS J, V20, P11812, DOI 10.1109/JSEN.2019.2946279
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YP, 2019, IEEE T MULTIMEDIA, V21, P2776, DOI 10.1109/TMM.2019.2913321
   Mahendran S, 2017, IEEE COMPUT SOC CONF, P494, DOI 10.1109/CVPRW.2017.73
   Massa F, 2016, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2016.648
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Muñoz E, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4062, DOI 10.1109/IROS.2016.7759598
   Muoz E, 2016, IEEE INT CONF ROBOT, P5623, DOI 10.1109/ICRA.2016.7487781
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Olivetti EC, 2020, LECT N MECH ENG, P665, DOI 10.1007/978-3-030-31154-4_56
   Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776
   Patil AV, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927702029
   Pavlakos G., 2017, 6 DOF OBJECT POSE SE, DOI [10.1109/ICRA.2017.7989233, DOI 10.1109/ICRA.2017.7989233]
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Poirson P, 2016, INT CONF 3D VISION, P676, DOI 10.1109/3DV.2016.78
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rambach J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P164, DOI 10.1109/ISMAR-Adjunct.2018.00058
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sahin C, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103898
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Su YZ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010300
   Sundermeyer M, 2020, INT J COMPUT VISION, V128, P714, DOI 10.1007/s11263-019-01243-8
   Tanzi L, 2021, INT J COMPUT ASS RAD, V16, P1435, DOI 10.1007/s11548-021-02432-y
   Tanzi L, 2020, EUR J RADIOL, V133, DOI 10.1016/j.ejrad.2020.109373
   Tanzi L, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2136
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23
   Trabelsi A, 2021, IEEE WINT CONF APPL, P2381, DOI 10.1109/WACV48630.2021.00243
   Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266
   Wang G, 2021, PROC CVPR IEEE, P16606, DOI 10.1109/CVPR46437.2021.01634
   Wang Y., 2019, 2019 IEEE INT C ROB, P284
   Wanqing Zhao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14122, DOI 10.1109/CVPR42600.2020.01414
   Wu J, 2018, IEEE INT C INT ROBOT, P6798, DOI 10.1109/IROS.2018.8593662
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiaocan Li, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2310, DOI 10.1109/ROBIO49542.2019.8961408
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Yang ZX, 2021, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR46437.2021.00390
   You JK, 2021, IEEE ACCESS, V9, P18597, DOI 10.1109/ACCESS.2021.3054493
   Zakharov S, 2019, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2019.00203
   Zhang X, 2019, IMAGE VISION COMPUT, V89, P1, DOI 10.1016/j.imavis.2019.06.013
   Zhao WQ, 2020, NEUROCOMPUTING, V389, P9, DOI 10.1016/j.neucom.2019.12.108
   Zhao ZF, 2018, ACSR ADV COMPUT, V78, P1
   Zhu YZ, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116268
   Zou WB, 2021, IEEE T CONSUM ELECTR, V67, P87, DOI 10.1109/TCE.2021.3057137
   Zuo GY, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207286
NR 72
TC 10
Z9 10
U1 21
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24605
EP 24643
DI 10.1007/s11042-022-14213-z
EA NOV 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000889032600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Islam, SM
   Joardar, S
   Sekh, AA
AF Islam, Sk Maidul
   Joardar, Subhankar
   Sekh, Arif Ahmed
TI DSSN: dual shallow Siamese network for fashion image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fashion retrieval; Siamese network; Weighted late fusion
ID CONVOLUTIONAL NETWORK; NEURAL-NETWORK; FUSION; CLASSIFICATION
AB Image retrieval is a way to search similar images from a given query image. The method successfully applied to different fashion image retrieval over different garments and footwear. However, research over complex fashion products such as ornaments have not got much momentum due to the complex nature of similarity and unavailability of suitable datasets. In this paper we have proposed a Dual Shallow Siamese Network (DSSN) for the task. The model has two identical Siamese networks and takes the same images as input but in a different representation. One subnetwork takes input as RGB color images and the other as identical segmented images. First, the networks are trained using positive and negative image pairs. Next, the trained model is used to find the difference between gallery and query images. The similarity score of the Siamese networks are then fused using weighted averaging. The method is applied on two public datasets, namely, RingFIR (earring dataset) and UT-Zap50K (footwear dataset). We have compared the retrieval accuracy of our method with other state-of-the-art image retrieval methods. The result shows that our method outperforms state-of-the-art methods. The source code and dataset is available publicly (https://github.com/skarifahmed/DSSN).
C1 [Islam, Sk Maidul] Global Inst Sci & Technol, Purba Medinipur, India.
   [Joardar, Subhankar] Haldia Inst Technol, Purba Medinipur, India.
   [Sekh, Arif Ahmed] XIM Univ, Bhubaneswar, India.
C3 Haldia Institute of Technology
RP Islam, SM (corresponding author), Global Inst Sci & Technol, Purba Medinipur, India.
EM iammaidul@gmail.com; subhankarranchi@yahoo.co.in; skarifahmed@gmail.com
RI Joardar, subhankar/AAD-5396-2022; Sk, Arif Ahmed/U-5120-2019
OI Joardar, subhankar/0000-0002-1542-3757; Sk, Arif
   Ahmed/0000-0003-0706-2565; Islam, Sk Maidul/0000-0003-2470-1269
CR Ak KE, 2019, IEEE INT CONF COMP V, P3121, DOI 10.1109/ICCVW.2019.00379
   Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   Ak KE, 2018, PATTERN RECOGN LETT, V112, P212, DOI 10.1016/j.patrec.2018.07.019
   Alsmadi MK, 2020, ARAB J SCI ENG, V45, P3317, DOI 10.1007/s13369-020-04384-y
   [Anonymous], 2015, P 8 INT C MOB MULT C
   Beaupre DA, 2019, IEEE COMPUT SOC CONF, P862, DOI 10.1109/CVPRW.2019.00115
   Bibi R, 2020, J AMB INTEL HUM COMP, V11, P5629, DOI 10.1007/s12652-020-01923-1
   Caltagirone L, 2019, ROBOT AUTON SYST, V111, P125, DOI 10.1016/j.robot.2018.11.002
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Cheng ZQ, 2017, PROC CVPR IEEE, P4169, DOI 10.1109/CVPR.2017.444
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Chung Y.A., 2017, ARXIV
   Corbière C, 2017, IEEE INT CONF COMP V, P2268, DOI 10.1109/ICCVW.2017.266
   Dong H., 2020, CVPR, P8120
   Erkut U., 2019, PROC 1 INT INFORMAT, P1, DOI DOI 10.1109/UBMYK48245.2019.8965513
   Gajic B, 2018, IEEE COMPUT SOC CONF, P1950, DOI 10.1109/CVPRW.2018.00243
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   GHOJOGH B, 2020, IEEE IJCNN
   Gu XL, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102276
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   Ha I, 2018, BUILD ENVIRON, V140, P23, DOI 10.1016/j.buildenv.2018.05.026
   Hamreras S, 2020, INTEGR COMPUT-AID E, V27, P317, DOI 10.3233/ICA-200625
   Hidayati SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P438, DOI 10.1145/3240508.3240546
   Hsiao SC, 2019, PROCEDIA COMPUT SCI, V159, P1863, DOI 10.1016/j.procs.2019.09.358
   Huang CL, 1998, IMAGE VISION COMPUT, V16, P149, DOI 10.1016/S0262-8856(97)00062-0
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Huang L, 2022, INT J MENT HEALTH AD, V20, P789, DOI 10.1007/s11469-020-00404-y
   Ilhan HO, 2020, MED BIOL ENG COMPUT, V58, P1047, DOI 10.1007/s11517-019-02101-y
   Islam Sk Maidul, 2021, RingFIR: A large volume earring dataset for fashion image retrieval, P100
   Islam SM., 2021, SN COMPUT SCI, V2, P1, DOI [10.1007/s42979-021-00734-1, DOI 10.1007/S42979-021-00734-1]
   Jaradat S, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P407, DOI 10.1145/3109859.3109861
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Junli Li, 2004, Proceedings. Third International Conference on Image and Graphics, P160
   Kalaiarasi G, 2019, CLUSTER COMPUT, V22, P11997, DOI 10.1007/s10586-017-1539-3
   Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30
   Karczmarek P, 2018, INT J FUZZY SYST, V20, P1047, DOI 10.1007/s40815-017-0355-5
   Khurana T, 2018, IEEE IMAGE PROC, P2102, DOI 10.1109/ICIP.2018.8451281
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kuang ZH, 2019, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2019.00316
   Lang YN, 2020, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR42600.2020.00267
   Lehmann TM, 2004, METHOD INFORM MED, V43, P354
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li ZM, 2016, INT C PATT RECOG, P2912, DOI 10.1109/ICPR.2016.7900079
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liao QX, 2016, Adv Inform Managemen, P1670, DOI 10.1109/IMCEC.2016.7867501
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318
   Liu GH, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107926
   Liu KH, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P313, DOI 10.1145/2911996.2912058
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Long FH, 2003, SIG COM TEC, P1
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663
   Miao YW, 2020, IEEE ACCESS, V8, P142669, DOI 10.1109/ACCESS.2020.3013631
   Nanni L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051573
   Pandey N, 2020, NEUROCOMPUTING, V414, P356, DOI 10.1016/j.neucom.2020.07.092
   Pelka O, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206229
   Peng LN, 2020, IEEE T VEH TECHNOL, V69, P1091, DOI 10.1109/TVT.2019.2950670
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Qingqing Tu, 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P479, DOI 10.1109/ICCCAS.2010.5581949
   Saxen F, 2019, INT SYMP IMAGE SIG, P176, DOI 10.1109/ISPA.2019.8868585
   Sharma P, 2003, PROCEEDINGS EC-VIP-MC 2003, VOLS 1 AND 2, P423
   Shi M., 2020, ARXIV
   Su HB, 2021, IEEE T CIRC SYST VID, V31, P3254, DOI 10.1109/TCSVT.2020.3034981
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   TERBRAAK CJF, 1986, VEGETATIO, V65, P3
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Thyagharajan KK, 2018, ADV ELECTR COMPUT EN, V18, P87, DOI 10.4316/AECE.2018.03012
   Verma S, 2018, IEEE IMAGE PROC, P500, DOI 10.1109/ICIP.2018.8451164
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wang X, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P7, DOI 10.1145/2911996.2912002
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wiggers KL, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852197
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu QH, 2020, MULTIMED TOOLS APPL, V79, P9419, DOI 10.1007/s11042-019-7605-5
   Xiao H., 2017, ARXIV170807747
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yasmin M, 2014, J APPL RES TECHNOL, V12, P87, DOI 10.1016/S1665-6423(14)71609-8
   Yin RP, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3434, DOI 10.1145/3308558.3313739
   Yu A, 2017, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2017.594
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Yu LH, 2021, MULTIMED TOOLS APPL, V80, P19157, DOI 10.1007/s11042-020-10355-0
   Zhang JM, 2019, MATH BIOSCI ENG, V16, P3345, DOI 10.3934/mbe.2019167
   Zhang J, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P102, DOI 10.1109/IMSCCS.2008.14
   Zhao L, 2019, CLOTH TEXT RES J, V37, P87, DOI 10.1177/0887302X18821187
   Zheng S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1670, DOI 10.1145/3240508.3240652
   Zhou W, 2019, J VIS COMMUN IMAGE R, V61, P112, DOI 10.1016/j.jvcir.2019.03.003
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
   Zou XX, 2019, IEEE COMPUT SOC CONF, P296, DOI 10.1109/CVPRW.2019.00039
NR 95
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16501
EP 16517
DI 10.1007/s11042-022-14204-0
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000882352400001
DA 2024-07-18
ER

PT J
AU Sheng, SH
   Zhao, XY
   Dou, WT
   Niu, DM
AF Sheng, Shouhe
   Zhao, Xiuyang
   Dou, Wentao
   Niu, Dongmei
TI A novel graph matching method based on multiple information of the graph
   nodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph matching; Local information; Intermediate information; Global
   information; Affinity matrix; Random walks
ID ALGORITHM
AB Graph matching is a fundamental NP-problem in computer graphics and computer vision. In this work, we present an approximate graph matching method. Given two graphs to be matched, the proposed method first constructs an association graph to convert the problem of graph matching into a problem of selecting nodes on the constructed graph. The nodes of the association graph represent candidate correspondences between the two original graphs. An affinity matrix is then computed based on the local, intermediate and global information of the original graphs' nodes, each element of which is used to measure the mutual consistency of a correspondence pair within the association graph. Updating the affinity of each correspondence pair with the affinities of relevant correspondences, our method then utilizes the reweighted random walks strategy to simulate random walks on the association graph and to iteratively obtain a quasi-stationary distribution. Finally, our method applies the Hungarian algorithm to discretize the distribution. Experimental results on four common datasets verify the effectiveness of the proposed method.
C1 [Sheng, Shouhe; Zhao, Xiuyang; Dou, Wentao; Niu, Dongmei] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, 336 West Rd Nan Xinzhuang, Jinan 250022, Shandong, Peoples R China.
C3 University of Jinan
RP Niu, DM (corresponding author), Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, 336 West Rd Nan Xinzhuang, Jinan 250022, Shandong, Peoples R China.
EM 1075322933@qq.com; xiuyangzhao@hotmail.com; 1825657862@qq.com;
   dniu_ujn@hotmail.com
FU National Nature Science Foundation of China [62102163]; Natural Science
   Foundation of Shandong province [ZR2019BF026, ZR2019MF013]
FX Our thanks to National Nature Science Foundation of China (No. 62102163)
   and Natural Science Foundation of Shandong province (No. ZR2019BF026,
   ZR2019MF013).
CR Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312
   Beibei Cui, 2021, Advances in Computer, Communication and Computational Sciences. Proceedings of IC4S 2019. Advances in Intelligent Systems and Computing (AISC 1158), P975, DOI 10.1007/978-981-15-4409-5_86
   Berg AC, 2005, PROC CVPR IEEE, P26
   Carletti V, 2019, PATTERN RECOGN LETT, V125, P591, DOI 10.1016/j.patrec.2019.07.001
   Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268
   Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492
   Cori M, 2005, LECT NOTES COMPUT SC, V3686, P81
   Cour T., 2007, Advances in Neural Information Processing Systems, V19, P313
   Cour T., 2007, International Conference on Artificial Intelligence and Statistics, P75
   Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   Hu N, 2014, PROC CVPR IEEE, P2313, DOI 10.1109/CVPR.2014.296
   Jiang B, 2019, INT J COMPUT VISION, V127, P1345, DOI 10.1007/s11263-019-01185-1
   Jiang B, 2017, AAAI CONF ARTIF INTE, P4089
   Jiang B, 2015, AAAI CONF ARTIF INTE, P3790
   Jiang B, 2017, PATTERN RECOGN, V61, P255, DOI 10.1016/j.patcog.2016.07.021
   Jiang B, 2014, PATTERN RECOGN, V47, P736, DOI 10.1016/j.patcog.2013.08.024
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Langville A. N., 2003, Internet Math, V1, P335, DOI DOI 10.1080/15427951.2004.10129091
   Lê-Huu DK, 2017, PROC CVPR IEEE, P4914, DOI 10.1109/CVPR.2017.522
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Leordeanu M., 2009, NIPS, P1114
   Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2
   Mills-Tettey Ayorkor., 2007, The dynamic hungarian algorithm for the assignment problem with changing costs
   Nie WZ, 2019, IEEE T CIRC SYST VID, V29, P1619, DOI 10.1109/TCSVT.2018.2852310
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2020, PATTERN RECOGN LETT, V130, P362, DOI 10.1016/j.patrec.2018.07.005
   Riesen K, 2010, ADV DATABASE SYST, V40, P217, DOI 10.1007/978-1-4419-6045-0_7
   Solnon C, 2010, ARTIF INTELL, V174, P850, DOI 10.1016/j.artint.2010.05.002
   Tian Y, 2012, LECT NOTES COMPUT SC, V7574, P821, DOI 10.1007/978-3-642-33712-3_59
   Ullmann Julian R., 2011, ACM J. Exp. Algorithmics, V15, DOI DOI 10.1145/1671970.1921702
   Wang RZ, 2019, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2019.00315
   Wang T, 2018, IEEE T PATTERN ANAL, V40, P2853, DOI 10.1109/TPAMI.2017.2767591
   Yang J, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108228
   Yu T., 2018, NIPS, P861
   Yu TS, 2020, PROC CVPR IEEE, P7121, DOI 10.1109/CVPR42600.2020.00715
   Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284
   Zhan YR, 2020, MULTIMED TOOLS APPL, V79, P11567, DOI 10.1007/s11042-019-08516-x
   Zhang Z, 2016, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2016.135
   Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667
NR 42
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16881
EP 16904
DI 10.1007/s11042-022-14071-9
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000876660900004
DA 2024-07-18
ER

PT J
AU Xiao, ZT
   Gao, J
   Wu, DQ
   Zhang, LY
   Zhang, QF
AF Xiao, Zhengtao
   Gao, Jian
   Wu, Dongqing
   Zhang, Lanyu
   Zhang, Qiaofen
TI Fast plane extraction method based on the point pair feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plane extraction; Plane detection; Point pair feature; RANSAC; Hough
   transform
ID HOUGH TRANSFORM; CLOUD
AB Extracting planes from a three-dimensional (3D) point cloud is a challenging problem for many applications with 3D point clouds. In this paper, a novel fast plane extraction method based on the point pair feature (PPF) is proposed. There are two stages included in the proposed method. One is the local processing stage to sample some points in a point cloud and calculate their PPF descriptors. In this stage, the coplanar property of the PPF is used to extract initial planes from the sampling points. The other one is a global processing stage to consider all the other points in the point cloud, and assess whether they are located in the initial planes by calculating the distance from each point to the initial planes. We can extract and determine the final planes in the global processing stage. Compared with the efficient random sample consensus (RANSAC) and the 3D kernel-based Hough transform (3DKHT), the results show that for the complex scene, the extracting time of our method is less than 0.3% of the RANSAC method, and the precision rate of our method is about 9% and 17% higher than that of the RANSAC method and 3DKHT method, respectively.
C1 [Xiao, Zhengtao] Guangdong Polytech Ind & Commerce, Sch Electromech Engn, Guangzhou 510510, Peoples R China.
   [Gao, Jian; Zhang, Lanyu; Zhang, Qiaofen] Guangdong Univ Technol, State Key Lab Precis Elect Mfg Technol & Equipmen, Guangzhou 510006, Peoples R China.
   [Wu, Dongqing] Zhongkai Univ Agr & Engn, Sch Computat Sci, Guangzhou 510220, Peoples R China.
C3 Guangdong University of Technology; Zhongkai University of Agriculture &
   Engineering
RP Gao, J (corresponding author), Guangdong Univ Technol, State Key Lab Precis Elect Mfg Technol & Equipmen, Guangzhou 510006, Peoples R China.
EM gaojian@gdut.edu.cn
RI CHEN, MINGWEI/KHT-6744-2024; Wang, Yining/JQW-2010-2023; yu,
   zhang/JWO-7724-2024; DAI, Jinjia/KCL-5110-2024; Liu,
   Yiwei/JUF-2477-2023; Zhang, Lanyue/JNS-8209-2023; Wu,
   Dongqing/KFA-3312-2024; Zhang, xiaohui/KEE-5747-2024
OI Wu, Dongqing/0000-0002-3861-234X; 
FU National Natural Science Foundation of China [52075106]
FX This research was funded by the National Natural Science Foundation of
   China under Grant No. 52075106. We gratefully thank the anonymous
   reviewers for their comments and suggestions for improving this paper.
CR Adams A., 2018, Readings for diversity and social justice, P1
   Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675
   Araújo AMC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107115
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Birdal T, 2020, IEEE T PATTERN ANAL, V42, P1333, DOI 10.1109/TPAMI.2019.2900309
   Borrmann D, 2011, 3D RES, V2, DOI 10.1007/3DRes.02(2011)3
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Drost B., 2010, Proc. 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2010.5540108
   Drost B, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P398, DOI 10.1109/3DV.2015.52
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   El-Sayed E, 2018, IET IMAGE PROCESS, V12, P1595, DOI 10.1049/iet-ipr.2017.1076
   Fan WZ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232789
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guinard S A, 2020, ISPRS ANN PHOTOGRAMM, VV-2-2020, P343
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Holz D, 2013, ADV INTELL SYST, V194, P61
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Hu L, 2020, MULTIMED TOOLS APPL, V79, P839, DOI 10.1007/s11042-019-08189-6
   Jiang P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030706
   Jin Z, 2019, IEEE T CIRC SYST VID, V29, P447, DOI 10.1109/TCSVT.2017.2780181
   Kaiser A, 2019, COMPUT GRAPH FORUM, V38, P167, DOI 10.1111/cgf.13451
   Li L, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050433
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020
   Mostafa SA, 2018, J STAT THEORY PRACT, V12, P290, DOI 10.1080/15598608.2017.1353456
   Rao G, 2018, IEEE-ASME T MECH, V23, P986, DOI 10.1109/TMECH.2017.2747133
   Sarker IH, 2023, MOBILE NETW APPL, V28, P296, DOI 10.1007/s11036-022-01937-3
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tian YF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051744
   Vera E, 2018, PATTERN RECOGN LETT, V103, P8, DOI 10.1016/j.patrec.2017.12.027
   Verma Rachna, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P154, DOI 10.1109/ICETCE48199.2020.9091735
   Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284
   Xiao ZT, 2020, MULTIMED TOOLS APPL, V79, P29305, DOI 10.1007/s11042-020-09525-x
   Xu S, 2021, IEEE T PATTERN ANAL, V43, P3991, DOI 10.1109/TPAMI.2020.2994935
   Yang LN, 2022, COMPUT STAND INTER, V82, DOI 10.1016/j.csi.2021.103608
NR 37
TC 0
Z9 0
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15027
EP 15042
DI 10.1007/s11042-022-14063-9
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000874426100001
DA 2024-07-18
ER

PT J
AU Ning, GY
AF Ning, Guiying
TI Two-dimensional Otsu multi-threshold image segmentation based on hybrid
   whale optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum inter-class variance algorithm; Two-dimensional Otsu; Image
   segmentation; Nonlinear convergence factor; Whale optimization algorithm
ID ENTROPY
AB Threshold segmentation is a commonly used method to deal with image segmentation problems. Aiming at the problems of the traditional maximum inter-class variance method (Otsu) in multi-threshold image segmentation, such as large amount of computation, long computation time and low segmentation accuracy. This paper proposes a two-dimensional Otsu multi-threshold image segmentation algorithm based on hybrid whale optimization algorithm. Firstly, the two-dimensional Otsu single-threshold segmentation method is extended to the two-dimensional Otsu multi-threshold segmentation method to improve the segmentation effect. At the same time, in order to reduce the calculation time and improve the solution accuracy, the new hybrid whale optimization algorithm proposed in this paper is used to calculate the threshold. The test is carried out through a set of classical image threshold segmentation sets, and the widely used image segmentation evaluation standards PSNR and SSIM are used for judgment. The results of this paper are also compared with the results of other novel algorithms, including the results of one-dimensional Otsu multi-threshold segmentation method. The results show that the proposed two-dimensional Otsu single-threshold segmentation improves the segmentation efficiency and quality, it is an effective image segmentation method.
C1 [Ning, Guiying] Liuzhou Inst Technol, Liuzhou 545616, Guangxi, Peoples R China.
RP Ning, GY (corresponding author), Liuzhou Inst Technol, Liuzhou 545616, Guangxi, Peoples R China.
EM guiyingling@126.com
RI ning, guiying/AAG-9582-2021
OI ning, guiying/0000-0003-3715-505X
FU Science and Technology Research Project of Guangxi Universities
   [KY2015YB521]; Youth Education Teachers' Basic Research Ability
   Enhancement Project of Guangxi Universities [2019KY1098]
FX This work partial financial support was received from the Science and
   Technology Research Project of Guangxi Universities (KY2015YB521), the
   Youth Education Teachers' Basic Research Ability Enhancement Project of
   Guangxi Universities (2019KY1098).
CR Elaziz MA., 2021, EXPERT SYST APPL, V175, P1
   Gao B, 2018, IEEE T IMAGE PROCESS, V27, P2160, DOI 10.1109/TIP.2017.2783627
   Gao FB., 2019, J HEIHE U, V10, P216
   Hamdaouil F, EFFICIENT MULTILEVEL
   Jun Q., 2018, J SUPERCOMPUT, V11, P1
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Liu J., 1993, Acta Automatica Sinica, V19, P101, DOI [10.3969/j.issn.1001-3695.2011.03.106, DOI 10.3969/J.ISSN.1001-3695.2011.03.106]
   Luo Jun, 2020, Systems Engineering and Electronics, V42, P2164, DOI 10.3969/j.issn.1001-506X.2020.10.03
   Luo J, 2019, J ELECTRON INF TECHN, V41, P2017, DOI 10.11999/JEIT180949
   Truong MTN, 2018, SOFT COMPUT, V22, P4197, DOI 10.1007/s00500-017-2709-1
   Mal Sandip, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P45, DOI 10.1007/978-981-13-7403-6_6
   Masoudi B., 2021, IRAN J COMPUTER SCI, V4, P1
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mishra S, 2018, ARAB J SCI ENG, V43, P7285, DOI 10.1007/s13369-017-3017-x
   [宁桂英 Ning Guiying], 2019, [系统科学与数学, Journal of Systems Science and Mathematical Sciences], V39, P120
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2018, SIGNAL IMAGE VIDEO P, V12, P385, DOI 10.1007/s11760-017-1170-z
   Paul Debapriya, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P485, DOI 10.1007/978-981-13-7403-6_43
   Qin J, 2019, J SUPERCOMPUT, V75, P955, DOI 10.1007/s11227-018-2622-0
   Ruan QQ., 2011, DIGITAL IMAGE PROCES
   [史春天 Shi Chuntian], 2021, [计算机工程与应用, Computer Engineering and Application], V57, P36
   Singh N, 2018, SOFT COMPUTING THEOR, P715, DOI DOI 10.1007/978-981-10-5699-4
   Song Wen-ging, 2015, Systems Engineering and Electronics, V37, P1504, DOI 10.3969/j.issn.1001-506X.2015.07.07
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2020, J INTELL FUZZY SYST, V38, P6031, DOI 10.3233/JIFS-179688
   Wang SHL., 2012, J COMPUT APPL, V32, P147
   WATKINS WA, 1979, J MAMMAL, V60, P155, DOI 10.2307/1379766
   Wiharto, 2019, INT J FUZZY LOG INTE, V19, P323, DOI 10.5391/IJFIS.2019.19.4.323
   Xing X., 2019, IMAGE PROCESS TECHNO, V38, P87
   Yao XT, 2019, IOP C SER EARTH ENV, V252, DOI 10.1088/1755-1315/252/4/042105
   [张海涛 Zhang Haitao], 2017, [计算机应用研究, Application Research of Computers], V34, P3880
   Zhang JSH., 2020, ELECT POWER, V35, P41
NR 33
TC 12
Z9 13
U1 31
U2 115
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15007
EP 15026
DI 10.1007/s11042-022-14041-1
EA OCT 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000870957300002
DA 2024-07-18
ER

PT J
AU Mathivanan, P
   Ganesh, AB
AF Mathivanan, P.
   Ganesh, A. Balaji
TI ECG steganography using Base64 encoding and pixel swapping technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG steganography; Base64 encoding; Threshold selection; QR code; Pixel
   swapping
AB ECG signals tagged with secret information are transferred through wireless communication channel in remote health monitoring applications. To hide secret information, the proposed steganography system uses ECG signal as cover data. The watermarked data (grey scale image or ECG signal) is transformed into 2D binary matrix (QR code), to enhance security of the steganography process. The Base64 encoding technique converts unsigned integer values to alphanumeric cypher text, which is then turned into a 2D binary matrix (QR code) through a QR code generator/reader. The threshold selection algorithm is used to select the coefficient position, and the pixel swapping technique is employed to incorporate watermark data into the selected location. Signal degradation is minimized by selecting coefficient locations are near to zero. The imperceptibility of the watermarked ECG signal is evaluated using performance metrics such as Peak Signal to Noise Ratio (PSNR), Percentage Residual Difference (PRD), Correlation Coefficient (CC), and Structural Similarity Measure Index (SSIM). Bit Error Rate is another metric used to evaluate the quality of extracted watermark data (BER). The watermarked signals imperceptibility is found to be good and is within the ideal value. Increase in payload capacity has increased signal deterioration. The steganography scheme has no BER, and the reconstructed signal is identical to the cover ECG signal.
C1 [Mathivanan, P.] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn Cyber Secur, Amrita Sch Comp, Chennai 601103, Tamil Nadu, India.
   [Ganesh, A. Balaji] Velammal Engn Coll, Elect Syst Design Lab, Chennai 600066, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Chennai; Velammal
   Engineering College
RP Mathivanan, P (corresponding author), Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn Cyber Secur, Amrita Sch Comp, Chennai 601103, Tamil Nadu, India.
EM mathiece05@gmail.com
RI P, Mathivanan/ABI-8419-2020; GANESH, DR. A/JJD-0095-2023
OI P, Mathivanan/0000-0002-0580-7757; GANESH, DR. A/0000-0002-0692-6213
CR Act A, 1996, PUBLIC LAW, V104, P191, DOI 10.4135/9781452234243.n359
   Al Ameen M, 2012, J MED SYST, V36, P93, DOI 10.1007/s10916-010-9449-4
   Amin MM, 2003, 4TH NATIONAL CONFERENCE ON TELECOMMUNICATION TECHNOLOGY, PROCEEDINGS, P21, DOI 10.1109/NCTT.2003.1188294
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Chen HM, 2012, J MED SYST, V36, P3907, DOI 10.1007/s10916-012-9862-y
   Chen ST, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0054-9
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Clifford G., 2002, SIGNAL PROCESSING ME
   Deng XP, 2015, OPT APPL, V45, P513, DOI 10.5277/oa150407
   HAMILTON PS, 1986, IEEE T BIO-MED ENG, V33, P1157, DOI 10.1109/TBME.1986.325695
   HEIL CE, 1989, SIAM REV, V31, P628, DOI 10.1137/1031129
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Ibaida A, 2011, COMPUT CARDIOL CONF, V38, P393
   Ibaida A, 2010, IEEE ENG MED BIO, P3891, DOI 10.1109/IEMBS.2010.5627671
   ISO B, 2006, 16022 BS ISO IEC
   Jero SE, 2016, ELECTRON LETT, V52, P283, DOI 10.1049/el.2015.3218
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Josefsson S., 2006, IETF, P1, DOI DOI 10.17487/RFC4648
   Lahoulou A., 2011, 2011 7th International Workshop on Systems, Signal Processing and their Applications (WOSSPA 2011), P219, DOI 10.1109/WOSSPA.2011.5931456
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Martins D., 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P824, DOI 10.1109/MINES.2010.175
   Mathivanan P, 2021, INT J IMAG SYST TECH, V31, P270, DOI 10.1002/ima.22477
   Mathivanan P., 2019, Proceedings of International Conference on Intelligent Computing and Applications (ICICA 2018). Advances in Intelligent Systems and Computing (AISC 846), P171, DOI 10.1007/978-981-13-2182-5_18
   Mathivanan P, 2019, MULTIMED TOOLS APPL, V78, P6763, DOI 10.1007/s11042-018-6471-x
   Mathivanan P, 2019, CRYPTOLOGIA, V43, P233, DOI 10.1080/01611194.2018.1549122
   Mathivanan P, 2018, AUSTRALAS PHYS ENG S, V41, P1057, DOI 10.1007/s13246-018-0695-y
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Patil V, 2018, L N COMPUT VIS BIOME, V28, P238, DOI 10.1007/978-3-319-71767-8_20
   Rahimi R, 2018, J PHYS CONF SER, V1007, DOI 10.1088/1742-6596/1007/1/012003
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Shekhawat A. S., 2014, INT J COMPUT APP, V105, P12
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yang CY, 2020, MULTIMED TOOLS APPL, V79, P24449, DOI 10.1007/s11042-020-09100-4
   Yang CY, 2018, SMART INNOV SYST TEC, V81, P129, DOI 10.1007/978-3-319-63856-0_16
   Yang CY, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0426-9
   Yang CY, 2021, IMPROVED ECG STEGANO
NR 40
TC 5
Z9 5
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14945
EP 14962
DI 10.1007/s11042-022-14072-8
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869613000002
DA 2024-07-18
ER

PT J
AU Shrarma, A
   Jadon, RS
AF Shrarma, Amita
   Jadon, R. S.
TI Characterization of Indian Visual Arts Architecture Ages and sub-ages
   using ML and Fuzzy-ML algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Characterization; Visual Arts; Machine learning; Neural network;
   Segmentation; Classification
AB India has a huge treasure of Visual art Architecture. In recent years, more attention is done to the digitization of these Indian Visual Arts Architectures for promoting the travel and tourism of the country across the world. Digitization will create a huge repository of Visual Arts Architecture images. But there exists no methodology to explore images of these huge repositories. In this paper, two machine learning-based methods were proposed that utilize these huge, digitized repositories and try to characterize the age and sub-age of Indian architectures based on the historical ontology available in the historical books. The first method was based on classification and the second method was based on segmentation. Two different variants of convolution neural networks were combined with fuzzy logic for the proposed methods. To analyze the results of the proposed methods performance evaluation matrix classification accuracy was used. The classification accuracy of the second method was best compared to the first method.
C1 [Shrarma, Amita; Jadon, R. S.] Madhav Inst Technol Sci, Dept Comp Sci & Engn, Gola ka Mandir, Gwalior 100190, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Shrarma, A (corresponding author), Madhav Inst Technol Sci, Dept Comp Sci & Engn, Gola ka Mandir, Gwalior 100190, Madhya Pradesh, India.
EM safalta.amita@gmail.com
CR Chacon M MI, 2006, ADV FUZZY LOGIC TECH, DOI [10.1007/978-1-84628-469-4_7, DOI 10.1007/978-1-84628-469-4_7]
   Goel A, 2012, P 8 INDIAN C COMPUTE, DOI [10.1145/2425333.2425334https://doi.org/10.1145/2425333.2425334, DOI 10.1145/2425333.2425334HTTPS://DOI.ORG/10.1145/2425333.2425334]
   Gupta U, 2015, NAT CONF COMPUT VIS
   Ninawe A, 2020, SOFT COMPUT APPL, P186, DOI [10.1007/978-3-030-51992-6_16, DOI 10.1007/978-3-030-51992-6_16]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saini A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P138, DOI 10.1109/BID.2017.8336587
   Singhania N., 2020, INDIAN ART CULTURE C
NR 7
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15493
EP 15513
DI 10.1007/s11042-022-13926-5
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864589600006
DA 2024-07-18
ER

PT J
AU Zanardelli, M
   Guerrini, F
   Leonardi, R
   Adami, N
AF Zanardelli, Marcello
   Guerrini, Fabrizio
   Leonardi, Riccardo
   Adami, Nicola
TI Image forgery detection: a survey of recent deep-learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Image forensics; Deep learning; Copy-move;
   Splicing; DeepFake; Survey
ID EXPOSING DIGITAL FORGERIES; CNN; WATERMARKING
AB In the last years, due to the availability and easy of use of image editing tools, a large amount of fake and altered images have been produced and spread through the media and the Web. A lot of different approaches have been proposed in order to assess the authenticity of an image and in some cases to localize the altered (forged) areas. In this paper, we conduct a survey of some of the most recent image forgery detection methods that are specifically designed upon Deep Learning (DL) techniques, focusing on commonly found copy-move and splicing attacks. DeepFake generated content is also addressed insofar as its application is aimed at images, achieving the same effect as splicing. This survey is especially timely because deep learning powered techniques appear to be the most relevant right now, since they give the best overall performances on the available benchmark datasets. We discuss the key-aspects of these methods, while also describing the datasets on which they are trained and validated. We also discuss and compare (where possible) their performance. Building upon this analysis, we conclude by addressing possible future research trends and directions, in both deep learning architectural and evaluation approaches, and dataset building for easy methods comparison.
C1 [Zanardelli, Marcello; Guerrini, Fabrizio; Leonardi, Riccardo; Adami, Nicola] CNIT Univ Brescia, Dept Informat Engn, Via Branze 38, I-25134 Brescia, Italy.
RP Zanardelli, M (corresponding author), CNIT Univ Brescia, Dept Informat Engn, Via Branze 38, I-25134 Brescia, Italy.
EM m.zanardelli005@unibs.it; fabrizio.guerrini@unibs.it;
   riccardo.leonardi@unibs.it; nicola.adami@unibs.it
RI Leonardi, Riccardo/F-5666-2010
OI zanardelli, marcello/0000-0001-5529-2408
FU Universita degli Studi di Brescia
FX Open access funding provided by Universita degli Studi di Brescia within
   the CRUI-CARE Agreement. No funding was received to assist with the
   preparation of this manuscript.
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   Achanta R., 2010, SLIC Superpixels
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], INT WEBD
   [Anonymous], 1999, AIM1657 MIT
   [Anonymous], ADOBE PHOTOSHOP
   [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   [Anonymous], 2004, VARIOUS COLUMBIA IMA
   [Anonymous], 2011, BLOG POST ELCOMSOFT
   [Anonymous], 2007, ONLINE ARTICLE ARSTE
   [Anonymous], NUMBERSPROTOCOLIO
   [Anonymous], 2006, TR2006579
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cao Z., 2020, ECCV, P387
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Chen M, 2007, LECT NOTES COMPUT SC, V4567, P342
   Chen TC, 2017, AGEING SOC, V37, P1798, DOI 10.1017/S0144686X16000623
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Christlein V, 2010, IEEE INT WORKS INFOR
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dittmann J, 2001, P SOC PHOTO-OPT INS, V4314, P175, DOI 10.1117/12.435398
   Doegar A, 2019, INT J COMPUTATIONAL, V2
   Dolhansky Brian, 2019, ARXIV191008854
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Faceswap, FACESWAP
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   GIMP, ABOUT US
   Goldman E., 2018, First Amendment Law Review, V17, P279
   Goodfellow I. J., 2014, Adv. Neural Inf. Process. Syst., V3
   Goodfellow I. J., 2014, ARXIV
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huynh TK, 2015, 2015 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES - RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P71, DOI 10.1109/RIVF.2015.7049877
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2008, LECT NOTES COMPUT SC, V5041, P19
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Keek, US
   Koptyra K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010082
   Korus P., 2016, Information Forensics and Security (WIFS), 2016 IEEE International Workshop on, P1, DOI DOI 10.1109/WIFS.2016.7823898
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Kowalski M, 2016, KOWALSKI M
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, WORKSHOP TRACK P
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li Y, 2016, CELEB DF LARGE SCALE, P3204, DOI [10.1109/CVPR42600.2020.00327, DOI 10.1109/CVPR42600.2020.00327]
   Li YH, 2019, PROC CVPR IEEE, P12489, DOI 10.1109/CVPR.2019.01278
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liao X, 2021, INFORM SCIENCES, V575, P231, DOI 10.1016/j.ins.2021.06.045
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   López-García X, 2019, COMUNICAR, V27, P9, DOI 10.3916/C59-2019-01
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lukas J, 2003, DIG FOR RES WORKSH
   Majumder M. T. H., 2018, 5 INT C NETWORKING S, P1
   Marra F, 2020, IEEE ACCESS, V8, P133488, DOI 10.1109/ACCESS.2020.3009877
   Moreira D, 2018, IEEE T IMAGE PROCESS, V27, P6109, DOI 10.1109/TIP.2018.2865674
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741657
   Nguyen Huy H, 2019, Use of a capsule network to detect fake images and videos
   Nightingale SJ, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0067-2
   Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Passarella A, 2012, COMPUT COMMUN, V35, P1, DOI 10.1016/j.comcom.2011.10.005
   Philbin J., 2007, The oxford buildings dataset
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Popescu A., 2004, TR2004515
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rajini NH, 2019, INT J RECENT TECHNOL, V8
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P142, DOI 10.1016/j.cag.2017.08.010
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Shen CH, 2019, NEW MEDIA SOC, V21, P438, DOI 10.1177/1461444818799526
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spohr Dominic, 2017, Business Information Review, V34, P150, DOI 10.1177/0266382117722446
   Thakur Rahul, 2019, 2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC), P561, DOI 10.1109/PEEIC47157.2019.8976868
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2019, COMMUN ACM, V62, P96, DOI 10.1145/3292039
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wojna Z, 2017, P BRIT MACH VIS C BM, P1, DOI [DOI 10.5244/C.31.10, 10.5244/C.31.10]
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
NR 109
TC 11
Z9 11
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17521
EP 17566
DI 10.1007/s11042-022-13797-w
EA OCT 2022
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863553600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Kaur, P
   Kumar, N
   Singh, M
AF Kaur, Prabhjot
   Kumar, Nitin
   Singh, Maheep
TI Biometric cryptosystems: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric Cryptosystem; Binding; Generation; Attacks; Performance
ID CRYPTOGRAPHIC KEY GENERATION; PALM IMAGE FUSION; FUZZY VAULT; EVALUATION
   METHODOLOGY; RECOGNITION SYSTEMS; ENCRYPTION SCHEME; GAIT RECOGNITION;
   SECURE; AUTHENTICATION; PROTECTION
AB Biometric Cryptosystem (BCS) combines characteristics of both the fields: biometric and cryptosystem, where biometric provides authentication and cryptosystem imparts security. Any biometric system is prone to attacks/security threats and BCS is an attempt to enhance system security without compromising its performance. BCS is surrounded by the concept of key; whereby key needs to be secured along with biometric signals using particular technique. In this work, a survey of 150 such techniques is presented. Furthermore, a separate section is dedicated to analyze the performance of these techniques. BCS is prone to various attacks and this study covers 30 such attacks, its countermeasures to thwart these attacks. In order to simulate BCS, a list of generic/attack type databases is also provided covering various physiological and behavioral biometrics. A brief discussion is presented on challenges and recommendations in BCS. Finally, several research directions are provided for the researchers working in this fascinating area.
C1 [Kaur, Prabhjot; Kumar, Nitin; Singh, Maheep] Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, N (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
EM nitin@nituk.ac.in
CR Abikoye OC, 2020, MULTIMED TOOLS APPL, V79, P23483, DOI 10.1007/s11042-020-08971-x
   Al-Saggaf AA, 2018, IET BIOMETRICS, V7, P278, DOI 10.1049/iet-bmt.2016.0146
   Albakri A, 2019, PROCEDIA COMPUT SCI, V160, P235, DOI 10.1016/j.procs.2019.09.462
   Amirthalingam G, 2016, J KING SAUD UNIV-COM, V28, P381, DOI 10.1016/j.jksuci.2014.12.011
   Anees A, 2018, PATTERN RECOGN, V77, P289, DOI 10.1016/j.patcog.2017.11.018
   Anjos A, 2014, ANTISPOOFING FACE DA
   [Anonymous], 1998, CVC Technical Report, DOI [10.1023/B:VISI.0000029666.37597, DOI 10.1023/B:VISI.0000029666.37597]
   [Anonymous], 2008, Proceedings of the 17th Conference on USENIX Security Symposium
   [Anonymous], 2007, TRCTIT0752 U TWENT
   Ao M, 2009, LECT NOTES COMPUT SC, V5558, P376
   Apon D, 2017, LECT NOTES COMPUT SC, V10332, P1, DOI 10.1007/978-3-319-60080-2_1
   Asthana R, 2021, MULTIMEDIA SYST, V27, P877, DOI 10.1007/s00530-021-00768-8
   Azzaz MS, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4211
   Bajwa G, 2016, COMPUT SECUR, V62, P95, DOI 10.1016/j.cose.2016.06.001
   Bardou R, 2012, LECT NOTES COMPUT SC, V7417, P608
   Barman S, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0020-1
   Baur S, 2019, IEEE INFOCOM 2019 IE, P1
   Bhatnagar G, 2014, EXPERT SYST APPL, V41, P4563, DOI 10.1016/j.eswa.2014.01.023
   Billeb S, 2015, IET BIOMETRICS, V4, P116, DOI 10.1049/iet-bmt.2014.0031
   Boyen X, 2005, LECT NOTES COMPUT SC, V3494, P147
   Buhan I, 2010, INT J INF SECUR, V9, P193, DOI 10.1007/s10207-010-0103-4
   Campisi P, 2008, IN PRESS
   Canetti R, 2016, LECT NOTES COMPUT SC, V9665, P117, DOI 10.1007/978-3-662-49890-3_5
   Cappelli R, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P174, DOI 10.1109/AUTOID.2007.380615
   Catuogno L, 2019, J AMB INTEL HUM COMP, V10, P2883, DOI 10.1007/s12652-018-1023-9
   Cavoukian A, 2009, SPRINGER ENCY, P1
   Chang D, 2021, INFORM SCIENCES, V546, P481, DOI 10.1016/j.ins.2020.08.065
   Chanukya PSVVN, 2020, MULTIMED TOOLS APPL, V79, P659, DOI 10.1007/s11042-019-08123-w
   Cheval Vincent, 2015, Principles of Security and Trust. 4th International Conference, POST 2015, held as part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015. Proceedings: LNCS 9036, P280, DOI 10.1007/978-3-662-46666-7_15
   Chmora AL, 2011, PROBL INFORM TRANSM+, V47, P201, DOI 10.1134/S0032946011020098
   Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   Connie T, 2004, PATTERN ANAL APPL, V7, P255, DOI 10.1007/s10044-004-0223-4
   Coron JS, 1999, LECT NOTES COMPUT SC, V1717, P292
   Daesung Moon, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P290, DOI 10.1109/ISCE.2009.5156914
   Nguyen D, 2017, PROCEDIA COMPUT SCI, V112, P936, DOI 10.1016/j.procs.2017.08.126
   Darun Tang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1306, DOI 10.1109/ICPR.2010.325
   Daugman John., 2000, BIOMETRIC DECISION L
   Davida GI, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P148, DOI 10.1109/SECPRI.1998.674831
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Draper SC, 2007, WIOPT 2007, P1
   Duong-Ngoc P, 2020, EFFICIENT NEWHOPE CR, V8
   Dwivedi R, 2020, J AMB INTEL HUM COMP, V11, P1495, DOI 10.1007/s12652-019-01437-5
   Elrefaei LA, 2022, J KING SAUD UNIV-COM, V34, P204, DOI 10.1016/j.jksuci.2019.10.011
   Emersic Z, 2015, 2015 4TH INTERNATIONAL WORK CONFERENCE ON BIOINSPIRED INTELLIGENCE (IWOBI), P27, DOI 10.1109/IWOBI.2015.7160139
   Failla P, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P241
   Feng YC, 2012, IEEE T INF FOREN SEC, V7, P613, DOI 10.1109/TIFS.2011.2170422
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Fierrez J, 2010, PATTERN ANAL APPL, V13, P235, DOI 10.1007/s10044-009-0151-4
   Freire MR, 2007, LECT NOTES COMPUT SC, V4642, P1134
   Fu B, 2009, IEEE T INF FOREN SEC, V4, P867, DOI 10.1109/TIFS.2009.2033227
   Galbally J, 2020, COMPUT SECUR, V96, DOI 10.1016/j.cose.2020.101902
   Garcia-Baleon HA, 2009, CERMA: 2009 ELECTRONICS ROBOTICS AND AUTOMOTIVE MECHANICS CONFERENCE, P15, DOI 10.1109/CERMA.2009.16
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Goh A, 2003, LECT NOTES COMPUT SC, V2828, P1
   Golic JD, 2008, IEEE T INFORM THEORY, V54, P2026, DOI 10.1109/TIT.2008.920211
   Gomez-Barrero M, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101700
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gross J., 2001, Tech. Rep. CMU-RI-TR-01-18, V45, P1
   Gross R, 2007, CMU ROBOTICS I T 07
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Hamouda E, 2016, ARAB J SCI ENG, V41, P2837, DOI 10.1007/s13369-015-2020-3
   Handschuh H, 1999, LECT NOTES COMPUT SC, V1556, P306
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hao Y, 2007, LECT NOTES COMPUT SC, V4844, P12
   Hao Y, 2008, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2008.4711746
   Hine GE, 2017, IEEE T INF FOREN SEC, V12, P1724, DOI 10.1109/TIFS.2017.2686005
   Hoang T, 2015, INT J INF SECUR, V14, P549, DOI 10.1007/s10207-015-0273-1
   Hogo MA, 2012, INT CARN CONF SECU, P110, DOI 10.1109/CCST.2012.6393545
   Hoque S, 2008, BLISS 2008: 2008 ECSIS SYMPOSIUM ON BIO-INSPIRED, LEARNING AND INTELLIGENT SYSTEMS FOR SECURITY, PROCEEDINGS, P17, DOI 10.1109/BLISS.2008.8
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Imamverdiev YN, 2012, AUTOM CONTROL COMPUT, V46, P66, DOI 10.3103/S0146411612020022
   Imamverdiyev Y, 2013, EXPERT SYST APPL, V40, P1888, DOI 10.1016/j.eswa.2012.10.009
   Inthavisas K, 2012, IET BIOMETRICS, V1, P46, DOI 10.1049/iet-bmt.2011.0008
   Itakura Y., 2005, International Journal of Information Security, V4, P288, DOI [10.1007/s10207-004-0065-5, DOI 10.1007/S10207-004-0065-5]
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jin Z, 2016, IEEE T SYST MAN CY-S, V46, P1415, DOI 10.1109/TSMC.2015.2499725
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Jindal AK, 2019, I SYMP CONSUM ELECTR
   Jindal AK, 2018, IEEE COMPUT SOC CONF, P575, DOI 10.1109/CVPRW.2018.00087
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Juels A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P408, DOI 10.1109/ISIT.2002.1023680
   Kanade S., 2009, WORLD ACAD SCI ENG T, V52, P330
   Kanade S, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P109
   Kang J, 2014, INFORM SCIENCES, V269, P1, DOI 10.1016/j.ins.2014.02.011
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   Kanhangad V, 2011, IEEE T IMAGE PROCESS, V20, P1415, DOI 10.1109/TIP.2010.2090888
   Karabat C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0255-5
   Karimian N, 2019, IEEE ACCESS, V7, P49135, DOI 10.1109/ACCESS.2019.2910753
   Karimian N, 2017, IEEE T BIO-MED ENG, V64, P1400, DOI 10.1109/TBME.2016.2607020
   Kaur P, 2018, INT C ADV COMP DAT S, P208, DOI DOI 10.1007/978-981-13-1810-8
   Kaur P, 2018, ADV INTELL SYST, V624, P493, DOI 10.1007/978-981-10-5903-2_50
   Kaur Tajinder., 2017, 2017 8th International Conference on Computing, Communication and Networking Technologies (ICCCNT), P1
   Khokher R, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P895, DOI 10.1109/CCAA.2015.7148503
   Kholmatov A, 2008, PROC SPIE, V6819, DOI 10.1117/12.766861
   Kholmatov A, 2006, LECT NOTES COMPUT SC, V4263, P981
   Kocher P, 2011, J CRYPTOGR ENG, V1, P5, DOI 10.1007/s13389-011-0006-y
   Kocher PC, 1995, ADV CRYPTOLOGY, P27
   Komulainen J, 2015, THESIS U OULU
   Komulainen J, 2013, INT CONF BIOMETR
   Kong A, 2006, PATTERN RECOGN, V39, P1359, DOI 10.1016/j.patcog.2005.10.025
   Kumar A, 2016, IEEE T INF FOREN SEC, V11, P2338, DOI 10.1109/TIFS.2016.2574309
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Kumar A, 2016, IEEE ACCESS, V4, P15, DOI 10.1109/ACCESS.2015.2428277
   Kumar A, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/967046
   Lai YL, 2021, IEEE T DEPEND SECURE, V18, P58, DOI 10.1109/TDSC.2018.2874245
   Lai YL, 2019, INFORM SCIENCES, V502, P492, DOI 10.1016/j.ins.2019.05.064
   Lee H, 2011, TELECOMMUN SYST, V47, P255, DOI 10.1007/s11235-010-9317-z
   Lee YJ, 2008, IEEE T SYST MAN CY B, V38, P1302, DOI 10.1109/TSMCB.2008.927261
   Lee YJ, 2007, LECT NOTES COMPUT SC, V4642, P800
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li C, 2015, IEEE T INF FOREN SEC, V10, P1193, DOI 10.1109/TIFS.2015.2402593
   Li HX, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P19, DOI 10.1109/IAS.2009.305
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li YF, 2011, INT J COMPUT MATH, V88, P1024, DOI 10.1080/00207160.2010.492213
   Lin You, 2012, Information and Communication Security. 14th International Conference (ICICS 2012). Proceedings, P453, DOI 10.1007/978-3-642-34129-8_44
   Lin You, 2010, Proceedings of the 5th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2010), P615, DOI 10.1109/ICCIT.2010.5711128
   Linnartz JP, 2003, LECT NOTES COMPUT SC, V2688, P393
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Lu Y, 2013, SENSORS-BASEL, V13, P14339, DOI 10.3390/s131114339
   Ma YK, 2017, IEEE ACCESS, V5, P16532, DOI 10.1109/ACCESS.2017.2737544
   Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maiorana E, 2007, P GRUPPO NAZIONALE T, P1
   Maiorana E, 2015, IEEE T INF FOREN SEC, V10, P900, DOI 10.1109/TIFS.2014.2384735
   Maiorana E, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2885239
   Maiorana E, 2010, EXPERT SYST APPL, V37, P3454, DOI 10.1016/j.eswa.2009.10.043
   Maiorana E, 2010, IEEE SIGNAL PROC LET, V17, P249, DOI 10.1109/LSP.2009.2038111
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Martinez-Diaz M, 2006, CAR C SECUR, P151, DOI 10.1109/CCST.2006.313444
   Martinian E, 2005, SECURE BIOMETRICS VI
   Merkle J, 2012, INT C BIOMETRICS SPE, P1
   Mihailescu P., 2009, BIOSIG, P43
   Monrose F., 2002, International Journal of Information Security, V1, P69, DOI 10.1007/s102070100006
   Monrose F, 2001, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2001.924299
   Murakami T, 2016, INFORM FUSION, V32, P93, DOI 10.1016/j.inffus.2016.02.002
   Nagakrishnan R, 2020, MULTIMED TOOLS APPL, V79, P20795, DOI 10.1007/s11042-020-08846-1
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nagar A, 2008, INT C PATT RECOG, P822
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Narayanan A., 2005, P ACM C COMP COMM SE, P364, DOI [10.1145/1102120.1102168, DOI 10.1145/1102120.1102168]
   Natgunanathan I, 2016, IEEE ACCESS, V4, P880, DOI 10.1109/ACCESS.2016.2535120
   Nazari S, 2016, SECUR COMMUN NETW, V9, P4957, DOI 10.1002/sec.1667
   Ngo DCL, 2004, LECT NOTES COMPUT SC, V3072, P195
   Nivedetha B, 2020, COMPUT COMMUN, V150, P94, DOI 10.1016/j.comcom.2019.11.007
   Ogiela M. R., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P673, DOI 10.1109/INCoS.2011.102
   Ong ThianSong., 2008, IJ Network Security, V6, P127
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Ortega-Garcia J, 2010, IEEE T PATTERN ANAL, V32, P1097, DOI 10.1109/TPAMI.2009.76
   Panchal G, 2019, MULTIMED TOOLS APPL, V78, P26979, DOI 10.1007/s11042-017-4528-x
   Panchal G, 2018, COMPUT ELECTR ENG, V69, P461, DOI 10.1016/j.compeleceng.2018.01.028
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Patil Pratap, 2020, International Journal of Information Technology, V12, P1043, DOI 10.1007/s41870-020-00501-0
   Peng JL, 2021, SOFT COMPUT, V25, P7657, DOI 10.1007/s00500-021-05732-2
   Peng JL, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023001
   Petit C., 2008, Proceedings of the ACM Symposium on Information, Computer and Communications Security (ASIACCS), P56, DOI DOI 10.1145/1368310.1368322
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ponce-Hernandez W, 2020, IEEE ACCESS, V8, P11152, DOI 10.1109/ACCESS.2020.2965165
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Prasanalakshmi B, 2012, PROCEDIA ENGINEER, V30, P303, DOI 10.1016/j.proeng.2012.01.865
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Rajan SR., 2020, J DANCE ED, P1, DOI [DOI 10.1080/15290824.2020.1766689, 10.1080/15290824.2020.1766689]
   Ranjan R, 2013, IEEE INT ADV COMPUT, P943
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Rathge C., 2009, Proc. of 13-th European Conference - Power Electronics and Applications, P1, DOI DOI 10.1049/IC.2009.0229
   Rathgeb C, 2011, IET COMPUT VIS, V5, P389, DOI 10.1049/iet-cvi.2010.0176
   Rathgeb C., 2015, INT WORKSH BIOM FOR, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Rathgeb C, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0049-9
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P511
   Rattani A, 2013, INT CONF BIOMETR
   Reddy ES, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P248, DOI 10.1109/CIT.2008.Workshops.20
   Roh JH, 2018, PROCEEDINGS OF 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P136, DOI 10.1109/ICITEED.2018.8534873
   Roy ND, 2020, MULTIMED TOOLS APPL, V79, P6823, DOI 10.1007/s11042-019-08507-y
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sandhya M, 2020, ADV INTELL SYST COMP, V1079, P359, DOI 10.1007/978-981-15-1097-7_30
   Sarier D, 2013, THESIS U LANDESBIBLI
   Sarier ND, 2021, INFORM SCIENCES, V573, P82, DOI 10.1016/j.ins.2021.05.036
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P18339, DOI 10.1007/s11042-019-7208-1
   Scheirer WJ, 2007, 2007 BIOMETRICS SYMPOSIUM, P30
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Sedenka J, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Sheng WG, 2008, IEEE T INF FOREN SEC, V3, P183, DOI 10.1109/TIFS.2008.922056
   Sheng WG, 2015, IEEE T SYST MAN CY-S, V45, P1205, DOI 10.1109/TSMC.2015.2389768
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Simoens K, 2012, IEEE T INF FOREN SEC, V7, P833, DOI 10.1109/TIFS.2012.2184092
   Song DXD, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P337
   Sousedik C, 2014, IET BIOMETRICS, V3, P219, DOI 10.1049/iet-bmt.2013.0020
   Soutar C, 1998, P SOC PHOTO-OPT INS, V3314, P178, DOI 10.1117/12.304705
   Soutar C, 1996, CARDTECH SECURETECH, V1, P245
   Spadavecchia, 2006, NETWORK BASED ASYNCH
   Standaert FX, 2009, LECT NOTES COMPUT SC, V5479, P443, DOI 10.1007/978-3-642-01001-9_26
   Stefan D, 2012, COMPUT SECUR, V31, P109, DOI 10.1016/j.cose.2011.10.001
   Stoianov A, 2010, PROC SPIE, V7667, DOI 10.1117/12.849028
   Sujitha V, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4513
   Sujitha V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1220-x
   Sun YN, 2019, IEEE J BIOMED HEALTH, V23, P987, DOI 10.1109/JBHI.2018.2860780
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Suresh P, 2018, TENCON IEEE REGION, P2175, DOI 10.1109/TENCON.2018.8650543
   Tan DL, 2006, INT C PATT RECOG, P1000
   Tan SY, 2012, SECUR COMMUN NETW, V5, P1312, DOI 10.1002/sec.408
   Tan Tuy Nguyen, 2018, IEIE Transactions on Smart Processing & Computing, V7, P97, DOI 10.5573/IEIESPC.2018.7.2.097
   Teoh ABJ, 2004, COMPUT SECUR, V23, P606, DOI 10.1016/j.cose.2004.06.002
   Teoh ABJ, 2008, C IND ELECT APPL, P2145, DOI 10.1109/ICIEA.2008.4582898
   Thakkar, 2018, TECHNIQUES LEVERAGED
   Nguyen TH, 2013, IET BIOMETRICS, V2, P48, DOI 10.1049/iet-bmt.2012.0060
   Tome P, 2015, INT CONF BIOMETR, P319, DOI 10.1109/ICB.2015.7139056
   Ton BT, 2013, INT CONF BIOMETR
   Trostle JT, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P125, DOI 10.1109/SECPRI.1998.674829
   Tuiri SE, 2019, 2019 2ND IEEE MIDDLE EAST AND NORTH AFRICA COMMUNICATIONS CONFERENCE (IEEEMENACOMM'19), P54, DOI 10.1109/menacomm46666.2019.8988578
   Uludag U., 2006, 2006 C COMPUTER VISI, P163
   Upmanyu M, 2010, IEEE T INF FOREN SEC, V5, P255, DOI 10.1109/TIFS.2010.2043188
   Van Hamme T, 2021, IEEE T INF FOREN SEC, V16, P5211, DOI 10.1109/TIFS.2021.3124735
   Verbitskiy E, 2003, PROC 24 BENELUX S IN, P1
   Verma G, 2019, OPT LASER ENG, V116, P32, DOI 10.1016/j.optlaseng.2018.12.010
   Voderhobli K, 2006, 7 ANN POSTGR S CONV, P1
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang YZ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188497
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Willems FMJ, 2010, IEEE INT WORKS INFOR
   Wu LF, 2010, INT CONF SIGN PROCES, P1675, DOI 10.1109/ICOSP.2010.5656719
   Wu X., 2008, 2008 19th International Conference on Pattern Recognition, P1
   Wu X, 2009, IEEE WORKSH APPL COM, P1
   Wu XQ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P53, DOI 10.1109/ICNC.2008.808
   Wu YD, 2010, IEEE INT CON MULTI, P78, DOI 10.1109/ICME.2010.5583388
   Wu ZD, 2018, INFORM SCIENCES, V433, P431, DOI 10.1016/j.ins.2016.12.048
   Wu ZD, 2016, SOFT COMPUT, V20, P4907, DOI 10.1007/s00500-015-1778-2
   Xia ZH, 2020, IEEE T SYST MAN CY-S, V50, P1526, DOI 10.1109/TSMC.2018.2874281
   Yamazaki Y, 2001, IEICE T INF SYST, VE84D, P879
   Yang, 2020, US Patent, Patent No. [10,594,688, 10594688]
   Yang SL, 2005, INT CONF ACOUST SPEE, P609
   Yang WC, 2018, IEEE ACCESS, V6, P36939, DOI 10.1109/ACCESS.2018.2844182
   Yazhuo Gong, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P166, DOI 10.1109/CSSE.2008.1181
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Yip WK, 2006, IEICE ELECTRON EXPR, V3, P410, DOI 10.1587/elex.3.410
   Yoon EJ, 2013, J SUPERCOMPUT, V63, P235, DOI 10.1007/s11227-010-0512-1
   Yoon S, 2015, P NATL ACAD SCI USA, V112, P8555, DOI 10.1073/pnas.1410272112
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zainon NAFM, 2017, 2017 IEEE CONFERENCE ON APPLICATION, INFORMATION AND NETWORK SECURITY (AINS), P37, DOI 10.1109/AINS.2017.8270421
   Zeng Z, 2007, ECUMN 2007: FOURTH EUROPEAN CONFERENCE ON UNIVERSAL MULTISERVICE NETWORKS, PROCEEDINGS, P439
   Zhang L, 2019, WIRELESS PERS COMMUN, V109, P2411, DOI 10.1007/s11277-019-06688-1
   Zhang T, 2007, PROCEEDINGS OF THE FIRST INTERNATIONAL SYMPOSIUM ON DATA, PRIVACY, AND E-COMMERCE, P221, DOI 10.1109/ISDPE.2007.48
   Zheng G, 2006, INT C PATT RECOG, P513
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 250
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16635
EP 16690
DI 10.1007/s11042-022-13817-9
EA SEP 2022
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000862219700007
DA 2024-07-18
ER

PT J
AU de la Fuente, C
   Castellanos, FJ
   Valero-Mas, JJ
   Calvo-Zaragoza, J
AF de la Fuente, Carlos
   Castellanos, Francisco J.
   Valero-Mas, Jose J.
   Calvo-Zaragoza, Jorge
TI Multimodal recognition of frustration during game-play with deep neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Audiovisual; Neural network; Emotion; Frustration
ID EMOTION RECOGNITION
AB Frustration, which is one aspect of the field of emotional recognition, is of particular interest to the video game industry as it provides information concerning each individual player's level of engagement. The use of non-invasive strategies to estimate this emotion is, therefore, a relevant line of research with a direct application to real-world scenarios. While several proposals regarding the performance of non-invasive frustration recognition can be found in literature, they usually rely on hand-crafted features and rarely exploit the potential inherent to the combination of different sources of information. This work, therefore, presents a new approach that automatically extracts meaningful descriptors from individual audio and video sources of information using Deep Neural Networks (DNN) in order to then combine them, with the objective of detecting frustration in Game-Play scenarios. More precisely, two fusion modalities, namely decision-level and feature-level, are presented and compared with state-of-the-art methods, along with different DNN architectures optimized for each type of data. Experiments performed with a real-world audiovisual benchmarking corpus revealed that the multimodal proposals introduced herein are more suitable than those of a unimodal nature, and that their performance also surpasses that of other state-of-the-art approaches, with error rate improvements of between 40% and 90%.
C1 [de la Fuente, Carlos; Castellanos, Francisco J.; Valero-Mas, Jose J.; Calvo-Zaragoza, Jorge] Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
C3 Universitat d'Alacant
RP de la Fuente, C (corresponding author), Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
EM cdlf4@alu.ua.es
RI Valero-Mas, Jose J./HSB-4673-2023; Castellanos Regalado, Francisco
   Jose/S-3302-2018
OI Valero-Mas, Jose J./0000-0001-8667-4070; Calvo-Zaragoza,
   Jorge/0000-0003-3183-2232; Castellanos Regalado, Francisco
   Jose/0000-0001-9949-5522
FU CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bahreini K, 2019, MULTIMED TOOLS APPL, V78, P18943, DOI 10.1007/s11042-019-7250-z
   Carvalhais T, 2018, 2018 INT C GRAPHICS, P1
   Cassani, 2019, AMPLITUDE MODULATION
   Chandrasekar P, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P341, DOI 10.1109/CSCITA.2014.6839284
   Chen D, 2016, RELATIONSHIP VIDEO G, P377
   Dworak Willyan, 2020, Design, User Experience, and Usability. Design for Contemporary Interactive Environments. 9th International Conference, DUXU 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12201), P426, DOI 10.1007/978-3-030-49760-6_30
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Fernandez R, 1998, INT CONF ACOUST SPEE, P3773, DOI 10.1109/ICASSP.1998.679705
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gilleade K.M., 2004, Proceedings of the 2004 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, P228, DOI [10.1145/1067343.1067372, DOI 10.1145/1067343.1067372]
   Granato M, 2020, MULTIMED TOOLS APPL, V79, P33657, DOI 10.1007/s11042-019-08585-y
   Güçlütürk Y, 2018, IEEE T AFFECT COMPUT, V9, P316, DOI 10.1109/TAFFC.2017.2751469
   Gunes H, 2005, IEEE SYS MAN CYBERN, P3437
   Horlings R., 2008, Proceedings of the 9th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing, pII.1, DOI [DOI 10.1145/1500879.1500888, 10.1145/1500879.1500888]
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Kosa M, 2022, BEHAV INFORM TECHNOL, V41, P2415, DOI 10.1080/0144929X.2021.1928753
   Kwon O.-W., 2003, Interspeech, P125
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Lim JZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082384
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   López C, 2020, IEEE T GAMES, V12, P155, DOI 10.1109/TG.2018.2883661
   Malta L, 2011, IEEE T INTELL TRANSP, V12, P109, DOI 10.1109/TITS.2010.2070839
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Miller MK, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P225, DOI 10.1145/2992154.2992185
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Ng YY, 2012, PROCD SOC BEHV, V51, P687, DOI 10.1016/j.sbspro.2012.08.225
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Noroozi F, 2021, IEEE T AFFECT COMPUT, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   Oh S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030866
   Pantic M, 2011, COGN TECHNOL, P115, DOI 10.1007/978-3-642-15184-2_8
   Picard R.W., 2000, Affective Computing
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sharma G, 2021, Advances in Data Science: Methodologies and Applications, P35
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Solovyev RA, 2020, 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P688, DOI [10.1109/elnano50318.2020.9088863, 10.1109/ELNANO50318.2020.9088863]
   Song M., 2021, Virtual Real. Intell. Hardw., V3, P76, DOI DOI 10.1016/J.VRIH.2020.10.004
   Song MS, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925464, 10.1109/ACII.2019.8925464]
   Staudemeyer R.C., 2019, arXiv
   Toselli AH, 2011, MULTIMODAL INTERACTIVE PATTERN RECOGNITON AND APPLICATIONS, P1, DOI 10.1007/978-0-85729-479-1
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Wimmer M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P145
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yannakakis GN, 2014, GUEST EDITORIAL EMOT
   Zhu Z, 2016, INTERSPEECH, P262, DOI 10.21437/Interspeech.2016-737
NR 50
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13617
EP 13636
DI 10.1007/s11042-022-13762-7
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kumari, N
   Acharjya, DP
AF Kumari, Nancy
   Acharjya, D. P.
TI Data classification using rough set and bioinspired computing in
   healthcare applications-an extensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Cuckoo search; Fish swarm; Swarm algorithm in healthcare;
   Classification; Feature selection; Rough set; Fuzzy rough set
ID PARTICLE SWARM OPTIMIZATION; ARTIFICIAL BEE COLONY; FEATURE-SELECTION;
   BAT ALGORITHM; ATTRIBUTE REDUCTION; FIREFLY ALGORITHM; KNOWLEDGE;
   FRAMEWORK; PREDICTION; MODEL
AB The change in living standard made people to think on their physical health. Accordingly, healthcare organizations are concentrating more on physical health of people in terms of disease diagnosis and patient care. Digitization is a step towards this end. Nevertheless, digitization generates a voluminous of data every second. Besides, these data contain uncertainties and may be imprecise. Analyzing such uncertainties and impreciseness in an information system is a critical task. Computational intelligence techniques are developed to handle such cases. These techniques include fuzzy set, rough set, soft set, neutrosophic set, bio-inspired, nature-inspired, and evolutionary computing. This research paper presents an extensive review of healthcare that has been carried out by researchers using rough and bio-inspired computing. The purpose of this review is to provide an understanding of prevailing research and relevant information in disease diagnosis concerning rough set and bio-inspired computing. Besides, the application and future scope of research are also presented.
C1 [Kumari, Nancy; Acharjya, D. P.] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Acharjya, DP (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM nancy.kumari@vit.ac.in; dpacharjya@gmail.com
RI Acharjya, Debi/T-1205-2018
OI Acharjya, Debi/0000-0003-3828-2050; Kumari, Dr.
   Nancy/0000-0002-4857-8106
CR Abd El Aziz M, 2018, NEURAL COMPUT APPL, V29, P925, DOI 10.1007/s00521-016-2473-7
   Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P13489, DOI 10.1007/s11042-021-11495-7
   Acharjya DP, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103924
   Acharjya DP, 2017, IIMB MANAG REV, V29, P122, DOI 10.1016/j.iimb.2017.05.002
   Africa ADM, 2015, INT J BIOMED ENG TEC, V18, P359, DOI 10.1504/IJBET.2015.071010
   Ahmed PK, 2021, INT J HEALTHC INF SY, V16, P49, DOI 10.4018/IJHISI.20210401.oa3
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Alia Ahmed F., 2017, International Journal of Information Technology and Computer Science, V9, P63, DOI 10.5815/ijitcs.2017.04.08
   Alkeshuosh AH, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P306, DOI 10.1109/COMAPP.2017.8079784
   Anitha A, 2018, NEURAL COMPUT APPL, V30, P3633, DOI 10.1007/s00521-017-2948-1
   [Anonymous], 2014, 2014 International Conference on Electronics and Communication Systems (ICECS), DOI DOI 10.1109/ECS.2014.6892729
   [Anonymous], 2011, INT J ARTIFICIAL INT, DOI DOI 10.5121/IJAIA.2011.2204
   Ardam S., 2019, J HLTH ADM, V22, P61
   Azadeh A, 2011, EXPERT SYST APPL, V38, P1364, DOI 10.1016/j.eswa.2010.07.033
   Bania RK, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105122
   Bello R, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P275
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Chakraborty C, 2022, IEEE T COMPUT SOC SY, V9, P1613, DOI 10.1109/TCSS.2022.3170375
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chalkidou K, 2014, LANCET ONCOL, V15, pE119, DOI 10.1016/S1470-2045(13)70547-3
   Chawla M, 2015, APPL ARTIF INTELL, V29, P617, DOI 10.1080/08839514.2015.1038434
   Chebrolu S, 2017, SOFT COMPUT, V21, P7543, DOI 10.1007/s00500-016-2308-6
   Chen Xiaoging, 2012, High Voltage Engineering, V38, P1403, DOI 10.3969/j.issn.1003-6520.2012.06.018
   Chen YM, 2017, SOFT COMPUT, V21, P6907, DOI 10.1007/s00500-016-2393-6
   Chen YM, 2015, KNOWL-BASED SYST, V81, P22, DOI 10.1016/j.knosys.2015.02.002
   Chen YM, 2010, PATTERN RECOGN LETT, V31, P226, DOI 10.1016/j.patrec.2009.10.013
   Cheruku R, 2018, APPL SOFT COMPUT, V67, P764, DOI 10.1016/j.asoc.2017.06.032
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Dash S, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147719895210
   Delgado-Osuna JA, 2016, INFORM SCIENCES, V326, P215, DOI 10.1016/j.ins.2015.07.051
   Dhal KG, 2018, P 5 STUDENT COMPUTER, P47, DOI [10.26493/978-961-7055-26-9.47-54, DOI 10.26493/978-961-7055-26-9.47-54]
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Elshazly Hanaa Ismail, 2013, International Journal of Fuzzy Systems Applications, V3, P31, DOI 10.4018/ijfsa.2013100103
   Emary E, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P346, DOI 10.1109/ICCES.2014.7030984
   Fan JC, 2018, INT J BIO-INSPIR COM, V12, P245
   Fister I, 2013, ELSEV INSIGHT, P73, DOI 10.1016/B978-0-12-405163-8.00004-1
   Gadekallu Thippa Reddy, 2017, International Journal of Fuzzy Systems Applications, V6, P25, DOI 10.4018/IJFSA.2017040102
   Gergin Z., 2019, INT J OPERATIONS RES, V10, P56, DOI DOI 10.4018/IJORIS.2019010104
   Gunasundari S, 2016, EXPERT SYST APPL, V56, P28, DOI 10.1016/j.eswa.2016.02.042
   He F, 2012, P 4 ELECT SYSTEM INT
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Inbarani HH, 2015, NEURAL COMPUT APPL, V26, P1859, DOI 10.1007/s00521-015-1840-0
   Inbarani HH, 2014, COMPUT METH PROG BIO, V113, P175, DOI 10.1016/j.cmpb.2013.10.007
   Jabar S. F., 2019, PERIODICALS ENG NATU, V7, P1152, DOI [https://doi.org/10.21533/pen.v7i3.656, DOI 10.21533/PEN.V7I3.656]
   Jackson D, 2011, STAT MED, V30, P2481, DOI 10.1002/sim.4172
   Jensen R., 2003, P OFTHE 2003 UK WORK, P15
   Jeyasingh Suganthi, 2017, Asian Pac J Cancer Prev, V18, P1257
   Jothi G, 2016, APPL SOFT COMPUT, V46, P639, DOI 10.1016/j.asoc.2016.03.014
   Kabir MM, 2012, EXPERT SYST APPL, V39, P3747, DOI 10.1016/j.eswa.2011.09.073
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Ke LJ, 2008, PATTERN RECOGN LETT, V29, P1351, DOI 10.1016/j.patrec.2008.02.006
   Kenndy J., 1995, P ICNN 95 INT C NEUR, P1942
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, INT J ENG SYST MODEL, V12, P188, DOI 10.1504/IJESMS.2021.115533
   Kora P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1379-7
   Krishnaiah V, 2016, INT J COMPUT APPL, V136, P43, DOI DOI 10.5120/IJCA2016908409
   Krumholz HM, 2014, HEALTH AFFAIR, V33, P1163, DOI 10.1377/hlthaff.2014.0053
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   [李晓磊 Li Xiaolei], 2002, [系统工程理论与实践, Systems Engineering-Theory & Practice], V22, P32
   Liu H, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P135, DOI 10.1109/IJCBS.2009.105
   Luan XY, 2016, NEUROCOMPUTING, V174, P522, DOI 10.1016/j.neucom.2015.06.090
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Mandal SK, 2012, EXPERT SYST APPL, V39, P3071, DOI 10.1016/j.eswa.2011.08.170
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Moameri S, 2018, INT J ENG-IRAN, V31, P2028, DOI 10.5829/ije.2018.31.12c.06
   Mohapatro A, 2020, INT J HEALTHC INF SY, V15, P40, DOI 10.4018/IJHISI.2020010103
   Muthukaruppan S, 2012, EXPERT SYST APPL, V39, P11657, DOI 10.1016/j.eswa.2012.04.036
   Neshat M, 2014, ARTIF INTELL REV, V42, P965, DOI 10.1007/s10462-012-9342-2
   Long NC, 2015, EXPERT SYST APPL, V42, P8221, DOI 10.1016/j.eswa.2015.06.024
   Palanisamy S., 2012, International Journal of Computer Science Issues (IJCSI), V9, P432
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z, 1997, EUR J OPER RES, V99, P48, DOI 10.1016/S0377-2217(96)00382-7
   Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pei D, 2005, INT J GEN SYST, V34, P603, DOI 10.1080/03081070500096010
   Rachna J., 2019, RECENT PATENTS COMPU, V12, P293, DOI [10.2174/2213275911666181120092223, DOI 10.2174/2213275911666181120092223]
   Radzikowska AM, 2002, FUZZY SET SYST, V126, P137, DOI 10.1016/S0165-0114(01)00032-X
   Rathi R, 2018, ARAB J SCI ENG, V43, P4215, DOI 10.1007/s13369-017-2838-y
   Reddy GT, 2020, EVOL INTELL, V13, P185, DOI 10.1007/s12065-019-00327-1
   Sakri SB, 2018, IEEE ACCESS, V6, P29637, DOI 10.1109/ACCESS.2018.2843443
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sharkawy RM, 2011, IEEE T DIELECT EL IN, V18, P1897, DOI 10.1109/TDEI.2011.6118628
   Singh B, 2020, HEALTH TECHNOL-GER, V10, P167, DOI 10.1007/s12553-018-00280-6
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Suguna N., 2010, Journal of Computing, V2, P49
   Taha Ahmed Majid, 2013, Journal of Theoretical and Applied Information Technology, V51, P1
   Velmurugan T, 2018, INT J ENG TECHNOL, V7, P74, DOI 10.14419/ijet.v7i2.26.12538
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang B, 2016, J COMB OPTIM, V31, P1045, DOI 10.1007/s10878-014-9809-y
   Wang F, 2014, LECT NOTES COMPUT SC, V8795, P24, DOI 10.1007/978-3-319-11897-0_4
   Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003
   Yan J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103268
   Yang X.-S., 2013, International Journal of Swarm Intelligence, P36, DOI DOI 10.1504/IJSI.2013.055801
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2011, INT J BIO-INSPIR COM, V3, P267, DOI 10.1504/IJBIC.2011.042259
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yue BX, 2007, LECT NOTES COMPUT SC, V4527, P397
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang C, 2014, C IND ELECT APPL, P748, DOI 10.1109/ICIEA.2014.6931262
   Zhang Y, 2017, INFORM SCIENCES, V418, P561, DOI 10.1016/j.ins.2017.08.047
   Zheng ZX, 2019, MATH COMPUT SIMULAT, V155, P227, DOI 10.1016/j.matcom.2018.04.013
   Zou L, 2019, IEEE ACCESS, V7, P90277, DOI 10.1109/ACCESS.2019.2926799
NR 115
TC 5
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13479
EP 13505
DI 10.1007/s11042-022-13776-1
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859771500003
DA 2024-07-18
ER

PT J
AU Ali, MH
   Jaber, MM
   Abd, SK
   Alkhayyat, A
   Albaghdadi, MF
AF Ali, Mohammed Hasan
   Jaber, Mustafa Musa
   Abd, Sura Khalil
   Alkhayyat, Ahmed
   Albaghdadi, Mustafa Fahem
TI Big data analysis and cloud computing for smart transportation system
   integration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Smart transportation; Big data analytics; Cloud computing; Traffic
   prediction; Machine learning
ID INTERNET; SCHEME; MODEL
AB Big data and cloud computing are becoming more critical in transportation systems as these technologies develop. Transportation companies can recognize and forecast potential traffic problems and offer appropriate responses. To avoid hindering mobility, one might use predictive analytics to assess the effect of various development initiatives and suggest a viable alternative. Due to automobiles' flexibility and rapid changes in their environment, creating an effective communication system for vehicular networks is tough. An intelligent transportation system with big data analytics and cloud computing (STS-BCC) is the goal of this research work. Data mining is used to anticipate traffic conditions using a machine learning method. The cloud platform provides a secure storage service and processing unit to aid traffic forecasting. The experimental analysis finds the prediction accuracy of 97.45% and proves the efficient integration of big data analytics and cloud computing technologies.
C1 [Ali, Mohammed Hasan] Imam Jaafar Al Sadiq Univ, Fac Informat Technol, Comp Tech Engn Dept, Najaf 10023, Iraq.
   [Jaber, Mustafa Musa] Dijlah Univ Coll, Dept Comp Sci, Baghdad 10021, Iraq.
   [Jaber, Mustafa Musa; Abd, Sura Khalil] Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
   [Alkhayyat, Ahmed] Islamic Univ, Coll Tech Engn, Najaf, Iraq.
   [Albaghdadi, Mustafa Fahem] Al Mustaqbal Univ Coll, Opt Tech Dept, Hilla 51001, Iraq.
C3 Imam Jaa'far al-Sadiq University; Islamic University College;
   Al-Mustaqbal University College
RP Abd, SK (corresponding author), Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
EM mh180250@gmail.com; Mustafa.jaber@turath.edu.iq; sura.khalil@duc.edu.iq;
   ahmedalkhayyat85@iunajaf.edu.iq
RI alkhayyat, ahmed/B-6434-2018
OI alkhayyat, ahmed/0000-0002-1270-4713
CR Ageed Zainab Salih, 2021, Qubahan Academic Journal, V1, P91, DOI 10.48161/qaj.v1n2a52
   Amudha G, 2018, WIRELESS PERS COMMUN, V102, P3303, DOI 10.1007/s11277-018-5369-2
   Andronie M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202497
   Appathurai A, 2020, CIRC SYST SIGNAL PR, V39, P734, DOI 10.1007/s00034-019-01224-9
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Gao JC, 2022, IEEE T SERV COMPUT, V15, P1411, DOI [10.1109/BigData47090.2019.9006011, 10.1109/TSC.2020.2993728, 10.1109/bigdata47090.2019.9006011]
   Gao JC, 2020, IEEE IC COMP COM NET, DOI 10.1109/icccn49398.2020.9209730
   Garg P, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P713, DOI 10.1109/Confluence51648.2021.9377161
   Gohar A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13095188
   Hu LW, 2018, PROCEDIA MANUF, V26, P1193, DOI 10.1016/j.promfg.2018.07.155
   Irshad A, 2021, SUSTAIN ENERGY TECHN, V48, DOI 10.1016/j.seta.2021.101571
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Manogaran G, 2022, IEEE T INTELL TRANSP, V23, P22467, DOI 10.1109/TITS.2021.3078753
   Manogaran G, 2021, IEEE SENS J, V21, P15564, DOI 10.1109/JSEN.2020.3017384
   Manogaran G, 2021, IEEE T INTELL TRANSP, V22, P3654, DOI 10.1109/TITS.2020.3037902
   Manogaran G, 2021, IEEE INTERNET THINGS, V8, P3360, DOI 10.1109/JIOT.2020.3022322
   Mohamed NA, 2015, INT CONF SOFT COMPUT, P230, DOI 10.1109/SOCPAR.2015.7492812
   Olayode I.O., 2021, Transport. Eng., V6, DOI [10.1016/j.treng.2021.100095, DOI 10.1016/J.TRENG.2021.100095]
   Rathore MM, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13147606
   Sundhari RPM, 2021, PEER PEER NETW APPL, V14, P2285, DOI 10.1007/s12083-020-00936-z
   Tri Gia Nguyen, 2020, Computational Data and Social Networks. 9th International Conference, CSoNet 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12575), P26, DOI 10.1007/978-3-030-66046-8_3
   Vijayalakshmi B, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4609
   Wang F, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4226
   Zhang DG, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4647
   Zhang YJ, 2023, ARAB J SCI ENG, V48, P4141, DOI 10.1007/s13369-021-06028-1
NR 25
TC 4
Z9 4
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 SEP 22
PY 2022
DI 10.1007/s11042-022-13700-7
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4S8LR
UT WOS:000857685800008
DA 2024-07-18
ER

PT J
AU Larbi, G
AF Larbi, Guezouli
TI Two-step text detection framework in natural scenes based on
   Pseudo-Zernike moments and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; CNN; PZM; Deep learning
ID CHARACTER-RECOGNITION; FAST COMPUTATION
AB Advanced Driver-Assistance Systems (ADAS) are becoming more and more topical projects for researchers. Their goal is to help people drive their cars easily. The increasing number of accidents reveals the great need of humans for human assistance by machines. In this paper, we propose a new framework using a single camera to detect text in natural scenes. First, we propose a filtering phase where we extract candidate text regions using pseudo-Zernike moments. Then, we propose a new convolutional neural network architecture (Scene Text Detection Network - STDN) for the classification phase. The results show that the proposed model reached approximate to 40 fps and an mAP of 88.12 %, thus a low computing time with a competitive accuracy.
C1 [Larbi, Guezouli] Univ Batna2, LaSTIC Lab, Fesdis, Algeria.
RP Larbi, G (corresponding author), Univ Batna2, LaSTIC Lab, Fesdis, Algeria.
EM larbi.guezouli@univ-batna2.dz
RI Guezouli, Larbi/A-2099-2013
OI Guezouli, Larbi/0000-0001-7636-4343
CR Ansari MA, 2017, INT J ADV RES COMPUT, V8
   Cheng ZZ, 2021, IEEE T IMAGE PROCESS, V30, P822, DOI 10.1109/TIP.2020.3038520
   Chong CW, 2003, INT J PATTERN RECOGN, V17, P1011, DOI 10.1142/S0218001403002769
   Dargan S, 2020, SOFT COMPUT, V24, P10111, DOI 10.1007/s00500-019-04525-y
   Dong HF, 2020, J PHYS CONF SER, V1634, DOI 10.1088/1742-6596/1634/1/012013
   Fernandez C, 2018, LEARNING IMBALANCED
   Fujitake M, 2021, IEEE SYS MAN CYBERN, P220, DOI 10.1109/SMC52423.2021.9658799
   Ghoshal R, 2018, 2018 4 INT C RECENT, P1, DOI [10.1109/RAIT.2018.8389021, DOI 10.1109/RAIT.2018.8389021]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1, DOI 10.1002/9781118646106
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Hinton G. E., 2012, 12070580 ARXIV
   Hosny KM, 2012, IMAGING SCI J, V60, P234, DOI 10.1179/1743131X11Y.0000000023
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN INTELLIGENT AND COMPUTING IN ENGINEERING (RICE III)
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar M, 2017, P NATL A SCI INDIA A, V87, P137, DOI 10.1007/s40010-016-0284-y
   Liu ZD, 2019, MULTIMED TOOLS APPL, V78, P18205, DOI 10.1007/s11042-019-7177-4
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2020, SOFT COMPUT, V24, P17279, DOI 10.1007/s00500-020-05018-z
   Narang SR, 2019, SOFT COMPUT, V23, P13603, DOI 10.1007/s00500-019-03897-5
   Papakostas G. A., 2010, Pattern Recognition and Image Analysis, V20, P56, DOI 10.1134/S1054661810010050
   Pujari P.S H, 2008, INT J IMAGE PROCESSI, V2
   Reddy Sangeeth, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P11074, DOI 10.1109/ICRA40945.2020.9196577
   Shin H.-C., 2016, Medical Image Recognition, Segmentation and Parsing, DOI [DOI 10.1016/B978-0-12-802581-9.00007-X, 10.1016/b978-0-12-802581-9.00007-x]
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Sravani M, 2021, MULTIMED TOOLS APPL, V80, P9671, DOI 10.1007/s11042-020-10113-2
   Su P, 2016, CORNELL U CS DEP MEN
   Toro V., 2015, THESIS BONN RHEIN SI
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Wang JD, 2020, IET COMPUT VIS, V14, P65, DOI 10.1049/iet-cvi.2018.5651
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Wu Z., 2020, T ELECT ENG IRANIAN
   Xiubin Dai, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P90, DOI 10.1007/978-3-642-36669-7_12
   Xu Wei, 2020, ICASIT 2020: Proceedings of the 2020 International Conference on Aviation Safety and Information Technology, P638, DOI 10.1145/3434581.3434705
   Zharikov I, 2019, ARXIV
   Zhou J., 2019, GRAPH NEURAL NETWORK, DOI DOI 10.1016/J.MEJO.2022.105639
NR 43
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10595
EP 10616
DI 10.1007/s11042-022-13690-6
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852464000002
DA 2024-07-18
ER

PT J
AU Srikanth, B
   Jayaprada, S
   Kumar, KK
   Chaduvula, K
   Markapudi, BR
   Khasim, S
AF Srikanth, B.
   Jayaprada, S.
   Kumar, K. Kranthi
   Chaduvula, Kavitha
   Markapudi, Babu Rao
   Khasim, Syed
TI An optimized generalized adversarial system for predicting specific
   substructures in brainstem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial model; Sensitivity and specificity; Brainstem;
   Cerebellum; Midbrain; Pons and medulla
ID FUSION
AB Nowadays, the medical field is enriched with rich technologies, especially with a medical image processing system. However, the image complexity has minimized the prediction and segmentation exactness rate requiring additional duration to execute the process. The current design article has focused on developing a novel Bat-based Generative Adversarial Model (BGAM) to gain the finest substructure localization and segmentation results to overcome this difficulty. Here, the fitness of Bat is updated in the classification layer of the generative adversarial approach to gain the tuned results. Finally, the designed model is validated with dual cases that are conventional generative adversarial models without a bat and generative adversarial models with the Bat. Moreover, the evaluation has produced the finest results for BGAM compared to the conventional generative approach. The designed novel approach is executed in a python environment, and the proficiency of the developed system is validated with other associated approaches. It has proved the finest outcome by earning the highest specificity and sensitivity rate.
C1 [Srikanth, B.] Kallam Haranadhareddy Inst Technol, Dept Comp Sci & Engn, Guntur 522019, Andhra Pradesh, India.
   [Jayaprada, S.] Lakireddy Bali Reddy Coll Engn, Dept Comp Sci & Engn, Mylavaram 521230, Andhra Pradesh, India.
   [Kumar, K. Kranthi] Vasireddy Venkatadri Inst Technol, IT Dept, Vijayawada, Andhra Pradesh, India.
   [Chaduvula, Kavitha] SR Gudlavalleru Engn Coll, Dept Informat Technol, Gudlavalleru 521356, Andhra Pradesh, India.
   [Markapudi, Babu Rao] Gudlavalleru Engn Coll, Dept Comp Sci & Engn, Gudlavalleru 521356, Andhra Pradesh, India.
   [Khasim, Syed] VIT AP Univ, Dept Comp Sci & Engn, Amaravati 522237, Andhra Pradesh, India.
C3 VIT-AP University
RP Srikanth, B (corresponding author), Kallam Haranadhareddy Inst Technol, Dept Comp Sci & Engn, Guntur 522019, Andhra Pradesh, India.
EM srikanth.busa@gmail.com; jayasomala@gmail.com; kk97976@gmail.com;
   kavithachaduvula12@gmail.com; baburaompd@gmail.com;
   syed.khasim@vitap.ac.in
RI chaduvula, kavitha/ABA-9860-2020; ., Dr. Syed Khasim/AAW-4820-2021;
   Konduru, Dr.Kranthi Kumar/AAW-9407-2021; Markapudi,
   Baburao/ABB-3205-2020; Busa, Dr. Srikanth/AEE-8043-2022
OI chaduvula, kavitha/0000-0002-1323-7563; ., Dr. Syed
   Khasim/0000-0003-1967-5449; Konduru, Dr.Kranthi
   Kumar/0000-0002-8419-7386; Markapudi, Baburao/0000-0002-1878-7820; Busa,
   Dr. Srikanth/0000-0003-0639-0743
CR Aggarwal A., 2021, International Journal of Information Management Data Insights, V1, DOI [10.1016/j.jjimei.2020.100004, DOI 10.1016/J.JJIMEI.2020.100004]
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arnts H, 2020, CORTEX, V132, P135, DOI 10.1016/j.cortex.2020.08.011
   Avendaño-Valencia LD, 2021, ARTIF INTELL MED, V114, DOI 10.1016/j.artmed.2021.102050
   Bouhrara M, 2020, NEUROIMAGE, V206, DOI 10.1016/j.neuroimage.2019.116307
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P1967, DOI 10.1109/TNNLS.2018.2875194
   Cronin NJ, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105583
   Dutt S, 2021, BRAIN IMAGING BEHAV, V15, P2572, DOI 10.1007/s11682-021-00459-y
   Elzayady M, 2021, EGYPT J RADIOL NUC M, V52, DOI 10.1186/s43055-020-00394-w
   Han BK, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109197
   Huang J, 2020, IEEE ACCESS, V8, P55145, DOI 10.1109/ACCESS.2020.2982016
   Iqbal T, 2022, J KING SAUD UNIV-COM, V34, P2515, DOI 10.1016/j.jksuci.2020.04.001
   Kann BH, 2021, CANCER CELL, V39, P916, DOI 10.1016/j.ccell.2021.04.002
   Kong FJ, 2020, IEEE WINT CONF APPL, P1803, DOI 10.1109/WACV45572.2020.9093339
   Lechanoine F, 2021, NEUROIMAGE, V236, DOI 10.1016/j.neuroimage.2021.118080
   Nair S., 2021, VASCULAR ANOMALIES O, P629, DOI [10.1007/978-981-15-1346-6_31, DOI 10.1007/978-981-15-1346-6_31]
   Pirovano A, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102167
   Rizvi SKJ, 2021, ARCH COMPUT METHOD E, V28, P4503, DOI 10.1007/s11831-021-09543-4
   Shi HS, 2020, ACTA NEUROPATHOL, V139, P813, DOI 10.1007/s00401-020-02134-w
   Singh RK, 2021, NEURAL COMPUT APPL, V33, P8871, DOI 10.1007/s00521-020-05636-6
   Sjöström H, 2020, PARKINSONISM RELAT D, V79, P18, DOI 10.1016/j.parkreldis.2020.08.004
   Tang, 2020, REBIRTH MYTHOLOGY SO, P1, DOI [10.1007/978-981-15-4393-7_1, DOI 10.1007/978-981-15-4393-7_1]
   Uppal S, 2022, INFORM FUSION, V77, P149, DOI 10.1016/j.inffus.2021.07.009
   Usman M, 2020, SCI TOTAL ENVIRON, V721, DOI 10.1016/j.scitotenv.2020.137778
   Wang F, 2020, COMPUTER VISION ECCV, DOI [10.1007/978-3-030-58580-8_8, DOI 10.1007/978-3-030-58580-8_8]
   Wang GT, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101787
   Wani IM, 2020, MED BIOL ENG COMPUT, V58, P1873, DOI 10.1007/s11517-020-02171-3
   Wei L., 2021, FUNDAMENTALS RADIOMI, P441, DOI [10.1007/978-3-030-65245-6_17, DOI 10.1007/978-3-030-65245-6_17]
   Xiang Gao, 2020, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), P1147, DOI 10.1145/3377811.3380415
   Yanru Xiao, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12239), P133, DOI 10.1007/978-3-030-57884-8_12
   Yuvapriya T, 2021, INT J DYNAM CONTROL, V9, P590, DOI 10.1007/s40435-020-00664-5
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390
NR 35
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7181
EP 7205
DI 10.1007/s11042-022-13663-9
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842591000003
DA 2024-07-18
ER

PT J
AU Ju, FJ
   Sun, YF
   Li, JQ
   Zhang, YX
   Piao, XL
AF Ju, Fujiao
   Sun, Yanfeng
   Li, Jianqiang
   Zhang, Yaxiao
   Piao, Xinglin
TI Principal component analysis based on graph embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Graph embedding; Principal component analysis;
   Feature extraction
ID FEATURE-EXTRACTION; CONVOLUTIONAL NETWORKS; PCA; REPRESENTATION; LPP
AB Dimensionality reduction plays an important role in image recognition and data mining Traditional methods extract features from data itself and ignore the structure information of data even though it is crucial for effective representation. Considering graph embedding method can capture and model the complicated relationships among data, therefore, we consider to incorporate graph convolution learning into principal component analysis (GCPCA) to abstract more effective features in this paper. The key idea of the proposed model is embedding graph convolutional to realize linear representation by fusing the relationship of data points. Then PCA is operated on projected data to extract effective features. The model can be solved to obtain a globally optimal closed-form solution, which is convenient for implementation and practical application. Experiments on some publicly available datasets demonstrate that the proposed GCPCA model show the better performance than the existing classical algorithms in terms of classification accuracy.
C1 [Ju, Fujiao; Sun, Yanfeng; Li, Jianqiang] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   [Zhang, Yaxiao] Beijing Union Univ, Beijing Key Lab Informat Serv Engn, Chaoyang 100101, Peoples R China.
   [Piao, Xinglin] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
C3 Beijing University of Technology; Beijing Union University; Peng Cheng
   Laboratory
RP Sun, YF (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
EM jfj2017@bjut.edu.cn; yfsun@bjutedu.cn; lijianqiang@bjut.edu.cn;
   zdhtyaxiao@buu.edu.cn; piaoxl@pcl.ac.cn
RI l, j/HNC-5728-2023; li, jy/HTT-1535-2023; li, jian/IAQ-2794-2023; LI,
   JIAN/JAX-3092-2023; Zhang, Jinfan/JPK-7588-2023; qi, li/JFE-7167-2023;
   Zhang, Jun/JPK-7723-2023; Li, Jing/GYU-5036-2022; LI,
   JIAN/GRY-2197-2022; LI, Jing/HNB-5575-2023; Liu, Jing/IQX-0664-2023; li,
   jian/GSE-0245-2022
FU Beijing Municipal Science and Technology Project [Z191100009119013,
   KM201910005028, KM202011417004]; National Natural Science Foundation of
   China [61772048, 61672071, 61902053]; Beijing Natural Science Foundation
   [4172003]
FX This research was supported by Beijing Municipal Science and Technology
   Project with no. Z191100009119013, in part by National Natural Science
   Foundation of China under Grant 61772048, 61672071 and 61902053, in part
   by the Beijing Natural Science Foundation under Grant 4172003, in part
   by Beijing Municipal Science and Technology Project KM201910005028 and
   KM202011417004.
CR Abraham R., 2012, Manifolds, Tensor Analysis, and Applications. Applied Mathematical Sciences, V75
   Benamira A, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P568, DOI 10.1145/3341161.3342958
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Celik S, 2014, PR MACH LEARN RES, V32, P1953
   Defferrard M, 2016, ADV NEUR IN, V29
   Feng GY, 2006, NEUROCOMPUTING, V69, P1733, DOI 10.1016/j.neucom.2006.01.006
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Jenatton Rodolphe, 2010, PMLR, V9, P366
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Ju FJ, 2015, IEEE T IMAGE PROCESS, V24, P4834, DOI 10.1109/TIP.2015.2469136
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim Y, 2008, C IND ELECT APPL, P2139, DOI 10.1109/ICIEA.2008.4582897
   Kipf TN, 2016, ARXIV
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kuncheva LI, 2014, IEEE T NEUR NET LEAR, V25, P69, DOI 10.1109/TNNLS.2013.2248094
   Leng L, 2011, 2 DIRECTIONAL 2 DIME
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu XE, 2020, AAAI CONF ARTIF INTE, V34, P8409
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lv JC, 2021, IEEE T IMAGE PROCESS, V30, P5252, DOI 10.1109/TIP.2021.3079800
   Pan SR, 2020, IEEE T CYBERNETICS, V50, P2475, DOI 10.1109/TCYB.2019.2932096
   Pang YW, 2010, NEUROCOMPUTING, V73, P968, DOI 10.1016/j.neucom.2009.08.020
   Shen XJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107023
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Torki Marwan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1068, DOI 10.1109/ICPR.2010.267
   van den Berg, 2018, ACM SIGKDD C KNOWLED
   Vasilescu MAO, 2003, PROC CVPR IEEE, P93
   Wang C, 2019, ARXIV
   Wang HX, 2013, NEURAL NETWORKS, V46, P190, DOI 10.1016/j.neunet.2013.06.002
   Wang J, 2012, RANDOM PROJECTION
   Wu M, 2019, IEEE DATA MINING, P648, DOI 10.1109/ICDM.2019.00075
   Wu ZH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1907
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie XC, 2008, IEEE T NEURAL NETWOR, V19, P1821, DOI 10.1109/TNN.2008.2004963
   Xu Y, 2010, PATTERN RECOGN, V43, P4165, DOI 10.1016/j.patcog.2010.06.016
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6
   Yuan YT, 2021, PROCEDIA COMPUT SCI, V183, P572, DOI 10.1016/j.procs.2021.02.099
   Zhang JP, 2010, IEEE INTELL SYST, V25, P54, DOI 10.1109/MIS.2010.8
   Zhao HX, 2011, CHIN CONT DECIS CONF, P1259, DOI 10.1109/CCDC.2011.5968382
   Zhao TY, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa212
   Ziwei Zhang, 2022, IEEE Transactions on Knowledge and Data Engineering, V34, P249, DOI 10.1109/TKDE.2020.2981333
NR 49
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7105
EP 7116
DI 10.1007/s11042-022-13620-6
EA AUG 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000841079300001
DA 2024-07-18
ER

PT J
AU Tapia-Dueñas, OA
   Sánchez-Cruz, H
   López, HH
AF Tapia-Duenas, Osvaldo A.
   Sanchez-Cruz, Hermilo
   Lopez, Hiram H.
TI 3D object simplification using chain code-based point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chain code; Voxelization; 3D shape; Data reduction; Key points
ID EFFICIENT; ALGORITHM; REPRESENTATION; RECOGNITION; INSPECTION
AB This work aims to obtain a sequence of 3D point clouds associated with a 3D object that reduces the volume data and preserves the shape of the original object. The sequence contains point clouds that give different simplifications of the object, from a very fine-tuned representation to a simple and sparse one. Such a sequence is important because it satisfies different needs, from a faithful representation with a low reduction of points to a significant data reduction that only preserves the main properties of the object. We construct the sequence in the following way. We first obtain a voxelization of the original 3D object. Then, we organize the voxels by slices to get a single chain code that represents the original 3D object. The point clouds depend on the key points of the chain code. The Hausdorff distance and the average geometric error prove that the point clouds are invariant under rigid rotations and maintain the shape of the object. Our results indicate that the proposed method has an average efficiency of 60% regarding the state-of-the-art simplification methods.
C1 [Tapia-Duenas, Osvaldo A.; Sanchez-Cruz, Hermilo] Univ Autonoma Aguascalientes, Dept Ciencias Comp, Aguascalientes 20100, Aguascalientes, Mexico.
   [Lopez, Hiram H.] Cleveland State Univ, Dept Math & Stat, Cleveland, OH 44115 USA.
C3 Universidad Autonoma de Aguascalientes; University System of Ohio;
   Cleveland State University
RP Sánchez-Cruz, H (corresponding author), Univ Autonoma Aguascalientes, Dept Ciencias Comp, Aguascalientes 20100, Aguascalientes, Mexico.
EM osvaldo.tapia@edu.uaa.mx; hermilo.sanchez@edu.uaa.mx;
   h.lopezvaldez@csuohio.edu
RI Sánchez-Cruz, Hermilo/B-2235-2016; Lopez, Hiram/A-3895-2016
OI Sánchez-Cruz, Hermilo/0000-0001-9081-6449; Lopez,
   Hiram/0000-0002-9832-7145
FU CONACyT [CVU 781156]; Universidad Autonoma de Aguascalientes [PII22-5];
   AMS-Simons Travel Grant
FX Osvaldo A. Tapia-Due~nas was partially supported by CONACyT, CVU 781156.
   Hermilo S ' anchezCruz was partially supported by Universidad Autonoma
   de Aguascalientes, grant PII22-5. Hiram H. L ' opez was partially
   supported by an AMS-Simons Travel Grant.
CR Cao C, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338130
   Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730
   Chen Z, 2021, IEEE ROBOT AUTOM LET, V6, P4720, DOI 10.1109/LRA.2021.3068939
   El Sayed AR, 2019, RAIRO-OPER RES, V53, P487, DOI 10.1051/ro/2018082
   Fan HH, 2021, PROC CVPR IEEE, P14199, DOI 10.1109/CVPR46437.2021.01398
   Fan Hehe, 2021, IEEE T PATTERN ANAL, P2
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Garcia DC, 2020, IEEE T IMAGE PROCESS, V29, P313, DOI 10.1109/TIP.2019.2931466
   Golla T, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.14009
   Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786
   Gu S, 2020, IEEE T IMAGE PROCESS, V29, P796, DOI 10.1109/TIP.2019.2936738
   Guarato AZ, 2018, INT J ADV MANUF TECH, V95, P1315, DOI 10.1007/s00170-017-1319-5
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Han HY, 2015, OPTIK, V126, P2157, DOI 10.1016/j.ijleo.2015.05.092
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Huang TX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P890, DOI 10.1145/3343031.3351061
   Ji CY, 2019, IEEE ACCESS, V7, P129029, DOI 10.1109/ACCESS.2019.2939684
   Kansal S, 2013, IEEE INT ADV COMPUT, P1385
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Kim J, 2020, IEEE ACCESS, V8, P83538, DOI 10.1109/ACCESS.2020.2991478
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Krüsi P, 2017, J FIELD ROBOT, V34, P940, DOI 10.1002/rob.21700
   Leal E, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134279
   Lee MY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135941
   Liu HS, 2019, PATTERN RECOGN, V92, P135, DOI 10.1016/j.patcog.2019.03.025
   Liu XY, 2019, IEEE I CONF COMP VIS, P9245, DOI 10.1109/ICCV.2019.00934
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Liu Z, 2021, IEEE NETWORK, V35, P202, DOI 10.1109/MNET.101.2000364
   Min Patrick, 2004, binvox
   Nguyen CHP, 2018, AUTOMAT CONSTR, V91, P44, DOI 10.1016/j.autcon.2018.03.008
   Ning XJ, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103111
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Qi JK, 2019, IEEE INT CON MULTI, P284, DOI 10.1109/ICME.2019.00057
   Sánchez-Cruz H, 2019, LECT NOTES COMPUT SC, V11524, P261, DOI 10.1007/978-3-030-21077-9_24
   Shah SAA, 2017, PATTERN RECOGN, V64, P29, DOI 10.1016/j.patcog.2016.10.028
   Shah SAA, 2016, NEUROCOMPUTING, V205, P1, DOI 10.1016/j.neucom.2015.11.019
   Shiquan Q., 2019, INT J PERFORMABILITY, V15, P782
   Shoaib M, 2019, J INTELL FUZZY SYST, V37, P7815, DOI 10.3233/JIFS-182742
   Song H, 2006, INT FED INFO PROC, V220, P461, DOI 10.1007/978-0-387-36594-7_49
   Song H, 2007, INT J COMPUT APPL T, V30, P236, DOI 10.1504/IJCAT.2007.017235
   Song H, 2009, INT J ADV MANUF TECH, V45, P583, DOI 10.1007/s00170-009-1980-4
   Szeliski R, 2011, TEXTS COMPUT SCI, P181, DOI 10.1007/978-1-84882-935-0_4
   Taha AA, 2015, IEEE T PATTERN ANAL, V37, P2153, DOI 10.1109/TPAMI.2015.2408351
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Tapia-Dueñas OA, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116080
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Toledo L, 2014, VISUAL COMPUT, V30, P949, DOI 10.1007/s00371-014-0975-9
   Vogiatzis G, 2011, IMAGE VISION COMPUT, V29, P434, DOI 10.1016/j.imavis.2011.01.006
   Wang LY, 2019, J INDIAN SOC REMOTE, V47, P349, DOI 10.1007/s12524-018-0893-9
   Wei JX, 2020, J INF PROCESS SYST, V16, P688, DOI 10.3745/JIPS.01.0057
   Yang Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155379
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Zou Y, 2018, PATTERN RECOGN, V76, P522, DOI 10.1016/j.patcog.2017.11.029
NR 54
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9491
EP 9515
DI 10.1007/s11042-022-13588-3
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000840056400001
DA 2024-07-18
ER

PT J
AU Khaitan, S
   Sagar, S
   Agarwal, R
AF Khaitan, Supriya
   Sagar, Shrddha
   Agarwal, Rashi
TI Chaos cryptosystem with optimal key selection for image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic function; Encryption; Decryption; Improved slap swarm
   optimization; Tent map
ID SCHEME; ALGORITHM; MAP; OPTIMIZATION
AB Nowadays, digital media usage over the internet has drastically increased; this has also generated the need to secure information. Several approaches have been adopted to implement the security of images. Researches have focused on chaotic functions to create different cryptography algorithms. Inspired by the researchers, we proposed a public key cryptosystem that combines the chaos tent map function with the Improved Salp swarm Optimization technique to encrypt and decrypt the images. Salp Swarm optimization algorithm is updated by applying crossover and mutation to generate a key for decryption. The encryption scheme includes a permutation and circular shift operation controlled by chaos-based key and control parameters. During the encryption process, an eight-bit shift register is used with XOR operation to enhance the unpredictability of cipher-image. The proposed scheme is evaluated for different parameters, experimental analysis shows the scheme is resistant to differential cryptoanalysis attack and entropy-based attacks.
C1 [Khaitan, Supriya; Sagar, Shrddha] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
   [Agarwal, Rashi] Galgotias Coll Engn & Technol, Dept MCA, Greater Noida, Uttar Pradesh, India.
C3 Galgotias University; Galgotias College of Engineering & Technology
   (GCET)
RP Khaitan, S (corresponding author), Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
EM Supriyakhaitan21@gmail.com; sagarshraddha@gmail.com;
   rasagarwal@gmail.com
RI Chandra, Dr. Supriya Khaitan/AAZ-4797-2021; Sagar, Shrddha/ACF-7952-2022
OI Chandra, Dr. Supriya Khaitan/0000-0002-3963-9536; Sagar,
   Shrddha/0000-0003-3647-1384
CR Abbasi SF, 2019, ADV INTELL SYST, V857, P764, DOI 10.1007/978-3-030-01177-2_56
   Ahmad Musheer, 2018, International Journal of Information Technology, V10, P247, DOI 10.1007/s41870-018-0099-y
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Çavusoglu Ü, 2019, CLUSTER COMPUT, V22, P1211, DOI 10.1007/s10586-018-02895-w
   Chen C, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12776-9
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Deng Xiao-Heng, 2014, Journal on Communications, V35, P216, DOI 10.3969/j.issn.1000-436x.2014.03.025
   Emary E, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158738
   Góra P, 2003, INT J BIFURCAT CHAOS, V13, P1299, DOI 10.1142/S0218127403007230
   Hao T, 2010, 2 INT C COMPUTER ENG, P2570
   Hegazy AE, 2019, ARAB J SCI ENG, V44, P3801, DOI 10.1007/s13369-018-3680-6
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Kalra M, 2019, INNOVATIONS COMPUTER, V74, DOI [10.1007/978-981-13-7082-3_20, DOI 10.1007/978-981-13-7082-3_20]
   Khaitan S., 2019, INT J RECENT TECHNOL, V8, P603
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Li XZ, 2018, INT J THEOR PHYS, V57, P2904, DOI 10.1007/s10773-018-3810-7
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Lu Zhen-su, 2004, Acta Electronica Sinica, V32, P416
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mariot Luca, 2015, P COMPANION PUBLICAT, P1425
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Pareek N, 2011, INT J NETWORK SECURI, DOI 10.5121/ijnsa.2011.3212
   Parlitz U, 1992, INT J BIFURCAT CHAOS, V2, P973, DOI 10.1142/S0218127492000823
   Rozouvan V, 2009, OPT LASER ENG, V47, P1, DOI 10.1016/j.optlaseng.2008.09.001
   Sayed GI, 2018, APPL INTELL, V48, P3462, DOI 10.1007/s10489-018-1158-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tubishat M, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113122
   Wang H, 2013, APPL MATH COMPUT, V221, P296, DOI 10.1016/j.amc.2013.06.074
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2019, OPT LASER ENG, V122, P225, DOI 10.1016/j.optlaseng.2019.04.005
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang DX, 2007, CHAOS SOLITON FRACT, V34, P1366, DOI 10.1016/j.chaos.2006.04.057
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhao J, 2011, 2011 INT C EL INF CO, P221, DOI [10.1109/ICEICE.2011.5777924, DOI 10.1109/ICEICE.2011.5777924]
NR 40
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39653
EP 39668
DI 10.1007/s11042-022-13535-2
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000836366300001
DA 2024-07-18
ER

PT J
AU You, MB
   Ban, LJ
   Wang, YH
   Kang, J
   Wang, GR
   Yuan, AH
AF You, Mengbo
   Ban, Lujie
   Wang, Yuhan
   Kang, Juan
   Wang, Guorui
   Yuan, Aihong
TI Unsupervised feature selection with joint self-expression and spectral
   analysis via adaptive graph constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised feature selection; Self-expression; Spectral analysis;
   Adaptive graph constraint
ID FACE
AB Unsupervised feature selection (UFS) plays a critical role in the maintenance of representative feature subset from high dimensional data. Both the spectral analysis model and the self-expression model are effective in selecting important features. However, few alternative methods embed these two models into a joint FS framework. To address this problem, we propose a novel UFS method that simultaneously selects the most representative feature subset and makes the selected feature subset discriminative by mapping the original features into the label space. Specifically, both the self-expression and spectral analysis are introduced into our method and the self-expression matrix is used as the FS matrix. The two modules are not simply added together, but interact with each other through two graph constraints which preserve the local structure and the manifold structure of the original data, respectively. Furthermore, this paper proposes an alternative iterative algorithm to solve the four matrices involved in the proposed method. To verify the effectiveness of our method, extensive experiments are implemented, and the experimental results prove that the proposed method achieves the best performance among the current state-of-the-art UFS methods. Moreover, an ablation study is performed to show the effectiveness of each part of the proposed method.
C1 [You, Mengbo; Ban, Lujie; Wang, Yuhan; Kang, Juan; Wang, Guorui; Yuan, Aihong] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [You, Mengbo; Yuan, Aihong] Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [You, Mengbo; Yuan, Aihong] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs
RP Yuan, AH (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.; Yuan, AH (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.; Yuan, AH (corresponding author), Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
EM ymb@nwafu.edu.cn; ahyuan@nwafu.edu.cn
RI Wang, Guorui/Y-8248-2019
OI Yuan, Aihong/0000-0002-7349-1483
FU National College Students Innovation and Entrepreneurship Training
   Program [S202010712042]; Natural Science Foundation of Shaanxi Province
   [2020JQ-279]; Doctoral Start-up Foundation of Northwest AF University
   [Z1090219095, Z109021803]
FX This work was supported in part by the National College Students
   Innovation and Entrepreneurship Training Program under Grant
   S202010712042, in part by the Natural Science Foundation of Shaanxi
   Province under Grant 2020JQ-279, in part by the Doctoral Start-up
   Foundation of Northwest A&F University under Grant Z1090219095, and
   Grant Z109021803.
CR Aihong Yuan, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12307), P185, DOI 10.1007/978-3-030-60636-7_16
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], 2012, P AAAI C ART INT
   Cai D., 2010, KDD, P333
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Cui GS, 2018, NEUROCOMPUTING, V292, P38, DOI 10.1016/j.neucom.2018.02.067
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gui J, 2017, IEEE T NEUR NET LEAR, V28, P1490, DOI 10.1109/TNNLS.2016.2551724
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Huang D, 2019, KNOWL-BASED SYST, V182, DOI 10.1016/j.knosys.2019.07.027
   Huang Q, 2020, AAAI CONF ARTIF INTE, V34, P4182
   Li WY, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108150
   Li XL, 2021, IEEE T CYBERNETICS, V51, P913, DOI 10.1109/TCYB.2019.2914351
   Li XL, 2019, IEEE T NEUR NET LEAR, V30, P1587, DOI 10.1109/TNNLS.2018.2868847
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu QM, 2018, NEUROCOMPUTING, V301, P36, DOI 10.1016/j.neucom.2018.04.001
   Luo C, 2022, INFORM SCIENCES, V586, P662, DOI 10.1016/j.ins.2021.11.068
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mi JX, 2013, OPTIK, V124, P6786, DOI 10.1016/j.ijleo.2013.05.099
   Murase Hiroshi, 1996, COLUMBIA OBJECT IMAG
   Nie FP, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9021-9
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI DOI 10.1145/1007730.1007731
   Qian M., 2013, P 23 INT JOINT C ART, P1621
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Venkatraman S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1728303
   Wang Q, 2022, IEEE T PATTERN ANAL, V44, P390, DOI 10.1109/TPAMI.2020.3007673
   Wang Q, 2022, IEEE T CYBERNETICS, V52, P10228, DOI 10.1109/TCYB.2021.3067137
   Wang Q, 2020, IEEE T GEOSCI REMOTE, V58, P8465, DOI 10.1109/TGRS.2020.2987955
   Xing E.P., 2001, P 18 INT C MACH LEAR, V1, P601, DOI DOI 10.3233/IDA-1997-1302
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   You MB, 2023, IEEE T KNOWL DATA EN, V35, P3030, DOI 10.1109/TKDE.2021.3124255
   Yuan AH, 2022, IEEE T CYBERNETICS, V52, P5522, DOI 10.1109/TCYB.2020.3034462
   Zhang R, 2019, IEEE T NEUR NET LEAR, V30, P2886, DOI 10.1109/TNNLS.2018.2884487
   Zhang R, 2018, IEEE T NEUR NET LEAR, V29, P3913, DOI 10.1109/TNNLS.2017.2740341
   Zhang R, 2017, IEEE IJCNN, P2784, DOI 10.1109/IJCNN.2017.7966199
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
   Zhou P, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107375
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 44
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5879
EP 5898
DI 10.1007/s11042-022-13426-6
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500001
DA 2024-07-18
ER

PT J
AU Puri, A
   Gupta, MK
   Sachdev, K
AF Puri, Arjun
   Gupta, Manoj Kumar
   Sachdev, Kanica
TI An ensemble-based approach using structural feature extraction method
   with class imbalance handling technique for drug-target interaction
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drug-target interaction; Class imbalance; Chemogenomic; Machine
   learning; Ensemble learning
ID CHEMICAL-STRUCTURE; IDENTIFICATION; CLASSIFICATION; NOISY; SMOTE
AB Various methods are developed to study drug-target interaction problems. One way to deal with the drug-target interaction problem is to use a wet laboratory, which is considered a time-consuming process. Another possible way is through computational techniques. These techniques are significant in terms of time and cost. However, computational techniques use traditional classifiers to predict drug-target interactions. Drug-target interaction datasets suffer from a class imbalance problem where non-interaction classes are large in number and interaction classes are less proportional. Traditional classifiers are affected by their biased nature towards the majority class. This article provides a proposed model which uses AM-PseAAC and MSF as feature representations for target and drug, respectively, and also uses SMOTE-ENN as a resampling technique to handle class imbalance. Finally, it uses a soft voting ensemble proposed by combining random forest and Xgboost ensemble learners. A comparison of the proposed model with the existing state of the art using standard datasets (enzyme, GPCR, Ion Channel, Nuclear Receptor) confirms that the proposed model outperforms. Experiments were performed at different stages of the proposed design, considering AUC, G-Mean, sensitivity, and specificity as performance metrics, which in turn validate our proposed framework.
C1 [Puri, Arjun; Gupta, Manoj Kumar; Sachdev, Kanica] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182023, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Puri, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182023, Jammu & Kashmir, India.
EM puri.arjun7@gmail.com; manoj.gupta@smvdu.ac.in; kanica.sachdev@gmail.com
RI Puri, Arjun/AAT-7751-2021
OI Puri, Arjun/0000-0003-1122-1442
CR Abdi H., 2010, ENCY RES DESIGN, V169, P1
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Bleakley K, 2009, BIOINFORMATICS, V25, P2397, DOI 10.1093/bioinformatics/btp433
   Bolton EE, 2010, ANN REP COMP CHEM, V4, P217, DOI 10.1016/S1574-1400(08)00012-1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Casini L, 2020, PHILOS ADV MEDICAL I, P81
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen C., 2004, USING RANDOM FOREST, V110, P24
   Chen HL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062975
   Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466
   Cunha L, 2014, DRUG DISCOV TODAY, V19, P936, DOI 10.1016/j.drudis.2014.01.003
   Ezzat A, 2017, METHODS, V129, P81, DOI 10.1016/j.ymeth.2017.05.016
   Ezzat A, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1377-y
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernández-Navarro F, 2011, PATTERN RECOGN, V44, P1821, DOI 10.1016/j.patcog.2011.02.019
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gaulton A, 2012, NUCLEIC ACIDS RES, V40, pD1100, DOI 10.1093/nar/gkr777
   Günther S, 2008, NUCLEIC ACIDS RES, V36, pD919, DOI 10.1093/nar/gkm862
   Hasanin T, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00301-0
   Hattori M, 2010, NUCLEIC ACIDS RES, V38, pW652, DOI 10.1093/nar/gkq367
   Huang YA, 2018, CURR PROTEIN PEPT SC, V19, P468, DOI 10.2174/1389203718666161122103057
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Johnson M. A., 1990, M 196 1988 LOS ANG C
   Kanehisa M, 2002, NOVART FDN SYMP, V247, P91
   Koziarski M, 2019, NEUROCOMPUTING, V343, P19, DOI 10.1016/j.neucom.2018.04.089
   Landry Y, 2008, FUND CLIN PHARMACOL, V22, P1, DOI 10.1111/j.1472-8206.2007.00548.x
   Law V, 2014, NUCLEIC ACIDS RES, V42, pD1091, DOI 10.1093/nar/gkt1068
   Lee W, 2017, INFORM SCIENCES, V381, P92, DOI 10.1016/j.ins.2016.11.014
   Li ZW, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10724-0
   Luque A, 2019, PATTERN RECOGN, V91, P216, DOI 10.1016/j.patcog.2019.02.023
   Mahadevan A, 2021, MULTIMED TOOLS APPL, V80, P6911, DOI 10.1007/s11042-020-10024-2
   Mahmud SMH, 2019, IEEE ACCESS, V7, P48699, DOI 10.1109/ACCESS.2019.2910277
   Mousavian Z, 2016, J PHARMACOL TOX MET, V78, P42, DOI 10.1016/j.vascn.2015.11.002
   Overington JP, 2006, NAT REV DRUG DISCOV, V5, P993, DOI 10.1038/nrd2199
   Puri A, 2019, IEEE Int. Conf. Issues Challenges Intell. Comput. Tech. ICICT 2019, DOI DOI 10.1109/ICICT46931.2019.8977650
   Rahman M. Mostafizur, 2013, International Journal of Machine Learning and Computing, V3, P59, DOI 10.7763/IJMLC.2013.V3.307
   Rayhan F, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18025-2
   Sachdev K, 2020, DRUG DEVELOP RES, V81, P650, DOI 10.1002/ddr.21669
   Sachdev K, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103159
   Sáez JA, 2015, INFORM SCIENCES, V291, P184, DOI 10.1016/j.ins.2014.08.051
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   van Laarhoven T, 2011, BIOINFORMATICS, V27, P3036, DOI 10.1093/bioinformatics/btr500
   Wang Wenhui, 2013, Pac Symp Biocomput, P53
   Xiao N, 2015, BIOINFORMATICS, V31, P1857, DOI 10.1093/bioinformatics/btv042
   Yamanishi Y, 2008, BIOINFORMATICS, V24, pI232, DOI 10.1093/bioinformatics/btn162
   Yamanishi Y, 2010, BIOINFORMATICS, V26, pi246, DOI 10.1093/bioinformatics/btq176
   ZIMMERMAN DW, 1993, J EXP EDUC, V62, P75, DOI 10.1080/00220973.1993.9943832
NR 49
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37499
EP 37517
DI 10.1007/s11042-022-13508-5
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000832843900003
DA 2024-07-18
ER

PT J
AU Wen, ZQ
   Lin, C
   Li, FZ
   Cui, LH
AF Wen, Zeqi
   Lin, Chuan
   Li, Fuzhang
   Cui, Linhao
TI Information recombination network for contour detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contour detection; VGG; Information recombination network
AB Convolutional Neural Network (CNN) has been widely used in various tasks of computer vision. For contour detection, the encoding network and decoding network structure are mainly used. The encoding network mainly uses existing networks such as VGG, and the decoding network that effectively integrates the features extracted from the encoding network has become a research hotspot in this field. To effectively integrate features, this paper proposes a Center-Far periphery and Center-Near periphery information recombination network (CFCN) based on the VGG encoding network. The decoding network is divided into three parts, Center-Far Periphery Layer (CF), Center-Near Periphery Layer (CN) and Central Base Layer (CB), the CF part aims to highlight the contour features of the main body, the CN part aims to highlight the contour details, and the CB provides benchmark information for the decoding network. Ultimately, the CF, CN, and CB are combined. On the basis of ensuring the complete contour of the main body, some detailed features are further retained. We used the F-measure for performance evaluation, and have achieved good performance on the BSDS and NYUD datasets. ODS = 0.818 on the BSDS dataset; the experimental result on the NYUD dataset is ODS = 0.764. The results show that it surpassed the human-level performance in each dataset.
C1 [Wen, Zeqi; Lin, Chuan; Li, Fuzhang; Cui, Linhao] Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Liuzhou 545006, Peoples R China.
C3 Guangxi University of Science & Technology
RP Lin, C (corresponding author), Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Liuzhou 545006, Peoples R China.
EM chuanlin@gxust.edu.cn
RI luo, chuan/IVH-5370-2023; lin, chuan/JBJ-7047-2023; lin,
   chuan/HHD-2571-2022; lin, chuan/HIK-1290-2022
OI lin, chuan/0000-0003-1779-1753
FU National Natural Science Foundation of China [61866002]; Guangxi Natural
   Science Foundation [2020GXNSFDA297006, 2018GXNSFAA138122,
   2015GXNSFAA139293]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61866002), Guangxi Natural Science Foundation (Grant
   No.2020GXNSFDA297006, Grant No. 2018GXNSFAA138122 and Grant No.
   2015GXNSFAA139293).
CR ABRAMATIC JF, 1981, COMPUT VISION GRAPH, V17, P79, DOI 10.1016/S0146-664X(81)80011-1
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Baldeon-Calisto M, 2020, NEUROCOMPUTING, V392, P325, DOI 10.1016/j.neucom.2019.01.110
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao YJ, 2021, IEEE T MULTIMEDIA, V23, P761, DOI 10.1109/TMM.2020.2987685
   Chowdhary CL, 2019, J APPL SCI ENG, V22, P691, DOI 10.6180/jase.201912_22(4).0011
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Gao LL, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P594
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782
   Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kazakova W, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P913
   Lin C, 2020, NEUROCOMPUTING, V409, P361, DOI 10.1016/j.neucom.2020.06.069
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Maninis KK, 2018, IEEE T PATTERN ANAL, V40, P819, DOI 10.1109/TPAMI.2017.2700300
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Ren X, 2012, ADV NEURAL INFORM PR, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252
   Seif A., 2010, 2010 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology (STUDENT 2010), P99, DOI 10.1109/STUDENT.2010.5686999
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tu ZW, 2005, IEEE I CONF COMP VIS, P1589
   Wang YP, 2017, PROC CVPR IEEE, P1724, DOI 10.1109/CVPR.2017.187
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zhang RF, 2021, J REAL-TIME IMAGE PR, V18, P647, DOI 10.1007/s11554-020-00980-1
   Zhang ZZ, 2016, PROC CVPR IEEE, P251, DOI 10.1109/CVPR.2016.34
NR 32
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3895
EP 3910
DI 10.1007/s11042-022-13430-w
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000826828100004
DA 2024-07-18
ER

PT J
AU Singh, R
   Ashok, A
   Saraswat, M
AF Singh, Roop
   Ashok, Alaknanda
   Saraswat, Mukesh
TI High embedding capacity based color image watermarking scheme using SBBO
   in RDWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Schur transform; Redundant discrete wavelet
   transform; Spiral biogeography-based optimization
ID DISCRETE WAVELET TRANSFORM; ROBUST; SVD; ALGORITHM; OPTIMIZATION; DWT
AB In a watermarking scheme, high embedding capacity and robust recovery is a challenging issue. The existing watermarking schemes embed either a binary or grayscale watermark in the luminance component of the color image, which influences the imperceptibility. Moreover, current schemes are lack of robustness against numerous image processing attacks. Therefore, this paper introduces a high embedding capacity-based color image watermarking scheme that embeds a watermark logo into the host image of the same dimension as the watermark logo. Arnold transform is employed to improve security while redundant discrete wavelet transform is used to increase embedding capacity in the suggested scheme. To balance the trade-off between imperceptibility and robustness, spiral biogeography-based optimization is employed, determining the optimum embedding factors. The hybridization of redundant discrete wavelet transform-Schur transform offers the shift-invariant, high embedding capacity and makes it computationally fast. The imperceptibility of the proposed scheme has been evaluated in terms of peak signal to noise ratio and similarity structure index while normalized correlation has been used for checking the robustness. The experiments validate the efficacy of the proposed scheme over twenty three watermarking attacks. Moreover, the proposed scheme outperforms the state-of-the-art schemes.
C1 [Singh, Roop] Uttarakhand Tech Univ, Dept Elect Commun Engn, Dehra Dun, Uttarakhand, India.
   [Ashok, Alaknanda] GB Pant Univ Agr & Technol, Coll Technol, Pantnagar 263153, Uttarakhand, India.
   [Saraswat, Mukesh] Jaypee Inst Informat Technol, Noida, India.
C3 Uttarakhand Technical University; Govind Ballabh Pant University of
   Agriculture Technology; Jaypee Institute of Information Technology
   (JIIT)
RP Singh, R (corresponding author), Uttarakhand Tech Univ, Dept Elect Commun Engn, Dehra Dun, Uttarakhand, India.
EM roopsolanki@gmail.com; alakn@rediffmail.com; saraswatmukesh@gmail.com
RI SINGH, ROOP/HHN-4945-2022
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Al-Otum HM, 2010, SIGNAL PROCESS, V90, P2498, DOI 10.1016/j.sigpro.2010.02.017
   Anand A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P366, DOI 10.1109/BigMM50055.2020.00063
   [Anonymous], 2020, SIPI
   Ansari IA, 2018, ARAB J SCI ENG, V43, P4085, DOI 10.1007/s13369-017-2777-7
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Chen BJ, 2018, MULTIMED TOOLS APPL, V77, P20809, DOI 10.1007/s11042-017-5511-2
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Dogan S, 2011, ADV ENG SOFTW, V42, P336, DOI 10.1016/j.advengsoft.2011.02.012
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Garg P, 2020, J INFORM OPTIM SCI, V41, P1499, DOI 10.1080/02522667.2020.1802124
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gupta M, 2014, 2014 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE)
   Hien TD, 2006, ADV SOFT COMP, V34, P401, DOI 10.1007/3-540-31662-0_31
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Karajeh H, 2019, MULTIMED TOOLS APPL, V78, P18395, DOI 10.1007/s11042-019-7214-3
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P13975, DOI 10.1007/s11042-020-10397-4
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P9315, DOI 10.1007/s11042-020-09943-x
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Lang FN, 2012, EXPERT SYST APPL, V39, P12046, DOI 10.1016/j.eswa.2012.03.070
   Lim WL, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/5803893
   Ma HP, 2011, ENG APPL ARTIF INTEL, V24, P517, DOI 10.1016/j.engappai.2010.08.005
   Ma HP, 2010, INFORM SCIENCES, V180, P3444, DOI 10.1016/j.ins.2010.05.035
   Mahoney MichaelSean., 1994, MATH CAREER PIERRE F
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mittal H, 2021, MULTIMED TOOLS APPL, V80, P7581, DOI 10.1007/s11042-020-09831-4
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pal R, 2019, APPL INTELL, V49, P3406, DOI 10.1007/s10489-019-01460-1
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Rajab L., 2015, J Softw Eng Appl, V08, P224, DOI [10.4236/jsea.2015.84023, DOI 10.4236/JSEA.2015.84023]
   Roy A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P537, DOI 10.1109/SPIN.2015.7095399
   Roy S, 2018, WIRELESS PERS COMMUN, V98, P2223, DOI 10.1007/s11277-017-4971-z
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Saraswat M, 2020, C INTELLIGENT SYSTEM, P31
   Saxena N, 2018, Adv Intell Syst Comput, P343, DOI DOI 10.1007/978-981-10-3773-3_34
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Singh R, 2011, INT C ADV COMP COMM, P948
   Singh R, 2020, C INTELLIGENT SYSTEM, P443
   Singh R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102734
   Singh R, 2020, IET IMAGE PROCESS, V14, P2052, DOI 10.1049/iet-ipr.2019.1059
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang GG, 2014, APPL MATH MODEL, V38, P2454, DOI 10.1016/j.apm.2013.10.052
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
NR 62
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3397
EP 3432
DI 10.1007/s11042-022-13286-0
EA JUL 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000820945600002
DA 2024-07-18
ER

PT J
AU Khan, U
   Yasin, A
   Jalal, A
   Abid, M
AF Khan, Usman
   Yasin, Amanullah
   Jalal, Ahmed
   Abid, Muhammad
TI Achieving enhanced accuracy and strength performance with parallel
   programming for invariant affine point cloud registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuda; Point cloud; Reconstruction; Tomography; Virtual reality
ID RECONSTRUCTION; ALGORITHM
AB Affine-transform of tomographic images maps pixels from image to world coordinates. However, affine transform application on each pixel consumes much time. Extraction of the point cloud of interest from the background is another challenge. The benchmark algorithms use approximations, therefore, compromising accuracy. Because of this fact, there arises a need for affine registration for 3D reconstruction. In this work, we present a computationally efficient affine registration of Digital Imaging and COmmunications in Medicine (DICOM) images. We introduce a novel GPU accelerated hierarchical clustering algorithm using Gaussian thresholding of inter-coordinate distances followed by maximal mutual information score merging for clutter removal. We also show that the reconstructed 3d models using our methodology have a best-case minimum error of 0.18 cm against physical measurements and have higher structural strength. This algorithm should apply to reconstruction, 3D printing, virtual reality, and 3D visualization.
C1 [Khan, Usman] SS CASE IT, Dept Elect & Comp Engn, St 33,Block A,Sect B-17, Islamabad, Pakistan.
   [Yasin, Amanullah; Jalal, Ahmed] Air Univ, PAF Complex E9, Islamabad, Pakistan.
   [Abid, Muhammad] COMSATS Univ Islamabad, Interdisciplinary Res Ctr, Wah Campus, Islamabad, Pakistan.
   [Abid, Muhammad] COMSATS Univ Islamabad, Dept Mech Engn, Wah Campus, Wah Cantt, Pakistan.
C3 Air University Islamabad; COMSATS University Islamabad (CUI); COMSATS
   University Islamabad (CUI)
RP Khan, U (corresponding author), SS CASE IT, Dept Elect & Comp Engn, St 33,Block A,Sect B-17, Islamabad, Pakistan.
EM usmankhanakbar@gmail.com; amanyasin@mail.au.edu.pk;
   ahmadjalal@mail.au.edu.pk; drabid@ciitwah.edu.pk
RI Abid, Muhammad/ADZ-2832-2022
OI Abid, Muhammad/0000-0002-1611-4964; Khan, Usman/0000-0001-7312-0028
CR [Anonymous], 1996, NAIWEN SHADED SURFAC
   [Anonymous], INTRO DICOM
   [Anonymous], 2020, RadiAnt DICOM Viewer
   [Anonymous], 2020, BONE CT SCAN DATA
   Asamoah D., 2018, INT J COMPUTER APPL, V181, P0975
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bohak C, 2020, ADV EXPT MED BIOL, V1235, DOI [10.1007/978-3-030-37639-01, DOI 10.1007/978-3-030-37639-01]
   Boileau P, 2018, J BONE JOINT SURG AM, V100, P57, DOI 10.2106/JBJS.16.01122
   Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P9
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Glaser DA, 2012, SPINE, V37, P1391, DOI 10.1097/BRS.0b013e3182518a15
   Kadioglu HH, 2006, Turk Neurosurg, V16, P69
   Kajiya J. T., 1983, Computer Graphics, V17, P91, DOI 10.1145/964967.801137
   Kanitsar A, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P37, DOI 10.1109/VISUAL.2002.1183754
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Khan U, 2020, USMANKHANAKBAR AFFIN
   Khan U., 2020, Medical Imaging and Radiation Sciences, P1, DOI DOI 10.31487/J.MIRS.2020.01.02
   Khan U, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1042-2
   Kim M, 2012, IMAGNG SCI DENT, V42, P25, DOI 10.5624/isd.2012.42.1.25
   Kumar S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1623854
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   Lee SY, 2018, J KOREAN PHYS SOC, V72, P805, DOI 10.3938/jkps.72.805
   LEVOY M, 1990, IEEE COMPUT GRAPH, V10, P33, DOI 10.1109/38.50671
   Li C, 2020, ADV ENG DESIGN SIMUL, P109
   Loizou CP, 2017, COMP MED SY, P419, DOI 10.1109/CBMS.2017.53
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Maqbool M, 2017, INTRODUCTION TO MEDI, DOI [10.1007/978-3-319-61540-08, DOI 10.1007/978-3-319-61540-08]
   Patel NP, 2016, Int J Res Med Sci, V4, P4380
   Pieper S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P632
   Sato Y, 1998, J COMPUT ASSIST TOMO, V22, P912, DOI 10.1097/00004728-199811000-00014
   Schulze JP, 2003, PARALLEL COMPUT, V29, P339, DOI 10.1016/S0167-8191(02)00250-8
   Sherekar R., 2014, AM J MECHAN ENG AUTO, V1, P48
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westover LA., 1992, SPLATTING PARALLEL F
NR 35
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2587
EP 2615
DI 10.1007/s11042-022-13178-3
EA JUL 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819704400002
DA 2024-07-18
ER

PT J
AU Yan, RY
   Yang, MQ
   Zheng, QH
   Wang, DQ
   Peng, C
AF Yan, Ruyu
   Yang, Mingqiang
   Zheng, Qinghe
   Wang, Deqiang
   Peng, Cheng
TI Facial expression recognition based on hybrid geometry-appearance and
   dynamic-still feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; LBP-TOP; Gabor feature; Geometric
   feature; Feature fusion
ID FACE; NETWORK; PATTERNS; SYSTEM
AB Emotion recognition through facial expression is regarded as one of the most effective methods to directly reflect a person's inner emotional state for affective computing. However, a key issue of facial expression recognition (FER) is how to design and fuse features from videos rapidly and thus extract representative features to improve the recognition accuracy efficaciously. In this paper, we propose a novel expression recognition framework to mitigate this issue. Specifically, we first present a new descriptor, the improved Local Binary Pattern from Three Orthogonal Planes (I-LBP-TOP), which can extract both the static and dynamic features in changing expressions, and set Gabor's magnitude feature (GMF) as texture information. Meanwhile, the facial landmarks of the peak frame are proposed to represent geometric feature (GF) and the spatiotemporal geometric feature (ST-GF) is obtained by extending it to time dimension. Then we integrate multiple features of image sequences to overcome the limitation of using one single feature descriptor. A support vector machine (SVM) with multiple kernels is applied to train three base classifiers. Finally, to realize reliable expression classification, a decision-level feature fusion method based on a relative majority voting (MV) strategy is also employed. Intensive experiments are conducted on the CK+ and Oulu-CASIA databases, where the experimental results demonstrate that our proposed method achieves an improved performance compared with the existing state-of-the-art hand-crafted approaches.
C1 [Yan, Ruyu; Yang, Mingqiang; Zheng, Qinghe; Wang, Deqiang; Peng, Cheng] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Shandong, Peoples R China.
C3 Shandong University
RP Yang, MQ (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao 266237, Shandong, Peoples R China.
EM yan17860779713@163.com; imageinstitute@outlook.com; 15005414319@163.com;
   wdq_sdu@sdu.edu.cn; chengpeng8169@163.com
FU National Key R&D Program of China [2018YFC0831503]; National Natural
   Science Foundation of China [61571275]; Shenzhen Science and Technology
   Research and Development Funds [JCYJ20170818104011781]
FX This research was supported by National Key R&D Program of China
   (2018YFC0831503), National Natural Science Foundation of China
   (61571275), Shenzhen Science and Technology Research and Development
   Funds (JCYJ20170818104011781).
CR Acevedo D, 2016, INT C PATT RECOG, P4124, DOI 10.1109/ICPR.2016.7900280
   Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   Awad A.I., 2016, Image Feature Detectors and Descriptors: Foundations and Applications, V1st
   Ben Tanfous A, 2020, IEEE T PATTERN ANAL, V42, P2594, DOI 10.1109/TPAMI.2019.2932979
   Bonab H, 2019, IEEE T NEUR NET LEAR, V30, P2735, DOI 10.1109/TNNLS.2018.2886341
   Bougourzi F, 2019, IET IMAGE PROCESS, V13, P1479, DOI 10.1049/iet-ipr.2018.6235
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen LF, 2018, IEEE T COGN DEV SYST, V10, P647, DOI 10.1109/TCDS.2017.2728003
   Clien JK, 2015, IEEE IMAGE PROC, P4967, DOI 10.1109/ICIP.2015.7351752
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DuoFeng, 2018, INT CONF CLOUD COMPU, P355, DOI 10.1109/CCIS.2018.8691380
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Gao T, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P2242, DOI 10.1109/FSKD.2017.8393119
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Gupta S, 2017, INT CONF COMM SYST, P163, DOI [10.1109/CSNT.2017.31, 10.1109/CSNT.2017.8418530]
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hassaballah M, 2013, SIGNAL IMAGE VIDEO P, V7, P307, DOI 10.1007/s11760-011-0239-3
   Hassaballah M., 2019, Recent Advances in Computer Vision: Theories and Applications
   Hassaballah M., 2011, International Journal of Computer Science Issues (IJCSI), V8, P272
   Hu M, 2019, IEEE ACCESS, V7, P118435, DOI 10.1109/ACCESS.2019.2936976
   Huang XH, 2012, PATTERN RECOGN LETT, V33, P2181, DOI 10.1016/j.patrec.2012.07.015
   Jan A, 2018, IEEE T COGN DEV SYST, V10, P668, DOI 10.1109/TCDS.2017.2721552
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Liliana DY, 2018, INT C ADV COMP SCI I, P391, DOI 10.1109/ICACSIS.2018.8618248
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu Y, 2020, IEEE T COGN DEV SYST, V12, P311, DOI 10.1109/TCDS.2019.2917711
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Meng DB, 2019, IEEE IMAGE PROC, P3866, DOI [10.1109/ICIP.2019.8803603, 10.1109/icip.2019.8803603]
   Ming Z, 2019, ARXIV 191103281
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2020, IEEE ACCESS, V8, P65340, DOI 10.1109/ACCESS.2020.2985086
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sadeghi H, 2013, IRAN CONF MACH, P159, DOI 10.1109/IranianMVIP.2013.6779970
   Sahoo S, 2016, IEEE STUDENT TECHNOL, P7, DOI 10.1109/TechSym.2016.7872646
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shanthi P, 2021, MULTIMED TOOLS APPL, V80, P10187, DOI 10.1007/s11042-020-10105-2
   Sikka Karan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301350
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Nguyen VD, 2014, IEEE T CIRC SYST VID, V24, P263, DOI 10.1109/TCSVT.2013.2254898
   Wang GJ, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1601, DOI 10.1109/CompComm.2017.8322810
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3017608
   Zheng Q., 2019, IAENG International Journal of Computer Science, V46, P178
   Zheng QH, 2020, MULTIDIM SYST SIGN P, V31, P793, DOI 10.1007/s11045-019-00686-z
NR 60
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2663
EP 2688
DI 10.1007/s11042-022-13327-8
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819704400005
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Acquisition super resolution from infrared images using proposed
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IR images; SR; SKLI; REI; LSI; Neural network; TKLI
ID SUPERRESOLUTION; INTERPOLATION
AB This paper suggests three novel proposed techniques for super resolution (SR) infrared (IR) images. The first algorithm is relied on the image acquisition model, which considers benefits of the sparse representations of low resolution (LR) and high resolution (HR) patches using Bi-cubic interpolation and minimum mean square error (MMSE) estimation. This estimation in HR image prediction stage providing a scheme can be interpreted as a feed forward neural network. The second scheme is based on up-sampling for IR images using Second Kernel Lanczos Interpolation (SKLI).The third scheme is depended on up-sampling for IR images using Third Kernel Lanczos Interpolation (TKLI).This technique is typically used to increase the sampling rate of a digital signal, or to shift it by a fraction of the sampling interval. The performance metrics are Peak Signal-To-Noise Ratio (PSNR) and computation time. Simulation results prove that the success of three presented techniques in acquisition high resolution of SR IR images. By comparing the three presented algorithms with Regularized Interpolation (REI) and least squares Interpolation (LSI) schemes of IR images. It is clear that the second suggested technique gives superior than REI and LSI schemes from point views PSNR and computation time. On the other hand the third presented technique is the best algorithms from point views PSNR and computation time to other techniques.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, SharqiaBilbis, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, SharqiaBilbis, Egypt.
EM eng_h_2006@yahoo.com
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, J BRAZ COMPUT SOC, DOI DOI 10.1590/S0104-65002006000100006
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P21539, DOI 10.1007/s11042-020-08899-2
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba HI, 2011, CIRC SYST SIGNAL PR, V30, P543, DOI 10.1007/s00034-010-9243-z
   Ashiba MI, 2020, MULTIMED TOOLS APPL, V79, P23111, DOI 10.1007/s11042-020-09039-6
   Bahy RM, 2014, SIGNAL PROCESS, V103, P155, DOI 10.1016/j.sigpro.2014.01.008
   Chen T, 2001, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2001.941305
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Han JK, 2001, OPT ENG, V40, P540, DOI 10.1117/1.1355250
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Mao YX, 2016, INFRARED PHYS TECHN, V76, P735, DOI 10.1016/j.infrared.2016.05.001
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Shin JH, 1998, IEEE T CONSUM ELECTR, V44, P1042, DOI 10.1109/30.713232
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XM, 2016, J SYST ARCHITECT, V64, P11, DOI 10.1016/j.sysarc.2015.11.007
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhao Y, 2016, INFRARED PHYS TECHN, V76, P139, DOI 10.1016/j.infrared.2016.02.001
   Zhao Y, 2015, INFRARED PHYS TECHN, V71, P506, DOI 10.1016/j.infrared.2015.06.017
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
NR 35
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2329
EP 2348
DI 10.1007/s11042-022-13273-5
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814956100001
DA 2024-07-18
ER

PT J
AU Bruno, A
   Capasso, P
   Cattaneo, G
   Petrillo, UF
   Improta, R
AF Bruno, Andrea
   Capasso, Paola
   Cattaneo, Giuseppe
   Petrillo, Umberto Ferraro
   Improta, Riccardo
TI A novel image dataset for source camera identification and image based
   recognition systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Recognition; Source camera identification; Pixel
   non-uniformity noise
AB Multimodal emotion recognition has attracted a great deal of attention in recent years, with new interesting applications now being considered. One promising application is in the digital image forensics fields where, for example, it gives the possibility to automatically highlight subjects that are in pain, in digital images under examination, by analyzing their facial expressions. However, finding an image that represents a possible crime leaves the problem of identifying the device used to take the image open. Such a problem has been addressed by Source Camera Identification algorithms (SCI, for short). These algorithms analyze some features hidden in a target image to find traces left by the sensor that captured the image. A particularly challenging case is when the candidate source cameras for an image under investigation are of the same manufacturer and model. A fair and universal assessment of these algorithms is only possible if standard datasets are used for their benchmarking. However, our comprehensive analysis has shown that the majority of the datasets proposed so far contain a collection of images taken with different types of cameras, mostly smartphones. We fill this gap by presenting UNISA2020, a novel image dataset that contains a large collection of real-world images taken with multiple conventional digital cameras of the same type. The images in our dataset have been assembled so as to avoid artifacts that could negatively affect the identification process. To validate our dataset, we also performed a comparative experimental analysis to investigate the performance of an SCI reference algorithm when running on our dataset as well as on other SCI standard datasets.
C1 [Bruno, Andrea; Capasso, Paola; Cattaneo, Giuseppe] Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
   [Petrillo, Umberto Ferraro] Univ Roma La Sapienza, Dipartimento Sci Stat, Rome, Italy.
   [Improta, Riccardo] Minist Interno, Dipartimento Pubbl Sicurezza, Serv Polizia Postale & Comunicaz, Ctr Nazl Contrasto Pedopornog Online CNCPO, Via Tuscolana 1548, I-00173 Rome, Italy.
C3 University of Salerno; Sapienza University Rome
RP Capasso, P (corresponding author), Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
EM andbruno@unisa.it; pcapasso@unisa.it; cattaneo@unisa.it;
   umberto.ferraro@uniroma1.it; riccardoimprota@gmail.com
RI Capasso, Paola/ACO-3819-2022; Cattaneo, Giuseppe/R-4680-2016
OI Capasso, Paola/0000-0002-5236-0492; 
FU Universit`a degli Studi di Salerno within the CRUI-CARE Agreement
FX Open access funding provided by Universit`a degli Studi di Salerno
   within the CRUI-CARE Agreement.
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Al Shaya O, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113801
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2005, PROX 2 ANN C INF SEC
   [Anonymous], 2017, THESIS
   Banerjee Dipan, 2021, Proceedings of the 2021 8th International Conference on Computing for Sustainable Global Development (INDIACom), P306, DOI 10.1109/INDIACom51348.2021.00053
   Bnhm, 2004, CALPHOTOS
   Bruno A, 2021, PATTERN RECOGN LETT, V151, P3, DOI 10.1016/j.patrec.2021.07.008
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Christlein V, 2010, IEEE INT WORKS INFOR
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Galdi C, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P648, DOI 10.5220/0007403706480655
   Gloe T., 2010, P SAC 10 2010 ACM S, P1584
   Goljan Miroslav, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.805701
   Goljan M, 2009, LECT NOTES COMPUT SC, V5450, P454, DOI 10.1007/978-3-642-04438-0_38
   Gupta B, 2018, DIGIT INVEST, V24, P121, DOI 10.1016/j.diin.2018.02.003
   Hadwiger Benjamin, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P500, DOI 10.1007/978-3-030-68780-9_40
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Liu YX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144701
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Milliet Q, 2014, SCI JUSTICE, V54, P470, DOI 10.1016/j.scijus.2014.07.001
   Ng T.T., 2004, ADVENT Technical Report
   Ramzan M, 2019, IEEE ACCESS, V7, P107560, DOI 10.1109/ACCESS.2019.2932114
   Richter F, 2010, DIGITAL CAMERA SALES
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Tang JY, 2007, IEEE T CIRC SYST VID, V17, P384, DOI 10.1109/TCSVT.2006.888941
   Tian HW, 2019, IEEE ACCESS, V7, P101046, DOI 10.1109/ACCESS.2019.2928356
   Tiwari M, 2018, FORENSIC SCI INT, V285, P111, DOI 10.1016/j.forsciint.2018.02.005
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
NR 36
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11221
EP 11237
DI 10.1007/s11042-022-13354-5
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000812445100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sathiamoorthy, S
   Saravanan, A
   Ponnusamy, R
AF Sathiamoorthy, S.
   Saravanan, A.
   Ponnusamy, R.
TI Mixture of histograms of autocorrelation based Chordiogram image
   descriptor for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE -Chordiogram image descriptor; Autocorrelation; Concentric square; Chord
   details
ID PLACE RECOGNITION; FAB-MAP; LOCALIZATION; FEATURES; SCALE; SHAPE;
   REPRESENTATION; EFFICIENT; ROTATION; PATTERN
AB This work proposes a novel feature descriptor for places image retrieval and we named it as mixture of histograms of autocorrelation based chordiogram image descriptor. The chordiogram image descriptor computes chord details from every pair of predominant edgels in a patch of image. The autocorrelation based chordiogram image descriptor estimates chord and its underlying texture details from identical predominant pair of edgels at distance 1. Though autocorrelation based chordiogram image descriptor is rich in chord and its underlying texture details and computed at more local level, exploitation of only one local feature for each of point interest leads to lose in spatial details which significantly affects retrieval accuracy. Moreover, autocorrelation based chordiogram image descriptor is sensitive to noise and its computation cost is significantly high. To address these issues, mixture of histograms of autocorrelation based chordiogram image descriptor is proposed in this paper. The proposed feature descriptor is computed from concentric squares 1 and 2 for each point of interest and it captures chord and its underlying texture and spatial details along with the corresponding relationship among the local features and the concentric squares. The proposed feature descriptor is assessed by performing comprehensive experiments on three image databases namely Garden point walking, St. Lucia and UA. The results demonstrate that the proposed feature descriptor performs significantly well for places image retrieval than the state-of-the-art feature descriptors in terms of performance and robustness to illumination, view pose and scaling changes.
C1 [Sathiamoorthy, S.; Saravanan, A.; Ponnusamy, R.] Annamalai Univ, Dept Comp & Informat Sci, Annamalainagar, India.
C3 Annamalai University
RP Sathiamoorthy, S (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Annamalainagar, India.
EM ks_sathia@yahoo.com; saraneseau@gmail.com; povi2006@gmail.com
OI R, Ponnusamy/0000-0003-2515-3727
CR Andreasson H., 2004, IFAC Proc., V37, P36
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bennet Rajesh M, 2020, 4 INT C COMPUTING ME, P465
   Bingyi Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P726, DOI 10.1007/978-3-030-58565-5_43
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Gholipour F, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P67, DOI 10.1109/IKT.2014.7030335
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Khaliq A, 2020, IEEE T ROBOT, V36, P561, DOI 10.1109/TRO.2019.2956352
   Kosecká J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   McManus C., 2014, ROBOTICS SCI SYSTEMS
   Mei Christopher., 2009, BMVC, P1, DOI DOI 10.5244/C.23.54.
   Merrill N., 2018, ROBOTICS SCI SYSTEMS
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murillo AC, 2007, IEEE INT CONF ROBOT, P3901, DOI 10.1109/ROBOT.2007.364077
   Murillo A. C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483
   O'Mahony Niall, 2020, Advances in Computer Vision. Proceedings of the 2019 Computer Vision Conference (CVC). Advances in Intelligent Systems and Computing (AISC 943), P128, DOI 10.1007/978-3-030-17795-9_10
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Saravanan A, 2019, 4 INT C COMMUNICATIO
   Seetharaman K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P68
   Siméoni O, 2019, PROC CVPR IEEE, P11643, DOI 10.1109/CVPR.2019.01192
   Singh G., 2010, ICRA Omnidirectional Vision Workshop
   Sivakumar S, 2020, PROCEEDING INT C COM, DOI [10.1007/978-3-030-43192-1_60, DOI 10.1007/978-3-030-43192-1_60]
   Sivakumar S., 2020, INT J FUTURE GEN COM, V13, P71
   Sünderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590
   Tomitca MA, 2020, ARXIV200913454
   Toshev A, 2012, INT J COMPUT VISION, V99, P123, DOI 10.1007/s11263-012-0521-z
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010
   Wang XL, 2017, J VIS COMMUN IMAGE R, V49, P129, DOI 10.1016/j.jvcir.2017.09.005
   Widya Aji Resindra, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0042-y
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Yang Y, 2018, PATTERN RECOGN, V76, P162, DOI 10.1016/j.patcog.2017.10.035
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zaffar M, 2021, INT J COMPUT VISION, V129, P2136, DOI 10.1007/s11263-021-01469-5
   Zaffar M, 2020, IEEE ROBOT AUTOM LET, V5, P1835, DOI 10.1109/LRA.2020.2969917
   Zeng ZQ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112257
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang XW, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107760
   Zitnick CL, 2010, LECT NOTES COMPUT SC, V6312, P170, DOI 10.1007/978-3-642-15552-9_13
NR 60
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1313
EP 1332
DI 10.1007/s11042-022-13200-8
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000811421000002
DA 2024-07-18
ER

PT J
AU Mozaffari, S
   Hamidi, HR
AF Mozaffari, Sonia
   Hamidi, Hamid Reza
TI Impacts of augmented reality on foreign language teaching: a case study
   of Persian language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Language Teaching; Foreign Language; Persian
ID CHALLENGES
AB The use of information technology in the field of foreign language teaching as an auxiliary tool is very important. In a foreign language classroom, place is just an abstract concept; where the language is separated from the community, culture and places in which it is used. Augmented reality is a technology in which virtual components are simultaneously combined with the real environment. Our aim in this study is to investigate the effects of location-based augmented reality in teaching Persian as a foreign language. In this study, after consulting with professors in the field of Persian language teaching and reviewing similar researches, we came to the conclusion that nothing has been done to teach Persian language using augmented reality. Therefore, a Persian game based on augmented reality was designed and implemented and then evaluated. For evaluation, two methods have been used; the user and the heuristic evaluation. Experts in the field of Persian language teaching, human-computer interaction and a number of language learners participated in the evaluation. Their feedback shows that the use of augmented reality increases satisfaction, enthusiasm and interaction with the environment and people, and also makes the process of learning and memorizing concepts more efficient.
C1 [Mozaffari, Sonia; Hamidi, Hamid Reza] Imam Khomeini Int Univ, Fac Engn & Technol, Comp Engn Dept, Qazvin, Iran.
C3 Imam Khomeini International University
RP Hamidi, HR (corresponding author), Imam Khomeini Int Univ, Fac Engn & Technol, Comp Engn Dept, Qazvin, Iran.
EM soniamozaffari@gmail.com; hamidreza.hamidi@eng.ikiu.ac.ir
OI Hamidi, Hamid Reza/0000-0001-6346-3318
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Cervi-Wilson T, 2018, INNOVATIVE LANGUAGE, P4958
   Collins A., 1988, Thinking, J. Philosophy Child., V8, P2, DOI [DOI 10.5840/THINKING19888129, 10.5840/thinking19888129]
   Freitas R., 2008, Proceedings of the 22nd British HCI Group Annual Conference on People and Computers: Culture, Creativity, Interaction, VVolume 22, P27
   Garrett James J., 2011, The elements of user experience: User-centered design for the web
   Geroimenko V., 2020, Augmented reality in education
   Godwin-Jones R, 2016, LANG LEARN TECHNOL, V20, P9
   Hadid A., 2019, Florida Journal of Educational Research, V57, P81
   Holden CL, 2011, INT J GAME-BASED LEA, V1, P1, DOI 10.4018/ijgbl.2011040101
   Huang XY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13094639
   Jadavi-Safa A., 2018, International Journal of Education Literacy Studies, V6, P15, DOI DOI 10.7575/AIAC.IJELS.V.6N.2P.15
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Liu TY, 2010, LECT NOTES COMPUT SC, V5960, P37, DOI 10.1007/978-3-642-12349-8_3
   Bojóquez EM, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/1069581
   Nielsen J., 1990, SIGCHI Bulletin, P249
   Parmaxi A, 2020, J COMPUT ASSIST LEAR, V36, P861, DOI 10.1111/jcal.12486
   Perry B, 2015, PROCD SOC BEHV, V174, P2308, DOI 10.1016/j.sbspro.2015.01.892
   Rahimi M, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019844081
   Rao P. S., 2019, ELT Vibes: International E-Journal for Research in ELT, V5, P136
   Riahi Chelvani, 2014, THESIS ALLAMEH TABAT
   Safar AH, 2017, EURASIA J MATH SCI T, V13, P417, DOI 10.12973/eurasia.2017.00624a
   Santos Marc Ericson C, 2016, Res Pract Technol Enhanc Learn, V11, P4, DOI 10.1186/s41039-016-0028-2
   Savitri AS, 2013, THESIS YOGYKARTA STA
   Scrivner O, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P395, DOI 10.1109/FTC.2016.7821639
   Toda AM, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-019-0106-1
   Tuli N, 2020, PROCEDIA COMPUTER SC, V172
   Wilson Chauncey., 2014, USER INTERFACE INSPE
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yurko NA, 2020, EUROPEAN SCI PLATFOR
NR 30
TC 4
Z9 4
U1 7
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4735
EP 4748
DI 10.1007/s11042-022-13370-5
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000810858900001
PM 35729930
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kliangkhlao, M
   Limsiroratana, S
AF Kliangkhlao, Mallika
   Limsiroratana, Somchai
TI Harnessing the power of big data digitization for market factors
   awareness in supply chain management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-series Decomposition; Demand and supply; Open Data Sensors; Machine
   learning; Statistical significance; Big Data Analysis
ID DATA ANALYTICS; REGRESSION; YIELD
AB An increasing complication due to the rise of dynamic trades and global industry causes a burden in decision-making. There is a need for multi-level perspective factors in supply chain management, such as short-long terms of demand and supply, and their impact on agricultural market dynamics. In this study, Big data is proposed as supply chain open data sensors for data digitization to deal with the problem. Although Big data supports comprehensive, real-time sources, and provides information about market functions, traditional machine learning technologies have proved insufficient for dealing with Big data characteristics. We then propose a time-series decomposition approach for extracting contexts about short-long term impacts to provide insights into Big data for determining market demand and supply. Our agri-big data digitization reveals the significant information about Big data with the better predictive ability and can support agri-big data analysis using any kind of machine learning model.
C1 [Kliangkhlao, Mallika; Limsiroratana, Somchai] Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Thailand.
C3 Prince of Songkla University
RP Kliangkhlao, M (corresponding author), Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Thailand.
EM kliangkhlao.m@gmail.com; somchai.l@psu.ac.th
RI Kliangkhlao, Mallika/JSL-5981-2023
OI Kliangkhlao, Mallika/0000-0002-1534-3255
CR Abdollahpour Shamsollah, 2020, Information Processing in Agriculture, V7, P500, DOI 10.1016/j.inpa.2020.01.003
   [Anonymous], 2019, INSIDER M
   Arunwarakorn S., 2019, Kasetsart Journal of Social Sciences, V40, P8
   Bank of Thailand, 2021, DAIL FOR EXCH RAT
   Belaud JP, 2019, COMPUT IND, V111, P41, DOI 10.1016/j.compind.2019.06.006
   Bocca FF, 2016, COMPUT ELECTRON AGR, V128, P67, DOI 10.1016/j.compag.2016.08.015
   Borodin V, 2016, EUR J OPER RES, V254, P348, DOI 10.1016/j.ejor.2016.03.057
   Chanchaichujit J., 2018, USING SIMULATION TOO, P19, DOI [10.1007/978-3-319-55816-5_2, DOI 10.1007/978-3-319-55816-5_2]
   Chen JC, 2018, IEEE INT C IND ENG E, V2017, P432
   Feurer M, 2019, SPRING SER CHALLENGE, P113, DOI 10.1007/978-3-030-05318-5_6
   Gardas BB, 2019, SUSTAIN PROD CONSUMP, V18, P19, DOI 10.1016/j.spc.2018.11.007
   Gaso DV, 2019, COMPUT ELECTRON AGR, V159, P75, DOI 10.1016/j.compag.2019.02.026
   Golmohammadi A, 2019, EUR J OPER RES, V275, P1037, DOI 10.1016/j.ejor.2018.12.027
   Gopal PSM, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104968
   Govindan K, 2018, TRANSPORT RES E-LOG, V114, P343, DOI 10.1016/j.tre.2018.03.011
   Hatami-Marbini A, 2022, OPER RES-GER, V22, P263, DOI 10.1007/s12351-020-00556-8
   Iceland Meteorological Office (IMO), 2019, CLIM CTR
   Ip RHL, 2018, COMPUT ELECTRON AGR, V151, P376, DOI 10.1016/j.compag.2018.06.008
   Kamble SS, 2020, INT J PROD ECON, V219, P179, DOI 10.1016/j.ijpe.2019.05.022
   Kim Y, 2015, MULTIMED TOOLS APPL, V74, P8849, DOI 10.1007/s11042-013-1632-4
   Kliangkhlao M, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND COMPUTER APPLICATIONS (ICSCA 2019), P81, DOI 10.1145/3316615.3316650
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Nguyen L, 2019, FUZZY SET SYST, V361, P114, DOI 10.1016/j.fss.2018.09.010
   Liu SF, 2013, INT J PROD RES, V51, P2123, DOI 10.1080/00207543.2012.709646
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Meng XH, 2020, PROD PLAN CONTROL, V31, P527, DOI 10.1080/09537287.2019.1657977
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Nakamori Y, 2020, J SYST SCI SYST ENG, V29, P291, DOI 10.1007/s11518-019-5450-8
   Perktold J., Statsmodels
   Prabodh, 2021, INT C ADV COMPUTER E, P31
   Reynard D, 2019, TRANSPORT RES D-TR E, V77, P449, DOI 10.1016/j.trd.2019.03.002
   Rubber Authority of Thailand, 2019, RUBB PRIC RUBB AUTH
   Samaniego-Medina R, 2016, J ECON BUS, V86, P1, DOI 10.1016/j.jeconbus.2016.03.001
   Schniederjans DG, 2020, INT J PROD ECON, V220, DOI 10.1016/j.ijpe.2019.07.012
   Sedgwick P, 2010, BMJ-BRIT MED J, V341, DOI 10.1136/bmj.c4414
   Shynkevich Y, 2017, NEUROCOMPUTING, V264, P71, DOI 10.1016/j.neucom.2016.11.095
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Stein S, 2018, EUR J AGRON, V92, P30, DOI 10.1016/j.eja.2017.09.010
   Tiwari S, 2018, COMPUT IND ENG, V115, P319, DOI 10.1016/j.cie.2017.11.017
   Tokyo Commodity Exchange Inc, 2019, US
   Verma S., 2020, MULTIMEDIA BIG DATA, P391, DOI 10.1007/978-981-13-8759-3
   Wang HS, 2019, PATTERN RECOGN, V89, P55, DOI 10.1016/j.patcog.2018.12.026
   Wang ZT, 2016, TRANS SYST SCI, V5, P107, DOI 10.1007/978-4-431-55218-5_7
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Yuan GH, 2019, PHYSICA A, V536, DOI 10.1016/j.physa.2019.04.240
   Zhang C, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.104989
   Zhang J, 2018, EXPERT SYST APPL, V97, P60, DOI 10.1016/j.eswa.2017.12.026
   Zhao J., 2020, J DATA INFO MANAG, V2, P95, DOI [DOI 10.1007/S42488-020-00025-Z, 10.1007/s42488-020-00025-z]
   Zhu Q, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105739
NR 49
TC 2
Z9 2
U1 7
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 347
EP 365
DI 10.1007/s11042-022-13309-w
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318300006
DA 2024-07-18
ER

PT J
AU Önal, MN
   Güraksin, GE
   Duman, R
AF Onal, Merve Nur
   Guraksin, Gur Emre
   Duman, Resat
TI Convolutional neural network-based diabetes diagnostic system via
   iridology technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Iridology; Diabetes determination; Image
   Processing; Image segmentation
ID CLASSIFICATION; RECOGNITION; IMAGES
AB Iridology is a sort of complementary medicine using the patterns, colors, and other properties of the iris to gather systemic information about a person's health status. To put it another way, iridology is the examination of the iris' sensitive structures. Iridology is employed in conjunction with other approaches by physicians to better understand their patients' needs. Examination and diagnosis, on the other hand, are highly subjective and dependent on medical experience of the physicians. It's also a time-consuming and exhausting process for physicians. This study proposed a hybrid method of deep learning and image processing for a more objective examination and diabetes diagnosis based on iris images. The suggested method initially detected the iris boundary and then automatically extracted the pancreatic region in the iridology chart. Image processing steps allowed for the detection of the pancreatic region on the iris and its automatic segmentation from the eye image. Afterward, diabetes was diagnosed using convolutional neural networks on images, and the results were compared with different convolutional neural network architectures. It was concluded that the proposed method combined with VGG-16 architecture and automatic segmentation of the pancreatic region resulted in an accuracy of 80%, a sensitivity of 100%, a precision of 71.42%, a specificity of 60%, and an f1 score performance of 83.33%.
C1 [Onal, Merve Nur] Afyon Kocatepe Univ, Dept Biomed Engn, Afyon, Turkey.
   [Guraksin, Gur Emre] Afyon Kocatepe Univ, Dept Comp Engn, Afyon, Turkey.
   [Duman, Resat] Bursa City Hosp, Dept Ophthalmol, Bursa, Turkey.
C3 Afyon Kocatepe University; Afyon Kocatepe University
RP Güraksin, GE (corresponding author), Afyon Kocatepe Univ, Dept Comp Engn, Afyon, Turkey.
EM emreguraksin@aku.edu.tr
RI Güraksın, Gür Emre/ABI-3335-2020
OI Güraksın, Gür Emre/0000-0002-1935-2781
FU Unit of Scientific Research and Projects of Afyon Kocatepe University
   [18, FEN.BIL.28]
FX This study was supported by the Unit of Scientific Research and Projects
   of Afyon Kocatepe University (Project No: 18.FEN.BIL.28).
CR Adelina DC, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P114, DOI 10.1109/KCIC.2017.8228573
   Amer Diabet Assoc, 2010, DIABETES CARE, V33, pS11, DOI [10.2337/dc12-s011, 10.2337/dc11-S062, 10.2337/dc10-S011, 10.2337/dc12-s064, 10.2337/dc14-S081, 10.2337/dc10-S062, 10.2337/dc11-S011, 10.2337/dc13-S067, 10.2337/dc13-S011]
   Aminah R, 2019, P 2019 6 INT C INF T, DOI [10.1109/icitacee.2019.8904125, DOI 10.1109/ICITACEE.2019.8904125]
   Aminah R, 2019, INT C ADV COMP SCI I, P133, DOI [10.1109/icacsis47736.2019.8979755, 10.1109/ICACSIS47736.2019.8979755]
   Andana SN, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SIGNALS AND SYSTEMS (ICSIGSYS), P79, DOI [10.1109/ICSIGSYS.2019.8811071, 10.1109/icsigsys.2019.8811071]
   Beagley J, 2014, DIABETES RES CLIN PR, V103, P150, DOI 10.1016/j.diabres.2013.11.001
   Behera SK., 2021, CATEGORIZATION COMMO, DOI [10.21203/rs.3.rs-136988/v1, DOI 10.21203/RS.3.RS-136988/V1]
   Chang SJ, 2021, IEEE T RADIAT PLASMA, V5, P253, DOI 10.1109/TRPMS.2020.2983391
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deeba K., 2020, Microprocessors and Microsystems, P103364, DOI [DOI 10.1016/J.MICPRO.2020.103364, 10.1016/j.micpro.2020.103364]
   Dewi AK, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTING (ICIC), P192, DOI 10.1109/IAC.2016.7905714
   Ernst E., 2008, Healing, Hype or Harm?: A Critical Analysis of Complementary and Alternative Medicine
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graksn GE, 2021, DZCE U J SCI TECHNOL, V9, P823, DOI [10.29130/dubited.866124, DOI 10.29130/DUBITED.866124]
   Güraksin GE, 2016, TURK J ELECTR ENG CO, V24, P1693, DOI 10.3906/elk-1305-271
   Hussein SE, 2013, BIOMED SIGNAL PROCES, V8, P534, DOI 10.1016/j.bspc.2013.04.006
   Itoh H, 2020, PROC SPIE, V11314, DOI 10.1117/12.2549532
   Jensen B., 1982, IRIDOLOGY SCI PRACTI, VII
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusuma FD, 2018, 2018 INT ELECT S KNO
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lodin A, 2009, ISSCS 2009: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, PROCEEDINGS,, P129
   Ma L, 2007, LECT NOTES COMPUT SC, V4901, P168
   Ma L, 2009, COMPUT MATH APPL, V57, P1862, DOI 10.1016/j.camwa.2008.10.012
   Permatasari LI, 2016, 2016 INTERNATIONAL CONFERENCE ON CONTROL, ELECTRONICS, RENEWABLE ENERGY AND COMMUNICATIONS (ICCEREC), P157, DOI 10.1109/ICCEREC.2016.7814983
   Samikannu R, 2020, CMC-COMPUT MATER CON, V63, P1133, DOI 10.32604/cmc.2020.08578
   Sethy PK, 2021, J X-RAY SCI TECHNOL, V29, P197, DOI 10.3233/XST-200784
   Shen B, 2007, 3 INT C INTELLIGENT, DOI [10.1109/iihmsp.2007.4457533, DOI 10.1109/IIHMSP.2007.4457533]
   SIMON A, 1979, JAMA-J AM MED ASSOC, V242, P1385, DOI 10.1001/jama.242.13.1385
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Songire SG., 2016, INT J COMPUT APPL, V133, P41
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Velia D, 2020, 2020 4 INT C INFORMA, DOI [10.1109/icicos51170.2020.9299081, DOI 10.1109/ICICOS51170.2020.9299081]
   Wani M A., 2020, Studies in Big Data, DOI DOI 10.1007/978-981-13-6794-6
NR 35
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 173
EP 194
DI 10.1007/s11042-022-13291-3
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805908000002
DA 2024-07-18
ER

PT J
AU Cohen, FS
   Zhong, Z
   Li, CX
AF Cohen, Fernand S.
   Zhong, Zheng
   Li, Chenxi
TI Semantic graph for word disambiguation in machine translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine translation; Semantic graph; Gibbs model; MLE; MAP; Iterative
   relaxation
ID LSTM
AB This work is an attempt to incorporate semantic context in machine translation using a combination of parallel corpora as well as feedback from human translators. Both parallel corpora and human translators help in determining what constitute keywords/key phrases that help in the disambiguation of words or phrases that lend themselves to multiple possible meanings. The disambiguation process uses a probabilistic language model that captures the dependencies of ambiguous words/phrases on those keywords/phrases through parametric conditional probabilities, with their parameters estimated using parallel corpora data. These are augmented via human translator feedbacks using an interface that maps the degree of confidence (a measure between 0 and 1, with 1 being 100% certainty about the word disambiguation) of the human translator in the disambiguation of a word/phrase into updated language model parameters. The disambiguation is made in accordance with the most probable meaning based on the keywords/phrases. This work also presents an iterative relaxation algorithm to disambiguate multiple words in one sentence by obtaining the translation with the highest joint probability. Experimental results using our model and method are reported on testbeds in the medical and literary fiction domains and our results fare more than favorably when compared to the state-of-the-art Neural Network (NN) based Word Sense Disambiguation approach. Our method goes beyond NN learning by extracting and modeling the essential semantic elements in the original language to faithfully capture the meaning of the source text.
C1 [Cohen, Fernand S.; Zhong, Zheng; Li, Chenxi] Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Cohen, FS (corresponding author), Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM fsc22@drexel.edu; zz397@dragons.drexel.edu; cl982@dragons.drexel.edu
CR BAI XJ, 2002, P NAT MACH TRANS C 2, P124
   Bassnett S., 2013, Translation Studies, V4th, DOI DOI 10.4324/9780203488232
   Chen KH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P358
   Chen L., 2019, P ICLR
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Cohen F., 1986, Modelling and application of stochastic processes, V1st, P243
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hassan WS, 2006, PMLA, V121, P753, DOI 10.1632/003081206X142869
   He Di, 2016, P ADV NEUR INF PROC, DOI DOI 10.5555/3157096.3157188
   Jimeno-Yepes AJ, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-223
   Kgebck, 2016, ARXIV PREPRINT ARXIV
   Koehn Philipp, 2003, HLT NAACL 2003 HUMAN, P48
   Kumar S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P169
   Kumar Sachin, 2019, P ICLR
   Li S. Z., 2009, Markov random field modeling in image analysis
   Liu XB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3613
   Lyons J., 1995, Linguistic Semantics: an Introduction, DOI [DOI 10.1017/CBO9780511810213, https://doi.org/10.1017/CBO9780511810213]
   Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133
   Mihalcea R. F., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, P5, DOI 10.1142/S0218213001000398
   Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149
   Nye M., 2016, Distillations, V2, P40
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Sutskever I, 2014, ADV NEUR IN, V27
   Tam Kwok-kan., 2012, Culture in Translation: Reception of Chinese Literature in Comparative Perspective
   Valiant L. G., 1984, Communications of the ACM, V27, P1134, DOI 10.1145/1968.1972
   Wang, 2021, ENGINEERING, DOI [10.1016/j.enwg.2021.03.02330, DOI 10.1016/J.ENWG.2021.03.02330]
   Wieting J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4344
   Yang J., 2020, P 58 ANN M ASS COMPU, P5979, DOI 10.18653/v1/2020.acl-main.531
   Yang ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6191
   Zacks S., 2014, PARAMETRIC STAT INFE
   Zhai P, 2019, IPCC Special Report on Climate Change, Desertification, Land Degradation, Sustainable Land Management, Food Security, and Greenhouse Gas Fluxes in Terrestrial Ecosystems, DOI DOI 10.1017/CBO9781107415324
NR 36
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43485
EP 43502
DI 10.1007/s11042-022-13242-y
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000801075000001
DA 2024-07-18
ER

PT J
AU Megahed, A
   Han, Q
AF Megahed, Amr
   Han, Qi
TI Identify videos with facial manipulations based on convolution neural
   network and dynamic texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face forensics; Video manipulation detection; Convolution neural
   network; Facial manipulation detection; Spatiotemporal features
AB Recent facial manipulation techniques based on deep learning can create a highly realistic face by changing expression, attributes, identity, or creating an entire face synthesis, that called recently Deep-Fake. With the rapid appearance of such applications, they have raised great security concerns. Therefore, corresponding forensic techniques are proposed to tackle this issue. However, existing techniques are either based on complex deep networks with a binary classification that are unable to distinguish between facial manipulation types or rely on fragile hand-crafted features with unsatisfactory results. To overcome these issues, we propose a learning-based detection method by creating an uncomplicated CNN network called FMD-Net relying on the dynamic textures as input. Moreover, it is able to distinguish between facial manipulation types such as Deepfake, Face2Face, FaceSwap, and NeuralTexture. By using dynamic textures of each video shot, motion and appearance features are combined which helped the network learn manipulation artifacts and provides a robust performance at various compression levels. We conduct extensive experiments on various benchmark datasets (FaceForensics++, DFDC, and Celeb-DF) to empirically demonstrate the superiority and effectiveness of the proposed method with both binary classification and multi-classification against the state-of-the-art methods.
C1 [Megahed, Amr; Han, Qi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
C3 Harbin Institute of Technology
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM amr.m@hit.edu.cn; qi.han@hit.edu.cn
FU National Natural Science Foundation of China [61771168, 61471141,
   61361166006, 61571018, 61531003]; Key Technology Program of Shenzhen,
   China [JSGG20160427185010977]; Basic Research Project of Shenzhen, China
   [JCYJ20150513151706561]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61771168, 61471141, 61361166006, 61571018, and
   61531003]; Key Technology Program of Shenzhen, China, [grant number
   JSGG20160427185010977]; Basic Research Project of Shenzhen, China [grant
   number JCYJ20150513151706561].
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Amrani M, 2018, NEURAL COMPUT APPL, V30, P2047, DOI 10.1007/s00521-018-3616-9
   [Anonymous], 2018, NY Times
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   auth, 2017, MATLAB DEEP LEARNING
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dolhansky B, 2019, ARXIV 191008854
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fung S, 2021, ARXIV 210411507
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Korshunov P, 2018, ARXIV 181208685
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, COMPUTATIONAL METHOD
   Kumar P, 2020, IEEE WINT CONF APPL, P2578, DOI [10.1109/WACV45572.2020.9093628, 10.1109/wacv45572.2020.9093628]
   Laws K.I., 1980, Textured Image Segmentation
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Megahed A, 2020, IEEE INT CONF TRUST, P1261, DOI 10.1109/TrustCom50675.2020.00169
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Rssler A, 2018, ARXIV 180309179
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Wang G, 2020, ARXIV 200804848
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI [10.1109/icassp40776.2020.9053969, 10.1109/ICASSP40776.2020.9053969]
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 48
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43441
EP 43466
DI 10.1007/s11042-022-13102-9
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000801075000002
DA 2024-07-18
ER

PT J
AU Goel, P
   Jain, R
   Nayyar, A
   Singhal, S
   Srivastava, M
AF Goel, Priya
   Jain, Rachna
   Nayyar, Anand
   Singhal, Shruti
   Srivastava, Muskan
TI Sarcasm detection using deep learning and ensemble learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sarcasm; Natural language processing (NLP); Long short-term memory
   (LSTM); Gated recurrent unit (GRU); And convolutional neural networks
   (CNN); Word2Vec; GloVe; fastText
ID SENTIMENT ANALYSIS; IDENTIFICATION; CLASSIFICATION; TWITTER
AB Across the globe, there is a noticeable upward trend of incorporating sarcasm in everyday life. This trend can be easily attributed to the frequent use of sarcasm in everyday life, but more specifically to social media and the Internet. This study aims to bridge the gap between human and machine intelligence to recognize and understand sarcastic behavior and patterns. The research is based on using various neural techniques, namely Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Baseline Convolutional Neural Networks (CNN) in an ensemble model to detect sarcasm on the internet. In order to improve the precision of the proposed model, the required dataset is also prepared on different previously trained word-embedding models like fastText, Word2Vec, and GloVe, etc., and their accuracies are compared. The aim is to be able to quantify the overall sentiment of the writer as positive or negative / sarcastic or non-sarcastic to ensure that the correct message is received to the intended audience. The final study revealed that the proposed ensemble model with word embeddings outperformed the other state-of-the-art models and deep learning models considered in this study with an accuracy of around 96% for News Headlines dataset, 73% for Reddit dataset, and amongst our proposed ensemble models, Weighted Average Ensemble gave the highest accuracy of around 99% and 82% for both the datasets respectively. Ensemble model used in our study improvised the stability, precision and predictive power of the proposed model.
C1 [Goel, Priya; Singhal, Shruti; Srivastava, Muskan] Bharati Vidyapeeths Coll Engn, Comp Sci Dept, New Delhi, India.
   [Jain, Rachna] Bhagwan Parshuram Inst Technol, Informat Technol Dept, New Delhi, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 Bhagwan Parshuram Institute of Technology; Duy Tan University; Duy Tan
   University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.; Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
EM priyagoel99@gmail.com; rachnajain@bpitindia.com;
   anandnayyar@duytan.edu.vn; shruti.singhal.2608@gmail.com;
   muskan.srivastava1904@gmail.com
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146; Jain, Rachna/0000-0002-1819-550X
CR Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   Aloufi S, 2018, IEEE ACCESS, V6, P78609, DOI 10.1109/ACCESS.2018.2885117
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   Amir S, 2016, P 20 SIGNLL C COMP N, P167, DOI DOI 10.18653/V1/K16-1017
   [Anonymous], 2016, ARXIV161008815
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Barbieri F., 2014, P 5 WORKSHOP COMPUTA, P50
   Bark O., 2017, DEEP LEARNING APPROA
   Bharti SK, 2016, DIGIT COMMUN NETW, V2, P108, DOI 10.1016/j.dcan.2016.06.002
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bouazizi M, 2018, IEEE ACCESS, V6, P64486, DOI 10.1109/ACCESS.2018.2876674
   Bouazizi M, 2017, IEEE ACCESS, V5, P20617, DOI 10.1109/ACCESS.2017.2740982
   Chung Junyoung, 2014, ARXIV14123555
   Dave K., 2003, P 12 INT C WORLD WID, P519, DOI [10.1145/775152.775226, DOI 10.1145/775152.775226]
   Felbo B., 2017, P 2017 C EMP METH NA, P1615, DOI DOI 10.18653/V1/D17-1169
   Fersini E, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (IEEE DSAA 2015), P981
   Filatova E, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P392
   Ghosh A, 2016, P 7 WORKSH COMP APPR, P161, DOI [10.18653/v1/W16-0425, DOI 10.18653/V1/W16-0425]
   Ghosh D., 2017, ARXIV PREPRINT ARXIV
   Hazarika D., 2018, P 27 INT C COMP LING, P1837
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Joshi A., 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, P1006
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Joulin A., 2016, ARXIV PREPRINT ARXIV, V2, P427
   Khodak M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P641
   KREUZ RJ, 1995, METAPHOR SYMB ACT, V10, P21, DOI 10.1207/s15327868ms1001_3
   Kumar Akshi, 2012, International Journal of Intelligent Systems and Applications, V4, P1, DOI 10.5815/ijisa.2012.10.01
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2027, DOI 10.1007/s00530-020-00672-7
   Kumar A, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5107
   Kumar A, 2017, LECT NOTES ENG COMP, P472
   Kumar Akshi, 2012, International Journal of Computer Science Issues (IJCSI), V9, P372
   Kumar A, 2019, J NEUROSURG, V130, P1784, DOI [10.3171/2018.11.JNS183191, 10.1007/s12652-019-01419-7]
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Kumari A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5839
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lemmens J, 2020, FIGURATIVE LANGUAGE PROCESSING, P264
   Ling J, 2016, LECT NOTES COMPUT SC, V9989, P203, DOI 10.1007/978-3-319-47602-5_39
   Liu P, 2014, LECT NOTES COMPUT SC, V8485, P459, DOI 10.1007/978-3-319-08010-9_49
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Manohar MY, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P618, DOI 10.1109/ICCONS.2017.8250536
   Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238
   Mehndiratta P, 2019, J DATA INFO SCI, V4, P56, DOI 10.2478/jdis-2019-0021
   Mehndiratta P, 2019, J DISCRET MATH SCI C, V22, P465, DOI 10.1080/09720529.2019.1637152
   Mehndiratta P, 2017, SCALABLE COMPUT-PRAC, V18, P219, DOI 10.12694/scpe.v18i3.1302
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Mishra A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P377, DOI 10.18653/v1/P17-1035
   Misra R., 2019, ARXIV PREPRINT ARXIV
   Onan A, 2019, ADV INTELL SYST COMP, V984, P293, DOI 10.1007/978-3-030-19807-7_29
   Pai PF, 2018, IEEE ACCESS, V6, P57655, DOI 10.1109/ACCESS.2018.2873730
   Patro J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6336
   Pelser D., 2019, PREPRINTS
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Porwal S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P746, DOI 10.1109/ICCONS.2018.8663147
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Saha S., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI [DOI 10.17485/ijst/2017/v10i25/114443, 10.17485/ijst/2017/v10i25/114443]
   Sarsam SM, 2020, INT J MARKET RES, V62, P578, DOI 10.1177/1470785320921779
   Shayaa S, 2018, IEEE ACCESS, V6, P37807, DOI 10.1109/ACCESS.2018.2851311
   Sobti P, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.557
   Tarigan J, 2018, INT J ADV COMPUTER R, V8
   Tseng CW, 2018, IEEE ACCESS, V6, P72870, DOI 10.1109/ACCESS.2018.2878478
   Wang K, 2018, IEEE WINT CONF APPL, P1842, DOI 10.1109/WACV.2018.00204
   Wu D, 2017, IEEE INT CONF COMMUN, P1, DOI 10.1109/ACCESS.2016.2647384
   Zhang Meishan, 2016, P COLING 2016 26 INT, P2449
NR 65
TC 10
Z9 10
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43229
EP 43252
DI 10.1007/s11042-022-12930-z
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900007
DA 2024-07-18
ER

PT J
AU Jiang, LM
   Fan, H
   Li, JJ
AF Jiang, Limai
   Fan, Hui
   Li, Jinjiang
TI DDFN: a depth-differential fusion network for multi-focus image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Convolutional pooling pyramid; Multi-focus image
AB Dueto the limitations of digital image capturing equipment, it is usually difficult for the photographer to obtain a complete and clear image of a certain scene in the case of dual targets and multiple targets. This is because most digital imaging systems have a limited depth of field control range, so they can only focus on one or a few objects in the far or near distance, resulting in clear and blurred areas with clear boundaries, that is multi-focus image. This kind of image limits further image processing, such as target recognition, image segmentation, target tracking and so on. Often, two multi-focus images can basically integrate all scene information completely, and multiple multi-focus images can also be fused by cascading all images. Inspired by this, we propose a new image fusion method based on binocular depth estimation and binocular image difference, called depth-differential mapping fusion network (DDFN). In detail, DDFN is based on the idea of residual U-Net and the network structure. It takes two multi-focus images as input, extracts rich hierarchical features through the convolutional pooling pyramid, and learns the residuals between them and the corresponding groundtruth. In this process, DDFN will use their differential information to encode, merge the depth information, and finally perform the decoding process, so the features in the multi-focus image pair will be fully extracted. Finally a clear image without defocusing blur area is formed. We have conducted multiple ablation experiments and comparative experiments, furthermore, a large number of results fully demonstrate the effectiveness of our network structure.
C1 [Jiang, Limai; Li, Jinjiang] Shandong Technol & Business Univ, Coinnovat Ctr, Shandong Coll & Univ Future Intelligent, Yantai, Shandong, Peoples R China.
   [Fan, Hui; Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Coinnovat Ctr, Shandong Coll & Univ Future Intelligent, Yantai, Shandong, Peoples R China.; Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai, Peoples R China.
EM fanlinw@263.net; lijinjiang@gmail.com
FU National Natural Science Foundation of China [61772319, 61773244,
   61976125, 61976124]; Shandong Natural Science Foundation of China
   [ZR2017MF049]; Yantai Key Research and Development Plan [2019XDHZ081]
FX This research was supported by the National Natural Science Foundation
   of China (61772319, 61773244, 61976125, 61976124), Shandong Natural
   Science Foundation of China (ZR2017MF049) and Yantai Key Research and
   Development Plan (2019XDHZ081).
CR Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Cai MR, 2015, INT CONF SOFTW ENG, P237, DOI 10.1109/ICSESS.2015.7339045
   Chen C, 2019, AAAI CONF ARTIF INTE, P8142
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Eigen D, 2014, ADV NEUR IN, V27
   EVERINGHAM M, 2011, TECH REP, V8
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Guo CL, 2019, IEEE T IMAGE PROCESS, V28, P2545, DOI 10.1109/TIP.2018.2887029
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jaritz Maximilian, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12602, DOI 10.1109/CVPR42600.2020.01262
   Joshi K., 2019, INT C ADV ENG SCI MA
   Jung H, 2020, IEEE T IMAGE PROCESS, V29, P3845, DOI 10.1109/TIP.2020.2966075
   Lai R, 2019, IEEE ACCESS, V7, P114385, DOI 10.1109/ACCESS.2019.2935006
   Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma B, 2019, ARXIV 190801703
   Ma HY, 2020, IEEE T IMAGE PROCESS, V29, P8668, DOI 10.1109/TIP.2020.3018261
   Ma JY, 2020, INFORM FUSION, V62, P110, DOI 10.1016/j.inffus.2020.04.006
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Ma JL, 2017, CHIN CONTR CONF, P5464, DOI 10.23919/ChiCC.2017.8028223
   Ma TS, 2020, APPL INTELL, V50, P905, DOI 10.1007/s10489-019-01523-3
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Naji MA, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P477
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahu A, 2015, 2014 INTERNATIONAL CONFERENCE ON MEDICAL IMAGING, M-HEALTH & EMERGING COMMUNICATION SYSTEMS (MEDCOM), P448
   Savi S, 2012, 19 IEEE INT C SYST S
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Shin K, 2020, BINOCULAR DEPTH ESTI
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137
   Yan X, 2018, ARXIV 180607272
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang Liu, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P135, DOI 10.1109/DSC50466.2020.00028
   Zafar R, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070060
   Zhang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107325
   Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang X, 2020, ARXIV 200501116
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
NR 51
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43013
EP 43036
DI 10.1007/s11042-022-12075-z
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800827600003
DA 2024-07-18
ER

PT J
AU Sharma, PC
   Raja, R
   Vishwakarma, SK
   Sharma, S
   Mishra, PK
   Kushwah, VS
AF Sharma, Prakash Chandra
   Raja, Rohit
   Vishwakarma, Santosh Kumar
   Sharma, Sanjiv
   Mishra, Pankaj Kumar
   Kushwah, Vivek Singh
TI Analysis of brain signal processing and real-time EEG signal enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer Interface; EEG signals; Epileptic seizures; Gaussian
   mix-model; Authoritative connection examination
ID ARTIFACT REMOVAL; FEATURE-EXTRACTION; AUTOMATIC REMOVAL; BLIND
   SEPARATION; MUSCLE ARTIFACT; NEURAL-NETWORK; EYE-MOVEMENT; HUMAN HEAD;
   LOCALIZATION; CLASSIFICATION
AB Cerebrum signals can be acquired and broken down with various techniques, as represented in the paper. Electroencephalogram (EEG) signals are damaged by various conventional i.e. signals related to muscle action, eye development, and body movement, which have non-cerebral inception. The outcomes of such traditions are superior to that of the cerebrum's electrical movement, so they cover the cortical signs of interest and bring a one-sided investigation. A few visually impaired source partition techniques have been created to expel ancient rarities from the EEG accounts. The iterative procedure for estimating detachment inside multichannel chronicles is computationally immovable in all cases. The curiosity segments require a tedious disconnected procedure except physically. The proposed work gives a curio expulsion calculation that depends on the authoritative connection examination (CCA) and Gaussian Mix-Model (GMM) to expand the nature of signs of EEG. In particular, EEG signs can be investigated utilizing various techniques, proposing a mix of strategies ideal for simplicity of automated examination and conclusion of epileptic seizures.
C1 [Sharma, Prakash Chandra; Vishwakarma, Santosh Kumar] Manipal Univ Jaipur, Sch Comp & Informat Technol, Jaipur, Rajasthan, India.
   [Raja, Rohit] Central Univ, Guru Ghasidas Vishwavidyalaya, Bilaspur, India.
   [Sharma, Sanjiv] Madhav Inst Sci & Technol, Gwalior, India.
   [Mishra, Pankaj Kumar; Kushwah, Vivek Singh] Amity Univ, Amity Sch Engn & Technol, Gwalior, India.
C3 Manipal University Jaipur; Guru Ghasidas Vishwavidyalaya; Madhav
   Institute of Technology & Science
RP Vishwakarma, SK (corresponding author), Manipal Univ Jaipur, Sch Comp & Informat Technol, Jaipur, Rajasthan, India.
EM prakashsharma12@gmail.com; drrohitraja1982@gmail.com;
   santoshscholar@gmail.com; er.sanjiv@gmail.com; pmishra@gwa.amity.edu;
   vskushwah@gwa.amity.edu
RI Raja, Rohit/ABA-3603-2020; Kushwah, Prof. (Dr.) Vivek Singh/X-3641-2019
OI Raja, Rohit/0000-0003-1195-497X; Kushwah, Prof. (Dr.) Vivek
   Singh/0000-0002-7721-7262; Sharma, Sanjiv/0000-0002-6880-0456
CR Agarwal R, 1998, ELECTROEN CLIN NEURO, V107, P44, DOI 10.1016/S0013-4694(98)00009-1
   Anaya-Isaza A., 2021, Inform. Med. Unlocked, V26, DOI DOI 10.1016/J.IMU.2021.100723
   Barbati G, 2004, CLIN NEUROPHYSIOL, V115, P1220, DOI 10.1016/j.clinph.2003.12.015
   Basser P. J., 1994, Biophysical Journal, V66, P259, DOI 10.1016/S0006-3495(94)80775-1
   Baumgartner C, 2006, CURR OPIN NEUROL, V19, P181, DOI 10.1097/01.wco.0000218236.44969.67
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193
   Berman J, 2009, MAGN RESON IMAGING C, V17, P205, DOI 10.1016/j.mric.2009.02.002
   Bulea TC, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00376
   Calinon S, 2007, IEEE T SYST MAN CY B, V37, P286, DOI 10.1109/TSMCB.2006.886952
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chandrakar R, 2022, MULTIMED TOOLS APPL, V81, P42149, DOI 10.1007/s11042-021-11290-4
   Cvetkovic D, 2008, DIGIT SIGNAL PROCESS, V18, P861, DOI 10.1016/j.dsp.2007.05.009
   da Silva FL, 2004, MAGN RESON IMAGING, V22, P1533, DOI 10.1016/j.mri.2004.10.010
   De Clercq W, 2006, IEEE T BIO-MED ENG, V53, P2583, DOI 10.1109/TBME.2006.879459
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Ding L, 2007, J CLIN NEUROPHYSIOL, V24, P130, DOI 10.1097/WNP.0b013e318038fd52
   Ding L, 2007, NEUROIMAGE, V34, P575, DOI 10.1016/j.neuroimage.2006.09.042
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Ebersole JS., 1995, ELECTROEN CLIN NEURO, V95, p18P, DOI [10.1016/0013-4694(95)97922-N, DOI 10.1016/0013-4694(95)97922-N]
   Escudero J, 2007, IEEE T BIO-MED ENG, V54, P1965, DOI 10.1109/TBME.2007.894968
   Esteller R, 2001, IEEE T CIRCUITS-I, V48, P177, DOI 10.1109/81.904882
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Friston KJ, 2009, SCIENCE, V326, P399, DOI 10.1126/science.1174521
   FRISTON KJ, 1993, J CEREBR BLOOD F MET, V13, P5, DOI 10.1038/jcbfm.1993.4
   Fritzsche KH, 2010, NEUROIMAGE, V51, P242, DOI 10.1016/j.neuroimage.2010.02.007
   Fukunaga, 1990, INTRO STAT PATTERN R, V592
   Gao JF, 2010, CLIN EEG NEUROSCI, V41, P53, DOI 10.1177/155005941004100111
   Gómez-Herrero G, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P130
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Hageman NS, 2009, IEEE T MED IMAGING, V28, P348, DOI 10.1109/TMI.2008.2004403
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   HAMALAINEN MS, 1989, IEEE T BIO-MED ENG, V36, P165, DOI 10.1109/10.16463
   Hamilton JD., 1994, TIME SERIES ANAL, DOI [10.1515/9780691218632, DOI 10.1515/9780691218632]
   HE B, 1992, MED BIOL ENG COMPUT, V30, P324, DOI 10.1007/BF02446971
   HE B, 1987, IEEE T BIO-MED ENG, V34, P406, DOI 10.1109/TBME.1987.326056
   He B., 2005, NEURAL ENG, DOI [10.1007/b112182, DOI 10.1007/B112182]
   He Bin, 2008, IEEE Rev Biomed Eng, V1, P23, DOI 10.1109/RBME.2008.2008233
   Hmlinen, 1984, INTERPRETING MEASURE
   Hsu WY, 2012, EXPERT SYST APPL, V39, P2743, DOI 10.1016/j.eswa.2011.08.132
   Jasper HerbertH., 1958, RETICULAR FORMATION
   Joyce CA, 2004, PSYCHOPHYSIOLOGY, V41, P313, DOI 10.1111/j.1469-8986.2003.00141.x
   Jung T-P, 1998, P 1997 C ADV NEURAL, V10
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Jung TP, 2001, P IEEE, V89, P1107, DOI 10.1109/5.939827
   Kamousi B, 2005, IEEE T NEUR SYS REH, V13, P166, DOI 10.1109/TNSRE.2005.847386
   KAVANAGH RN, 1978, IEEE T BIO-MED ENG, V25, P421, DOI 10.1109/TBME.1978.326339
   Khare SK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3070608
   Khare SK, 2021, BIOCYBERN BIOMED ENG, V41, P679, DOI 10.1016/j.bbe.2021.04.008
   Khare SK, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105722
   Kordylewski H, 2001, IEEE T INF TECHNOL B, V5, P202, DOI 10.1109/4233.945291
   Kothe C. A. E., 2016, Google Patents
   Kousarrizi MRN, 2009, P INT JOINT C BIOINF
   Kumar AS, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114880
   Lawhern V, 2015, 2015 IEEE INT C SYST
   Lee L, 2003, NEUROIMAGE, V19, P457, DOI 10.1016/S1053-8119(03)00062-4
   Liao LD, 2012, P IEEE, V100, P1553, DOI 10.1109/JPROC.2012.2184829
   Lichtman JW, 2008, NAT REV NEUROSCI, V9, P417, DOI 10.1038/nrn2391
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   MANGUN GR, 1991, J EXP PSYCHOL HUMAN, V17, P1057, DOI 10.1037/0096-1523.17.4.1057
   Mayaud L, 2013, NEUROPHYSIOL CLIN, V43, P217, DOI 10.1016/j.neucli.2013.06.002
   MeyerLindenberg A, 1996, ELECTROEN CLIN NEURO, V99, P405, DOI 10.1016/S0013-4694(96)95699-0
   Mognon A, 2011, PSYCHOPHYSIOLOGY, V48, P229, DOI 10.1111/j.1469-8986.2010.01061.x
   Mori S, 2009, CURR OPIN NEUROL, V22, P362, DOI 10.1097/WCO.0b013e32832d954b
   MOSHER JC, 1992, IEEE T BIO-MED ENG, V39, P541, DOI 10.1109/10.141192
   Mosher JC, 1999, IEEE T SIGNAL PROCES, V47, P332, DOI 10.1109/78.740118
   Mullen T, 2013, 2013 35 ANN INT C IE
   Pandey S, 2022, INT J REMOTE SENS, V43, P5848, DOI 10.1080/01431161.2021.2000062
   Pierce JMS., 2002, Brain, V125, P441, DOI [DOI 10.1093/BRAIN/125.2.441, 10.1093/brain/awf038]
   Plummer C, 2008, EPILEPSIA, V49, P201, DOI 10.1111/j.1528-1167.2007.01381.x
   Vázquez RR, 2012, BIOMED SIGNAL PROCES, V7, P389, DOI 10.1016/j.bspc.2011.06.005
   Shao SY, 2009, IEEE T BIO-MED ENG, V56, P336, DOI 10.1109/TBME.2008.2005969
   Sharma PC, 2020, WIRELESS PERS COMMUN, V110, P1143, DOI 10.1007/s11277-019-06778-0
   Subasi A, 2005, COMPUT METH PROG BIO, V78, P87, DOI 10.1016/j.cmpb.2004.10.009
   Subasi A, 2007, EXPERT SYST APPL, V32, P1084, DOI 10.1016/j.eswa.2006.02.005
   Taran S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105367
   Tatum WO, 2011, J CLIN NEUROPHYSIOL, V28, P252, DOI 10.1097/WNP.0b013e31821c3c93
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Übeyli ED, 2009, COMPUT BIOL MED, V39, P733, DOI 10.1016/j.compbiomed.2009.06.001
   Vergult A, 2007, EPILEPSIA, V48, P950, DOI 10.1111/j.1528-1167.2007.01031.x
   Winkler I, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-30
   Wolters CH, 2006, NEUROIMAGE, V30, P813, DOI 10.1016/j.neuroimage.2005.10.014
   Xu XL, 2004, PHYS MED BIOL, V49, P327, DOI 10.1088/0031-9155/49/2/010
   YAN Y, 1991, MED BIOL ENG COMPUT, V29, P475, DOI 10.1007/BF02442317
   Zhang YC, 2006, NEUROIMAGE, V31, P1513, DOI 10.1016/j.neuroimage.2006.02.027
   Zhou WD, 2009, PROG NAT SCI-MATER, V19, P1165, DOI 10.1016/j.pnsc.2008.11.013
NR 87
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41013
EP 41033
DI 10.1007/s11042-022-12887-z
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000796326600001
DA 2024-07-18
ER

PT J
AU Ahmad, S
   Pal, R
   Ganivada, A
AF Ahmad, Shadab
   Pal, Rajarshi
   Ganivada, Avatharam
TI Rank level fusion of multimodal biometrics using genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometrics; Rank level fusion; Genetic algorithm
ID SCORE; RECOGNITION; MODEL
AB Multimodal biometric systems are highly used over unimodal biometric systems. The multimodal systems fuse information from multiple biometric traits to overcome the limitations, like, inter-class similarities, non-universality of unimodal biometric systems. This fusion significantly enhances the overall performance of the biometric systems. One of the ways of fusing information for multimodal biometrics is rank level fusion. In this paper, rank level fusion is formulated as an optimization problem. A novel genetic algorithm (GA) based method is proposed for rank level fusion of multimodal biometrics. It minimizes the distances between an aggregated rank list and each input rank list being derived from individual biometric trait. The proposed method uses Spearman footrule distance measure to find the said distance between a pair of rank lists. Superiority of the proposed method over several existing rank level and score level fusion methods is demonstrated experimentally.
C1 [Ahmad, Shadab; Ganivada, Avatharam] Univ Hyderabad, Hyderabad, India.
   [Ahmad, Shadab; Pal, Rajarshi] Inst Dev & Res Banking Technol, Hyderabad, India.
C3 University of Hyderabad
RP Ahmad, S (corresponding author), Univ Hyderabad, Hyderabad, India.; Ahmad, S (corresponding author), Inst Dev & Res Banking Technol, Hyderabad, India.
EM shadab.ahmad013@gmail.com; iamrajarshi@yahoo.co.in; avatharg@uohyd.ac.in
RI Ahmad, Shadab/JGD-1760-2023
CR Abaza A, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P459
   Abderrahmane H, 2020, IET BIOMETRICS, V9, P91, DOI 10.1049/iet-bmt.2018.5265
   Ahmad S, 2019, INT S SIGNAL PROCESS, P6474
   Ahmed F, 2015, VISUAL COMPUT, V31, P915, DOI 10.1007/s00371-015-1092-0
   Alinodehi SPH, 2016, IEEE T CYBERNETICS, V46, P1551, DOI 10.1109/TCYB.2015.2451595
   Alshehri H, 2018, IEEE ACCESS, V6, P28951, DOI 10.1109/ACCESS.2018.2840330
   Bansal N, 2017, IEEE INT CONF SIG PR, P159, DOI 10.1109/ISPCC.2017.8269668
   Basha A J, 2010, 2010 IEEE INT C COMP, P18
   Ben Jemaa S, 2017, COMPUT J, V60, P969, DOI 10.1093/comjnl/bxw024
   Bhatnagar J, 2007, PROC CVPR IEEE, P2978
   Bhatt HS, 2013, IEEE IMAGE PROC, P2993, DOI 10.1109/ICIP.2013.6738616
   Borade SN, 2016, 2016 24 MEDITERRANEA
   Byahatti Poornima, 2020, IOP Conference Series: Materials Science and Engineering, V925, DOI 10.1088/1757-899X/925/1/012031
   Chen LK, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0110-9
   Chia C, 2010, 2010 20 INT C PATTER, P11761179
   Devi DVR, 2016, IEEE INT C COMPUTATI
   El Shafey LE, 2014, SCALABLE PROBABILIST
   Falguera F P S, 2008, 2008 11 IEEE INT C C, P413420
   Hanmandlu M, 2011, PATTERN RECOGN LETT, V32, P1843, DOI 10.1016/j.patrec.2011.06.029
   Harada T, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3400031
   Hezil N, 2017, IET BIOMETRICS, V6, P351, DOI 10.1049/iet-bmt.2016.0072
   Hu Y, 2004, IEEE INT C ROBOTICS, V5
   IDIAP, 2014, BIOSC BIOM SCOR THES
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kabir W, 2019, IEEE ACCESS, V7, P59437, DOI 10.1109/ACCESS.2019.2914992
   Kabir W, 2018, IEEE T INF FOREN SEC, V13, P1989, DOI 10.1109/TIFS.2018.2807790
   Kabir W, 2016, IEEE INT SYMP CIRC S, P93, DOI 10.1109/ISCAS.2016.7527178
   Kumar A, 2012, 2012 9 INT C INFORM, P3641
   Kumar A, 2010, 2010 IEEE INT C IMAG
   Kumar A, 2011, IEEE T SYST MAN CY C, V41, P743, DOI 10.1109/TSMCC.2010.2089516
   Li C, 2015, IEEE T INF FOREN SEC, V10, P1193, DOI 10.1109/TIFS.2015.2402593
   Liu ZY, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1635, DOI 10.1109/CISP.2015.7408147
   Makihara Y, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P18, DOI 10.1109/ACPR.2013.211
   Mansouri N, 2018, IET COMPUT VIS, V12, P69, DOI 10.1049/iet-cvi.2017.0055
   Mohammadi A, 2019, IEEE T CYBERNETICS, V49, P3471, DOI 10.1109/TCYB.2018.2845661
   Monwar M M, 2008, 5 INT C INFORM TECHN
   Monwar MM, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P175, DOI 10.1109/ICCI-CC.2013.6622241
   Monwar MM, 2013, SIGNAL IMAGE VIDEO P, V7, P137, DOI 10.1007/s11760-011-0226-8
   Monwar MM, 2008, IEEE APP IMG PAT, P117
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Othman N, 2015, IEEE T INF FOREN SEC, V10, P1590, DOI 10.1109/TIFS.2015.2421314
   OU, 2013, OU IS BIOM SCOR DAT
   Pantraki E, 2017, IET BIOMETRICS, V6, P290, DOI 10.1049/iet-bmt.2016.0122
   Paul PP, 2014, 2014 IEEE 13TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI-CC), P80, DOI 10.1109/ICCI-CC.2014.6921445
   Paul PP, 2014, IEEE T SYST MAN CY-S, V44, P1522, DOI 10.1109/TSMC.2014.2331920
   Pihur V, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-62
   Poh N, 2002, P 12 IEEE WORKSHOP N
   Prakash A, 2011, EXPERT SYST APPL, V38, P3161, DOI 10.1016/j.eswa.2010.09.002
   Rahman MW, 2017, 2017 IEEE S SERIES C, P17
   Ross ArunA., 2006, HDB MULTIBIOMETRICS, V6
   Rudolph G, 1999, CL6799 U DORTM
   Shafey LE, 2014, THESIS EPFL
   Sharma R, 2018, IET BIOMETRICS, V7, P474, DOI 10.1049/iet-bmt.2017.0076
   Sharma R, 2015, NAT CONF COMPUT VIS
   Silva PH, 2018, 2018 IEEE C EVOLUTIO, P18
   Sing JK, 2019, INFORM FUSION, V47, P60, DOI 10.1016/j.inffus.2018.07.005
   Soltanpour S, 2017, IET BIOMETRICS, V6, P27, DOI 10.1049/iet-bmt.2015.0120
   Sun ZP, 2019, IEEE ACCESS, V7, P145692, DOI 10.1109/ACCESS.2019.2944148
   Susyanto N, 2017, 2017 INT C BIOMETRIC, P13
   Tahmasebi A., 2011, Proceedings of the 2011 International Conference on Intelligent Computation and Bio-Medical Instrumentation (ICBMI 2011), P208, DOI 10.1109/ICBMI.2011.36
   Talebi H, 2015, IEEE INT C IDENTITY, P17
   Tumpa SN, 2020, IEEE ACCESS, V8, P157663, DOI 10.1109/ACCESS.2020.3018958
   Walia GS, 2019, IET BIOMETRICS, V8, P231, DOI 10.1049/iet-bmt.2018.5018
   Ware JM, 2003, BCS CONF SERIES, P33
   Wasnik P, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P515, DOI 10.23919/ICIF.2018.8455860
   Ye Y, 2016, 2016 INT C BIOMETRIC, P15
   Yin X, 2019, IEEE T INF FOREN SEC
   Ylioinas J, 2014, INT C PATT RECOG, P4471, DOI 10.1109/ICPR.2014.765
   Zang WK, 2019, IEEE ACCESS, V7, P18821, DOI 10.1109/ACCESS.2019.2894726
   Zhang R, 2019, IEEE ACCESS, V7, P121360, DOI 10.1109/ACCESS.2019.2937553
   Zhang Y, 2019, IEEE ACCESS, V7, P31711, DOI 10.1109/ACCESS.2019.2903723
   Zitzler E., 2000, Evolutionary Computation, V8, P173, DOI 10.1162/106365600568202
NR 73
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40931
EP 40958
DI 10.1007/s11042-022-12688-4
EA MAY 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177800001
DA 2024-07-18
ER

PT J
AU Basha, SHS
   Pulabaigari, V
   Mukherjee, S
AF Basha, S. H. Shabbeer
   Pulabaigari, Viswanath
   Mukherjee, Snehasis
TI An information-rich sampling technique over spatio-temporal CNN for
   classification of human actions in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; 3-Dimensional convolutional neural networks
   (3D CNN); Gaussian weighing function; Long short term memory (LSTM)
ID HUMAN ACTION RECOGNITION; NETWORK
AB We propose a novel video sampling scheme for human action recognition in videos, using Gaussian Weighing Function. Traditionally in deep learning-based human activity recognition approaches, either a few random frames or every k(th) frame of the video is considered for training the 3D CNN, where k is a small positive integer, like 4, 5, or 6. This kind of sampling reduces the volume of the input data, which speeds-up the training network and also avoids overfitting to some extent, thus enhancing the performance of the 3D CNN model. In the proposed video sampling technique, consecutive k frames of a video are aggregated into a single frame by computing a Gaussian-weighted summation of the k frames. The resulting frame preserves the information in a better way than the conventional approaches and experimentally shown to perform better. In this paper, a 3-Dimensional deep CNN is proposed to extract the spatio-temporal features and follows Long Short-Term Memory (LSTM) to recognize human actions. The proposed 3D CNN architecture is capable of handling the videos where the camera is placed at a distance from the performer. Experiments are performed with KTH, WEIZMANN, and CASIA-B Human Activity and Gait datasets, whereby it is shown to outperform state-of-the-art deep learning based techniques. We achieve 95.78%, 95.27%, and 95.27% over the KTH, WEIZMANN, and CASIA-B human action and gait recognition datasets, respectively.
C1 [Basha, S. H. Shabbeer; Pulabaigari, Viswanath] Indian Inst Informat Technol Sri City, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
   [Mukherjee, Snehasis] Shiv Nadar Univ, Comp Sci & Engn Dept, Greater Noida, India.
C3 Shiv Nadar University
RP Basha, SHS (corresponding author), Indian Inst Informat Technol Sri City, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
EM shabbeer.sh@iiits.in; viswanath.p@iiits.in;
   snehasis.mukherjee@snu.edu.in
RI SH, Shabbeer Basha/M-7237-2016
FU NVIDIA
FX We acknowledge the support of NVIDIA with the donation of the GeForce
   Titan XP GPU used for this research.
CR Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   [Anonymous], 2011, INT WORKSH HUM BEH U
   [Anonymous], 2016, COMPUT VISUAL MEDIA
   Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Buddubariki V, 2016, P 10 IND C COMP VIS, P76
   Chaudhry R, 2009, 2009 IEEE C COMPUTER
   Chen M-y, 2009, Mosift: Recognizing human actions in surveillance videos, CMU-CS-09-161
   Cho K., 2014, ARXIV14061078
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dollar P., 2005, 2 JOINT IEEE INT WOR, P6572
   Fathi A, 2008, COMPUTER VISION PATT, P18
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Han D, 2018, NEURAL COMPUT APPL, V30, P2787, DOI 10.1007/s00521-017-2883-1
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Jaouedi N, 2020, J KING SAUD UNIV-COM, V32, P447, DOI 10.1016/j.jksuci.2019.09.004
   Jhuang H, 2007, COMPUTER VISION 2007, P18
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Karpathy A, 2014, P IEEE C COMPUTER VI
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Kingma D. P., 2014, arXiv
   Kovashka A, 2010, COMPUTER VISION PATT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu X, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02335-x
   Lu X, 2020, ARXIV 200707020
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Malgireddy MR, 2013, J MACH LEARN RES, V14, P2189
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Mukherjee S, 2015, LECT NOTES COMPUT SC, V9163, P488, DOI 10.1007/978-3-319-20904-3_44
   Mukherjee S, 2014, MACH VISION APPL, V25, P1033, DOI 10.1007/s00138-013-0589-7
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Nazir S, 2018, BAG EXPRESSION FRAME
   Ning J, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9180666
   Ning X, 2020, JWSAA JOINT WEAK SAL
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ramya P, 2021, MULTIMED TOOLS APPL, V80, P8147, DOI 10.1007/s11042-020-10140-z
   Sarfraz S, 2021, ARXIV 210311264
   Schindler K, 2008, 2008 IEEE C COMPUTER, P18
   Schuldt C, 2004, PATTERN RECOGN, V3, P3236
   Simonyan K, 2014, ADV NEUR IN, V27
   Srivastava N., 2015, INT C MACHINE LEARNI
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun L, 2017, IEEE INT C COMPUTER
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tran D, 2015, COMPUTER VISION ICCV
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Yang J., 2015, Int. J. Signal Process. Image Process. Pattern Recognit, V8, P241, DOI [10.14257/ijsip.2015.8.1.21, DOI 10.14257/IJSIP.2015.8.1.21]
   Yu J, 2020, VISUAL COMPUT, V36, P1457, DOI 10.1007/s00371-019-01751-1
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang YQ, 2019, PATTERN RECOGN, V93, P228, DOI 10.1016/j.patcog.2019.04.023
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 61
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40431
EP 40449
DI 10.1007/s11042-022-12856-6
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000792555900002
PM 35572387
OA Green Submitted, Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Verma, A
   Saha, R
   Kumar, N
   Kumar, G
   Tai-Hoon-Kim
AF Verma, Amandeep
   Saha, Rahul
   Kumar, Neeraj
   Kumar, Gulshan
   Tai-Hoon-Kim
TI A detailed survey of denial of service for IoT and multimedia systems:
   Past, present and futuristic development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; DoS; DDoS; Prevention; Detection; IDS; Traceback; Tolerance;
   Mitigation
ID INTRUSION DETECTION SYSTEM; USER AUTHENTICATION SCHEME; DDOS-ATTACK
   DETECTION; ANOMALY DETECTION; INDUSTRIAL INTERNET; DEFENSE-MECHANISMS;
   FLOODING ATTACKS; NETWORK; EFFICIENT; TRACEBACK
AB The rise in frequency and volume of Distributed Denial of Service (DDoS) attacks has made it a destructive weapon of attackers which can disrupt the services of any network including the Internet of Things. It is almost impossible to avoid DDoS attacks completely but still these attacks can be handled efficiently. It is a core security issue as these attacks can cause financial loss to organizations. So, it is necessary to know DoS/DDoS attack types and their solutions. This paper reviews major known DoS/DDoS attacks, attack tools, their prevention, detection, and traceback techniques. Solutions include techniques like filtering, honeypots, signature & anomaly-based detection, Link testing, Packet marking, and many more are reviewed in this paper. A proper analysis of these attacks and solutions is necessary for new strategy formation. This paper is beneficial for researchers and professionals working in this area to understand these attacks and see the latest scenarios. Areas that require more concentration can be identified and by working on them, a more secure working environment can be provided to end-users and organizations.
C1 [Verma, Amandeep; Saha, Rahul; Kumar, Gulshan] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
   [Kumar, Neeraj] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Neeraj] Univ Petr & Energy Studies, Dept Comp Sci, Dehra Dun, Uttarakhand, India.
   [Kumar, Neeraj] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Kumar, Neeraj] King Abdulaziz Univ, Jeddah, Saudi Arabia.
   [Tai-Hoon-Kim] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Lovely Professional University; Thapar Institute of Engineering &
   Technology; University of Petroleum & Energy Studies (UPES); Asia
   University Taiwan; King Abdulaziz University; Beijing Jiaotong
   University
RP Kumar, N (corresponding author), Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.; Kumar, N (corresponding author), Univ Petr & Energy Studies, Dept Comp Sci, Dehra Dun, Uttarakhand, India.; Kumar, N (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Kumar, N (corresponding author), King Abdulaziz Univ, Jeddah, Saudi Arabia.
EM vermaaman78658@gmail.com; rsahaaot@gmail.com; neeraj.kumar@thapar.edu;
   gulshan3971@gmail.com; taihoonn@daum.net
RI Kumar, Neeraj/L-3500-2016; Verma, Amandeep/GNP-5290-2022
OI Kumar, Neeraj/0000-0002-3020-3947; SAHA, RAHUL/0000-0003-3921-9512;
   Verma, Amandeep/0000-0003-3863-5231
CR Ahmed Z., 2019, INT J COMPUTER APPL, V975, P8887
   Ahmim A, 2019, IEEE INT CONF DISTR, P228, DOI 10.1109/DCOSS.2019.00059
   Ahuja N, 2019, INT CONF ADV COMPU
   akmak SD, 2021, 2021 IEEE INT C COMM, P16
   Al-Duwairi B, 2020, COMPUT SECUR, V99, DOI 10.1016/j.cose.2020.102071
   Aldaej Abdulaziz, 2019, IEEE Access, DOI DOI 10.1109/ACCESS.2019.2893445
   AlEroud A, 2013, ADV INTELL SYST, V172, P431
   Ali A, 2020, IEEE ACCESS, V8
   Alomari E., 2012, International Journal of Computer Applications, V49, P24, DOI [10.5120/7640-0724, DOI 10.5120/7640-0724]
   AlOmary RY, 2014, 2014 5TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS)
   Alsaadi HIH, 2022, COMPUT INTELL-US, V38, P855, DOI 10.1111/coin.12433
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0351-y
   Amin SO, 2006, LECT NOTES COMPUT SC, V4238, P263
   Anagnostopoulos M, 2013, COMPUT SECUR, V39, P475, DOI 10.1016/j.cose.2013.10.001
   Andrysiak T, 2016, ADV INTELL SYST COMP, V403, P797, DOI 10.1007/978-3-319-26227-7_75
   [Anonymous], SECURELISTCOMDDOS RE
   [Anonymous], 2006, 14 IEEE INT S MOD AN
   [Anonymous], SECURITYRADWARECOMDD
   [Anonymous], 2010, INT J ELECT COMPUT S
   Anwar M., 2018, INT BHURBAN C APPL S, P866
   Aroua M. K., 2012, Proceedings of the 2012 IEEE 36th IEEE Annual Computer Software and Applications Conference Workshops (COMPSACW), P230, DOI 10.1109/COMPSACW.2012.50
   Aura T., 2001, LNCS, V2133, P170, DOI [DOI 10.1007/3-540-44810-122, 10.1007/3-540-44810-122]
   Baba T, 2002, IEEE INTERNET COMPUT, V6, P20, DOI 10.1109/4236.991439
   Baecher P, 2006, LECT NOTES COMPUT SC, V4219, P165
   Baig ZA, 2010, IET INFORM SECUR, V4, P333, DOI 10.1049/iet-ifs.2009.0255
   Baskar M, 2018, TIME VARIANT PREDICA
   Behal Sunny, 2017, International Journal of Network Security, V19, P383, DOI 10.6633/IJNS.201703.19(3).07
   Bellovin S., 2003, ICMP TRACEBACK MESSA
   Besharati E, 2019, J AMB INTEL HUM COMP, V10, P3669, DOI 10.1007/s12652-018-1093-8
   Bhattacharyya DK, 2016, DDOS ATTACKS: EVOLUTION, DETECTION, PREVENTION, REACTION, AND TOLERANCE, P1, DOI 10.1201/b20614
   Bhavani Y, 2020, ADV INTELLIGENT SYST, V1090, DOI [10.1007/978-981-15-1480-7-40, DOI 10.1007/978-981-15-1480-7-40]
   Bhuyan MH, 2015, PATTERN RECOGN LETT, V51, P1, DOI 10.1016/j.patrec.2014.07.019
   Bhuyan MH, 2014, COMPUT J, V57, P537, DOI 10.1093/comjnl/bxt031
   Bijalwan A, 2015, J NETW, V10, P287, DOI 10.4304/jnw.10.5.287-293
   Bista S, 2018, DDOS ATTACK DETECTIO
   Bouyeddou B, 2020, ENG SCI TECHNOL, V23, P870, DOI 10.1016/j.jestch.2020.05.002
   BRADEN R., 1994, RFC1633
   Brustoloni J., 2002, WWW 02, P553
   Burch H, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTEENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XIV), P319
   Burton J., 2003, CISC SEC PROF GUID S, P1
   Bush Stephen F, 2010, NANOSCALE COMMUNICAT
   Cannady J., 1998, P 1998 NAT INF SYST
   Casas P, 2012, COMPUT COMMUN, V35, P772, DOI 10.1016/j.comcom.2012.01.016
   Cerroni W, 2015, COMPUT SECUR, V52, P1, DOI 10.1016/j.cose.2015.03.006
   Challa S, 2018, COMPUT ELECTR ENG, V69, P534, DOI 10.1016/j.compeleceng.2017.08.003
   Chan GY, 2013, J NETW COMPUT APPL, V36, P829, DOI 10.1016/j.jnca.2012.11.006
   Chen CL, 2009, J UNIVERS COMPUT SCI, V15, P488
   Chen E., 2001, Active Networks, V2207, P1
   Chen Y, 2006, INT S COLLAB TECHNOL
   Chung CY, 2000, INTEGRITY INTERNAL C, V37, DOI [10.1007/978-0-387-35501-6-12, DOI 10.1007/978-0-387-35501-6-12]
   Daimi K., 2018, Computer and network security essentials
   Damon E, 2012, PROCEEDINGS OF THE 2012 INFORMATION SECURITY CURRICULUM DEVELOPMENT CONFERENCE (INFOSEC CD '12), P21
   Das AK, 2018, IEEE INTERNET THINGS, V5, P4900, DOI 10.1109/JIOT.2018.2877690
   Dean D., 2002, ACM Transactions on Information and Systems Security, V5, P119, DOI 10.1145/505586.505588
   Dekeris B, 2006, 28 INT C INF TECHN I
   Dong S, 2019, IEEE ACCESS, V11
   Dorigo M, 1991, The Ant System: An Autocatalytic Optimizing Process
   Elhag S, 2015, EXPERT SYST APPL, V42, P193, DOI 10.1016/j.eswa.2014.08.002
   Enigo V.S.F., 2020, P 5 INT C COMM EL SY, P567
   Fadlallah A, 2008, 2008 3 INT C INF COM
   Feinstein L, 2003, DARPA INFORMATION SURVIVABILITY CONFERENCE AND EXPOSITION, VOL I, PROCEEDINGS, P303, DOI 10.1109/discex.2003.1194894
   Ferguson P, 1998, 2267 RFC IETF
   Forouzan B.A., 2003, DATA COMMUN
   Fortunati S, 2016, SIGNAL IMAGE VIDEO P, V10, P687, DOI 10.1007/s11760-015-0796-y
   Fossaceca JM, 2015, EXPERT SYST APPL, V42, P4062, DOI 10.1016/j.eswa.2014.12.040
   François J, 2012, IEEE ACM T NETWORK, V20, P1828, DOI 10.1109/TNET.2012.2194508
   Garg A, 2002, INT WORKSH QUAL SERV, P45, DOI 10.1109/IWQoS.2002.1006573
   Gasti P., 2013, 2013 22 INT C COMP C
   Gavrilis D, 2005, COMPUT NETWORKS ISDN
   Gil MT, 2001, P 10 C USENIX SEC S, V10
   Gilad Y, 2012, ACM T INFORM SYST SE, V15, DOI 10.1145/2240276.2240277
   Gong C, 2008, IEEE T PARALL DISTR, V19, P1310, DOI 10.1109/TPDS.2007.70817
   Gonzalez O, 1997, REAL TIM SYST SYMP P, P79, DOI 10.1109/REAL.1997.641271
   Gopi R, 2021, ENHANCED METHOD ANN
   Gulisano V, 2015, EXPERT SYST APPL, V42, P9620, DOI 10.1016/j.eswa.2015.07.027
   Haider S, 2020, IEEE ACCESS, V11
   Hamedi-Hamzehkolaie M, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1142, DOI 10.1109/ISTEL.2012.6483158
   Han ZY, 2010, INT CONF COMP SCI, P98, DOI 10.1109/ICCSIT.2010.5563881
   Hancock B, 2000, COMPUT SECUR, V19, P669
   Hauben, 2007, HIST ARPANET
   He DB, 2018, IEEE T IND INFORM, V14, P3618, DOI 10.1109/TII.2017.2771382
   He DBA, 2016, WIREL NETW, V22, P491, DOI 10.1007/s11276-015-0983-3
   Heinanen J, 1999, REQUEST COMMENTS PRO
   Hoque N, 2017, COMPUT COMMUN, V110, P48, DOI 10.1016/j.comcom.2017.05.015
   Hoque N, 2016, SECUR COMMUN NETW, V9, P2032, DOI 10.1002/sec.1460
   Horng SJ, 2011, EXPERT SYST APPL, V38, P306, DOI 10.1016/j.eswa.2010.06.066
   Hsu W., IEEE INFOCOM SER
   Hu JK, 2009, IEEE NETWORK, V23, P42, DOI 10.1109/MNET.2009.4804323
   Hussain B, 2021, IEEE T IND INFORM, V17, P860, DOI 10.1109/TII.2020.2974520
   imon M, 2019, ADV INTELLIGENT SYST, V984, DOI [10.1007/978-3-030-19807-7-12, DOI 10.1007/978-3-030-19807-7-12]
   Inamdar K, 2014, I C EMERG TECH TREND, DOI 10.1109/ET2ECN.2014.7044975
   Ioannidis J, 2002, P NETW DISTR SYST SE, P6
   Izaddoost A, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P441, DOI 10.1109/ADCOM.2007.103
   Jacobson V, 1999, 2598 INT ENG TASK FO
   Jalili R, 2005, LECT NOTES COMPUT SC, V3439, P192
   Jamader AR, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P377, DOI [10.1109/iccs45141.2019.9065692, 10.1109/ICCS45141.2019.9065692]
   Jamali S, 2014, COMPUT ELECTR ENG, V40, P2013, DOI 10.1016/j.compeleceng.2014.05.012
   Jan NY, 2009, EXPERT SYST APPL, V36, P11145, DOI 10.1016/j.eswa.2009.02.097
   Jelodar H, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P156, DOI 10.1109/ICCICCT.2014.6992947
   Jiang XX, 2006, J PARALLEL DISTR COM, V66, P1165, DOI 10.1016/j.jpdc.2006.04.012
   Jin C. G., 2003, ACM CCS
   Juels A., 1999, Proceedings 1999 Network and Distributed System Security Symposium, P151
   Kalia A., 2015, ACM SIGCOMM COMP COM, V44, P295
   Kalkan K, 2017, IEEE SYST J, V11, P2761, DOI 10.1109/JSYST.2016.2602848
   Kantardzic M., 2020, DATA MINING CONCEPTS, V3rd ed.
   Karami A, 2015, NEUROCOMPUTING, V151, P1262, DOI 10.1016/j.neucom.2014.11.003
   Kargl F., 2001, P 10 INT C WORLD WID, P514, DOI DOI 10.1145/371920.372148
   Karimazad R, 2011, INT PROC COMPUT SCI, V11, P44
   Kaur ChahalJ., 2019, NEW REV INFORM NETWO, V24, P31, DOI [DOI 10.1080/13614576.2019.1611468, 10.1080/13614576.2019.1611468]
   Kemmerer D, 2002, COMPUTER, P27, DOI 10.1109/MC.2002.1012428
   Khajuria A, 2013, INT J ENHANCED RES M, V2, P37
   Khajuria A, 2013, KNOWLEDGE BASED SYST
   Khattab SM, 2003, ITR INT C INF TECHN
   Koay A, 2018, 2018 32 INT C INF
   Krasnov A. E., 2018, INT J APPL ENG RES, V13, P5647
   Kshirsagar D., 2016, Perspectives in Science, V8, P4, DOI DOI 10.1016/J.PISC.2016.06.074
   Kumar KPK, 2014, RECENT TRENDS COMPUT, V420, DOI [10.1007/978-3-642-54525-2-4, DOI 10.1007/978-3-642-54525-2-4]
   Kumar Manish, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P248, DOI 10.1109/ICOEI48184.2020.9142954
   Kumar N, 2015, FUTURE GENER COMP SY, V48, P60, DOI 10.1016/j.future.2014.10.013
   Kumar PAR, 2011, COMPUT COMMUN, V34, P1328, DOI 10.1016/j.comcom.2011.01.012
   Kumar S., 2007, Internet Monitoring and Protection, P25, DOI DOI 10.1109/ICIMP.2007.42
   Kumar S, 1994, DEP COMPUTER SCI TEC
   Kumar V., 2012, International Journal of Computer Applications Information Technology, V1, P35
   Le Anh, 2008, INFOCOM WORKSH 2008, P1
   Lee C., The Journal of Supercomputing, V77, P2021
   Lee HCJ, 2003, LECT NOTES COMPUT SC, V2836, P124
   Lee K, 2008, EXPERT SYST APPL, V34, P1659, DOI 10.1016/j.eswa.2007.01.040
   Lee SM, 2012, COMPUT MATH APPL, V63, P501, DOI 10.1016/j.camwa.2011.08.020
   Lee S, 2011, EXPERT SYST APPL, V38, P14891, DOI 10.1016/j.eswa.2011.05.058
   Lee TH, 2020, IEEE INT CONF COMM, DOI 10.1109/iccworkshops49005.2020.9145085
   Li YH, 2012, EXPERT SYST APPL, V39, P424, DOI 10.1016/j.eswa.2011.07.032
   Limwiwatkul L, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P605
   Lin CH, 2013, J AMB INTEL HUM COMP, V4, P275, DOI 10.1007/s12652-011-0091-x
   Liu ZT, 2019, IEEE T INF FOREN SEC, V14, P1098, DOI 10.1109/TIFS.2018.2870828
   Loukas G, 2010, COMPUT J, V53, P1020, DOI 10.1093/comjnl/bxp078
   Lu K, 2007, COMPUT NETW, V51, P5036, DOI 10.1016/j.comnet.2007.08.008
   Ma XL, 2014, IEEE COMMUN LETT, V18, P114, DOI 10.1109/LCOMM.2013.112613.132275
   Mahajan D., 2013, International Journal of Computer Applications, V67, P21, DOI [https://doi.org/10.5120/11504-7221, DOI 10.5120/11504-7221]
   Mahajan R, 2002, ACM SIGCOMM COMP COM, V32, P69, DOI 10.1145/510726.510743
   Mahjabin T, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717741463
   Malliga S, 2018, 2018 INT C INT COMP
   Manavi MT, 2018, COMPUT ELECTR ENG, V72, P26, DOI 10.1016/j.compeleceng.2018.09.001
   Mankin A, 2001, IEEE IC COMP COM NET
   Mankins D., 2001, 17 ANN COMP SEC APPL
   Migga Kizza Joseph, 2017, GUIDE COMPUTER NETWO
   Mirkovic J, 2005, IEEE T DEPEND SECURE, V2, P216, DOI 10.1109/TDSC.2005.35
   Mishra A, 2011, EUR INT SEC INF C
   Mittal V., 2013, INT J COMPUTER APPL, V64, P1, DOI [10.5120/10619-2143, DOI 10.5120/10619-2143]
   Mugunthan S., 2019, J. Soft Comput. Paradig, V1, P80
   Muhammad M.B., 2020, IEEE IJCNN
   MYTHILI T, 2019, ENHANCED PACKET MARK
   Nadiammai GV, 2014, EGYPT INFORM J, V15, P37, DOI 10.1016/j.eij.2013.10.003
   National Institute of Standards and Technology, 1995, CONCEPTUAL FRAMEWORK
   Negi PS, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P129, DOI [10.1109/confluence47617.2020.9057961, 10.1109/Confluence47617.2020.9057961]
   NG CK, 2018, HONEYPOT FRAMEWORKS, DOI [10.1007/978-981-10-7739-5, DOI 10.1007/978-981-10-7739-5]
   Dao NN, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P245, DOI 10.1109/ICOIN.2018.8343118
   Nilsson NilsJ., 1996, INTRO MACHINE LEARNI
   Oikonomou G, 2006, ANN COMPUT SECURITY
   Okafor K., 2016, Int. J. Comput. Appl, V138, P18, DOI [10.5120/ijca2016908930, DOI 10.5120/IJCA2016908930]
   Orosz P., 2018, NOMS 2018 2018 IEEE, P1
   Osanaiye O, 2016, J NETW COMPUT APPL, V67, P147, DOI 10.1016/j.jnca.2016.01.001
   Ozcelik ?, 2016, 2016 4 INT IST, P15
   Peddabachigari S, 2007, J NETW COMPUT APPL, V30, P114, DOI 10.1016/j.jnca.2005.06.003
   Peneti S., 2020, J CRIT REV, V7, P1328
   Peng T, 2003, 2003 IEEE INT C
   Phan TV, 2020, IEEE T NETW SERV MAN, V17, P1349, DOI 10.1109/TNSM.2020.3004415
   Pharande S, 2015, IEEE INT ADV COMPUT, P834, DOI 10.1109/IADCC.2015.7154823
   Pinzón CI, 2011, APPL SOFT COMPUT, V11, P4384, DOI 10.1016/j.asoc.2010.12.003
   Poongodi M, 2019, IEEE ACCESS, V7, P183532, DOI 10.1109/ACCESS.2019.2960367
   Poongodi M, 2019, IEEE ACCESS, V7, P158481, DOI 10.1109/ACCESS.2019.2945682
   Raghavan S. V., 2011, INVESTIGATION DETECT
   Rahul Vigneswaran K, 2019, LECT NOTES ELECT ENG
   Ramaki AA, 2014, COMPUT SECUR
   Rohit MH, 2019, 2019 IEEE INT C ROB, P58
   Saad Redhwan M. A., 2013, International Journal on Network Security, V4, P35
   Sadoddin R, 2009, COMPUT SECUR, V28, P153, DOI 10.1016/j.cose.2008.11.010
   Saifullah, 2009, DEFENDING DISTRIBUTE
   Sardana A, 2008, P 2 INT C INF SEC
   Sarnovsky M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020203
   Sastry CS, 2007, INFORM SCIENCES, V177, P5275, DOI 10.1016/j.ins.2006.07.007
   Saurabh S, 2014, COMPUT COMMUN, V42, P60, DOI 10.1016/j.comcom.2014.01.003
   Savage S, 2001, IEEE ACM T NETWORK, V9, P226, DOI 10.1109/90.929847
   Saxena R, 2020, CLUSTER COMPUT, V23, P1329, DOI 10.1007/s10586-019-02994-2
   Schnackenberg D, 2001, DISCEX'01: DARPA INFORMATION SURVIVABILITY CONFERENCE & EXPOSITION II, VOL I, PROCEEDINGS, P56, DOI 10.1109/DISCEX.2001.932192
   Schnackenberg D, 2000, P DISCEX JAN
   Sengupta N, 2020, COGNITIVE INTELLIGEN
   Sharma R, 2020, 2020 IFIP NETW C NET
   Shi Z, 2019, 2019 IEEE GLOB COMM
   Shiaeles SN, 2012, COMPUT SECUR, V31, P782, DOI 10.1016/j.cose.2012.06.002
   Shohani RB, 2021, WIRELESS PERS COMMUN, V120, P379, DOI 10.1007/s11277-021-08465-5
   Snoeren AC., 2002, IEEE ACM T NETWORK, V10, P721, DOI 10.1109/TNET.2002.804827
   Spitzner L., 2003, HONEYTOKENS OTHER HO
   Spitzner L, 2003, 19 ANN COMP SEC
   Srivastava A, 2011, COMM COM INF SC, V203, P570
   Stevanovic D, 2012, EXPERT SYST APPL, V39, P8707, DOI 10.1016/j.eswa.2012.01.210
   Stone R, 2000, USENIX ASS P 9
   Su MY, 2011, EXPERT SYST APPL, V38, P3492, DOI 10.1016/j.eswa.2010.08.137
   Su MY, 2011, J NETW COMPUT APPL, V34, P722, DOI 10.1016/j.jnca.2010.10.009
   Su MY, 2010, J COMMUN NETW-S KOR, V12, P375, DOI 10.1109/JCN.2010.6388474
   Su MY, 2009, COMPUT SECUR, V28, P301, DOI 10.1016/j.cose.2008.12.001
   Subba B, 2019, IEEE I C ADV NETW TE, DOI 10.1109/ants47819.2019.9117966
   Tan ZY, 2014, IEEE T PARALL DISTR, V25, P447, DOI 10.1109/TPDS.2013.146
   Tanenbaum Andrew S, 2014, COMPUTER NETWORKS BO
   Tao Y, 2013, IEEE INT CONF TRUST
   Tellenbach B, 2011, COMPUT NETW, V55, P3485, DOI 10.1016/j.comnet.2011.07.008
   Thantharate A, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P852, DOI [10.1109/CCWC47524.2020.9031158, 10.1109/ccwc47524.2020.9031158]
   Thomas R, 2003, DARPA INF SURV C
   Tupakula UK, 2003, ACM INT C P SERIES, P204
   Udhayan J., 2011, International Journal of Network Security, V13, P152
   Vacas I, 2018, 2018 14TH EUROPEAN DEPENDABLE COMPUTING CONFERENCE (EDCC 2018), P128, DOI 10.1109/EDCC.2018.00031
   Venkatraman R., 2018, P 2018 IEEE INT C SY, P1, DOI DOI 10.1109/ICSCAN.2018.8541174
   Verma A., 2004, SANS I GLOBAL INFORM
   Verwoerd T, 2002, COMPUT COMMUN, V25, P1356, DOI 10.1016/S0140-3664(02)00037-3
   Vetha S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5279
   Vijayalakshmi M, 2014, J INF SCI ENG
   Wan XY, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P428, DOI 10.1109/WCINS.2010.5541813
   Wang Qinquan, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P630, DOI 10.1109/ETCS.2010.196
   Wang WY, 2001, INT FED INFO PROC, V65, P369
   Wazid M, 2017, IEEE T IND INFORM, V13, P3144, DOI 10.1109/TII.2017.2732999
   Weiler NN, 2002, WET ICE 2002 11
   Wu SY, 2009, EXPERT SYST APPL, V36, P5605, DOI 10.1016/j.eswa.2008.06.138
   Wu YC, 2011, INT J AD HOC UBIQ CO, V7, P121, DOI 10.1504/IJAHUC.2011.038998
   Xiang Y, 2009, IEEE T PARALL DISTR, V20, P567, DOI 10.1109/TPDS.2008.132
   Xu X, 2005, LECT NOTES ARTIF INT, V3584, P696
   Yan Q, 2016, IEEE COMMUN SURV TUT, V18, P602, DOI 10.1109/COMST.2015.2487361
   Yao G, 2015, IEEE T INF FOREN SEC, V10, P471, DOI 10.1109/TIFS.2014.2381873
   Yau DKY, 2005, IEEE ACM T NETWORK, V13, P29, DOI 10.1109/TNET.2004.842221
   Yu J, 2013, J SYST ARCHITECT, V59, P1005, DOI 10.1016/j.sysarc.2013.08.008
   Yu J, 2008, COMPUT COMMUN, V31, P4212, DOI 10.1016/j.comcom.2008.09.018
   Zargar ST, 2013, IEEE COMMUN SURV TUT, V15, P2046, DOI 10.1109/SURV.2013.031413.00127
   Zhang GS, 2006, J RES PRACT INF TECH, V38, P69
   Zhang ZZ, 2015, MULTIMED TOOLS APPL, V74, P3477, DOI 10.1007/s11042-014-1885-6
   Zhao W., 2000, INTERNET QUALITY SER, DOI DOI 10.7916/D8T15FTV
   Zhauniarovich Y, 2019, P 2019 IEEE C NETW
   Zoo, 2021, IEEE J SEL AREA COMM
NR 235
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19879
EP 19944
DI 10.1007/s11042-021-11859-z
EA MAY 2022
PG 66
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000791638100003
DA 2024-07-18
ER

PT J
AU Wang, WC
   Jiang, L
   Lin, SR
   Fang, H
   Meng, QG
AF Wang, Weichao
   Jiang, Lei
   Lin, Shiran
   Fang, Hui
   Meng, Qinggang
TI Imitation learning based decision-making for autonomous vehicle control
   at traffic roundabouts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced driving assistance system; Intelligent roundabout-join task;
   Imitation learning
ID CLASSIFICATION
AB The essential of developing an advanced driving assistance system is to learn human-like decisions to enhance driving safety. When controlling a vehicle, joining roundabouts smoothly and timely is a challenging task even for human drivers. In this paper, we propose a novel imitation learning based decision making framework to provide recommendations to join roundabouts. Our proposed approach takes observations from a monocular camera mounted on vehicle as input and use deep policy networks to provide decisions when is the best timing to enter a roundabout. The domain expert guided learning framework can not only improve the decision-making but also speed up the convergence of the deep policy networks. We evaluate the proposed framework by comparing with state-of-the-art supervised learning methods, including conventional supervised learning methods, such as SVM and kNN, and deep learning based methods. The experimental results demonstrate that the imitation learning-based decision making framework, which ourperforms supervised learning methods, can be applied in driving assistance system to facilitate better decision-making when approaching roundabouts.
C1 [Wang, Weichao; Jiang, Lei; Lin, Shiran; Fang, Hui; Meng, Qinggang] Loughborough Univ, Comp Sci Dept, Epinal Way, Loughborough, Leics, England.
C3 Loughborough University
RP Fang, H (corresponding author), Loughborough Univ, Comp Sci Dept, Epinal Way, Loughborough, Leics, England.
EM w.wang3@lboro.ac.uk; H.Fang@lboro.ac.uk
RI shen, jickie/GSN-7389-2022
OI Fang, Hui/0000-0001-9365-7420
CR Abdulkader MMS, 2015, APPL SOFT COMPUT, V37, P196, DOI 10.1016/j.asoc.2015.08.020
   Adler B, 2014, J FIELD ROBOT, V31, P912, DOI 10.1002/rob.21526
   Aeberhard M, 2015, IEEE INTEL TRANSP SY, V7, P42, DOI 10.1109/MITS.2014.2360306
   Alom Md. Zahangir., 2018, Computing Research Repository
   Anggodo Y., 2017, J. Environ. Eng. Sustain. Technol, V3, P92, DOI [10.21776/ub.jeest.2017.003.02.4, DOI 10.21776/UB.JEEST.2017.003.02.4]
   [Anonymous], 2017, ELECT IMAG, DOI [DOI 10.2352/ISSN.2470-1173.2017.19.AVM-023, 10.2352/ISSN.2470-1173.2017.19.AVM-023]
   Ballester P., 2016, 30 AAAI C ARTIFICIAL
   Bansal M, 2018, ARXIV 181203079
   Bojarski M, 2017, ARXIV 170407911
   Chen Ai-ling, 2006, Journal of Zhejiang University (Science), V7, P607, DOI 10.1631/jzus.2006.A0607
   Codevilla F, 2018, IEEE INT CONF ROBOT, P4693
   El Hamdani S, 2017, LECT NOTES COMPUT SC, V10542, P95, DOI 10.1007/978-3-319-68179-5_9
   Cuenca LG, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121536
   Cuenca LG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102386
   Gritschneder F, 2016, IEEE INT VEH SYM, P433, DOI 10.1109/IVS.2016.7535422
   Guerrero-Ibáñez J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041212
   Hassannejad H, 2015, EXPERT SYST APPL, V42, P4167, DOI 10.1016/j.eswa.2015.01.032
   Hawke J, 2019, ARXIV 191200177
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hecht J, 2018, OPT PHOTONICS NEWS, V29, P26
   Hester T., 2018, Thirty-second AAAI Conference on Artificial Intelligence
   Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912
   Indu S., 2011, Int. J. Eng. Sci. Technol, V3, P429
   Jones M, 2018, US Patent, Patent No. [10,054,944, 10054944]
   Jurewicz C, 2017, UNDERSTANDING IMPROV
   Kebria PM, 2020, IEEE-CAA J AUTOMATIC, V7, P82, DOI 10.1109/JAS.2019.1911825
   Kennedy JV, 2008, NAT ROUND C TRB KANS, P1821
   Lin SH, 2016, NEUROCOMPUTING, V218, P197, DOI 10.1016/j.neucom.2016.08.056
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Liu J, 2018, FUTURE GENER COMP SY, V78, P817, DOI 10.1016/j.future.2017.02.017
   Muffert M, 2013, IEEE INTEL TRANSP SY, V5, P22, DOI 10.1109/MITS.2013.2244934
   Muffert M, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P565, DOI 10.1109/IVS.2012.6232178
   Okumura B, 2016, IEEE T INTELL VEHICL, V1, P20, DOI 10.1109/TIV.2016.2551545
   Pan Y, 2017, ARXIV 170907174
   Noi PT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010018
   Pomerleau DA, 1989, ADV NEURAL INFORM PR
   Rampasek L, 2016, CELL SYST, V2, P12, DOI 10.1016/j.cels.2016.01.009
   Rathod V., 2017, Tensorflow detection model zoo
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rhinehart C, 2018, ARXIV 181006544
   Rodrigues M, 2018, IEEE T INTELL VEHICL, V3, P425, DOI 10.1109/TIV.2018.2873916
   Sarfaraz Masood, 2018, DETECTING DISTRACTIO
   Sun L., 2016, ResNet on Tiny ImageNet
   Sun S., 2019, Improving DQN and TRPO with Hierarchical Meta-controllers
   Vallati M, 2016, AAAI CONF ARTIF INTE, P3188
   Van Brummelen J, 2018, TRANSPORT RES C-EMER, V89, P384, DOI 10.1016/j.trc.2018.02.012
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang T, 2019, ARXIV 190706838
   Wang W, 2018, MULTICAMERAS BASED D, P75
   Wang W, 2019, 2019 IEEE INT C VEH, P16
   Wang WC, 2018, I C CONT AUTOMAT ROB, P1460, DOI 10.1109/ICARCV.2018.8581347
   Wei Liu, 2016, SSD SINGLE SHOT MULT
   Williams G, 2017, 2017 IEEE INT C ROB
   Williams S, 2020, ARTIF INTELL MED, V110, DOI 10.1016/j.artmed.2020.101966
   Wolf P, 2017, IEEE INT VEH SYM, P244, DOI 10.1109/IVS.2017.7995727
   Wong DC, 2019, COMP MED SY, P32, DOI 10.1109/CBMS.2019.00017
   Yadav N., 2017, Int. Res. J. Eng. Technol. (IRJET), P586
   Yi Z, 2017, 2017 IEEE INT C IMAG
   Zeng W, 2019, P IEEE C COMPUTER VI
   Zimmermann RS, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.102795
NR 60
TC 9
Z9 9
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39873
EP 39889
DI 10.1007/s11042-022-12300-9
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790645700002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kaur, D
   Saini, KK
   Kumar, D
AF Kaur, Damandeep
   Saini, Khushil Kumar
   Kumar, Devender
TI Cryptanalysis and enhancement of an authentication protocol for secure
   multimedia communications in IoT-enabled wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Multimedia; Security; Sensor node; Gateway node
ID KEY AGREEMENT SCHEME; 2-FACTOR USER AUTHENTICATION; MUTUAL
   AUTHENTICATION; INTERNET
AB Multimedia technology is a sub field of Internet of Things (IoT) in which multimedia devices are embedded to Wireless Sensor Network (WSN). In this, such devices are used for the flow of multimedia applications such as videos, audios and still images over the internet. For transferring these applications, sensor node captures all the data and transfer it to Gateway Node (GWN) via open channel. Due to the vulnerability of the open channel from the attackers, there are many security issues involved in it and have been researched for many years. Recently, Mishra et al. have presented an authentication protocol for multimedia technology using wireless sensor networks which can be applied in coal mine environment and authors had claimed that this protocol is secure from various attacks. But, in this paper, their protocol is analyzed and proved that it is vulnerable to sensor node impersonation attack, sensor node anonymity problem and insecure session key agreement. Also, a new authentication protocol has been proposed by overcoming these flaws. ProVerif tool is used for the formal security verification. Moreover, the performance of the proposed protocol in terms of computational cost, communication cost, storage cost and security features is compared with other related schemes and it is shown that the proposed protocol offers more security features.
C1 [Kaur, Damandeep] Ericsson India Global Serv, Gurugram, Haryana, India.
   [Saini, Khushil Kumar] NSUT, Dept Comp Sci, Engn, New Delhi, India.
   [Kumar, Devender] NSUT, Dept Informat Technol, New Delhi, India.
C3 Netaji Subhas University of Technology; Netaji Subhas University of
   Technology
RP Kumar, D (corresponding author), NSUT, Dept Informat Technol, New Delhi, India.
EM damankaur55@gmail.com; khushil.nsit@gmail.com; dk_iitm@yahoo.co.in
RI SAINI, KHUSHIL/JRX-9251-2023
CR Akyildiz IF, 2007, IEEE WIREL COMMUN, V14, P32, DOI 10.1109/MWC.2007.4407225
   Chen TH, 2010, ETRI J, V32, P704, DOI 10.4218/etrij.10.1510.0134
   Das AK, 2012, J NETW COMPUT APPL, V35, P1646, DOI 10.1016/j.jnca.2012.03.011
   Das ML, 2009, IEEE T WIREL COMMUN, V8, P1086, DOI 10.1109/TWC.2008.080128
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Farash MS, 2016, AD HOC NETW, V36, P152, DOI 10.1016/j.adhoc.2015.05.014
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Hamid Z, 2016, MULTIMED TOOLS APPL, V75, P8195, DOI 10.1007/s11042-015-2737-8
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   Jiang Q, 2017, IEEE ACCESS, V5, P3376, DOI 10.1109/ACCESS.2017.2673239
   Jiang Q, 2015, PEER PEER NETW APPL, V8, P1070, DOI 10.1007/s12083-014-0285-z
   Kaur D, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3745
   Khan MK, 2010, SENSORS-BASEL, V10, P2450, DOI 10.3390/s100302450
   Kumar D, 2019, J AMB INTEL HUM COMP, V10, P641, DOI 10.1007/s12652-018-0712-8
   Kumar P, 2012, SENSORS-BASEL, V12, P1625, DOI 10.3390/s120201625
   Kumari S, 2019, IEEE ACCESS, V7, P39717, DOI 10.1109/ACCESS.2019.2905731
   Kumari S, 2016, COMPUT NETW, V104, P137, DOI 10.1016/j.comnet.2016.05.007
   Li JL, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3295
   Mishra D, 2018, MULTIMED TOOLS APPL, V77, P18295, DOI 10.1007/s11042-017-5376-4
   Ostad-Sharif A, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1120-5
   Spreitzer R, 2018, IEEE COMMUN SURV TUT, V20, P465, DOI 10.1109/COMST.2017.2779824
   Sureshkumar V, 2019, FUTURE GENER COMP SY, V100, P938, DOI 10.1016/j.future.2019.05.058
   Turkanovic M, 2013, ELEKTRON ELEKTROTECH, V19, P109, DOI 10.5755/j01.eee.19.6.2038
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wang D, 2018, IEEE T DEPEND SECURE, V15, P708, DOI 10.1109/TDSC.2016.2605087
   Xie Q, 2017, COMPUT ELECTR ENG, V59, P218, DOI 10.1016/j.compeleceng.2016.11.038
   Xu S., 2013, Int Rev Comput Softw, V8, P197
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
NR 28
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39367
EP 39385
DI 10.1007/s11042-022-12088-8
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000004
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Guo, YF
   Huang, JC
   Dai, M
   Deng, M
   Yu, QJ
AF Zhou, Zhiheng
   Guo, Yongfan
   Huang, Junchu
   Dai, Ming
   Deng, Ming
   Yu, Qingjun
TI Superpixel attention guided network for accurate and real-time salient
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Superpixel segmentation; Deep clustering;
   Image segmentation
AB Edge information has been proven to be effective for remedying the unclear boundaries of salient objects. Current salient object detection (SOD) methods usually utilize edge detection as an auxiliary task to introduce explicit edge information. However, edge detection is unable to provide the indispensable regional information for SOD, which may result in incomplete salient objects. To alleviate this risk, observing that superpixels hold the inherent property that contains both edge and regional information, we propose a superpixel attention guided network (SAGN) in this paper. Specifically, we first devise a novel supervised deep superpixel clustering (DSC) method to form the relation between superpixels and SOD. Based on the DSC, we build a superpixel attention module (SAM), which provides superpixel attention maps that can neatly separate different salient foreground and background regions, while preserving accurate boundaries of salient objects. Under the guidance of the SAM, a lightweight decoder with a simple but effective structure is able to yield high-quality salient objects with accurate and sharp boundaries. Hence, our model only contains less than 5 million parameters and achieves a real-time speed of around 40 FPS. Whilst offering a lightweight model and fast speed, our method still outperforms other 11 state-of-the-art approaches on six benchmark datasets.
C1 [Zhou, Zhiheng; Guo, Yongfan; Huang, Junchu; Dai, Ming; Deng, Ming] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Zhou, Zhiheng; Guo, Yongfan; Huang, Junchu; Dai, Ming; Deng, Ming] South China Univ Technol, Minist Educ, Key Lab Big Data & Intelligent Robot, Guangzhou, Peoples R China.
   [Yu, Qingjun] Dalian Neusoft Univ Informat, Sch Digital Arts & Design, Dalian, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.; Zhou, ZH (corresponding author), South China Univ Technol, Minist Educ, Key Lab Big Data & Intelligent Robot, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023; Yu, Qing/KIG-5023-2024
FU National Key R&D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research projects
   (201902020008).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen CR, 2020, AAAI CONF ARTIF INTE, V34, P10510
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Parimala M, 2021, SOFTWARE PRACT EXPER, V51, P550, DOI 10.1002/spe.2851
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   Reddy GT, 2020, COMPUT COMMUN, V157, P64, DOI 10.1016/j.comcom.2020.04.004
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schuurmans M., 2018, ARXIV180602705
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somayaji S R K, 2020, ARXIV201101473
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Xie JY, 2016, PR MACH LEARN RES, V48
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang B, 2017, PR MACH LEARN RES, V70
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao K, 2019, IEEE I CONF COMP VIS, P8848, DOI 10.1109/ICCV.2019.00894
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 55
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38921
EP 38944
DI 10.1007/s11042-022-13083-9
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500010
DA 2024-07-18
ER

PT J
AU Jallouli, M
   Sayahi, I
   Ben Mabrouk, A
AF Jallouli, Malika
   Sayahi, Ikbel
   Ben Mabrouk, Anouar
TI Robust crypto-watermarking approach based on spherical harmonics and AES
   algorithm for 3D mesh safe transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AES algorithm; Multiresolution 3D mesh; Quantification method; Spherical
   harmonics; Spherical harmonics entropy
AB The wide range of applications of 3D meshes and the birth of very high-speed networks for storing 3D models in remote multimedia databases have made the copyright protection of these objects a necessity. In order to contribute to safe sharing, transfer and indexing of 3D multiresolution meshes, a new crypto-watermarking approach is proposed based on spherical harmonics and AES encryption algorithm. Data to be inserted, in this case, is a grayscale image already encrypted using AES256 algorithm. The host mesh, to be watermarked, is decomposed using spherical harmonics to extract frequency coefficients and to compute optimal order for reconstruction. These coefficients undergo two watermarking iterations. During each round, modulation, insertion using quantification method and demodulation steps are implemented. Finally, reconstruction of watermarked mesh using a minimal number of coefficients is conducted. The results established show clearly that our algorithm protects the mesh quality even with the insertion of a large amount of information (a whole image) while ensuring real time execution. The application of various attacks (noise addition, coordinate quantization, smoothing, translation, rotation, uniform scaling and compression) to a watermarked mesh did not prevent the correct retrieval of inserted information. Our approach presents then an enhancement compared to existing ones.
C1 [Jallouli, Malika] Univ Sousse, Ecole Natl Ingn Sousse, LATIS Lab Adv Technol & Intelligent Syst, Sousse 4023, Tunisia.
   [Sayahi, Ikbel] Univ Sfax, Res Grp Intelligent Machines Lab, ENIS, Sfax 3100, Tunisia.
   [Ben Mabrouk, Anouar] Univ Kairouan, Higher Inst Appl Math & Comp Sci, Dept Math, Kairouan 3100, Tunisia.
   [Ben Mabrouk, Anouar] Univ Monastir, Fac Sci, Dept Math, Lab Algebra Number Theory & Nonlinear Anal LR18ES, Monastir 5019, Tunisia.
   [Ben Mabrouk, Anouar] Univ Tabuk, Fac Sci, Dept Math, Tabuk, Saudi Arabia.
C3 Universite de Sousse; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS); Universite de Kairouan; Universite de Monastir; University
   of Tabuk
RP Sayahi, I (corresponding author), Univ Sfax, Res Grp Intelligent Machines Lab, ENIS, Sfax 3100, Tunisia.
EM jallouli.malika3@gmail.com; sayahi.ikbel@gmail.com;
   anouar.benmabrouk@fsm.rnu.tn
RI Ben Mabrouk, Anouar/B-6289-2014
OI Ben Mabrouk, Anouar/0000-0002-2571-1066
CR Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   [Anonymous], 2001, FEDERAL INFORM PROCE, V197
   Basyoni Lamiaa, 2015, 7th International Conference on Information Technology, P612, DOI 10.15849/icit.2015.0107
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Bülow T, 2004, IEEE T PATTERN ANAL, V26, P1650, DOI 10.1109/TPAMI.2004.129
   Celine R., 2011, REV ELECTRONIQUE FRA, V5, P27
   Che XJ, 2012, INT J PARALLEL EMERG, V27, P133, DOI 10.1080/17445760.2011.574631
   Garg H, 2014, INT CONF COMM SYST, P788, DOI 10.1109/CSNT.2014.165
   Hamid M. R. A., 2017, 2017 IEEE 28 ANN INT, P1
   Jallouli M, 2020, SOFT COMPUT, V24, P5231, DOI 10.1007/s00500-019-04274-y
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Kohli R, 2013, INT J ADV RES COMPUT, V3
   Kohli R., 2013, INT J ADV RES COMPUT, V3, P18
   Kumar BJS, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P501, DOI 10.1109/ICCSP.2017.8286408
   Li L, 2018, IEEE MULTIMEDIA, V25, P49, DOI 10.1109/MMUL.2018.112142343
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Liu J, 2017, NEUROCOMPUTING, V237, P304, DOI 10.1016/j.neucom.2016.12.065
   Mateo MJ, 2010, J DAIRY SCI, V93, P1882, DOI 10.3168/jds.2009-2777
   Mehan, 2018, J ADV INF FUSION, V13, P106
   Muna ML., 2021, IRAQI J SCI, V62, P4999
   Payan F, 2006, IEEE T VIS COMPUT GR, V12, P649, DOI 10.1109/TVCG.2006.73
   Sayahi I, 2019, MULTIMED TOOLS APPL, V78, P13877, DOI 10.1007/s11042-018-6721-y
   Sayahi I, 2017, ADV INTELL SYST, V527, P526, DOI 10.1007/978-3-319-47364-2_51
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sharma N, 2020, IET INFORM SECUR, V14, P745, DOI 10.1049/iet-ifs.2019.0601
   Sridhar P, 2017, INT CONF COMPUT POW, P153, DOI 10.1109/ICCPEIC.2017.8290357
   Tsai YY, 2016, MULTIMED TOOLS APPL, V75, P7891, DOI 10.1007/s11042-015-2707-1
   Wang JT, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1095, DOI 10.1109/IS3C.2014.285
   Wang K, 2009, CORESA 09 COMPRESSIO
   Xiao Zhou, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1509, DOI 10.1109/CECNet.2012.6201895
   Yang Y, 2017, IEEE T VIS COMPUT GR, V23, P1002, DOI 10.1109/TVCG.2016.2525771
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
NR 32
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38543
EP 38567
DI 10.1007/s11042-022-13113-6
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200003
DA 2024-07-18
ER

PT J
AU Ramakrishnan, AH
   Rajappa, M
   Krithivasan, K
   Chatzistergos, PE
   Chockalingam, N
   Nalluri, MR
AF Ramakrishnan, Ananth Hari
   Rajappa, Muthaiah
   Krithivasan, Kannan
   Chatzistergos, Panagiotis E.
   Chockalingam, Nachiappan
   Nalluri, Madhusudhana Rao
TI A concept for movement-based computerized segmentation of connective
   tissue in ultrasound imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tendon; Ligament; Connective tissue; Segmentation algorithm; Normalized
   cross correlation; Displacement map
ID ACTIVE CONTOURS; TENDON; MOTION; SYSTEM
AB This study proposes a novel concept for the computerized segmentation of ultrasound images of connective tissue based on movement. Tendons and ligaments are capable of almost frictionless movement relative to their neighbouring tissues making them good candidates for movement-based segmentation. To demonstrate this concept, a central cross section of the patellar tendon was imaged in the axial plane while movement was generated by manually pulling and pushing the skin close to the imaging area. Maps of internal movement were created for four representative pairs of consecutive images using normalised cross corelation. Thresholding followed by a series of morphological operations (k-clustering, blob extraction, curve fitting) enabled the extraction of the superficial-most tendon boundary. Comparison against manually segmented outputs indicated good agreement against ground truth (average +/- STDEV Bhattacharyya distance: 0.170 +/- 0.039). In contrast to the more superficial parts of the tissue, the applied method for motion generation did not result in clearly visible movement in the tissue areas deeper in the imaging window. The segmentation of the entire tendon will require movement patterns that involve equally the entire tendon (e.g., generated by a contraction of the in-series muscle). The results of this study demonstrate for the first time that movement mapping can be used for the segmentation of connective tissue. Further research will be needed to identify the optimal way to use motion to complement existing segmentation approaches which are based on signal intensity, texture, and shape features.
C1 [Ramakrishnan, Ananth Hari; Rajappa, Muthaiah; Krithivasan, Kannan] SASTRA Deemed Univ, Sch Comp, Comp Vis & Soft Comp Lab, Thanjavur 613401, India.
   [Chatzistergos, Panagiotis E.; Chockalingam, Nachiappan] Staffordshire Univ, Ctr Biomech & Rehabil Technol, Sch Hlth Sci & Wellbeing, Stoke On Trent ST4 2DE, Staffs, England.
   [Nalluri, Madhusudhana Rao] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amrita Sch Engn, Coimbatore 641112, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Staffordshire University; Amrita Vishwa Vidyapeetham; Amrita Vishwa
   Vidyapeetham Coimbatore
RP Rajappa, M (corresponding author), SASTRA Deemed Univ, Sch Comp, Comp Vis & Soft Comp Lab, Thanjavur 613401, India.
EM muthaiah66@gmail.com; n_madhusudanarao@cb.amrita.cdu
RI k, k/KFT-2541-2024; su, haobo/JPK-2362-2023; Chockalingam,
   Nachiappan/C-4423-2014; k, k/KFC-0221-2024; K, Kannan/GPK-0744-2022; k,
   k/HZK-4476-2023
OI Chockalingam, Nachiappan/0000-0002-7072-1271; Chatzistergos,
   Panagiotis/0000-0002-1580-0225; nalluri, Dr.Madhusudana
   rao/0000-0002-5315-1932; Ramakrishnan, Ananth Hari/0000-0002-0603-4979;
   Rajappa, Muthaiah/0000-0002-6659-1961
FU UK-India Education and Research Initiative (UKIERI) grant 'Ultrasound
   based assessment of tissue biomechanics to enhance the clinical
   management of foot related pathologies' [DST/INT/UK/P-145/2016];
   Department of Science and Technology (DST), New Delhi
FX This work has been supported by the UK-India Education and Research
   Initiative (UKIERI) grant 'Ultrasound based assessment of tissue
   biomechanics to enhance the clinical management of foot related
   pathologies' (Project reference number: DST/INT/UK/P-145/2016).
   Financial support was also obtained from Department of Science and
   Technology (DST), New Delhi. The authors would also like to thank TATA
   Realty-IT City - SASTRA Srinivasa Ramanujam Research cell of SASTRA
   University.
CR [Anonymous], 2013, J GLOB RES COMPUT SC
   Bahner DP, 2016, J ULTRAS MED, V35, P183, DOI 10.7863/ultra.15.02036
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Blankstein A, 2011, WORLD J ORTHOP, V2, P13, DOI 10.5312/wjo.v2.i2.13
   BOHS LN, 1991, IEEE T BIO-MED ENG, V38, P280, DOI 10.1109/10.133210
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Buscarini E, 2013, MANUAL DIAGNOSITIC U
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chernak LA, 2012, J BIOMECH, V45, P2618, DOI 10.1016/j.jbiomech.2012.08.001
   Chuang BI, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187042
   Couceiro MS, 2012, SIGNAL IMAGE VIDEO P, V6, P343, DOI 10.1007/s11760-012-0316-2
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dawoud N. N., 2011, INT J COMPUT APPL, V18, P30
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Gautam K. S., 2021, International Journal of Computers and Applications, V43, P858, DOI 10.1080/1206212X.2019.1642438
   Gautam KS, 2019, SOFT COMPUT, V23, P2813, DOI 10.1007/s00500-019-03870-2
   Gebäck T, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-75
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P214, DOI 10.5201/ipol.2012.g-cv
   Giachetti A, 2000, IMAGE VISION COMPUT, V18, P247, DOI 10.1016/S0262-8856(99)00018-9
   Gupta R, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-157
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hisham MB, 2015, IEEE ST CONF RES DEV, P100, DOI 10.1109/SCORED.2015.7449303
   Hodgson RJ, 2012, BRIT J RADIOL, V85, P1157, DOI 10.1259/bjr/34786470
   Jintasuttisak T, 2014, INT C CONTR AUTOMAT, P692, DOI 10.1109/ICCAS.2014.6987868
   Kiritbhai PM, 2021, 2021 INT C COMM CONT, P3
   Klappstein J, 2009, LECT NOTES COMPUT SC, V5414, P611, DOI 10.1007/978-3-540-92957-4_53
   Korstanje JWH, 2010, J BIOMECH, V43, P1373, DOI 10.1016/j.jbiomech.2010.01.001
   Kumar D.T.S., 2020, Journal of Innovative Image Processing, V2, P128, DOI 10.36548/jiip.2020.3.002
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P9791, DOI 10.1007/s11042-018-6599-8
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Kuok CP, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-00768-1
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Maganaris CN, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00091
   Martins N, 2018, IEEE J BIOMED HEALTH, V22, P1261, DOI 10.1109/JBHI.2017.2723819
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Ramakrishnan A., 2019, INT CONF COMPUT, P1, DOI [10.1109/FG.2019.8756529, DOI 10.1109/icccnt45670.2019.8944550]
   Ramu SM, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102560
   Saad Sultan Malik, 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Bioimaging, P71
   Singh V, 2017, IEEE T GEOSCI REMOTE, P1
   Singh V, 2015, PROCEEDINGS OF THE 18TH ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS, VOL 1, P225, DOI 10.1007/978-3-319-13359-1_18
   Singh V, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0129-6
   Tillett J., 2005, Proceedings of the 2nd Indian International Conference on Artificial Intelligence, P1474
   Tsechpenakis G, 2011, MULTI MODALITY STATE-OF-THE-ART MEDICAL IMAGE SEGMENTATION AND REGISTRATION METHODOLOGIES, VOL 1, P33, DOI 10.1007/978-1-4419-8195-0_2
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhou GQ, 2020, IEEE T ULTRASON FERR, V67, P2531, DOI 10.1109/TUFFC.2020.2979481
NR 52
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38053
EP 38066
DI 10.1007/s11042-022-12932-x
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sarkar, JL
   Majumder, A
   Panigrahi, CR
   Roy, S
   Pati, B
AF Sarkar, Joy Lal
   Majumder, Abhishek
   Panigrahi, Chhabi Rani
   Roy, Sudipta
   Pati, Bibudhendu
TI Tourism recommendation system: a survey and future research directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tour recommendation; Social media; Tourism; POIs; Itineraries; RS; AI
ID PERSONALIZED RECOMMENDATION; BAYESIAN NETWORK; EXPERT-SYSTEM; DESIGN;
   ATTRACTIONS; FRAMEWORK; ALGORITHM; TRAVEL; LOCATIONS; PLACES
AB A Recommendation System (RS) is an intelligent computer based system which provide valuable suggestions to the user and are used in several domains. Social media platforms are the most common internet applications due to the large number of users. The numerous posts, likes, etc. have accrued on social media platforms and can be used in variety of recommendation systems. In this work, the primary focus is the tourism domain, where RS serves as a valuable tool for the tourist to plan his trip. Traditional RS systems only cater to the needs of the tourist by examining few factors. However, there are a large range of factors such as environment factors , actual geo-coordinates, trip destination, preferences of the user etc. that need to be taken into account in order to make a foolproof recommendation to the tourists. Tourism Recommendation Systems (TRS) provide suggestions to the tourists to identify the most suited transport (flight, train, etc.), accommodations, museums, special interest places and other items which are required for the trip. Several techniques are used and a thorough study of various techniques of traditional RS and TRS techniques have been done which are specially designed for tourism domain. Various Artificial Intelligence (AI) techniques have been highlighted which are used to solve the tourist recommendation problem. Also, future research direction has been suggested which would improvise the Quality of Service (QoS) of the RS in tourism industry.
C1 [Sarkar, Joy Lal; Majumder, Abhishek] Tripura Univ, Agartala, India.
   [Panigrahi, Chhabi Rani; Pati, Bibudhendu] Rama Devi Womens Univ, Bhubaneswar, India.
   [Roy, Sudipta] Assam Univ, Silchar, India.
C3 Tripura University; Assam University
RP Majumder, A (corresponding author), Tripura Univ, Agartala, India.
EM joylalsarkar@gmail.com; abhi2012@gmail.com; panigrahichhabi@gmail.com;
   sudipta.it@gmail.com; patibibudhendu@gmail.com
RI Majumder, Abhishek/GQO-9495-2022; Majumder, Abhishek/AAV-3041-2020; Roy,
   Sudipta/T-5231-2019; Panigrahi, Chhabi Rani/AAT-7956-2020; Pati,
   Bibudhendu/X-9503-2019; Majumder, Abhishek/ABC-3221-2021
OI Majumder, Abhishek/0000-0001-8451-0451; Majumder,
   Abhishek/0000-0001-8451-0451; Roy, Sudipta/0000-0001-5161-9311;
   Panigrahi, Chhabi Rani/0000-0002-4015-4587; Pati,
   Bibudhendu/0000-0002-2544-5343; Sarkar, Joy Lal/0000-0001-7017-1057;
   Roy, Sudipta/0000-0003-0244-6455
CR Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Aliannejadi M., 2017, ACM Transactions on Information Systems, V36, P1, DOI DOI 10.1145/3231933
   Alonso K., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P650
   Amatriain X, 2011, RECOMMENDER SYSTEMS HANDBOOK, P39, DOI 10.1007/978-0-387-85820-3_2
   [Anonymous], 2008, INTELL ARTIF
   [Anonymous], 2011, CORRABS11065213
   [Anonymous], 2017, Encyclopedia of Machine Learning and Data Mining, DOI DOI 10.1007/978-1-4899-7687-1964
   [Anonymous], 2020, Web of Science
   [Anonymous], 2012, INT C INF PROC MAN U
   [Anonymous], 2012, P 6 ACM C REC SYST D
   Ardissono L, 2003, APPL ARTIF INTELL, V17, P687, DOI [10.1080/713827254, 10.1080/08839510390225050]
   Ashbrook D, 2003, PERS UBIQUIT COMPUT, V7, P275, DOI 10.1007/s00779-003-0240-0
   Ayala VAA, 2017, RECTOUR RECSYS
   Banerjee S, 2010, STUD COMPUT INTELL, V273, P59
   Batet M, 2012, EXPERT SYST APPL, V39, P7319, DOI 10.1016/j.eswa.2012.01.086
   Bedi Punam, 2014, Databases in Networked Information Systems. 9th International Workshop, DNIS 2014. Proceedings: LNCS 8381, P189, DOI 10.1007/978-3-319-05693-7_12
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Bin CZ, 2019, MULTIMED TOOLS APPL, V78, P35135, DOI 10.1007/s11042-019-08096-w
   Borràs J, 2014, EXPERT SYST APPL, V41, P7370, DOI 10.1016/j.eswa.2014.06.007
   Brilhante I, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P757, DOI 10.1145/2505515.2505643
   Brilhante IR, 2015, INFORM PROCESS MANAG, V51, P1, DOI 10.1016/j.ipm.2014.10.003
   Brudy F., 2014, P INT S PERVASIVE DI, P1, DOI [DOI 10.1145/2611009.2611028, 10.1145/2611009.2611028]
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Castillo L, 2008, EXPERT SYST APPL, V34, P1318, DOI 10.1016/j.eswa.2006.12.029
   Ceccaroni L, 2009, THIRD INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2009, PROCEEDINGS, P7, DOI 10.1109/ICDS.2009.25
   Chen BL, 2017, EXPERT SYST APPL, V79, P225, DOI 10.1016/j.eswa.2017.01.037
   Cheng A.-J., 2011, P 19 ACM INT C MULTI, P83
   Dang DC, 2013, EUR J OPER RES, V229, P332, DOI 10.1016/j.ejor.2013.02.049
   Daramola O, 2009, Information and communication technologies in tourism 2009, P135, DOI DOI 10.1007/978-3-211-93971-0
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   De C FM, 2014, P 19 INT C WORLD WID, P94
   Deng MF, 2011, TOURISM MANAGE, V32, P1075, DOI 10.1016/j.tourman.2010.09.006
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Dietz LW, 2018, P WORKSH REC TOUR RE, V7, P13
   Ding H, 2016, IEEE C EVOL COMPUTAT, P4022, DOI 10.1109/CEC.2016.7744300
   Dujmovic JJ, 2006, INT J APPROX REASON, V41, P3, DOI 10.1016/j.ijar.2005.06.006
   Ennis A, 2013, INT J PERVASIVE COMP, V9, P367, DOI 10.1108/IJPCC-09-2013-0026
   Fenza G, 2011, IEEE INT CONF FUZZY, P131
   Gao R, 2018, NEUROCOMPUTING
   Gao Y., 2010, Proceedings of Descriptional Complexity of Formal Systems 12th Workshop (DCFS 2010), P123
   Garcia A, 2010, LECT NOTES COMPUT SC, V6385s, P486, DOI 10.1007/978-3-642-16985-4_47
   Garcia I, 2014, EXPERT SYST APPL, V41, P1245, DOI 10.1016/j.eswa.2013.07.111
   Garcia I, 2011, EXPERT SYST APPL, V38, P7683, DOI 10.1016/j.eswa.2010.12.143
   Garcia-Crespo Angel, 2009, Telematics and Informatics, V26, P306, DOI 10.1016/j.tele.2008.11.008
   García-Crespo A, 2011, EXPERT SYST APPL, V38, P13310, DOI 10.1016/j.eswa.2011.04.152
   Gasmi A, 2016, IEEE SYS MAN CYBERN, P3995, DOI 10.1109/SMC.2016.7844858
   Gavalas D, 2014, J HEURISTICS, V20, P291, DOI 10.1007/s10732-014-9242-5
   Gavalas D, 2011, PERS UBIQUIT COMPUT, V15, P759, DOI 10.1007/s00779-011-0389-x
   Gong SJ, 2009, PROCEEDINGS OF THE 2009 PACIFIC-ASIA CONFERENCE ON CIRCUITS, COMMUNICATIONS AND SYSTEM, P690, DOI 10.1109/PACCS.2009.66
   Gui-Rong Xue, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P114
   Herzog Daniel, 2018, P WORKSH REC TOUR RE, P18
   Hsu FM, 2012, EXPERT SYST APPL, V39, P3257, DOI 10.1016/j.eswa.2011.09.013
   Hsu SH, 2007, LECT NOTES COMPUT SC, V4471, P166
   Hu O-WB, 2013, 14 INT C COMP AID SY, P200
   Huang Y, 2015, IEEE T EMERG TOP COM, V3, P2015
   Huang YX, 2009, EXPERT SYST APPL, V36, P933, DOI 10.1016/j.eswa.2007.10.019
   Jamali M., 2009, P 3 ACM C REC SYST O, P181
   Jannach D, 2010, TOURISM INFORM VISUA, P38
   Kang EY, 2006, LECT NOTES ARTIF INT, V4251, P392
   Kapcak O., 2018, WORKSH REC TOUR LOC, P33
   Katsumi H, 2020, UBICOMP/ISWC '20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P46, DOI 10.1145/3410530.3414421
   Khatibi A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102057
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   Kosmides P, 2014, 2014 INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCES AND IN INDUSTRY (MCSI 2014), P277, DOI 10.1109/MCSI.2014.39
   Kotiloglu S, 2017, TOURISM MANAGE, V62, P76, DOI 10.1016/j.tourman.2017.03.005
   Kurashima T, 2013, KNOWL INF SYST, V37, P37, DOI 10.1007/s10115-012-0580-z
   LAMSFUS C, 2011, P ENTER C AUSTR JAN, P179
   Lamsfus C, 2009, KEOD 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND ONTOLOGY DEVELOPMENT, P424
   LASS C, 2017, P 2 WORKSH REC TOUR, P18
   Lee CS, 2009, EXPERT SYST APPL, V36, P6740, DOI 10.1016/j.eswa.2008.08.016
   Lee H, 2019, INFORM PROCESS MANAG, V56, P1376, DOI 10.1016/j.ipm.2018.01.005
   Lee I, 2013, P ANN HICSS, P3129, DOI 10.1109/HICSS.2013.451
   Leng Y, 2016, P DAT GOOD EXCH D4GX, V2016
   Li L, 2019, INFORM PROCESS MANAG, V56, P1391, DOI 10.1016/j.ipm.2018.03.009
   Li X, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3057283
   Liao JZ, 2018, SCI PROGRAMMING-NETH, V2018, DOI 10.1155/2018/3907804
   Lim, 2016, P 24 C US MOD
   Lim KH., 2016, PROC 26 INT C AUTOMA, P115
   Lim KH, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1778
   Lim KH, 2016, P I C AUTOMAT PLAN S, P412
   Liu GQ, 2014, SCI WORLD J, DOI 10.1155/2014/616030
   Liu Q, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON DIELECTRIC LIQUIDS (ICDL)
   Loh S., 2003, Information Technology and Tourism, V6, P157, DOI 10.3727/1098305031436980
   Lorenzi F., 2011, P 2011 IEEE WIC ACM, P22
   Lorenzi F, 2011, PROC INT C TOOLS ART, P329, DOI 10.1109/ICTAI.2011.56
   Lu Eric Hsueh-Chan, 2011, 2011 12th IEEE International Conference on Mobile Data Management (MDM 2011), P152, DOI 10.1109/MDM.2011.13
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Lu X., 2010, Proceedings of the 18th ACM International Conference on Multimedia, Firenze Italy, 25 October 2010, DOI [19.1145/1873951.1873972, DOI 10.1145/1873951.1873972]
   Lucas JP, 2013, EXPERT SYST APPL, V40, P3532, DOI 10.1016/j.eswa.2012.12.061
   Majid A, 2015, DATA KNOWL ENG, V95, P66, DOI 10.1016/j.datak.2014.11.001
   Ruiz-Martínez JM, 2011, INT J INNOV COMPUT I, V7, P6115
   Santiago FM, 2012, EXPERT SYST APPL, V39, P11737, DOI 10.1016/j.eswa.2012.04.080
   Martinez-Torres MR, 2019, TOURISM MANAGE, V75, P393, DOI 10.1016/j.tourman.2019.06.003
   Maruyama A, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2 (REGULAR PAPERS), PROCEEDINGS, P18
   Meehan K, 2013, INT CONF PERVAS COMP, P328
   Mezni H, 2018, SOFTWARE PRACT EXPER, V48, P2080, DOI 10.1002/spe.2605
   Mobasher B, 2004, LECT NOTES COMPUT SC, V3209, P57, DOI 10.1007/978-3-540-30123-3_4
   Montejo-Ráez A, 2011, EXPERT SYST APPL, V38, P10085, DOI 10.1016/j.eswa.2011.02.005
   Moreno A, 2013, ENG APPL ARTIF INTEL, V26, P633, DOI 10.1016/j.engappai.2012.02.014
   Mottini Alejandro, 2018, RECTOUR RECSYS, P28
   Najafabadi MK, 2019, INFORM PROCESS MANAG, V56, P526, DOI 10.1016/j.ipm.2018.12.007
   O' Sullivan D., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P219, DOI 10.1142/S0218213004001491
   Palumbo E, 2017, P ACM RECSYS WORKSH
   Pan WS, 2013, APPL MATH INFORM SCI, V7, P675, DOI 10.12785/amis/070235
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Pearl J., 1988, PROBABILISTIC REASON
   Peng P, 2019, MULTIMED TOOLS APPL, V78, P24347, DOI 10.1007/s11042-018-6847-y
   Rashid A, 2023, COMPLEX INTELL SYST, V9, P2773, DOI 10.1007/s40747-021-00342-9
   Rathonyi G., 2013, APSTRACT: Applied Studies in Agribusiness and Commerce, P105
   Rawat YS, 2017, IEEE T CIRC SYST VID, V27, P149, DOI 10.1109/TCSVT.2016.2555658
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Ricci F., 2010, TOURISM INFORM VISUA, P73
   Ruotsalo T, 2013, J WEB SEMANT, V20, P50, DOI 10.1016/j.websem.2013.03.001
   Sarkar JL, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115026
   Sarkar JL, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100943
   Savir Amihai, 2013, P 7 ACM C REC SYST, P391, DOI DOI 10.1145/2507157.2507196
   Sebastia L, 2010, ADV INTELL SOFT COMP, V71, P547
   Sebastia L, 2009, INT J ARTIF INTELL T, V18, P717, DOI 10.1142/S0218213009000378
   Seidel I, 2010, TOURISM INFORM VISUA, P209
   Shambour Q, 2011, INT J INTELL SYST, V26, P814, DOI 10.1002/int.20495
   Sieh HP, 2015, IEEE INT C DATA MINI, P1207
   Smyth B, 2000, KNOWL-BASED SYST, V13, P53, DOI 10.1016/S0950-7051(00)00046-0
   Souffriau W, 2008, APPL ARTIF INTELL, V22, P964, DOI 10.1080/08839510802379626
   T-H B., 2016, MULTIMED TOOLS APPL, V76, P22
   Tai CH, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1209
   Tan Y, 2010, LECT NOTES COMPUT SC, V6145, P355
   Linaza MT, 2011, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2011, P1
   Uddin Md Reaz, 2011, 2011 12th IEEE International Conference on Mobile Data Management (MDM 2011), P39, DOI 10.1109/MDM.2011.12
   Umanets A, 2014, PROC TECH, V17, P407, DOI 10.1016/j.protcy.2014.10.248
   Valls A, 2003, AI COMMUN, V16, P129
   Vansteenwegen P., 2007, OR Insight, V20, P21, DOI DOI 10.1057/0RI.2007.17
   Vansteenwegen P, 2011, EXPERT SYST APPL, V38, P6540, DOI 10.1016/j.eswa.2010.11.085
   Vicient C, 2013, ENG APPL ARTIF INTEL, V26, P1092, DOI 10.1016/j.engappai.2012.08.002
   Wang W, 2011, CONCURR COMP-PRACT E, V23, P850, DOI 10.1002/cpe.1676
   Wilson DC, 2003, INT J PATTERN RECOGN, V17, P863, DOI 10.1142/S0218001403002678
   Wu B, 2009, IEEE INT VEH SYM, P1407, DOI 10.1109/IVS.2009.5164491
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P32079, DOI 10.1007/s11042-020-09569-z
   Xu-yin W, 2006, INT C MAN SCI ENG
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Yang WS, 2013, J SYST SOFTWARE, V86, P12, DOI 10.1016/j.jss.2012.06.041
   Yin HZ, 2016, IEEE T KNOWL DATA EN, V28, P2566, DOI 10.1109/TKDE.2016.2580511
   Yin Z, 2011, P 2011 SIAM INT C DA
   Ying HC, 2019, WORLD WIDE WEB, V22, P2209, DOI 10.1007/s11280-018-0596-8
   Yoon H, 2010, LECT NOTES COMPUT SC, V6406, P19, DOI 10.1007/978-3-642-16355-5_5
   Yu FQ, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1264, DOI 10.1145/3366423.3380202
   Yu Y., 2015, WORKSH 29 AAAI C ART, P53
   Yu Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7436948
   Yu ZW, 2016, IEEE T HUM-MACH SYST, V46, P151, DOI 10.1109/THMS.2015.2446953
   Yuan FJ, 2016, PROC INT C TOOLS ART, P46, DOI [10.1109/ICTAI.2016.15, 10.1109/ICTAI.2016.0018]
   Yuan J., 2012, P 18 ACM SIGKDD INT, P186
   Zhang YC, 2007, EPL-EUROPHYS LETT, V80, DOI 10.1209/0295-5075/80/68003
   Zhao KZ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3216
   Zhao SL, 2016, AAAI CONF ARTIF INTE, P315
   Zheng Y, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889683
   Zhou W, 2019, INFORM PROCESS MANAG, V56, P955, DOI 10.1016/j.ipm.2019.02.002
NR 156
TC 14
Z9 14
U1 15
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8983
EP 9027
DI 10.1007/s11042-022-12167-w
EA APR 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000784679300023
DA 2024-07-18
ER

PT J
AU Bhujade, VG
   Sambhe, V
AF Bhujade, Vaishali G.
   Sambhe, Vijay
TI Role of digital, hyper spectral, and SAR images in detection of plant
   disease with deep learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease; Deep learning; Agriculture; Image classification; Neural
   network; Hyperspectral images; SAR images; Segmentation
ID NEURAL-NETWORKS; CLASSIFICATION; IDENTIFICATION
AB In agriculture, plants plays a major role and taking attention of plants is very critical. Generally, the plant are affected through various diseases like fungi, virus and bacteria. Finding of these diseases are main challenging task for a plant disease identification and classification. In the past few years, machine learning (ML) methods have been developed for the plant disease detection. But, the advancement in a subsection of ML, that is, DL (deep learning) models provide a great solution in the agricultural areas in the recent decades. The main objective of the paper is to provide the survey of numerous DL classification models for the plant disease detection by analysing the digital, hyper spectral and SAR images. This paper provide the review of different deep learning architectures which is utilized for plant disease identification and classification. The role of digital, hyper spectral and SAR images with deep learning models for plant disease detection is reviewed. Further, the different well-known DL architecture for plant disease classification is studied. In addition, the current challenges and their solutions of plant disease identification are discussed. Also, the application of DL and advantages/disadvantages of DL structure in plant domain are presented. Finally, the future scope of DL structure for plant domain is discussed. The preparation of this review is to permit future research to learn higher competences of deep learning while identifying plant diseases by enhancing system performance and accuracy.
C1 [Bhujade, Vaishali G.] VJTI, Comp Engn Dept, Mumbai, Maharashtra, India.
   [Sambhe, Vijay] VJTI, Mumbai, Maharashtra, India.
C3 Veermata Jijabai Technological Institute (VJTI); Veermata Jijabai
   Technological Institute (VJTI)
RP Bhujade, VG (corresponding author), VJTI, Comp Engn Dept, Mumbai, Maharashtra, India.
EM vaishali.hardeo@gmail.com; vksambhe@it.vjti.ac.in
CR Abdulridha J, 2020, PRECIS AGRIC, V21, P955, DOI 10.1007/s11119-019-09703-4
   Adeli S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142190
   Lam AN, 2015, IEEE INT CONF AUTOM, P476, DOI 10.1109/ASE.2015.73
   Ananthi VP, 2020, ARTIF INTELL, P137
   [Anonymous], 2017, COMPUT INTEL NEUROSC
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Barbedo JGA, 2017, EUR J PLANT PATHOL, V147, P349, DOI 10.1007/s10658-016-1007-6
   Ashok S, 2020, P 2020 5 INT C COMM, P979, DOI [DOI 10.1109/ICCES48766.2020.9137986, 10.1109/ICCES48766.2020.9137986]
   Baranowski P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122913
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Bastings J., 2017, P 2017 C EMP METH NA, P1957, DOI 10.18653/v1/d17-1209
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Chanda Moumita, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1029, DOI 10.1109/ICOEI.2019.8862552
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen YR, 2002, COMPUT ELECTRON AGR, V36, P173, DOI 10.1016/S0168-1699(02)00100-X
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chowdhary KP, 2020, DETECTION COTTON LEA, V3
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Dai JF, 2016, ADV NEUR IN, V29
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   Dharmaprakash R, 2021, BASED PLANT DIS CLAS
   Dias PA, 2018, COMPUT IND, V99, P17, DOI 10.1016/j.compind.2018.03.010
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gavhale KR, 2014, IOSR journal of computer engineering (iosr-jce), V16, P10, DOI [DOI 10.9790/0661-16151016, 10.9790/0661-16151016]
   Gewali U.B., 2018, Machine learning based hyperspectral image analysis: a survey
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Graeff S, 2006, CENT EUR J BIOL, V1, P275, DOI 10.2478/s11535-006-0020-8
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Ha JG, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042621
   Hamel P., 2010, ISMIR, P339
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hernández S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106597
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Huang Po-Yao, 2016, P 1 C MACH TRANSL, DOI DOI 10.18653/V1/W16-2360
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Jin X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030395
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P818, DOI 10.1007/s00034-019-01041-0
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumain SC, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P243, DOI 10.1109/ICSCCC.2018.8703305
   Kumar S, 2020, SUSTAIN COMPUT-INFOR, V28
   LEI Y, 2020, REMOTE SENS-BASEL, V12
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe A, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0233-z
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mustafa MS, 2020, NEURAL COMPUT APPL, V32, P11419, DOI 10.1007/s00521-019-04634-7
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Nandhini SA, 2018, WIRELESS PERS COMMUN, V102, P725, DOI 10.1007/s11277-017-5092-4
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Petrellis N, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091952
   Pooja V, 2017, 2017 IEEE TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT (TIAR), P130, DOI 10.1109/TIAR.2017.8273700
   Prashanthi V., 2020, Int J Adv Trends Comput Sci Eng, V9, P2632, DOI [10.30534/ijatcse/2020/21932020, DOI 10.30534/IJATCSE/2020/21932020]
   Pujari JD, 2016, INT J INTERACT MULTI, V3, P6, DOI 10.9781/ijimai.2016.371
   Qiang Z., 2019, INT C SMART CIT INF, P118
   [秦立峰 Qin Lifeng], 2020, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P212
   Quan YH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223801
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ramesh Shima, 2018, 2018 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C). Proceedings, P41, DOI 10.1109/ICDI3C.2018.00017
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
   Signoroni A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5050052
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tete TN, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P523, DOI 10.1109/I2CT.2017.8226184
   Thomas S, 2018, J PLANT DIS PROTECT, V125, P5, DOI 10.1007/s41348-017-0124-6
   Thushara BL, 2020, ANAL PLANT DIS USING, V13
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Tran TT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081601
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Vamsidhar E., 2019, International Journal of Engineering and Advanced Technology, V8, P442
   Waghmare Harshal, 2016, 2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN), P513, DOI 10.1109/SPIN.2016.7566749
   Wani MY., 2018, Int J Chem Stud, V2, P1184
   Wu H., 2019, Plant Phenome Journal, Volume, V2, P1, DOI DOI 10.2135/TPPJ2019.03.0006
   Xie C, 2015, SCI REP-UK, V5, DOI 10.1038/srep08914
   Yuan L, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105039
   Zhang N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193188
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhu XL, 2018, COGN SYST RES, V52, P223, DOI 10.1016/j.cogsys.2018.06.008
NR 110
TC 7
Z9 7
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33645
EP 33670
DI 10.1007/s11042-022-13055-z
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200004
DA 2024-07-18
ER

PT J
AU Arora, P
   Mishra, A
   Malhi, A
AF Arora, Priya
   Mishra, Ashutosh
   Malhi, Avleen
TI Machine learning Ensemble for the Parkinson's disease using protein
   sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Gene identification; Physicochemical properties;
   Ensemble method
ID NEURAL-NETWORK; TOPOLOGICAL FEATURES; LOGISTIC-REGRESSION; COMPUTER
   VISION; CLASSIFICATION; PREDICTION; SUPPORT; CANCER; ARCHITECTURE;
   ALZHEIMERS
AB The most challenging issue in diagnosing and treating neurological disorders is gene identification that causes the disease. Classification of the genes that cause or initiate different genes leading to diseases with neurological disorders like Parkinson's disease, is a grave challenge in biomedical research. Detecting neurological disorders has a significant contribution in genetics, which require the deployment of machine learning methods which are still in its infancy. For exploring protein sequences (genes), computational analysis is a vital technique, since a manual comparison of multiple sequences results in impracticality. It helps to find a gene in the sequence and to combine protein sequences into a class of similar sequence. There are many traditional methods available for detection of Parkinson's disease. However, relatively less comparative work is done on Machine Learning techniques using protein sequences for evaluation of Parkinson's disease. This paper demonstrates the comparison of multiple classification methods to identify Parkinson's disease using hydrophobicity and Amino Acid Composition as feature extraction methods. Classification methods are then combined to propose a 2-level ensemble method based on the false prediction rate. The performance of these methods is evaluated using Precision, Recall, F-Score and ROC curves. Experimental results have demonstrated that Random Forest, SVM, Neural Network (PCANNET) and Naive Bayes classifiers individually performed best based on their performance metrics under 5-fold cross validation, whereas the proposed method outperforms Random Forest and SVM by 1.96%, NB by 1.1% and PCANNET by 1.68% respectively. Further, statistical analysis has been added to validate the proposed method.
C1 [Arora, Priya; Mishra, Ashutosh; Malhi, Avleen] Bournemouth Univ, Dept Comp & Informat, Bournemouth, Dorset, England.
C3 Bournemouth University
RP Arora, P (corresponding author), Bournemouth Univ, Dept Comp & Informat, Bournemouth, Dorset, England.
EM priya.arora@thapar.edu; ashutosh.mishra@thapar.edu;
   amalhi@bournemouth.ac.uk
OI Arora, Priya/0000-0002-6191-6448
CR Abu-Nimeh S., 2007, P ANT WORK GROUPS 2, DOI DOI 10.1145/1299015.1299021
   Ala U, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000043
   Avci D, 2016, PARKINSONS DIS-US, V2016, DOI 10.1155/2016/5264743
   Babu GS, 2013, EXPERT SYST APPL, V40, P1519, DOI 10.1016/j.eswa.2012.08.070
   Balaji VR, 2020, MEASUREMENT, V163, DOI 10.1016/j.measurement.2020.107922
   Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045
   Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600
   Carugo O, 2008, PROTEIN SCI, V17, P2187, DOI 10.1110/ps.037762.108
   Chen HL, 2013, EXPERT SYST APPL, V40, P263, DOI 10.1016/j.eswa.2012.07.014
   Chuang CL, 2011, ARTIF INTELL MED, V53, P15, DOI 10.1016/j.artmed.2011.06.002
   Danaee Padideh, 2017, Pac Symp Biocomput, V22, P219, DOI 10.1142/9789813207813_0022
   Das R, 2010, EXPERT SYST APPL, V37, P1568, DOI 10.1016/j.eswa.2009.06.040
   Doran, 2006, 2006 INTELLIGENT MUL
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Freudenberg J, 2002, BIOINFORMATICS, V18, pS110, DOI 10.1093/bioinformatics/18.suppl_2.S110
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Ghiasi MM, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105400
   Gunduz H, 2019, IEEE ACCESS, V7, P115540, DOI 10.1109/ACCESS.2019.2936564
   HANSON DG, 1984, LARYNGOSCOPE, V94, P348
   Hastie T., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, DOI DOI 10.1007/978-0-387-84858-7
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jacob SG, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16), DOI 10.1145/2980258.2980312
   Jowkar GH, 2016, COMPUT BIOL CHEM, V64, P263, DOI 10.1016/j.compbiolchem.2016.07.004
   Kaur H, 2020, NEURAL COMPUT APPL, V32, P12697, DOI 10.1007/s00521-020-04720-1
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Langston JW, 2002, NEUROTOXICOLOGY, V23, P443, DOI 10.1016/S0161-813X(02)00098-0
   Lei CK, 2019, FUEL, V239, P297, DOI 10.1016/j.fuel.2018.11.006
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Miao Y, 2017, COMPUT METH PROG BIO, V150, P107, DOI 10.1016/j.cmpb.2017.08.006
   Mordelet F, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-389
   Nilashi M, 2017, COMPUT CHEM ENG, V106, P212, DOI 10.1016/j.compchemeng.2017.06.011
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Ozcift A, 2012, J MED SYST, V36, P2141, DOI 10.1007/s10916-011-9678-1
   Pereira CR, 2016, COMPUT METH PROG BIO, V136, P79, DOI 10.1016/j.cmpb.2016.08.005
   Pergialiotis V, 2018, PUBLIC HEALTH, V164, P1, DOI 10.1016/j.puhe.2018.07.012
   Perveen S, 2016, PROCEDIA COMPUT SCI, V82, P115, DOI 10.1016/j.procs.2016.04.016
   Prasad R., 2016, J Biosens Bioelectron, V7, P2
   Prashanth R, 2016, INT J MED INFORM, V90, P13, DOI 10.1016/j.ijmedinf.2016.03.001
   Radivojac P, 2008, PROTEINS, V72, P1030, DOI 10.1002/prot.21989
   Rajesh KNVPS, 2018, BIOMED SIGNAL PROCES, V41, P242, DOI 10.1016/j.bspc.2017.12.004
   Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shahid AH, 2020, BIOMED ENG LETT, V10, P227, DOI 10.1007/s13534-020-00156-7
   Shepherd AJ, 2003, PROTEINS, V50, P290, DOI 10.1002/prot.10290
   Simm S, 2016, BIOL RES, V49, DOI 10.1186/s40659-016-0092-5
   Singh VP, 2020, NEURAL COMPUT APPL, V32, P2963, DOI 10.1007/s00521-019-04581-3
   Smalter A, 2007, IEEE INT C BIOINFORM, P209, DOI 10.1109/BIBM.2007.47
   Soumaya Z, 2020, J MED SIGNALS SENS, V10, P60, DOI 10.4103/jmss.JMSS_61_18
   Tan C, 2009, J PHARMACEUT BIOMED, V49, P746, DOI 10.1016/j.jpba.2008.12.010
   Tejeswinee K, 2017, PROCEDIA COMPUT SCI, V115, P188, DOI 10.1016/j.procs.2017.09.125
   Tsangaratos P, 2016, CATENA, V145, P164, DOI 10.1016/j.catena.2016.06.004
   Vasquez-Correa JC, 2020, SPEECH COMMUN, V122, P56, DOI 10.1016/j.specom.2020.07.005
   Vásquez-Correa JC, 2017, INTERSPEECH, P314, DOI 10.21437/Interspeech.2017-1078
   Wang SH, 2017, FUND INFORM, V151, P325, DOI 10.3233/FI-2017-1495
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xu JZ, 2006, BIOINFORMATICS, V22, P2800, DOI 10.1093/bioinformatics/btl467
   Xu L, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00033
   Yang P, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097079
   Yang P, 2012, BIOINFORMATICS, V28, P2640, DOI 10.1093/bioinformatics/bts504
   Yousef A, 2015, J BIOMED INFORM, V56, P300, DOI 10.1016/j.jbi.2015.06.018
   Yousef A, 2013, J THEOR BIOL, V336, P231, DOI 10.1016/j.jtbi.2013.07.001
   Yu CY, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-167
   Zhang, 2011, BMC BIOINFORMATICS, V12, P1, DOI [10.1186/1471-2105-12-S5-S1, DOI 10.1186/1471-2105-12-S5-S1]
   Zhang HB, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3300125
   Zhang HR, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100042
   Zhang YD, 2016, EXPERT SYST, V33, P239, DOI 10.1111/exsy.12146
NR 66
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32215
EP 32242
DI 10.1007/s11042-022-12960-7
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600003
DA 2024-07-18
ER

PT J
AU Rustam, F
   Imtiaz, Z
   Mehmood, A
   Rupapara, V
   Choi, GS
   Din, S
   Ashraf, I
AF Rustam, Furqan
   Imtiaz, Zainab
   Mehmood, Arif
   Rupapara, Vaibhav
   Choi, Gyu Sang
   Din, Sadia
   Ashraf, Imran
TI Automated disease diagnosis and precaution recommender system using
   supervised machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Intelligent systems; Disease prediction; Automated health
   recommender; Machine learning; Disease diagnosis
ID RANDOM FOREST; CLASSIFICATION; FRAMEWORK
AB Similar to many other professions, the medical field has undergone immense automation during the past decade. The complexity and rise of healthcare data led to a surge in artificial intelligence applications. Despite increased automation, such applications lack the desired accuracy and efficiency for healthcare problems. To address the aforementioned issue, this study presents an automatic health care system that can effectively substitute a doctor at an initial stage of diagnosis and help save time by recommending the necessary precautions. The proposed approach comprises two modules where Modul-1 aims at training the machine learning models using the disease symptoms dataset and their corresponding symptoms and precautions. Preprocessing and feature extraction are done as prerequisite steps. In Module-1 several algorithms are applied to the disease dataset such as support vector machine, random forest, extra trees classifier, logistic regression, multinomial naive Bayes, and decision tree. Module-2 interacts with the user (patient) through which the patient can describe the illness symptoms using a microphone. The voice data are transformed into text using the Google speech recognizer. The transformed data is later used with the trained model for disease prediction, as well as, recommending the precautions. The proposed approach achieves an accuracy of 99.9% during the real-time evaluation.
C1 [Rustam, Furqan] Univ Management & Technol, Sch Syst & Technol, Dept Software Engn, Lahore 54770, Pakistan.
   [Imtiaz, Zainab] Khwaja Fareed Univ Engn & IT, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Mehmood, Arif] Islamia Univ Bahawalpur, Dept Comp Sci, Informat Technol, Bahawalpur, Pakistan.
   [Rupapara, Vaibhav] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Choi, Gyu Sang; Din, Sadia; Ashraf, Imran] Yeungnam Univ, Dept Informat Commun Engieering, Gyongsan, South Korea.
C3 University of Management & Technology (UMT); Islamia University of
   Bahawalpur; State University System of Florida; Florida International
   University; Yeungnam University
RP Din, S (corresponding author), Yeungnam Univ, Dept Informat Commun Engieering, Gyongsan, South Korea.
EM furqan.rustam1@gmail.com; Zainabimtiaz29@hotmail.com;
   arifnhmp@gmail.com; Vaibhav.rupapara.sept@gmail.com; castchoi@ynu.ac.kr;
   sadiadin@yu.ac.kr; imranashraf@ynu.ac.kr
RI Ashraf, Imran/T-3635-2019; Rustam, Furqan/ABE-4772-2020
OI Ashraf, Imran/0000-0002-8271-6496; Rustam, Furqan/0000-0001-8403-1047;
   Din, Sadia/0000-0003-0921-4462
CR Al-Nazer A, 2014, PROCEDIA COMPUT SCI, V32, P101, DOI 10.1016/j.procs.2014.05.403
   Ashraf I, 2018, MICROMACHINES-BASEL, V9, DOI 10.3390/mi9100534
   Balog K, 2009, INFORM PROCESS MANAG, V45, P1, DOI 10.1016/j.ipm.2008.06.003
   Banu M. A. N., 2013, INT J TECHNICAL RES, V1, P41
   Bao YJ, 2016, C IND ELECT APPL, P1383, DOI 10.1109/ICIEA.2016.7603801
   Ben Schafer J, 2001, DATA MIN KNOWL DISC, V5, P115, DOI 10.1023/A:1009804230409
   BENEDIKTSSON JA, 1992, IEEE T SYST MAN CYB, V22, P688, DOI 10.1109/21.156582
   Bennett K.P., 2000, SIGKDD EXPLOR NEWSL, V2, P1, DOI [10.1145/380995.380999, DOI 10.1145/380995.380999]
   Bhat S, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2107, DOI 10.1109/ICACCI.2013.6637506
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Bird Steven., 2005, NLTK-Lite: Efficient Scripting for Natural Language Processing
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Davis D., 2008, Predicting individual disease risk based on medical history, P769
   Deng H., 2012, JCDL, P71, DOI DOI 10.1145/2232817.2232833
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Désir C, 2012, IEEE T BIO-MED ENG, V59, P2677, DOI 10.1109/TBME.2012.2204747
   Devlin J., 2018, BERT PRE TRAINING DE
   Feldman K, 2015, J BIOMED INFORM, V57, P377, DOI 10.1016/j.jbi.2015.07.017
   Fox Susannah, 2013, Health Online 2013, P1
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Gomathi K., 2016, INT J SYSTEM SOFTWAR, V4, P2
   Grégoire G, 2015, EAS PUBLICATIONS, V66, P45, DOI 10.1051/eas/1466005
   Guo XT, 2007, INT J INTELL SYST, V22, P401, DOI 10.1002/int.20206
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Khan AH, 2020, SMART INNOV SYST TEC, V169, P1, DOI [10.1007/978-981-15-1616-0_1, 10.1007/s41870-020-00495-9]
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Kuncheva LI, 2003, LECT NOTES COMPUT SC, V2652, P1126
   Lashari Saima Anwar, 2018, MATEC Web of Conferences, V150, DOI 10.1051/matecconf/201815006003
   Lee T, 2006, INT J ELECTRON COMM, V11, P125, DOI 10.2753/JEC1086-4415110206
   Lim Thean Pheng, 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P1193, DOI 10.1109/ITSIM.2010.5561485
   Macdonald C, 2008, KNOWL INF SYST, V16, P259, DOI 10.1007/s10115-007-0105-3
   McCormick T., 2011, HIERARCHICAL MODEL A
   Middleton SE., 2004, ONTOLOGY BASED RECOM, DOI [10.1007/978-3-540-24750-0_24, DOI 10.1007/978-3-540-24750-0_24]
   Osmar R Z., 1999, INTRO DATA MINING
   Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k
   Patil P., 2020, Disease symptom prediction
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Periasamy ARPon., 2015, INT RES J ENG TECHNO, V2, P2395
   Ramalingam V.V., 2018, International Journal of Engineering Technology, V7, P684, DOI [10.14419/ijet.v7i2.8.10557, DOI 10.14419/IJET.V7I2.8.10557]
   Rao A S, 2020, CLIN SIGNIFICANCE ME
   Rustam F, 2020, IEEE ACCESS, V8, P30234, DOI 10.1109/ACCESS.2020.2972632
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Sahoo AK, 2019, COMPUTATION, V7, DOI 10.3390/computation7020025
   Saleh B., 2020, Int. J. Med. Rev., V7, P15
   Schapire RE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1401
   Sharma Mugdha, 2017, INT C NEXT GEN COMP, P199
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Tung HW, 2004, 2004 IEEE INTERNATIONAL CONFERNECE ON E-TECHNOLOGY, E-COMMERE AND E-SERVICE, PROCEEDINGS, P259
   Yu WDD, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3443, DOI 10.1109/BigData.2016.7841006
   Zaïane OR, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P55, DOI 10.1109/CIE.2002.1185862
NR 57
TC 9
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31929
EP 31952
DI 10.1007/s11042-022-12897-x
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000005
DA 2024-07-18
ER

PT J
AU Wang, XT
   Chen, YY
   Yamasaki, T
AF Wang, Xueting
   Chen, Yiyan
   Yamasaki, Toshihiko
TI Spatially adaptive multi-scale contextual attention for image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Spatially adaptive; Contextual attention; Multi-scale
   attention
AB Image inpainting is the task to fill missing regions of an image. Recently, researchers have achieved a great performance by using convolutional neural networks (CNNs) with the conventional patch-matching method. Existing methods compute the attention scores, which are based on the similarity of patches between the known and missing regions. Considering that patches at different spatial positions can convey different levels of detail, we propose a spatially adaptive multi-scale attention score that uses the patches of different scales to compute scores for each pixel at different positions. Through experiments on the Paris Street View and Places datasets, our proposal shows slight improvement compared with some related methods on the quantitative evaluation metrics commonly used in the existing methods. Moreover, we found that these quantitative metrics are not appropriate enough considering the subjective impressions of the generated images. Therefore, we conducted subjective evaluation through user study for comparison, which shows that our proposal has superiority of performance generating much more detailed and subjectively plausible images.
C1 [Wang, Xueting; Chen, Yiyan; Yamasaki, Toshihiko] Univ Tokyo, Dept Informat Commun & Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
   [Wang, Xueting] CyberAgent Inc, AI Lab, Shibuya Ku, Shibuya Scramble Sq 2-24-12, Tokyo, Japan.
C3 University of Tokyo
RP Wang, XT (corresponding author), Univ Tokyo, Dept Informat Commun & Engn, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.; Wang, XT (corresponding author), CyberAgent Inc, AI Lab, Shibuya Ku, Shibuya Scramble Sq 2-24-12, Tokyo, Japan.
EM xt_wang@hal.t.u-tokyo.ac.jp; chenyiyan@hal.t.u-tokyo.ac.jp;
   yamasaki@cvm.t.u-tokyo.ac.jp
RI zhou, you/KBC-3567-2024; chen, yiyan/JEF-0230-2023; wang,
   xueting/JPY-2782-2023
OI Wang, Xueting/0000-0002-1009-1095
FU  [JP19H05590];  [JP19K20289]
FX This work was partially financially supported by the Grants-in-Aid for
   Scientific Research Numbers JP19H05590 and JP19K20289.
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cho K., 2014, ARXIV14061078
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Liao L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3156, DOI 10.1109/ICASSP.2018.8462549
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu Xinkai, 2020, ARXIV200707020
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng L, 2021, MULTIMEDIA SYST, V27, P363, DOI 10.1007/s00530-020-00697-y
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang N, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Wang N, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107448
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 42
TC 4
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31831
EP 31846
DI 10.1007/s11042-022-12489-9
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000019
OA hybrid
DA 2024-07-18
ER

PT J
AU Chootong, C
   Shih, TK
AF Chootong, Chalothon
   Shih, Timothy K.
TI Tech-Talk-Sum: fine-tuning extractive summarization and enhancing BERT
   text contextualization for technological talk videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summary; Spoken summarization; BERT; Technological talk; Attention
   mechanism
AB Automatic summarization is a task to condense the data to a shorter version while preserving key informational components and the meaning of content. In this paper, we introduce Tech-Talk-Sum, which is the combination of BERT (Bidirectional Encoder Representations from Transformers) and the attention mechanism to summarize the technological talk videos. We first introduce the technology talk datasets that were constructed from YouTube including short- and long-talk videos. Second, we explored various sentence representations from BERT's output. Using the top hidden layer to represent sentences is the best choice for our datasets. The outputs from BERT were fed forward to the Bi-LSTM network to build local context vectors. Besides, we built the document encoder layer that leverages BERT and the self-attention mechanism to express the semantics of a video caption and to form the global context vector. Third, the undirected LSTM was added to bridge the local and global sentence's contexts to predict the sentence's salience score. Finally, the video summaries were generated based on the scores. We trained a single unified model on long-talk video datasets. ROUGE was utilized to evaluate our proposed methods. The experimental results demonstrate that our model has generalization ability, and achieves the baselines and state-of-the-art results for both long and short videos.
C1 [Chootong, Chalothon] Kasetsart Univ, Fac Sci Sriracha, Chon Buri, Thailand.
   [Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Kasetsart University; National Central University
RP Chootong, C (corresponding author), Kasetsart Univ, Fac Sci Sriracha, Chon Buri, Thailand.
EM chootong.c@ku.th; timothykshih@gmail.com
OI chootong, chalothon/0000-0001-9448-4576
FU Ministry of Science and Technology of Taiwan
   [MOST105-2923-S-008-001-MY3]
FX The authors would like to thank the Ministry of Science and Technology
   of Taiwan for supporting our research under grant No.
   MOST105-2923-S-008-001-MY3.
CR Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Ashutosh, 2019, ARXIV190408398
   Chen KY, 2015, IEEE-ACM T AUDIO SPE, V23, P1322, DOI 10.1109/TASLP.2015.2432578
   Dode Albi., 2017, IOSR-JCE, V19, P01, DOI DOI 10.9790/0661-1901030107
   Fiori A, 2014, ADV DATA MIN DATABAS, P1, DOI 10.4018/978-1-4666-5019-0
   FU Z, 2019, J PHYS C SERIES, V1168
   Jacob D, 2016, COMPUTER SCI, DOI 10.18653/v1/n19-1423
   Jadhav A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P142
   Kumar Y.J., 2016, Journal of Computer Science, V12, P178
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730
   Liu Yang, 2019, ARXIV190310318
   Liu Yinhan, 2019, ARXIV190711692
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan Shashi, 2018, NAACL HLT, DOI DOI 10.18653/V1/N18-1158
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Tsai CI, 2016, IEEE W SP LANG TECH, P158, DOI 10.1109/SLT.2016.7846259
   Vaswani A, 2017, ADV NEUR IN, V30
   Victor, 2020, ARXIV191001108
   Wang QC, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214701
   Wang YS, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4187
   Wu LJ, 2018, AAAI CONF ARTIF INTE, P5578
   Wu YX, 2018, AAAI CONF ARTIF INTE, P5602
   Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P779
   Zhang Y, 2016, IEEE IND ELEC, P918, DOI 10.1109/IECON.2016.7793761
   Zhenzhong L, 2020, P ICLR 2020 AB ETH
NR 28
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31295
EP 31312
DI 10.1007/s11042-022-12812-4
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336500014
DA 2024-07-18
ER

PT J
AU Haghanifar, A
   Majdabadi, MM
   Choi, Y
   Deivalakshmi, S
   Ko, S
AF Haghanifar, Arman
   Majdabadi, Mahdiyar Molahasani
   Choi, Younhee
   Deivalakshmi, S.
   Ko, Seokbum
TI COVID-CXNet: Detecting COVID-19 in frontal chest X-ray images using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Chest X-ray; Convolutional neural networks; CheXNet; Imaging
   features
AB One of the primary clinical observations for screening the novel coronavirus is capturing a chest x-ray image. In most patients, a chest x-ray contains abnormalities, such as consolidation, resulting from COVID-19 viral pneumonia. In this study, research is conducted on efficiently detecting imaging features of this type of pneumonia using deep convolutional neural networks in a large dataset. It is demonstrated that simple models, alongside the majority of pretrained networks in the literature, focus on irrelevant features for decision-making. In this paper, numerous chest x-ray images from several sources are collected, and one of the largest publicly accessible datasets is prepared. Finally, using the transfer learning paradigm, the well-known CheXNet model is utilized to develop COVID-CXNet. This powerful model is capable of detecting the novel coronavirus pneumonia based on relevant and meaningful features with precise localization. COVID-CXNet is a step towards a fully automated and robust COVID-19 detection system.
C1 [Haghanifar, Arman] Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
   [Majdabadi, Mahdiyar Molahasani; Choi, Younhee; Ko, Seokbum] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
   [Deivalakshmi, S.] Natl Inst Technol, Trichy, India.
C3 University of Saskatchewan; University of Saskatchewan; National
   Institute of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Ko, S (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
EM arman.haghanifar@usask.ca; m.molahasani@usask.ca;
   younhee.choi@irdinc.com; deiva@nitt.edu; seokbum.ko@usask.ca
RI Ko, Seokbum/H-8366-2012; Molahasani Majdabadi, Mahdiyar/AHE-4246-2022
OI Ko, Seokbum/0000-0002-9287-317X; Deivalakshmi, S/0000-0002-7019-9807
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Al-Mujtaba Mohammed, 2019, 2019 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE). Proceedings, DOI 10.1109/ICCCEEE46830.2019.9071305
   [Anonymous], 2017, Learning to diagnose from scratch by exploiting dependencies among labels
   Arriaga-Garcia EF, 2014, INT CONF ELECTR COMM, P28, DOI 10.1109/CONIELECOMP.2014.6808563
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Barstugan M, 2020, ARXIV200309424
   Brueck, 2020, THERE IS ONLY ONE WA
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Castro-Zunti R, 2020, COMPUT MED IMAG GRAP, V82, DOI 10.1016/j.compmedimag.2020.101718
   Cellina M, 2020, RADIOGRAPHY
   Cozzi A, 2020, EUR J RADIOL, V132, DOI 10.1016/j.ejrad.2020.109272
   Dey N, 2020, COGN COMPUT, V12, P1011, DOI 10.1007/s12559-020-09751-3
   Finlayson S. G., 2018, Science
   Furlow Bryant, 2010, Radiol Technol, V81, P437
   Geffen, 2020, COVID 19 CHEST XRAY
   Ghassemi, 2020, ARXIV200611988
   Godasu R, 2020, P 15 ANN C MIDW ASS, V5, P28
   Gomes Juliana C., 2022, Research on Biomedical Engineering, V38, P15, DOI 10.1007/s42600-020-00091-7
   Gozes O, 2020, ARXIV 200305037
   Hassanien A.E., 2020, MEDRXIV, DOI https://doi.org/10.1101/2020.03.30.20047787
   Ittyachen AM, 2017, RESPIR MED CASE REP, V22, P257, DOI 10.1016/j.rmcr.2017.09.009
   Jacobi A, 2020, CLIN IMAG, V64, P35, DOI 10.1016/j.clinimag.2020.04.001
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jassim S, 2020, AI BASED CHEST XRAY
   Jin YH, 2020, MILITARY MED RES, V7, DOI 10.1186/s40779-020-0233-6
   Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527
   Kedia P, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107184
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Kim Hyungjin, 2020, Radiology, V296, pE145, DOI 10.1148/radiol.2020201343
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Mangal A, 2020, 200409803 ARXIV
   Pereira RM, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105532
   Phan LT, 2020, NEW ENGL J MED, V382, P872, DOI 10.1056/NEJMc2001272
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qian LJ, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200033
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ranjan E, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293408
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rio Donald C, 2014, Cold Spring Harb Protoc, V2014, P1207, DOI 10.1101/pdb.prot080887
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Serrano CO, 2020, EUR J RADIOL, V131, DOI 10.1016/j.ejrad.2020.109236
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Stirenko S, 2018, 2018 IEEE 38TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P422, DOI 10.1109/ELNANO.2018.8477564
   Sun LY, 2021, PROC IEEE INT SYMP, DOI 10.1109/ISIE45552.2021.9576293
   Sze-To A, 2019, LECT NOTES COMPUT SC, V11663, P325, DOI 10.1007/978-3-030-27272-2_28
   Tabik S, 2020, IEEE J BIOMED HEALTH, V24, P3595, DOI 10.1109/JBHI.2020.3037127
   Tilve A, 2020, 2020 INT C EMERGING, P1, DOI [10.1109/ic-ETITE47903.2020.152, DOI 10.1109/IC-ETITE47903.2020.152]
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Wang Y, 2020, MULTIDIM SYST SIGN P, V31, P1163, DOI 10.1007/s11045-020-00703-6
   Winther HB, 2020, COVID 19 IMAGE REPOS
   World Health Organization, 2020, Coronavirus disease 2019 (COVID-19) situation report -72
   Zech JR, 2019, ARXIV191203606
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
   Zompatori M, 2014, EUR RESPIR REV, V23, P519, DOI 10.1183/09059180.00001314
NR 60
TC 79
Z9 79
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30615
EP 30645
DI 10.1007/s11042-022-12156-z
EA APR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200002
PM 35431611
OA Green Published, Bronze, Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Chen, J
   Chen, T
   Shen, MQ
   Shi, YH
   Wang, DJ
   Zhang, X
AF Chen, Jia
   Chen, Tao
   Shen, Mengqi
   Shi, Yunhai
   Wang, Dongjing
   Zhang, Xin
TI Gated three-tower transformer for text-driven stock market prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock market prediction; Transformer; Attention mechanism; Feature
   fusion; Text-Driven
ID NEURAL-NETWORKS; PRICES; REPRESENTATIONS
AB Effective stock market prediction can significantly assist individual and institutional investors to make better trading decisions and help government stabilize the market. Therefore, a variety of methods have been proposed to tackle the issue of stock market prediction recently. However, it is still quite challenging to effectively extract the correlations and temporal information from multivariate time series of market data and integrate various kinds of features as well as auxiliary information, which is important for improving the performance of stock market prediction. This paper proposes an entirely Transformer based model, namely Gated Three-Tower Transformer (GT(3)), to incorporate numerical market information and social text information for accurate stock market prediction. Firstly, we devise a Channel-Wise Tower Encoder (CWTE) to capture the channel-wise features from transposed numerical data embeddings. Secondly, we design a Shifted Window Tower Encoder (SWTE) with Multi-Temporal Aggregation to extract and aggregate the multi-scale temporal features from the original numerical data embeddings. Then we adopt the encoder of vanilla Transformer as a Text Tower Encoder (TTE) to obtain the high-level textual features. Furthermore, we design a Cross-Tower Attention mechanism to assist the model to learn the trend-relevant significance of each daily text representation by leveraging the temporal features from SWTE. Finally, we unify CWTE, SWTE, and TTE as the GT(3) model through a self-adaptive gate layer to perform end-to-end text-driven stock market prediction by fusing three types of features effectively and efficiently. Extensive experimental results on a real-world dataset show that the proposed model outperforms state-of-the-art baselines.
C1 [Chen, Jia; Chen, Tao; Shen, Mengqi; Wang, Dongjing; Zhang, Xin] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Shi, Yunhai] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Zhang, X (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM zhangxin@hdu.edu.cn
RI Shen, Mengqi/IQS-6356-2023; zhou, xuan/GZA-8157-2022
OI Shen, Mengqi/0000-0001-8372-7376; 
FU Natural Science Foundation of Zhejiang Province
FX This research is supported by Natural Science Foundation of Zhejiang
   Province under No.LQ21F020015 and No.LQ20F020015.
CR Akita R., 2016, P IEEE ACIS 15 INT C, P1, DOI [DOI 10.1109/ICIS.2016.7550882, 10.1109/ICIS.2016.7550882]
   Arroyo-Fernandez I, 2019, COMPUT SPEECH LANG, V56, P107, DOI 10.1016/j.csl.2019.01.005
   Bagnall A, 2017, DATA MIN KNOWL DISC, V31, P606, DOI 10.1007/s10618-016-0483-9
   Basak S, 2019, N AM J ECON FINANC, V47, P552, DOI 10.1016/j.najef.2018.06.013
   Bhalla V.K., 2008, Investment Management: Security Analysis and Portfolio Management
   Bollen J., 2011, Computer, V44, P91, DOI 10.1109/MC.2011.323
   BUTLER KC, 1992, J BANK FINANC, V16, P197, DOI 10.1016/0378-4266(92)90085-E
   Dami S, 2021, MULTIMED TOOLS APPL, V80, P19947, DOI 10.1007/s11042-021-10778-3
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327
   Franses PH, 1999, INT J FORECASTING, V15, P1, DOI 10.1016/S0169-2070(98)00053-3
   Gallagher LA, 2002, SOUTH ECON J, V69, P345, DOI 10.2307/1061676
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gervais S, 2001, J FINANC, V56, P877, DOI 10.1111/0022-1082.00349
   Geurts P., 2001, European Conference on Principles of Data Mining and Knowledge Discovery, P115, DOI [10.1007/3-540-44794-610, DOI 10.1007/3-540-44794-610, DOI 10.1007/3-540-44794-6_10]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gunduz H, 2017, KNOWL-BASED SYST, V137, P138, DOI 10.1016/j.knosys.2017.09.023
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsieh TY, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P607, DOI 10.1145/3437963.3441815
   Hu Y, 2015, EXPERT SYST APPL, V42, P212, DOI 10.1016/j.eswa.2014.07.059
   Jin XB, 2021, ENERGIES, V14, DOI 10.3390/en14061596
   Kara Y, 2011, EXPERT SYST APPL, V38, P5311, DOI 10.1016/j.eswa.2010.10.027
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Kavussanos MG., 2001, APPL FINAN EC, V11, P573, DOI DOI 10.1080/09603100010013006
   Kim T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212320
   Li SY, 2019, ADV NEUR IN, V32
   Lines J, 2015, DATA MIN KNOWL DISC, V29, P565, DOI 10.1007/s10618-014-0361-2
   Liu Jintao, 2019, P 1 WORKSHOP FINANCI
   Liu Minghao, 2021, ARXIV210314438
   Ni HH, 2021, WORLD WIDE WEB, V24, P849, DOI 10.1007/s11280-021-00880-9
   Oguiza I., 2020, TSAI STATE OF THE AR
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Rotman M, 2021, AAAI CONF ARTIF INTE, V35, P9428
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sarantis N, 2001, INT J FORECASTING, V17, P459, DOI 10.1016/S0169-2070(01)00093-0
   Serra J., 2018, CCIA, P120, DOI 10.3233/978-1-61499-918-8-120
   Sharaf M, 2021, MULTIMED TOOLS APPL, V80, P17923, DOI 10.1007/s11042-021-10579-8
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Sutskever I, 2014, ADV NEUR IN, V27
   Thakkar A, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114800
   Tong Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P118, DOI 10.1109/ICMLA.2019.00027
   Torres JF, 2021, BIG DATA-US, V9, P3, DOI 10.1089/big.2020.0159
   Vaswani A, 2017, ADV NEUR IN, V30
   VIRTANEN I, 1987, OMEGA-INT J MANAGE S, V15, P145, DOI 10.1016/0305-0483(87)90029-6
   Wang Z., 2017, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2017.7966039
   Wu HZ, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1627, DOI 10.1145/3269206.3269290
   Yong B.X., 2017, MODELING DESIGN SIMU, P356, DOI DOI 10.1007/978-981-10-6463-031
   Yusen L, 2021, PREDICTING BEHAV DEA
   Zhang LH, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2141, DOI 10.1145/3097983.3098117
   Zhou F, 2019, EXPERT SYST APPL, V115, P136, DOI 10.1016/j.eswa.2018.07.065
NR 52
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30093
EP 30119
DI 10.1007/s11042-022-11908-1
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500001
DA 2024-07-18
ER

PT J
AU Farooq, U
   Shereen, M
   Zia, K
   Rabbi, I
AF Farooq, Umar
   Shereen, Muneeba
   Zia, Kashif
   Rabbi, Ihsan
TI Reducing the impact of players' transfer in managing scalable virtual
   worlds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual worlds; Scalability; OpenSimulator; Teleport; Multi-core
   architectures
AB Virtual worlds are both computation and communication intensive as they provide rich content and frequent updates to players for an improved performance. Virtual worlds use spatial partitioning to scale and dynamic scalability frameworks are the preferred choice for an improved resource utilisation. However, they are very costly in terms of time, as the re-allocation process involves transferring both content and players. Similarly, for an improved interactive experience, users are sent to transit region during a transfer. However, it adds a huge amount of time when an increasing number of users are transferred in sequence. This paper introduces the methods used for players' movement in OpenSimulator framework with an emphasis on teleport mechanism. It investigates the impact of sequential transfer of increasing number of players on content transfer during the re-allocation process before developing a parallel alternative. The proposed method utilises multi-core processors to transfer players, using the teleport method, in a re-locating region, which is compared with the sequential method adopted earlier for implementing scalability in OpenSimulator. Two different implementations of the parallel algorithm one using, parallel for, and the other utilising, chunk partitioning, are used for comparison with the sequential approach. It is demonstrated that both the parallel implementations improved over the sequential approach in terms of time. Chunk partitioning, however, obtained the best result for the current configurations. Overall, huge reductions in time were observed in the re-allocation process using the improved mechanisms. However, additional and dedicated resources are expected to further improve the timings required for players' transfer and re-allocation process.
C1 [Farooq, Umar; Shereen, Muneeba; Rabbi, Ihsan] Univ Sci & Technol Bannu, Dept Comp Sci, Bannu, Khyber Pakhtunk, Pakistan.
   [Zia, Kashif] Sohar Univ, Fac Comp & Informat Technol, Sohar, Oman.
C3 University of Science & Technology Bannu; Sohar University
RP Rabbi, I (corresponding author), Univ Sci & Technol Bannu, Dept Comp Sci, Bannu, Khyber Pakhtunk, Pakistan.
EM umar214@gmail.com; muneebashereen@yahoo.com; kzia@su.edu.om;
   ihsan.rabbi@ustb.edu.pk
RI Rabbi, Ihsan/F-3121-2013
OI Rabbi, Ihsan/0000-0003-1699-6300
CR Abdulazeez SA, 2018, INT C E LEARN GAM, P177
   Alahuhta P., 2014, Journal for Virtual Worlds Research, V7
   [Anonymous], 2010, 1004 PORTL STAT U DE
   [Anonymous], 2010, CISC VIS NETW IND GL
   [Anonymous], 2013, SHOULD YOU HOST AMAZ
   [Anonymous], 2011, ICCNIT 11
   Balan RK, 2005, LECT NOTES COMPUT SC, V3790, P390
   Behnke L, 2020, THESIS U W SCOTLAND
   Chan Luther., 2007, NETGAMES 07, P37, DOI [10.1145/1326257.1326264, DOI 10.1145/1326257.1326264]
   Dai Z., 2021, Designing, deploying, and evaluating virtual and augmented reality in education, P143, DOI DOI 10.4018/978-1-7998-5043-4.CH007
   Elfizar, 2019, International Conference on Data Engineering 2015 (DaEng-2015). Proceedings: Lecture Notes in Electrical Engineering (LNEE 520), P21, DOI 10.1007/978-981-13-1799-6_3
   Elfizar, 2019, International Conference on Data Engineering 2015 (DaEng-2015). Proceedings: Lecture Notes in Electrical Engineering (LNEE 520), P11, DOI 10.1007/978-981-13-1799-6_2
   Farlow S M, 2018, THESIS LOUISIANA STA
   Farooq U, 2017, INFORMATICA, V42
   Farooq U, 2018, ICFNDS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON FUTURE NETWORKS AND DISTRIBUTED SYSTEMS, DOI 10.1145/3231053.3231056
   Farooq U, 2017, VIRTUAL REAL-LONDON, V21, P193, DOI 10.1007/s10055-017-0307-2
   Farooq U, 2017, SIMUL MODEL PRACT TH, V72, P118, DOI 10.1016/j.simpat.2016.12.010
   Gonzalez J, 2021, ARXIV PREPRINT ARXIV
   Hakonen M., 2014, Journal of Virtual Worlds Research, V7
   Harris David., 2013, Digital Design and Computer Architecture
   Hillar G., 2010, PROFESSIONAL PARALLE
   Keller J, 2017, ANN WORK NETW, P46
   Kim Jinhwan, 2020, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V20, P73, DOI 10.7236/JIIBC.2020.20.3.73
   Lake D, 2010, ANN WORK NETW
   Linden Lab Inc., 2 LIFE OFFICIAL WEBS
   Malaby ThomasM., 2009, Making Virtual Worlds: Linden Lab and Second Life
   osgrid.org Inc, OSGRID OP SOURC MET
   Petrovic VM, 2018, IEEE ACCESS, V6, P39976, DOI 10.1109/ACCESS.2018.2855970
   Prasetya K., 2008, Proc. 7th ACM SIGCOMM Workshop on Network and System Support for Games (NetGames '08), P72
   Prendinger H, 2018, VIRTUAL REAL-LONDON, V22, P263, DOI 10.1007/s10055-017-0322-3
   Ringler R, 2014, C MULTITHREADED PARA
   Spieldenner T, 2018, VISUAL COMPUT, V34, P1269, DOI 10.1007/s00371-018-1564-0
   Wang TQ, 2006, J SUPERCOMPUT, V36, P249, DOI 10.1007/s11227-006-8296-z
   Yilmaz L, 2014, WINT SIMUL C PROC, P2797, DOI 10.1109/WSC.2014.7020122
   Yoginath SB, 2015, ACM T MODEL COMPUT S, V26, DOI 10.1145/2746232
   Yunjo An, 2019, Foundations and Trends in Smart Learning. Proceedings of 2019 International Conference on Smart Learning Environments. Lecture Notes in Educational Technology (LNET), P89, DOI 10.1007/978-981-13-6908-7_12
NR 36
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29423
EP 29442
DI 10.1007/s11042-022-12505-y
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700010
DA 2024-07-18
ER

PT J
AU Ullah, A
   Chakir, A
AF Ullah, Arif
   Chakir, Aziza
TI Improvement for tasks allocation system in VM for cloud datacenter using
   modified bat algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Virtual machine; Task allocation; Datacenter
AB Since its inception, cloud computing has greatly transformed our lives by connecting the entire world through shared computational resources over the internet. The COVID-19 pandemic has also disrupted the traditional learning and businesses and led us towards an era of cloud-based activities. Virtual machine is one of the main elements of virtualization in cloud computing that represents physical server into the virtual machine. The utilizations of these VM's are important to achieved effective task scheduling mechanism in cloud environment. This paper focuses on improvment of the task distribution system in VM for cloud computing using load balancing technique. For that reason modification took place at Bat algorithm fitness function value this section used in load balancer section. When algorithm iteration are complete then time to distribute the task among different VM therefore in this section of algorithm was modified. The second modification took place at the search process of Bat at dimension section. The proposed algorithm is known as modified Bat algorithm. Four parameter are used to check the performance of the system which are throughput, makespan, degree of imbalance and processing time. The proposed algorithm provides efficient result as compaire to other standard technique. Hence the proposed algorithm improved cloud data center accuracy and efficiency.
C1 [Ullah, Arif] Riphah Int Univ, Dept Comp, Faisalabad 44000, Punjab, Pakistan.
   [Chakir, Aziza] Hassan II Univ, Fac Law Econ & Social Sci, Casablanca, Morocco.
C3 Hassan II University of Casablanca
RP Ullah, A (corresponding author), Riphah Int Univ, Dept Comp, Faisalabad 44000, Punjab, Pakistan.
EM Arifullahms88@gmail.com; aziza1chakir@gmail.com
RI ULLAH, ARIF/C-3845-2019
OI ULLAH, ARIF/0000-0002-7740-2206
CR Adhikari M, 2019, J NETW COMPUT APPL, V128, P64, DOI 10.1016/j.jnca.2018.12.010
   Afzal S, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0146-7
   Ahdhullah SS, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2428
   Alam T, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03663-2
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Cai XJ, 2016, INT J BIO-INSPIR COM, V8, P205, DOI 10.1504/IJBIC.2016.078666
   Chaudhury KS., 2021, TURK J COMPUT MATH E, V12, P3885, DOI [10.1109/CESYS.2016.7889943, DOI 10.1109/CESYS.2016.7889943]
   Cheng TCE, 2001, IIE TRANS, V33, P413, DOI 10.1080/07408170108936839
   Cho KM, 2015, NEURAL COMPUT APPL, V26, P1297, DOI 10.1007/s00521-014-1804-9
   Cui YF, 2019, CLUSTER COMPUT, V22, P11005, DOI 10.1007/s10586-017-1285-6
   Dong S, 2020, CLUSTER COMPUT, V23, P1125, DOI 10.1007/s10586-019-02982-6
   Huang HC, 2016, IEEE T IND INFORM, V12, P972, DOI 10.1109/TII.2016.2542206
   Jian CF, 2019, IEEE ACCESS, V7, P58602, DOI 10.1109/ACCESS.2019.2914261
   Kaur Amanpreet, 2019, International Journal of Information Technology, V11, P119, DOI 10.1007/s41870-018-0231-z
   Kaur T, 2019, MULTIMED TOOLS APPL, V78, P21853, DOI 10.1007/s11042-019-7498-3
   Kavousi-Fard A, 2016, IEEE T SMART GRID, V7, P740, DOI 10.1109/TSG.2015.2434844
   Khooban MH, 2015, INT J ELEC POWER, V71, P254, DOI 10.1016/j.ijepes.2015.03.017
   Kintsakis AM, 2017, SOFTWAREX, V6, P217, DOI 10.1016/j.softx.2017.07.007
   Lin WW, 2019, J GRID COMPUT, V17, P699, DOI 10.1007/s10723-019-09499-7
   Meijer C, 2020, SOFTWAREX, V12, DOI 10.1016/j.softx.2020.100626
   Mishra SK, 2020, J KING SAUD UNIV-COM, V32, P149, DOI 10.1016/j.jksuci.2018.01.003
   Mondal B, 2012, PROC TECH, V4, P783, DOI 10.1016/j.protcy.2012.05.128
   Negi S, 2021, J SUPERCOMPUT, V77, P8787, DOI 10.1007/s11227-020-03601-7
   Ouhame S, 2021, NEURAL COMPUT APPL, V33, P10043, DOI 10.1007/s00521-021-05770-9
   Ouhame S, 2020, INT J ONLINE BIOMED, V16, P4, DOI 10.3991/ijoe.v16i14.16623
   Pérez J, 2017, STUD COMPUT INTELL, V667, P343, DOI 10.1007/978-3-319-47054-2_23
   Perez J, 2015, IEEE C EVOL COMPUTAT, P464, DOI 10.1109/CEC.2015.7256926
   Powers C, 2021, SOFTWAREX, V14, DOI 10.1016/j.softx.2021.100696
   Priya V, 2019, APPL SOFT COMPUT, V76, P416, DOI 10.1016/j.asoc.2018.12.021
   Sharma S., 2016, Ind. J. Sci. Technol, V9, P1
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Tripathi D, 2020, MULTIMED TOOLS APPL, V79, P31889, DOI 10.1007/s11042-020-09538-6
   Ullah Arif, 2020, International Journal of High Performance Computing and Networking, V16, P43, DOI 10.1504/IJHPCN.2020.110258
   Ullah A., 2019, IAES INT J ARTIF INT, V8, P156, DOI DOI 10.11591/IJAI.V8.I2.PP156-167
   Ullah A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03496-z
   Ullah A, 2020, INT J MODEL SIMUL SC, V11, DOI 10.1142/S1793962320500415
   Xu MX, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4123
   Yue SH, 2021, MULTIMED TOOLS APPL, V80, P3863, DOI 10.1007/s11042-020-09876-5
   Yue XF, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106157
NR 39
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29443
EP 29457
DI 10.1007/s11042-022-12904-1
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777642100001
PM 35401026
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Roy, M
   Thounaojam, DM
   Pal, S
AF Roy, Moumita
   Thounaojam, Dalton Meitei
   Pal, Shyamosree
TI Perceptual hashing scheme using KAZE feature descriptors for
   combinatorial manipulations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual image hashing; KAZE features; Key point descriptor;
   Manipulations
ID RING PARTITION; IMAGE
AB Perceptual image hashing methods utilize the visual phenomenon of the images and produce a fixed-length hash function and this hash value can be utilized for digital signature of an image. It can be used to show robustness against the digital manipulations done on the image and hence can be of use in different applications, viz., image indexing, tamper detection, etc. But to generate an efficient hash function is scarce as there is an inverse relationship of perceptual robustness and discrimination capability criteria. In this paper, we propose a robust and discrimination capable hash function by considering KAZE point feature descriptor for combinatorial manipulations. The KAZE detectors are used to find the stable key points of the image and then the three strongest regions are considered based on the strongest three key points of the image. Using these points, the features are generated and finally, the local features are used to generate the hash function and this hash function not only provides a good discrimination capable value with good robustness but also shows good results for double attacks and multiple combinations of attacks. Moreover, it outperforms the state-of-the-art algorithms in consideration for performances between discrimination capability and perceptual robustness.
C1 [Roy, Moumita; Thounaojam, Dalton Meitei; Pal, Shyamosree] Natl Inst Technol Silchar, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Roy, M (corresponding author), Natl Inst Technol Silchar, Silchar, Assam, India.
EM moumita0101@gmail.com; dalton@cse.nits.ac.in; spal@cse.nits.ac.in
RI Roy, Moumita/AEV-6631-2022; thounaojam, Dalton/AAN-8432-2020
OI Roy, Moumita/0000-0001-6835-5471; Thounaojam, Dalton/0000-0002-2655-3821
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2010, IMPLEMENTATION BENCH
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Du L, 2021, MULTIMED TOOLS APPL, V80, P22927, DOI 10.1007/s11042-020-08736-6
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Gharde ND, 2018, MULTIMED TOOLS APPL, V77, P30815, DOI 10.1007/s11042-018-6115-1
   Hamid H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106648
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassan E, 2012, IEEE T MULTIMEDIA, V14, P1179, DOI 10.1109/TMM.2012.2190388
   Hernandez R., 2011, Proceedings of 2011 IEEE 54th International Midwest Symposium on Circuits and Systems (MWSCAS '11), P1
   Hong WX, 2020, IEEE WINT CONF APPL, P2520, DOI [10.1109/WACV45572.2020.9093487, 10.1109/wacv45572.2020.9093487]
   Huang Z, 2020, IEEE T MULTIMEDIA
   Jie Z, 2013, ARXIV13064079
   Karsh RK, 2018, MULTIMED TOOLS APPL, V77, P25409, DOI 10.1007/s11042-018-5799-6
   Khelaifi F, 2020, MULTIMED TOOLS APPL, V79, P19025, DOI 10.1007/s11042-020-08619-w
   Lefebvre F., 2002, Signal Processing Conference, 2002 11th European, P1
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Neelima A, 2016, COMPUT J, V59, P1275, DOI 10.1093/comjnl/bxv079
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Patil V. H., 2019, Journal Computing, V14, P210
   Qin C, 2019, IEEE ACCESS, V7, P45460, DOI 10.1109/ACCESS.2019.2908029
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Sajjad M, 2019, IEEE T IND INFORM, V15, P6541, DOI 10.1109/TII.2019.2921652
   Singh KM, 2019, CURR SCI INDIA, V117, P1340, DOI 10.18520/cs/v117/i8/1340-1344
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Tang ZJ, 2013, IMAGING SCI J, V61, P241, DOI 10.1179/1743131X11Y.0000000039
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2013, AEU-INT J ELECTRON C, V67, P717, DOI 10.1016/j.aeue.2013.02.009
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Wang XF, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115642
   Weber AG., 2018, USC-SIPI Report, V432, P1
   Weng L, 2009, IEEE INT CON MULTI, P1074, DOI 10.1109/ICME.2009.5202684
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Xue MF, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/9795621
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   Zhao Y, 2020, IEEE ACCESS, V8, P26041, DOI 10.1109/ACCESS.2020.2970757
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 42
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29045
EP 29073
DI 10.1007/s11042-022-12626-4
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375700002
DA 2024-07-18
ER

PT J
AU Rohith, G
   Kumar, LS
AF Rohith, G.
   Kumar, Lakshmi Sutha
TI Design of Deep Convolution Neural Networks for categorical signature
   classification of raw panchromatic satellite images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Remote sensing signature classification;
   Adam optimizer; Panchromatic images
ID SCENE CLASSIFICATION; SCALE; FEATURES
AB Remote Sensing categorical signature classification has gained significant implications on spatial resolution image analysis due to differences in the sensors' spatial response and surface variations. As a consequence, the grey level co-occurrence of probability texture features for the classification task is crucial. Traditionally, deep learning-based Convolution Neural Network (CNN) classifiers for spectral/spatially scaled signatures (Hyperspectral or Multispectral images) extract deep features and accurately classify remote sensing scenes into appropriate labels/categories. While dealing with raw panchromatic images, the spatial with varied angular signatures will have untrained grey scale patterns, translational and rotational variations. It is still a bottleneck to label and classify data using pre-trained models from two separate sources based on its spatial structural characteristics. In this paper, a thirteen-layer deep CNN model is designed for categorical signature classification of the raw panchromatic satellite dataset. The design is carried out in three stages- Firstly, the method extracts the global content and meanings of remote sensing images at the scene level. Then, it cross compares with training and testing of identified complex remote sensing signatures in raw inter dataset images with large inter and intra-class variations. Finally, the validation of the 70:30 training-testing set is done to classify a batch of images into the respective labeled signatures (Land and sea) with an accuracy of 88.9%. The modified versions of five state-of-the-art pre-trained classifiers are tested to check the efficacy of the proposed approach.
C1 [Rohith, G.; Kumar, Lakshmi Sutha] Natl Inst Technol, Dept Elect & Commun Engn, Pondicherry, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry
RP Rohith, G (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Pondicherry, India.
EM rohith.giridharan@gmail.com
RI Rohith, Gorrepati/ABH-7282-2020; Kumar, Lakshmi Sutha/P-9990-2019
OI Rohith, Gorrepati/0000-0003-1081-027X; Kumar, Lakshmi
   Sutha/0000-0002-9069-3132
CR Bhosle K, 2019, J INDIAN SOC REMOTE, V47, P1949, DOI 10.1007/s12524-019-01041-2
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Chen GZ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050719
   Chen ST, 2021, MULTIMED TOOLS APPL, V80, P1859, DOI 10.1007/s11042-020-09480-7
   Chen YY, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5090154
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding L., 2018, Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci, V42, P277, DOI [10.5194/isprs-archives-XLII-3-277-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-3-277-2018]
   Djerriri K, 2018, INT GEOSCI REMOTE SE, P2479, DOI 10.1109/IGARSS.2018.8518501
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Garzonio R, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050472
   Ghazouani F, 2018, ONTOLOGY INFORM SCI, DOI [10.5772/intechopen.72730, DOI 10.5772/INTECHOPEN.72730]
   Gu YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102110
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua YS, 2021, ISPRS J PHOTOGRAMM, V177, P89, DOI 10.1016/j.isprsjprs.2021.04.006
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hung SC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186151
   Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li HF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061594
   Li T, 2019, MULTIMED TOOLS APPL, V78, P3411, DOI 10.1007/s11042-018-5986-5
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Lin LL, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01666-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Merugu S, 2021, J INDIAN SOC REMOTE, V49, P703, DOI 10.1007/s12524-020-01265-7
   Mhangara P, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051881
   Minetto R, 2019, IEEE T GEOSCI REMOTE, V57, P6530, DOI 10.1109/TGRS.2019.2906883
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Paul A, 2021, NEURAL COMPUT APPL, V33, P1575, DOI 10.1007/s00521-020-05069-1
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rohith G, 2021, MULTIMED TOOLS APPL, V80, P25033, DOI 10.1007/s11042-021-10861-9
   Rohith G., 2020, INT C MACH LEARN IM, P343, DOI [10.1007/978-981-15-6315-728, DOI 10.1007/978-981-15-6315-728]
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J, 2019, BIG EARTH DATA, V3, P232, DOI 10.1080/20964471.2019.1657720
   Su TF, 2019, MULTIMED TOOLS APPL, V78, P34173, DOI 10.1007/s11042-019-08224-6
   Sumbul G, 2019, INT GEOSCI REMOTE SE, P5901, DOI [10.1109/IGARSS.2019.8900532, 10.1109/igarss.2019.8900532]
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Unnikrishnan A, 2019, MULTIMED TOOLS APPL, V78, P18379, DOI 10.1007/s11042-019-7179-2
   Wang GL, 2017, IEEE J-STARS, V10, P4104, DOI 10.1109/JSTARS.2017.2705419
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhao B, 2016, IEEE T GEOSCI REMOTE, V54, P2108, DOI 10.1109/TGRS.2015.2496185
   Zhao LJ, 2019, MULTIMED TOOLS APPL, V78, P9667, DOI 10.1007/s11042-018-6548-6
   Zhao LJ, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.035004
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 63
TC 3
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28367
EP 28404
DI 10.1007/s11042-022-12928-7
EA MAR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644000003
DA 2024-07-18
ER

PT J
AU Xiang, C
   Su, ML
   Zhang, CY
   Wang, F
   Yang, MC
   Niu, ZD
AF Xiang, Chao
   Su, Minglan
   Zhang, Chaoying
   Wang, Feng
   Yang, Mingchuan
   Niu, Zhendong
TI E-CapsGan: Generative adversarial network using capsule network as
   feature encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-CapsGan; Feature encoder; Image generation; Image compression encoding
AB We explore using the theory of Capsule Network(CapsNet) in Generative Adversarial Network(GAN). The traditional Convolutional Neural Networks(CNNs) cannot explain the spatial relationship between the part and whole, so it will lose some of the target's attribute information such as direction and posture. Capsule Network, proposed by Hinton in 2017, overcomes the defect of CNNs. In order to utilize the attributes of the target as much as possible, we propose the E-CapsGan which applies the CapsNet to encode the input image attribute features and guide the data generation of GAN. We explore the application of the E-CapsGan in two scenarios. For image generation, we propose the E-CapsGan1, which uses the CapsNet as an additional attribute feature encoder to obtain image attribute features to guide GAN. For image compression encoding, we explore the E-CapsGan2 which employs the CapsNet as the encoder to compress images into vectors, and GAN as the decoder to reconstruct the original images from vectors. On multiple datasets, qualitative and quantitative experiments are used to demonstrate the superior performance of E-CapsGan1 in image generation and the feasibility of E-CapsGan2 in image compression encoding.
C1 [Xiang, Chao; Niu, Zhendong] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Xiang, Chao; Su, Minglan; Zhang, Chaoying; Wang, Feng; Yang, Mingchuan] Res Institue China Telecom Corp Ltd, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Niu, ZD (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
EM zniu@bit.edu.cn
RI niu, zhendong/KIJ-1559-2024
FU National Key R&D Program of China [2019YFB1406302]; National Natural
   Science Foundation of China [61370137, 61902016]; Ministry of
   Education-China Mobile Research Foundation Project [2016/2-7]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2019YFB1406302, National Natural Science Foundation of China
   under Grant 61370137, 61902016, the Ministry of Education-China Mobile
   Research Foundation Project under Grant 2016/2-7.
CR AlBahar B, 2019, IEEE I CONF COMP VIS, P9015, DOI 10.1109/ICCV.2019.00911
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Chang SW, 2020, IEEE ACCESS, V8, P79876, DOI 10.1109/ACCESS.2020.2990700
   Chen Z, 2018, ARXIV180808692
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu J, IEEE CVF C COMP VIS
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jaiswal A., 2018, P EUR C COMP VIS ECC
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kinli F, 2019, IEEE INT CONF COMP V, P3109, DOI 10.1109/ICCVW.2019.00376
   Kurach K, 2019, PR MACH LEARN RES, V97
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CC, 2018, IEEE IMAGE PROC, P2132, DOI 10.1109/ICIP.2018.8451161
   Liu HD, 2019, IEEE I CONF COMP VIS, P4831, DOI 10.1109/ICCV.2019.00493
   Ma TY, 2018, ACM S THEORY COMPUT, P2, DOI 10.1145/3188745.3232194
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marusaki K, 2020, ARXIV200308047
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Nguyen Huy H, 2019, Use of a capsule network to detect fake images and videos
   PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1109/CVPR.2012.6248092, 10.1109/CVPR.2012.6248092]
   Radford A., 2015, ARXIV
   Rawlinson D, 2018, ARXIV180406094
   Sabour S, 2017, ADV NEUR IN, V30
   Shi HJ, 2018, INT C PATT RECOG, P73, DOI 10.1109/ICPR.2018.8545894
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang D, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23142
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xiao H., 2017, ARXIV170807747
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zhang BW, 2018, IEEE ACCESS, V6, P58284, DOI 10.1109/ACCESS.2018.2874623
   Zhao W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3110
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 36
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26425
EP 26442
DI 10.1007/s11042-022-12279-3
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464800004
DA 2024-07-18
ER

PT J
AU Dhanjal, AS
   Singh, W
AF Dhanjal, Amandeep Singh
   Singh, Williamjeet
TI An optimized machine translation technique for multi-lingual speech to
   sign language notation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech to sign language; Direct translation; Machine learning; HamNoSys
ID SYSTEM; RECOGNITION; BANGLA; TEXT
AB Due to the lack of assistive resources, hard-of-hearing people cannot live independently. Sign language or gesture language is the natural language and it is the primary mode of communication for hard-of-hearing people. Researchers and IT companies are continuously trying to find the best solutions to minimize the communication barriers for hearing-impaired people. Existing translation techniques for speech to sign language on the web platform are consuming higher resources. This study presents an optimized technique for direct machine translation of multi-lingual speech to Indian sign language using the HamNoSys notation system, whereas existing techniques were translating speech-text-HamNoSys. Performance comparison of both existing and the proposed techniques is analyzed in this study. The proposed technique optimizes the resources for the following parameters: CPU, heap memory, primary memory, and classes load. The result shows that the existing technique takes 220 MB heap memory, 10 threads, 2236 classes, and CPU for 12 s. The proposed technique consumes only 210.4 MB, 9 threads, 2113 classes, and CPU for 9 s.
C1 [Dhanjal, Amandeep Singh] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   [Singh, Williamjeet] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Punjabi University; Punjabi University
RP Dhanjal, AS (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
EM aman.dhanjal134@live.com; williamjeet@gmail.com
OI Singh, Amandeep/0000-0002-7763-9174
FU Department of Science and Technology, under the Scheme for Young
   Scientists & Technologists (SYST), by the Government of India
   [SP/YO/382/2018(G)]
FX This is supported by the Department of Science and Technology, under the
   Scheme for Young Scientists & Technologists (SYST), by the Government of
   India [SP/YO/382/2018(G)].
CR Abushariah M. A. M., 2010, Computer and Communication Engineering (ICCCE), 2010 International Conference on, P1
   Almasoud A.M., 2012, Journal of Software Engineering and Applications, V5, P604, DOI DOI 10.4236/JSEA.2012.58069
   [Anonymous], 2004, LREC
   Anuja K., 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P1382, DOI 10.1109/NABIC.2009.5393721
   Bouzid Y, 2014, IEEE INT CONF ADV LE, P601, DOI 10.1109/ICALT.2014.176
   Bouzid Y, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND SOFTWARE APPLICATIONS (ICEESA), P215
   Bouzid Y, 2013, IEEE INT CONF ADV LE, P92, DOI 10.1109/ICALT.2013.31
   Brour M, 2019, PROCEDIA COMPUT SCI, V148, P236, DOI 10.1016/j.procs.2019.01.066
   Buttussi F, 2007, WEB3D 2007 - 12TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, PROCEEDINGS, P61
   Cox S., 2002, ASSETS 2002. Proceedings of the Fifth International ACM SIGCAPH Conference on Assistive Technologies, P205, DOI 10.1145/638249.638287
   Cox S, 2003, INT J HUM-COMPUT INT, V16, P141, DOI 10.1207/S15327590IJHC1602_02
   da Rocha Costa A. C., 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P202
   Dhake D., 2020, INT J ENG APPL SCI T, V5, P254
   Efthimiou E, 2009, LECT NOTES COMPUT SC, V5614, P21, DOI 10.1007/978-3-642-02707-9_3
   Elliott R., 2008, Universal Access in the Information Society, V6, P375, DOI 10.1007/s10209-007-0102-z
   Elliott R, 2000, P 4 INT ACM C ASS TE, P101, DOI DOI 10.1145/354324.354349
   Huenerfauth M., 2008, TACCESS, V1, P1, DOI DOI 10.1145/1361203.1361206
   Joy J, 2020, ASSIST TECHNOL, V32, P153, DOI 10.1080/10400435.2018.1508093
   Kamal Z, 2020, LANG RESOUR EVAL, P117
   Karpouzis K, 2007, COMPUT EDUC, V49, P54, DOI 10.1016/j.compedu.2005.06.004
   Karpov A, 2016, PROCEDIA COMPUT SCI, V81, P201, DOI 10.1016/j.procs.2016.04.050
   Kaur A, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P372
   Kaur K, 2016, PROCEDIA COMPUT SCI, V89, P794, DOI 10.1016/j.procs.2016.06.063
   Kaur Rajneet, 2018, 2018 International Conference on Smart Systems and Inventive Technology (ICSSIT), P498, DOI 10.1109/ICSSIT.2018.8748597
   Kose H, 2012, INT J SOC ROBOT, V4, P273, DOI 10.1007/s12369-012-0142-2
   Kouremenos D, 2010, BEHAV INFORM TECHNOL, V29, P467, DOI 10.1080/01449290903420192
   Krishnamoorthy P, 2007, IETE TECH REV, V24, P351
   Kumar Kuldeep, 2012, International Journal of Computational Systems Engineering, V1, P25, DOI 10.1504/IJCSYSE.2012.044740
   Kumar Y, 2017, INT J SPEECH TECHNOL, V20, P297, DOI 10.1007/s10772-017-9408-2
   López-Colino F, 2017, IETE TECH REV, V34, P11, DOI 10.1080/02564602.2016.1141075
   Lopez-Ludena V, 2011, METHODOLOGY DEV SPEE, P1
   Luqman H, 2019, UNIVERSAL ACCESS INF, V18, P939, DOI 10.1007/s10209-018-0622-8
   Masbate AMM., 2020, ELEM ED ONLINE, V19, P78, DOI [10.17051/ilkonline.2020.04.108, DOI 10.17051/ILKONLINE.2020.04.108]
   Matsumoto T, 2009, P 3 INT UN COMM S, P363
   Morgan G., 2003, Deafness Education International, V5, P157, DOI [10.1179/146431503790560655, DOI 10.1179/146431503790560655]
   Naert L, 2021, MACH TRANSL, V35, P405, DOI 10.1007/s10590-021-09268-y
   Nair MS, 2016, 2016 INTERNATIONAL CONFERENCE ON NEXT GENERATION INTELLIGENT SYSTEMS (ICNGIS), P6
   Nawshin S, 2020, IEEE REGION 10 SYMP, P440
   Neves C, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6035
   Oh J., 2017, SMPTE MOTION IMAG J, V126, P57, DOI [10.5594/JMI.2016.2632278, DOI 10.5594/JMI.2016.2632278]
   Qaisar SM, 2019, J ELECTR ENG TECHNOL, V14, P955, DOI 10.1007/s42835-018-00071-z
   Rajaganapathy S, 2015, PROCEDIA COMPUT SCI, V50, P10, DOI 10.1016/j.procs.2015.04.004
   Ravanelli M, 2019, INT CONF ACOUST SPEE, P6465, DOI [10.13140/rg.2.2.18985.44647, 10.1109/ICASSP.2019.8683713]
   Reddy CKA, 2016, IEEE ENG MED BIO, P3670, DOI 10.1109/EMBC.2016.7591524
   San-Segundo R, 2008, SPEECH COMMUN, V50, P1009, DOI 10.1016/j.specom.2008.02.001
   Shahriar R, 2017, IEEE REG 10 HUMANIT, P1, DOI 10.1109/R10-HTC.2017.8288892
   Sindhu DV, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P262, DOI 10.1109/ICEECCOT.2016.7955227
   Stokoe WC, 2005, J DEAF STUD DEAF EDU, V10, P3, DOI 10.1093/deafed/eni001
   Stoll S, 2020, INT J COMPUT VISION, V128, P891, DOI 10.1007/s11263-019-01281-2
   Su HY, 2009, IEEE T AUDIO SPEECH, V17, P1305, DOI 10.1109/TASL.2009.2016234
   Veale T., 1998, Machine Translation, V13, P81, DOI 10.1023/A:1008014420317
   Vichyaloetsiri T, 2017, INT CONF COMP INFO, P180, DOI 10.1109/CITS.2017.8035336
   Wu Chung-Hsien., 2007, ACM Transactions on Asian Language Information Processing, V6, P1, DOI DOI 10.1145/1227850.1227851
   Zelinka J, 2020, IEEE WINT CONF APPL, P3384, DOI 10.1109/WACV45572.2020.9093516
   Zhao LW, 2000, LECT NOTES ARTIF INT, V1934, P54
NR 55
TC 1
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24099
EP 24117
DI 10.1007/s11042-022-12763-w
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000019
DA 2024-07-18
ER

PT J
AU Bastanfard, A
   Amirkhani, D
   MohammadinAff, M
AF Bastanfard, Azam
   Amirkhani, Dariush
   MohammadinAff, Mohammad
TI Toward image super-resolution based on local regression and nonlocal
   means
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution (SR); Local regression; Nonlocal means; Single image
   super-resolution (SISR)
ID HIGH-RESOLUTION IMAGE; SPARSE REPRESENTATIONS; RECONSTRUCTION;
   HALLUCINATION
AB Super-resolution algorithms have many weaknesses because they have low resolution and quality. These weaknesses are due to limitations and high cost of hardware implementation. Therefore, software methods are used due to its high accuracy and low cost. Super-resolution is used in a variety of applications, including satellite imagery, medicine, CCTV cameras, etc. Super-resolution is divided into two main categories: super-resolution using an input image and super-resolution using multiple input images. Considering the great use of the subject, this paper provides a method for increasing the resolution using an input image. In the proposed method, we improved the image super-resolution based on local regression and nonlocal means. The proposed method consists of two stages: a learning phase and a reconstruction phase. After the initial implementation, we compared the results with a quick and accurate method and found the difference. Then, using the Genetic algorithm, these differences were applied to the initial image. Results showed that our proposed method performed 2.4% and 2.2% better than the RAISR and LANR-NLM methods, Respectively.
C1 [Bastanfard, Azam] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Amirkhani, Dariush] Univ Quebec Qutaouais, Dept Comp Sci & Engn, Gatineau, PQ, Canada.
   [MohammadinAff, Mohammad] IRIB Univ, Dept Media Engn, Tehran, Iran.
C3 Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM Bastanfard@kiau.ac.ir; amid01@uqo.ca; mohammad1992mohammdi71@gmail.com
RI Amirkhani, Dariush/IYT-2131-2023; Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X; Amirkhani,
   Dariush/0000-0001-5653-9644
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   [Anonymous], 2009, P ADV NEUR INF PROC
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Begin Isabelle., 2006, P 3 CANADIAN C COMPU, P72
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509
   Borman S., 1998, SPATIAL RESOLUTION E
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Cheeseman P, 1996, FUND THEOR, V62, P293
   Chen C, 2012, CONF REC ASILOMAR C, P608, DOI 10.1109/ACSSC.2012.6489079
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Han D., 2013, Comparison of commonly used image interpolation methods, P1556
   Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   KOMATSU T, 1993, IEE PROC-I, V140, P19, DOI 10.1049/ip-i-2.1993.0005
   Li Tian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P493, DOI 10.1109/ICPR.2010.127
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nguyen N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P351, DOI 10.1109/ICIP.2000.899387
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190
   Reibman AR, 2006, IEEE IMAGE PROC, P2017, DOI 10.1109/ICIP.2006.312895
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Singh A., 2014, ACCV
   Singh A, 2020, MULTIMED TOOLS APPL, V79, P1641, DOI 10.1007/s11042-019-08254-0
   Siu WC, 2012, ASIAPAC SIGN INFO PR
   Sun J, 2003, PROC CVPR IEEE, P729
   Tekalp A. M., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P169, DOI 10.1109/ICASSP.1992.226249
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang WY, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00552-8
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
NR 48
TC 17
Z9 17
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23473
EP 23492
DI 10.1007/s11042-022-12584-x
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800028
DA 2024-07-18
ER

PT J
AU Gupta, A
   Semwal, VB
AF Gupta, Anjali
   Semwal, Vijay Bhaskar
TI Occluded Gait reconstruction in multi person Gait environment using
   different numerical methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi persons environment (MPG); Occlusion; Interpolation; Linear
   interpolation; Cubic spline interpolation; Shape preservation method;
   Curve fitting
ID RECOGNITION; TRACKING
AB Gait biometrics have been a topic of profound interest in recent years. To generate the walking trajectory for robots, humans are traced and modelled using Kinect and IMU sensors. The gait pattern model is developed through the data which is collected during the subject's walking cycles. But in real scenarios, the subject is often obstructed by different static and dynamic objects due to which the gait data is lost. This obstruction is known as occlusion. To achieve this a dataset for 25 subjects has been prepared using kinect sensor in static as well as in multi person environment. The state-of-the-art in this method is the regeneration and reconstruction of human walking trajectories caused by occlusion in multi person gait environments. This is similar to human activity recognition and robot walking trajectories generation. It will also explore the importance of neuro-muscular interaction during the gait cycle. The results of the generated gait model can be tested on real humanoid robots and used to improve the walking problems of elderly subjects and patients for rehabilitation. Interpolation and curve fitting techniques are used to find the missing data. For this several interpolation techniques like Lagrange's interpolation, piece-wise Cubic Hermite interpolation, spline interpolation, Periodic curve fitting, Linear curve fitting and Quadratic curve fitting are used for reconstruction purposes. To evaluate the accuracy and efficiency of each technique error evaluating parameters like MSE, RMSE, MAE and MAPE are computed to analyze and compare their performances. The results show that the Cubic Hermite outperforms all the methods as it interpolates values closest to the actual data due to its non linear nature.
C1 [Gupta, Anjali; Semwal, Vijay Bhaskar] Maulana Azad Natl Inst Technol Bhopal, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Gupta, A (corresponding author), Maulana Azad Natl Inst Technol Bhopal, Bhopal, MP, India.
EM anjalig376@gmail.com; vsemwal@manit.ac.in
RI GUPTA, ANJALI/ACG-0746-2022; Semwal, Vijay Bhaskar/B-5628-2017
OI GUPTA, ANJALI/0000-0003-1860-2352; Semwal, Vijay
   Bhaskar/0000-0003-0767-6057
FU SERB, DST, Govt. of India; DST [ECR/2018/000203]; Higher Education
   Financing Agency (HEFA) under CSR [SAN/CSR/08/2021-22]
FX The work is funded by SERB, DST, Govt. of India to Dr. Vijay Bhaskar
   Semwal under Early Career Award(ECR) with DST No: ECR/2018/000203 dated
   04-June-2019 and Higher Education Financing Agency (HEFA) under CSR
   Grant with Sanctioned order no-SAN/CSR/08/2021-22.
CR Ahmed MH, 2017, IEEE INT C CYBERNET, P243
   [Anonymous], 2017, ARXIV171006548
   Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117582
   Babaee M, 2017, IEEE IMAGE PROC, P2592, DOI 10.1109/ICIP.2017.8296751
   Barker PM, 2020, J ATMOS OCEAN TECH, V37, P605, DOI 10.1175/JTECH-D-19-0211.1
   Bijalwan V, 2021, IEEE SENS J, V21, P14213, DOI 10.1109/JSEN.2021.3066473
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Bourke P., 1999, MISCELLANEOUS PROJEC, V1
   Chattopadhyay P, 2015, PATTERN RECOGN LETT, V63, P9, DOI 10.1016/j.patrec.2015.06.004
   Chen X, 2016, MULTIMED TOOLS APPL, V75, P6505, DOI 10.1007/s11042-015-2585-6
   Das D, 2019, RGAIT NET EFFECTIVE
   Erdogan K. J. J. O. T. S., 2013, Journal of Technical Science and Technologies, V2, P47
   Gloersen O, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152616
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Gupta A., 2020, EMOTION INFORM PROCE, DOI [10.1007/978-3-030-48849-9_12, DOI 10.1007/978-3-030-48849-9_12]
   Hagan P.S., 2006, Applied Mathematical Finance, V13, P89
   Hofmann M, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P594
   Hofmann M, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P99
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Liu GD, 2006, VISUAL COMPUT, V22, P721, DOI 10.1007/s00371-006-0080-9
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Nixon Mark, 2008, Biometric Technology Today, V16, P8, DOI [10.1016/S0969-4765(08)70103-6, DOI 10.1016/S0969-4765(08)70103-6]
   Noor Norazian Mohamed, 2015, Materials Science Forum, V803, P278, DOI 10.4028/www.scientific.net/MSF.803.278
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Roy A, 2011, SIGNAL IMAGE VIDEO P, V5, P415, DOI 10.1007/s11760-011-0245-5
   Semwal VB, 2013, 2013 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, ROBOTICS AND EMBEDDED SYSTEMS (CARE-2013)
   Semwal VB, 2021, J SUPERCOMPUT, V77, P12256, DOI 10.1007/s11227-021-03768-7
   Semwal VB, 2022, ARTIF INTELL REV, V55, P1149, DOI 10.1007/s10462-021-09979-x
   Semwal VB, 2015, ROBOT AUTON SYST, V70, P181, DOI 10.1016/j.robot.2015.02.009
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Semwal VB, 2013, 2013 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, ROBOTICS AND EMBEDDED SYSTEMS (CARE-2013)
   Singh JP, 2020, MULTIMEDIA SYST, V26, P249, DOI 10.1007/s00530-019-00641-9
   Singh Jasvinder Pal, 2019, 2019 INT C ISSUES CH, P1
   Sivarathinabala M, 2019, J INTELL FUZZY SYST, V36, P2511, DOI 10.3233/JIFS-181210
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Uddin MZ., 2019, IPSJ T COMPUT VIS AP, V11, P1, DOI [10.1186/s41074-019-0053-3, DOI 10.1186/S41074-019-0053-3]
   Wang Kai., 2013, InSight: Rivier Academic Journal, V9
   Zha Y, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P353, DOI 10.1109/CompComm.2016.7924722
   Zhang YQ, 2019, PATTERN RECOGN, V93, P228, DOI 10.1016/j.patcog.2019.04.023
   Zhong Y, 2015, INT CONF BIOMETR THE
NR 41
TC 10
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23421
EP 23448
DI 10.1007/s11042-022-12218-2
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800011
DA 2024-07-18
ER

PT J
AU Lavanya, K
   Karnick, S
   Ghalib, MR
   Shankar, A
   Khapre, S
   Tayubi, IA
AF Lavanya, K.
   Karnick, Sarayu
   Ghalib, Muhammad Rukunuddin
   Shankar, Achyut
   Khapre, Shailesh
   Tayubi, Iftikhar Aslam
TI A novel method for vehicle detection in high-resolution aerial remote
   sensing images using YOLT approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLO; You only look once; YOLT; You only look twice; COWC; Cars Overhead
   With Context; CNN; Convolutional neural network; SSD; Single-shot
   detector
ID CONVOLUTIONAL NEURAL-NETWORK; OBJECT DETECTION
AB Owing to the innovative challenge stood by an intergovernmental military alliance, we have proposed a model to find novel solutions in the areas of data filtering/combining, visualization, and predictive analytics. Detecting tiny objects over huge zones has stayed as a major confront in satellite imagery examination. Among the confronts, the absolute quantity of pixels and topographical degree per picture are principle things. To deal with these issues, Multi-Scale Swift Detection System using COWC dataset to localize vehicles, i.e., cars in aerial imagery rapidly is implemented. We propose a model, Multiscale swift detection system that evaluates the satellite-images of an arbitrarily large size at a rate of 0.2 km(2)/s in the confined resolution. Forging over the TensorFlow object-detection API paper [11], this model provides an integrated tactic to various object-detection frameworks that can sprint interpretation on images of random size. The Multiscale swift detection system includes a customized version-type of YOLO, known as YOLT. The approach can hastily detect objects of infinitely various scales with comparatively less training data upon multiple sensors. It can quickly detect objects of immensely diverse scales with comparatively modest training data over several sensors. For the object detection area of the work, we use the COWC dataset, which features aerial imagery taken in different locations. Here the mean size of cars is assumed to be roughly constant. We assess bulky test-images at confined resolution and discover mAP scores of 0.2 to 0.8 for the vehicle-localization. Also computed a yield score of F1 > 0.8 attaining both the highest mAP value and rapid inference speed with the YOLT architecture.
C1 [Lavanya, K.; Karnick, Sarayu] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Ghalib, Muhammad Rukunuddin] De Montfort Univ, Sch Sci, Dubai, U Arab Emirates.
   [Shankar, Achyut] Amity Univ, Sch Engn & Technol, Noida, India.
   [Khapre, Shailesh] IIIT Naya Raipur, Data Sci & Artificial Intelligence Dept, Naya Raipur, India.
   [Tayubi, Iftikhar Aslam] King Abdulaziz Univ, Fac Comp & Informat Technol Rabigh, Jeddah, Saudi Arabia.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Amity University
   Noida; King Abdulaziz University
RP Shankar, A (corresponding author), Amity Univ, Sch Engn & Technol, Noida, India.
EM lavanya.k@vit.ac.in; sarayu.karnick@gmail.com; ruk.ghalib@ieee.org;
   ashankar2711@gmail.com; shaileshaprerkl@gmail.com;
   iftikhar.tayubi@gmail.com
RI tayubi, iftikhar/GLR-8498-2022; Ghalib, Muhammad Rukunuddin/C-4485-2019;
   KHAPRE, SHAILESH/D-1566-2018; tayubi, iftikhar/GQI-1407-2022
OI tayubi, iftikhar/0000-0002-2797-8522; Ghalib, Muhammad
   Rukunuddin/0000-0002-2786-3370; tayubi, iftikhar/0000-0002-2797-8522;
   Shankar, Achyut/0000-0003-3165-3293; KHAPRE,
   SHAILESH/0000-0001-6596-4933
CR Ardö H, 2018, IET COMPUT VIS, V12, P171, DOI 10.1049/iet-cvi.2017.0077
   Chen C. L. Philip, 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen JY, 2018, ENG APPL ARTIF INTEL, V73, P92, DOI 10.1016/j.engappai.2018.04.023
   Chen ZY, 2016, IEEE T GEOSCI REMOTE, V54, P103, DOI 10.1109/TGRS.2015.2451002
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Glagolevs J., 2017, 2017 5 IEEE WORKSHOP, P1
   Gonzalez LF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010097
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Liu QW, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103333
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao W, 2020, INT J REMOTE SENS, V41, P31, DOI 10.1080/01431161.2019.1624858
   Shrivastava Shailesh, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P327, DOI 10.1007/978-981-13-7403-6_31
   Song SL, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080683
   Van Etten A, 2019, IEEE WINT CONF APPL, P735, DOI 10.1109/WACV.2019.00083
   van Gemert JC, 2015, LECT NOTES COMPUT SC, V8925, P255, DOI 10.1007/978-3-319-16178-5_17
   Wu H, 2015, IEEE SYS MAN CYBERN, P2956, DOI 10.1109/SMC.2015.514
NR 20
TC 9
Z9 8
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23551
EP 23566
DI 10.1007/s11042-022-12613-9
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800006
DA 2024-07-18
ER

PT J
AU Khanna, K
   Gambhir, S
   Gambhir, M
AF Khanna, Ketna
   Gambhir, Sapna
   Gambhir, Mohit
TI A novel technique for image classification using short-time Fourier
   transform and local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern; Short-time Fourier transform; Chi-square; FDR;
   Variance threshold; Classification; JAFFE dataset
ID STATISTICS
AB Machine Learning (ML) has been widely used for Image processing. The pertinent feature extraction and feature selection techniques can help us to accomplish many complex tasks. This paper presents a framework for the classification of emotions using ML. Training and testing have been done using the JAFFE (Japanese Female Facial Expression) dataset. The work proposes a combination of Short-Time Fourier Transform (STFT) and Local Binary Pattern (LBP) for extracting interesting features. Also, a fusion of popular feature reduction techniques namely: Fisher Discriminant Ratio (FDR), variance threshold method and chi-square test has been introduced. The selected relevant features are applied to the Support Vector Machine (SVM) classifier. Performance analysis of the existing techniques and the proposed technique has been carried out where the latter was found efficient. The proposed pipeline performs better in terms of accuracy, specificity and sensitivity as compared to the state of art.
C1 [Khanna, Ketna; Gambhir, Sapna] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
   [Gambhir, Mohit] Minist Educ, Delhi 110001, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Khanna, K (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
EM ketnakhanna05@gmail.com; sapnagambhir@gmail.com; mohitgambhir@gmail.com
RI Khanna, Ketna/KUD-2096-2024; Gambhir, Mohit/JTV-5001-2023
CR Alpaydin Ethem., 2010, INTRO MACHINE LEARNI, P9
   Bock DE., 2007, STATS MODELING WORLD, P606
   Borges F, 2020, IEEE LAT AM T, V18, P1093, DOI 10.1109/TLA.2020.9099687
   Bracewell R.N., 2000, FOURIER TRANSFORM IT
   Chrysikopoulos H.S., 2009, Clinical MR Imaging and Physics
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dat TH, 2007, INT CONF ACOUST SPEE, P337
   Fisher RA, 1922, J R STAT SOC, V85, P87, DOI 10.2307/2340521
   Friedman JH, 1997, COMP SCI STAT, V29, P3
   Hemanth DJ, 2012, COMM COM INF SC, V350, P349
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Khanna K., 2020, J CRIT REV, V7, P1461, DOI [10.31838/jcr.07.18.188, DOI 10.31838/JCR.07.18.188]
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Li MJ, 2020, IEEE ACCESS, V8, P72308, DOI 10.1109/ACCESS.2020.2987914
   Mark S.N., 2002, FEATURE EXTRACTION I
   Ming X., 2009, STUDY APPL MACHINE L
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Popa CA, 2018, LECT NOTES COMPUT SC, V10878, P300, DOI 10.1007/978-3-319-92537-0_35
   Ravishankar S, 2020, P IEEE, V108, P86, DOI 10.1109/JPROC.2019.2936204
   Sejdic E, 2009, DIGIT SIGNAL PROCESS, V19, P153, DOI 10.1016/j.dsp.2007.12.004
   Shi S, 2017, INT CONF ACOUST SPEE, P1373, DOI 10.1109/ICASSP.2017.7952381
   Soni D., 2016, INT RES J ENG TECHNO, V3, P437
   Susmita R., 2019, INT C MACH LEARN BIG
   Tao Y, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P120
NR 25
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20705
EP 20718
DI 10.1007/s11042-022-12671-z
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000010
DA 2024-07-18
ER

PT J
AU Lakshmi, TRV
   Reddy, CVK
   Padmavathi, K
   Swaraja, K
   Meenakshi, K
AF Lakshmi, T. R. Vijaya
   Reddy, Ch Venkata Krishna
   Padmavathi, K.
   Swaraja, K.
   Meenakshi, K.
TI Entropy based single image dehazing with refined transmission using
   holistic edges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Scattering coefficient; Depth and Transmission maps; Hue
   disparity; Non-achromatic atmospheric light
ID QUALITY ASSESSMENT; WEATHER; MODEL
AB The natural occurrences of haze, mist and fog obscures the optically captured outdoor scenes. The essential parameters of the atmospheric scattering model for dehazing are air-light (which depends on atmospheric light) and transmission map. Inaccurate estimation of these parameters leads to halo-artifacts, color distortions, etc. The performance of the available single-image dehazing models is limited by the color shifts caused due to the offset of light sources. The proposed work estimates the atmospheric light component by considering the lowest entropy from the quad-decomposed image as the haze opaque regions in the scene considered has low entropy. The transmission map is estimated by computing the scattering parameter, further refined with the holistic edges to calculate haze at different densities. A regression model is trained with the haze relevant features such as hue disparity, contrast, and darkness to compute the scattering coefficient rigorously. This improves the color shifts and visibility of the degraded outdoor scenes and mitigates the imbalances in the haze density concentrations in the scenes. The current model is evaluated using reference-based and non-reference based metrics to emphasize its perceptibility on hazy images when blended with pure light and non-achromatic light. The evaluations on real-hazy images signify that the true colors are well preserved, and the degree of visibility is improved compared to the state-of-the-art models.
C1 [Lakshmi, T. R. Vijaya] Mahatma Gandhi Inst Technol, Dept ECE, Hyderabad, India.
   [Reddy, Ch Venkata Krishna] Chaitanya Bharathi Inst Technol, Dept EEE, Hyderabad, India.
   [Padmavathi, K.; Swaraja, K.; Meenakshi, K.] GRIET, Dept ECE, Hyderabad, India.
C3 Chaitanya Bharathi Institute of Technology; Gokaraju Rangaraju Institute
   of Engineering & Technology
RP Lakshmi, TRV (corresponding author), Mahatma Gandhi Inst Technol, Dept ECE, Hyderabad, India.
EM trvijayalakshmi_ece@mgit.ac.in; chvkrishnareddy_eee@cbit.ac.in
RI T R, Vijaya Lakshmi/AAP-1431-2020; Reddy, venkata krishna/ACL-7113-2022;
   kuraparthi, swaraja/AAY-9068-2020
OI T R, Vijaya Lakshmi/0000-0002-1197-2935; Reddy, venkata
   krishna/0000-0002-3319-5639; 
CR [Anonymous], 2016, PROC 10 INT S COMMUN
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen Z, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103286
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   DENG G, 1993, ELECTRON LETT, V29, P803, DOI 10.1049/el:19930536
   DENG G, 1995, IEEE T IMAGE PROCESS, V4, P506, DOI 10.1109/83.370681
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hulburt EO, 1941, J OPT SOC AM, V31, P467, DOI 10.1364/JOSA.31.000467
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Kansal I, 2020, MULTIMED TOOLS APPL, V79, P12069, DOI 10.1007/s11042-019-08240-6
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lakshmi TRV, 2018, ALEX ENG J, V57, P2393, DOI 10.1016/j.aej.2017.09.009
   Lakshmi TRV, 2018, SIGNAL IMAGE VIDEO P, V12, P223, DOI 10.1007/s11760-017-1149-9
   Liang D, 2014, INT J OPTOMECHATRONI, V8, P14, DOI 10.1080/15599612.2014.890686
   Linan Y., 2012, TELKOMNIKA INDONESIA, V10, P1644, DOI DOI 10.11591/TELK0MNIKA.V10I7.1556
   Liu CX, 2016, VISUAL COMPUT, V32, P911, DOI 10.1007/s00371-016-1259-3
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nafchi HZ, 2018, IEEE T BROADCAST, V64, P518, DOI 10.1109/TBC.2018.2818402
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shwartz S, 2006, BLIND HAZE SEPARATIO
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tan Z, 2014, FAST SINGLE IMAGE DE
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Thirumala VL, 2021, TURK J ELECTR ENG CO, V29, P994, DOI 10.3906/elk-2004-7
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xiao JS, 2023, COMPUTING, V105, P717, DOI 10.1007/s00607-021-00907-z
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xingyong Lv, 2010, 2010 Pacific Graphics (PG). Proceedings 18th Pacific Conference on Computer Graphics and Applications, P62, DOI 10.1109/PacificGraphics.2010.16
   Xu H, 2012, P INT C INF SCI TECH, P03
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang H., 2010, P 2010 3 INT C IM SI, V2, P2010
   Yu J, 2010, INT CONF SIGN PROCES, P1048, DOI 10.1109/ICOSP.2010.5655901
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 48
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20229
EP 20253
DI 10.1007/s11042-022-12485-z
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600019
DA 2024-07-18
ER

PT J
AU Ghodhbani, H
   Neji, M
   Razzak, I
   Alimi, AM
AF Ghodhbani, Hajer
   Neji, Mohamed
   Razzak, Imran
   Alimi, Adel M.
TI You can try without visiting: a comprehensive survey on virtually try-on
   outfits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual try-on; Fashion industry; Fashion detection; Fashion synthesis
AB Since the last years and until now, technology has made fast progress for many industries, in particularly, garment industry which aims to follow consumer desires and demands. One of these demands is to fit clothes before purchasing them on-line. Therefore, many research works have been focused on how to develop an intelligent apparel industry to ensure the online shopping experience. Image-based virtual try-on is among the most potential approach of virtual fitting that tries on target clothes into customer's image, therefore, it has received considerable research efforts in the recent years. However, there are several challenges involved in development of virtual try-on that make it difficult to achieve naturally looking virtual outfit such as shape, pose, occlusion, illumination cloth texture, logo and text etc. The aim of this study is to provide a comprehensive and structured overview of extensive research on the advancement of virtual try-on. This review first introduces virtual try-on and its challenges followed by its demand in fashion industry. We summarize state-of-the-art image based virtual try-on for both fashion detection and fashion synthesis as well as their respective advantages, drawbacks, and guidelines for selection of specific try-on model followed by its recent development and successful application. Finally, we conclude the paper with promising directions for future research.
C1 [Ghodhbani, Hajer; Neji, Mohamed; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines REGIM Lab, BP 1173, Sfax 3038, Tunisia.
   [Neji, Mohamed] Natl Sch Elect & Telecommun Sfax Technopk, BP 1163, Sfax 3018, Tunisia.
   [Razzak, Imran] Univ Technol, Adv Analyt Inst, Sydney, NSW, Australia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University of Technology Sydney; University of Johannesburg
RP Ghodhbani, H (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines REGIM Lab, BP 1173, Sfax 3038, Tunisia.
EM hajer.ghodhbani@regim.usf.tn
RI Razzak, Imran/AEW-5139-2022; Ghodhbani, Hajer/KFR-8355-2024
OI Razzak, Imran/0000-0002-3930-6600; 
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Chen HN, 2019, 2019 URSI ASIA-PACIFIC RADIO SCIENCE CONFERENCE (AP-RASC), DOI [10.3390/polym11122039, 10.23919/ursiap-rasc.2019.8738337]
   Cheng WH, 2021, ACM COMPUT SURV, V54, DOI [10.1145/3447239, 10.1145/3552468.3554360]
   Cui YR, 2018, COMPUT GRAPH FORUM, V37, P109, DOI 10.1111/cgf.13552
   Dalmia A, 2018, ARXIV PREPRINT ARXIV
   Donato G, 2002, LECT NOTES COMPUT SC, V2352, P21
   Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423
   Everingham M., 2010, BMVC, V2, P5
   Ge YY, 2021, PROC CVPR IEEE, P8481, DOI 10.1109/CVPR46437.2021.00838
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Han XT, 2019, IEEE I CONF COMP VIS, P10470, DOI 10.1109/ICCV.2019.01057
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Hariharan B, 2020, FASHIONPEDIA ONTOLOG
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou M, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4681
   Hsieh CW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P275, DOI 10.1145/3343031.3351075
   Hsieh CW, 2019, IEEE IMAGE PROC, P4694, DOI [10.1109/icip.2019.8803681, 10.1109/ICIP.2019.8803681]
   Hu K, 2021, ARXIV PREPRINT ARXIV
   Huang FH, 2021, IEEE ACCESS, V9, P49189, DOI 10.1109/ACCESS.2021.3069245
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Issenhuth Thibaut, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P619, DOI 10.1007/978-3-030-58565-5_37
   Ji W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P764
   Johnsen TE, 2017, IND MARKET MANAG, V61, P130, DOI 10.1016/j.indmarman.2016.03.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lähner Z, 2018, LECT NOTES COMPUT SC, V11208, P698, DOI 10.1007/978-3-030-01225-0_41
   Lee S, 2019, IEEE I CONF COMP VIS, P4412, DOI 10.1109/ICCV.2019.00451
   Li J, 2017, ARXIV PREPRINT ARXIV, P3193
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P11354
   Li SJ, 2014, IEEE COMPUT SOC CONF, P488, DOI 10.1109/CVPRW.2014.78
   Li YX, 2019, IEEE INT CON MULTI, P820, DOI 10.1109/ICME.2019.00146
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1571, DOI 10.1145/3240508.3240646
   Liu JH, 2020, NEUROCOMPUTING, V414, P215, DOI 10.1016/j.neucom.2020.06.033
   Liu LL, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104097
   Liu S, 2014, IEEE MULTIMEDIA, V21, P72, DOI 10.1109/MMUL.2014.25
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Luo XH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P654, DOI 10.1145/3240508.3240634
   Ma LQ, 2017, ADV NEUR IN, V30
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Minar M. R., 2020, CVPR WORKSH
   Neuberger A, 2020, PROC CVPR IEEE, P5183, DOI 10.1109/CVPR42600.2020.00523
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Omid Mohammadi S, 2021, SMART FASHION REV AI
   Oyewusi WF, 2021, IEEE COMPUT SOC CONF, P3963, DOI 10.1109/CVPRW53098.2021.00446
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Peng X, 2018, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2018.00237
   PONSMOLL G, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.3073711
   Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899
   Puri D., 2019, INT C COMPUTING COMM, P1
   Raj A., 2018, P EUR C COMP VIS ECC, P666
   Ren B, 2021, ARXIV PREPRINT ARXIV
   Rozière B, 2021, IEEE T IMAGE PROCESS, V30, P4036, DOI 10.1109/TIP.2021.3065845
   Ruan T, 2019, AAAI CONF ARTIF INTE, P4814
   Santesteban, 2021, U.S. Patent Application, Patent No. [16/639,923, 16639923]
   Sarkar K, 2021, ARXIV PREPRINT ARXIV
   Shi H, 2020, BMVC
   Si CY, 2018, PROC CVPR IEEE, P118, DOI 10.1109/CVPR.2018.00020
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Song SJ, 2019, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2019.00246
   Song SJ, 2018, IEEE MULTIMEDIA, V25, P102, DOI 10.1109/MMUL.2018.2875860
   Statista, 2020, GLOB APP MARK STAT F
   Sun F, 2019, IEEE IMAGE PROC, P519, DOI [10.1109/ICIP.2019.8803811, 10.1109/icip.2019.8803811]
   Sun SM, 2021, INT C PATT RECOG, P1582, DOI 10.1109/ICPR48806.2021.9412002
   Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21
   Theobalt Christian, 2020, COMPUTER VISION ECCV
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Turkut U, 2020, 2020 INT C HUM COMP, P1
   Vandana M, 2020, HERE ARE 3 WAYS BUSI
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang JS, 2020, PROC CVPR IEEE, P5830, DOI 10.1109/CVPR42600.2020.00587
   Wang TY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356512
   Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2017, ADV NEUR IN, V30
   Wu ZH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P293, DOI 10.1145/3343031.3351083
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xu M, 2021, P IEEE CVF INT C COM, P13859
   Yahong Z, 2021, HAPTICMEDIA
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yan SJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P172, DOI 10.1145/3123266.3123276
   Yang F, 2021, PROC CVPR IEEE, P9894, DOI 10.1109/CVPR46437.2021.00977
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Yang S, 2016, ARXIV PREPRINT ARXIV
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Yu RY, 2019, IEEE I CONF COMP VIS, P10510, DOI 10.1109/ICCV.2019.01061
   Yu T, 2019, PROC CVPR IEEE, P5499, DOI 10.1109/CVPR.2019.00565
   Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng N, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P266, DOI 10.1145/3343031.3350946
   Zheng S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1670, DOI 10.1145/3240508.3240652
   Zhu H, 2020, DEEP FASHION3D DATAS
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou XX, 2019, IEEE COMPUT SOC CONF, P296, DOI 10.1109/CVPRW.2019.00039
NR 107
TC 4
Z9 4
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19967
EP 19998
DI 10.1007/s11042-022-12802-6
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767089800006
PM 35291716
OA Bronze, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Zuo, MJ
   Cheng, S
   Gong, LH
AF Zuo, Mei-Juan
   Cheng, Shan
   Gong, Li-Hua
TI Secure and robust watermarking scheme based on the hybrid optical
   bi-stable model in the multi-transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Hybrid optical bi-stable model; Discrete cosine
   transform; Dual tree complex wavelet transform; Singular value
   decomposition
ID DIGITAL WATERMARKING; DWT-SVD; DCT
AB A good watermarking scheme should guarantee its robustness to various attacks. Most watermarking algorithms can resist some general image attacks, while some algorithms display the weak robustness to the rotation attack. To improve the robustness of the digital watermarking scheme against the rotation attack, a new secure watermarking scheme based on the hybrid optical bi-stable model in the multi-transform domain is proposed. In the proposed scheme, the original image is decomposed by the three-level dual tree complex wavelet transform. The dual tree complex wavelet transform possesses approximate translation invariance, good directional selectivity and moderate redundancy. Then the watermark image is scrambled by the Arnold transform and the chaos sequence based on the hybrid optical bi-stable model. Afterwards, the real low frequency is divided into some small matrices of size 8 x 8 and a coefficient matrix is generated after performing the discrete cosine transform on each matrix. To enhance the robustness of the watermarking algorithm, singular value decomposition is employed and the singular values of the watermark image are embedded into the real low frequency regions of the host image with a suitable embedding rule. Experimental results demonstrate that the proposed watermarking scheme is much better in terms of the robustness of the image.
C1 [Zuo, Mei-Juan; Gong, Li-Hua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Cheng, Shan] Jiangxi Vocat Coll Mech & Elect Technol, Dept Elect Engn, Nanchang 330013, Jiangxi, Peoples R China.
C3 Nanchang University
RP Gong, LH (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM lhgong@ncu.edu.cn
OI Gong, Lihua/0000-0002-1180-3023
FU National Natural Science Foundation of China [61861029]; Cultivation
   Plan of Applied Research of Jiangxi Province [20181BBE58022]; Innovation
   Special Foundation of Graduate Student of Jiangxi Province [YC2020-S103]
FX This work is supported by the National Natural Science Foundation of
   China (Grant no. 61861029), the Cultivation Plan of Applied Research of
   Jiangxi Province (Grant no. 20181BBE58022), and the Innovation Special
   Foundation of Graduate Student of Jiangxi Province (Grant no.
   YC2020-S103).
CR Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Esfahani R, 2019, MULTIMED TOOLS APPL, V78, P16159, DOI 10.1007/s11042-018-6892-6
   Fan DS, 2013, J MOD OPTIC, V60, P749, DOI 10.1080/09500340.2013.810789
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kumar CA, 2019, INT CONF ADVAN COMPU, P567, DOI [10.1109/ICACCS.2019.8728398, 10.1109/icaccs.2019.8728398]
   Loo P, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P29, DOI 10.1109/ICIP.2000.899275
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Saikrishna N, 2016, PROCEDIA COMPUT SCI, V93, P808, DOI 10.1016/j.procs.2016.07.299
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh P, 2013, AFRICON
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Tan YL, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11121505
   Ying QC, 2019, MATH BIOSCI ENG, V16, P4788, DOI 10.3934/mbe.2019241
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang Z, 2016, INT CONF SIGN PROCES, P805, DOI 10.1109/ICSP.2016.7877942
   Zheng PJ, 2020, MULTIMED TOOLS APPL, V79, P18343, DOI 10.1007/s11042-019-08490-4
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 35
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17033
EP 17056
DI 10.1007/s11042-022-12035-7
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599600005
DA 2024-07-18
ER

PT J
AU Galmés, B
   Moyà-Alcover, G
   Bibiloni, P
   Varona, J
   Jaume-i-Capó, A
AF Galmes, Bernat
   Moya-Alcover, Gabriel
   Bibiloni, Pedro
   Varona, Javier
   Jaume-i-Capo, Antoni
TI Geometric-based nail segmentation for clinical measurements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Toenail; Segmentation; Medical image; Computer vision; Machine learning
AB A robust segmentation method that can be used to perform measurements on toenails is presented. The proposed method is used as the first step in a clinical trial to objectively quantify the incidence of a particular pathology. For such an assessment, it is necessary to distinguish a nail, which locally appears to be similar to the skin. Many algorithms have been used, each of which leverages different aspects of toenail appearance. We used the Hough transform to locate the tip of the toe and estimate the nail location and size. Subsequently, we classified the super-pixels of the image based on their geometric and photometric information. Thereafter, the watershed transform delineated the border of the nail. The method was validated using a 348-image medical dataset, achieving an accuracy of 0.993 and an F-measure of 0.925. The proposed method is considerably robust across samples, with respect to factors such as nail shape, skin pigmentation, illumination conditions, and appearance of large regions affected by a medical condition.
C1 [Galmes, Bernat; Moya-Alcover, Gabriel; Varona, Javier; Jaume-i-Capo, Antoni] Univ Balearic Isl, Dept Math & Comp Sci, UGiVIA Res Grp, Palma De Mallorca, Spain.
   [Bibiloni, Pedro] Hlth Res Inst Balearic Isl IdISBa, Palma De Mallorca 07010, Spain.
   [Bibiloni, Pedro] Univ Balearic Isl, Dept Math & Comp Sci, SCOPIA Res Grp, Palma De Mallorca, Spain.
   [Moya-Alcover, Gabriel; Varona, Javier; Jaume-i-Capo, Antoni] Univ Illes Balears, Lab Artificial Intelligence Applicat LAIA UIB, Palma De Mallorca, Spain.
C3 Universitat de les Illes Balears; Institut Investigacio Sanitaria Illes
   Balears (IdISBa); Universitat de les Illes Balears; Universitat de les
   Illes Balears
RP Moyà-Alcover, G (corresponding author), Univ Balearic Isl, Dept Math & Comp Sci, UGiVIA Res Grp, Palma De Mallorca, Spain.; Moyà-Alcover, G (corresponding author), Univ Illes Balears, Lab Artificial Intelligence Applicat LAIA UIB, Palma De Mallorca, Spain.
EM gabriel.moya@uib.es
RI Varona, Javier/X-5831-2018; Moya-Alcover, Gabriel/L-3129-2018;
   Jaume-i-Capo, Antoni/I-4053-2015
OI Moya-Alcover, Gabriel/0000-0002-3412-5499; Jaume-i-Capo,
   Antoni/0000-0003-3312-5347
FU CRUE-CSIC agreement; Springer Nature; Ministerio de Economia, Industria
   y Competitividad (MINECO); Agencia Estatal de Investigacion (AEI);
   European Regional Development Funds (ERDF) - MCIN/AEI [TIN 2016-75404-P,
   TIN2016-81143-R, PID2019104829RAI00]; Govern de les Illes Balears
   [PROCOE/2/2017]; European Social Fund;  [FPI/1645/2014]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. We acknowledge the Ministerio de Economia, Industria y
   Competitividad (MINECO), the Agencia Estatal de Investigacion (AEI), and
   the European Regional Development Funds (ERDF) for its support for the
   projects TIN 2016-75404-P (AEI/FEDER, UE), TIN2016-81143-R (AEI/FEDER,
   UE), and Project PID2019104829RAI00 -"EXPLainable Artificial
   INtelligence systems for health and well-beING (EXPLAINING)" funded by
   MCIN/AEI/10.13039/501100011033. We also acknowledge the Govern de les
   Illes Balears for its support for the project PROCOE/2/2017. P. Bibiloni
   also benefited from the fellowship FPI/1645/2014 under an operational
   program co-financed by the European Social Fund.
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   [Anonymous], 2013, 2013 IEEE 6 INT C BI
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Easwaramoorthy S, 2016, 2016 INT C REC TREND, P1, DOI DOI 10.1109/ICETETS.2016.7603054
   Fujishima N., 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P233, DOI 10.1109/GCCE.2012.6379589
   Fujishima N, 2013, IAPR INT C MACH VIS, P117
   Fukunaka SCYU., 2012, NICOGRAPH INT, V12, P198
   Gauns Dessai Sneha N., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P656, DOI 10.1109/I-SMAC.2018.8653712
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, P535
   Hastie T., 2009, The Elements of Statistical Learning
   Juna V, 2019, RECENT TRENDS ANALOG, V2
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kumar A, 2014, EXPERT SYST APPL, V41, P373, DOI 10.1016/j.eswa.2013.07.057
   Kumar Mente R., 2017, INT J ENG COMPUT SCI, V6, P22830
   Kumuda NS, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING RESEARCH IN ELECTRONICS, COMPUTER SCIENCE AND TECHNOLOGY (ICERECT), P270, DOI 10.1109/ERECT.2015.7499025
   Kumuda NS, 2016, ADV INTELL SYST, V381, P259, DOI 10.1007/978-81-322-2526-3_28
   Kurniastuti I, 2018, P INT C TECHN ED 201, V1
   Lee S-H, 2016, IEEE INT C SIG IM PR
   Marulkar S, 2018, INT C REC TRENDS IM, P116
   MEYER F, 1992, IEE CONF PUBL, V354, P303
   Tolentino LK, 2018, J TELECOMMUNICATION, V10, P181
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang YM, 2013, IEICE T INF SYST, VE96D, P1894, DOI 10.1587/transinf.E96.D.1894
NR 23
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16117
EP 16132
DI 10.1007/s11042-022-12234-2
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600007
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kalburgi, SS
   Manimozhi, M
AF Kalburgi, Shivaraj Sharanabasappa
   Manimozhi, M.
TI Taylor-spotted hyena optimization algorithm for reliable and
   energy-efficient cluster head selection based secure data routing and
   failure tolerance in WSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network (WSN); Network failure; Route maintenance;
   Cluster head (CH) selection; And data routing
ID PROTOCOL
AB Wireless Sensor Network (WSN) comprises sensor nodes, and these nodes are generally battery-powered such that the batteries are not recharged because of their inaccessibility in the hostile environment. WSN is prone to node or link failure due to environmental hazards, like internal and interference faults in the sensor nodes. The link failure can result in network disconnection, so the data cannot get the path to Base Station or sink node. The link failure degrades the quality of the network in a hostile environment. To mitigate this issue and tolerate network failure, an effective Cluster Head (CH) selection mechanism is devised by the developed Taylor-Spotted Hyena Optimization (Taylor-SHO), which integrates the Taylor series with Spotted Hyena Optimization (SHO). The proposed approach is employed for the effective CH selection process using fitness measure depending on energy, distance, and delay. Then, the data routing is done by the modified k-Vertex Disjoint Path Routing (mod-kVDPR) algorithm, which is derived by modifying kVDPR using the parameters, such as link reliability and throughput. At last, the route maintenance is engaged to observe the delivery operation of data packets and report the link failure. The performance of the proposed method is analyzed using simulation network with 50 nodes and 10 nodes. Also, the proposed scheme is compared with Distributed Energy Efficient Heterogeneous Clustering approach, Grey Wolf Optimizer, Tabu particle swarm optimization, and Herding Optimization-Greedy conventional techniques. The proposed method has a delay of 0.00075 s., energy of 0.0018 J, the throughput of 5499 kbps for simulation network with 50 nodes; and has the delay of 0.0007 s., energy of 0.00089 J, and throughput of 7148.7 kbps for simulation network with 100 nodes.
C1 [Kalburgi, Shivaraj Sharanabasappa; Manimozhi, M.] VIT Univ, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kalburgi, SS (corresponding author), VIT Univ, Vellore, Tamil Nadu, India.
EM kalburgi.shivaraj2016@vitstudent.ac.in
RI Kalburgi, Shivaraj/KVY-1019-2024
OI kalburgi, shivaraj sharanabasappa/0000-0001-5179-8276
CR Abbasi AA, 2007, COMPUT COMMUN, V30, P2826, DOI 10.1016/j.comcom.2007.05.024
   Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Bacanin N, 2020, MATHEMATICS-BASEL, V8, P1
   Balachandra M, 2014, WIREL NETW, V20, P2395, DOI 10.1007/s11276-014-0754-6
   Bojja GR, 2020, AMCIS 2020 PROCEEDINGS
   Borawake-Satao R, 2019, MULTIMED TOOLS APPL, V78, P32659, DOI 10.1007/s11042-019-7619-z
   Bui TTH, 2023, J SUSTAIN FINANC INV, V13, P264, DOI 10.1080/20430795.2021.1891787
   Chanak P, 2017, AD HOC NETW, V56, P158, DOI 10.1016/j.adhoc.2016.12.006
   Daneshvar SMMH, 2019, IEEE ACCESS, V7, P170019, DOI 10.1109/ACCESS.2019.2955993
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Elma KJ, 2018, INT J APPL ENG RES, V13, P337
   Gupta N, 2021, MULTIMED TOOLS APPL, V80, P22301, DOI 10.1007/s11042-021-10820-4
   Han GJ, 2016, IEEE WIREL COMMUN, V23, P140, DOI 10.1109/MWC.2016.1400052WC
   Huang JH, 2017, CLUSTER COMPUT, V20, P3071, DOI 10.1007/s10586-017-0993-2
   Hung NT, 2020, P INT C HIGH ED VIET
   John Jacob., 2019, J NETWORKING COMMUNI, V2, P20
   Jung K, 2017, MULTIMED TOOLS APPL, V76, P18175, DOI 10.1007/s11042-016-4190-8
   Kaur T, 2018, IEEE SENS J, V18, P4614, DOI 10.1109/JSEN.2018.2828099
   Kelotra Amit., 2019, J NETWORKING COMMUNI, V2, P24, DOI DOI 10.46253/JNACS.V2I1.A3
   Kumar R, 2016, WIREL NETW, V22, P1461, DOI 10.1007/s11276-015-1039-4
   Li FG, 2013, IEEE SENS J, V13, P3677, DOI 10.1109/JSEN.2013.2262271
   Lindsey S, 2002, AEROSP CONF PROC, P1125, DOI 10.1109/aero.2002.1035242
   Logambigai R, 2016, WIREL NETW, V22, P945, DOI 10.1007/s11276-015-1013-1
   Mangai SA., 2014, International Journal of Computer Application, V89, P41, DOI DOI 10.5120/15470-4112
   Mehra PS, 2020, J KING SAUD UNIV SCI, V32, P390, DOI 10.1016/j.jksus.2018.04.031
   Mehta D, 2022, MULTIMED TOOLS APPL, V81, P35083, DOI 10.1007/s11042-020-09633-8
   Morsy NA, 2018, WIRELESS PERS COMMUN, V103, P2575, DOI 10.1007/s11277-018-5948-2
   Nayyar A, 2020, MULTIMED TOOLS APPL, V79, P35221, DOI 10.1007/s11042-019-7627-z
   Palaniappan S, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-014-0234-9
   Pattnaik S, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4354
   Rao PCS, 2021, MULTIMED TOOLS APPL, V80, P26093, DOI 10.1007/s11042-021-10901-4
   Rao PCS, 2016, LECT NOTES COMPUT SC, V9873, P222, DOI 10.1007/978-3-319-48959-9_20
   Reddy P. K., 2019, J NETWORKING COMMUNI, V2, P23
   Sreedharan PS, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4536
   Strumberger I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112515
   Sujanthi S, 2020, WIRELESS PERS COMMUN, V114, P2135, DOI 10.1007/s11277-020-07469-x
   Vijayalakshmi K, 2019, CLUSTER COMPUT, V22, P12275, DOI 10.1007/s10586-017-1608-7
   Vinitha A, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4440
   Wang J, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9472075
   Yadav AK, 2017, PEER PEER NETW APPL, V10, P897, DOI 10.1007/s12083-016-0441-8
   Zhou Y, 2017, IEEE ACCESS, V5, P2241, DOI 10.1109/ACCESS.2016.2633826
   Zivkovic M., 2021, Data Intelligence and Cognitive Informatics, P803, DOI DOI 10.1007/978-981-15-8530-2_63
NR 43
TC 10
Z9 10
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15815
EP 15839
DI 10.1007/s11042-022-12302-7
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200008
DA 2024-07-18
ER

PT J
AU Kazemi, V
   Shahzadi, A
   Bizaki, HK
AF Kazemi, Vahdat
   Shahzadi, Ali
   Bizaki, Hossein Khaleghi
TI Multifocus image fusion using adaptive block compressive sensing by
   combining spatial frequency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multifocus image fusion; Adaptive block compressive sensing; Spatial
   frequency; Fusion rule; Consistency verification
AB Image fusion is an important branch of the image processing field that makes fuse different information of multiple optical sensors images from the same scene into one complete image. The fused image includes a more dependable and informative description of the scene. With the development of compressive sensing (CS) theory, the compressive domain image fusion method attracts more and more attention. The sampling rate assignment policy for measurement matrix is one of the most important steps in CS and plays a critical role in compression and reconstruction. In this paper, we present a novel multifocus image fusion technique using adaptive sampling rate for block compressive sensing based on textural feature. Firstly, the spatial frequency is utilized to extract the textural features of image blocks. This was then used for adaptive measurement and combining rule. Secondly, the blocks which have large spatial frequency values (e.g., blocks with edges and textures) were assigned high sampling rates. Finally, the combined image was reconstructed with the smooth projected Landweber algorithm. The simulation results show that the proposed method has better performance, in both subjective and objective terms, with respect to the conventional methods.
C1 [Kazemi, Vahdat; Shahzadi, Ali] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
   [Bizaki, Hossein Khaleghi] Malek Ashtar Univ Technol, Dept Elect & Comp Engn, Tehran, Iran.
C3 Semnan University; Malek Ashtar University of Technology
RP Kazemi, V (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM Vandat.kazerni@semnan.ac.ir; Shahzadi@semnan.ac.ir; Bizaki@gmail.com
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen Y, 2015, FRONT INFORM TECH EL, V16, P227, DOI 10.1631/FITEE.1400217
   Cheng F, 2014, COMM COM INF SC, V484, P107
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eldar Y. C., 2012, COMPRESSED SENSING T
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Juanjuan Han, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P1463, DOI 10.1109/ICALIP.2010.5684502
   Kaur G, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1420, DOI 10.1109/ICEEOT.2016.7754918
   Kazemi V, 2014, IRAN CONF ELECTR ENG, P1668, DOI 10.1109/IranianCEE.2014.6999806
   Kutyniok G., 2013, GAMMMitteilungen, V36, P79, DOI DOI 10.1002/GAMM.201310005
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li Weiwei, 2014, [The Journal of China Universities of Posts and Telecommunications, 中国邮电高校学报], V21, P68
   Li X, 2011, IET IMAGE PROCESS, V5, P141, DOI 10.1049/iet-ipr.2010.0084
   Lin BH, 2016, INT CONF ACOUST SPEE, P1432, DOI 10.1109/ICASSP.2016.7471913
   Liu F, 2013, LECT NOTES ELECTR EN, V256, P803, DOI 10.1007/978-3-642-38466-0_89
   Liu S-S, 2013, P 2 INT C COMP SCI E
   Luo XY, 2009, IEEE IMAGE PROC, P2205, DOI 10.1109/ICIP.2009.5413866
   Luo XY, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3478879
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Petrovic V, 2015, INFORM FUSION, V22, P119, DOI 10.1016/j.inffus.2014.05.002
   Qaisar S, 2013, J COMMUN NETW-S KOR, V15, P443, DOI 10.1109/JCN.2013.000083
   Qiao W, 2012, IEEE IMAGE PROC, P909, DOI 10.1109/ICIP.2012.6467008
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Wan T, 2011, INT J COMPUT MATH, V88, P3915, DOI 10.1080/00207160.2011.598229
   Wan T, 2008, IEEE IMAGE PROC, P1308, DOI 10.1109/ICIP.2008.4712003
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang S-L, INT S PHOT DET IM 20
   Yang SL, 2013, PROC SPIE, V8910, DOI 10.1117/12.2033808
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
   Zhang Q, 2016, INFRARED PHYS TECHN, V74, P11, DOI 10.1016/j.infrared.2015.11.003
   Zheng Hai-bo, 2013, Journal of China Universities of Posts and Telecommunications, V20, P97, DOI 10.1016/S1005-8885(13)60056-4
NR 40
TC 3
Z9 3
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15153
EP 15170
DI 10.1007/s11042-022-12072-2
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600018
DA 2024-07-18
ER

PT J
AU Khayyat, MM
   Elrefaei, LA
AF Khayyat, Manal M.
   Elrefaei, Lamiaa A.
TI Deep reinforcement learning approach for manuscripts image
   classification and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reinforcement learning; Image retrieval; Deep features fusion;
   Locality-sensitive hashing
AB The automatic classification and retrieval of images is a challenging task, especially when dealing with low-quality and faded inks images, such as the historical manuscripts. Therefore, in this study we develop a reinforcement learning agent that is capable of interacting with an environment including historical Arabic manuscript images and retrieve the most similar images to a query image. First, the deep visual features of the images are extracted utilizing the pre-trained VGG19 convolutional neural network. Then, the associated deep textual features of the images are also extracted utilizing the attentional BiLSTM deep learning model. Both features are fused using the concatenation merge layer and hashed to reduce the dimensionality among the fused feature vectors for better image classification and retrieval. The proposed method tested on a manually collected dataset and recorded a promising high accuracy proved that the computer vision could be better performing than the humans' vision.
C1 [Khayyat, Manal M.] Umm Al Qura Univ, Comp Sci Dept, Deanship Preparatory Year Joint Med Track, Mecca, Saudi Arabia.
   [Elrefaei, Lamiaa A.] Benha Univ, Fac Engn Shoubra, Elect Engn Dept, Cairo, Egypt.
C3 Umm Al Qura University; Egyptian Knowledge Bank (EKB); Benha University
RP Khayyat, MM (corresponding author), Umm Al Qura Univ, Comp Sci Dept, Deanship Preparatory Year Joint Med Track, Mecca, Saudi Arabia.
EM mmkhayat@uqu.edu.sa; lamia.alrefaai@feng.bu.edu.eg
RI Elrefaei, Lamiaa/ABB-5716-2021; Khayyat, Manal/GRF-1380-2022; Khayyat,
   Dr. Manal M./GRF-1399-2022
OI Elrefaei, Lamiaa/0000-0001-5781-2251; Khayyat, Dr. Manal
   M./0000-0003-0830-4757
FU Deanship of Scientific Research at Umm Al-Qura University
   [22UQU4400271DSR02]
FX The authors would like to thank the Deanship of Scientific Research at
   Umm Al-Qura University for supporting this work by Grant Code:
   (22UQU4400271DSR02)
CR Al Aghbari Z, 2009, INT CONF RES CHAL, P217, DOI 10.1109/RCIS.2009.5089285
   Alam M, 2020, K NEAREST NEIGHBORS
   Bandyopadhyay S., 2017, P 18 INT C DISTR COM, P1
   Bawa M, 2005, INT WORLD WID WEB C, P1
   Bozas K, 2012, LECT NOTES COMPUT SC, V7431, P210, DOI 10.1007/978-3-642-33179-4_21
   Brownlee J., 2020, GENTLE INTRO THRESHO
   Chen TS, 2018, AAAI CONF ARTIF INTE, P6730
   El Makhfi N, 2019, ADV SCI TECHNOL ENG, V4, P99, DOI DOI 10.25046/AJ040612
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kekre HB, 2011, CONTENT BASED IMAGE, P284
   Khayyat M, 2020, INT ARAB J INFORM TE, V17
   Khayyat MM, 2020, IEEE ACCESS, V8, P136460, DOI 10.1109/ACCESS.2020.3010882
   Khayyat MM, 2020, INT J COMPUT DIGITAL, V9, P1
   Lin EL, 2020, APPL INTELL, V50, P2488, DOI 10.1007/s10489-020-01637-z
   Marr B., 2018, Forbes
   Mysiak K, 2020, CLASSIFICATION METRI
   Nie WZ, 2019, IEEE IMAGE PROC, P2389, DOI [10.1109/ICIP.2019.8803343, 10.1109/icip.2019.8803343]
   Othman, 2015, THESIS KING FAHD U P, P1
   Peng Y., 2018, ARXIV180202904, V2, P1
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Schuderer A, 2021, SIM ENV DECOUPLING O, V1, P1
   Shi XS, 2018, PATTERN RECOGN, V81, P14, DOI 10.1016/j.patcog.2018.03.015
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Varga D, 2016, IEEE SYS MAN CYBERN, P2636, DOI 10.1109/SMC.2016.7844637
   Wang H, 2020, MULTIMED TOOLS APPL, V79, P15015, DOI 10.1007/s11042-020-08668-1
   Wang J., 2014, CoRR
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yahia, 2011, THESIS KING FAHD U P, P1
   Yao J, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2298, DOI 10.1145/3366423.3380294
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhou JH, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2842, DOI 10.1145/3366423.3380047
   2012, ADAPT LEARN OPTIM, V12, P1
NR 36
TC 2
Z9 2
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15395
EP 15417
DI 10.1007/s11042-022-12572-1
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600016
DA 2024-07-18
ER

PT J
AU Paul, A
   Kandar, S
AF Paul, Aakash
   Kandar, Shyamalendu
TI Simultaneous encryption of multiple images using pseudo-random sequences
   generated by modified Newton-Raphson technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pseudo random sequence; Chaos; Non-chaotic technique; Numerical
   analysis; Newton-Raphson method; Multiple-image encryption technique;
   NIST randomness test
ID WAVELET TRANSFORM; MAP; ALGORITHM; OPERATION; CHAOS
AB A multiple image encryption using pseudo random (PR) sequence is proposed in this article. A non-chaotic technique pillared on modified Newton- Raphson method is applied to produce the PR sequence. To do that, a tangent is drawn to the given function from a middle point of two seed values. The fraction part of the function computed at the intersecting point of the tangent with X - axis is applied to produce the PR sequence. NIST test says in support of the randomness of the PR sequence. The encryption of the plaintext images are achieved by row wise gray value substitution and multi image iterated addition with bitwise circular shift operation. The process makes the plaintext images noise like. Simulation results are presented to exhibit the validity of the proposed method and security analysis proves its immunity against different attacks. Comparison with some recent state of the art chaotic map based schemes provides it a strong base in multiple-image encryption technique.
C1 [Paul, Aakash; Kandar, Shyamalendu] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Kandar, S (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
EM aakash18iiest@gmail.com; shyamalenduk@it.iiests.ac.in
CR Abdullah Hikmat N., 2017, 2017 International Conference on Current Research in Computer Science and Information Technology (ICCIT), P121, DOI 10.1109/CRCSIT.2017.7965545
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Almalkawi IT, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102384
   Alqaralleh Bassam A. Y., 2024, Personal and Ubiquitous Computing, V28, P17, DOI 10.1007/s00779-021-01543-2
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Das Subhajit, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P19, DOI 10.1007/978-981-10-7566-7_3
   Das S, 2017, IEEE ICC
   Deb S, 2021, MULTIMED TOOLS APPL, V80, P19803, DOI 10.1007/s11042-020-10308-7
   Dey D, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.52
   Elshamy AM, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0461-x
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Galántai A, 2000, J COMPUT APPL MATH, V124, P25, DOI 10.1016/S0377-0427(00)00435-0
   Han FL, 2006, ISSCAA 2006: 1ST INTERNATIONAL SYMPOSIUM ON SYSTEMS AND CONTROL IN AEROSPACE AND ASTRONAUTICS, VOLS 1AND 2, P1273
   Hikal NA, 2020, J KING SAUD UNIV-COM, V32, P870, DOI 10.1016/j.jksuci.2018.09.006
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang ZJ., 2000, OPT LASER ENG, V124
   Hwang HC, 2016, WIRELESS PERS COMMUN, V91, P1765, DOI 10.1007/s11277-016-3398-2
   Ibrahim S, 2020, IEEE ACCESS, V8, P160433, DOI 10.1109/ACCESS.2020.3020746
   Jiang N, 2019, INT J THEOR PHYS, V58, P979, DOI 10.1007/s10773-018-3989-7
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li HJ, 2011, OPT LASER ENG, V49, P753, DOI 10.1016/j.optlaseng.2011.03.017
   Li XY, 2018, OPT LASER ENG, V102, P106, DOI 10.1016/j.optlaseng.2017.10.023
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Lidong L, 2020, IEEE ACCESS, V8, P210382, DOI 10.1109/ACCESS.2020.3039891
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Liu S, 2023, INTERACT LEARN ENVIR, V31, P3340, DOI 10.1080/10494820.2021.1927115
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu S, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106537
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Luo YL, 2018, IEEE ACCESS, V6, P77740, DOI 10.1109/ACCESS.2018.2884013
   Mohammed EA, 2019, J PHYS CONF SER, V1234, DOI 10.1088/1742-6596/1234/1/012037
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Pan XM, 2015, APPL OPTICS, V54, P8485, DOI 10.1364/AO.54.008485
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Rajagopalan S., 2018, 2018 international conference on computer communication and informatics (ICCCI), P1, DOI 10.1109/ICCCI.2018.8441284
   Rakheja P, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-020-2219-8
   Ramasamy J, 2020, WIRELESS PERS COMMUN, V112, P1355, DOI 10.1007/s11277-020-07106-7
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Saravanan S, 2021, SOFT COMPUT, V25, P5299, DOI 10.1007/s00500-020-05528-w
   Shah AA, 2020, J REAL-TIME IMAGE PR, V17, P2139, DOI 10.1007/s11554-020-01008-4
   Shao ZH, 2021, MULTIMED TOOLS APPL, V80, P8973, DOI 10.1007/s11042-020-09961-9
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Sui LS, 2013, OPT LETT, V38, P1996, DOI 10.1364/OL.38.001996
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wahby Shalaby Mohamed A., 2020, 2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES), P288, DOI 10.1109/NILES50944.2020.9257876
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiong Y, 2018, OPT LASER ENG, V101, P113, DOI 10.1016/j.optlaseng.2017.10.010
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou KL, 2019, DIGIT SIGNAL PROCESS, V93, P115, DOI 10.1016/j.dsp.2019.07.013
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 69
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14355
EP 14378
DI 10.1007/s11042-022-12210-w
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300009
DA 2024-07-18
ER

PT J
AU Yang, QM
   Yu, L
   Tian, SW
   Song, JM
AF Yang, Qimeng
   Yu, Long
   Tian, Shengwei
   Song, Jinmiao
TI Word-level and phrase-level strategies for figurative text
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metaphor detection; Attention mechanism; Phrase level; Word level; Deep
   learning
ID EMPIRICAL MODE DECOMPOSITION
AB Metaphors are a common language tool used in communication that widely exist in natural language. Metaphor detection is beneficial to improving the performance of natural language processing tasks such as machine translation. The current metaphor detection method captures the semantic incoherence of the metaphorical word and its surrounding text. However, it ignores the different contributions of phrases and words. In addition, word information and its contextual information should be deeply integrated. We propose a learning framework that combines word representations, contextual representations and combined representations. Specifically, we establish word-level and phrase-level attention mechanisms to learn enhanced feature representations. For the word-level attention, we extract word embedding, part-of-speech (POS) and distance features as multilevel representations and use multi-attention to obtain weight information. For the phrase-level attention, the IndRNN and self-attention are employed to obtain the deep semantic representation of the sentence. By using this strategy, our model has the ability to mine richer semantic representations. Experiments on the VUA metaphor corpus show that our method achieves an F-score of 69.7% on the test dataset, thereby surpassing the scores of all the existing models by a considerable margin.
C1 [Yang, Qimeng; Song, Jinmiao] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830000, CO, Peoples R China.
   [Yu, Long] Xinjiang Univ, Network Ctr, Urumqi 830000, CO, Peoples R China.
   [Tian, Shengwei] Xinjiang Univ, Sch Software, Urumqi 830000, CO, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University
RP Yu, L (corresponding author), Xinjiang Univ, Network Ctr, Urumqi 830000, CO, Peoples R China.
EM yqm_xju@163.com; yul@xju.edu.cn; tianshengwei@163.com; sjm@dhm.edu.cn
RI Wang, Zhi/GZB-2713-2022
OI Wang, Zhi/0000-0001-6952-8848; Yu, Long/0000-0002-9038-4129
FU National Natural Science Foundation of China [61962057]; Key Program of
   the National Natural Science Foundation of China [U2003208]; Major
   Science and Technology Projects in the Autonomous Region [2020A03004-4]
FX We thank the anonymous reviewers for their insightful comments. This
   work was supported by the National Natural Science Foundation of China
   (61962057), the Key Program of the National Natural Science Foundation
   of China (U2003208), and the Major Science and Technology Projects in
   the Autonomous Region (2020A03004-4).
CR Assaf D, 2013, 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE, COGNITIVE ALGORITHMS, MIND, AND BRAIN (CCMB), P60, DOI 10.1109/CCMB.2013.6609166
   Cameron L., 2003, METAPHOR ED DISCOURS
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Crisp P, 2007, METAPHOR SYMBOL, V22, P1
   Del Tredici M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4573
   Dinh Do, 2016, P 4 WORKSH MET NLP, P28, DOI [10.18653/v1/W16-1104, DOI 10.18653/V1/W16-1104]
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Gao G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P607
   Hanks P, 2004, INT J LEXICOGR, V17, P245, DOI 10.1093/ijl/17.3.245
   Hinton G. E., 2012, 12070580 ARXIV
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Huang, 2014, INT J COMPUTATIONAL, V19
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Iwendi C, 2020, COMPUT COMMUN, V161, P160, DOI 10.1016/j.comcom.2020.07.032
   Klebanov BB, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P101
   Lakoff G., 2003, METAPHORS WE LIVE
   Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683
   Mohler Michael, 2013, P 1 WORKSH MET NLP, P27
   Mykowiecka A, 2018, P WORKSH FIG LANG PR, P24
   Neuman Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062343
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Pramanick M, 2018, Proceedings of the Workshop on Figurative Language Processing, P67, DOI DOI 10.18653/V1/W18-0908
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rai S, 2016, P 4 WORKSH MET NLP S, P18
   Rei Marek, 2017, P 2017 C EMP METH NA, P1537, DOI [DOI 10.18653/V1/D17-1162, 10.18653/v1/D17-1162]
   Shutova E, 2010, LREC, V2, P222
   Shutova E., 2016, PROC C N AM CHAPTER, P160, DOI [10.18653/V1/N16-1020, DOI 10.18653/V1/N16-1020]
   Shutova E, 2017, COMPUT LINGUIST, V43, P71, DOI 10.1162/COLI_a_00275
   Steen G. J., 2010, A Method for Linguistic Metaphor Identification: from MIP to MIPVU, DOI 10.1075/celcr.14
   Stowe Kevin, 2019, P 23 C COMPUTATIONAL, P362
   Swarnkar K, 2018, Proceedings of the Workshop on Figurative Language Processing, P115, DOI DOI 10.18653/V1/W18-0914
   Tsvetkov Y, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P248
   Turney Peter, 2011, P 2011 C EMPIRICAL M, P680
   Wu C, 2018, P WORKSH FIG LANG PR, P110, DOI 10.18653/v1/W18-0913
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 35
TC 0
Z9 0
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14339
EP 14353
DI 10.1007/s11042-022-12233-3
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300013
DA 2024-07-18
ER

PT J
AU Garg, A
   Nayyar, A
   Singh, AK
AF Garg, Ankit
   Nayyar, Anand
   Singh, Anuj Kumar
TI Improved seam carving for structure preservation using efficient energy
   function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam carving; Saliency detection; Edge-detection;
   Content-aware-retargeting; Multi-operator; Image quality assessment
   (IQA)
ID IMAGE; SIMILARITY
AB To reduce the consumption of power and making the handling of display devices easy the manufacturers are reducing the size of the screen. To fit the visual contents into the small screen of display devices without any image deformation development of an efficient image retargeting technique is required. The traditional seam carving technique is widely used to change the aspect ratio of the image. This technique produces the distortions on the prominent line segments when the successive optimal seam starts intersecting at the same location on their structure. In this paper, an improved seam carving technique is proposed which overcomes the limitation of the traditional seam carving technique. The novelty of the proposed technique is to restrict the occurrence of intersection by the optimal seams at the same location on the line structures and bypass them at the nearby locations. To meet this objective the proposed technique performs the energy enhancement operation at the intersection point. To justify the effectiveness of the proposed technique, the obtained results are compared and analyzed using subjective and objective image quality assessment (IQA) methods. In the subjective analysis, the observers provide their opinions about deformations on three quality parameters namely luminance (l), color (c), and structure (s). In the objective assessment, the structural similarity index measure (SSIM) generated various SSIM index values based on these parameters. After the IQA assessment, it is found that the average percentage similarly obtained from the traditional seam carving technique is 64.03% while in the case of the proposed technique it is 70.87%. The high percentage of similarity among all state of art justify the efficiency of the proposed technique.
C1 [Garg, Ankit; Singh, Anuj Kumar] Amity Univ, Gurugram 122413, Haryana, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 Duy Tan University; Duy Tan University
RP Garg, A (corresponding author), Amity Univ, Gurugram 122413, Haryana, India.
EM ankitgitm@gmail.com
RI Singh, Dr. Anuj Kr./HGB-0160-2022; Nayyar, Anand/F-3732-2015; Singh,
   Anuj Kumar/ABF-9762-2021; Garg, Ankit/ABD-9886-2020
OI Nayyar, Anand/0000-0002-9821-6146; Garg, Dr. Ankit/0000-0002-6466-2738
CR Afshar F, 2017, IRAN CONF MACH, P58, DOI 10.1109/IranianMVIP.2017.8342369
   Andreadis I., 2005, P IEEE INSTR MEAS TE, V3, P2028, DOI DOI 10.1109/IMTC.2005.1604529
   [Anonymous], 2005, P 18 ANN ACM S US IN
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Chang CH, 2012, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2012.6247786
   Chen JS, 2016, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2016.61
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Choi J, 2016, J SIGNAL PROCESS SYS, V85, P275, DOI 10.1007/s11265-015-1084-3
   Cui J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107242
   Dong WM, 2012, J COMPUT SCI TECH-CH, V27, P121, DOI 10.1007/s11390-012-1211-6
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2129-x
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Gal R., 2006, RENDERING TECHNIQUES, P2
   Garg A, 2020, IET IMAGE PROCESS, V14, P2965, DOI 10.1049/iet-ipr.2019.1032
   Garg A, 2020, KSII T INTERNET INF, V14, P2997, DOI 10.3837/tiis.2020.07.015
   Garg A, 2021, SIGNAL IMAGE VIDEO P, V15, P185, DOI 10.1007/s11760-020-01736-x
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Guo YC, 2018, SIGNAL PROCESS-IMAGE, V67, P171, DOI 10.1016/j.image.2018.06.010
   Han DI, 2005, LECT NOTES COMPUT SC, V3656, P1258
   Hashemzadeh M, 2019, SIGNAL PROCESS, V155, P233, DOI 10.1016/j.sigpro.2018.09.037
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu WY, 2014, IEEE J EM SEL TOP C, V4, P70, DOI 10.1109/JETCAS.2014.2298259
   Huo LN, 2016, PATTERN RECOGN, V49, P162, DOI 10.1016/j.patcog.2015.07.005
   Israni S, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3561, DOI 10.1109/ICEEOT.2016.7755367
   Jiang W, 2009, 2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P895, DOI 10.1109/ASICON.2009.5351551
   Kiess J, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3231598
   Kiess J, 2012, PROC SPIE, V8304, DOI 10.1117/12.906386
   Kiess J, 2010, PROC SPIE, V7542, DOI 10.1117/12.840263
   Kim CH, 2003, IEEE T CIRC SYST VID, V13, P549, DOI 10.1109/TCSVT.2003.813431
   Kopf S, 2009, MULTIMEDIA MOBILE DE, V7256
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Liang Y, 2017, IEEE T VIS COMPUT GR, V23, P1099, DOI 10.1109/TVCG.2016.2517641
   Liang Y, 2013, IEEE COMPUT GRAPH, V33, P68, DOI 10.1109/MCG.2012.123
   Liang Y, 2012, SIGNAL PROCESS, V92, P1243, DOI 10.1016/j.sigpro.2011.11.018
   Lifang Wu, 2014, Journal of Multimedia, V9, P483, DOI 10.4304/jmm.9.4.483-492
   Liu Z, 2010, OPT ENG, V49, DOI 10.1117/1.3281667
   Mohammadi Pedram, 2014, Majlesi Journal of Electrical Engineering
   Muñoz A, 2001, IEEE T IMAGE PROCESS, V10, P1365, DOI 10.1109/83.941860
   Othman Z, 2018, LECT NOTE DATA ENG, V5, P316, DOI 10.1007/978-3-319-59427-9_34
   Palubinskas G, 2017, INT J IMAGE DATA FUS, V8, P32, DOI 10.1080/19479832.2016.1273259
   Panozzo D, 2012, COMPUT GRAPH FORUM, V31, P229, DOI 10.1111/j.1467-8659.2012.03001.x
   Patel Diptiben, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P89, DOI 10.1007/978-981-10-7898-9_8
   Patel D, 2019, IET IMAGE PROCESS, V13, P885, DOI 10.1049/iet-ipr.2018.5283
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Senturk ZK., 2019, 2019 1 INT INFORMATI, P1, DOI [10.1109/UBMYK48245.2019.8965618, DOI 10.1109/UBMYK48245.2019.8965618]
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Shafieyan F, 2017, SIGNAL PROCESS-IMAGE, V50, P34, DOI 10.1016/j.image.2016.10.006
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Tomaszewska AL., 2016, J ELECTRON IMAGING, V25
   Vaquero D, 2010, PROC SPIE, V7798, DOI 10.1117/12.862419
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Xuan L, 2017, INT CONF SOFTW ENG, P275, DOI 10.1109/ICSESS.2017.8342913
   Yan B, 2015, IEEE T CIRC SYST VID, V25, P15, DOI 10.1109/TCSVT.2014.2329374
   Yang L, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14018
   Yihjia Tsai, 2013, Applied Mechanics and Materials, V385-386, P1453, DOI 10.4028/www.scientific.net/AMM.385-386.1453
   Zaifeng Shi, 2008, 2008 International Conference on Neural Networks and Signal Processing, P388, DOI 10.1109/ICNNSP.2008.4590378
   Zeng H, 2019, PROC CVPR IEEE, P5942, DOI 10.1109/CVPR.2019.00610
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P8067, DOI 10.1007/s11042-016-3318-1
   Zhou B, 2016, J VIS COMMUN IMAGE R, V41, P21, DOI 10.1016/j.jvcir.2016.09.002
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2376-5
NR 72
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12883
EP 12924
DI 10.1007/s11042-022-12003-1
EA FEB 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000759366800002
DA 2024-07-18
ER

PT J
AU Li, CL
   Liu, JH
   Zhu, JJ
   Zhang, WZ
   Bi, LH
AF Li, Canlin
   Liu, Jinhua
   Zhu, Jinjuan
   Zhang, Weizheng
   Bi, Lihua
TI Mine image enhancement using adaptive bilateral gamma adjustment and
   double plateaus histogram equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mine image enhancement; Cuckoo search; HSV color space; Image with
   non-uniform illumination
ID CONTRAST ENHANCEMENT; RETINEX; ALGORITHM
AB Due to the lack of underground space and lighting in coal mine, there are some problems in the mine image, such as poor contrast, uneven illumination, blurred edge and so on. A mine image enhancement method based on cuckoo search is proposed in this paper. This method is based on HSV color space, and uses the Cuckoo Search (CS) algorithm combined with the proposed new conversion function, which utilizes the benefits of both bilateral gamma adjustment (BIGA) function and double plateaus histogram equalization (DPHE). The average brightness is integrated into the evaluation function, and entropy, brightness difference and gray standard variance are used as the objective function of each bird nest to evaluate the mine image enhancement results. The contrast and brightness of image are globally enhanced by finding the optimal parameter values, and the detail enhancement of mine image is achieved. The experimental results show that compared with other traditional and latest image enhancement algorithms, the proposed method can significantly improve the brightness and contrast of mine images, and the image details are richer, and the visual effect is greatly improved.
C1 [Li, Canlin; Zhu, Jinjuan; Zhang, Weizheng; Bi, Lihua] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, 136 Kexue Rd, Zhengzhou 450000, Peoples R China.
   [Liu, Jinhua] Shanghai Univ, Shanghai Film Acad, 149 Yanchang Rd, Shanghai 200072, Peoples R China.
C3 Zhengzhou University of Light Industry; Shanghai University
RP Li, CL (corresponding author), Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, 136 Kexue Rd, Zhengzhou 450000, Peoples R China.; Liu, JH (corresponding author), Shanghai Univ, Shanghai Film Acad, 149 Yanchang Rd, Shanghai 200072, Peoples R China.
EM lcl_zju@aliyun.com; jinhua1427@hotmail.com
RI Li, Can-Lin/GNP-3900-2022
OI Zhang, Weizheng/0000-0002-6838-0850
FU Science and Technology Planning Project of Henan Province [212102210097]
FX This work was supported by the Science and Technology Planning Project
   of Henan Province under Grant 212102210097.
CR Agrawal S, 2012, LECT NOTES COMPUT SC, V7677, P82, DOI 10.1007/978-3-642-35380-2_11
   Al-Ameen Z, 2019, IET IMAGE PROCESS, V13, P1314, DOI 10.1049/iet-ipr.2018.6585
   Chen Zhi-gang, 2008, Optics and Precision Engineering, V16, P2030
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Daniel E, 2015, OPTIK, V126, P1726, DOI 10.1016/j.ijleo.2015.05.027
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   Gao QQ, 2011, C IND ELECT APPL, P234, DOI 10.1109/ICIEA.2011.5975586
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P266, DOI 10.5201/ipol.2012.g-ace
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Li P, 2018, CHIN CONTR CONF, P9584, DOI 10.23919/ChiCC.2018.8483674
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Paul A, 2018, IET IMAGE PROCESS, V12, P1617, DOI 10.1049/iet-ipr.2017.1088
   Petrol AB, 2014, IMAGE PROCESS ON LIN, V4, P71, DOI 10.5201/ipol.2014.107
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rahman SMM, 2010, IET IMAGE PROCESS, V4, P374, DOI 10.1049/iet-ipr.2009.0163
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Rao S.S., 2009, ENG OPTIMIZATION THE, DOI DOI 10.1002/9780470549124
   Song XD, 2016, INT C INTEL HUM MACH, P183, DOI 10.1109/IHMSC.2016.27
   Song Yan-feng, 2008, Infrared Laser Engineering, V37, P308
   Wang DW, 2018, ACTA PHYS SIN-CH ED, V67, DOI 10.7498/aps.67.20181288
   Wang W, 2008, INT C WAVEL ANAL PAT, P80, DOI 10.1109/ICWAPR.2008.4635754
   Wang ZC, 2012, ADV MATER RES-SWITZ, V468-471, P204, DOI 10.4028/www.scientific.net/AMR.468-471.204
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 37
TC 8
Z9 8
U1 12
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12643
EP 12660
DI 10.1007/s11042-022-12407-z
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758977800002
DA 2024-07-18
ER

PT J
AU Dey, R
   Balabantaray, RC
   Mohanty, S
AF Dey, Raghunath
   Balabantaray, Rakesh Chandra
   Mohanty, Sanghamitra
TI Offline Odia handwritten character recognition with a focus on compound
   characters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bounding box; Median blur filtering; Odia compound characters; Machine
   learning classifiers
AB Recognition of Odia character images is one of the ongoing applications of offline OCR. An attempt has been made here to develop an efficient feature extraction procedure that can assist the recognition of Odia handwritten digits, basic characters, and compound characters. Three different kinds of strategies have been carried here for character recognition. First, the various characters are recognized using three feature extraction procedures individually, followed by a merged feature set with a set of standard machine learning algorithms. In the second approach, the recognition of the characters is performed by popular RNN and CNN by providing the same feature set instead of giving immediate images, unlike traditional networks. The same feature sets, as well as classifiers, are applied to recognize different categories of characters. The third task was to incorporate a set of Odia compound characters into our suggested character recognition framework. The dataset that has been created for this purpose consists of numerals, basic characters, and compound characters. The proposed method achieves a recognition accuracy of 86.56% on this dataset with 112 classes of characters.
C1 [Dey, Raghunath; Balabantaray, Rakesh Chandra] Int Inst Informat Technol, Bhubaneswar, India.
   [Mohanty, Sanghamitra] Sri Sri Univ, Cuttack, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Dey, R (corresponding author), Int Inst Informat Technol, Bhubaneswar, India.
EM c118003@iiit-bh.ac.in; rakesh@iiit-bh.ac.in; sangham1@rediffmail.com
OI Dey, Raghunath/0000-0002-0295-8189
CR Agrawal P, 2021, MULTIMED TOOLS APPL, V80, P5319, DOI 10.1007/s11042-020-09818-1
   [Anonymous], 1981, Median filtering: statistical properties, DOI DOI 10.1007/BFB0057597
   [Anonymous], 2014, INDIAN J SCI TECHNOL
   BARUCH O, 1988, PATTERN RECOGN LETT, V8, P271, DOI 10.1016/0167-8655(88)90034-7
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Bhowmik TK, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P105
   Das D, 2018, POLITICS OF SWIDDEN FARMING: ENVIRONMENT AND DEVELOPMENT IN EASTERN INDIA, P1
   Das D, 2020, MULTIMED TOOLS APPL, V79, P33023, DOI 10.1007/s11042-020-09457-6
   Das D, 2019, MULTIMED TOOLS APPL, V78, P19495, DOI 10.1007/s11042-019-7330-0
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Dash, 2020, ARXIV200401551
   Dash KS, 2017, ARTIF INTELL REV, V48, P473, DOI 10.1007/s10462-016-9507-5
   Dash KS, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P187
   Dash KS, 2014, IEEE REGION 10 SYMP, P531, DOI 10.1109/TENCONSpring.2014.6863091
   Dash KS, 2015, IET IMAGE PROCESS, V9, P874, DOI 10.1049/iet-ipr.2015.0146
   Dey Raghunath, 2019, 2019 International Conference on Information Technology (ICIT), P178, DOI 10.1109/ICIT48102.2019.00038
   DEY R, 2021, MULTIMED TOOLS APPL
   Dey Raghunath, 2020, IEEE INT C ELECT COM, P1
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Huh JH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060890
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Jindal T, 2013, P 4 INT WORKSH MULT, P1
   Kaur RP, 2020, MULTIMED TOOLS APPL, V79, P7435, DOI 10.1007/s11042-019-08365-8
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Maalej R, 2020, MULTIMED TOOLS APPL, V79, P17969, DOI 10.1007/s11042-020-08740-w
   Majhi B, 2018, ARAB J SCI ENG, V43, P3887, DOI 10.1007/s13369-017-2652-6
   Maswadi K, 2021, MULTIMED TOOLS APPL, V80, P21709, DOI 10.1007/s11042-020-10447-x
   Mohapatra RK, 2015, NAT CONF COMPUT VIS
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal U, 2007, PROC INT CONF DOC, P749
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Rehman A, 2019, MULTIMED TOOLS APPL, V78, P10889, DOI 10.1007/s11042-018-6577-1
   Roy K, 2005, PROC INT CONF DOC, P770, DOI 10.1109/ICDAR.2005.183
   Roy S, 2017, PATTERN RECOGN LETT, V90, P15, DOI 10.1016/j.patrec.2017.03.004
   Sebti A, 2017, MULTIMED TOOLS APPL, V76, P23589, DOI 10.1007/s11042-016-4129-0
   Sethy A., 2020, MACH VIS INSPECTION, V1, P197, DOI DOI 10.1002/9781119682042.CH9
   Sethy A, 2018, ADV INTELL SYST COMP, V563, P187, DOI 10.1007/978-981-10-6872-0_18
   Sethy A, 2017, INT CONF COMPUT INT, P83, DOI 10.1109/CINE.2017.27
   Sethy A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1099, DOI 10.1109/CCAA.2016.7813880
   Sethy Abhisek, 2019, INT J INNOV TECHNOL, V8, P788, DOI DOI 10.35940/IJITEE.I7787.078919
   Singh PK, 2018, MULTIMED TOOLS APPL, V77, P8441, DOI 10.1007/s11042-017-4745-3
   Tripathy N., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5296, P174, DOI 10.1117/12.530230
NR 42
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10469
EP 10495
DI 10.1007/s11042-022-12148-z
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700027
DA 2024-07-18
ER

PT J
AU Guo, JK
   Lv, ZH
AF Guo, Jinkang
   Lv, Zhihan
TI Application of Digital Twins in multiple fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital Twins; Virtual reality; Industry; Personalized medicine;
   Aerospace; Logistics
ID CHALLENGES; SYSTEM; HEALTH; TIME
AB With the development of science and technology, the high-tech industry is developing rapidly, and various new-age technologies continue to appear, and Digital Twins (DT) is one of them. As a brand-new interactive technology, DT technology can handle the interaction between the real world and the virtual world well. It has become a hot spot in the academic circles of all countries in the world. DT have developed rapidly in recent years result from centrality, integrity and dynamics. It is integrated with other technologies and has been applied in many fields, such as smart factory in industrial production, digital model of life in medical field, construction of smart city, security guarantee in aerospace field, immersive shopping in commercial field and so on. The introduction of DT is mostly a summary of concepts, and few practical applications of Digital Twins are introduced. The purpose of this paper is to enable people to understand the application status of DT technology. At the same time, the introduction of core technologies related to DT is interspersed in the application introduction. Finally, combined with the current development status of DT, predict the future development trend of DT and make a summary.
C1 [Guo, Jinkang] Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Peoples R China.
   [Lv, Zhihan] Uppsala Univ, Fac Arts, Dept Game Design, Uppsala, Sweden.
C3 Qingdao University; Uppsala University
RP Lv, ZH (corresponding author), Uppsala Univ, Fac Arts, Dept Game Design, Uppsala, Sweden.
EM lvzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074;
   Jinkang, Guo/0000-0003-2633-6314
FU Uppsala University; National Natural Science Foundation of China
   [61902203]
FX Open access funding provided by Uppsala University. This work was
   supported in part by the National Natural Science Foundation of China
   (No. 61902203).
CR Agalianos K, 2020, PROCEDIA MANUF, V51, P1636, DOI 10.1016/j.promfg.2020.10.228
   Ahmadi-Assalemi G., 2020, Cyber Defence in the Age of AI, Smart Societies and Augmented Humanity, P133, DOI [10.1007/978-3-030-35746-7_8, DOI 10.1007/978-3-030-35746-7_8]
   Albraikan A, 2020, CONNECTED HLTH SMART
   Allam Z, 2021, LAND USE POLICY, V101, DOI 10.1016/j.landusepol.2020.105201
   [Anonymous], 2018, EXPLORING POSSIBILIT
   Assawaarayakul C, 2019, 2019 4TH TECHNOLOGY INNOVATION MANAGEMENT AND ENGINEERING SCIENCE INTERNATIONAL CONFERENCE (TIMES-ICON), DOI 10.1109/times-icon47539.2019.9024430
   August, 2019, ATZ PROD WORLDW, V6, P54, DOI [10.1007/s38312-019-0012-0, DOI 10.1007/S38312-019-0012-0]
   Bachelor G, 2020, IEEE SYST J, V14, P1568, DOI 10.1109/JSYST.2019.2925627
   Barat Souvik, 2019, 2019 Winter Simulation Conference (WSC), P157, DOI 10.1109/WSC40007.2019.9004694
   Barricelli BR, 2020, IEEE ACCESS, V8, P26637, DOI 10.1109/ACCESS.2020.2971576
   Benes F, 2017, PROCEEDINGS OF THE 14TH EAI INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING, NETWORKING AND SERVICES (MOBIQUITOUS 2017), P525, DOI 10.1145/3144457.3144516
   Björnsson B, 2019, GENOME MED, V12, DOI 10.1186/s13073-019-0701-3
   Bonitz L, 2019, SLEEP MED, V64, pS45
   Bouzguenda I, 2019, SUSTAIN CITIES SOC, V50, DOI 10.1016/j.scs.2019.101627
   Chinotaikul P., 2020, PROC 1 INT C BIG DAT, P1
   Clohessy T, 2014, INT CONF UTIL CLOUD, P836, DOI 10.1109/UCC.2014.136
   Cureton P., 2021, Shaping Smart for Better Cities, P267
   De Luca, 2020, P 2 WORKSH STRUCT UN
   DEMARTINI M, 2019, ADV PRODUCTION MANAG, V567
   Di Rienzo A., 2015, Proc. ACM Int. Joint Conf. Pervasive and Ubiquitous Computing and Proc. ACM Int. Symp. Wearable Comput, P779, DOI DOI 10.1145/2800835.2807955
   Dignan J, 2020, IET SMART CITIES, V2, P109, DOI 10.1049/iet-smc.2020.0071
   Du X, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P20, DOI 10.1109/UEMCON.2017.8248972
   Duan B, 2016, 2016 11 INT C REL MA, P1, DOI [10.1109/ICRMS.2016.8050073, DOI 10.1109/ICRMS.2016.8050073]
   Duan W., 2019, P ACM INT C PROCEEDI, P488
   El Saddik A, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.023121167
   Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358
   Pérez JG, 2017, DG.O 2017: THE PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL GOVERNMENT RESEARCH: INNOVATIONS AND TRANSFORMATIONS IN GOVERNMENT, P616, DOI 10.1145/3085228.3085265
   Glaessgen E., 2012, 53 AIAA ASME ASCE AH, DOI DOI 10.2514/6.2012-1818
   Golse N, 2021, J HEPATOL, V74, P661, DOI 10.1016/j.jhep.2020.10.036
   Guo JP, 2019, J AMB INTEL HUM COMP, V10, P1189, DOI 10.1007/s12652-018-0953-6
   Hanel Albrecht, 2020, Procedia CIRP, P1399, DOI 10.1016/j.procir.2020.04.017
   Ivanov S, 2020, 2020 GLOBAL SMART INDUSTRY CONFERENCE (GLOSIC), P178, DOI [10.1109/glosic50886.2020.9267879, 10.1109/GloSIC50886.2020.9267879]
   Kara A, 2018, ARTIF CELL NANOMED B, V46, pS264, DOI 10.1080/21691401.2018.1491478
   Kawabe K, 2013, P 5 INT C MAN EM DIG, P33, DOI [10.1145/2536146.2536178, DOI 10.1145/2536146.2536178]
   Kim HS, 2019, FASH TEXT, V6, DOI 10.1186/s40691-019-0187-z
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Laamarti F, 2020, IEEE ACCESS, V8, P105950, DOI 10.1109/ACCESS.2020.2999871
   Lindström D, 2008, ANN SURG, V248, P739, DOI 10.1097/SLA.0b013e3181889d0d
   LIU S, 2020, J MANUF SYST
   Liu Y, 2019, IEEE ACCESS, V7, P49088, DOI 10.1109/ACCESS.2019.2909828
   Lv ZH, 2020, FUTURE GENER COMP SY, V109, P103, DOI 10.1016/j.future.2020.03.039
   Matheus R, 2017, P 10 INT C THEOR PRA, P405, DOI [10.1145/3047273.3047386, DOI 10.1145/3047273.3047386]
   Morris MR, 2014, P 17 ACM C COMP SUPP, P662, DOI DOI 10.1145/2531602.2531707
   Morrison JH, 2016, MIT M
   Nagarajan S, 2020, ADV COMPUT, V117, P247, DOI 10.1016/bs.adcom.2019.09.005
   Oikonomou, 2017, 2017 9 INT C VIRT WO
   Park J, 2021, J OPER RES SOC, V72, P1578, DOI 10.1080/01605682.2020.1740624
   PHANDEN RK, 2020, MATER TODAY-PROC
   Pokhrel, 2020, DIGITAL TWINS CYBERS, DOI 10.1145/3387940.3392199
   Reifsnider Kenneth., 2013, 54 AIAA ASME ASCE AH, DOI DOI 10.2514/6.2013-1578
   Rienzo AD, 2016, P INT WORK C ADV VIS, P356, DOI [10.1145/2909132.2926087, DOI 10.1145/2909132.2926087]
   Rios Jose, 2016, International Journal of Agile Systems and Management, V9, P212
   Rivera L. F., 2020, P IEEEACM 42 INT C S, P631
   Ruohomäki T, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P155, DOI 10.1109/IS.2018.8710517
   Salinger S. J., 2020, LECT NOTES COMPUTER, V12312
   Scherrenbacher, 2019, ATZ PROD WORLDW, V6, P36
   Schirrmeister, 2019, SYSTEM EMULATION DIG
   Shafiq B., 2016, P 17 INT DIG GOV RES, P58, DOI DOI 10.1145/2912160.2912205
   Shafto M., 2012, NATL AERONAUTICS SPA, V32, P1
   Shvedenko VN, 2019, AUTOM DOC MATH LINGU, V53, P122, DOI 10.3103/S0005105519030038
   Stark R., 2019, INT ACAD PRODUCTION
   Svítek M, 2020, STUD COMPUT INTELL, V853, P426, DOI 10.1007/978-3-030-27477-1_33
   Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186
   Tao F, 2018, INT J ADV MANUF TECH, V94, P3563, DOI 10.1007/s00170-017-0233-1
   Trombin M, 2020, EMERGING TECHNOLOGIE, V242, DOI 10.1007/978-3-030-22773-9_11
   Tuegel E, 2012, 53 AIAA ASME ASCE AH, P1812
   Uhlemann THJ, 2017, PROC CIRP, V61, P335, DOI 10.1016/j.procir.2016.11.152
   Vaskovsky Andrey M., 2020, 2020 4th Scientific School on Dynamics of Complex Networks and their Application in Intellectual Robotics (DCNAIR), P251, DOI 10.1109/DCNAIR50402.2020.9216776
   Villanueva FJ, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL CONFERENCE ON HUMAN-MACHINE SYSTEMS (ICHMS), P66, DOI 10.1109/ichms49158.2020.9209384
   Wang KJ, 2020, INT J ADV MANUF TECH, V107, P4687, DOI 10.1007/s00170-020-05314-w
   West T., 2017, COMPLEX ADAPTIVE SYS
   Wright Louise, 2020, Advanced Modeling and Simulation in Engineering Sciences, V7, DOI 10.1186/s40323-020-00147-4
   Xue F, 2020, ISPRS J PHOTOGRAMM, V167, P418, DOI 10.1016/j.isprsjprs.2020.07.020
   YANG S, IEEE T NEURAL NETW L
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang XD, 2019, J INTELL FUZZY SYST, V37, P425, DOI 10.3233/JIFS-179097
   Yu G, 2021, FUTURE GENER COMP SY, V115, P583, DOI 10.1016/j.future.2020.09.010
   Yun Yeji., 2019, J OPEN INNOV TECHNOL, V5, P92, DOI [DOI 10.3390/JOITMC5040092, DOI 10.3390/joitmc5040092, 10.3390/JOITMC5040092]
   Zakzak L, 2019, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL GOVERNMENT RESEARCH (DGO2019): GOVERNANCE IN THE AGE OF ARTIFICIAL INTELLIGENCE, P141, DOI 10.1145/3325112.3325236
   Zhang HJ, 2020, INT J ADV MANUF TECH, V107, P1927, DOI 10.1007/s00170-020-05056-9
   Zhang Y, 2017, 2017 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY AND MANAGEMENT (ICITM), P114, DOI 10.1109/ICITM.2017.7917906
NR 81
TC 32
Z9 33
U1 11
U2 102
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26941
EP 26967
DI 10.1007/s11042-022-12536-5
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000756208600001
PM 35194381
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Islam, MS
   Rahman, MM
   Rahman, MH
   Rivolta, MW
   Aktaruzzaman, M
AF Islam, Md Shafiqul
   Rahman, Md Moklesur
   Rahman, Md Hafizur
   Rivolta, Massimo Walter
   Aktaruzzaman, Md
TI RATNet: A deep learning model for Bengali handwritten characters
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bengali; Handwritten character recognition; Dataset; Convolutional
   neural network; Residual attention; Deep learning
AB The Bengali language is based on a set of symbols for basic characters, modifiers, compound characters, and numerals. The recognition rates of handwritten basic characters and numerals are very high. However, the recognition rates of compound characters and modifiers are still poor. This might be due to their large class size with huge writing styles, much similarity, and unavailability of sufficient data for deep learning. In fact, there are some compound characters which appear very rare in practice. A proper selection of frequently used characters may reduce class size, and hence improving the accuracy. In this study, we performed a statistics on the frequency of compound characters, we developed two datasets for modifiers and compound characters, and finally we proposed a heterogeneous deep learning model (RATNet) for characters recognition. A statistics was performed on two daily Bengali newspapers, and characters with frequency >= 5% were selected. The handwriting of selected characters was collected from 130 writers of different ages and professions. The performance of RATNet model was evaluated on the proposed datasets and also three other existing datasets (i.e., ISI, CMATERdb, BanglaLekha-Isolated). In addition, the performance of RATNet was also compared with LeNet-5, VGG-16, ResNet-50, and DenseNet-121 models. We selected 87 out of 107 compound characters. The proposed RATNet model outperforms other models providing 99.66%, 99.27%, 98.78%, and 97.70% accuracy, respectively for the recognition of numerals, basic characters, modifiers, and compound characters on the CMATERdb dataset while keeping the number of parameters relatively low likely due to layer heterogeneity.
C1 [Islam, Md Shafiqul; Rahman, Md Moklesur] Peoples Univ Bangladesh, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Rahman, Md Hafizur] Islamic Univ, Dept Elect & Elect Engn, Kushtia, Bangladesh.
   [Rivolta, Massimo Walter] Univ Milan, Dipartimento Informat, Milan, Italy.
   [Aktaruzzaman, Md] Islamic Univ, Dept Comp Sci & Engn, Kushtia 7003, Bangladesh.
C3 Peoples University of Bangladesh; Islamic University; University of
   Milan; Islamic University
RP Aktaruzzaman, M (corresponding author), Islamic Univ, Dept Comp Sci & Engn, Kushtia 7003, Bangladesh.
EM aktaruzzaman@iu.ac.bd
RI Rahman, Md Hafizur/AFM-9964-2022; Aktaruzzaman, Md/HJG-7441-2022;
   Rivolta, Massimo/J-6542-2019
OI Rahman, Md Hafizur/0000-0002-1981-6582; Aktaruzzaman,
   Md/0000-0003-0349-1434; Rivolta, Massimo/0000-0002-8553-2414; Rahman, Md
   Hafizur/0000-0002-2742-049X; Rahman, Md Moklesur/0000-0002-7716-1318; Md
   Shafiqul, Islam/0000-0001-9469-2041
FU University Grants Commission (UGC) of Bangladesh; Islamic University,
   Kushtia, Bangldesh
FX We thankfully acknowledge the contribution of those volunteers, who
   participated in writing the characters. We are grateful to Prof. Dr.
   Ujjal Bhattacharya, Indian Statistical Institute for providing the ISI
   handwritten numeral dataset. We are also grateful to the University
   Grants Commission (UGC) of Bangladesh and the authority of Islamic
   University, Kushtia-7003, Bangldesh for providing partial financial
   support to develop this dataset.
CR Akhand MAH, 2016, PROCEEDINGS OF 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE 2016), P311, DOI 10.1109/ICCCE.2016.73
   Akhand M. A. H., 2015, ELECT ENG INF COMMUN, P1
   Ali AAA, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1294-6
   Alom MZ, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6747098
   Amin MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205884
   [Anonymous], 2015, Deep convolutional network for handwritten chinese character recognition
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2014, P INT C EL INF COMM
   [Anonymous], 2009, IICAI
   [Anonymous], 2017, P 2017 IEEE INT C IM, DOI DOI 10.1109/ICIVPR.2017.7890867
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, ARXIVABS151203385
   Ba J., 2014, ARXIV PREPRINT ARXIV
   Basu S, 2009, PATTERN RECOGN, V42, P1467, DOI 10.1016/j.patcog.2009.01.008
   Bhattacharya U, 2012, PATTERN ANAL APPL, V15, P445, DOI 10.1007/s10044-012-0278-6
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Bhowmik TK, 2009, INT J DOC ANAL RECOG, V12, P97, DOI 10.1007/s10032-009-0084-x
   Biswas M, 2017, ARXIV170310661
   Breuel TM, 2013, PROC INT CONF DOC, P683, DOI 10.1109/ICDAR.2013.140
   Chatterji SK., 2002, INDOGER FORSCH, V47, P370
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Das N., 2010, J Comput, V2, P109
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Das N, 2012, APPL SOFT COMPUT, V12, P1592, DOI 10.1016/j.asoc.2011.11.030
   Fard AE, 2019, INT ICE CONF ENG, DOI 10.1109/ice.2019.8792644
   Gruber I, 2017, LECT NOTES ARTIF INT, V10459, P67, DOI 10.1007/978-3-319-66471-2_8
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma D. P., 2014, arXiv
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mnih V, 2014, ADV NEUR IN, V27
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Pal U., 2007, Proceedings of 10th International Conference on Information Technology (ICIT), P208, DOI [DOI 10.1109/ICIT.2007.62, 10.1109/ICIT.2007.43, DOI 10.1109/ICIT.2007.43]
   Park Jongchan, 2018, arXiv preprint arXiv:1807.06514
   Purnamawati S, 2018, J PHYS C SERIES
   Rabby AKMSA, 2018, PROCEDIA COMPUT SCI, V143, P528, DOI 10.1016/j.procs.2018.10.426
   Racki D, 2018, IEEE WINT CONF APPL, P1331, DOI 10.1109/WACV.2018.00150
   Rahman Mahbubar, 2015, International Journal of Image, Graphics and Signal Processing, V7, P42, DOI 10.5815/ijigsp.2015.08.05
   Rahman MM, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1682-y
   Rownak AF, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P938, DOI 10.1109/ICIEV.2016.7760138
   Roy S, 2017, PATTERN RECOGN LETT, V90, P15, DOI 10.1016/j.patrec.2017.03.004
   Saufi M.M., 2018, Indonesian Journal of Electrical Engineering and Computer Science, V12, P455
   Shopon Md, 2016, 2016 International Workshop on Computational Intelligence (IWCI), P64, DOI 10.1109/IWCI.2016.7860340
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tsai C, 2016, RECOGNIZING HANDWRIT, P405
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wikipedia contributors, 2020, LIST LANG NUMB NAT S
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
NR 48
TC 3
Z9 3
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10631
EP 10651
DI 10.1007/s11042-022-12070-4
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700025
DA 2024-07-18
ER

PT J
AU Kumar, D
   Kukreja, V
AF Kumar, Deepak
   Kukreja, Vinay
TI Deep learning in wheat diseases classification: A systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Neural networks; Support vector machine; Wheat diseases
ID WINTER-WHEAT; YELLOW RUST; STRIPE RUST; FEATURES; IMAGES; RECOGNITION;
   REFLECTANCE; TECHNOLOGY; PREDICTION; ALGORITHM
AB The main goal of this paper is to review systematically the recent studies that have been published and discussed WD prediction models. The literature analysis is performed based on studies published from January 1997 to February 2021 by following Kitchenham instructions. After inclusion/exclusion and quality assessment criteria screening, a total of 74 studies have been selected. The literature shows that WD is categorized into three (fungal diseases, bacterial diseases, and insect diseases) types. The research analysis shows that most of the work in the literature has been found on wheat stripe rust (60.81%) disease and the most used prediction technique is ANN (13.32%). The results show that accuracy (67%) is the most prominent performance metric and in the year 2020, a maximum number of papers are published on WD. Also, only five studies have used hybrid approaches which are the combination of SVM and NN techniques.
C1 [Kumar, Deepak; Kukreja, Vinay] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Kukreja, V (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM deepak.k@chitkara.edu.in; onlyvinaykukreja@gmail.com
RI Kukreja, Vinay/AAT-7893-2021
OI Kukreja, Vinay/0000-0002-9760-0824; Kumar, Deepak/0000-0002-6282-8925
CR Abbas FI., 2020, IRAQI J SCI, V61, P2408
   Abdollahpour Shamsollah, 2020, Information Processing in Agriculture, V7, P500, DOI 10.1016/j.inpa.2020.01.003
   Abdulhussien, 2015, J THI QAR SCI, V5, P80
   Al-Shamayleh AS, 2018, MULTIMED TOOLS APPL, V77, P28121, DOI 10.1007/s11042-018-5971-z
   Atispha, 2018, RUSS WHEAT APH
   Balaghi R, 2008, INT J APPL EARTH OBS, V10, P438, DOI 10.1016/j.jag.2006.12.001
   Bebronne R., 2019, Precision agriculture'19, P255, DOI DOI 10.3920/978-90-8686-888-9_31
   Bebronne R, 2020, BIOSYST ENG, V197, P257, DOI 10.1016/j.biosystemseng.2020.06.011
   Bolton MD, 2008, MOL PLANT PATHOL, V9, P563, DOI 10.1111/J.1364-3703.2008.00487.X
   Byamukama E, 2019, BACTERIAL LEAF BLIGH
   Carol G, 2013, DIS PROFILE LEAF BLO
   Chen DM, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P251, DOI 10.1145/3007669.3007701
   De Wolf ED, 2000, PHYTOPATHOLOGY, V90, P108, DOI 10.1094/PHYTO.2000.90.2.108
   Dutta S, 2014, J INDIAN SOC REMOTE, V42, P335, DOI 10.1007/s12524-013-0329-5
   Ennadifi E., 2020, INT C INT SYST COMP, P1, DOI [10.1109/ISCV49265.2020.9204258, DOI 10.1109/ISCV49265.2020.9204258]
   Figuera M., 2010, MOL PLANT PATHOL, V19, P1536
   Francl LJ, 1997, AGR FOREST METEOROL, V88, P57, DOI 10.1016/S0168-1923(97)00051-8
   Gaikwad VP, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND INFORMATION MANAGEMENT (ICISIM), P110, DOI 10.1109/ICISIM.2017.8122158
   Galanakis CM, 2018, WOODHEAD PUBL FOOD S, P1
   Genaev Mikhail, 2020, 2020 Cognitive Sciences, Genomics and Bioinformatics (CSGB), P40, DOI 10.1109/CSGB51356.2020.9214703
   Guo M, 2019, BIOSYST ENG, V184, P37, DOI 10.1016/j.biosystemseng.2019.04.022
   Haider W, 2021, IEEE ACCESS, V9, P31104, DOI 10.1109/ACCESS.2021.3058582
   Haiguang Wang, 2012, 2012 8th International Conference on Natural Computation, P246, DOI 10.1109/ICNC.2012.6234701
   Han LX, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P638, DOI 10.1109/SAI.2015.7237209
   Hasan MM, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0366-8
   Holly L, 2015, SNOW MOULD WINTER CE
   Huang H., 2012, APPL SCI, V9, p558 570
   Huang LS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102887
   Hussein AA, 2018, IEEE ENER CONV, P7, DOI 10.1109/ECCE.2018.8557510
   Islam SMM, 2019, 2019 93RD ARFTG MICROWAVE MEASUREMENT CONFERENCE (ARFTG), DOI 10.1109/arftg.2019.8739240
   Jahan N., 2020, ASABE M PRES, P2, DOI [10.13031/aim.202000372, DOI 10.13031/AIM.202000372]
   Jiang L, 2018, COMPUT ELECTRON AGR, V154, P46, DOI 10.1016/j.compag.2018.08.047
   Jiang TL, 2008, WHEAT COMMON PESTS D
   Jin X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030395
   Jinghui Li, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2543, DOI 10.1109/CISP.2010.5646912
   John W, 2011, WHEAT STREAK MOSAIC
   Jorge DS, 2016, RUST DIS WHEAT
   Karasi M., 2016, FUSARIUM HEAD BLIGHT
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Kuang W, 2013, COMPUTER COMPUTING 1, P324
   Kumar M., 2017, International Journal of Latest Technology in Engineering, Management & Applied Science, V6, P73
   Lihong Mo, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P475, DOI 10.1109/ICICISYS.2010.5658476
   Lin ZQ, 2019, IEEE ACCESS, V7, P11570, DOI 10.1109/ACCESS.2019.2891739
   Line RF, 2002, ANNU REV PHYTOPATHOL, V40, P75, DOI 10.1146/annurev.phyto.40.020102.111645
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Luise S, 2020, FLAG SMUT WHEAT
   Ma JC, 2019, EUR J AGRON, V103, P117, DOI 10.1016/j.eja.2018.12.004
   Majumdar D, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P400, DOI 10.1145/2791405.2791474
   Mark AM, 2016, LEAF STEM STRIPE RUS
   Mathias IM, 2016, IEEE LAT AM T, V14, P309, DOI 10.1109/TLA.2016.7430094
   Mi ZW, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.558126
   Moshou D, 2004, COMPUT ELECTRON AGR, V44, P173, DOI 10.1016/j.compag.2004.04.003
   Nie C, 2014, INT C COMP COMP TECH, P444
   Nithya VS., 2011, INT J SCI ENG RES, V2, P1
   Niu XJ, 2014, INT C ADV MECH SYST, P270, DOI 10.1109/ICAMechS.2014.6911663
   Oyewola DO, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.352
   Özkan K, 2019, J SCI FOOD AGR, V99, P4977, DOI 10.1002/jsfa.9732
   Patricia R, 2014, VOTE COUNTING
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Pradeep KR, 2020, WHEAT DIS SYMPTOMS
   Pryzant R, 2017, IEEE COMPUT SOC CONF, P1524, DOI 10.1109/CVPRW.2017.196
   Qiu RC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222658
   Raichaudhuri R, 2017, ADV INTELL SYST, V468, P569, DOI 10.1007/978-981-10-1675-2_56
   Ray M, 2017, TECHNOL FORECAST SOC, V118, P128, DOI 10.1016/j.techfore.2017.02.012
   Ruan R, 1998, CEREAL CHEM, V75, P455, DOI 10.1094/CCHEM.1998.75.4.455
   Sabrol H., 2013, INT J COMPUT SCI ENG, V3, P85
   Sadeghi-Tehran P, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01176
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sally P, 2018, DIAGNOSING YELLOW SP
   Sarah W, 2017, BACTERIAL DIS PLANTS
   Sarayloo Z, 2015, IRAN CONF ELECTR ENG, P1193, DOI 10.1109/IranianCEE.2015.7146396
   SHIPTON WA, 1971, BOT REV, V37, P231, DOI 10.1007/BF02858957
   Singh R., 2018, ASIAN J COMPUT SCI T, V7, P76, DOI [10.51983/ajcst-2018.7.3.1892, DOI 10.51983/AJCST-2018.7.3.1892]
   Snilstveit B, 2012, J DEV EFFECT, V4, P409, DOI 10.1080/19439342.2012.710641
   Sood Shivani, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P341, DOI 10.1109/ICISS49785.2020.9316123
   Stephen NW, 2011, DIS MANAGEMENT WHEAT
   Su JY, 2018, COMPUT ELECTRON AGR, V155, P157, DOI 10.1016/j.compag.2018.10.017
   Su T, 2019, NEURAL NETW WORLD, V29, P345, DOI 10.14311/NNW.2019.29.021
   Su W.-H., 2020, 2020 ASABE ANN INT V, P1
   Su WH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010026
   Syngenta, 2013, SEPT LEAF SPOT
   Tutygin, 2019, VIBROENGINEERING PRO, V25, P122
   University of York, 2014, CTR REV DISS
   Varinderjit Kaur A.O., 2017, International Journal of Emerging Technologies in Engineering Research, V5, P133
   Wang AM, 2014, ADV MATER RES-SWITZ, V886, P580, DOI 10.4028/www.scientific.net/AMR.886.580
   Wang HG, 2012, IFIP ADV INF COMM TE, V369, P504
   Wen JF, 2012, INFORM SOFTWARE TECH, V54, P41, DOI 10.1016/j.infsof.2011.09.002
   Wenxia B, 2021, SUSTAIN COMPUT-INFOR, V30
   Xie X, 2016, INT SOC OPTICS PHOTO, V155
   Xu PF, 2017, PROCEDIA COMPUT SCI, V107, P836, DOI 10.1016/j.procs.2017.03.177
   Yang KM, 2013, MATH COMPUT MODEL, V58, P644, DOI 10.1016/j.mcm.2011.10.037
   Zambia, 2017, SPOT BLOTCH WHEAT
   Zhang DY, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105588
   Zhang DY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202375
   Zhang JC, 2017, BIOSYST ENG, V162, P20, DOI 10.1016/j.biosystemseng.2017.07.003
   Zhang JC, 2014, COMPUT ELECTRON AGR, V100, P79, DOI 10.1016/j.compag.2013.11.001
   Zhang N, 2019, BIOSYST ENG, V186, P83, DOI 10.1016/j.biosystemseng.2019.06.008
   Zhang X, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131554
   Zhao JL, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9080936
   Zheng Q, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020278
   Zheng Q, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030868
NR 101
TC 20
Z9 20
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10143
EP 10187
DI 10.1007/s11042-022-12160-3
EA FEB 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800005
DA 2024-07-18
ER

PT J
AU Rathor, S
   Agrawal, S
AF Rathor, Sandeep
   Agrawal, Sanket
TI Sense understanding of text conversation using temporal convolution
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal CNN; Spatio temporal; Sense understanding; Text processing;
   Advance machine learning technique
ID DOMAIN CLASSIFICATION; RECOGNITION
AB This paper proposes a model which uses Spatio Temporal features for real-time sense understanding of a text conversation. The proposed model uses CNN along with the concept of LSTM to create a new Spatio temporal cell. Furthermore, the proposed model is used to classify the sentences into eight senses. The model achieved an F-Score around 0.984 on sense classification. Additionally, the efficiency and capabilities of the model are also tested on a standard IMDB sentiment classification dataset. On the IMDB dataset, the model gave an accuracy of 89.27. The experimental results show that the proposed model works better than a CNN model, a Bi-LSTM model, and a combination of CNN & LSTM model in terms of a number of parameters and execution time.
C1 [Rathor, Sandeep] GLA Univ, Dept CEA, Mathura, India.
   [Agrawal, Sanket] Infosys Ltd, Pune, Maharashtra, India.
C3 GLA University; Infosys Limited
RP Rathor, S (corresponding author), GLA Univ, Dept CEA, Mathura, India.
EM sandeep.rathor@gla.ac.in; sanket.agrawal@infosys.com
OI rathor, sandeep/0000-0002-2882-0487
CR Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004
   Camacho-Collados J., 2017, ARXIV PREPRINT ARXIV
   Feizollah A, 2019, IEEE ACCESS, V7, P83354, DOI 10.1109/ACCESS.2019.2923275
   Gui L, 2022, IEEE T KNOWL DATA EN, V34, P1915, DOI 10.1109/TKDE.2020.2999489
   Hall JK, 2019, MOD LANG J, V103, P80, DOI 10.1111/modl.12535
   Jiahao Wang, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12306), P3, DOI 10.1007/978-3-030-60639-8_1
   Li SJ, 2023, IEEE T PATTERN ANAL, V45, P6647, DOI 10.1109/TPAMI.2020.3021756
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Luo LX, 2019, PERS UBIQUIT COMPUT, V23, P405, DOI 10.1007/s00779-018-1183-9
   Parcheta Z, 2019, LECT NOTES COMPUT SC, V11506, P596, DOI 10.1007/978-3-030-20521-8_49
   Poonpakdee P, 2017, PROCEDIA COMPUT SCI, V110, P46, DOI 10.1016/j.procs.2017.06.113
   Rathor S, 2019, J AMB INTEL HUM COMP, V10, P3617, DOI 10.1007/s12652-018-1087-6
   Rathor S, 2019, INT J ARTS TECHNOL, V11, P309
   Rintyarna Bagus Setya, 2020, International Journal of Information and Decision Sciences, V12, P75
   Rusch TK, 2020, ARXIV PREPRINT ARXIV
   Sharma AK, 2020, PROCEDIA COMPUT SCI, V167, P1139, DOI 10.1016/j.procs.2020.03.416
   Shi XJ, 2015, ADV NEUR IN, V28
   Voramontri Duangruthai, 2019, International Journal of Information and Decision Sciences, V11, P209
   Wang X., 2016, P COL 2016 26 INT C, P2428
   Widiastuti NI, 2019, IOP CONF SER-MAT SCI, V662, DOI 10.1088/1757-899X/662/5/052010
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   Zhang Y., 2018, ARXIV PREPRINT ARXIV
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
NR 23
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9897
EP 9914
DI 10.1007/s11042-022-12090-0
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800009
PM 35194387
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Sethy, PK
   Behera, SK
AF Sethy, Prabira Kumar
   Behera, Santi Kumari
TI Automatic classification with concatenation of deep and handcrafted
   features of histological images for breast carcinoma diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast carcinoma diagnosis; Deep feature; Handcrafted feature;
   Concatenation; Histological images; Biopsy
ID CANCER
AB The second leading cause of death from cancer among women is breast cancer. In order to prevent avoidable deaths, early detection is extremely necessary. Malignancy evaluation of tissue biopsies, however, is complicated and based on observer subjectivity. In addition, histological images stained with hematoxylin and eosin (H&E) exhibit a highly variable appearance, also at the same degree of malignancy. In this paper, we propose a classification model based on KNN with the combination of deep and handcrafted features using histological images to diagnose breast cancer. Here, four malignancy levels are considered, namely normal, benign, in situ, and invasive. The classification of four malignancy levels is examined by three classifiers with three sets of deep features and three handcrafted features. The deep features are extracted from the fc6 layer of three pre-trained networks: alexnet, vgg16, and vgg19. The handcrafted features are GLCM, HOG, and LBP. After evaluation, the top-performed classifier, deep feature, and handcrafted features are considered to frame the classification model. The classification model based on fine- KNN with combining the feature of vgg16 and LBP achieved satisfactory diagnostic effectiveness (accuracy) of 84.2% and area under the curve (AUC) of 0.85. Further, the likelihood ratio for positive results (LR+) is greater than 10, i.e., 12.5, which implicates the proposed method has a significant contribution to the diagnosis and a good diagnostic test.
C1 [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Sambalpur 768019, Odisha, India.
   [Behera, Santi Kumari] VSSUT, Dept Comp Sci & Engn, Burla 768019, Odisha, India.
C3 Sambalpur University; Veer Surendra Sai University of Technology
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Sambalpur 768019, Odisha, India.
EM prabirsethy.05@gmail.com
RI Sethy, Prabira kumar/W-5929-2019; Behera, Santi Kumari/GPF-3681-2022
OI Sethy, Prabira kumar/0000-0003-3477-6715; Behera, Santi
   Kumari/0000-0003-4857-7821
CR Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   [Anonymous], 2005, TR0509 RENSS POL I D
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Bailing Zhang, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P180, DOI 10.1109/BMEI.2011.6098229
   BASAVANHALLY A, 2011, P SPIE, V7963
   Behera S.K., 2020, Karbala International Journal of Modern Science, V6, P16, DOI [10.33640/2405- 609X.1675, DOI 10.33640/2405-609X.1675]
   Behera SK, 2021, INFORM PROCESS AGR, V8, P244, DOI 10.1016/j.inpa.2020.05.003
   Bejnordi BE, 2016, IEEE T MED IMAGING, V35, P404, DOI 10.1109/TMI.2015.2476509
   BEJNORDI BE, 2015, P SPIE, V9420
   Belsare AD, 2015, TENCON IEEE REGION
   Boucheron LE, 2010, INT CONF ACOUST SPEE, P666, DOI 10.1109/ICASSP.2010.5495124
   Brook A., 2007, BREAST CANC DIAGNOSI
   Chen YH, 2016, ENERGIES, V9, DOI 10.3390/en9020070
   Cohen JF, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-012799
   Dubitzky, 2007, FUNDAMENTALS DATA MI, DOI DOI 10.1007/978-0-387-47509-7
   Elmore JG, 2015, JAMA-J AM MED ASSOC, V313, P1122, DOI 10.1001/jama.2015.1405
   Elston C W, 2002, Histopathology, V41, P154
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Filipczuk P, 2013, IEEE T MED IMAGING, V32, P2169, DOI 10.1109/TMI.2013.2275151
   FONDON I, 2018, COMPUT BIOL MED
   George YM, 2014, IEEE SYST J, V8, P949, DOI 10.1109/JSYST.2013.2279415
   Greenlee RT, 2000, CA-CANCER J CLIN, V50, P7, DOI 10.3322/canjclin.50.1.7
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Li X, 2015, P SPIE, V9420, DOI 10.1117/12.2079935
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   National Breast Cancer Foundation, 2015, BREAST CANC DIAGN
   Pego A, 2015, BIOIMAGING
   Pego A, 2015, 4 INT S APPL BIOIM B
   Rosen P.P., 2001, ROSENS BREAST PATHOL
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sethy PK, 2020, J AMB INTEL HUM COMP, V11, P5703, DOI 10.1007/s12652-020-01938-8
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Smith RA, 2004, CA-CANCER J CLIN, V54, P41, DOI 10.3322/canjclin.54.1.41
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   Veta M, 2013, PROC SPIE, V8676, DOI 10.1117/12.2006626
   Vu TH, 2016, IEEE T MED IMAGING, V35, P738, DOI 10.1109/TMI.2015.2493530
   Wang D., 2016, ARXIV PREPRINT ARXIV
   Wei BZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P348, DOI 10.1109/ICCCBDA.2017.7951937
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
NR 44
TC 14
Z9 14
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9631
EP 9643
DI 10.1007/s11042-021-11756-5
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000753738300001
DA 2024-07-18
ER

PT J
AU Arslan, Y
   Canbolat, H
AF Arslan, Yuksel
   Canbolat, Huseyin
TI Sound based alarming based video surveillance system design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio surveillance; Hazardous sound event detection; Deep learning;
   Video surveillance
ID CAMERAS; EVENTS
AB Modern video surveillance systems consist of a network of many video cameras. Constantly video camera systems are being installed for security reasons in prisons, elevators, automatic teller machines and more. Usually, video cameras are connected to a display screen from which security personnel monitor suspicious activity. As security personnel monitor multiple locations simultaneously, this manual task is labor intensive and inefficient. These camera systems have some other drawbacks such that they have limited coverage and security personnel cannot see all the points even though they are looking at the camera. Therefore, most of the time, some other sensors should accompany to video cameras. Although audio surveillance is in its early stage, there has been considerable amount of work in this area in the last decade. On the other hand, currently, there are no practical audio surveillance solutions for security on the market. In this paper, audio surveillance is integrated to current video surveillance systems using deep learning. We develop a complete system and show a working prototype. It is encouraging to see that the system is good enough and can be used in real life.
C1 [Arslan, Yuksel] Ankara Sci Univ, Dept Software Engn, Ankara, Turkey.
   [Canbolat, Huseyin] Ankara Yildirim Beyazit Univ, Dept Elect & Elect Engn, Ankara, Turkey.
C3 Ankara Science University; Ankara Yildirim Beyazit University
RP Arslan, Y (corresponding author), Ankara Sci Univ, Dept Software Engn, Ankara, Turkey.
EM yuksel.arslan@ankarabilim.edu.tr
RI Arslan, Yuksel/GRN-8418-2022
CR Ahmed T, 2013, INT CONF ACOUST SPEE, P513, DOI 10.1109/ICASSP.2013.6637700
   [Anonymous], 2009, CISCO IP VIDEO SURVE
   [Anonymous], 2017, P DET CLASS AC SCEN
   Anrew, INTRO MACHINE LEARNI
   Arslan Y., 2017, ASTES J, V2, P145, DOI [10.25046/aj020618, DOI 10.25046/AJ020618]
   Arslan Y, 2017, SIG PROCESS COMMUN
   ATREY P.K., 2006, 2006 IEEE INT C AC S, DOI DOI 10.1109/ICASSP.2006.1661400
   Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
   Bramberger M, 2006, COMPUTER, V39, P68, DOI 10.1109/MC.2006.55
   Cakir E, 2017, P DETECTION CLASSIFI, P27
   Chen JF, 2005, LECT NOTES COMPUT SC, V3468, P47, DOI 10.1385/1-59259-820-x:047
   Cho H, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P743, DOI 10.1109/HPCC.2014.114
   Chu S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P885, DOI 10.1109/ICME.2006.262661
   Cucchiara R, 2011, P 2 ND WORKSH VID SU
   Dang A, 2017, WORKSH DCASE2017 CHA
   Dufaux, THESIS
   FOGGIA P, 2019, BOOK IMAGE ANAL PROC
   Foggia P, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Foggia P, 2015, PATTERN RECOGN LETT, V65, P22, DOI 10.1016/j.patrec.2015.06.026
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hossain MA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/135257
   KOTUS J, 2016, MULTIMED TOOLS APPL
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Lim H., 2017, P DET CLASS AC SCEN
   Lin CF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P655, DOI 10.1109/UIC-ATC.2012.72
   Lo B. P. L., 2003, Acta Automatica Sinica, V29, P393
   Lopatka K, 2016, MULTIMED TOOLS APPL, V75, P10407, DOI 10.1007/s11042-015-3105-4
   Mesaros A, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060162
   Park JS, 2020, MULTIMED TOOLS APPL, V79, P16127, DOI 10.1007/s11042-019-7547-y
   Radhakrishnan R, 2005, P SOC PHOTO-OPT INS, V5685, P64, DOI 10.1117/12.587814
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Rodriguez-Silva D. A., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P991, DOI 10.1109/CLOUD.2012.44
   Rouas J., 2006, 2006 IEEE INT TRANSP, P733
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   SHARAFF A, 2019, ADV COMPUTER COMMUNI
   Thumwarin P, 2014, 2014 FOURTH JOINT INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONIC AND ELECTRICAL ENGINEERING (JICTEE 2014)
   Tian YL, 2008, MACH VISION APPL, V19, P315, DOI 10.1007/s00138-008-0153-z
   Vacher Michel, 2010, 2010 12th IEEE International Conference on e-Health Networking, Applications and Services (Healthcom 2010), P330, DOI 10.1109/HEALTH.2010.5556546
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Wang JC, 2008, IEEE T AUTOM SCI ENG, V5, P25, DOI 10.1109/TASE.2007.911680
   Wang Y-K., 2012, P 8 INT C INT INF HI
   Weninger F, 2011, INT CONF ACOUST SPEE, P337
   Yamakawa Nobuhide, 2011, Modern Approaches in Applied Intelligence. Proceedings 24th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems (IEA/AIE 2011), P1, DOI 10.1007/978-3-642-21827-9_1
NR 45
TC 3
Z9 3
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7969
EP 7991
DI 10.1007/s11042-022-12028-6
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500002
DA 2024-07-18
ER

PT J
AU Sathiyamurthi, P
   Ramakrishnan, S
AF Sathiyamurthi, P.
   Ramakrishnan, S.
TI Speech encryption using hybrid-hyper chaotic system and binary masking
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid chaos; Hyper chaotic system; Zaslavsky map; Zigzag map;
   Permutation; Substitution; Binary masking
ID ALGORITHM; MAP; IMPLEMENTATION
AB In this paper, a novel speech encryption algorithm based on hybrid-hyper chaotic system has presented. Instead of using normal chaotic system a hybrid-hyper chaotic system has used for improving the security level of speech communication models. Hyper-chaotic system is highly complex and dynamic system than normal chaotic system where it has more than one positive Lyapunov exponents. Hybrid chaotic system has designed by a disturbed discrete system by another one discrete system. In this algorithm, the input speech signal has compressed by Discrete Cosine Transform (DCT) to reduce the residual intelligibility. The compressed speech signal has permuted by hybrid chaotic system, which has designed using Zaslavsky and Zigzag maps. For substitution process, a reference speech signal has generated by Hidden Markov Model (HMM) speech synthesizer and permuted by using hyper-chaotic system. Masking of encryption signal has done by a masking sequence, which has obtained from the hyper-chaotic system. Our proposed work provides high security for the audio and speech signal over an insecure public network than other traditional speech encryption algorithms based on normal chaotic systems. The betterment of proposed algorithm is proven using the following metrics: key space analysis, key sensitivity analysis, information entropy measure, correlation coefficient analysis, Signal to Noise Ratio (SNR) analysis, subjective evaluation of speech quality, Perceptual Evaluation of Speech Quality (PESQ) analysis, NSCR (Number of Samples Changing Rate) and UACI (Unified Averaged Changed Intensity) analysis have carried out from cryptographic point of view and presented in this paper. The results proof that the proposed speech encryption algorithm ensures appreciable security system with robust encryption and decryption quality.
C1 [Sathiyamurthi, P.; Ramakrishnan, S.] Dr Mahalingam Coll Engn & Technol, Dept Informat Technol, Pollachi, Tamil Nadu, India.
RP Sathiyamurthi, P (corresponding author), Dr Mahalingam Coll Engn & Technol, Dept Informat Technol, Pollachi, Tamil Nadu, India.
EM sathyamurthi.bit@gmail.com; ram_f77@yahoo.com
RI S, Ramakrishnan/A-1134-2012; , Dr.P.Sathiyamurthi/AFH-3769-2022
OI S, Ramakrishnan/0000-0002-8224-4812; Pattusamy,
   Sathiyamurthi/0000-0001-8885-7153
CR Advanced Encryption Standard, 2001, FED INF PROC STAND P, V197
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Biswas D, 2017, NONLINEAR DYNAM, V89, P1733, DOI 10.1007/s11071-017-3548-4
   Biswas D, 2016, NONLINEAR DYNAM, V83, P2331, DOI 10.1007/s11071-015-2484-4
   Daemen J, 2001, DR DOBBS J, V26, P137
   Elkholy MM, 2016, NAT RADIO SCI CO, P159, DOI 10.1109/NRSC.2016.7450849
   Elminaaml DSA, 2008, INT J COMPUT SCI NET, V8, P280
   Elsafty AH, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153347
   Etem T, 2020, APPL ACOUST, V170, DOI 10.1016/j.apacoust.2020.107481
   Farsana FJ, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P279, DOI 10.1109/SAPIENCE.2016.7684153
   Forouzan BA., 2015, Cryptography and network security
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gopalakrishnan T, 2017, IETE J RES, V63, P172, DOI 10.1080/03772063.2016.1251855
   Guo QJ, 2017, IEEE ACCESS, V5, P22453, DOI 10.1109/ACCESS.2017.2760882
   He R, 1998, PHYS REV E, V57, P1532, DOI 10.1103/PhysRevE.57.1532
   Imran OA, 2020, PROCEDIA COMPUT SCI, V167, P1028, DOI 10.1016/j.procs.2020.03.402
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Kohli R, 2013, INT J ADV RES COMPUT, V3
   Kumar LP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1497, DOI 10.1109/RTEICT.2016.7808081
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lin QH, 2006, IEEE T CIRCUITS-I, V53, P1320, DOI 10.1109/TCSI.2006.875164
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Nagakrishnan R., 2019, INTELL SYST APPL, V940, P1070
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Peng X, 2003, OPTIK, V114, P69, DOI 10.1078/0030-4026-00224
   Sadkhan SB, 2016, AL SAD INT C MULT IT
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Sathiyamurthi P, 2019, J TEST EVAL, V47, P3028, DOI 10.1520/JTE20170283
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Sathiyamurthi P., 2021, J CHENGDU UNIV TECHN, V26, P1
   Slimani D, 2018, PROCEDIA COMPUT SCI, V128, P79, DOI 10.1016/j.procs.2018.03.011
   Stallings W., 2006, Cryptography and Network Security, V4th
   Venkat M., 2006, INT J NETW SECUR, V7, P15
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang XY, 2012, OPT COMMUN, V285, P562, DOI 10.1016/j.optcom.2011.10.098
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P124, DOI 10.1016/j.cnsns.2009.03.035
   Wu XY, 2007, PHYS LETT A, V365, P403, DOI 10.1016/j.physleta.2007.01.034
   Yang T, 1997, IEEE T CIRCUITS-I, V44, P976, DOI 10.1109/81.633887
   ZASLAVSKY GM, 1978, PHYS LETT A, V69, P145, DOI 10.1016/0375-9601(78)90195-0
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zheng Fan, 2008, Journal of China Universities of Posts and Telecommunications, V15, P64, DOI 10.1016/S1005-8885(08)60109-0
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 50
TC 15
Z9 15
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6331
EP 6349
DI 10.1007/s11042-021-11757-4
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740597400001
DA 2024-07-18
ER

PT J
AU Nandi, U
   Ghorai, A
   Singh, MM
   Changdar, C
   Bhakta, S
   Pal, RK
AF Nandi, Utpal
   Ghorai, Anudyuti
   Singh, Moirangthem Marjit
   Changdar, Chiranjit
   Bhakta, Shubhankar
   Pal, Rajat Kumar
TI Indian sign language alphabet recognition system using CNN with diffGrad
   optimizer and stochastic pooling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Data augmentation; Pooling; Optimizer; Dropout;
   Convolution; Batch normalization
ID GESTURE RECOGNITION; INDEPENDENT SYSTEM; NETWORKS
AB India has the largest deaf population in the world and sign language is the principal medium for such persons to share information with normal people and among themselves. Yet, normal people do not have any knowledge of such language. As a result, there is a huge communication barrier between normal and deaf-dumb persons. Again, sign language interpreters are not easily available and it is a very costly solution for a long period. The sign language recognition system reduces the communication gaps between normal and deaf-dumb persons. The methodologies to recognize Indian sign language are recently in the developing stage and there is no approach to recognize signs in real-time. Here, we have proposed a fingerspelling recognition system of static signs for the Indian sign language alphabet using convolutional neural networks combined with data augmentation, batch normalization, dropout, stochastic pooling, and diffGrad optimizer. To continue the research, a total of 62,400 images of 26 static signs have been taken from various users. The proposed method achieves the highest training and validation accuracy of 99.76% and 99.64%, respectively , that outperforms other examined systems.
C1 [Nandi, Utpal] Vidyasagar Univ, Dept Comp Sci, Midnapore, W Bengal, India.
   [Ghorai, Anudyuti] Kharagpur Coll, Dept Comp Sci, Kharagpur, W Bengal, India.
   [Ghorai, Anudyuti] Kharagpur Coll, BCA, Kharagpur, W Bengal, India.
   [Singh, Moirangthem Marjit] North Eastern Reg Inst Sci & Technol, Dept Comp Sci & Engn, Nirjuli, Arunachal Prade, India.
   [Changdar, Chiranjit] Belda Coll, Dept Comp Sci, Belda, W Bengal, India.
   [Bhakta, Shubhankar] Mahishadal Girls Coll, Dept Comp Sci, Purba Medinipur, W Bengal, India.
   [Pal, Rajat Kumar] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
C3 Vidyasagar University; North Eastern Regional Institute of Science &
   Technology (NERIST); Mahishadal Girls College; University of Calcutta
RP Nandi, U (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore, W Bengal, India.
RI PAL, RAJAT KUMAR K/N-5872-2018; Nandi, Utpal/AAW-9041-2021; Singh,
   Moirangthem Marjit/KPA-8781-2024
OI Nandi, Utpal/0000-0002-9638-1906; Singh, Moirangthem
   Marjit/0000-0002-7314-9645; GHORAI, ANUDYUTI/0000-0002-0320-6333
CR AGRAWAL SC, 2012, 2012 4 INT C INT HUM, P1
   Ahmed W, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P120, DOI 10.1109/INFOSCI.2016.7845312
   AL-Rousan M, 2009, APPL SOFT COMPUT, V9, P990, DOI 10.1016/j.asoc.2009.01.002
   [Anonymous], 2013, Journal of Image and Graphics, DOI DOI 10.12720/JOIG.1.1.34-38
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Dahmani D, 2014, J VIS COMMUN IMAGE R, V25, P1240, DOI 10.1016/j.jvcir.2013.12.019
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dubey SR, 2020, IEEE T NEUR NET LEAR, V31, P4500, DOI 10.1109/TNNLS.2019.2955777
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo D, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152121
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang X, 2019, MULTIMED TOOLS APPL, V79, P1
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kim SY, 2017, IEEE SENS J, V17, P2975, DOI 10.1109/JSEN.2017.2679220
   Kingma D. P., 2014, arXiv
   Kishore PVV, 2016, INT CONF ADV COMPU, P346, DOI 10.1109/IACC.2016.71
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar DA, 2016, 2016 IEEE ANN IND C, P1
   Kumar EK, 2020, NEUROCOMPUTING, V372, P40, DOI 10.1016/j.neucom.2019.09.059
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P8823, DOI 10.1007/s11042-017-4776-9
   Kumar P, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P157, DOI 10.23919/MVA.2017.7986825
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lewis M. P., 2013, Ethnologue: Languages of the World, Seventeenth Edition, V17th
   Mali Deepali, 2019, P INT C COMM INF PRO
   Mehrotra K, 2015, LECT NOTES COMPUT SC, V9164, P528, DOI 10.1007/978-3-319-20801-5_59
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mohandes M, 2012, COMPUT ELECTR ENG, V38, P422, DOI 10.1016/j.compeleceng.2011.10.013
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Naglot D, 2016, 2016 INT C INV COMP, V2, P1, DOI DOI 10.1109/INVENTIVE.2016.7824830
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Raghuveera T, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-019-1250-6
   Rahaman MA, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P192, DOI 10.1109/ICCITechn.2014.7073150
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Sahoo Ashok Kumar, 2020, INDIAN SIGN LANGUAGE, DOI [10.1002/9781119682042.ch2, DOI 10.1002/9781119682042.CH2]
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Shanableh T, 2011, DIGIT SIGNAL PROCESS, V21, P535, DOI 10.1016/j.dsp.2011.01.015
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629481
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Tripathi K, 2015, PROCEDIA COMPUT SCI, V54, P523, DOI 10.1016/j.procs.2015.06.060
   Tripathi K, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2211, DOI 10.1109/ICACCI.2015.7275945
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Uddin M.Y. S., 2016, IEEE SMARTCOMP 16, P1, DOI DOI 10.1109/ICISET.2016.7856532
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Yang WW, 2016, PATTERN RECOGN LETT, V78, P28, DOI 10.1016/j.patrec.2016.03.030
   Yasir F, 2015, 2015 IEEE 8TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA) PROCEEDINGS, P35, DOI 10.1109/IWCIA.2015.7449458
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Zeiler M. D., 2013, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1301.3557
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986
NR 59
TC 12
Z9 12
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9627
EP 9648
DI 10.1007/s11042-021-11595-4
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000740429700011
DA 2024-07-18
ER

PT J
AU Rai, AK
   Om, H
   Chand, S
AF Rai, Arun Kumar
   Om, Hari
   Chand, Satish
TI High-fidelity reversible data hiding technique based on adaptive pairing
   of prediction errors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Rhombus prediction; Adaptive pairing; Pairwise
   embedding
ID PVO; EXPANSION
AB Reversible data hiding (RDH) allows the complete recovery of the cover media after data extraction which makes RDH a popular choice among various information sensitive domains. Till date, a plethora of RDH techniques focusing on high-quality marked images with decent embedding capacity have been proposed. Among them pairwise prediction error expansion and pixel value ordering are the noteworthy introductions. However, there is still a requirement of the work which can provide both high-fidelity stego-image along with high-embedding capacity. In this paper, an attempt has been made to achieve better capacity-distortion tradeoff by adaptively choosing prediction error pairs for embedding. An improved version of pairwise PEE has been proposed that hides the secret data into the cover image in two passes by exploiting adaptive pixel pairing. Firstly, the cover image is divided into two independent sets such that alternate pixels are traversed in each set. Then sequential data embedding is performed on the two independent sets where the rhombus predictor is utilized for calculating prediction errors. The pixels in each set are divided into three-pixel blocks such that the pixels in a block are sorted according to their rhombus mean. In the first pass, the first and last pixels are predicted using their corresponding rhombus means, while in the second pass, they're predicted using the middle pixel. The two prediction errors obtained in each pass are paired together adaptively such that the frequency of embeddable prediction error pairs is increased. It limits the proportion of shifted pixels as well as helps in improving the overall embedding capacity. The experimental results demonstrate that the proposed method achieves reasonable performance improvement when compared with other well-known RDH methods.
C1 [Rai, Arun Kumar; Om, Hari] Indian Sch Mines Dhanbad, Indian Inst Technol, Dhanbad, Bihar, India.
   [Chand, Satish] Jawaharlal Nehru Univ, Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Jawaharlal Nehru
   University, New Delhi
RP Rai, AK (corresponding author), Indian Sch Mines Dhanbad, Indian Inst Technol, Dhanbad, Bihar, India.
EM arunrai.dei@gmail.com; hariom4india@gmail.com; schand20@gmail.com
CR Abbasi R, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3680
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P7125, DOI 10.1007/s11042-018-6469-4
   He WG, 2021, IEEE T IMAGE PROCESS, V30, P5045, DOI 10.1109/TIP.2021.3078088
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   Kao Y., 2018, RECENT ADV INTELLIGE, P280, DOI [10.1007/978-3-030-03745-1_35, DOI 10.1007/978-3-030-03745-1_35]
   Kaur GJ, 2022, INT J SUST DEV WORLD, V29, P18, DOI 10.1080/13504509.2021.1896589
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kumar R, 2020, MULTIMED TOOLS APPL, V79, P22635, DOI 10.1007/s11042-020-09069-0
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ou B, 2019, LECT NOTES COMPUT SC, V11378, P169, DOI 10.1007/978-3-030-11389-6_13
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P26047, DOI 10.1007/s11042-019-7692-3
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Xiang HY, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2585983
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
NR 31
TC 0
Z9 0
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19637
EP 19653
DI 10.1007/s11042-021-11338-5
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000740429700005
DA 2024-07-18
ER

PT J
AU Garg, H
   Sharma, B
   Shekhar, S
   Agarwal, R
AF Garg, Hitendra
   Sharma, Bhisham
   Shekhar, Shashi
   Agarwal, Rohit
TI Spoofing detection system for e-health digital twin using EfficientNet
   Convolution Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital twin; Spoofing; EfficientNet; Authentication system; e-Health
   cloud
ID FINGERPRINT LIVENESS DETECTION; IRIS; TEXTURE; ATTACKS; IMAGES
AB Digital Twin is the mirror image of any living or non-living objects. Digital Twin and Cyber-physical system (CPS) provides a new era for industries especially in the healthcare sector that keeps track of health data of individuals to provide on-demand, fast and efficient services to the users. In the suggested system, various health parameters of the patients are collected through different health instruments, wearable devices that communicate data to the primary database; used for analysis purposes for better diagnosis and training for automated systems. The primary database in a physical object and parallelly maintain virtual object/digital twin of the same in order of analyzing, summarize and mine data for diagnosis, monitoring the patient in real-time. The e-health cloud data need to be protected from unauthorized access by biometric authentication using iris biometric trait. The proposed paper suggested two phases EfficientNet Convolution Neural Network-based framework for identifying the real or spoofed user sample. The proposed system is trained using EfficientNet Convolution Neural Network on different datasets of spoofed and actual iris biometric samples to discriminate the original and spoofed one.
C1 [Garg, Hitendra; Shekhar, Shashi; Agarwal, Rohit] GLA Univ, Mathura, Uttar Pradesh, India.
   [Sharma, Bhisham] Chitkara Univ, Sch Engn & Technol, Baddi, Himachal Prades, India.
C3 GLA University
RP Sharma, B (corresponding author), Chitkara Univ, Sch Engn & Technol, Baddi, Himachal Prades, India.
EM hitendra.garg@gla.ac.in; bhisham.sharma@chitkarauniversity.edu.in;
   Shashi.shekhar@gla.ac.in; rohit.agrwal@gla.ac.in
RI Garg, Hitendra/AAV-6756-2020; Sharma, Bhisham/AAB-7076-2020
OI Sharma, Bhisham/0000-0002-3400-3504; Garg, Dr.
   Hitendra/0000-0002-4273-2328
CR Abhishek K, 2015, PROCEDIA COMPUT SCI, V58, P447, DOI 10.1016/j.procs.2015.08.061
   Agarwal R, 2020, WIRELESS PERS COMMUN, V115, P2627, DOI 10.1007/s11277-020-07700-9
   Agrawal R, 2019, INT J BIOMETRICS, V11, P177, DOI 10.1504/IJBM.2019.099065
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], 2014, NASATM2014218257
   Bahga A, 2013, IEEE J BIOMED HEALTH, V17, P894, DOI 10.1109/JBHI.2013.2257818
   Brettel M., 2017, INT J MECH IND SCI E, V12, P47, DOI DOI 10.5281/ZENODO.1336426
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen R, 2012, PATTERN RECOGN LETT, V33, P1513, DOI 10.1016/j.patrec.2012.04.002
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Framling K, 2003, DEP COMPUTER SCI E B
   Galbally J., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P271, DOI 10.1109/ICB.2012.6199819
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Glaessgen E., 2012, 53 AIAA ASME ASCE AH, DOI DOI 10.2514/6.2012-1818
   Gockel B., 2012, 53 AIAA ASME ASCE AH, P1813
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Grieves M., 2014, White paper
   Grieves M., 2017, TRANSDISCIPLINARY PE, P85, DOI [DOI 10.1007/978-3-319-38756-7_4, 10.1007/978-3-319-38756-7_4]
   Guo L., 2010, P IEEE INT C E HLTH, DOI [10.1109/EDT.2010.5496512, DOI 10.1109/EDT.2010.5496512]
   He CG, 2013, IEEE T BIO-MED ENG, V60, P230, DOI 10.1109/TBME.2012.2222404
   Kannala J, 2012, INT C PATT RECOG, P1363
   Latif G., 2020, Fog Computing for Healthcare 4.0 Environments, P251, DOI [10.1007/978-3-030-46197-3_10, DOI 10.1007/978-3-030-46197-3_10, 10.1007/978-3-030-46197-310, DOI 10.1007/978-3-030-46197-310]
   Liu X, 2017, ENG LET, V25, P360
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Matsumoto T, 2002, LECT NOTES COMPUT SC, V2501, P574
   Nasiri Somayeh, 2019, Acta Inform Med, V27, P253, DOI 10.5455/aim.2019.27.253-258
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   Raja KB, 2015, IEEE T INF FOREN SEC, V10, P2048, DOI 10.1109/TIFS.2015.2440188
   Reifsnider Kenneth., 2013, 54 AIAA ASME ASCE AH, DOI DOI 10.2514/6.2013-1578
   Ruiz-Albacete V, 2008, LECT NOTES COMPUT SC, V5372, P181, DOI 10.1007/978-3-540-89991-4_19
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraj S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1925-y
   Shafto M., 2010, NATL AERONAUTICS SPA
   Sten Antti., 2003, 4th Australian Information Warfare and IT Security Conference, P333
   Tan M., 2020, P 2020 IEEE CVF C CO, P10
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tuegel E., 53 AIAAASMEASCEAHSAS, DOI DOI 10.2514/6.2012-1812
   Tuegel E. J., 2011, International Journal of Aerospace Engineering, V2011, DOI [DOI 10.1155/2011/154798, 10.1155/2011/154798]
   Van Gorp P, 2014, IEEE J BIOMED HEALTH, V18, P36, DOI 10.1109/JBHI.2013.2257821
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yao Q, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0104-3
NR 46
TC 16
Z9 16
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26873
EP 26888
DI 10.1007/s11042-021-11578-5
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000739790800006
DA 2024-07-18
ER

PT J
AU Xia, DW
   Bai, Y
   Zheng, YL
   Hu, Y
   Li, YT
   Li, HQ
AF Xia, Dawen
   Bai, Yu
   Zheng, Yongling
   Hu, Yang
   Li, Yantao
   Li, Huaqing
TI A parallel SP-DBSCAN algorithm on spark for waiting spot recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data analytics; Image processing; Waiting spot recommendation; Taxi
   GPS trajectory data; DBSCAN; Spark; Silhouette coefficient; Pickup rate
AB It is challenging for complex urban transportation networks to recommend taxi waiting spots for mobile passengers because the traditional centralized mining platform cannot address the storage and calculation problems of GPS trajectory big data, and especially the boundary identification of DBSCAN is difficult on the Spark parallel processing framework. To this end, we propose a parallel DBSCAN optimization algorithm with the silhouette coefficient and the pickup rate on Spark in this paper, named SP-DBSCAN, where users merely input one parameter to complete the distributed recommendation of the best waiting spot. Specifically, under the Hadoop distributed computing platform, a general framework of distributed modeling for waiting spot recommendation on Spark is developed to solve the distributed storage and parallel computing issues of the serial algorithm in handling data partition and clustering of large-scale traffic data on a single machine. Moreover, we put forward a parallel SP-DBSCAN algorithm on Spark to recommend the best waiting spot for passengers, where the traditional DBSCAN algorithm is optimized via the silhouette coefficient and the boarding ratio to address the parameter sensitive problem and the issue of the center of the non-convex clustering graph is solved by giving one cluster with two centroids in the clustering hotspot areas. Finally, experimental results on four groups of real-world taxi GPS trajectory data sets demonstrate that compared with C-DBSCAN and P-DBSCAN, the recognition rate of SP-DBSCAN is increased by 1.6%, 6.2%, 3.47%, and 5.8%, respectively. The empirical study indicates that the clustering region generated by our SP-DBSCAN algorithm can satisfy the requirements that passengers can ride in the hotspot area when they have not successfully hitchhiked at a specific location and turned to the next spot randomly.
C1 [Xia, Dawen; Bai, Yu; Zheng, Yongling] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Yantao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Chongqing University; Southwest University -
   China
RP Xia, DW (corresponding author), Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.; Li, HQ (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI CHEN, MINGWEI/KHT-6744-2024
OI Li, Huaqing/0000-0001-6310-8965; Xia, Dawen/0000-0002-0151-9643
FU National Natural Science Foundation of China [61762020, 61773321,
   62162012, 62173278, 62072061]; Science and Technology Talents Fund for
   Excellent Young of Guizhou, China [QKHPTRC20195669]; Science and
   Technology Support Program of Guizhou, China [QKHZC2021YB531];
   Scientific Research Platform Project of Guizhou Minzu University
   [[2021]04]
FX This work described in this paper was supported in part by the National
   Natural Science Foundation of China (Grant nos. 61762020, 61773321,
   62162012, 62173278, and 62072061), the Science and Technology Talents
   Fund for Excellent Young of Guizhou, China (Grant no. QKHPTRC20195669),
   the Science and Technology Support Program of Guizhou, China (Grant no.
   QKHZC2021YB531), and the Scientific Research Platform Project of Guizhou
   Minzu University (Grant no. GZMUSYS[2021]04). The authors would like to
   thank Datatang (Beijing) Technology Co., Ltd. for providing the
   experimental data.
CR Akbari Z, 2016, IFIP ADV INF COMM TE, V475, P280, DOI 10.1007/978-3-319-44944-9_24
   Alshammari H, 2018, IEEE T CLOUD COMPUT, V6, P1031, DOI 10.1109/TCC.2016.2535261
   [Anonymous], 2012, P ACM SIGKDD INT WOR
   Asadianfam S, 2020, MULTIMED TOOLS APPL, V79, P24645, DOI 10.1007/s11042-020-09099-8
   Chen C, 2014, IEEE T INTELL TRANSP, V15, P1451, DOI 10.1109/TITS.2014.2298892
   Chmiel W, 2016, MULTIMED TOOLS APPL, V75, P10529, DOI 10.1007/s11042-016-3367-5
   Farajzadeh N, 2018, MULTIMED TOOLS APPL, V77, P6775, DOI 10.1007/s11042-017-4597-x
   Han DW, 2018, IEEE INT CONF BIG DA, P305, DOI 10.1109/BigData.2018.8622258
   Han DW, 2016, IEEE SYM PARA DISTR, P1393, DOI 10.1109/IPDPSW.2016.57
   He YB, 2014, FRONT COMPUT SCI-CHI, V8, P83, DOI 10.1007/s11704-013-3158-3
   Heidari S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0236-x
   Hou J, 2018, NEURAL COMPUT APPL, V30, P99, DOI 10.1007/s00521-016-2699-4
   Hou QH, 2019, NEURAL COMPUT APPL, V31, P4703, DOI 10.1007/s00521-018-3447-8
   Hu H, 2020, NEURAL COMPUT APPL, V32, P6481, DOI 10.1007/s00521-018-03983-z
   Huang F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121301
   Jiang XM, 2005, J TRANSP ENG, V131, P771, DOI 10.1061/(ASCE)0733-947X(2005)131:10(771)
   Lai WH, 2019, IEEE ACCESS, V7, P104085, DOI 10.1109/ACCESS.2019.2931334
   Lei XJ, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5578-9
   Li LT, 2020, INFORM SYST, V91, DOI 10.1016/j.is.2020.101504
   Li YD, 2016, MULTIMED TOOLS APPL, V75, P11683, DOI 10.1007/s11042-015-2676-4
   Liu P, 2018, MULTIMED TOOLS APPL, V77, P10867, DOI 10.1007/s11042-017-5364-8
   Luo GC, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P548, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.85
   Marinakis V, 2020, FUTURE GENER COMP SY, V110, P572, DOI 10.1016/j.future.2018.04.062
   Miao F, 2016, IEEE T AUTOM SCI ENG, V13, P463, DOI 10.1109/TASE.2016.2529580
   Peixoto DA, 2019, DISTRIB PARALLEL DAT, V37, P697, DOI 10.1007/s10619-018-7254-0
   Qiu Z, 2014, LECT NOTES COMPUT SC, V8485, P793, DOI 10.1007/978-3-319-08010-9_85
   Qu ZW, 2019, IEEE ACCESS, V7, P62273, DOI 10.1109/ACCESS.2019.2916342
   Rafi M, 2019, MULTIMED TOOLS APPL, V78, P19735, DOI 10.1007/s11042-019-7153-z
   Rong HG, 2020, IEEE ACCESS, V8, P10528, DOI 10.1109/ACCESS.2020.2965171
   Rong HG, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1346, DOI 10.1109/SmartWorld.2018.00234
   Segatori A, 2018, IEEE T FUZZY SYST, V26, P174, DOI 10.1109/TFUZZ.2016.2646746
   Starczewski A, 2019, LECT NOTES ARTIF INT, V11509, P420, DOI 10.1007/978-3-030-20915-5_38
   Sun SL, 2011, IEEE T INTELL TRANSP, V12, P466, DOI 10.1109/TITS.2010.2093575
   Wang C, 2020, IEEE T PARALL DISTR, V31, P2346, DOI 10.1109/TPDS.2020.2990924
   Wang HZ, 2017, INFORM SCIENCES, V388, P62, DOI 10.1016/j.ins.2017.01.016
   Wang L, 2020, IEEE T INTELL TRANSP, V21, P2216, DOI 10.1109/TITS.2019.2933497
   Wang W, 2014, LECT NOTES ARTIF INT, V8933, P293, DOI 10.1007/978-3-319-14717-8_23
   Xia DW, 2016, NEUROCOMPUTING, V179, P246, DOI 10.1016/j.neucom.2015.12.013
   Yuan NJ, 2013, IEEE T KNOWL DATA EN, V25, P2390, DOI 10.1109/TKDE.2012.153
   Zhang J, 2017, MULTIMED TOOLS APPL, V76, P12005, DOI 10.1007/s11042-016-3936-7
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P321
NR 41
TC 8
Z9 9
U1 6
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4015
EP 4038
DI 10.1007/s11042-021-11639-9
EA NOV 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722792800001
DA 2024-07-18
ER

PT J
AU Mu, D
   Yue, CL
AF Mu, Di
   Yue, Chaolong
TI Machine recognition efficiency study of safety signs based on image
   degradation simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Safety signs; Image degradation; Machine recognition; Convolutional
   neural network
ID SPEED-LIMIT SIGN; TRAFFIC SIGNS; DESIGN; SYSTEM; COLOR; SHAPE
AB This study focuses on the influence of image degradation on machine recognition of safety signs. This paper attempts to classify and grade the image degradation of safety signs. By the means of simulation, this paper also tries to break the limit of real-time image recognition. In this paper, the image degradation of safety signs is classified into 12 types. Each type is simulated by different ways of picture processing. All the pictures are performed machine recognition by convolutional neural network, and the accuracy is recorded. The mechanism of image degradation affecting the recognition efficiency is studied, and an A/B test with real-time safety signs is conducted to evaluate the performance. The results show that the effect of pixel displacement on the recognition efficiency is generally lower than the effect of pixel replacement by calculation. The effect on the recognition efficiency is smaller with less pixel displacement and simpler calculation. Overlay and fusion make the recognition efficiency unstable. The recognition efficiency of real-time safety signs will be higher when the test group contains degraded images as samples. The main part of a safety sign is very important in the recognition process and should be dealt with appropriate protection.
C1 [Mu, Di] Chinese Acad Sci, Inst Sci & Dev, Beijing 100190, Peoples R China.
   [Mu, Di] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Yue, Chaolong] Natl Cultural Heritage Adm, Natl Ctr Archaeol, Beijing 100013, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Mu, D (corresponding author), Chinese Acad Sci, Inst Sci & Dev, Beijing 100190, Peoples R China.; Mu, D (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM mudonata@hotmail.com; cl.yue@uch-china.com
FU National Ethnic Affairs Commission of the People's Republic of China
   [2021-GMC-013]; China Charity Alliance [2020ZLJH-23]; Institutes of
   Science and Development of the Chinese Academy of Sciences [Y9X1831Q];
   National Office for Philosophy and Social Sciences of China [19AZD019]
FX This paper is supported by the National Ethnic Affairs Commission of the
   People's Republic of China (2021-GMC-013), the China Charity Alliance
   (2020ZLJH-23), the Institutes of Science and Development of the Chinese
   Academy of Sciences (Y9X1831Q), and the National Office for Philosophy
   and Social Sciences of China (19AZD019).
CR Abdi L, 2018, SIGNAL IMAGE VIDEO P, V12, P75, DOI 10.1007/s11760-017-1132-5
   Ai CB, 2016, TRANSPORT RES C-EMER, V63, P96, DOI 10.1016/j.trc.2015.12.002
   [Anonymous], 2015, PLOS ONE, DOI DOI 10.1371/JOURNAL.PONE.0120885
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Balali V, 2017, ADV ENG INFORM, V32, P263, DOI 10.1016/j.aei.2017.03.006
   Balducci F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124147
   Balog M, 2016, L N INST COMP SCI SO, V166, P584, DOI 10.1007/978-3-319-33681-7_49
   Ben Romdhane N, 2016, LECT NOTES COMPUT SC, V9730, P341, DOI 10.1007/978-3-319-41501-7_39
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Chang CW, 2010, J PSYCHOLINGUIST RES, V39, P21, DOI 10.1007/s10936-009-9123-5
   CHEN Y, 2016, MATEC WEB C, V42
   Ciresan D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1918, DOI 10.1109/IJCNN.2011.6033458
   Gonzalez-Reyna SE, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/364305
   Farhat W, 2019, J AMB INTEL HUM COMP, V10, P491, DOI 10.1007/s12652-017-0673-3
   Gim J, 2015, LECT NOTES COMPUT SC, V9164, P437, DOI 10.1007/978-3-319-20801-5_48
   Gomes SL, 2017, NEURAL COMPUT APPL, V28, pS573, DOI 10.1007/s00521-016-2388-3
   Gong YS, 2016, LECT NOTES ELECTR EN, V348, P553, DOI 10.1007/978-81-322-2580-5_50
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gudigar A, 2019, NEURAL COMPUT APPL, V31, P395, DOI 10.1007/s00521-017-3063-z
   Gudigar A, 2017, MULTIMED TOOLS APPL, V76, P6973, DOI 10.1007/s11042-016-3321-6
   Gudigar A, 2016, MULTIMED TOOLS APPL, V75, P333, DOI 10.1007/s11042-014-2293-7
   Hao Q, 2020, IEEE ACCESS, V8, P13769, DOI 10.1109/ACCESS.2020.2964314
   Harisubramanyabalaji SP, 2018, LECT NOTES COMPUT SC, V11094, P548, DOI 10.1007/978-3-319-99229-7_49
   Hazelhoff L, 2014, MACH VISION APPL, V25, P1893, DOI 10.1007/s00138-014-0628-z
   Hienonen P, 2017, LECT NOTES COMPUT SC, V10617, P212, DOI 10.1007/978-3-319-70353-4_19
   International Organization for Standardization (ISO), 2011, 70102011 ISO, P14
   Keser T, 2018, TEH VJESN, V25, P23, DOI 10.17559/TV-20150901133605
   Li H., 2017, COAL EC RES, V37, P38
   Lin CC, 2012, SENSORS-BASEL, V12, P6415, DOI 10.3390/s120506415
   Liu CS, 2019, IEEE ACCESS, V7, P86578, DOI 10.1109/ACCESS.2019.2924947
   López G, 2016, ACCIDENT ANAL PREV, V96, P130, DOI 10.1016/j.aap.2016.08.008
   Madani A, 2018, NEURAL COMPUT APPL, V30, P2807, DOI 10.1007/s00521-017-2887-x
   Nartey OT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092684
   O'Connor PDT., 2012, PRACTICAL RELIABILIT, P4
   Prieto MS, 2009, IMAGE VISION COMPUT, V27, P673, DOI 10.1016/j.imavis.2008.07.006
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Shao FM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103192
   Soilan M, 2016, INT ARCH PHOTOGRAMM, V41, P717, DOI 10.5194/isprsarchives-XLI-B3-717-2016
   Souani C, 2014, J REAL-TIME IMAGE PR, V9, P79, DOI 10.1007/s11554-013-0348-z
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Wang GY, 2014, VISUAL COMPUT, V30, P539, DOI 10.1007/s00371-013-0879-0
   Wu F, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01775-5
   Yan G, 2017, J INTELL FUZZY SYST, V33, P873, DOI 10.3233/JIFS-162138
   Yin SY, 2015, SENSORS-BASEL, V15, P2161, DOI 10.3390/s150102161
   Yu YT, 2016, ISPRS J PHOTOGRAMM, V113, P106, DOI 10.1016/j.isprsjprs.2016.01.005
   Zaklouta F, 2014, ROBOT AUTON SYST, V62, P16, DOI 10.1016/j.robot.2012.07.019
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   Zhang Y., 2016, URGENT RESCUE, V42, P37
   Zhang Z, 2017, SAFETY SCI, V91, P132, DOI 10.1016/j.ssci.2016.07.021
NR 49
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2127
EP 2143
DI 10.1007/s11042-021-11369-y
EA OCT 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000709303300002
DA 2024-07-18
ER

PT J
AU Li, XY
   Chen, ZQ
AF Li, Xinye
   Chen, Zeqian
TI Single image super-resolution reconstruction based on fusion of internal
   and external features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internal features; External features; SFT module; Single image
   super-resolution; Deep residual network
AB Recent advances in image super-resolution (SR) explore the power of deep learning to achieve a better reconstruction performance. The deep reconstruction methods mostly reconstruct the super-resolution image based on a large amount of external data training. In order to make full use of the internal features of the image, we propose a novel network for SR called super-resolution network by fusing internal and external features (SRNIF). Specifically, we use the self-similar image itself as the prior knowledge and propose a fully convolutional deep neural network (called Internal Feature Enhancement module, IFE) to extract the internal features of the image so as to obtain detailed texture of the inputted image. Then, the detailed features extracted by the internal feature enhancement module are embedded into the residual network, and the spatial feature transform (SFT) module is used to form the residual module. A deep residual network based on the fusion of internal and external features is built. The proposed method comes with a strong early reconstruction ability and can create the final high-resolution image step by step. Experimental results show that the method has enhanced the texture characteristics and quality of the reconstructed image, and the visual effect and peak signal-to-noise ratio (PSNR) has been improved.
C1 [Li, Xinye; Chen, Zeqian] North China Elect Power Univ, Dept Elect & Commun Engn, Baoding, Hebei, Peoples R China.
   [Li, Xinye] North China Elect Power Univ, Hebei Key Lab Power Internet Things Technol, Baoding 071003, Hebei, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Chen, ZQ (corresponding author), North China Elect Power Univ, Dept Elect & Commun Engn, Baoding, Hebei, Peoples R China.
EM 243553789@qq.com
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bruna J., 2016, ICLR, P1
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Gao M., 2018, MATEC WEB C, P1
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Izonin Ivan, 2015, 2015 Xth International Scientific and Technical Conference - Computer Sciences and Information Technologies (CSIT). Proceedings, P25, DOI 10.1109/STC-CSIT.2015.7325423
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   LIU D., 2018, ADV NEURAL INF PROCE, V31, P1673, DOI [DOI 10.48550/ARXIV.1806.02919, 10.48550/arXiv.1806.02919]
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Michaeli T, 2013, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2013.121
   Peleshko Dmytro, 2016, International Journal of Intelligent Systems and Applications, V8, P1, DOI 10.5815/ijisa.2016.12.01
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P235, DOI 10.1109/DSMP.2016.7583548
   Rashkevych Y, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P944, DOI 10.1109/UKRCON.2017.8100390
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Singh A, 2015, LECT NOTES COMPUT SC, V9004, P552, DOI 10.1007/978-3-319-16808-1_37
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tirer T, 2019, IEEE SIGNAL PROC LET, V26, P1080, DOI 10.1109/LSP.2019.2920250
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang Yang, 2019, INT C LEARN REPR
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhangyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301266
   ZONTAK M, 2011, PROC CVPR IEEE, P977, DOI DOI 10.1109/CVPR.2011.5995401
NR 44
TC 5
Z9 5
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1589
EP 1605
DI 10.1007/s11042-021-11400-2
EA OCT 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000704962000002
DA 2024-07-18
ER

PT J
AU Saracevic, M
   Sharma, SK
   Ahmad, K
AF Saracevic, Muzafer
   Sharma, Sudhir Kumar
   Ahmad, Khaleel
TI A novel block encryption method based on Catalan random walks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Catalan objects; Random walks; Data encryption; Security
   analysis; Multimedia security
ID SECRET-KEY AGREEMENT; ALGORITHM; TECHNOLOGY; EFFICIENT; NUMBERS
AB This paper presents a novel encryption method based on individual block ciphering using Catalan random walks. This paper aims to offer some new possibilities of multimedia data protection to realize the rights of participants in the multimedia distribution chain (image, text, video, sound). Also, the emphasis is on advanced analysis of Catalan numbers and their combinatorial representations in multimedia security. The proposed method consists of five phases: conversion, division, selection, encryption, and generation. We presented the application of our method in ensuring the security of multimedia content. The proposed method was implemented in Java. In the experimental testing, we provide the time and space complexity of Catalan keys generation and Maurer's universal statistical test for the proposed method. Also, we state security analysis using machine learning methods and comparative analysis with existing methods of encrypting data into a blockchain.
C1 [Saracevic, Muzafer] Univ Novi Pazar, Dept Comp Sci, Novi Pazar, Serbia.
   [Sharma, Sudhir Kumar] Inst Informat Technol & Management, Dept Comp Sci, Delhi, India.
   [Ahmad, Khaleel] Maulana Azad Natl Urdu Univ, Dept Comp Sci & Informat Technol, Hyderabad, India.
RP Ahmad, K (corresponding author), Maulana Azad Natl Urdu Univ, Dept Comp Sci & Informat Technol, Hyderabad, India.
EM muzafers@uninp.edu.rs; sharmasudhir08@gmail.com;
   khaleelahmad@manuu.edu.in
RI Saracevic, Muzafer/N-9130-2015; Ahmad, Khaleel/GPK-2715-2022; Sharma,
   Sudhir/ITT-7007-2023
OI Saracevic, Muzafer/0000-0003-2577-7927; Ahmad,
   Khaleel/0000-0002-5682-7184; Sharma, Sudhir/0000-0001-6932-9160; Sharma,
   Sudhir Kumar/0000-0003-4838-8481
CR Ablayev FM, 2018, LOBACHEVSKII J MATH, V39, P957, DOI 10.1134/S1995080218070028
   Albahrani EA, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102445
   [Anonymous], 2009, Catalan Numbers with Applications
   [Anonymous], 2005, CATALAN ADDENDUM ENU
   Balzarova MA, 2021, CORP GOV-INT J BUS S, V21, P159, DOI 10.1108/CG-08-2020-0328
   Dubovitskaya A, 2020, ONCOLOGY-BASEL, V98, P403, DOI 10.1159/000504325
   Fedorova EP, 2020, EUR J CONTEMP EDUC, V9, P552, DOI 10.13187/ejced.2020.3.552
   Feng T, 2021, CMC-COMPUT MATER CON, V66, P871, DOI 10.32604/cmc.2020.012146
   Filimonau V, 2020, INT J HOSP MANAG, V87, DOI 10.1016/j.ijhm.2019.102383
   Gilad-Bachrach R., 2004, P 21 INT C MACH LEAR, P43, DOI [10.1145/1015330.1015352, DOI 10.1145/1015330.1015352]
   Guo LY, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102741
   Kapalova N, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1788292
   Kendon VM, 2006, PHILOS T R SOC A, V364, P3407, DOI 10.1098/rsta.2006.1901
   Lee SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091127
   Li LF, 2017, INT C WAVEL ANAL PAT, P93, DOI 10.1109/ICWAPR.2017.8076670
   Li X, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P901, DOI [10.1109/SIPROCESS.2019.8868638, 10.1109/siprocess.2019.8868638]
   Liang M, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-2612-z
   Luo W, 2020, BASIC CLIN PHARMACOL, V126, P217
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Manzoor A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (ICBC), P99, DOI [10.1109/BLOC.2019.8751336, 10.1109/bloc.2019.8751336]
   Maurer U. M., 1992, Journal of Cryptology, V5, P89, DOI 10.1007/BF00193563
   MAURER UM, 1993, IEEE T INFORM THEORY, V39, P733, DOI 10.1109/18.256484
   Omar IA, 2021, ARAB J SCI ENG, V46, P3001, DOI 10.1007/s13369-020-04989-3
   Pal O, 2021, ICT EXPRESS, V7, P76, DOI 10.1016/j.icte.2019.08.002
   Pal O, 2020, IEEE T CONSUM ELECTR, V66, P1, DOI 10.1109/TCE.2019.2959629
   Pal O, 2019, MULTIMED TOOLS APPL, V78, P18835, DOI 10.1007/s11042-019-7257-5
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   Rodrigo MNN, 2020, BUILDINGS-BASEL, V10, DOI 10.3390/buildings10080140
   Saba, 2018, MATHCODE
   Sanders J, 2020, ANN STAT, V48, P3488, DOI 10.1214/19-AOS1939
   Sapra R, 2021, INT J HEALTHC INF SY, V16, P1, DOI 10.4018/IJHISI.20210401.oa1
   Saracevic M, 2021, J INF SCI ENG, V37, P469, DOI 10.6688/JISE.202103_37(2).0012
   Saracevic M, 2020, IET INTELL TRANSP SY, V14, P1456, DOI 10.1049/iet-its.2019.0855
   Saracevic M, 2019, FUTURE GENER COMP SY, V100, P186, DOI 10.1016/j.future.2019.05.010
   Saracevic M, 2018, ACTA POLYTECH HUNG, V15, P91
   Saracevic MH, 2021, IEEE T RELIAB, V70, P819, DOI 10.1109/TR.2020.3010973
   Kumar AS, 2021, CONCURRENT ENG-RES A, V29, P249, DOI 10.1177/1063293X211008586
   Wang J, 2020, TEH VJESN, V27, P1774, DOI 10.17559/TV-20200108173930
   Xu C, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500601
   Yang CN, 2011, IEEE T COMPUT, V60, P1503, DOI 10.1109/TC.2010.242
   Zhang HJ, 2020, BASIC CLIN PHARMACOL, V126, P183
NR 41
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36667
EP 36684
DI 10.1007/s11042-021-11497-5
EA SEP 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000696768700003
DA 2024-07-18
ER

PT J
AU Gautam, A
   Raman, B
AF Gautam, Anjali
   Raman, Balasubramanian
TI Brain strokes classification by extracting quantum information from CT
   scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature extraction; Local binary pattern; Ischemic
   stroke; Hemorrhagic stroke; Computed tomography
ID FEATURE DESCRIPTOR; PATTERNS; IMAGES; SCALE
AB Brain strokes are considered a worldwide medical emergency. In this paper, we present a new feature extractor that can classify brain computed tomography (CT) scan images into normal, ischemic stroke or hemorrhagic stroke. The proposed feature extractor is based on comparing neighbours with the center pixel where diagonal neighbours are thresholded with the average intensity of whole image. The remaining horizontal and vertical pixels are obtained by thresholding them with their adjacent neighbour. Thereafter, binary values of the obtained images are used to generate the pattern code for the center pixel. Further, in such a way patter code is computed for whole image which is then used to generate 1-D feature vector known as a local neighbourhood pattern (LNP) descriptor by extracting quantum information from the image. The effectiveness of our feature extracted is proved by conducting experiments on real CT scan images of patients' brain. For experiments, we have taken nine different classifiers to identify efficacy obtained by extracting LNP features. We have also compared the results obtained by LNP with the results of local binary patterns (LBP) variants, local ternary patterns (LTP), local wavelet patterns (LWP) and local diagonal extrema patterns (LDEP) descriptors. All the experimental results demonstrate that the proposed feature descriptor gives high classification accuracy as compared to other state-of-the-art feature descriptors.
C1 [Gautam, Anjali; Raman, Balasubramanian] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
   [Gautam, Anjali] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Roorkee
RP Gautam, A (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.; Gautam, A (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM anjaligautam@iiita.ac.in; balarfma@iitr.ac.in
FU Ministry of Human Resource Development, Government of India, India
   [MHC-02-23-200-428]
FX This study was funded by the Ministry of Human Resource Development,
   Government of India, India (grant number MHC-02-23-200-428).
CR Abdel-Hamid L, 2020, J DIGIT IMAGING, V33, P151, DOI 10.1007/s10278-019-00189-0
   Berbar MA, 2014, VISUAL COMPUT, V30, P19, DOI 10.1007/s00371-013-0774-8
   Dang YJ, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2004-9
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Gattringer T, 2018, ISCHAEMIC STROKE YOU, V113
   Gautam A, 2020, PATTERN ANAL APPL, V23, P797, DOI 10.1007/s10044-019-00838-8
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guyon I, 2005, FEATURE EXTRACTION F, P1
   Jeena RS, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION & COMPUTING INDIA (ICCC), P366, DOI 10.1109/ICCC.2015.7432922
   Jenitta A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0799-z
   Kanchana R, 2020, BIOMED ENG LETT, V10, P333, DOI 10.1007/s13534-020-00158-5
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Kumar PK, 2019, SN APPL SCI, V46
   Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Mehtre BM, 1998, INFORM PROCESS MANAG, V34, P109, DOI 10.1016/S0306-4573(97)00049-6
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Putzu L, 2014, ARTIF INTELL MED, V62, P179, DOI 10.1016/j.artmed.2014.09.002
   Rebouças PP, 2017, COMPUT METH PROG BIO, V148, P27, DOI 10.1016/j.cmpb.2017.06.011
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Reshef A, 2008, J NUCL MED, V49, P1520, DOI 10.2967/jnumed.107.043919
   Ruan Y, 2016, QUANTUM INF PROCESS, V15, P4049, DOI 10.1007/s11128-016-1391-z
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Sathish D, 2019, VISUAL COMPUT, V35, P57, DOI 10.1007/s00371-017-1447-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Vesey AT, 2017, CIRC-CARDIOVASC IMAG, V10, DOI 10.1161/CIRCIMAGING.116.004976
   Yu LH, 2018, SIGNAL IMAGE VIDEO P, V12, P247, DOI 10.1007/s11760-017-1152-1
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang RJ, 2017, ARTIF INTELL MED, V83, P44, DOI 10.1016/j.artmed.2017.05.006
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
NR 36
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 15927
EP 15943
DI 10.1007/s11042-021-11342-9
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000695454300001
DA 2024-07-18
ER

PT J
AU Vishnoi, VK
   Kumar, K
   Kumar, B
AF Vishnoi, Vibhor Kumar
   Kumar, Krishan
   Kumar, Brajesh
TI A comprehensive study of feature extraction techniques for plant leaf
   disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer Vision; Image processing; Plant leaf diseases; Feature
   extraction; Classification; Machine learning
ID IMAGE FEATURES; COLOR FEATURES; CLASSIFICATION; IDENTIFICATION;
   SEGMENTATION; RECOGNITION; FUSION; DESCRIPTORS; SUPERPIXEL; SVM
AB Agriculture has been the most primary source of the livelihood of man for thousands of years. Even today, it provides subsistence to about 50% of the world population. Plant diseases are the serious cause of big losses to crop production every year worldwide. It is necessary to keep the plants healthy at various stages of their growth/development to deal with the financial losses from plant diseases. Symptoms of infections are visible mainly at plant leaves; thus leaves are commonly used to detect and identify the diseases. Detecting the disease through visual observation is itself a challenging task and requires a lot of human expertise. Image processing techniques along with computational intelligence or soft computing techniques can be used to provide a better assistance for disease detection to the farmers. A disease in plants can be detected based on its symptoms extracted in the form of features. Feature extraction techniques thus play a vital role in such systems. The paper emphasizes on the review of hand-crafted and deep learning based feature extraction with their merits and demerits. It provides a comprehensive discussion on a variety of image features such as color, texture, and shape for various disorders in different cultures.
C1 [Vishnoi, Vibhor Kumar; Kumar, Krishan] Gurukula Kangri Vishwavidyalaya, Dept Comp Sci, Haridwar 249404, Uttarakhand, India.
   [Kumar, Brajesh] MJP Rohilkhand Univ, Dept Comp Sci & IT, Bareilly 243006, Uttar Pradesh, India.
C3 Gurukul Kangri Vishwavidyalaya; Mahatma Jyotiba Phule Rohilkhand
   University
RP Vishnoi, VK (corresponding author), Gurukula Kangri Vishwavidyalaya, Dept Comp Sci, Haridwar 249404, Uttarakhand, India.
EM rs.vibhorkvishnoi@gkv.ac.in; krishan.kumar@gkv.ac.in; bkumar@mjpru.ac.in
RI Kumar, Brajesh/C-6216-2018; Vishnoi, Vibhor/ABH-1446-2020
OI Kumar, Brajesh/0000-0001-8100-7287; Vishnoi, Vibhor/0000-0002-6682-4171;
   KUMAR, KRISHAN/0000-0002-9296-1655
CR Abed S, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P297, DOI 10.1109/ISCAIE.2018.8405488
   Aduwo J. R., 2010, P ICDM WORKSH, P114
   Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Anami Basavaraj S., 2020, Information Processing in Agriculture, V7, P272, DOI 10.1016/j.inpa.2019.08.005
   [Anonymous], 2011, Int J Image Process
   Anthonys G, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P403, DOI 10.1109/ICIINFS.2009.5429828
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Asfarian A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P77, DOI 10.1109/IC3INA.2013.6819152
   Bai XB, 2017, COMPUT ELECTRON AGR, V136, P157, DOI 10.1016/j.compag.2017.03.004
   Bashir K, 2019, MEHRAN UNIV RES J EN, V38, P239, DOI 10.22581/muet1982.1901.20
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bera T, 2019, SURVEY RICE PLANT DI, DOI [10.1007/978-981-13-1501-5, DOI 10.1007/978-981-13-1501-5]
   Bernardes A.A., 2013, Topics in Medical Image Processing and Computational Vision, P67, DOI DOI 10.1007/978-94-007
   Bruce A, 1996, IEEE SPECTRUM, V33, P26, DOI 10.1109/6.540087
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7_17
   Chouhan SS, 2020, ARCH COMPUT METHOD E, V27, P611, DOI [10.1007/s11831-019-09324-0, 10.33552/abeb.2018.01.000510]
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   Cruz A, 2019, COMPUT ELECTRON AGR, V157, P63, DOI 10.1016/j.compag.2018.12.028
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dandawate Y, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P794, DOI 10.1109/ICACCI.2015.7275707
   Deshapande A.S., 2019, Fungal Disease Detection in Maize Leaves Using Haar wavelet Features, DOI [10.1007/978-981-13-1742-2, DOI 10.1007/978-981-13-1742-2]
   Deshpande T., 2017, PRS Legislative, Research, V53, P6
   Dubey SR, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P346, DOI 10.1109/ICCCT.2012.76
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gawali PD., 2017, INT J RECENT INNOV E, V2, P90
   Gharge S., 2015, Emerging Research in Computing, Information, Communication and Applications, P493, DOI [10.1007/978-81-322-2553-9_44, DOI 10.1007/978-81-322-2553-9_44]
   Ghosh M, 2019, EVOL INTELL, V12, P713, DOI 10.1007/s12065-019-00279-6
   Hallau L, 2018, PLANT PATHOL, V67, P399, DOI 10.1111/ppa.12741
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jadhav S. B., 2016, IAES Int. J. Artif. Intell. (IJ-AI), V5, P13, DOI 10.11591/ijai.v5.i1.pp13-21
   Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858
   Jolly P, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P178, DOI 10.1109/SITIS.2016.36
   Joshi AA, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P471, DOI 10.1109/CAST.2016.7915015
   Karadag K, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2019.01.001
   Kaur Kawaljit, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P183, DOI 10.1109/ICOEI.2017.8300913
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kulkarni AH., 2012, Inter J Modern Eng Res, V2, P3661
   Kumar B, 2020, INT J REMOTE SENS, V41, P6248, DOI 10.1080/01431161.2020.1736732
   Kusumo BS, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P93, DOI 10.1109/IC3INA.2018.8629507
   Liu H, 2008, CH CRC DATA MIN KNOW, P3
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lowe D.G., 1999, PROC INT C COMPUTER
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pires RDL, 2016, COMPUT ELECTRON AGR, V125, P48, DOI 10.1016/j.compag.2016.04.032
   Luo J, 2015, J ELECTR COMPUT ENG, V2015, DOI 10.1155/2015/164547
   Maenpaa T., 2003, The Local binary pattern approach to texture analysis: Extenxions and applications
   Mainkar P.M., 2015, INT J INNOV EMERG RE, V2, P139
   Manjarrez-Sachez J, 2020, IEEE LAT AM T, V18, P1487, DOI 10.1109/TLA.2020.9111686
   Martinez JM, 2003, JTC1SC29WG11 ISOIEC
   Masazhar A. N. I., 2017, BOOK DIGITAL IMAGE P, P1, DOI 10.1109/ICSIMA.2017.8311978
   Mejía-Lavalle M, 2013, 2013 INTERNATIONAL CONFERENCE ON MECHATRONICS, ELECTRONICS AND AUTOMOTIVE ENGINEERING (ICMEAE 2013), P115, DOI 10.1109/ICMEAE.2013.46
   Ministryof Agriculture & FarmersWelfare GoI, 2018, ANN REP 2018 19
   Mohan KJ., 2016, INT J COMPUT APPL, V144, P34, DOI DOI 10.5120/IJCA2016910505
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar U, 2015, ADV INTELL SYST, V323, P641, DOI 10.1007/978-3-319-11310-4_55
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Orillo J.W., 2014, P 2014 INT C HUM NAN, P1, DOI [10.1109/HNICEM.2014.7016248, DOI 10.1109/HNICEM.2014.7016248]
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Patil P, 2017, IEEE I C COMP INT CO, P1071
   Phadikar Santanu, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P420, DOI 10.1109/ICCITECHN.2008.4803079
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Prajapati BS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2499, DOI 10.1109/ICEEOT.2016.7755143
   Prasad S, 2012, LECT NOTES COMPUT SC, V7677, P372, DOI 10.1007/978-3-642-35380-2_44
   Pujari Jagadeesh D., 2013, International Journal of Image, Graphics and Signal Processing, V6, P24, DOI 10.5815/ijigsp.2014.01.04
   Pujari JD, 2016, INT J INTERACT MULTI, V3, P6, DOI 10.9781/ijimai.2016.371
   Pujari JD, 2015, PROCEDIA COMPUT SCI, V46, P1802, DOI 10.1016/j.procs.2015.02.137
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Ramakrishnan M, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P964, DOI 10.1109/ICCSP.2015.7322641
   Ramesh Shima, 2018, 2018 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C). Proceedings, P41, DOI 10.1109/ICDI3C.2018.00017
   Renugopal K., 2015, INT J ENG RES TECHNO, V4, P919
   Revathi P., 2014, Int. J. Eng. Sci. Technol., V3, P22
   Rothe PR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   SABROL H, 2016, INDIAN J SCI TECHNOL, V9, pN1252, DOI DOI 10.17485/ijst/2016/v9i44/92825
   Sabrol H, 2017, INT J ELECT COMPUT E, V7, P194, DOI [10.11591/ijece.v7i1.11531, DOI 10.11591/IJECE.V7I1.11531]
   Sabrol H., 2016, INT J COMPUT SCI INF, V14, P622
   Samajpati BJ, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1015, DOI 10.1109/ICCSP.2016.7754302
   Sannakki SS, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT), DOI 10.1109/ICCCNT.2013.6726616
   Sengar N, 2018, COMPUTING, V100, P1189, DOI 10.1007/s00607-018-0638-1
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Shinde R.C., 2015, INT J ADV RES, V3, P522
   Shrivastava S., 2014, Automatic Brown Spot and Frog Eye Detection from the Image Captured in the Field, V4, P131
   Singh K., 2019, INT J ELECTR COMPUT, V9, P660, DOI [DOI 10.11591/IJECE.V9I1.PP660-666, 10.11591/ijece.v9i1]
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P419, DOI 10.1109/ICACEA.2015.7164741
   Song Kai, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P246, DOI 10.1109/ICMTMA.2011.66
   Stanchev PL, 2004, Proceedings of the Seventh IASTED International Conference on Computer Graphics and Imaging, P395
   Sudha V P, 2017, INT J COMPUTER TREND, V43, P138, DOI 10.14445/22312803/IJCTT-V43P121
   Tian Y, 2011, INTELL AUTOM SOFT CO, V17, P519, DOI 10.1080/10798587.2011.10643166
   Vishnoi VK, 2021, J PLANT DIS PROTECT, V128, P19, DOI 10.1007/s41348-020-00368-0
   Waghmare Harshal, 2016, 2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN), P513, DOI 10.1109/SPIN.2016.7566749
   Wang LW, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P286, DOI 10.1109/CISP.2014.7003793
   Yang M., 2008, PATTERN RECOGN, P43, DOI DOI 10.5772/6237
   Yao Q, 2009, 2009 INTERNATIONAL CONFERENCE ON ENGINEERING COMPUTATION, P79, DOI 10.1109/ICEC.2009.73
   Zhang DY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0187470
   Zhang M, 2011, PATTERN RECOGN LETT, V32, P2036, DOI 10.1016/j.patrec.2011.08.003
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang SW, 2017, COMPUT ELECTRON AGR, V140, P338, DOI 10.1016/j.compag.2017.06.016
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhang YC, 2007, INT C WAVEL ANAL PAT, P124
   Zhang Z., 2014, SENSORS TRANSDUCERS, V166, P181
NR 106
TC 24
Z9 24
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 367
EP 419
DI 10.1007/s11042-021-11375-0
EA SEP 2021
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000694787500003
DA 2024-07-18
ER

PT J
AU Zhao, J
   Chen, ZX
   Wu, QMJ
   Li, XM
   Cai, L
   Zhu, K
AF Zhao, Jie
   Chen, Zhenxue
   Wu, Q. M. Jonathan
   Li, Xianming
   Cai, Lei
   Zhu, Kai
TI Improved edge-guided network for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Edge prior; Feature fusion; Convolutional
   neural network; Feature extraction
AB In recent years, deep learning has been successfully applied to image super-resolution. It is still a challenge to reconstruct high-frequency details from low-resolution images. However, many works lack attention to the high-frequency part. We find that edge prior information can be used to extract high-frequency parts and applying soft edges to image reconstruction has achieved great results. Inspired by this, we focus on how to make full use of edge information to generate high-frequency details. We propose an improved edge-guided neural network for single image super-resolution (IEGSR), which makes full use of the edge prior information to reconstruct images with more abundant high-frequency information. For high-frequency information, we propose an edge-net to generate image edges better. For low-frequency information, we propose a global and local feature extraction module (GLM) to reconstruct the texture details. For the fusion of high-frequency information and low-frequency information, we propose a progressive fusion method, which can greatly reduce the number of parameters. Extensive experimental results demonstrate that our method can obtain images with sharper details. Applying our model to the Manga109 test set, the PSNR value of 4 times image super-resolution is as high as 39.02.
C1 [Zhao, Jie; Chen, Zhenxue; Li, Xianming; Zhu, Kai] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
   [Cai, Lei] Henan Inst Sci & Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
C3 Shandong University; University of Windsor; Henan Institute of Science &
   Technology
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM jiezhao@mail.sdu.edu.cn; chenzhenxue@sdu.edu.cn; jwu@uwindsor.ca;
   mingli@sdu.edu.cn; cailei2014@126.com; zhukaiqaq@mail.sdu.edu.cn
RI Zhang, Youmin/AAT-7095-2020; Zhu, Kai/M-9959-2015
OI Zhang, Youmin/0000-0002-9731-5943; Zhu, Kai/0000-0002-9451-0890; Chen,
   Zhenxue/0000-0001-9637-5170
FU National Natural Science Foundation of China [61876099]; National Key
   R&D Program of China [2019YFB1311001]; Scientific and Technological
   Development Project of Shandong Province [2019GSF111002]; Shenzhen
   Science and Technology Research and Development Funds
   [JCYJ20180305164401921]; Foundation of Ministry of Education Key
   Laboratory of System Control and Information Processing [Scip201801];
   Foundation of Key Laboratory of Intelligent Computing & Information
   Processing of Ministry of Education [2018ICIP03]; Foundation of State
   Key Laboratory of Integrated Services Networks [ISN20-06]
FX This work was supported in part by the National Natural Science
   Foundation of China (61876099), in part by the National Key R&D Program
   of China (2019YFB1311001), in part by the Scientific and Technological
   Development Project of Shandong Province (2019GSF111002), in part by the
   Shenzhen Science and Technology Research and Development Funds
   (JCYJ20180305164401921), in part by the Foundation of Ministry of
   Education Key Laboratory of System Control and Information Processing
   (Scip201801), in part by the Foundation of Key Laboratory of Intelligent
   Computing & Information Processing of Ministry of Education
   (2018ICIP03), and in part by the Foundation of State Key Laboratory of
   Integrated Services Networks (ISN20-06). Jie Zhao and Zhenxue Chen
   contributed equally to this work and should be considered as the
   co-first authors.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Almalioglu Y, 2020, IEEE T MED IMAGING, V39, P4297, DOI 10.1109/TMI.2020.3016744
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hayat K, 2018, DIGIT SIGNAL PROCESS, V81, P198, DOI 10.1016/j.dsp.2018.07.005
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim K, 2018, ARXIV COMPUTER VISIO
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee J, 2020, IEEE J EM SEL TOP C, V10, P320, DOI 10.1109/JETCAS.2020.3014454
   Li F, 2018, IEEE ACCESS, V6, P33421, DOI 10.1109/ACCESS.2018.2846363
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu H, 2019, INFORM SCIENCES, V473, P44, DOI 10.1016/j.ins.2018.09.018
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Ma JB, 2020, IEEE T MED IMAGING, V39, P2920, DOI 10.1109/TMI.2020.2980839
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Pang YW, 2019, IEEE T INF FOREN SEC, V14, P3322, DOI 10.1109/TIFS.2019.2916592
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23815, DOI 10.1007/s11042-018-5915-7
   Shao WQ, 2020, INT J COMPUT VISION, V128, P2107, DOI 10.1007/s11263-019-01269-y
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Toutounchi F, 2018, IEEE INT CONF MULTI, P01
   Wang C, 2019, LIGHTWEIGHT IMAGE SU
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wen ZJ, 2020, COMPUT VIS IMAGE UND, V199, DOI 10.1016/j.cviu.2020.103007
   Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 42
TC 11
Z9 12
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 343
EP 365
DI 10.1007/s11042-021-11429-3
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000694561400001
DA 2024-07-18
ER

PT J
AU Goshvarpour, A
   Goshvarpour, A
AF Goshvarpour, Atefeh
   Goshvarpour, Ateke
TI Eye-blinking analysis as a marker of emotional states
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye-blinking; Human emotion recognition; Feedforward neural network;
   k-Nearest neighbor
ID RECOGNITION; EEG; TRACKING; SAD; ECG
AB In recent years, designing intelligent humanoid robots/computers capable of recognizing and responding to human emotions becomes the objective of many studies. To achieve this goal, various stimuli and paradigms were evaluated in laboratory set-ups. In bio-signal processing approaches, the primary focus of experiments has been devoted to the signal which reflects the inner status of man in encountering affective stimuli. However, external statuses, like eye features, can also provide pertinent information about emotions. The main objective of this study was to evaluate the ability of the eye-blinking measures in a single modality form for designing an affect recognizer. We analyzed different statistical, spectral- and nonlinear-based features of the signals of the SEED-IV database in sad, happy, fear, and neutral affective states. Additionally, several decision-making strategies including naive Bayes, support vector machine, feedforward neural network (NN), and the k-nearest neighbor were carried out. The role of parameterization of classification algorithms on emotion recognition rates was also investigated. The NN classifier in tenfold cross-validation outperformed the other classification schemes. By implementing NN with a hidden layer size of 8, a classification accuracy of 98.67% was achieved for fear/neutral discrimination. The critical role of classification parameter adjustment to the results was also revealed. However, we did not conclude the optimal classifier parameter to obtain maximum performance. The impressive performance of the presented algorithm makes our proposed framework a superior one compared to the state-of-the-art approaches and paves the way for designing future emotion recognition systems based on eye-blinking data.
C1 [Goshvarpour, Atefeh] Sahand Univ Technol, Fac Elect Engn, Dept Biomed Engn, Tabriz, Iran.
   [Goshvarpour, Ateke] Imam Reza Int Univ, Dept Biomed Engn, Rezvan Campus,Phalestine Sq, Mashhad, Razavi Khorasan, Iran.
C3 Sahand University of Technology
RP Goshvarpour, A (corresponding author), Imam Reza Int Univ, Dept Biomed Engn, Rezvan Campus,Phalestine Sq, Mashhad, Razavi Khorasan, Iran.
EM af_goshvarpour@sut.ac.ir; ateke.goshvarpour@gmail.com
RI Goshvarpour, Atefeh/AAC-3145-2020; Goshvarpour, Ateke/IZD-8225-2023;
   Goshvarpour, Ateke/AAB-5275-2019
OI Goshvarpour, Atefeh/0000-0002-0343-4344; Goshvarpour,
   Ateke/0000-0002-5185-5645; Goshvarpour, Ateke/0000-0002-5185-5645
CR Al-gawwam S, 2018, IEEE INT SYMP SIGNAL, P388, DOI 10.1109/ISSPIT.2018.8642682
   Alghowinem S., 2014, Intelligent Systems for Science and Information, V542, P261, DOI [DOI 10.1007/978-3-319-04702-7_15, 10.1007/978-3-319, DOI 10.1007/978-3-319]
   Becker H, 2020, IEEE T AFFECT COMPUT, V11, P244, DOI 10.1109/TAFFC.2017.2768030
   Bek J, 2020, J NEUROSCI METH, V331, DOI 10.1016/j.jneumeth.2019.108524
   Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629
   Black MH, 2017, NEUROSCI BIOBEHAV R, V80, P488, DOI 10.1016/j.neubiorev.2017.06.016
   Breakspear S., 2015, P IEEE INT C AUT FAC
   Cohn JF, 2003, BEHAV RES METH INS C, V35, P420, DOI 10.3758/BF03195519
   Ekman Paul., 1973, DARWIN FACIAL EXPRES
   Goshvarpour A, 2020, PHYS ENG SCI MED, V43, P119, DOI 10.1007/s13246-019-00825-7
   Goshvarpour A, 2020, J MED BIOL ENG, V40, P451, DOI 10.1007/s40846-020-00526-7
   Goshvarpour A, 2019, COGN NEURODYNAMICS, V13, P161, DOI 10.1007/s11571-018-9516-y
   Goshvarpour A, 2018, CHAOS SOLITON FRACT, V114, P400, DOI 10.1016/j.chaos.2018.07.035
   Goshvarpour A, 2017, BIOMED J, V40, P355, DOI 10.1016/j.bj.2017.11.001
   Goshvarpour A, 2017, AUSTRALAS PHYS ENG S, V40, P617, DOI 10.1007/s13246-017-0571-1
   Goshvarpour A, 2017, SIGNAL IMAGE VIDEO P, V11, P1347, DOI 10.1007/s11760-017-1092-9
   Goshvarpour A, 2020, COGN COMPUT, V12, P602, DOI 10.1007/s12559-019-09699-z
   Goshvarpour A, 2017, BIOMED SIGNAL PROCES, V38, P67, DOI 10.1016/j.bspc.2017.05.006
   Goshvarpour A, 2017, AUSTRALAS PHYS ENG S, V40, P277, DOI 10.1007/s13246-017-0530-x
   Goshvarpour A, 2016, NONLIN DYNAM PSYCHOL, V20, P353
   Gruebler A, 2014, IEEE T AFFECT COMPUT, V5, P227, DOI 10.1109/TAFFC.2014.2313557
   Guo JJ, 2019, IEEE ENG MED BIO, P3071, DOI [10.1109/EMBC.2019.8856563, 10.1109/embc.2019.8856563]
   HIGUCHI T, 1988, PHYSICA D, V31, P277, DOI 10.1016/0167-2789(88)90081-4
   Hsu YL, 2020, IEEE T AFFECT COMPUT, V11, P85, DOI 10.1109/TAFFC.2017.2781732
   KOWLER E, 1995, VISION RES, V35, P1897, DOI 10.1016/0042-6989(94)00279-U
   Lamba P. S., 2018, INT 110 J ELECT COMP, V8
   LIPTON RB, 1980, PSYCHIAT RES, V3, P193, DOI 10.1016/0165-1781(80)90036-0
   Lu YF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1170
   MACKINTOSH JH, 1983, BRIT J PSYCHIAT, V143, P55, DOI 10.1192/bjp.143.1.55
   Maffei A, 2019, PHYSIOL BEHAV, V204, P256, DOI 10.1016/j.physbeh.2019.02.037
   McMonnies C. W., 2010, ENCY EYE, P202, DOI [10.1016/b978-0-12-374203-2.00079-8, DOI 10.1016/B978-0-12-374203-2.00079-8]
   Nardelli M, 2015, IEEE T AFFECT COMPUT, V6, P385, DOI 10.1109/TAFFC.2015.2432810
   Partala T., 2000, P 2000 S EYE TRACKIN, P123, DOI [DOI 10.1145/355017.355042, 10.1145/355017.355042]
   Schmidtmann G, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520961116
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   Singh MI, 2017, BIOCYBERN BIOMED ENG, V37, P498, DOI 10.1016/j.bbe.2017.05.004
   Smith ML, 2005, PSYCHOL SCI, V16, P184, DOI 10.1111/j.0956-7976.2005.00801.x
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
   Zheng WL, 2014, IEEE ENG MED BIO, P5040, DOI 10.1109/EMBC.2014.6944757
NR 39
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33727
EP 33746
DI 10.1007/s11042-021-11304-1
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687926000001
DA 2024-07-18
ER

PT J
AU Al-Azawi, M
   Yang, YJ
   Istance, H
AF Al-Azawi, Mohammad
   Yang, Yingjie
   Istance, Howell
TI Two-stage salient object identification and segmentation based on
   irregularity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Irregularity; Saliency; Image Processing; Thresholding; Fuzzy
ID VISUAL-ATTENTION; REGION DETECTION; MODEL; ALGORITHM; DISTANCE; MAPS
AB Saliency extraction is a technique inspired by the human approach in processing a selected portion of the visual information received. This feature in the human visual system helps reduce the processing the brain needs to extract important information and neglect general and unimportant information. This paper presents a novel approach to identifying the saliency of regions in a scene from which objects likely to be salient can be extracted. The proposed approach uses two stages, namely, local saliency identification (LSI) and global saliency identification (GSI) and uses irregularity as the saliency measure in both stages. Local saliency uses the structure of the object to determine saliency while global saliency identifies the saliency of the region based on the contrast in relation to the entire background. An object is considered to be salient if it satisfies both local and global criteria. In this work, the key challenges and limitations of existing methods, such as the sensitivity to texture and noise, the need to manually define certain parameters, and the need to have pre-knowledge of the nature of the image, were considered and appropriate solutions have been suggested. The proposed algorithm was tested on a set of 1000 images selected from MSRA saliency identification standard dataset and benchmarked with state-of-the-art approaches. The results obtained showed very good efficiency and this is evident from the evaluation values obtained from the used evaluation method, e. g. the value of the F-measure, reached 96.5 per cent in some cases. The limitation of the approach was with complex objects which themselves comprising more than one important region such as an image of a person. This will be discussed thoroughly in the result section.
C1 [Al-Azawi, Mohammad] Oman Coll Management & Technol, Muscat, Oman.
   [Yang, Yingjie] De Montfort Univ, Inst Artificial Intelligence, Leicester, Leics, England.
   [Istance, Howell] Tampere Univ, TAUCHI, Tampere, Finland.
C3 De Montfort University; Tampere University
RP Al-Azawi, M (corresponding author), Oman Coll Management & Technol, Muscat, Oman.
EM mohd.alazawi@omancollege.edu.om; yyang@dmu.ac.uk; howell.istance@tuni.fi
RI Al-Azawi, Mohammad A. N./A-1777-2018
OI Al-Azawi, Mohammad A. N./0000-0003-3073-610X
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Al-Azawai M., 2019, INT J ENG TECHNOL, V8, P83
   al-Azawi A.n., 2013, International Journal of Computers and Applications, V83, P36, DOI [10.5120/14480-2781, DOI 10.5120/14480-2781]
   Al-Azawi MAN., 2021, LETT COMPUT VIS IMAG, V20, P1, DOI [10.5565/rev/elcvia.1325, DOI 10.5565/REV/ELCVIA.1325]
   Al-Azawi M, 2016, MULTIMED TOOLS APPL, V75, P25, DOI 10.1007/s11042-014-2248-z
   Al-Azawi M, 2014, IEEE INT ADV COMPUT, P946, DOI 10.1109/IAdCC.2014.6779450
   ALAZAWI M, 2013, IEEE INT C COMP INT, DOI DOI 10.1109/ICCIC.2013.6724128
   Azam S, 2016, BENCHMARK COMPUTATIO, P134, DOI DOI 10.5220/0005678701340142
   Banerjee M, 2003, PATTERN RECOGN, V36, P2649, DOI 10.1016/S0031-3203(03)00174-2
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce NDB, 2007, VISUAL CORRELATES FI, P289
   Cha SH, 2002, PATTERN RECOGN, V35, P1355, DOI 10.1016/S0031-3203(01)00118-2
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   CHOI YS, 1995, OPTOMETRY VISION SCI, V72, P439, DOI 10.1097/00006324-199507000-00003
   Davis JW, 2004, P C COMP VIS PATT RE, DOI [10.1109/CVPR.2004.431, DOI 10.1109/CVPR.2004.431]
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Filipe S, 2015, ARTIF INTELL REV, V43, DOI 10.1007/s10462-012-9385-4
   GARG A, 2017, INT J ENG TECHNOLOGY, V9, P2742, DOI [10.21817/ijet/2017/v9i4/170904406, DOI 10.21817/IJET/2017/V9I4/170904406]
   Gide MS, 2012, INT WORK QUAL MULTIM, P200, DOI 10.1109/QoMEX.2012.6263871
   Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hase PAK., 2014, INT J ENG SCI INNOV, V3, P263
   Hashemi S., 2015, CIENCIA NAT, V37, P297, DOI [10.5902/2179460X20786, DOI 10.5902/2179460X20786]
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Hu YQ, 2004, LECT NOTES COMPUT SC, V3332, P993
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kapsalas P., 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P147, DOI 10.1109/CBMI.2008.4564940
   Kim C, 2013, J VISION, V13, DOI 10.1167/13.4.5
   Kim S, 2003, LECT NOTES COMPUT SC, V2728, P39
   Klein RM, 2000, TRENDS COGN SCI, V4, P138, DOI 10.1016/S1364-6613(00)01452-2
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lin DW, 2007, LECT NOTES COMPUT SC, V4810, P389
   Lin YW, 2013, IEEE T PATTERN ANAL, V35, P314, DOI 10.1109/TPAMI.2012.119
   Lin YW, 2010, AAAI CONF ARTIF INTE, P967
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2011, IET IMAGE PROCESS, V5, P122, DOI 10.1049/iet-ipr.2009.0382
   Loupias E, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P518, DOI 10.1109/ICIP.2000.899469
   Luo S., 2013, EUVIP, V2013, P184
   Lyudvichenko V, 2017, INT C INTELL COMP CO, P403, DOI 10.1109/ICCP.2017.8117038
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mitra S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187209
   Pele O, 2008, LECT NOTES COMPUT SC, V5304, P495, DOI 10.1007/978-3-540-88690-7_37
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rahmani R., 2005, ACM WORKSHOP MULTIME, P227, DOI DOI 10.1145/1101826.1101863
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012
   Selvaraj A., 2009, The Open Signal Processing Journal, V2, P14, DOI [DOI 10.2174/1876825300902010014, 10.2174/1876825300902010014]
   Song H., 2006, P 6 WORLD C INT CONT, V2, P10298, DOI [10.1109/WCICA.2006.1714018, DOI 10.1109/WCICA.2006.1714018]
   Stottinger Julian, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204286
   Tasse FP, 2016, SIGGRAPH ASIA 2016 T, P1
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Vinay M. B., 2019, Int. J. Recent Technol. Eng. (IJRTE), V7, P412
   Wang W., 2019, ARXIV190409146
   Yu ZH, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P686
   Zhang H, 2006, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2006.312424
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zhaoyi Deng, 2019, 2019 International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P358, DOI 10.1109/MLBDBI48998.2019.00081
   Zhou B, 2010, PHASE DISCREPANCY AN
   Zhu CB, 2018, MULTIMED TOOLS APPL, V77, P25181, DOI 10.1007/s11042-018-5780-4
NR 67
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33275
EP 33295
DI 10.1007/s11042-021-11378-x
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000685385600001
DA 2024-07-18
ER

PT J
AU Nurseitov, D
   Bostanbekov, K
   Kurmankhojayev, D
   Alimova, A
   Abdallah, A
   Tolegenov, R
AF Nurseitov, Daniyar
   Bostanbekov, Kairat
   Kurmankhojayev, Daniyar
   Alimova, Anel
   Abdallah, Abdelrahman
   Tolegenov, Rassul
TI Handwritten Kazakh and Russian (HKR) database for text recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document analysis and recognition; Handwritten Russian and Kazakh text
   recognition; Benchmark dataset
ID OFF-LINE; WRITER IDENTIFICATION; NEURAL-NETWORK
AB In this paper, we introduce a large scale dataset, called HKR, to address challenging detection and recognition problems of handwritten Russian and Kazakh text in the scanned documents. We present a new Russian and Kazakh database (with about 95% of Russian and 5% of Kazakh words/sentences respectively) for offline handwriting recognition. A few pre-processing and segmentation procedures have been developed together with the database. The database is written in Cyrillic and shares the same 33 characters. Besides these characters, the Kazakh alphabet also contains 9 additional specific characters. This dataset is a collection of forms. The sources of all the forms in the datasets were generated by LaTeXwhich subsequently was filled out by persons with their handwriting. The database consists of more than 1500 filled forms. There are approximately 63000 sentences, more than 715699 symbols produced by approximately 200 different writers. It can serve researchers in the field of handwriting recognition tasks by using deep and machine learning. For experiments, we used several popular text recognition methods for word and line recognition like CTC-based and attention-based methods. The results indicate the diversity of HKR. The dataset is available at .
C1 [Nurseitov, Daniyar; Bostanbekov, Kairat; Alimova, Anel; Abdallah, Abdelrahman] KazMunayGas Engn LLP, Nur Sultan, Kazakhstan.
   [Kurmankhojayev, Daniyar] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
   [Nurseitov, Daniyar; Bostanbekov, Kairat; Alimova, Anel; Abdallah, Abdelrahman; Tolegenov, Rassul] Satbayev Univ Almaty, Alma Ata, Kazakhstan.
C3 Hong Kong Polytechnic University
RP Abdallah, A (corresponding author), KazMunayGas Engn LLP, Nur Sultan, Kazakhstan.; Abdallah, A (corresponding author), Satbayev Univ Almaty, Alma Ata, Kazakhstan.
EM abdoelsayed2016@gmail.com
RI Bostanbekov, Kairat/I-5362-2016; Kurmankhojayev, Daniyar/GZL-1279-2022;
   Abdallah, Abdelrahman/AAF-4672-2021; Abdallah, Abdelrahman/HCI-9483-2022
OI Bostanbekov, Kairat/0000-0003-2869-772X; Kurmankhojayev,
   Daniyar/0000-0002-9723-1336; Abdallah, Abdelrahman/0000-0001-8747-4927; 
FU Ministry of Education and Science of the Republic of Kazakhstan
   [AP05135175]
FX We would like to thank the following people for helping with this
   research project: Maksat Kanatov and Kuanysh Slyamkhan. This work was
   funded by the Ministry of Education and Science of the Republic of
   Kazakhstan (Grant No AP05135175)
CR Abadi Martin, 2016, arXiv
   Abdallah A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120141
   Al-Ma'adeed S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P485, DOI 10.1109/IWFHR.2002.1030957
   Alma'adeed S, 2004, KNOWL-BASED SYST, V17, P75, DOI 10.1016/j.knosys.2004.03.002
   ALMAADEED S, 2012, J ELECT COMPUT ENG
   [Anonymous], 2002, PRIK CIFED
   Augustin E, 2006, P INT WORKSH FRONT H, P231
   Bahdanau D., 2014, 3 INT C LEARN REPR
   Bensefia A, 2005, PATTERN RECOGN LETT, V26, P2080, DOI 10.1016/j.patrec.2005.03.024
   Bhattacharya U, 2012, PATTERN ANAL APPL, V15, P445, DOI 10.1007/s10044-012-0278-6
   Bluche T, 2017, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2017.111
   Bostanbekov, 2020, CHARACTER ERROR RATE
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Daniels ZA, 2013, PROC INT CONF DOC, P1385, DOI 10.1109/ICDAR.2013.280
   Das Soumendu, 2014, International Journal of Image, Graphics and Signal Processing, V7, P9, DOI 10.5815/ijigsp.2015.01.02
   Diem M, 2013, PROC INT CONF DOC, P1422, DOI 10.1109/ICDAR.2013.287
   dos Santos Rodolfo P., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P651, DOI 10.1109/ICDAR.2009.183
   Dreuw Philippe, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3541, DOI 10.1109/ICIP.2011.6116480
   Fiel S, 2013, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2013.114
   Fischer Andreas, 2013, Graph-Based Representations in Pattern Recognition. 9th IAPR-TC-15 International Workshop, GbRPR 2013. Proceedings, P194, DOI 10.1007/978-3-642-38221-5_21
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken, 2014, CONTINUOUS HANDWRITT, P391, DOI DOI 10.1007/978-0-85729-859-1_12
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gatos B, 2006, INT C PATT RECOG, P998
   Geist J., 1994, 2 CENSUS OPTICAL CHA
   Guichard Laurent, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P57, DOI 10.1109/ICFHR.2010.15
   Gunter S., 2003, International Journal on Document Analysis and Recognition, V5, P224, DOI 10.1007/s10032-002-0088-2
   Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hinton G, 2012, Cited on, V14, P2
   Jain R, 2011, PROC INT CONF DOC, P769, DOI 10.1109/ICDAR.2011.159
   John Jomy, 2013, International Journal of Image, Graphics and Signal Processing, V5, P53, DOI 10.5815/ijigsp.2013.04.07
   Kermorvant Christopher, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P241, DOI 10.1109/ICFHR.2010.45
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Lcm HT, LINE LEVEL HANDWRITT
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu HL, 2005, PROC INT CONF DOC, P19
   Maken P, 2021, MULTIMED TOOLS APPL, V80, P24573, DOI 10.1007/s11042-021-10837-9
   Maken P, 2019, CYBERN INF TECHNOL, V19, P51, DOI 10.2478/cait-2019-0015
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   Montreuil Florent, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P853, DOI 10.1109/ICDAR.2009.132
   Net, 2020, NOMEROFF NET AUTOMAT
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Puigcerver J, 2017, PROC INT CONF DOC, P67, DOI 10.1109/ICDAR.2017.20
   Salvi D, 2013, IEEE WORK APP COMP, P505, DOI 10.1109/WACV.2013.6475061
   Scheidl H., 2018, HANDWRITTEN TEXT REC
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Siddiqi I, 2010, PATTERN RECOGN, V43, P3853, DOI 10.1016/j.patcog.2010.05.019
   SMITH SJ, 1994, IEEE T PATTERN ANAL, V16, P915, DOI 10.1109/34.310689
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tao DP, 2014, PATTERN RECOGN LETT, V35, P186, DOI 10.1016/j.patrec.2012.06.014
   Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14
   Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Wshah S, 2012, INT CONF FRONT HAND, P14, DOI 10.1109/ICFHR.2012.264
   Wshah S, 2012, INT C PATT RECOG, P310
   Zamora-Martínez F, 2014, PATTERN RECOGN, V47, P1642, DOI 10.1016/j.patcog.2013.10.020
   Zhou SS, 2014, MULTIMED TOOLS APPL, V71, P1363, DOI 10.1007/s11042-012-1270-2
   Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394
NR 60
TC 7
Z9 7
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 33075
EP 33097
DI 10.1007/s11042-021-11399-6
EA AUG 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684489300002
DA 2024-07-18
ER

PT J
AU Pavlovic, N
   Sarac, M
   Adamovic, S
   Saracevic, M
   Ahmad, K
   Macek, N
   Sharma, DK
AF Pavlovic, Nikola
   Sarac, Marko
   Adamovic, Sasa
   Saracevic, Muzafer
   Ahmad, Khaleel
   Macek, Nemanja
   Sharma, Deepak Kumar
TI An approach to adding simple interface as security gateway architecture
   for IoT device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT security; Gateway security; IoT communication systems; IoT network
   performance
ID 5G
AB It is not a secret that Internet of Things (IoT) devices often come with not so realistic processing power (i.e. processing power and storage requirements) that would provide a basis for strong security and encryption algorithms. This work proposes an approach to adding a simple interface as a security gateway architecture for IoT devices. The security interface provides mapping for the IoT device remote services as long as support for stronger cryptographic algorithms. The solution improves the security of the data that IoT devices send to remote services by performing compatible cryptographic algorithms on the data before it sends to remote services. The result of this work is the development of a security interface that provides support for any cryptographic algorithm, uses Internet Protocol (IP) mapping to prevent access to the devices behind the interface from non-authorized IP addresses. As such it provides robust protection against attacks and data manipulation. The work is tested for memory usage and the strength of the security it provides.
C1 [Pavlovic, Nikola; Sarac, Marko; Adamovic, Sasa] Singidunum Univ, Fac Informat & Comp, Belgrade, Serbia.
   [Saracevic, Muzafer] Univ Novi Pazar, Dept Comp Sci, Novi Pazar, Serbia.
   [Ahmad, Khaleel] Maulana Azad Natl Urdu Univ, Dept Comp Sci & Informat Technol, Hyderabad, India.
   [Macek, Nemanja] Megatrend Univ, Fac Comp Sci, Belgrade, Serbia.
   [Sharma, Deepak Kumar] Netaji Subhas Univ Technol, Dept Informat Technol, Delhi, India.
C3 Netaji Subhas University of Technology
RP Pavlovic, N (corresponding author), Singidunum Univ, Fac Informat & Comp, Belgrade, Serbia.
EM nikola.pavlovic.141@singimail.rs; msarac@singidunum.ac.rs;
   sadamovic@singidunum.ac.rs; muzafers@uninp.edu.rs;
   khaleelahmad@manuu.edu.in; nmacek@megatrend.edu.rs;
   dk.sharma1982@yahoo.com
RI Ahmad, Khaleel/GPK-2715-2022; Šarac, Marko/CAG-4362-2022; Saracevic,
   Muzafer/N-9130-2015; Adamovic, Sasa/AAX-2104-2021
OI Ahmad, Khaleel/0000-0002-5682-7184; Šarac, Marko/0000-0001-8241-2778;
   Saracevic, Muzafer/0000-0003-2577-7927; Adamovic,
   Sasa/0000-0002-2875-685X; Sharma, Deepak Kumar/0000-0001-6117-3464
CR Alrawi O, 2019, P IEEE S SECUR PRIV, P1362, DOI 10.1109/SP.2019.00013
   Andriansyah M, 2017, INT CONF COMP APPL I
   Bechtel MG, 2019, IEEE REAL TIME, P357, DOI 10.1109/RTAS.2019.00037
   Bhat B, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P887, DOI 10.1109/CCAA.2015.7148500
   Buford J, 2009, MORGAN KAUFMANN SERI
   Chavez-Santiago R, 2015, WIRELESS PERS COMMUN, V83, P1617, DOI 10.1007/s11277-015-2467-2
   Cirani S, 2015, IEEE INT CONF SENS, P43
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Iqbal Haroon., 2019, International Journal of Computer Sciences and Engineering, Vol, V7, Issue, P833, DOI [10.26438/ijcse/v7i5.833837, DOI 10.26438/IJCSE/V7I5.833837]
   Kavianpour Alireza, 2017, 2017 IEEE 4th International Conference on Cyber-Security and Cloud Computing (CSCloud), P306, DOI 10.1109/CSCloud.2017.45
   Liu G., 2016, Chin. J. Eng, V8, DOI [DOI 10.1155/2016/5974586, DOI 10.1109/ICNSC.2016.7478980]
   Mahmoud R., 2015, 2015 Journal of Cyber Security and Mobility, P65, DOI DOI 10.13052/JCSM2245-1439.414
   Mahmoud R, 2015, INT CONF INTERNET, P336, DOI 10.1109/ICITST.2015.7412116
   Mavromoustakis CX, 2016, MODEL OPTIM SCI TECH, V8, P1, DOI 10.1007/978-3-319-30913-2
   Mielczarek W, 2015, COMM COM INF SC, V522, P431, DOI 10.1007/978-3-319-19419-6_41
   Mushtaq MF, 2017, INT J ADV COMPUT SC, V8, P333
   Nawir M, 2016, INT CONF ELECTRON D, P321, DOI 10.1109/ICED.2016.7804660
   Neves P, 2017, COMPUT STAND INTER, V54, P229, DOI 10.1016/j.csi.2016.12.008
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P18383, DOI 10.1007/s11042-018-5660-y
   Rong C, 2013, RFID SECURITY, P345, DOI [10.1016/b978-0-12-394397-2.00018-0, DOI 10.1016/B978-0-12-394397-2.00018-0]
   Sarma R, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P162, DOI 10.1109/icscc.2019.8843649
   Sasipriya S, 2016, IEEE I C COMP INT CO, P1021
   Sun HY, 2018, CC'18: PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION, P196, DOI 10.1145/3178372.3179527
   Usha D., 2018, International Journal of Advanced Research, V6, P566, DOI [DOI 10.21474/IJAR01/7839, 10.21474/IJAR01/7839]
   Xin Zhou, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P1118, DOI 10.1109/IFOST.2011.6021216
   Zunino C, 2020, COMPUT STAND INTER, V71, DOI 10.1016/j.csi.2020.103433
NR 26
TC 10
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36931
EP 36946
DI 10.1007/s11042-021-11389-8
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000684489400001
DA 2024-07-18
ER

PT J
AU Narla, VL
   Gulivindala, S
   Chanamallu, SR
   Gangwar, DP
AF Narla, Venkata Lalitha
   Gulivindala, Suresh
   Chanamallu, Srinivasa Rao
   Gangwar, D. P.
TI BCH encoded robust and blind audio watermarking with tamper detection
   using hash
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio Watermarking; BCH coding; Digital rights management;
   False-positive problem; Hash Function; Tamper Detection
ID ALGORITHM; CAPACITY; MODULATION; SCHEME
AB International Federation of Phonographic Industry (IFPI) has laid requirements for digital audio watermarking (DAW) schemes with regard to robustness, imperceptibility and payload. In addition, DAW schemes have to offer audio integrity. Many of the schemes fails to provide both copyright protection and tamper detection. Moreover, tamper detection of audio is not evaluated in quantitative manner. Therefore, a robust and blind DAW scheme has been developed in transform domain to suffice this requirement. Further, an objective performance metric, detection accuracy, is proposed to quantify the performance of tamper detection. In the proposed work, audio is fragmented and transform coefficients are obtained using Wavelet and Cosine Transforms. Watermark image is pre-processed using logistic map and BCH code. This pre-processed image is inserted into singular values of audio signal coefficients through quantization index modulation. Hash is generated with SHA-512 algorithm and is inserted in watermarked audio frames. Hash recovery at the receiver allows to identify any tampering involved in audio viz., deletion, copy-move and substitute attacks. Singular vectors are not required to extract the watermark, thus this method is free from false positive problem and can provide copyright protection. Experimentation is carried out on five different classes of audios which substantiates that robustness, imperceptibility and payload results are acquiescent to IFPI standard. Further, comparative analysis indicates that developed scheme is better when compared with other state-of art-schemes. Consequently, this DAW scheme helps in forensic examination of audio recording for authentication purpose.
C1 [Narla, Venkata Lalitha; Gulivindala, Suresh] GMR Inst Technol, Dept Elect & Commun Engn, Rajam, Andhra Pradesh, India.
   [Chanamallu, Srinivasa Rao] JNTUK Univ Coll Engn, Dept Elect & Commun Engn, Vizianagaram, Andhra Pradesh, India.
   [Gangwar, D. P.] Cent Forens Sci Lab, Chandigarh, Punjab, India.
C3 GMR Institute of Technology; Jawaharlal Nehru Technological University -
   Kakinada
RP Narla, VL (corresponding author), GMR Inst Technol, Dept Elect & Commun Engn, Rajam, Andhra Pradesh, India.
EM lalitha.nv@gmrit.edu.in
RI GULIVINDALA, SURESH/AAN-5146-2020
OI GULIVINDALA, SURESH/0000-0002-8411-8190
CR Ahmad M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070266
   Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Chen XR, 2020, MEDIA CULT SOC, V42, P727, DOI 10.1177/0163443719876617
   Cichowski J, 2015, MULTIMED TOOLS APPL, V74, P4415, DOI 10.1007/s11042-013-1636-0
   Erçelebi E, 2009, DIGIT SIGNAL PROCESS, V19, P265, DOI 10.1016/j.dsp.2008.11.007
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29229, DOI 10.1007/s11042-018-6767-x
   Homburg Helge., 2005, ISMIR, P528
   Hu HT, 2019, IEEE ACCESS, V7, P180395, DOI 10.1109/ACCESS.2019.2958095
   Hu HT, 2017, EURASIP J AUDIO SPEE, P1, DOI 10.1186/s13636-017-0106-4
   Hu HT, 2017, CLUSTER COMPUT, V20, P805, DOI 10.1007/s10586-017-0770-2
   Hu HT, 2016, CIRC SYST SIGNAL PR, V35, P553, DOI 10.1007/s00034-015-0074-9
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Jo D, 2018, IEEE COMMUN LETT, V22, P894, DOI 10.1109/LCOMM.2018.2806482
   Karajeh H, 2019, ANALOG INTEGR CIRC S, V99, P571, DOI 10.1007/s10470-018-1332-0
   Kaur A, 2018, MULTIMEDIA SYST, V24, P341, DOI 10.1007/s00530-017-0545-x
   Kaur A, 2018, ETRI J, V40, P133, DOI 10.4218/etrij.2017-0092
   Lalitha NV, 2013, 2013 IEEE ASIA PACIFIC CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS & ELECTRONICS (PRIMEASIA), P196, DOI 10.1109/PrimeAsia.2013.6731204
   Lalitha NV., 2016, INT J ENG TECHNOLOGY, V8, P486
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Meenakshi K, 2020, MULTIMED TOOLS APPL, V79, P29865, DOI 10.1007/s11042-020-09250-5
   Mehallegue N, 2020, MULTIMED TOOLS APPL, V79, P2031, DOI 10.1007/s11042-019-08271-z
   Pourhashemi SM, 2019, MULTIMED TOOLS APPL, V78, P22883, DOI 10.1007/s11042-019-7595-3
   Shi CH, 2020, IEEE ACCESS, V8, P22249, DOI 10.1109/ACCESS.2020.2970093
   Wang XK, 2014, MULTIMED TOOLS APPL, V71, P1157, DOI 10.1007/s11042-012-1259-x
   Wu QL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050723
   Xiang SJ, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8492672
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 30
TC 5
Z9 5
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32925
EP 32945
DI 10.1007/s11042-021-11370-5
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000683639000001
DA 2024-07-18
ER

PT J
AU Liu, D
   Chen, LX
   Wang, LF
   Wang, ZY
AF Liu, Dong
   Chen, Longxi
   Wang, Lifeng
   Wang, Zhiyong
TI A multi-modal emotion fusion classification method combined expression
   and speech based on attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal emotion classification; Attention mechanism; Feature fusion;
   Spatiotemporal emotional characteristics; Mel Frequency Cepstral
   Coefficient (MFCC); Speech features
AB This paper researches how to use attention mechanism to fuse the time series information of facial expression and speech, and proposes a multi-modal feature fusion emotion recognition model based on attention mechanism. First, facial expression features and speech features are extracted. Facial expression feature extraction, based on C3D-LSTM hybrid model, can effectively obtain the temporal and spatial expression features in videos. For speech feature extraction, Mel Frequency Cepstral Coefficient (MFCC) is used for extracting the initial speech features, and convolution neural network is for further features. Then, a face and speech recognition method based on attention mechanism is proposed. Through the attention analysis of the fusion features, the proposed method can obtain the relationship between the features, so that the features without noise and with strong distinguishability obtain more weight, and reduce the weight of noisy features at the same time. Finally, this method is applied to face expression and speech fusion recognition. The experimental results show that the proposed multi-modal emotion classification model is better than those in other literatures in RML dataset, with an average recognition rate of up to 81.18%.
C1 [Liu, Dong; Chen, Longxi; Wang, Lifeng; Wang, Zhiyong] Shandong Youth Univ Polit Sci, Sch Informat Engn, Jinan 250103, Peoples R China.
C3 Shandong Youth University of Political Science
RP Liu, D (corresponding author), Shandong Youth Univ Polit Sci, Sch Informat Engn, Jinan 250103, Peoples R China.
EM sdyu_dong@163.com
FU Natural Science Foundation of Shandong Province of China
   [ZR202103020833]; Social Science Planning Research Project of Shandong
   Province [18CLYJ50]; Shandong Soft Science Research Program
   [2018RKB01144]; Project of Shandong Province Higher Educational Science
   and Technology Program [J15LN15]
FX This work was supported in part by the Natural Science Foundation of
   Shandong Province of China under Grant ZR202103020833, Social Science
   Planning Research Project of Shandong Province under Grant 18CLYJ50, in
   part by the Shandong Soft Science Research Program under Grant
   2018RKB01144, and in part by The Project of Shandong Province Higher
   Educational Science and Technology Program under Grant J15LN15.
CR Angrick M, 2019, NEUROCOMPUTING, V342, P145, DOI 10.1016/j.neucom.2018.10.080
   Aytar Y., 2016, Advances in neural information processing systems (NeurIPS), V29, P892
   Bodla N, 2017, IEEE WINT CONF APPL, P586, DOI 10.1109/WACV.2017.71
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Feigao, 2020, COMPUT ENG APPL, V56, P140
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Hu YT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1107, DOI 10.1145/2733373.2806293
   Li WJ, 2019, SOFT COMPUT, V23, P11817, DOI 10.1007/s00500-018-03735-0
   Lubis N, 2018, IEICE T INF SYST, VE101D, P2092, DOI 10.1587/transinf.2017EDP7362
   [马江河 Ma Jianghe], 2019, [西安电子科技大学学报, Journal of Xidian University], V46, P143
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Song KS, 2018, INT CONF UBIQ ROBOT, P472, DOI 10.1109/URAI.2018.8441795
   Sun B, 2016, COMM COM INF SC, V663, P621, DOI 10.1007/978-981-10-3005-5_51
   Thulasidharan PP., 2018, INT J COMPUTER ENCES, V06, P95, DOI DOI 10.26438/IJCSE/V6SI6.9598
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
NR 16
TC 1
Z9 1
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41677
EP 41695
DI 10.1007/s11042-021-11260-w
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000682496300004
DA 2024-07-18
ER

PT J
AU Gani, G
   Qadir, F
AF Gani, Gulnawaz
   Qadir, Fasel
TI Copy move forgery detection using DCT, PatchMatch and cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Copy-move image forgery; Discrete Cosine transform;
   Cellular automata
AB Copy-move image forgery is a type of digital image forgery where content is copied and pasted within the same image, either by hiding foreground objects within an image by copying a background region over them or by emphasizing some foreground objects of the image through duplication. To prevent any consequences arising from the consumption of these forged images, many Copy-Move Forgery Detection (CMFD) techniques have been proposed in the past that analyze a suspected input image for a possible copy-move forgery. However, the existing detectors show limited detection accuracy in presence of post-processing manipulations like noise addition, compression, blur etc., which, in turn, are often used to hide the traces of tampering and produce convincing forgeries. In this paper, we propose a block-based CMFD technique which works well under these post-processing manipulations. We use Discrete Cosine Transform and Cellular Automata to extract features from the image blocks, which are subsequently matched using the patch match algorithm. Also, to extract the cloned regions corresponding to the matched features in a reliable way, we propose a simple and efficient CA-based post-processing procedure. The experimental results on the standard dataset demonstrate the effectiveness of our method for detecting copy-move forgeries under diverse post-processing manipulations of noise, compression, blur, brightness change, contrast change and their combinations.
C1 [Gani, Gulnawaz; Qadir, Fasel] Univ Kashmir, Dept Comp Sci, North Campus, Baramulla 193103, Jammu & Kashmir, India.
C3 University of Kashmir
RP Qadir, F (corresponding author), Univ Kashmir, Dept Comp Sci, North Campus, Baramulla 193103, Jammu & Kashmir, India.
EM gulnawazgani@gmail.com; fasel.scholars@gmail.com
RI Gani, Gulnawaz/GYV-5914-2022
OI Gani, Gulnawaz/0000-0001-8309-3123
CR Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al-Qershi OM, 2018, MULTIMED TOOLS APPL, V77, P31807, DOI 10.1007/s11042-018-6201-4
   ALQERSHI OM, 2019, MULTIDIMEN SYST SIGN
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   ARDIZZONE E, 2015, IEEE T INFORM FORENS
   BAKIAH N, 2018, FORENS SCI INT
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   BILLINGS SA, 2003, IEEE T SYST MAN CY B
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Cheng NN, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2929562
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chuang JC, 2019, MULTIMED TOOLS APPL, V78, P35537, DOI 10.1007/s11042-019-08193-w
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Fridrich J, 2003, INT J COMPUT SCI ISS, DOI 10.1109/PACIIA.2008.240
   Gani G, 2021, EVOL SYST-GER, V12, P503, DOI 10.1007/s12530-019-09309-1
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jeelani Z, 2019, J KING SAUD U COMPUT, DOI 10.1016/j.jksuci.2018.12.006
   Jeelani Z, 2018, INT J INTELL COMPUT, V11, P353, DOI 10.1108/IJICC-10-2017-0132
   Kaura WCN, 2018, P 2017 INT C INN INF, DOI 10.1109/ICIIECS.2017.8276160
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li L, 2013, J INFORM HID MULTIME
   LIN C, 2019, MULTIMED TOOLS APPL
   LIU Y, 2020, MULTIMED TOOLS APPL
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Nightingale SJ, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0067-2
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rosin PL, 2010, COMPUT VIS IMAGE UND, V114, P790, DOI 10.1016/j.cviu.2010.02.005
   Roy A, 2020, STUDIES COMPUTATIONA, DOI 10.1007/978-981-10-7644-2_5
   Roy A, 2017, IEEE IMAGE PROC, P4083, DOI 10.1109/ICIP.2017.8297050
   ROY S, 2020, MULTIMED TOOLS APPL
   Soni B, 2019, J INF SECUR APPL, V45, P44, DOI 10.1016/j.jisa.2019.01.007
   SUN X, 2011, IEEE T SYST MAN CY B
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tralic D, 2016, MULTIMED TOOLS APPL, V75, P16881, DOI 10.1007/s11042-015-2961-2
   Wang HR, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/7064131
   Wolfram S., 2002, A new kind of science
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Yang SY, 2018, MULTIMED TOOLS APPL, V77, DOI 10.1007/s11042-017-5190-z
   Yin JL, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102832
   Yu J., 2019, IEEE T NEUR NET LEAR
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 49
TC 3
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32219
EP 32243
DI 10.1007/s11042-021-11174-7
EA JUL 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678013400004
DA 2024-07-18
ER

PT J
AU Zhao, YJ
   Zhang, HB
   Zhang, XL
   Chen, XJ
AF Zhao, Yunji
   Zhang, Haibo
   Zhang, Xinliang
   Chen, Xiangjun
TI Fire smoke detection based on target-awareness and depthwise
   convolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire smoke detection; Target-awareness; Depthwise separable; Fixed
   convolution kernel; TADS
AB Because smoke usually appears before a flame arises, fire smoke detection is significant for early warning systems. This paper proposes a TADS (Target-awareness and Depthwise Separability) algorithm based on target-awareness and depthwise separability. Current deep learning methods with pre-trained convolutional neural networks by abundant and vast datasets are used to realize generic object recognition tasks. As for smoke detection, collecting large quantities of smoke data is challenging for small sample smoke objects. The basis is that the objects of interest can be arbitrary object classes with arbitrary forms. Thus, deep feature maps acquired by target-awareness pre-trained networks are used for modeling these objects of arbitrary forms to distinguish them from unpredictable and complex environments. The authors introduced this scheme to deal with smoke detection. The depthwise separable method with a fixed convolution kernel replacing the training iterations can improve the algorithm's speed to meet the enhanced requirements of real-time fire spreading for detecting speed. The experimental results demonstrate that the proposed algorithm can detect early smoke in real-time, and it is superior to the state-of-the-art methods in terms of accuracy and speed.
C1 [Zhao, Yunji; Zhang, Xinliang] Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Haibo] Xinyang Univ, Sch Big Data & Artificial Intelligence, Xinyang 464000, Henan, Peoples R China.
   [Chen, Xiangjun] Henan Polytech Univ, Coll Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University; Xinyang University; Henan Polytechnic
   University
RP Zhao, YJ (corresponding author), Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo 454000, Henan, Peoples R China.
EM auyjz@hpu.edu.cn
RI zhao, yunji/GRS-8084-2022; Zhang, Haibo/HLP-9266-2023
OI zhao, yunji/0000-0001-6024-9105; 
FU Foundation of Henan Educational Committee [16A413009, 13B413037];
   National Natural Science Foundation of China [61973105, 61573130];
   Fundamental Research Funds for the Universities of Henan Province
   [NSFRF200504]; Key Technologies R\&D Program of Henan Province of China
   [192102210073, 212102210145]
FX We wish to thank the authors of TADT, Faster-RCNN and YOLOv3 for
   providing source code and the University of Salerno for providing the
   fire detection dataset. This research was funded by the Foundation of
   Henan Educational Committee grant number 16A413009 and 13B413037; the
   National Natural Science Foundation of China grant number 61973105 and
   61573130; the Fundamental Research Funds for the Universities of Henan
   Province grant number NSFRF200504; the Key Technologies R\&D Program of
   Henan Province of China grant number 192102210073 and 212102210145.
CR [Anonymous], 2007, IFPA FIR SUPPR DET R
   Appana DK, 2017, INFORM SCIENCES, V418, P91, DOI 10.1016/j.ins.2017.08.001
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bu FJ, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.08.007
   Chunwei T., 2018, COMPUT ENG COMPUT SC, V43, P741
   Gaur A, 2020, FIRE TECHNOL, V56, P1943, DOI 10.1007/s10694-020-00986-y
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guoliang Y., 2018, COMPUT ENG COMPUT SC, V43, P627
   Howard A. G., 2017, PREPRINT
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu YC, 2018, MULTIMED TOOLS APPL, V77, P29283, DOI 10.1007/s11042-018-5978-5
   Jia Y, 2016, FIRE TECHNOL, V52, P1271, DOI 10.1007/s10694-014-0453-y
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199
   Lin GH, 2019, FIRE TECHNOL, V55, P1827, DOI 10.1007/s10694-019-00832-w
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   Morerio P, 2012, IEEE IMAGE PROC, P1041, DOI 10.1109/ICIP.2012.6467041
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Pan HY, 2020, SIGNAL IMAGE VIDEO P, V14, P675, DOI 10.1007/s11760-019-01600-7
   Park KM, 2020, IET IMAGE PROCESS, V14, P1141, DOI 10.1049/iet-ipr.2018.5305
   Park M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082202
   Pundir AS, 2019, FIRE TECHNOL, V55, P2419, DOI 10.1007/s10694-019-00872-2
   Pundir AS, 2017, FIRE TECHNOL, V53, P1943, DOI 10.1007/s10694-017-0665-z
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Shiping Ye, 2017, Pattern Recognition and Image Analysis, V27, P131
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Xu G, 2017, ARXIV PREPRINT ARXIV
   Xu G, 2019, FIRE SAFETY J, V105, P277, DOI 10.1016/j.firesaf.2019.03.004
   Xu G, 2017, FIRE SAFETY J, V93, P53, DOI 10.1016/j.firesaf.2017.08.004
   Ye W, 2015, FIRE SAFETY J, V73, P91, DOI 10.1016/j.firesaf.2015.03.001
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan FN, 2019, NEUROCOMPUTING, V357, P248, DOI 10.1016/j.neucom.2019.05.011
NR 37
TC 12
Z9 15
U1 6
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27407
EP 27421
DI 10.1007/s11042-021-11037-1
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651689300003
DA 2024-07-18
ER

PT J
AU Zhao, Q
AF Zhao, Qiang
TI Research on the application of local binary patterns based on color
   distance in image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color-based LBP; Machine learning; Image classification; Image features
ID FUSION; LBP; RETRIEVAL; FEATURES; SCALE
AB Local Binary Patterns (LBP) is an texture feature, which is widely used in texture discrimination, face recognition, painting classification and other fields. The previous LBP feature extraction methods and many improved algorithms are all based on the gray scale image. Because there is information loss during the conversion from color image to gray image, the LBP methods need combine with other color features to improve the accuracy of classification. In this paper, a LBP encoding method for color image based on color space distance is proposed, which can not only directly achieve LBP feature from color image, but also can be applied to improve various previous methods. The experiment shows that color-based LBP method can filter background information better. With three different classifiers, the accuracy of classification which only used color-based LBP features is about 15% higher than that of existing LBP features. Finally, the application effect in local binary patterns histograms (LBPH) with color-based LBP further proves the advantage.
C1 [Zhao, Qiang] Shanxi Univ, Sch Automat & Software Engn, Taiyuan 030001, Peoples R China.
C3 Shanxi University
RP Zhao, Q (corresponding author), Shanxi Univ, Sch Automat & Software Engn, Taiyuan 030001, Peoples R China.
EM hmoe@vip.qq.com
OI Zhao, Qiang/0000-0002-9506-4140
CR Alamgir N, 2018, FIRE SAFETY J, V102, P1, DOI 10.1016/j.firesaf.2018.09.003
   Belagali P. P., 2015, INT J SCI REIJSR, V4, P1440
   Chandana P., 2015, INT J ADV RES COMPUT, V4, P671, DOI [10.17148/IJARCCE.2015.45142, DOI 10.17148/IJARCCE.2015.45142]
   Ciocca G, 2015, MULTIMED TOOLS APPL, V74, P3013, DOI 10.1007/s11042-013-1766-4
   Das R., 2019, INT C ADV MACH LEARN, P712
   Das R, 2019, NEURAL COMPUT APPL, V31, P675, DOI 10.1007/s00521-017-3099-0
   Fu YL, 2020, WOMEN ENGIN SCIENCE, P301, DOI 10.1007/978-3-030-11866-2_13
   Guarnera F, 2019, IEEE IMAGE PROC, P4594, DOI [10.1109/ICIP.2019.8803502, 10.1109/icip.2019.8803502]
   Hangbyung, 2018, 2018 IEEE INT C VEH, P564
   Hapsani, 2020, INT C SCI TECHN, P1
   Haq M.R., 2019, 2019 International Joint Conference on Neural Network (IJCNN'19), P1
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huss N, 2020, MED TEACH, V42, P1097, DOI 10.1080/0142159X.2020.1797998
   Khammari M, 2019, IET IMAGE PROCESS, V13, P1880, DOI 10.1049/iet-ipr.2018.5560
   Lan RS, 2020, NEURAL COMPUT APPL, V32, P4317, DOI 10.1007/s00521-018-03968-y
   Ledoux A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061404
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nazari M.R., 2010, Int. J. Comput. Appl., V7, P33, DOI DOI 10.5120/1327-1636
   Nicolay, 2018, P IEEE INT C SMART I, P1, DOI DOI 10.1109/ICSIMA.2018.8688781
   Nisa M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144966
   Nithin P., 2019, P IEEE 7 INT C SMART, P1
   Obulesh A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS AND COMPUTATIONAL INTELLIGENCE (ICBDAC), P352, DOI 10.1109/ICBDACI.2017.8070863
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Saleh SA, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P112, DOI 10.1109/ISCO.2017.7855964
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shrivastava N, 2016, MULTIMED TOOLS APPL, V75, P6569, DOI 10.1007/s11042-015-2589-2
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Singh H, 2017, INT J RIVER BASIN MA, V15, P347, DOI 10.1080/15715124.2017.1300159
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   Toreini E, 2017, ACM T PRIV SECUR, V20, DOI 10.1145/3092816
   Veerashetty S, 2020, MULTIMED TOOLS APPL, V79, P9935, DOI 10.1007/s11042-019-7345-6
   Zeebaree Diyar Qader, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P106, DOI 10.1109/ICOASE.2019.8723827
NR 39
TC 10
Z9 10
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27279
EP 27298
DI 10.1007/s11042-021-10996-9
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651346700001
DA 2024-07-18
ER

PT J
AU Kumar, D
AF Kumar, Devender
TI A secure and efficient user authentication protocol for wireless sensor
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; User traceability; Denial of service; Insider
   attack; Wireless sensor networks; Impersonation attack
ID KEY AGREEMENT SCHEME; MUTUAL AUTHENTICATION; CRYPTANALYSIS
AB To provide the secure communication in wireless sensor networks (WSNs) is one of the challenging issues as the channel used is wireless. User authentication is a mechanism which is used to provide the secure communication in them. In this paper, it is devised a secure and efficient user authentication protocol using hash function for WSNs. It is formally analyzed the security of the proposed protocol using random oracle model and showed informally that it is resistant to various known attacks. Its security is formally verified using AVISPA tool. Its performance analysis along with the related schemes is evaluated in terms of security features, computational, communication, storage, and energy consumption costs. It has computational cost of 9 ms and storage cost of 30 bytes, which are less than the related schemes. Also it is more secure than them.
C1 [Kumar, Devender] NSUT, Dept Informat Technol, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Kumar, D (corresponding author), NSUT, Dept Informat Technol, New Delhi, India.
EM dk_iitm@yahoo.co.in
CR [Anonymous], 2002, WSNA '02
   Carlson J, 2003, FIFTH IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, PROCEEDINGS, P21
   Chandrakar P, 2017, COMPUT COMMUN, V110, P26, DOI 10.1016/j.comcom.2017.05.009
   Claycomb WR, 2011, J NETW COMPUT APPL, V34, P418, DOI 10.1016/j.jnca.2010.03.004
   Das AK, 2016, SECUR COMMUN NETW, V9, P2070, DOI 10.1002/sec.1464
   Das AK, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2933
   Das AK, 2016, PEER PEER NETW APPL, V9, P223, DOI 10.1007/s12083-014-0324-9
   Das AK, 2015, WIRELESS PERS COMMUN, V82, P1377, DOI 10.1007/s11277-015-2288-3
   Das ML, 2009, IEEE T WIREL COMMUN, V8, P1086, DOI 10.1109/TWC.2008.080128
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Gope P, 2016, IEEE T IND ELECTRON, V63, P7124, DOI 10.1109/TIE.2016.2585081
   He DJ, 2010, AD HOC SENS WIREL NE, V10, P361
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He DB, 2015, INFORM SCIENCES, V321, P263, DOI 10.1016/j.ins.2015.02.010
   Hui-Feng Huang, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P27, DOI 10.1109/IIHMSP.2010.14
   Jiang Q, 2017, COMPUT ELECTR ENG, V63, P182, DOI 10.1016/j.compeleceng.2017.03.016
   Jiang Q, 2017, IEEE ACCESS, V5, P3376, DOI 10.1109/ACCESS.2017.2673239
   Jiang Q, 2016, J NETW COMPUT APPL, V76, P37, DOI 10.1016/j.jnca.2016.10.001
   Jiang Q, 2015, PEER PEER NETW APPL, V8, P1070, DOI 10.1007/s12083-014-0285-z
   Kaur D, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3745
   Khan MK, 2010, SENSORS-BASEL, V10, P2450, DOI 10.3390/s100302450
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Ko LC, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS 2008), P191
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kumar D, 2020, IET NETW, V9, P315, DOI 10.1049/iet-net.2019.0009
   Kumar D, 2019, J AMB INTEL HUM COMP, V10, P641, DOI 10.1007/s12652-018-0712-8
   Kumar P, 2012, SENSORS-BASEL, V12, P1625, DOI 10.3390/s120201625
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Kumari S, 2016, COMPUT NETW, V104, P137, DOI 10.1016/j.comnet.2016.05.007
   Li CT, 2013, SENSORS-BASEL, V13, P9589, DOI 10.3390/s130809589
   Li X, 2016, SECUR COMMUN NETW, V9, P2643, DOI 10.1002/sec.1214
   Niu YJ, 2011, COMMUN NONLINEAR SCI, V16, P1986, DOI 10.1016/j.cnsns.2010.08.015
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Shnayder V., 2004, Proceedings of the 2nd international conference on Embedded Networked Sensor Systems SenSys04, P188, DOI DOI 10.1145/1031495.1031518
   Shojafar M., 2020, J SUPERCOMPUT, P1
   Tseng HR, 2007, GLOB TELECOMM CONF, P986
   Tsern-Huei Lee, 2008, 2008 Second International Conference on Sensor Technologies and Applications (SENSORCOMM), P657, DOI 10.1109/SENSORCOMM.2008.43
   Vaidya B, 2010, INT J COMMUN SYST, V23, P1201, DOI 10.1002/dac.1097
   Wang D, 2018, IEEE T DEPEND SECURE, V15, P708, DOI 10.1109/TDSC.2016.2605087
   Wang XY, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/11/110503
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P99, DOI 10.1016/j.cnsns.2008.05.002
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wong KHM, 2006, IEEE INTERNATIONAL CONFERENCE ON SENSOR NETWORKS, UBIQUITOUS, AND TRUSTWORTHY COMPUTING, VOL 1, PROCEEDINGS, P244
   Wu F, 2018, PEER PEER NETW APPL, V11, P1, DOI 10.1007/s12083-016-0485-9
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
NR 45
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27131
EP 27154
DI 10.1007/s11042-021-10950-9
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650615800001
DA 2024-07-18
ER

PT J
AU Chan, SX
   Huang, C
   Bai, C
   Ding, WL
   Chen, SY
AF Chan, Sixian
   Huang, Cheng
   Bai, Cong
   Ding, Weilong
   Chen, Shengyong
TI Res2-UNeXt: a novel deep learning framework for few-shot cell image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation of medical images; Data augmentation; Deep learning; Image
   processing
ID CONVOLUTIONAL NEURAL-NETWORKS; BRAIN-TUMOR SEGMENTATION
AB Recently, developing more accurate and more efficient deep learning algorithms for medical images segmentation attracts more and more attentions of researchers. Most of methods increase the depth of the network to replace with acquiring multi-information. The costs of training images annotation are too expensive to label by hand. In this paper, we propose a multi-scale and better performance deep architecture for medical image segmentation, named Res2-UNeXt. Our architecture is an encoder-decoder network with Res2XBlocks. The Res2XBlocks aim at acquiring multi-scale information better in images. To cooperate with Res2-UNeXt, we put forward a simple and efficient method of data augmentation. The data augmentation method, based on the process of cell movement and deformation, has biological implications in away. We evaluate Res2-UNeXt in comparison with recent variants of U-Net: UNet++, CE-Net and LadderNet and the method that different from U-Net architecture: FCN and DFANet on the dataset of ISBI cell tracking challenge 2019 via four different cell images. The experimental results demonstrate that Res2-UNeXt can achieve better performance than both recent variants of U-Net and non-U-Net architecture methods. Besides, the proposed architecture and the data augmentation method have been proven efficiently by the ablation experiments.
C1 [Chan, Sixian; Huang, Cheng; Bai, Cong; Ding, Weilong; Chen, Shengyong] Zhejiang Univ Technol, Coll Comp Sci, 288 Rd LiuHe, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Ding, WL (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, 288 Rd LiuHe, Hangzhou 310023, Zhejiang, Peoples R China.
EM sxchan@zjut.edu.cn; wlding@zjut.edu.cn
RI Bai, Cong/T-9188-2019; Chen, S./H-3083-2011
OI Bai, Cong/0000-0002-6177-3862; , cheng/0000-0002-1856-1709
FU National Natural Science Foundation of China [U1908210, 61906168];
   Zhejiang Public Welfare Technology Research Plan / Social Development
   Project [LGF21F020015]
FX This work is partially supported by National Natural Science Foundation
   of China under Grant No. U1908210, 61906168, Zhejiang Public Welfare
   Technology Research Plan / Social Development Project No.LGF21F020015.
CR Burghelea T, 2005, PHYS FLUIDS, V17, DOI 10.1063/1.2077367
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Dong N., 2018, BMVC, V4, P4
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Fahrig R, 2000, MED PHYS, V27, P30, DOI 10.1118/1.598854
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guan S, 2020, IEEE J BIOMED HEALTH, V24, P568, DOI 10.1109/JBHI.2019.2912935
   Hauberg S, 2016, JMLR WORKSH CONF PRO, V51, P342
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Iglovikov V., 2018, Ternausnet: U-Net with VGG11 encoder pre-trained on Imagenet for image segmentation, P1
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MUG, 2017, COMM COM INF SC, V723, P571, DOI 10.1007/978-3-319-60964-5_50
   Kingma D. P., 2014, arXiv
   Li H., 2019, P IEEE CVF C COMP VI, P9522, DOI [DOI 10.1109/CVPR.2019.00975, 10.1109/CVPR.2019.00975]
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   McAuliffe MJ, 2001, COMP MED SY, P381
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nazir, 2020, MICROSC RES TECHNIQ
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ratner Alexander J, 2017, Adv Neural Inf Process Syst, V30, P3239
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Roth HR., 2018, Med. IMAGING Technol, V36, P63, DOI [10.11409/mit.36.63, DOI 10.11409/MIT.36.63]
   Shaban A, 2017, ARXIV PREPRINT ARXIV, DOI 10.5244/C.31.167
   Shelhamer E., 2018, P INT C MACH LEARN
   Taghanaki S. A., 2019, ARXIV191007655
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Wang H, 2005, PHYS MED BIOL, V50, P2887, DOI 10.1088/0031-9155/50/12/011
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xing L, 2019, ARXIV191102521
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhuang J.T., 2018, ARXIV PREPRINT ARXIV
NR 45
TC 20
Z9 21
U1 7
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13275
EP 13288
DI 10.1007/s11042-021-10536-5
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000648376700002
DA 2024-07-18
ER

PT J
AU Li, S
   Hu, L
   Sun, CY
   Chi, L
   Li, HT
AF Li, Shuai
   Hu, Liang
   Sun, Chengyu
   Chi, Ling
   Li, Hongtu
TI Comparative assessment of PEE methods and new performance measurement
   for RDH
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding(RDH); Prediction error expansion (PEE);
   Steganography
AB The paper mainly analyzes four typical reversible data hiding (RDH) algorithms that use PEE technology in combination: Conventional Prediction-error-expansion(C-PEE), Adaptive Prediction-error-expansion(A-PEE), Pairwise Prediction-error-expansion (P-PEE), Improve Pairwise Prediction-error-expansion(IP-PEE). And the experimental comparison results are also given. In addition, in the research process, we found that the peak signal-to-noise ratio (PSNR) and embedding capacity (EC) of many algorithms are very close, due to lack of benchmark tools for technical evaluation in the RDH field, thus this paper proposes a new performance measurement method based on the PSNR and EC measurement, we call it the prediction error accuracy rate, Determined by the ratio of the capacity that meets the embedding conditions to the total capacity of the image, combined with the measurement of this method, can better determine whether the performance of the algorithm is optimal. Finally, in this area, challenge and future directions are also given.
C1 [Li, Shuai; Hu, Liang; Sun, Chengyu; Chi, Ling; Li, Hongtu] JiLin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
C3 Jilin University
RP Li, S (corresponding author), JiLin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
EM shuaili18@mails.jlu.edu.cn; hul@jlu.edu.cn; suncy18@mails.jlu.edu.cn;
   chiling@jlu.edu.cn; lihongtu@jlu.edu.cn
OI Li, Shuai/0000-0003-4547-4683
FU National Key RD Plan of China [2017YFA0604500]; National Sci-Tech
   Support Plan of China [2014BAH02F00]; National Natural Science
   Foundation of China [61701190]; Youth Science Foundation of Jilin
   Province of China [20160520011JH, 20180520021JH]; Youth Sci-Tech
   Innovation Leader and Team Project of Jilin Province of China
   [20170519017JH]; Key Technology Innovation Cooperation Project of
   Government and University for the whole Industry Demonstration
   [SXGJSF2017-4]; Key scientific and technological R&D Plan of Jilin
   Province of China [20180201103GX]; Project of Jilin Province Development
   and Reform Commission [2019FGWTZC001]
FX This work is funded by: National Key R&D Plan of China under Grant No.
   2017YFA0604500, and by National Sci-Tech Support Plan of China under
   Grant No. 2014BAH02F00, and by National Natural Science Foundation of
   China under Grant No. 61701190, and by Youth Science Foundation of Jilin
   Province of China under Grant No. 20160520011JH &20180520021JH, and by
   Youth Sci-Tech Innovation Leader and Team Project of Jilin Province of
   China under Grant No. 20170519017JH, and by Key Technology Innovation
   Cooperation Project of Government and University for the whole Industry
   Demonstration under Grant No. SXGJSF2017-4, and by Key scientific and
   technological R&D Plan of Jilin Province of China under Grant No.
   20180201103GX, and by Project of Jilin Province Development and Reform
   Commission under Grant No. 2019FGWTZC001..
CR [Anonymous], 2013, P 1 ACM WORKSH INF H
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Feng GR, 2012, NEUROCOMPUTING, V82, P62, DOI 10.1016/j.neucom.2011.10.028
   Feng GR, 2012, J SYST SOFTWARE, V85, P392, DOI 10.1016/j.jss.2011.08.033
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hsiao JY, 2017, J INF SCI ENG, V33, P289
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang HJ, 2010, KSII T INTERNET INF, V4, P655, DOI 10.3837/tiis.2010.08.0012
   Jeni M., 2013, 2013 International Conference on Information Communication and Embedded Systems (ICICES 2013), P121, DOI 10.1109/ICICES.2013.6508355
   Kim, 2014, INT WORKSH DIG WAT, P254
   Leung HY, 2013, J SYST SOFTWARE, V86, P2204, DOI 10.1016/j.jss.2013.04.020
   Li HF, 2018, MULTIMED TOOLS APPL, V77, P18203, DOI 10.1007/s11042-017-5075-1
   Li J, 2012, IEEE IMAGE PROC, P2181, DOI 10.1109/ICIP.2012.6467326
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li S, 2020, IEEE ACCESS, V8, P214732, DOI 10.1109/ACCESS.2020.3040048
   Li T., 2020, IEEE ACCESS, V99, P1
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo Y., 2011, Mistreatment and Psychological Well-being Among Older Adults : Exploring the Role of Psychosocial Resources and Deficits, P1, DOI DOI 10.1109/ICME.2011.6011833
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Ou B., 2013, J SYST SOFTW, V86
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2012, NEUROCOMPUTING, V93, P67, DOI 10.1016/j.neucom.2012.04.021
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qi Y, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P102, DOI 10.1109/YAC.2017.7967386
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi X, 2013, INFORM SCIENCES, V240, P173, DOI 10.1016/j.ins.2013.03.031
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tudoroiu, 2011, ISSCS 2011, P1
   Wang C, 2010, IEEE IMAGE PROC, P3673, DOI 10.1109/ICIP.2010.5652508
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xie XZ, 2020, MULTIMED TOOLS APPL, V79, P24329, DOI 10.1007/s11042-019-08402-6
   Xu JJ, 2017, LECT NOTES COMPUT SC, V10082, P407, DOI 10.1007/978-3-319-53465-7_30
   Xuan G., 2012, INT WORKSH DIG WAT
   Xuan GR, 2010, IEEE INT SYMP CIRC S, P1129, DOI 10.1109/ISCAS.2010.5537323
   Yi S, 2018, SIGNAL PROCESS, V150, P171, DOI 10.1016/j.sigpro.2018.04.016
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 51
TC 0
Z9 0
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23541
EP 23560
DI 10.1007/s11042-021-10938-5
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000647349000005
DA 2024-07-18
ER

PT J
AU Diker, A
   Sönmez, Y
   Özyurt, F
   Avci, E
   Avci, D
AF Diker, Aykut
   Sonmez, Yasin
   Ozyurt, Fatih
   Avci, Engin
   Avci, Derya
TI Examination of the ECG signal classification technique DEA-ELM using
   deep convolutional neural network features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep features; Differential evolution
   algorithm; Electrocardiogram; Extreme learning machine
ID EXTREME LEARNING-MACHINE; SYSTEM; ALGORITHM
AB The accurate separation of ECG signals has become crucial to identify heart diseases. Machine learning methods are widely used to separate ECG signals. The aim of this study was to obtain optimal number of hidden neurons of the Extreme Learning Machine (ELM) using the differential evolution algorithm (DEA) and increase the accuracy rate of ECG classification. In this study, a public database on PhysioNet was used for ECG signal classification. A deep feature method using convolutional neural network was used to extract the major features of the ECG samples. Then, a conventional ELM was applied to the ECG signals. Subsequently, the ECG signals with deep properties were shared with the MATLAB classifier toolbox (k-NN, SVM, Decision Trees). In addition, the ECG signals in the dataset were tested using the Genetic Algorithm Wavelet Kernel-ELM (GAWK-ELM). Finally, the DEA-ELM was improved for the determination of the number of hidden neurons. This study optimized the hidden neuron numbers of traditional ELM with DEA using deep learning capabilities in the feature extraction. The aim of was to maximize the best cost of the DEA and achieve the optimal number of hidden neurons in ELM. Accuracy (Acc), sensitivity (Se), specificity (Spe) and F-measure were used as the performance metrics for the classifier performances. The classification results were 80.60%, 81.50%, and 83.12% with SVM, ELM and DEA-ELM, respectively. Thus, the best classification scores were accomplished with an accuracy of 83.12% with the algorithm supported by the DEA.
C1 [Diker, Aykut] Bandirma Onyedi Eylul Univ, Dept Software Engn, TR-10200 Balikesir, Turkey.
   [Sonmez, Yasin] Batman Univ, Tech Sci Vocat Sch, TR-72000 Batman, Turkey.
   [Ozyurt, Fatih; Avci, Engin] Firat Univ, Technol Fac, Software Engn, TR-23000 Elazig, Turkey.
   [Avci, Derya] Firat Univ, Tech Sci Vocat Sch, TR-23000 Elazig, Turkey.
C3 Bandirma Onyedi Eylul University; Batman University; Firat University;
   Firat University
RP Diker, A (corresponding author), Bandirma Onyedi Eylul Univ, Dept Software Engn, TR-10200 Balikesir, Turkey.
EM aykutdiker@gmail.com
RI Avcı, Derya/W-2243-2018; Diker, Aykut/AAM-6054-2020; AVCI,
   ENGIN/W-4134-2018; Özyurt, Fatih/W-4385-2018
OI Avcı, Derya/0000-0002-5204-0501; Diker, Aykut/0000-0002-1207-8548;
   Özyurt, Fatih/0000-0002-8154-6691
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   Escalona-Morán MA, 2015, IEEE J BIOMED HEALTH, V19, P892, DOI 10.1109/JBHI.2014.2332001
   [Anonymous], 2017, Bitlis Eren Univ. J. Sci. Technol., DOI [10.17678/beuscitech.344953, DOI 10.17678/BEUSCITECH.344953]
   Avci D, 2016, J ELECTR ENG TECHNOL, V11, P993, DOI 10.5370/JEET.2016.11.4.993
   Avci E, 2013, EXPERT SYST APPL, V40, P3984, DOI 10.1016/j.eswa.2013.01.011
   Avci E, 2012, EXPERT SYST APPL, V39, P12340, DOI 10.1016/j.eswa.2012.04.012
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Chen XY, 2018, IEEE ACCESS, V6, P21745, DOI 10.1109/ACCESS.2018.2828499
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Comert Z., 2017, 2017 25 SIGNAL PROCE, DOI 10.1109/SIU.2017.7960152
   Cömert Z, 2015, SIG PROCESS COMMUN, P2569, DOI 10.1109/SIU.2015.7130409
   Cynthya, 2013, ARXIV PREPRINT ARXIV
   Diker A, 2017, SIG PROCESS COMMUN
   Dogan RO, 2018, 26 SIGN PROC COMM AP, V2018, P1
   Ferreira MVD, 2018, EXPERT SYST APPL, V110, P250, DOI 10.1016/j.eswa.2018.06.010
   Engelbrecht, 2007, INTRO DIFFERENTIAL E
   Farahani HF, 2017, IET SCI MEAS TECHNOL, V11, P1058, DOI 10.1049/iet-smt.2016.0444
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Hsieh, 2017, J CARDIOVASC DIS DIA
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karci, 2017, J COMPUT SCI-NETH, V2, P10
   Karpagachelvi, 2011, J COMPUT SCI-NETH, V8
   Keskinturk T., 2006, ISTANBUL COMMERCE U, V9, P85
   Khorrami H, 2010, EXPERT SYST APPL, V37, P5751, DOI 10.1016/j.eswa.2010.02.033
   Kim J, 2009, BIOMED ENG ONLINE, V8, DOI 10.1186/1475-925X-8-31
   Korürek M, 2010, EXPERT SYST APPL, V37, P7563, DOI 10.1016/j.eswa.2010.04.087
   Koyuncu, 2005, 3 2005 DEN OT SEMP, P216
   Kulkarni S. P., 2015, INT J RECENT INNOV T, P276, DOI DOI 10.17762/IJRITCC2321-8169.150156
   Limam M, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.171-325
   Liu D, 2018, PATTERN RECOGN LETT, V110, P16, DOI 10.1016/j.patrec.2018.03.015
   Mannurmath J., 2014, INT J SCI ENG TECHNO, V3, P1946
   Melgani F, 2008, IEEE T INF TECHNOL B, V12, P667, DOI 10.1109/TITB.2008.923147
   Nwankpa C., 2018, ARXIV181103378
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Ojha D., 2014, INT J BIOMEDICAL BIO, V8, P114
   Ozyurt F, 2020, J SUPERCOMPUT, V76, P8413, DOI 10.1007/s11227-019-03106-y
   Ozyurt F, 2020, SOFT COMPUT, V24, P8163, DOI 10.1007/s00500-019-04383-8
   Pasolli E, 2015, BIOMED SIGNAL PROCES, V19, P130, DOI 10.1016/j.bspc.2014.10.013
   Piuri V., 2018, PATTERN RECOGN LETT, P1, DOI DOI 10.1109/RTSI.2018.8548432
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   Rai HM, 2013, MEASUREMENT, V46, P3238, DOI 10.1016/j.measurement.2013.05.021
   Sadhukhan D, 2012, PROC INT CONF EMERG, P122, DOI 10.1109/EAIT.2012.6407876
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Teodoro FGS, 2017, IEEE IJCNN, P2911, DOI 10.1109/IJCNN.2017.7966216
   Singh R, 2007, PROC WRLD ACAD SCI E, V26, P361
   Tavares LD, 2015, NEUROCOMPUTING, V166, P164, DOI 10.1016/j.neucom.2015.04.018
   Traore BB, 2018, ECOL INFORM, V48, P257, DOI 10.1016/j.ecoinf.2018.10.002
   Villa MCS, 2017, ESTUD CIEN, V69, P1
   Wu JE, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P309, DOI 10.1109/ICDSP.2016.7868568
   Yang WA, 2016, INT J PROD RES, V54, P4703, DOI 10.1080/00207543.2015.1111534
   Ye, 2008, FLY OPTIMIZATION DIF, P464
   Zhang, 2020, PROCESS BIOCHEM
   Zihlmann M, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.070-060
NR 65
TC 15
Z9 15
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24777
EP 24800
DI 10.1007/s11042-021-10517-8
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700006
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Zhang, DH
   Xu, FJ
AF Zhang, Qiu-yu
   Zhang, Deng-hai
   Xu, Fu-jiu
TI An encrypted speech authentication and tampering recovery method based
   on perceptual hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech authentication; Perceptual hashing; Least square curve
   fitting; Tampering location; Tampering recovery
AB With the progress of speech retrieval technology in the cloud, it brings a lot of conveniences for speech user. Yet, the inquiry encrypted speech results from the speech retrieval system are faced with some secure issues to settle, such as integrity authentication and tampering recovery. In this paper, an encrypted speech authentication and tampering recovery method based on perceptual hashing is proposed. Firstly, the original speech is scrambled by Duffing mapping to construct an encrypted speech library in the cloud, through extracting product of uniform sub-band spectrum variance and spectral entropy of encrypted speech and constructing a perceptual hashing sequence to generate the hashing template of the cloud. From this, a one-to-one correspondence between the encrypted speech and perceptual hashing sequence is established. Secondly, the authentication digest of encrypted speech is extracted according to the inquiry result during the retrieval. Then, the authentication digest and the perceptual hashing sequence of the hashing template in the cloud are matched by the Hamming distance algorithm. Finally, for encrypted speech that fails authentication, tampering detection and location are performed, and the tampered samples are recovered by the least square curve fitting method. The simulation results show that the proposed method can extract the authentication digest directly in the encrypted speech, and the authentication digest not only has good discrimination and robustness, but it accurately locates the tampered area for malicious substitution and mute attacks. In addition, the proposed method can recover tampered speech signals in high quality without any extra information.
C1 [Zhang, Qiu-yu; Zhang, Deng-hai; Xu, Fu-jiu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078). The authors would like to thank the
   anonymous reviewers for their helpful comments and suggestions.
CR Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Chen J, 2018, IEEE TRUST BIG, P86, DOI 10.1109/TrustCom/BigDataSE.2018.00023
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Jawad AK, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCE IN SUSTAINABLE ENGINEERING AND ITS APPLICATION (ICASEA), P7, DOI 10.1109/ICASEA.2018.8370947
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P29303, DOI 10.1007/s11042-018-5959-8
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kaur A, 2018, ETRI J, V40, P133, DOI 10.4218/etrij.2017-0092
   Koçal OH, 2016, TURK J ELECTR ENG CO, V24, P4129, DOI 10.3906/elk-1411-167
   Kumar R, 2019, COMPUT SCI REV, V33, P1, DOI 10.1016/j.cosrev.2019.05.002
   Kusuma EJ, 2017, P 2017 INT C INNOVAT, P1, DOI DOI 10.1109/INNOCIT.2017.8319132
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Lu WH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072390
   Luo X, 2014, WUHAN UNIV J NAT SCI, V19, P497, DOI [DOI 10.1007/s11859-014-1044-y, 10.1007/s11859-014-1044-y]
   Menendez-Ortiz A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204442
   Menendez-Ortiz A, 2017, MULTIMED TOOLS APPL, V76, P14197, DOI 10.1007/s11042-016-3783-6
   Mostafa A, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P235, DOI 10.1109/ICENCO.2015.7416354
   Mustafa I, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123028
   Q Qian, 2016, 2016 AS PAC SIGN INF, P1, DOI DOI 10.1109/APSIPA.2016.7820814
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qian Q, 2016, MULTIMED TOOLS APPL, V75, P13431, DOI 10.1007/s11042-015-2801-4
   Rihan D., 2015, International Journal of Engineering Research and Technology, V4, P151, DOI DOI 10.1109/ICICT.2005.1598556
   Shahadi HI, 2018, COMPUT ELECTR ENG, V68, P425, DOI 10.1016/j.compeleceng.2018.04.018
   Sheela SJ, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Sun, 2019, ADV COMPUTER COMMUNI, P173, DOI [10.1007/978-981-13-0344-9_14, DOI 10.1007/978-981-13-0344-9_14]
   Wang Wei, 2016, Audio Engineering, V40, P40, DOI 10.16311/j.audioe.2016.05.09
   [吴新忠 Wu Xinzhong], 2019, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V42, P83
   Xiang SJ, 2018, IET INFORM SECUR, V12, P42, DOI 10.1049/iet-ifs.2017.0092
   Yang WX, 2018, MULTIMED TOOLS APPL, V77, P17937, DOI 10.1007/s11042-017-5505-0
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
NR 35
TC 7
Z9 7
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24925
EP 24948
DI 10.1007/s11042-021-10905-0
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700003
DA 2024-07-18
ER

PT J
AU Lin, L
   Zhang, G
   Wang, JX
   Tian, M
   Wu, SC
AF Lin, Lan
   Zhang, Ge
   Wang, Jingxuan
   Tian, Miao
   Wu, Shuicai
TI Utilizing transfer learning of pre-trained AlexNet and relevance vector
   machine for regression for predicting healthy older adult's brain age
   from structural MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain age prediction; Regression analysis; Transfer learning; Machine
   learning; Biomarker; Aging
ID INDIVIDUAL BRAINAGE; SCHIZOPHRENIA
AB Discrepancies between the estimated brain age from brain structural MRI and the chronological age have been associated with a broad spectrum of neurocognitive disorders. The performance of brain age estimation heavily depends on predefined or hand-crafted features. Although 3D convolutional neural network (CNN) based approaches have been proposed, they require high computational cost, large memory load, and numerous images. Coupling a pre-trained 2D CNN for transfer learning with a well-established relevance vector machine for regression approach can greatly enhance the capabilities of the model. Several important strategies, including feature transfer learning, 3D feature concatenation, and dimensionality reduction were taken. The estimated brain age was modeled by structural magnetic resonance imaging (sMRI) from 594 normal healthy older individuals (age 50-90 years). We proposed and manifested a pre-trained AlexNet as a robust feature extractor. Also, the considerable cost of developing a 3D CNN was avoided by applying 3D feature concatenation and data reduction. The proposed method achieves superior performance with a mean absolute error of 4.51 years for old subjects. The predicted brain age also demonstrated high test-retest reliability (intra-class correlation coefficient of 0.979). The effectiveness and robustness of the proposed model were well studied. The proposed approach can compete with or even outperform those state-of-the-art approaches, and feature transfer learning strategy can introduce new perspectives to some well-established brain age prediction models with predefined or hand-crafted features.
C1 [Lin, Lan; Zhang, Ge; Wang, Jingxuan; Tian, Miao; Wu, Shuicai] Beijing Univ Technol, Coll Life Sci & Bioengn, Beijing Int Platform Sci & Technol Cooperat, Intelligent Physiol Measurement & Clin Translat, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Lin, L (corresponding author), Beijing Univ Technol, Coll Life Sci & Bioengn, Beijing Int Platform Sci & Technol Cooperat, Intelligent Physiol Measurement & Clin Translat, Beijing 100124, Peoples R China.
EM lanlin@bjut.edu.cn
RI Lin, Lan/KSM-2759-2024
OI LIN, LAN/0000-0002-3431-2753
FU National Natural Science Foundation of China [81971683]; Natural Science
   Foundation of Beijing Municipality [L182010]; Scientific Research
   General Project of Beijing Municipal Education Committee
   [KM201810005033]
FX This research was financially supported by grants from National Natural
   Science Foundation of China (81971683),Natural Science Foundation of
   Beijing Municipality (L182010) and the Scientific Research General
   Project of Beijing Municipal Education Committee (KM201810005033).
CR Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Ball G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-18253-6
   Cole JH, 2018, MOL PSYCHIATR, V23, P1385, DOI 10.1038/mp.2017.62
   Cole JH, 2017, TRENDS NEUROSCI, V40, P681, DOI 10.1016/j.tins.2017.10.001
   Cole JH, 2017, NEUROIMAGE, V163, P115, DOI 10.1016/j.neuroimage.2017.07.059
   Cole JH, 2017, NEUROBIOL AGING, V56, P41, DOI 10.1016/j.neurobiolaging.2017.04.006
   Cole JH, 2017, NEUROLOGY, V88, P1349, DOI [10.1212/wnl.0000000000003790, 10.1212/WNL.0000000000003790]
   Cole JH, 2015, ANN NEUROL, V77, P571, DOI 10.1002/ana.24367
   Franke K, 2015, NEUROIMAGE, V115, P1, DOI 10.1016/j.neuroimage.2015.04.036
   Franke K, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00090
   Franke K, 2012, NEUROIMAGE, V63, P1305, DOI 10.1016/j.neuroimage.2012.08.001
   Franke K, 2010, NEUROIMAGE, V50, P883, DOI 10.1016/j.neuroimage.2010.01.005
   Grajauskas LA, 2019, AGEING RES REV, V49, P67, DOI 10.1016/j.arr.2018.11.004
   Harada CN, 2013, CLIN GERIATR MED, V29, P737, DOI 10.1016/j.cger.2013.07.002
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jieqiong Wang, 2012, Machine Learning in Medical Imaging. Third International Workshop (MLMI 2012). Held in Conjunction with MICCAI 2012. Revised Selected Papers, P111, DOI 10.1007/978-3-642-35428-1_14
   Khundrakpam BS, 2015, NEUROIMAGE, V111, P350, DOI 10.1016/j.neuroimage.2015.02.046
   Kolenic M, 2018, J PSYCHIATR RES, V99, P151, DOI 10.1016/j.jpsychires.2018.02.012
   Koutsouleris N, 2014, SCHIZOPHRENIA BULL, V40, P1140, DOI 10.1093/schbul/sbt142
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lancaster J, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00028
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Miller KL, 2016, NAT NEUROSCI, V19, P1523, DOI 10.1038/nn.4393
   Nenadic I, 2017, PSYCHIAT RES-NEUROIM, V266, P86, DOI 10.1016/j.pscychresns.2017.05.006
   O'Sullivan Shane, 2019, Brain Inform, V6, P3, DOI 10.1186/s40708-019-0096-3
   Pardoe HR, 2018, NEUROINFORMATICS, V16, P43, DOI 10.1007/s12021-017-9346-9
   Pardoe HR, 2017, EPILEPSY RES, V133, P28, DOI 10.1016/j.eplepsyres.2017.03.007
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salthouse TA, 2019, PSYCHOL AGING, V34, P17, DOI 10.1037/pag0000288
   Schnack HG, 2016, AM J PSYCHIAT, V173, P607, DOI 10.1176/appi.ajp.2015.15070922
   Tipping ME, 2000, ADV NEUR IN, V12, P652
   Wang B, 2011, J NEUROSCI METH, V199, P140, DOI 10.1016/j.jneumeth.2011.04.022
   Zhao YH, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116149
NR 36
TC 12
Z9 12
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24719
EP 24735
DI 10.1007/s11042-020-10377-8
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638867400001
DA 2024-07-18
ER

PT J
AU Rani, S
   Kumar, M
AF Rani, Shalli
   Kumar, Munish
TI Prediction of the mortality rate and framework for remote monitoring of
   pregnant women based on IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pregnant women; Machine learning; Classification algorithms; IoT; Cloud
   server
ID HEALTH; SYSTEM
AB To save the risk during the pregnancies in remote areas (where women cannot approach the doctors in the urban areas for proper check-ups), the authors have proposed an IoT based remote monitoring of pregnant ladies where the data is collected at the cloud server. Machine learning techniques will be applied on the trimesters' attributes to find out the reasons of mortality rate of the babies. The use of these advanced technologies in pregnant women care environment can absolutely eradicate the pregnancy complications and harmful incidents. An initial work towards this study is to assess mortality risk prediction in pregnant ladies using machine-learning algorithms for proper prediction and treatment on time. A dataset of 10,000 pregnant women is analysed in this study. Classification algorithms are used to check the death rate of new born babies based on the mother's age. The survival ratio is presented by applying the various algorithms. Two class SVM model is presented as the most accurate prediction model which outperformed over boosted decision tree, average perceptron, decision forest, locally deep SVM, Bayes point machine, decision forest and logistic regression. Age of the mother and frequency of the pregnancy without proper gap (i.e. less than 3 years) make impact on the mortality rate of the babies. Among the various algorithms, the AUC value of decision forest is augmented at 91.4% whereas two class SVM shows significantly improved performance to 96.6%. The authors have proposed machine learning-based final model, death rate of infants, frequency of pregnancy and age of the mother were interrelated as notable risk factors for mortality in Indian ladies along with other issues.
C1 [Rani, Shalli] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
C3 Chitkara University, Punjab
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM Shall.rani@chitkara.edu.in; munishcse@gmail.com
RI University, Chitkara/AAZ-3040-2021; Rani, Shalli/AGY-9513-2022; Kumar,
   Munish/P-7756-2018
OI University, Chitkara/0000-0003-3776-7136; Rani,
   Shalli/0000-0002-8474-9435; Kumar, Munish/0000-0003-0115-1620
CR [Anonymous], 2017, BROADBAND COMMUNICAT
   [Anonymous], 2018, INT C COMM INF COMP, DOI DOI 10.1109/ICCICT.2018.8325882
   [Anonymous], 2017, INT J ADV RES METHOD
   [Anonymous], 2016, WHO LIB CATALOGUING, P176
   Aravind, 2017, INT J INFO SC COMPUT, V11
   Castillejo P, 2013, IEEE WIREL COMMUN, V20, DOI 10.1109/MWC.2013.6590049
   Fouad H, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107757
   Jezewski J, 2016, MICROPROCESS MICROSY, V46, P35, DOI 10.1016/j.micpro.2016.07.005
   Khan Aurangzeb, 2010, Journal of Advances in Information Technology, V1, P4, DOI 10.4304/jait.1.1.4-20
   Korhonen I, 2003, IEEE ENG MED BIOL, V22, P66, DOI 10.1109/MEMB.2003.1213628
   Kovacevic Z, 2020, HEALTH TECHNOL-GER, V10, P151, DOI 10.1007/s12553-019-00386-5
   Lee RG, 2007, IEEE T INF TECHNOL B, V11, P507, DOI 10.1109/TITB.2006.888701
   López-Gatius F, 2007, THERIOGENOLOGY, V67, P1324, DOI 10.1016/j.theriogenology.2007.02.004
   Mahon P, 2010, J BONE MINER RES, V25, P14, DOI 10.1359/jbmr.090701
   Megalingam Rajesh Kannan, 2013, 2013 IEEE Global Humanitarian Technology Conference: South Asia Satellite (GHTC-SAS), P164, DOI 10.1109/GHTC-SAS.2013.6629909
   Mohanta Bhagyashree, 2019, 2019 International Conference on Applied Machine Learning (ICAML). Proceedings, P191, DOI 10.1109/ICAML48257.2019.00044
   Redondi A, 2013, AD HOC NETW, V11, P39, DOI 10.1016/j.adhoc.2012.04.006
   Sharma R, 2013, REPROD BIOL ENDOCRIN, V11, DOI 10.1186/1477-7827-11-66
   Takei K, 2015, ADV HEALTHC MATER, V4, P487, DOI 10.1002/adhm.201400546
   UN, 2016, SUSTAINABLE DEV GOAL
   Vinitha, INT J ADV RES METHOD
NR 21
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24555
EP 24571
DI 10.1007/s11042-021-10823-1
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637685200002
DA 2024-07-18
ER

PT J
AU Rajendran, S
   Krithivasan, K
   Doraipandian, M
AF Rajendran, Sujarani
   Krithivasan, Kannan
   Doraipandian, Manivannan
TI A novel cross cosine map based medical image cryptosystem using dynamic
   bit-level diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Cross cosine map; Cryptography; Medical image; Security
AB Development in networking technology has made the remote diagnosis and treatment of patients a reality through telemedicine. At the same time, storing and transmitting medical documents over an insecure network has always been a daunting challenge. Literature shows that the existing medical image cryptosystems suffer from serious shortcomings. The present work attempts to address this crucial area and propose a suitable solution. A novel hybrid 2-Dimensional Cross Cosine Map (2D-CCM) with an improved chaotic behaviour cryptosystem is proposed. Chaotic series generated by proposed 2D-CCM is utilized in confusion and diffusion architecture. A new dynamic Bit-Flipping in diffusion approach increases the complexity to achieve good encryption results. Simulation and security level assessment is carried out by executing Statistical and differential attack analysis, key sensitivity and exhaustive attack analysis. Robustness is evidenced by the result of noise and crop attack analysis. In addition, SHA-256 is utilized to feed the seed key value of 2D-CCM to resist plaintext attacks. All the assessment and comparison results illustrate that the cipher possesses enhanced security and efficiency than the existing state of the art. Hence the proposed cipher is absolutely apt for secure medical image communication.
C1 [Rajendran, Sujarani] SASTRA Deemed Univ, Dept Comp Sci, Srinivasa Ramanujan Ctr, Kumbakonam, Tamil Nadu, India.
   [Krithivasan, Kannan] SASTRA Deemed Univ, Dept Math, Discrete Math Res Lab DMRL, Thanjavur, Tamil Nadu, India.
   [Doraipandian, Manivannan] SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Doraipandian, M (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, Tamil Nadu, India.
EM rsujarani@src.sastra.edu; kkannan@maths.sastra.edu; dmv@cse.sastra.edu
RI k, k/KFC-0221-2024; K, Kannan/GPK-0744-2022; su, haobo/JPK-2362-2023; k,
   k/KFT-2541-2024; k, k/HZK-4476-2023
OI Rajendran, Sujarani/0000-0001-9827-0807
FU Department of Science and Technology, India [SR/FST/ETI-371/2014,
   SR/FST/MSI-107/2015]; Tata Realty-IT City - SASTRA Srinivasa Ramanujan
   Research Cell of our University
FX The authors of the present work thank the Department of Science and
   Technology, India for offering significant improvement in S&T
   Infrastructure in Universities and Higher Educational Institutions
   (SR/FST/ETI-371/2014), (SR/FST/MSI-107/2015) and Tata Realty-IT City -
   SASTRA Srinivasa Ramanujan Research Cell of our University and for their
   financial support. They wish to acknowledge SASTRA Deemed University,
   Thanjavur for providing the necessary infrastructural support to carry
   out the present work.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Attaullah, 2019, MULTIMED TOOLS APPL, V78, P31467, DOI 10.1007/s11042-019-07981-8
   Bechikh R, 2015, SIGNAL PROCESS-IMAGE, V39, P151, DOI 10.1016/j.image.2015.09.006
   Benvenuto CJ, 2012, GALOIS FIELD CRYPTOG, P1
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P8065, DOI 10.1007/s00521-019-04312-8
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   Elashry IF, 2020, MULTIMED TOOLS APPL, V79, P20665, DOI 10.1007/s11042-019-08322-5
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   Farah MAB, 2020, NEW EFFICIENT MEDICA
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang R, 2020, MULTIMED TOOLS APPL, V79, P27483, DOI 10.1007/s11042-020-09163-3
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Rajendran S, 2020, MULTIMED TOOLS APPL, V79, P12447, DOI 10.1007/s11042-019-08396-1
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Sahi A, 2016, COMPUT BIOL MED, V78, P1, DOI 10.1016/j.compbiomed.2016.09.003
   Sathishkumar GA, 2011, COMM COM INF SC, V133, P290
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tan CH, 2016, INFORM PROCESS LETT, V116, P116, DOI 10.1016/j.ipl.2015.09.014
   Tong Xiaojun, 2012, Wuhan University Journal of Natural Sciences, V17, P461, DOI 10.1007/s11859-012-0871-y
   Vidhya R, 2020, MULTIMED TOOLS APPL, V79, P30281, DOI 10.1007/s11042-020-09462-9
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
NR 46
TC 8
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24221
EP 24243
DI 10.1007/s11042-021-10798-z
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636427800002
DA 2024-07-18
ER

PT J
AU Prasanna, MSM
   Shaila, SG
   Vadivel, A
AF Prasanna, M. S. M.
   Shaila, S. G.
   Vadivel, A.
TI Phrase-level sentence patterns for estimating positive and negative
   emotions using Neuro-fuzzy model for information retrieval applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentences; Phrases patterns; Positive emotions; Negative emotions;
   Classification; Fuzzy; Rules
ID SENTIMENT ANALYSIS; NETWORK; CLASSIFICATION
AB The paper proposes phrase-level emotion patterns using Neuro-Fuzzy model. At the initial stage, the emotional patterns at phrase level are obtained using POS Tags and EMOT Actifiers that results into 16 patterns. These patterns works well with the sentences having single emotion and classifies them into Positive and Negative polarities. However, it is observed that these patterns are unable to define the exact boundary between positive and negative polarities of these sentence patterns. Thus, this issue will affect the classification accuracy due to imprecise boundary between the sentences. Mixed emotions exist in long sentences with multi phrases and therefore the sentences are broken at Phrase-level. The patterns are extracted at phrase-level and converted as fuzzy rules for the classification of mixed emotion patterns. Intensity grades are calculated for the patterns based on the features of phrases and their structure in the sentence. These intensity grades classify the patterns at phrase level into Positive and Negative emotions. Based on the intensity grades, a suitable weighing mechanism is proposed for the multi phrasal sentence structure which decides the degree of Positive and Negative polarities of emotion in a sentence. Higher weighted phrasal pattern decides the Positive and Negative polarities of emotion in a sentence. Proposed approach performs well and achieves good F-Scores compared with other comparative approaches on benchmark datasets.
C1 [Prasanna, M. S. M.; Shaila, S. G.] Dayananda Sagar Univ, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
   [Vadivel, A.] ICFAI Fdn Higher Educ, IcfaiTech, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
C3 The ICFAI Foundation for Higher Education (IFHE); ICFAI Tech (Faculty of
   Science & Technology)
RP Vadivel, A (corresponding author), ICFAI Fdn Higher Educ, IcfaiTech, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM prasana.msm@gmail.com; shaila.research@gmail.com; vadinitt@gmail.com
RI A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676
CR Abid F, 2019, FUTURE GENER COMP SY, V95, P292, DOI 10.1016/j.future.2018.12.018
   Agichtein E., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P85, DOI 10.1145/336597.336644
   [Anonymous], 2004, THESIS U SUSSEX
   [Anonymous], 321 MIT MED LAB PERC
   [Anonymous], 1884, Mind, DOI DOI 10.1093/MIND/OS-IX.34.188
   [Anonymous], 1995, Int. J. Lexicogr., DOI [10.1093/ijl/8.4.281, DOI 10.1093/IJL/8.4.281]
   Asghar MZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171649
   Balahur A, 2013, DATA KNOWL ENG, V88, P113, DOI 10.1016/j.datak.2013.08.002
   Balahur A, 2012, IEEE T AFFECT COMPUT, V3, P88, DOI 10.1109/T-AFFC.2011.33
   Bandhakavi A, 2017, PATTERN RECOGN LETT, V93, P133, DOI 10.1016/j.patrec.2016.12.009
   Bao SH, 2009, IEEE DATA MINING, P699, DOI 10.1109/ICDM.2009.94
   Barnaghi P, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), P52, DOI 10.1109/BigDataService.2016.36
   Basiri ME, 2020, IEEE T COMPUT SOC SY, V7, P113, DOI 10.1109/TCSS.2019.2951326
   Berland M., 1999, P 37 ANN M ASS COMPU, P57, DOI DOI 10.3115/1034678.1034697
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brin S, 1999, LECT NOTES COMPUT SC, V1590, P172
   Cambria E., 2009, Proceedings ofCAEPIA, P32
   Ceron A, 2016, INFORM SCIENCES, V367, P105, DOI 10.1016/j.ins.2016.05.052
   Chaumartin F., 2007, P 4 INT WORKSH SEM E, P422, DOI DOI 10.3115/1621474.1621568
   Chen CT, 2019, INFORM SCIENCES, V502, P268, DOI 10.1016/j.ins.2019.06.050
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chesley P., 2006, Training, V580, P233
   Danisman A., 2008, AISB 2008 Convention Communication, Interaction and Social Intelligence, P53
   Das D, 2009, P ACL IJCNLP 2009 C, P149
   Das D, 2010, J INTELL SYST, V19, P145, DOI 10.1515/JISYS.2010.19.2.145
   Desmet B, 2013, EXPERT SYST APPL, V40, P6351, DOI 10.1016/j.eswa.2013.05.050
   Dyer M.G., 1987, COGNITION EMOTION, V1, P323
   EKBAL A, 2008, POLIBITS, V37, P20, DOI DOI 10.17562/PB-37-3
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elbagir S, 2019, IEEE ACCESS, V7, P163677, DOI 10.1109/ACCESS.2019.2952127
   ESULI A., 2005, Proceedings of the 14th ACM international conference on Information and knowledge management, P617
   Fabian M., 2007, 16 INT WORLD WID WEB, P697
   Galitsky BA, 2012, DATA KNOWL ENG, V81-82, P21, DOI 10.1016/j.datak.2012.07.003
   Grassi M, 2009, LECT NOTES COMPUTER, V5707
   Hai Z, 2017, IEEE T KNOWL DATA EN, V29, P1172, DOI 10.1109/TKDE.2017.2669027
   Huq MR, 2017, INT J ADV COMPUT SC, V8, P19
   Phan HT, 2020, IEEE ACCESS, V8, P14630, DOI 10.1109/ACCESS.2019.2963702
   Phan HT, 2019, J INTELL FUZZY SYST, V37, P7251, DOI 10.3233/JIFS-179336
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Ji P, 2019, IEEE T SYST MAN CY-S, V49, P1993, DOI 10.1109/TSMC.2018.2875163
   Jurek Anna., 2015, Security Informatics, V4, P9, DOI DOI 10.1186/S13388-015-0024-X
   Katz P., 2007, Proceedings of the 4th International Workshop on Semantic Evaluations, P308
   Keshavarz H, 2017, KNOWL-BASED SYST, V122, P1, DOI 10.1016/j.knosys.2017.01.028
   Kolya A., 2011, WORKSH REL MOD SEM C, P19
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Liang HZ, 2020, IEEE ACCESS, V8, P54164, DOI 10.1109/ACCESS.2020.2979012
   Lin Kevin Hsin-Yih, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P733, DOI 10.1145/1277741.1277882
   Long W, 2018, NEURAL COMPUT APPL, V30, P661, DOI 10.1007/s00521-016-2684-y
   Malandrakis N, 2013, IEEE T AUDIO SPEECH, V21, P2379, DOI 10.1109/TASL.2013.2277931
   Martin JR, 2007, LANGUAGE OF EVALUATION: APPRAISAL IN ENGLISH, P1, DOI 10.1057/9780230511910
   Neviarouskaya A., 2007, INT C WEBL SOC MED I, P293
   Niu HN, 2003, INT CONF ACOUST SPEE, P125
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pantel P, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P321
   Pong-Inwong C, 2019, INT J MACH LEARN CYB, V10, P2177, DOI 10.1007/s13042-018-0800-2
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Raj RJR, 2020, INT CONF COMM SYST, P150, DOI [10.1109/CSNT48778.2020.9115750, 10.1109/CSNT.2020.29]
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Rivera JD, 1977, PSYCHOL ISSUES MONOG, V4
   Rosen-Zvi Michal., 2004, UAI
   Sanagar S, 2020, IEEE ACCESS, V8, P118050, DOI 10.1109/ACCESS.2020.3005242
   SCHERER KR, 1993, COGNITION EMOTION, V7, P325, DOI 10.1080/02699939308409192
   Strapparava C., 2004, Lrec, Volume, V4, P1083
   Strapparava C., 2007, P 4 INT WORKSH SEM E, P70
   Subasic P, 2001, IEEE T FUZZY SYST, V9, P483, DOI 10.1109/91.940962
   Swaminathan A, 2022, IETE J RES, V68, P3235, DOI 10.1080/03772063.2020.1756471
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Ul Haq M, 2019, KSII T INTERNET INF, V13, P3144, DOI 10.3837/tiis.2019.06.021
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119
   Wikarsa L, 2015, 1 INT C WIR TEL ICWT, P1
   Wu FZ, 2016, INFORM SCIENCES, V373, P149, DOI 10.1016/j.ins.2016.09.002
   Xia R, 2016, INFORM PROCESS MANAG, V52, P36, DOI 10.1016/j.ipm.2015.04.003
   Xudong He, 1999, Proceedings. Twenty-Third Annual International Computer Software and Applications Conference (Cat. No.99CB37032), P462, DOI 10.1109/CMPSAC.1999.814327
   Yu L, 2015, 2015 12TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P49, DOI 10.1109/WISA.2015.24
   Zeng DJ, 2019, J INTELL FUZZY SYST, V36, P3971, DOI 10.3233/JIFS-169958
   Zhang Y, 2008, INT J COMPUT SCI NET, V8, P127
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhou F, 2020, NEUROCOMPUTING, V392, P38
NR 78
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20151
EP 20190
DI 10.1007/s11042-020-10422-6
EA MAR 2021
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900005
DA 2024-07-18
ER

PT J
AU Geetha, R
   Ramyadevi, K
   Balasubramanian, M
AF Geetha, R.
   Ramyadevi, K.
   Balasubramanian, M.
TI Prediction of domestic power peak demand and consumption using
   supervised machine learning with smart meter dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electricity-consumption; Random forest; Artificial neural network (ANN);
   Support vector machine (SVM)
ID SUPPORT VECTOR REGRESSION; EMPIRICAL MODE DECOMPOSITION; ALGORITHM; SVR
AB The prediction of electricity consumption is a vital foundation for smart energy management. Since the consumption of power varies with different appliances, better forecasting of power and peak demand is an essential accomplishment for the proper planning and development of the power generation and distribution system. This forecast analysis helps the service providers and the government to understand the lifestyle of the customers. The existing prediction and forecasting models are not meeting the standard requirements and moreover difficult to apply in practice. The forecast says that the boom of electric vehicles will increase the demand of electricity globally by 3% for the upcoming year. There exists a number of machine learning algorithms for classification and decision making. But the accuracy of the exiting methods have shown inferior performance in terms of prediction which leads to inefficient decision making in the quantity of electricity generation. This paper proposes the use of random forest supervised learning model to forecast the consumption of power and identify the level of peak demand. The large smart meter dataset collected at varying seasons of the year is fed to the random forest classifier technique for better analysis and forecasting. This approach outperforms in terms of accuracy, stability and generalization. In addition, this paper investigates the existing models and compares the performance with those models. The performance analysis shows that this model performs better than the other investigated models with performance accuracy of 95.67% and enhanced accuracy of precision and recall.
C1 [Geetha, R.; Ramyadevi, K.; Balasubramanian, M.] SA Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 S.A. Engineering College
RP Geetha, R (corresponding author), SA Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM geetha@saec.ac.in
RI MANTHIRAMOORTHY, BALASUBRAMANIAN/AFS-3480-2022; S.A. Engineering
   College, Geetha R/AFK-5225-2022; Asst.Professor, Ms. Ramya devi
   K/AAA-4706-2022; , Geetha/AAG-3802-2022
OI S.A. Engineering College, Geetha R/0000-0002-4541-3314; ,
   Geetha/0000-0002-4541-3314; Asst.Professor, Ms. Ramya devi
   K/0000-0002-1094-0050
CR Ahmad MW, 2017, ENERG BUILDINGS, V147, P77, DOI 10.1016/j.enbuild.2017.04.038
   Ashier Zhou S, 2019, IEEE EXPLORE
   CANWAN N, 2017, IEEE T POWER SYST, V32
   CHEN J, 2008, IEEE T POWER SYST, V23
   Chiaraviglio L, 2018, IEEE T SUST COMPUT, V3, P274, DOI 10.1109/TSUSC.2018.2838338
   Chou J-S, 2018, HYBRID MACHINE LEARN, DOI 10.1109/JSYST.2018.2890524
   Edomah N, MODELLING FUTURE ELE, P5, DOI 10.1109/ACESS.2017.2769338
   FAN GF, 2016, NEUROCOMPUTING
   FERNNDEZDELGADO M, 2014, J MACH LEARN RES, V15, P3133
   Geetha R, 2021, ARCH COMPUT METHOD E, V28, P2861, DOI 10.1007/s11831-020-09478-2
   Guo S, 2019, ASS ADVANCEMENT ARTI, V33, DOI 10.1609/aaai.v33i01.3301922
   Guo YC, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024676
   Hamed, 2018, ELECTRICITY PRICE FO, V9, DOI 10.1109/TSG.2017.2717282
   Hideitsu H, 2013, VERSATILLE CLUSTERIN, V4, DOI 10.1016/j.apenergy.2014.08.111
   HOBBY JD, 2012, IEEE T, V3
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Imtiaz A, 2006, EVALUATION FORECASTI, DOI 10.1109/PECON.2006.346658
   Jain A, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033704
   Karimtabar N, 2015, IEEE EXPLORE, DOI 10.1109/PRIA.2015.7161634
   Khan I, SEGMENTATION FACTORI, V4, DOI 10.1109/ACCESS.2016.2619898
   Kwac J, 2018, IEEE T SMART GRID, V9, P2409, DOI 10.1109/TSG.2016.2611600
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   LI S, 2019, IEEE INTERNET THINGS, V6
   Lin, 2016, MULTISTEP ELECTRICIT, P27, DOI [10.1109/TPDS.2015,2388479, DOI 10.1109/TPDS.2015,2388479]
   MIN TT, 2011, IEEE T SMART GRID, V2
   MOLLA T, 2019, CSEE J POWER ENERGY
   Ranjbar, 2006, IEEE EXPLORE, DOI 10.1109/PEDES.2006.344294
   Robu V, 2018, IEEE T SMART GRID, V9, P4468, DOI 10.1109/TSG.2017.2660580
   SHARMA S, 2018, IEEE GLOBE WORK, pN1288
   ZEDAN FM, 2010, IEEE, V25
   Zhang, 2020, IEEE EXPLORE, V8, DOI 10.1109/acess.2020.2980079
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
   Zhao JH, 2007, IEEE T POWER SYST, V22, P376, DOI 10.1109/TPWRS.2006.889139
NR 36
TC 12
Z9 12
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19675
EP 19693
DI 10.1007/s11042-021-10696-4
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500007
DA 2024-07-18
ER

PT J
AU Chattopadhyay, AK
   Nag, A
   Singh, JP
AF Chattopadhyay, Arup Kumar
   Nag, Amitava
   Singh, Jyoti Prakash
TI An efficient verifiable (<i>t</i>,<i>n</i>)-threshold secret image
   sharing scheme with ultralight shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Secret image sharing; Verifiable; XOR;
   Resource-constrained device; Cloud service provider
ID COLOR IMAGES
AB A secret sharing scheme partitions a secret into a set of shares and distributes them among the eligible participants, with each participant receiving one share of the secret. The sharing technique allows any qualified subset of participants to recover the secret. In (t,n)-threshold secret sharing schemes, the secret is distributed among n participants in the form of shares, such that every participant holds exactly one share. Individual share reveals nothing about the secret. Any subset of participants of size t or more (t <= n) can combine their shares and compute the secret, while any subset of size < t is not able to do so. This paper proposes a verifiable (t,n)-threshold secret image sharing (VSIS) scheme. In the proposed scheme, a secret image is shared among n participants with an intention that if t or more (t <= n) participants collaborate, then the secret image can be computed successfully. Still, any less than t participants get nothing. The scheme makes use of polynomial-based secret sharing and XOR operations to construct the shares and recover the secret image. Our scheme's main advantage is that it presents the public shares as integer numbers (not image matrices produced in previous SIS schemes), much smaller than the secret image. It also generates a public share-image of the size the same as that of the secret image. Thus, the public shares can be efficiently transferred over the public network and efficiently stored in memory. The scheme applies to both grayscale and color images. The use of Elliptic Curve Cryptography (ECC) enables the participants to choose their own secret shadows and compute the pseudo shares (integer numbers) independently. Hence the entire communications can take place safely on public channels. The pseudo shares are verifiable to the participants as well as the combiner. The combination of small public shares and the elliptic curve cryptosystem makes this scheme ideal for resource-constrained devices. In contrast, public share-image can be safely stored with a Cloud Service Provider (CSP).
C1 [Chattopadhyay, Arup Kumar] Inst Engn & Management, Kolkata, WB, India.
   [Nag, Amitava] Cent Inst Technol Kokrajhar, Kokrajhar, Assam, India.
   [Singh, Jyoti Prakash] Natl Inst Technol Patna, Patna, Bihar, India.
C3 Institute of Engineering & Management (IEM), Kolkata; National Institute
   of Technology (NIT System); National Institute of Technology Patna
RP Singh, JP (corresponding author), Natl Inst Technol Patna, Patna, Bihar, India.
EM ardent.arup@gmail.com; amitava.nag@cit.ac.in; jps@nitp.ac.in
RI Nag, Amitava/C-5421-2016; Chattopadhyay, Arup Kumar/AAR-5145-2020;
   Singh, Jyoti Prakash/I-4953-2016
OI Nag, Amitava/0000-0003-4408-7307; Singh, Jyoti
   Prakash/0000-0002-3742-7484
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Bahramian M., 2017, Algebr. Struct. Appl., V4, P45
   Belguith S, 2020, J PARALLEL DISTR COM, V135, P1, DOI 10.1016/j.jpdc.2019.08.014
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chattopadhyay AK, 2021, MULTIMED TOOLS APPL, V80, P35051, DOI 10.1007/s11042-020-09174-0
   Chattopadhyay AK, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P1025, DOI 10.1109/UEMCON.2018.8796568
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen D, 2019, IEEE ACCESS, V7, P107104, DOI 10.1109/ACCESS.2019.2929090
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chen YC, 2013, DIGIT SIGNAL PROCESS, V23, P1496, DOI 10.1016/j.dsp.2013.05.014
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Das A, 2010, APPL MATH LETT, V23, P993, DOI 10.1016/j.aml.2010.04.024
   Dehkordi MH, 2008, COMPUT COMMUN, V31, P1777, DOI 10.1016/j.comcom.2007.11.014
   Dehkordi MH, 2008, INFORM SCIENCES, V178, P2262, DOI 10.1016/j.ins.2007.11.031
   Dehkordi MH, 2008, COMPUT STAND INTER, V30, P187, DOI 10.1016/j.csi.2007.08.004
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Dutta S, 2017, LECT NOTES COMPUT SC, V10681, P58, DOI 10.1007/978-3-319-72089-0_4
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Herranz J, 2014, DESIGN CODE CRYPTOGR, V73, P841, DOI 10.1007/s10623-013-9831-6
   Hu CQ, 2012, THEOR COMPUT SCI, V445, P52, DOI 10.1016/j.tcs.2012.05.006
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Katz J., 2014, INTRO MODERN CRYPTOG
   Kumar S.N., 2015, International Transaction of Electrical and Computer Engineers System, V3, P1
   Lin CC, 2003, OPT ENG, V42, P2340, DOI 10.1117/1.1588661
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu YX, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1084-7
   Ma J, 2019, INT WORKSH DIG WAT, P421
   Mashhadi, 2020, INF SECUR J, P1
   Mashhadi S, 2020, J APPL SEC RES, V15, P84, DOI 10.1080/19361610.2019.1696607
   Mashhadi S, 2015, INFORM SCIENCES, V294, P31, DOI 10.1016/j.ins.2014.08.046
   Miao FY, 2017, CHINESE J ELECTRON, V26, P557, DOI 10.1049/cje.2016.08.014
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Nag A, 2017, INT ARAB J INF TECHN, V14, P448
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Prasetyo H, 2019, MULTIMED TOOLS APPL, V78, P24837, DOI 10.1007/s11042-019-7710-5
   Prasetyo H, 2019, IEEE ACCESS, V7, P37473, DOI 10.1109/ACCESS.2019.2902853
   Sardar M.K., 2020, J. Vis. Commun. Image Represent.
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shao J, 2014, INFORM SCIENCES, V278, P104, DOI 10.1016/j.ins.2014.03.025
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Stinson D. R., 2018, Cryptography Theory and Practice
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Yeh KH, 2016, IEEE ACCESS, V4, P10288, DOI 10.1109/ACCESS.2016.2638038
   Yuan JT, 2019, INFORM SCIENCES, V496, P42, DOI 10.1016/j.ins.2019.04.061
   Zhao JJ, 2007, COMPUT STAND INTER, V29, P138, DOI 10.1016/j.csi.2006.02.004
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
   Zhou ZL, 2018, IEEE ACCESS, V6, P15021, DOI 10.1109/ACCESS.2018.2811722
NR 62
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34969
EP 34999
DI 10.1007/s11042-021-10523-w
EA FEB 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000618600400003
DA 2024-07-18
ER

PT J
AU Zhuo, W
   He, ZC
   Zheng, MY
   Hu, BC
   Wang, RJ
AF Zhuo, Wei
   He, Zhichao
   Zheng, Mengying
   Hu, Beichen
   Wang, Ruijuan
TI Research on personalized image retrieval technology of video stream big
   data management model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Personalized image annotation; Multi-source data
   fusion; Video images; Global features
ID NETWORK
AB The irrelevant background information in the personalized image is easy to be quantified into the same word as the main target, and the quantization process will inevitably cause the loss of a lot of visual information. This phenomenon will seriously reduce the quality of the generated theme when the personalized image content is complex. This paper proposes a Multi-Source Big Data Fusion Annotation (MSBDFA) model. The model obtains similar personalized images by analyzing the relevant multi-source information of the personalized images, and uses the annotations of the similar personalized images to label the personalized images. For the personalized images with complex background visual information, the personalized image retrieval based on complete information modeling uses the high-dimensional Gaussian distribution to directly model the continuous visual features of the personalized images, and uses the two-level spectral clustering algorithm to distribute the regional topics, so as to embed the complete local information contained in the visual features into the global features of the personalized image. Therefore, this method can completely retain visual information during the modeling process, so that the targets buried in the complex background can be better classified. The experimental results on the standard database show that the method proposed in this paper can generate high-quality personalized image subjects in complex scenes and has good retrieval performance.
C1 [Zhuo, Wei] Zhengzhou Univ, Henan Inst Big Data, Zhengzhou 450000, Henan, Peoples R China.
   [He, Zhichao; Zheng, Mengying; Hu, Beichen; Wang, Ruijuan] Zhengzhou Univ, Sch Software, Hanwei Internet Things Res Sch, Zhengzhou 450000, Henan, Peoples R China.
C3 Zhengzhou University; Zhengzhou University
RP Wang, RJ (corresponding author), Zhengzhou Univ, Sch Software, Hanwei Internet Things Res Sch, Zhengzhou 450000, Henan, Peoples R China.
EM rjwang@zzu.edu.cn
RI Wang, Zejun/KBB-8454-2024
CR Anshari Muhammad, 2019, Applied Computing and Informatics, V15, P94, DOI 10.1016/j.aci.2018.05.004
   Arthanari J, 2019, CLUSTER COMPUT, V22, pS3771, DOI 10.1007/s10586-018-2284-y
   Arulmozhi P, 2019, ARTIF INTELL REV, V52, P323, DOI 10.1007/s10462-017-9591-1
   Belcastro L, 2019, INT J PARALLEL EMERG, V34, P632, DOI 10.1080/17445760.2017.1422501
   Bouchakwa M, 2020, PROG ARTIF INTELL, V9, P1, DOI 10.1007/s13748-019-00195-x
   Chen XW, 2019, CLUSTER COMPUT, V22, P13293, DOI 10.1007/s10586-018-1848-1
   Govindaraj P, 2019, SIGNAL IMAGE VIDEO P, V13, P771, DOI 10.1007/s11760-018-1407-5
   Jeong S, 2019, STRUCT INFRASTRUCT E, V15, P82, DOI 10.1080/15732479.2018.1500617
   Jin YR, 2019, MULTIMED TOOLS APPL, V78, P1289, DOI 10.1007/s11042-018-6172-5
   Kasban H, 2019, MULTIMED TOOLS APPL, V78, P35211, DOI 10.1007/s11042-019-08100-3
   Li XG, 2019, J INTELL FUZZY SYST, V37, P3425, DOI 10.3233/JIFS-179146
   Liu Y, 2019, WORLD WIDE WEB, V22, P1313, DOI 10.1007/s11280-018-0585-y
   Meerja KA, 2019, MOBILE NETW APPL, V24, P1078, DOI 10.1007/s11036-018-1063-6
   Mo YQ, 2019, INT J WIREL INF NETW, V26, P152, DOI 10.1007/s10776-019-00434-x
   Mohamed A, 2020, ARTIF INTELL REV, V53, P989, DOI 10.1007/s10462-019-09685-9
   Prasanth T, 2019, CLUSTER COMPUT, V22, P2027, DOI 10.1007/s10586-017-1320-7
   Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2
   Sun ST, 2019, CLUSTER COMPUT, V22, P2383, DOI 10.1007/s10586-017-1498-8
   Tai LJ, 2019, MULTIMED TOOLS APPL, V78, P4579, DOI 10.1007/s11042-018-6391-9
   Xing ZC, 2019, INT J WIREL INF NETW, V26, P183, DOI 10.1007/s10776-019-00440-z
NR 20
TC 7
Z9 7
U1 8
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41527
EP 41544
DI 10.1007/s11042-020-10499-z
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000616915300002
DA 2024-07-18
ER

PT J
AU Pereira, EM
   Torres, RD
   dos Santos, JA
AF Pereira, Erico M.
   Torres, Ricardo da S.
   dos Santos, Jefersson A.
TI A genetic algorithm approach for image representation learning through
   color quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color quantization; Representation learning; Feature extraction; Genetic
   Algorithm; Content-based image retrieval
ID FRAMEWORK; NETWORK
AB Over the last decades, hand-crafted feature extractors have been used to encode image visual properties into feature vectors. Recently, data-driven feature learning approaches have been successfully explored as alternatives for producing more representative visual features. In this work, we combine both research venues, focusing on the color quantization problem. We propose two data-driven approaches to learn image representations through the search for optimized quantization schemes, which lead to more effective feature extraction algorithms and compact representations. Our strategy employs Genetic Algorithm, a soft-computing apparatus successfully utilized in Information-retrieval-related optimization problems. We hypothesize that changing the quantization affects the quality of image description approaches, leading to effective and efficient representations. We evaluate our approaches in content-based image retrieval tasks, considering eight well-known datasets with different visual properties. Results indicate that the approach focused on representation effectiveness outperformed baselines in all tested scenarios. The other approach, which also considers the size of created representations, produced competitive results keeping or even reducing the dimensionality of feature vectors up to 25%.
C1 [Pereira, Erico M.; dos Santos, Jefersson A.] Univ Fed Minas Gerais, Dept Comp Sci, Av Antonio Carlos 6627, BR-31270010 Belo Horizonte, MG, Brazil.
   [Torres, Ricardo da S.] Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, Campinas, SP, Brazil.
   [Torres, Ricardo da S.] NTNU Norwegian Univ Sci & Technol, Dept ICT & Nat Sci, Alesund, Norway.
C3 Universidade Federal de Minas Gerais; Universidade Estadual de Campinas;
   Norwegian University of Science & Technology (NTNU)
RP dos Santos, JA (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Av Antonio Carlos 6627, BR-31270010 Belo Horizonte, MG, Brazil.
EM emarco.pereira@dcc.ufmg.br; ricardo.torres@ntnu.no;
   jefersson@dcc.ufmg.br
RI dos Santos, Jefersson/HKW-4282-2023; Torres, Ricardo da S./C-4526-2012
OI dos Santos, Jefersson/0000-0002-8889-1586; Torres,
   Ricardo/0000-0001-9772-263X; Pereira, Erico Marco/0000-0002-5150-9574
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brasil
   (CAPES) [001]; Brazilian National Council for Scientific and
   Technological Development (CNPq) [424700/2018-2, 311395/2018-0]; Minas
   Gerais Research Foundation (FAPEMIG) [APQ-00449-17]; CAPES
   [88881.145912/2017-01]; Sao Paulo Research Foundation-FAPESP
   [2014/12236-1, 2015/24494-8, 2016/50250-1, 2017/20945-0];
   FAPESP-Microsoft Virtual Institute [2013/50155-0, 2013/50169-1,
   2014/50715-9]
FX This study was financed in part by: the Coordenacao de Aperfeicoamento
   de Pessoal de Nivel Superior-Brasil (CAPES)-Finance Code 001; the
   Brazilian National Council for Scientific and Technological Development
   (CNPq)-grants #424700/2018-2 and #311395/2018-0; and the Minas Gerais
   Research Foundation (FAPEMIG)-grant APQ-00449-17. Authors are also
   grateful to CAPES (grant #88881.145912/2017-01), Sao Paulo Research
   Foundation-FAPESP (grants #2014/12236-1, #2015/24494-8, #2016/50250-1,
   and #2017/20945-0) and the FAPESP-Microsoft Virtual Institute (grants
   #2013/50155-0, #2013/50169-1, and #2014/50715-9).
CR [Anonymous], 2005, OBJECT CONCEPT RECOG
   Baeza-Yates R., 1999, Modern information retrieval
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bharti V, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P294, DOI [10.1109/confluence47617.2020.9057841, 10.1109/Confluence47617.2020.9057841]
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Penatti OAB, 2008, SIBGRAPI, P163, DOI 10.1109/SIBGRAPI.2008.20
   Bo L., 2011, Neural Information Processing Systems, P2115
   Bukh, 1992, JSTOR
   Coates A., 2011, P 28 INT C MACH LEAR, V28, P921
   Criminisi Antonio., 2004, MICROSOFT RES CAMBRI
   Davis L., 1991, Handbook of Genetic Algorithms
   Davis S. M., 1978, Remote Sensing: The Quantitative Approach, P405
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Fan WG, 2004, J AM SOC INF SCI TEC, V55, P628, DOI 10.1002/asi.20009
   García-Lamont F, 2020, MULTIMED TOOLS APPL, V79, P1555, DOI 10.1007/s11042-019-08278-6
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Khaldi B, 2019, IET IMAGE PROCESS, V13, P1401, DOI 10.1049/iet-ipr.2018.6440
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   Kingma D. P., 2013, ARXIV13126114
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li T, 2019, MULTIMED TOOLS APPL, V78, P3411, DOI 10.1007/s11042-018-5986-5
   LI X, 2019, MULTIMEDIA TOOLS APP, V78
   Li Y, 2002, INT C PATT RECOG, P952, DOI 10.1109/ICPR.2002.1048195
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Makhzani A, 2013, ARXIV13125663, P5663
   Makhzani A., 2015, P 28 INT C NEURAL IN, P2791
   MOHSENI S, 2020, IEEE ACCESS, V8
   Nakamura RYM, 2014, IEEE T GEOSCI REMOTE, V52, P2126, DOI 10.1109/TGRS.2013.2258351
   Nayar SK, 1996, IEEE INT CONF ROBOT, P2321, DOI 10.1109/ROBOT.1996.506510
   Ng A., 2011, CS294A LECT NOTES
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Omran MG, 2005, INFORM-J COMPUT INFO, V29, P261
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Pérez-Delgado ML, 2019, APPL INTELL, V49, P2482, DOI 10.1007/s10489-018-1389-6
   Ponti M, 2016, NEUROCOMPUTING, V173, P385, DOI 10.1016/j.neucom.2015.04.114
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Rifai S., 2011, CONTRACTIVE AUTOENCO, DOI DOI 10.5555/3104482.3104587
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Rodriguez-Coayahuitl L, 2019, GENET PROGRAM EVOL M, V20, P413, DOI 10.1007/s10710-019-09354-4
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Scheunders P, 1996, PATTERN RECOGN LETT, V17, P547, DOI 10.1016/0167-8655(96)00011-6
   Sheng T, 2018, 2018 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2), P14, DOI 10.1109/EMC2.2018.00011
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Suganuma M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P497, DOI 10.1145/3071178.3071229
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Torres R. S. D., 2006, RITA, V13, P161
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie LX, 2017, IEEE I CONF COMP VIS, P1388, DOI 10.1109/ICCV.2017.154
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 66
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15315
EP 15350
DI 10.1007/s11042-020-10194-z
EA FEB 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yong, CW
   Teo, K
   Murphy, BP
   Hum, YC
   Tee, YK
   Xia, KJ
   Lai, KW
AF Yong, Ching Wai
   Teo, Kareen
   Murphy, Belinda Pingguan
   Hum, Yan Chai
   Tee, Yee Kai
   Xia, Kaijian
   Lai, Khin Wee
TI Knee osteoarthritis severity classification with ordinal regression
   module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cumulative-link loss function; Kellgren-Lawrence grade; Knee radiograph;
   Ordinal regression module; Osteoarthritis
ID NEURAL-NETWORKS; EPIDEMIOLOGY; IMPACT
AB Osteoarthritis (OA) is a common form of knee arthritis which causes significant disability and is threatening to plague patient's quality of life. Although this chronic condition does not lead to fatality, still there exists no known cure for OA. Diagnosis of OA can be confirmed primarily based on radiographic findings. Being a progressive disease, early identification of OA is crucial for clinical interventions to curtail the OA degeneration. Kellgren-Lawrence (KL) grading system has been traditionally employed to assess the knee OA severity. Due to the recent advancements of deep learning in computer vision, more studies have employed deep neural network in automatically predicting KL grade from plain knee joint radiograph. However, these studies treat KL grading as a multi-class classification task and ignore the inherent ordinal nature within the KL grades. In this study, we propose an ordinal regression module for neural networks to treat KL grading as an ordinal regression task. Our module takes an input from neural network and produces 4 cut-points to partition the prediction space into 5 respective KL grades. The proposed model is optimized by a cumulative-link loss function. Performance of the model is evaluated against various notable neural networks and significant improvements on the knee OA KL grade prediction were demonstrated.
C1 [Yong, Ching Wai; Teo, Kareen; Murphy, Belinda Pingguan; Lai, Khin Wee] Univ Malaya, Fac Engn, Dept Biomed Engn, Jalan Univ, Kuala Lumpur 50603, Malaysia.
   [Hum, Yan Chai; Tee, Yee Kai] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Mechatron & Biomed Engn, Jalan Sungai Long, Kajang 43200, Selangor, Malaysia.
   [Xia, Kaijian] Soochow Univ, Changshu Peoples Hosp 1, Changshu Hosp, Changshu, Jiangsu, Peoples R China.
C3 Universiti Malaya; Universiti Tunku Abdul Rahman (UTAR); Soochow
   University - China
RP Lai, KW (corresponding author), Univ Malaya, Fac Engn, Dept Biomed Engn, Jalan Univ, Kuala Lumpur 50603, Malaysia.
EM lai.khinwee@um.edu.my
RI Hum, Yan Chai/H-9021-2018; Lai, Khin Wee/A-2997-2011; Tee, Yee
   Kai/O-1677-2015; Teo, Kareen/AAQ-9463-2021
OI Hum, Yan Chai/0000-0002-9657-8311; Lai, Khin Wee/0000-0002-8602-0533;
   Tee, Yee Kai/0000-0002-0263-6358; 
FU Fundamental Research Grant Scheme (FRGS), Ministry of Education,
   Malaysia [FRGS/1/2018/TK04/UM/02/9]
FX This work was supported by Fundamental Research Grant Scheme (FRGS)
   FRGS/1/2018/TK04/UM/02/9, Ministry of Education, Malaysia. Data and/or
   research tools used in the preparation of this manuscript were obtained
   and analyzed from the controlled access datasets distributed from the
   Osteoarthritis Initiative (OAI). OAI is a collaborative informatics
   system created by the National Institute of Mental Health and the
   National Institute of Arthritis, Musculoskeletal and Skin Diseases
   (NIAMS) to provide a worldwide resource to quicken the pace of biomarker
   identification, scientific investigation and OA drug development.
CR [Anonymous], 2014, BURD MUSC DIS US BMU
   Antony J., 2017, INT C MACH LEARN DAT, P376, DOI [10.1007/978-3-319-62416-7_27, DOI 10.1007/978-3-319-62416-7_27]
   Antony J, 2016, INT C PATT RECOG, P1195, DOI 10.1109/ICPR.2016.7899799
   Braun HJ, 2012, BONE, V51, P278, DOI 10.1016/j.bone.2011.11.019
   Chen PJ, 2019, COMPUT MED IMAG GRAP, V75, P84, DOI 10.1016/j.compmedimag.2019.06.002
   Culvenor AG, 2015, KNEE SURG SPORT TR A, V23, P3532, DOI 10.1007/s00167-014-3205-0
   Faur CI, 2020, RES SQUARE, DOI [10.21203/rs.3.rs-29937/v1, DOI 10.21203/RS.3.RS-29937/V1]
   Górriz M, 2019, PR MACH LEARN RES, V102, P197
   GUCCIONE AA, 1994, AM J PUBLIC HEALTH, V84, P351, DOI 10.2105/AJPH.84.3.351
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hirota K, 2017, DEV APPL OPTICAL COH
   Höfener H, 2018, COMPUT MED IMAG GRAP, V70, P43, DOI 10.1016/j.compmedimag.2018.08.010
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Jiang ZX, 2018, COMPUT MED IMAG GRAP, V68, P1, DOI 10.1016/j.compmedimag.2018.04.005
   KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494
   Losina E, 2011, ANN INTERN MED, V154, P217, DOI 10.7326/0003-4819-154-4-201102150-00001
   Luyten FP, 2012, KNEE SURG SPORT TR A, V20, P401, DOI 10.1007/s00167-011-1743-2
   Man G S, 2014, J Med Life, V7, P37
   Manjón JV, 2018, COMPUT MED IMAG GRAP, V69, P43, DOI 10.1016/j.compmedimag.2018.05.001
   Neogi T, 2013, OSTEOARTHR CARTILAGE, V21, P1145, DOI 10.1016/j.joca.2013.03.018
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2017, J MACH LEARN RES, V18, P1
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sangha O, 2000, RHEUMATOLOGY, V39, P3, DOI 10.1093/rheumatology/39.suppl_2.3
   Schiphof D, 2008, ANN RHEUM DIS, V67, P1034, DOI 10.1136/ard.2007.079020
   Shamir L, 2009, OSTEOARTHR CARTILAGE, V17, P1307, DOI 10.1016/j.joca.2009.04.010
   Su H, 2015, LECT NOTES COMPUT SC, V9351, P383, DOI 10.1007/978-3-319-24574-4_46
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tiulpin A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56527-3
   Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yong CW, 2018, ADV SCI LETT, V24, P1771, DOI 10.1166/as1.2018.11156
   Zisserman A, 2015, AB14091556 CORR
NR 36
TC 21
Z9 21
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41497
EP 41509
DI 10.1007/s11042-021-10557-0
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000611964400002
DA 2024-07-18
ER

PT J
AU Kumar, A
   Om, H
AF Kumar, Ashish
   Om, Hari
TI An enhanced and provably secure authentication protocol using Chebyshev
   chaotic maps for multi-server environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiserver authentication; Chaotic maps; Security attacks; ProVerif;
   Timestamps
AB Multiserver authentication requires users to have only one-time registration for accessing different permissible services securely from various servers over an insecure network. To date, many multiserver authentication protocols have been presented in the literature. Most of them require the registration server's participation at the time of authentication, leading to increased communication overhead and bandwidth overload of the registration server. Recently, Lee et al. introduced a multiserver authentication protocol using extended chaotic maps that permits registered users and servers to authenticate with each other directly. In this paper, we revisit Lee et al.'s protocol and find that it is insecure against user impersonation and session-specific temporary information attacks. Additionally, the protocol uses timestamps, which may cause serious time synchronization problems. The weaknesses of Lee et al.'s protocol prompted us to propose another protocol based on extended chaotic maps, which is free from serious time synchronization problems, more efficient in terms of computation and communication overheads, and more robust against all known attacks. Furthermore, our protocol adds extra functionality features such as considering the users' registration expiration, server scalability, and inclusion of two new phases: a deregistration phase and a registration renewal phase for a registered user. Our protocol's security has been validated using the automated tool ProVerif and proven through formal and informal analyses. With better security protection, fewer complexities, and additional features, the proposed protocol is more suitable for practical use than other related protocols.
C1 [Kumar, Ashish; Om, Hari] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Kumar, A (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM ashish.iitdhn@gmail.com; hariom4india@gmail.com
RI OM, HARI/AAY-6011-2021
OI OM, HARI/0000-0002-9750-2706; Kumar, Ashish/0000-0002-3073-3614
CR Abadi M, 2001, ACM SIGPLAN NOTICES, V36, P104, DOI 10.1145/373243.360213
   Abadi M, 2009, LECT NOTES COMPUT SC, V5643, P35, DOI 10.1007/978-3-642-02658-4_5
   Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Ali Z, 2020, IEEE ACCESS, V8, P107993, DOI 10.1109/ACCESS.2020.3000716
   Amin Ruhul, 2016, International Journal of Network Security, V18, P172
   Amin R, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5989151
   Amin R, 2015, WIRELESS PERS COMMUN, V84, P439, DOI 10.1007/s11277-015-2616-7
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Bergamo P, 2005, IEEE T CIRCUITS-I, V52, P1382, DOI 10.1109/TCSI.2005.851701
   Canetti R, 2001, LECT NOTES COMPUT SC, V2045, P453
   Chang CC, 2016, INT J COMMUN SYST, V29, P290, DOI 10.1002/dac.2830
   Chatterjee S, 2018, IEEE T DEPEND SECURE, V15, P824, DOI 10.1109/TDSC.2016.2616876
   Chen CT, 2015, SECUR COMMUN NETW, V8, P1608, DOI 10.1002/sec.1109
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Gupta PC, 2016, WIRELESS PERS COMMUN, V87, P225, DOI 10.1007/s11277-015-3040-8
   Hassan A, 2019, MOBILE NETW APPL, V24, P890, DOI 10.1007/s11036-018-1145-5
   Hsieh WB, 2014, J SUPERCOMPUT, V70, P133, DOI 10.1007/s11227-014-1135-8
   Irshad A, 2018, ARAB J SCI ENG, V43, P811, DOI 10.1007/s13369-017-2764-z
   Irshad A, 2017, WIRELESS PERS COMMUN, V95, P3185, DOI 10.1007/s11277-017-3990-0
   Irshad A, 2018, MULTIMED TOOLS APPL, V77, P1167, DOI 10.1007/s11042-016-4236-y
   Irshad A, 2016, J SUPERCOMPUT, V72, P1623, DOI 10.1007/s11227-016-1688-9
   Islam SKH, 2014, WIRELESS PERS COMMUN, V79, P1975, DOI 10.1007/s11277-014-1968-8
   Jangirala S, 2017, WIRELESS PERS COMMUN, V95, P2735, DOI 10.1007/s11277-017-3956-2
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kumar A, 2018, DIGIT COMMUN NETW, V4, P27, DOI 10.1016/j.dcan.2017.09.004
   Lee CC, 2014, NONLINEAR DYNAM, V76, P853, DOI 10.1007/s11071-013-1174-3
   Lee TF, 2019, MULTIMED TOOLS APPL, V78, P31649, DOI 10.1007/s11042-019-07949-8
   Li CT, 2016, SECUR COMMUN NETW, V9, P2276, DOI 10.1002/sec.1487
   Li LH, 2001, IEEE T NEURAL NETWOR, V12, P1498, DOI 10.1109/72.963786
   Li X, 2016, WIRELESS PERS COMMUN, V89, P569, DOI 10.1007/s11277-016-3293-x
   Lin IC, 2003, FUTURE GENER COMP SY, V19, P13, DOI 10.1016/S0167-739X(02)00093-6
   Lu YR, 2016, SECUR COMMUN NETW, V9, P1321, DOI 10.1002/sec.1417
   Maitra T, 2016, SECUR COMMUN NETW, V9, P4615, DOI 10.1002/sec.1653
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Moon J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145263
   Pointcheval D, 2008, LECT NOTES COMPUT SC, V5037, P277, DOI 10.1007/978-3-540-68914-0_17
   Qi MP, 2019, MULTIMED TOOLS APPL, V78, P27553, DOI 10.1007/s11042-019-07812-w
   Reddy AG, 2017, IEEE ACCESS, V5, P3622, DOI 10.1109/ACCESS.2017.2666258
   Sahoo SS, 2018, WIRELESS PERS COMMUN, V101, P1307, DOI 10.1007/s11277-018-5764-8
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
   Sudhakar T, 2020, WIREL NETW, V26, P4909, DOI 10.1007/s11276-018-01922-3
   Sureshkumar V, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3358
   Tan ZW, 2016, SECUR COMMUN NETW, V9, P1384, DOI 10.1002/sec.1424
   Tsai JL, 2015, INT J COMMUN SYST, V28, P1955, DOI 10.1002/dac.2829
   Wang B, 2013, WIRELESS PERS COMMUN, V68, P361, DOI 10.1007/s11277-011-0456-7
   Xie Q, 2017, IEEE T INF FOREN SEC, V12, P1382, DOI 10.1109/TIFS.2017.2659640
   Xu Z., 2017, Proceedings, V19, P595
   Yoon EJ, 2013, J SUPERCOMPUT, V63, P235, DOI 10.1007/s11227-010-0512-1
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhu HF, 2015, NONLINEAR DYNAM, V82, P835, DOI 10.1007/s11071-015-2198-7
NR 51
TC 4
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14163
EP 14189
DI 10.1007/s11042-020-10320-x
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400009
DA 2024-07-18
ER

PT J
AU Huang, W
   Zhou, XS
   Dong, MC
   Xu, HY
AF Huang, Wei
   Zhou, Xiaoshu
   Dong, Mingchao
   Xu, Huaiyu
TI Multiple objects tracking in the UAV system based on hierarchical deep
   high-resolution network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; UAV; HDHNet; Fusion loss
AB Robust and high-performance visual multi-object tracking is a big challenge in computer vision, especially in a drone scenario. In this paper, an online Multi-Object Tracking (MOT) approach in the UAV system is proposed to handle small target detections and class imbalance challenges, which integrates the merits of deep high-resolution representation network and data association method in a unified framework. Specifically, while applying tracking-by-detection architecture to our tracking framework, a Hierarchical Deep High-resolution network (HDHNet) is proposed, which encourages the model to handle different types and scales of targets, and extract more effective and comprehensive features during online learning. After that, the extracted features are fed into different prediction networks for interesting targets recognition. Besides, an adjustable fusion loss function is proposed by combining focal loss and GIoU loss to solve the problems of class imbalance and hard samples. During the tracking process, these detection results are applied to an improved DeepSORT MOT algorithm in each frame, which is available to make full use of the target appearance features to match one by one on a practical basis. The experimental results on the VisDrone2019 MOT benchmark show that the proposed UAV MOT system achieves the highest accuracy and the best robustness compared with state-of-the-art methods.
C1 [Huang, Wei; Xu, Huaiyu] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.
   [Huang, Wei; Xu, Huaiyu] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhou, Xiaoshu; Dong, Mingchao; Xu, Huaiyu] ShanghaiTech Univ, Shanghai 201210, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; ShanghaiTech University
RP Huang, W (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.; Huang, W (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM huangw@sari.ac.cn
FU Scale Test Verification Assessment and Demonstration Application for
   SEANET Program of the Chinese Academy of Sciences [XDC02070800]
FX This work is supported by the Scale Test Verification Assessment and
   Demonstration Application for SEANET Program of the Chinese Academy of
   Sciences. Grant No. is XDC02070800.
CR [Anonymous], 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]
   [Anonymous], 2014, ARXIV14097618
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Chen BY, 2018, LECT NOTES COMPUT SC, V11211, P328, DOI 10.1007/978-3-030-01234-2_20
   Chen K., 2019, arXiv preprint arXiv:1906.07155
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Deng JK, 2019, IEEE T IMAGE PROCESS, V28, P3636, DOI 10.1109/TIP.2019.2899267
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu Peng, 2020, ARXIV PREPRINT ARXIV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Marvasti-Zadeh S. Mojtaba, 2019, ARXIV191200535
   Mills-Tettey G.A., 2007, The dynamic Hungarian algorithm for the assignment problem with changing costs
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Ren LL, 2018, LECT NOTES COMPUT SC, V11207, P605, DOI 10.1007/978-3-030-01219-9_36
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang SY, 2016, LECT NOTES COMPUT SC, V9914, P100, DOI 10.1007/978-3-319-48881-3_8
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang J, 2019, ARXIV PREPRINT ARXIV
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xu Y., 2019, IEEE ICC, DOI DOI 10.1109/icc.2019.8761264
   Yang J, 2017, IEEE COMPUT SOC CONF, P2025, DOI 10.1109/CVPRW.2017.253
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang PY, 2019, IEEE INT CONF COMP V, P37, DOI 10.1109/ICCVW.2019.00011
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou X., 2019, arXiv
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 58
TC 15
Z9 18
U1 4
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13911
EP 13929
DI 10.1007/s11042-020-10427-1
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500007
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, QW
   Wang, YH
   Jiang, B
   Wang, X
   Su, RJ
AF Zhang, Qiuwen
   Wang, Yihan
   Jiang, Bin
   Wang, Xiao
   Su, Rijian
TI Adaptive CU partition and early skip mode detection for H.266/VVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.266/VVC; Adaptive CU decision; Early skip; Intra prediction
ID TERMINATION ALGORITHM; DECISION ALGORITHM; INTRA
AB The Joint Video Exploration Team (JVET) has started to develop the next-generation video coding standard-H.266/Versatile Video Coding (H.266/VVC) based on H.265/High Efficiency Video Coding (H.265/HEVC) to provide higher compression performance. The H.266/VVC supports the flexible quadtree with a nested multi-type tree (QTMT) partition structure including quadtree (QT), binary tree (BT), and ternary tree (TT). The coding unit (CU) sizes range from 128 to 4 for the luma component or from 64 to 2 for the chroma component in the QTMT splitting structure. The introduction of small CU size, i.e., 2xN, leads to inefficient hardware implementation because it causes pipeline delayed and needs to process 2xN pixels in the hardware architecture. In addition, the inter or bi-predicted of small CU requires a higher memory bandwidth than the bi-predicted of 8x8 CU in H.266/VVC. To solve the above issues, we introduce a fast method to accelerate CU partition and mode decision, including an adaptive CU partition method and early skip mode detection method. The proposed algorithm consists of two parts: (1) adaptive remove 2xN CUs by skipping BT and TT splitting mode; (2) early skip bi-predicted or inter prediction of small CU. The experimental results demonstrate that the proposed scheme can save 47% coding time while maintaining the coding performance.
C1 [Zhang, Qiuwen; Wang, Yihan; Jiang, Bin; Wang, Xiao; Su, Rijian] Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Zhang, QW (corresponding author), Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
EM zhangqwen@126.com
RI wang, yihan/HTN-8802-2023
FU National Natural Science Foundation of China [61771432, 61302118,
   61773018, 61702464, 61803346]; Basic Research Projects of Education
   Department of Henan [21zx003, 20A880004]; Key Research and Development
   Program of Henan [202102210179]
FX This work was supported in part by the National Natural Science
   Foundation of China No. 61771432, 61302118, 61773018, 61702464, and
   61803346, the Basic Research Projects of Education Department of Henan
   No. 21zx003, and 20A880004, and the Key Research and Development Program
   of Henan No. 202102210179.
CR [Anonymous], The vvc test model 1
   Bjontegaard G., 2001, Document VCEG-M33
   Bjontegaard G., 2008, VCEGAI11
   Bossen, 2019, JVETN1010
   Bross B., 2019, Document JVET-M1001
   Chen C-C, 2016, 4 JVET M
   Chen Ching-Yeh, 2018, 11 JVET M LJUBLJ SI
   Chen J., 2016, 3 M GEN MAY
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Feng ZQ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P551, DOI 10.1109/ICIVC.2018.8492898
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Fu T, 2019, IEEE INT CON MULTI, P61, DOI 10.1109/ICME.2019.00019
   He Y, 2019, JVETM0862
   Huang XP, 2017, SIGNAL IMAGE VIDEO P, V11, P33, DOI 10.1007/s11760-016-0887-4
   Huang YW, 2020, IEEE T CIRC SYST VID, V30, P1311, DOI 10.1109/TCSVT.2019.2945048
   Li X., 2018, 11 JVET M LJUBLJ SI
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Lin TL, 2020, J REAL-TIME IMAGE PR, V17, P493, DOI 10.1007/s11554-018-0794-8
   Lin TL, 2018, IEEE INT C ELECTR TA
   Liu S, 2018, JVETL1001
   Liu S., 2018, P 11 JVET M LJUBL SL, VVolume 22, P1649
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Park SH, 2019, IEEE ACCESS, V7, P172597, DOI 10.1109/ACCESS.2019.2956196
   Ramezanpour M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P45, DOI 10.1109/IranianMVIP.2015.7397501
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zhang QW, 2021, MULTIMEDIA SYST, V27, P1, DOI 10.1007/s00530-020-00688-z
   Zhang QW, 2020, IEEE ACCESS, V8, P117539, DOI 10.1109/ACCESS.2020.3004580
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
   Zhang QW, 2015, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-015-0058-5
   Zhang QW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053017
   Zhang QW, 2014, ELECTRON LETT, V50, P994, DOI 10.1049/el.2014.0065
   Zhao X, 2015, 52 M
NR 34
TC 1
Z9 1
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13957
EP 13973
DI 10.1007/s11042-020-10252-6
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500003
DA 2024-07-18
ER

PT J
AU Sasank, VVS
   Venkateswarlu, S
AF Sasank, V. V. S.
   Venkateswarlu, S.
TI Brain tumor classification using modified kernel based softplus extreme
   learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Kernel based softplus extreme learning machine;
   Morphological operation; Fuzzy c-means
AB An uncontrollable growth of abnormal cells in the brain may result in brain tumor. Two different categories of brain tumor are benign and malignant. The doctors need to provide an efficient treatment for tumor affected patients, usually, the treatment process for both the types of tumors are different, as these two types may show diverse properties. Therefore it is necessary to accurately segment and classify the two types of brain tumor from MRI so that the doctors can provide proper treatment to each patient. For such segmentation and classification, a practical approach is introduced in this method. The tumor classification from MRI undergoes 4 different phases they are pre-processing, segmentation, feature extraction, and classification. During pre-processing, the Laplacian of Gaussian (LoG) and Contrast Limited Adaptive Histogram Equalization (CLAHE) is applied. Then, the features from the segmented image is extracted using three different extraction techniques. But sometimes the extracted features may found in large dimension with relevant and irrelevant features. To reduce that, an optimization based feature selection process is included before tumor classification phase. A kernel based Softplus extreme learning machine (KSELM) is used for classification. Finally, the experimental analysis is carried out with BRATS 2014, 2015, 2018, and BRT (Brain tumor) dataset. The performance metrics like accuracy, specificity, PPV, FNR, FPR, DSC, JSI, and sensitivity are determined. Different existing brain tumor classification techniques are compared with this proposed KSELM technique.
C1 [Sasank, V. V. S.; Venkateswarlu, S.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Sasank, VVS (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
EM sasank64@gmail.com
RI VVS, Dr Sasank/AAJ-5316-2021
CR Amin J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1453-8
   [Anonymous], 2012, INT J ADV INF SCI SE, DOI DOI 10.4156/AISS.VOL4.ISSUE18.1
   [Anonymous], 2018, Technologies for Smart-City Energy Security and Power (ICSESP), DOI DOI 10.1109/ICSESP.2018.8376669
   [Anonymous], 2015, J INFORM HIDING MULT
   BAHADURE NB, 2017, INT J BIOMED IMAGING, P1, DOI DOI 10.1155/2017/9749108
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Chen S, 2016, MED BIOL ENG COMPUT, V54, P1793, DOI 10.1007/s11517-016-1469-x
   Dey V, 2010, INT ARCH PHOTOGRAMM, V38, P31
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Irum I, 2015, J Eng Sci Technol Rev, V8, P41
   Kalam R, 2016, COMPUT SCI INF TECHN, P47, DOI DOI 10.5121/CSIT.2016.60405
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Masood S., 2013, RES J APPL SCI ENG T, V5, P49, DOI DOI 10.19026/RJASET.5.5083
   Mathew AR, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1744, DOI 10.1109/ICICICT1.2017.8342834
   Nakib A, 2009, IMAGE VISION COMPUT, V27, P1343, DOI 10.1016/j.imavis.2008.12.004
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Özyurt F, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P410, DOI 10.1109/UBMK.2018.8566537
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Sharif Muhammad, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1063, DOI 10.1007/s12652-018-1075-x
   Sharif M, 2020, NEURAL COMPUT APPL, V32, P15975, DOI 10.1007/s00521-019-04679-8
   Singh NP, 2017, ADV INTELL SYST COMP, V516, P611, DOI 10.1007/978-981-10-3156-4_65
   Song B, 2016, LECT NOTES COMPUT SC, V10154, P162, DOI 10.1007/978-3-319-55524-9_16
   Sutojo T, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P182, DOI 10.1109/ICITISEE.2017.8285491
   Tahir B, 2019, MICROSC RES TECHNIQ, V82, P803, DOI 10.1002/jemt.23224
   Tharwat A., 2019, NEURAL COMPUT APPL, P1
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
NR 33
TC 14
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13513
EP 13534
DI 10.1007/s11042-020-10423-5
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776200005
DA 2024-07-18
ER

PT J
AU Evangelou, I
   Savelonas, M
   Papaioannou, G
AF Evangelou, Iordanis
   Savelonas, Michalis
   Papaioannou, Georgios
TI PU learning-based recognition of structural elements in architectural
   floor plans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image analysis; PU learning; Architectural floor plans
ID AUTOMATIC-ANALYSIS
AB This work introduces a computational method for the recognition of structural elements in architectural floor plans. The proposed method requires minimal user interaction and is capable of effectively analysing floor plans in order to identify different types of structural elements in various notation styles. It employs feature extraction based on Haar kernels and PU learning, in order to retrieve image regions, which are similar to a user-defined query. Most importantly, apart from this user-defined query, the proposed method is not dependent on learning from labelled samples. Therefore, there is no need for laborious annotations to form large datasets in various notation styles. The experimental evaluation has been performed on a publicly available and diverse dataset of floor plans. The results show that the proposed method outperforms a state-of-the-art method, with respect to retrieval accuracy. Further experiments on additional floor plans of various notation styles, demonstrate its general applicability.
C1 [Evangelou, Iordanis; Papaioannou, Georgios] Athens Univ Econ & Business, Dept Informat, Athens, Greece.
   [Savelonas, Michalis] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
C3 Athens University of Economics & Business
RP Savelonas, M (corresponding author), Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM iordanise@aueb.gr; msavelonas@uth.gr; gepap@aueb.gr
RI Papaioannou, Georgios/AAH-9642-2021
OI Papaioannou, Georgios/0000-0003-4774-0746
CR Ahmed S, 2011, PROC INT CONF DOC, P864, DOI 10.1109/ICDAR.2011.177
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bekker J, 2020, MACH LEARN, V109, P719, DOI 10.1007/s10994-020-05877-5
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Bradski G, 2000, DR DOBBS J, V25, P120
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cherneff J., 1992, Res. Eng. Des., V3, P195
   Claesen M, 2015, NEUROCOMPUTING, V160, P73, DOI 10.1016/j.neucom.2014.10.081
   de las Heras LP, 2014, INT J DOC ANAL RECOG, V17, P221, DOI 10.1007/s10032-013-0215-2
   Delalandre M, 2010, INT J DOC ANAL RECOG, V13, P187, DOI 10.1007/s10032-010-0120-x
   Dodge S, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P358, DOI 10.23919/MVA.2017.7986875
   Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901
   Gerstweiler G, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6040101
   Kalervo A, 2019, LECT NOTES COMPUT SC, V11482, P28, DOI 10.1007/978-3-030-20205-7_3
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu T, 2007, INT J DOC ANAL RECOG, V9, P31, DOI 10.1007/s10032-006-0029-6
   Mace S., 2010, P 9 IAPR INT WORKSH, P167, DOI 10.1145/1815330.1815352
   Mewada HK, 2020, INT J DOC ANAL RECOG, V23, P253, DOI 10.1007/s10032-020-00357-x
   Mordelet F, 2014, PATTERN RECOGN LETT, V37, P201, DOI 10.1016/j.patrec.2013.06.010
   Or Siu-Hang., 2005, Proc. of Vision, Modeling, P25
   Ryall K., 1995, P 3 INT C DOC AN REC, V2, P964, DOI [10.1109/ICDAR.1995.602062, DOI 10.1109/ICDAR.1995.602062]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Toussaint G., 1983, SOLVING GEOMETRIC PR
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Weber M., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P289, DOI 10.1109/ICFHR.2010.122
   WESSEL R, 2008, P ICFHR, DOI DOI 10.1109/ICFHR.2010.122
   Xingyu Guo, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1720, DOI 10.1109/CompComm.2018.8780679
   Yamada T, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL JOINT WORKSHOP ON MULTIMEDIA ARTWORKS ANALYSIS AND ATTRACTIVENESS COMPUTING IN MULTIMEDIA (MMART&ACM'18), P1, DOI 10.1145/3209693.3209700
   Zeng ZL, 2019, IEEE I CONF COMP VIS, P9095, DOI 10.1109/ICCV.2019.00919
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Ziran Z, 2018, LECT NOTES ARTIF INT, V11081, P383, DOI 10.1007/978-3-319-99978-4_30
NR 35
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13235
EP 13252
DI 10.1007/s11042-020-10295-9
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300009
DA 2024-07-18
ER

PT J
AU Wang, XY
   Lin, SJ
   Li, Y
AF Wang, Xingyuan
   Lin, Shujuan
   Li, Yong
TI Bit-level image encryption algorithm based on BP neural network and gray
   code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BP neural network; Gray code; Hyperchaotic Lorentz system; Bit-level;
   Image encryption
ID SEMI-TENSOR PRODUCT; CHAOTIC SYSTEM; SCHEME; PERMUTATION
AB In recent years, people have put forward various image encryption algorithms based on pixel level. In fact, bit level encryption has better effect than pixel level encryption. Therefore, this paper proposes a new bit-level image encryption algorithm based on Back Propagation (BP) neural network and Gray code. Firstly, the plaintext image is conversioned into binary image, then, the hyperchaotic Lorentz system is used to generate two sets of chaotic sequences for the Gray code bit-level permutation operation to generate the permutation matrix. Secondly, the permutation matrix is converted into a bit matrix reverse order output to generate a diffusion matrix. Finally, the algorithm uses a BP neural network composed of Logistic map and Piece-Wise Linear Chaotic (PWLCM) map to generate a key stream. The key stream is xored with the diffusion matrix to generate a ciphertext matrix. The experimental results show that the algorithm improves the encryption efficiency, has good security and can resist common attack methods.
C1 [Wang, Xingyuan; Lin, Shujuan; Li, Yong] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 2450274321@qq.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR Ahmad M, 2018, J INTELL FUZZY SYST, V34, P1323, DOI 10.3233/JIFS-169428
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Gao H, 2019, COMPUT OPT, V43, P258, DOI 10.18287/2412-6179-2019-43-2-258-263
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Lv XP, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501245
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Ratnavelu K, 2017, SIGNAL PROCESS, V140, P87, DOI 10.1016/j.sigpro.2017.05.002
   Sokouti M, 2018, COMPUT SCI REV, V29, P14, DOI 10.1016/j.cosrev.2018.05.002
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang XY, 2007, ACTA PHYS SIN-CH ED, V56, P5136, DOI 10.7498/aps.56.5136
   Wang XY, 2019, CHINESE PHYS B, V28, DOI 10.1088/1674-1056/28/4/040504
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2019, OPT LASER ENG, V122, P225, DOI 10.1016/j.optlaseng.2019.04.005
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wei TD, 2019, NEURAL NETWORKS, V116, P35, DOI 10.1016/j.neunet.2019.03.016
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
   Zhang XP, 2018, CHINESE PHYS B, V27, DOI 10.1088/1674-1056/27/8/080701
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 37
TC 20
Z9 21
U1 3
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11655
EP 11670
DI 10.1007/s11042-020-10202-2
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700014
DA 2024-07-18
ER

PT J
AU Wang, ZY
AF Wang, Zhiyang
TI An algorithm for ATM recognition of spliced money based on image
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spliced money; Left and right numbers; One-dimensional gray scale
   projection; Image processing; Template matching; Transparent tape; ATM;
   RGB components
AB According to the problem of spliced money in ATM (Automatic Teller Machine), the paper puts forward a template matching algorithm for recognition of left and right numbers based on one-dimensional gray scale projection. First it uses the Canny boundary detection algorithm to separate the banknote boundary from the R component image, and then preprocesses the image to make the subsequent processing easier; secondly applies the predefined location to divide the area of left and right numbers; thirdly calculates the one-dimensional gray scale projection curves of left and right numbers, based on which every character or number is divided; finally carries out the operation of template matching to obtain correlation coefficients of every character or number, comparing which with threshold it judges whether the left and right numbers are matched. For the transparent tape attached to the spliced money, a method based on the difference in object reflectivity to recognize the tape is designed. First it highlights the characteristics of the tape by preprocessing and binary morphological analysis of the B component image. Finally, it judges whether there is transparent tape on the surface of the banknote according to the set threshold value. Experimental results show that both number matching and tape detection can be completed, and algorithm can correctly recognize spliced money. The correct recognition rate of the algorithm reaches 100%, and the false positive rate?false negative rate are both 0. The processing is fast and simple, which meets the requirements of ATM.
C1 [Wang, Zhiyang] Anhui Vocat Coll Elect & Informat Technol, Dept Elect Engn, Bengbu 233030, Anhui, Peoples R China.
RP Wang, ZY (corresponding author), Anhui Vocat Coll Elect & Informat Technol, Dept Elect Engn, Bengbu 233030, Anhui, Peoples R China.
EM 181566286@qq.com
RI Wang, Zhiyang/L-7659-2019
OI Wang, Zhiyang/0000-0003-2836-4060; Wang, bengzhu/0000-0002-7721-5056
FU Department of Education of Anhui Province (China); Anhui Vocational
   College of Electronics & Information technology
FX This work was supported by Department of Education of Anhui Province
   (China) and Anhui Vocational College of Electronics & Information
   technology.
CR [Anonymous], 2020, J CONSUM BEHAV, DOI [10.1186/s12931-019-1261-1, DOI 10.1002/cb.1844]
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ben Salah M, 2011, IEEE T IMAGE PROCESS, V20, P545, DOI 10.1109/TIP.2010.2066982
   CHEN Y, 2020, WIREL COMMUN MOB COM, V6, P1
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chen Z, 2016, OPT LASER TECHNOL, V80, P1, DOI 10.1016/j.optlastec.2015.12.013
   Ein-shoka AA, 2018, OPTIK, V160, P146, DOI 10.1016/j.ijleo.2017.12.056
   Geng YN, 2012, APPL OPTICS, V51, P3538, DOI 10.1364/AO.51.003538
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Joanna IO, 2013, P COMP AN IM PATT WO
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   [李代万 Li Daiwan], 2002, [北方交通大学学报, Journal of Northern Jiaotong University], V26, P80
   Li Y, 2019, COMPUTER DIGITAL ENG, V22, P428
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   [刘承香 LIU Cheng-xiang], 2009, [激光与红外, Laser and Infrared], V39, P685
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mao G, 2017, J GEOM, V35, P62
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Ren Q, 2017, CHINA STRATEGIC EMER, V40, P118
   Wan MJ, 2018, INFRARED PHYS TECHN, V91, P164, DOI 10.1016/j.infrared.2018.04.003
   Wang H., 2018, ACTA ELECT SINICA, V46, P2588
   Wang J, 2019, MATH BIOSCI ENG, V16, P5851, DOI 10.3934/mbe.2019292
   Yang S, 2019, ELECT ENG PRODUCT WO, V20, P64
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Ziemer J, 2019, IEEE GLOB HUMANIT C, P9, DOI 10.1109/ghtc46095.2019.9033089
NR 35
TC 1
Z9 1
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11471
EP 11489
DI 10.1007/s11042-020-10348-z
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700010
DA 2024-07-18
ER

PT J
AU Hematpour, N
   Ahadpour, S
   Behnia, S
AF Hematpour, Nafiseh
   Ahadpour, Sodeif
   Behnia, Sohrab
TI Presence of dynamics of quantum dots in the digital signature using DNA
   alphabet and chaotic S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum digital signature; Quantum dots; Chaos; DNA coding; Substitution
   box(S-box); Repudiation; Forgery
ID MAPS; HIERARCHY; ALGORITHM; DESIGN
AB The integrity and authenticity of the message, and it's nonrepudiation, are provided by digital signatures. We introduce quantum digital signature schemes based on Quantum Dots, where DNA coding is used to increase the intricacy of phase space. We attain the optimal security standard by constructing a deterministic dynamic system in a finite phase space with n points and by using symbolic dynamics. Also, given the chaotic Substitution box(S-box), a confusing step has been added for greater security. The introduced quantum dynamical map is used to create procedures to resistance again the common attacks in the digital signature such as non-repudiation, unforgeability, and transferability. Its security depends on the length of the signature, directly.
C1 [Hematpour, Nafiseh; Ahadpour, Sodeif] Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
   [Behnia, Sohrab] Urmia Univ Technol, Dept Phys Urmia, Orumiyeh, Iran.
C3 University of Mohaghegh Ardabili; Urmia University of Technology
RP Ahadpour, S (corresponding author), Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
EM n_hematpour@uma.ac.ir; ahadpour@uma.ac.ir
OI Hematpour, Nafiaeh/0000-0002-0651-6564; Ahadpour,
   Sodeif/0000-0002-0474-4678
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Advanced encryption standard (aes), 2001, FED INF PROC STAND I
   Ahadpour S, 2012, ARXIV12075590V1
   Akhshani A, 2010, INT J MOD PHYS C, V21, P275, DOI 10.1142/S0129183110015117
   AMIN ST, 2006, COMPUTATIONAL INTELL, P116
   Andersson E, 2006, PHYS REV A, V74, DOI 10.1103/PhysRevA.74.022304
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Behnia S, 2017, PHYS LETT A, V381, P36, DOI 10.1016/j.physleta.2016.10.037
   Behnia S, 2014, APPL SOFT COMPUT, V21, P481, DOI 10.1016/j.asoc.2014.03.022
   Behnia S, 2011, J COMPUT APPL MATH, V235, P3455, DOI 10.1016/j.cam.2011.02.006
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   BORDA M.E., 2009, Acta Technica Napocensis-Electronica-Telecomunicatii (Electronics and Telecommunications), V1, P21
   Castagnino M, 2009, PHYSICA A, V388, P247, DOI 10.1016/j.physa.2008.10.019
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chang WL, 2011, J SUPERCOMPUT, V56, P129, DOI 10.1007/s11227-009-0347-9
   Chen FL, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-017-1778-5
   CHEN JJ, 2020, QUANTUM INF PROCESS, V19
   Chen WW, 2017, J GERIATR CARDIOL, V14, P1, DOI 10.11909/j.issn.1671-5411.2017.01.012
   Chen XB, 2014, QUANTUM INF COMPUT, V14, P589
   Clarke PJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2172
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Collins RJ, 2016, OPT LETT, V41, P4883, DOI 10.1364/OL.41.004883
   Cusick TW, 2017, CRYPTOGRAPHIC BOOLEAN FUNCTIONS AND APPLICATIONS, 2ND EDITION, P1
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Donaldson RJ, 2016, PHYS REV A, V93, DOI 10.1103/PhysRevA.93.012329
   Dunjko V, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.040502
   Emary C, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.066203
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gehani A., 2000, DNA Based Computers V. DIMACS Workshop (Series in Discrete Mathematics and Theoretical Computer Science Vol.54), P233
   Gholamin P, 2017, CHINESE J PHYS, V55, P1300, DOI 10.1016/j.cjph.2017.07.002
   Gottesman D., 2001, Quantum digital signatures
   Harrison P., 2016, Quantum Wells, Wires and Dots
   Heider D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-176
   Hematpour N, 2018, DIGITAL SIGNATURE QU
   Hernandez-Ardieta JL, 2013, COMPUT SECUR, V34, P67, DOI 10.1016/j.cose.2012.11.009
   Herranz J, 2009, INFORM SCIENCES, V179, P1647, DOI 10.1016/j.ins.2009.01.023
   Hirsch JG, 2012, AIP CONF PROC, V1424, DOI 10.1063/1.3688964
   HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Jafarizadeh MA, 2006, PRAMANA-J PHYS, V67, P1073, DOI 10.1007/s12043-006-0024-y
   Jafarizadeh MA, 2001, J STAT PHYS, V104, P1013, DOI 10.1023/A:1010449627146
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kneifel JD, 1999, FIPS PUB, P46
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Li J, 2015, IEEE COMMUN LETT, V19, P115, DOI 10.1109/LCOMM.2014.2379253
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Lou XP, 2020, IEEE ACCESS, V8, P13218, DOI 10.1109/ACCESS.2020.2966255
   Lou XP, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2014-7
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Rauhe H., 2000, P 6 DIMACS WORKSH DN, P13
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Sinha A, 2003, OPT COMMUN, V218, P229, DOI 10.1016/S0030-4018(03)01261-6
   Strogatz SH, 2000, NONLINEAR DYNAMICS C, P478
   Sun Y, 2011, J SYST SOFTWARE, V84, P1471, DOI 10.1016/j.jss.2011.02.041
   Vaudenay S, 2006, CLASSICAL INTRO CRYP, P260
   Wallden P, 2015, PHYS REV A, V91, DOI 10.1103/PhysRevA.91.042304
   Wallden P, 2014, J PHYS A-MATH THEOR, V47, DOI 10.1088/1751-8113/47/12/125303
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wei ZH, 2015, INT J THEOR PHYS, V54, P2505, DOI 10.1007/s10773-014-2478-x
   Yin HL, 2017, PHYS REV A, V95, DOI 10.1103/PhysRevA.95.032334
   Yin HL, 2016, PHYS REV A, V93, DOI 10.1103/PhysRevA.93.032316
   Zhang HG, 2010, IEEE T SYST MAN CY B, V40, P831, DOI 10.1109/TSMCB.2009.2030506
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
   2011, STUD COMPUT INTELL, V354, P1
NR 72
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10509
EP 10531
DI 10.1007/s11042-020-10059-5
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591969200001
DA 2024-07-18
ER

PT J
AU Jain, V
   Phophalia, A
AF Jain, Vikas
   Phophalia, Ashish
TI M-ary Random Forest-A new multidimensional partitioning approach to
   Random Forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Decision tree; Ensemble method; Machine learning; Random
   Forest; Regression
AB Random Forest (RF) is composed of decision trees as base classifiers. In general, a decision tree recursively partitions the feature space into two disjoint subspaces using a single feature as axis-parallel splits for each internal node. The oblique decision tree uses a linear combination of features (to form a hyperplane) to partition the feature space in two subspaces. The later approach is an NP-hard problem to compute the best-suited hyperplane. In this work, we propose to use multiple features at a node for splitting the data as in axis parallel method. Each feature independently divides into two subspaces and this process is done by multiple features at one node. Hence, the given space is divided into multiple subspaces simultaneously, and in turn, to construct the M-ary trees. Hence, the forest formed is named as M-ary Random Forest (MaRF). To measure the performance of the task in MaRF, we have extended the notion of tree strength of the regression tree. We empirically prove that the performance of the MaRF improves due to the improvement in the strength of the M-ary trees. We have shown the performance to wide range of datasets ranging from UCI datasets, Hyperspectral dataset, MNIST dataset, Caltech 101 and Caltech 256 datasets. The efficiency of the MaRF approach is found satisfactory as compared to state-of-the-art methods.
C1 [Jain, Vikas; Phophalia, Ashish] Indian Inst Informat Technol, Vadodara 382028, Gujarat, India.
RP Jain, V (corresponding author), Indian Inst Informat Technol, Vadodara 382028, Gujarat, India.
EM 201671001@iiitvadodara.ac.in; ashish_p@iiitvadodara.ac.in
RI Jain, Vikas/AAO-2353-2021
OI Jain, Vikas/0000-0002-6382-5814
CR Akash PS, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P611, DOI [10.1109/ICREST.2019.8644396, 10.1109/icrest.2019.8644396]
   Amaratunga D, 2008, BIOINFORMATICS, V24, P2010, DOI 10.1093/bioinformatics/btn356
   [Anonymous], 2005, Signal theory methods in multispectral remote sensing
   Asuncion A., 2007, Uci machine learning repository
   Balyan M, 2019, CURR PRACT OPHTHALM, P161, DOI 10.1007/978-981-13-7673-3_12
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Biau G, 2008, J MACH LEARN RES, V9, P2015
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Denil M., 2014, PR MACH LEARN RES, P665
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Griffin G., 2007, CALTECH 256 OBJECT C
   He Z, 2016, SIGNAL PROCESS, V120, P209, DOI 10.1016/j.sigpro.2015.09.004
   Ishwaran Hemant, 2015, Mach Learn, V99, P75, DOI 10.1007/s10994-014-5451-2
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Louppe G., 2014, Ph.D. thesis
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Menze BH, 2011, LECT NOTES ARTIF INT, V6912, P453, DOI 10.1007/978-3-642-23783-6_29
   Mishina Y, 2015, IEICE T INF SYST, VE98D, P1630, DOI 10.1587/transinf.2014OPP0004
   Murthy SK, 1994, J ARTIF INTELL RES, V2, P1, DOI 10.1613/jair.63
   Paul A.K., 2016, P 2016 IEEE CAN C EL, P1
   Paul A, 2019, PATTERN RECOGN, V94, P13, DOI 10.1016/j.patcog.2019.05.013
   Paul A, 2018, IEEE T IMAGE PROCESS, V27, P4012, DOI 10.1109/TIP.2018.2834830
   Satish P, 2014, IEEE ICST WORKSHOP, P88, DOI 10.1109/ICSTW.2014.11
   Wang L, 2016, HYPERSPECTRAL IMAGE PROCESSING, P1, DOI 10.1007/978-3-662-47456-3
   Wickramarachchi DC, 2016, COMPUT STAT DATA AN, V96, P12, DOI 10.1016/j.csda.2015.11.006
   Winham SJ, 2013, STAT ANAL DATA MIN, V6, P496, DOI 10.1002/sam.11196
   Yang J, 2007, LECT NOTES COMPUT SC, V4663, P197
   Zhang L, 2015, IEEE T CYBERNETICS, V45, P2165, DOI 10.1109/TCYB.2014.2366468
   Zhang YQ, 2018, IEEE J-STARS, V11, P1082, DOI 10.1109/JSTARS.2018.2809781
   Zhao YM, 2017, I C NETWORK PROTOCOL, DOI 10.1109/TNNLS.2017.2729778
NR 35
TC 6
Z9 6
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35217
EP 35238
DI 10.1007/s11042-020-10047-9
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000587058000007
DA 2024-07-18
ER

PT J
AU Zhong, YH
   Zhang, J
   Zhou, ZK
   Cheng, XY
   Huang, G
   Li, Q
AF Zhong, Yuanhong
   Zhang, Jing
   Zhou, Zhaokun
   Cheng, Xinyu
   Huang, Guan
   Li, Qiang
TI Recovery of image and video based on compressive sensing via tensor
   approximation and Spatio-temporal correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block-based compressive sensing; Image and video recovery; Low-rank
   tensor approximation; High order singular value decomposition (HOSVD);
   Spatio-temporal correlation
ID SPARSITY
AB In recent years, block-based compressive sensing (BCS) has been extensively studied because it can reduce computational complexity and data storage by dividing the image into smaller patches, but the performance of the reconstruction algorithm is not satisfactory. In this paper, a new reconstruction model for image and video is proposed. The model makes full use of spatio-temporal correlation and utilizes low-rank tensor approximation to improve the quality of the reconstructed image and video. For image recovery, the proposed model obtains a low-rank approximation of a tensor formed by non-local similar patches, and improves the reconstruction quality from a spatial perspective by combining non-local similarity and low-rank property. For video recovery, the reconstruction process is divided into two phases. In the first phase, each frame of the video sequence is regarded as an independent image to be reconstructed by taking advantage of spatial property. The second phase performs tensor approximation through searching similar patches within frames near the target frame, to achieve reconstruction by putting the spatio-temporal correlation into full play. The resulting model is solved by an efficient Alternating Direction Method of Multipliers (ADMM) algorithm. A series of experiments show that the quality of the proposed model is comparable to the current state-of-the-art recovery methods.
C1 [Zhong, Yuanhong; Zhang, Jing; Cheng, Xinyu] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing, Peoples R China.
   [Zhou, Zhaokun; Huang, Guan] Chongqing Univ, Chongqing Automot Collaborat Innovat Ctr, Chongqing, Peoples R China.
   [Li, Qiang] State Power Investment Corp, Tibet Branch, Chongqing, Peoples R China.
C3 Chongqing University; Chongqing University; State Power Investment
   Corporation
RP Zhong, YH (corresponding author), Chongqing Univ, Sch Microelect & Commun Engn, Chongqing, Peoples R China.
EM zhongyh@cqu.edu.cn; zhangj_cqu@163.com; zkzhoufust@gmail.com;
   xinyu_ch@163.com; hgcqu6698@gmial.com; 15446640@163.com
RI ZHANG, JING/HKF-4837-2023; Zhou, zhaokun/JFA-9413-2023; Yuan,
   Fang/JQV-7426-2023
OI ZHANG, JING/0000-0001-6595-7661; Zhong, Yuanhong/0000-0001-5689-1146
FU National Natural Science Foundation [61501069]; Technology Innovation
   and Application Development Project of Chongqing
   [cstc2019jscx-msxmX0167]
FX This work was supported by National Natural Science Foundation
   (No.61501069) and by Technology Innovation and Application Development
   Project of Chongqing (cstc2019jscx-msxmX0167).
CR Asif MS, 2013, IEEE T SIGNAL PROCES, V61, P5905, DOI 10.1109/TSP.2013.2279362
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eftekhari A, 2015, APPL COMPUT HARMON A, V39, P67, DOI 10.1016/j.acha.2014.08.005
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Hegde C., 2008, Advances in Neural Information Processing Systems (Vancouver 2006), P641
   Hegde C, 2012, IEEE T INFORM THEORY, V58, P7204, DOI 10.1109/TIT.2012.2210860
   Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1
   Lingala SG, 2011, IEEE T MED IMAGING, V30, P1042, DOI 10.1109/TMI.2010.2100850
   Lu HY, 2018, NEUROCOMPUTING, V303, P88, DOI 10.1016/j.neucom.2018.04.046
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Mun S, 2010, IEEE DATA COMPR CONF, P547, DOI 10.1109/DCC.2010.90
   Palangi H, 2016, IEEE T SIGNAL PROCES, V64, P4504, DOI 10.1109/TSP.2016.2557301
   Shi WZ, 2019, PROC CVPR IEEE, P12282, DOI 10.1109/CVPR.2019.01257
   Siddamal KV, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P639, DOI 10.1109/ECS.2015.7124986
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Van Veen D., 2018, COMPRESSED SENSING D
   Xu J, 2012, SIGNAL PROCESS, V92, P2614, DOI 10.1016/j.sigpro.2012.04.001
   Zhang J, 2020, IEEE J-STSP, V14, P765, DOI 10.1109/JSTSP.2020.2977507
   Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang J, 2012, IEEE J EM SEL TOP C, V2, P380, DOI 10.1109/JETCAS.2012.2220391
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhao C., 2016, ORYX, V1, P1
   Zhao C, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P402, DOI 10.1109/VCIP.2014.7051591
NR 34
TC 0
Z9 1
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7433
EP 7450
DI 10.1007/s11042-020-09907-1
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400003
DA 2024-07-18
ER

PT J
AU Nguyen, H
   Nguyen, T
   Nguyen, DT
AF Nguyen, Hung
   Nguyen, Thin
   Nguyen, Duc Thanh
TI A graph-based approach for population health analysis using Geo-tagged
   tweets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graphs; Large-scale computing; Health on the web; Population health;
   Geo-tagged tweets
ID SOCIAL MEDIA; CENTRALITY
AB We propose in this work a graph-based approach for automatic public health analysis using social media. In our approach, graphs are created to model the interactions between features and between tweets in social media. We investigated different graph properties and methods in constructing graph-based representations for population health analysis. The proposed approach is applied in two case studies: (1) estimating health indices, and (2) classifying health situation of counties in the US. We evaluate our approach on a dataset including more than one billion tweets collected in three years 2014, 2015, and 2016, and the health surveys from the Behavioral Risk Factor Surveillance System. We conducted realistic and large-scale experiments on various textual features and graph-based representations. Experimental results verified the robustness of the proposed approach and its superiority over existing ones in both case studies, confirming the potential of graph-based approach for modeling interactions in social networks for population health analysis.
C1 [Nguyen, Hung] Nha Trang Univ, Fac IT, Nha Trang, Vietnam.
   [Nguyen, Thin] Deakin Univ, Appl Artificial Intelligence Inst, Geelong, Vic 3220, Australia.
   [Nguyen, Duc Thanh] Deakin Univ, Sch Informat Technol, Geelong, Vic 3220, Australia.
C3 Nha Trang University; Deakin University; Deakin University
RP Nguyen, DT (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3220, Australia.
EM hungnd@ntu.edu.vn; thin.nguyen@deakin.edu.au; duc.nguyen@deakin.edu.au
RI Nguyen, Thin/IXD-7832-2023
OI Nguyen, Thin/0000-0003-3467-8963
CR Aiello AE, 2020, ANNU REV PUBL HEALTH, V41, P101, DOI 10.1146/annurev-publhealth-040119-094402
   Akbari M, 2018, P INT C WEB SOC MED, P552
   Allington D, 2021, PSYCHOL MED, V51, P1763, DOI [10.1017/S003329172000224X, 10.1017/S0033291721000593]
   [Anonymous], 2012, Proceedings of the Sixth International AAAI Conference on Weblogs and Social Media
   Bai H, 2015, 2015 IEEE 6 INT S PO, P1
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Bekalu MA, 2019, HEALTH EDUC BEHAV, V46, P69, DOI 10.1177/1090198119863768
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borgwardt KM, 2007, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2007, P4
   Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132
   Brandes U, 2008, SOC NETWORKS, V30, P136, DOI 10.1016/j.socnet.2007.11.001
   Brownstein JS, 2010, NEW ENGL J MED, V362, P1731, DOI 10.1056/NEJMsr1002707
   Cheng B, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P4584, DOI 10.1109/WCICA.2010.5554118
   Chun H, 2008, IMC'08: PROCEEDINGS OF THE 2008 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P57
   Conway Mike, 2019, Yearb Med Inform, V28, P208, DOI 10.1055/s-0039-1677918
   Culotta A., 2010, Proceedings of the first workshop on social media analytics, P115, DOI [DOI 10.1145/1964858.1964874, 10.1145/1964858.1964874]
   Culotta A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1335, DOI 10.1145/2556288.2557139
   De Choudhury M, 2013, INT CONF PER COMP, P41, DOI 10.4108/icst.pervasivehealth.2013.252106
   Dittrich J, 2012, PROC VLDB ENDOW, V5, P2014, DOI 10.14778/2367502.2367562
   Dredze M, 2012, IEEE INTELL SYST, V27, P81, DOI 10.1109/MIS.2012.76
   Farhadloo M, 2018, JMIR PUBLIC HLTH SUR, V4, P57, DOI 10.2196/publichealth.8186
   França U, 2016, COMPLEXITY, V21, P280, DOI 10.1002/cplx.21687
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gibbons J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219550
   Ginsberg J, 2009, NATURE, V457, P1012, DOI 10.1038/nature07634
   Giorgi P, 2018, ISSAC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND ALGEBRAIC COMPUTATION, P167, DOI 10.1145/3208976.3208991
   Gittelman S, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3970
   HOUSE JS, 1988, SCIENCE, V241, P540, DOI 10.1037/0003-066X.59.8.676
   Nguyen H, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103277
   Jang K, 2019, HEALTH COMMUN, V34, P991, DOI 10.1080/10410236.2018.1449552
   Kershaw Daniel., 2014, Proc. of WebSci'14, P220, DOI DOI 10.1145/2615569.2615678
   Kingma D. P., 2014, arXiv
   Leskovec J., 2008, P 17 INT C WORLD WID, DOI 10.1145/1367497.1367620
   Merchant RM, 2020, JAMA-J AM MED ASSOC, V323, P2011, DOI 10.1001/jama.2020.4469
   Merchant RM, 2020, JAMA-J AM MED ASSOC, V323, P411, DOI 10.1001/jama.2019.21084
   Müller MM, 2019, FRONT PUBLIC HEALTH, V7, DOI 10.3389/fpubh.2019.00081
   Myers J. L., 2010, RES DESIGN STAT ANAL
   Opsahl T, 2010, SOC NETWORKS, V32, P245, DOI 10.1016/j.socnet.2010.03.006
   Page L., 1999, PAGERANK CITATION RA
   Pagoto S, 2019, J MED INTERNET RES, V21, DOI 10.2196/16661
   Parker J, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P562
   Parrish RG, 2010, PREV CHRONIC DIS, V7
   Paul Michael J., 2011, P 5 INT AAAI C WEBL, P265
   Pennebaker J. W., 2015, LINGUISTIC INQUIRY A
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Rozenblum R, 2013, BMJ QUAL SAF, V22, P183, DOI 10.1136/bmjqs-2012-001744
   Salathé M, 2013, NEW ENGL J MED, V369, P401, DOI 10.1056/NEJMp1307752
   Schwartz Hansen Andrew, 2013, P INT AAAI C WEB SOC, P583
   Sedgwick R, 2019, CURR OPIN PSYCHIATR, V32, P534, DOI 10.1097/YCO.0000000000000547
   Shervashidze N, 2011, J MACH LEARN RES, V12, P2539
   Doan T, 2019, INT SYMP ELECTR ELEC, P63, DOI [10.1109/ISEE2.2019.8921365, 10.1109/isee2.2019.8921365]
   Nguyen T, 2020, FUTURE GENER COMP SY, V110, P620, DOI 10.1016/j.future.2018.01.014
   Nguyen T, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P99, DOI 10.1145/3041021.3054136
   Wilson C, 2009, EUROSYS'09: PROCEEDINGS OF THE FOURTH EUROSYS CONFERENCE, P205
   Wu SQ, 2013, BMC PUBLIC HEALTH, V13, DOI [10.1186/1471-2458-13-636, 10.1186/1471-2458-13-320]
   Zaharia Zaharia M. M., Login: The Usenix Magazine, V37 37, P45
   Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438
NR 57
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7187
EP 7204
DI 10.1007/s11042-020-10034-0
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583943700002
PM 33132740
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mahabadi, A
   Hosseini, M
AF Mahabadi, Aminollah
   Hosseini, Mohammad
TI SLPA-based parallel overlapping community detection approach in large
   complex social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Overlapping community detection; Large and complex social networks;
   Parallel processing; Speaker-listener push-pull propagation approach
   (SL3PA); Speaker-listener propagation approach (SLPA); Speaker-listener
   push-pull propagation algorithm (SL3PA degrees); Speaker-listener
   propagation algorithm (SLPA degrees)
ID LABEL PROPAGATION ALGORITHM
AB Performance improvement of community detection is anNPproblem in large social networks analysis where by integrating the overlapped communities' information and modularity maximization increases the time complexity and memory usage. This paper presents an online parallel overlapping community detection approach based on a speaker-listener propagation algorithm by proposing a novel parallel algorithm and applying three new metrics. This approach is presented to improve modularity and expand scalability for getting a significantly speedup in low time-consuming and usage memory through an agent-based parallel implementation in a multi-core architecture. The key ideas of our approach are increasing the communities' conductance score, limiting the speaking-listening stages and executing a strategic updating order to develop a speaker-listeners label propagation algorithm for getting better speedup and semi-deterministic results without using prior training or requiring particular predefined features. Experimental results of used large datasets compared with state-of-the-art algorithms show that the proposed method is extremely convergence and achieves an average 820% speedup in the label propagation algorithm, and significantly improves the modularity that are effective in finding better overlapping communities in a linear time complexityO(m) and lower usage memoryO(n).
C1 [Mahabadi, Aminollah; Hosseini, Mohammad] Shahed Univ, Comp Engn Dept, Tehran, Iran.
   [Mahabadi, Aminollah] Shahed Univ, Acoust Res Ctr, Tehran, Iran.
C3 Shahed University; Shahed University
RP Mahabadi, A (corresponding author), Shahed Univ, Comp Engn Dept, Tehran, Iran.; Mahabadi, A (corresponding author), Shahed Univ, Acoust Res Ctr, Tehran, Iran.
EM mahabadi@shahed.ac.ir
CR [Anonymous], ARXIV12020425
   [Anonymous], 2008, P 1 INT WORKSH MULT, DOI [10.1145/1370082.1370085, DOI 10.1145/1370082.1370085]
   Attal JP, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4355
   Banerjee S, 2019, EXPERT SYST APPL, V125, P1, DOI 10.1016/j.eswa.2019.01.070
   Barber MJ, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026129
   Bastami E, 2019, SWARM EVOL COMPUT, V44, P176, DOI 10.1016/j.swevo.2018.03.001
   Baumes J, 2005, LECT NOTES COMPUT SC, V3495, P27
   Berahmand K, 2018, INT J MOD PHYS B, V32, DOI 10.1142/S0217979218500625
   Chakraborty T, 2019, KNOWL-BASED SYST, V163, P241, DOI 10.1016/j.knosys.2018.08.033
   Ebrahimi M, 2018, PHYSICA A, V505, P825, DOI 10.1016/j.physa.2018.03.033
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fayyad U, 1996, AI MAG, V17, P37
   Garza SE, 2019, PHYSICA A, V534, DOI 10.1016/j.physa.2019.122058
   Geng WJ, 2012, THIRD CONFERENCE ON HORTICULTURE SCIENCE AND TECHNOLOGY (CHST 2012), P254
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Javed MA, 2018, J NETW COMPUT APPL, V108, P87, DOI 10.1016/j.jnca.2018.02.011
   Jin D, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3373760
   Kouni IB, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2019.113020
   Kuzmin K, 2015, SCI PROGRAMMING-NETH, V2015, DOI 10.1155/2015/461362
   Kuzmin K, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P204, DOI 10.1109/SocialCom.2013.37
   Lancichinetti A, 2009, NEW J PHYS, V11, DOI 10.1088/1367-2630/11/3/033015
   Leskovec J., 2014, SNAP Datasets: Stanford large network dataset collection
   Li XM, 2020, WIREL NETW, V26, P5503, DOI 10.1007/s11276-019-01938-3
   Liu W, 2016, SCI REP-UK, V6, DOI 10.1038/srep22470
   Liu X, 2010, PHYSICA A, V389, P1493, DOI 10.1016/j.physa.2009.12.019
   Mellado JP, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/8/085010
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Nicosia V, 2009, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2009/03/P03024
   Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607
   Qiao YC, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P439, DOI 10.1109/ICCCBDA.2017.7951954
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Riedy EJ, 2012, LECT NOTES COMPUT SC, V7203, P286, DOI 10.1007/978-3-642-31464-3_29
   Souravlas S, 2019, IEEE ACCESS, V7, P20499, DOI 10.1109/ACCESS.2019.2897783
   Tasgin M, 2019, PHYSICA A, V513, P315, DOI 10.1016/j.physa.2018.09.044
   Thakur K, 2019, IT PROF, V21, P41, DOI 10.1109/MITP.2018.2881373
   Whang JJ, 2016, IEEE T KNOWL DATA EN, V28, P1272, DOI 10.1109/TKDE.2016.2518687
   Xu XW, 1999, DATA MIN KNOWL DISC, V3, P263, DOI 10.1023/A:1009884809343
   Yamaguchi Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3224
   Yan J, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P272, DOI 10.1145/3301551.3301611
   Zhang XK, 2017, PHYS LETT A, V381, P2691, DOI 10.1016/j.physleta.2017.06.018
   Zhang YZ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P997
NR 41
TC 7
Z9 7
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6567
EP 6598
DI 10.1007/s11042-020-09993-1
EA OCT 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000578977800003
OA Bronze
DA 2024-07-18
ER

PT J
AU Xu, JF
   Sun, ZX
   Ma, C
AF Xu, Junfeng
   Sun, Zhengxing
   Ma, Chen
TI Crowd aware summarization of surveillance videos by deep reinforcement
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance video summarization; Crowd behaviors; Deep reinforcement
   learning; Unsupervised video summarization
ID OPTIMIZATION; SELECTION
AB Surveillance videos which record crowd behaviors have dramatically increased due to the wide applications. A quick view of such crowd surveillance video in a constrained time is an increasing demand because it always contain a huge number of redundancy frames. In this paper, we focus on summarization of crowd surveillance videos. But it is not easy due to two reasons. First, how to make the decision to keep or discard a subshot from the input surveillance video stream so that the summary can outline the main behaviors of the crowd over a limited frames sequence. Second, how to maintain performance of summarization model for long surveillance videos. To tackle these challenges, we formulate surveillance video summarization as a sequential decision-making process and train the summarization network with reinforcement learning-based framework. A novel crowd location-density reward is proposed to teach summarization network to produce high-quality summaries. In addition, a summarization network with three layers LSTM is designed to maintain performance across longer time spans. Extensive experiments on three public crowd surveillance videos datasets show that the proposed method achieves state-of-the-art performance.
C1 [Xu, Junfeng; Sun, Zhengxing; Ma, Chen] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
EM njumagic@nju.edu.cn; szx@nju.edu.cn; njumagic@nju.edu.cn
RI Sun, Zhengxing/A-7411-2011
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; Innovation Fund of State Key Laboratory for Novel Software
   Technology [ZZKT2013A12, ZZKT2016A11, ZZKT2018A09]
FX This work was supported by National High Technology Research and
   Development Program of China (No.2007AA01Z334), National Natural Science
   Foundation of China (Nos.61321491 and 61272219), Innovation Fund of
   State Key Laboratory for Novel Software Technology (Nos. ZZKT2013A12,
   ZZKT2016A11 and ZZKT2018A09).
CR [Anonymous], 2002, P 10 ACM INT C MULT
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Berger V.W., 2007, Selection Bias and Covariate Imbalances in Randomized Clinical Trials
   Chao WL, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P191
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong WK, 2019, AAAI CONF ARTIF INTE, P8247
   Feng LT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P976, DOI 10.1145/3240508.3240651
   Ferryman J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P143, DOI 10.1109/AVSS.2010.90
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Gao Z, 2018, MACH VISION APPL, V29, P1101, DOI 10.1007/s00138-018-0954-7
   GONG B, 2014, ADV NEURAL INFORM PR, P2069
   GYGLI M, 2015, PROC CVPR IEEE, P3090, DOI DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2043612.2043613
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Janisch J, 2019, AAAI CONF ARTIF INTE, P3959
   Jay N., 2019, P 36 INT C MACH LEAR, P3050
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kingma D. P., 2014, arXiv
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lei Z, 2019, IEEE INT CON MULTI, P368, DOI 10.1109/ICME.2019.00071
   Li Q, 2016, MULTIMED TOOLS APPL, V75, P17393, DOI 10.1007/s11042-015-3003-9
   Li Y, 2011, CBMI, P163
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Lu GL, 2017, MULTIMED TOOLS APPL, V76, P6309, DOI 10.1007/s11042-016-3263-z
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Lv P, 2018, ABS180806749 CORR
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Pritch Y, 2007, IEEE I CONF COMP VIS, P833
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sindhu V, 2017, PROCEDIA ENGINEER, V184, P1, DOI 10.1016/j.proeng.2017.04.063
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   SONG YL, 2015, PROC CVPR IEEE, P5179, DOI [DOI 10.1109/CVPR.2015.7299154, 10.1109/CVPR.2015.7299154]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   van Seijen Harm, 2017, Advances in Neural Information Processing Systems
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang K, 2018, LECT NOTES COMPUT SC, V11212, P391, DOI 10.1007/978-3-030-01237-3_24
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhao B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P863, DOI 10.1145/3123266.3123328
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhou Kaiyang, 2018, BMVC, P298
NR 53
TC 11
Z9 11
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6121
EP 6141
DI 10.1007/s11042-020-09888-1
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700007
DA 2024-07-18
ER

PT J
AU Hu, ZT
   Qin, XJ
AF Hu, Zhongtian
   Qin, Xujia
TI Extended interactive and procedural modeling method for ancient chinese
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive modeling; Procedural modeling; Ancient chinese architecture;
   Level of detail
ID 'YINGZAO-FASHI'; GENERATION
AB The manual modeling of ancient Chinese architecture is long and tedious work for artists due to the strict and complex construction rules. Existing procedural modeling methods can reduce the modeling workload; however, only limited types of ancient buildings can be made, and users can only edit the building frame and not the components. Therefore, we have improved the existing methods to solve these problems. In addition, we propose an ancient building frame extraction method that can extract a building frame from an existing nonsegmented building mesh, thereby providing users with an editable initial frame. Furthermore, we propose an automatic level of detail (LOD) method; building models made by our method can be automatically simplified without prefabricated low-poly proxies. The experimental results show that our method can be used to model different styles of ancient Chinese architecture. The building frames and components are easy to edit and can allow nonexpert users to construct a target architecture in minutes. The size of the saved file is greatly reduced compared to that of existing methods. Building frame extraction can significantly accelerate the modeling speed and improve the quality of users' work. The proposed LOD method exhibits a higher performance than the existing method based on mesh simplification.
C1 [Hu, Zhongtian; Qin, Xujia] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology
RP Qin, XJ (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM 2111812100@zjut.edu.cn; qxj@zjut.edu.cn
FU National Natural Science Foundation of China [61672462]; Natural Science
   Foundation of Zhejiang province, China [LY20F020025]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61672462) and the Natural Science
   Foundation of Zhejiang province, China (Grant No. LY20F020025)
CR Barroso S, 2013, COMPUT GRAPH-UK, V37, P238, DOI 10.1016/j.cag.2013.01.003
   Bromberg-Martin E, 2004, ACM SIGGRAPH POSTERS, P30
   Chen X, 2008, BUILD ENERGY ENV, V27, P1
   Demir I, 2018, COMPUT GRAPH-UK, V74, P257, DOI 10.1016/j.cag.2018.05.013
   Edelsbrunner J, 2017, COMPUT GRAPH-UK, V64, P14, DOI 10.1016/j.cag.2017.01.004
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gao X, 2018, ISPRS J PHOTOGRAMM, V143, P72, DOI 10.1016/j.isprsjprs.2018.04.023
   Glahn Else., 1984, Chinese Traditional Architecture, P47
   Guo QH, 1998, ARCHIT HIST, V41, P1, DOI 10.2307/1568644
   Hao Liu, 2010, Proceedings Second International Workshop on Education Technology and Computer Science (ETCS 2010), P360, DOI 10.1109/ETCS.2010.205
   Hou F, 2012, IEEE T VIS COMPUT GR, V18, P30, DOI 10.1109/TVCG.2011.22
   Huang C, 2015, INT S SMART GRAPH, P16
   Huang CY, 2013, VISUAL COMPUT, V29, P1303, DOI 10.1007/s00371-012-0771-3
   Huang IT, 2004, ACM T GRAPHIC, V22, P689
   Kelly T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944854
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P27387, DOI 10.1007/s11042-018-5926-4
   Li E, 2014, INT C DIGITAL HOME, P157, DOI 10.1109/ICDH.2014.38
   Li ML, 2016, COMPUT GRAPH-UK, V54, P84, DOI 10.1016/j.cag.2015.07.004
   Li S, 2003, J SOC ARCHIT HIST, V62, P470
   Liu J, 2018, INT J ARCHIT HERIT, V12, P280, DOI 10.1080/15583058.2017.1410253
   Liu J, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2835495
   Liu Y, 2012, COMPUT GRAPH-UK, V36, P178, DOI 10.1016/j.cag.2012.01.003
   Lovset T, 2013, COMPUT GRAPH-UK, V37, P256, DOI 10.1016/j.cag.2013.01.007
   Maekawa T, 2007, COMPUT AIDED DESIGN, V39, P313, DOI 10.1016/j.cad.2006.12.008
   Martin I, 2019, COMPUT GRAPH-UK, V84, P93, DOI 10.1016/j.cag.2019.08.003
   Martinovic A, 2013, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2013.33
   Merrell P, 2011, IEEE T VIS COMPUT GR, V17, P715, DOI 10.1109/TVCG.2010.112
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951
   Pandunata Priza, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P68, DOI 10.1109/CGIV.2010.18
   Qin Xujia, 2002, Journal of Computer Aided Design & Computer Graphics, V14, P275
   Ren P, 2017, PRESENCE-VIRTUAL AUG, V26, P389, DOI 10.1162/PRES_a_00304
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Tan P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409061
   Tavares RS, 2011, EXPERT SYST APPL, V38, P2951, DOI 10.1016/j.eswa.2010.08.084
   Vouzounaras G, 2014, MULTIMED TOOLS APPL, V70, P361, DOI 10.1007/s11042-011-0823-0
   Wang R, 2011, COMPUTER MODERNIZATI, V185, P70
   Wonka P, 2003, ACM T GRAPHIC, V22, P669, DOI 10.1145/882262.882324
   Wu FZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601162
   Yao ZJ, 2016, EXPERT SYST APPL, V51, P26, DOI 10.1016/j.eswa.2015.12.019
   Yeguas E, 2012, MULTIMED TOOLS APPL, V60, P1, DOI 10.1007/s11042-011-0795-0
   Zhang RM, 2017, IOP C SER EARTH ENV, V69, DOI 10.1088/1755-1315/69/1/012087
   Zhang SM, 2012, ADV ENG INFORM, V26, P705, DOI 10.1016/j.aei.2012.04.002
   Zhu JY, 2014, INT CONF MEAS, P787, DOI 10.1109/ICMTMA.2014.194
   Zmugg R, 2014, VISUAL COMPUT, V30, P1009, DOI 10.1007/s00371-013-0912-3
NR 46
TC 6
Z9 6
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5773
EP 5807
DI 10.1007/s11042-020-09744-2
EA OCT 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000576875100001
DA 2024-07-18
ER

PT J
AU Yasar, H
   Ceylan, M
AF Yasar, Huseyin
   Ceylan, Murat
TI A novel comparative study for detection of Covid-19 on CT lung images
   using texture analysis, machine learning, and deep learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Convolutional neural networks (CNN); Deep learning; Lung CT
   classification; Machine learning; Texture analysis methods
ID CORONAVIRUS DISEASE; DIAGNOSIS; 2019-NCOV; PATIENT; WUHAN
AB The Covid-19 virus outbreak that emerged in China at the end of 2019 caused a huge and devastating effect worldwide. In patients with severe symptoms of the disease, pneumonia develops due to Covid-19 virus. This causes intense involvement and damage in lungs. Although the emergence of the disease occurred a short time ago, many literature studies have been carried out in which these effects of the disease on the lungs were revealed by the help of lung CT imaging. In this study, 1.396 lung CT images in total (386 Covid-19 and 1.010 Non-Covid-19) were subjected to automatic classification. In this study, Convolutional Neural Network (CNN), one of the deep learning methods, was used which suggested automatic classification of CT images of lungs for early diagnosis of Covid-19 disease. In addition, k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM) was used to compare the classification successes of deep learning with machine learning. Within the scope of the study, a 23-layer CNN architecture was designed and used as a classifier. Also, training and testing processes were performed for Alexnet and Mobilenetv2 CNN architectures as well. The classification results were also calculated for the case of increasing the number of images used in training for the first 23-layer CNN architecture by 5, 10, and 20 times using data augmentation methods. To reveal the effect of the change in the number of images in the training and test clusters on the results, two different training and testing processes, 2-fold and 10-fold cross-validation, were performed and the results of the study were calculated. As a result, thanks to these detailed calculations performed within the scope of the study, a comprehensive comparison of the success of the texture analysis method, machine learning, and deep learning methods in Covid-19 classification from CT images was made. The highest mean sensitivity, specificity, accuracy, F-1 score, and AUC values obtained as a result of the study were 0,9197, 0,9891, 0,9473, 0,9058, 0,9888; respectively for 2-fold cross-validation, and they were 0,9404, 0,9901, 0,9599, 0,9284, 0,9903; respectively for 10-fold cross-validation.
C1 [Yasar, Huseyin] Minist Hlth Republ Turkey, Ankara, Turkey.
   [Ceylan, Murat] Konya Tech Univ, Fac Engn & Nat Sci, Dept Elect & Elect Engn, Konya, Turkey.
C3 Ministry of Health - Turkey; Konya Technical University
RP Yasar, H (corresponding author), Minist Hlth Republ Turkey, Ankara, Turkey.
EM mirhendise@gmail.com; mceylan@ktun.edu.tr
RI Yaşar, Hüseyin/GLV-6400-2022
OI Yaşar, Hüseyin/0000-0002-7583-980X
CR Albarello F, 2020, INT J INFECT DIS, V93, P192, DOI 10.1016/j.ijid.2020.02.043
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Armato III S.G., 2015, DATA LIDC IDRI, DOI [DOI 10.7937/K9/TCIA.2015.LO9QL9SX, 10.7937/K9/TCIA.2015.LO 9QL9SX]
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Bloice MD, 2019, BIOINFORMATICS, V35, P4522, DOI 10.1093/bioinformatics/btz259
   Bloice MD, 2017, ARXIV 170804680
   BLOICE MD, 2019, ARXIV191107922
   Chen HJ, 2020, LANCET, V395, P809, DOI 10.1016/S0140-6736(20)30360-3
   Cheng SC, 2020, J FORMOS MED ASSOC, V119, P747, DOI 10.1016/j.jfma.2020.02.007
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Cohen JP, 2020, ARXIV2020
   Han ZY, 2020, IEEE T MED IMAGING, V39, P2584, DOI 10.1109/TMI.2020.2996256
   Hardalac F, 2020, MULTIMED TOOLS APPL, V79, P22929, DOI 10.1007/s11042-020-09005-2
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Hu XF, 2020, QUANT IMAG MED SURG, V10, P508, DOI 10.21037/qims.2020.02.10
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li MZ, 2020, ACAD RADIOL, V27, P603, DOI 10.1016/j.acra.2020.03.003
   Li W, 2020, PEDIATR RADIOL, V50, P796, DOI 10.1007/s00247-020-04656-7
   Lim J, 2020, J KOREAN MED SCI, V35, DOI 10.3346/jkms.2020.35.e79
   Lin C, 2020, CLIN IMAG, V63, P7, DOI 10.1016/j.clinimag.2020.02.008
   Liu KC, 2020, EUR J RADIOL, V126, DOI 10.1016/j.ejrad.2020.108941
   Long JTB, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-1536-6
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103044
   Ornek AH, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P191, DOI [10.1109/tsp.2019.8769068, 10.1109/TSP.2019.8769068]
   Ouyang X, 2020, IEEE T MED IMAGING, V39, P2595, DOI 10.1109/TMI.2020.2995508
   Pan YY, 2020, EUR RADIOL, V30, P3306, DOI 10.1007/s00330-020-06731-x
   Pathak Y, 2022, IRBM, V43, P87, DOI 10.1016/j.irbm.2020.05.003
   Qin CX, 2020, EUR J NUCL MED MOL I, V47, P1281, DOI 10.1007/s00259-020-04734-w
   Sakagianni A, 2020, STUD HEALTH TECHNOL, V272, P13, DOI 10.3233/SHTI200481
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen C, 2020, J PHARM ANAL, V10, P123, DOI 10.1016/j.jpha.2020.03.004
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   VAPNIK VN, 1964, AUTOMAT REM CONTR+, V25, P103
   Xia W., 2020, PEDIATR PULM, V55, P1169, DOI [10.1002/ppul.24718 10.1002/ppul.24718, DOI 10.1002/ppul.24718]
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P12007, DOI 10.1007/s11042-019-08566-1
   Xu X, 2020, EUR J NUCL MED MOL I, V47, P1275, DOI 10.1007/s00259-020-04735-9
   Xu YH, 2020, J INFECTION, V80, P394, DOI 10.1016/j.jinf.2020.02.017
   Yang W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229651
   Yasar H, 2016, J MED IMAG HEALTH IN, V6, P710, DOI 10.1166/jmihi.2016.1737
   Zhao J., 2020, ARXIV PREPRINT ARXIV
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
NR 45
TC 42
Z9 42
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5423
EP 5447
DI 10.1007/s11042-020-09894-3
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600012
PM 33041635
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dagher, I
   Mikhael, S
   Al-Khalil, O
AF Dagher, Issam
   Mikhael, Sandy
   Al-Khalil, Oubaida
TI Gabor face clustering using affinity propagation and structural
   similarity index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face clustering; Affinity propagation; Gabor; Structural similarity
   index
AB Clustering is an important technique in data mining. It separates data points into different groups or clusters in such a way that objects in the same group are more similar to each other in some sense than with the objects in other groups. Gabor face clustering using affinity propagation and structural similarity index is composed of: A representation based on Gabor filters which has been shown to perform very well in face features, Affinity propagation clustering algorithm which is flexible, high speed, and does not require to specify the number of clusters, and structural similarity index which is a very powerful method for measuring the similarity between two images. Experimental results on two benchmark face datasets (LFW and IJB-B) show that our method outperforms well known clustering algorithms such as k-means, spectral clustering and Agglomerative.
C1 [Dagher, Issam; Mikhael, Sandy; Al-Khalil, Oubaida] Univ Balamand, Dept Comp Engn, Tripoli, Lebanon.
C3 University Balamand
RP Dagher, I (corresponding author), Univ Balamand, Dept Comp Engn, Tripoli, Lebanon.
EM dagheri@balamand.edu.lb
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2014, P EUR C COMP VIS ECC
   [Anonymous], 2015, P CVPR
   [Anonymous], 1998, 24 COMP VIS CTR
   Bäuml M, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P7, DOI 10.1109/AVSS.2014.6918636
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Cui JY, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P367
   Du G, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P722, DOI 10.1109/ICNIDC.2009.5360997
   Dueck D., 2009, AFFINITY PROPAGATION
   Ho J, 2003, P CVPR
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Liu Ting, 2007, 2007 IEEE WORKSHOP A, P28, DOI DOI 10.1109/WACV.2007.18
   Meshoul, 2017, CLOUD COMP TECHN APP, P1
   Sarwas G, 2018, SIG P ALGO ARCH ARR, P55, DOI 10.23919/SPA.2018.8563400
   Shi YC, 2018, IEEE T INF FOREN SEC, V13, P1626, DOI 10.1109/TIFS.2018.2796999
   Tian Y., 2007, P CVPR
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Wang J, 2012, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2012.6247790
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei PC, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0313-7
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang LF, 2018, INT CONF MACH LEARN, P337, DOI 10.1109/ICMLC.2018.8526946
   Zhang MJ, 2008, RETROVIROLOGY, V5, DOI 10.1186/1742-4690-5-82
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680
NR 27
TC 6
Z9 7
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4719
EP 4727
DI 10.1007/s11042-020-09822-5
EA OCT 2020
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574355100003
DA 2024-07-18
ER

PT J
AU Narayana, GS
   Kolli, K
AF Narayana, G. Surya
   Kolli, Kamakshaiah
TI Fuzzy K-means clustering with fast density peak clustering on
   multivariate kernel estimator with evolutionary multimodal optimization
   clusters on a large dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-means clustering; Multimodal optimization; Crowding differential
   evaluation; Density value; Center distance
ID ALGORITHM
AB Many conventional optimization approaches concentrate more on addressing only one appropriate solution. Thus, these methods were to be utilized often, hence there were no chances of producing the intended solution. Therefore, the issue of multimodal optimization has to be considered. So, to reduce the difficulties by the clustering and further, it followed by the optimization technique. Here, the variety of real-time and artificial techniques are used. Using the FCDP-Fast Clustering with Density Peak, we calculate the density values after determining the center with the help of objective function. Then, the fuzzy clustering is applied to form the clustered groups with the density and center values. Finally, we optimize the data using the CDE-Crowding Differential Evaluation methodology. Performance analysis is then proceeded with some existing methods by using the performance metrics like NMI and ARI. After validation, it concluded that the proposed method was superior to the existing method.
C1 [Narayana, G. Surya] Sreyas Inst Engn & Technol, Cse Dept, Hyderabad, India.
   [Kolli, Kamakshaiah] Geethanjali Coll Engn & Technol, Dept CSE, Hyderabad, India.
C3 Geethanjali College of Engineering & Technology
RP Narayana, GS (corresponding author), Sreyas Inst Engn & Technol, Cse Dept, Hyderabad, India.
EM surya.aits@gmail.com
RI Kolli, Kamakshaiah/ABC-6892-2020; SuryaNarayana, G/ADD-4506-2022;
   KAMAKSHAIAH, KOLLI/R-2414-2017
OI Kolli, Kamakshaiah/0000-0003-3313-7444; SuryaNarayana,
   G/0000-0002-5552-3971; KAMAKSHAIAH, KOLLI/0000-0003-3313-7444
CR Ahrari A, 2017, EVOL COMPUT, V25, P439, DOI [10.1162/evco_a_00182, 10.1162/EVCO_a_00182]
   Amiri E, 2016, APPL SOFT COMPUT, V41, P15, DOI 10.1016/j.asoc.2015.12.008
   [Anonymous], 2015, ARXIV150800457
   Bryant A, 2018, IEEE T KNOWL DATA EN, V30, P1109, DOI 10.1109/TKDE.2017.2787640
   Calfa BA, 2015, COMPUT CHEM ENG, V78, P51, DOI 10.1016/j.compchemeng.2015.04.012
   Chander S, 2018, ALEX ENG J, V57, P267, DOI 10.1016/j.aej.2016.12.013
   Das P, 2018, APPL SOFT COMPUT, V70, P590, DOI 10.1016/j.asoc.2018.05.045
   Emami H, 2015, ARAB J SCI ENG, V40, P3545, DOI 10.1007/s13369-015-1826-3
   Fouedjio F, 2016, SPAT STAT-NETH, V18, P333, DOI 10.1016/j.spasta.2016.07.003
   Heil J, 2019, GEODERMA, V337, P11, DOI 10.1016/j.geoderma.2018.09.004
   Hou J, 2019, IEEE T IND INFORM
   Jia H, 2017, IEEE T NEURAL NETWOR, V29, P3308
   Liang J, 2019, IEEE T IMAGE PROCESS, V28, P3973, DOI 10.1109/TIP.2019.2903294
   Matioli LC, 2018, J APPL STAT, V45, P347, DOI 10.1080/02664763.2016.1277191
   Mittal M, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1300
   Nayak J, 2018, AIN SHAMS ENG J, V9, P379, DOI 10.1016/j.asej.2016.01.010
   Nock R, 2006, IEEE T PATTERN ANAL, V28, P1223, DOI 10.1109/TPAMI.2006.168
   Panagiotakis C, 2015, J CLASSIF, V32, P212, DOI 10.1007/s00357-015-9182-2
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Qu BY, 2016, SWARM EVOL COMPUT, V26, P23, DOI 10.1016/j.swevo.2015.07.003
   Scognamiglio L, 2016, GEOPHYS J INT, V206, P792, DOI 10.1093/gji/ggw173
   Sengupta S, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P137, DOI 10.1109/CCWC.2018.8301693
   Sitompul O, 2018, IOP C SERIES MAT SCI
   Nguyen TPQ, 2019, APPL SOFT COMPUT, V75, P254, DOI 10.1016/j.asoc.2018.11.028
   Wang WT, 2019, INFORMATION, V10, DOI 10.3390/info10060208
   Wang YT, 2017, EXPERT SYST APPL, V72, P457, DOI 10.1016/j.eswa.2016.10.006
   Wang ZJ, 2018, IEEE T EVOLUT COMPUT, V22, P894, DOI 10.1109/TEVC.2017.2769108
   Wu XH, 2015, APPL MATH MODEL, V39, P3398, DOI 10.1016/j.apm.2014.11.041
   Xu J., 2016, IJCAI, P2224
   Xu J, 2016, INFORM SCIENCES, V373, P200, DOI 10.1016/j.ins.2016.08.086
   Xu SL, 2019, INT J MACH LEARN CYB, V10, P3213, DOI 10.1007/s13042-019-01012-6
   Yang CL, 2015, APPL SOFT COMPUT, V30, P113, DOI 10.1016/j.asoc.2015.01.031
   Yang Q, 2017, IEEE T EVOLUT COMPUT, V21, P191, DOI 10.1109/TEVC.2016.2591064
   Yu WJ, 2018, INFORM SCIENCES, V423, P1, DOI 10.1016/j.ins.2017.09.044
   Zhong CM, 2019, PATTERN RECOGN, V92, P93, DOI 10.1016/j.patcog.2019.03.020
   Zhuo L, 2019, IEEE ACCESS
   Zhuo LL, 2019, IEEE ACCESS, V7, P74612, DOI 10.1109/ACCESS.2019.2918772
NR 37
TC 6
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4769
EP 4787
DI 10.1007/s11042-020-09718-4
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574355100002
DA 2024-07-18
ER

PT J
AU Lyu, MJ
   Yuan, SM
AF Lyu, Mei-Jing
   Yuan, Shyan-Ming
TI Cloud-based physiological sound-controlled intelligent music and
   blood-pressure control system for assisting family caregivers of
   dementia patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dementia; Healthcare; Sensor; Fuzzy logic; Hypertension; Music
ID EXPERIENCES; PEOPLE
AB Population aging causes the prevalence of hypertension to increase, which increases the incidence of dementia and leads to premature death. The simultaneous development of these two diseases accelerates the progression of dementia, leading to a reduction in the patient's quality of life. This is difficult for caregivers, as it causes them to shoulder a greater burden and brings greater emotional stress, resulting in their wanting to end the care relationship or even neglect or abuse patients. In addition, their own mental and physical health is also severely affected, causing them to seek medical treatment themselves. In view of this problem, we propose a cloud-based physiological sound-controlled intelligent music and blood-pressure control system to assist family caregivers of dementia patients to reduce their burden as well as their stress. We interview family caregivers regarding the benefits of this system in assisting them and find that most caregivers find the system to be helpful.
C1 [Lyu, Mei-Jing; Yuan, Shyan-Ming] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lyu, MJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM worktanya33kimo@gmail.com; smyuan@cs.nctu.edu.tw
RI Yuan, Shyan-Ming/O-1809-2013
OI Yuan, Shyan-Ming/0000-0002-3621-9528
CR Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Alzheimer's Disease International, 2018, STAT ART DEM RES NEW
   [Anonymous], 2020, HYPERTENSION
   [Anonymous], 2018, INT J SCI TECHNOL RE, V7, P171
   [Anonymous], 2020, iPad
   [Anonymous], 2018, American Heart Association News
   Aruanno B, 2019, MULTIMED TOOLS APPL, V78, P13517, DOI 10.1007/s11042-018-7089-8
   Bekiroglu T, 2013, COMPLEMENT THER MED, V21, P147, DOI 10.1016/j.ctim.2013.03.005
   British Association For Music Therapy, 2016, LEAD FIG COM TOG HOL
   Cloud Decision Center, 2018, HEALTHCARE IT NEWS H
   Day JR, 2011, NURS RES PRACT, V2011, DOI 10.1155/2011/408024
   Dell Incorporated, 2013, POWEREDGE M1000E TEC
   DeVeaux Scott., 1995, Jazz in America: Who's Listening? Research Division Report #31, National Endowment for the Arts
   EMedExpert staff, 2017, MUS PROM HLTH
   EMOTIV, 2020, EMOTIV INS 5 CHANN M
   Fang R, 2017, TRANSL NEURODEGENER, V6, DOI 10.1186/s40035-017-0073-9
   Iadecola C, 2014, HYPERTENSION, V64, P3, DOI 10.1161/HYPERTENSIONAHA.114.03040
   Kirkland K, 2020, ALZHEIMERS DIS
   Kuo Y.H., 2014, TAIPEI CITY MED J, V11, P89, DOI [10.6200/TCMJ.2014.11.1.07, DOI 10.6200/TCMJ.2014.11.1.07]
   Lam KY, 2017, MULTIMED TOOLS APPL, V76, P489, DOI 10.1007/s11042-015-3047-x
   Launer LJ, 2000, NEUROBIOL AGING, V21, P49, DOI 10.1016/S0197-4580(00)00096-8
   LORD TR, 1993, PERCEPT MOTOR SKILL, V76, P451, DOI 10.2466/pms.1993.76.2.451
   Lyu MJ, 2020, IEEE ACCESS, V8, P20977, DOI 10.1109/ACCESS.2020.2969482
   Masimo, 2020, MIGHTYSAT FING PULS
   Mayo Clinic, 2017, DEM SYMPT CAUS
   Microsoft Azure, 2020, AZ KIN DK
   Noachtar S, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P21
   Omron, 2020, 7 SER WIR WRIST BLOO
   Park H, 2009, J GERONTOL NURS, V35, P47, DOI 10.3928/00989134-20090706-01
   Peeters MMM, 2016, COMPUT HUM BEHAV, V63, P727, DOI 10.1016/j.chb.2016.06.003
   Sherratt K, 2004, AGING MENT HEALTH, V8, P3, DOI 10.1080/13607860310001613275
   do Amaral MAS, 2016, INT J CARDIOL, V214, P462, DOI 10.1016/j.ijcard.2016.03.197
   Sung HC, 2010, J CLIN NURS, V19, P1056, DOI 10.1111/j.1365-2702.2009.03016.x
   Williams B, 2018, J HYPERTENS, V36, P2284, DOI [10.1097/HJH.0000000000001961, 10.1097/HJH.0000000000002026]
   WRIGHT SD, 1985, J RELIG HEALTH, V24, P31, DOI 10.1007/BF01533257
   Xie J., 2017, J. Int. Council Electr. Eng., V7, P188, DOI [10.1080/22348972.2017.1348890, DOI 10.1080/22348972.2017.1348890]
   Yasa IGMNA, 2014, TELKOMNIKA INDONES J, V12, P5669
NR 37
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4399
EP 4419
DI 10.1007/s11042-020-09931-1
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573781100001
DA 2024-07-18
ER

PT J
AU Lin, YK
   Wang, CF
   Chang, CY
   Sun, HL
AF Lin, Yih-Kai
   Wang, Chu-Fu
   Chang, Ching-Yu
   Sun, Hao-Lun
TI An efficient framework for counting pedestrians crossing a line using
   low-cost devices: the benefits of distilling the knowledge in a neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Counting pedestrians; Distilling knowledge; LBP cascade classifier
AB In this paper, an efficient framework for counting pedestrians crossing a line of interest is proposed. Nowadays, the convolutional neural networks have very good results on pedestrian detection and tracking. However, the major drawback of the neural networks is that they require heavy computing resources. This limits the application of neural networks in low-cost systems. Thus, the low power consuming pedestrian counting systems with comparable performance are still important. To achieve this goal, the proposed method distils the pedestrian detection knowledge from a neural network to train thelocal binary patterns(LBP) cascade classifier model to detect pedestrians. Then a matching and tracking algorithm is used to count the number of pedestrians. An automaton was developed to eliminate the bouncing position of the detected pedestrians. The experimental comparisons show that, compared to Ma et al. and Felzenszwalb et al.'s methods, the quality of the line of interest counting of the proposed method is about the same and, at the same time, the execution time of the proposed method is much less.
C1 [Lin, Yih-Kai; Wang, Chu-Fu; Chang, Ching-Yu; Sun, Hao-Lun] Natl Pingtung Univ, 4-18 Minsheng Rd, Pingtung, Taiwan.
C3 National Pingtung University
RP Lin, YK (corresponding author), Natl Pingtung Univ, 4-18 Minsheng Rd, Pingtung, Taiwan.
EM yklin@mail.nptu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST-108-2221-E-153-005]
FX Supported by the Ministry of Science and Technology of Taiwan under
   contracts MOST-108-2221-E-153-005
CR [Anonymous], 2019, ARXIV190102620
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Cong Y, 2009, PROC CVPR IEEE, P1093, DOI 10.1109/CVPRW.2009.5206648
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean J., 2015, NIPS DEEP LEARNING R
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Ma CM, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1100, DOI 10.1109/ISKE.2008.4731094
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Ma Z, 2016, IEEE T CIRC SYST VID, V26, P1955, DOI 10.1109/TCSVT.2015.2489418
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Schrier MJ, 2017, US Patent App, V14, Patent No. 14997120
   Tang JP, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2953560
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao ZY, 2016, LECT NOTES COMPUT SC, V9912, P712, DOI 10.1007/978-3-319-46484-8_43
   Zheng HC, 2019, IEEE T CIRC SYST VID, V29, P787, DOI 10.1109/TCSVT.2018.2807806
NR 24
TC 13
Z9 15
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4037
EP 4051
DI 10.1007/s11042-020-09276-9
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719700001
DA 2024-07-18
ER

PT J
AU Zhang, WZ
   Lu, GQ
   Zhang, SC
   Li, YG
AF Zhang, Wenzhen
   Lu, Guangquan
   Zhang, Shichao
   Li, Yonggang
TI Self-paced hybrid dilated convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks (CNNs); Self-paced learning(SPL); Hybrid
   dilated convolution(HDC)
AB Convolutional neural networks (CNNs) can learn the features of samples by supervised manner, and obtain outstanding achievements in many application fields. In order to improve the performance and generalization of CNNs, we propose a self-learning hybrid dilated convolution neural network (SPHDCNN), which can choose relatively reliable samples according to the current learning ability during training. In order to avoid the loss of useful feature map information caused by pooling, we introduce hybrid dilated convolution. In the proposed SPHDCNN, weight is applied to each sample to reflect the easiness of the sample. SPHDCNN employs easier samples for training first, and then adds more difficulty samples gradually according to the current learning ability. It gradually improves its performance by this learning mechanism. Experimental results show SPHDCNN has strong generalization ability, and it achieves more advanced performance compared to the baseline method.
C1 [Zhang, Wenzhen; Lu, Guangquan; Zhang, Shichao; Li, Yonggang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM jianjiu17@outlook.com; guangquanl85@gmail.com;
   zhangsc@mailbox.gxnu.edu.cn; stublyg@hotmail.com
RI Lu, Guangquan/JXL-7832-2024; Zhang, Shichao/JXW-9650-2024
OI Lu, Guangquan/0000-0001-6908-6269; 
FU National Natural Science Foundation of China [61836016, 61876046,
   81701780, 61672177]; Guangxi Natural Science Foundation
   [2017GXNSFBA198221]; Project of Guangxi Science and Technology
   [GuiKeAD19110133, GuiKeAD17195062]; Innovation Project of Guangxi
   Graduate Education [JXXYYJSCXXM-012, JXXYYJSCXXM-011, JGY20200026];
   Research and Education Project of Guangxi Normal University [2019YR006];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [20-A-01-01]; Basic Competence Promotion Project for Young and
   Middle-aged Teachers in Guangxi Education Department [2019KY0062]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No: 61836016, 61876046, 81701780 and 61672177); the Guangxi
   Natural Science Foundation (Grant No: 2017GXNSFBA198221); the Project of
   Guangxi Science and Technology (GuiKeAD19110133 and GuiKeAD17195062);
   Innovation Project of Guangxi Graduate Education (Grant No:
   JXXYYJSCXXM-012, JXXYYJSCXXM-011, JGY20200026); Research and Education
   Project of Guangxi Normal University (Grant No: 2019YR006); Research
   Fund of Guangxi Key Lab of Multi-source Information Mining & Security
   (Grant No: 20-A-01-01); and Basic Competence Promotion Project for Young
   and Middle-aged Teachers in Guangxi Education Department (Grant No:
   2019KY0062).
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], CoRR abs/1511.07122
   Basu S., 2013, Proc. AAAI, V27, P109
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bi S, 2019, IEEE ASME INT C ADV, P19, DOI [10.1109/aim.2019.8868606, 10.1109/AIM.2019.8868606]
   Fang YC, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115664
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Jiao CZ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040424
   Khan Faisal, 2011, ADV NEURAL INFORM PR, V24
   Kingma D. P., 2014, arXiv
   Kumar A, 2010, ASIA PACIF MICROWAVE, P1189
   Larochelle D., 2007, P 24 INT C MACHINE L, P473, DOI DOI 10.1145/1273496.1273556
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2018, APPL SOFT COMPUT, V71, P698, DOI 10.1016/j.asoc.2018.07.021
   Li H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2110
   Meng Deyu, 2015, ARXIV151106049
   Oord A., 2016, ARXIV160903499
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Radovic M, 2017, J IMAGING, V3, DOI 10.3390/jimaging3020021
   Rifai S., 2011, CONTRACTIVE AUTOENCO, DOI DOI 10.5555/3104482.3104587
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang Kevin, 2012, P INT C NEUR INF PRO, P647
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Zhang L, 2019, IEEE ACCESS, V7, P109729, DOI 10.1109/ACCESS.2018.2865613
   Zhao Q, 2015, AAAI CONF ARTIF INTE, P3196
   Zhu PF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3235
   Zhu XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107175
   Zhu XF, 2020, WORLD WIDE WEB, V23, P1969, DOI 10.1007/s11280-019-00731-8
NR 29
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34169
EP 34181
DI 10.1007/s11042-020-09868-5
EA SEP 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000572865900007
DA 2024-07-18
ER

PT J
AU Li, YF
   Wang, X
   Cui, L
   Zhang, JJ
   Huang, CK
   Luo, X
   Qi, SH
AF Li, Yifan
   Wang, Xuan
   Cui, Lei
   Zhang, Jiajia
   Huang, Chengkai
   Luo, Xuan
   Qi, Shuhan
TI Autoencoder-based self-supervised hashing for cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Hash learning; Autoencoder; Self-supervised
AB Cross-modal retrieval has gained lots of attention in the era of the multimedia data explosion. Taking advantage of low storage cost and fast retrieval speed, hash learning-based methods become more and more popular in this field. The crucial bottlenecks of cross-modal retrieval are twofold: the heterogeneous gap in different modalities and the semantic gap among similar data with various modalities. To address these issues, we adopt self-supervised fashion to bridge the heterogeneous gap by generating the cohesive features of different instances. To mitigate the semantic gap, we use triplet sampling to optimize the semantic loss in inter-modal and intra-modal, which increase the discriminability of our approach. Experimental on two benchmark datasets show the efficiency and robustness of our method, and the extended experiments show the scalability.
C1 [Li, Yifan; Wang, Xuan; Cui, Lei; Zhang, Jiajia; Huang, Chengkai; Luo, Xuan; Qi, Shuhan] Harbin Inst Technol Shenzhen, Comp Sci & Technol, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology
RP Qi, SH (corresponding author), Harbin Inst Technol Shenzhen, Comp Sci & Technol, Shenzhen, Peoples R China.
EM yifanli@cs.hitsz.edu.cn; wangxuan@cs.hitsz.edu.cn;
   cuilei@cs.hitsz.edu.cn; zhangjiajia@hit.edu.cn; fjswhck@hrbeu.edu.cn;
   graceluo24x@gmail.com; shuhanqi@cs.hitsz.edu.cn
RI LI, yi/HKO-0480-2023; Li, Yifan/HGA-6843-2022; Li, Yifan/IAQ-2592-2023;
   Liu, Yi/HTN-4916-2023; Li, Yifan/JCE-0660-2023
OI Li, Yifan/0000-0002-3249-1778; Li, Yifan/0000-0002-9243-0264; Li,
   Yifan/0000-0002-3249-1778
CR Akaho S, 2006, ARXIV06090710609071
   [Anonymous], 2009, NUSWIDE: A real-world web image database from National University of Singapore, DOI DOI 10.1145/1646396.1646452
   [Anonymous], 2008, Proceedings of the 25th international conference on Machine learning
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Carreira-Perpiñán MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen J., 2018, INT JOINT C ART INT, P613
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226
   Guan J, 2019, J VIS COMMUN IMAGE R, V58, P675, DOI 10.1016/j.jvcir.2018.12.025
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kolesnikov A, 2019, PROC CVPR IEEE, P1920, DOI 10.1109/CVPR.2019.00202
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li BC, 2019, IEEE T MULTIMEDIA, V21, P522, DOI 10.1109/TMM.2018.2856090
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu H, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1589, DOI 10.1145/3240508.3240684
   Liu XW, 2019, AAAI CONF ARTIF INTE, P4400
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Solomon ELS, 2017, MINERAL MET MAT SER, P349, DOI 10.1007/978-3-319-52392-7_50
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang X., 2016, AS C COMP VIS ACCV
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang CR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1135
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641
NR 38
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17257
EP 17274
DI 10.1007/s11042-020-09599-7
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000572719800006
DA 2024-07-18
ER

PT J
AU Sengupta, D
   Biswas, A
   Gupta, P
AF Sengupta, Debapriya
   Biswas, Arindam
   Gupta, Phalguni
TI Non-linear weight adjustment in adaptive gamma correction for image
   contrast enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Adaptive gamma correction; Non-linear weight
   adjustment; Steepness parameter; Contrast enhancement; Brightness
   adjustment
ID HISTOGRAM EQUALIZATION; RELEVANCE-FEEDBACK; FACE RECOGNITION;
   BRIGHTNESS; ALGORITHM; NETWORK; COLOR
AB Image enhancement remains an intricate problem, crucial for image analysis. Several algorithms exist for the same. A few among these algorithms categorize images into different classes based on their statistical parameters and apply separate enhancement functions for each class. One such algorithm is the well-known adaptive gamma correction (AGC) algorithm. It works well for each class of images, but fails when the statistical parameters lie on the boundary of separation of two classes. We have developed an enhancement algorithm which can enhance images which lie on the boundary of separation equally well, as images which lie deep inside the boundary. The basic idea behind the algorithm is to combine the different enhancement functions of AGC using non-linear weight adjustments. Both contrast and brightness have been modified using these weight adjustments. We have conducted experiments on a data-set consisting of 9979 images. Results show that by using the proposed algorithm, average entropy of the enhanced images increases by 3.97%and average root mean square (rms) increases by 14.29%over AGC. Visual improvement is also perceivable.
C1 [Sengupta, Debapriya; Biswas, Arindam] Indian Inst Engn Sci & Technol, Howrah, India.
   [Sengupta, Debapriya] Natl Inst Tech Teachers Training & Res, Kolkata, India.
   [Gupta, Phalguni] GLA Univ, Mathura, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   National Institute of Technical Teachers Training & Research, Kolkata;
   GLA University
RP Sengupta, D (corresponding author), Indian Inst Engn Sci & Technol, Howrah, India.; Sengupta, D (corresponding author), Natl Inst Tech Teachers Training & Res, Kolkata, India.
EM debapriya_20oct@yahoo.co.in; barindam@gmail.com; pg@gla.ac.in
OI Sengupta, Debapriya/0000-0002-4192-6227
CR Ai N, 2016, MULTIMED TOOLS APPL, V75, P6647, DOI 10.1007/s11042-015-2597-2
   [Anonymous], CNSTR2007001 CALTECH
   [Anonymous], 2016, EURASIP J IMAGE VIDE
   [Anonymous], 2010, CNSTR2010001 CALTECH
   Bhandari AK, 2014, ISA T, V53, P1286, DOI 10.1016/j.isatra.2014.04.007
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Braun GJ, 1999, J ELECTRON IMAGING, V8, P380, DOI 10.1117/1.482706
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen SD, 2004, DIGIT SIGNAL PROCESS, V14, P413, DOI 10.1016/j.dsp.2004.04.001
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen ZK, 2001, APPL OPTICS, V40, P1195, DOI 10.1364/AO.40.001195
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Fan D.P., 2018, IJCAI
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gonzalez Rafael C., 2014, DIGITAL IMAGE PROCES
   Guillon S, 1998, SIGNAL PROCESS, V67, P237, DOI 10.1016/S0165-1684(98)00042-5
   Huang SC, 2014, IEEE T IMAGE PROCESS, V23, P4426, DOI 10.1109/TIP.2014.2348869
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   Jung SW, 2014, IEEE SIGNAL PROC LET, V21, P382, DOI 10.1109/LSP.2014.2303157
   Kansal S, 2019, MULTIMED TOOLS APPL, P1
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Lisani JL, 2018, IEEE IMAGE PROC, P1747, DOI 10.1109/ICIP.2018.8451655
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu H, 2018, INFORM SCIENCES, V468, P142, DOI 10.1016/j.ins.2018.08.022
   Matz S. C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P484, DOI 10.1109/ICIP.1999.817161
   Mortezaie Z, 2019, MULTIMED TOOLS APPL, V78, P1
   Nunes FLS, 1999, PROC SPIE, V3661, P1105, DOI 10.1117/12.348505
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Patel AX, 2014, NEUROIMAGE, V95, P287, DOI 10.1016/j.neuroimage.2014.03.012
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Ramponi G, 1999, SIGNAL PROCESS, V77, P349, DOI 10.1016/S0165-1684(99)00086-9
   Sapiro G, 1997, GRAPH MODEL IM PROC, V59, P407, DOI 10.1006/gmip.1997.0446
   SAW JG, 1984, AM STAT, V38, P130, DOI 10.2307/2683249
   Shi ZH, 2016, MULTIMED TOOLS APPL, V75, P12245, DOI 10.1007/s11042-016-3421-3
   Singh KB, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P199, DOI 10.1109/IESPC.2017.8071892
   Smolka B, 2001, SIGNAL PROCESS, V81, P465, DOI 10.1016/S0165-1684(00)00226-7
   Su YT, 2019, NEUROCOMPUTING, V347, P200, DOI 10.1016/j.neucom.2019.04.011
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Tao DC, 2007, IEEE T KNOWL DATA EN, V19, P568, DOI 10.1109/TKDE.2007.1003
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Terol-Villalobos IR, 1998, J ELECTRON IMAGING, V7, P641, DOI 10.1117/1.482654
   Tsai CM, 2011, MACH VISION APPL, V22, P21, DOI 10.1007/s00138-009-0223-x
   VERDENET J, 1981, EUR J NUCL MED, V6, P261, DOI 10.1007/BF00251349
   Voronin V, 2018, IEEE SW SYMP IMAG, P5, DOI 10.1109/SSIAI.2018.8470344
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zuo YF, 2019, INFORM SCIENCES, V495, P52, DOI 10.1016/j.ins.2019.05.003
NR 56
TC 8
Z9 10
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3835
EP 3862
DI 10.1007/s11042-020-09583-1
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572601100004
DA 2024-07-18
ER

PT J
AU Uysal, E
   Güraksin, GE
AF Uysal, Esin
   Guraksin, Gur Emre
TI Computer-aided retinal vessel segmentation in retinal images:
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal blood vessel segmentation; Convolutional neural network; Image
   segmentation; Deep learning; Image processing
ID BLOOD-VESSELS; MATCHED-FILTER; ALGORITHM; EXTRACTION; WAVELET
AB In medicine, diagnosis is as important as treatment. Retinal blood vessels are the most easily visible vessels in the whole body, and therefore, play a key role in the diagnosis of numerous diseases and eye disorders. Systematic and eye diseases cause morphologic variations, such as the growing, narrowing or branching of retinal blood vessels. Imaging-based screening of retinal blood vessels plays an important role in the identification and follow-up of eye diseases. Therefore, automatic retinal vessel segmentation can be used to diagnose and monitor those diseases. Computer-aided algorithms are required for the analysis of progression of eye diseases. This study proposes a hybrid method that provides a combination of pre-processing and data augmentation methods with a deep learning model. Pre-processing was used to solve the irregular clarification problems and to form a contrast between the background and retinal blood vessels. After pre-processing step, a convolutional neural network (CNN) was designed and then trained for the extraction of retinal blood vessels. In the training phase, data augmentation was performed to improve training performance. The CNN was trained and tested in the DRIVE database, which is commonly used in retinal blood vessel segmentation and publicly available for studies in this area. Results showed that the proposed system extracted vessels with a sensitivity of 77.78%, specificity of 97,84%, precision of 84.17% and accuracy of 95.27%. This study also compared the results to those of previous studies. The comparison showed that the proposed method is an efficient and successful method for extracting retinal blood vessels. Moreover, the pre-processing phases improved the system performance. We believe that the proposed method and results will make contribution to the literature.
C1 [Uysal, Esin; Guraksin, Gur Emre] Afyon Kocatepe Univ, Dept Biomed Engn, Afyon, Turkey.
C3 Afyon Kocatepe University
RP Güraksin, GE (corresponding author), Afyon Kocatepe Univ, Dept Biomed Engn, Afyon, Turkey.
RI Güraksın, Gür Emre/ABI-3335-2020
OI Güraksın, Gür Emre/0000-0002-1935-2781
CR [Anonymous], 2016, INT J ENG COMPUTER S
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   David R, 2014, COMMUNICATING PICTUR, P99
   Delibasis KK, 2010, COMPUT METH PROG BIO, V100, P108, DOI 10.1016/j.cmpb.2010.03.004
   Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang B, 2003, DETECTION RETINAL VE
   Fathi A, 2013, BIOMED SIGNAL PROCES, V8, P71, DOI 10.1016/j.bspc.2012.05.005
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Ghoshal R, 2019, MULTIMED TOOLS APPL, V78, P25221, DOI 10.1007/s11042-019-7719-9
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo YH, 2018, MEASUREMENT, V125, P586, DOI 10.1016/j.measurement.2018.05.003
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Kolar R, 2011, EUR SIGNAL PR CONF, P298
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Melinscak M., 2015, VISAPP 2015 10 INT C, P577, DOI DOI 10.5220/0005313005770582
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P71, DOI 10.1016/j.cmpb.2018.02.001
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Salem SA, 2007, MED BIOL ENG COMPUT, V45, P261, DOI 10.1007/s11517-006-0141-2
   Sane P, 2017, IEEE WISPNET C, P2250
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Soomro TA, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P113
   Soomro TA, 2017, PATTERN ANAL APPL, V20, P927, DOI 10.1007/s10044-017-0630-y
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Stanton AV, 1995, J HYPERTENS, V13, P1724
   SUSSMAN EJ, 1982, JAMA-J AM MED ASSOC, V247, P3231, DOI 10.1001/jama.247.23.3231
   Wang C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020168
   Wong TY, 2001, SURV OPHTHALMOL, V46, P59, DOI 10.1016/S0039-6257(01)00234-X
   Yao ZJ, 2016, INT SYM COMPUT INTEL, P406, DOI [10.1109/ISCID.2016.1100, 10.1109/ISCID.2016.99]
   Yavuz Z, 2018, THESIS
   Yim J, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P345
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 49
TC 27
Z9 30
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3505
EP 3528
DI 10.1007/s11042-020-09372-w
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400003
DA 2024-07-18
ER

PT J
AU Wu, GX
   Li, YC
AF Wu, Guixian
   Li, Yuancheng
TI CyclicNet: an alternately updated network for semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Convolutional neural networks; Fully
   convolutional networks; Image understanding
AB In recent years, with the continuous breakthrough in deep learning, convolutional neural networks (CNNs) have shown great potential for semantic segmentation. CNNs achieve better results by deepening or widening the network, but they increase the utilization rate of computing resources and even have the phenomenon of the vanishing gradient. A new convolutional neural network architecture with alternately updated clique (CliqueNet) can get a deeper network and improves the utilization of network features. In order to maximize the transmission of semantic information, this paper introduces the clique block of CliqueNet and proposes a new fully convolutional network based on the encoder-decoder structure, which calls the CyclicNet, an alternately updated network for semantic segmentation. Besides, the long skip connections and short skip connections are added in the network to avoid the vanishing gradient. The experiment was conducted on the CamVid and Cityscapes. Comparing it with the current advanced architectures shows that CyclicNet can maximize information flow and achieve the most superior results.
C1 [Wu, Guixian; Li, Yuancheng] North China Elect Power Univ, Sch Control & Comp Engn, Beijing, Peoples R China.
C3 North China Electric Power University
RP Li, YC (corresponding author), North China Elect Power Univ, Sch Control & Comp Engn, Beijing, Peoples R China.
EM luckywgx@163.com; yuancheng@ncepu.cn
RI Li, yuancheng/IUO-3866-2023
OI Li, Yuancheng/0000-0001-8074-7259
FU Fundamental Research Funds for the Central Universities [2020YJ003]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (NO.2020YJ003).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8
   Ding HH, 2020, IEEE T IMAGE PROCESS, V29, P3520, DOI 10.1109/TIP.2019.2962685
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Malekijoo A, 2019, MULTIMED TOOLS APPL, V78, P32379, DOI 10.1007/s11042-019-07990-7
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Nurhadiyatna A, 2017, INT SYMP IMAGE SIG, P153, DOI 10.1109/ISPA.2017.8073587
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Paszke A., 2016, ARXIV160602147
   Salscheider NO, 2020, ICPRAM: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P555, DOI 10.5220/0009142905550561
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tian X, 2019, J SOFTW
   Wang JW, 2020, APPL INTELL, V50, P1045, DOI 10.1007/s10489-019-01587-1
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wu JR, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107268
   Xie XL, 2018, INT C PATT RECOG, P2196, DOI 10.1109/ICPR.2018.8545414
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Zhang SX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030427
   Zhou ZG, 2021, INT J CONTROL, V94, P223, DOI 10.1080/00207179.2019.1590644
NR 40
TC 4
Z9 4
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3213
EP 3227
DI 10.1007/s11042-020-09791-9
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200010
DA 2024-07-18
ER

PT J
AU Gupta, V
   Khera, S
   Turk, N
AF Gupta, Vatsal
   Khera, Sonam
   Turk, Neelam
TI MQTT protocol employing IOT based home safety system with ABE encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; MQTT protocol; ABE encryption; KP-ABE; WSN; ESP; PIR; MQ-5; Blynk;
   cloudMQTT
AB This project aims towards the usage of MQTT (Message queueing telemetry transport) protocol in IoT (Internet of things) along with adopting a feasible means of encrypting the message transfers in applications. The lightweight nature of MQTT protocol makes possible the transfer of information speedily and hence, has now being used in applications related to IoT, WSN (Wireless sensor networks), and M2M (Machine to machine) communications. Here, MQTT is deployed between ESP-8266 Wi-Fi SoCs namely- NodeMCU ESP-8266 12E and ESP-01 8266 Wi-Fi modules. Both communicate using the MQTT protocol using the internet via Wi-Fi. The ESP-8266 Wi-Fi SoCs have completely revolutionized approach towards IoT because of numerous advantages. This project also includes the usage of 2 sensors namely- PIR (Passive InfraRed) motion detector sensors and an MQ-5 gas sensor which sense human presence and some gases respectively. These sensors read the environment around them for the required information, systems encrypt that information and subsequently, transmit the data over the internet to the MQTT broker stationed at the cloud. This encrypted data is then sent to a central node- NodeMCU ESP-8266 12E which decrypts it and then alerts the user about any mishappening, through the Blynk app.
C1 [Gupta, Vatsal] Maharaja Agrasen Inst Technol, Dept Elect & Commun Engn, Delhi, India.
   [Khera, Sonam; Turk, Neelam] JC Bose Univ Sci & Technol, YMCA, Dept Elect Engn, Faridabad, Haryana, India.
C3 Maharaja Agrasen Institute of Technology; J.C. Bose University of
   Science & Technology, YMCA
RP Gupta, V (corresponding author), Maharaja Agrasen Inst Technol, Dept Elect & Commun Engn, Delhi, India.
EM vatsal.gupta97@gmail.com; sonamkhattar@yahoo.co.in; neelamturk@gmail.com
OI Gupta, Vatsal/0000-0001-7465-4101; Khera, Sonam/0000-0002-6621-2503;
   Turk, Neelam/0000-0001-8653-9223
CR [Anonymous], 2019, TECHNOLOGY TRENDS DO
   [Anonymous], 2017, Int. J. Pure Appl. Math.
   [Anonymous], 2015, MQTT BASICS MQTT ESS
   Bhatt A, 2013, INSIGHT LEARN WORKIN
   Goyal V., 2006, P 13 ACM C COMP COMM, P89, DOI DOI 10.1145/1180405.1180418
   Grgic K, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND TECHNOLOGIES (SST), P249, DOI 10.1109/SST.2016.7765668
   Jose AC, 2017, IEEE SENS J, V17, P4269, DOI 10.1109/JSEN.2017.2705045
   Kocakulak M, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Kuo YW, 2018, IEEE SENS J, V18, P5187, DOI 10.1109/JSEN.2018.2832664
   Mainetti L., 2011, SoftCOM 2011, 19th International Conference on Software, Telecommunications and Computer Networks, P1
   Rouse M, MQTT MQ TELEMETRY TR
   Singh M, 2015, INT CONF COMM SYST, P746, DOI 10.1109/CSNT.2015.16
   Wang XL, 2014, IEEE ICC, P725, DOI 10.1109/ICC.2014.6883405
NR 13
TC 17
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2931
EP 2949
DI 10.1007/s11042-020-09750-4
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100005
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Liu, ZJ
   Wang, JC
   Hu, LF
   Liu, ST
AF Wu, Jingjing
   Liu, Zhengjun
   Wang, Jicheng
   Hu, Lifa
   Liu, Shutian
TI A compact image encryption system based on Arnold transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Arnold transformation; Data security; Image processing
AB A novel compact image encryption system is proposed based on Arnold transformation (AT). In general, AT is a pixel-scramble tool in image encryption, but its security is not high enough as an independent cryptosystem because of its periodicity. Hence, extra diffusion operations are needed to diffuse the pixel values to acquire the higher security. Here an encryption algorithm is proposed by AT. Firstly, the corresponding coordinates of each pixel in original image are calculated by AT. Secondly, the pixel values of the two corresponding coordinates are disturbed by another AT. These two processes can diffuse the pixel values of the original image. At last, the diffused image is pixel scrambled by AT with different parameters. This is the confusion process. In proposed scheme, the diffusing and confusing operations are both realized by AT. At the same time, the image is encrypted as a pixel distribution instead of a data stream. The key space, key sensitivity, the correlation, the cost time and the security of proposed cryptosystem are analyzed and the results confirm that the proposed image encryption algorithm demonstrates extraordinary performance.
C1 [Wu, Jingjing; Wang, Jicheng; Hu, Lifa] Jiangnan Univ, Sch Sci, Wuxi, Jiangsu, Peoples R China.
   [Liu, Zhengjun; Liu, Shutian] Harbin Inst Technol, Dept Phys, Harbin, Peoples R China.
C3 Jiangnan University; Harbin Institute of Technology
RP Wu, JJ (corresponding author), Jiangnan Univ, Sch Sci, Wuxi, Jiangsu, Peoples R China.
EM ftxbs123@163.com
RI Liu, Zhengjun/A-2665-2010; Hu, tom/HPF-9066-2023
OI Liu, Zhengjun/0000-0003-2886-8496; Hu, Lifa/0000-0003-1041-9086
FU National Natural Science Foundation of China [11947028, 11874132];
   Fundamental Research Funds for the Central Universities
FX This work is supported by the National Natural Science Foundation of
   China (No.11947028; No.11874132) and the Fundamental Research Funds for
   the Central Universities (No.JUSRP12041).
CR Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Boussif M, 2020, IET IMAGE PROCESS, V14, P1209, DOI 10.1049/iet-ipr.2019.0042
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Farwa S, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0135-x
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Liang XK, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540223
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Madhusudhan KN, 2021, J AMB INTEL HUM COMP, V12, P5413, DOI 10.1007/s12652-020-02028-5
   Naik K, 2018, INT ARAB J INF TECHN, V15, P739
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   Wu C, 2010, J COMPUTE AIDED DESI, V22, P831
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou N.R., 2018, Quantum Inf. Process., V17
NR 21
TC 27
Z9 28
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2647
EP 2661
DI 10.1007/s11042-020-09828-z
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000006
DA 2024-07-18
ER

PT J
AU Wang, XH
   Yan, K
AF Wang, Xiuhui
   Yan, Ke
TI Gait classification through CNN-based ensemble learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble learning; CNN; Gait recognition
ID FRAMEWORK
AB Gait is a biological characteristic for video surveillance and many other applications, which can be used to identify individuals at a large distance. In this paper, a gait classification framework based on CNN Ensemble (GCF-CNN) is proposed, which includes three modules: 1) Feature extraction and preprocessing: use random sampling with replacement strategy to generate a serial of training sets from gait silhouette images; 2) Gait models training: construct and train primary CNN classifiers using different hyper-parameters, and train them a secondary classifier to combine them; 3) Gait classification: utilize the trained two-level classifier to achieve gait classification. In addition, the proposed classification framework is evaluated on the CASIA Gait Database and OU-ISIR Gait Database. And it is demonstrated by comprehensive experiments that the proposed classification framework can achieve outstanding performance in correct classification rate with respect to several state-of-the-art methods.
C1 [Wang, Xiuhui; Yan, Ke] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
RI Yan, Keyu/IXX-0343-2023
OI Wang, Xiuhui/0000-0003-1773-9760
FU National Natural Science Foundation of China [61303146, 61602431];
   Natural Science Foundation of Zhejiang Province
FX This work is supported by the National Natural Science Foundation of
   China (No. 61303146 and 61602431) and the Natural Science Foundation of
   Zhejiang Province (No.Y20F020113).
CR [Anonymous], 2006, INT C AUT FAC GEST R
   ARIYANTO G, 2011, INT C BIOM WASH DC U
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   Dewanjee S, 2011, EVID-BASED COMPL ALT, V2011, P1, DOI 10.1093/ecam/nep080
   Elghazel H, 2015, MACH LEARN, V98, P157, DOI 10.1007/s10994-013-5337-8
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Jia N, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P774, DOI 10.1109/BTAS.2017.8272769
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Li JY, 2017, IEEE T KNOWL DATA EN, V29, P257, DOI 10.1109/TKDE.2016.2619350
   Li XL, 2018, IEEE T NEUR NET LEAR, V29, P1454, DOI 10.1109/TNNLS.2017.2672978
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Schaar MVD Tekin C, 2015, IEEE T SIGNAL PROCES, V99, P1
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tong M, 2020, NEURAL COMPUT APPL, V32, P5285, DOI 10.1007/s00521-019-04030-1
   Tong M, 2019, NEUROCOMPUTING, V325, P90, DOI 10.1016/j.neucom.2018.09.086
   Uddin Md Zasim, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0041-z
   Wang X, 2019, MATTER, V1, P1, DOI DOI 10.1016/J.NEUROBIOLAGING.2018.11.025
   Wang XH, 2020, NEURAL COMPUT APPL, V32, P7275, DOI 10.1007/s00521-019-04256-z
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   [王修晖 Wang Xiuhui], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P709
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P330, DOI 10.1109/TNNLS.2011.2178315
NR 34
TC 12
Z9 12
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1565
EP 1581
DI 10.1007/s11042-020-09777-7
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000567642600001
DA 2024-07-18
ER

PT J
AU Liu, QY
   Wu, HZ
   Zhang, XP
AF Liu, Qingyang
   Wu, Hanzhou
   Zhang, Xinpeng
TI Adaptive video data hiding with low bit-rate growth based on texture
   selection and ternary syndrome-trellis coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video data hiding; Distortion function; STC; H.264/AVC
ID ALGORITHM; STREAMS
AB Data hiding aims to embed a secret payload into a cover object without introducing significant degradation of the cover. The resulting object containing hidden information, typically also called stego, will not arouse obvious suspicion from the monitor. A number of data hiding systems have been designed for digital images and only a few focus on video sequences. Actually, video is quite desirable for data hiding due to its large capacity for carrying a payload. It motivates us to present an adaptive data hiding scheme to video sequences in this paper. In the proposed scheme, the non-zero quantized Discrete Cosine Transform (QDCT) coefficients of intra-frames are used to embed the secret payload based on ternary syndrome-trellis coding (STC) equipped with a well-designed distortion function. In order to realize data hiding with low bit-rate growth, the non-zero QDCT coefficients in complex texture regions with high amplitude are further exploited for data embedding. Experimental results have shown that, comparing with a part of related works, the proposed work provides high embedding capacity and lower bit-rate growth. And, the video quality after data hiding can be kept with a high level. In addition, the proposed work does not expose suspicious histogram distribution and block characteristics, which has shown the superiority and applicability of the proposed work.
C1 [Liu, Qingyang; Wu, Hanzhou; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Wu, HZ (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM h.wu.phd@ieee.org
RI Wu, Hanzhou/AAL-3361-2021
OI Wu, Hanzhou/0000-0002-1599-7232
FU National Natural Science Foundation of China [61902235, U1636206,
   U1936214, 61525203]; "Chen Guang" project [19CG46]; Shanghai Municipal
   Education Commission; Shanghai Education Development Foundation
FX This work was partly supported by the National Natural Science
   Foundation of China under grant numbers 61902235, U1636206, U1936214 and
   61525203. It was also supported by "Chen Guang" project under grant
   number 19CG46, co-funded by the Shanghai Municipal Education Commission
   and Shanghai Education Development Foundation.
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2007, PROC SPIE
   [Anonymous], 2016, ENRGY PROCED, DOI DOI 10.1016/J.EGYPRO.2016.06.072
   [Anonymous], 2017, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-64185-0_15
   Chen Y, 2019, IEEE T DEPEND SECUR, V1
   Chen Y, 2020, CMC-COMPUT MATER CON, V63, P911, DOI 10.32604/cmc.2020.08027
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P20157, DOI 10.1007/s11042-017-5411-5
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jindal H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P465, DOI 10.1109/PDGC.2018.8745772
   Jindal H, 2018, WIREL NETW, V24, P3241, DOI 10.1007/s11276-017-1532-z
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Jindal H, 2017, AD HOC SENS WIREL NE, V39, P1
   Jindal H, 2017, WIRELESS PERS COMMUN, V97, P881, DOI 10.1007/s11277-017-4542-3
   Jindal H, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P251, DOI 10.1109/PDGC.2014.7030751
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Khosrvi MR, 2019, P INT C PAR DISTR PR, P87
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim DW, 2010, IMAGE VISION COMPUT, V28, P1220, DOI 10.1016/j.imavis.2009.12.006
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P8043, DOI 10.1007/s11042-017-4698-6
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mehta S, 2015, INT J ENG RES COMPUT, V2, P47
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Mourya G, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P187, DOI 10.1109/NGCT.2015.7375109
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Saxena S, P INT C PAR SOL DIST
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang ZC, 2018, IEEE ACCESS, V6, P74917, DOI 10.1109/ACCESS.2018.2884198
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiang Y, 2016, IEEE ACCESS, V4, P9740, DOI DOI 10.1109/ACCESS.2016.2612138
   Xu DW, 2016, SIGNAL PROCESS-IMAGE, V47, P369, DOI 10.1016/j.image.2016.08.003
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Xue YM, 2019, SIGNAL PROCESS-IMAGE, V76, P22, DOI 10.1016/j.image.2019.04.012
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 55
TC 3
Z9 3
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32935
EP 32955
DI 10.1007/s11042-020-09613-y
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739600001
DA 2024-07-18
ER

PT J
AU Singh, OP
   Singh, AK
   Srivastava, G
   Kumar, N
AF Singh, Om Prakash
   Singh, A. K.
   Srivastava, Gautam
   Kumar, Neeraj
TI Image watermarking using soft computing techniques: A comprehensive
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Steganography; Copyright; Machine learning; CNN; SVM;
   Neural networks; Genetic algorithm; Fuzzy logic; PCA
ID DISCRETE WAVELET TRANSFORM; DIGITAL WATERMARKING; COPYRIGHT PROTECTION;
   DWT-SVD; ENCRYPTED WATERMARK; MEDICAL IMAGE; ROBUST; SCHEME; ALGORITHM;
   DCT
AB Image watermarking techniques are used to provide copyright protection and verify ownership of media/entities. This technique refers to the concept of embedding of secret data/information of an owner in a given media/entity for determining any ownership conflicts that can arise. Many watermarking approaches have been offered by various authors in the last few years. However, there are not enough studies and comparisons of watermarking techniques in soft computing environments. Nowadays, soft computing techniques are used to improve the performance of watermarking algorithms. This paper surveys soft computing-based image watermarking for several applications. We first elaborate on novel applications, watermark characteristics and different kinds of watermarking systems. Then, soft computing based watermarking approaches providing robustness, imperceptibility and good embedding capacity are compared systematically. Furthermore, major issues and potential solutions for soft computing-based watermarking are also discussed to encourage further research in this area. Thus, this survey paper will be helpful for researchers to implement an optimized watermarking scheme for several applications.
C1 [Singh, Om Prakash; Singh, A. K.] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Srivastava, Gautam] Brandon Univ, Dept Math & Comp Sci, Brandon, MB, Canada.
   [Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, Taichung, Taiwan.
   [Kumar, Neeraj] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Neeraj] Asia Univ Taiwan, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; Brandon University; China Medical University Taiwan;
   Thapar Institute of Engineering & Technology; Asia University Taiwan
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM omprakash7667@gmail.com; amit_245singh@yahoo.com;
   srivastavag@brandonu.ca; neeraj.kumar@thapar.edu
RI SINGH, OM PRAKASH/GLS-8702-2022; SINGH, OM PRAKASH/AFR-7033-2022;
   Srivastava, Gautam/N-5668-2019; Kumar, Neeraj/L-3500-2016; Singh, Amit
   Kumar/D-1300-2015
OI SINGH, OM PRAKASH/0000-0003-2582-5669; Srivastava,
   Gautam/0000-0001-9851-4103; Kumar, Neeraj/0000-0002-3020-3947; Singh,
   Amit Kumar/0000-0001-7359-2068
CR Abbasi A, 2015, MEASUREMENT, V74, P116, DOI 10.1016/j.measurement.2015.06.006
   Abdullatif M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P235, DOI 10.1109/CSPA.2013.6530048
   Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P11751, DOI 10.1007/s11042-017-4815-6
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Alromih A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124346
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Amiri T, 2016, MULTIMED TOOLS APPL, V75, P8527, DOI 10.1007/s11042-015-2770-7
   Anand A, 2020, IEEE MULTIMEDIA, V27, P133, DOI 10.1109/MMUL.2020.2993269
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], 2011, INT J COMPUT ELECT E, DOI DOI 10.7763/IJCEE.2011.V3.285
   [Anonymous], 2015, INT J SIGNAL PROCESS
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Ayesha S, 2015, ADV INTELL SYST, V327, P141, DOI 10.1007/978-3-319-11933-5_16
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Cai ZL, 2008, PROCEEDINGS OF THE 27TH CHINESE CONTROL CONFERENCE, VOL 6, P581, DOI 10.1109/CHICC.2008.4605683
   Carballeira P., 2012, P 3DTV C TRUE VIS CA, P1
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Dhar JP, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0731-x
   Dharwadkar NV., 2010, INT J COMPUTER APPL, V2, P60
   Etemad E, 2018, MULTIMED TOOLS APPL, V77, P2033, DOI 10.1007/s11042-016-4278-1
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Fu YG, 2008, COMPUT STAND INTER, V30, P115, DOI 10.1016/j.csi.2007.08.013
   Fu YG, 2013, OPTIK, V124, P517, DOI 10.1016/j.ijleo.2011.12.042
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Ghadi M, 2018, LECT NOTES ARTIF INT, V10868, P844, DOI 10.1007/978-3-319-92058-0_81
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Ghazvini M, 2017, J APPL SEC RES, V12, P260, DOI 10.1080/19361610.2017.1277878
   Gonge S, 2017, ADV INTELL SYST COMP, V683, P84
   Gonge SS, 2015, COMM COM INF SC, V536, P290, DOI 10.1007/978-3-319-22915-7_28
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Himanshu H., 2011, 3 INT C EM TRENDS EN, P146
   Hongqin Shi, 2014, Journal of Software, V9, P1749, DOI 10.4304/jsw.9.7.1749-1756
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Hou Y, 2005, OPT ENG, V44
   Huang S, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5985, DOI 10.1109/WCICA.2008.4594557
   Huang S, 2009, ICIC 2009: SECOND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTING SCIENCE, VOL 2, PROCEEDINGS, P238, DOI 10.1109/ICIC.2009.170
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Jagadeesh B, 2015, PROCEDIA COMPUT SCI, V46, P1618, DOI 10.1016/j.procs.2015.02.095
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Jun-Dong Chang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P173, DOI 10.1109/ISNE.2013.6512330
   Kasana G, 2017, OPTIK, V142, P191, DOI 10.1016/j.ijleo.2017.05.027
   Kaushal M, 2018, APPL SOFT COMPUT, V70, P423, DOI 10.1016/j.asoc.2018.05.023
   Kora P, 2020, BIOMED SIGNAL PROCES, V55, P1
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lakshmi C, 2018, COMPUT METH PROG BIO, V159, P11, DOI 10.1016/j.cmpb.2018.02.021
   Lei, 2017, MULTIMED TOOLS APPL, V78, P27085
   Li CD, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P183
   Li CH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1255
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li LD, 2011, AEU-INT J ELECTRON C, V65, P435, DOI 10.1016/j.aeue.2010.06.001
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Loukhaoukha K, 2014, OPTO-ELECTRON REV, V22, P45, DOI 10.2478/s11772-014-0177-z
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609
   Manikandan VM, 2018, COMPUT ELECTR ENG, V72, P614, DOI 10.1016/j.compeleceng.2018.03.007
   Mingzhi C, 2013, J MULTIMEDIA, V8
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P3, DOI 10.1109/MCE.2016.2614375
   Moosazadeh M, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P19, DOI 10.1109/ICWR.2016.7498441
   Naiss I, 2013, IEEE T INFORM THEORY, V59, P760, DOI 10.1109/TIT.2012.2222345
   Nakamoto M, 2008, INT CONF SIGN PROCES, P5, DOI 10.1109/ICOSP.2008.4697055
   Oueslati S., 2010, Int J Image Process, V4, P218
   Pandey HM, 2020, FUTURE GENER COMP SY, V111, P213, DOI 10.1016/j.future.2020.04.034
   Papakostas GA, 2016, COMPLEX INTELL SYST, V2, P205, DOI 10.1007/s40747-016-0023-7
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Rai A, 2010, MULTIMED TOOLS APPL, V76, P18605
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Rajani D, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107556
   Rakhmawati L, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0462-3
   Ramamurthy N., 2012, CONT ENG SCI, V5, P137
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Ramanjaneyulu K., 2013, Int. J. Appl. Innov. Eng. Manag., V2, P445
   Ramly S, 2011, COMM COM INF SC, V194, P372
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Reddy MR, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P126, DOI 10.1109/NETACT.2017.8076754
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Rubio-Hernan J, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0060-9
   Sakr N, 2005, 2005 IEEE International Workshop on Haptic Audio Visual Environments and their Applications, P121
   Sameena Fatima, 2013, INT J COMPUTER APPL, V74, P16, DOI DOI 10.5120/12945-0014
   Sangeetha N, 2018, COMPLEX INTELL SYST, V4, P181, DOI 10.1007/s40747-017-0065-5
   Sathik M.M., 2010, International Journal of Advanced Science and Technology, V24, P61
   Senthilkumaran N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P844, DOI 10.1109/ARTCom.2009.219
   Sharma D, 2016, INT J ADV TECHNOL, V7
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Singh Amit Kumar, 2020, IT Professional, V22, P45, DOI 10.1109/MITP.2019.2961898
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P497, DOI 10.1109/PDGC.2012.6449871
   Singh A, 2017, MIS Q EXEC, V16, P1
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sukanesh R, 2015, ADV INTELL SYST, V325, P17, DOI 10.1007/978-81-322-2135-7_3
   Sundararajan M, 2018, MATER TODAY-PROC, V5, P1138, DOI 10.1016/j.matpr.2017.11.194
   Swain Monalisa, 2020, Machine Learning and Information Processing. Proceedings of ICMLIP 2019. Advances in Intelligent Systems and Computing (AISC 1101), P477, DOI 10.1007/978-981-15-1884-3_43
   Takore Tamirat Tagesse, 2018, International Journal of Intelligent Systems and Applications, V10, P50, DOI 10.5815/ijisa.2018.11.06
   TalatNaheed I, 2014, INTELLIGENT REVERSIB, V125, P2515
   Tamane Sharvari C., 2012, International Journal of Computer Science & Information Technology, V4, P117, DOI 10.5121/ijcsit.2012.4110
   Tanwar Lavi, 2018, 2018 2nd IEEE International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES), P1165, DOI 10.1109/ICPEICES.2018.8897456
   Thakur S., 2018, Cryptographic and Information Security Approaches for Images and Videos, P467
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   Vafaei M, WORLD APPL SCI J, V22, P1572
   Vairaprakash S, 2018, COMPUT ELECTR ENG, V70, P826, DOI 10.1016/j.compeleceng.2017.12.029
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang FX, 2008, INT CONF SIGN PROCES, P2194
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Wang XY, 2009, EXPERT SYST APPL, V36, P9056, DOI 10.1016/j.eswa.2008.12.040
   Wen XB, 2009, SOFT COMPUT, V13, P355, DOI 10.1007/s00500-008-0331-y
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xing Y, 2010, RADIOENGINEERING, V19, P62
   Xiong X., 2015, WORLD J ENG TECHNOL, V3, P177
   Yadav Jyotsna, 2018, Procedia Computer Science, V132, P863, DOI 10.1016/j.procs.2018.05.098
   Yang HY, 2013, ENG APPL ARTIF INTEL, V26, P2058, DOI 10.1016/j.engappai.2013.04.014
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Yang JL, 2019, LECT NOTES COMPUT SC, V11983, P263, DOI 10.1007/978-3-030-37352-8_23
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
   Yu ZX, 2008, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, P12, DOI 10.1109/ICCSIT.2008.194
   Yuan Y, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 2, P175, DOI 10.1109/IMSCCS.2006.187
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang DX, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P608, DOI 10.1109/ICICISYS.2009.5358112
   Zhang J, 2002, IEEE INT C TOOLS ART, P472
   Zhang Yanhong., 2009, Wseas Trans Comput, V8, P174
   Zhang Y, 2019, IEEE INT CONF ELECTR, P41, DOI [10.1109/ICEIEC.2019.8784574, 10.1109/iceiec.2019.8784574]
   Zhao MW, 2008, I C WIREL COMM NETW, P12505
   Zhu H, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1079, DOI 10.1145/3219819.3219826
   2015, CRIT CONSTR, P1
NR 149
TC 45
Z9 46
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30367
EP 30398
DI 10.1007/s11042-020-09606-x
EA AUG 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000564977900001
DA 2024-07-18
ER

PT J
AU Das Adhikary, D
   Gupta, D
AF Das Adhikary, Debjyoti
   Gupta, Deepak
TI Applying over 100 classifiers for churn prediction in telecom companies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Customer churn prediction; Predictive analytics;
   Business intelligence; Operational research
ID CLASSIFICATION; MACHINE
AB In today's date where machine learning is the key to solve so many problems in different fields, one really should know the extent of its importance in their field. One of the major applications of machine learning is Predictive Analytics. Churn prediction is one of the key steps for customer retention in this saturating market scenario [31]. This is one of the major objectives and any toolkit which can give insights on this can be really beneficial for any service providing companies. Furthermore, one of the major problems that business analysts face during this procedure is to decide which classifier to select. In the continuously evolving field of machine learning where developers are constantly coming up with new machine learning algorithms, it is often difficult for the analysts to have knowledge about the varied options. In our work, we try to analyze and compare the performance of over 100 classifiers in churn prediction of a telecom company. We have used renowned classifiers from different families. This work can serve as the first step for any data scientist who wants to develop a churn prediction system for their application. Also, we try to explore efficient algorithms that will give a better result. Churn prediction is a mildly imbalanced set of the problem which degrade the performance of classifiers. The highest accuracy is given by the Regularized Random Forest classifier. Since the problem is imbalanced, we also consider the area under the Receiver Operating Characteristic (ROC) curve and the classifier Bagging Random Forest produces the best result in this scenario.
C1 [Das Adhikary, Debjyoti; Gupta, Deepak] Natl Inst Technol, Dept Comp Sci & Engn, Yupia, Arunachal Prade, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh
RP Gupta, D (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Yupia, Arunachal Prade, India.
EM djnaruto007@gmail.com; deepakjnu85@gmail.com
RI Gupta, Deepak/H-4151-2019
OI Gupta, Deepak/0000-0002-6375-8615
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   [Anonymous], 2014, Applied Predictive Analytics: Principles and Techniques for the Professional Data Analyst
   [Anonymous], 2015, RSTUDIO INT DEV R
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   [Anonymous], 2008, LIBLINEAR LIB LARGE
   [Anonymous], 1997, P ICML 97 P 14 INT C
   Borah P, 2019, NEURAL COMPUT APPL, P1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Castro EG, 2015, IEEE T COMP INTEL AI, V7, P255, DOI 10.1109/TCIAIG.2015.2401979
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cleary S, 1995, EDUCATIONAL INNOVATION IN ECONOMICS AND BUSINESS ADMINISTRATION, P108
   Cohen W.W., 1995, P 12 INT C MACH LEAR, P115, DOI [DOI 10.1016/B978-1-55860-377-6.50023-2, 10.1016/B978-1-55860-377-6.50023-2]
   Dalvi PK, 2016, 2016 SYMPOSIUM ON COLOSSAL DATA ANALYSIS AND NETWORKING (CDAN)
   Dong L, 2005, LECT NOTES ARTIF INT, V3721, P84
   Farquad M.A.H., 2012, INT J ELECT CUSTOMER, V48, P6
   Fernández A, 2010, INFORM SCIENCES, V180, P1268, DOI 10.1016/j.ins.2009.12.014
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P144
   Frank E., 2003, Proceedings of the Conference on Uncertainty in Artificial Intelligence, P249
   Frank Eibe, 2001, EUR C MACH LEARN, P145, DOI 10.1007/3-540-44795-413
   Frank EN, 2001, EAAP PUBLIC, P63
   Frank J, 2014, APPL NUMER HARMON AN, P1, DOI 10.1007/978-1-4614-9521-5_1
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932
   Huang G., 2004, 2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No. 04CH37541), V2
   Idris Adnan, 2012, 2012 IEEE INT C SYST
   Ismail M R., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P213, DOI [10.14257/ijmue.2015.10.7.22, DOI 10.14257/IJMUE.2015.10.7.22]
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174
   Kohavi R., 1995, WRAPPERS PERFORMANCE
   Kumar Krishan, 2013, CUSTOMER RETENTION S
   Kumar MA, 2009, EXPERT SYST APPL, V36, P7535, DOI 10.1016/j.eswa.2008.09.066
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Melville P., 2003, In: International Joint Conference on Artificial Intelligence, V3, P505
   Mozer Michael, 1999, P NEUR INF PROC SYST
   Nasiri JA, 2015, PATTERN RECOGN, V48, P984, DOI 10.1016/j.patcog.2014.09.020
   Pamina, 2018, TELECOM CHURN TERADA
   PAO YH, 1992, COMPUTER, V25, P76, DOI 10.1109/2.144401
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peng XJ, 2016, INFORM SCIENCES, V340, P86, DOI 10.1016/j.ins.2016.01.023
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Quinlan John R, 1992, 5 AUSTR JOINT C ART, V92
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   Richeldi Marco, 2002, CHURN ANAL CASE STUD, V17, P2
   Richhariya B, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107150
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Richhariya B, 2018, 2018 IEEE S SERIES C
   Rodríguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Savitha R, 2012, INFORM SCIENCES, V187, P277, DOI 10.1016/j.ins.2011.11.003
   Seni G., 2010, Ensemble Methods in Data Mining: Improving Accuracy through Combining Predictions
   Shankar K, 2020, J AMB INTEL HUM COMP, V11, P1821, DOI 10.1007/s12652-018-1161-0
   Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540
   Sharma S., 2019, IEEE T SYSTEMS MAN C
   Sumner M, 2005, LECT NOTES ARTIF INT, V3721, P675
   Suresh S, 2008, INFORM SCIENCES, V178, P2621, DOI 10.1016/j.ins.2008.02.009
   Tanveer M, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3344998
   Tanveer M, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105617
   Tanveer M, 2019, APPL SOFT COMPUT, V78, P164, DOI 10.1016/j.asoc.2019.02.022
   Tanveer M, 2016, APPL INTELL, V45, P174, DOI 10.1007/s10489-015-0751-1
   Vafeiadis T, 2015, SIMUL MODEL PRACT TH, V55, P1, DOI 10.1016/j.simpat.2015.03.003
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Webb Geoffrey I., 2000, MACHINE LEARNING, V40
   Witten I.H., 2005, PRACTICAL MACHINE LE, V2
   Xie YY, 2009, EXPERT SYST APPL, V36, P5445, DOI 10.1016/j.eswa.2008.06.121
   ZHAO Y, 2005, LECT NOTES COMPUTER
NR 67
TC 17
Z9 17
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35123
EP 35144
DI 10.1007/s11042-020-09658-z
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000562943300003
DA 2024-07-18
ER

PT J
AU Ke, SF
   Hu, RM
   Wang, XC
   Wu, TZ
   Li, G
   Wang, ZY
AF Ke, Shanfa
   Hu, Ruimin
   Wang, Xiaochen
   Wu, Tingzhao
   Li, Gang
   Wang, Zhongyuan
TI Single Channel multi-speaker speech Separation based on quantized ratio
   mask and residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-speaker; Speech separation; Deep clustering; Quantized; IRM;
   Residual network
ID FEATURES
AB The recently-proposed deep clustering-based algorithms represent a fundamental advance towards the single-channel multi-speaker speech sep- aration problem. These methods use an ideal binary mask to construct the objective function and K-means clustering method to estimate the ideal bina- ry mask. However, when sources belong to the same class or the number of sources is large, the assumption that one time-frequency unit of the mixture is dominated by only one source becomes weak, and the IBM-based separation causes spectral holes or aliasing. Instead, in our work, the quantized ideal ratio mask was proposed, the ideal ratio mask is quantized to have the output of the neural network with a limited number of possible values. Then the quan- tized ideal ratio mask is used to construct the objective function for the case of multi-source domination, to improve network performance. Furthermore, a network framework that combines a residual network, a recurring network, and a fully connected network was used for exploiting correlation information of frequency in our work. We evaluated our system on TIMIT dataset and show 1.6 dB SDR improvement over the previous state-of-the-art methods.
C1 [Ke, Shanfa; Hu, Ruimin; Wang, Xiaochen; Wu, Tingzhao; Li, Gang; Wang, Zhongyuan] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Ke, Shanfa; Hu, Ruimin; Wang, Xiaochen] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
   [Wu, Tingzhao; Li, Gang; Wang, Zhongyuan] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China.; Hu, RM (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
EM hrm@whu.edu.cn
RI Wang, Zhongyuan/ABD-2189-2020
FU National Key R&D Program of China [2017YFB1002803]; National Nature
   Science Foundation of China [61761044]; Hubei Province Technological
   Innovation Major Project [2017AAA123]
FX This research is partially supported by the National Key R&D Program of
   China (No. 2017YFB1002803), National Nature Science Foundation of China
   (No.U1736206, No. 61761044), Hubei Province Technological Innovation
   Major Project (No. 2017AAA123).
CR Aihara R, 2019, INT CONF ACOUST SPEE, P690, DOI [10.1109/icassp.2019.8682695, 10.1109/ICASSP.2019.8682695]
   [Anonymous], 1993, NASA STIRECON TECH R, V93, DOI DOI 10.6028/NIST.IR.4930
   Bregman A. S., 1990, Auditory Scene Analysis: The Perceptual Organization of Sound, DOI [10.7551/mitpress/1486.001.0001, DOI 10.7551/MITPRESS/1486.001.0001]
   Chan TST, 2016, IEEE SIGNAL PROC LET, V23, P287, DOI 10.1109/LSP.2016.2514845
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Du J, 2016, IEEE-ACM T AUDIO SPE, V24, P1424, DOI 10.1109/TASLP.2016.2558822
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Hasegawa-Johnson M, 2014, AC SPEECH SIGN PROC, p1562C
   Healy EW, 2017, J ACOUST SOC AM, V141, P4230, DOI 10.1121/1.4984271
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hu K, 2013, IEEE T AUDIO SPEECH, V21, P120, DOI 10.1109/TASL.2012.2215591
   Hummersone C, 2014, SIGNALS COMMUN TECHN, P349, DOI 10.1007/978-3-642-55016-4_12
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Isik Y, 2016, INTERSPEECH, P545, DOI 10.21437/Interspeech.2016-1176
   Itakura K, 2018, IEEE-ACM T AUDIO SPE, V26, P831, DOI 10.1109/TASLP.2017.2789320
   Rodríguez-Serrano FJ, 2014, MULTIMED TOOLS APPL, V72, P925, DOI 10.1007/s11042-013-1398-8
   Ke SF, 2019, IEEE INT CON MULTI, P1414, DOI 10.1109/ICME.2019.00245
   Kolbæk M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Le Roux J, 2019, IEEE J-STSP, V13, P370, DOI 10.1109/JSTSP.2019.2904183
   Li JY, 2014, IEEE-ACM T AUDIO SPE, V22, P745, DOI 10.1109/TASLP.2014.2304637
   Li XF, 2019, IEEE-ACM T AUDIO SPE, V27, P645, DOI 10.1109/TASLP.2019.2892412
   Lu R, 2018, IEEE SIGNAL PROC LET, V25, P1315, DOI 10.1109/LSP.2018.2853566
   Luo Y, 2017, AC SPEECH SIGN PROC, p246C
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P382, DOI 10.1109/TASL.2009.2029711
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038
   Oord A., 2016, ARXIV160903499
   Pedersen MS., 2006, SOURCE SEPARATION HE
   Raffel Colin, 2014, P 15 INT SOC MUS INF, P84
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Venkatesan R, 2018, MULTIMED TOOLS APPL, V77, P20129, DOI 10.1007/s11042-017-5458-3
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Virtanen T, 2013, IEEE T AUDIO SPEECH, V21, P2277, DOI 10.1109/TASL.2013.2263144
   Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459
   Wang ZQ, 2019, INT CONF ACOUST SPEE, P71, DOI 10.1109/ICASSP.2019.8683231
   Wang ZQ, 2018, INTERSPEECH, P2718, DOI 10.21437/Interspeech.2018-1940
   Wang ZQ, 2018, INTERSPEECH, P2708, DOI 10.21437/Interspeech.2018-1629
   Wang ZQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P686, DOI 10.1109/ICASSP.2018.8462507
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Yul D, 2017, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2017.7952154
   Zhang XL, 2016, IEEE-ACM T AUDIO SPE, V24, P967, DOI 10.1109/TASLP.2016.2536478
NR 45
TC 1
Z9 1
U1 5
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32225
EP 32241
DI 10.1007/s11042-020-09419-y
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300006
DA 2024-07-18
ER

PT J
AU Kim, DY
   Park, JH
   Lee, Y
   Kim, S
AF Kim, Dae-Young
   Park, Ji-Hoon
   Lee, Youngchan
   Kim, Seokhoon
TI Network virtualization for real-time processing of object detection
   using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network virtualization; Real-time processing; Object detection; Deep
   learning
AB These days, networked cameras are used in various applications using deep learning. In particular, as the deep learning technology for image processing develops, image-based application services using networked camera are expanding. Object detections are the representative application in the image-based applications. Images from the networked camera are transmitted to a deep learning machine, which performs object detection using a deep neural network (DNN) algorithm. For real-time processing of the object detection, lightweight of the image learning steps is needed. Both preprocessing of training sets and lightweight learning models can reduce computing loads for image learning. However, it is most important to receive video frames from the network camera without delay. In this paper, we provide a way for the learning machine to receive video frames with minimal delay. The proposed method is a kind of network virtualization for image-based object detection. It monitors network the status of available network interfaces in networked cameras. When a camera transmit video frames, the virtualized module determines the appropriate network interface to reduce delay. The performance of the proposed method is evaluated in the image-based object detection system using deep learning.
C1 [Kim, Dae-Young; Park, Ji-Hoon; Lee, Youngchan] Daegu Catholic Univ, Sch Comp Software, Gyongsan 38430, South Korea.
   [Kim, Seokhoon] Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
C3 Catholic University of Daegu; Soonchunhyang University
RP Kim, S (corresponding author), Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
EM kimdy81@cu.ac.kr; wlgns12www@cu.ac.kr; dldudcks@cu.ac.kr;
   seokhoon@sch.ac.kr
OI Kim, Seokhoon/0000-0002-7919-6557; Kim, Dae-Young/0000-0003-4901-3075
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2020R1I1A3066543];
   Soonchunhyang University Research Fund
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(NRF-2020R1I1A3066543), and this work was supported by the
   Soonchunhyang University Research Fund.
CR Blenk A, 2016, IEEE COMMUN SURV TUT, V18, P655, DOI 10.1109/COMST.2015.2489183
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Keras, 2020, KERAS
   Kim DY, 2019, KSII T INTERNET INF, V13, P1599, DOI 10.3837/tiis.2019.03.027
   Kim DY, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/6195024
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Monsanto C., 2013, NSDI, V13, P1, DOI 10.1002/pmic.201300387.This
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Xia WF, 2015, IEEE COMMUN SURV TUT, V17, P27, DOI 10.1109/COMST.2014.2330903
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
NR 15
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35851
EP 35869
DI 10.1007/s11042-020-09603-0
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000561518100002
DA 2024-07-18
ER

PT J
AU Mary, NAB
   Singh, AR
   Athisayamani, S
AF Mary, Ani Brown N.
   Singh, Robert A.
   Athisayamani, Suganya
TI Banana leaf diseased image classification using novel HEAP auto encoder
   (HAE) deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Banana leaf diseases; Deep learning; Classification; Auto encoder
ID PLANT-DISEASE
AB Among the fruit harvest, banana is one of the most significant crops in the international business for yielding the foreign exchange in many African countries. Nowadays, banana leaf diseases are the most significant factors regarding agricultural goods. These diseases result in a severe decline in the quantity and quality of agricultural food. Moreover, early recognition and classification of these banana leaf diseases are much needed. In this work, a novel deep learning technique called Heap Auto Encoders (HAEs) has been proposed. This proposed method can straightly extract important features and reduce the exhausted use of handcrafted features. Besides, over fitting difficulty in the training method is reduced, and the performance for a small training set is improved. The dropout method and the Rectified Linear Units (ReLU) activation function are also applied in HAE. The results of the proposed technique indicate that the proposed method is superior to traditional techniques. This framework provides the highest classification accuracy of 99.35% for real data sets.
C1 [Mary, Ani Brown N.] Sarah Tucker Coll, Comp Sci, Plot 6,7 KLN Colony, Tirunelveli 627007, Tamil Nadu, India.
   [Singh, Robert A.] Kalasalingam Acad Res & Educ, Sch Comp, Krishnankoil, Tamil Nadu, India.
   [Athisayamani, Suganya] Sastra Deemed Be Univ, Sch Comp, Plot 6,7 KLN Colony, Thanjavur, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education; Shanmugha Arts, Science,
   Technology & Research Academy (SASTRA)
RP Mary, NAB (corresponding author), Sarah Tucker Coll, Comp Sci, Plot 6,7 KLN Colony, Tirunelveli 627007, Tamil Nadu, India.
EM anibrownvimal@gmail.com
RI Mary, Ani Brown/AAZ-5896-2020; Robert Singh, A./AAH-9208-2021
OI A, Robert Singh/0000-0001-5485-2186; Athisayamani,
   Suganya/0000-0002-4349-8836
CR Akila, 2018, INT J ENG RES TECHNO, V6
   Amara J., 2017, DATENBANKSYSTEME BUS
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Chen D, 2008, EXPECTATION MAXIMIZA
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Devi R, 2016, INT J LATEST TECHNOL, P55
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Harvey CA, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0089
   Liu G, 2018, HINDAWI MATH PROBLEM
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Owomugisha G, 2014, 1 INT C US MOB ICT A
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Patil R., 2019, J Emerg Technol Innov Res, V6, P151
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Raut S P., 2004, Diseases of Fruits and Vegetables: Volume II: Diagnosis and Management, P37, DOI DOI 10.1007/1-4020-2607-2_2
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Shirahatti J, 2018, P INT C COMM EL SYST
   Strange RN, 2005, PHYTOPATHOLOGY, V43
   Tai APK, 2014, NAT CLIM CHANGE, V4, P817, DOI [10.1038/nclimate2317, 10.1038/NCLIMATE2317]
   Türkoglu M, 2019, TURK J ELECTR ENG CO, V27, P1636, DOI 10.3906/elk-1809-181
   Venkataramanan A., 2019, Int. J. Comput. Sci. Eng., V11, P40
   Vipinadas M.J., 2016, INT J ADV ENG RES SC, V3, P120
   Wang Sida, 2013, P INT C MACH LEARN, P118
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
NR 29
TC 18
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30601
EP 30613
DI 10.1007/s11042-020-09521-1
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559655200001
DA 2024-07-18
ER

PT J
AU Rescigno, M
   Spezialetti, M
   Rossi, S
AF Rescigno, Martina
   Spezialetti, Matteo
   Rossi, Silvia
TI Personalized models for facial emotion recognition through transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial emotion recognition; Convolutional neural networks; Transfer
   learning; Affective computing
ID EXPRESSION RECOGNITION
AB Emotions represent a key aspect of human life and behavior. In recent years, automatic recognition of emotions has become an important component in the fields of affective computing and human-machine interaction. Among many physiological and kinematic signals that could be used to recognize emotions, acquiring facial expression images is one of the most natural and inexpensive approaches. The creation of a generalized, inter-subject, model for emotion recognition from facial expression is still a challenge, due to anatomical, cultural and environmental differences. On the other hand, using traditional machine learning approaches to create a subject-customized, personal, model would require a large dataset of labelled samples. For these reasons, in this work, we propose the use of transfer learning to produce subject-specific models for extracting the emotional content of facial images in the valence/arousal dimensions. Transfer learning allows us to reuse the knowledge assimilated from a large multi-subject dataset by a deep-convolutional neural network and employ the feature extraction capability in the single subject scenario. In this way, it is possible to reduce the amount of labelled data necessary to train a personalized model, with respect to relying just on subjective data. Our results suggest that generalized transferred knowledge, in conjunction with a small amount of personal data, is sufficient to obtain high recognition performances and improvement with respect to both a generalized model and personal models. For both valence and arousal dimensions, quite good performances were obtained (RMSE = 0.09 and RMSE = 0.1 for valence and arousal, respectively). Overall results suggested that both the transferred knowledge and the personal data helped in achieving this improvement, even though they alternated in providing the main contribution. Moreover, in this task, we observed that the benefits of transferring knowledge are so remarkable that no specific active or passive sampling techniques are needed for selecting images to be labelled.
C1 [Rescigno, Martina; Spezialetti, Matteo; Rossi, Silvia] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
C3 University of Naples Federico II
RP Rossi, S (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
EM silvia.rossi@unina.it
RI Rossi, Silvia/C-2615-2008
OI Rossi, Silvia/0000-0002-3379-1756; Spezialetti,
   Matteo/0000-0001-5786-3999
FU Universita degli Studi di Napoli Federico II within the CRUI-CARE
   Agreement
FX Open access funding provided by Universita degli Studi di Napoli
   Federico II within the CRUI-CARE Agreement.
CR Arriaga O., 2019, 27 EUROPEAN S ARTIFI, P221
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Chang WY, 2017, IEEE COMPUT SOC CONF, P1963, DOI 10.1109/CVPRW.2017.246
   Chao L, 2015, P 5 INT WORKSH AUD V, P65, DOI [DOI 10.1145/2808196.2811634, 10.1145/2808196.2811634]
   Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P, 1997, NONVERBAL COMMUNICAT, P27, DOI DOI 10.4324/9781351243131-3
   Feffer M., 2018, INT C MACH LEARN DAT, P316, DOI [10.1007/978-3-319-96133-0_24, DOI 10.1007/978-3-319-96133-0_24]
   Gal Yarin, 2016, Uncertainty in deep learning
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo R, 2013, INT CONF PER COMP, P436, DOI 10.4108/icst.pervasivehealth.2013.252133
   Harris JM, 2018, J CONSUM BEHAV, V17, P239, DOI 10.1002/cb.1710
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Hasani B, 2017, IEEE COMPUT SOC CONF, P1955, DOI 10.1109/CVPRW.2017.245
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Izquierdo-Reyes J, 2018, INT J INTERACT DES M, V12, P1447, DOI 10.1007/s12008-018-0473-9
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jian-De Li, 2017, 2017 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT), DOI 10.1109/DFT.2017.8244448
   Jiang J, 2008, TECHNICAL REPORT
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kohavi R., 1995, STUDY CROSS VALIDATI, DOI DOI 10.1067/MOD.2000.109031
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuhn M, 2013, Applied predictive modeling, P600, DOI [10.1007/978-1-4614-6849-3, 10.1007/978-1-4614-6849-3_3]
   Lench HC, 2011, PSYCHOL BULL, V137, P834, DOI 10.1037/a0024244
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Lindquist KA, 2013, PSYCHOL BULL, V139, P255, DOI 10.1037/a0029038
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Picard R. W., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P829
   Plutchik R, 1980, THEORIES EMOTION
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Ringeval F, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1335, DOI 10.1145/2733373.2806408
   Rossi S, 2018, IEEE ROMAN, P522, DOI 10.1109/ROMAN.2018.8525514
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salovey P, 1990, IMAG COGN PERS, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG]
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sayette MA, 2012, PSYCHOL SCI, V23, P869, DOI 10.1177/0956797611435134
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Soleymani M, 2014, IEEE INT CON MULTI
   Soleymani M, 2012, IEEE SYS MAN CYBERN, P3304, DOI 10.1109/ICSMC.2012.6378301
   Spezialetti M, 2018, BEHAV INFORM TECHNOL, V37, P855, DOI 10.1080/0144929X.2018.1485745
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Susskind J, 2010, 2010001 UTML TR
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tomkins S. S., 2008, Affect, imagery, consciousness: The complete edition
   Trnka R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00522
   Tsymbalov Evgenii, 2018, Analysis of Images, Social Networks and Texts. 7th International Conference, AIST 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11179), P247, DOI 10.1007/978-3-030-11027-7_24
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Verschuere B, 2006, PSYCHOL BELG, V46, P99, DOI 10.5334/pb-46-1-2-99
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wager S., 2013, Advances in Neural Information Processing Systems
   Walecki R., 2017, IMAVIS IN PRESS, V259, P143
   Wu DR, 2019, INFORM SCIENCES, V474, P90, DOI 10.1016/j.ins.2018.09.060
   Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P1980, DOI 10.1109/CVPRW.2017.248
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
NR 81
TC 15
Z9 16
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35811
EP 35828
DI 10.1007/s11042-020-09405-4
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000559430400004
OA hybrid
DA 2024-07-18
ER

PT J
AU Lakshmi, MD
   Murugan, SS
AF Lakshmi, M. Dhana
   Murugan, S. Sakthivel
TI Keypoint-based mapping analysis on transformed Side Scan Sonar images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keypoint detection; Point mapping; Repeatability rate; Mapping rate
ID CLASSIFICATION
AB In recent years, detecting wrecks and submerged sites is a challenging task and time-consuming. A fine technique is required to pick out features from the sea-floor. Side Scan Sonar (SSS) has been used for underwater imaging to detect submerged objects on the sea-floor. Due to the rotational and translational instabilities of SSS tow-fish, the acquired SSS images may be distorted. Hence, this paper concentrates on the geometric transformation analysis for different shadows of SSS images. Based on the intensity-based threshold method, the SSS images are classified as high-shadows, low-shadows, no-shadows, and semi-shadows. Different keypoint detector and mapping algorithms are considered for the extraction of keypoints (features) and matching of those detected points. The point mapping performance was evaluated using Repeatability rate and Mapping rate. It is observed that the Mapping rate of 98.7% is obtained using Scale Invariant Feature Transform (SIFT) with Fast Library for Approximate Nearest Neighbor Search (FLANN) and RANdom Sample Consensus (RANSAC). It is also inferred that the Repeatability rate is 0.8 using Oriented FAST & Rotated BRIEF (ORB) compared with other algorithms considered.
C1 [Lakshmi, M. Dhana; Murugan, S. Sakthivel] SSN Coll Engn, Dept Elect & Commun Engn, Underwater Acoust Res Lab, Chennai 603110, Tamil Nadu, India.
C3 SSN College of Engineering
RP Murugan, SS (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Underwater Acoust Res Lab, Chennai 603110, Tamil Nadu, India.
EM mdhanalakshmi@ssn.edu.in; sakthivels@ssn.edu.in
RI M, Dhana Lakshmi/HNP-4203-2023; S, Sakthivel Murugan/JZD-2226-2024
OI M, Dhana Lakshmi/0000-0001-7233-9255; Santhanam, Dr.Sakthivel
   Murugan/0000-0002-3777-8807
FU Department of Science and Technology (DST) under SSTP
   [DST/SSTP/Tamilnadu/102/2017-18]; DST
FX This work is a part of project funded by Department of Science and
   Technology (DST) under SSTP. Grant No: DST/SSTP/Tamilnadu/102/2017-18.
   The authors wish to thank DST for their support.
CR [Anonymous], 2019, SIDE SCAN SONAR
   [Anonymous], P 8 IND C COMP VIS G
   [Anonymous], 2010, INT J COMPUT SCI ENG
   [Anonymous], 2018, SID SCAN SON
   Anoopa S, 2016, PROC TECH, V24, P1358, DOI 10.1016/j.protcy.2016.05.148
   Artur G, 2015, OCEAN ENG, V109, P439, DOI 10.1016/j.oceaneng.2015.09.026
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Clay C.S., 1977, ACOUSTICAL OCEANOGRA
   COBRA DT, 1992, IEEE J OCEANIC ENG, V17, P252, DOI 10.1109/48.153442
   Das S., 2013, International Journal of Engineering Trends and Technology (IJETT), V4, P1764
   Denbigh PN, 1982, RECENT DEV SIDE SCAN, P81
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Herath Mudiyanselage DD, 2018, THESIS
   IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]
   Jiang C., 1992, SHADOW IDENTIFICATIO
   JIANG CX, 1994, CVGIP-IMAG UNDERSTAN, V59, P213, DOI 10.1006/ciun.1994.1014
   Khidkikar Mahesh, 2012, Intelligent Robotics and Applications. Proceedings of the 5th International Conference, ICIRA 2012, P367, DOI 10.1007/978-3-642-33509-9_36
   Klein M., 2002, International Handbook of Underwater Archaeology, P667, DOI [DOI 10.1007/978-1-4615-0535-839, DOI 10.1007/978-1-4615-0535-8_39, 10.1007/978-1-4615-0535-8_39]
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin CY, 2000, PROC SPIE, V3971, P90, DOI 10.1117/12.385012
   Raju P. D. R., 2012, Int. J. Comput. Sci. Eng. Technol, V2, P776
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salvador E, 2001, INT CONF ACOUST SPEE, P1545, DOI 10.1109/ICASSP.2001.941227
   Shivratriwar NM, 2012, INT J ADV RES COMPUT
   Singh N, 2014, IJARCET, V3
   Tao WL, 2018, IET IMAGE PROCESS, V12, P194, DOI 10.1049/iet-ipr.2017.0172
   Tareen S.A.K., 2018, 2018 INT C COMPUTING, P1, DOI DOI 10.1109/ICOMET.2018.8346440
   Tedzuwan R, 2015, SIGNAL IMAGE PROCESS, P447
NR 28
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26703
EP 26733
DI 10.1007/s11042-020-09247-0
EA JUL 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700007
OA Bronze
DA 2024-07-18
ER

PT J
AU Yeh, IC
   Lin, SS
   Hung, ST
   Lee, TY
AF Yeh, I-Cheng
   Lin, Shih-Syun
   Hung, Shuo-Tse
   Lee, Tong-Yee
TI Disparity-preserving image rectangularization for stereoscopic panorama
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video processing; Stereoscopic panorama; Image warping; Disparity
   preserving
AB This study aims at generating a long strip stereoscopic panorama with a rectangular boundary from a stereoscopic video. The issues arising from this goal are how to automatically select appropriate frames to reduce geometric distortion in image stitching, how to preserve disparity under image warping, and how to generate a rectangular panoramic stereoscopic image without the loss of boundary information. To deal with these issues and to generate visually smooth stereoscopic panorama, a disparity-aware image warping is proposed. Moreover, the image warping method is performed on the irregular left and right panoramic images simultaneously with a hybrid control mesh to generate a rectangular panorama while preserving the spatial shape and disparity as much as possible. Experimental results on various stereo video contents show that the proposed method can effectively preserve both the spatial shapes and pixel disparity.
C1 [Yeh, I-Cheng] Yuan Ze Univ, Taoyuan, Taiwan.
   [Lin, Shih-Syun] Natl Taiwan Ocean Univ, Keelung, Taiwan.
   [Hung, Shuo-Tse] MStar Semicond Inc, Hsinchu, Taiwan.
   [Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan, Taiwan.
C3 Yuan Ze University; National Taiwan Ocean University; National Cheng
   Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.
EM ichenyeh@saturn.yzu.edu.tw; linss@mail.ntou.edu.tw;
   hungshoutse@gmail.com; tonylee@mail.ncku.edu.tw
RI Lin, Shih-Syun/ABD-8570-2020
OI Lin, Shih-Syun/0000-0002-8360-5819
FU Ministry of Science and Technology [108-2221-E-155-033-MY2,
   108-2221-E-019-038-MY2, 108-2221-E-006-038-MY3, 107-2221-E-006-196-MY3]
FX We thank the anonymous reviewers for valuable comments and Cheng-Yue Qiu
   and Yun-Chen Lin for taking some exprimental videos and preproessing
   results. This work was supported by Ministry of Science and Technology
   under no. 108-2221-E-155-033-MY2, 108-2221-E-019-038-MY2,
   108-2221-E-006-038-MY3 and 107-2221-E-006-196-MY3.
CR Agarwala A, 2005, ACM T GRAPHIC, V24, P821, DOI 10.1145/1073204.1073268
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barron JT, 2016, LECT NOTES COMPUT SC, V9907, P617, DOI 10.1007/978-3-319-46487-9_38
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Capeto U, 2019, 3D STEREOSCOPIC PHOT
   Capeto U, 2014, DEPTH MAP AUTOMATIC
   Capeto U, 2015, DEPTH MAP AUTOMATIC
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   He KM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462004
   Jin Y, 2010, VISUAL COMPUT, V26, P769, DOI 10.1007/s00371-010-0472-8
   Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366150
   Lin SS, 2016, IEEE T CIRC SYST VID, V26, P801, DOI 10.1109/TCSVT.2015.2409711
   Lin SS, 2014, IEEE T CIRC SYST VID, V24, P759, DOI 10.1109/TCSVT.2013.2291282
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu F., 2008, P 16 ACM INT C MULTI, P329
   Niu YZ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366202
   Oettermann Stephan., 1997, PANORAMA HIST MASS M
   Rhemann C, 2012, CVPR
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Yan Tao., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, VRST '13, P251
   Yan WQ, 2017, IEEE T CIRC SYST VID, V27, P1934, DOI 10.1109/TCSVT.2016.2564838
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang F, 2015, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2015.7298811
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
NR 32
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26123
EP 26138
DI 10.1007/s11042-020-09159-z
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547247600004
DA 2024-07-18
ER

PT J
AU Rashwan, HA
   Garcia, MA
   Abdulwahab, S
   Puig, D
AF Rashwan, Hatem A.
   Angel Garcia, Miguel
   Abdulwahab, Saddam
   Puig, Domenec
TI Action representation and recognition through temporal co-occurrence of
   flow fields and convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Temporal co-occurrence; Optical flow fields;
   Principal component analysis; Support vector machine; Convolutional
   neural networks CNN; Deep learning models
ID GAIT REPRESENTATION; IMAGE; DESCRIPTORS; DENSE
AB Many applications require action recognition skills, from human-machine interaction to intelligent video surveillance. Action recognition in video sequences cannot be based on simply processing raw color images or optical flow fields. Color images provide appearance information of moving objects, but lack motion features. They are also very sensitive to variations due to clothing and camera pose that badly affect the action recognition accuracy. In turn, raw optical flow measures instantaneous motion, not the overall dynamics of actions, and is sensitive to noise. More robust and meaningful motion features and classifiers are thus required for action recognition to be reliable. This paper proposes a new action recognition technique based on a deep convolutional neural network (CNN) fed with Histograms of Optical Flow Co-Occurrence (HOF-CO) motion features. HOF-CO is a robust motion representation previously proposed by the authors to encode the relative frequency of pairs of optical flow directions computed at each image pixel. Experimental results show that this approach outperforms state-of-the-art action recognition methods on three different public datasets KTH, UCF-11 Youtube and HOLLYWOOD2.
C1 [Rashwan, Hatem A.; Abdulwahab, Saddam; Puig, Domenec] Univ Rovira & Virgili, Dept Comp Engn & Math, Tarragona, Spain.
   [Angel Garcia, Miguel] Univ Autnoma Madrid, Dept Elect & Commun Technol, Madrid, Spain.
C3 Universitat Rovira i Virgili
RP Rashwan, HA (corresponding author), Univ Rovira & Virgili, Dept Comp Engn & Math, Tarragona, Spain.
EM hatem.abdellatif@urv.cat; miguelangel.garcia@uam.es;
   saddam.abdulwahab@urv.cat; domenec.puig@urv.cat
RI Rashwan, Hatem A./P-5760-2016; Rashwan, Hatem A./S-2181-2019; Garcia,
   Miguel Angel/C-4304-2014
OI Rashwan, Hatem A./0000-0001-5421-1637; Garcia, Miguel
   Angel/0000-0003-2611-6821
CR Ahmed I, 2018, IEEE INTERNET THINGS, V5, P1598, DOI 10.1109/JIOT.2017.2787779
   Ali S, 2007, INT J KNOWL-BASED IN, V11, P1
   [Anonymous], 2016, LONG TERM TEMPORAL C
   Bashir K, 2009, P BRIT MACH VIS C 1
   BenAbdelkader C, 2001, LECT NOTES COMPUT SC, V2091, P284
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Castro FM, 2014, INT C PATT RECOG, P1692, DOI 10.1109/ICPR.2014.298
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Das Choudhury S, 2013, COMPUT VIS IMAGE UND, V117, P1770, DOI 10.1016/j.cviu.2013.08.003
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hayder Ali CAEGM, 2011, INT J SIGNAL PROCESS, V4, P3141
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He WH, 2010, INT CONF COMP SCI, P78, DOI 10.1109/ICCSIT.2010.5564509
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kovac J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/484320
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P822, DOI 10.1016/j.jvcir.2014.01.012
   Lee H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/384384
   Lu JY., 2016, MATH PROBL ENG, V2016, DOI DOI 10.1155/2016/3195492
   McLaughlin N, 2017, IEEE T CIRC SYST VID, V27, P525, DOI 10.1109/TCSVT.2016.2619498
   Misra Ishan., 2016, Unsupervised learning using sequential veri cation for action recognition
   Paszke Adam, 2017, Pytorch
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Rahmani H, 2016, LEARNING DEEP MODEL, Vabs/1602.00828
   Rashwan HA, 2019, MACH VISION APPL, V30, P139, DOI 10.1007/s00138-018-0982-3
   Rashwan HA, 2013, IEEE T IMAGE PROCESS, V22, P2589, DOI 10.1109/TIP.2013.2253481
   Rashwan HA, 2012, COMPUT VIS IMAGE UND, V116, P953, DOI 10.1016/j.cviu.2012.04.006
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Subetha T, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu ZX, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P791, DOI 10.1145/2964284.2964328
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
NR 42
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34141
EP 34158
DI 10.1007/s11042-020-09194-w
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000544843700001
DA 2024-07-18
ER

PT J
AU Wu, YQ
   Li, ZY
   Chen, Y
   Nai, K
   Yuan, J
AF Wu, Yiqiang
   Li, Zhiyong
   Chen, Ying
   Nai, Ke
   Yuan, Jin
TI Real-time traffic sign detection and classification towards real traffic
   scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic sign recognition; Small object detection; Data augmentation;
   Image synthesis
ID RECOGNITION
AB In this paper we propose a real-time traffic sign recognition algorithm which is robust to the small-sized objects and can identify all traffic sign categories. Specifically, we present a two-level detection framework which consists of the region proposal module(RPM) which is responsible for locating the objects and the classification module(CM) which aims to classify the located objects. In addition, to solve the problem of insufficient samples, we present an effective data augmentation method based on traffic sign logo to generate enough training data. The experiments are conducted in TT100k, and the results show the superiority of our method.
C1 [Wu, Yiqiang; Li, Zhiyong; Chen, Ying; Nai, Ke; Yuan, Jin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Wu, Yiqiang; Li, Zhiyong; Chen, Ying; Nai, Ke; Yuan, Jin] Key Lab Embedded & Network Comp Hunan Prov, Changsha, Peoples R China.
C3 Hunan University
RP Li, ZY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.; Li, ZY (corresponding author), Key Lab Embedded & Network Comp Hunan Prov, Changsha, Peoples R China.
EM zhiyong.li@hnu.edu.cn
RI li, zy/HZM-1892-2023; Wang, Zejun/KBB-8454-2024; wu, yi/JEP-1581-2023;
   Zhang, Yanchao/JMB-7717-2023
CR [Anonymous], PROC CVPR IEEE
   Bahlmann C, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P255
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Berkaya SK, 2016, EXPERT SYST APPL, V48, P67, DOI 10.1016/j.eswa.2015.11.018
   Bloice MD, 2019, BIOINFORMATICS, V35, P4522, DOI 10.1093/bioinformatics/btz259
   Chen WH, 2018, FUTURE GENER COMP SY, V89, P78, DOI 10.1016/j.future.2018.06.021
   Chen Y, 2019, J VIS COMMUN IMAGE R, V58, P486, DOI 10.1016/j.jvcir.2018.11.044
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946
   Devries T, 2017, COMPUT VIS PATTERN R
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goebel R, 2018, LECT NOTES COMPUT SC, V11015, P295, DOI 10.1007/978-3-319-99740-7_21
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Meng ZB, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P217, DOI 10.1109/IRI.2017.57
   Nai K, 2019, KNOWLEDGE BASED SYST, V104789, P181
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salti S, 2015, PATTERN RECOGN, V48, P1039, DOI 10.1016/j.patcog.2014.05.017
   Sermanet P., 2014, INT C LEARN REPR
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang Y, 2016, IEEE T INTELL TRANSP, V17, P2022, DOI 10.1109/TITS.2015.2482461
   Zhong Z, 2017, COMPUT VIS PATTERN R
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 36
TC 30
Z9 31
U1 3
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18201
EP 18219
DI 10.1007/s11042-020-08722-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800042
DA 2024-07-18
ER

PT J
AU Murugan, R
   Roy, P
   Singh, U
AF Murugan, R.
   Roy, Parthapratim
   Singh, Utkarsh
TI An abnormality detection of retinal fundus images by deep convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retina; Diabetic retinopathy; Machine leaning; Deep learning;
   Convolutional neural network
ID DIABETIC MACULAR EDEMA; AUTOMATED DETECTION; OPTIC DISC; GLAUCOMA
   DETECTION; RETINOPATHY; DIAGNOSIS; CLASSIFICATION; SEGMENTATION;
   PHOTOGRAPHS; VALIDATION
AB Identification of retinal diseases is a test for the ophthalmologists as the anomalies are just unmistakable at the beginning period. Early detection of these diseases can avoid lasting vision misfortune. Dealing with a lot of retinal images and location of variations from the norm because of these infections is difficult just as tedious. In this work, the deep learning algorithm has proposed to check the abnormality condition of retina with the help of retinal fundus images. In deep leaning a training set is produced with features of variations from the norm present in the retinal images and the infection the retina is experiencing. The deep Convolutional Neural Network (CNN) classifier predicts the infection for every retinal images in the wake of social event the learning from training the set. The rightness of desire is resolved to evaluate the viability of the classifier. The proposed technique was executed in MATLAB and assessed both normal and abnormal diabetic retinopathy retinal images of IDRID, ROC, and local datasets. The proposed technique has gotten better execution measurements, for example, sensitivity of 98.2%, Specificity of 98.45%, accuracy of 98.56% and average area under receiver operating characteristics of 0.9 when contrasted with different conditions of the workmanship strategies.
C1 [Murugan, R.] Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
   [Roy, Parthapratim] Silchar Med Coll & Hosp, Dept Ophthalmol, Silchar 788014, Assam, India.
   [Singh, Utkarsh] LNM Inst Informat Technol, Dept Elect & Commun Engn, Jaipur 302031, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; LNM Institute of Information Technology
RP Murugan, R (corresponding author), Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM murugan.rmn@gmail.com
OI R, MURUGAN/0000-0002-9341-3810
CR Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Alghamdi A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P17
   [Anonymous], 2013, ARXIV13051052
   Arcadu F, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0172-3
   Aziza E.Z., 2019, 2019 6th International Conference on Image and Signal Processing and their Applications (ISPA). 2019 6th International Conference on Image and Signal Processing and their Applications (ISPA), P1, DOI DOI 10.1109/ISPA48434.2019.8966905
   Banerjee S, 2015, PROCEDIA COMPUT SCI, V46, P402, DOI 10.1016/j.procs.2015.02.037
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chai YD, 2018, KNOWL-BASED SYST, V161, P147, DOI 10.1016/j.knosys.2018.07.043
   Choi J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174407
   Chudzik P, 2018, IEEE ENG MED BIO, P770, DOI 10.1109/EMBC.2018.8512354
   Colas E, 2016, ACTA OPHTHALMOL, V94, DOI 10.1111/j.1755-3768.2016.0635
   Ferreira MVD, 2018, EXPERT SYST APPL, V110, P250, DOI 10.1016/j.eswa.2018.06.010
   El Abbadi NK, 2013, INT J COMPUT SCI, V10, P1
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Ghazal M, 2020, IEEE ACCESS, V8, P34387, DOI 10.1109/ACCESS.2020.2974158
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hatanaka Y, 2018, PROC INT WORKSH ADV
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Köse C, 2011, J MED BIOL ENG, V31, P395, DOI 10.5405/jmbe.724
   Larsen M, 2003, INVEST OPHTH VIS SCI, V44, P761, DOI 10.1167/iovs.02-0418
   Li F, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.4
   Lin GM, 2018, J OPHTHALMOL, V2018, DOI 10.1155/2018/2159702
   Mo J, 2018, NEUROCOMPUTING, V290, P161, DOI 10.1016/j.neucom.2018.02.035
   Niemeijer M, 2007, INVEST OPHTH VIS SCI, V48, P2260, DOI 10.1167/iovs.06-0996
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Rakhlin A, 2018, DIABETIC RETINOPATHY
   Raman V, 2016, I C COMM SOFTW NET, P636, DOI 10.1109/ICCSN.2016.7586601
   Raumviboonsuk P, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0099-8
   Rekhi RS, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P482, DOI 10.1109/UPCON.2017.8251096
   Rekhi RS, 2017, 2017 INT C WORKSH BI, P1, DOI [10.1109/IWOBI.2017.7985527, DOI 10.1109/IWOBI.2017.7985527]
   Roy Chowdhury Amrita, 2017, CSI Transactions on ICT, V5, P71, DOI 10.1007/s40012-016-0132-x
   Sahlsten J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47181-w
   Salam AA, 2017, 2017 INTERNATIONAL CONFERENCE ON SIGNALS AND SYSTEMS (ICSIGSYS), P227, DOI 10.1109/ICSIGSYS.2017.7967046
   Sathananthavathi V, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P89, DOI 10.1109/ICICCT.2017.7975165
   Sengar N, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P412, DOI 10.1109/TSP.2015.7296294
   Shah P, 2020, INDIAN J OPHTHALMOL, V68, P398, DOI 10.4103/ijo.IJO_966_19
   Simard PY, 2003, PROC INT CONF DOC, P958
   SOPHARAK A., 2008, International Conference on Embedded Systems and Intelligent Technology, P139, DOI DOI 10.1109/CBMS.2012.6266341
   Srinivasan PP, 2014, BIOMED OPT EXPRESS, V5, P3568, DOI 10.1364/BOE.5.003568
   Takahashi H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179790
   Tymchenko B, 2020, ICPRAM: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P501, DOI 10.5220/0008970805010509
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Yamuna T, 2013, INT C TREND COMPUT C, P236, DOI 10.1109/ICE-CCN.2013.6528500
   Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326
   Yu X, 2004, ABNORMALITY DETECTIO
   Zahoor MN, 2017, IEEE ACCESS, V5, P12293, DOI 10.1109/ACCESS.2017.2723320
   Zilly Julian G., 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P136, DOI 10.1007/978-3-319-24888-2_17
NR 55
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24949
EP 24967
DI 10.1007/s11042-020-09217-6
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615300001
DA 2024-07-18
ER

PT J
AU Abd El-Moneim, S
   Nassar, MA
   Dessouky, MI
   Ismail, NA
   El-Fishawy, AS
   Abd El-Samie, FE
AF Abd El-Moneim, Samia
   Nassar, M. A.
   Dessouky, Moawad I.
   Ismail, Nabil A.
   El-Fishawy, Adel S.
   Abd El-Samie, Fathi E.
TI Text-independent speaker recognition using LSTM-RNN and speech
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; MFCCs; Spectrum; Log-spectrum; LSTM-RNN;
   Reverberation; Speech enhancement
ID CLASSIFICATION
AB Speaker recognition revolution has lead to the inclusion of speaker recognition modules in several commercial products. Most published algorithms for speaker recognition focus on text-dependent speaker recognition. In contrast, text-independent speaker recognition is more advantageous as the client can talk freely to the system. In this paper, text-independent speaker recognition is considered in the presence of some degradation effects such as noise and reverberation. Mel-Frequency Cepstral Coefficients (MFCCs), spectrum and log-spectrum are used for feature extraction from the speech signals. These features are processed with the Long-Short Term Memory Recurrent Neural Network (LSTM-RNN) as a classification tool to complete the speaker recognition task. The network learns to recognize the speakers efficiently in a text-independent manner, when the recording circumstances are the same. The recognition rate reaches 95.33% using MFCCs, while it is increased to 98.7% when using spectrum or log-spectrum. However, the system has some challenges to recognize speakers from different recording environments. Hence, different speech enhancement techniques, such as spectral subtraction and wavelet denoising, are used to improve the recognition performance to some extent. The proposed approach shows superiority, when compared to the algorithm of R. Togneri and D. Pullella (2011).
C1 [Abd El-Moneim, Samia] Tanta High Inst Engn & Technol, Dept Elect Commun, Tanta, Egypt.
   [Nassar, M. A.; Dessouky, Moawad I.; El-Fishawy, Adel S.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Ismail, Nabil A.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University; Princess Nourah bint Abdulrahman
   University
RP Abd El-Moneim, S (corresponding author), Tanta High Inst Engn & Technol, Dept Elect Commun, Tanta, Egypt.
EM semsemkab@yahoo.com; nassar54@yahoo.com; dr_moawad@yahoo.com;
   Nabil.Ismail@el-eng.menofia.edu.eg; aelfishawy@hotmail.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; Nassar, Mohamed/IQW-5116-2023; Ismail,
   Nabil/AAV-4721-2021
OI Sayed, Fathi/0000-0001-8749-9518; Ismail, Nabil/0000-0001-7818-2631;
   El-Fishawy, Adel/0000-0003-1567-457X
CR Abd El-Samie FE, 2011, SPRINGER BRIEFS ELEC
   Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Bhattacharya G., 2016, ODYSSEY, V2016, P9
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Das A., 2014, Digit. Technol., V1, P1, DOI DOI 10.12691/DT-1-1-1
   Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380
   Evans NWD, 2005, IEEE EUR SIGN PROC C
   Gish H, 1994, IEEE SIGNAL PROC MAG, V11, P18, DOI 10.1109/79.317924
   Gonzalez-Dominguez J., 2014, P INT 2014 SING 1418, P2155, DOI DOI 10.21437/INTERSPEECH.2014-483
   Kaladharan N., 2014, Int J Comput Applic, V96, P45, DOI [10.5120/16858-6739, DOI 10.5120/16858-6739]
   Karam M., 2014, Journal of Signal and Information Processing, V5, P32
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kumari VSR, 2013, INT J ENG TRENDS TEC, V5, P107
   LARSSON J, 2014, THESIS
   Li KP, 1983, APPROACH TEXT INDEPE, P555
   Mihov S.G., 2009, Annual Journal of Electronics
   Nilufar S, 2012, INT CONF ACOUST SPEE, P501, DOI 10.1109/ICASSP.2012.6287926
   Parada PP, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P567, DOI 10.1109/GlobalSIP.2014.7032181
   Sant'Ana R, 2006, IEEE T AUDIO SPEECH, V14, P931, DOI 10.1109/TSA.2005.858054
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Sharma A, 2005, IEEE INT S SIGN PROC
   Togneri R, 2011, IEEE CIRC SYST MAG, V11, P23, DOI 10.1109/MCAS.2011.941079
   Yegnanarayana B, 2000, IEEE T SPEECH AUDI P, V8, P267, DOI 10.1109/89.841209
   Zazo R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146917
NR 24
TC 25
Z9 26
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24013
EP 24028
DI 10.1007/s11042-019-08293-7
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100002
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Kassem, MA
   Foaud, MM
AF Hosny, Khalid M.
   Kassem, Mohamed A.
   Foaud, Mohamed M.
TI Skin melanoma classification using ROI and data augmentation with deep
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin Cancer; Melanoma; Classification; DCNN; SVM; GoogleNet
ID IMAGES; SYSTEM
AB Automatic classification of color images of skin helps clinicians and dermatologists in examining and investigating skin melanoma. In this paper, a new deep convolutional neural network-based classification method is proposed. The proposed method consists of three main steps. First, the input color images of skin are preprocessed where the region of interest (ROI) are segmented. Second, the segmented ROI images are augmented using rotation and translation transformations. Third, different deep convolutional neural network (DCNN) architectures such as Alex-net, ResNet101, and GoogleNet are utilized. The last three layers are dropped out and replaced with new layers to be more appropriate with the task of lesion classification. The performance of the proposed method has been evaluated using three different datasets, MED-NODE, DermIS & DermQuest and ISIC 2017. The proposed DCNN have fine-tuned and trained using 85%, tested and verified using 15% of the overall datasets. The proposed method significantly improved the classification process especially with modified GoogleNet where the classification accuracy was 99.29%, 99.15%, and 98.14% for MED-NODE, DermIS & DermQuest, and ISIC 2017 respectively.
C1 [Hosny, Khalid M.] Zagazig Univ, Dept Informat Technol, Fac Comp & Informat, Zagazig 44519, Egypt.
   [Kassem, Mohamed A.] Kafrelshiekh Univ, Dept Robot & Intelligent Machines, Fac Artificial Intelligence, Kafrelshiekh 33511, Egypt.
   [Foaud, Mohamed M.] Zagazig Univ, Fac Engn, Dept Elect & Commun, Zagazig 44519, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Kafrelsheikh University; Egyptian Knowledge Bank (EKB);
   Zagazig University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Fac Comp & Informat, Zagazig 44519, Egypt.
EM k_hosny@yahoo.com; cs.engineer.mohamed.1987@gmail.com
RI Kassem, Mohamed A/AAF-3990-2019; Hosny, Khalid M./B-1404-2008; Kassem,
   Mohamed/JFS-7681-2023
OI Kassem, Mohamed A/0000-0002-5150-5004; Hosny, Khalid
   M./0000-0001-8065-8977; Kassem, Mohamed/0000-0003-2778-0089
CR Almarashi Jamal Q. M., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534125
   Amelard R, 2012, IEEE ENG MED BIO, P4458, DOI 10.1109/EMBC.2012.6346956
   [Anonymous], 2017, Convolutional Neural Networks
   Arifin M. S., 2012, IEEE INT C MACHINE L, V5, P1675
   Azulay RD, 2015, DERMATOLOGIA
   Basavaprasad B, 2015, PROCEDIA COMPUT SCI, V45, P328, DOI 10.1016/j.procs.2015.03.153
   Bastanfard A, 2006, GRAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P313
   Brinker TJ, 2019, EUR J CANCER, V111, P148, DOI 10.1016/j.ejca.2019.02.005
   Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Cavalcanti P.G., 2013, Color Medical Image Analysis, P15, DOI [10.1007/978-94-007-5389-1_2, DOI 10.1007/978-94-007-5389-1_2]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang WY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076212
   Codella N.C.F., 2017, SKIN LES AN MEL DET
   Das N, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P208, DOI 10.1109/ICACC.2013.48
   Esteva A, 2015, PROJECT REPORT
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Goodfellow I., 2016, DEEP LEARNING UNPUB
   Grube M, 2009, 2009 3RD INTERNATIONAL CONFERENCE ON SIGNALS, CIRCUITS AND SYSTEMS (SCS 2009), P135
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hosny KM, 2019, PLOS ONE, V14, P1
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jafari MH, 2016, IEEE ENG MED BIO, P1357, DOI 10.1109/EMBC.2016.7590959
   Karabulut EM, 2016, ANN INT C INT COMP C, V2
   Khalid S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3211-4
   Kostopoulos SA, 2017, INT J MED INFORM, V105, P1, DOI 10.1016/j.ijmedinf.2017.05.016
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao TF, 2015, RETHINK ASIA INT REL, P1
   Maglogiannis I, 2009, IEEE T INF TECHNOL B, V13, P721, DOI 10.1109/TITB.2009.2017529
   Majtner T, 2019, MULTIMED TOOLS APPL, V78, P11883, DOI 10.1007/s11042-018-6734-6
   Moura N, 2019, MULTIMED TOOLS APPL, V78, P6869, DOI 10.1007/s11042-018-6404-8
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Navarro F, 2019, IEEE J BIOMED HEALTH, V23, P501, DOI 10.1109/JBHI.2018.2825251
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pham TC, 2018, LECT NOTES COMPUTER, V10752, P573
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Prusa Joseph D., 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0065-8
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Stojanovic M, 2014, VOJNOSANIT PREGL, V71, P1062, DOI 10.2298/VSP1411062S
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
NR 50
TC 45
Z9 46
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24029
EP 24055
DI 10.1007/s11042-020-09067-2
EA JUN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100003
DA 2024-07-18
ER

PT J
AU Chu, CH
AF Chu, Chung-Hua
TI Efficient digital holographic 3d human image reconstruction and
   improvement on mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital holographic image reconstruction; Mobile devices; Image
   restoration; Hologram
ID DECONVOLUTION; RECOGNITION; DISPLAY
AB Advanced digital holography attracts a lot of attentions for 3D visualization nowadays. The representation of high-resolution digital holographic 3D human images suffers from computational inefficiency on the mobile devices due to the limited hardware for digital holographic processing. Specifically, to reconstruct the high-quality holographic image needs to compensate for the phase aberration, which needs lots of expensive optical hardware components to acquire measurements such as different axial distances, illumination angles, wavelengths, polarization states, and so on. To reduce computational complexity in digital holographic 3D human image reconstruction, we propose an efficient and effective algorithm to simplify Fresnel transforms for the mobile devices. Our algorithm reduces the number of FFTs and fastens the calculation of the exponential function in the Fresnel integral for the digital holography image reconstruction. Specifically, we reformulate the Fresnel integral and use a polynomial approximation to approximate the exponential function. In the holographic image quality improvement, we modify a maximum a posteriori (MAP) estimation to improve the quality of the reconstructed holographic 3D image restoration. Our algorithm outperforms previous approaches in not only smaller running time but also the better quality of the digital holographic 3D human image representation for the mobile devices.
C1 [Chu, Chung-Hua] Natl Taichung Univ Sci & Technol, Dept Multimedia Design, Taichung, Taiwan.
C3 National Taichung University of Science & Technology
RP Chu, CH (corresponding author), Natl Taichung Univ Sci & Technol, Dept Multimedia Design, Taichung, Taiwan.
EM chchu@gm.nutc.edu.tw
CR Ahrenberg L, 2009, J DISP TECHNOL, V5, P111, DOI 10.1109/JDT.2009.2013159
   [Anonymous], 1980, Software Manual for the Elementary Functions
   [Anonymous], 2015, Microsoft Hololens
   Bruckstein AM, 1998, IEEE T IMAGE PROCESS, V7 of 11
   Chan CH, 2012, IEEE IMAGE PROC, P1989, DOI 10.1109/ICIP.2012.6467278
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Cheng C-J, 2014, J DISPLAY TECHNOLOGY, V10 of 4
   Cuche E, 2000, APPL OPTICS, V39, P4070, DOI 10.1364/AO.39.004070
   DEMETRAKOPOULOS TH, 1974, APPL OPTICS, V13, P665, DOI 10.1364/AO.13.000665
   Domingo Mery DF, 2000, 15 WORLD C NOND TEST
   Driggers RG, 2003, ENCY OPTICAL ENG ABE, P412
   Ferraro P, 2004, OPT LETT, V29, P854, DOI 10.1364/OL.29.000854
   Fukuoka T, 2016, J DISP TECHNOL, V12, P315, DOI 10.1109/JDT.2015.2479646
   GABOR D, 1948, NATURE, V161, P777, DOI 10.1038/161777a0
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Goodman J. W., 2005, INTRO FOURIER OPTICS, DOI DOI 10.1117/1.601121
   Hong HY, 2003, OPT ENG, V42, P3471, DOI 10.1117/1.1621409
   Huang HC, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105683
   Imbe M, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.4.044102
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Kantabutra V, 1996, IEEE T COMPUTERS, V45 of 3
   Kim S.-C, 2008, APPL OPTICS, V47 of 19
   Kreis TM, 1997, P SPIE, V3098
   Latychevskaia T, 2013, OPT EXPRESS, V21, P7726, DOI 10.1364/OE.21.007726
   Lauterborn W, 2003, ADV TEXTS PHYS
   Lefèvre V, 2008, LECT NOTES COMPUT SC, V5045, P114, DOI 10.1007/978-3-540-85521-7_7
   Liu SJ, 2019, OPT COMMUN, V436, P253, DOI 10.1016/j.optcom.2018.12.038
   Lucente M, 1993, J ELECT IMAGING, V2 of 1
   Masuda N, 2006, OPT EXPRESS, V14, P603, DOI 10.1364/OPEX.14.000603
   Mohammad Tofighi KK, 2014, DENOISING USING PROJ
   Muller J.-M., 1997, ELEMENTARY FUNCTIONS
   Nishitsuji T, 2011, OSA TECH DIG
   OK E, 2006, DIFFRACTION FOURIER
   Pandey N, 2009, P SPIE, V7442
   Paturzo M, 2010, OPT EXPRESS, V18, P8806, DOI 10.1364/OE.18.008806
   Prasad S, 2002, J OPT SOC AM A, V19, P1286, DOI 10.1364/JOSAA.19.001286
   Ren ZB, 2019, IEEE T IND INFORM, V15, P6179, DOI 10.1109/TII.2019.2913853
   Ren ZB, 2019, ADV PHOTONICS, V1, DOI 10.1117/1.AP.1.1.016004
   Rivenson Y, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0196-0
   Roberto Corda CP, 2019, 11 INT C QUAL MULT E
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   Shuqun Zhang JZ, INT C NAT COMP
   TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V151, P501
   Tsang PWM, 2012, OPT EXPRESS, V20, P5962, DOI 10.1364/OE.20.005962
   Uddin MS, 2011, J SCI ENG, V2, P35
   Uzan A, SPECKLE DENOISING DI, V52
   Wang Z, 2019, OPT EXPRESS, V27, P2689, DOI 10.1364/OE.27.002689
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao F, 2009, DIGITAL PHOTOGRAPHY, V7250, P72500
   Yagle AE, 2003, P SOC PHOTO-OPT INS, V5205, P390, DOI 10.1117/12.504466
   Yitzhaky Y, 1997, GRAPH MODEL IM PROC, V59, P310, DOI 10.1006/gmip.1997.0435
   Zhang FC, 2004, OPT LETT, V29, P1668, DOI 10.1364/OL.29.001668
NR 56
TC 1
Z9 1
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23935
EP 23955
DI 10.1007/s11042-020-09089-w
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540671300003
DA 2024-07-18
ER

PT J
AU Rajput, SS
   Arya, KV
AF Rajput, Shyam Singh
   Arya, K. V.
TI A robust face super-resolution algorithm and its application in
   low-resolution face recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-resolution face recognition; Super-resolution; Noisy face images;
   Functional-interpolation; Dictionary or Training based models
ID IMAGE INTERPOLATION; HALLUCINATION; REGRESSION
AB In real-world surveillance scenario, the face recognition (FR) systems pose a lot of challenges due to the captured low-resolution (LR) and noisy probe images. A new face super-resolution (SR) algorithm is proposed to design a recognition model overcoming the challenges of existing FR systems. The proposed SR algorithm inherits the merits of functional-interpolation and dictionary-based SR techniques. The functional interpolation assists in generating more discriminable output, whereas the dictionary-based approach assists in eliminating noise effects from the reconstruction process. Consequently, it produces more discriminable and noise-free high-resolution (HR) images from captured noisy LR probe images, suitable for real-world problems like low-resolution face recognition. The results obtained from the experiments performed on several popular face image datasets including FEI, FERET, and CAS-PEAL-R1 show that the proposed algorithm performs better than all the comparative SR methods.
C1 [Rajput, Shyam Singh] Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
   [Arya, K. V.] ABV Indian Inst Informat Technol & Management, Gwalior 474015, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; ABV-Indian Institute of Information Technology &
   Management, Gwalior
RP Rajput, SS (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM ershyamrajput@gmail.com; kvarya@iiitm.ac.in
RI Rajput, Shyam Singh/AAU-4448-2020
OI Rajput, Shyam Singh/0000-0002-1244-7366
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chu YJ, 2017, SIGNAL PROCESS, V141, P144, DOI 10.1016/j.sigpro.2017.05.012
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Hennings-Yeomans PH, 2008, PROC CVPR IEEE, P3637
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jiang JJ, 2017, IEEE INT CON MULTI, P469, DOI 10.1109/ICME.2017.8019459
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2016, INT CONF ACOUST SPEE, P2089, DOI 10.1109/ICASSP.2016.7472045
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiang JJ, 2014, SIGNAL PROCESS, V103, P168, DOI 10.1016/j.sigpro.2014.02.014
   Jiang JJ, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041120
   Nguyen K, 2018, PATTERN RECOGN, V78, P23, DOI 10.1016/j.patcog.2018.01.002
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LIU L, 2017, IEEE T CYBERNETICS, V18, P1189
   Liu LC, 2017, IEEE T CYBERNETICS, V47, P600, DOI 10.1109/TCYB.2016.2521428
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Neves J, 2016, ARTIF INTELL REV, V46, P515, DOI 10.1007/s10462-016-9474-x
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Rajput Shyam Singh, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P252, DOI 10.1109/TBIOM.2019.2939808
   Rajput Shyam Singh, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P635, DOI 10.1007/978-981-13-1135-2_48
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   RAJPUT SS, 2018, APPL INTELLIGENCE
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xing R, 2014, INT C INTEL HUM MACH, P67, DOI 10.1109/IHMSC.2014.119
   Xing XL, 2016, SIGNAL PROCESS, V125, P329, DOI 10.1016/j.sigpro.2016.02.009
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang X, 2008, PROC CVPR IEEE, P117
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 52
TC 16
Z9 16
U1 8
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23909
EP 23934
DI 10.1007/s11042-020-09072-5
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540407000001
DA 2024-07-18
ER

PT J
AU Chen, XL
   Zhang, XX
   Xie, HR
   Tao, XH
   Wang, F
   Xie, NF
   Hao, TY
AF Chen, Xieling
   Zhang, Xinxin
   Xie, Haoran
   Tao, Xiaohui
   Wang, Fu Lee
   Xie, Nengfu
   Hao, Tianyong
TI A bibliometric and visual analysis of artificial intelligence
   technologies-enhanced brain MRI research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance imaging; Artificial intelligence; Latent Dirichlet
   allocation; Research topics
ID MILD COGNITIVE IMPAIRMENT; MAGNETIC-RESONANCE IMAGE; FUNCTIONAL NETWORK;
   PATTERN-RECOGNITION; FMRI DATA; CLASSIFICATION; SEGMENTATION; SINGLE;
   DIAGNOSIS; DISORDER
AB With the advances and development of imaging and computer technologies, the application of artificial intelligence (AI) in the processing of magnetic resonance imaging (MRI) data has become a significant research field. Based on 2572 research articles concerning AI-enhanced brain MRI processing, this study provides a latent Dirichlet allocation based bibliometric analysis for the exploration of the status, trends, major research issues, and potential future directions of the research field. The trend analyses of articles and citations demonstrate a flourishing and increasing impact of the research.Neuroimageis the most prolific and influential journal. The USA andUniversity College Londonhave contributed the most to the research. The collaboration between European countries is very close. Essential research issues such asImage segmentation,Mental disorder,Functional network connectivity, andAlzheimer's diseasehave been uncovered. Potential inter-topic research directions such asFunctional network connectivityandMental disorder,Image segmentationandImage classification,Cognitive impairmentandDiffusion imaging, as well asSense and memoryandEmotion and feedback, have been highlighted.
C1 [Chen, Xieling] Educ Univ Hong Kong, Dept Math & Informat Technol, Hong Kong, Peoples R China.
   [Zhang, Xinxin] South China Normal Univ, Inst Brain Res & Rehabil, Guangzhou, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.
   [Tao, Xiaohui] Univ Southern Queensland, Sch Sci, Toowoomba, Qld, Australia.
   [Wang, Fu Lee] Open Univ Hong Kong, Sch Sci & Technol, Hong Kong, Peoples R China.
   [Xie, Nengfu] Chinese Acad Agr Sci, Inst Agr Informat, Beijing, Peoples R China.
   [Hao, Tianyong] South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
C3 Education University of Hong Kong (EdUHK); South China Normal
   University; Lingnan University; University of Southern Queensland; Hong
   Kong Metropolitan University; Chinese Academy of Agricultural Sciences;
   South China Normal University
RP Hao, TY (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
EM haoty@m.scnu.edu.cn
RI Xie, Haoran/AAW-8845-2020; tao, xiaohui/KCK-2677-2024; Tao,
   Xiaohui/JKI-2330-2023; Wang, Fu Lee/AAD-9782-2021; Xie,
   Haoran/AFS-3515-2022; Hao, Tianyong/HJH-2742-2023
OI Wang, Fu Lee/0000-0002-3976-0053; Xie, Haoran/0000-0003-0965-3617; Hao,
   Tianyong/0000-0002-9792-3949; PV, THAYYIB/0000-0001-8929-0398
CR Agirre-Arrizubieta Z, 2009, BRAIN, V132, P3060, DOI 10.1093/brain/awp137
   Ahmadvand A, 2015, APPL MATH COMPUT, V256, P808, DOI 10.1016/j.amc.2015.01.053
   Algunaid RF, 2018, BIOMED SIGNAL PROCES, V43, P289, DOI 10.1016/j.bspc.2018.02.018
   Allen EA, 2014, CEREB CORTEX, V24, P663, DOI 10.1093/cercor/bhs352
   Altameem T, 2015, CONNECT SCI, V27, P305, DOI 10.1080/09540091.2014.970126
   Andersson P, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/045004
   Bae Y, 2018, J DIGIT IMAGING, V31, P252, DOI 10.1007/s10278-017-0020-4
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Baldauf D, 2014, SCIENCE, V344, P424, DOI 10.1126/science.1247003
   Bastian M., 2009, P INT AAAI C WEBL SO, V3, P361
   Bhuvaneswari KS, 2017, J EXP THEOR ARTIF IN, V29, P663, DOI 10.1080/0952813X.2016.1212106
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bollmann S, 2019, NEUROIMAGE, V195, P373, DOI 10.1016/j.neuroimage.2019.03.060
   Brambilla P, 2003, BRAIN RES BULL, V61, P557, DOI 10.1016/j.brainresbull.2003.06.001
   Cabezas M, 2011, COMPUT METH PROG BIO, V104, pE158, DOI 10.1016/j.cmpb.2011.07.015
   Cabral C, 2016, SCHIZOPHRENIA BULL, V42, pS110, DOI 10.1093/schbul/sbw053
   Cai CB, 2018, MAGN RESON MED, V80, P2202, DOI 10.1002/mrm.27205
   Cai KP, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170875
   Cao M, 2017, CEREB CORTEX, V27, P1949, DOI 10.1093/cercor/bhw038
   Chen MS, 2017, COMPUT ASSIST SURG, V22, P200, DOI 10.1080/24699322.2017.1389398
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Chen X, 2019, INT WORKSH HUM BRAIN, P69
   Chen XD, 2020, J ASIAN NAT PROD RES, V22, P1024, DOI 10.1080/10286020.2019.1680646
   Chen X, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103855
   Chen XL, 2020, BRIT J EDUC TECHNOL, V51, P692, DOI 10.1111/bjet.12907
   Chen XL, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0757-4
   Chen XL, 2019, ONLINE INFORM REV, V43, P29, DOI 10.1108/OIR-03-2018-0068
   Chen XL, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0692-9
   Chen XL, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/1827074
   Chen XL, 2018, BMC MED INFORM DECIS, V18, DOI [10.1186/s12870-018-1555-3, 10.1186/s12911-018-0594-x]
   Chen YC, 2020, NEUROIMAGE, V207, DOI 10.1016/j.neuroimage.2019.116389
   Chen YP, 2015, MOL NEURODEGENER, V10, DOI 10.1186/1750-1326-10-4
   Cheng B, 2017, NEUROINFORMATICS, V15, P115, DOI 10.1007/s12021-016-9318-5
   Cheng H, 2015, SCHIZOPHR RES, V168, P345, DOI 10.1016/j.schres.2015.08.011
   Cherubini A, 2014, MOVEMENT DISORD, V29, P266, DOI 10.1002/mds.25737
   Chong CD, 2017, CEPHALALGIA, V37, P828, DOI 10.1177/0333102416652091
   Codari M, 2019, AM J ROENTGENOL, V212, P280, DOI 10.2214/AJR.18.20389
   Deraeve J, 2018, NEUROINFORMATICS, V16, P253, DOI 10.1007/s12021-018-9371-3
   Di Plinio S, 2018, HUM BRAIN MAPP, V39, P4689, DOI 10.1002/hbm.24315
   Diekhof EK, 2016, NEUROPSYCHOLOGIA, V84, P70, DOI 10.1016/j.neuropsychologia.2015.10.016
   Duchesne S, 2009, NEUROIMAGE, V47, P1363, DOI 10.1016/j.neuroimage.2009.04.023
   Ecker C, 2010, NEUROIMAGE, V49, P44, DOI 10.1016/j.neuroimage.2009.08.024
   Eklund A, 2017, NEUROIMAGE, V155, P354, DOI 10.1016/j.neuroimage.2017.04.069
   Falkai P, 2018, DIALOGUES CLIN NEURO, V20, P179
   Fang DB, 2018, LIBR HI TECH, V36, P400, DOI 10.1108/LHT-06-2017-0132
   Feis RA, 2018, NEUROIMAGE-CLIN, V20, P188, DOI 10.1016/j.nicl.2018.07.014
   Focke NK, 2011, HUM BRAIN MAPP, V32, P1905, DOI 10.1002/hbm.21161
   Fukuma R, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00478
   Gao LL, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1903-6
   Ge Y, 2006, AM J NEURORADIOL, V27, P1165
   Ghosh P, 2018, J VIS COMMUN IMAGE R, V54, P63, DOI 10.1016/j.jvcir.2018.04.007
   Giger ML, 2018, J AM COLL RADIOL, V15, P512, DOI 10.1016/j.jacr.2017.12.028
   Goubran M, 2020, HUM BRAIN MAPP, V41, P291, DOI 10.1002/hbm.24811
   Grossman M, 2010, CURR OPIN NEUROL, V23, P643, DOI 10.1097/WCO.0b013e32833fd540
   Gunning-Dixon FM, 2009, INT J GERIATR PSYCH, V24, P109, DOI 10.1002/gps.2087
   Guo H, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00639
   Hacker CD, 2013, NEUROIMAGE, V82, P616, DOI 10.1016/j.neuroimage.2013.05.108
   Han X, 2007, IEEE T MED IMAGING, V26, P479, DOI 10.1109/TMI.2007.893282
   Hao TY, 2018, SOFT COMPUT, V22, P7875, DOI 10.1007/s00500-018-3511-4
   Harris LN, 2016, J CLIN ONCOL, V34, P1134, DOI 10.1200/JCO.2015.65.2289
   Hart H, 2014, J AM ACAD CHILD PSY, V53, P569, DOI 10.1016/j.jaac.2013.12.024
   Heinzel A, 2012, J NUCL MED, V53, P552, DOI 10.2967/jnumed.111.097352
   Henkelman RM, 2001, NMR BIOMED, V14, P57, DOI 10.1002/nbm.683
   Hill D, 2010, EXPERT OPIN INV DRUG, V19, P23, DOI 10.1517/13543780903381320
   Hoexter MQ, 2013, J AFFECT DISORDERS, V150, P1213, DOI 10.1016/j.jad.2013.05.041
   HUANG M, 2017, SCI REP-UK, V7, P1, DOI [DOI 10.1038/SREP39880, DOI 10.1038/S41598-016-0028-X]
   Iqbal A, 2018, IEEE T BIO-MED ENG, V65, P2519, DOI 10.1109/TBME.2018.2806958
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Jha D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/9060124
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Jiang RK, 2019, IEEE ACCESS, V7, P23579, DOI 10.1109/ACCESS.2019.2899990
   Jie B, 2015, HUM BRAIN MAPP, V36, P489, DOI 10.1002/hbm.22642
   Jin CF, 2017, HUM BRAIN MAPP, V38, P4479, DOI 10.1002/hbm.23676
   Jin W, 2017, J MED IMAG HEALTH IN, V7, P400, DOI 10.1166/jmihi.2017.2028
   Johnston BA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132958
   Jung RE, 2010, HUM BRAIN MAPP, V31, P398, DOI 10.1002/hbm.20874
   Karimaghaloo Z, 2012, IEEE T MED IMAGING, V31, P1181, DOI 10.1109/TMI.2012.2186639
   Khatami M, 2017, PATTERN RECOGN, V63, P593, DOI 10.1016/j.patcog.2016.09.020
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Koush Y, 2017, NEUROIMAGE, V156, P489, DOI 10.1016/j.neuroimage.2017.06.039
   Kumar M, 2017, NEUROIMAGE, V155, P422, DOI 10.1016/j.neuroimage.2017.03.037
   Lenglet C, 2009, NEUROIMAGE, V45, pS111, DOI 10.1016/j.neuroimage.2008.10.054
   Li R, 2013, PLOS ONE
   Li Y, 2020, NEUROCOMPUTING, V379, P370, DOI 10.1016/j.neucom.2019.10.085
   Li ZC, 2018, EUR RADIOL, V28, P3640, DOI 10.1007/s00330-017-5302-1
   Lian QS, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107444
   Lim KY, 2018, EXPERT SYST APPL, V112, P288, DOI 10.1016/j.eswa.2018.06.041
   Lim L, 2013, PLOS ONE, V8, DOI [10.1371/journal.pone.0084487, 10.1371/journal.pone.0063660]
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Liu Y, 2018, KSII T INTERNET INF, V12, P4336, DOI 10.3837/tiis.2018.09.012
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lorenzetti V, 2009, J AFFECT DISORDERS, V117, P1, DOI 10.1016/j.jad.2008.11.021
   Mann HB, 1945, ECONOMETRICA, V13, P245, DOI 10.2307/1907187
   Miwa K, 2014, RADIAT ONCOL, V9, DOI 10.1186/1748-717X-9-181
   MOED HF, 1995, SCIENTOMETRICS, V33, P381, DOI 10.1007/BF02017338
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mwangi B, 2013, NEUROIMAGE, V75, P58, DOI 10.1016/j.neuroimage.2013.02.055
   Nieuwenhuis M, 2012, NEUROIMAGE, V61, P606, DOI 10.1016/j.neuroimage.2012.03.079
   Nomi JS, 2016, HUM BRAIN MAPP, V37, P1770, DOI 10.1002/hbm.23135
   Park H, 2013, NEUROSCI LETT, V550, P17, DOI 10.1016/j.neulet.2013.06.042
   Pereira S, 2016, J NEUROSCI METH, V270, P111, DOI 10.1016/j.jneumeth.2016.06.017
   Pesapane F, 2018, INSIGHTS IMAGING, V9, P745, DOI 10.1007/s13244-018-0645-y
   Ranlund S, 2018, NEUROIMAGE-CLIN, V20, P1026, DOI 10.1016/j.nicl.2018.10.008
   Rasero J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207385
   Rasoolinejad M, 2019, ARCH PEDIATR INFECT, V7, DOI 10.5812/pedinfect.80318
   Reichert C, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00116
   Rovira A, 2009, ARCH NEUROL-CHICAGO, V66, P587, DOI 10.1001/archneurol.2009.49
   Rubin-Falcone H, 2018, J AFFECT DISORDERS, V227, P498, DOI 10.1016/j.jad.2017.11.043
   Saladi S, 2018, INT J IMAG SYST TECH, V28, P207, DOI 10.1002/ima.22271
   Serpa MH, 2014, BIOMED RES INT-UK, V2014, DOI 10.1155/2014/706157
   Shenton ME, 2001, SCHIZOPHR RES, V49, P1, DOI 10.1016/S0920-9964(01)00163-3
   Sheth D, 2020, J MAGN RESON IMAGING, V51, P1310, DOI 10.1002/jmri.26878
   Shi F, 2010, NEUROIMAGE, V49, P391, DOI 10.1016/j.neuroimage.2009.07.066
   Soch J, 2016, NEUROIMAGE, V141, P469, DOI 10.1016/j.neuroimage.2016.07.047
   Song Y, 2019, COMPUT EDUC, V137, P12, DOI 10.1016/j.compedu.2019.04.002
   Stamile C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156405
   Szilágyi L, 2012, COMPUT METH PROG BIO, V108, P80, DOI 10.1016/j.cmpb.2012.01.005
   Tian Dan, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P686, DOI 10.1109/ICBBE.2007.179
   Tredinnick L., 2017, Business Information Review, V34, P37
   Valli I, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00052
   Wallace GL, 2013, BRAIN, V136, P1956, DOI 10.1093/brain/awt106
   Wang J, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00166
   Wang L, 2012, J AFFECT DISORDERS, V142, P6, DOI 10.1016/j.jad.2012.04.013
   Wang PY, 2016, J ALZHEIMERS DIS, V54, P359, DOI 10.3233/JAD-160102
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Wang WX, 2018, ELECTRON COMMER R A, V29, P142, DOI 10.1016/j.elerap.2018.04.003
   Wei HJ, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116064
   Wise T, 2018, ACTA PSYCHIAT SCAND, V138, P73, DOI 10.1111/acps.12887
   Wolz R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025446
   Wu GR, 2015, NEUROIMAGE, V106, P34, DOI 10.1016/j.neuroimage.2014.11.025
   Wu JW, 2017, BRAIN, V140, P344, DOI 10.1093/brain/aww328
   Wu X, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00061
   Wu Y, 2013, J DIGIT IMAGING, V26, P786, DOI 10.1007/s10278-012-9568-1
   Yin XB, 2017, J ELECTROCERAM, V39, P210, DOI 10.1007/s10832-017-0083-0
   Zang WK, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120964
   Zhan Y, 2015, J ALZHEIMERS DIS, V47, P1057, DOI 10.3233/JAD-142820
   Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
   Zhang JN, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00152
   Zhang J, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3956536
   Zhang S, 2019, MED IMAGE ANAL, V54, P238, DOI 10.1016/j.media.2019.03.011
   Zhang T, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418570057
   Zhang T, 2014, NEUROCOMPUTING, V134, P122, DOI 10.1016/j.neucom.2012.12.081
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2015, INT J GYNECOL CANCER, V25, P4, DOI 10.1097/IGC.0000000000000314
   Zia R, 2018, INT J IMAG SYST TECH, V28, P153, DOI 10.1002/ima.22266
NR 146
TC 10
Z9 11
U1 7
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17335
EP 17363
DI 10.1007/s11042-020-09062-7
EA JUN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000539519200002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU El Ogri, O
   Daoui, A
   Yamni, M
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF El Ogri, O.
   Daoui, A.
   Yamni, M.
   Karmouni, H.
   Sayyouri, M.
   Qjidaa, H.
TI New set of fractional-order generalized Laguerre moment invariants for
   pattern recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional-order generalized Laguerre polynomials; Fractional-order
   moment invariants; Fast and accurate computation; Pattern recognition
ID JACOBI-FOURIER MOMENTS; IMAGE-ANALYSIS; FAST COMPUTATION; ZERNIKE
   MOMENTS; EFFICIENT
AB This article presents a new series of invariant moments, called Fractional-order Generalized Laguerre Moment Invariants (FGLMI), based on Fractional-order Generalized Laguerre polynomials (FGLPs). To begin, we provide the relations and the properties necessary to define the fractional-order generalized Laguerre moments. Then, we present the theoretical framework to derive invariants from fractional-order moments with respect to the change in orientation, size and position based on the algebraic relationships between FGLM and fractional-order geometric moments. In addition, a fast and precise algorithm has been proposed for the calculation of FGLM in order to speed up the calculation time and ensure the numerical stability of the invariant moments. Numerical experiments are carried out to demonstrate the efficiency of FGLM and their proposed invariants compared to existing methods, with regard to the reconstruction of 2D and 3D images, the computation time, the global entity extraction capacity and image localization, invariability property and 2D / 3D image classification performance on different 2D and 3D image databases. The theoretical and experimental results presented clearly show the efficiency of the descriptors proposed for the representation and classification of 2D and 3D images by other types of orthogonal moments.
C1 [El Ogri, O.; Yamni, M.; Karmouni, H.; Qjidaa, H.] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
   [Daoui, A.; Sayyouri, M.] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, My Abdallah Ave Km 5 Imouzzer Rd,72 BP, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Ogri, O (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
EM omar.elogri@usmba.ac.ma; achraf.daoui@usmba.ac.ma;
   mohamed.yamni@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Ogri, Omar El/AFC-5868-2022; Karmouni, Hicham/ACB-0232-2022; Yamni,
   Mohamed/AAD-8740-2022; DAOUI, Achraf/AAE-7012-2022; Sayyouri,
   Mhamed/AAB-5496-2020
OI Ogri, Omar El/0000-0003-4807-0641; Karmouni, Hicham/0000-0001-9225-8380;
   DAOUI, Achraf/0000-0002-2326-9550; Sayyouri, Mhamed/0000-0002-1615-419X;
   Hassan, qjidaa/0000-0003-4505-5243; Yamni, Mohamed/0000-0002-9436-8361
CR Asli BHS, 2014, INFORM SCIENCES, V288, P73, DOI 10.1016/j.ins.2014.07.046
   Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Bhrawy AH, 2016, APPL MATH MODEL, V40, P832, DOI 10.1016/j.apm.2015.06.012
   Bhrawy A, 2016, MATH METHOD APPL SCI, V39, P1765, DOI 10.1002/mma.3600
   Bhrawy AH, 2014, FRACT CALC APPL ANAL, V17, P1137, DOI 10.2478/s13540-014-0218-9
   Bolourchi P, 2017, SIGNAL IMAGE VIDEO P, V11, P1033, DOI 10.1007/s11760-017-1054-2
   Camacho-Bello C, 2014, J OPT SOC AM A, V31, P124, DOI 10.1364/JOSAA.31.000124
   Chen BJ, 2019, MULTIMED TOOLS APPL, V78, P8057, DOI 10.1007/s11042-018-6595-z
   Chen BJ, 2018, IEEE ACCESS, V6, P56637, DOI 10.1109/ACCESS.2018.2871952
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   El Ogri O, 2019, PROCEDIA COMPUT SCI, V148, P428, DOI 10.1016/j.procs.2019.01.055
   Fan D.-P., 2019, ARXIV190706781
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   Hosny KM, 2007, PATTERN RECOGN, V40, P3597, DOI 10.1016/j.patcog.2007.04.014
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   HOSNY KM, 2017, J REAL-TIME IMAGE PR, P1
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jahid T, 2018, MULTIMED TOOLS APPL, V77, P19811, DOI 10.1007/s11042-017-5371-9
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Kaur Parminder, 2018, International Journal of Computer Mathematics: Computer Systems Theory, V3, P64, DOI 10.1080/23799927.2018.1457080
   Kaur P, 2019, NEURAL COMPUT APPL, V31, P8749, DOI 10.1007/s00521-018-3939-6
   Kazem S, 2013, APPL MATH MODEL, V37, P5498, DOI 10.1016/j.apm.2012.10.026
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   KOEKOEK R, 1993, SIAM J MATH ANAL, V24, P768, DOI 10.1137/0524047
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Mennesson J, 2014, PATTERN RECOGN LETT, V40, P27, DOI 10.1016/j.patrec.2013.12.014
   Mohammadi F, 2016, ADV DIFFER EQU-NY, DOI 10.1186/s13662-016-0989-x
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nevai Paul, 1994, LINEAR COMPLEX ANAL, V3, P177
   Pandey VK, 2018, MULTIDIM SYST SIGN P, V29, P1529, DOI 10.1007/s11045-017-0516-6
   Parand K, 2017, TBIL MATH J, V10, P31, DOI 10.1515/tmj-2017-0004
   Parand K, 2016, RIC MAT, V65, P307, DOI 10.1007/s11587-016-0291-y
   PRATAMA SF, 2016, INNOVATIONS BIOINSPI, P347, DOI DOI 10.1007/978-3-319-28031-8_30
   Sayyouri M, 2019, J REAL TIME IMAGE PR, P1
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Singh C, 2014, DIGIT SIGNAL PROCESS, V27, P95, DOI 10.1016/j.dsp.2013.12.004
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Upneja R, 2015, PATTERN RECOGN, V48, P1836, DOI 10.1016/j.patcog.2014.11.012
   Xia T, 2007, J OPT SOC AM A, V24, P50, DOI 10.1364/JOSAA.24.000050
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Yang B, 2017, SIGNAL PROCESS, V132, P77, DOI 10.1016/j.sigpro.2016.09.013
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   YANG M, 2018, APPL SCI BASEL, V8
   Zhang HQ, 2016, COMM COM INF SC, V662, P766, DOI 10.1007/978-981-10-3002-4_62
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 57
TC 24
Z9 24
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23261
EP 23294
DI 10.1007/s11042-020-09084-1
EA JUN 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977700003
DA 2024-07-18
ER

PT J
AU Jahangir, S
   Shah, T
AF Jahangir, Saria
   Shah, Tariq
TI Designing S-boxes triplet over a finite chain ring and its application
   in RGB image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-box; Finite chain ring; Submodule; Group of units; Nonlinearity and
   RGB image encryption
ID CRYPTANALYSIS
AB In this article, we have developed an encryption technique to encrypt any kind of digital information. The main work is to construct the component of the block ciphers namely the substitution boxes (S-boxes) over an algebraic structure of finite chain ring; and then use these S-boxes in image encryption applications. The present formation is based on the finite commutative chain ring R-9 = DOUBLE-STRUCK CAPITAL Z(2) + uDOUBLE-STRUCK CAPITAL Z(2) + horizontal ellipsis + u(k - 1)DOUBLE-STRUCK CAPITAL Z(2) (module over itself) which is exactly twice of 256. The multiplicative group of unit elements of R-9 precisely has 256 elements and the set of all nonunit elements in R-9 forms a submodule of module R-9 consisting of 256 elements. By using this point we initiate a new 8 x 8 S-box triplet generation technique which addresses the group of units of R-9 and the submodule of R-9. This new construction technique of S-boxes ensures random values in the area of the initial domain of transformation. The proposed S-boxes have been examined by algebraic, statistical and texture analyses. A comparison of the expected and existing S-boxes reveals that the proposed S-boxes are comparatively better and can be used in the well known ciphers. Another goal of this work is to suggest an encryption technique for colored (RGB) images based on permutation keys and triplet of newly generated S-boxes. The outcomes of the security, statistical and the differential analyses have proved that our scheme is better for the image encryption.
C1 [Jahangir, Saria; Shah, Tariq] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Jahangir, S (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM saira156@gmail.com; stariqshah@gmail.com
RI Jahnagir, Saira/GZK-4935-2022
OI Jahangir, Saira/0000-0002-8595-3622
CR Altaleb A, 2017, AIP ADV, V7, DOI 10.1063/1.4978264
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   BIHAM E, 1991, LECT NOTES COMPUT SC, V537, P2
   Crama Y., 2011, Boolean Functions: Theory, Algorithms, and Applications
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   DETOMBE J, 1992, LECT NOTES COMPUTER
   Feng D, 2000, DESIGN ANAL BLOCK CI
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HELLESETH T, 1978, IEEE T INFORM THEORY, V24, P627, DOI 10.1109/TIT.1978.1055928
   HOU XD, 2007, COMMUTATIVE CHAIN RI
   Hussain I., 2011, WORLD APPL SCI J, V14, P1779
   Hussain I, 2011, P PAKISTAN ACAD SCI, V48, P111
   Hussain I., 2010, Int. J. Contemp. Math. Sci., V5, P1263
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Jamal SS, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0125-z
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   KHANNA VK, 1998, COURSE ABSTRACT ALGE
   Kim J, 2009, CRYPTOLOGIA, V33, P246, DOI 10.1080/01611190802653228
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P10227, DOI 10.1007/s11042-018-6586-0
   Liu LY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122650
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   ROTHAUS OS, 1976, J COMB THEORY A, V20, P300, DOI 10.1016/0097-3165(76)90024-8
   Shah Dawood, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P38, DOI 10.1109/ICAEM.2018.8536281
   Shah T., 2011, STAT ANAL S BOX IMAG, V6, P4110
   Shah T, 2017, COMPUT APPL MATH, V36, P843, DOI 10.1007/s40314-015-0265-9
   SHAHZAD I, 2019, SECURITY COMMUNICATI
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   WANG X, 2018, APPL SCI BASEL, V8
   Wang Y, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501278
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yi X, 1997, GLOB TELECOMM CONF, P689, DOI 10.1109/GLOCOM.1997.638418
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
NR 35
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26885
EP 26911
DI 10.1007/s11042-020-08995-3
EA JUN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000538196300002
DA 2024-07-18
ER

PT J
AU Baykal, E
   Dogan, H
   Ercin, ME
   Ersoz, S
   Ekinci, M
AF Baykal, Elif
   Dogan, Hulya
   Ercin, Mustafa Emre
   Ersoz, Safak
   Ekinci, Murat
TI Modern convolutional object detectors for nuclei detection on pleural
   effusion cytology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pleural effusion; Cytology; Nuclei detection; Convolutional neural
   networks; Convolutional object detectors
AB Nuclei detection is a crucial step in the cell-based analysis of a wide range of pathological images. It is also the basis of many automated methods such as cell counting, segmentation, and tracking. Nevertheless, it is seen as a challenging task because the nuclei display variability of size, shape, orientation and intensity and number of nuclei. In recent years, a variety of Convolutional Neural Network (CNN) based object detectors have been proposed. Although these methods have demonstrated superior success in different object detection problems, they have not yet been used for nuclei detection on pathology images. The main contributions of this work are: 1) We propose the first implementation of the faster region-based convolutional neural network (Faster R-CNN), the region-based fully convolutional network (R-FCN), and the single shot multibox detector (SSD) methods for nuclei detection on pathology images. These methods are viewed as 'modern convolutional object detectors'. 2) We present a novel database of pleural effusion cytology images. We used proposed object detectors with different 'feature extractors' such as Residual Network (ResNet), Inception v2, and MobileNet for performance comparison. Experiments show that all these object detectors using different feature extractors achieve remarkable detection speed and accuracy.
C1 [Baykal, Elif; Dogan, Hulya; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
   [Ercin, Mustafa Emre; Ersoz, Safak] Karadeniz Tech Univ, Dept Pathol, TR-61080 Trabzon, Turkey.
   [Ercin, Mustafa Emre; Ersoz, Safak] Karadeniz Tech Univ, Fac Med, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University; Karadeniz Technical University;
   Karadeniz Technical University
RP Baykal, E (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM ebaykal@ktu.edu.tr; hulya@ktu.edu.tr; drmustafaemreercin@ktu.edu.tr;
   sersoz@ktu.edu.tr; ekinci@ktu.edu.tr
RI Ercin, Mustafa Emre/AAU-6389-2020; Dogan, Hulya/AAW-9173-2021; Kablan,
   Elif Baykal/AAS-4282-2020; Baykal Kablan, Elif/JCP-1902-2023; Baykal
   Kablan, Elif/JVO-0310-2024; Ekinci, Murat/A-9653-2012; ersöz,
   safak/AAM-9041-2021
OI Ercin, Mustafa Emre/0000-0002-7340-8045; Baykal Kablan,
   Elif/0000-0003-3552-638X; Baykal Kablan, Elif/0000-0003-3552-638X; 
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Baykal E, 2017, P 25 SIGN PROC COMM, P1
   Cakir E, 2009, DIAGN CYTOPATHOL, V37, P4, DOI 10.1002/dc.20938
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Dai KJ, 2016, OBJECT DETECTION VIA
   Davidson B, 2011, DIAGNOSIS PROGNOSIS
   DeBiasi EM, 2015, EUR RESPIR J, V46, P495, DOI 10.1183/09031936.00217114
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG JT, 2017, IEEE ICC
   Irshad Humayun, 2013, J Pathol Inform, V4, pS12, DOI 10.4103/2153-3539.109870
   Kashif MN, 2016, I S BIOMED IMAGING, P1029, DOI 10.1109/ISBI.2016.7493441
   Lezoray O, 2003, MACH VISION APPL, V14, P166, DOI 10.1007/s00138-002-0120-z
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Malekmehr D, 2018, CALIFORNIA PLEURAL E
   MAREL M, 1993, CHEST, V104, P1486, DOI 10.1378/chest.104.5.1486
   Mufidah R., 2017, P INT C ALG COMP SYS, P9
   Normalization B, 2015, ACCELERATING DEEP NE
   Öz SD, 2018, FLORENCE NIGHTINGALE, V26, P1, DOI 10.26650/FNJN.387142
   Paliy I, 2010, LECT NOTES COMPUT SC, V6352, P521, DOI 10.1007/978-3-642-15819-3_68
   Papanicolaou G. N., 1942, Science, V95, P438, DOI 10.1126/science.95.2469.438
   Rathod V., 2017, Tensorflow detection model zoo
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schneider TE, 2007, PROC SPIE, V6514, DOI 10.1117/12.710355
   Sheaff MT, 2012, CYTOPATHOLOGY INTRO
   SHEPPARD CJR, 1978, OPT LETT, V3, P115, DOI 10.1364/OL.3.000115
   Shidham VB., 2007, Cytopathologic diagnosis of serous fluids, V1st
   SHOTTON DM, 1989, J CELL SCI, V94, P175
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Song TH, 2017, I S BIOMED IMAGING, P1040, DOI 10.1109/ISBI.2017.7950694
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   Xie YP, 2018, MED IMAGE ANAL, V44, P245, DOI 10.1016/j.media.2017.07.003
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
NR 43
TC 7
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15417
EP 15436
DI 10.1007/s11042-019-7461-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900059
DA 2024-07-18
ER

PT J
AU Ou, WH
   Xuan, RS
   Gou, JP
   Zhou, Q
   Cao, YF
AF Ou, Weihua
   Xuan, Ruisheng
   Gou, Jianping
   Zhou, Quan
   Cao, Yongfeng
TI Semantic consistent adversarial cross-modal retrieval exploiting
   semantic similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Semantic consistency; Semantic similarity; Common
   representation; Adversarial learning
ID CAROTID-ARTERY WALL; SPACE; REPRESENTATION; IMAGES
AB Cross-modal retrieval aims to search the semantically similar instances from the other modalities given a query from one modality. However, the differences of the distributions and representations between different modalities make that the similarity of different modalities can not be measured directly. To address this problem, in this paper, we propose a novel semantic consistent adversarial cross-modal retrieval (SC-ACMR), which learns semantic consistent representation for different modalities under adversarial learning framework by considering the semantic similarity from intra-modality and inter-modality. Specifically, for intra-modality, we minimize the intra-class distances. For the inter-modality, we require class center of different modalities with same semantic label to be as close as possible, and also minimize the distances between the samples and the class center with same semantic label from different modalities. Furthermore, we preserve the semantic similarity of transformed features of different modalities through a semantic similarity matrix. Comprehensive experiments on two benchmark datasets are conducted and the experimental results show that the proposed method have learned more compact semantic representations and achieved better performance than many existing methods in cross-modal retrieval.
C1 [Ou, Weihua; Xuan, Ruisheng; Cao, Yongfeng] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Peoples R China.
   [Gou, Jianping] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Zhou, Quan] Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Nanjing, Peoples R China.
   [Zhou, Quan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Guizhou Normal University; Jiangsu University; Nanjing University of
   Posts & Telecommunications; Nanjing University
RP Ou, WH (corresponding author), Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Peoples R China.
EM ouweihuahust@gmail.com
RI Ou, Weihua/T-9156-2019; Gou, Jianping/JQX-2453-2023
OI Ou, Weihua/0000-0001-5241-7703; Gou, Jianping/0000-0003-1413-0693
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2011, P ICML
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Dong SJ, 2018, INT SYM COMPUT INTEL, P3, DOI 10.1109/ISCID.2018.10102
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao ZF, 2018, IEEE T MED IMAGING, V37, P273, DOI 10.1109/TMI.2017.2746879
   Gao ZF, 2017, MED IMAGE ANAL, V37, P1, DOI 10.1016/j.media.2017.01.004
   Gong MM, 2016, PR MACH LEARN RES, V48
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   Hua Y, 2016, VISUAL COMMUNICATION, P1
   Huang X, 2020, IEEE T CYBERNETICS, V50, P1047, DOI 10.1109/TCYB.2018.2879846
   Jiang XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P69, DOI 10.1145/2733373.2806240
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Peng Y, 2019, ACM T MULTIM COMPUT, DOI DOI 10.1145/3284750
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Srivastava Neelam., 2012, The Postcolonial Gramsci, P1
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xi Z, 2017, ARXIV171109347
   Xu T, 2016, IEEE T MULTIMEDIA, V18, P208, DOI [10.1109/TMM.2015.2508146, DOI 10.1109/TMM.2015.2508146]
   Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang J, 2020, IEEE T CYBERNETICS, V50, P489, DOI 10.1109/TCYB.2018.2868826
NR 52
TC 10
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14733
EP 14750
DI 10.1007/s11042-019-7343-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900024
DA 2024-07-18
ER

PT J
AU Aloysius, N
   Geetha, M
AF Aloysius, Neena
   Geetha, M.
TI Understanding vision-based continuous sign language recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous sign language; Vision-based; Movement epenthesis; Review
ID HIDDEN MARKOV-MODELS; FRAMEWORK; HAND; COARTICULATION; MOVEMENT
AB Real-time sign language translation systems, that convert continuous sign sequences to text/speech, will facilitate communication between the deaf-mute community and the normal hearing majority. A translation system could be vision-based or sensor-based, depending on the type of input it receives. To date, most of the commercial systems for this purpose are sensor-based, which are expensive and not user-friendly. Vision-based sign translation systems are the need of the hour but should overcome many challenges to build a full-fledged working system. Preliminary investigations in this work have revealed that the traditional approaches to continuous sign language recognition (CSLR) using HMM, CRF and DTW, tried to solve the problem of Isolated Sign Language Recognition (ISLR) and extended the solution to CSLR, leading to reduced performance. The main challenge of identifying Movement Epenthesis (ME) segments in continuous utterances, were handled explicitly with these traditional methods. With the advent of technologies like Deep Learning, more feasible solutions for vision-based CSLR are emerging, which has led to an increase in the research on vision-based approaches. In this paper, a detailed review of all the works in vision-based CSLR is presented, based on the methods they have followed. The challenges posed in continuous sign recognition are also discussed in detail, followed by a brief on sensor-based systems and benchmark databases. Finally, performance evaluation of all the associated methods are performed, which leads to a short discussion on the overall study and concludes by pointing out future research directions in the field.
C1 [Aloysius, Neena; Geetha, M.] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amrita Sch Engn, Amritapuri, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri
RP Aloysius, N (corresponding author), Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amrita Sch Engn, Amritapuri, India.
EM neenaloysius@ymail.com; geetham@am.amrita.edu
RI M, Geetha/ABF-7809-2021; aloysius, neena/ABC-3918-2021
OI aloysius, neena/0000-0002-3212-6607
CR Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   [Anonymous], 2015, INT J MULT UBIQUITOU
   [Anonymous], 2010, EUROPEAN C COMPUTER
   Azoz Y, 2003, MACH VISION APPL, V13, P286, DOI 10.1007/s00138-002-0110-1
   Bengio Y., 1995, Advances in Neural Information Processing Systems 7, P553
   Bhuyan MK, 2006, LECT NOTES COMPUT SC, V4338, P564
   Billinghurst M., 1998, Computer Graphics, V32, P60, DOI 10.1145/307710.307730
   Bowden R, 2016, P 7 WORKSH REPR PROC, P121
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   BUNGEROTH J, 2008, ATIS SIGN LANGUAGE C, P2943
   Calin AD, 2016, INT SYMP SYMB NUMERI, P264, DOI [10.1109/SYNASC.2016.43, 10.1109/SYNASC.2016.049]
   Camgoz NC, 2017, IEEE I CONF COMP VIS, P3075, DOI 10.1109/ICCV.2017.332
   Camgoz NC, 2018, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2018.00812
   Choudhury A, 2017, J INTELL SYST, V26, P471, DOI 10.1515/jisys-2016-0009
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Crasborn O., 2008, TheCorpus NGT. An open access digital corpus of movies with annotations of Sign Language of theNetherlands
   Cui R, 2019, IEEE T MULTIMEDIA, VPP, P1
   Cui RP, 2017, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2017.175
   Dreuw P, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1115
   Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1911
   Forster J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785
   FOWLER CA, 1993, LANG SPEECH, V36, P171, DOI 10.1177/002383099303600304
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gao W, 2000, INT J PATTERN RECOGN, V14, P587, DOI 10.1142/S0218001400000386
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Geetha M, 2013, 2013 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN COMMUNICATION, CONTROL, SIGNAL PROCESSING AND COMPUTING APPLICATIONS (IEEE-C2SPCA-2013)
   Ghahramani Z, 1996, ADV NEUR IN, V8, P472
   Gonzalez AM, 2010, 17TH ESPRM EUROPEAN CONGRESS OF PHYSICAL AND REHABILITATION MEDICINE, P234
   Graf HP, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P88, DOI 10.1109/AFGR.1996.557248
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Guo D, 2018, AAAI CONF ARTIF INTE, P6845
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Han J, 2007, 5 INT C COMP VIS SYS
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   Hassan M, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0225-3
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holden EJ, 2005, MACH VISION APPL, V16, P312, DOI 10.1007/s00138-005-0003-1
   Huang J, 2018, 32 AAAI C ART INT
   Huang X. D., 1990, Hidden Markov Models for Speech Recognition
   Johnston T., 2007, AUSTR SIGN LANGUAGE
   Kendon Adam., 1988, CROSS CULTURAL PERSP
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Kong WW, 2014, PATTERN RECOGN, V47, P1294, DOI 10.1016/j.patcog.2013.09.014
   Kumar DA, 2018, MULTIMED TOOLS APPL, V77, P32063, DOI 10.1007/s11042-018-6199-7
   Kumar S, 2003, PROC CVPR IEEE, P119
   Kwolek B, 2019, 11 INT C MACH VIS IC, V11041
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Liang R.-H., 1997, Continuous Gesture Recognition System for Taiwanese Sign Language
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Liao YQ, 2019, IEEE ACCESS, V7, P38044, DOI 10.1109/ACCESS.2019.2904749
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liddell Scott K., 2003, Grammar, gesture, and meaning in American Sign Language
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Martínez AM, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P167, DOI 10.1109/ICMI.2002.1166987
   Masood Sarfaraz, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P623, DOI 10.1007/978-981-10-7566-7_63
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Molchanov P., 2016, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P4207, DOI DOI 10.1109/CVPR.2016.456
   Morency C, 2007, TRANSPORT RES REC, P1, DOI 10.3141/2002-01
   MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527
   Nag R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P2071
   Nakjai P, 2019, J SIGNAL PROCESS SYS, V91, P131, DOI 10.1007/s11265-018-1375-6
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pereira J, PEREIRA FCN CONDITIO
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Pitsikalis V., 2011, Computer Vision and Pattern Recognition Workshops, P1, DOI DOI 10.1109/CVPRW.2011.5981681
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sako Shinji, 2013, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8009, P548, DOI 10.1007/978-3-642-39188-0_59
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Shan C, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P669
   Smith P, 2007, IMAGE VISION COMPUT, V25, P1432, DOI 10.1016/j.imavis.2006.12.012
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063
   Sutton-Spence R, 1999, LINGUISTICS BRIT SIG
   Thapa V, 2019, ADV INTELL SYST, V740, P219, DOI 10.1007/978-981-13-1280-9_22
   Tolba MF, 2013, NEURAL COMPUT APPL, V23, P999, DOI 10.1007/s00521-012-1024-0
   Tomkins W., 1969, Indian sign language, V92
   Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741
   Vogler C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P116, DOI 10.1109/ICCV.1999.791206
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Von Agris U, 2008, 2008 19 INT C PATT R, P1, DOI DOI 10.1109/ICPR.2008.4761363
   Von Agris U., 2007, Gesture in Human-Computer Interaction and Simulation
   Wallach HM., 2004, TECHNICAL REPORTS CI, V24, P22
   Wang HJ, 2019, IEEE T MULTIMEDIA, V21, P2806, DOI 10.1109/TMM.2019.2915032
   Wang HJ, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2897735
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Warchol D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051078
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953
   Xiao QK, 2019, IEEE ACCESS, V7, P112258, DOI 10.1109/ACCESS.2019.2925654
   Xue QF, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091945
   Yang HD, 2010, PATTERN RECOGN, V43, P2858, DOI 10.1016/j.patcog.2010.03.007
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang RD, 2006, INT C PATT RECOG, P108
   Yang RD, 2010, IEEE T PATTERN ANAL, V32, P462, DOI 10.1109/TPAMI.2009.26
   Yang R, 2007, PROC CVPR IEEE, P3501
   Yang WW, 2016, PATTERN RECOGN LETT, V78, P28, DOI 10.1016/j.patrec.2016.03.030
   Yuan Q, 2002, INT C PATT RECOG, P75, DOI 10.1109/ICPR.2002.1044616
   Zadghorban M, 2018, PATTERN ANAL APPL, V21, P323, DOI 10.1007/s10044-016-0579-2
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zheng L, 2017, 2017 IEEE INNOVATIVE SMART GRID TECHNOLOGIES - ASIA (ISGT-ASIA), P38
NR 116
TC 29
Z9 29
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22177
EP 22209
DI 10.1007/s11042-020-08961-z
EA MAY 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533491800001
DA 2024-07-18
ER

PT J
AU Wang, ZZ
   Liu, DHS
   Lei, YH
   Niu, XK
   Wang, SW
   Shi, L
AF Wang, Zhizhong
   Liu, Donghaisheng
   Lei, Yuehui
   Niu, Xiaoke
   Wang, Songwei
   Shi, Li
TI Small target detection based on bird's visual information processing
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Small-target detection; Saliency
   algorithm; Super-resolution; Large fields of view
ID VEHICLE DETECTION; OBJECT DETECTION; MODULATION
AB Detecting small targets in large fields of view is a challenging task. Nowadays, many targets detection models based on the convolutional neural network (CNN) achieve excellent performance. However, these CNN-based detectors are inefficient when applied to tasks of real-time detection of small targets. This paper proposes a small-target detection model in large fields of view based on the tectofugal-thalamofugal-accessory optic system of birds. Within this model, first, we design an unsupervised saliency algorithm to generate saliency regions to suppress background information according to the visual information processing mechanism of the tectofugal pathway of birds. Second, we design a super-resolution (SR) analysis method to enlarge small targets and improve image resolution by the information processing mechanism of the accessory optic system of birds. Then, according to the information processing mechanism of the thalamofugal pathway, we propose a CNN-based method to detect small targets. We further test our model on two public datasets (the VEDAI dataset and DLR 3 K dataset), and the experimental results demonstrate that the proposed detection model outperforms the state-of-the-art methods on small-target detection.
C1 [Wang, Zhizhong; Liu, Donghaisheng; Lei, Yuehui; Niu, Xiaoke; Wang, Songwei] Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Peoples R China.
   [Shi, Li] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
C3 Zhengzhou University; Tsinghua University
RP Wang, ZZ (corresponding author), Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Peoples R China.
EM wzz1982@zzu.edu.cn; dhs.liu@outlook.com; wangsongwei@zzu.edu.cn;
   zzushi@126.com
OI Niu, Xiaoke/0000-0002-1249-4728
FU National Natural Science Foundation of China (NSFC) [61673353]; NSFC
   [61603344]; Key research projects of Henan colleges and Universities
   [15A120017]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) General program (61673353), Young Scientist Fund of NSFC
   (61603344) and Key research projects of Henan colleges and
   Universities(15A120017).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   ALEXEY AB, 2018, IMPROVE OBJECT DETEC
   [Anonymous], 1993, J Cogn Neurosci, V5, P373, DOI 10.1162/jocn.1993.5.3.373
   [Anonymous], COMPUT VIS PATTERN R
   BESSETTE BB, 1989, VISUAL NEUROSCI, V2, P27, DOI 10.1017/S0952523800004296
   Boehnke SE, 2008, CURR OPIN NEUROBIOL, V18, P544, DOI 10.1016/j.conb.2008.11.004
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Butler AB., 2005, COMP VERTEBRATE NEUR
   Cao YT, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010028
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Ewert JP, 2001, COMP BIOCHEM PHYS A, V128, P417, DOI 10.1016/S1095-6433(00)00333-0
   Fecteau JH, 2006, TRENDS COGN SCI, V10, P382, DOI 10.1016/j.tics.2006.06.011
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Ju MR, 2019, IEEE ACCESS, V7, P85771, DOI 10.1109/ACCESS.2019.2924960
   Khare M, 2014, IET IMAGE PROCESS, V8, P334, DOI 10.1049/iet-ipr.2012.0428
   Kong LF, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012138
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Ku J, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2018.00013
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li DW, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281589
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu G, 2012, IEEE INT C AUTOMAT L, P363, DOI 10.1109/ICAL.2012.6308220
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lou J, 2017, MULTIMED TOOLS APPL, V76, P14781, DOI 10.1007/s11042-016-4025-7
   Mandal M, 2019, IEEE IMAGE PROC, P3098, DOI 10.1109/icip.2019.8803262
   Mandt MJ, 2019, PREHOSP EMERG CARE, V23, P663, DOI 10.1080/10903127.2019.1566422
   Medina L, 2000, TRENDS NEUROSCI, V23, P1, DOI 10.1016/S0166-2236(99)01486-1
   Mysore SP, 2010, J NEUROSCI, V30, P1727, DOI 10.1523/JNEUROSCI.3740-09.2010
   Northmore D, 2011, ENCYCLOPEDIA OF FISH PHYSIOLOGY: FROM GENOME TO ENVIRONMENT, VOLS 1-3, P131
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Reiner A, 2005, ANAT REC PART A, V287A, P1080, DOI 10.1002/ar.a.20253
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Suganyadevi K, 2014, ENG APPL ARTIF INTEL, V28, P210, DOI 10.1016/j.engappai.2013.09.007
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang P, 2009, ELECTRON LETT, V45, P156, DOI 10.1049/el:20092206
   Yang MY, 2019, PHOTOGRAMM ENG REM S, V85, P297, DOI 10.14358/PERS.85.4.297
   Yang Y, 2008, NAT NEUROSCI, V11, P595, DOI 10.1038/nn.2107
   ZHONG JD, 2017, SENSORS BASEL, V17
NR 53
TC 4
Z9 4
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22083
EP 22105
DI 10.1007/s11042-020-08807-8
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533180600001
DA 2024-07-18
ER

EF